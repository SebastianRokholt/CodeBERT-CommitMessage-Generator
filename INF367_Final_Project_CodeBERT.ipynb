{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLwqR0yrwWPf"
   },
   "source": [
    "## INF367: Final Project\n",
    "# Fine-Tuning CodeBERT for Git Commit Message Generation\n",
    "---\n",
    "> by **Sebastian Einar Salas RÃ¸kholt**<br>\n",
    "> INF367 - Selected Topics for Artificial Intelligence: Language Processing <br>\n",
    "> Autumn 2022 <br>\n",
    "> The University of Bergen, Department for Informatics <br>\n",
    "\n",
    "---\n",
    "\n",
    "Project code repository available at [Github.com](https://github.com/SebastianRokholt/CodeBERT-CommitMessage-Generator)\n",
    "<br>\n",
    "\n",
    "**[Read the Project Report](#)**\n",
    "</br>\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [**Introduction**](#intro)<br>\n",
    "\n",
    "2. [**Inital Setup**](#setup)<br>\n",
    "\n",
    "3. [**Data Collection**](#collection)<br>\n",
    "\n",
    "4. [**Data Pre-processing**](#pre-processing)<br>\n",
    "\n",
    "5. [**Modelling**](#modelling)<br>\n",
    "    5.1       [*Architecture*](#architecture) <br>\n",
    "    5.2       [*Fine-tuning CodeBERT on Git diffs*](#fine-tune) <br>\n",
    "    5.3       [*Running predictions*](#pred) <br>\n",
    "\n",
    "6. [**Evaluation and Future Work**](#test-eval) <br>\n",
    "\n",
    "7. [**Credits and References**](#ref) <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"intro\"></a>1) Introduction\n",
    "\n",
    "The aim of this project is to extend the work on NL-PL language modelling proposed in [CodeBERT: A Pre-Trained Model for Programming and Natural Languages](https://arxiv.org/abs/2002.08155) (Feng et al, 2020) by reproducing and experimenting with the work proposed in [CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model](https://arxiv.org/abs/2105.14242) (Jung, 2021). \n",
    "\n",
    "The former of the two papers presented research on creating a large, pre-trained language model for natural language and programming language, with many possible downstream tasks such as code search, code repair, code completion, and code documentation generation. The latter of the two papers presents experiments on applying CodeBERT to code documentation generation, specifically an application for automatically generating commit messages. \n",
    "\n",
    "I will be attempting to experiment with the methodology proposed in the CommitBERT paper, and will hopefully be able to reproduce some of the results. It is important to note, however, that I have access to severely limited compute resources and will therefore not be able to reproduce a high-performance model. \n",
    "\n",
    "My primary goal with this project is to learn as much as I can about the methods proposed in the two papers. I want to achieve this goal by attempting to fine-tune a \"CommitBERT\"-style language model on a small dataset consisting of open source code repositories, including some of my own Github repositories. I hope that the resulting model will be able to capture some of my commit message writing style, though I obviously will need to fine-tune on many other repositories as well. \n",
    "\n",
    "Since I have resource and time constraint, I will not be doing all of the work from scratch. Specificaly, I will be downloading fine-tuned CodeBERT model weights to use as initial model weights before fine-tuning my own CodeBERT model on git diffs. The initial weights are retrieved from Tae-Hwan Jung's open source code for the CommitBERT paper. I will also be using a wide array of imported packages and tools, including Microsoft's CodeBERT training script from the original CodeBERT paper's code - though I have tweaked it somewhat in order to fit my machine learning pipeline. I have tried to give credit where credit is due, so that it is clear what code I have written myself and what I have imported from other libraries and projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM9A6cjr9Ekv"
   },
   "source": [
    "### Notebook Setup\n",
    "This notebook is designed to run in Google Colab. Fine-tuning the language model on a CPU is infeasible, so you may either skip these cells (and download the trained weights) or attempt to fine-tune the model with a GPU/TPU. I trained on an Nvidia A100 Tensor Core GPU, which was available through Google Colab Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nf02JDCYg3vd",
    "outputId": "22716322-29ee-4a94-9a5a-cd7b83cb9530"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "git clone https://github.com/SebastianRokholt/CodeBERT-CommitMessage-Generator.git\n",
    "cd codebert-commit-generator\n",
    "pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LreH3lfLGtY",
    "outputId": "a337276e-a804-4101-c376-78e91fb123de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 10:13:28 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   28C    P0    44W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Displaying the GPU setup for the notebook environment\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training on an A100 GPU, the Pytorch installation needs to be Cu111 compatible\n",
    "%%shell\n",
    "pip install -q torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v63CrlaXatVF",
    "outputId": "f3cd0396-c212-414f-845c-5f98c72253c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 17:31:27.720884: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-06 17:31:27.822276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-06 17:31:27.822291: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-06 17:31:27.843269: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-06 17:31:28.352815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-06 17:31:28.352866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-06 17:31:28.352873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Utility stuff\n",
    "import os\n",
    "import easydict \n",
    "import whatthepatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import (RobertaConfig, RobertaTokenizer)\n",
    "from greykode_commit.model import Seq2Seq\n",
    "from greykode_commit.utils import convert_examples_to_features\n",
    "from greykode_commit.model.diff_roberta import RobertaModel\n",
    "\n",
    "# Constants\n",
    "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaModel, RobertaTokenizer)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Github Repositories. \n",
    "I will try to collect git diffs from 50 repositories, where 4 of them are my own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories to crawl: ['SebastianRokholt/Data-Science-Projects', 'SebastianRokholt/Hybrid-Recommender-System', 'Jonnashell/info216-groupproject', 'SebastianRokholt/Soccer-Predictions', 'IBM/pytorch-seq2seq', 'tiangolo/fastapi', 'TheAlgorithms/Python', 'vinta/awesome-python', 'django/django', 'pallets/flask', 'httpie/httpie', 'josephmisiti/awesome-machine-learning', 'ansible/ansible', 'psf/requests', 'deepfakes/faceswap', 'apache/incubator-superset', 'XX-net/XX-Net', 'pandas-dev/pandas', 'satwikkansal/wtfpython', 'pypa/pipenv', 'donnemartin/interactive-coding-challenges', 'mitmproxy/mitmproxy', 'donnemartin/data-science-ipython-notebooks', 'tornadoweb/tornado', 'chubin/cheat.sh', 'trailofbits/algo', 'geekcomputers/Python', 'encode/django-rest-framework', 'apache/airflow', 'matterport/Mask_RCNN', 'swisskyrepo/PayloadsAllTheThings', 'yunjey/pytorch-tutorial', 'sqlmapproject/sqlmap', 'psf/black', 'keon/algorithms', 'google/python-fire', 'explosion/spaCy', 'drduh/macOS-Security-and-Privacy-Guide', 'nicolargo/glances', 'sebastianruder/NLP-progress', 'StevenBlack/hosts', 'celery/celery', 'magenta/magenta', 'gto76/python-cheatsheet', 'reddit-archive/reddit', 'numpy/numpy', 'sherlock-project/sherlock', 'charlax/professional-programming', 'pytorch/examples', 'openai/gpt-2']\n",
      "Progress: 1 out of 50 downloaded. \n",
      "Progress: 2 out of 50 downloaded. \n",
      "Progress: 3 out of 50 downloaded. \n",
      "Progress: 4 out of 50 downloaded. \n",
      "Progress: 5 out of 50 downloaded. \n",
      "Progress: 6 out of 50 downloaded. \n",
      "Progress: 7 out of 50 downloaded. \n",
      "Progress: 8 out of 50 downloaded. \n",
      "Progress: 9 out of 50 downloaded. \n",
      "Progress: 10 out of 50 downloaded. \n",
      "Progress: 11 out of 50 downloaded. \n",
      "Progress: 12 out of 50 downloaded. \n",
      "Progress: 13 out of 50 downloaded. \n",
      "Progress: 14 out of 50 downloaded. \n",
      "Progress: 15 out of 50 downloaded. \n",
      "Progress: 16 out of 50 downloaded. \n",
      "Progress: 17 out of 50 downloaded. \n",
      "Progress: 18 out of 50 downloaded. \n",
      "Progress: 19 out of 50 downloaded. \n",
      "Progress: 20 out of 50 downloaded. \n",
      "Progress: 21 out of 50 downloaded. \n",
      "Progress: 22 out of 50 downloaded. \n",
      "Progress: 23 out of 50 downloaded. \n",
      "Progress: 24 out of 50 downloaded. \n",
      "Progress: 25 out of 50 downloaded. \n",
      "Progress: 26 out of 50 downloaded. \n",
      "Progress: 27 out of 50 downloaded. \n",
      "Progress: 28 out of 50 downloaded. \n",
      "Progress: 29 out of 50 downloaded. \n",
      "Progress: 30 out of 50 downloaded. \n",
      "Progress: 31 out of 50 downloaded. \n",
      "Progress: 32 out of 50 downloaded. \n",
      "Progress: 33 out of 50 downloaded. \n",
      "Progress: 34 out of 50 downloaded. \n",
      "Progress: 35 out of 50 downloaded. \n",
      "Progress: 36 out of 50 downloaded. \n",
      "Progress: 37 out of 50 downloaded. \n",
      "Progress: 38 out of 50 downloaded. \n",
      "Progress: 39 out of 50 downloaded. \n",
      "Progress: 40 out of 50 downloaded. \n",
      "Progress: 41 out of 50 downloaded. \n",
      "Progress: 42 out of 50 downloaded. \n",
      "Progress: 43 out of 50 downloaded. \n",
      "Progress: 44 out of 50 downloaded. \n",
      "Progress: 45 out of 50 downloaded. \n",
      "Progress: 46 out of 50 downloaded. \n",
      "Progress: 47 out of 50 downloaded. \n",
      "Progress: 48 out of 50 downloaded. \n",
      "Progress: 49 out of 50 downloaded. \n",
      "Progress: 50 out of 50 downloaded. \n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "import git\n",
    "from time import sleep\n",
    "import os\n",
    "from threading import Thread\n",
    "\n",
    "class RepoScraper():\n",
    "    \"\"\"\n",
    "    A class for \"Scraping\" Git Repositories, i.e. downloading by git cloning them to the specified download path.\n",
    "    \"\"\"\n",
    "    def __init__(self, repositories, download_path):\n",
    "        \"\"\"\n",
    "        :param repositories: The total number of Github repositories to be downloaded\n",
    "        :param download_path: The path to the directory for downloading all of the scraped repositories\n",
    "        \"\"\"\n",
    "        self.queue = Queue()  # data structure for scraping repos\n",
    "        self.count = 0  # keeps track of progress\n",
    "        self.total_n_repos = len(repositories)\n",
    "        self.download_path = download_path\n",
    "\n",
    "        # Multithreading with 16 threads.\n",
    "        # NB! More threads => higher memory usage\n",
    "        for _ in range(16):\n",
    "            _thread = Thread(target=self.cloner)\n",
    "            _thread.daemon = True\n",
    "            _thread.start()\n",
    "\n",
    "    def clone_repos(self, repo_gh_file_path):\n",
    "        \"\"\"\n",
    "        :param repo_gh_file_path: The file path to the Github repository, e.g: SebastianRokholt/CodeBERT-CommitMessage-Generator\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Clone repo to download dir\n",
    "            git.Repo.clone_from(\n",
    "                f'https://:@github.com/{repo_gh_file_path}.git',\n",
    "                f'{self.download_path}/{repo_gh_file_path}'\n",
    "            )\n",
    "\n",
    "            sleep(0.2)  # Trying to avoid blacklisting due to high page request frequency\n",
    "\n",
    "            self.count += 1 \n",
    "            print(f\"Progress: {self.count} out of {self.total_n_repos} downloaded. \")\n",
    "        \n",
    "        # Very basic error handling\n",
    "        except git.exc.GitError as e:\n",
    "            print(f\"The following error occurred while attempting to clone repository from https://:@github.com/{repo_gh_file_path}.git: \")\n",
    "            print(e)\n",
    "\n",
    "    def cloner(self):\n",
    "        \"\"\"\n",
    "        Runs the crawling method (clone_repos) on the repositories according to the crawl queue. \n",
    "        Called by the multithreading daemon. \n",
    "        Terminates when the crawl queue is empty. \n",
    "        \"\"\"\n",
    "        while True:\n",
    "            repo_file_path = self.queue.get()  # Retrieves the next repo from the queue\n",
    "            self.clone_repos(repo_file_path)  # Runs the crawling method on the repo\n",
    "            self.queue.task_done()  # Registers the task (crawling the repo) as completed\n",
    "\n",
    "    def join_queue(self):\n",
    "        \"\"\"\n",
    "        Blocks until all repos in the crawl queue have been gotten and processed.\n",
    "        Unblocks when count of unfinished tasks drops to zero.\n",
    "        \"\"\"\n",
    "        self.queue.join()\n",
    "\n",
    "    def put_queue(self, repo_file_path):\n",
    "        \"\"\"\n",
    "        Puts a repo into the crawl queue. \n",
    "        \"\"\"\n",
    "        self.queue.put(repo_file_path)\n",
    "        \n",
    "\n",
    "download_path=\"data/raw/python\"\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Read the repositories to crawl from file\n",
    "repositories = []\n",
    "with open(\"repositories/python-50.txt\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        repositories.append(line.replace('https://github.com/', ''))\n",
    "print(\"Repositories to crawl:\", repositories)\n",
    "\n",
    "# Instantiate the repo scraper\n",
    "scraper = RepoScraper(repositories=set(repositories), download_path=download_path)\n",
    "\n",
    "# Start scraping\n",
    "for repo in repositories:\n",
    "    # Put each repo in the crawl queue\n",
    "    scraper.put_queue(repo)\n",
    "scraper.join_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I used Tae-Hwang Jung's pre-processing algorithm (CommitBERT paper page 4) \n",
    "# and parsing script (gitparser.py) as a starting point and guide:\n",
    "# https://github.com/graykode/commit-autosuggestions/blob/master/gitparser.py\n",
    "# See the project report for details about which changes I made, and why. \n",
    "\n",
    "# IMPORTS\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import jsonlines\n",
    "import spacy\n",
    "import errno\n",
    "from pydriller import RepositoryMining\n",
    "from transformers import RobertaTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "# CONSTANTS\n",
    "repositories=\"repositories/python-50.txt\"\n",
    "repos_dir=\"data/raw/python\"\n",
    "output_dir=\"data/parsed/python\"\n",
    "output_file = os.path.join(output_dir, 'dataset.jsonl')\n",
    "cb_tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# LANGUAGE DETECTION\n",
    "@Language.factory(\"language_detector\")\n",
    "def create_language_detector(nlp, name):\n",
    "    return LanguageDetector(language_detection_function=None)\n",
    "\n",
    "detect_lang = spacy.load(\"en_core_web_sm\")\n",
    "detect_lang.add_pipe('language_detector')\n",
    "english_not_detected = []\n",
    "\n",
    "\n",
    "# GENERAL FUNCTIONS\n",
    "def process_commits(repos_dir, repo, codebert_tokenize=\"code_only\"):\n",
    "    \"\"\"\n",
    "    Pre-processes commit messages in a repo.\n",
    "    Tokenizes the commit messages and the diff code for each commit in a repository. \n",
    "    Determines whether diff code has been added or deleted.\n",
    "\n",
    "    :param repo: A pre-downloaded Git repository to process.\n",
    "    :param codebert_tokenize: Specifies whether to tokenize the message text and/or code in the commit message. \n",
    "                     Set to \"all\" (default), \"code_only\" or None. \n",
    "    \"\"\"\n",
    "    repo_path = os.path.join(repos_dir, repo)\n",
    "    # Basic error handling for input params\n",
    "    if codebert_tokenize not in [\"code_only\", \"all\", None]:\n",
    "        raise Exception(\"Input parameter codebert_tokenize must be 'code_only', 'all' or None. \")\n",
    "    if not os.path.exists(repo_path):\n",
    "        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), repo_path)\n",
    "\n",
    "    # Loops over all commits in the repository (Python code only)\n",
    "    for commit in RepositoryMining(repo_path, only_modifications_with_file_types=\"py\").traverse_commits():\n",
    "        # Get the commit message text\n",
    "        msg = commit.msg.split(\"\\n\")[0]\n",
    "        # Remove unecessary characters from the message\n",
    "        cleaned_msg = re.sub(r\"(\\(|)#([0-9])+(\\)|)\", \"\", msg)\n",
    "        # Only keep commits with commit messages in English\n",
    "        langdetect_result = detect_lang(cleaned_msg)._.language\n",
    "        if langdetect_result[\"language\"] != \"en\":\n",
    "            english_not_detected.append(cleaned_msg)\n",
    "            continue\n",
    "        # Tokenizing the commit message text\n",
    "        if codebert_tokenize == \"all\":\n",
    "            # Tokenize the commit message with a CodeBERT tokenizer\n",
    "            msg_tokens = cb_tokenizer.tokenize(cleaned_msg)\n",
    "        else: \n",
    "            # Only perform simple NLTK tokenization\n",
    "            msg_tokens = word_tokenize(cleaned_msg)\n",
    "\n",
    "        # Only keep messages that are over a certain length, so that the model has enough text to train on\n",
    "        if len(msg_tokens) < 3:\n",
    "            continue\n",
    "        # Only keep commits with less than four file changes\n",
    "        if len(commit.modifications) > 3:\n",
    "            continue\n",
    "        # Discard commits that reference an issue, e.g. \"#454123\" or \"gh-24558\"\n",
    "        filter_expr = re.compile(r'(#|gh-)[0-9]{3,}')\n",
    "        if any((match := filter_expr.search(msg_token)) for msg_token in msg_tokens):\n",
    "            print(f\"Discarding commit, found issue reference in:\\n{msg_token}\")\n",
    "            continue\n",
    "        \n",
    "        # Looping over the file modifications in the commit\n",
    "        for mod in commit.modifications:\n",
    "            # FILTERING\n",
    "            if not (mod.old_path and mod.new_path):\n",
    "                continue\n",
    "            if os.path.splitext(mod.new_path)[1] != \".py\": # Python code only (excluding notebooks)\n",
    "                continue\n",
    "            if (not mod.diff_parsed[\"added\"]) or (not mod.diff_parsed[\"deleted\"]): # Only added and deleted code\n",
    "                continue\n",
    "            \n",
    "            # Keep track of added and deleted code in the file\n",
    "            added, deleted = [], []\n",
    "\n",
    "            # Looping over added lines of code\n",
    "            for _, code in mod.diff_parsed[\"added\"]:\n",
    "                if codebert_tokenize == \"all\" or codebert_tokenize == \"code_only\":\n",
    "                    # Tokenizing the added line of code with a CodeBERT tokenizer\n",
    "                    code = cb_tokenizer.tokenize(code)\n",
    "                added.extend(code)\n",
    "\n",
    "            # Looping over deleted lines of code\n",
    "            for _, code in mod.diff_parsed[\"deleted\"]:\n",
    "                if codebert_tokenize == \"all\" or codebert_tokenize == \"code_only\":\n",
    "                    # Tokenizing the deleted line of code with a CodeBERT tokenizer\n",
    "                    code = cb_tokenizer.tokenize(code)\n",
    "                deleted.extend(code)\n",
    "            \n",
    "            # Check to see if the source length is a max of 256 tokens. \n",
    "            # (Long messages make fine-tuning difficult)\n",
    "            if added and deleted and (len(added) + len(deleted) <= 256):\n",
    "                with jsonlines.open(output_file, mode=\"a\") as writer:\n",
    "                    writer.write({\n",
    "                            \"commit_message\": msg_tokens,\n",
    "                            \"added\": added,\n",
    "                            \"deleted\": deleted\n",
    "                            })\n",
    "\n",
    "# Saves parsed (tokenized) code to json lines (.jsonl)\n",
    "def create_jsonl_dataset(lines, purpose):\n",
    "    saved_path = os.path.join(output_dir, purpose)\n",
    "    for line in lines:\n",
    "        with jsonlines.open(f\"{saved_path}.jsonl\", mode=\"a\") as dataset:\n",
    "            dataset.write(line)\n",
    "\n",
    "\n",
    "# RUNNING THE PRE-PROCESSING STEPS ON THE DOWNLOADED REPOSITORIES\n",
    "repos = set()\n",
    "with open(repositories, encoding=\"utf-8\") as f:\n",
    "    for _, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        repos.add(line.replace('https://github.com/', ''))\n",
    "\n",
    "# Ensure that the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process the Git repositories\n",
    "for i, repo in enumerate(repos): \n",
    "    print(f\"Processing repo number {i + 1} out of {len(repos)} ({repo})\")\n",
    "    try:\n",
    "        process_commits(repos_dir, repo, codebert_tokenize=\"code_only\")\n",
    "    except FileNotFoundError as err:\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "# Printing some negative samples from language detection task\n",
    "print(f\"Some examples of words that were labelled as not English: \", english_not_detected[:30])\n",
    "print(f\"Number of words labelled as not English: {len(english_not_detected)}\\n\\n\")\n",
    "\n",
    "# Load the processed commits from the dataset.jsonl file to a single list\n",
    "data = []\n",
    "with open(output_file, encoding=\"utf-8\") as dataset_file:\n",
    "    for line in dataset_file:\n",
    "        line = line.strip()  # Remove unecessary whitespace\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Creating train, validation and test datasets by shuffling and splicing the list\n",
    "# Adding a seed to the randomizer keeps the split consistent over multiple trials\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "create_jsonl_dataset(data[:int(len(data) * 0.9)], purpose='train')\n",
    "create_jsonl_dataset(data[int(len(data) * 0.9):int(len(data) * 0.95)], purpose='valid')\n",
    "create_jsonl_dataset(data[int(len(data) * 0.95):], purpose='test')\n",
    "\n",
    "print(\"\\nShowing some examples of training data: \")\n",
    "for data_dict in data[:int(len(data) * 0.9)][:10]:\n",
    "    print(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqY05w4OwWPq"
   },
   "source": [
    "### Fine-Tuning CodeBERT on Git Diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKKlYd2c1-uU",
    "outputId": "24fe4174-4cea-472c-f37f-a2f1801aac6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] --model_type MODEL_TYPE --model_name_or_path\n",
      "                MODEL_NAME_OR_PATH --output_dir OUTPUT_DIR\n",
      "                [--load_model_path LOAD_MODEL_PATH]\n",
      "                [--train_filename TRAIN_FILENAME]\n",
      "                [--dev_filename DEV_FILENAME] [--test_filename TEST_FILENAME]\n",
      "                [--config_name CONFIG_NAME] [--tokenizer_name TOKENIZER_NAME]\n",
      "                [--max_source_length MAX_SOURCE_LENGTH]\n",
      "                [--max_target_length MAX_TARGET_LENGTH] [--do_train]\n",
      "                [--do_eval] [--do_test] [--do_lower_case] [--no_cuda]\n",
      "                [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                [--eval_batch_size EVAL_BATCH_SIZE]\n",
      "                [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                [--learning_rate LEARNING_RATE] [--beam_size BEAM_SIZE]\n",
      "                [--weight_decay WEIGHT_DECAY] [--adam_epsilon ADAM_EPSILON]\n",
      "                [--max_grad_norm MAX_GRAD_NORM]\n",
      "                [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]\n",
      "                [--eval_steps EVAL_STEPS] [--train_steps TRAIN_STEPS]\n",
      "                [--warmup_steps WARMUP_STEPS] [--local_rank LOCAL_RANK]\n",
      "                [--seed SEED]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model_type MODEL_TYPE\n",
      "                        Model type: e.g. roberta\n",
      "  --model_name_or_path MODEL_NAME_OR_PATH\n",
      "                        Path to pre-trained model: e.g. roberta-base\n",
      "  --output_dir OUTPUT_DIR\n",
      "                        The output directory where the model predictions and\n",
      "                        checkpoints will be written.\n",
      "  --load_model_path LOAD_MODEL_PATH\n",
      "                        Path to trained model: Should contain the .bin files\n",
      "  --train_filename TRAIN_FILENAME\n",
      "                        The train filename. Should contain the .jsonl files\n",
      "                        for this task.\n",
      "  --dev_filename DEV_FILENAME\n",
      "                        The dev filename. Should contain the .jsonl files for\n",
      "                        this task.\n",
      "  --test_filename TEST_FILENAME\n",
      "                        The test filename. Should contain the .jsonl files for\n",
      "                        this task.\n",
      "  --config_name CONFIG_NAME\n",
      "                        Pretrained config name or path if not the same as\n",
      "                        model_name\n",
      "  --tokenizer_name TOKENIZER_NAME\n",
      "                        Pretrained tokenizer name or path if not the same as\n",
      "                        model_name\n",
      "  --max_source_length MAX_SOURCE_LENGTH\n",
      "                        The maximum total source sequence length after\n",
      "                        tokenization. Sequences longer than this will be\n",
      "                        truncated, sequences shorter will be padded.\n",
      "  --max_target_length MAX_TARGET_LENGTH\n",
      "                        The maximum total target sequence length after\n",
      "                        tokenization. Sequences longer than this will be\n",
      "                        truncated, sequences shorter will be padded.\n",
      "  --do_train            Whether to run training.\n",
      "  --do_eval             Whether to run eval on the dev set.\n",
      "  --do_test             Whether to run eval on the dev set.\n",
      "  --do_lower_case       Set this flag if you are using an uncased model.\n",
      "  --no_cuda             Avoid using CUDA when available\n",
      "  --train_batch_size TRAIN_BATCH_SIZE\n",
      "                        Batch size per GPU/CPU for training.\n",
      "  --eval_batch_size EVAL_BATCH_SIZE\n",
      "                        Batch size per GPU/CPU for evaluation.\n",
      "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
      "                        Number of updates steps to accumulate before\n",
      "                        performing a backward/update pass.\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        The initial learning rate for Adam.\n",
      "  --beam_size BEAM_SIZE\n",
      "                        beam size for beam search\n",
      "  --weight_decay WEIGHT_DECAY\n",
      "                        Weight deay if we apply some.\n",
      "  --adam_epsilon ADAM_EPSILON\n",
      "                        Epsilon for Adam optimizer.\n",
      "  --max_grad_norm MAX_GRAD_NORM\n",
      "                        Max gradient norm.\n",
      "  --num_train_epochs NUM_TRAIN_EPOCHS\n",
      "                        Total number of training epochs to perform.\n",
      "  --max_steps MAX_STEPS\n",
      "                        If > 0: set total number of training steps to perform.\n",
      "                        Override num_train_epochs.\n",
      "  --eval_steps EVAL_STEPS\n",
      "  --train_steps TRAIN_STEPS\n",
      "  --warmup_steps WARMUP_STEPS\n",
      "                        Linear warmup over warmup_steps.\n",
      "  --local_rank LOCAL_RANK\n",
      "                        For distributed training: local_rank\n",
      "  --seed SEED           random seed for initialization\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "cd CodeBERT-CommitMessage-Generator\n",
    "python3 train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JiTAjj-BjCA",
    "outputId": "a1ad9a2c-16df-4b4b-9cd5-f337df4b9dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1YrkwfM-0VBCJaa9NYaXUQPODdGPsmQY4\n",
      "To: /content/models/added/pytorch_model.bin\n",
      "100% 707M/707M [00:02<00:00, 261MB/s]\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_CODEBERT_MODEL='1YrkwfM-0VBCJaa9NYaXUQPODdGPsmQY4'\n",
    "!pip install gdown \\\n",
    "    && mkdir -p CodeBERT-CommitMessage-Generator/models/added \\\n",
    "    && gdown \"https://drive.google.com/uc?id=$PRETRAINED_CODEBERT_MODEL\" -O models/added/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LreH3lfLGtY",
    "outputId": "4bccaee4-e602-4459-c257-2e1f9051a57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 02:18:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    64W / 400W |      0MiB / 40536MiB |      4%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGFV7BmM5QcI",
    "outputId": "5b5eb23b-cc5a-4b84-ba7b-2bf3a9d9b987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0% 0/10000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:764: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
      "loss 0.6633:  10% 998/10000 [15:41<2:22:30,  1.05it/s]/content/CodeBERT-CommitMessage-Generator/commit/model/model.py:169: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  prevK = bestScoresId // numWords\n",
      "Total: 88\n",
      "loss 0.0157:  20% 1998/10000 [31:36<2:06:41,  1.05it/s]Total: 88\n",
      "loss 0.0077:  30% 2998/10000 [47:29<1:50:48,  1.05it/s]Total: 88\n",
      "loss 0.0078:  40% 3998/10000 [1:03:22<1:35:11,  1.05it/s]Total: 88\n",
      "loss 0.0046:  50% 4998/10000 [1:19:15<1:19:09,  1.05it/s]Total: 88\n",
      "loss 0.0041:  60% 5998/10000 [1:35:08<1:03:22,  1.05it/s]Total: 88\n",
      "loss 0.0032:  70% 6998/10000 [1:51:01<47:30,  1.05it/s]Total: 88\n",
      "loss 0.002:  80% 7998/10000 [2:06:54<31:41,  1.05it/s]Total: 88\n",
      "loss 0.0016:  90% 8998/10000 [2:22:47<15:52,  1.05it/s]Total: 88\n",
      "loss 0.0014: 100% 9998/10000 [2:38:41<00:01,  1.05it/s]Total: 88\n",
      "loss 0.0003: 100% 10000/10000 [2:38:55<00:00,  1.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Microsoft's CodeBERT training script (with Tae-Hwang Jung's modifications) \n",
    "# to fine-tune CodeBERT on Git repositories\n",
    "%%shell\n",
    "\n",
    "lr=5e-5\n",
    "batch_size=32\n",
    "beam_size=8  # Reduced from 10\n",
    "source_length=256  # Maximum code input token length\n",
    "target_length=128  # Maximum commit message text token length\n",
    "output_dir=models/diff\n",
    "train_file=data/parsed/python/train.jsonl  # 80%\n",
    "dev_file=data/parsed/python/valid.jsonl  # 10%\n",
    "test_file=data/parsed/python/test.jsonl  # 10%\n",
    "num_train_epochs=8  # Number of training epochs to perform\n",
    "eval_steps=1000  # Number of evaluation steps to perform\n",
    "# The encoder of the Seq2Seq transformer model \n",
    "# is initialised with CodeBERT weights fine-tuned for code documentation generation\n",
    "saved_model=models/added/pytorch_model.bin\n",
    "\n",
    "python3 train.py --do_train --do_eval --do_test --model_type roberta \\\n",
    "\t--model_name_or_path microsoft/codebert-base \\\n",
    "\t--load_model_path $saved_model \\\n",
    "\t--train_filename $train_file \\\n",
    "\t--dev_filename $dev_file \\\n",
    "\t--test_filename $test_file \\\n",
    "\t--output_dir $output_dir \\\n",
    "\t--max_source_length $source_length \\\n",
    "\t--max_target_length $target_length \\\n",
    "\t--beam_size $beam_size \\\n",
    "\t--train_batch_size $batch_size \\\n",
    "\t--eval_batch_size $batch_size \\\n",
    "\t--learning_rate $lr \\\n",
    "\t--train_steps $train_steps \\\n",
    "\t--eval_steps $eval_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKijOMs2gntt"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"CodeBERT-CommitMessage-Generator/models/diff/checkpoint-best-bleu/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0XS8CZ7wwWPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train steps:  10000\n",
      "Total eval steps:  10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing training loss\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "with open(\"models/diff/loss/train_loss-python-50.txt\", \"r\", encoding=\"UTF-8\") as file:\n",
    "    for line in file.readlines():\n",
    "        step, loss = line.split(\":\")\n",
    "        train_loss.append(float(loss.replace(\"\\n\", \"\")))\n",
    "\n",
    "with open(\"models/diff/loss/eval_loss-python-50.txt\", \"r\", encoding=\"UTF-8\") as file:\n",
    "    for line in file.readlines():\n",
    "        step, loss = line.split(\":\")\n",
    "        eval_loss.append(float(loss.replace(\"\\n\", \"\")))\n",
    "        \n",
    "print(f\"Total train steps: \", len(train_loss))\n",
    "print(f\"Total eval steps: \", len(eval_loss))\n",
    "train_steps = [i for i in range(len(train_loss))]\n",
    "eval_steps = [(i+1)*1000 for i in range(len(eval_loss))]\n",
    "plt.plot(train_steps, train_loss, label=\"Training loss\")\n",
    "plt.plot(eval_steps, eval_loss, label=\"Validation loss\")\n",
    "plt.title('Model Loss During Fine-Tuning')\n",
    "plt.xlabel('Training steps')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_u1osYJ86B0"
   },
   "source": [
    "### Running predictions on a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\t\t   pytorch_model_tuned_python-50.bin\r\n",
      "pytorch_model.bin  pytorch_model_tuned_python-5.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls models/diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6FGW8SsKjeGR",
    "outputId": "64b4075e-d467-41b3-ba05-4079ef8b4fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available?   False\n"
     ]
    }
   ],
   "source": [
    "class Example(object):\n",
    "    \"\"\"A single training/test example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 idx,\n",
    "                 added,\n",
    "                 deleted,\n",
    "                 target,\n",
    "                 ):\n",
    "        self.idx = idx\n",
    "        self.added = added\n",
    "        self.deleted = deleted\n",
    "        self.target = target\n",
    "\n",
    "def get_model(model_class, config, tokenizer, mode):\n",
    "    encoder = model_class(config=config)\n",
    "    decoder_layer = nn.TransformerDecoderLayer(\n",
    "        d_model=config.hidden_size, nhead=config.num_attention_heads\n",
    "    )\n",
    "    decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "    model = Seq2Seq(encoder=encoder, decoder=decoder, config=config,\n",
    "            beam_size=args.beam_size, max_length=args.max_target_length,\n",
    "            sos_id=tokenizer.cls_token_id, eos_id=tokenizer.sep_token_id)\n",
    "\n",
    "    assert args.load_model_path\n",
    "    print(\"model path: \", os.path.join(args.load_model_path, mode, 'pytorch_model.bin'))\n",
    "    assert os.path.exists(os.path.join(args.load_model_path, mode, 'pytorch_model.bin'))\n",
    "\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join(args.load_model_path, mode, 'pytorch_model.bin'),\n",
    "            map_location=torch.device('cpu')\n",
    "        ),\n",
    "        strict=False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_features(examples):\n",
    "    features = convert_examples_to_features(examples, args.tokenizer, args, stage='test')\n",
    "    all_source_ids = torch.tensor(\n",
    "        [f.source_ids[:args.max_source_length] for f in features], dtype=torch.long\n",
    "    )\n",
    "    all_source_mask = torch.tensor(\n",
    "        [f.source_mask[:args.max_source_length] for f in features], dtype=torch.long\n",
    "    )\n",
    "    all_patch_ids = torch.tensor(\n",
    "        [f.patch_ids[:args.max_source_length] for f in features], dtype=torch.long\n",
    "    )\n",
    "    return TensorDataset(all_source_ids, all_source_mask, all_patch_ids)\n",
    "\n",
    "def inference(model, data):\n",
    "    \"\"\"\n",
    "    :data: A torch.utils.data.dataset.TensorDataset object\n",
    "    \"\"\"\n",
    "    # Calculate bleu\n",
    "    eval_sampler = SequentialSampler(data)\n",
    "    eval_dataloader = DataLoader(data, sampler=eval_sampler, batch_size=len(data))\n",
    "\n",
    "    model.eval()\n",
    "    p = []\n",
    "    for batch in tqdm(eval_dataloader, total=len(eval_dataloader)):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        source_ids, source_mask, patch_ids = batch\n",
    "        with torch.no_grad():\n",
    "            preds = model(source_ids=source_ids, source_mask=source_mask, patch_ids=patch_ids)\n",
    "            for pred in preds:\n",
    "                t = pred[0].cpu().numpy()\n",
    "                t = list(t)\n",
    "                if 0 in t:\n",
    "                    t = t[:t.index(0)]\n",
    "                text = args.tokenizer.decode(t, clean_up_tokenization_spaces=False)\n",
    "                p.append(text)\n",
    "    return p\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'load_model_path': 'models', \n",
    "    'model_type': 'roberta',\n",
    "    'config_name' : 'microsoft/codebert-base',\n",
    "    'tokenizer_name' : 'microsoft/codebert-base',\n",
    "    'max_source_length' : 512,\n",
    "    'max_target_length' : 128,\n",
    "    'beam_size' : 10,\n",
    "    'do_lower_case' : False,\n",
    "    'device' : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "})\n",
    "\n",
    "print(\"Is GPU available?  \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZFdp9aL9ior"
   },
   "source": [
    "Building the PL-NL model with the fine-tuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "zsISSK8oQBfD",
    "outputId": "5f0c9099-ef46-4daa-feef-43fca2ee5d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path:  models/diff/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name)\n",
    "args.tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name, do_lower_case=args.do_lower_case)\n",
    "\n",
    "# Build model\n",
    "args.diff_model = get_model(model_class=model_class, config=config,\n",
    "                        tokenizer=args.tokenizer, mode='diff').to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dtAhq1V99cY"
   },
   "source": [
    "Running prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zF5JFAqiwWP6"
   },
   "outputs": [],
   "source": [
    "diffmessage = \"\"\"\n",
    "diff --git a/newfile.py b/newfile.py\n",
    "new file mode 100644\n",
    "index 0000000..cbb72b8\n",
    "--- /dev/null\n",
    "+++ b/newfile.py\n",
    "@@ -0,0 +1,9 @@\n",
    "+#!/usr/bin/env python3\n",
    "+\n",
    "-import torch\n",
    "-import argparse\n",
    "-import numpy\n",
    "+import numpy as np\n",
    "+def multiply_vectors(v1, v2):\n",
    "+    return np.dot(v1, v2)\n",
    "\"\"\"\n",
    "\n",
    "diffmessage2 = \"\"\"\n",
    "diff --git a/test.py b/test.py\n",
    "index d13f441..1b1b82a 100644\n",
    "--- a/test.py\n",
    "+++ b/test.py\n",
    "@@ -1,6 +1,3 @@\n",
    "\n",
    "-import torch\n",
    "-import argparse\n",
    "-import numpy\n",
    "-import sklearn\n",
    "+import matplotlib.pyplot as plt\n",
    "def add(a, b):\n",
    "     return a + b\n",
    "\"\"\"\n",
    "\n",
    "diffmessage3 = \"\"\"\n",
    "diff --git a/test.py b/test.py\n",
    "new file mode 100644\n",
    "index 0000000..d13f441\n",
    "--- /dev/null\n",
    "+++ b/test.py\n",
    "@@ -0,0 +1,6 @@\n",
    "+\n",
    "+import torch\n",
    "+import argparse\n",
    "+\n",
    "+def add(a, b):\n",
    "+    return a + b\n",
    "\"\"\"\n",
    "\n",
    "diffmessage4 = \"\"\"\n",
    "diff --git a/newfile.py b/newfile.py\n",
    "new file mode 100644\n",
    "index 0000000..8724a42\n",
    "--- /dev/null\n",
    "+++ b/newfile.py\n",
    "@@ -0,0 +1,5 @@\n",
    "+#!usr/bin/env python3\n",
    "+\n",
    "+# Gets the url\n",
    "+def get_url(domain, path):\n",
    "+    return domain + \"/\" + path\n",
    "diff --git a/ngrok.conf b/ngrok.conf\n",
    "new file mode 100644\n",
    "index 0000000..8e50d0f\n",
    "--- /dev/null\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0bq--xO2D6vl",
    "outputId": "4a17af0b-6fb7-44b5-89b3-319d75ae033b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Tokenized diff number 0 ------\n",
      "['#', '!/', 'usr', '/', 'bin', '/', 'env', 'Ä python', '3', 'Ä import', 'Ä n', 'umpy', 'Ä as', 'Ä np', 'Ä def', 'Ä multiply', '_', 've', 'ctors', '(', 'v', '1', ',', 'Ä v', '2', '):', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä return', 'Ä np', '.', 'dot', '(', 'v', '1', ',', 'Ä v', '2', ')']\n",
      "['import', 'Ä torch', 'Ä import', 'Ä arg', 'parse', 'Ä import', 'Ä n', 'umpy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:04<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autogenerated commit message: \n",
      " ['naming convention fixes in many files ']\n",
      "\n",
      "\n",
      "----- Tokenized diff number 1 ------\n",
      "['import', 'Ä mat', 'plot', 'lib', '.', 'py', 'plot', 'Ä as', 'Ä pl', 't']\n",
      "['import', 'Ä torch', 'Ä import', 'Ä arg', 'parse', 'Ä import', 'Ä n', 'umpy', 'Ä import', 'Ä sk', 'learn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autogenerated commit message: \n",
      " ['isort --profile black . ']\n",
      "\n",
      "\n",
      "----- Tokenized diff number 2 ------\n",
      "['import', 'Ä torch', 'Ä import', 'Ä arg', 'parse', 'Ä def', 'Ä add', '(', 'a', ',', 'Ä b', '):', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä return', 'Ä a', 'Ä +', 'Ä b']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autogenerated commit message: \n",
      " ['naming convention fixes in many files ']\n",
      "\n",
      "\n",
      "----- Tokenized diff number 3 ------\n",
      "['#', '!', 'usr', '/', 'bin', '/', 'env', 'Ä python', '3', 'Ä #', 'Ä Gets', 'Ä the', 'Ä url', 'Ä def', 'Ä get', '_', 'url', '(', 'domain', ',', 'Ä path', '):', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä return', 'Ä domain', 'Ä +', 'Ä \"/', '\"', 'Ä +', 'Ä path']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:06<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autogenerated commit message: \n",
      " ['Update pythonfinder']\n",
      "\n",
      "\n",
      "----- Tokenized diff number 3 ------\n",
      "['auth', 'token', ':', 'Ä 1', 'ks', 'k', 'Z', 'g', 'J', '8', 'K', 'p', 'CR', 'v', 'Y', 'nz', 'SF', '63', 'Ac', 'od', 'v', 'Br', '_', '4', 'RM', 'X', 'x', 'F', 'o', '4', 'Sa', '2', 'q', 'L', 'r', 'Ra', 'K', 'j', 'h', 'J', 'W', 'Ä region', ':', 'Ä j', 'p', 'Ä console', '_', 'ui', ':', 'Ä False', 'Ä tunnels', ':', 'Ä ', 'Ä ', 'Ä input', ':', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä addr', ':', 'Ä 5000', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä proto', ':', 'Ä http', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä output', ':', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä addr', ':', 'Ä 5000', 'Ä ', 'Ä ', 'Ä ', 'Ä ', 'Ä proto', ':', 'Ä http']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:02<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autogenerated commit message: \n",
      " ['Native YAML - system ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, diffmsg in enumerate([diffmessage, diffmessage2, diffmessage3, diffmessage4]):\n",
    "    # Parse the git diff with whatthepatch package\n",
    "    # Retrieve changes (added and deleted lines of code)\n",
    "    for idx, example in enumerate(whatthepatch.parse_patch(diffmsg)):\n",
    "        if not example.changes:\n",
    "            print(f\"no changes in {idx}\")\n",
    "            continue\n",
    "\n",
    "        isadded, isdeleted = False, False\n",
    "        added, deleted = [], []\n",
    "\n",
    "        # Determine if the line is added or deleted and add it to the corresponding list\n",
    "        for change in example.changes:\n",
    "            if change.old == None and change.new != None and change.line != \"\":\n",
    "                added.append(change.line)\n",
    "                isadded = True\n",
    "            elif change.old != None and change.new == None and change.line != \"\":\n",
    "                deleted.append(change.line)\n",
    "                isdeleted = True\n",
    "\n",
    "        # Tokenization\n",
    "        added_tokens = args.tokenizer.tokenize(\" \".join(added))\n",
    "        deleted_tokens = args.tokenizer.tokenize(\" \".join(deleted))\n",
    "        print(f\"\\n\\n----- Tokenized diff, from diff number {i + 1} ------\")\n",
    "        print(added_tokens)\n",
    "        print(deleted_tokens)\n",
    "\n",
    "        # Create a numerical vector representation\n",
    "        testsample = [Example(idx, added_tokens, deleted_tokens, target=None)]\n",
    "        sampledata = get_features(testsample)\n",
    "\n",
    "        # Generate a commit message\n",
    "        message = inference(model=args.diff_model, data=sampledata)\n",
    "        print(\"Autogenerated commit message: \\n\", message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uB6-INswWP9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e13d24989e9aa84deaafec43a9be4b3b9f46f3756b11886b1eace5ab5637549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
