{"commit_tokens": ["Allow", "for", "more", "than", "one", "ROLE", "as", "per", "the", "spec"], "add_tokens": "# Add a role field, ROLE. def add_role ( role ) @card << :: Vcard :: DirectoryInfo :: Field . create ( \"ROLE\" , :: Vcard . encode_text ( role ) ) ;", "del_tokens": "# Set the role field, ROLE. def role = ( role ) delete_if { | l | l . name == \"ROLE\" } @card << :: Vcard :: DirectoryInfo :: Field . create ( \"ROLE\" , :: Vcard . encode_text ( role ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "a", "vim", "typeo", "."], "add_tokens": "# @param [Object] obj The object to patch. def self . patch ( obj )", "del_tokens": "# @param [Object] obj The object to patch. def self.patch(obj)", "commit_type": "fix"}
{"commit_tokens": ["updated", "post", "specs", "and", "implementation", "with", "new", "api"], "add_tokens": "Typhoeus :: RemoteProxyObject . new ( base_easy_object ( url , :post , options ) , :on_success => options [ :on_success ] , :on_failure => options [ :on_failure ] )", "del_tokens": "if Typhoeus . multi_running? Typhoeus . add_easy_request ( base_easy_object ( url , :post , options , filter_wrapper_block ( :post , block ) ) ) else Typhoeus . service_access do post ( url , options , & block ) end end", "commit_type": "update"}
{"commit_tokens": ["Changed", "version", "components", "to", "local", "variables"], "add_tokens": "major = 0 minor = 0 patch = 6 VERSION = [ major , minor , patch ] . join ( '.' ) unless defined? Bigcommerce :: VERSION", "del_tokens": "MAJOR = 0 unless defined? Bigcommerce :: MAJOR MINOR = 0 unless defined? Bigcommerce :: MINOR PATCH = 6 unless defined? Bigcommerce :: PATCH VERSION = [ MAJOR , MINOR , PATCH ] . join ( '.' ) unless defined? Bigcommerce :: VERSION", "commit_type": "change"}
{"commit_tokens": ["Add", "TrickBag", "::", "Numeric", "::", "MultiCounter#total_count", "#percent_of_total_hash", ".."], "add_tokens": "let ( :sample_data ) { %w( Open New Open Closed Open New Closed Open Open Open ) } sample_data . each { | datum | subject . increment ( datum ) } expect ( subject . total_count ) . to eq ( 10 ) end specify 'creating from an array works correctly' do m_counter = MultiCounter . from_array ( sample_data ) expect ( m_counter . total_count ) . to eq ( 10 ) expect ( m_counter [ 'Open' ] ) . to eq ( 6 ) end specify 'percent_of_total_hash is correctly calculated' do ptotal_hash = MultiCounter . from_array ( sample_data ) . percent_of_total_hash expect ( ptotal_hash [ 'Open' ] ) . to eq ( 0.6 ) expect ( ptotal_hash [ 'Closed' ] ) . to eq ( 0.2 ) expect ( ptotal_hash [ 'New' ] ) . to eq ( 0.2 )", "del_tokens": "results = %w( Open New Open Closed Open New Closed ) results . each { | r | subject . increment ( r ) } expect ( s˚ubject. t otal_count) . t o q( 7 )", "commit_type": "add"}
{"commit_tokens": ["fixed", "long", "standing", "prefix", "bug"], "add_tokens": "@prefix = \"/#{@prefix}/\" . gsub ( / ^ \\/ \\/ / , \"\" ) @request = Rack :: MockRequest . new ( app ) build_index build_tables map \"/#{@prefix}\" do def build_index install_file ( @request . request ( \"GET\" , \"#{@prefix}\" ) . body , def build_tables install_file ( @request . request ( \"GET\" , \"#{@prefix}#{table.slug}/\" ) . body , install_file ( @request . request ( \"GET\" , \"#{@prefix}#{table.slug}/#{page}/\" ) . body , end", "del_tokens": "request = Rack :: MockRequest . new ( app ) build_index request build_tables request prefix = @prefix map \"/#{prefix}\" do def build_index ( request ) install_file ( request . request ( \"GET\" , \"/#{@prefix}/\" ) . body , def build_tables ( request ) install_file ( request . request ( \"GET\" , \"/#{@prefix}/#{table.slug}/\" ) . body , install_file ( request . request ( \"GET\" , \"/#{@prefix}/#{table.slug}/#{page}/\" ) . body , end", "commit_type": "fix"}
{"commit_tokens": ["moved", "Mailgun", "::", "Base", ".", "submit", "to", "Mailgun", ".", "submit"], "add_tokens": "end # Submits the API call to the Mailgun server def self . submit ( method , url , parameters = { } ) begin return JSON ( RestClient . send ( method , url , parameters ) ) rescue = > e error_message = nil if e . http_body begin error_message = JSON ( e . http_body ) [ \"message\" ] rescue raise e raise Mailgun :: Error . new ( error_message ) raise e", "del_tokens": "# Submits the API call to the Mailgun server def self . submit ( method , url , parameters = { } ) begin return JSON ( RestClient . send ( method , url , parameters ) ) rescue = > e error_message = nil if e . http_body begin error_message = JSON ( e . http_body ) [ \"message\" ] rescue raise e end raise Mailgun :: Error . new ( error_message ) raise e", "commit_type": "move"}
{"commit_tokens": ["fixing", "schema", "validation", "issues", "with", "CCR", "export"], "add_tokens": "to_ccr_socialhistory ( xml , patient ) to_ccr_encounters ( xml , patient ) xml . Source", "del_tokens": "to_ccr_encounters ( xml , patient ) to_ccr_socialhistory ( xml , patient )", "commit_type": "fix"}
{"commit_tokens": ["made", "method_deprecated", "a", "class", "method"], "add_tokens": "sclz . method_deprecated ( :get_number , :number ) sclz . method_deprecated ( :get_subject , :subject ) sclz . method_deprecated ( :get_body , :body ) sclz . method_deprecated ( :get_media , :default_media ) sclz . method_deprecated ( :get_text , :default_text ) sclz . method_deprecated ( :get_attachment , :attachment ) def self . method_deprecated ( from , to )", "del_tokens": "method_deprecated ( :get_number , :number ) method_deprecated ( :get_subject , :subject ) method_deprecated ( :get_body , :body ) method_deprecated ( :get_media , :default_media ) method_deprecated ( :get_text , :default_text ) method_deprecated ( :get_attachment , :attachment ) protected def method_deprecated ( from , to )", "commit_type": "make"}
{"commit_tokens": ["updated", "with", "email", "data", "customer", "endpoint", "and", "tests"], "add_tokens": "def start_on_drip_campaign ( recipient_address , drip_campaign_id , email_data = { } ) if email_data . nil? payload = { recipient_address : recipient_address } . to_json else payload = { recipient_address : recipient_address , email_data : email_data } . to_json end def list_customers_on_campaign ( drip_campaign_id ) SendWithUs :: ApiRequest . new ( @configuration ) . get ( 'drip_campaigns/#{drip_campaign_id}/customers' . to_sym ) end def list_customers_on_campaign_step ( drip_campaign_id , drip_campaign_step_id ) SendWithUs :: ApiRequest . new ( @configuration ) . get ( 'drip_campaigns/#{drip_campaign_id}/step/#{drip_campaign_step_id}/customers' . to_sym ) end", "del_tokens": "def start_on_drip_campaign ( recipient_address , drip_campaign_id ) payload = { recipient_address : recipient_address } . to_json", "commit_type": "update"}
{"commit_tokens": ["Use", "a", "real", "error", "class", "for", "bad", "signals", "."], "add_tokens": "raise Error . new ( \"Unknown signal #{stop_signal}\" ) unless ( 0 .. 31 ) . include? ( stop_signal ) raise Error . new ( \"Unknown signal #{stop_signal}\" ) unless Signal . list . include? ( short_sig )", "del_tokens": "raise \"Unknown signal #{stop_signal}\" unless ( 0 .. 31 ) . include? ( stop_signal ) raise \"Unknown signal #{stop_signal}\" unless Signal . list . include? ( short_sig )", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "configuring", "the", "reload_on_failure", "and", "reload_connections", "flags", "in", "elasticsearch", "-", "transport", ".", "Useful", "if", "your", "ElasticSearch", "cluster", "is", "behind", "a", "load", "balancer", "and", "does", "not", "have", "direct", "access", "to", "the", "network", "addresses", "of", "the", "nodes", "."], "add_tokens": "config_param :reload_connections , :bool , :default => true config_param :reload_on_failure , :bool , :default => false reload_connections : @reload_connections , reload_on_failure : @reload_on_failure ,", "del_tokens": "reload_connections : true ,", "commit_type": "allow"}
{"commit_tokens": ["Updated", "numeric", "validator", "to", "raise", "if", "precision", "and", "scale", "are", "invalid"], "add_tokens": "# FIXME: if precision and scale are not specified, can we assume that it is an integer? if precision > scale && scale > 0 return true if value =~ / \\A [+-]?(?: \\d {1, #{ precision - scale } }| \\d {0, #{ precision - scale } } \\. \\d {1, #{ scale } }) \\z / elsif precision > scale && scale == 0 elsif precision == scale return true if value =~ / \\A [+-]?(?:0(?: \\. \\d {1, #{ scale } })?) \\z / raise ArgumentError , \"Invalid precision #{precision.inspect} and scale #{scale.inspect} for #{field_name} (value: #{value.inspect} #{value.class})\"", "del_tokens": "if precision == scale return true if value =~ / \\A [+-]?(?:0(?: \\. \\d {1, #{ scale } })?) \\z / elsif scale == 0 return true if value =~ / \\A [+-]?(?: \\d {1, #{ precision - scale } }| \\d {0, #{ precision - scale } } \\. \\d {1, #{ scale } }) \\z /", "commit_type": "update"}
{"commit_tokens": ["Changed", "default", "date", "to", "today", "rather", "than", "DB", "max", "value"], "add_tokens": "@date ||= Date . today", "del_tokens": "@date ||= Meter . maximum ( :created_on )", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "that", "didn", "t", "check", "all", "conditions"], "add_tokens": "return false unless comparator . call ( attribute , model_value ) return true", "del_tokens": "return comparator . call ( attribute , model_value )", "commit_type": "fix"}
{"commit_tokens": ["add", "an", "option", "to", "prevent", "re", "-", "raising", "of", "Javascript", "errors", "in", "Ruby"], "add_tokens": "attr_reader :server , :client , :logger , :raise_errors def initialize ( server , client , logger = nil , raise_errors = true ) @raise_errors = raise_errors error ( JavascriptError , json [ 'error' ] ) error ( BrowserError , json [ 'error' ] ) json [ 'response' ] def error ( klass , message ) if raise_errors raise klass . new ( message ) else log message end end", "del_tokens": "attr_reader :server , :client , :logger def initialize ( server , client , logger = nil ) raise JavascriptError . new ( json [ 'error' ] ) raise BrowserError . new ( json [ 'error' ] ) else json [ 'response' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "options", "for", "host", ":", "port", "through", "ENV", "to", "connect", "to", "the", "server"], "add_tokens": "host = ENV [ 'HOST' ] || ENV [ 'host' ] || 'localhost' port = ENV [ 'PORT' ] || ENV [ 'port' ] || 27017 @db = XGen :: Mongo :: Driver :: Mongo . new ( host , port ) . db ( 'ruby-mongo-test' )", "del_tokens": "@db = XGen :: Mongo :: Driver :: Mongo . new . db ( 'ruby-mongo-test' )", "commit_type": "add"}
{"commit_tokens": ["Added", "rakelib", ".", "Some", "docs"], "add_tokens": "attr_accessor :izpackVersion , :appName , :version", "del_tokens": "attr_accessor :control , :prerm , :postinst , :postrm , :preinst , :triggers , :version", "commit_type": "add"}
{"commit_tokens": ["Adds", "additional", "exception", "when", "connection", "refused", "."], "add_tokens": "rescue Errno :: EINVAL , Redis :: CannotConnectError => e warn \"[Parse::Cache Error] #{e}\"", "del_tokens": "rescue Redis :: CannotConnectError => e warn \"[Parse::Cache Error] Cache store connection failed. #{e}\"", "commit_type": "add"}
{"commit_tokens": ["Added", "failing", "tests", "for", "namespaced", "models", "."], "add_tokens": "NAMESPACED_MODELS = File . join ( File . dirname ( __FILE__ ) , 'models' , 'namespaced' ) $LOAD_PATH . unshift ( NAMESPACED_MODELS ) Dir [ File . join ( NAMESPACED_MODELS , \"*.rb\" ) ] . sort . each { | file | require File . basename ( file ) } end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Updating", "rails", "requirement", "to", "support", "rails4"], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "update"}
{"commit_tokens": ["Add", "helper", "to", "share", "breadcrumbs", "between", "view", "and", "controller", "."], "add_tokens": "before_filter ( options ) do | instance | _breadcrumbs << Crumb . new ( name , url ) def _breadcrumbs @_breadcrumbs ||= [ ] _breadcrumbs . clear base . send :helper_method , :_breadcrumbs", "del_tokens": "before_filter options do | instance | crumbs << Crumb . new ( name , url ) def crumbs @crumbs ||= [ ] crumbs . clear", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "allow", "for", "ruby", "2", "syntax"], "add_tokens": "def fit_at ( type , slope : nil , intercept : nil , n : nil )", "del_tokens": "def fit_at ( type , slope : , intercept : , n : )", "commit_type": "change"}
{"commit_tokens": ["Using", "i18n", "configuration", "instead", "of", "a", "custom", "translation", "method"], "add_tokens": "flash [ :notice ] = t ( 'ransack.saved_search.save.success' ) flash [ :error ] = t ( 'ransack.saved_search.save.error' )", "del_tokens": "flash [ :notice ] = translate ( 'ransack.saved_search.save.success' ) flash [ :error ] = translate ( 'ransack.saved_search.save.error' )", "commit_type": "use"}
{"commit_tokens": ["Fix", "git_data", "params", "issue", "add", "method", "documentation", "."], "add_tokens": "# The Git Database API gives you access to read and write raw Git objects # to your Git database on GitHub and to list and update your references # (branch heads and tags). def git_data ( options = { } ) # Many of the resources on the users API provide a shortcut for getting # information about the currently authenticated user.", "del_tokens": "def git_data ( options )", "commit_type": "fix"}
{"commit_tokens": ["adds", "delay", "in", "before", "each"], "add_tokens": "sleep 2", "del_tokens": "sleep 1", "commit_type": "add"}
{"commit_tokens": ["updated", "for", "_content", "and", "@", "keys"], "add_tokens": "# # Keys beginning with \"@\" are treated as explicit attributes for their container. # You can use both :attributes! and \"@\" keys to specify attributes. # In the event of a conflict, the \"@\" key takes precedence. order ( hash ) . each do | key | node_attr = attributes [ key ] || { } if hash [ key ] . respond_to? ( :keys ) explicit_keys = hash [ key ] . keys . select { | k | k =~ / ^@ / } explicit_attr = { } explicit_keys . each { | k | explicit_attr [ k [ 1 .. - 1 ] ] = hash [ key ] [ k ] } node_attr . merge! ( explicit_attr ) explicit_keys . each { | k | hash [ key ] . delete ( k ) } node_value = node_value . delete ( \"_content\" ) || node_value end yield xml , key , hash [ key ] , node_attr # Ignore Explicit Attributes orderable = order . delete_if { | k | k =~ / ^@ / } hashable = hash . keys . select { | k | ! ( k =~ / ^@ / ) } missing , spurious = hashable - orderable , orderable - hashable", "del_tokens": "order ( hash_without_attributes ) . each do | key | yield xml , key , hash_without_attributes [ key ] , ( attributes [ key ] || { } ) missing , spurious = hash_without_order . keys - order , order - hash_without_order . keys", "commit_type": "update"}
{"commit_tokens": ["Added", "followers", "count", "to", "twitter", "user"], "add_tokens": ":screen_name , :statuses_count , :verified , :protected , :followers_count :screen_name , :statuses_count , :verified , :protected , :followers_count ]", "del_tokens": ":screen_name , :statuses_count , :verified , :protected :screen_name , :statuses_count , :verified , :protected ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "after", "moving", "to", "Ssh", "instead", "of", "ssh", "for", "consistency", "with", "proxy", "features"], "add_tokens": "f . provider_type 'Ssh'", "del_tokens": "f . provider_type 'ssh'", "commit_type": "fix"}
{"commit_tokens": ["Move", "test", "routes", "to", "somewhere", "more", "sensible", "."], "add_tokens": "ActionController :: Routing :: Routes . draw do | map | map . resources :widgets end", "del_tokens": "def setup ActionController :: Routing :: Routes . draw do | map | map . resources :widgets end end", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "broken", "test", "bringing", "cargo_streamer", "coverage", "up", "to", "100%"], "add_tokens": "StringIO . open do | sio | cs = OfflineMirror :: CargoStreamer . new ( sio , \"w\" ) cs . write_cargo_section ( \"test\" , [ \"test\" ] , :human_readable => true ) end", "del_tokens": "cs = OfflineMirror :: CargoStreamer . new ( StringIO . new , \"w\" ) cs . write_cargo_section ( \"test\" , \"test\" , :human_readable => true )", "commit_type": "fix"}
{"commit_tokens": ["Add", "artifact_name", "as", "an", "optional", "argument", "to", "sem", "-", "dist"], "add_tokens": ":artifact_name => \"Specifies the name of the artifact. Tag will be appeneded to this name\" , attr_reader :artifact_name , :host , :name , :user , :dir , :dry_run , :tag @artifact_name = found_arguments . delete ( :artifact_name )", "del_tokens": "attr_reader :host , :name , :user , :dir , :dry_run , :tag", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "readme", "to", "fit", "the", "redone", "methods"], "add_tokens": "def post_item ( omeka_item ) def put_item ( omeka_item ) def delete_item ( omeka_item )", "del_tokens": "# def post_items ( omeka_item ) def put_items ( omeka_item ) def delete_items ( omeka_item )", "commit_type": "update"}
{"commit_tokens": ["Implement", "text", "for", "the", "progress", "bar", "."], "add_tokens": "def initialize ( x , y , w , h , bg , fg , max_value = 100 , value = 100 , fg_margin_x = 0 , fg_margin_y = 0 , #fg_left = nil, fg_right = nil, font = nil , text_color = 0xff000000 , format = '/' ) # @fg_left = fg_left # @fg_right = fg_right def percentage = ( pct ) @value = ( pct * @max_value ) . round if @value > @max_value @value = @max_value elsif @value < 0 @value = 0 end end if @font @text = @format == '%' ? \"#{(@value.to_f / @max_value * 100).round}%\" : \"#{@value}/#{@max_value}\" @font . draw_rel @text , @x + @fg_margin_x + @w / 2 , @y + @fg_margin_y + @h / 2 , 0 , 0.5 , 0.5 , 1 , 1 , @text_color end", "del_tokens": "def initialize ( x , y , w , h , bg , fg , max_value = 100 , value = 100 , fg_margin_x = 0 , fg_margin_y = 0 , fg_left = nil , fg_right = nil , font = nil , text_color = 0 , format = nil ) @fg_left = fg_left @fg_right = fg_right", "commit_type": "implement"}
{"commit_tokens": ["fixed", "some", "math", "problems", "caused", "by", "methods", "being", "redefined", "by", "mathn"], "add_tokens": "require 'ruby_units/complex'", "del_tokens": "require 'ruby_units/complex'", "commit_type": "fix"}
{"commit_tokens": ["Move", "cli", "options", "and", "parsing", "to", "CLI", "class"], "add_tokens": "autoload :CLI , 'build_status_server/cli' autoload :Config , 'build_status_server/config' autoload :Server , 'build_status_server/server' autoload :VERSION , 'build_status_server/version'", "del_tokens": "autoload :Config , 'build_status_server/config' autoload :Server , 'build_status_server/server'", "commit_type": "move"}
{"commit_tokens": ["Added", "yardoc", "to", "Rakefile", "."], "add_tokens": "module_function :parent_module module_function :class_unqualified_name module_function :optional_args_block_call module_function :extract_file_rdoc", "del_tokens": "alias :unqualified_class_name :class_unqualified_name extend ( RubyTools )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "monotonic", "clock", "for", "measurements"], "add_tokens": "Perf . clock_time ( & work ) Perf . clock_time ( & work )", "del_tokens": ":: Benchmark . realtime ( & work ) :: Benchmark . realtime ( & work )", "commit_type": "change"}
{"commit_tokens": ["added", "a", "couple", "of", "pending", "tests", "around", "utf8", "checks", "will", "get", "to", "those", "soon"], "add_tokens": "it \"should not parse JSON with a comment, with :allow_comments set to false\" do it \"should parse JSON with a comment, with :allow_comments set to true\" do it \"should not parse invalid UTF8 with :check_utf8 set to true\" do pending # not sure how to write this test yet end it \"should parse invalid UTF8 with :check_utf8 set to false\" do pending # not sure how to write this test yet end", "del_tokens": "it \"should not parse JSON with a comment\" do it \"should parse JSON with a comment\" do", "commit_type": "add"}
{"commit_tokens": ["added", "basics", "needed", "for", "download"], "add_tokens": "def on_success * args , & block", "del_tokens": "def on_ignore * args , & block", "commit_type": "add"}
{"commit_tokens": ["Removing", "more", "unneeded", "stuff", "."], "add_tokens": "@interval = 5 daemonize if @options [ :daemon ] process_build_queue && sleep ( @interval ) CI . logger . info \"Stopping CI Client...\" def daemonize Process . daemon if @options [ :daemon ]", "del_tokens": "Process . daemon if @options [ :daemon ] set_program_name trap_int_signals process_build_queue sleep 5 def set_program_name $PROGRAM_NAME = \"ci\" def trap_int_signals Signal . trap ( :INT ) { stop } end", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "probe", "allows", "a", "the", "return", "value", "to", "be", "intercepted", "feature", "."], "add_tokens": "# returning the actual value of the method. The block is an after callback # that intercepts the return value. Mocks or other modifications can # be done to the return value. # probe(subject).method_name(arg1, arg2) { |return_value| } # The ProbeCreator also supports a block sytnax. The block accepts # a after_call callback, instead of a return value as with MockCreator # and StubCreator. # probe(User) do |m| # m.find('4') do |user| # mock(user).valid? {false} # end # # user = User.find('4') # user.valid? # false def method_missing ( method_name , * args , & after_call ) scenario . after_call ( & after_call ) if after_call scenario", "del_tokens": "# returning return_value. # probe(subject).method_name(arg1, arg2) { return_value } # The ProbeCreator also supports a block sytnax. # probe(subject) do |m| # m.method_name(arg1, arg2) { return_value } def method_missing ( method_name , * args , & returns )", "commit_type": "implement"}
{"commit_tokens": ["Use", "input", "field", "shared", "examples", "to", "test", "#text_area"], "add_tokens": "add_error_to_input! html_tag , 'input' when / ^<textarea / add_error_to_input! html_tag , 'textarea' def add_error_to_input! html_tag , element html_tag . sub! ( element , %'#{element} aria-describedby=\"error_message_#{field}\"' )", "del_tokens": "add_error_to_input! html_tag def add_error_to_input! html_tag html_tag . sub! ( 'input' , %'input aria-describedby=\"error_message_#{field}\"' )", "commit_type": "use"}
{"commit_tokens": ["Update", "MODS", "mapping", "and", "task", "to", "correctly", "avoid", "duplicate", "creation"], "add_tokens": "unless relations [ :parent ] . nil? @resource . parent = relations [ :parent ] @resource . parent . save @resource . parent . children << relations [ :siblings ] end vocabs = { } vocabs [ :prism ] = Prism . new # TODO: prism mapping # TODO: use some recursion here # (resource.agents ||= []) << map_agents(node.xpath('name'), 'dcterms.creator') relations [ :parent ] = resource when 'otherFormat' when 'isReferencedBy' when 'references' when 'original' relations [ :siblings ] << resource relations [ :children ] << resource # resource.save agents #.uniq", "del_tokens": "@resource . parent = relations [ :parent ] @resource . parent . children << relations [ :siblings ] unless @resource . parent . nil? def save @resource . parent . save unless @resource . parent . nil? @resource . save end vocabs = { :dcterms => { } , :bibo => { } , :prism => { } } vocabs [ :prism ] = { } # TODO: prism mapping relations [ :parent ] = resource relations [ :siblings ] << resource when 'otherFormat' when 'isReferencedBy' when 'references' when 'original' relations [ :children ] << resource # TODO: use some recursion here resource . agents << map_agents ( node . xpath ( 'name' ) , 'dcterms.creator' ) resource . save # ensure similarity searches are fresh agent . tire . index . refresh agents", "commit_type": "update"}
{"commit_tokens": ["Move", "RPC", "return", "Method", "handling", "from", "Channel", "to", "Connection", "."], "add_tokens": "\"response to #{req_type} => #{res.fetch(:method)}\\n#{res.inspect}\" if expect && res . fetch ( :method ) != expect res . fetch ( :properties )", "del_tokens": "res_type = FFI :: Method . lookup ( res . class ) res = res . to_h ( false ) \"response to #{req_type} => #{res_type}\\n#{res.inspect}\" if expect && res_type != expect res", "commit_type": "move"}
{"commit_tokens": ["Updated", "inline", "class", "and", "method", "comments", "for", "API", "docs"], "add_tokens": "## # Objects of this class represent the various tags available in ESS # ## # Returns the dictionary describing this tag. # def dtd return @dtd end ## # There should never be a need to create an Element object yourself, # except if you're the developer of this library. Use ESS::Maker.make # if you need to create a new ESS document. # # === Parameters # # [name] a symbol, the name of the tag being created # [dtd] a hash describing the tag # ## # Return the name of the tag as a symbol. # ## # Returns or sets the text contained in this tag # ## # Returns a short description of this object. # ## # Validates the tag according to its DTD and all child tags. Throws an # ESS::Validation::ValidationError exception in case the document is # incomplete or an invalid value if found. # ## # Same as #validate, but returns false if an error is found, instead of # throwing exceptions. # ## # Returns the feed as an XML document in a string. An Builder::XmlMarkup # object can be passed as an argument and used as output, instead of # generating a string object. # ## # A convenience method for pushing the current document to aggregators. # It calls the ESS::Pusher.push_to_aggregators method and passes all # options to it. # ## # Same as #to_xml!, but accepts no arguments. # ## # Disables postprocessing of tag values. # ## # Enables postprocessing of tag values. ## # Returns true if postprocessing has been disabled. # ## # Handles methods corresponding to a tag name, ending with either # _list or _attr, or starting with add_ . #", "del_tokens": "attr_reader :dtd", "commit_type": "update"}
{"commit_tokens": ["remove", "slickmap", "into", "own", "extension"], "add_tokens": "@source_paths ||= [", "del_tokens": "[", "commit_type": "remove"}
{"commit_tokens": ["Moving", "rubyversion", "logic", "to", "upper", "level"], "add_tokens": "VERSION = \"4.0.1\" . freeze", "del_tokens": "VERSION = '4.0.1' . freeze", "commit_type": "move"}
{"commit_tokens": ["Allow", "customization", "of", "each", "HABTM", "check", "box", "."], "add_tokens": "habtm_single_check_box_template ( :name => \"#{base_name}[]\" , :id => field_id , :value => c [ 1 ] , :checked => @object . send ( method ) . include? ( c [ 1 ] ) , :label => @template . label_tag ( field_id , c [ 0 ] ) ) ## # Render a single check box in a HABTM set. # def habtm_single_check_box_template ( l = { } ) <<-END < div class = \"habtm_single_check_box\" > < input type = \"checkbox\" name = \"#{l[:name]}\" id = \"#{l[:id]}\" value = \"#{l[:value]}\" #{'checked=\"checked\"' if l[:checked]}} /> #{l[:label]}</div> END end", "del_tokens": "@template . content_tag ( :div , :class => \"field\" ) do @template . check_box_tag ( \"#{base_name}[]\" , c [ 1 ] , @object . send ( method ) . include? ( c [ 1 ] ) , :id => field_id ) + @template . label_tag ( field_id , c [ 0 ] ) end", "commit_type": "allow"}
{"commit_tokens": ["added", "test", "for", "_data", "/", "authors", ".", "yml", "data", "and", "corrected", "mistakes"], "add_tokens": "it \"does use author reference with data from _data/authors.yml\" do expect ( contents ) . to match / <author> \\s *<name>Garth< \\/ name> \\s *<email>example@mail.com< \\/ email> \\s *<uri>http: \\/ \\/ garthdb.com< \\/ uri> \\s *< \\/ author> / end expect ( feed . items . count ) . to eql ( 9 )", "del_tokens": "expect ( feed . items . count ) . to eql ( 8 )", "commit_type": "add"}
{"commit_tokens": ["Use", "SimpleDelegator", "instead", "of", "inheriting", "from", "String"], "add_tokens": "class Token < SimpleDelegator", "del_tokens": "class Token < String", "commit_type": "use"}
{"commit_tokens": ["Remove", "autoload", "because", "it", "s", "not", "threadsafe"], "add_tokens": "require 'chef_zero/core_ext' require 'chef_zero/log'", "del_tokens": "require 'chef_zero/core_ext' autoload :Log , 'chef_zero/log'", "commit_type": "remove"}
{"commit_tokens": ["Removed", "constants", "from", "service", "class"], "add_tokens": "url = [ \"/v1/catalog/service/#{key}\" ] register = @conn . put '/v1/agent/service/register' , json_definition deregister = @conn . get \"/v1/agent/service/deregister/#{service_name}\"", "del_tokens": "GET_URL = \"/v1/catalog/service\" REGISTER_URL = '/v1/agent/service/register' DEREGISTER_URL = '/v1/agent/service/deregister' url = [ \"#{Service::GET_URL}/#{key}\" ] register = @conn . put Service :: REGISTER_URL , json_definition deregister = @conn . get \"#{Service::DEREGISTER_URL}/#{service_name}\"", "commit_type": "remove"}
{"commit_tokens": ["Add", "method", "to", "set", "access", "token"], "add_tokens": "client . set_access_token ( 'abc' , '123' )", "del_tokens": "client . init_access_token ( :oauth_verifier => 'abc' ) stub_request ( :post , \"http://localhost:2990/jira/plugins/servlet/oauth/request-token\" ) . to_return ( :body => \"\" ) stub_request ( :post , \"http://localhost:2990/jira/plugins/servlet/oauth/access-token\" ) . to_return ( :body => \"\" )", "commit_type": "add"}
{"commit_tokens": ["add", "to_hash", "method", "for", "ObjectifiedHash"], "add_tokens": "# Creates a new ObjectifiedHash object. @hash = hash def to_hash @hash end alias_method :to_h , :to_hash # Delegate to ObjectifiedHash.", "del_tokens": "# Creates a new ObjectifiedHash. # Delegate to ObjectifiedHash", "commit_type": "add"}
{"commit_tokens": ["fixed", "edit_resource_url", "returning", "always", "the", "same", "value"], "add_tokens": "self . public_send \"edit_#{resource_url_method}\" . to_sym , ( resource || @resource )", "del_tokens": "@edit_resource_url ||= self . public_send \"edit_#{resource_url_method}\" . to_sym , ( resource || @resource )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "blacklist", "of", "directories", "that", "should", "never", "be", "recursively", "watched", "."], "add_tokens": "# A list of directories that should never be recursively watched. # # * Files in `/dev/fd` sometimes register as directories, but are not enumerable. RECURSIVE_BLACKLIST = %w[ /dev/fd ] watch ( d , * flags , & callback ) if ! RECURSIVE_BLACKLIST . include? ( d ) && File . directory? ( d )", "del_tokens": "watch ( d , * flags , & callback ) if File . directory? ( d )", "commit_type": "add"}
{"commit_tokens": ["Adding", "form_helper", "form_builder", "and", "adjusting", "tabs"], "add_tokens": "require_relative 'dora/helpers/tabs_helper'", "del_tokens": "require_relative 'dora/helpers/tabs' ActionView :: Base . send ( :include , Dora :: Helpers :: TabsHelper )", "commit_type": "add"}
{"commit_tokens": ["add", "rate", "option", "to", "chunks"], "add_tokens": "attr_accessor :original_file , :original_duration , :start_time , :duration , :chunk_file , :rate def initialize ( original_file , original_duration , start_time , duration , rate ) @original_file = original_file @start_time = start_time @duration = [ duration , ( @original_duration - @start_time ) ] . min @rate = rate @chunk_file = Tempfile . new ( [ File . basename ( @original_file ) , '.wav' ] ) Utility . trim_to_flac ( @original_file . path , @chunk_file . path , @start_time , @duration , @rate )", "del_tokens": "attr_accessor :original_file , :original_duration , :start_time , :duration , :chunk_file def initialize ( original_file , original_duration , start_time , duration ) @original_file = original_file @start_time = start_time @duration = [ duration , ( @original_duration - @start_time ) ] . min @chunk_file = Tempfile . new ( [ File . basename ( @original_file ) , '.flac' ] ) Utility . trim_to_flac ( @original_file . path , @duration , @chunk_file . path , @start_time , @duration )", "commit_type": "add"}
{"commit_tokens": ["Make", "initialize", "recognize", "the", "engines", "key", "."], "add_tokens": "# The options can be used to pre-register engines and provide configuration for them. # The engines will have specific configurations, but the UserManager class recognizes # the 'engines' key. # # The 'engines' key will have engine names as the subkeys. These should be in underscore # format. And each subkey will be an array of domain names to register to the engine. # # { # :engines => { # 'example_engine' => [ # 'example.com', # 'example.net' # ], # 'my_gem/my_engine' => [ # 'example.org' # ] # } # } # @options = ( options || { } ) . deep_symbolize_keys if @options [ :engines ] . is_a? ( :: Hash ) @options [ :engines ] . each do | engine_name , domain_list | domain_list = [ domain_list ] unless domain_list . is_a? ( :: Array ) engine = begin engine_name . classify . constantize rescue NameError nil end if engine register_auth_engine engine , * domain_list end end end", "del_tokens": "@options = ( options || { } ) . symbolize_keys", "commit_type": "make"}
{"commit_tokens": ["Use", "custom", "JSON", "serialization", "."], "add_tokens": "# Alias of #export. def as_json ( options = nil ) export ( options ) end # Convert the #as_json result to JSON. def to_json ( options = nil ) as_json ( options ) . to_json end", "del_tokens": "include ActiveModel :: Serializers :: JSON", "commit_type": "use"}
{"commit_tokens": ["Make", "Handler", "configurable", "add", "tests"], "add_tokens": "websocket_port : '8080' , debug : false , redis_address : 'redis://0.0.0.0:6379/0' , socket_handler : Slanger :: Handler", "del_tokens": "websocket_port : '8080' , debug : false , redis_address : 'redis://0.0.0.0:6379/0'", "commit_type": "make"}
{"commit_tokens": ["Fix", "rails2", "for", "nested", "resources"], "add_tokens": "class Resource alias_method :mkd_initialize , :initialize def initialize ( entities , options ) @real_path = options . delete ( :real_path ) @real_path = @real_path . to_s . singularize if @real_path mkd_initialize ( entities , options ) end def nesting_name_prefix @real_path ? \"#{shallow_name_prefix}#{@real_path}_\" : \"#{shallow_name_prefix}#{singular}_\" end def nesting_path_prefix @nesting_path_prefix ||= ( @real_path ? \"#{shallow_path_prefix}/#{path_segment}/:#{@real_path}_id\" : \"#{shallow_path_prefix}/#{path_segment}/:#{singular}_id\" ) end end #localized(nil) do opts [ :real_path ] = opts [ :singular ] || name #end", "del_tokens": "localized ( nil ) do end", "commit_type": "fix"}
{"commit_tokens": ["fixed", "small", "bug", "where", "taxamatch", "returned", "nil", "instead", "of", "false"], "add_tokens": "match = taxamatch_preparsed ( preparsed_1 , preparsed_2 ) rescue false result = false", "del_tokens": "match = taxamatch_preparsed ( preparsed_1 , preparsed_2 ) rescue nil result = nil", "commit_type": "fix"}
{"commit_tokens": ["Updating", "usage", "example", "for", "Natto", "::", "MeCab", "to", "illustrate", "wakati", "use", "."], "add_tokens": "# mecab = Natto::MeCab.new(:output_format_type=>'wakati') # => #<Natto::MeCab:0x28dd471c @ptr=#<FFI::Pointer address=0x28a027d8>, \\ # @options={:output_format_type=>\"wakati\"}, \\ # puts m.parse('ネバネバの組み合わせ美味しいです。') # => ネバネバ の 組み合わせ 美味しい です 。", "del_tokens": "# mecab = Natto::MeCab.new # => #<Natto::MeCab:0x289b88e0 @ptr=#<FFI::Pointer address=0x288865c8>, \\ # @options={}, \\ # puts mecab.parse(\"ネバネバの組み合わせ美味しいです。\") # ネバネバ 名詞,サ変接続,*,*,*,*,ネバネバ,ネバネバ,ネバネバ # の 助詞,連体化,*,*,*,*,の,ノ,ノ # 組み合わせ 名詞,一般,*,*,*,*,組み合わせ,クミアワセ,クミアワセ # 美味しい 形容詞,自立,*,*,形容詞・イ段,基本形,美味しい,オイシイ,オイシイ # です 助動詞,*,*,*,特殊・デス,基本形,です,デス,デス # 。 デス記号,句点,*,*,*,*,。,。,。 # EOS # => nil #", "commit_type": "update"}
{"commit_tokens": ["Fix", "error", "where", "the", "community", "site", "does", "not", "give", "an", "adequate", "response"], "add_tokens": "( @response . parsed_response [ 'error_messages' ] || [ ] ) . map do | error |", "del_tokens": "@response . parsed_response [ 'error_messages' ] . map do | error |", "commit_type": "fix"}
{"commit_tokens": ["Fix", "whitepace", "(", "trailing", "blanks", ")", "."], "add_tokens": "if ud", "del_tokens": "if ud", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "documentation", "tweaked", "tests", "added", "multiple", "-", "when", "-", "done", "test"], "add_tokens": "# batch has completed executing, or a block can be executed.", "del_tokens": "# batch has completed executing.", "commit_type": "add"}
{"commit_tokens": ["Remove", "remaining", "functions", "out", "of", "C", ";", "remove", "rake_compiler", "."], "add_tokens": "require \"h3/structs\" H3_TO_STR_BUF_SIZE = 32 H3_STR = FFI :: MemoryPointer . new ( :char , H3_TO_STR_BUF_SIZE ) attach_function :geoToH3 , [ Structs :: GeoCoord . by_ref , :int ] , H3_INDEX attach_function :h3ToGeo , [ H3_INDEX , :pointer ] , :void attach_function :h3ToString , [ H3_INDEX , :pointer , :int ] , :void def self . geo_to_h3 ( coords , resolution ) raise TypeError unless coords . is_a? ( Array ) raise ArgumentError unless coords . count == 2 raise RangeError if coords . any? { | d | d > 1000000 } lat , lon = coords coords = Structs :: GeoCoord . new coords [ :lat ] = degs_to_rads ( lat ) coords [ :lon ] = degs_to_rads ( lon ) geoToH3 ( coords , resolution ) end def self . h3_to_geo ( h3_index ) coords = Structs :: GeoCoord . new h3ToGeo ( h3_index , coords . pointer ) [ rads_to_degs ( coords [ :lat ] ) , rads_to_degs ( coords [ :lon ] ) ] end def self . h3_to_string ( h3_index ) h3ToString ( h3_index , H3_STR , H3_TO_STR_BUF_SIZE ) H3_STR . read_string end", "del_tokens": "require \"h3/h3\" require \"h3/version\"", "commit_type": "remove"}
{"commit_tokens": ["Add", "follows_from", "option", "to", "Tracer#start_span"], "add_tokens": "# # @param child_of [SpanContext, Span] child_of (ChildOf) refers to a # parent Span that caused *and* somehow depends upon the new child Span. # Often (but not always), the parent Span cannot finish until the child # Span does. # # An timing diagram for a child Span that is blocked on the new Span: # # [-Parent Span----------] # [-Child Span----] # # See http://opentracing.io/documentation/pages/spec # # @param follows_from [SpanContext, Span] follows_from (FollowsFrom) # refers to a parent Span that does not depend in any way on the result # of the new child Span. For instance, one might use FollowsFrom Span to # describe pipeline stages separated by queues, or a fire-and-forget # cache insert at the tail end of a web request. # # A FollowsFrom Span is part of the same logical trace as the new Span: # i.e., the new Span is somehow caused by the work of its FollowsFrom # Span. # # All of the following could be valid timing diagrams for children that # \"FollowFrom\" a parent: # # [-Parent Span--] [-Child Span-] # # [-Parent Span--] # [-Child Span-] # # [-Parent Span-] # [-Child Span-] # # See http://opentracing.io/documentation/pages/spec # # # def start_span ( operation_name , child_of : nil , follows_from : nil , start_time : Time . now , tags : nil )", "del_tokens": "# TODO(bhs): Support FollowsFrom and multiple references # @param child_of [SpanContext, Span] SpanContext that acts as a parent to # the newly-started Span. If a Span instance is provided, its # context is automatically substituted. def start_span ( operation_name , child_of : nil , start_time : Time . now , tags : nil )", "commit_type": "add"}
{"commit_tokens": ["fix", "double", "publishing", "staging", "messages", "during", "release"], "add_tokens": "invoke :integrate , [ 'staging' , '--quiet' ]", "del_tokens": "invoke :integrate , [ 'staging' ]", "commit_type": "fix"}
{"commit_tokens": ["fix", "broken", "tests", "suite", "for", "the", "has_many", "custom", "field"], "add_tokens": "@client . locations_custom_fields . build :label => 'Country' , :_alias => 'country' , :kind => 'String' @project . tasks_custom_fields . build :label => 'Task Locations' , :_alias => 'locations' , :kind => 'has_many' , :target => @client . locations_klass . to_s @company . employees_custom_fields . build :label => 'Task' , :_alias => 'task' , :kind => 'has_one' , :target => @project . tasks_klass . to_s @project . tasks_custom_fields . build :label => 'Developers' , :_alias => 'developers' , :kind => 'has_many' , :target => @company . employees_klass . to_s , :reverse_lookup => 'task'", "del_tokens": "@client . location_custom_fields . build :label => 'Country' , :_alias => 'country' , :kind => 'String' @project . task_custom_fields . build :label => 'Task Locations' , :_alias => 'locations' , :kind => 'has_many' , :target => @client . location_klass . to_s puts \"_______________\" @company . employee_custom_fields . build :label => 'Task' , :_alias => 'task' , :kind => 'has_one' , :target => @project . task_klass . to_s puts \"number of fields #{@company.employee_klass.custom_fields.try(:size) || 0}\" @company . invalidate_employee_klass @company . fetch_employee_klass puts @company . employee_klass . custom_fields . inspect puts \"_______________\" @project . task_custom_fields . build :label => 'Developers' , :_alias => 'developers' , :kind => 'has_many' , :target => @company . employee_klass . to_s , :reverse_lookup => 'task' puts \"========\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "binary", "download", "URIs", "from", "non", "-", "GitHub", "sources"], "add_tokens": "version = config . crate_version return false unless ( tgz = download_versioned_github_release_binary ( uri , version ) ) unless ENV . key? ( 'THERMITE_TEST' ) # :nocov: puts \"Downloading compiled version (#{version}) from GitHub\" # :nocov: http_get ( uri )", "del_tokens": "version = config . toml [ :package ] [ :version ] return unless ( tgz = download_versioned_github_release_binary ( uri , version ) ) # :nocov: def http_get ( uri ) Net :: HTTP . get ( URI ( uri ) ) end # :nocov: case ( response = Net :: HTTP . get_response ( URI ( uri ) ) ) when Net :: HTTPClientError nil when Net :: HTTPServerError raise Net :: HTTPServerException . new ( response . message , response ) else unless ENV . key? ( 'THERMITE_TEST' ) # :nocov: puts \"Downloading latest compiled version (#{version}) from GitHub\" # :nocov: end StringIO . new ( http_get ( response [ 'location' ] ) )", "commit_type": "add"}
{"commit_tokens": ["added", "#base", "and", "#current_account", "helpers", ".", "added", "#follow", "and", "#leave", "."], "add_tokens": "module Helpers def base ( username = current_account . username , password = current_account . password ) @base ||= Twitter :: Base . new ( username , password ) end def current_account @current_account ||= Account . active exit ( 'No current account.' ) if @current_account . blank? @current_account end", "del_tokens": "module Helpers", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "message", "for", "LARGE_ITEM_NOT_FOUND"], "add_tokens": "return nil if result_code == Aerospike :: ResultCode :: KEY_NOT_FOUND_ERROR", "del_tokens": "return if result_code == Aerospike :: ResultCode :: KEY_NOT_FOUND_ERROR", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "deangelo", "-", "llooker", "/", "gzr", "/", "issues", "/", "23"], "add_tokens": "title_used = search_dashboards_by_title ( source [ :title ] , target_space_id ) . fetch ( 0 , nil ) existing_dashboard = search_dashboards_by_slug ( source [ :slug ] , target_space_id ) . fetch ( 0 , nil ) if source [ :slug ] if existing_dashboard then title_used = false if title_used . id == existing_dashboard . id else existing_dashboard = title_used title_used = false end slug_used = false if existing_dashboard && slug_used && slug_used . id == existing_dashboard . id say_warning \"slug #{slug_used.slug} already used for dashboard #{slug_used.title} in space #{slug_used.space_id}\" say_warning \"dashboard will be imported with new slug\" if title_used then raise Gzr :: CLI :: Error , \"Dashboard #{source[:title]} already exists in space #{target_space_id}\\nDelete it before trying to upate another dashboard to have that title.\" end ( keys_to_keep ( 'update_dashboard' ) - [ :space_id , :user_id , :slug ] ) . include? k", "del_tokens": "existing_dashboard = search_dashboards_by_title ( source [ :title ] , target_space_id ) . fetch ( 0 , nil ) if existing_dashboard then if ! ( existing_dashboard . space_id == slug_used . space_id && existing_dashboard . title == slug_used . title ) then say_warning \"slug #{slug_used.slug} already used for dashboard #{slug_used.title} in space #{slug_used.space_id}\" say_warning \"dashboard will be imported with new slug\" end else say_warning \"slug #{slug_used.slug} already used for dashboard #{slug_used.title} in space #{slug_used.space_id}\" say_warning \"dashboard will be imported with new slug\" end ( keys_to_keep ( 'update_dashboard' ) - [ :space_id , :user_id , :title , :slug ] ) . include? k", "commit_type": "fix"}
{"commit_tokens": ["Added", "clean!", "to", "base", "module", ".", "Updated", "Readme"], "add_tokens": "describe \"clean!\" do it \"should clean out the Redis storage for this Predictor\" do BaseRecommender . input_matrix ( :set1 ) BaseRecommender . input_matrix ( :set2 ) sm = BaseRecommender . new sm . set1 . add_set \"item1\" , [ \"foo\" , \"bar\" ] sm . set1 . add_set \"item2\" , [ \"nada\" , \"bar\" ] sm . set2 . add_set \"item3\" , [ \"bar\" , \"other\" ] Predictor . redis . keys ( \"#{sm.redis_prefix}:*\" ) . should_not be_empty sm . clean! Predictor . redis . keys ( \"#{sm.redis_prefix}:*\" ) . should be_empty end end", "del_tokens": "# binding.pry", "commit_type": "add"}
{"commit_tokens": ["Move", "init", ".", "rb", "code", "to", "main", "lib", "code", "to", "make", "it", "easier", "for", "the", "plugins", "to", "become", "gem", "-", "compatible", "."], "add_tokens": "require 'table_helper'", "del_tokens": "require 'table_helper' ActionController :: Base . class_eval do helper PluginAWeek :: Helpers :: TableHelper end", "commit_type": "move"}
{"commit_tokens": ["added", "twittbot", "list", "-", "templates"], "add_tokens": "desc 'generate TEMPLATE_NAME' , 'Installs a template' desc 'list-templates' , 'Lists all templates' def list_templates require 'twittbot/template_lister' lister = Twittbot :: TemplateLister . new options lister . list end", "del_tokens": "desc 'generate TEMPLATE_NAME' , 'Generates a template'", "commit_type": "add"}
{"commit_tokens": ["Use", "null", "-", "safe", "string", "method", "for", "symbols", "as", "well", "as", "strings", "."], "add_tokens": "when String then Lib . lua_pushlstring ( @pointer , o , o . bytesize ) when Symbol then Lib . lua_pushlstring ( @pointer , o . to_s , o . to_s . bytesize )", "del_tokens": "when String then Lib . lua_pushlstring ( @pointer , o , o . unpack ( 'C*' ) . size ) when Symbol then Lib . lua_pushstring ( @pointer , o . to_s )", "commit_type": "use"}
{"commit_tokens": ["fix", "parameter", "name", "for", "sharing", "Files", "and", "folders"], "add_tokens": "@request . put ( [ 'file' , file_id . to_s , 'share' ] , { share : { shareTo : user_id , Access : access_type } } . merge ( options ) ) @request . put ( [ 'folder' , folder_id . to_s , 'share' ] , { share : { shareTo : user_id , Access : access_type } } . merge ( options ) )", "del_tokens": "@request . put ( [ 'file' , file_id . to_s , 'share' ] , { share : { shareTo : user_id , fileShare : access_type } } . merge ( options ) ) @request . put ( [ 'folder' , folder_id . to_s , 'share' ] , { share : { shareTo : user_id , fileShare : access_type } } . merge ( options ) )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "unused", "file", "and", "updated", "transaction", "api", "."], "add_tokens": "def add_transaction_request ( method , url , resource = nil , if_none_exist = nil ) add_batch_request ( method , url , resource , if_none_exist ) def add_batch_request ( method , url , resource = nil , if_none_exist = nil ) request . ifNoneExist = if_none_exist if ! if_none_exist . nil?", "del_tokens": "def add_transaction_request ( method , url , resource = nil ) add_batch_request ( method , url , resource ) def add_batch_request ( method , url , resource = nil )", "commit_type": "remove"}
{"commit_tokens": ["Remove", "all", ".", "rhtml", "occurences"], "add_tokens": "# try to add .html/.htm to see if that exists.", "del_tokens": "# try to add .html/.htm/.rhtml to see if that exists.", "commit_type": "remove"}
{"commit_tokens": ["Add", "initial", "repos", "api", "."], "add_tokens": "class API include Connection include Request include Repos def initialize end private def _validate_user_repo_params end", "del_tokens": "class Api", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "pass", "custom", "enumerator", "builder"], "add_tokens": "# Use this to _always_ interrupt the job after it's been running for more than N seconds. # @example # # JobIteration.max_job_runtime = 5.minutes # # This setting will make it to always interrupt a job after it's been iterating for 5 minutes. # Defaults to nil which means that jobs will not be interrupted except on termination signal. attr_accessor :max_job_runtime # Used internally for hooking into job processing frameworks like Sidekiq and Resque. attr_accessor :interruption_adapter # Set if you want to use your own enumerator builder instead of default EnumeratorBuilder. # @example # # class MyOwnBuilder < JobIteration::EnumeratorBuilder # # ... # end # # JobIteration.enumerator_builder = MyOwnBuilder attr_accessor :enumerator_builder self . enumerator_builder = JobIteration :: EnumeratorBuilder", "del_tokens": "attr_accessor :max_job_runtime , :interruption_adapter", "commit_type": "allow"}
{"commit_tokens": ["Add", "an", "initial", "test", "for", "Draft#publish!"], "add_tokens": "full_published_path = File . expand_path ( \"#{site.directory}/#{Post.dirname}/#{filename}\" )", "del_tokens": "full_published_path = File . expand_path ( \"#{Post.dirname}/#{filename}\" )", "commit_type": "add"}
{"commit_tokens": ["fix", "ExternalCall", "patch", "in", "state", "test"], "add_tokens": "set_fixture_limit 3 ExternalCall . send :alias_method , :apply_msg , :orig_apply_msg", "del_tokens": "set_fixture_limit 1 apply_msg = lambda do | msg , code = nil | orig_apply_msg ( msg , code ) end ExternalCall . send :define_method , :apply_msg , & apply_msg", "commit_type": "fix"}
{"commit_tokens": ["Fix", "specs", "(", "hopefully", ")"], "add_tokens": ":icon_path => Pathname . new ( File . dirname ( __FILE__ ) ) . join ( '../../images/success.png' ) . to_s , :transient => true :transient => true , :icon_path => '~/.guard/success.png' , :transient => true", "del_tokens": ":icon_path => Pathname . new ( File . dirname ( __FILE__ ) ) . join ( '../../images/success.png' ) . to_s :icon_path => '~/.guard/success.png'", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "special", "cases", "in", "Mash", "(", "id", "type", ")"], "add_tokens": "it \"should not call super if id is not a key\" do @mash . id . should == nil end it \"should return the value if id is a key\" do @mash . id = \"Steve\" @mash . id . should == \"Steve\" end it \"should not call super if type is not a key\" do @mash . type . should == nil end", "del_tokens": "# it \"should call super if type is not a key\" do # @mash.type.should == Hashie::Mash # end", "commit_type": "add"}
{"commit_tokens": ["Improve", "how", "Rev", "::", "Loop", ".", "default", "is", "stored"], "add_tokens": "require 'thread' # Monkeypatch Thread to include a method for obtaining the default Rev::Loop class Thread def _rev_loop @_rev_loop ||= Rev :: Loop . new end end Thread . current . _rev_loop", "del_tokens": "@@default_loop = { } # Well awesome, variables stashed in Thread.current[] # are only accessible in the context of the Fiber where # they were stored. Soo... we need to make our own # thread-local store if we want Fiber compatibility # # I think this should be sufficient... but it may need # a mutex or something, got me. @@default_loop [ Thread . current ] ||= Loop . new", "commit_type": "improve"}
{"commit_tokens": ["Move", "to", "passing", "in", "an", "IO", "object", "via", "option", "to", "all", "commands", "that", "accept", "options", "."], "add_tokens": "# @option options [IO] :live_stream an IO object to stream packer output to # in addition to saving output in the output object. command ( args , options [ :live_stream ] ) ) def command ( args , stream = nil ) options = { timeout : execution_timeout , live_stream : stream } # @option options [IO] :live_stream an IO object to stream packer output to # in addition to saving output in the output object. Packer :: Output :: Push . new ( command ( args , options [ :live_stream ] ) ) # @option options [IO] :live_stream an IO object to stream packer output to # in addition to saving output in the output object. Packer :: Output :: Validate . new ( command ( args , options [ :live_stream ] ) )", "del_tokens": "command ( args , options . fetch ( :stream_output , false ) ) ) def command ( args , stream = false ) options = { timeout : execution_timeout } options [ :live_stream ] = $stdout if stream Packer :: Output :: Push . new ( command ( args ) ) Packer :: Output :: Validate . new ( command ( args ) )", "commit_type": "move"}
{"commit_tokens": ["Update", "spec", "to", "remove", "deprecated", "reference", "to", "Fixnum"], "add_tokens": "expect ( result . id ) . to be_a ( Integer )", "del_tokens": "expect ( result . id ) . to be_a ( Fixnum )", "commit_type": "update"}
{"commit_tokens": ["Move", "instance", "methods", "inclusion", "to", "happen", "once", "in", "Memoizable"], "add_tokens": "include InstanceMethods descendant . extend ( ModuleMethods ) private_class_method :included", "del_tokens": "descendant . module_eval do extend ModuleMethods include InstanceMethods end", "commit_type": "move"}
{"commit_tokens": ["Fixed", "nested", "directory", "recursion", "(", "was", "working", "but", "only", "because", "hash", "isn", "t", "present", "on", "subdirs", ")", "."], "add_tokens": "c [ :id ] = entry [ :id ] c [ :modified ] = parse_time ( c [ :modified ] ) if c [ :is_dir ] # queue dir for later c [ :hash ] = entry [ :hash ] recur_dirs << c else # update iff modified out << [ :update , c ] if modified? ( entry , c ) out = ( entry [ :revision ] != res [ :revision ] ) || ( time_to_s ( entry [ :modified ] ) != time_to_s ( res [ :modified ] ) ) out ||= ( entry [ :hash ] != res [ :hash ] ) if res . has_key? ( :hash ) log . debug \"#{entry[:path]}: r#{entry[:revision]} vs. r#{res[:revision]}, h#{entry[:hash]} vs. h#{res[:hash]}, t#{time_to_s(entry[:modified])} vs. t#{time_to_s(res[:modified])} => #{out}\"", "del_tokens": "# update iff modified if modified? ( entry , c ) c [ :id ] = entry [ :id ] c [ :modified ] = parse_time ( c [ :modified ] ) if c [ :is_dir ] c [ :hash ] = entry [ :hash ] recur_dirs << c # queue dir for later else out << [ :update , c ] end log . debug \"#{entry[:path]}: r#{entry[:revision]} vs. r#{res[:revision]}, h#{entry[:hash]} vs. h#{res[:hash]}, t#{time_to_s(entry[:modified])} vs. t#{time_to_s(res[:modified])}\" out = ! ( entry [ :revision ] == res [ :revision ] && entry [ :hash ] == res [ :hash ] && time_to_s ( entry [ :modified ] ) == time_to_s ( res [ :modified ] ) )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "for", "all", "options", "in", "#upload", "."], "add_tokens": "include DropboxApi :: Endpoints :: OptionsValidator # @example # client = DropboxApi::Client.new # client.upload \"/file.txt\", \"File contents...\", :mode => :add # #=> #<DropboxApi::Metadata::File: @name=\"file (1).txt\" ...> # @option options mode [DropboxApi::Metadata::WriteMode] Selects what to # do if the file already exists. The default is +add+. # @option options autorename [Boolean] If there's a conflict, as determined # by +mode+, have the Dropbox server try to autorename the file to avoid # conflict. The default for this field is +false+. # @option options client_modified [DateTime] The value to store as the # +client_modified+ timestamp. Dropbox automatically records the time at # which the file was written to the Dropbox servers. It can also record # an additional timestamp, provided by Dropbox desktop clients, mobile # clients, and API apps of when the file was actually created or # modified. # @see DropboxApi::Metadata::WriteMode validate_options ( [ :mode , :autorename , :client_modified , :mute ] , options ) options [ :mode ] = build_write_mode_param ( options [ :mode ] ) if options [ :mode ] options [ :client_modified ] = options [ :client_modified ] . utc . strftime ( \"%FT%TZ\" ) if options [ :client_modified ] perform_request ( options . merge ( { :path => path } ) , content ) end private def build_write_mode_param ( write_mode ) case write_mode when String , Symbol DropboxApi :: Metadata :: WriteMode . new write_mode when DropboxApi :: Metadata :: WriteMode write_mode else raise ArgumentError , \"Invalid write mode: #{write_mode.inspect}\" end . to_hash", "del_tokens": "# @option options autorename [Boolean] If there's a conflict, as # determined by mode, have the Dropbox server try to autorename the # file to avoid conflict. The default for this field is False. # @option options mute [Boolean] Normally, users are made aware of any file # modifications in their Dropbox account via notifications in the client # software. If true, this tells the clients that this modification # shouldn't result in a user notification. The default for this field is # `false`. perform_request ( { :path => path } , content )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "return", "column", "widths", "."], "add_tokens": "renderer . resize ? expand : renderer . column_widths shrink ColumnSet . widths_from ( table )", "del_tokens": "renderer . column_widths = expand if renderer . resize renderer . column_widths = shrink renderer . column_widths = ColumnSet . widths_from ( table )", "commit_type": "change"}
{"commit_tokens": ["fixed", "typo", "in", "log", "name"], "add_tokens": ":log => 'log/boxgrinder.log'", "del_tokens": ":log => 'log/boxgridner.log'", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "bad", "responses", "."], "add_tokens": "\"#{code.to_s} #{response.msg}\" . strip when Hash : errors . collect { | k , v | \"#{k}: #{v}\" }", "del_tokens": "puts \"#{code} #{response.msg}\" when Hash : errors . collect { | k , v | \"#{k} #{v}\" }", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "to", "ensure", "connection", "is", "reset", "if", "filter", "chain", "is", "halted"], "add_tokens": "around_action :halt_filter_chain , :if => proc { | c | c . params [ :halt_filter_chain ] } around_action :explode , :if => proc { | c | c . params [ :explode ] } def halt_filter_chain false end def explode raise end record = SourceRecord . create! ( :name => 'reset test' ) get :index expect ( SourceRecord . last ) . to eq ( record ) end it 'resets to the previous connection when the filter chain is halted' do record = SourceRecord . create! ( :name => 'reset after halt test' ) get :index , :halt_filter_chain => true expect ( SourceRecord . last ) . to eq ( record ) end it 'resets to the previous connection if the action raises an exception' do record = SourceRecord . create! ( :name => 'reset after raise test' ) begin get :index , :explode => true ; rescue ; end expect ( SourceRecord . last ) . to eq ( record )", "del_tokens": "expect do SourceRecord . create get :index SourceRecord . create end . to change { SourceRecord . count } . by ( 2 )", "commit_type": "add"}
{"commit_tokens": ["Remove", "log", "and", "fix", "conditional"], "add_tokens": "session [ :cart_id ] = params [ :order_id ] if params [ :order_id ] and request . env [ 'PATH_INFO' ] . include? ( 'checkout' )", "del_tokens": "ap request . env [ 'PATH_INFO' ] ap request . env [ 'PATH_INFO' ] . split ( '/' ) ap request . env [ 'PATH_INFO' ] . split ( '/' ) . first == 'checkout' ap '----------' session [ :cart_id ] = params [ :order_id ] if params [ :order_id ] # and request.env['PATH_INFO'].split('/').first == 'checkout'", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "specifying", "a", "left", "recursive", "start", "rule"], "add_tokens": "# We invoke the rules indirectly via apply # instead of by just calling them as methods because # if the rules use left recursion, apply needs to # manage that. apply ( :_root ) apply :\" _ #{ method } \"", "del_tokens": "_root ? true : false # This is not shared with code_generator.rb so this can be standalone __send__ ( \"_#{method}\" ) ? true : false", "commit_type": "fix"}
{"commit_tokens": ["added", "first", "round", "of", "catalog", "objects"], "add_tokens": "# Core modules irequire 'modules' , 'create.rb' irequire 'modules' , 'deleted.rb' irequire 'modules' , 'list.rb' irequire 'modules' , 'search.rb' irequire 'modules' , 'show.rb' irequire 'modules' , 'update.rb' # Core classes # Errors irequire 'errors' , 'method_unavailable_error.rb' # Endpoint Classes irequire 'brokerage.rb' irequire 'category.rb' irequire 'client.rb' irequire 'event.rb' irequire 'office.rb' irequire 'user.rb'", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "rel", "parameter", "to", "the", "links", "."], "add_tokens": "items << link_to ( image_tag ( thumbnail_image ) , full_image , rel : 'simple-gallery' )", "del_tokens": "items << link_to ( image_tag ( thumbnail_image ) , full_image )", "commit_type": "add"}
{"commit_tokens": ["make", "older", "rails", "apps", "happy", "without", "using", "Hash", ".", "compact!"], "add_tokens": "options = options . compact", "del_tokens": "options . compact!", "commit_type": "make"}
{"commit_tokens": ["change", "owner", "role", "to", "owner"], "add_tokens": "attribute :owner , singular : true , kind : :role", "del_tokens": "attribute :role , singular : true", "commit_type": "change"}
{"commit_tokens": ["remove", "@@unique_id", "which", "isn", "t", "doing", "anything"], "add_tokens": "instance = klazz . find ( obj . pid )", "del_tokens": "# # Class variables # @@unique_id = 0 def self . unique_id @@unique_id end instance = klazz . load_instance ( obj . pid ) # increment the unique id to ensure that all documents in the search index are unique @@unique_id += 1", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "remaining", "flags", "on", "mirror", "update"], "add_tokens": "cmd = 'aptly mirror create' def update ignore_cksum : false , ignore_sigs : false cmd = 'aptly mirror update' cmd += ' -ignore-checksums' if ignore_cksums cmd += ' -ignore-signatures' if ignore_sigs cmd += \" #{@name.to_safe}\" Aptly :: runcmd cmd", "del_tokens": "cmd = \"aptly mirror create\" def update Aptly :: runcmd \"aptly mirror update #{@name.to_safe}\"", "commit_type": "implement"}
{"commit_tokens": ["Add", "embed", "code", "piece", "types"], "add_tokens": "'One Column of Text' => 'FullWidthText' , 'Two Columns of Text' => 'TwoColumnText' , 'Three Columns of Text' => 'ThreeColumnText' , 'One Column Image' => 'FullWidthImage' , 'Wrapped Image with Text' => 'LeftWrappedImageWithText' , 'Image and Text (No Wrap)' => 'LeftImageRightText' , 'Embedded Content' => 'FullWidthEmbeddedContent'", "del_tokens": "'One Column of Text' => 'FullWidthText' , 'Two Columns of Text' => 'TwoColumnText' , 'Three Columns of Text' => 'ThreeColumnText' , 'One Column Image' => 'FullWidthImage' , 'Wrapped Image with Text' => 'LeftWrappedImageWithText' , 'Image and Text (No Wrap)' => 'LeftImageRightText'", "commit_type": "add"}
{"commit_tokens": ["Created", "new", "release", "with", "pdf", "engine", "options"], "add_tokens": "VERSION = [ 0 , 2 , 5 , 7 ]", "del_tokens": "VERSION = [ 0 , 2 , 5 , 6 ]", "commit_type": "create"}
{"commit_tokens": ["Change", "to", "use", "latest", "syntax"], "add_tokens": "def initialize ( ** settings )", "del_tokens": "def initialize ( settings = { } )", "commit_type": "change"}
{"commit_tokens": ["fix", "presence", "channel", "&", "some", "styles"], "add_tokens": "get_user_data . where ( \"users.email =?\" , @user_data [ :email ] )", "del_tokens": ". where ( \"users.email =?\" , params [ :email ] )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "Linux", "path", "opening", "."], "add_tokens": "hidapi_regex = / ^ \\/ dev \\/ hidapi \\/ / usb_bus_regex = / ^ \\/ dev \\/ bus \\/ usb \\/ (?<BUS> \\d +) \\/ (?<ADDR> \\d +)$ / if hidapi_regex . match ( path ) path = File . expand_path ( File . readlink ( path ) , File . dirname ( path ) ) elsif ! usb_bus_regex . match ( path ) raise HIDAPI :: DevicePathInvalid , 'Cannot open file paths other than /dev/hidapi/XXX or /dev/bus/usb/XXX/XXX paths.' end match = usb_bus_regex . match ( path ) interface = ( options . delete ( :interface ) || 0 ) . to_s ( 16 ) path = HIDAPI :: Device . validate_path ( \"#{match['BUS']}:#{match['ADDR']}:#{interface}\" )", "del_tokens": "raise HIDAPI :: DevicePathInvalid , 'Cannot open file paths other than /dev/hidapi paths.' unless path . index ( '/dev/hidapi/' ) == 0 path = File . expand_path ( File . readlink ( path ) , File . dirname ( path ) ) match = / \\/ dev \\/ bus \\/ usb \\/ (?<BUS> \\d +) \\/ (?<ADDR> \\d +) / . match ( path ) path = HIDAPI :: Device . validate_path ( \"#{match['BUS']}:#{match['ADDR']}:0\" )", "commit_type": "improve"}
{"commit_tokens": ["added", "touch", "exists", "delete", "get_header"], "add_tokens": "writeOperationForOperationType ( Apik :: Operation :: TOUCH ) writeOperationForBinName ( '' , Apik :: Operation :: READ ) @dataOffset += binName . length + OPERATION_HEADER_SIZE", "del_tokens": "writeOperationForOperationType ( TOUCH ) writeOperationForBinName ( '' , READ ) @dataOffset += binNam . length + OPERATION_HEADER_SIZE", "commit_type": "add"}
{"commit_tokens": ["Added", "query", "methods", "for", "action", "types"], "add_tokens": "# => true if action is a new_action # => true if action is a collection_action def collection_action? ( action ) collection_actions . include? action . to_sym end # => true if action is a member_action def member_action? ( action ) member_actions . include? action . to_sym end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "CLI", "bug", "where", "timeline", "was", "being", "put", "in", "the", "wrong", "place", "when", "output", "dir", "is", "specified", "without", "a", "trailing", "slash"], "add_tokens": "def timeline_page_path File . join ( outdir , 'timeline.html' ) end File . open ( timeline_page_path , 'w+' ) do | doc | %x[ open #{ timeline_page_path } ]", "del_tokens": "File . open ( outdir + 'timeline.html' , 'w+' ) do | doc | %x{ open #{ outdir } timeline.html }", "commit_type": "fix"}
{"commit_tokens": ["made", "broke", "out", "worker", "restart", "from", "jobspec", "creation"], "add_tokens": "sleep 10 Jobtracker . update_status ( \"put workers back on the queue\" ) Jobtracker . update_status ( \"#{Jobtracker.to_s} still on queue, waiting\" ) Jobtracker . update_status ( \"Sent notification at #{Jobtracker.last_notification}\" ) Jobtracker . set_test_env Jobtracker . update_status ( \"delete old books and datasets\" ) Jobtracker . update_status ( \"enqueue jobtracker, wait 45s\" )", "del_tokens": "sleep 5 puts \"#{Jobtracker.to_s} still on queue, waiting\" \"Sent notification at #{Jobtracker.last_notification}\" . oputs Mobilize :: Jobtracker . kill_workers sleep 5 puts 'enqueue 4 workers on Resque' Mobilize :: Jobtracker . prep_workers puts \"delete old books and datasets\" puts \"enqueue jobtracker, wait 45s\"", "commit_type": "make"}
{"commit_tokens": ["Adds", "functionality", "to", "allow", "dependency", "validation"], "add_tokens": "VERSION = \"1.1.0\"", "del_tokens": "VERSION = \"1.0.9\"", "commit_type": "add"}
{"commit_tokens": ["Move", "master", "nil", "check", "above", "slave", "node", "check"], "add_tokens": "# Skip this group if there is no master next if master . nil?", "del_tokens": "# Skip this group if there is no master next if master . nil?", "commit_type": "move"}
{"commit_tokens": ["made", "dispatch", "more", "rack", "compliant", "."], "add_tokens": "return [ 500 , { 'Content-Type' => 'text/plain' } , [ \"Server Not Ready\" ] ] if @booting [ 500 , { 'Content-Type' => 'text/plain' } , [ \"Exception: #{e}\\n\\n#{bt}\" ] ]", "del_tokens": "return [ 500 , { } , \"Server Not Ready\" ] if @booting [ 500 , { } , \"Exception: #{e}\\n\\n#{bt}\" ]", "commit_type": "make"}
{"commit_tokens": ["Use", "assert_dom_equal", "when", "speaking", "HTMLish"], "add_tokens": "assert_dom_equal %Q{<ul>} , @builder . open_tabs assert_dom_equal %Q{<ul style=\"foo\">} , @builder . open_tabs ( :style => \"foo\" ) assert_dom_equal %Q{</ul>} , @builder . close_tabs assert_dom_equal %Q{</ul>} , @builder . close_tabs ( :foo => \"bar\" ) assert_dom_equal %Q{<li><a href=\"#\">Welcome</a></li>} , @builder . tab_for ( :welcome , 'Welcome' , '#' ) assert_dom_equal %Q{<li><a href=\"http://foobar.com/\">Foo Bar</a></li>} , @builder . tab_for ( :welcome , 'Foo Bar' , 'http://foobar.com/' ) assert_dom_equal %Q{<li><span>Dashboard</span></li>} , @builder . tab_for ( :dashboard , 'Dashboard' , '#' ) assert_dom_equal %Q{<li><span>Foo Bar</span></li>} , @builder . tab_for ( :dashboard , 'Foo Bar' , '#' )", "del_tokens": "assert_equal '<ul>' , @builder . open_tabs assert_equal '<ul style=\"foo\">' , @builder . open_tabs ( :style => \"foo\" ) assert_equal \"</ul>\" , @builder . close_tabs assert_equal '</ul>' , @builder . close_tabs ( :foo => \"bar\" ) assert_dom_equal '<li><a href=\"#\">Welcome</a></li>' , @builder . tab_for ( :welcome , 'Welcome' , '#' ) assert_dom_equal '<li><a href=\"http://foobar.com/\">Foo Bar</a></li>' , @builder . tab_for ( :welcome , 'Foo Bar' , 'http://foobar.com/' ) assert_dom_equal '<li><span>Dashboard</span></li>' , @builder . tab_for ( :dashboard , 'Dashboard' , '#' ) assert_dom_equal '<li><span>Foo Bar</span></li>' , @builder . tab_for ( :dashboard , 'Foo Bar' , '#' )", "commit_type": "use"}
{"commit_tokens": ["Made", "DWrite", "accept", "transfer_syntax", "as", "a", "keyword", "to", "improve", "its", "ability", "to", "write", "DICOM", "objects", "without", "meta", "header"], "add_tokens": "@stream . encode_last ( \"0000\" , \"HEX\" ) # (2 reserved bytes) @stream . encode_last ( \"0001\" , \"HEX\" ) # (Value) value = @stream . encode_value ( @implementation_uid , \"STR\" ) value = @stream . encode_value ( @implementation_name , \"STR\" ) # Version information: @implementation_uid = \"1.2.826.0.1.3680043.8.641\" @implementation_name = \"RUBY_DICOM_0.6\"", "del_tokens": "@stream . encode_last ( \"0000\" , \"HEX\" ) @stream . encode_last ( \"0100\" , \"HEX\" ) value = @stream . encode_value ( \"1.2.826.0.1.3680043.8.641\" , \"STR\" ) # Ruby DICOM UID value = @stream . encode_value ( \"RUBY_DICOM\" , \"STR\" )", "commit_type": "make"}
{"commit_tokens": ["Added", "active_scaffold_controller_for", "refactored", "_nested", ".", "rhtml", "."], "add_tokens": "controller = active_scaffold_controller_for ( klass ) return controller . active_scaffold_config unless controller . nil? or ! controller . uses_active_scaffold? def active_scaffold_controller_for ( klass , parent_controller = nil ) controller_named_path = \"\" controller_path = \"\" if parent_controller path = parent_controller . split ( '/' ) path . pop # remove the parent controller path . collect! { | p | p . capitalize } controller_named_path = \"#{path.join(\"::\")}::\" controller_path = \"#{path.join(\"/\")}/\" end [ \"#{klass.to_s}\" , \"#{klass.to_s.pluralize}\" ] . each do | controller_name | controller = \"#{controller_named_path}#{controller_name.camelize}Controller\" . constantize rescue next return \"#{controller_path}#{controller_name}\" end nil end", "del_tokens": "[ \"#{klass.to_s}\" , \"#{klass.to_s.pluralize}\" ] . each do | controller_name | controller = eval ( \"#{controller_name}Controller\" ) rescue next return controller . active_scaffold_config if controller . uses_active_scaffold? end", "commit_type": "add"}
{"commit_tokens": ["Add", "specs", "for", "Queryable#empty?", "."], "add_tokens": "query_pairs . map { | pair | pair . map { | e | escape ? CGI :: escape ( e . to_s ) : e } . join ( \"=\" ) } . join ( '&' )", "del_tokens": "query_pairs . map { | pair | pair . map { | e | escape ? CGI :: escape ( e . to_s ) : e } . join ( \"=\" ) } . join ( '&' )", "commit_type": "add"}
{"commit_tokens": ["Add", "Unreloader#record_split_class", "for", "handling", "classes", "split", "into", "multiple", "files"], "add_tokens": "if opts . fetch ( :reload , true ) @reloader = @cooldown = false if @reloader if @reloader # Record that a class is split into multiple files. +main_file+ should be # the main file for the class, which should require all of the other # files. +files+ should be a list of all other files that make up the class. def record_split_class ( main_file , * files ) if @reloader files = Unreloader . expand_paths ( files ) files . each do | file | record_dependency ( file , main_file ) end @reloader . skip_reload ( files ) end end", "del_tokens": "if @reload = opts . fetch ( :reload , true ) @cooldown = false if @reload if @reload", "commit_type": "add"}
{"commit_tokens": ["Remove", "conditional", "and", "file", "check", "for", "speedup"], "add_tokens": "Dir [ \"#{dir_path}/#{pattern}/*.yml\" ] . map do | p | Page . new p", "del_tokens": "Dir [ \"#{dir_path}/#{pattern}/*.yml\" ] . map do | p | Page . new ( p ) if ( File . file? ( p ) )", "commit_type": "remove"}
{"commit_tokens": ["Implement", "chainability", "through", "pure", "Client", "branching", "."], "add_tokens": "branch ( options ) . request verb , uri branch default_options . with_callback ( event , block ) branch default_options . with_headers ( headers ) def default_options @default_options ||= Options . new def default_options = ( opts ) @default_options = Options . new ( opts ) private def branch ( options ) Client . new ( options )", "del_tokens": "options = options . dup options [ :response ] ||= ( verb == :head ? :object : :parsed_body ) options [ :headers ] = default_headers . merge ( options [ :headers ] || { } ) options [ :callbacks ] = event_callbacks default_client . request verb , uri , options EventCallback . new event , event_callbacks , & block Parameters . new default_headers . merge ( headers ) def default_client @default_client ||= Client . new end def default_client = ( default_client ) @default_client = default_client def default_headers @default_headers ||= { } def default_headers = ( headers ) @default_headers = headers end def event_callbacks @event_callbacks ||= { } def event_callbacks = ( callbacks ) @event_callbacks = callbacks end", "commit_type": "implement"}
{"commit_tokens": ["use", "mkpath", "instead", "for", "mkdir"], "add_tokens": "FileUtils . mkpath directory unless Dir . exists? directory", "del_tokens": "Dir . mkdir directory unless Dir . exists? directory", "commit_type": "use"}
{"commit_tokens": ["added", "textarea", "model", "for", "pages"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20141021183653 ) do create_table \"fae_text_areas\" , force : true do | t | t . integer \"contentable\" t . string \"label\" t . text \"content\" t . integer \"position\" , default : 0 t . boolean \"on_stage\" , default : true t . boolean \"on_prod\" , default : false t . datetime \"created_at\" t . datetime \"updated_at\" end", "del_tokens": "ActiveRecord :: Schema . define ( version : 20141021181927 ) do", "commit_type": "add"}
{"commit_tokens": ["add", "JSONProp", "Stack", "and", "the", "ability", "to", "update", "properties", "in", "bulk"], "add_tokens": "else JSONProp . new ( key : key ) require 'aws_cf/props/json_prop'", "del_tokens": "else StringProp . new ( key : key ) #TODO fail ArgumentError, \"Invalid spec: #{spec_line}\"", "commit_type": "add"}
{"commit_tokens": ["Make", "some", "has_many", "options", "unsupported"], "add_tokens": "super + [ :active_model , :target_ids ] - [ :through , :dependent , :source , :source_type , :counter_cache , :as ]", "del_tokens": "super + [ :active_model , :target_ids ]", "commit_type": "make"}
{"commit_tokens": ["Fix", "typos", "that", "cause", "NameError", "rather", "than", "ConfigFileError", "to", "be", "raised", "."], "add_tokens": "no_config_file_error ( target ) raise ConfigFileError , \"There is no config file at #{filename}\" end", "del_tokens": "no_config_file_error ( file ) raise ConfigFileError , \"There is no config file at #{file}\" end", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "spec", "for", "a", "bug"], "add_tokens": "# given it \"should not index nodes that are not part of the relationship\" do pending # when c = nil Neo4j :: Transaction . run do c = Customer . new o = Order . new c . name = \"kalle\" o . cost = \"123\" end # then orders = Order . find ( 'Customer.name' => 'kalle' ) orders . size . should == 0 end it \"should index relationships\" do", "del_tokens": "it \"should index relationships\" do # use Order index # id is the node id of Order.nodeId . Customer.nodeId # update document key: Customer.name value", "commit_type": "add"}
{"commit_tokens": ["added", "attribute", "method", "to", "SemanticAttributesHelper"], "add_tokens": "@@value_methods = %w/ to_label display_name full_name name title username login value to_s / cattr_reader :label_str_method def attribute ( method ) label_class = [ \"label\" ] value_class = [ \"value\" ] content = [ template . content_tag ( :span , label_for_attribute ( method ) , { :class => label_class . join ( \" \" ) } ) , template . content_tag ( :span , value_of_attribute ( method ) , { :class => value_class . join ( \" \" ) } ) ] . join template . content_tag ( :li , content ) end def label_for_attribute ( method ) if record . class . respond_to? ( :human_attribute_name ) record . class . human_attribute_name ( method . to_s ) else method . to_s . send ( :humanize ) end end def value_of_attribute ( method ) record . send ( method ) . to_s", "del_tokens": "@@label_str_method = :humanize @@value_methods = %w/ to_label display_name fill_name name title username login value to_s / def attribute", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "initial", "and", "final", "XOR", "masks", "for", "Digest", "::", "CRC16Genibus", "."], "add_tokens": "require 'digest/crc16_genibus' describe Digest :: CRC16Genibus do let ( :expected ) { 'cde7' }", "del_tokens": "require 'digest/crc16_modbus' describe Digest :: CRC16Modbus do let ( :expected ) { 'c20a' }", "commit_type": "fix"}
{"commit_tokens": ["Added", "CVE", "-", "2013", "-", "1821", ".", "Adding", "this", "check", "introduces", "a", "new", "RubyVersionCheck"], "add_tokens": "it \"must have test for CVE-2013-1821\" do sc = kb . find ( \"CVE-2013-1821\" ) sc . should_not be_nil sc . class . should == Codesake :: Dawn :: Kb :: CVE_2013_1821 end", "del_tokens": "it \"must have test for CVE-2013-1821\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "per", "-", "file", "non", "-", "post", "layouts", "based", "on", "the", "header", "value", "."], "add_tokens": "if layout_option if layout_option == \"none\" f . puts Liquid :: Template . parse ( file . to_s ) . render! ( \"site\" => self ) else layout_file = File . join ( self . directory , \"_layouts\" , \"#{layout_option}.html\" ) layout = Liquid :: Template . parse ( File . read ( layout_file ) ) f . puts layout . render! ( \"page\" => { \"title\" => [ title ] . compact } , \"content\" => Liquid :: Template . parse ( file . to_s ) . render! ( \"site\" => self ) ) end", "del_tokens": "if layout_option == \"none\" f . puts Liquid :: Template . parse ( file . to_s ) . render! ( \"site\" => self )", "commit_type": "allow"}
{"commit_tokens": ["Updated", "app", "version", "and", "history"], "add_tokens": "BUGFIX = 2", "del_tokens": "BUGFIX = 1", "commit_type": "update"}
{"commit_tokens": ["Allow", "credentials", "to", "be", "set", "via", "the", "configure", "block"], "add_tokens": "def initialize ( options = nil ) options = { :username => Metaforce . configuration . username , :password => Metaforce . configuration . password , :security_token => Metaforce . configuration . security_token } if options . nil?", "del_tokens": "def initialize ( options = { } )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "to", "search", "UPCAST", "reciprocally", "on", "blas_char", "method"], "add_tokens": "t = k :: UPCAST [ t ] || t :: UPCAST [ k ]", "del_tokens": "t = k :: UPCAST [ t ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "order", "behavior", ".", "Keep", "param", "sequence", "for", "order", "method"], "add_tokens": "When / ^(order|reorder) \"([^\"]+)\" records by \"([^\"]+)\"$ / do | sort_method , klass , attributes | step %Q(#{sort_method} records by \"#{attributes}\") When / ^(order|reorder) records by \"([^\"]+)\"$ / do | sort_method , attributes | @records = @records . send ( sort_method , fields )", "del_tokens": "When / ^order \"([^\"]+)\" records by \"([^\"]+)\"$ / do | klass , attributes | step %Q(order records by \"#{attributes}\") When / ^order records by \"([^\"]+)\"$ / do | attributes | @records = @records . order ( fields )", "commit_type": "fix"}
{"commit_tokens": ["made", "readline", "a", "plugin", "and", "allowed", "for", "non", "-", "irb", "console"], "add_tokens": "options = { :readline_plugin => Bond :: Readline } . merge options extend ( options [ :readline_plugin ] ) setup all_input = line_buffer Object . const_defined? ( :IRB ) ? Mission . new ( :action => IRB :: InputCompletor :: CompletionProc ) : lambda { | e | [ ] }", "del_tokens": "Defaultbreakchars = \" \\t\\n\\\"\\\\'`><=;|&{(\" Readline . completion_append_character = nil if Readline . respond_to? ( \"basic_word_break_characters=\" ) Readline . basic_word_break_characters = Defaultbreakchars end Readline . completion_proc = self all_input = Readline . line_buffer Mission . new :action => IRB :: InputCompletor :: CompletionProc", "commit_type": "make"}
{"commit_tokens": ["Add", "specs", "for", "Util", ".", "escape_zero_byte", "."], "add_tokens": "class Dummy include Ethon :: Easies :: Util end let ( :klass ) { Dummy . new } context \"when value has no zero byte\" do let ( :value ) { \"hello world\" } it \"returns same value\" do klass . escape_zero_byte ( value ) . should be ( value ) end end context \"when value has zero byte\" do let ( :value ) { \"hello \\0world\" } it \"returns escaped\" do klass . escape_zero_byte ( value ) . should eq ( \"hello \\\\0world\" ) end end", "del_tokens": "let ( :hash ) { { } } let ( :params ) { Ethon :: Easies :: Params . new ( hash ) } it", "commit_type": "add"}
{"commit_tokens": ["Adds", "the", "start", "of", "a", "renderer"], "add_tokens": "# [\"#{root}/path/one\", \"/file2.rb\"], # [\"#{root}/path/two\", \"/file1.rb\"]", "del_tokens": "# [\"#{root}/path/one\", \"#{root}/file2.rb\"], # [\"#{root}/path/two\", \"#{root}/file1.rb\"]", "commit_type": "add"}
{"commit_tokens": ["added", "cli", "and", "started", "to", "convert", "to", "a", "gem"], "add_tokens": "def self . create ( config , default_config ) watcher_class = config [ :name ] watcher_class . classify . constantize . new ( default_config ) \"#{Roy::Client.queue_prefix}-#{@options[:name]}\" , while Roy :: Client . keep_running? do message = message . to_json if message . is_a? Hash @queue . send_message ( message )", "del_tokens": "def self . create ( config ) watcher_class = config [ :perform ] . to_s watcher_class . classify . constantize . new ( config [ :queue ] ) \"#{Roy.queue_prefix}-#{@options[:name]}\" , while Roy . keep_running? do @queue . send_message ( message . to_json )", "commit_type": "add"}
{"commit_tokens": ["created", "test", "for", "one", "pixel", "images", "(", "fail", ")"], "add_tokens": "it \"should create a image of one pixel of color #{c.r}, #{c.g}, #{c.b}\" do image = Image . new ( 1 , 1 ) { | x , y | c } image . get_pixel ( 0 , 0 ) . should be == c end test_one_pixel ( Color . from_rgba ( 0 , 0 , 0 , 255 ) ) test_one_pixel ( Color . from_rgba ( 255 , 255 , 255 , 255 ) ) test_one_pixel ( Color . from_rgba ( 255 , 255 , 255 , 128 ) ) 10 . times do test_one_pixel ( Color . from_rgba ( rand ( 255 ) , rand ( 255 ) , rand ( 255 ) , rand ( 255 ) ) ) end", "del_tokens": "image = Image . new ( 1 , 1 ) { | x , y | c } image . get_pixel ( x , y ) . should be == c", "commit_type": "create"}
{"commit_tokens": ["Add", "license", "to", "Gem", "spec"], "add_tokens": "VERSION = '0.1.1'", "del_tokens": "VERSION = '0.1.0'", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "and", "clean", "up", "code", "a", "bit", "."], "add_tokens": "private return string unless string . is_a? String # Try it as UTF-8 directly cleaned = string . dup . force_encoding ( 'UTF-8' ) if cleaned . valid_encoding? cleaned else utf8clean ( string ) end utf8clean ( string ) end def utf8clean ( string ) # Force it to UTF-8, throwing out invalid bits string . encode ( 'UTF-16' , 'UTF-8' , :invalid => :replace , :replace => '' ) . encode ( 'UTF-8' , 'UTF-16' )", "del_tokens": "return string unless string . is_a? String # Try it as UTF-8 directly cleaned = string . dup . force_encoding ( 'UTF-8' ) if cleaned . valid_encoding? cleaned else # Some of it might be old Windows code page string . encode ( Encoding :: UTF_8 , Encoding :: Windows_1250 ) end # Force it to UTF-8, throwing out invalid bits string . encode ( 'UTF-16' , 'UTF-8' , :invalid => :replace , :replace => '' ) . encode ( 'UTF-8' , 'UTF-16' )", "commit_type": "add"}
{"commit_tokens": ["fixed", "class", "scope", "+", "query", "chaining"], "add_tokens": "delegate :all , :order_by , :sort_by , :order , :sort , :limit , :where , to : :blank_relation # Reset params when directly called on association class # def where(*args) # blank_relation.params = {} # blank_relation.where(*args) # end @blank_relation . params = { } @blank_relation end def method_missing ( name , * args , & block ) puts \"==========> method missing! #{name}\" blank_relation . send ( name , * args , & block )", "del_tokens": "delegate :all , :where , :order_by , :sort_by , :order , :sort , :limit , to : :blank_relation", "commit_type": "fix"}
{"commit_tokens": ["changing", "default", "to", "bcrypt", "adding", "gem", "dependency"], "add_tokens": ":@encryption_provider => CryptoProviders :: BCrypt ,", "del_tokens": ":@encryption_provider => CryptoProviders :: SHA256 ,", "commit_type": "change"}
{"commit_tokens": ["remove", "setting", "timestamp", "for", "now"], "add_tokens": "@metadata = event_data . fetch ( :metadata , { } )", "del_tokens": "@metadata = event_data . fetch ( :metadata , { timestamp : Time . now . utc } )", "commit_type": "remove"}
{"commit_tokens": ["allow", "multiple", "filter", "parameters", "to", "be", "passed", "through", "as", "a", ":", "delimited", "string"], "add_tokens": "filter_pieces = filter_string . split ( \":\" ) name = filter_pieces . shift value = filter_pieces . join ( \":\" ) value = nil unless value . present?", "del_tokens": "name , value = filter_string . split ( \":\" )", "commit_type": "allow"}
{"commit_tokens": ["Updating", "readme", "and", "merging", "in", "a", "couple", "new", "storage", "tests"], "add_tokens": "def load_30_errors end def test_get_many_options load_30_errors # def test_dump # load_30_errors # assert @s.dump('errors').length > 0 # end def test_ids load_30_errors assert_equal 31 , @s . ids ( 'errors' ) . length end", "del_tokens": "def test_get_many_options", "commit_type": "update"}
{"commit_tokens": ["Changed", "inflectors", "for", "irregulars", "."], "add_tokens": "# Put singular-form to plural form transformations here [ / ^person$ / , 'people' ] , [ / ^child$ / , 'children' ] , # Put plural-form to singular form transformations here [ / ^people$ / , 'person' ] , [ / ^children$ / , 'child' ] ,", "del_tokens": "[ 'person' , 'people' ] , [ 'people' , 'person' ] , [ 'children' , 'child' ] , [ 'child' , 'children' ]", "commit_type": "change"}
{"commit_tokens": ["added", "some", "more", "attributes", "for", "an", "account"], "add_tokens": "data = '0256' # Länge des Datensatzes data += 'Q' # Satzart data += '%8i' % @account . bank_number # BLZ des Einreichinstituts data += '%10i' % @account . nr # Kundennummer data += '%35s' % @account . street # Einreichinstitut Zeile 1 u. 2: Name; Zeile 3: Straße Postfach; Zeile 4: Ort data += '%35s' % @account . city # Einreichinstitut Zeile 1 u. 2: Name; Zeile 3: Straße Postfach; Zeile 4: Ort data += @date . strftime ( \"%y%m%d\" ) # Erstellungsdatum In der Form JJMMTT data += '01' # laufende Nummer Laufende Tagesnummer data += '%095i' % 0 # Reserve raise \"DTAUS: Längenfehler P (#{data.size} <> 256)\\n\" f ata. s ize = 56 dta_string << data", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "an", "encapsulation", "issue", "during", "inheritance"], "add_tokens": "@contract = Contract . new ( assurances : contract . assurances . clone , expectations : contract . expectations . clone , consequences : contract . consequences . clone )", "del_tokens": "@contract = contract", "commit_type": "fix"}
{"commit_tokens": ["allow", "specifying", "class", "names", "and", "multiple", "classes", "in", "formatter", "mappings"], "add_tokens": "add ( [ String , Numeric , TrueClass , FalseClass ] , :object ) # You can add multiple classes at once by passing an array of classes. # # You can also pass class names as strings instead of the classes themselves. This can # help avoid loading dependency issues. This applies only to classes; modules cannot be # passed in as strings. # Array ( klass ) . each do | k | if k . class == Module @module_formatters [ k ] = formatter else k = k . name if k . is_a? ( Class ) @class_formatters [ k ] = formatter end # # You can remove multiple classes at once by passing an array of classes. # # You can also pass class names as strings instead of the classes themselves. This can # help avoid loading dependency issues. This applies only to classes; modules cannot be # passed in as strings. Array ( klass ) . each do | k | if k . class == Module @module_formatters . delete ( k ) else k = k . name if k . is_a? ( Class ) @class_formatters . delete ( k ) end formatter = @class_formatters [ klass . name ]", "del_tokens": "add ( String , :object ) add ( Numeric , :object ) add ( TrueClass , :object ) add ( FalseClass , :object ) if klass . is_a? ( Class ) @class_formatters [ klass ] = formatter else @module_formatters [ klass ] = formatter if klass . is_a? ( Class ) @class_formatters . delete ( klass ) else @module_formatters . delete ( klass ) formatter = @class_formatters [ klass ]", "commit_type": "allow"}
{"commit_tokens": ["updated", "generators", "to", "create", "config", "/", "initializers", "/", "auditing", ".", "rb"], "add_tokens": "attr_accessor :report_on , :report_method", "del_tokens": "attr_accessor :report_on , :report_method , :serialize_type", "commit_type": "update"}
{"commit_tokens": ["added", "named", "param", "types", "example"], "add_tokens": "when 'word' ; \"([a-zA-Z]+?)\" when 'string' ; \"(\\\\w+?)\"", "del_tokens": "when 'string' , 'word' ; \"(\\\\w+?)\"", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "header", "section", "to", "the", "grammar", "so", "we", "can", "run", "in", "directly", "for", "development", "."], "add_tokens": "if $0 == __FILE__ $LOAD_PATH . unshift File . dirname ( __FILE__ ) + \"/../../\" module Yap module Shell module Parser end end end require 'yap/shell/parser/nodes' end module_eval ( <<'...end grammar.y/module_eval...' , 'grammar.y' , 101 ) ast = Yap :: Shell :: ParserImpl . new . parse ( src )", "del_tokens": "module_eval ( <<'...end grammar.y/module_eval...' , 'grammar.y' , 87 ) ast = Yap :: Shell :: Parser . new . parse ( src )", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "README", "and", "CHANGELOG"], "add_tokens": "VERSION = '1.0.0' . freeze", "del_tokens": "VERSION = '1.0.0.beta' . freeze", "commit_type": "update"}
{"commit_tokens": ["fixed", "up", "the", "cycle_through_nodes", "method", "so", "it", "makes", "sense", "."], "add_tokens": "hash . each . with_index do | node , j | case node . type when :text # hash[j][:nodes].nil? i += 1 # should inc i and NOT run the count_child_nodes method on it since it don't got no :nodes when :tag # aka !hash[j].nil? and !hash[j][:nodes].nil? i += 1 RubyBBCode . log hash [ j ] i += count_child_nodes ( hash [ j ] [ :nodes ] ) if ! hash [ j ] . nil? end", "del_tokens": "return 1 if hash . nil? hash . each . with_index do | el , j | i += 1 if ! hash [ j ] . nil? and ! hash [ j ] [ :nodes ] . nil? i += count_child_nodes ( hash [ j ] [ :nodes ] ) if ! hash [ j ] . nil?", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "test", "for", "newlines", "within", "quotes"], "add_tokens": "Then ( / ^there should be ( \\d +) error$ / ) do | count | end Given ( / ^I have a CSV with carriage returns in fields$ / ) do @csv = \"\\\"Foo\\\",\\\"Bar\\\",\\\"Baz\\\"\\r\\n\\\"Bing\\\",\\\"Bang\\nBung\\\",\\\"Bong\\\"\"", "del_tokens": "Then ( / ^there should be ( \\d +) error$ / ) do | count |", "commit_type": "add"}
{"commit_tokens": ["added", "RAILS_GEM_VERSION", "parameter", "for", "rake", "spec", "task"], "add_tokens": "if ENV [ 'RAILS_GEM_VERSION' ] =~ / ^2.0 / gem 'activerecord' , '=2.0.2' gem 'actionpack' , '=2.0.2' gem 'activesupport' , '=2.0.2' gem 'composite_primary_keys' , '=0.9.93' elsif ENV [ 'RAILS_GEM_VERSION' ] =~ / ^2.1 / gem 'activerecord' , '=2.1.2' gem 'actionpack' , '=2.1.2' gem 'activesupport' , '=2.1.2' gem 'composite_primary_keys' , '=1.0.8' else gem 'activerecord' , '=2.2.2' gem 'actionpack' , '=2.2.2' gem 'activesupport' , '=2.2.2' gem 'composite_primary_keys' , '=2.2.0' end", "del_tokens": "# gem 'activerecord', '=2.0.2' # gem 'actionpack', '=2.0.2' # gem 'activesupport', '=2.0.2' # gem 'composite_primary_keys', '=0.9.93' # gem 'activerecord', '=2.1.2' # gem 'actionpack', '=2.1.2' # gem 'activesupport', '=2.1.2' # gem 'composite_primary_keys', '=1.0.8' gem 'activerecord' , '=2.2.2' gem 'actionpack' , '=2.2.2' gem 'activesupport' , '=2.2.2' gem 'composite_primary_keys' , '=2.2.0'", "commit_type": "add"}
{"commit_tokens": ["Added", "text", "columns", "to", "use", "ILIKE", "query"], "add_tokens": "when :string , :text", "del_tokens": "when :string", "commit_type": "add"}
{"commit_tokens": ["Add", "SessionID", "and", "FetchToken", "to", "get", "user", "authentication", "tokens", "for", "an", "RuName", "application", "."], "add_tokens": "unless auth_token . blank? RequesterCredentials do eBayAuthToken auth_token . to_s end", "del_tokens": "RequesterCredentials do eBayAuthToken auth_token . to_s", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "to", "ensure", ".", "to_param", "returns", "String", "."], "add_tokens": "def test_to_param_should_return_a_string assert_equal String , users ( :joe ) . to_param . class end User . find ( [ 'non-existent-slug' , 'yet-another-non-existent-slug' ] )", "del_tokens": "User . find ( [ 'non-existe nt-slug' , 'yet-another-non-existent-slug' ] )", "commit_type": "add"}
{"commit_tokens": ["Allow", "relations", "to", "be", "reloaded", "of", "a", "different", "subclass"], "add_tokens": "ldaptor = self . class while ldaptor . superclass . respond_to? ( :connection ) && ldaptor . superclass . connection == self . connection ldaptor = ldaptor . superclass end value . instance_variable_set ( :@ldaptor , ldaptor )", "del_tokens": "value . instance_variable_set ( :@ldaptor , self . class )", "commit_type": "allow"}
{"commit_tokens": ["add", "stripe", "button", "-", ".", "erb"], "add_tokens": "#before_filter :setup_gateway response = Stripe :: Charge . create (", "del_tokens": "before_filter :setup_gateway response = @@gateway . purchase (", "commit_type": "add"}
{"commit_tokens": ["Added", "to_s", "method", "to", "User", "class"], "add_tokens": "def to_s @username end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Fix", "DirmonEntry", "when", "the", "archive", "path", "does", "not", "exist"], "add_tokens": "# Creates the archive directory if one is set @archive_pathname ||= begin if archive_directory path = Pathname . new ( archive_directory ) path . mkpath unless path . exist? path . realpath else Pathname . new ( self . class . default_archive_directory ) . realdirpath end end next if file_name . start_with? ( archive_pathname . to_s )", "del_tokens": "Pathname . new ( archive_directory || self . class . default_archive_directory ) next if file_name . start_with? ( archive_pathname . realpath . to_s )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "using", "Vlad", "as", "a", "delivery", "mechanism", "for", "issuing", "commands", "on", "remote", "servers"], "add_tokens": "# Define a logging target and understand packages, policies and deployment DSL", "del_tokens": "# Understand packages, policies and deployment DSL end # Define a logging target class Object", "commit_type": "add"}
{"commit_tokens": ["Fix", "errors", "related", "to", "special", "chars", "in", "method", "name"], "add_tokens": "aop_applied_flag = \"@aop_applied_#{method}\" aop_applied_flag . gsub! %r( [?!=+ \\- \\* / \\^ \\| & \\[ \\] <>%~] ) , \"_\" aop_applied_flag = \"@aop_applied_#{method}\" aop_applied_flag . gsub! %r( [?!=+ \\- \\* / \\^ \\| & \\[ \\] <>%~] ) , \"_\"", "del_tokens": "aop_applied_flag = :\" @aop_applied_ #{ method } \" aop_applied_flag = :\" @aop_applied_ #{ method } \"", "commit_type": "fix"}
{"commit_tokens": ["remove", "size", "attribute", "add", "css", "styling", "for", "inputs"], "add_tokens": "super ( attr , html_options ) super ( attr , html_options ) super ( attr , html_options )", "del_tokens": "super ( attr , { :size => 30 } . merge ( html_options ) ) super ( attr , { :size => 30 } . merge ( html_options ) ) super ( attr , { :size => 15 } . merge ( html_options ) )", "commit_type": "remove"}
{"commit_tokens": ["add", "full_feature", "config", "to", "easily", "add", "group", "of", "config"], "add_tokens": "def full_feature self . events = [ :call , :return ] result_config . import_return_to_call = true result_config . include_instance_var = true result_config . include_local_var = true end", "del_tokens": "# why need self? without self, the events will not really changed, why?. seems a bug in Struct", "commit_type": "add"}
{"commit_tokens": ["Added", "remember", "me", "functionality", "."], "add_tokens": "def login_user ( user , remember = false ) cookies . permanent [ :caboose_user_id ] = user . id if remember Caboose . log ( \"remember = #{remember}\" ) Caboose . log ( cookies [ :caboose_user_id ] ) validate_cookie # Checks to see if a remember me cookie value is present. def validate_cookie if cookies [ :caboose_user_id ] && User . exists? ( cookies [ :caboose_user_id ] ) user = User . find ( cookies [ :caboose_user_id ] ) login_user ( user ) return true end return false end", "del_tokens": "def login_user ( user )", "commit_type": "add"}
{"commit_tokens": ["Allow", "aliases", "in", "YAML", "config"], "add_tokens": "config_path = Rails . root . join ( 'config' , 'disqus_api.yml' ) if config_path . exist? DisqusApi . config = YAML . load ( ERB . new ( config_path . read ) . result ) [ Rails . env ]", "del_tokens": "config_path = File . join ( Rails . root , 'config' , \"disqus_api.yml\" ) if File . exist? ( config_path ) DisqusApi . config = YAML . safe_load ( ERB . new ( File . read ( Rails . root . join ( \"config\" , \"disqus_api.yml\" ) ) ) . result ) [ Rails . env ]", "commit_type": "allow"}
{"commit_tokens": ["Use", "readpartial", "with", "8k", "chunk", "size"], "add_tokens": "CHUNK_SIZE = 8192 @yajl . on_parse_complete = Proc . new do | obj | while true begin @yajl << io . readpartial ( CHUNK_SIZE ) rescue EOFError => e break end end", "del_tokens": "@yajl . parse ( io ) do | obj |", "commit_type": "use"}
{"commit_tokens": ["Fix", "lack", "of", "precision", "in", "time", "comparison"], "add_tokens": "assert_equal now . to_i , e . mtime . to_i assert_equal now . to_i , e . ctime . to_i", "del_tokens": "assert_equal now , e . mtime assert_equal now , e . ctime", "commit_type": "fix"}
{"commit_tokens": ["fix", "proxy", "for", "subclass", "without", "defining"], "add_tokens": "#ENV['DEBUG'] = 'true'", "del_tokens": "#ENV['DEBUG'] = 'true'", "commit_type": "fix"}
{"commit_tokens": ["Added", "start", "point", "for", "user", "retrieval"], "add_tokens": "options [ :start ] ? get ( @user + \"?startUsername=#{options[:start]}\" ) : get ( @user ) add_feed add_feed", "del_tokens": "# get_users options [ :start ] ? get ( @user + \"?startUsername=#{options[:start]}\" ) : get @user # Switch to add_feed @feeds << GoogleApps :: Atom . feed ( @response . body ) @feeds << GoogleApps :: Atom . feed ( @response . body )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "read", "&", "write", "json", "format"], "add_tokens": "raise WriteError , \"File `#{file}` already exists. \" \"Use :force option to overwrite.\" when '.json' require 'json' JSON . parse ( File . read ( file ) ) :: File . write ( file , YAML . dump ( data ) ) when '.json' require 'json' :: File . write ( file , JSON . pretty_generate ( data ) )", "del_tokens": "raise WriteError , \"File `#{file}` already exists.\" File . write ( file , YAML . dump ( data ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "HttpRetriever", "and", "modify", "the", "cache", "to", "cascade"], "add_tokens": "# @param *caches [ActiveSupport::Cache] If a list then the head of the the # list should will be checked before the tail. If the head is empty but # the tail is not then the head will be filled with the value of the tail. def initialize ( * caches ) @caches = caches # Call walks through each cache, returning a value if the item exists in # any cache, otherwise popularing each cache with the value of yield. value = read_and_upfill ( feature_name ) # nil is an acceptable value in the case of a missing feature definition return nil if value . nil? return value if value != false value_to_write = yield @caches . each do | cache | cache . write ( key ( feature_name ) , value_to_write ) end return value_to_write end def expire ( feature_name ) @caches . each { | c | c . delete ( key ( feature_name ) ) } # Walks through the list of caches, returning the first stored value. # # If a value is found in a cache after the first then all caches earlier # in that list will be backfilled. # # @param url [String] a feature name # @return [false, nil, Feature] false when no value is found, otherwise # the value stored in the cache (including nil) def read_and_upfill ( feature_name ) @caches . each . with_index do | cache , index | if cache . exist? ( key ( feature_name ) ) value = cache . read ( key ( feature_name ) ) @caches [ 0 ... index ] . each do | cache | cache . write ( key ( feature_name ) , value ) end return value end end return false end", "del_tokens": "# @param cache [#fetch] An instance of a cache class which implements #fetch like ActiveSupport::Cache does def initialize ( cache ) @cache = cache @cache . fetch ( key ( feature_name ) ) { yield }", "commit_type": "add"}
{"commit_tokens": ["Implement", "customization", "of", "resource", "model", "name"], "add_tokens": "@model ||= options [ :model ] || infer_model_class end def model_name options [ :as ] || model . model_name", "del_tokens": "options [ :model ] || infer_model_class", "commit_type": "implement"}
{"commit_tokens": ["moved", "the", "database", "to", "memory", "instead", "of", "disk"], "add_tokens": "# config.before(:suite) do # DatabaseCleaner.strategy = :transaction # DatabaseCleaner.clean_with(:truncation) # end # config.before(:each) do # DatabaseCleaner.start # end # config.after(:each) do # DatabaseCleaner.clean # end", "del_tokens": "config . before ( :suite ) do DatabaseCleaner . strategy = :transaction DatabaseCleaner . clean_with ( :truncation ) end config . before ( :each ) do DatabaseCleaner . start end config . after ( :each ) do DatabaseCleaner . clean end", "commit_type": "move"}
{"commit_tokens": ["use", "_", "for", "assigned", "but", "unused", "variables", "."], "add_tokens": "field , _modulus , facts , _roots , _addelems = f . decompose", "del_tokens": "field , modulus , facts , roots , addelems = f . decompose", "commit_type": "use"}
{"commit_tokens": ["change", "#respond_to?", "to", "avoid", "iRuby", "error"], "add_tokens": "# Returns true foe existing methods and # #to_<term_name> when name is a valid terminal type. term = meth [ 0 .. 2 ] == 'to_' && OptionHandling . valid_terminal? ( meth [ 3 .. - 1 ] ) term || super", "del_tokens": "# Returns true in all cases (to handle options) except # #to_<name> when name isn't a valid terminal type. ! ( meth [ 0 .. 2 ] == 'to_' ) || OptionHandling . valid_terminal? ( meth [ 3 .. - 1 ] )", "commit_type": "change"}
{"commit_tokens": ["Fix", "windows", "shell", "escaping", "."], "add_tokens": "Shellwords . shellescape ( @filename )", "del_tokens": "if self . class . windows? @filename . gsub ( / \\/ / , '\\\\' ) else Shellwords . shellescape ( @filename ) end", "commit_type": "fix"}
{"commit_tokens": ["improved", "spec", "for", "testing", "whitespace", "ignoring"], "add_tokens": "it \"ignore_whitespace should work\" do new_parser do ignore_whitespace rule :foobar , \"foo\" , \"bar\" end test_parse \"foobar\" test_parse \"foo bar\" test_parse \"foo \\t \\r \\f \\n bar\" test_parse \" foobar\" test_parse \"foobar \" end it \"the failure_index should be the furthest point reached, even if we managed to successfully match less\" do it \"parsing twice when the first didn't match all input should, but the second just failed, shouldn't report 'did not match entire input'\" do rule :statement , \"0\" , :one? , :one? , :one? test_parse \"011\\n0\" test_parse \"0111\\n0\"", "del_tokens": "it \"the failure_index should be the furthest point reached, even if we managed to match successfully less\" do it \"parsing twice when the first didn't match all input should but the second just failed shouldn't report 'did not match entire input'\" do rule :statement , \"0\" , :one?", "commit_type": "improve"}
{"commit_tokens": ["fix", "Beam", "::", "pass", "schedule", "it", "should", "return", "in", "next", "IO", "loop"], "add_tokens": "# prevent 'add new callbacks' during callback call, new callbacks will run in next turn callbacks = @callbacks @callbacks = [ ] while ( callback = callbacks . shift )", "del_tokens": "while ( callback = @callbacks . shift )", "commit_type": "fix"}
{"commit_tokens": ["create", "soft", "link", "in", "the", "before", "block"], "add_tokens": "FileUtils . mkdir_p @working_dir FileUtils . ln_s \"#{@working_dir}\" , \"#{@public_folder}\"", "del_tokens": "if File . exist? ( @working_dir ) fail IOError , 'A unique name cannot be created for this session.' end unless File . exist? ( @tempdir ) fail IOError , 'The Temporary folder cannot be found.' end FileUtils . mkdir_p @working_dir FileUtils . ln_s \"#{@working_dir}\" , \"#{@public_folder}\"", "commit_type": "create"}
{"commit_tokens": ["Added", "cuke", "steps", "for", "discovery", "."], "add_tokens": "unless ENV [ \"RUBY_UPNP_ENV\" ] == \"testing\" set_sock_opt ( Socket :: IPPROTO_IP , Socket :: IP_MULTICAST_LOOP , \"\\000\" ) end", "del_tokens": "#unless ENV[\"RUBY_UPNP_ENV\"] == \"testing\" # set_sock_opt(Socket::IPPROTO_IP, Socket::IP_MULTICAST_LOOP, \"\\000\") #end", "commit_type": "add"}
{"commit_tokens": ["Change", "LtiLinkItem", "to", "LtiLink", "in", "tool_settings", ".", "rb"], "add_tokens": "LTI_LINK_TYPE = 'LtiLink'", "del_tokens": "LTI_LINK_TYPE = 'LtiLinkItem'", "commit_type": "change"}
{"commit_tokens": ["Add", "multiple", "asset", "send", "api", "(", "Api#send_assets", ")"], "add_tokens": "before_filter :change_network , { :include => [ :list_unspent , :get_balance , :issue_asset , :send_asset , :send_assets , :send_bitcoin ] } # Creates a transaction for sending multiple asset from an address to another. # @param[String] from The open asset address to send the asset from. # @param[Array[OpenAssets::SendAssetParams]] send_asset_params The send Asset information(asset_id, amount, to). # @param[Integer] fees The fess in satoshis for the transaction. # @param[String] mode 'broadcast' (default) for signing and broadcasting the transaction, # 'signed' for signing the transaction without broadcasting, # 'unsigned' for getting the raw unsigned transaction without broadcasting\"\"\"='broadcast' # @return[Bitcoin::Protocol:Tx] The resulting transaction. def send_assets ( from , send_asset_params , fees = nil , mode = 'broadcast' ) builder = OpenAssets :: Transaction :: TransactionBuilder . new ( @config [ :dust_limit ] ) colored_outputs = get_unspent_outputs ( [ oa_address_to_address ( from ) ] ) transfer_specs = send_asset_params . map { | param | [ param . asset_id , OpenAssets :: Transaction :: TransferParameters . new ( colored_outputs , param . to , from , param . amount ) ] } tx = builder . transfer_assets ( transfer_specs , from , fees . nil? ? @config [ :default_fees ] : fees ) tx = process_transaction ( tx , mode ) tx end", "del_tokens": "before_filter :change_network , { :include => [ :list_unspent , :get_balance , :issue_asset , :send_asset , :send_bitcoin ] }", "commit_type": "add"}
{"commit_tokens": ["Allow", "nodes", "to", "be", "non", "executable", "but", "with", ">", "0", "runs"], "add_tokens": "# There is a rare case of non executable nodes that have important data in runs / full_runs, # like `if cond; end`, so make sure it's actually executable first... executable? && runs > 0", "del_tokens": "runs > 0", "commit_type": "allow"}
{"commit_tokens": ["Make", "Form", "raise", "FormError", "instead", "of", "ValidationError"], "add_tokens": "valid? || ( raise OnsContext :: FormError . new ( errors ) )", "del_tokens": "valid? or raise OnsContext :: ValidationError . new ( errors )", "commit_type": "make"}
{"commit_tokens": ["Use", "separate", "queries", "for", "Que", "0", ".", "x", "and", "1", ".", "x"], "add_tokens": "query = queues . empty? && base_query || base_query + \" AND queue IN (#{names(queues)})\" private def base_query return QUE_V0_QUERY if defined? ( :: Que :: Version ) return QUE_V1_QUERY if defined? ( :: Que :: VERSION ) raise \"Couldn't find Que version\" end def names ( queues ) queues . map { | queue | \"'#{queue}'\" } . join ( \",\" ) end def query_const ( query ) query . gsub ( / \\s + / , \" \" ) . strip . freeze end QUE_V0_QUERY = query_const ( <<-QUERY ) SELECT COUNT ( * ) AS total FROM que_jobs WHERE run_at < NOW ( ) QUERY QUE_V1_QUERY = query_const ( <<-QUERY ) SELECT COUNT ( * ) AS total FROM que_jobs WHERE finished_at IS NULL AND expired_at IS NULL AND run_at <= NOW ( ) QUERY", "del_tokens": "QUERY = %{ SELECT count ( * ) AS total FROM que_jobs WHERE run_at < now ( ) } . freeze query = case when queues . none? then QUERY when queues . one? then \"#{QUERY} AND queue = '#{queues.first}'\" else queue_names = queues . map { | queue | \"'#{queue}'\" } . join ( ', ' ) %Q{#{QUERY} AND queue IN (#{queue_names})} end", "commit_type": "use"}
{"commit_tokens": ["Fixed", "some", "instances", "of", "comment_timestamp"], "add_tokens": "VERSION = \"0.5.11\"", "del_tokens": "VERSION = \"0.5.10\"", "commit_type": "fix"}
{"commit_tokens": ["Implement", "--", "all", "-", "colors", "and", "--", "color", "options"], "add_tokens": "[ palette . notation , color_fg , formatting , color_bg ] . flatten . compact . join ( \";\" )", "del_tokens": "notation = \"38;5\" if palette . color_depth == 256 [ notation , color_fg , formatting , color_bg ] . flatten . compact . join ( \";\" )", "commit_type": "implement"}
{"commit_tokens": ["Implemented", "build", "and", "create", "for", "Factory"], "add_tokens": "# options: (Hash) # class: the class that will be used when generating instances for this # factory. def self . define ( name , options = { } ) instance = Factory . new ( name , options ) # Calculates the class that should be instantiated by generation methods. # # If a class was passed when defining this factory, that class will be # returned. Otherwise, the class will be guessed from the factory name. # # Returns: # The class that will be instantiated by generation methods. def build_class @build_class ||= @options [ :class ] || name . to_s . classify . constantize end def initialize ( name , options = { } ) #:nodoc: options . assert_valid_keys ( :class ) @name = name @options = options @lazy_attributes = { } # Generates and returns an instance from this factory. Attributes can be # individually overridden by passing in a Hash of attribute => value pairs. # # Arguments: # attrs: (Hash) # See attributes # # Returns: # An instance of the class this factory generates, with generated # attributes assigned. def build ( attrs = { } ) instance = build_class . new attributes ( attrs ) . each do | attr , value | instance . send ( :\" #{ attr } = \" , value ) end instance end # Generates, saves, and returns an instance from this factory. Attributes can # be individually overridden by passing in a Hash of attribute => value # pairs. # # If the instance is not valid, an ActiveRecord::Invalid exception will be # raised. # # Arguments: # attrs: (Hash) # See attributes # # Returns: # A saved instance of the class this factory generates, with generated # attributes assigned. def create ( attrs = { } ) instance = build ( attrs ) instance . save! instance end", "del_tokens": "def self . define ( name ) instance = Factory . new ( name ) def initialize ( name ) #:nodoc: @name = name @lazy_attributes = { }", "commit_type": "implement"}
{"commit_tokens": ["Use", "a", "helper", "method", "to", "load", "the", "project", "scope", "rather", "than", "always", "trying", "to", "select", "it"], "add_tokens": "def project @project ||= Project . find params [ :project_id ] if params [ :project_id ]", "del_tokens": "before_action :find_project_scope private def find_project_scope @project = Project . find params [ :project_id ] if params [ :project_id ]", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "thread", "partial"], "add_tokens": "VERSION = \"0.1.16\"", "del_tokens": "VERSION = \"0.1.15\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "comments", "in", "LHS", "files", "a", "la", "GHC"], "add_tokens": "BIRD_TRACKS_REGEX = / ^ \\> ( \\- \\- | )(.*) / tracks = line . scan ( BIRD_TRACKS_REGEX ) [ 0 ] ( tracks . first == \" \" ) ? tracks [ 1 ] : tracks . join", "del_tokens": "BIRD_TRACKS_REGEX = / ^ \\> (.*) / line . gsub ( BIRD_TRACKS_REGEX , '\\1' )", "commit_type": "add"}
{"commit_tokens": ["Use", "rspec", "metadata", "to", "append", "uninhibited", "features"], "add_tokens": "# @param [ExampleGroup] example_group the example group of example def skip_examples_after ( example , example_group = self ) # If the example failed or got an error, then skip the dependent examples. # If the failure occurred in a background example group, then skip all # examples in the feature. # # @param [Example] example the current example def handle_exception ( example ) if example . instance_variable_get ( :@exception ) if metadata [ :background ] skip_examples_after ( example , ancestors [ 1 ] ) else skip_examples_after ( example )", "del_tokens": "# @param [ExampleGroup] example_group the example group of example def skip_examples_after ( example_group , example ) private # Extends an ExampleGroup with the features required for running # Uninhibited specs. # # @param [ExampleGroup] base the example group # @api private def self . extended ( base ) base . after ( :each ) do if example . instance_variable_get ( :@exception ) if example . example_group . metadata [ :background ] self . class . skip_examples_after ( self . class . ancestors [ 1 ] , example ) else self . class . skip_examples_after ( self . class , example ) end", "commit_type": "use"}
{"commit_tokens": ["adding", "support", "for", "internal", "eval", "token", "parsing"], "add_tokens": "attr_accessor :heredoc_marker def initialize ( command : command , args : args , heredoc_marker : nil ) @heredoc_marker = heredoc_marker break if i >= tokens . length || token . tag != :Argument when :Heredoc @ast . last . heredoc_marker = token . value i += 1 i += 1", "del_tokens": "def initialize ( command : command , args : args ) break if i >= tokens . length break if [ :Terminator , :ConditionalTerminator ] . include? ( token . tag ) i += 1", "commit_type": "add"}
{"commit_tokens": ["Adding", "confirmable", "module", "generating", "confirmation", "code", "and", "confirming", "a", "user", "account", "."], "add_tokens": "extend ClassMethods self . password_salt = secure_digest ( Time . now . utc , random_string , password ) if password_salt . blank? # Generate a string randomically based on rand method # def random_string ( 1 .. 10 ) . map { rand . to_s } end", "del_tokens": "#attr_accessor :password, :password_confirmation extend ClassMethods self . password_salt = secure_digest ( Time . now . utc , password ) if password_salt . blank?", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "cache", "method", "for", "size", "calcualtion"], "add_tokens": "@cached_size_method = nil # Stores the current size method # @api public attr_accessor :cached_size_method # Holds the environment variables # @api public # return rows and columns return cached_size_method . ( ) unless cached_size_method . nil? check_size ( :size_from_java ) || check_size ( :size_from_win_api ) || check_size ( :size_from_ioctl ) || check_size ( :size_from_io_console ) || check_size ( :size_from_readline ) || check_size ( :size_from_tput ) || check_size ( :size_from_stty ) || check_size ( :size_from_env ) || check_size ( :size_from_ansicon ) || DEFAULT_SIZE # Check if a method returns a correct size and cache it # # @param [String] method_name # # @api private def check_size ( method_name ) size_method = method ( method_name . to_sym ) size = size_method . ( ) return if size . nil? self . cached_size_method = size_method size end private_module_function :check_size", "del_tokens": "# # return rows & columns size = size_from_java size ||= size_from_win_api size ||= size_from_ioctl size ||= size_from_io_console size ||= size_from_readline size ||= size_from_tput size ||= size_from_stty size ||= size_from_env size ||= size_from_ansicon size || DEFAULT_SIZE", "commit_type": "change"}
{"commit_tokens": ["Add", "option", "to", "stop", "displaying", "errors", "to", "the", "console", "."], "add_tokens": "attr_accessor :prefix , :quiet @prefix = options [ :prefix ] || 'Configuration' @quiet = options [ :quiet ] || false $stderr . puts \"#{@prefix} : #{severity} - #{message}\" unless @quiet == true", "del_tokens": "attr_accessor :prefix @prefix = options [ :prefix ] || 'Configuration :' $stderr . puts \"#{@prefix} #{severity} - #{message}\"", "commit_type": "add"}
{"commit_tokens": ["Move", "these", "files", "around", "for", "consistency", "s", "sake", "."], "add_tokens": "require File . join ( File . dirname ( __FILE__ ) , * %w{ active_record postgresql_cursors cursors_3 } ) require File . join ( File . dirname ( __FILE__ ) , * %w{ active_record postgresql_cursors cursors_2 } )", "del_tokens": "require File . join ( File . dirname ( __FILE__ ) , 'postgresql_cursors_3' ) require File . join ( File . dirname ( __FILE__ ) , 'postgresql_cursors_2' )", "commit_type": "move"}
{"commit_tokens": ["Add", "symbol", "test", "in", "element"], "add_tokens": "context \"when the field is a string\" do let ( :element ) do described_class . new ( \"name\" , \"value\" ) end let ( :encoded ) do element . to_bson end it \"encodes the type + field + value\" do expect ( encoded ) . to eq ( \"#{String::BSON_TYPE}#{\"name\".to_bson_cstring}#{\"value\".to_bson}\" ) end context \"when the field is a symbol\" do let ( :element ) do described_class . new ( :name , \"value\" ) end let ( :encoded ) do element . to_bson end it \"encodes the type + field + value\" do expect ( encoded ) . to eq ( \"#{String::BSON_TYPE}#{\"name\".to_bson_cstring}#{\"value\".to_bson}\" ) end", "del_tokens": "let ( :element ) do described_class . new ( \"name\" , \"value\" ) end let ( :encoded ) do element . to_bson it \"encodes the type + field + value\" do expect ( encoded ) . to eq ( \"#{String::BSON_TYPE}#{\"name\".to_bson_cstring}#{\"value\".to_bson}\" )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "ports", "using", "dataflow", "variables", "and", "a", "single", "state", "variable", ".", "Actors", "now", "don", "t", "need", "to", "use", "anything", "except", "ports", "and", "dataflow", "."], "add_tokens": "require 'port' class Actor < Thread include Dataflow #Instance variables aren't working properly #declare :stream, :port attr_reader :stream , :port def initialize ( & block ) @stream = Variable . new @port = Port . new @stream #unify @port, Port.new(@stream) super { instance_eval & block } port . send message private def receive value = @stream . head stream = @stream . tail value", "del_tokens": "require 'dataflow' module ActorModule # Create a new unbound dataflow variable def __push__ local do | x | @__outerqueue__ << x @__innerqueue__ << x end end def __check__ @__outerqueue__ = [ ] unless defined? @__outerqueue__ @__innerqueue__ = [ ] unless defined? @__innerqueue__ end # Give an unbound variable to the sender def __getouter__ __check__ __push__ if @__outerqueue__ . empty? @__outerqueue__ . shift end # Give an unbound variable to the process def __getinner__ __check__ __push__ if @__innerqueue__ . empty? @__innerqueue__ . shift unify __getouter__ , message def receive __getinner__ end end class Actor < Thread include ActorModule def initialize ( & block ) super { instance_eval & block }", "commit_type": "implement"}
{"commit_tokens": ["Adding", "code", "before", "removing", "it"], "add_tokens": "require 'arjdbc/teradata/adapter'", "del_tokens": "require 'arjdbc/teradata/adapter'", "commit_type": "add"}
{"commit_tokens": ["added", "parent_class", "options", "to", "flow", "registry", "all"], "add_tokens": "# Warning: using parent_class forces us to load everything, make this potentially much slower as we have to do the # pagination in the app, not in the db def all ( parent_class : nil , ** options ) # load every ID if we have a parent_class options . merge ( from : nil , to : nil ) unless parent_class . nil? ids = self . public_flows ( options ) + self . private_flows ( options ) unless parent_class . nil? from = from . to_i to = to . nil? ? - 1 : to . to_i ids . select! do | id | klass = Flow . read_flow_class ( id ) ! klass . nil? && klass <= parent_class end . slice! ( from .. to ) end return ids", "del_tokens": "def all ( options = { } ) return self . public_flows ( options ) + self . private_flows ( options )", "commit_type": "add"}
{"commit_tokens": ["added", "image", "into", "examples", "dir"], "add_tokens": "dir = File . expand_path ( File . join ( \"..\" , \"..\" , \"lib\" ) )", "del_tokens": "dir = File . expand_path ( File . join ( \"..\" , \"..\" ) )", "commit_type": "add"}
{"commit_tokens": ["Removed", "pivotal", "-", "tracker", "gem", "dependency"], "add_tokens": "VERSION = \"0.2.8\"", "del_tokens": "VERSION = \"0.2.7\"", "commit_type": "remove"}
{"commit_tokens": ["Added", "ability", "to", "run", "in", "dry", "mode", "where", "requests", "aren", "t", "actually", "made"], "add_tokens": "config . announce_endpoint : nil return unless live? response = post ( endpoint , JSON . dump ( payload ) ) return unless live? def live? ! config . dry_run end # TODO: Defer this to another thread def post ( endpoint , body ) connection . post ( endpoint , body ) end private", "del_tokens": "config . announce_endpoint : nil response = connection . post ( endpoint , JSON . dump ( payload ) ) # private", "commit_type": "add"}
{"commit_tokens": ["Added", "set", "block", "for", "the", "module", "and", "the", "plugin", "to", "give", "the", "plugin", "some", "extra", "functionality"], "add_tokens": "set do custom_function :virtual_host , <<-EOM } EOM end", "del_tokens": "custom_function :virtual_host , <<-EOM } EOM", "commit_type": "add"}
{"commit_tokens": ["added", "pending", "spec", "to", "test", "for", "valid?", "method", "for", "authentication"], "add_tokens": "before ( :each ) do end it \"should be able to instantiate a new instance\" do it \"should be able to validate it's authentication\" do pending @ticketmaster . valid? . should be_true end", "del_tokens": "it \"should be able to instantiate a new instance\" do", "commit_type": "add"}
{"commit_tokens": ["Changed", "scope", "test", "to", "require", "a", "scope"], "add_tokens": "raise \"Scope not set! [ActsAsTenant]\" unless ActsAsTenant . current_tenant where ( { fkey => ActsAsTenant . current_tenant . id } )", "del_tokens": "where ( { fkey => ActsAsTenant . current_tenant . id } ) if ActsAsTenant . current_tenant", "commit_type": "change"}
{"commit_tokens": ["Making", "Consumer#subscribe", "private", "to", "avoid", "having", "to", "think", "about", "how", "to", "handle", "post", "#consume", "subscribe", "calls"], "add_tokens": "# Subscribe to a queue which will invoke the supplied block when # a message is received. # Additionally declaring a binding to the specified exchange/key pair. # # @param exchange [String] # @param type [String] # @param queue [String] # @param key [String] # @return [Messaging::Consumer] # @api public def subscribe ( exchange , type , queue , key ) consumer_channels . each do | channel | ex = declare_exchange ( channel , exchange , type , config . exchange_options ) q = declare_queue ( channel , ex , queue , key , config . queue_options ) q . subscribe ( :ack => true ) do | meta , payload | log . debug ( \"Receieved message on channel #{meta.channel.id} from queue #{queue.inspect}\" ) # If this raises an exception, the connection # will be closed, and the message requeued by the broker. on_message ( meta , payload ) meta . ack end end self end", "del_tokens": "# Subscribe to a queue which will invoke the supplied block when # a message is received. # Additionally declaring a binding to the specified exchange/key pair. # # @param exchange [String] # @param type [String] # @param queue [String] # @param key [String] # @return [Messaging::Consumer] # @api public def subscribe ( exchange , type , queue , key ) consumer_channels . each do | channel | ex = declare_exchange ( channel , exchange , type , config . exchange_options ) q = declare_queue ( channel , ex , queue , key , config . queue_options ) q . subscribe ( :ack => true ) do | meta , payload | log . debug ( \"Receieved message on channel #{meta.channel.id} from queue #{queue.inspect}\" ) # If this raises an exception, the connection # will be closed, and the message requeued by the broker. on_message ( meta , payload ) meta . ack end end self end", "commit_type": "make"}
{"commit_tokens": ["Fix", "constructor", "freezes", "newly", "created", "instance", "instead", "of", "dup"], "add_tokens": "freezer . freeze ( super )", "del_tokens": "freezer . call ( super )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "jackpot_app", ".", "rb", "from", "root", "directory", "."], "add_tokens": "require_relative '../lib/jackpot/app'", "del_tokens": "require_relative '../jackpot_app'", "commit_type": "remove"}
{"commit_tokens": ["fix", "a", "bug", "in", "LinkFormat#visit", "that", "wrongly", "adds", "an", "empty", "alt", "attribute"], "add_tokens": "htmlelement [ ALT ] = caption if caption", "del_tokens": "htmlelement [ ALT ] = caption", "commit_type": "fix"}
{"commit_tokens": ["added", "grid", "-", "name", "classes", "for", "tags"], "add_tokens": "@text_field_tag ||= h . text_field_tag scoped_name , grid . params [ name . intern ] , class : \"grid grid-#{name}\" h . select_tag scoped_name , h . options_for_select ( collection , grid . params [ name . intern ] ) , class : \"grid grid-#{name}\"", "del_tokens": "@text_field_tag ||= h . text_field_tag scoped_name , grid . params [ name . intern ] , :class => 'grid' h . select_tag scoped_name , h . options_for_select ( collection , grid . params [ name . intern ] ) , :class => 'grid'", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "unicode", "characters"], "add_tokens": "context \"for escape sequences\" do examples_exist_and_match ( / \\x42 / , / \\x1D / , / \\x3 word / , / #{ \"\\x80\" . force_encoding ( \"ASCII-8BIT\" ) } / ) end context \"for unicode sequences\" do examples_exist_and_match ( / \\u6829 / , / \\uabcd / ) end", "del_tokens": "context \"for escape sequences \" examples_exist_and_match ( / \\x42 / , / \\x1D / , / \\x3 word / , / #{ \"\\x80\" . force_encoding ( \"ASCII-8BIT\" ) } / )", "commit_type": "add"}
{"commit_tokens": ["Changed", "save", "behavior", "to", "create", "the", "object", "if", "it", "s", "new"], "add_tokens": "def new? ! id end create if new? raise ModelIsNew if new?", "del_tokens": "raise ModelIsNew unless id", "commit_type": "change"}
{"commit_tokens": ["fixed", "migration", "and", "removed", "old", "test", ".", "minor", "bug", "fixed", "and", "added", "ajax", "update_positions"], "add_tokens": "resources :banners do collection do post :update_positions end end", "del_tokens": "resources :banners", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "parse", "object", "paths", "as", "well", "as", "rails", "style", "routes", "."], "add_tokens": "name = if crumb . name formatted = options [ :capitalize ] ? crumb . name . capitalize : crumb . name truncate ( formatted , :length => options [ :crumb_length ] ) else '[name-error]' end url = url_for _process_url_for ( crumb . url ) private def _process_url_for ( url ) if url . is_a? ( String ) || url . is_a? ( Symbol ) return send url else return url end end", "del_tokens": "name = crumb . name ? truncate ( crumb . name . upcase , :length => options [ :crumb_length ] ) : '' url = send ( crumb . url )", "commit_type": "add"}
{"commit_tokens": ["Added", "modifications", "for", "timestamp", "support"], "add_tokens": "# RSI: added mapping for TIMESTAMP WITH TIME ZONE / LOCAL TIME ZONE type OCI8 :: BindType :: Mapping [ OCI8 :: SQLT_TIMESTAMP ] = OCI8 :: BindType :: Time OCI8 :: BindType :: Mapping [ OCI8 :: SQLT_TIMESTAMP_TZ ] = OCI8 :: BindType :: Time OCI8 :: BindType :: Mapping [ OCI8 :: SQLT_TIMESTAMP_LTZ ] = OCI8 :: BindType :: Time when / timestamp /i then :timestamp # RSI: changed to native TIMESTAMP type # :timestamp => { :name => \"DATE\" }, :timestamp => { :name => \"TIMESTAMP\" } , # RSI: TIMESTAMP support elsif value && column && column . type == :timestamp # add up to 9 digits of fractional seconds to inserted time \"TO_TIMESTAMP('#{value.to_s(:db)}.#{(\"%.9f\"%value.to_f).split('.')[1]}','YYYY-MM-DD HH24:MI:SS:FF9')\"", "del_tokens": ":timestamp => { :name => \"DATE\" } ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "ArgumentError", "for", "invalid", "endpoint"], "add_tokens": "raise ArgumentError , \"Unable to find WSDL at: #{@uri}\" if ! soap_actions || soap_actions . empty?", "del_tokens": "raise ArgumentError , \"Unable to find WSDL at: #{@uri}\" unless soap_actions", "commit_type": "fix"}
{"commit_tokens": ["added", "cleanup", "chain", "if", "disconnect"], "add_tokens": "@nodes . each { | node | node . cleanup } @nodes . each { | node | node . cleanup }", "del_tokens": "#NOD rescue # @connected = false # @server_version = nil # @user = nil # @password = nil # @database = nil # raise ConnectionError # end", "commit_type": "add"}
{"commit_tokens": ["Use", "instance", "variable", "to", "set", "pid", "so", "it", "does", "t", "switch", "to", "user", "assigned", "(", "Kevin", "Clark", ")"], "add_tokens": "# DON'T USE THIS INTERNALLY. Use the instance variable. -- Kev # No really, trust me. Use the instance variable. if @tracking_pid or ( self . pid_file . nil? and WRITES_PID . include? ( action ) ) @pid_file = default_pid_file", "del_tokens": "if @tracking_pid or ( self . pid_file . nil? and WRITES_PID . include? ( action ) ) self . pid_file = default_pid_file", "commit_type": "use"}
{"commit_tokens": ["added", "strip_blank", "to", "column_filter", "and", "driver"], "add_tokens": "attr_reader :grid , :name , :input_options , :input_tag , :formatter , :order , :label def initialize grid , name , opts = { } @label = opts . delete ( :label ) { grid . translate ( :filters , name ) } @input_options = opts . delete ( :input ) { nil } @input_tag = opts . delete ( :input_tag ) { nil } @include_blank = opts . delete ( :include_blank ) { false } @formatter = opts . delete ( :formatter ) { nil } @param_scoped = opts . delete ( :param_scoped ) { true } @order = opts . delete ( :order ) { nil } if coll = opts . delete ( :input_collection ) { nil } @opts = opts", "del_tokens": "attr_reader :grid , :name , :input_options , :input_tag , :formatter , :order def initialize grid , name , opts = { } @label = opts [ :label ] @input_options = opts [ :input ] @input_tag = opts [ :input_tag ] @include_blank = opts [ :include_blank ] @formatter = opts [ :formatter ] @param_scoped = opts . fetch ( :param_scoped ) { true } @order = opts [ :order ] if coll = opts [ :input_collection ] end def label @label ||= grid . translate ( :filters , name )", "commit_type": "add"}
{"commit_tokens": ["Add", "keyword", "initialization", "for", "mixins"], "add_tokens": "def initialize_mixins ( mixins = nil , ** kwargs ) initialize_kwargs ( ** kwargs ) unless kwargs . empty? def initialize_kwargs ( ** kwargs ) kwargs . each do | keyword , argument | initializer = \"initialize_kwarg_#{keyword}\" . to_sym can_init = respond_to? ( initializer ) raise ArgumentError , \"unknown keyword: #{keyword}\" unless can_init send initializer , argument end end", "del_tokens": "def initialize_mixins ( mixins = nil )", "commit_type": "add"}
{"commit_tokens": ["Use", "current_namespace", "to", "get", "class", "name"], "add_tokens": "class_tokens = const_indexes . map { | i | flat_sexp [ i + 1 ] } class_tokens . insert ( 0 , @current_namespace ) unless @current_namespace . empty? class_name = class_tokens . join ( '::' ) def find_last_line ( params , token = 'class' ) token_name , line = params token_indentation = lines [ line - 1 ] . index ( token ) last_line = lines [ line .. - 1 ] . index { | l | l =~ %r( ^ \\s { #{ token_indentation } }end$ ) } module_params = find_class_params ( element ) module_params += [ find_last_line ( module_params ) ] @current_namespace << module_params . first", "del_tokens": "class_name = const_indexes . map { | i | flat_sexp [ i + 1 ] } . join ( '::' ) def find_last_line ( class_params ) class_name , line = class_params class_indentation = lines [ line - 1 ] . index ( 'class' ) last_line = lines [ line .. - 1 ] . index { | l | l =~ %r( ^ \\s { #{ class_indentation } }end$ ) } # TODO # get module name and add it to current namespace", "commit_type": "use"}
{"commit_tokens": ["add", "catch", "for", "X", "-", "Zendesk", "-", "API", "-", "Warn"], "add_tokens": "client . tickets . create ( :abaded => \"blergh\" )", "del_tokens": "tickets = client . tickets . recent show_many = client . topics . show_many ( :verb => :post , :ids => [ 22 , 2 ] ) puts client . topics puts show_many . to_a", "commit_type": "add"}
{"commit_tokens": ["Add", "all", "dependencies", "to", "test", ".", "Use", "map", "to", "generate", "packages", "."], "add_tokens": "File . open ( @config . pwd . join ( \"requirements.txt\" ) ) . map do | line | p_split [ 0 ]", "del_tokens": "packages = [ ] File . open ( @config . pwd . join ( \"requirements.txt\" ) ) . each do | line | packages . push ( p_split [ 0 ] ) packages", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "#", "{", "type", "}", "_can?", "appeared", "again"], "add_tokens": ":: CanTango . config . users . registered . each do | user |", "del_tokens": ":: CanTango . config . users . registered . each do | user |", "commit_type": "fix"}
{"commit_tokens": ["fixed", "syntax", "errors", ".", "moved", "objectives", "to", "spec_helper", "."], "add_tokens": "s . easybib = \"foobar\" :type => :book , :media => :print , :title => \"The Catcher in the Rye\" , :type => :author , :publication => { :name => \"Little, Brown\" , :city => \"Boston\" , :year => \"1995\" }", "del_tokens": "s . easybib_key \"foobar\" :title => \"Catcher in the Rye\" , :function => \"author\" , :publisher => \"Little, Brown\" , :city => \"Boston\" , :year => \"1995\"", "commit_type": "fix"}
{"commit_tokens": ["fix", "logic", "in", "clearing", "entry", "processing"], "add_tokens": "clear_processed ( entries ) clear_processed ( entries )", "del_tokens": "clear_processed ( entries ) clear_processed ( entries )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "use", "different", "formatting", "and", "remove", "auto", "spin"], "add_tokens": "spinners = TTY :: Spinner :: Multi . new \"[:spinner] main\" , format : :pulse sp1 = spinners . register \"[:spinner] one\" , format : :classic sp2 = spinners . register \"[:spinner] two\" , format : :classic sp3 = spinners . register \"[:spinner] three\" , format : :classic", "del_tokens": "spinners = TTY :: Spinner :: Multi . new \"[:spinner] main\" spinners . auto_spin sp1 = spinners . register \"[:spinner] one\" sp2 = spinners . register \"[:spinner] two\" sp3 = spinners . register \"[:spinner] three\"", "commit_type": "change"}
{"commit_tokens": ["Added", "debugger", "and", "fixed", "the", "bug", "in", "Board#cell_at"], "add_tokens": "@cells [ y ] [ x ] if @cells [ y ]", "del_tokens": "@cells [ x ] [ y ] if @cells [ x ]", "commit_type": "add"}
{"commit_tokens": ["Added", "config", "option", "to", "set", "rsync", "flags"], "add_tokens": "@flags = @options [ :flags ] ||= ' -rltDvz' cmd = \"rsync \" cmd << \"#{@flags} \" cmd << \" -e\" if @exclude_file || @exclude cmd << \" --exclude-from #{@exclude_file}\" if @exclude_file cmd << \" --exclude #{@exclude}\" if @exclude cmd << \" --include-from #{@include_file}\" if @include_file cmd << \" --include #{@include}\" if @include cmd << \" --rsh='ssh -p#{@port}'\" if @user && @port cmd << \" --delete\" if @delete #{\"# flags: #{options[:flags]}\".ljust(40)} # Modify flags as necessary to suit your hosting setup", "del_tokens": "cmd = \"rsync -avz \" cmd << \" -e \" if @exclude_file || @exclude cmd << \" --exclude-from #{@exclude_file} \" if @exclude_file cmd << \" --exclude #{@exclude} \" if @exclude cmd << \" --include-from #{@include_file} \" if @include_file cmd << \" --include #{@include} \" if @include cmd << \" --rsh='ssh -p#{@port}' \" if @user && @port cmd << \" --delete \" if @delete", "commit_type": "add"}
{"commit_tokens": ["Use", "duck", "typing", "instead", "of", "a", "type", "check", "."], "add_tokens": "elsif ( object . respond_to? ( :read ) ) then", "del_tokens": "elsif ( object . is_a? ( IO ) ) then", "commit_type": "use"}
{"commit_tokens": ["fix", "warnings", "and", "errors", "related", "to", "object_id", "on", "all", "ruby", "versions"], "add_tokens": "VERSION = \"0.9.6\"", "del_tokens": "VERSION = \"0.9.5\"", "commit_type": "fix"}
{"commit_tokens": ["changed", "db", "configs", "for", "specs"], "add_tokens": "db = Mongo :: Connection . new . db ( name ) db . add_user ( \"mongoid\" , \"test\" ) config . master = db", "del_tokens": "config . master = Mongo :: Connection . new . db ( name )", "commit_type": "change"}
{"commit_tokens": ["Make", "sure", "Session", "initialization", "fails", "when", "no", "shop", "is", "provided", "in", "constructor", ".", "Added", "test", "for", "that", ".", "Also", "added", "tobi", "s", "context", "ultralite", "remix", ";", ")"], "add_tokens": "context \"Session\" do test \"should raise error when blank shop url is provided\" do assert_raise ( ArgumentError ) { ShopifyAPI :: Session . new ( \"\" ) } end test \"should not be valid without token\" do session = ShopifyAPI :: Session . new ( \"testshop.myshopify.com\" ) assert_not session . valid? end test \"should be valid with any token\" do session = ShopifyAPI :: Session . new ( \"testshop.myshopify.com\" , \"any-token\" ) assert session . valid? end", "del_tokens": "def setup @session_no_token = ShopifyAPI :: Session . new ( \"testshop.myshopify.com\" ) @session = ShopifyAPI :: Session . new ( \"testshop.myshopify.com\" , \"any-token\" ) end def test_session_not_valid_without_token assert_not @session_no_token . valid? end def test_session_is_valid_with_any_token assert @session . valid?", "commit_type": "make"}
{"commit_tokens": ["fix", "inv", "for", "symmetric", "matrices", "(", "size", "[", "0", "]", "was", "doing", "utterly", "the", "wrong", "thing", ")"], "add_tokens": "self . solve ( self . class . eye ( rows ) )", "del_tokens": "self . solve ( self . class . eye ( size [ 0 ] ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "docs", "and", "fixed", "proxy", "for", "oath", "client"], "add_tokens": "# Sets or gets the api_version to be used in API calls # # @return [String] # Sets or gets the api unit system to be used in API calls # # @return [String] # # @example Set this using the {Fitgem::ApiUnitSystem} # client.api_unit_system = Fitgem::ApiUnitSystem.UK # Sets or gets the user id to be used in API calls # # @return [String] @consumer ||= OAuth :: Consumer . new ( @consumer_key , @consumer_secret , { :site => 'http://api.fitbit.com' , :proxy => @proxy } )", "del_tokens": "@consumer ||= OAuth :: Consumer . new ( @consumer_key , @consumer_secret , { :site => 'http://api.fitbit.com' , :request_endpoint => @proxy } )", "commit_type": "add"}
{"commit_tokens": ["adding", "route", "to", "create", "public", "token", "for", "update", "mode"], "add_tokens": "match 'create_token' , to : 'link#create_token' , via : :post", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "File", ".", "directory?", "rather", "than", "File", ".", "exist?", "to", "check", "directory", "existence"], "add_tokens": "@paths [ directory ] . delete ( basename ) unless File . directory? ( path )", "del_tokens": "@paths [ directory ] . delete ( basename ) unless File . exist? ( path )", "commit_type": "use"}
{"commit_tokens": ["Fix", "duplicate", "no", "difference", "here!", "in", "diff", "when", "actual", "array", "has", "more", "items", "than", "the", "expected"], "add_tokens": "string_diff = remove_comma_from_end_of_arrays ( @differ . diff_as_string ( actual , expected ) . lstrip ) string_diff + suffix json = fix_blank_lines_in_empty_hashes JSON . pretty_generate ( comparable ) add_comma_to_end_of_arrays json def add_comma_to_end_of_arrays string string . gsub ( / ( \\n \\s * \\] ) / , ',\\1' ) end def remove_comma_from_end_of_arrays string string . gsub ( / ,( \\n \\s * \\] ) / , '\\1' ) end", "del_tokens": "@differ . diff_as_string ( actual , expected ) . lstrip + suffix fix_blank_lines_in_empty_hashes JSON . pretty_generate ( comparable )", "commit_type": "fix"}
{"commit_tokens": ["add", "generic", "http", "error", "handling", "in", "connection"], "add_tokens": "require_relative 'error' CODE_ERRORS = { 400 => ClientError , 401 => UnauthorizedError , 404 => NotFoundError , 409 => ConflictError , 500 => ServerError } http_call ( symbol , add_api ( relative_path ) , kwords ) def http_call ( symbol , path , kwords ) response = connection . send ( symbol , path , kwords ) error = CODE_ERRORS . fetch ( response . code , nil ) fail error , response . body if error response end", "del_tokens": "connection . send ( symbol , add_api ( relative_path ) , kwords )", "commit_type": "add"}
{"commit_tokens": ["Improve", "layout", "in", "preparation", "for", "modal"], "add_tokens": "@path = params [ :path ] || ''", "del_tokens": "@path = params [ :path ] || '/'", "commit_type": "improve"}
{"commit_tokens": ["Added", "keyboard", "controls", "to", "select", "links"], "add_tokens": "VERSION = \"0.1.1\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "add"}
{"commit_tokens": ["Add", "--", "no", "-", "brew", "option"], "add_tokens": "errors = [ ] # Install Simple 2D on supported platforms unless ARGV . include? \"--no-brew\" # Simple 2D not installed if ` which simple2d ` . empty? # Homebrew not installed, print and quit if ` which brew ` . empty? errors << \"Ruby 2D uses a library called Simple 2D.\" << \"On OS X, this can be installed using Homebrew.\" << \"Install Homebrew, then try installing this gem again.\\n\" << \"Learn more at http://brew.sh\" print_errors ( errors ) exit # Install Simple 2D using Homebrew else ` brew tap simple2d/tap ` ` brew install simple2d ` end # Simple 2D installed, update to latest version else # Homebrew not installed if ` which brew ` . empty? # TODO: Check for latest version manually and update # Homebrew installed, get latest version of Simple 2D else # An alternative, but slower and updates all formulas: # `brew update` # `brew upgrade simple2d` ` brew untap simple2d/tap ` ` brew tap simple2d/tap ` ` brew upgrade simple2d ` end # Configure Simple 2D and create Makefile", "del_tokens": "errors = [ ] # Simple 2D not installed if ` which simple2d ` . empty? # Homebrew not installed, print and quit if ` which brew ` . empty? errors << \"Ruby 2D uses a library called Simple 2D.\" << \"On OS X, this can be installed using Homebrew.\" << \"Install Homebrew, then try installing this gem again.\\n\" << \"Learn more at http://brew.sh\" print_errors ( errors ) exit # Install Simple 2D using Homebrew else ` brew tap simple2d/tap ` ` brew install simple2d ` end # Simple 2D installed, update to latest version else # Homebrew not installed if ` which brew ` . empty? # TODO: Check for latest version manually and update # Homebrew installed, get latest version of Simple 2D else # An alternative, but slower and updates all formulas: # `brew update` # `brew upgrade simple2d` ` brew untap simple2d/tap ` ` brew tap simple2d/tap ` ` brew upgrade simple2d `", "commit_type": "add"}
{"commit_tokens": ["Use", "enable", "/", "disable", "for", "BufferedIO"], "add_tokens": "@writer . disable if @writer and @writer . attached? return if @writer and @writer . enabled? if @writer @writer . enable else @writer = Writer . new ( @io , self ) @writer . attach ( evloop ) end", "del_tokens": "@writer . detach if @writer and @writer . attached? return if @writer and @writer . attached? @writer ||= Writer . new ( @io , self ) @writer . attach evloop", "commit_type": "use"}
{"commit_tokens": ["Fix", "sudo", "handling", "for", "streaming", "commands"], "add_tokens": "return @sudo_available unless @sudo_available . nil? @sudo_available = run_command ( 'sudo -V' , :process_sudo => false ) . success? Chef :: Log . debug ( \"`sudo` not available on #{host}\" ) unless @sudo_available @sudo_available def run_command ( command , options = { } ) defaults = { :process_sudo => true } options = defaults . merge ( options )", "del_tokens": "@sudo_available ||= run_command ( 'sudo -V' , :process_sudo => false ) . success? Chef :: Log . debug ( \"`sudo` not available on #{host}\" ) def run_command ( command , options = { :process_sudo => true } )", "commit_type": "fix"}
{"commit_tokens": ["Add", "FileStore", "to", "manage", "the", "working", "directory", "and", "the", "staging", "area"], "add_tokens": "require 'vcs_toolkit/object_store' require 'vcs_toolkit/file_store' require 'vcs_toolkit/vcs'", "del_tokens": "require 'vcs_toolkit/object_store' module VCSToolkit end", "commit_type": "add"}
{"commit_tokens": ["make", "lock", "a", "real", "concurrent", "lock"], "add_tokens": "@mutex = Mutex . new @mutex . synchronize do exclusive do sync result = yield flush result end", "del_tokens": "exclusive do sync result = yield flush result", "commit_type": "make"}
{"commit_tokens": ["Add", "deployment", "to", "AWS", "environment", "from", "gem", "."], "add_tokens": "def initialize ( use_bundled_cert ) Aws . use_bundled_cert! if use_bundled_cert def deploy ( bucket , relative_path , version , application_name , deployment_group ) begin codedeploy = Aws :: CodeDeploy :: Client . new ( ) codedeploy . create_deployment ( { application_name : application_name , # required deployment_group_name : deployment_group , revision : { revision_type : 'S3' , s3_location : { bucket : bucket , key : File . join ( relative_path , \"#{version.to_s}.zip\" ) , bundle_type : 'zip' } } , deployment_config_name : 'CodeDeployDefault.OneAtATime' , description : \"#{application_name}:#{deployment_group} - #{bucket}_#{File.join(relative_path, \"#{version.to_s}.zip\")}\" , ignore_application_stop_failures : false } ) rescue Aws :: CodeDeploy :: Errors :: ServiceError puts \"Failed to deploy resource: #{exception}\" rescue Exception => exception puts \"Failed to connect to AWS: #{exception}\" end end", "del_tokens": "def initialize ( )", "commit_type": "add"}
{"commit_tokens": ["ADD", "size", "in", "points", "rounding", "to", "up"], "add_tokens": "context \"convert.size_in_points\" do it \"com valor exato\" do image = LatexToPng :: Convert . new ( filename : \"#{ROOT_DIR_SPEC}/support/flux.tex\" ) expect ( image . size_in_points ( \"12px\" ) ) . to eq \"9pt\" end it \"com valor inexato pontos arredondadndo\" do image = LatexToPng :: Convert . new ( filename : \"#{ROOT_DIR_SPEC}/support/flux.tex\" ) expect ( image . size_in_points ( \"18px\" ) ) . to eq \"14pt\" end", "del_tokens": "it \"convert.size_in_points de pixels para pontos\" do image = LatexToPng :: Convert . new ( filename : \"#{ROOT_DIR_SPEC}/support/flux.tex\" ) expect ( image . size_in_points ( \"12px\" ) ) . to eq \"9pt\" end it \"convert.size_in_points de pixels para pontos arredondadndo\" do image = LatexToPng :: Convert . new ( filename : \"#{ROOT_DIR_SPEC}/support/flux.tex\" ) expect ( image . size_in_points ( \"18px\" ) ) . to eq \"14pt\"", "commit_type": "add"}
{"commit_tokens": ["Added", "docs", "to", "directories", "created", "by", "new", "and", "init", "commands"], "add_tokens": "dirs = %w{ docs images fonts pages files layouts includes stylesheets javascripts } . map do | asset |", "del_tokens": "dirs = %w{ images fonts pages files layouts includes stylesheets javascripts } . map do | asset |", "commit_type": "add"}
{"commit_tokens": ["Added", "version", ".", "rb", "tweaked", "rakefile"], "add_tokens": "require 'genspec/version'", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "in", "some", "debugging", "for", "finding", "the", "right", "handler", "class"], "add_tokens": "klass = children . find do | klass | Launchy . log ( \"Seeing if #{klass.name} handles scheme #{scheme}\" klass . handles? ( scheme ) end if klass then Launchy . log ( \"#{klass.name} handles #{scheme}\" ) return klass end", "del_tokens": "klass = children . find { | klass | klass . handles? ( scheme ) } return klass if klass", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "deploy", "creation", "page"], "add_tokens": "resources :deploys , :id => / \\d + / , :only => [ :new , :show , :create ]", "del_tokens": "resources :deploys , :id => / \\d + / , :only => [ :show , :create ]", "commit_type": "add"}
{"commit_tokens": ["Use", "existing", "handler", "method", "for", "member", "event"], "add_tokens": "process_member_event event", "del_tokens": "@users . process_member_event self , event", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "to", "Pandora", "::", "Station", "to", "skip", "ads", "in", "the", "station", "song", "stream", "."], "add_tokens": "next if song_data [ 'adToken' ] end . compact", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["adds", "bootstrap", "-", "kaminari", "-", "views"], "add_tokens": "[ 'ransack' , '>= 1.4.1' ] , [ 'bootstrap-kaminari-views' , '>= 0.0.5' ]", "del_tokens": "[ 'ransack' , '>= 1.4.1' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "delete", "method", "and", "fixed", "a", "bug", "when", "saving", "records"], "add_tokens": "remove ( record ) def self . remove ( record ) record_id = record . id . to_s record_hash = record . hash if self . all . map ( & :hash ) . include? ( record_hash ) record_index . delete ( record_id ) self . all . delete ( record ) end end def delete record = self . class . find_by_id ( self . id ) self . class . remove ( self ) self . class . find_by_id ( self . id ) . nil? end", "del_tokens": "if self . all . map ( & :hash ) . include? ( record_hash ) record_index . delete ( record_id ) self . all . delete ( record ) end", "commit_type": "add"}
{"commit_tokens": ["Make", "webrick", "log", "more", "sanely"], "add_tokens": "require 'frankenstein/server/webrick_logger' # Start the server instance running in a separate thread. begin wrapped_logger = Frankenstein :: Server :: WEBrickLogger . new ( logger : @logger ) @server = WEBrick :: HTTPServer . new ( Logger : wrapped_logger , BindAddress : nil , Port : @port , AccessLog : [ [ wrapped_logger , WEBrick :: AccessLog :: COMMON_LOG_FORMAT ] ] ) @server . mount \"/\" , Rack :: Handler :: WEBrick , app rescue = > ex @logger . fatal ( \"Frankenstein::Server#run\" ) { ( [ \"Exception while trying to create WEBrick::HTTPServer: #{ex.message} (#{ex.class})\" ] + ex . backtrace ) . join ( \"\\n \" ) } ensure @op_cv . signal end end begin @server . start if @server rescue = > ex @logger . fatal ( \"Frankenstein::Server#run\" ) { ( [ \"Exception while running WEBrick::HTTPServer: #{ex.message} (#{ex.class})\" ] + ex . backtrace ) . join ( \"\\n \" ) }", "del_tokens": "# Start the server instance running. @server = WEBrick :: HTTPServer . new ( Logger : @logger , BindAddress : nil , Port : @port ) @server . mount \"/\" , Rack :: Handler :: WEBrick , app @op_cv . signal @server . start", "commit_type": "make"}
{"commit_tokens": ["Use", "--", "debug", ".", "Moar", "debugging", "output"], "add_tokens": "Strainer . ui . debug \"Resetting sandbox...\" Strainer . ui . debug \" Destroying sandbox at '#{SANDBOX}'\" Strainer . ui . debug \" Creating sandbox at '#{SANDBOX}'\" Strainer . ui . debug \"Copying '#{files}' to '#{SANDBOX}'\" Strainer . ui . debug \"Creating directory '#{chef_path}'\" Strainer . ui . debug \"Writing '#{chef_path}/knife.rb' with content: \\n\\n#{contents}\\n\" Strainer . ui . debug \"Copying '#{cookbook.name}' to '#{sandbox_path}'\" Strainer . ui . debug \"Sandbox#load_cookbook('#{cookbook_name}')\" Strainer . ui . debug \" found cookbook at '#{path}'\" raise Strainer :: Error :: CookbookNotFound , \"'#{path}' existed, but I could not extract a cookbook. Is there a 'metadata.rb'?\" Strainer . ui . debug \" did not find '#{cookbook_name}' in any of the sources - resorting to the default cookbook_store...\" cookbook || raise ( Strainer :: Error :: CookbookNotFound , \"Could not find '#{cookbook_name}' in any of the sources.\" ) Strainer . ui . debug \"Setting Sandbox#cookbooks_paths to #{paths.map(&:to_s)}\"", "del_tokens": ":: Strainer . ui . debug \"Resetting sandbox...\" :: Strainer . ui . debug \" Destroying sandbox at '#{SANDBOX}'\" :: Strainer . ui . debug \" Creating sandbox at '#{SANDBOX}'\" :: Strainer . ui . debug \"Copying '#{files}' to '#{SANDBOX}'\" :: Strainer . ui . debug \"Creating directory '#{chef_path}'\" :: Strainer . ui . debug \"Writing '#{chef_path}/knife.rb' with content: \\n\\n#{contents}\\n\" :: Strainer . ui . debug \"Copying '#{cookbook.name}' to '#{sandbox_path}'\" :: Strainer . ui . debug \"Sandbox#load_cookbook('#{cookbook_name}')\" :: Strainer . ui . debug \" found cookbook at '#{path}'\" raise :: Strainer :: Error :: CookbookNotFound , \"'#{path}' existed, but I could not extract a cookbook. Is there a 'metadata.rb'?\" :: Strainer . ui . debug \" did not find '#{cookbook_name}' in any of the sources - resorting to the default cookbook_store...\" cookbook || raise ( :: Strainer :: Error :: CookbookNotFound , \"Could not find '#{cookbook_name}' in any of the sources.\" ) :: Strainer . ui . debug \"Setting Sandbox#cookbooks_paths to #{paths.map(&:to_s)}\"", "commit_type": "use"}
{"commit_tokens": ["Moved", "altered", "Date", "/", "DateTime", "stuff", "to", "TimePoint", "."], "add_tokens": "DEBUG = true include Tracing if $DEBUG require \"runt/timepoint\"", "del_tokens": "DEBUG = false", "commit_type": "move"}
{"commit_tokens": ["Move", "the", "normalization", "logic", "from", "Triplet", "to", "Triplet", "::", "Normalize"], "add_tokens": "require 'shared_helper'", "del_tokens": "require 'shared_helper' # requires hexp", "commit_type": "move"}
{"commit_tokens": ["Fix", "some", "calls", "in", "tests"], "add_tokens": "@@company_id = \"\" response = @@client . company . retrieve ( @@company_id ) :country_code => \"US\" :country_code => \"US\"", "del_tokens": "response = @@client . company . retrieve ( @@verification_id ) :country => \"US\" :country => \"US\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "messaging", "on", "startup", "."], "add_tokens": "puts \"Listening on UDP #{udp_server[\"address\"]}:#{udp_server[\"port\"]}\" if verbose", "del_tokens": "# TODO # Add initialization output if verbose # like setting up udp server # and such", "commit_type": "add"}
{"commit_tokens": ["use", "a", "generic", "errors", "array", "for", "handling", "command", "line", "option", "errors"], "add_tokens": "@errors = [ ] @errors << \"You have to specify a beanstalk host!\" @errors << \"You have to specify a recipients file!\" end if @errors . size > 0 puts \"Errors:\" @errors . each do | error | puts \" - #{error}\" end puts", "del_tokens": "puts \"You have to specify a beanstalk host!\" puts opts exit 2 puts \"You have to specify a recipients file!\"", "commit_type": "use"}
{"commit_tokens": ["Add", "in", "*", "basic", "*", "test", "suite"], "add_tokens": "cast = \" as! #{@swift_type}\" \"instantiateViewControllerWithIdentifier(\\\"#{@name}\\\")#{cast}\"", "del_tokens": "cast = \"as! #{@swift_type}\" \"instantiateViewControllerWithIdentifier(\\\"#{@name}\\\") #{cast}\"", "commit_type": "add"}
{"commit_tokens": ["implement", "directory", "listening", "if", "requested", "path", "is", "a", "folder"], "add_tokens": "code = '404 Not Found' def send ( code , message , type = 'text/html' ) print \"HTTP/1.1 #{code}\\r\\n\" + \"Content-Type: #{type}\\r\\n\" +", "del_tokens": "code = 404 def send ( code , message ) print \"HTTP/1.1 #{code} Not Found\\r\\n\" + \"Content-Type: text/plain\\r\\n\" +", "commit_type": "implement"}
{"commit_tokens": ["use", "sinatra", "-", "sequel", "to", "establish", "db", "connection"], "add_tokens": "require 'sinatra/sequel' # Establish the database connection; or, omit this and use the DATABASE_URL # environment variable as the connection string: set :database , 'mysql://username@hostname/database' @generator = Namey :: Generator . new ( @database )", "del_tokens": "before do @generator = Namey :: Generator . new end", "commit_type": "use"}
{"commit_tokens": ["Add", "newlines", "to", "MinispadeFilter", "output", "."], "add_tokens": "code = %[\"use strict\";\\n] + code if @use_strict function = \"function() {\\n#{code}\\n}\" ret = \"minispade.register('#{@module_id_generator.call(input)}', #{function});\\n\"", "del_tokens": "code = '\"use strict\"; ' + code if @use_strict function = \"function() {#{code}}\" ret = \"minispade.register('#{@module_id_generator.call(input)}',#{function});\"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "separate", "config", "and", "credential", "INI", "files"], "add_tokens": "# Reads in credential files in Amazon's download format and presents the credentials to you def load_inis ( config_ini_file , credentials_ini_file = nil ) @credentials = load_config_ini ( config_ini_file ) if credentials_ini_file @credentials . merge! ( load_credentials_ini ( credentials_ini_file ) ) end end def load_config_ini ( config_ini_file ) inifile = IniFile . load ( File . expand_path ( config_ini_file ) ) config = { } config [ profile_name ] = profile end config end def load_credentials_ini ( credentials_ini_file ) inifile = IniFile . load ( File . expand_path ( credentials_ini_file ) ) config = { } if inifile inifile . each_section do | section | profile = inifile [ section ] . inject ( { } ) do | result , pair | result [ pair [ 0 ] . to_sym ] = pair [ 1 ] result end profile [ :name ] = section config [ section ] = profile config credentials_file = ENV [ 'AWS_CREDENTIAL_FILE' ] || File . expand_path ( '~/.aws/credentials' ) if File . file? ( credentials_file ) load_inis ( config_file , credentials_file ) else load_inis ( config_file ) end", "del_tokens": "# Reads in a credentials file in Amazon's download format and presents the credentials to you def load_ini ( credentials_ini_file ) inifile = IniFile . load ( File . expand_path ( credentials_ini_file ) ) @credentials [ profile_name ] = profile else # Get it to throw an error File . open ( File . expand_path ( credentials_ini_file ) ) do load_ini ( config_file )", "commit_type": "add"}
{"commit_tokens": ["added", "the", "remote", "proxy", "objects"], "add_tokens": "require 'typhoeus/remote_proxy_object' Thread . current [ :curl_multi ] ||= Typhoeus :: Multi . new def self . perform_easy_requests", "del_tokens": "def self . add_after_service_access_callback ( & block ) @after_service_access_callbacks ||= [ ] @after_service_access_callbacks << block end def self . multi_running? ! Thread . current [ :curl_multi_running ] . nil? end def self . service_access ( & block ) Thread . current [ :curl_multi ] ||= Typhoeus :: Multi . new Thread . current [ :curl_multi_running ] = true block . call Thread . current [ :curl_multi_running ] = nil @after_service_access_callbacks . each { | b | b . call } unless @after_service_access_callbacks . nil?", "commit_type": "add"}
{"commit_tokens": ["Removing", "unused", "files", ".", "Simplifying", "module", "dependencies"], "add_tokens": "require_relative 'jackpot/version' raw_config = File . read ( File . dirname ( __FILE__ ) + \"/../config/jackpot.yml\" ) JACKPOT_CONFIG = YAML . load ( raw_config ) [ ENV [ 'RACK_ENV' ] ]", "del_tokens": "require_relative 'jackpot/clients'", "commit_type": "remove"}
{"commit_tokens": ["Fix", "long", "-", "standing", "typo"], "add_tokens": "millennia : 'ml' millennia : [ 'millenium' , 'millennia' ] ,", "del_tokens": "millenia : 'ml' millennia : [ 'millenium' , 'millenia' ] ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "use_fdb", "to", "as3", "rakefile", "template"], "add_tokens": "# m.use_fdb = true # m.use_fcsh = true", "del_tokens": "# m.use_fcsh = true", "commit_type": "add"}
{"commit_tokens": ["change", "before", "/", "after", "logic", "so", "instead", "of", "applying", "after", "last", "we", "don", "t", "apply", "it", "at", "all", "if", "there", "is", "a", "before", ";", "bump", "version"], "add_tokens": "migrates = apply_files . collect { | path | File . basename ( path ) . slice ( 0 .. - 11 ) } migrates . each do | name | base , divider , _ = name . partition ( '_after' ) next if divider . empty? if migrates . include? ( \"#{base}_before\" ) file_ending = \"#{name}_apply.sql\" apply_files . delete_if { | path | path . end_with? ( file_ending ) }", "del_tokens": "apply_files . sort! do | valx , valy | if valx . end_with? ( '_before_apply.sql' ) - 1 elsif valy . end_with? ( '_before_apply.sql' ) 1 else valx <=> valy", "commit_type": "change"}
{"commit_tokens": ["use", "bundler", "generate", "gem", "to", "bring", "the", "gem", "to", "the", "latest", "standard"], "add_tokens": "# require \"giantbomb/version\" # module Giantbomb # # Your code goes here... # end # VERSION = '1.5.4'", "del_tokens": "VERSION = '1.5.4'", "commit_type": "use"}
{"commit_tokens": ["use", "ERB", "to", "generate", "handlers"], "add_tokens": "require \"erb\" template = IO . read ( template_path ) # Important ERB variables with examples: # @handler - handlers/controllers/posts.create # @process_type - controller @process_type = @handler . split ( '/' ) [ 1 ] . singularize result = ERB . new ( template , nil , \"-\" ) . result ( binding ) IO . write ( js_path , result ) # FileUtils.cp(template_path, js_path)", "del_tokens": "FileUtils . cp ( template_path , js_path ) # FileUtils.touch(js_path)", "commit_type": "use"}
{"commit_tokens": ["allow", "continuation", "for", "track", "listing"], "add_tokens": "def listtracks ( continuation_token : nil ) pb_body . continuation_token = continuation_token unless continuation_token . nil?", "del_tokens": "def listtracks", "commit_type": "allow"}
{"commit_tokens": ["Update", "version", "and", "changelog", "for", "release"], "add_tokens": "VERSION = '3.1.1'", "del_tokens": "VERSION = '3.1.0'", "commit_type": "update"}
{"commit_tokens": ["Fix", "#list", "and", "one", "test", "."], "add_tokens": "next if File . directory? ( file ) end . compact", "del_tokens": "end", "commit_type": "fix"}
{"commit_tokens": ["Made", "descriptions", "more", "Subject", "-", "centric"], "add_tokens": "# Subject views a web page. # Subject places a sales order - referred to as an # ecommerce transaction in other Snowplow trackers.", "del_tokens": "# Track a page view event. # Track a sales order - referred to as an # ecommerce transaction in other Snowplow # trackers.", "commit_type": "make"}
{"commit_tokens": ["added", "<<", "method", "to", "add", "active", "styles", "&", "fixed", "whitespace"], "add_tokens": "self . << obj def << style @active << style end str . gsub ( / ( #{ Regexp . escape ( glyph ) } +)(.+?) \\1 / ) { stylize $2 , styles } end end", "del_tokens": "@active << obj str . gsub ( / ( #{ Regexp . escape ( glyph ) } +)(.+?) \\1 / ) { stylize $2 , styles } end end", "commit_type": "add"}
{"commit_tokens": ["moved", "add", "lang", "to", "generator", "instead", "of", "rake"], "add_tokens": "t . string :< % = lang % > _status , default : 'untranslated'", "del_tokens": "t . string :< % = lang % > _status", "commit_type": "move"}
{"commit_tokens": ["Fixed", "problem", "with", "not", "searching", "for", "all", "of", "the", "possible", "types", "of", "StateDeadline", "classes", "when", "updating", "an", "existing", "deadline", "."], "add_tokens": "state_deadline = state_deadlines . find_or_initialize_by_state_id ( #{record.id}) state_deadline . stateful_id = self . id", "del_tokens": "state_deadline = self . class :: StateDeadline . find_or_initialize_by_stateful_id_and_state_id ( self . id , #{record.id})", "commit_type": "fix"}
{"commit_tokens": ["implemented", "exception", "safe", "checking", "of", "if", "the", "node", "destination", "of", "method", "call", "is", "inside", "the", "sandbox"], "add_tokens": "sandbox_inside = true begin sandbox_inside = ( klass . instance_method ( method_name ) . bind ( recv ) . body . file == sandbox . source ) rescue TypeError end if sandbox_inside", "del_tokens": "if klass . instance_method ( method_name ) . bind ( recv ) . body . file == sandbox . source", "commit_type": "implement"}
{"commit_tokens": ["Add", "Issue", ".", "has_many", ":", "worklogs"], "add_tokens": "'attachment' => [ { 'foo' => 'bar' } , { 'baz' => 'flum' } ] , 'worklog' => { ' worklogs ' => [{' foo ' => ' bar '}, {' baz ' => ' flum ' } ] } , subject . should have_many ( :worklogs , JIRA :: Resource :: Worklog ) subject . worklogs . length . should == 2", "del_tokens": "'attachment' => [ { 'foo' => 'bar' } , { 'baz' => 'flum' } ]", "commit_type": "add"}
{"commit_tokens": ["Make", "appbundler", "copy", "over", "Gemfile", ".", "lock"], "add_tokens": "app = App . new ( app_path , bin_path ) created_stubs = app . write_executable_stubs app . copy_bundler_env", "del_tokens": "created_stubs = App . new ( app_path , bin_path ) . write_executable_stubs", "commit_type": "make"}
{"commit_tokens": ["implemented", "an", "after", "painting", "hook", "so", "the", "composer", "can", "highlight", "props"], "add_tokens": "require 'limelight/paint_action' end def after_painting ( flag = true , & block ) if flag @panel . after_paint_action = PaintAction . new ( & block ) else @panel . after_paint_action = nil end end", "del_tokens": "end", "commit_type": "implement"}
{"commit_tokens": ["Fix", "rubocop", "Style", "/", "IndentArray", "cop"], "add_tokens": "{ type : 'skype' , value : random_word } , { type : 'email' , value : random_email }", "del_tokens": "{ type : 'skype' , value : random_word } , { type : 'email' , value : random_email }", "commit_type": "fix"}
{"commit_tokens": ["allow", "configuration", "of", "the", "Faraday", "adapter"], "add_tokens": "builder . adapter ( config . adapter || Faraday . default_adapter )", "del_tokens": "builder . adapter Faraday . default_adapter", "commit_type": "allow"}
{"commit_tokens": ["Fix", "fail", "not", "reported", "when", "class", "coverage", "is", "below", "minimum"], "add_tokens": "VERSION = '0.1.1' . freeze", "del_tokens": "VERSION = '0.1.0' . freeze", "commit_type": "fix"}
{"commit_tokens": ["Fix", "AVP", "type", "of", "Framed", "-", "IP", "-", "Address"], "add_tokens": "'Framed-IP-Address' => [ 8 , OctetString ] ,", "del_tokens": "'Framed-IP-Address' => [ 8 , IPAddress ] ,", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "allow", "compatibility", "with", "rails", "4"], "add_tokens": "create_ar_sync_migration ( model ) def create_ar_sync_migration ( model_name )", "del_tokens": "create_migration ( model ) def create_migration ( model_name )", "commit_type": "update"}
{"commit_tokens": ["Use", "our", "own", "more", "informative", "ssh", "-", "askpass", "stub", "."], "add_tokens": "ENV [ 'SSH_ASKPASS' ] = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '..' , ' .. ', ' .. ' , 'scripts' , 'stub_ssh_askpass' ) )", "del_tokens": "if File . exists? ( '/bin/false' ) ENV [ 'SSH_ASKPASS' ] = '/bin/false' else ENV [ 'SSH_ASKPASS' ] = '/usr/bin/false' end", "commit_type": "use"}
{"commit_tokens": ["Make", "tests", "a", "bit", "easier", "to", "read", "with", "some", "empty", "lines"], "add_tokens": "", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Use", "add_score", "method", "for", "result", "set", "observation"], "add_tokens": "comparator . add_observer ( result_set , :add_score ) comparator . add_observer ( result_set , :add_score )", "del_tokens": "comparator . add_observer ( result_set ) comparator . add_observer ( result_set )", "commit_type": "use"}
{"commit_tokens": ["changing", "the", "way", "of", "delegation"], "add_tokens": "eval \"def #{ß}( *aa, &b ); puts '%s, %s' % ['#{ß}', self]; self.y_petri_manipulator.send #{ß}, *aa, &b end\"", "del_tokens": "eval \"def #{ß}( *aa, &b ); puts '%s, %s' % '#{ß}', self; self.y_petri_manipulator.send #{ß}, *aa, &b end\"", "commit_type": "change"}
{"commit_tokens": ["Use", "POST", "instead", "of", "GET", "to", "send", "a", "notification"], "add_tokens": "API_PATH = \"/publicapi/add\" DEPRECATED_API_PATH = \"/api/add_notification.php?application=%s&event=%s&description=%s\" USER_AGENT = \"Prowler/1.0.3\" 'User-Agent' => USER_AGENT request = Net :: HTTP :: Post . new ( API_PATH , headers ) request . set_form_data ( { 'apikey' => api_key , 'priority' => priority , 'application' => application , 'event' => event , 'description' => message } ) request = Net :: HTTP :: Get . new ( sprintf ( DEPRECATED_API_PATH , URI . escape ( application ) , URI . escape ( event ) , URI . escape ( message ) ) , headers )", "del_tokens": "def path ( * params ) #:nodoc: sprintf ( \"/publicapi/add?apikey=%s&priority=%d&application=%s&event=%s&description=%s\" , * params ) end def deprecated_path ( * params ) #:nodoc: sprintf ( \"/api/add_notification.php?application=%s&event=%s&description=%s\" , * params ) end 'User-Agent' => 'ProwlScript/1.0' request = Net :: HTTP :: Get . new ( path ( api_key , priority , URI . escape ( application ) , URI . escape ( event ) , URI . escape ( message ) ) , headers ) request = Net :: HTTP :: Get . new ( deprecated_path ( URI . escape ( application ) , URI . escape ( event ) , URI . escape ( message ) ) , headers )", "commit_type": "use"}
{"commit_tokens": ["Add", "DetailedLogSubscriber", "to", "more", "easily", "debug", "ActiveResource", "requests", "/", "responses"], "add_tokens": "def request_with_detailed_log_subscriber ( method , path , * arguments ) result = request_without_detailed_log_subscriber ( method , path , * arguments ) detailed_log_subscriber ( result , arguments ) result rescue = > e detailed_log_subscriber ( e . response , arguments ) if e . respond_to? ( :response ) raise end def detailed_log_subscriber ( response , arguments ) ActiveSupport :: Notifications . instrument ( \"request.active_resource_detailed\" ) do | payload | payload [ :response ] = response payload [ :data ] = arguments end end alias_method_chain :request , :detailed_log_subscriber end", "del_tokens": "# alias_method :handle_response_without_instance, :handle_response # alias_method :handle_response, :handle_response_with_instance end", "commit_type": "add"}
{"commit_tokens": ["Fix", "calling", "destroy", "or", "clear", "on", "session"], "add_tokens": "request . session . send ( request . session . respond_to? ( :destroy ) ? :destroy : :clear )", "del_tokens": "request . session . send respond_to? ( :destroy ) ? :destroy : :clear", "commit_type": "fix"}
{"commit_tokens": ["updated", "db", "options", "to", "match", "those", "found", "in", "the", "SEM", "Rush", "API", "docs"], "add_tokens": "DBS = [ :us , :uk , :ca , :ru , :de , :fr , :es , :it , :br , :au , :ar , :be , :ch , :dk , :fi , :hk , :ie , :il , :mx , :nl , :no , :pl , :se , :sg , :tr ] #\"us\" - for Google.com, \"uk\" - for Google.co.uk, \"ru\" - for Google.ru, \"de\" for Google.de, \"fr\" for Google.fr, \"es\" for Google.es, \"it\" for Google.it Beta, \"br\" for Google.com.br Beta, \"au\" for Google.com.au Beta, etc", "del_tokens": "DBS = [ :us , :uk , :ru , :de , :fr , :es , :it , :br , :au ] #\"us\" - for Google.com, \"uk\" - for Google.co.uk, \"ru\" - for Google.ru, \"de\" for Google.de, \"fr\" for Google.fr, \"es\" for Google.es, \"it\" for Google.it Beta, \"br\" for Google.com.br Beta, \"au\" for Google.com.au Beta.", "commit_type": "update"}
{"commit_tokens": ["Add", "Creole", "to", "valid", "markup", "formats", "."], "add_tokens": "VALID_PAGE_RE = / ^(.+) \\. (md|mkdn?|mdown|markdown|textile|rdoc|org|creole|re?st( \\. txt)?|asciidoc|pod| \\d )$ /i when / \\. (creole)$ /i :creole when :creole then 'creole'", "del_tokens": "VALID_PAGE_RE = / ^(.+) \\. (md|mkdn?|mdown|markdown|textile|rdoc|org|re?st( \\. txt)?|asciidoc|pod| \\d )$ /i", "commit_type": "add"}
{"commit_tokens": ["Use", "Color", "representation", "inside", "Light"], "add_tokens": "@color = Color . from_struct ( payload . color . snapshot )", "del_tokens": "@color = payload . color . snapshot", "commit_type": "use"}
{"commit_tokens": ["Adds", "support", "for", "redirecting", "log", "files", "for", "daemon"], "add_tokens": "VERSION = \"0.1.3\"", "del_tokens": "VERSION = \"0.1.2\"", "commit_type": "add"}
{"commit_tokens": ["added", "resolv", "-", "replace", "in", "attempt", "to", "fix", "socketerrors"], "add_tokens": "require 'resolv-replace.rb' require_relative 'restful_resource/version' require_relative 'restful_resource/paginated_array' require_relative 'restful_resource/parameter_missing_error' require_relative 'restful_resource/resource_id_missing_error' require_relative 'restful_resource/open_object' require_relative 'restful_resource/associations' require_relative 'restful_resource/base' require_relative 'restful_resource/old_base'", "del_tokens": "require_relative \"restful_resource/version\" require_relative \"restful_resource/paginated_array\" require_relative \"restful_resource/parameter_missing_error\" require_relative \"restful_resource/resource_id_missing_error\" require_relative \"restful_resource/open_object\" require_relative \"restful_resource/associations\" require_relative \"restful_resource/base\" require_relative \"restful_resource/old_base\"", "commit_type": "add"}
{"commit_tokens": ["changed", "hash", "keys", "and", "request_uri", "to", "to_s"], "add_tokens": "request = Net :: HTTP :: Get . new ( uri . to_s ) content [ :mime_type ] = response . content_type content [ :length ] = response . content_length content [ :body ] = response . body", "del_tokens": "request = Net :: HTTP :: Get . new ( uri . request_uri ) content [ :content_type ] = response . content_type content [ :content_length ] = response . content_length content [ :content_body ] = response . body", "commit_type": "change"}
{"commit_tokens": ["Fix", "eager", "loading", "with", "lazy", "world", "initialization"], "add_tokens": "@world . reload! if @world", "del_tokens": "ActionDispatch :: Reloader . to_prepare do ForemanTasks . dynflow . eager_load_actions! world . reload! end", "commit_type": "fix"}
{"commit_tokens": ["added", "create", "util", "for", "reviews", "endpoint"], "add_tokens": "describe \".create_review\" , :vcr do let ( :attributes ) { { comment : \"Awesome place\" , rating : 5 } } it \"creates a new review\" do client . create_review ( 1 , attributes ) assert_requested :post , bs_url ( \"reviews\" ) , body : { booking_id : 1 , reviews : [ attributes ] } . to_json end it \"returns newly created review\" do VCR . use_cassette ( 'BookingSync_API_Client_Reviews/_create_review/creates_a_new_review' ) do review = client . create_review ( 1 , attributes ) expect ( review . comment ) . to eql ( attributes [ :comment ] ) expect ( review . rating ) . to eql ( attributes [ :rating ] ) end end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "to", "find", "gnu", "make"], "add_tokens": "MAKE = ENV [ 'MAKE' ] || %w[ gmake make ] . find { | c | system ( c , '-v' ) } RUBY_PLATFORM =~ / mswin / ? 'nmake' : MAKE", "del_tokens": "RUBY_PLATFORM =~ / mswin / ? 'nmake' : 'make'", "commit_type": "make"}
{"commit_tokens": ["Added", "resource", ".", "exists?", "method", "and", "fixed", "resource", ".", "retrieve!"], "add_tokens": "results = self . class . find_by ( @client , uri : @data [ 'uri' ] ) if @data [ 'uri' ] && ( ! defined? ( results ) || results . empty? ) # Check if a resource exists # @note name or uri must be specified inside resource # @return [Boolean] Whether or not resource exists def exists? fail 'Must set resource name or uri before trying to retrieve!' unless @data [ 'name' ] || @data [ 'uri' ] return true if @data [ 'name' ] && self . class . find_by ( @client , name : @data [ 'name' ] ) . size == 1 return true if @data [ 'uri' ] && self . class . find_by ( @client , uri : @data [ 'uri' ] ) . size == 1 false end", "del_tokens": "results = self . class . find_by ( @client , uri : @data [ 'uri' ] ) if @data [ 'uri' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Parse", "Master", "Key", "ignores", "Relations", "fixes", "User", "URI"], "add_tokens": "without_relations = without_reserved without_relations . each { | k , v | if v . is_a? Hash if v [ Protocol :: KEY_TYPE ] == Protocol :: TYPE_RELATION without_relations . delete ( k ) end end } body = without_relations . to_json", "del_tokens": "body = without_reserved . to_json", "commit_type": "add"}
{"commit_tokens": ["Fixed", "auto", "-", "insertion", "of", "File", ".", "dirname", "(", "input", ")", ".", "No", "paths", "that", "are", "children", "of", "other", "paths", "will", "be", "added", "to", "the", "MXMLC", "or", "COMPC", "tasks"], "add_tokens": "compiler = compc @compc_output do | t | t . source_path << @src t . source_path << @test assert_equal ( 2 , compiler . source_path . size ) assert_equal ( 'src' , compiler . source_path [ 0 ] ) assert_equal ( 'test' , compiler . source_path [ 1 ] )", "del_tokens": "compc @compc_output do | t | t . source_path << 'src' t . source_path << 'test'", "commit_type": "fix"}
{"commit_tokens": ["Add", "encoding", "and", "create", "directory", "unless", "exist", "."], "add_tokens": "# encoding: utf-8 unless File . exist? ( file . file_path_for_directory ( locale ) ) Dir . mkdir ( file . file_path_for_directory ( locale ) ) end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["fix", "rspec", "adapter", "nil", "exception"], "add_tokens": "start_mongrel ( :port => selenium_config . application_port ) if selenium_config . start_server && selenium_config . start_server . to_sym == :true", "del_tokens": "start_mongrel ( :port => selenium_config . application_port ) if selenium_config . start_server . to_sym == :true", "commit_type": "fix"}
{"commit_tokens": ["changed", "Scrape", ".", "scrape_data", "to", "accurately", "parse", "all"], "add_tokens": "puts \"-------------------------------------------------\" puts \"-------------------------------------------------\" doc . css ( \"tbody tr\" ) . each do | row | #shows how many rows there are in total for the page, may come in handy later rows = Nokogiri :: HTML ( open ( \"http://prices.tcgplayer.com/price-guide\" ) ) . css ( \"tbody tr\" ) [ 0 .. - 1 ] MTG . all # Scraper.counter # => returns 198 rows", "del_tokens": "doc . css ( \"tbody\" ) . each do | row | #Scrape.scrape_data parses through one row, but doesn't gather the collections #of the rest of the following cards. I need to iterate throught the array value #of the css selectors that are set before the '.text' methods of each of them. #first going to find out how many rows there are in total to then see how to iterate them rows = Nokogiri :: HTML ( open ( \"http://prices.tcgplayer.com/price-guide\" ) ) . css ( \"tbody tr\" ) [ 1 .. - 1 ] # MTG.all Scraper . counter # => returns 197 rows", "commit_type": "change"}
{"commit_tokens": ["Adding", "polymorphic", "object", "not", "Notification"], "add_tokens": "belongs_to :object , :polymorphic => :true", "del_tokens": "attr_accessor :object", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "d", "to", "self", ".", "included"], "add_tokens": "def self . included ( base )", "del_tokens": "def self . include ( base )", "commit_type": "add"}
{"commit_tokens": ["Add", "size", "-", "checking", "for", "maximum", "message", "size"], "add_tokens": "specify \"message total size too large\" do", "del_tokens": "specify \"message total size too large\" , pending : \"total size limit\" do", "commit_type": "add"}
{"commit_tokens": ["Changing", "the", "output", "of", "the", "fieldlist", "options", "think", "this", "looks", "better", ".."], "add_tokens": "ui . color ( 'Key' , :bold ) , ui . color ( 'Type' , :bold ) , ui . color ( 'Value' , :bold ) object_fields << ui . color ( k , :yellow , :bold )", "del_tokens": "ui . color ( 'Key' , :yellow , :bold ) , ui . color ( 'Type' , :yellow , :bold ) , ui . color ( 'Value' , :yellow , :bold ) object_fields << k", "commit_type": "change"}
{"commit_tokens": ["allow", "doc", "identifier", "to", "be", "absent"], "add_tokens": "dn += \"&mdash;#{docyear}\" if dn && docyear", "del_tokens": "dn += \"&mdash;#{docyear}\" if docyear", "commit_type": "allow"}
{"commit_tokens": ["use", "a", "real", "UUID", "via", "uuidtools", "gem"], "add_tokens": "require 'uuidtools' @agent_uuid = UUIDTools :: UUID . random_create . hexdigest", "del_tokens": "@agent_uuid = 12345", "commit_type": "use"}
{"commit_tokens": ["Fix", "rubocop", "warning", "TrailingComma", "in", "to_markdown_heading"], "add_tokens": "expected : \"# hoge\\n## hige\" expected : \"# hoge\\n# hige\" expected : \"# hoge\\n## hige\\n# hege\" expected : \"# hoge\\n## hige1\\n## hige2\\n# hege\" }", "del_tokens": "expected : \"# hoge\\n## hige\" , expected : \"# hoge\\n# hige\" , expected : \"# hoge\\n## hige\\n# hege\" , expected : \"# hoge\\n## hige1\\n## hige2\\n# hege\" , } ,", "commit_type": "fix"}
{"commit_tokens": ["added", "option", "to", "specify", "token", "method", "to", "use"], "add_tokens": "attr_accessor :id , :secret , :site , :connection , :options , :raise_errors , :token_method # <tt>:access_token_method</tt> :: Specify the method to use for token endpoints, can be :get or :post # (note: for Facebook this should be :get and for Google this should be :post) self . token_method = self . options . delete ( :access_token_method ) || :get", "del_tokens": "attr_accessor :id , :secret , :site , :connection , :options , :raise_errors", "commit_type": "add"}
{"commit_tokens": ["Adds", "a", "hosted", "sync", "document", "example", "file"], "add_tokens": "puts \"The hosted PDF is now available for public download at #{status_response.download_url}\"", "del_tokens": "puts \"Hosted PDF is available for public download at #{status_response.download_url}\"", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "create", "keyspaces", "with", "NetworkReplicationStrategy"], "add_tokens": "execute ( create_keyspace_statement ( config ) ) def create_keyspace_statement ( config ) validate_config ( config ) <<-CQL . strip_heredoc CREATE KEYSPACE #{config.keyspace} WITH replication = { 'class' : '#{config.replication[' class ']}' , #{replication_options_statement(config)} } CQL end elsif config_requires_replication? ( config ) && ! config_includes_replication? ( config ) def config_requires_replication? ( config ) config . replication [ 'class' ] == 'SimpleStrategy' end def replication_options_statement ( config ) if config . replication [ 'class' ] == \"SimpleStrategy\" \"'replication_factor': #{config.replication['replication_factor']}\" elsif config . replication [ 'class' ] == \"NetworkTopologyStrategy\" config . replication . reject { | k , v | k == 'class' } . map { | k , v | \"'#{k}': #{v}\" } . join ( \", \" ) end end", "del_tokens": "validate_config ( config ) execute ( \"CREATE KEYSPACE #{config.keyspace} WITH replication = { 'class' :' #{ config . replication [ 'class' ] } ' , 'replication_factor' : #{ config . replication [ 'replication_factor' ] } } \" ) end unless config_includes_replication? ( config )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "few", "integer", "-", ">", "string", "conversion", "errors", "."], "add_tokens": "getwhat << word_prefix ( w ) if File . exists? ( File . join ( aai_config [ :index_file ] + [ word_prefix ( w ) . to_s ] ) ) File . open ( File . join ( aai_config [ :index_file ] + [ name . to_s ] ) ) do | f |", "del_tokens": "getwhat << word_prefix ( w ) if File . exists? ( File . join ( aai_config [ :index_file ] + [ word_prefix ( w ) ] ) ) File . open ( File . join ( aai_config [ :index_file ] + [ name ] ) ) do | f |", "commit_type": "fix"}
{"commit_tokens": ["fixed", "problem", "with", "passwords", "for", "filetransfer"], "add_tokens": "Veewee :: Ssh . transfer_file ( \"localhost\" , filename , filename , ssh_options )", "del_tokens": "Veewee :: Ssh . transfer_file ( \"localhost\" , filename , ssh_options )", "commit_type": "fix"}
{"commit_tokens": ["Use", "yes", "and", "no", "instead", "of", "true", "and", "false", "on", "i18n", "."], "add_tokens": "[ [ I18n . t ( :\" simple_form.yes \" , :default => 'Yes' ) , true ] , [ I18n . t ( :\" simple_form.no \" , :default => 'No' ) , false ] ]", "del_tokens": "[ [ I18n . t ( :\" simple_form.true \" , :default => 'Yes' ) , true ] , [ I18n . t ( :\" simple_form.false \" , :default => 'No' ) , false ] ]", "commit_type": "use"}
{"commit_tokens": ["Remove", "arid_cache", "methods", ";", "move", "install", "/", "uninstall", "/", "init", "to", "a", "rails", "/", "directory", "."], "add_tokens": "ActiveRecord :: Base . logger = Logger . new ( open ( File . join ( File . dirname ( __FILE__ ) , 'log' , 'test.log' ) ) )", "del_tokens": "ActiveRecord :: Base . logger = Logger . new ( STDOUT )", "commit_type": "remove"}
{"commit_tokens": ["Added", "HTML", "ID", "search", "to", "Container#field", "and", "Container#fill_in", "to", "allow", "fields"], "add_tokens": "# @param [Boolean] id assumes the given label is an HTML ID and searches for it. def field ( label , start_node : nil , include_groups : false , placeholder : false , id : false ) elsif id start_node . element ( id : label ) . to_subtype # @param [Boolean] id assumes the given label is an HTML ID and searches for it. def fill_in ( label , value , start_node : nil , include_groups : nil , placeholder : false , id : false ) placeholder : placeholder , id : id", "del_tokens": "def field ( label , start_node : nil , include_groups : false , placeholder : false ) def fill_in ( label , value , start_node : nil , include_groups : nil , placeholder : false ) placeholder : placeholder", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "default", "group", "by", "setting", "lazily", "."], "add_tokens": "add_group ( new_group ) groups . each do | g | groups . map do | g | groups . map do | g | def add_group ( group ) @groups = ( groups << group ) end def groups @groups ||= [ [ :vendor , { assets_path : @assets_path } ] ] end", "del_tokens": "@groups ||= [ [ :vendor , { assets_path : @assets_path } ] ] @groups << new_group @groups . each do | g | @groups . map do | g | @groups . map do | g |", "commit_type": "fix"}
{"commit_tokens": ["Remove", "dependency", "on", "que", "-", "web"], "add_tokens": "QUERY = %{ SELECT count ( * ) AS total , count ( locks . job_id ) AS running , coalesce ( sum ( ( error_count > 0 AND locks . job_id IS NULL ) :: int ) , 0 ) AS failing , coalesce ( sum ( ( error_count = 0 AND locks . job_id IS NULL ) :: int ) , 0 ) AS scheduled FROM que_jobs LEFT JOIN ( SELECT ( classid :: bigint << 32 ) + objid :: bigint AS job_id FROM pg_locks WHERE locktype = 'advisory' ) locks USING ( job_id ) } . freeze query = queue ? \"#{QUERY} WHERE queue = '#{queue}'\" : QUERY", "del_tokens": "query = :: Que :: Web :: SQL [ :dashboard_stats ] query = \"#{query} WHERE queue = '#{queue}'\" if queue", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "missing", "test", "coverage"], "add_tokens": "return @logger if @logger && logger . nil? @logger = OptionalLogger :: Logger . new ( logger )", "del_tokens": "if logger . nil? @logger = OptionalLogger :: Logger . new ( nil ) if @logger . nil? else @logger = OptionalLogger :: Logger . new ( logger ) end return @logger", "commit_type": "fix"}
{"commit_tokens": ["use", "STDOUT", "for", "errors", "avoid", "unnecessary", "raise", "and", "exception"], "add_tokens": "STDERR . puts \"unrecognized command `#{@command}'\" exit 1 STDERR . puts \"Error: #{e}\" STDERR . puts \"Internal failure. #{e}\"", "del_tokens": "class UnknownCommand < StandardError ; end raise UnknownCommand , \"unrecognized command `#{@command}'\" puts \"Error: #{e}\" puts \"Internal failure. #{e}\"", "commit_type": "use"}
{"commit_tokens": ["implement", "domain", "and", "tests", "all", "tests", "passing"], "add_tokens": "attr_accessor :input_files attr_accessor :output_files attr_reader :domain errors = self . validate_config config unless errors . empty? raise TargetLoadError . new ( \"The target definition at #{@config_path} contains the following errors:\\n#{errors.join(\"\\n\")}\" ) end raise TargetLoadError . new ( \"Target was not valid according to the domain definition\" ) unless @domain . target_valid? # validate the config against the domain definition. Return an array # whose length will be the number of errors found. Thus an array of # length 0 indicates that the config is valid according to the domain # specification. def validate_config config @domain . target_valid? config end", "del_tokens": "attr_reader :input_files attr_reader :output_files", "commit_type": "implement"}
{"commit_tokens": ["Remove", "fields", "helper", "from", "being", "tested", "."], "add_tokens": "fields -= [ :button , :multipart= , :submit , :fields ,", "del_tokens": "fields -= [ :button , :multipart= , :submit ,", "commit_type": "remove"}
{"commit_tokens": ["adding", "ability", "to", "test", "ccr", "agains", "schema", ".", "need", "to", "have", "schema", "available", "though", "as", "due", "to", "licensing", "it", "cannot", "be", "pushed", "to", "the", "repo"], "add_tokens": "#this will only run if there is an environment variable set to point to the #schema location. Cant be pushing the schema to github ya know . if ENV [ 'CCR_SCHEMA' ] xsd = Nokogiri :: XML :: Schema ( open ( ENV [ 'CCR_SCHEMA' ] ) ) assert_equal [ ] , xsd . validate ( doc ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "transaction", "in", "the", "case", "of", "adding", "a", "pending", "follow"], "add_tokens": "Amico . redis . multi do | transaction | transaction . zadd ( \"#{Amico.namespace}:#{Amico.pending_key}:#{scope}:#{to_id}\" , Time . now . to_i , from_id ) transaction . zadd ( \"#{Amico.namespace}:#{Amico.pending_with_key}:#{scope}:#{from_id}\" , Time . now . to_i , to_id ) end", "del_tokens": "Amico . redis . zadd ( \"#{Amico.namespace}:#{Amico.pending_key}:#{scope}:#{to_id}\" , Time . now . to_i , from_id ) Amico . redis . zadd ( \"#{Amico.namespace}:#{Amico.pending_with_key}:#{scope}:#{from_id}\" , Time . now . to_i , to_id )", "commit_type": "use"}
{"commit_tokens": ["Add", "new", "request_driver", "for", "action_dispatch", "subclassing", "action_controller", ".", "This", "gives", "cleaner", "support", "for", "rails3", "differences", "."], "add_tokens": "@request = ActionDispatchRequest . new ( request )", "del_tokens": "@request = ActionControllerRequest . new ( request )", "commit_type": "add"}
{"commit_tokens": ["Changed", "option", ":", "validation_context", "on", "property", "declaration", "to", ":", "validates", "=", ">", "[", "list", "of", "contexts", "]"], "add_tokens": "opts [ :context ] = property . options [ :validates ] if property . options . has_key? ( :validates )", "del_tokens": "opts [ :context ] = property . options [ :validation_context ] if property . options . has_key? ( :validation_context )", "commit_type": "change"}
{"commit_tokens": ["Add", "spec", "coverage", "for", "the", "onload", "changes"], "add_tokens": "high_chart ( @placeholder , @chart ) . should match ( / } \\( \\) / ) it \"should call any existing onload function\" do high_chart ( @placeholder , @chart ) . should match ( / onload = window.onload; / ) high_chart ( @placeholder , @chart ) . should match ( / if \\( typeof onload == \"function\" \\) \\s *onload \\( \\) / )", "del_tokens": "high_chart ( @placeholder , @chart ) . should match ( / \\} \\s * \\) \\s *; / ) it \"should generate generate ready function (no conflict with prototype)\" do high_chart ( @placeholder , @chart ) . should match ( / jQuery \\( function \\( \\) \\s * \\{ / )", "commit_type": "add"}
{"commit_tokens": ["Adds", "helpers", "for", "syntactic", "sugar", "for", "getting", "@options", "."], "add_tokens": "attr_reader :request attr_reader :options @options = @args . last . is_a? ( :: Hash ) ? pop : { } def opts ( key , default = nil ) if default . nil? return @options . fetch key else return @options . fetch ( key ) { default } end end", "del_tokens": "@opts = @args . last . is_a? ( :: Hash ) ? pop : { }", "commit_type": "add"}
{"commit_tokens": ["Add", "special", "class", "for", "menu", "levels", "."], "add_tokens": "content_tag ( :li , :id => page . title , :class => page_class ) do def page_class ( page ) if page . is_root? 'level1' elsif page . parent . is_root? 'level2' else 'level3' end end", "del_tokens": "content_tag ( :li , :id => page . title ) do", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "Patron", ".", "version", "method", "."], "add_tokens": "yaml = YAML . load_file ( cwd . expand_path + '../VERSION.yml' ) patch = ( yaml [ 'patch' ] || yaml [ :patch ] ) . to_i \"#{major}.#{minor}.#{patch}\"", "del_tokens": "yaml = YAML . load_file ( cwd . expand_path / '../VERSION.yml' ) \"#{major}.#{minor}\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "exception", "handling", "to", "all", "classes"], "add_tokens": "unless tripList . nil? if tripList . is_a? ( Array ) tripList . each do | trip | @tripArr << TripIt :: Trip . new ( @client , trip [ 'id' ] , params [ :include_objects ] ) end else @tripArr << TripIt :: Trip . new ( @client , tripList [ 'id' ] , params [ :include_objects ] ) unless progList . nil? if progList . is_a? ( Array ) progList . each do | prog | @progArr << TripIt :: PointsProgram . new ( prog ) end else @progArr << TripIt :: PointsProgram . new ( progList )", "del_tokens": "if tripList . is_a? ( Array ) tripList . each do | trip | @tripArr << TripIt :: Trip . new ( @client , trip [ 'id' ] , params [ :include_objects ] ) else @tripArr << TripIt :: Trip . new ( @client , tripList [ 'id' ] , params [ :include_objects ] ) if progList . is_a? ( Array ) progList . each do | prog | @progArr << TripIt :: PointsProgram . new ( prog ) else @progArr << TripIt :: PointsProgram . new ( progList )", "commit_type": "add"}
{"commit_tokens": ["Make", "Util", "a", "class", "and", "remove", "includes", "of", "the", "old", "module"], "add_tokens": "# Provides general utility methods class Util", "del_tokens": "# These methods don't belong to any specific class. They get included # in the #Context, #Socket and #Poller classes. module Util", "commit_type": "make"}
{"commit_tokens": ["fixed", "error", "caused", "when", "the", "response", "of", "the", "API", "call", "is", "an", "array"], "add_tokens": "200 => lambda { body = JSON . parse ( response . body ) body = { body : body } if body . is_a? ( Array ) body . merge! ( response . headers . slice ( * headers_to_keep ) ) } , fn = error_handler . detect { | k , _ | k === response . status }", "del_tokens": "200 => lambda { JSON . parse ( response . body ) . merge! ( response . headers . slice ( * headers_to_keep ) ) } , fn = error_handler . detect { | k , _ | k === response . status }", "commit_type": "fix"}
{"commit_tokens": ["Use", "original", "protocol", "when", "testing", "and", "harvesting", "image", "data"], "add_tokens": "def large_url ( protocol_relative = true ) if protocol_relative protocol_relative_url + 'media/?size=l' else url + 'media/?size=l' end def medium_url ( protocol_relative = true ) if protocol_relative protocol_relative_url + 'media/?size=m' else url + 'media/?size=m' end def thumbnail_url ( protocol_relative = true ) if protocol_relative protocol_relative_url + 'media/?size=t' else url + 'media/?size=t' end", "del_tokens": "def large_url protocol_relative_url + 'media/?size=l' def medium_url protocol_relative_url + 'media/?size=m' def thumbnail_url protocol_relative_url + 'media/?size=t'", "commit_type": "use"}
{"commit_tokens": ["Allow", "api", "version", "to", "be", "set", "when", "calling", "describe"], "add_tokens": "def describe ( version = nil ) @describe ||= describe! ( version ) def describe! ( version = nil ) soap . body = { :api_version => version } unless version . nil?", "del_tokens": "def describe @describe ||= describe! def describe!", "commit_type": "allow"}
{"commit_tokens": ["Make", "sure", "Responses", "in", "a", "collection", "include", "answers", "fix", "issue", "with", "data_submitted", "being", "returned", "as", "datesubmitted", "for", "Response", "List"], "add_tokens": "def datesubmitted = ( value ) self . date_submitted = value end end ; end", "del_tokens": "end ; end", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "lambdas", "and", "arrays", "of", "method", "symbols", "to", "success", "callback"], "add_tokens": "self . class . aasm_events [ name ] . execute_success_callback ( self ) if persist_successful", "del_tokens": "self . send ( self . class . aasm_events [ name ] . success ) if persist_successful && self . class . aasm_events [ name ] . success", "commit_type": "add"}
{"commit_tokens": ["Fix", "finding", "of", "assets", "without", "categories"], "add_tokens": "last_associations_var = \"categories#{category_associations.size - 1}\" end . with ( \"asset, CASE #{last_associations_var} WHEN [] THEN [null] ELSE #{last_associations_var} END AS #{last_associations_var}\" ) . unwind ( category : last_associations_var )", "del_tokens": "end . unwind ( category : \"categories#{category_associations.size - 1}\" )", "commit_type": "fix"}
{"commit_tokens": ["updated", "rspecs", "to", "match", "refactoring", "for", "navigation"], "add_tokens": "VERSION = \"0.0.8\"", "del_tokens": "VERSION = \"0.0.7\"", "commit_type": "update"}
{"commit_tokens": ["Added", ".", "sandi_meter", "ignore", "file"], "add_tokens": "read_ignore_file ( path ) unless @exclude_patterns Dir [ \"#{path}/**/*.rb\" ] . reject { | f | @exclude_patterns && f =~ / #{ @exclude_patterns } / } . each do | file | def read_ignore_file ( path ) ignore_file_path = File . join ( path , 'sandi_meter' , '.sandi_meter' ) if File . exists? ( ignore_file_path ) @exclude_patterns ||= File . read ( ignore_file_path ) . split ( \"\\n\" ) . join ( \"|\" ) end end", "del_tokens": "Dir [ \"#{path}/**/*.rb\" ] . each do | file |", "commit_type": "add"}
{"commit_tokens": ["Made", "some", "useful", "helpers", "protected", "instead", "of", "private"], "add_tokens": "# Protected helper method that returns the first n items, starting just after protected def first_item_after ( item , items_left , n ) # Protected helper method that returns the last n items, ending just before protected def last_item_before ( item , items_left , n )", "del_tokens": "# Private helper method that returns the first n items, starting just after private def first_item_after ( item , items_left , n ) # Private helper method that returns the last n items, ending just before private def last_item_before ( item , items_left , n )", "commit_type": "make"}
{"commit_tokens": ["Update", "README", ".", "md", "and", "example"], "add_tokens": "english_locale = translator . file ( \"#{dir}/en.yml\" ) japanese_locale = english_locale . to ( :ja ) german_locale = english_locale . to ( :de )", "del_tokens": "english_locale = :: YamlTranslator :: Locale . load_file ( \"#{dir}/en.yml\" ) japanese_locale = english_locale . translate ( translator , to : :ja ) german_locale = english_locale . translate ( translator , to : :de )", "commit_type": "update"}
{"commit_tokens": ["Fix", "method_missing", "to", "avoid", "issues", "with", "no", "arguments"], "add_tokens": "def method_missing ( method , args = { } , & block )", "del_tokens": "def method_missing ( method , args , & block ) puts \"calling method_missing #{method}\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "check", "for", "the", "old", "way", "of", "doing", "data_only"], "add_tokens": "@data_only = opts . is_a? ( TrueClass ) || ! ! opts [ :data_only ]", "del_tokens": "@data_only = ! ! opts [ :data_only ]", "commit_type": "add"}
{"commit_tokens": ["allow", "use", "of", "rdiscount", "if", "--", "rdiscount", "is", "set", "and", "gem", "is", "installed"], "add_tokens": "attr_accessor :source , :dest , :lsi , :pygments , :markdown_proc Jekyll . markdown_proc = Proc . new { | x | Maruku . new ( x ) . to_html }", "del_tokens": "attr_accessor :source , :dest , :lsi , :pygments", "commit_type": "allow"}
{"commit_tokens": ["Adding", "css", "classes", "to", "form"], "add_tokens": "def simple_ #{helper}(record_or_name_or_array, *args, &block) css_class = case record_or_name_or_array when String , Symbol then record_or_name_or_array . to_s when Array then dom_class ( record_or_name_or_array . last ) else dom_class ( record_or_name_or_array ) end options [ :html ] ||= { } options [ :html ] [ :class ] = \"simple_form \\#{css_class} \\#{options[:html][:class]}\" . strip #{helper}(record_or_name_or_array, *(args << options), &block)", "del_tokens": "def simple_ #{helper}(*args, &block) #{helper}(*(args << options), &block)", "commit_type": "add"}
{"commit_tokens": ["Fixing", "node", "field", "returning", "null"], "add_tokens": "model_class . find_by ( id : id )", "del_tokens": "result = model_class . where ( id : id ) result = result . accessible_by ( context . ability ) if context . ability result . first", "commit_type": "fix"}
{"commit_tokens": ["Add", "option", "type", "doc", "."], "add_tokens": "# @option opts [String] :host the service host (default +localhost+) # @option opts [String] :version the caTissue version identifier", "del_tokens": "# @option opts :host the service host (default +localhost+) # @option opts :version the caTissue version identifier", "commit_type": "add"}
{"commit_tokens": ["Removed", "--", "local", "from", "gem", "install", "line"], "add_tokens": "sudo_gem \"install pkg/#{GEM_NAME}-#{GEM_VERSION} --no-update-sources\"", "del_tokens": "sudo_gem \"install --local pkg/#{GEM_NAME}-#{GEM_VERSION} --no-update-sources\"", "commit_type": "remove"}
{"commit_tokens": ["Added", "lotus", "-", "router", ".", "rb", "as", "Bundler", "facility"], "add_tokens": "require 'coveralls' Coveralls . wear! require 'lotus-router'", "del_tokens": "require 'minitest/spec' require 'lotus/router'", "commit_type": "add"}
{"commit_tokens": ["Update", "simple", "callers", "of", "logical_cpus", "to", "cpu_total_cores"], "add_tokens": "hardware [ :cpu_total_cores ] = hardware [ :cpu_cores_per_socket ] . to_i * hardware [ :numvcpus ] . to_i", "del_tokens": "hardware [ :logical_cpus ] = hardware [ :cpu_cores_per_socket ] . to_i * hardware [ :numvcpus ] . to_i", "commit_type": "update"}
{"commit_tokens": ["Add", "some", "tests", "and", "a", "bit", "of", "cleanup", "."], "add_tokens": "module ShopifyVersion", "del_tokens": "module Shopify", "commit_type": "add"}
{"commit_tokens": ["changing", "gem", "name", "bump", "version"], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "change"}
{"commit_tokens": ["Make", "setting", "CBC", "log", "level", "optional"], "add_tokens": "# Older versions of COIN-OR do not support setting the log level via # the C interface in which case setParameter will not be defined Cbc . Cbc_setParameter ptr , 'logLevel' , '0' if Cbc . respond_to? ( :Cbc_setParameter )", "del_tokens": "Cbc . Cbc_setParameter ptr , 'logLevel' , '0'", "commit_type": "make"}
{"commit_tokens": ["Added", "CVE", "-", "2013", "-", "1855"], "add_tokens": "require \"codesake_dawn/knowledge_base\" require \"codesake_commons\"", "del_tokens": "require \"codesake_dawn/basic_check\"", "commit_type": "add"}
{"commit_tokens": ["Moved", "header", "intialization", "to", "Algebra", "::", "Project#header"], "add_tokens": "@relation , @attributes = relation , attributes . to_ary end def header @header ||= Header . new ( @relation . header . values_at ( * @attributes ) )", "del_tokens": "@relation = relation @header = Header . new ( @relation . header . values_at ( * attributes ) )", "commit_type": "move"}
{"commit_tokens": ["Update", "cbc", "-", "wrapper", "version"], "add_tokens": "VERSION = \"0.3.15\"", "del_tokens": "VERSION = \"0.3.14\"", "commit_type": "update"}
{"commit_tokens": ["Add", "comments", "to", "mailers", "."], "add_tokens": "module BarkestCore ## # This mailer is used for the generic contact form. class ContactForm < :: BarkestCore :: ApplicationMailerBase ## # Sends the message from the contact form. def contact ( msg ) @data = { msg : msg , client_ip : msg . remote_ip , gems : BarkestCore . gem_list ( Rails . application . class . parent_name . underscore , 'rails' , 'barkest*' ) , } mail subject : msg . full_subject , reply_to : msg . your_email end", "del_tokens": "class BarkestCore :: ContactForm < :: BarkestCore :: ApplicationMailerBase # Subject can be set in your I18n file at config/locales/en.yml # with the following lookup: # # en.barkest_core.contact_form.contact.subject # def contact ( msg ) @data = { msg : msg , client_ip : msg . remote_ip , gems : BarkestCore . gem_list ( Rails . application . class . parent_name . underscore , 'rails' , 'barkest*' ) , } mail subject : msg . full_subject , reply_to : msg . your_email", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "minor", "test", "bug", ".", "Patch", "by", "James", "Golick", "."], "add_tokens": "assert_redirected_to admin_blog_post_path ( Post . find ( :first , :order => \"id DESC\" ) . id )", "del_tokens": "assert_redirected_to admin_blog_post_path ( Post . count )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "readme", "examples", "on", "rubinius"], "add_tokens": ") . should match ( %r{ < ! DOCTYPE html PUBLIC < input ( type = \"checkbox\" | checked = \"checked\" ) { 2 } / > < / html > } m ) @tree . render ( ) . should match ( %r{ < ! DOCTYPE html > < input ( ( type = \"checkbox\" | checked ) ) { 2 } > < / html > } m ) ) . should match ( %r{ <html><body><div><p>foo<input( type=\"checkbox\"| checked){2}></div> }m )", "del_tokens": ") . should == <<EOF < ! DOCTYPE html PUBLIC < input type = \"checkbox\" checked = \"checked\" / > < / html > EOF @tree . render ( ) . should == <<EOF < ! DOCTYPE html > < input type = \"checkbox\" checked > < / html > EOF ) . should == '<html><body><div><p>foo<input type=\"checkbox\" checked></div>'", "commit_type": "fix"}
{"commit_tokens": ["Moved", "commands", "into", "separate", "files", ".", "Added", "folder", "for", "rfm", "module", "and", "changed", "gems", "to", "autoload", "to", "speed", "up", "startup", "time", "in", "rails", ".", "It", "now", "is", "only", "loads", "as", "needed", "."], "add_tokens": "path = File . expand_path ( File . dirname ( __FILE__ ) ) $: . unshift ( path ) unless $: . include? ( path ) module Rfm autoload :Error , \"rfm/error\" autoload :Factory , \"rfm/factory\" autoload :Result , \"rfm/result\" autoload :Utility , \"rfm/utility\" autoload :Database , 'rfm/commands/database' autoload :FieldControl , 'rfm/commands/field_control' autoload :Layout , 'rfm/commands/layout' autoload :Script , 'rfm/commands/script' autoload :Server , 'rfm/commands/server' end", "del_tokens": "$: << File . expand_path ( File . dirname ( __FILE__ ) ) require 'rfm_command' require 'rfm_util' require 'rfm_result' require 'rfm_factory' require 'rfm_error'", "commit_type": "move"}
{"commit_tokens": ["added", "local", "JVM", "connection", "feature"], "add_tokens": "# [:port] the port which will be listens to JMX connections. # if the port is 0, jmxrmi port is not published EOCMD if port != 0 cmd << <<-EOCMD . split ( \"\\n\" ) . join ( \" \" ) - J - Dcom . sun . management . jmxremote . port = #{port} - J - Dcom . sun . management . jmxremote . ssl = false - J - Dcom . sun . management . jmxremote . authenticate = #{!pwd_file.nil?} EOCMD if pwd_file and access_file cmd << \" -J-Dcom.sun.management.jmxremote.password.file=#{pwd_file}\" cmd << \" -J-Dcom.sun.management.jmxremote.access.file=#{access_file}\" end ps = \"ps a -w -o pid,command | grep -w jconsole\" ps << \" | grep port=#{port}\" if port != 0 ps << \" | grep -v grep | grep -v ruby | cut -c -5\" jconsole_pid = ` #{ ps } `", "del_tokens": "# [:port] the port which will be listens to JMX connections - J - Dcom . sun . management . jmxremote . port = #{port} - J - Dcom . sun . management . jmxremote . ssl = false - J - Dcom . sun . management . jmxremote . authenticate = #{!pwd_file.nil?} EOCMD if pwd_file and access_file cmd << \" -J-Dcom.sun.management.jmxremote.password.file=#{pwd_file}\" cmd << \" -J-Dcom.sun.management.jmxremote.access.file=#{access_file}\" jconsole_pid = ` ps a -w -o pid,command | grep -w jconsole | grep port= #{ port } | grep -v grep | grep -v ruby | cut -c -5 `", "commit_type": "add"}
{"commit_tokens": ["Added", "search_cfg", "nil", "check", "for", "single", "searcher", "search", "page"], "add_tokens": "@common_searches = [ ] if searcher_cfg and searcher_cfg . has_key? 'common_searches' @common_searches = searcher_cfg [ 'common_searches' ] end", "del_tokens": "@common_searches = searcher_cfg [ 'common_searches' ] || [ ]", "commit_type": "add"}
{"commit_tokens": ["Remove", "extraneous", "3rd", "argument", "to", "d_read"], "add_tokens": "buf << parent . d_read ( pos + buf . length , thisLen )", "del_tokens": "buf << parent . d_read ( pos + buf . length , thisLen , mark_dirty )", "commit_type": "remove"}
{"commit_tokens": ["Make", "use", "of", "Enumerator", "methods", "."], "add_tokens": "each_data_path ( path ) . find { | full_path | File . file? ( full_path ) } each_data_path ( path ) . find { | full_path | File . directory? ( full_path ) } each_data_path ( path ) . to_a def each_data_file ( path ) each_data_file ( path ) . to_a each_data_dir ( path ) . to_a", "del_tokens": "each_data_path ( path ) do | full_path | return full_path if File . file? ( full_path ) end return nil each_data_path ( path ) do | full_path | return full_path if File . directory? ( full_path ) end return nil enum_for ( :each_data_path , path ) . to_a def each_data_file ( path , & block ) enum_for ( :each_data_file , path ) . to_a enum_for ( :each_data_dir , path ) . to_a", "commit_type": "make"}
{"commit_tokens": ["Improve", "option", "parsing", "to", "support", "params"], "add_tokens": "options = { } parser = OptionParser . new do | opts | opts . banner = \"Usage: #{opts.program_name} [options] [scss-files]\" opts . separator '' opts . separator 'Common options:' opts . on_tail ( '-h' , '--help' , 'Show this message' ) do puts opts . help exit end opts . on_tail ( '-v' , '--version' , 'Show version' ) do puts \"#{opts.program_name} #{VERSION}\" exit end end parser . parse! ( args ) rescue OptionParser :: InvalidOption => ex puts ex , '' puts parser . help exit # Take the rest of the arguments as files/directories options [ :files ] = args run ( options ) private def run ( options ) files = SCSSLint . extract_files_from ( options [ :files ] ) runner = Runner . new begin runner . run files report_lints ( runner . lints ) exit 1 if runner . lints? rescue NoFilesError => ex puts ex . message exit - 1 end end", "del_tokens": "opts = OptionParser . new do | opts | opts . banner = 'Usage: scss-lint [scss-files]' end . parse! ( args ) files = SCSSLint . extract_files_from ( opts ) runner = Runner . new runner . run files report_lints ( runner . lints ) exit 1 if runner . lints? rescue NoFilesError => ex puts ex . message exit - 1", "commit_type": "improve"}
{"commit_tokens": ["fixed", "send_data", "bug", "(", "from", "eventmachine", "client", "/", "server", ")", ".", "fixed", "socket", "spec"], "add_tokens": "super ( @request_buffer . data )", "del_tokens": "super ( @request_buffer . write )", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "second", "example", "metadata", "file", "for", "unit", "tests"], "add_tokens": "describe IosDeployKit :: AppScreenshot do", "del_tokens": "describe IosDeployKit :: AppScreenshot , now : true do", "commit_type": "add"}
{"commit_tokens": ["Use", "not_to", "receive", "instead", "of", "should_not_receive"], "add_tokens": "expect ( checker1 ) . not_to receive ( :check ) . with ( filename , content )", "del_tokens": "checker1 . should_not_receive ( :check ) . with ( filename , content )", "commit_type": "use"}
{"commit_tokens": ["Add", "name", "to", "license", ".", "Version", "Bump", "."], "add_tokens": "VERSION = \"1.0.3\"", "del_tokens": "VERSION = \"1.0.2\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "txn_id", "parameter", "of", "status", "operation"], "add_tokens": "expect ( params ) . to eq '{\"opcode\":\"30\",' '\"txn_id\":\"1265\",' '\"merchant_site\":\"123\",' '\"order_id\":\"dsfkjdslkfjdlks\",' '\"sign\":\"07bbb1f2f41327e64f7f80b24c9a64ff887d8f0b4abe8cca04cc4b7e0eeaf08f\"}'", "del_tokens": "expect ( params ) . to eq '{\"opcode\":\"30\",\"merchant_site\":\"123\",\"order_id\":\"dsfkjdslkfjdlks\",\"sign\":\"30067d2400b2b012e31f9300ff2c8d609faf9400556a50a6bfb6ffca129991ac\"}'", "commit_type": "allow"}
{"commit_tokens": ["Allow", "wrapping", "objects", "that", "act", "as", "arrays", "but", "are", "not", "Enumerable"], "add_tokens": "if records . nil? elsif ( records . is_a? ( Enumerable ) ) return records . compact . map { | record | self . for_record ( record ) } elsif ( records . respond_to? ( :to_a ) ) return records . to_a . compact . map { | record | self . for_record ( record ) }", "del_tokens": "case records when nil when Enumerable return records . compact . collect { | record | self . for_record ( record ) }", "commit_type": "allow"}
{"commit_tokens": ["Added", "compatibility", "with", "Rails", "3"], "add_tokens": "require File . expand_path ( 'lib/common_view_helpers' , File . dirname ( __FILE__ ) )", "del_tokens": "require File . dirname ( __FILE__ ) + '/lib/common_view_helpers' ActionView :: Base . send ( :include , CommonViewHelpers :: ViewHelpers )", "commit_type": "add"}
{"commit_tokens": ["make", "search", "on", "subclasses", "of", "a", "single", "table", "inheritance", "model", "work"], "add_tokens": "# TODO: the automatic index initialization only works if # every model class has it's if self . superclass == ActiveRecord :: Base result = self . find ( id_array ) else # no direct subclass of Base --> STI # TODO: AR will filter out hits from other classes for us, but this # will lead to less results retrieved --> scoping of ferret query # to self.class is still needed. result = self . find ( :all , :conditions => [ \"id in (?)\" , id_array ] ) end logger . debug \"Result id_array: #{id_array.inspect}, result: #{result}\"", "del_tokens": "# TODO: this only works if every model class has it's result = self . find ( id_array ) logger . debug \"Result id_array: #{id_array.inspect}, result: #{result}\"", "commit_type": "make"}
{"commit_tokens": ["Added", "classify", "to", "string", "."], "add_tokens": "self . gsub ( / \\s / , \"_\" ) . split ( '_' ) . map ( & :capitalize ) . join ( ' ' ) def classify self . gsub ( / \\s / , \"_\" ) . titleize . gsub ( / \\W / , \"\" ) end", "del_tokens": "self . split ( '_' ) . map ( & :capitalize ) . join ( ' ' )", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "round", "-", "trip", "tests", "to", "complete", "test", "coverage", ";", "cleaned", "up", "code"], "add_tokens": "def to_string ( xml ) return nil unless xml formatter = REXML :: Formatters :: Pretty . new ( 2 ) formatter . compact = true out = StringIO . new formatter . write ( xml , out ) out . string end to_string ( actual_xml ) == to_string ( expected_xml ) expected_string = to_string ( to_element ( expected ) ) actual_string = to_string ( to_element ( actual ) ) || actual \"expected XML:\\n#{expected_string}\\n\\nbut was:\\n#{actual_string}\" end failure_message_when_negated do | actual | \"expected not to get XML:\\n\\t#{actual_xml}\"", "del_tokens": "else nil actual_xml . to_s == expected_xml . to_s expected_xml = to_element ( expected ) \"expected xml:\\n\\t#{expected_xml.to_s}\\nbut was:\\n\\t#{actual_xml.to_s}\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "unitialized", "instance", "var", "warnings"], "add_tokens": "@file = nil @file . close if @file", "del_tokens": "@file . close if @file . respond_to? :close", "commit_type": "fix"}
{"commit_tokens": ["Adds", "experimental", "jwt", "support", "."], "add_tokens": "@jwt_secret = _opts . delete ( :jwt_secret ) if @jwt_secret . nil? # Verify state in the response matches the one in the session if response . state != @state raise :: OmniAuth :: Strategies :: OAuth2 :: CallbackError . new ( nil , :csrf_detected ) end else if JWT . decode ( response . state , @jwt_secret ) [ 0 ] [ 'state' ] . nil? raise :: OmniAuth :: Strategies :: OAuth2 :: CallbackError . new ( nil , :csrf_detected ) end", "del_tokens": "# Verify state in the response matches the one in the session if response . state != @state raise :: OmniAuth :: Strategies :: OAuth2 :: CallbackError . new ( nil , :csrf_detected )", "commit_type": "add"}
{"commit_tokens": ["Adds", "image", "as", "additional", "attribute", "to", "shell", ".", "rb"], "add_tokens": "VERSION = '0.3.1' def n ( msg , title = '' , image = 'success' ) Notifier . notify ( msg , :title => title , :image => :\" #{ image } \" )", "del_tokens": "VERSION = '0.3.0' def n ( msg , title = '' ) :: Guard :: Notifier . notify ( msg , :title => title )", "commit_type": "add"}
{"commit_tokens": ["Updated", "SimpleInherited", "spec", "to", "use", "public", "API", "."], "add_tokens": "inputs", "del_tokens": "@filtered_input", "commit_type": "update"}
{"commit_tokens": ["Fix", "rake", "pg", "task", "to", "work", "as", "expected", "again", "."], "add_tokens": "spec . pattern = './spec/unit/*_spec.rb'", "del_tokens": "spec . pattern = './spec/*_spec.rb'", "commit_type": "fix"}
{"commit_tokens": ["moved", "compose", "file", "location", "from", "temp", "folder", "to", "same", "as", "original"], "add_tokens": "directory = File . dirname ( @compose_file ) temp_file = directory + '/tmp_docker-compose.yml' @system_runner . remove_entry_secure temp_file", "del_tokens": "directory = @system_runner . mktmpdir temp_file = directory + '/docker-compose.yml' @system_runner . remove_entry_secure directory", "commit_type": "move"}
{"commit_tokens": ["Add", "invoice", "line", "to", "proxy", "items", "when", "building", "an", "invoice", "line"], "add_tokens": "def append ( item ) alias :<< :append", "del_tokens": "def << ( item )", "commit_type": "add"}
{"commit_tokens": ["Adding", "eager_load_entry_mapping", "config", "option", "and", "defaulting", "to", "true", ".", "This", "will", "control", "whether", "the", "engine", "s", "initializers", "will", "eager", "load", "the", "application", "in", "an", "attempt", "to", "set", "the", "entry_mapping", "configuration", "so", "they", "can", "be", "used", "in", "ActiveSupport", "notifications", "."], "add_tokens": ":enable_preview_domain , :eager_load_entry_mapping @eager_load_entry_mapping = true", "del_tokens": ":enable_preview_domain", "commit_type": "add"}
{"commit_tokens": ["add", "google", "s", "recommended", "prev", "and", "next", "meta", "tags", "for", "pagination"], "add_tokens": "# @option default [String, Integer] :refresh (nil) meta refresh tag; # @option default [String] :prev (nil) add prev link tag; # @option default [String] :next (nil) add next link tag. # canonical, prev and next [ :canonical , :prev , :next ] . each do | tag_name | next unless href = meta_tags . delete ( tag_name ) result << tag ( :link , :rel => tag_name , :href => href ) end", "del_tokens": "# @option default [String, Integer] :refresh (nil) meta refresh tag. # canonical result << tag ( :link , :rel => :canonical , :href => meta_tags [ :canonical ] ) unless meta_tags [ :canonical ] . blank? meta_tags . delete ( :canonical )", "commit_type": "add"}
{"commit_tokens": ["added", "grit", "repo", "method", "head_commit_sha", "()"], "add_tokens": "local_sha = head_commit_sha ( ) def head_commit_sha ( ) head = @grit_repo . heads . find { | r | r . name == @branch } head && head . commit . id end", "del_tokens": "local_sha = @grit_repo . heads . find { | r | r . name == @branch } . commit . id", "commit_type": "add"}
{"commit_tokens": ["fixed", "variables", "names", ".", "Removed", "unuseful", "File", ".", "join"], "add_tokens": "wsdl . document = self . class . get_manifest if AkamaiApi . use_local_manifests && @local_manifest File . join AkamaiApi . wsdl_folder , @local_manifest @remote_manifest @remote_manifest = remote @local_manifest = local", "del_tokens": "wsdl . document = File . join self . class . get_manifest if AkamaiApi . use_local_manifests && @@local_manifest File . join AkamaiApi . wsdl_folder , @@local_manifest @@remote_manifest @@remote_manifest = remote @@local_manifest = local", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "proper", "Guide", "to", "the", "OSD", "."], "add_tokens": "# TODO: This is an ugly data structure. Refactor. channel : channel , schedule : whats_on? ( channel ) # TODO: Add test def times self [ :channels ] . first [ :schedule ] . collect { | s | s [ :time ] } end if block_given? yield show else show end", "del_tokens": "name : channel . display_name , schedule : whats_on? ( channel ) do | show | show . program_name . titleize end yield show", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "some", "important", "err", "messages", "would", "not", "print", "in", "red", "red"], "add_tokens": "if line_prefix =~ / ^err :: / color = \"31\" else color = 34 end log ( IMPORTANT , colorize ( message , color ) , line_prefix ) if ! message . strip . empty?", "del_tokens": "log ( IMPORTANT , colorize ( message , \"34\" ) , line_prefix )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "detect", "if", "speaker", "has", "music", "and", "add", "CLI", "command", "to", "play", "all"], "add_tokens": "speakers . each do | speaker | speaker . pause if speaker . has_music? end end # Play all speakers def play_all speakers . each do | speaker | speaker . play if speaker . has_music? def send_to_all_speakers ( action ) if self . groups . length > 0 self . groups . each { | group | group . send action } else self . speakers . each { | speaker | speaker . send action } end end", "del_tokens": "self . groups . each do | group | group . pause", "commit_type": "add"}
{"commit_tokens": ["add", "NaN", "+", "Infinity", "checking", "to", "Fixnum", "+", "Bignum"], "add_tokens": "str = self . to_s if str == \"NaN\" || str == \"Infinity\" || str == \"-Infinity\" raise :: FFI_Yajl :: EncodeError . new ( \"'#{str}' is an invalid number\" ) end if str == \"NaN\" || str == \"Infinity\" || str == \"-Infinity\" raise :: FFI_Yajl :: EncodeError . new ( \"'#{str}' is an invalid number\" ) end", "del_tokens": "str = self . to_s", "commit_type": "add"}
{"commit_tokens": ["added", "percentage", "format", "handling", "to", "formats", "example"], "add_tokens": "name \"percentage, scientific\" # scientific data rows data_opts . each do | opts | row { cell { data Osheet :: Format . new ( :scientific , opts ) . key } columns [ 1 .. - 1 ] . each do | col | cell { data col . meta [ :value ] format :scientific , opts } end } end", "del_tokens": "name \"percentage\"", "commit_type": "add"}
{"commit_tokens": ["move", "core_ext", "folder", "to", "mohawk"], "add_tokens": "require \"mohawk/core_ext/string\"", "del_tokens": "require_all \"lib/core_ext\"", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "rails", "3", "beta", "3"], "add_tokens": "$logger = Logger . new 'test/test.log' #STDOUT 'password' => 'password'", "del_tokens": "$logger = Logger . new STDOUT #'test/test.log' 'password' => ''", "commit_type": "fix"}
{"commit_tokens": ["update", "spec", "to", "assume", "no", "special", "api", "privilege"], "add_tokens": "let ( :api ) { double ( :api , username : \"alice\" , privilege : nil ) }", "del_tokens": "let ( :api ) { double ( :api , username : \"alice\" ) }", "commit_type": "update"}
{"commit_tokens": ["using", "Hpricot", "to", "parse", "receiving", "xml", "."], "add_tokens": "ValidationError = ' < ?x ml version = \"1.0\" encoding = \"UTF-8\" ? > < response > < status > < id > 4 < / id > < message > Validation Error < / message > < / status > < / response > ' ValidationSuccess = ' < ?x ml version = ”1.0 ” ?> < response > < requestId > F81D4FAE - 7 DEC - 11 D0 - A765 - 00 A0C91E6BF6 < / requestId > < confCode > 123 abc < / confCode > < status > < id > 1 < / id > < message > Success < / message > < / status > < / response > ' setup { FourInfo :: Request . any_instance . stubs ( :perform ) . returns ( ValidationSuccess ) @user . confirm_sms! }", "del_tokens": "setup { @user . confirm_sms! }", "commit_type": "use"}
{"commit_tokens": ["change", "min", "site_prism", "to", "2018", "vesrion"], "add_tokens": "VERSION = \"0.6.2\"", "del_tokens": "VERSION = \"0.6.1\"", "commit_type": "change"}
{"commit_tokens": ["Add", "method", "to_geometry", "for", "rgeo", "which", "it", "returns", "self"], "add_tokens": "end def to_geometry self end def to_geometry self end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", "implementation", "for", "the", "/", "sys", "/", "mounts", "/", "<mount_point", ">", "/", "tune", "endpoint", "."], "add_tokens": "class Mount < Response . new ( :type , :description , :config ) ; end # Tune a mount at the given path. # # @example # Vault.sys.mount_tune(\"pki\", max_lease_ttl: '87600h') #=> true # # @param [String] path # the path to write # @param [Hash] data # the data to write def mount_tune ( path , data = { } ) json = client . post ( \"/v1/sys/mounts/#{CGI.escape(path)}/tune\" , JSON . fast_generate ( data ) ) return true end", "del_tokens": "class Mount < Response . new ( :type , :description ) ; end", "commit_type": "add"}
{"commit_tokens": ["Create", "download", "--", "release", "option", "and", "validate", "that", "the", "key", "exists", "in", "the", "version", "hash"], "add_tokens": "c . option '--release STRING' , 'Used to specify an old or pre-release version of Xcode. Otherwise, latest GA release of Xcode is downloaded.' if options . release xcode_version = options . release else xcode_version = XcodeInstaller :: XcodeVersions :: LATEST end if XcodeInstaller :: XcodeVersions :: GUI . has_key? ( xcode_version ) xcode_url = XcodeInstaller :: XcodeVersions :: GUI [ xcode_version ] else puts \"No Xcode release with number #{xcode_version}. Use the 'list' command to see a list of known releases.\" exit end puts xcode_url", "del_tokens": "xcode_version = XcodeInstaller :: XcodeVersions :: LATEST xcode_url = XcodeInstaller :: XcodeVersions :: GUI [ xcode_version ]", "commit_type": "create"}
{"commit_tokens": ["use", "github", "authorizations", "api", "to", "request", "oauth", "token"], "add_tokens": "# @see http://developer.github.com/v3/oauth/#scopes def request_token ( username , password ) payload = { :scopes => [ 'repo' ] , :note => 'Socialcast Git eXtension' , :note_url => 'https://github.com/socialcast/socialcast-git-extensions' } . to_json response = RestClient :: Request . new ( :url => \"https://api.github.com/authorizations\" , :method => \"POST\" , :user => username , :password => password , :payload => payload , :headers => { :accept => :json , :content_type => :json } ) . execute data = JSON . parse response . body data [ 'token' ] rescue RestClient :: Exception => e data = JSON . parse e . http_body HighLine . say \"Failed to obtain OAuth token: #{data['message']}\" false end # @see http://developer.github.com/v3/pulls/ def create_pull_request ( token , branch , repo , body ) response = RestClient :: Request . new ( :url => \"https://api.github.com/repos/#{repo}/pulls\" , :method => \"POST\" , :payload => payload , :headers => { :accept => :json , :content_type => :json , 'Authorization' => \"bearer #{token}\" } ) . execute", "del_tokens": "def create_pull_request ( username , password , branch , repo , body ) response = RestClient :: Request . new ( :url => \"https://api.github.com/repos/#{repo}/pulls\" , :method => \"POST\" , :user => username , :password => password , :payload => payload , :headers => { :accept => :json , :content_type => :json } ) . execute", "commit_type": "use"}
{"commit_tokens": ["Changed", "the", "service", "@collections", "to", "be", "a", "hash", "where", "the", "key", "is", "the", "collection", "name", "and", "the", "value", "is", "the", "EntityType"], "add_tokens": "@collections = { } @collections = Hash [ collections . collect { | c | [ c [ \"Name\" ] , c [ \"EntityType\" ] ] } ]", "del_tokens": "@collections = [ ] @collections = collections . collect { | c | c [ \"Name\" ] }", "commit_type": "change"}
{"commit_tokens": ["Added", "new", "CLI", "method", "open", "which", "opens", "a", "profile", "page", "for", "a", "user", ".", "Added", "--", "force", "options", "to", "ignore", "since", "id", "in", "replies", "and", "timelines", ".", "Refactored", "output", "of", "tweets", "."], "add_tokens": "TINY = 1", "del_tokens": "TINY = 0", "commit_type": "add"}
{"commit_tokens": ["Removed", "need", "for", "downcase", "option", "just", "made", "case", "from", "mustaches", ".", "yml", "config", "cascade", "to", "output", ";", "Updated", "README", "to", "reflect", "this"], "add_tokens": "def compile self . mustache_build def mustache_build mustache_build_folder_structure ( mustaches_config ) def mustache_build_folder_structure mustaches_config , parent = \"\" dir = ( parent . eql? \"\" ) ? \"#{dir}\" : \"#{parent}/#{dir}\" mustache_build_folder_structure ( logic_file , dir ) mustache_template_build ( dir , template_file , logic_file ) mustache_template_build ( dir , template_file , template_class ) def mustache_template_build dir , template_file , logic_file output_file = logic_file #Output file should match the syntax of the mustaches config", "del_tokens": "def compile downcase = true self . mustache_build downcase def mustache_build downcase = true mustache_build_folder_structure ( mustaches_config , downcase ) def mustache_build_folder_structure mustaches_config , downcase , parent = \"\" dir = ( parent . eql? \"\" ) ? \"#{dir}\" : \"#{parent}/#{camelcase_to_underscore(dir)}\" mustache_build_folder_structure ( logic_file , downcase , dir ) mustache_template_build ( dir , downcase , template_file , logic_file ) mustache_template_build ( dir , downcase , template_file , template_class ) def mustache_template_build dir , downcase , template_file , logic_file output_file = ( downcase . eql? true ) ? logic_file : logic_class_name", "commit_type": "remove"}
{"commit_tokens": ["updated", "classes", "privilege", "package", "to", "allow", "definition", "of", "methods"], "add_tokens": "instances_of ( Class ) . allow nil , :inherited , :method_added , :singleton_method_added", "del_tokens": "instances_of ( Class ) . allow nil , :inherited", "commit_type": "update"}
{"commit_tokens": ["Added", "validation", "to", "check", "if", "given", "flag", "names", "are", "symbols"], "add_tokens": "raise ArgumentError , \"has_flags: flag keys should be positive integers, and #{flag_key} is not\" unless is_valid_flag_key ( flag_key ) raise ArgumentError , \"has_flags: flag names should be symbols, and #{flag_name} is not\" unless is_valid_flag_name ( flag_name ) def is_valid_flag_name ( flag_name ) flag_name . is_a? ( Symbol ) end", "del_tokens": "raise ArgumentError , \"has_flags: keys should be positive integers, and #{flag_key} is not\" unless is_valid_flag_key ( flag_key )", "commit_type": "add"}
{"commit_tokens": ["fix", "support", "for", "zmq", "sockets", "which", "don", "t", "support", "recv"], "add_tokens": "if connection . channel . is_a? ( ZMQChannel ) @zmq_connections << connection connection . connection_completed end", "del_tokens": "@zmq_connections << connection if connection . channel . is_a? ( ZMQChannel )", "commit_type": "fix"}
{"commit_tokens": ["Added", "info", "update", "and", "fetch", "methods", "to", "RRD", "::", "Base"], "add_tokens": "it \"should create a graph using simple DSL\" do xit \"should create a graph using advanced DSL\" do result = RRD . graph IMG_FILE , :title => \"Test\" , :width => 800 , :height => 250 do for_rrd_data \"cpu0\" , :cpu0 => :average , :from => RRD_FILE for_rrd_data \"mem\" , :memory => :average , :from => RRD_FILE , :start => \"-1d\" , :end => \"n\" , :shift => 3600 using_calculated_data \"half_mem\" , :calc => \"mem,2,/\" using_value \"mem_avg\" , :calc => \"mem,AVERAGE\" draw_line :data => \"mem\" , :color => \"#0000FF\" , :label => \"Memory\" , :width => 1 draw_area :data => \"cpu\" , :color => \"#00FF00\" , :label => \"CPU 0\" print_comment \"Information: \" print_value \"mem_avg\" , :format => \"%6.2lf %SB\" end result . should be_true File . should be_file ( IMG_FILE ) end", "del_tokens": "it \"should create a graph\" do", "commit_type": "add"}
{"commit_tokens": ["Adds", "nested", "route", "for", "resource"], "add_tokens": "\"\\n component :#{file_name} do\\n end\"", "del_tokens": "\"\\n component :#{file_name}\"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "param", "keys", "as", "Symbols", "."], "add_tokens": "# result = AwesomeSpawn.run('echo', :params => {:out => \"; rm /some/file\"}) # prevent command line injection. Keys as symbols are prefixed with `--`, # and `_` is replaced with `-`. # - `{:key => \"value\"}` generates `--key value` # - `{:key= => \"value\"}` generates `--key=value` # - `{:key_name => \"value\"}` generates `--key-name value` # - `{:key => nil}` generates `--key` [ sanitize_key ( k ) , sanitize_value ( v ) ] end end def sanitize_key ( key ) case key when Symbol then \"--#{key.to_s.tr(\"_\", \"-\")}\" else key end end def sanitize_value ( value ) case value when Array then value . collect { | i | i . to_s . shellescape } when NilClass then value else value . to_s . shellescape", "del_tokens": "# result = AwesomeSpawn.run('echo', :params => {\"--out\" => \"; rm /some/file\"}) # prevent command line injection. # - `{\"--key\" => nil}` generates `--key` v = case v when Array ; v . collect { | i | i . to_s . shellescape } when NilClass ; v else v . to_s . shellescape end [ k , v ]", "commit_type": "add"}
{"commit_tokens": ["fix", "no", "method", "error", "rescue"], "add_tokens": "rescue", "del_tokens": "rescue NoMethodError", "commit_type": "fix"}
{"commit_tokens": ["Add", "vendor", "to", "included", "gem", "files"], "add_tokens": "VERSION = '0.0.3'", "del_tokens": "VERSION = '0.0.2'", "commit_type": "add"}
{"commit_tokens": ["Move", "data", "folder", "load", "as", "the", "responsibility", "of", "preprocessing"], "add_tokens": "def up return unless NanocConrefFS :: Variables . data_files . nil? data_files = NanocConrefFS :: Datafiles . collect_data ( data_dir_name ) NanocConrefFS :: Variables . data_files = data_files NanocConrefFS :: Variables . variables = { } return unless NanocConrefFS :: Variables . variables [ rep ] . nil? data_files = NanocConrefFS :: Variables . data_files data = NanocConrefFS :: Datafiles . process ( data_files , config , rep ) NanocConrefFS :: Variables . variables [ rep ] = { 'site' => { 'config' => config , 'data' => data } }", "del_tokens": "def load_objects ( dir_name , kind , klass ) if NanocConrefFS :: Variables . data_files . nil? data_files = NanocConrefFS :: Datafiles . collect_data ( data_dir_name ) NanocConrefFS :: Variables . data_files = data_files NanocConrefFS :: Variables . variables = { } end super if NanocConrefFS :: Variables . variables [ rep ] . nil? data_files = NanocConrefFS :: Variables . data_files data = NanocConrefFS :: Datafiles . process ( data_files , config , rep ) NanocConrefFS :: Variables . variables [ rep ] = { 'site' => { 'config' => config , 'data' => data } } end", "commit_type": "move"}
{"commit_tokens": ["allow", "double", "single", "-", "quotes", "in", "single", "-", "quote", "string"], "add_tokens": "SINGLE_LINE_COMMENT_REGEX = / \\A \\s *\"(.*)$ / chunk = get_new_chunk tokenize_chunk ( chunk ) elsif single_line_comment = chunk [ SINGLE_LINE_COMMENT_REGEX ] && ( @tokens . last . nil? || @tokens . last [ 0 ] == :NEWLINE ) comment = chunk [ SINGLE_LINE_COMMENT_REGEX ] elsif inline_comment = chunk [ / \\A \\s *\"[^\"]*?$ / ] @i += inline_comment . size # inline comment, don't consume newline character elsif string_double = chunk [ / \\A \"(.*?)\" / , 1 ] @tokens << [ :STRING_D , string_double ] @i += string_double . size + 2 elsif string_single = chunk [ / \\A '(([^']|'')*)' / , 1 ] @tokens << [ :STRING_S , string_single ] @i += string_single . size + 2", "del_tokens": "COMMENT_REGEX = / \\A \\s *\".*$ / @inline_comment_allowed = false tokenize_chunk ( get_new_chunk ) break @inline_comment_allowed = true elsif inline_comment = chunk [ COMMENT_REGEX ] && @inline_comment_allowed comment = chunk [ COMMENT_REGEX ] @i += comment . size # inline comment, don't consume newline character elsif single_line_comment = chunk [ COMMENT_REGEX ] && ( @tokens . last . nil? || @tokens . last [ 0 ] == :NEWLINE ) comment = chunk [ COMMENT_REGEX ] elsif string = chunk [ / \\A (\"|')(.*?)( \\1 ) / , 2 ] type = ( $1 == '\"' ? :D : :S ) @tokens << [ :\" STRING_ #{ type } \" , string ] @i += string . size + 2", "commit_type": "allow"}
{"commit_tokens": ["removed", "activesupport", "&", "i18n", "dependencies"], "add_tokens": "full_name << camelize ( namespace ) + '.' unless namespace . nil? full_name << camelize ( method_name ) # camelize('get_profiles') def camelize ( name ) words = name . split ( '_' ) first_word = words . shift words . map ( & :capitalize ) . unshift ( first_word ) . join", "del_tokens": "full_name << convert ( namespace ) + '.' unless namespace . nil? full_name << convert ( method_name ) # convert('get_profiles') def convert ( name ) name . camelize ( :lower )", "commit_type": "remove"}
{"commit_tokens": ["Updated", "migration", "runner", "example", "to", "show", "the", "new", "syntax", "."], "add_tokens": "# create_table :people do # column :id, Integer, :serial => true # column :name, String, :size => 50 # column :age, Integer # drop_table :people", "del_tokens": "# execute \"CREATE TABLE people (id serial, name varchar)\" # execute \"DROP TABLE people\"", "commit_type": "update"}
{"commit_tokens": ["updated", "doc", "and", "fixed", "minor", "issues"], "add_tokens": "load_apis", "del_tokens": "load_apis", "commit_type": "update"}
{"commit_tokens": ["Adding", "ohai", "time", "attribute", "adding", "domain", "attribute"], "add_tokens": "end # Domain is everything after the first dot fqdn =~ / .+? \\. (.*) / domain $1", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["add", "faraday", "and", "create", "ToolProxyRegistrationService", "methods"], "add_tokens": "def initialize ( registration_request ) @registration_request = registration_request def tool_consumer_profile return @tool_consumer_profile if @tool_consumer_profile connection = Faraday . new response = connection . get ( @registration_request . tc_profile_url ) @tool_consumer_profile = IMS :: LTI :: Models :: ToolConsumerProfile . new . from_json ( response . body ) def service_profiles tool_consumer_profile . services_offered . map ( & :profile ) end def register_tool_proxy ( tool_proxy ) service = tool_consumer_profile . services_offered . find { | s | s . formats . include? ( 'application/vnd.ims.lti.v2.toolproxy+json' ) && s . actions . include? ( 'POST' ) } conn = Faraday . new do | conn | conn . request :oauth , consumer_key : @tool_consumer_profile . reg_key , consumer_secret : @tool_consumer_profile . reg_password conn . adapter :net_http end response = conn . post do | req | req . url service . endpoint req . headers [ 'Content-Type' ] = 'application/json' req . body = tool_proxy . to_json end if response . status == 201 IMS :: LTI :: Models :: ToolProxy . new . from_json ( tool_proxy . to_json ) . from_json ( response . body ) end", "del_tokens": "def initialize ( registration_reqeust ) @tool_consumer_profile = tool_consumer_profile def register_tool_proxy ( tool_proxy , reg_key , reg_password ) def services ( )", "commit_type": "add"}
{"commit_tokens": ["add", "switch", "statis", "on", "post", "fix", "destroy", "all", "deleted", "posts", "action"], "add_tokens": "cookies [ :lato_blog__current_language ] = BLOG_LANGUAGES_IDENTIFIER . first if BLOG_LANGUAGES_IDENTIFIER . include? language", "del_tokens": "languages = blog__get_languages_identifier cookies [ :lato_blog__current_language ] = ( languages && languages . length > 0 ) ? languages . first : nil languages = blog__get_languages_identifier if languages . include? language", "commit_type": "add"}
{"commit_tokens": ["Use", "modifier", "form", "of", "if", "statement"], "add_tokens": "return instance . to_whodunnit if instance . respond_to? ( :to_whodunnit )", "del_tokens": "if instance . respond_to? ( :to_whodunnit ) return instance . to_whodunnit end", "commit_type": "use"}
{"commit_tokens": ["improved", "code", "(", "syntax", "only", ")", "according", "to", "code", "conventions"], "add_tokens": "it { expect ( subject . instance_variable_get ( :@message ) ) . to eql ( message ) } before do", "del_tokens": "it { expect ( subject . instance_variable_get ( :@message ) ) . to eql ( message ) } #mock before do", "commit_type": "improve"}
{"commit_tokens": ["Allow", "svgs", "to", "use", "dimensions"], "add_tokens": "def svg_icon ( file , options = { } ) name = icon_name ( file ) %Q{<svg class=\"#{config[:base_class]} #{name} #{options[:class] || \"\"}\" #{dimensions(@files[file])}><use xlink:href=\"##{name}\"/>#{title(options)}#{desc(options)}</svg>} . html_safe", "del_tokens": "def svg_icon ( name , options = { } ) name = icon_name ( name ) %Q{<svg class=\"#{config[:base_class]} #{name} #{options[:class] || \"\"}\"><use xlink:href=\"##{name}\"/>#{title(options)}#{desc(options)}</svg>} . html_safe", "commit_type": "allow"}
{"commit_tokens": ["adding", "ability", "to", "get", "all", "cells", "in", "a", "column", "by", "using", "a", "column", "reference", "(", "eg", ".", "Sheet1specsA", ")"], "add_tokens": "@ref == area . getFirstCell . formatAsString rescue false", "del_tokens": "@ref == area . getFirstCell . formatAsString", "commit_type": "add"}
{"commit_tokens": ["Move", "buffer", "style", "default", "values", "to", "a", "new", "constant", "."], "add_tokens": "# The default for the options according to GEOS are as found in # Geos::Constants::BUFFER_PARAMS_DEFAULTS. options = Constants :: BUFFER_PARAM_DEFAULTS . merge ( options )", "del_tokens": "# Options: # # * :quad_segs - defaults to 8. # * :endcap - defaults :round. # * :join - defaults to :round. # * :mitre_limit - defaults to 5.0. options = { :quad_segs => 8 , :endcap => :round , :join => :round , :mitre_limit => 5.0 } . merge ( options )", "commit_type": "move"}
{"commit_tokens": ["updated", "rspec", "syntax", "for", "node_helper_spec"], "add_tokens": "assigns [ :current_node ] == @page assigns [ :controller ] = @controller assigns [ :controller ] = @controller assigns [ :current_node ] = @page assigns [ :current_node ] = @page assigns [ :current_node ] = @page assigns [ :current_node ] = @page assigns [ :current_node ] = @page assigns [ :current_node ] = @page assigns [ :current_node ] = @page", "del_tokens": "@current_node . should == @page @current_node = @page @current_node = @page @current_node = @page @current_node = @page @current_node = @page @current_node = @page @current_node = @page", "commit_type": "update"}
{"commit_tokens": ["Use", "shallow", "fetch", "when", "retrieving", "tags"], "add_tokens": "res += ` #{ ssh_cmd } git fetch --depth 1 --tags 2>&1 `", "del_tokens": "res += ` #{ ssh_cmd } git fetch --tags 2>&1 `", "commit_type": "use"}
{"commit_tokens": ["Make", "session", "return", "an", "empty", "hash", "when", "Session", "support", "is", "turned", "off"], "add_tokens": "@request . env [ 'rack.session' ] || { }", "del_tokens": "@request . env [ 'rack.session' ]", "commit_type": "make"}
{"commit_tokens": ["Use", "Hash#key?", "instead", "of", "Hash#has_key?"], "add_tokens": "return @reader = format if READERS . key? ( format . to_s ) return @writer = format if WRITERS . key? ( format . to_s )", "del_tokens": "return @reader = format if READERS . has_key? ( format . to_s ) return @writer = format if WRITERS . has_key? ( format . to_s )", "commit_type": "use"}
{"commit_tokens": ["Add", "ancestry", "to", "pages", "."], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20120915124116 ) do t . string \"ancestry\" add_index \"wafflemix_pages\" , [ \"ancestry\" ] , :name => \"index_wafflemix_pages_on_ancestry\"", "del_tokens": "ActiveRecord :: Schema . define ( :version => 20120901151704 ) do", "commit_type": "add"}
{"commit_tokens": ["Update", "ChangeLog", "and", "bump", "version", "."], "add_tokens": "VERSION = '1.2.11'", "del_tokens": "VERSION = '1.2.10.1'", "commit_type": "update"}
{"commit_tokens": ["Added", "inter", "-", "process", "locking", "."], "add_tokens": "module Utilities class SyncedPStore < :: PStore def initialize ( file ) super ( file , false ) end def transaction ( read_only = false , & block ) @flock ||= path + '.lock' File . open ( @flock , File :: RDWR | File :: CREAT ) do super end end end end Utilities :: SyncedPStore . new ( File . join ( Dir . tmpdir , instance_key . to_s ) )", "del_tokens": ":: PStore . new ( File . join ( Dir . tmpdir , instance_key . to_s ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "exit", "code", "tests", "."], "add_tokens": "command . execute ( \"echo 'nooo'; exit 1\" ) do | cmd | \"[\\e[32m#{uuid}\\e[0m] Running \\e[33;1mecho 'nooo'; exit 1\\e[0m\\n\" , \"[\\e[32m#{uuid}\\e[0m] \\t\\e[32mnooo\\e[0m\\n\" , command . execute! ( \"echo 'nooo'; exit 1\" ) } . to raise_error ( TTY :: Command :: FailedError , / Invoking `echo 'nooo'; exit 1` failed with status / )", "del_tokens": "command . execute ( :exit , '1' ) do | cmd | \"[\\e[32m#{uuid}\\e[0m] Running \\e[33;1mexit 1\\e[0m\\n\" , command . execute! ( :exit , '1' ) } . to raise_error ( TTY :: Command :: FailedError , / Invoking `exit 1` failed with status / )", "commit_type": "fix"}
{"commit_tokens": ["Move", "the", "remaining", "queries", "that", "are", "used", "in", "normal", "operation", "to", "prepared", "statements", "."], "add_tokens": "check = Que . execute ( :check_job , [ row [ 'priority' ] , row [ 'run_at' ] , row [ 'job_id' ] ] ) message = \"#{error.message}\\n#{error.backtrace.join(\"\\n\")}\" Que . execute :set_error , [ count , run_at , message , row [ 'priority' ] , row [ 'run_at' ] , row [ 'job_id' ] ] Que . execute :destroy_job , [ @attrs [ 'priority' ] , @attrs [ 'run_at' ] , @attrs [ 'job_id' ] ]", "del_tokens": "check = Que . execute \"SELECT 1 AS one FROM que_jobs WHERE priority = $1 AND run_at = $2 AND job_id = $3;\" , [ row [ 'priority' ] , row [ 'run_at' ] , row [ 'job_id' ] ] message = \"#{error.message}\\n#{error.backtrace.join(\"\\n\")}\" Que . execute \"UPDATE que_jobs SET error_count = $1, last_error = $2, run_at = $3 WHERE priority = $4 AND run_at = $5 AND job_id = $6;\" , [ count , message , run_at , row [ 'priority' ] , row [ 'run_at' ] , row [ 'job_id' ] ] Que . execute \"DELETE FROM que_jobs WHERE priority = $1 AND run_at = $2 AND job_id = $3\" , [ @attrs [ 'priority' ] , @attrs [ 'run_at' ] , @attrs [ 'job_id' ] ]", "commit_type": "move"}
{"commit_tokens": ["make", "the", "logger", "configurable", "defaulting", "to", "Rails", "logger", "if", "none", "is", "set", "."], "add_tokens": "attr_writer :logger # return a logger - if #logger= has set one, then that; if Rails is defined, use its logger; # otherwise, a dummy that logs to /dev/null def logger @logger ||= begin if Object . const_defined? ( 'Rails' ) Rails . logger else require 'logger' :: Logger . new ( File . open ( '/dev/null' , File :: WRONLY ) ) end end end # # you may also pass in a Logger on the :logger key. @logger = attrs [ :logger ] || attrs [ 'logger' ] logger . error $! , $! . backtrace logger . info \"Verfication failed: time outside valid range: #{t}\"", "del_tokens": "Rails . logger . error $! , $! . backtrace if defined? ( Rails ) Rails . logger . info \"Verfication failed: time outside valid range: #{t}\" if defined? ( Rails )", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "configure", "custom", "parameters", "classes"], "add_tokens": "class << self include Configurable configurable_attr :default_processing_method configurable_attr :default_processing_options , { } configurable_attr :default_mime_type configurable_attr :default_encoding , { } end attr_accessor :uid , :processing_method , :processing_options , :mime_type , :encoding %w( processing_method processing_options mime_type encoding ) . each do | attribute | instance_variable_set \"@#{attribute}\" , ( attributes [ attribute . to_sym ] || self . class . send ( \"default_#{attribute}\" ) ) @uid = attributes [ :uid ]", "del_tokens": "attr_accessor :uid , :processing_method , :mime_type attr_writer :processing_options , :encoding %w( uid processing_method processing_options mime_type encoding ) . each do | attribute | instance_variable_set ( \"@#{attribute}\" , attributes [ attribute . to_sym ] ) def processing_options @processing_options ||= { } end def encoding @encoding ||= { } end", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "key", "formatting", "and", "wrote", "some", "tests"], "add_tokens": "VERSION = \"0.4.1\" . freeze", "del_tokens": "VERSION = \"0.4.0\" . freeze", "commit_type": "fix"}
{"commit_tokens": ["updated", "README", "and", "removed", "obsolete", "rake", "tasks"], "add_tokens": "VERSION = \"0.1.6\"", "del_tokens": "VERSION = \"0.1.5\"", "commit_type": "update"}
{"commit_tokens": ["Allow", "for", "a", "title", "in", "the", "logging", "output", "."], "add_tokens": "title = event . payload [ :title ] \"#{color(\"Profiler Output: #{title}\", YELLOW, true)}\\n#{report}\"", "del_tokens": "\"#{color(\"Profiler Output\", YELLOW, true)}\\n#{report}\"", "commit_type": "allow"}
{"commit_tokens": ["Use", "block", "form", "of", "Dir", ".", "chdir"], "add_tokens": "VERSION = '1.3.7'", "del_tokens": "VERSION = '1.3.6'", "commit_type": "use"}
{"commit_tokens": ["updated", "the", "results", "folder", "structure"], "add_tokens": "index_file = \"#{@html_path}/results.html\" File . open ( \"#{@html_path}/files/table.html\" , 'w+' ) { | file | file . write ( erb_table . result ( binding ) ) } File . open ( \"#{@html_path}/files/table.html\" , 'a' ) { | file | file . write ( erb . result ( binding ) ) } plot_statistics = Plot . new ( \"files/json/#{filename}_statistics.json\" , index_file = \"#{html_path}/results.html\" table_file = \"#{html_path}/files/table.html\" FileUtils . mkdir ( \"#{html_path}/files/json/\" ) FileUtils . mv Dir . glob ( \"#{html_path}/#{filename}_*.json\" ) , \"#{html_path}/files/json/\" #} if no_mafft >= ( no_queries - no_evidence )", "del_tokens": "index_file = \"#{@html_path}/index.html\" File . open ( \"#{@html_path}/table.html\" , 'w+' ) { | file | file . write ( erb_table . result ( binding ) ) } File . open ( \"#{@html_path}/table.html\" , 'a' ) { | file | file . write ( erb . result ( binding ) ) } plot_statistics = Plot . new ( \"#{filename}_statistics.json\" , index_file = \"#{html_path}/index.html\" table_file = \"#{html_path}/table.html\" #} if no_mafft >= ( no_queries - no_evidence )", "commit_type": "update"}
{"commit_tokens": ["Fixed", "a", "minor", "validation", "mesage", "issue"], "add_tokens": "error_strings = [ 'Improper image header' , 'no decode delegate for this image format' , ] if e . to_s =~ / #{ error_strings . join ( '|' ) } / if @invalid_image elsif self . class . require_image && ! has_image? errors . add field_name , self . class . missing_image_message", "del_tokens": "if e . to_s =~ / no decode delegate for this image format / if self . class . require_image && ! has_image? errors . add field_name , self . class . missing_image_message elsif @invalid_image", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "to", "only", "glob", "valid", "project", "files", "/", "directories", "."], "add_tokens": "def glob ( pattern ) within do Dir . glob ( pattern ) do | path | if ( @project_files . include? ( path ) || File . directory? ( path ) ) yield path end end end", "del_tokens": "def glob ( pattern , & block ) within { Dir . glob ( pattern , & block ) }", "commit_type": "make"}
{"commit_tokens": ["making", "Net", "::", "DataSet#plot", "work", "if", "no", ":", "time", "named", "argument", "is", "supplied"], "add_tokens": "delegate :place , :transition , :element , def Net * args , & block", "del_tokens": "delegate :place , :transition , :element , def Net * ordered , ** named , & block", "commit_type": "make"}
{"commit_tokens": ["Allowing", "arbitrary", "column", "types", "to", "be", "defined", "."], "add_tokens": "def method_missing ( type , * args ) name , rest = args define_column ( :type => type , :name => name )", "del_tokens": "def varchar ( name ) define_column ( :type => :varchar , :name => name )", "commit_type": "allow"}
{"commit_tokens": ["Make", "cart#update", "check", "for", "params", "[", ":", "attributes", "]", "[", ":", "quantity", "]", "AND", "params", "[", ":", "quantity", "]"], "add_tokens": "quantity = params [ :attributes ] [ :quantity ] . to_i || params [ :quantity ] . to_i", "del_tokens": "quantity = params [ :attributes ] [ :quantity ] . to_i", "commit_type": "make"}
{"commit_tokens": ["added", "Rufus", "::", "Tokyo", ".", "lib", "method", "(", "one", "lib", "for", "the", "whole", "interpreter", "for", "now", ":", "(", ")"], "add_tokens": "# # find Tokyo Cabinet lib paths = Array ( ENV [ 'TOKYO_CABINET_LIB' ] || %w{ / opt /local / lib / libtokyocabinet . dylib / usr /local / lib / libtokyocabinet . dylib / usr /local / lib / libtokyocabinet . so } ) paths . each do | path | if File . exist? ( path ) ffi_lib ( path ) @lib = path break end end # # Returns the path to the Tokyo Cabinet dynamic library currently in use # def self . lib Rufus :: Tokyo :: Func . instance_variable_get ( :@lib ) end", "del_tokens": "#ffi_lib '../tokyo-cabinet/libtokyocabinet.dylib' ffi_lib ENV [ 'TOKYO_CABINET_LIB' ] || '/usr/local/lib/libtokyocabinet.so'", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "feature", "to", "ModifiedSupportSpecs", "strategy", "and", "fix", "the", ":", "bug", ":"], "add_tokens": "Crystalball :: Predictor . new ( execution_map , repo , from : execution_map . commit ) do | predictor | let ( :strategies ) { [ ] } # to be overridden let ( :execution_map ) { Crystalball :: MapStorage :: YAMLStorage . load ( Pathname . new ( root . join ( 'execution_map.yml' ) ) ) }", "del_tokens": "Crystalball :: Predictor . new ( map , repo , from : map . commit ) do | predictor | let ( :strategies ) { [ ] } # to be overriden let ( :map ) { Crystalball :: MapStorage :: YAMLStorage . load ( Pathname . new ( root . join ( 'execution_map.yml' ) ) ) }", "commit_type": "add"}
{"commit_tokens": ["Update", "MetaEnum", "::", "Type#", "[]", "docs"], "add_tokens": "# Since symbols are used from code, it is considered an error if the key is # When key can be converted to an integer by value_normalizer, then it is # considered the value of the Element to return. Retrieving by value is # be considered fatal. In this case it returns a MissingElement is with value # as the key. This allows a Type to only specify the values it needs while", "del_tokens": "# Since symbols are used from number, it is considered an error if the key is # When key can be converted to an integer by Integer(), then it is # considered the number of the Element to return. Retrieving by number is # be considered fatal. In this case it returns a MissingElement is with number # as the key. This allows a Type to only specify the values is needs while", "commit_type": "update"}
{"commit_tokens": ["add", "concurrency", "http", "requests", "spec"], "add_tokens": "# bind localhost seems have some problem on MACOS, it connect two fd and never release them(even call close). # so just don't close them to avoid duplication fd. after { #client.close }", "del_tokens": "client . close client . close", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "run", "tests", "by", "line", "number"], "add_tokens": "@clashfile = read_config # If tests are limited, only show specified tests @options [ :only ] = expand_list_of_numbers ( @options [ :only ] ) tests = default_array ( @clashfile ) . map do | test | read_test_line_numbers ( path )", "del_tokens": "# If tests are limited, only run specified tests tests = read_config tests = default_array ( tests ) . map do | test |", "commit_type": "add"}
{"commit_tokens": ["Allow", "people", "to", "inject", "a", "logger", "of", "their", "choice", "."], "add_tokens": "@logger = $stdout class << self attr_accessor :logger end def log ( text , logger = self . class . logger ) logger . respond_to? ( :info ) ? logger . info ( text ) : logger . puts ( text )", "del_tokens": "def log ( text ) puts text", "commit_type": "allow"}
{"commit_tokens": ["Allows", "production", "certificates", "to", "be", "specified"], "add_tokens": "opts . on ( '-s' , '--use_tls' , 'require a secure connection?' ) do | v |", "del_tokens": "opts . on ( '-u' , '--use_tls' , 'access using test creds' ) do | v |", "commit_type": "allow"}
{"commit_tokens": ["Removing", "dead", "code", "from", "UT", "and", "implementing", "a", "few", "skipped", "UT"], "add_tokens": "let ( :blob_name2 ) { \"blobname2\" } subject . create_page_blob container_name , blob_name2 , length end describe 'when the options hash is used' do it 'if none match is specified' do content = \"\" 512 . times . each { | i | content << \"@\" } blob = subject . create_blob_pages container_name , blob_name2 , 0 , 511 , content assert_raises ( Azure :: Core :: Http :: HTTPError ) do subject . create_blob_pages container_name , blob_name2 , 1024 , 1535 , content , { :if_none_match => blob . properties . etag } it 'if match is specified' do content = \"\" 512 . times . each { | i | content << \"@\" } blob = subject . create_blob_pages container_name , blob_name , 0 , 511 , content subject . create_blob_pages container_name , blob_name , 1024 , 1535 , content , { :if_match => blob . properties . etag } end", "del_tokens": "describe 'when the options hash is used' do it '' do skip \"TODO\" # describe \"when only start_range is specified\" do # it 'clears data from the specified offset to the end of the blob' do # subject.clear_blob_pages container_name, blob_name, 512 # ranges = subject.list_page_blob_ranges container_name, blob_name, 0, 2560 # ranges.length.must_equal 1 # ranges[0][0].must_equal 0 # ranges[0][1].must_equal 511 # end # end # describe \"when only end_range is specified\" do # it 'clears data from the start of the blog to the specified offset' do # subject.clear_blob_pages container_name, blob_name, nil, 2047 # ranges = subject.list_page_blob_ranges container_name, blob_name, 0, 2560 # ranges.length.must_equal 1 # ranges[0][0].must_equal 2048 # ranges[0][1].must_equal 2559 # end # end # describe \"when neither start_range or end_range is specified\" do # it 'clears the entire blob' do # subject.clear_blob_pages container_name, blob_name # ranges = subject.list_page_blob_ranges container_name, blob_name, 0, 2560 # ranges.length.must_equal 0 # end # end", "commit_type": "remove"}
{"commit_tokens": ["added", "support", "for", "new", "JWT", "auth", "method"], "add_tokens": "attr_reader :access_token , :refresh_token , :client_id , :client_secret , :identifier , :as_user_id def initialize ( access_token = ENV [ 'BOX_DEVELOPER_TOKEN' ] , refresh_token : nil , client_id : ENV [ 'BOX_CLIENT_ID' ] , client_secret : ENV [ 'BOX_CLIENT_SECRET' ] , @client_id = client_id @client_secret = client_secret new_tokens = Boxr :: refresh_tokens ( @refresh_token , client_id : client_id , client_secret : client_secret )", "del_tokens": "attr_reader :access_token , :refresh_token , :box_client_id , :box_client_secret , :identifier , :as_user_id def initialize ( access_token = ENV [ 'BOX_DEVELOPER_TOKEN' ] , refresh_token : nil , box_client_id : ENV [ 'BOX_CLIENT_ID' ] , box_client_secret : ENV [ 'BOX_CLIENT_SECRET' ] , @box_client_id = box_client_id @box_client_secret = box_client_secret new_tokens = Boxr :: refresh_tokens ( @refresh_token , box_client_id : box_client_id , box_client_secret : box_client_secret )", "commit_type": "add"}
{"commit_tokens": ["added", "unit", "tests", "for", "bin", "/", "howitzer"], "add_tokens": "#RSpec.configure do |config| #end RSpec . configure do | configuration | configuration . mock_with :rspec do | configuration | configuration . syntax = :expect end", "del_tokens": "RSpec . configure do | config |", "commit_type": "add"}
{"commit_tokens": ["Added", "Proper", "class", "to", "format", "proper", "strings", "."], "add_tokens": "require 'pry'", "del_tokens": "require 'pry'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "reduce", "variable", "allocation", "."], "add_tokens": "nest_color ( collapse_reset ( ansi_string ) , ansi_colors )", "del_tokens": "ansi_string = nest_color ( collapse_reset ( ansi_string ) , ansi_colors ) ansi_string", "commit_type": "change"}
{"commit_tokens": ["Improve", "error", "message", "for", "type", "validation"], "add_tokens": "types = case @json_types . size when 1 @json_types . first when 2 @json_types . join ( ' or ' ) when 3 .. Float :: INFINITY @json_types [ 0 .. - 2 ] . join ( ', ' ) << \", or #{@json_types.last}\" end \"#{instance.inspect} must be a #{types}\"", "del_tokens": "# REFACTOR types = @json_types [ 0 .. - 2 ] . join ( ', ' ) << \", or #{@json_types.last}\" \"#{instance.inspect} must be #{types}\"", "commit_type": "improve"}
{"commit_tokens": ["added", "support", "for", "include", "and", "no_includes", "fixed", "only", "to", "only", "allow", "accessible", "attributes"], "add_tokens": "Array . wrap ( $restful_json_domains_providing_referer_path ) . each do | domain | options = { } options [ :restful_json_include ] = params [ :include ] . split ( ',' ) . collect { | s | s . to_sym } if params [ :include ] options [ :restful_json_no_includes ] = true if params [ :no_includes ] options [ :restful_json_only ] = params [ :only ] . split ( ',' ) . collect { | s | s . to_sym } if params [ :only ]", "del_tokens": "domains = ( $restful_json_domains_providing_referer_path . is_a? Array ) ? $restful_json_domains_providing_referer_path : [ $restful_json_domains_providing_referer_path ] domains . each do | domain | options = params [ :only ] ? { restful_json_only : params [ :only ] . split ( ',' ) . collect { | s | s . to_sym } } : { }", "commit_type": "add"}
{"commit_tokens": ["Made", "validate", "directive", "accept", "block", "and", "validate", "against", "its", "boolean", "value", "."], "add_tokens": "if obj [ 'validate' ] validators [ name ] = case obj [ 'validate' ] when Proc obj [ 'validate' ] when Regexp , String Regexp . new ( obj [ 'validate' ] . to_s ) else raise ValidateExpectsRegexpOrBlock end # Validate the argument if we need to, against a regexp or a block. if validators [ name ] if validators [ name ] . is_a? ( Regexp ) && validators [ name ] =~ value elsif validators [ name ] . is_a? ( Proc ) && validators [ name ] . call ( value ) else raise ArgumentValidationFails end end class ValidateExpectsRegexpOrBlock < ParseError ; end", "del_tokens": "if obj [ 'validate' ] && obj [ 'validate' ] . respond_to? ( :to_s ) validators [ name ] = Regexp . new ( obj [ 'validate' ] . to_s ) elsif obj [ 'validate' ] raise ValidateExpectsRegexp # Validate the argument if we need to. raise ArgumentValidationFails if validators [ name ] && validators [ name ] !~ value class ValidateExpectsRegexp < ParseError ; end", "commit_type": "make"}
{"commit_tokens": ["added", "more", "comments", "to", "top", "level", "module"], "add_tokens": "# emulator = TN3270.emulator_for :extra do |emulator| # emulator.session_file = 'path_to_session_file' # end # Another option is to mixin the +TE3270::ScreenFactory+ module on use the factory methods to create the screen # objects. If you are using Cucumber you can do this by calling the +World+ method in your env.rb file. # # @example Registering the ScreenFactory with Cucumber World # World(TE3270::ScreenFactory) # # @emulator = TE3270.emulator_for :quick3270 do |emulator| # emulator.session_file = 'path_to_session_file' # end # # Now in your step definitions you can simply have the following: # # @example Using the factory method in a step definition # on(MainframeScreen).do_something # # @see TE3270::ScreenFactory for more details on using the factory and navigation methods #", "del_tokens": "# emulator = TN3270.emulator_for :extra", "commit_type": "add"}
{"commit_tokens": ["Created", "new", "contracts", "for", "unstructured", "events", "and", "custom", "contexts"], "add_tokens": "t . track_page_view ( 'http://www.example.com' , nil , nil , [ { 'schema' => 'iglu:com.acme/page/jsonschema/1-0-0' , 'data' => { 'page_type' => 'test' } , { 'schema' => 'iglu:com.acme/user/jsonschema/1-0-0' , 'data' => { 'user_type' => 'tester' } } ] ) 'co' => \"{\\\"schema\\\":\\\"iglu:com.snowplowanalytics.snowplow/contexts/jsonschema/1-0-0\\\",\\\"data\\\":[{\\\"schema\\\":\\\"iglu:com.acme/page/jsonschema/1-0-0\\\",\\\"data\\\":{\\\"page_type\\\":\\\"test\\\"}},{\\\"schema\\\":\\\"iglu:com.acme/user/jsonschema/1-0-0\\\",\\\"data\\\":{\\\"user_type\\\":\\\"tester\\\"}}]}\"", "del_tokens": "t . track_page_view ( 'http://www.example.com' , nil , nil , { 'page' => { 'page_type' => 'test' } , 'user' => { 'user_type' => 'tester' } ) 'co' => \"{\\\"page\\\":{\\\"page_type\\\":\\\"test\\\"},\\\"user\\\":{\\\"user_type\\\":\\\"tester\\\"}}\" , 'cv' => 'com.example'", "commit_type": "create"}
{"commit_tokens": ["Adding", "more", "lexer", "examples", "and", "fixing", "issue", "with", "ambiguous", "redirects", "."], "add_tokens": "ARG = / [^ \\s ; \\| \\( \\) \\{ \\} \\[ \\] \\& \\! \\\\ \\< ][^ \\s ; \\| \\( \\) \\{ \\} \\[ \\] \\& \\! \\> \\< ]* / REDIRECTION = / \\A (([12]?>&?[12]?) \\s *(?![12]>)( #{ ARG } )?) /", "del_tokens": "ARG = / [^0-9 \\s ; \\| \\( \\) \\{ \\} \\[ \\] \\& \\! \\\\ \\< ][^ \\s ; \\| \\( \\) \\{ \\} \\[ \\] \\& \\! \\> \\< ]* / REDIRECTION = / \\A (([12]?>&?[12]?) \\s *( #{ ARG } )?) /", "commit_type": "add"}
{"commit_tokens": ["add", "bunch", "of", "docs", "and", "improve", "context", ".", "evaluate_filters"], "add_tokens": "# manipulate set of context and filters for it, # allow evaluating filters in given context # super ( method ) do evaluate_local_filters ( method ) end", "del_tokens": "super ( method ) evaluate_local_filters ( method )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "retrieving", "a", "FAQ", ".", "Fixed", "NotFound", "constant", "."], "add_tokens": "# Returns a single Tender FAQ. # @param [URI, String, Integer] id_or_href The faq ID or HREF. Can be either a URI # instance, a string containing a URI, or a queue ID as a numeric string or integer. # @return [Hash] The faq attributes in a Hash. def get_faq ( id_or_href ) get ( singleton_uri ( id_or_href , 'faqs' ) ) end when Net :: HTTPNotFound ; raise Love :: NotFound , \"The resource #{uri} was not found!\"", "del_tokens": "when Net :: NotFound ; raise Love :: NotFound , \"The resource #{uri} was not found!\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "issues", "with", "non", "-", "escaped", "folder", "paths"], "add_tokens": "dir_selected = directory ? File . expand_path ( directory ) : Dir . pwd # Make sure we don't fail when config path has spaces config : config ? Shellwords . escape ( config ) : nil , # Needs to be escaped before comparsion with escaped file paths dir_selected = Shellwords . escape ( dir_selected ) map { | file | Shellwords . escape ( File . expand_path ( file ) ) } . uniq .", "del_tokens": "dir_selected = directory ? File . expand_path ( directory ) : Shellwords . escape ( Dir . pwd ) config : config , map { | file | Shellwords . escape ( file ) } . uniq . map { | file | File . expand_path ( file ) } .", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "multiple", "queue", "names", "in", "Que"], "add_tokens": "def queue ( * queues ) query = case when queues . none? then QUERY when queues . one? then \"#{QUERY} AND queue = '#{queues.first}'\" else queue_names = queues . map { | queue | \"'#{queue}'\" } . join ( ', ' ) %Q{#{QUERY} AND queue IN (#{queue_names})} end", "del_tokens": "def queue ( queue = nil ) query = queue ? \"#{QUERY} AND queue = '#{queue}'\" : QUERY", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "mercury", "it", "should", "register", "images"], "add_tokens": "register Sinatra :: Images full_file = File . join ( options . views , filename ) if File . exists? ( full_file ) view_file = full_file", "del_tokens": "helpers Sinatra :: Images if File . exists? ( File . join ( options . views , filename ) ) view_file = File . join ( options . views , filename )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "initialization", "and", "add", "test", "coverage", "."], "add_tokens": "@database = args . first if args . first . is_a? String", "del_tokens": "@database = args . first", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "OS", "version", "pattern", "replacements"], "add_tokens": "v1 = pattern [ \"os_v1_replacement\" ] . sub ( '$1' , v1 || '' ) v2 = pattern [ \"os_v2_replacement\" ] . sub ( '$1' , v2 || '' ) v3 = pattern [ \"os_v3_replacement\" ] . sub ( '$1' , v3 || '' ) v4 = pattern [ \"os_v4_replacement\" ] . sub ( '$1' , v4 || '' )", "del_tokens": "v1 = pattern [ \"v1_replacement\" ] . sub ( '$1' , v1 || '' ) v2 = pattern [ \"v2_replacement\" ] . sub ( '$1' , v2 || '' ) v3 = pattern [ \"v3_replacement\" ] . sub ( '$1' , v3 || '' ) v4 = pattern [ \"v3_replacement\" ] . sub ( '$1' , v3 || '' )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "version", "and", "gem", "dependencies"], "add_tokens": "gem 'dm-core' , '~>0.9.9'", "del_tokens": "gem 'dm-core' , '~>0.9.8'", "commit_type": "update"}
{"commit_tokens": ["add", "empty", "new", "line", "parser", ";", "add", "test", "for", "code", "block"], "add_tokens": "return [ \"<code class=\\\"code-#{lang}\\\">#{(Markascend.escape_html block) if block}</code>\" ]", "del_tokens": "return \"<code class=\\\"code-#{lang}\\\">#{(Markascend.escape_html block) if block}</code>\"", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "dirty", "fix", "to", "use", "update", "for", "TPRs", "in", "deploy_resources"], "add_tokens": "command = [ \"--namespace=#{@namespace}\" ] # TPRs must use update for now: https://github.com/kubernetes/kubernetes/issues/39906 if resources . any? { | r | r . tpr? } command << \"update\" else command << \"apply\" end", "del_tokens": "command = [ \"apply\" , \"--namespace=#{@namespace}\" ]", "commit_type": "add"}
{"commit_tokens": ["Added", "terminated", "method", "into", "Runner"], "add_tokens": "break if terminated? Terminator . catch_signals { terminate } def terminate @terminated = true end def terminated? @terminated end", "del_tokens": "@terminated = false break if @terminated Terminator . catch_signals { @terminated = true }", "commit_type": "add"}
{"commit_tokens": ["Updated", "docs", "with", "filter", "examples"], "add_tokens": "# :sort => 'pageviews', # :filters => ['browser == Firefox']})", "del_tokens": "# :sort => 'pageviews'})", "commit_type": "update"}
{"commit_tokens": ["remove", "should", "from", "spec", "heads"], "add_tokens": "describe Rufus :: Lua :: State do describe '#gc_collect!' do it 'raises when called on a closed Rufus::Lua::State instance' do s = Rufus :: Lua :: State . new s . close lambda { s . gc_collect! } . should raise_error ( RuntimeError ) end describe '#gc_count' do it 'returns an indication about the Lua interpreter memory usage' do before_usage = @s . gc_count @s . eval ( \"return table.concat({ 'hello', 'from', 'Lua' }, ' ')\" ) after_usage = @s . gc_count after_usage . should > before_usage end", "del_tokens": "describe 'Rufus::Lua::State (gc)' do it 'should raise an exception when operating on closed states' do s = Rufus :: Lua :: State . new s . close lambda { s . gc_collect! } . should raise_error ( RuntimeError ) it 'should accurately count Lua interpreter memory usage' do before_usage = @s . gc_count @s . eval ( \"return table.concat({ 'hello', 'from', 'Lua' }, ' ')\" ) after_usage = @s . gc_count after_usage . should > before_usage", "commit_type": "remove"}
{"commit_tokens": ["use", "RUBY_INTEGER_UNIFICATION", "instead", "of", "HAVE_RB_CFIXNUM"], "add_tokens": "@upcast << \"#ifdef RUBY_INTEGER_UNIFICATION\" @upcast << \"rb_hash_aset(hCast, rb_cInteger, #{t});\" @upcast << \"#else\" @upcast << \"rb_hash_aset(hCast, rb_cFixnum, #{t});\" @upcast << \"rb_hash_aset(hCast, rb_cBignum, #{t});\" @upcast << \"#endif\"", "del_tokens": "if defined? ( Fixnum ) && Fixnum != Integer @upcast << \"rb_hash_aset(hCast, rb_cFixnum, #{t});\" @upcast << \"rb_hash_aset(hCast, rb_cBignum, #{t});\" else # RUBY_VERSION >= \"2.4.0\" @upcast << \"rb_hash_aset(hCast, rb_cInteger, #{t});\" end", "commit_type": "use"}
{"commit_tokens": ["Added", "abstraction", "for", "handling", "class", "."], "add_tokens": "require_relative 'class_ruby.rb' @classRuby = Languages :: Ruby :: ClassRuby . new return @classRuby . get_class ( line )", "del_tokens": "# Verify if line has the keyword and return it, otherwise return nil # @param line String to apply the regex # @return Return nil if anything is find, or the class name regexExpression = / ^ \\s *class \\b [ | \\t ]+ \\s *(.*) \\b / return apply_regex ( line , regexExpression ) # Verify if a line has an attribute. If it has attribute, first the # function capture all lines and remove \"@\" or \":\" and whitespace, finally # it splits the string by \",\" and return an array. Otherwise it returns # nil. # @param line to inpect for find attribute. # @return Return nil if not find attribute or an array with the attribute.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "most", "of", "the", "bugs", "."], "add_tokens": "proc = store [ cache_key ] = Proc . new { | ids | scope . send ( $1 ) . count } super #replaced_method_missing(method, *args)", "del_tokens": "require 'arid_cache/cache_hash' proc = store [ cache_key ] = Proc . new { | ids | scope . send ( key ) . count } replaced_method_missing ( method , * args )", "commit_type": "fix"}
{"commit_tokens": ["removing", "old", "comments", "adding", "docs", "to", "rest", "/", "categories"], "add_tokens": "# it returns an Array containing the categories for the given countries, # or the DEFAULT_COUNTRY if no countries was given. # @param client[Yourub::Client] # @param countries[Array] # # # @example # client = Yourub::Client.new # categories = Yourub::REST::Categories.for_country(client, [\"US\"]) # def for_countries ( client , countries ) param = { \"part\" => \"snippet\" , \"regionCode\" => countries }", "del_tokens": "def for_country ( client , country ) param = { \"part\" => \"snippet\" , \"regionCode\" => country }", "commit_type": "remove"}
{"commit_tokens": ["Update", "app", "/", "helpers", "/", "spree", "/", "admin", "/", "navigation_helper_decorator", ".", "rb"], "add_tokens": "end", "del_tokens": "def button ( text , icon_name = nil , button_type = 'submit' , options = { } ) button_tag ( content_tag ( 'span' , icon ( icon_name ) + ' ' + text ) , options . merge ( :type => button_type ) ) end def button_link_to ( text , url , html_options = { } ) if ( html_options [ :method ] && html_options [ :method ] . to_s . downcase != 'get' && ! html_options [ :remote ] ) form_tag ( url , :method => html_options . delete ( :method ) ) do button ( text , html_options . delete ( :icon ) , nil , html_options ) end else if html_options [ 'data-update' ] . nil? && html_options [ :remote ] object_name , action = url . split ( '/' ) [ - 2 .. - 1 ] html_options [ 'data-update' ] = [ action , object_name . singularize ] . join ( '_' ) end html_options . delete ( 'data-update' ) unless html_options [ 'data-update' ] link_to ( text_for_button_link ( text , html_options ) , url , html_options_for_button_link ( html_options ) ) end end end", "commit_type": "update"}
{"commit_tokens": ["Adding", "the", "ability", "to", "skip", "middleware", "init", "via", "configs"], "add_tokens": "SETTINGS = [ :skip_middleware , :app_root , :named_maintenance_file_paths , @skip_middleware = false", "del_tokens": "SETTINGS = [ :app_root , :named_maintenance_file_paths ,", "commit_type": "add"}
{"commit_tokens": ["Use", "next", "in", "lambda", "to", "allow", "for", "non", "-", "method", "-", "based", "dispatch", "in", "firering"], "add_tokens": "next", "del_tokens": "return", "commit_type": "use"}
{"commit_tokens": ["fix", "handling", "of", "symbols", "on", "the", "left", "of", "a", "where", "value"], "add_tokens": "cache_find_bys . include? ( where_values . map { | wv | wv . left . name . to_s } . sort ) && # any of the set of where-values to cache match this relation", "del_tokens": "cache_find_bys . include? ( where_values . map { | wv | wv . left . name } . sort ) && # any of the set of where-values to cache match this relation", "commit_type": "fix"}
{"commit_tokens": ["added", "missing", "method", "to", "ReportEmail"], "add_tokens": "Hash [ * self . viable_report_filters . map { | filter | filter . filter_match_params } . flatten ] . def viable_report_filters @viable_report_filters ||= report_filters . to_a . select { | rf | filter_options_for ( rf . filter_name ) . present? } end self . resource_class :: REPORT_DEFINITION_OPTIONS . reject { | name , label | ( self . viable_report_filters . pluck ( :filter_name ) + self . report . viable_report_filters . pluck ( :filter_name ) ) . include? name }", "del_tokens": "Hash [ * self . report_filters . map { | filter | filter . filter_match_params } . flatten ] . self . resource_class :: REPORT_DEFINITION_OPTIONS . reject { | name , label | ( self . report_filters . pluck ( :filter_name ) + self . report . report_filters . pluck ( :filter_name ) ) . include? name }", "commit_type": "add"}
{"commit_tokens": ["update", "Rakefile", "(", "fix", "test", ")"], "add_tokens": "sleep ( 0.5 ) sleep ( 0.5 )", "del_tokens": "sleep ( 0.1 ) sleep ( 0.1 )", "commit_type": "update"}
{"commit_tokens": ["added", "method", "to", "substitute", "the", "app_name", "value", "from", "yml", "file", "and", "replace", "with", "@project_name"], "add_tokens": "check_replace_string_pairs_for_project_name_sub ( file [ :symbols ] ) def check_replace_string_pairs_for_project_name_sub ( hash ) unless @project_name . nil? hash . each do | key , value | if key == :app_name hash [ key ] = @project_name end end end end", "del_tokens": "# TODO Write method to check config yaml for app_name string replacements and substitute the name of the app as set in @project_name", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "thrown", "exception", "when", "processing", "some", "special", "table", "files"], "add_tokens": "while stuff [ 0 ] =~ / \\# / # Some tables' head lines start with a '#', such as *mim2gene.txt* in OMIM break if stuff [ 0 ] =~ / \\# [ \\w ]+ \\t / comments << stuff . shift . gsub ( / ^ \\# / , '' ) end", "del_tokens": "comments << stuff . shift . gsub ( / ^ \\# / , '' ) while ( stuff [ 0 ] =~ / \\# / )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "on_exception", "callbacks", "to", "allow", "custom", "error", "handling"], "add_tokens": "it 'should raise an Pling::Errors if no on_exception callback is set' do gateway . stub ( :deliver! ) . and_raise ( Pling :: Error ) expect { gateway . deliver ( message , device ) } . to raise_error Pling :: Error end it 'should not raise an Pling::Errors if an on_exception callback is set' do gateway = gateway_class . new ( :on_exception => lambda { } ) gateway . stub ( :deliver! ) . and_raise ( Pling :: Error ) expect { gateway . deliver ( message , device ) } . to_not raise_error Pling :: Error end it 'should pass the exception to the callback' do gateway = gateway_class . new ( :on_exception => lambda { | error | error . should be_kind_of Pling :: Error } ) gateway . stub ( :deliver! ) . and_raise ( Pling :: Error ) gateway . deliver ( message , device ) end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["make", "sign", "rsa", "/", "dsa", "method", "to", "class", "method"], "add_tokens": "def self . sign ( string ) def self . verify? ( string , sign )", "del_tokens": "def sign ( string ) def verify? ( string , sign )", "commit_type": "make"}
{"commit_tokens": ["add", "a", "simple", "output", "for", "status", "and", "add", "a", "list", "of", "messages", "from", "the", "supervisor", "to", "the", "status", "output"], "add_tokens": "require 'procodile/message' opts . on ( \"--simple\" , \"Return overall status\" ) do cli . options [ :simple ] = true end elsif @options [ :simple ] if status [ 'messages' ] . empty? message = status [ 'instances' ] . map { | p , i | \"#{p}[#{i.size}]\" } puts \"OK || #{message.join(', ')}\" else message = status [ 'messages' ] . map { | p | Message . parse ( p ) } . join ( ', ' ) puts \"Issues || #{message}\" end if @options [ :simple ] puts \"NotRunning || Procodile supervisor isn't running\" else raise Error , \"Procodile supervisor isn't running\" end", "del_tokens": "raise Error , \"Procodile supervisor isn't running\"", "commit_type": "add"}
{"commit_tokens": ["add", "additional", "entrypoint", "to", "TThreadPoolServer", "with", "easy", "exception", "handling"], "add_tokens": "@thread_q = SizedQueue . new ( num ) @exception_q = Queue . new @running = false ## exceptions that happen in worker threads will be relayed here and ## must be caught. 'retry' can be used to continue. (threads will ## continue to run while the exception is being handled.) def rescuable_serve Thread . new { serve } unless @running raise @exception_q . pop end ## exceptions that happen in worker threads simply cause that thread ## to die and another to be spawned in its place. def serve @thread_q . push ( :token ) rescue Exception => e @exception_q . push ( e ) @thread_q . pop ( ) # thread died!", "del_tokens": "@q = SizedQueue . new ( num ) def serve ( ) @q . push ( :token ) @q . pop ( ) # thread died!", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "that", "was", "messing", "up", "the", "callstack"], "add_tokens": "print \"Stopped by breakpoint %d at %s:%s\\n\" , n , file , line #context.stop_frame = -1", "del_tokens": "print \"Stopped at breakpoint %d at %s:%s\\n\" , n , file , line context . stop_frame = - 1 process_commands ( context , file , line )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "durability", "-", "level", "to", "PutObject", "."], "add_tokens": "# application/octet-stream. The number of distributed replicates of an object # stored in Manta can be set with an optional :durability_level; the default # is 2. durability_level = opts [ :durability_level ] if durability_level raise unless durability_level > 0 headers . push ( [ 'Durability-Level' , durability_level ] ) end if content_type raise unless content_type . is_a? String headers . push ( [ 'Content-Type' , content_type ] ) end", "del_tokens": "# application/octet-stream. headers . push ( [ 'Content-Type' , content_type ] ) if content_type", "commit_type": "add"}
{"commit_tokens": ["fixed", "another", "ActiveRecord", "dependency", ";", "this", "time", "on", "#blank?"], "add_tokens": "return false if access_token . nil?", "del_tokens": "return false if access_token . blank?", "commit_type": "fix"}
{"commit_tokens": ["added", "usefull", "to_s", "method", "to", "entry"], "add_tokens": "def to_s \"<<Entry: #{@entry.title.content} >>\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "way", "to", "get", "containers", "when", "processing", "an", "EAD", "into", "a", "bunch", "of", "meads", ".", "temporary", "work", "around", "the", "case", "where", "there", "the", "c01s", "are", "not", "series", "level"], "add_tokens": "expected = { :valid => [ \"ua023_006\" ] , :invalid => [ \"mc00145\" , \"mc00240\" , \"ua015_010\" , \"ua023_031\" , \"ua110_041\" ] }", "del_tokens": "expected = { :valid => [ \"ua023_006\" ] , :invalid => [ \"mc00240\" , \"ua015_010\" , \"ua023_031\" , \"ua110_041\" ] }", "commit_type": "add"}
{"commit_tokens": ["Change", "some", "methods", "to", "private"], "add_tokens": "connect ( host , port ) command ( 'login' , { 'client_login_name' => user , 'client_login_password' => pass } ) private private private", "del_tokens": "self . connect ( host , port ) self . command ( 'login' , { 'client_login_name' => user , 'client_login_password' => pass } )", "commit_type": "change"}
{"commit_tokens": ["Create", "model", "Event", "Sale", "for", "create", "report"], "add_tokens": "class EventSales", "del_tokens": "class Orderlist", "commit_type": "create"}
{"commit_tokens": ["Upgraded", "rubocop", "and", "fixed", "some", "style", "issues"], "add_tokens": "default = Rails . root . join ( \"config\" , \"config.yml\" ) local = Rails . root . join ( \"config\" , \"config-local.yml\" )", "del_tokens": "default = File . join ( Rails . root , \"config\" , \"config.yml\" ) local = File . join ( Rails . root , \"config\" , \"config-local.yml\" )", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "typo", "in", "Client", "(", "contents", "-", ">", "key", ")"], "add_tokens": "name , key = Util . safe_read ( path )", "del_tokens": "name , contents = Util . safe_read ( path )", "commit_type": "fix"}
{"commit_tokens": ["Add", "check", "for", "RUBY_ENGINE", "constant"], "add_tokens": "if defined? ( RUBY_ENGINE ) and ( RUBY_ENGINE == 'ruby' ) and ( RUBY_VERSION >= '1.9' )", "del_tokens": "if RUBY_ENGINE == 'ruby' and RUBY_VERSION >= '1.9'", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "pushing", "gems", "via", "API"], "add_tokens": "self . user_api_key && ! self . user_api_key . empty?", "del_tokens": "! self . user_api_key . blank?", "commit_type": "add"}
{"commit_tokens": ["remove", "core_exts", "in", "favor", "of", "activesupport"], "add_tokens": "require 'active_support/core_ext/class/attribute_accessors' require 'active_support/core_ext/hash/keys' require 'active_support/core_ext/hash/slice'", "del_tokens": "require 'rets4r/core_ext/class/attribute_accessors' require 'rets4r/core_ext/hash/keys' require 'rets4r/core_ext/hash/slice'", "commit_type": "remove"}
{"commit_tokens": ["Moved", "attribute", "validation", "into", "the", "Attribute", "class"], "add_tokens": "class AttributeDefinitionError < RuntimeError end def initialize ( name , static_value , lazy_block ) name = name . to_sym if name . to_s =~ / =$ / raise AttributeDefinitionError , \"factory_girl uses 'f.#{name.to_s.chop} value' syntax \" + \"rather than 'f.#{name} = value'\" end unless static_value . nil? || lazy_block . nil? raise AttributeDefinitionError , \"Both value and block given\" end @name = name @static_value = static_value @lazy_block = lazy_block", "del_tokens": "attr_writer :static_value , :lazy_block def initialize ( name ) @name = name", "commit_type": "move"}
{"commit_tokens": ["added", "#standardize", "to", "dataframe", "and", "added", "optional", "arg", "for", "dup"], "add_tokens": "# # == Arguments # # * +vectors_to_dup+ - An Array specifying the names of Vectors to # be duplicated. Will duplicate the entire DataFrame if not specified. def dup vectors_to_dup = nil vectors_to_dup = @vectors unless vectors_to_dup new_order = vectors_to_dup . each do | vec | Daru :: MultiIndex . new ( vectors_to_dup ) vectors_to_dup . each do | vector | Daru :: Index . new ( vectors_to_dup ) Daru :: DataFrame . new src , order : new_order , index : @index . dup , name : @name , clone : true", "del_tokens": "def dup @vectors . each do | vec | @vectors . each do | vector | Daru :: DataFrame . new src , order : @vectors . dup , index : @index . dup , name : @name , clone : true", "commit_type": "add"}
{"commit_tokens": ["Use", "inspect", "instead", "of", "pretty", "inspect", "for", "rails", "free", "environments"], "add_tokens": "fail ( \"Bad response: #{rest_response.inspect}\" ) unless @parsed_response [ 'result_ok' ] && @parsed_response [ 'result_ok' ] . to_s . downcase == 'true'", "del_tokens": "fail \"Bad response: #{@parsed_response.pretty_inspect}\" unless @parsed_response [ 'result_ok' ] && @parsed_response [ 'result_ok' ] . to_s . downcase == 'true'", "commit_type": "use"}
{"commit_tokens": ["updated", "and", "added", "new", "tests", "to", "verify", "object", "support"], "add_tokens": "class ObjectSupportTest < ActiveSupport :: TestCase", "del_tokens": "class WithoutShortcutsTest < ActiveSupport :: TestCase", "commit_type": "update"}
{"commit_tokens": ["Fixing", "the", "odd", "order", "mistake"], "add_tokens": "attr_accessor :name , :display_name , :log_exclude , :base_path , :sv_path , :service_path , :etc_path , :data_path , :log_path , :command_map , :fh_output , :kill_users run_sv_command ( * args ) begin graceful_kill rescue SystemExit end get_all_services . each do | die_daemon_die | run_command ( \"pkill -KILL -f 'runsv #{die_daemon_die}'\" ) end service = args [ 1 ] command_to_run = args [ 0 ] if args . length > 1 && command_map [ command_to_run ] [ :arity ] != 2", "del_tokens": "attr_accessor :name , :display_name , :log_exclude , :base_path , :sv_path , :service_path , :data_path , :log_path , :command_map , :fh_output , :kill_users if args . length == 2 run_sv_command ( args [ 1 ] , args [ 0 ] ) else run_sv_command ( args [ 0 ] ) end graceful_kill status = args [ 1 ] if args . length == 2 command_to_run = args [ 1 ] check_arity = true else command_to_run = args [ 0 ] end if check_arity && command_map [ command_to_run ] [ :arity ] != 2", "commit_type": "fix"}
{"commit_tokens": ["FIx", "the", "response", "parser", "to", "use", "Faraday", "s", "on_complete", "handler", "."], "add_tokens": "@app . call ( env ) . on_complete do | response_env | if response_env [ :response_headers ] [ 'content-type' ] =~ / \\b json \\b / hash_body = JSON . parse ( response_env [ :body ] ) response_env [ :body ] = RecursiveOpenStruct . new ( hash_body , recurse_over_arrays : true ) end response_env [ :body ] = Response . from_result response_env [ :body ]", "del_tokens": "response = @app . call ( env ) if env [ :response_headers ] [ 'content-type' ] =~ / \\b json \\b / hash_body = JSON . parse ( env [ :body ] ) env [ :body ] = RecursiveOpenStruct . new ( hash_body , recurse_over_arrays : true ) env [ :body ] = Response . from_result env [ :body ] response", "commit_type": "fix"}
{"commit_tokens": ["add", "rmdir_f", "and", "change", "rm_f"], "add_tokens": "if File . directory? ( pa . p ) if o [ :force ] ; next else raise Errno :: EISDIR , \"is a directory -- #{pa.p}\" end end next if pa . directory? def rm_f * paths paths , o = paths . extract_options o [ :force ] = true rm * paths , o end paths , o = paths . extract_options if not File . directory? ( pa . p ) if o [ :force ] ; next else raise Errno :: ENOTDIR , \"not a directory -- #{pa.p}\" end end def rmdir_f * paths paths , o = paths . extract_options o [ :force ] = true rmdir * paths , o end", "del_tokens": "alias rm_f rm raise Errno :: ENOTDIR , \"-- #{pa}\" if not File . directory? ( pa . p )", "commit_type": "add"}
{"commit_tokens": ["Changed", "Errors", "to", "match", "mailgun", "api", "error", "types", "and", "also", "handle", "not", "found", "records"], "add_tokens": "begin error_code = e . http_code error_message = JSON ( e . http_body ) [ \"message\" ] error = Mailgun :: Error . new ( :code => error_code || nil , :message => error_message || nil ) if error . handle . kind_of? Mailgun :: ErrorBase raise error else return error . handle rescue raise e", "del_tokens": "error_message = nil if e . respond_to? :http_body begin error_message = JSON ( e . http_body ) [ \"message\" ] rescue raise e raise Mailgun :: Error . new ( error_message ) raise e", "commit_type": "change"}
{"commit_tokens": ["Move", "reserved", "slugs", "so", "extensions", "could", "use", "them"], "add_tokens": "Archangel . config . to_h . select do | key | Archangel . reserved_page_keywords . include? ( key )", "del_tokens": "Archangel . config . to_h . select do | key , _val | %i[ auth_path backend_path frontend_path ] . include? ( key )", "commit_type": "move"}
{"commit_tokens": ["add", "second", "arg", "options", "to", "Sign", "::", "Wap", ".", "verify?"], "add_tokens": "def self . verify? ( params , options = { } ) key = options [ :pid ] || Alipay . key sign = params . delete ( 'sign' ) case params [ 'sec_id' ] when 'MD5' verify_md5? ( key , sign , params ) when '0001' # RSA raise NotImplementedError , \"RSA sign is unimplemented\" else raise ArgumentError , \"wrong sec_id, allow value: 'MD5', '0001'\" end end def self . params_to_string ( params ) SORTED_VERIFY_PARAMS . map do | key | end def self . verify_md5? ( key , sign , params ) sign == Digest :: MD5 . hexdigest ( \"#{params_to_string(params)}#{key}\" )", "del_tokens": "def self . verify? ( params ) query = SORTED_VERIFY_PARAMS . map do | key | params [ 'sign' ] == Digest :: MD5 . hexdigest ( \"#{query}#{Alipay.key}\" )", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "form", "parameters", "for", "PUT", "and", "PATCH", "method", "types"], "add_tokens": "paramType = if path . include? ( \":#{param}\" ) 'path' else %w[ POST PUT PATCH ] . include? ( method ) ? 'form' : 'query' end", "del_tokens": "paramType = path . include? ( \":#{param}\" ) ? 'path' : ( method == 'POST' ) ? 'form' : 'query'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "failing", "spec", "on", "creating", "Xcodeproj", "::", "Config", "with", "no", "argument"], "add_tokens": "def initialize ( xcconfig_hash_or_file = { } )", "del_tokens": "def initialize ( xcconfig_hash_or_file )", "commit_type": "fix"}
{"commit_tokens": ["Added", "better", "transition", "error", "messages"], "add_tokens": "raise ( StateNotFound , transition_error ( path ) ) unless state raise ( InvalidTransition , transition_error ( path ) ) unless new_states . last . leaf? raise ( InvalidEvent , transition_error ( name ) ) unless state self . find_states ( current_state . path ) . include? find_state ( path ) def transition_error ( state ) \"Unable to transition from #{current_state} to #{state}\" end", "del_tokens": "raise ( StateNotFound , path ) unless state raise ( InvalidTransition , path ) unless new_states . last . leaf? raise ( InvalidEvent , name ) unless state self . find_states ( current_state . path ) . include? find_state ( path )", "commit_type": "add"}
{"commit_tokens": ["Allow", "users", "to", "construct", "a", "service", "with", "the", "access", "token", "and", "realm", "included", "in", "the", "initializer", "just", "like", "model", "classes", "."], "add_tokens": "def initialize ( attributes = { } ) attributes . each { | key , value | public_send ( \"#{key}=\" , value ) }", "del_tokens": "def initialize ( )", "commit_type": "allow"}
{"commit_tokens": ["Add", "tests", "for", "the", "Stack", "Monitor", "."], "add_tokens": "rescue :: Aws :: CloudFormation :: Errors :: ValidationError => e", "del_tokens": "rescue :: AWS :: CloudFormation :: Errors :: ValidationError => e", "commit_type": "add"}
{"commit_tokens": ["Fix", "Image", "example", "and", "add", "simple", "test", "coverage", "for", "Rubyvis", "::", "Image"], "add_tokens": "\"height\" => s . height , \"xlink:href\" => s . url", "del_tokens": "\"height\" => s . height e . add_attribute ( \"xlink:href\" , s . url ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "underscore", "to", "unused", "argument", "in", "grep", ".", "rb"], "add_tokens": "@result = run \"grep -#{@config.grep_options} #{@path} -e '#{@expression}'\" do | _out , err |", "del_tokens": "@result = run \"grep -#{@config.grep_options} #{@path} -e '#{@expression}'\" do | out , err |", "commit_type": "add"}
{"commit_tokens": ["Allow", "permitters", "to", "be", "used", "without", "a", "current_user", "method"], "add_tokens": "@permitter_class_to_permitter [ pclass ] = pclass . new ( params , defined? ( current_user ) ? current_user : nil , current_authorizer_method && defined? ( current_authorizer_method ) ? __send__ ( current_authorizer_method ) : nil )", "del_tokens": "@permitter_class_to_permitter [ pclass ] = pclass . new ( params , current_user , current_authorizer_method && defined? ( current_authorizer_method ) ? __send__ ( current_authorizer_method ) : nil )", "commit_type": "allow"}
{"commit_tokens": ["changed", "gem", "name", "to", "comply", "with", "rubyforge", "16", "char", "limit"], "add_tokens": "require 'eb_nested_set'", "del_tokens": "require 'even_better_nested_set'", "commit_type": "change"}
{"commit_tokens": ["using", "patched", "version", "of", "database_cleaner", "for", "specs", "to", "drop", "tables"], "add_tokens": "DatabaseCleaner . clean_with ( :truncation ) DatabaseCleaner . drop_tables :users , :roles , :users_roles", "del_tokens": "DatabaseCleaner . clean_with ( :truncation ) # DatabaseCleaner.clean", "commit_type": "use"}
{"commit_tokens": ["Updated", "with", "security", "patches", "."], "add_tokens": "VERSION = \"0.5.7\"", "del_tokens": "VERSION = \"0.5.6\"", "commit_type": "update"}
{"commit_tokens": ["Move", "String", "extension", "to", "core_ext"], "add_tokens": "require \"pattern_patch/core_ext\"", "del_tokens": "require \"pattern_patch/string\"", "commit_type": "move"}
{"commit_tokens": ["Removed", "use", "of", "autoload", "in", "preparation", "for", "Ruby", "3", "."], "add_tokens": "require 'canard/version' require 'canard/user_model'", "del_tokens": "require \"canard/version\" module Canard autoload :UserModel , 'canard/user_model' end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "comment", "for", "current", "behavior", "."], "add_tokens": "# Upstream attribute we don't support. Sets are an error and gets always", "del_tokens": "# Upstream attribute we don't support. Sets are ignored and gets always", "commit_type": "fix"}
{"commit_tokens": ["Use", "i18n", "with_locale", "instead", "of", "locale", "setter"], "add_tokens": "locale = payload . dig ( \"custom\" , \"locale\" ) || I18n . default_locale I18n . with_locale ( locale ) { yield }", "del_tokens": "I18n . locale = payload . dig ( \"custom\" , \"locale\" ) || I18n . default_locale yield ensure I18n . locale = I18n . default_locale", "commit_type": "use"}
{"commit_tokens": ["Fixing", "up", "some", "issues", "with", "Travis", "."], "add_tokens": "require 'simplecov' SimpleCov . start", "del_tokens": "require \"codeclimate-test-reporter\" CodeClimate :: TestReporter . start", "commit_type": "fix"}
{"commit_tokens": ["Added", "total_friends", "()", "and", "total_blocked", "()"], "add_tokens": "# total # of invited and invited_by without association loading def total_friends ( friend_ids + inverse_friend_ids ) . count end # total # of blockades and blockedes_by without association loading def total_blocked ( blocked_friend_ids + blocked_inverse_friend_ids + blocked_pending_inverse_friend_ids ) . count end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["changed", "view_path", "and", "name", "for", "text", "column", "instead", "of", "string"], "add_tokens": "t . text :view_path , null : false t . text :name , null : false", "del_tokens": "t . string :view_path , null : false t . string :name , null : false", "commit_type": "change"}
{"commit_tokens": ["add", "incremental", "solver", "&", "each_sat"], "add_tokens": "# # Utility methods for PropLogic. # # Combine all terms with or. # @param [Term] terms to combine # @return [Term] combined term # Combine all terms with and. # @param [Term] terms to combine # @return [Term] combined term # Create new variable. Variable . new ( * args ) end # loop while satisfiable. # Note: Loop continues infinitely if no addition was given inside the loop. # @yield [Term, IncrementalSolver] yield for each term. def sat_loop ( initial_term ) incremental = PropLogic . incremental_solver . new initial_term loop do sat = incremental . sat? break unless sat yield sat , incremental end arr . combination ( num ) { | c | yield c }", "del_tokens": "Variable . new * args arr . combination ( num ) { | c | yield c }", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "concise", "readable", "and", "ruby", "idiomatic", "way"], "add_tokens": "@curs and @curs . alive?", "del_tokens": "if @curs and @curs . alive? @curs . alive? end", "commit_type": "add"}
{"commit_tokens": ["fix", "invalid", "multibyte", "escape", "bug"], "add_tokens": "if ip =~ / ( \\d +).( \\d +).( \\d +).( \\d +) /n", "del_tokens": "if ip =~ / ( \\d +).( \\d +).( \\d +).( \\d +) /", "commit_type": "fix"}
{"commit_tokens": ["Make", "Scraper", "handle", "email", "arguments", "better"], "add_tokens": "def get user_id search_url = URLS [ :user_search ] % { searchString : user_id } if webnames . include? ( user_id ) new ( user_id ) # If user_id looks like an email and still gets a result. elsif webnames . size == 1 && / .*@.* \\. .* / =~ user_id new ( webnames . first )", "del_tokens": "def get user_identifier search_url = URLS [ :user_search ] % { searchString : user_identifier } if webnames . include? user_identifier new ( user_identifier )", "commit_type": "make"}
{"commit_tokens": ["Fix", "status", "command", "if", "there", "s", "a", "standby", "instance", "in", "the", "ASG"], "add_tokens": "if ec2_instance ip_address = ec2_instance . public_ip_address || \"#{ec2_instance.private_ip_address} (PRV)\" uptime = uptime_format ( ec2_instance . launch_time ) else # We've seen race conditions where ASG tells us about instances that EC2 is no longer # aware of. ip_address = 'unknown' uptime = 'unknown' end ip_address , uptime", "del_tokens": "# @todo What about ASGs with only private IPs? ec2_instance . public_ip_address , uptime_format ( ec2_instance . launch_time )", "commit_type": "fix"}
{"commit_tokens": ["Use", "to_key_wood", "for", "initializing", "forest", "contents"], "add_tokens": "result << content . to_key_wood", "del_tokens": "result << KeyTree [ content ]", "commit_type": "use"}
{"commit_tokens": ["Allows", "the", "authenticate", "and", "authenticate!", "method", "to", "specify", "that", "you", "don", "t", "want", "to", "store", "the", "user", "in", "the", "session"], "add_tokens": "# :api: public # The method that is called from above. This method calls the underlying authenticate! method # Acts as a guarding method for the strategy. # This will halt the strategy, and set the user in the approprieate scope. # # opts <Hash> - Any options to recirect with. end", "del_tokens": "# :api: public # The method that is called from above. This method calls the underlying authetniate! method # Acts as a guarding method for the strategy. # This will halt the strategy, and set the user in the approprieate scope. # # opts <Hash> - Any options to recirect with. end", "commit_type": "allow"}
{"commit_tokens": ["Removed", "references", "to", "history", "elements", "on", "patient", "models"], "add_tokens": "# Returns an array of elements that exist on this patient, that # Returns an array of elements that exist on this patient, that # Returns an array of elements that exist on this patient. Optionally # takes a category and/or, which returns all elements of that QDM", "del_tokens": "# Returns an array of history elements that exist on this patient, that # Returns an array of history elements that exist on this patient, that # Returns an array of history elements that exist on this patient. Optionally # takes a category and/or, which returns all history elements of that QDM", "commit_type": "remove"}
{"commit_tokens": ["Add", "specs", "for", "new", "email", "regex"], "add_tokens": "Email . new ( :email => \"visitorservices@vmfa.museum\" ) . should be_valid Email . new ( :email => \"info@samoa.travel\" ) . should be_valid email = Email . new ( :email => \"not.an.email.address\" )", "del_tokens": "email = Email . new ( :email => \"fake@email.address\" )", "commit_type": "add"}
{"commit_tokens": ["use", "the", "metadata", "item", "in", "map", "layer", "summary", "creation"], "add_tokens": "metadata : metadata . map { | md | md . to_hash } ,", "del_tokens": "metadata : metadata ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "spec", "for", "new", "error", "type", "."], "add_tokens": "expect { fsm . stop } . to raise_error ( FiniteMachine :: InvalidStateError , / state 'green' / )", "del_tokens": "expect { fsm . stop } . to raise_error ( FiniteMachine :: TransitionError , / state 'green' / )", "commit_type": "fix"}
{"commit_tokens": ["adding", "some", "sample", "output", "for", "boolean_select_input", "and", "using", "true", "/", "false", "instead", "of", "1", "/", "0", "for", "the", "choices", "inline", "with", "what", "boolean_radio_input", "is", "doing"], "add_tokens": "# # Returns something like: # # <li class=\"boolean_select required\" id=\"post_public_input\"> # <label for=\"post_public\"> # make this sucker public?<abbr title=\"required\">*</abbr> # </label> # <select id=\"post_public\" name=\"post[public]\"> # <option value=\"1\">hell yeah</option> # <option value=\"0\">No</option> # </select> # </li> # # TODO: Doesn't handle :include_blank => true, but then again, neither do most of the inputs. choices = [ [ options [ :true ] , true ] , [ options [ :false ] , false ] ]", "del_tokens": "choices = [ [ options [ :true ] , 1 ] , [ options [ :false ] , 0 ] ]", "commit_type": "add"}
{"commit_tokens": ["Added", "resource", "class", "for", "namespaces", "support", "and", "updated", "version"], "add_tokens": "Utils . new . get_controllers . each do | scope | namespace = scope . first ( scope - namespace . to_a ) . each do | klass | klass = \"#{namespace}::#{klass}\" unless namespace == \"default\" permissions << Permission . new ( :controller => klass . gsub ( / _controller / , \"\" ) . to_sym , :actions => ApplicationResource . new ( klass ) . klass . instance_variable_get ( :@_checkable_routes ) ) end", "del_tokens": "Utils . new . get_controllers . each do | klass | permissions << Permission . new ( :controller => klass . gsub ( / _controller / , \"\" ) . to_sym , :actions => klass . camelize . constantize . instance_variable_get ( :@_checkable_routes ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "size", "and", "color", "is", "nil"], "add_tokens": "border_properties . sz = node . attribute ( 'sz' ) . value . to_f / 8.0 if node . attribute ( 'sz' ) if node . attribute ( 'color' ) border_properties . color = node . attribute ( 'color' ) . value unless node . attribute ( 'shadow' ) . nil? border_properties . shadow = node . attribute ( 'shadow' ) . value end if border_properties . color != 'auto' border_properties . color = Color . from_int16 ( border_properties . color ) end", "del_tokens": "border_properties . sz = node . attribute ( 'sz' ) . value . to_f / 8.0 border_properties . color = node . attribute ( 'color' ) . value unless node . attribute ( 'shadow' ) . nil? border_properties . shadow = node . attribute ( 'shadow' ) . value end if border_properties . color != 'auto' border_properties . color = Color . from_int16 ( border_properties . color )", "commit_type": "fix"}
{"commit_tokens": ["Add", "extract", "controller", "logic", "for", "bypassing", "impression", "to", "bot?", "method"], "add_tokens": "Impressionist :: Bots . bot? ( request . user_agent )", "del_tokens": "Impressionist :: Bots :: WILD_CARDS . each do | wild_card | return true if request . user_agent and request . user_agent . downcase . include? wild_card end Impressionist :: Bots :: LIST . include? request . user_agent", "commit_type": "add"}
{"commit_tokens": ["Remove", "dependencies", "on", "github", "forks", "in", "favour", "of", "local", "patches"], "add_tokens": "base . send :include , Tire :: Model :: Callbacks2 # local patched version", "del_tokens": "base . send :include , Tire :: Model :: Callbacks", "commit_type": "remove"}
{"commit_tokens": ["Change", "to", "allow", "for", "indifferent", "key", "fetching"], "add_tokens": "if first_key . to_s . include? ( key_delim ) first_key . split ( key_delim ) else keys end # Fetch value under deeply nested keys with indiffernt key access value = settings [ key ] || settings [ key . to_sym ]", "del_tokens": "first_key . to_s . include? ( key_delim ) ? first_key . split ( key_delim ) : keys # Fetch value under deeply nested keys value = settings [ key ]", "commit_type": "change"}
{"commit_tokens": ["changing", "split", "location", "of", "files"], "add_tokens": "file_list . each do | file |", "del_tokens": "file_list . split ( \"\\n\" ) . each do | file |", "commit_type": "change"}
{"commit_tokens": ["fix", "missing", "tests", "and", "add", "in", "find", "method"], "add_tokens": "def find ( params = { } ) self . class . new ( parent , attributes . merge ( { 'params' => params } ) ) end URITemplate . new ( href_template || href ) . expand ( params )", "del_tokens": "URITemplate . new ( href_template || href ) . expand ( _params )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "twemoji", "extractor", "so", "that", "missing", "emojis", "are", "downloadable"], "add_tokens": "basenames = emoji . code_points . map do | code_point | code_point . to_i ( 16 ) . to_s ( 16 ) end \"/twitter/twemoji/v2.2.1/#{directory_name}/#{basenames.join('-')}.#{extension}\"", "del_tokens": "\"/twitter/twemoji/v2.2.1/#{directory_name}/#{emoji.code_points.join('-').downcase}.#{extension}\"", "commit_type": "fix"}
{"commit_tokens": ["fixed", "List", "::", "Matcher", ".", "pattern", "%w", "(", "a", "b", "c", "d", "e", "f", "g", "gh", ")", "bug"], "add_tokens": "a = Alternate . new ( self , special , list )", "del_tokens": "a = list . size == 1 ? Leaf . new ( self , special , list [ 0 ] ) : Alternate . new ( self , special , list )", "commit_type": "fix"}
{"commit_tokens": ["Added", "namespace", "hack", "to", "root", "elements"], "add_tokens": "REXML :: Document . new ( xml . sub ( / ^<([^ \\/ >]+) / , \"<\\\\1 xmlns:rs='http://www.openarchives.org/rs/terms/'\" ) ) . root", "del_tokens": "REXML :: Document . new ( xml . sub ( / ^<([a-z]+)> / , \"<\\\\1 xmlns:rs='http://www.openarchives.org/rs/terms/'>\" ) ) . root", "commit_type": "add"}
{"commit_tokens": ["Add", "summary", "and", "image_urls", "to", "as_json"], "add_tokens": "model_slug : self . class . model_slug , summary : summary , image_urls : @asset . reload . image_array . map ( & :source_url )", "del_tokens": "model_slug : self . class . model_slug", "commit_type": "add"}
{"commit_tokens": ["Use", "Rails", "4", "for", "tests"], "add_tokens": "config . eager_load = false", "del_tokens": "config . whiny_nils = true", "commit_type": "use"}
{"commit_tokens": ["Improved", "specs", "for", "migration", "runner", "."], "add_tokens": "before ( :each ) do end it 'should create a new migration object, and add it to the list of migrations' do it 'should allow multiple migrations to be added' do migration ( 2 , :add_dob_to_people ) { } migration ( 2 , :add_favorite_pet_to_people ) { } migration ( 3 , :add_something_else_to_people ) { } @@migrations . should have ( 4 ) . items end it 'should raise an error on adding with a duplicated name' do lambda { migration ( 1 , :create_people_table ) { } } . should raise_error ( RuntimeError , / Migration name conflict / ) end after ( :each ) do @@migrations = [ ] end", "del_tokens": "it 'should create a new migration object, and add it to the list of migrations' do", "commit_type": "improve"}
{"commit_tokens": ["Adds", "the", "multimap", "gem", "(", "epic", "fail", ")", "in", "order", "to", "get", "proper", "route", "create", "/", "update", "actions"], "add_tokens": "@mailgun . routes . find @sample_route_id options = { } options [ :priority ] = 1 options [ :expression ] = [ :match_recipient , \"sample.mailgun.org\" ] options [ :action ] = [ [ :forward , \"http://test-site.com\" ] , [ :stop ] ] . with ( @mailgun . routes . send ( :route_url ) , instance_of ( Multimap ) ) options [ :action ] , options = { } . with ( \"#{@mailgun.routes.send(:route_url, @sample_route_id)}\" , instance_of ( Multimap ) )", "del_tokens": "@mailgun . routes . get @sample_route_id options = Hash . new { | h , k | h [ k ] = Hash . new ( & h . default_proc ) } options [ :priority ] = 1 options [ :expression ] = \"match_recipent(\\\"sample.mailgun.org\\\")\" options [ :action ] = \"forward(\\\"http://test-site.com\\\")\" . with ( \"#{@mailgun.routes.send(:route_url)}\" , { :description => options [ :description ] , :priority => options [ :priority ] , :expression => options [ :expression ] , :action => options [ :action ] } ) [ options [ :action ] ] options = Hash . new { | h , k | h [ k ] = Hash . new ( & h . default_proc ) } . with ( \"#{@mailgun.routes.send(:route_url, @sample_route_id)}\" , options )", "commit_type": "add"}
{"commit_tokens": ["Moving", "to", "rspec", "so", "that", "we", "can", "run", "a", "single", "example"], "add_tokens": "uri = URI . parse ( \"#{files_url}/#{token}/#{device_id}/#{service_id}/#{file_handle.id}\" )", "del_tokens": "parent = file_handle . id || 0 uri = URI . parse ( \"#{files_url}/#{token}/#{device_id}/#{service_id}/#{parent}/#{file_handle.name}\" )", "commit_type": "move"}
{"commit_tokens": ["Use", "Git", "for", "user", "identification", "if", "not", "otherwise", "defined"], "add_tokens": "@name || Origen . app . rc . git? ? Origen . app . rc . user_name : nil || @id # Origen.app.rc.git? ? Origen.app.rc.user_email : nil || begin Origen . app . rc . git? ? Origen . app . rc . user_email : nil || begin if Origen . site_config . email_domain \"#{id}@#{Origen.site_config.email_domain}\" end", "del_tokens": "@name || @id if Origen . site_config . email_domain \"#{id}@#{Origen.site_config.email_domain}\"", "commit_type": "use"}
{"commit_tokens": ["Add", "spec", "for", "collection", "includes", "."], "add_tokens": "attr_reader :options def name @options [ :as ] || @name . to_s end", "del_tokens": "attr_reader :name , :options", "commit_type": "add"}
{"commit_tokens": ["Add", "default", "all", "actions", "for", "after", "and", "before", "hook"], "add_tokens": "def before ( actions = :* , action = nil , & block ) def after ( actions = :* , action = nil , & block )", "del_tokens": "def before ( actions , action = nil , & block ) def after ( actions , action = nil , & block )", "commit_type": "add"}
{"commit_tokens": ["added", "Trainer", "an", "interactive", "shell", "prompt", "for", "adding", "scrape", "patterns", "for", "websites"], "add_tokens": "def initialize ( uri : , payload : , scrape_details : nil ) @scrape_details = scrape_details ! ! ( scrape_details ) return nil unless scrape_details [ data_type ]", "del_tokens": "def initialize ( uri : , payload : ) SCRAPE_PATTERNS [ 'domains' ] . key? ( root_domain )", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "choose", "encoding"], "add_tokens": "ENCODINGS = %w( UTF-8 iso-8859-1 ) attr_accessor :encoding_csv rows = CSV . parse ( open ( self . data_file . url ) . read , :col_sep => @separatorChar ) @encoding_csv = @encoding_csv ? @encoding_csv : 'utf-8' #csv_string=open(self.data_file.url,'r:iso-8859-1:utf-8').read.encode('utf-8') csv_string = open ( self . data_file . url , \"r:#{@encoding_csv}\" ) . read . encode ( 'utf-8' ) rows = CSV . parse ( csv_string , :col_sep => @separatorChar ) #rows = CSV.parse(open(self.data_file.url).read, :col_sep => separatorChar)", "del_tokens": "rows = CSV . parse ( open ( self . data_file . url ) . read , :col_sep => separatorChar ) rows = CSV . parse ( open ( self . data_file . url ) . read , :col_sep => separatorChar )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "init", "command", "where", "directories", "could", "be", "uncreated", "before", "usage"], "add_tokens": "unless File . directory? file output_path = \"#{path}/#{output_name}\" FileUtils . mkdir_p File . dirname ( output_path ) unless File . directory? File . dirname ( output_path ) FileUtils . copy ( file , output_path )", "del_tokens": "if File . directory? file FileUtils . mkdir_p \"#{path}/#{output_name}\" else FileUtils . copy ( file , \"#{path}/#{output_name}\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "broker", "identity", "to", "AMQP", "client", "settings", "for", "use", "in", "log", "messages"], "add_tokens": "logger . warn ( \"Reconnecting to broker #{@settings[:identity]} due to missing server heartbeats\" ) logger . warn ( \"Attempting to reconnect to #{@settings[:identity]}\" )", "del_tokens": "logger . warning ( \"Attempting to reconnect to broker rs-broker-#{@settings[:host].gsub('-', '~').to_s}-#{@settings[:port].to_i}\" )", "commit_type": "add"}
{"commit_tokens": ["Change", "exit", "by", "abort", "to", "exit", "properly", "in", "require", "during", "tests"], "add_tokens": "abort require \"strings2csv/converter\"", "del_tokens": "exit require \"strings2csv/converter\"", "commit_type": "change"}
{"commit_tokens": ["Add", "proxmox", "version", "compatibility", "check", "at", "compute", "resource", "creation"], "add_tokens": "require 'foreman_fog_proxmox/semver' logger . debug ( _ ( \"Proxmox compute resource version is %{version}\" ) % { version : version } ) raise :: Foreman :: Exception . new ( _ ( \"Proxmox version %{version} is not semver suitable\" ) % { version : version } ) unless ForemanFogProxmox :: Semver . is_semver? ( version ) ForemanFogProxmox :: Semver . to_semver ( version ) >= ForemanFogProxmox :: Semver . to_semver ( \"5.3.0\" ) && ForemanFogProxmox :: Semver . to_semver ( version ) < ForemanFogProxmox :: Semver . to_semver ( \"5.5.0\" ) v = identity_client . read_version \"#{v['version']}.#{v['release']}\"", "del_tokens": "version == '5.3' identity_client . read_version", "commit_type": "add"}
{"commit_tokens": ["Move", "SimpleIDN", "itself", "to", "use", "Encoding", "and", "support", "multiple", "Encodings"], "add_tokens": "ACE_PREFIX = 'xn--' . encode ( Encoding :: UTF_8 ) . freeze ASCII_MAX = 0x7E DOT = '.' . encode ( Encoding :: UTF_8 ) . freeze return nil if domain . nil? edomain = domain . encode ( Encoding :: UTF_8 ) domain_array = edomain . split ( LABEL_SEPERATOR_RE ) rescue [ ] out << ( s . codepoints . any? { | cp | cp > ASCII_MAX } ? ACE_PREFIX + Punycode . encode ( s ) : s ) out . join ( DOT ) . encode ( domain . encoding ) return nil if domain . nil? edomain = domain . encode ( Encoding :: UTF_8 ) domain_array = edomain . split ( LABEL_SEPERATOR_RE ) rescue [ ] out . join ( DOT ) . encode ( domain . encoding )", "del_tokens": "ACE_PREFIX = 'xn--' DOT = '.' domain_array = domain . split ( LABEL_SEPERATOR_RE ) rescue [ ] out << ( s =~ / [^A-Z0-9@ \\- *_] /i ? ACE_PREFIX + Punycode . encode ( s ) : s ) out . join ( DOT ) domain_array = domain . split ( LABEL_SEPERATOR_RE ) rescue [ ] out . join ( DOT )", "commit_type": "move"}
{"commit_tokens": ["made", "it", "so", "you", "can", "put", "raw", "javascript", "variables", "in", "the", "options"], "add_tokens": "js_options = options_to_js ( collection_options . except ( :options_with_raw_js ) , collection_options [ :options_with_raw_js ] ) OpenSeadragon ( #{js_options}); # converts a ruby hash to a javascript object without stringifying the raw_js_keys # so you can put js variables in there def options_to_js ( options , raw_js_keys = [ ] ) normal = options . except ( * raw_js_keys ) . map do | k , v | val = if v . is_a? ( Hash ) or v . is_a? ( Array ) JSON . pretty_generate ( v ) else JSON . dump ( v ) end JSON . dump ( k ) + \": \" + val end raw_js = options . slice ( * raw_js_keys ) . map { | k , v | k . to_s + \": \" + v . to_s } \"{\\n\" + ( normal + raw_js ) . join ( \",\\n\" ) + \"}\" end", "del_tokens": "OpenSeadragon ( #{JSON.pretty_generate(collection_options)}); #<%=javascript_include_tag \"openseadragon.js\" %>", "commit_type": "make"}
{"commit_tokens": ["Fix", "to", "see", "Net", "::", "SSH", "::", "Config", ".", "for", "in", "itamae"], "add_tokens": "# itamae itself sees Net:SSH::Config.for(host) # here, we set ssh config if property file specially specifies command << \" -u #{properties['ssh_user']}\" if properties [ 'ssh_user' ] command << \" -i #{(Array(properties['ssh_keys']) || []).first}\" if properties [ 'ssh_keys' ] command << \" -p #{properties['ssh_port']}\" if properties [ 'ssh_port' ]", "del_tokens": "config = Net :: SSH :: Config . for ( host ) $stdout . puts \"DEBUG: Net::SSH::Config.for(#{host.inspect}) => #{config}\" if @options [ :debug ] command << \" -u #{properties['ssh_user'] || config[:user] || ENV['USER']}\" command << \" -i #{(properties['ssh_keys'] || []).first || (config[:keys] || []).first || (File.exist?(File.expand_path('~/.ssh/id_dsa')) ? '~/.ssh/id_dsa' : '~/.ssh/id_rsa')}\" command << \" -p #{properties['ssh_port'] || config[:port] || 22}\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "examples", "for", "show", "actions"], "add_tokens": "let ( :headers ) do { 'Accept' => 'application/vnd.api+json' } end let ( :params ) do local_params = options . try ( :params ) || { } options [ :action ] == :show ? local_params . merge! ( options [ :record ] ) : local_params end json [ 'data' ] . is_a? ( Array ) ? json [ 'data' ] : [ json [ 'data' ] ] include_context 'with \"page\" param' , options if options [ :actions ] == :index", "del_tokens": "let ( :headers ) { { 'Accept' => 'application/vnd.api+json' } } let ( :params ) { options . try ( :params ) || { } } json [ 'data' ] . is_a? ( Array ) ? json [ 'data' ] : Array ( json [ 'data' ] ) include_context 'with \"page\" param' , options", "commit_type": "fix"}
{"commit_tokens": ["Updated", "comment", "model", "mentions", "method"], "add_tokens": "FiatNotifications :: Notification :: CreateNotificationJob . set ( wait : 5 . seconds ) . perform_later ( self , self . authorable , i , \"mentioned\" , \"User\" , [ i . id ] )", "del_tokens": "FiatNotifications :: Notification :: CreateNotificationJob . set ( wait : 5 . seconds ) . perform_later ( self , self . authorable , i , \"mentioned\" , nil , nil )", "commit_type": "update"}
{"commit_tokens": ["Move", "some", "autoloads", "to", "an", "explicit", "require", "for", "the", "main", "yap", "file", "."], "add_tokens": "require 'yap/shell' require 'yap/world' module Yap", "del_tokens": "module Yap autoload :Shell , \"yap/shell\" autoload :World , \"yap/world\"", "commit_type": "move"}
{"commit_tokens": ["Add", "priority", "queue", "support", "for", "bunny", "message", "count"], "add_tokens": "if options . key? ( \"x-max-priority\" ) queue = channel . queue ( queue_name , :durable => options [ :durable ] , :arguments => { \"x-max-priority\" => options [ \"x-max-priority\" ] } ) else queue = channel . queue ( queue_name , :durable => options [ :durable ] ) end", "del_tokens": "queue = channel . queue ( queue_name , :durable => options [ :durable ] )", "commit_type": "add"}
{"commit_tokens": ["removing", "nested", "endpoints", "from", "single", "use", "cases", "realizing", "that", "they", "don", "t", "make", "much", "sense"], "add_tokens": "VERSION = '0.4.6'", "del_tokens": "VERSION = '0.4.5'", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "sql", "props", "as", "the", "file", "name", "you", "can", "write", "the", "sql", "after", "the", "file", "generation", "."], "add_tokens": "props . map ( & :camelize ) . join change = Liquigen :: Sql . new '# write your sql here, and you can remove the quote outside.' set . changes << change", "del_tokens": "\"With#{props.size}Clauses\" props . each do | sql | change = Liquigen :: Sql . new sql set . changes << change end", "commit_type": "use"}
{"commit_tokens": ["use", "saved_changes", "to", "check", "updates"], "add_tokens": "assert users ( :legacy_user ) . authenticated? ( 'my_password' ) assert users ( :legacy_user ) . saved_changes . has_key? ( :crypted_password ) assert users ( :legacy_user ) . saved_changes . has_key? ( :salt )", "del_tokens": "crypted_password = users ( :legacy_user ) . crypted_password salt = users ( :legacy_user ) . salt assert users ( :legacy_user ) . authenticated? ( 'my_password' ) users ( :legacy_user ) . reload assert_not_equal crypted_password , users ( :legacy_user ) . crypted_password assert_not_equal salt , users ( :legacy_user ) . salt", "commit_type": "use"}
{"commit_tokens": ["fix", "up", "some", "logging", "around", "backend", "discovery"], "add_tokens": "log . warn \"synapse: no backends and no default servers for service #{@name}; using previous backends: #{@backends.inspect}\" log . warn \"synapse: no backends for service #{@name}; using default servers: #{@default_servers.inspect}\" log . info \"synapse: discovered #{new_backends.length} backends for service #{@name}\"", "del_tokens": "log . warn \"synapse: no backends and no default servers for service #{@name}; using previous list: #{@backends.inspect}\" log . warn \"synapse: no backends for service #{@name}; using default backends: #{@default_servers.inspect}\" log . info \"synapse: discovered new backends for service #{@name}: #{new_backends.inspect}\"", "commit_type": "fix"}
{"commit_tokens": ["Improve", "docker", "garbage", "collect", "task"], "add_tokens": "desc 'Garbage collect unused docker data' system 'docker system prune --all --force'", "del_tokens": "desc 'Garbage collect unused docker filesystem layers' system 'docker image prune'", "commit_type": "improve"}
{"commit_tokens": ["added", "predicate", "methods", "for", "properties", "that", "let", "you", "determine", "if", "a", "property", "is", "set", "or", "not"], "add_tokens": "owner_clazz . class_eval do attr_accessor name define_method \"#{name}?\" do ! self . send ( name ) . nil? && ! self . send ( name ) . try ( :blank? ) end end", "del_tokens": "owner_clazz . send :attr_accessor , name", "commit_type": "add"}
{"commit_tokens": ["fix", "Pharos", "::", "Kube", "::", "Resource", ".", "from_file", "to", "transform", "YAML", "keys"], "add_tokens": "return new ( YAML . load_file ( path ) )", "del_tokens": "# recursively transform YAML keys to ruby attribute symbols def self . transform_yaml ( value ) case value when Hash Hash [ value . keys . map { | key | [ key . gsub ( '-' , '_' ) . to_sym , transform_yaml ( value [ key ] ) ] } ] when Array value . map { | v | transform_yaml ( v ) } else value end end return new ( transform_yaml ( YAML . load_file ( path ) ) )", "commit_type": "fix"}
{"commit_tokens": ["move", "more", "from", "old", "version"], "add_tokens": "# d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2+...+(p_i - q_i)^2+...+(p_n - q_n)^2}", "del_tokens": "#d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2+...+(p_i - q_i)^2+...+(p_n - q_n)^2}", "commit_type": "move"}
{"commit_tokens": ["Fix", "duplication", "of", "points", "on", "appending", "segment", "to", "track"], "add_tokens": "", "del_tokens": "@points . concat ( seg . points ) unless seg . nil?", "commit_type": "fix"}
{"commit_tokens": ["changed", "parent", "class", "of", "ValidationsFailedError", "to", "be", "StandardError", "and", "not", "Exception", "changed", "db", ".", "save", "to", "return", "true", "if", "not", "dirty"], "add_tokens": "class ValidationsFailedError < :: StandardError ; end return true unless document . dirty?", "del_tokens": "class ValidationsFailedError < :: Exception ; end return unless document . dirty?", "commit_type": "change"}
{"commit_tokens": ["fixed", "doc", "on", "map_csv", "to", "use", "import"], "add_tokens": "# results = import(some_string, :type => :io, :map => a_row_map) # other_results = import('/path/to/file.csv', :map => a_row_map)", "del_tokens": "# results = import_string(some_string, a_row_map) # other_results = import_csv('/path/to/file.csv', a_row_map)", "commit_type": "fix"}
{"commit_tokens": ["added", "better", "tests", "and", "fixed", "some", "bugs", "that", "the", "tests", "revealed", "and", "also", "added", "a", "default", "exceptionlist", "for", "each", "matchlist"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "info", "message", "when", "previewing", "data"], "add_tokens": "puts \"View your records at #{result.data[:url]}\"", "del_tokens": "puts \"View your records at #{result['url']}\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "on", "cutting", "passing", "size"], "add_tokens": "cut_passing_size_if_possible ( passing , @size ) . times do # This logic is used for cutting passing size. When passing size is greater # than buckets size, we can cut passing size to less than bucket size # because the buckets are circulated. # # `*` is current position. # When the bucket size is 3: # # [*, , ] # # Then when the passing = 3, position will be 0 (0-origin): # # [*, , ] -3> [ ,*, ] -2> [ , ,*] -1> [*, , ] # # Then passing = 6, position will be 0 again: # # [*, , ] -6> [ ,*, ] -5> [ , ,*] -4> [*, , ] -3> [ ,*, ] -2> [ , ,*] -1> [*, , ] # # In that case we can cut the passing size from 6 to 3. # That is \"cut passing size\" here. def cut_passing_size_if_possible ( passing , size ) if passing >= size * 2 ( passing % size ) + size else passing end end", "del_tokens": "passing = passing . div @size + @size if passing > 2 * @size passing . times do", "commit_type": "fix"}
{"commit_tokens": ["Move", "data", "store", "init", "to", "MemoryStore", "make", "it", "possible", "to", "use", "other", "data", "stores"], "add_tokens": "@data_store = options [ :data_store ] || MemoryStore . new @data_store . clear", "del_tokens": "clear_data @data_store = DataStore :: MemoryStore . new # Create containers data_store . create_dir ( [ ] , 'clients' ) data_store . create_dir ( [ ] , 'cookbooks' ) data_store . create_dir ( [ ] , 'data' ) data_store . create_dir ( [ ] , 'environments' ) data_store . create_dir ( [ ] , 'file_store' ) data_store . create_dir ( [ ] , 'nodes' ) data_store . create_dir ( [ ] , 'roles' ) data_store . create_dir ( [ ] , 'sandboxes' ) data_store . create_dir ( [ ] , 'users' ) # Set defaults data_store . create ( [ 'clients' ] , 'chef-validator' , '{ \"validator\": true }' ) data_store . create ( [ 'clients' ] , 'chef-webui' , '{ \"admin\": true }' ) data_store . create ( [ 'environments' ] , '_default' , '{ \"description\": \"The default Chef environment\" }' ) data_store . create ( [ 'users' ] , 'admin' , '{ \"admin\": true }' )", "commit_type": "move"}
{"commit_tokens": ["Fix", "spec", "names", "to", "match", "intended", "behavior"], "add_tokens": "it \"should yield\" do it \"should not yield\" do", "del_tokens": "it \"should not yield\" do it \"should yield\" do", "commit_type": "fix"}
{"commit_tokens": ["Adding", "down", "up", "and", "held"], "add_tokens": "attr_reader :scene , :up_actions , :down_actions , :held_actions @held_actions ||= Hash . new ( :_no_action ) def on_hold ( * args , & block ) options = ( args . last . is_a? ( Hash ) ? args . pop : { } ) args . each do | keystroke | @held_actions [ keystroke ] = block || lambda { | instance | send ( options [ :do ] ) } end end def trigger_held_buttons held_actions . each do | key , action | scene . instance_eval ( & action ) if scene . window . button_down? ( key ) end end def button_down ( id )", "del_tokens": "attr_reader :scene , :up_actions , :down_actions def fire_downer_events def button_down ( id ) warn \"This event currently does not fire\" end", "commit_type": "add"}
{"commit_tokens": ["add", "force_quotes", "option", "to", "FixedColumnCsvSink"], "add_tokens": "def initialize ( filename : , fields : , encoding : 'UTF-8' , force_quotes : false ) @csv = CSV . open ( filename , 'wb' , encoding : encoding , headers : true , force_quotes : force_quotes )", "del_tokens": "def initialize ( filename : , fields : , encoding : 'UTF-8' ) @csv = CSV . open ( filename , 'wb' , encoding : encoding , headers : true )", "commit_type": "add"}
{"commit_tokens": ["Updating", "the", "API", "endpoint", "to", "be", "HTTPS"], "add_tokens": "DARKSKY_API_URL = 'https://api.darkskyapp.com/v1'", "del_tokens": "DARKSKY_API_URL = 'http://api.darkskyapp.com/v1'", "commit_type": "update"}
{"commit_tokens": ["move", "connection", "management", "into", "Session", "and", "make", "threadsafe"], "add_tokens": "require '/Users/adam/rush/lib/rush'", "del_tokens": "require '/home/adam/rush/lib/rush'", "commit_type": "move"}
{"commit_tokens": ["moving", "to", "options", "to", "different", "file"], "add_tokens": "require_relative \"bootstrap_options\" @bootstrap = BootstrapForm :: BootstrapOptions . new ( options . delete ( :bootstrap ) || { } )", "del_tokens": "# Container for bootstrap specific form builder options. It controls options # that define form layout and grid sizing. class BootstrapOptions attr_reader :layout , :label_col_class , :control_col_class , :label_align_class , :inline_margin_class def initialize ( options = { } ) @layout = options [ :layout ] || \"default\" @label_col_class = options [ :label_col_class ] || \"col-sm-2\" @control_col_class = options [ :control_col_class ] || \"col-sm-10\" @label_align_class = options [ :label_align_class ] || \"text-sm-right\" @inline_margin_class = options [ :inline_margin_class ] || \"mr-sm-2\" end def horizontal? @layout . to_s == \"horizontal\" end def inline? @layout . to_s == \"inline\" end def offset_col_class label_col_class . sub ( / \\A col-( \\w +)-( \\d +) \\z / , 'offset-\\1-\\2' ) end end @bootstrap = BootstrapOptions . new ( options . delete ( :bootstrap ) || { } )", "commit_type": "move"}
{"commit_tokens": ["fixed", "workflow", "for", "worker", "unit", "tests"], "add_tokens": "workflow . class . extend ( WorkerUnitTestFlow :: ClassMethods ) module ClassMethods def terminal? ( name ) return true end", "del_tokens": "def terminal? ( name ) return true", "commit_type": "fix"}
{"commit_tokens": ["Fix", "exception", "handling", "in", "OVFManager"], "add_tokens": "nfcLease . HttpNfcLeaseAbort if nfcLease", "del_tokens": "nfcLease . HttpNfcLeaseAbort", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "specify", "question", "prefix", "."], "add_tokens": "header = \"#{@prompt.prefix}#{@question} #{render_header}\"", "del_tokens": "header = @question + Codes :: SPACE + render_header", "commit_type": "add"}
{"commit_tokens": ["update", "spec", "tests", "for", "CHEF", "-", "2161"], "add_tokens": "@formatter . call ( \"monkey\" , time , \"test\" , \"mos def\" ) . should == \"[#{time.iso8601}] monkey: mos def\\n\" end", "del_tokens": "@formatter . call ( \"monkey\" , time , \"test\" , \"mos def\" ) . should == \"[#{time.rfc2822}] monkey: mos def\\n\" end", "commit_type": "update"}
{"commit_tokens": ["moved", "attribute", "assignment", "methods", "into", "a", "dedicated", "module"], "add_tokens": "require \"kalimba/attribute_assignment\" include Kalimba :: AttributeAssignment", "del_tokens": "# Assign attributes from the given hash # # @param [Hash<[Symbol, String] => Any>] params # @param [Hash] options # @return [void] def assign_attributes ( params = { } , options = { } ) params . each { | name , value | send ( \"#{name}=\" , value ) } end", "commit_type": "move"}
{"commit_tokens": ["add", "a", "convenience", "#google", "method", "to", "oauthable", "objects"], "add_tokens": "base . send :include , InstanceMethods end end module InstanceMethods def update_access_token! ( access_token ) self . oauth_access_token = access_token self . oauth_access_token_expires_at = 59 . minutes . from_now self . save end def google GoogleAPI :: Client . new ( self )", "del_tokens": "define_method :update_access_token! do | access_token | self . oauth_access_token = access_token self . oauth_access_token_expires_at = 59 . minutes . from_now self . save end", "commit_type": "add"}
{"commit_tokens": ["Used", "Reek", "to", "refactor", "the", "project"], "add_tokens": "# The main director of the program # Directs its gametype when to retrieve information from the user setup_game main_game_loop def setup_game if @game_type . computer_goes_first? @computer_letter = O get_move_from_computer! else @computer_letter = X end @game_type . update_board end def main_game_loop [ :get_move_from_user! , :get_move_from_computer! ] . each do | command | @game_type . send ( command ) @game_type . update_board break if game_over? end end", "del_tokens": "if @game_type . computer_goes_first? @computer_letter = O get_move_from_computer! else @computer_letter = X end @game_type . update_board @game_type . get_move_from_user! @game_type . update_board break if game_over? get_move_from_computer! @game_type . update_board break if game_over?", "commit_type": "use"}
{"commit_tokens": ["Use", "rb", "-", "fsevent", "native", "support", "for", "watching", "multiple", "-", "directories", "instead", "of", "a", "workers", "-", "pool"], "add_tokens": "@worker = init_worker @worker_thread = Thread . new { @worker . run } @poll_thread = Thread . new { poll_changed_dirs } @worker . stop Thread . kill ( @worker_thread ) if @worker_thread # Initializes a FSEvent worker and adds a watcher for # each directory passed to the adapter. def init_worker worker . watch ( @directories . dup , :latency => @latency ) do | changes | changes . each { | path | @changed_dirs << path . sub ( LAST_SEPARATOR_REGEX , '' ) }", "del_tokens": "@workers = Array . new ( @directories . size ) { | i | init_worker_for ( @directories [ i ] ) } @workers_pool = @workers . map { | w | Thread . new { w . run } } @poll_thread = Thread . new { poll_changed_dirs } @workers . map ( & :stop ) @workers_pool . map { | t | Thread . kill ( t ) if t } # Initializes a FSEvent worker for a given directory # and sets its callback. # # @param [String] directory the directory to be watched def init_worker_for ( directory ) worker . watch ( directory , :latency => @latency ) do | directories | directories . each { | path | @changed_dirs << path . sub ( LAST_SEPARATOR_REGEX , '' ) }", "commit_type": "use"}
{"commit_tokens": ["Made", "directory", "tasks", "print", "nicer", "and", "added", "ability", "to", "pass", "args", "to", "task", "groups"], "add_tokens": "def task_group ( name , * args ) instance_exec ( * args , & description . find_task_group ( name ) )", "del_tokens": "def task_group ( name ) instance_eval ( & description . find_task_group ( name ) )", "commit_type": "make"}
{"commit_tokens": ["use", "VariaModel", "in", "JSON", "Config"], "add_tokens": "require 'chozo/errors' class JSON < Config :: Abstract class << self mass_assign ( MultiJson . decode ( json , options ) ) f . write ( self . to_json ( pretty : true ) )", "del_tokens": "module JSON extend ActiveSupport :: Concern include Chozo :: Config module ClassMethods self . attributes = MultiJson . decode ( json , options ) f . write ( self . to_json )", "commit_type": "use"}
{"commit_tokens": ["Added", "documentation", "and", "prepare", "to", "test", "navigation", "."], "add_tokens": "# Kuniri module connect all the elements and use it in the proper sequence. # @class Kuniri # @brief Kuniri class have the reference for all files and settings. # Basically this class launch the application. # @param pPath Receives the path of configuration file. If any element # is given, it tries to find in the current folder. # If the parser was already ran, entry in the navigation mode. This mode # is similar to bash terminal, however instead of see the folder # directory you can see the code. @configurationInfo # !@attribute Hash with configuration description @filesProject # !@attribute Array with object reference of all files @parser # !@attribute Execute the parser based on settings. @parserFiles # !@attribute Final output from parser. @log # !@attribute Log reference. # !@param pPath Relative path of the project. # !@param pLanguage Language extension for make the parser.", "del_tokens": "# Kuniri is the main class of the system, responsible for handling: monitoring # style, language type, and Settings. @configurationInfo @filesProject @parser @parserFiles @log", "commit_type": "add"}
{"commit_tokens": ["use", "own", "case", "equality", "code", "only", "for", "proxied", "objects"], "add_tokens": "debug { \"create new proxy class for #{klass} from #{proxy_superclass} with#{'out' unless cow} cow\" } define_case_equality klass # fix case equality for wrapped objects, kind_of?(klass) works, but klass === was failing def define_case_equality ( klass ) class << klass def === ( obj ) CowProxy :: Base === obj ? obj . kind_of? ( self ) : super ( obj ) end end end", "del_tokens": "debug do \"create new proxy class for #{klass}#{\" from #{proxy_superclass}\" if proxy_superclass} with\" \"#{'out' unless cow} cow\" end # fix case equality for wrapped objects, kind_of?(klass) works, but klass === was failing class << klass def === ( obj ) obj . kind_of? ( self ) end end", "commit_type": "use"}
{"commit_tokens": ["Add", "limit", "buy", "market", "buy", "cancel", "order"], "add_tokens": "# book - optional, book to return orders for. Default btc_cad. # group - optional, group orders with the same price (0 - false; 1 - true). Default: 1. def order_book params = { }", "del_tokens": "# - Optional fields - # book - book to return orders for. Default btc_cad. # group - group orders with the same price (0 - false; 1 - true). Default: 1. def order_book ( params = { } )", "commit_type": "add"}
{"commit_tokens": ["implement", "LightIO", "::", "Library", "::", "Mutex"], "add_tokens": "require_relative 'mutex' def exclusive ( & blk ) @thread_mutex . synchronize ( & blk ) @thread_mutex = LightIO :: Library :: Mutex . new", "del_tokens": "# TODO implement def exclusive raise \"not implement\" yield", "commit_type": "implement"}
{"commit_tokens": ["added", "support", "for", "namespace", "settings"], "add_tokens": "def namespace = ( value ) @namespace = value end @namespace || Tml . config . cache [ :namespace ] || Tml . config . application [ :key ] [ 0 .. 5 ]", "del_tokens": "Tml . config . cache [ :namespace ] || Tml . config . application [ :key ] [ 0 .. 5 ]", "commit_type": "add"}
{"commit_tokens": ["Add", "label", "filter", "and", "hook", "it", "to", "command", "line"], "add_tokens": "require \"rof/filters/label\"", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "<p", ">", "instead", "of", "<caption", ">"], "add_tokens": "puts %Q[<p class=\"listcaption\">リスト#{getChap}#{@chapter.list(id).number}: #{escape_html(caption)}</p>] puts %Q[<p class=\"sourcecaption\">#{escape_html(caption)}</p>] puts %Q(<p class=\"emlistcaption\">#{caption}</p>) unless caption . nil? puts %Q[<p class=\"imagecaption\">] puts %Q[</p>] table_begin rows . first . size puts %Q[<p class=\"tablecaption\">表#{getChap}#{@chapter.table(id).number}: #{escape_html(caption)}</p>] puts \"<p class='notecaption'>#{escape_html(caption)}</p>\" unless caption . nil?", "del_tokens": "puts %Q[<caption class=\"list\">リスト#{getChap}#{@chapter.list(id).number}: #{escape_html(caption)}</caption>] puts %Q[<caption class=\"source\">#{escape_html(caption)}</caption>] puts %Q(<caption class=\"emlist\">#{caption}</caption>) unless caption . nil? puts %Q[<caption class=\"image\">] puts %Q[</caption>] table_begin rows . first . size puts \"<thead>\" puts \"</thead>\" puts \"<tbody>\" puts \"</tbody>\" puts \"<tbody>\" puts \"</tbody>\" puts %Q[<caption=\"table\">表#{getChap}#{@chapter.table(id).number}: #{escape_html(caption)}</caption>] puts \"<caption class='note'>#{escape_html(caption)}</caption>\" unless caption . nil?", "commit_type": "use"}
{"commit_tokens": ["Use", "Code", "Climate", "s", "coverage", "tracking"], "add_tokens": "begin require 'codeclimate-test-reporter' CodeClimate :: TestReporter . start rescue LoadError end", "del_tokens": "require 'simplecov' SimpleCov . command_name 'RSpec'", "commit_type": "use"}
{"commit_tokens": ["removed", "completion", "handler", "and", "return", "driver", "from", "initalization"], "add_tokens": "@driver # Decide whether to execute specs in parallel or not # @param [String] platform # @param [int] threads # @param [String] spec_path # @param [boolean] parallel", "del_tokens": "# Decide where to execute specs in parallel or not completion = args [ :completion ] completion unless completion . nil? # Execute a completion handler", "commit_type": "remove"}
{"commit_tokens": ["Added", ":", "uri", "to", "InstanceMethods#redisinfo"], "add_tokens": ":uri => self . class . uri , :db => self . class . db ,", "del_tokens": ":db => self . class . db || 0 ,", "commit_type": "add"}
{"commit_tokens": ["Move", "attributes_for_index", "and", "attributes_for_form", "to", "Resource", "module"], "add_tokens": "if defined? ( self . class :: ATTRIBUTES_FOR_INDEX ) @resource . attributes_for_index = self . class :: ATTRIBUTES_FOR_INDEX end if defined? ( self . class :: ATTRIBUTES_FOR_FORM ) @resource . attributes_for_form = self . class :: ATTRIBUTES_FOR_FORM end if defined? ( self . class :: RESOURCE_MODEL ) self . class :: RESOURCE_MODEL else controller_name . classify . constantize end params . require ( @resource . model_name . param_key ) . permit ( * @resource . attributes_for_form . map ( & :strong_parameter ) )", "del_tokens": "@attributes_for_index = attributes_for_index @attributes_for_form = attributes_for_form def attributes_for_index self . class :: ATTRIBUTES_FOR_INDEX rescue NameError @resource . collect_attributes . reject do | a | %w( created_at updated_at ) . include? ( a . name ) end end def attributes_for_form self . class :: ATTRIBUTES_FOR_FORM rescue NameError @resource . collect_attributes . reject do | a | %w( id created_at updated_at ) . include? ( a . name ) end end self . class :: RESOURCE_MODEL rescue NameError controller_name . classify . constantize params . require ( @resource . model_name . param_key ) . permit ( * attributes_for_form . map ( & :strong_parameter ) )", "commit_type": "move"}
{"commit_tokens": ["Added", "spec", "for", "cmd", "/", "orignate", ".", "rb"], "add_tokens": "Log . debug \"Trying load paths\" if found_command_path = LOAD_PATH . detect { | command_path | File . file? ( File . join ( command_path , \"#{command}.rb\" ) ) } command_file = Pathname . new ( found_command_path ) . join ( command ) Log . debug \"Trying to load #{command_file}\" load command_file . to_s + \".rb\"", "del_tokens": "if command_file = LOAD_PATH . detect { | command_path | File . file? ( File . join ( command_path , \"#{command}.rb\" ) ) } load command_file", "commit_type": "add"}
{"commit_tokens": ["make", "insert_hash_helper", "quote", "the", "field", "names", "for", "insert", "in", "case", "you", "are", "using", "a", "reserved", "word", "for", "a", "column", "name"], "add_tokens": "insert ( \"#{keyword} INTO #{table} (`#{names.join('`,`')}`) VALUES (#{values.join(',')})\" )", "del_tokens": "insert ( \"#{keyword} INTO #{table} (#{names.join(',')}) VALUES (#{values.join(',')})\" )", "commit_type": "make"}
{"commit_tokens": ["Adds", "optional", "db", "migrating", "to", "deploy", "command"], "add_tokens": "def deploy! ( stack_name , migrate_db = false , app_name = Momentum . config [ :app_base_name ] ) command : { name : 'deploy' , args : { 'migrate' => [ migrate_db . to_s ] } } ,", "del_tokens": "def deploy! ( stack_name , app_name = Momentum . config [ :app_base_name ] ) command : { name : 'deploy' } ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "Telegrammer", "::", "Bot#get_user_profile_photos", "documentation"], "add_tokens": "# @option params [Integer] :user_id Required. Unique identifier of the target user.", "del_tokens": "# @option params [Integer] :chat_id Required. Unique identifier of the target user.", "commit_type": "fix"}
{"commit_tokens": ["allow", "docker", "-", "compose", "run"], "add_tokens": "# Idempotently up the given services in the project. # Idempotently run a service in the project. # @param [String] service name to run # @param [String] cmd command statement to run # @param [Boolean] detached if true, to start services in the background; # otherwise, monitor logs in the foreground and shutdown on Ctrl+C # @param [Boolean] no_deps if true, just run specified services without # running the services that they depend on # @param [Array] env_vars a list of environment variables (see: -e flag) # @param [Boolean] rm remove the container when done # @raise [Error] if command fails def run ( service , * cmd , detached : false , no_deps : false , env_vars : [ ] , rm : false ) formated_vars = env_vars . map { | v | { e : v } } run! ( 'run' , { d : detached , no_deps : no_deps , rm : rm } , * formated_vars , service , cmd ) end", "del_tokens": "# Idempotently run services in the project,", "commit_type": "allow"}
{"commit_tokens": ["changed", "to", "default", "missions", "to", "anywhere"], "add_tokens": "Bond . complete ( :anywhere => / ::([A-Z][^: \\. \\( ]*)$ / ) { | e | Object . constants } Bond . complete ( :anywhere => / ( \\$ [^ \\s .]*)$ / , :search => false ) { | e |", "del_tokens": "Bond . complete ( :on => / ::([A-Z][^: \\. \\( ]*)$ / , :search => false ) { | e | Object . constants . grep ( / ^ #{ Regexp . escape ( e . matched [ 1 ] ) } / ) . collect { | f | \"::\" + f } } Bond . complete ( :on => / ( \\$ [^ \\s .]*)$ / , :search => false ) { | e |", "commit_type": "change"}
{"commit_tokens": ["Changed", "the", "code", "slightly", "to", "handle", "different", "dm", "versions", "."], "add_tokens": "@database_name = adapter . options [ 'database' ] || adapter . options [ 'path' ] [ 1 .. - 1 ]", "del_tokens": "@database_name = adapter . options [ 'path' ] [ 1 .. - 1 ]", "commit_type": "change"}
{"commit_tokens": ["removed", "copy", "-", "paste", "artifact"], "add_tokens": "# Get a hash presentation of the image.", "del_tokens": "# Get a hash presentation of the (first) image.", "commit_type": "remove"}
{"commit_tokens": ["add", "a", "description", "to", "the", "review", "request"], "add_tokens": "def create_pull_request ( username , password , branch , repo , body ) payload = { :title => branch , :base => 'master' , :head => branch , :body => body } . to_json", "del_tokens": "def create_pull_request ( username , password , branch , repo ) payload = { :title => branch , :base => 'master' , :head => branch } . to_json", "commit_type": "add"}
{"commit_tokens": ["Change", "spec", "API", "for", "adding", "browser", "/", "page", "actions", "and", "apps"], "add_tokens": "## # A Tay::Specification::BrowserAction or nil attr_reader :browser_action ## # A Tay::Specification::PageAction or nil attr_reader :page_action ## # A Tay::Specification::PackagedApp or nil attr_reader :packaged_app # Create a new Tay::Specification::BrowserAction and pass it to the block # for set up. def add_browser_action ( & block ) raise Tay :: InvalidSpecification . new ( 'Browser action already set up' ) if @browser_action @browser_action = BrowserAction . new yield @browser_action # Create a new Tay::Specification::BrowserAction and pass it to the block # for set up. def add_page_action ( & block ) raise Tay :: InvalidSpecification . new ( 'Page action already set up' ) if @page_action @page_action = PageAction . new yield @page_action # Create a new Tay::Specification::BrowserAction and pass it to the block # for set up. def add_packaged_app ( & block ) raise Tay :: InvalidSpecification . new ( 'Packaged app already set up' ) if @packaged_app @packaged_app = PackagedApp . new yield @packaged_app", "del_tokens": "# If a block is given, a new Tay::Specification::BrowserAction will be # created and passed to the block for set up. If no block is given, the # current browser action (or nil) will be returned. def browser_action if block_given? @browser_action = BrowserAction . new yield @browser_action else @browser_action end # If a block is given, a new Tay::Specification::PageAction will be # created and passed to the block for set up. If no block is given, the # current page action (or nil) will be returned. def page_action if block_given? @page_action = PageAction . new yield @page_action else @page_action end # If a block is given, a new Tay::Specification::PackagedApp will be # created and passed to the block for set up. If no block is given, the # current app (or nil) will be returned. def packaged_app if block_given? @packaged_app = PackagedApp . new yield @packaged_app else @packaged_app end", "commit_type": "change"}
{"commit_tokens": ["fixed", "issue", "for", "non", "-", "RESTful", "controllers"], "add_tokens": "if params [ \"id\" ] . to_s [ 0 ] != \"_\" && available_public_methods . include? ( params [ \"id\" ] . to_sym ) elsif ( request . delete? || params [ \"_method\" ] . to_s . upcase == 'DELETE' ) && available_methods . include? ( :delete ) && ! available_public_methods . include? ( params [ \"id\" ] . to_sym ) got_from_action = delete elsif request . get? && available_methods . include? ( :show ) got_from_action = show", "del_tokens": "if ( request . delete? || params [ \"_method\" ] . to_s . upcase == 'DELETE' ) && available_methods . include? ( :delete ) && ! available_public_methods . include? ( params [ \"id\" ] . to_sym ) got_from_action = delete elsif request . get? if params [ \"id\" ] . to_s [ 0 ] != \"_\" && available_public_methods . include? ( params [ \"id\" ] . to_sym ) elsif available_methods . include? ( :show ) got_from_action = show end", "commit_type": "fix"}
{"commit_tokens": ["added", "further", "functional", "tests", "fixture", "for", "response", "block", "debugging", "and", "further", "documentation"], "add_tokens": "attr_accessor :request_xml , :response_xml , :response_block attr_reader :three_secure", "del_tokens": "attr_accessor :request_xml attr_reader :response_xml , :three_secure", "commit_type": "add"}
{"commit_tokens": ["remove", "test_double_spec", "and", "make", "half", "of", "to_ary_spec", "pass"], "add_tokens": "Spy :: Subroutine . new ( obj , :to_ary ) . hook ( force : true ) . and_return ( :non_nil_value ) Spy :: Subroutine . new ( obj , :to_ary ) . hook ( force : true ) . and_return ( :non_nil_value ) obj = Spy . double ( 'foo' ) let ( :obj ) { Spy . double ( 'obj' ) . as_null_object } let ( :obj ) { Spy . double ( 'obj' ) }", "del_tokens": "Spy . on ( obj , :to_ary ) { :non_nil_value } Spy . on ( obj , :to_ary ) { :non_nil_value } obj = double ( 'foo' ) let ( :obj ) { double ( 'obj' ) . as_null_object } let ( :obj ) { double ( 'obj' ) }", "commit_type": "remove"}
{"commit_tokens": ["fix", "extension", "of", "shared", "object", "on", "MacOS"], "add_tokens": "sys ( \"make -j4 VERBOSE=1\" ) extension_name = \"libcouchbase.#{RbConfig::CONFIG[\"SOEXT\"]}\" extension_path = File . expand_path ( File . join ( build_dir , extension_name ) ) extension_name . gsub! ( / \\. dylib / , '.bundle' ) install_path = File . expand_path ( File . join ( __dir__ , \"..\" , \"lib\" , \"couchbase\" , extension_name ) )", "del_tokens": "require \"rbconfig\" sys ( \"make -j4\" ) extension_path = File . expand_path ( File . join ( build_dir , 'libcouchbase.so' ) ) install_path = File . expand_path ( File . join ( __dir__ , \"..\" , \"lib\" , \"couchbase\" ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "with", "event", "data", "not", "loaded", "on", "queue"], "add_tokens": ":unq => \"\" , unq = if unq . class == BSON :: OrderedHash then unq . delete \"_id\" unq . to_json end", "del_tokens": ":unq => \"type\" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "resource", "/", "collection", "pages", "and", "actions", "."], "add_tokens": "Rails . logger . debug \"User #{user.try_all(*Itsf::Backend.resource_title_methods)} is allowed to access #{permission_identifier}\" Rails . logger . debug \"User #{user.try_all(*Itsf::Backend.resource_title_methods)} is not allowed to access #{permission_identifier}\"", "del_tokens": "Rails . logger . debug \"User #{user} is allowed to access #{permission_identifier}\" Rails . logger . debug \"User #{user} is not allowed to access #{permission_identifier}\"", "commit_type": "add"}
{"commit_tokens": ["Remove", "ANSI", "quotes", "from", "query", "to", "make", "compatible", "with", "MySQL", "by", "default", "."], "add_tokens": "user . login_histories . where ( 'incline_user_login_histories.created_at <= ?' , Time . now - max_months . months ) . delete_all", "del_tokens": "user . login_histories . where ( '\"incline_user_login_histories\".\"created_at\" <= ?' , Time . now - max_months . months ) . delete_all", "commit_type": "remove"}
{"commit_tokens": ["Fix", "issue", "with", "change", "detection", "."], "add_tokens": "if update_type == :no_change false else true \"creating local\" \"updating local\" elsif update_type == :sent and @data [ 2 , 9 ] == \"+++++++++\" \"creating remote\" elsif update_type == :sent \"updating remote\" [ :checksum , :size , :timestamp , :permissions , :owner , :group , :acl ] . each do | prop |", "del_tokens": "if update_type == :message return true elsif update_type == :recv return true elsif update_type == :change return true false \"creating\" \"updating\" #[:checksum, :size, :timestamp, :permissions, :owner, :group, :acl].each do |prop| [ :checksum , :size , :permissions , :owner , :group , :acl ] . each do | prop |", "commit_type": "fix"}
{"commit_tokens": ["Fix", "created", "swagger", "json", "file"], "add_tokens": "VERSION_SWAGGER = '1.0.4' VERSION_API = '1.0.0' BASE_PATH = 'localhost:3000' @version_swagger = VERSION_SWAGGER @version_api = VERSION_API @base_path = BASE_PATH", "del_tokens": "@version_swagger = '1.0.4' @version_api = '1.0.0' @base_path = 'localhost:3000'", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", "in", "tcfg_get", "not", "using", "fully", "resolved", "config"], "add_tokens": "tcfg [ key ]", "del_tokens": "tier_code_defaults [ key ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "with", "has_many", "relationships", "not", "saving"], "add_tokens": "self . addObjectsFromArray ( [ record ] ) objects . each do | object | object . send ( \"#{self.belongs_to.class.to_s.underscore}=\" , self . belongs_to ) if self . belongs_to end", "del_tokens": "self . content << record update_properties self", "commit_type": "fix"}
{"commit_tokens": ["added", "@responsible", "to", "endpoint", "method", "modules", "built", "#build_for_show", "method", "and", "added", "catalog", "classes"], "add_tokens": "resp . header = 'fake header string (we don\\'t currently process this)' def self . show_response r = self . response r . body = { \"url\" => \"/brokerages/2\" , \"updated_at\" => \"2011-12-18T17:30:06Z\" , \"natb_member\" => true , \"name\" => \"Golden Tickets\" , \"id\" => \"2\" , \"abbreviation\" => \"Golden Tickets\" } r end", "del_tokens": "resp . header = ''", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "Loader", "module", "to", "find", "loader", "classes"], "add_tokens": "require 'key_tree/loader' loader = Loader [ type ] meta_data << { load : { type : type , type = type . to_sym unless type . nil?", "del_tokens": "loader = get_loader ( type ) meta_data << { load : { type : type . to_sym , # Get a class for loading external serialization for +type+ # +require+s the class provider if necessary. # def self . get_loader ( type ) Class . const_get ( type . upcase ) rescue NameError require type . to_s retry end", "commit_type": "use"}
{"commit_tokens": ["Moved", "vagrant", "plugin", "classes", "to", "a", "dedicated", "folder", "v1"], "add_tokens": "require 'nugrant/vagrant/v1/command/root' require 'nugrant/vagrant/v1/config/user' Vagrant . commands . register ( :user ) { Nugrant :: Vagrant :: V1 :: Command :: Root } Vagrant . config_keys . register ( :user ) { Nugrant :: Vagrant :: V1 :: Config :: User }", "del_tokens": "require 'nugrant/vagrant/command/root' require 'nugrant/vagrant/config/user' Vagrant . commands . register ( :user ) { Nugrant :: Vagrant :: Command :: Root } Vagrant . config_keys . register ( :user ) { Nugrant :: Vagrant :: Config :: User }", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "target_index_key", "config", "."], "add_tokens": "config_param :target_index_key , :string , :default => nil if @target_index_key && record [ @target_index_key ] target_index = record . delete @target_index_key elsif @logstash_format", "del_tokens": "if @logstash_format", "commit_type": "add"}
{"commit_tokens": ["Improved", "--", "help", "argument", "it", "can", "optionally", "take", "name", "of", "a", "task", "and", "provide", "useful", "informations", "about", "it"], "add_tokens": "argument ( \"-H\" , \"--help\" ) do | task_name = nil | if task_name task = Task [ task_name ] if task p task # TODO else abort \"Task #{task_name} doesn't exist\" end else Kernel . abort \"Use #{$0} -T for list of all available tasks or -i for interactive session\" end", "del_tokens": "argument ( \"-H\" , \"--help\" ) do Kernel . abort \"Use #{$0} -T for list of all available tasks or -i for interactive session\"", "commit_type": "improve"}
{"commit_tokens": ["Updated", "property", "type", "to", "use", "Integer", "instead", "of", "Fixnum", "internally"], "add_tokens": "if Integer == property . type", "del_tokens": "if Fixnum == property . type", "commit_type": "update"}
{"commit_tokens": ["make", "version", "related", "configs", "required"], "add_tokens": "required :supported_versions , [ String ] required :version_aliases , Hash required :version , String required :version , String", "del_tokens": "optional :supported_versions , [ String ] optional :version_aliases , Hash optional :version , String optional :version , String", "commit_type": "make"}
{"commit_tokens": ["Remove", "add_observer", "call", "from", "Configuration"], "add_tokens": "compare = stub ( 'compare' ) compare = stub ( 'compare' )", "del_tokens": "compare . expects ( :add_observer ) . with ( config , :add_score ) compare . expects ( :add_observer ) . with ( config , :add_score ) within . expects ( :add_observer ) . with ( config , :add_score ) compare = stub ( 'compare' , :add_observer => nil ) compare = stub ( 'compare' , :add_observer => nil )", "commit_type": "remove"}
{"commit_tokens": ["add", "pending", "test", "placeholders", "for", "variation", "support"], "add_tokens": "poop_json = %q/{\"name\":\"PILE OF POO\",\"unified\":\"1F4A9\",\"variations\":[],\"docomo\":\"\",\"au\":\"E4F5\",\"softbank\":\"E05A\",\"google\":\"FE4F4\",\"image\":\"1f4a9.png\",\"sheet_x\":11,\"sheet_y\":19,\"short_name\":\"hankey\",\"short_names\":[\"hankey\",\"poop\",\"shit\"],\"text\":null}/ @poop . variations . should eq ( [ ] ) @poop . sheet_x . should eq ( 11 ) it \"should have a flag to output forced emoji variant char encoding if requested\" describe \"#variant?\" do it \"should indicate when a character has an alternate variant encoding\" end describe \"#variant\" do it \"should return the most likely variant encoding for the char\" it \"should return null if no variant encoding for the char exists\" end end", "del_tokens": "poop_json = %q/{\"name\":\"PILE OF POO\",\"unified\":\"1F4A9\",\"docomo\":\"\",\"au\":\"E4F5\",\"softbank\":\"E05A\",\"google\":\"FE4F4\",\"image\":\"1f4a9.png\",\"sheet_x\":13,\"sheet_y\":19,\"short_name\":\"hankey\",\"short_names\":[\"hankey\",\"poop\",\"shit\"],\"text\":null}/ @poop . sheet_x . should eq ( 13 ) end", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "with", "user", "hash", "bumped", "version"], "add_tokens": "secret_string = \"#{options[:secret]}#{user_details[:id].blank? ? user_details[:email] : user_details[:id]}\"", "del_tokens": "secret_string = \"#{options[:secret]}#{user_details[:email].blank? ? user_details[:id] : user_details[:email]}\"", "commit_type": "fix"}
{"commit_tokens": ["remove", "all", "actions", "except", "new", "and", "create", "on", "users", "controller"], "add_tokens": "", "del_tokens": "before_filter :authenticate , :except => [ :new , :create ] before_filter :ensure_user_is_accessing_self , :only => [ :edit , :update , :show ] def index @users = User . find :all end def show @user = User . find params [ :id ] end def edit @user = User . find params [ :id ] end def update @user = User . find params [ :id ] if @user . update_attributes params [ :user ] flash [ :notice ] = \"User updated.\" redirect_back_or root_url else render :action => \"edit\" end end def destroy @user = User . find params [ :id ] @user . destroy redirect_to root_url end def ensure_user_is_accessing_self return if current_user and current_user . respond_to? ( :admin? ) and current_user . admin? deny_access ( 'You cannot edit that user.' , :redirect => root_url ) unless current_user . id . to_i == params [ :id ] . to_i end def url_after_update root_url end", "commit_type": "remove"}
{"commit_tokens": ["Moving", "server", "declarations", "to", "jackpot", "/", "app"], "add_tokens": "require_relative 'lib/jackpot/app'", "del_tokens": "require_relative 'lib/jackpot/server' require 'sinatra' require 'json'", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "server", "version", "detection", "[", "r5913", "]"], "add_tokens": "if compare_versions ( server_version , '1.1.0' ) >= 0 begin response = @resource [ \"class/#{@database}/#{name}\" ] . get rescue raise NotFoundError end rslt = process_response ( response , :mode => :strict ) classes = [ rslt ] else end #puts \"OOO #{classes}\"", "del_tokens": "#uuu if compare_versions('1.1.0', server_version) >= 0 # begin # response = @resource[\"class/#{@database}/#{name}\"].get # rescue # raise NotFoundError # end # rslt = process_response(response, :mode => :strict) # classes = [rslt['class']] # else #uuu # in version 1.0.0 the 'properties' are Array, not Hash # rslt = {} # classes[0]['properties'].each { |p| rslt[p['name']] = p } # classes[0]['properties'] = rslt # end", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "to", "decode", "map"], "add_tokens": "Hash [ * im_data . map ]", "del_tokens": "Hash [ im_data . map ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "rendering", "of", "provided", "values", "when", "rendering", "a", "form"], "add_tokens": "data = self . data attr_accessor :error_class , :auto_id , :initial , :data , :files", "del_tokens": "data = @data attr_accessor :error_class , :auto_id , :initial", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "to", "documentation", "and", "added", "dependency", "on", "specific", "nokogiri", "version", "due", "to", "changes", "that", "break", "rfm", "."], "add_tokens": "# * *sort_order* can be +descend+ or +ascend+ and determines the order", "del_tokens": "# * *sort_order* can be +desc+ (descending) or +asc+ (ascending) and determines the order", "commit_type": "fix"}
{"commit_tokens": ["add", "Array#find!", "find_all!", "first!", "last!"], "add_tokens": "extend ClassMethods extend ClassMethods :: Path extend ClassMethods :: Dir extend ClassMethods :: State extend ClassMethods :: Cmd include Path include State", "del_tokens": "extend ClassMethods extend ClassMethods :: Path extend ClassMethods :: Dir extend ClassMethods :: State extend ClassMethods :: Cmd include Path include State", "commit_type": "add"}
{"commit_tokens": ["Fixed", "A", "/", "B", "alternative", "choosing", "to", "work", "with", "jQuery", "(", "previously", "required", "Prototype", ".", "js", "or", "jRails", ")", "."], "add_tokens": "@completed_at ||= redis [ key ( :completed_at ) ] @completed_at && Time . at ( @completed_at . to_i )", "del_tokens": "time = redis [ key ( :completed_at ) ] time && Time . at ( time . to_i )", "commit_type": "fix"}
{"commit_tokens": ["allow", "nil", "in", "URI", "rule"], "add_tokens": "return true if uri_string . nil? uri = URI ( uri_string ) @required_parts . each do | part | if uri . send ( part ) . nil? || uri . send ( part ) . empty? return false true rescue :: URI :: InvalidURIError return false", "del_tokens": "begin uri = URI ( uri_string ) @required_parts . each do | part | if uri . send ( part ) . nil? || uri . send ( part ) . empty? return false end true rescue :: URI :: InvalidURIError => e return false", "commit_type": "allow"}
{"commit_tokens": ["Allow", "units", "to", "be", "parsed", "when", "uppercased"], "add_tokens": "unit = $3 && $3 . strip . downcase", "del_tokens": "unit = $3 && $3 . strip", "commit_type": "allow"}
{"commit_tokens": ["Added", "additional", "access", "methods", "for", "format", "parameter", "data", "."], "add_tokens": "#A format engine variable specification. #The fixed part of this variable specification. #The (optional) numeric format parameters or nil. #The (optional) parameter data as a string or an empty string. attr_reader :parm_str #Setup a variable format specification. @format = $PREMATCH + $POSTMATCH @parm_str = $MATCH if ( @parm_str ) =~ / \\. / @parms = [ @parm_str ] @format = format @parm_str = \"\" @parms = nil #Is this variable supported by the engine? #Has a width been specified? def has_width? parms end has_width? ? parms [ 0 ] . to_i : 0 end #Get the width as a string def width_str has_width? ? parms [ 0 ] : \"\" #Has a precision been specified? def has_prec? has_width? && parms . length > 1 end #Get the precision parameter. has_prec? ? parms [ 1 ] . to_i : 0 end #Get the precision as a string def prec_str has_prec? ? parms [ 1 ] : \"\" #Format onto the output string #Parse from the input string #Inspect for debugging.", "del_tokens": "# A format engine variable specification. # The fixed part of this variable specification. # The (optional) numeric format parameters. # Setup a variable format specification. @format = $PREMATCH + $POSTMATCH if ( digits = $MATCH ) =~ / \\. / @parms = [ digits ] @parms = nil @format = format # Is this variable supported by the engine? parms ? parms [ 0 ] . to_i : 0 # Get the precision parameter. ( parms && parms . length > 1 ) ? parms [ 1 ] . to_i : 0 # Format onto the output string # Parse from the input string # Inspect for debugging.", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "work", "with", "profiled", "configs"], "add_tokens": "def initialize ( config ) @current_chef_server = Cheffish . default_chef_server ( config )", "del_tokens": "def initialize @current_chef_server = Cheffish . default_chef_server", "commit_type": "add"}
{"commit_tokens": ["create", "new", "modules", "to", "extend", "as", "copy", "of", "the", "original", "role", "one"], "add_tokens": "new_role = __next_role_for ( role_mod ) def __next_role_for ( mod ) new_role = __last_role new_role ? new_role . __copy_instance_methods_from ( mod ) : __add_role_for ( mod ) def __add_role_for ( mod ) role = mod . dup role", "del_tokens": "new_role = __next_empty_role new_role . __copy_instance_methods_from ( role_mod ) def __next_empty_role __add_empty_role! unless __last_role __last_role def __add_empty_role! role = Module . new", "commit_type": "create"}
{"commit_tokens": ["Fix", "gemspec", "to", "include", "example", "/", "dir"], "add_tokens": "VERSION = \"0.9.5\"", "del_tokens": "VERSION = \"0.9.4\"", "commit_type": "fix"}
{"commit_tokens": ["add", "dry", "run", "and", "verbose", "options"], "add_tokens": "objects = deduplicate ( load_scraped_objects ) # Removes all duplicate objects and corrects any foreign keys. # # @param [Hash] objects a hash of scraped objects keyed by ID # @return [Hash] the objects without duplicates def deduplicate ( objects ) losers_to_winners = build_losers_to_winners_map ( objects ) # Remove all losers. losers_to_winners . each_key do | key | objects . delete ( key ) end # Swap the IDs of losers for the IDs of winners. objects . each do | id , object | object . foreign_keys . each do | property | value = object [ property ] if value && losers_to_winners . key? ( value ) object [ property ] = losers_to_winners [ value ] end end end objects end", "del_tokens": "objects = load_scraped_objects losers_to_winners = build_losers_to_winners_map ( objects ) # Remove all losers. losers_to_winners . each_key do | key | objects . delete ( key ) end # Swap the IDs of losers for the IDs of winners. objects . each do | id , object | object . foreign_keys . each do | property | value = object [ property ] if value && losers_to_winners . key? ( value ) object [ property ] = losers_to_winners [ value ] end end end", "commit_type": "add"}
{"commit_tokens": ["use", "polymorphic", "path", "where", "possible"], "add_tokens": "redirect_to polymorphic_path ( model_class )", "del_tokens": "redirect_to :action => 'index'", "commit_type": "use"}
{"commit_tokens": ["Added", "ability", "to", "specify", "css", "or", "js", "in", "root"], "add_tokens": "path = \"/javascripts/#{path}\" unless path =~ %r( (^/)|(://) ) # Prepend javascripts directory to path if not a full URL or the root is specified path = \"/stylesheets/#{path}\" unless path =~ %r( (^/)|(://) ) # Prepend stylesheets directory to path if not a full URL or the root is specified", "del_tokens": "path = \"/javascripts/#{path}\" unless path . include? \"://\" # Add stylesheets directory to path if not a full URL path = \"/stylesheets/#{path}\" unless path . include? \"://\" # Add stylesheets directory to path if not a full URL", "commit_type": "add"}
{"commit_tokens": ["Fix", "mutant", "double", "diff", "monkeypatch"], "add_tokens": "class Memoized # Return source # # @return [String] # # @api private # def source Unparser . unparse ( memoizer_node ( node ) ) end memoize :source end", "del_tokens": "# Return source # # @return [String] # # @api private # def source Unparser . unparse ( memoizer_node ( node ) ) end memoize :source", "commit_type": "fix"}
{"commit_tokens": ["Use", "class", "comparision", "operators", "instead", "of", "ancestors", ".", "include?", "."], "add_tokens": "else # assume number_class.ancestors.include?(Numeric) (number_class < Numeric)", "del_tokens": "else # assume number_class.ancestors.include?(Numeric)", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "BMP", "images"], "add_tokens": "\"\\x4d\\x4d\\x00\\x2a\" . force_encoding ( \"binary\" ) , \"\\x42\\x4d\" . force_encoding ( \"binary\" ) # BMP", "del_tokens": "\"\\x4d\\x4d\\x00\\x2a\" . force_encoding ( \"binary\" )", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "load", "the", "group", "object", "properly", "when", "checking", "by", "user", "memberships", "."], "add_tokens": "groups_map . each_with_object ( [ ] ) do | ( dn , group_entry ) , acc | acc << group_entry if @ldap . load_group ( group_entry ) . is_member? ( user_entry ) @ldap . search ( options )", "del_tokens": "groups_map . each_with_object ( [ ] ) do | ( dn , group ) , acc | acc << group if @ldap . group ( group ) . is_member? ( user_entry ) rs = @ldap . search ( options ) return [ ] if rs == false Array ( rs )", "commit_type": "make"}
{"commit_tokens": ["Add", "docs", "and", "helpful", "info", "to", "Humus", ".", "with_snapshot", "."], "add_tokens": "# Load this in Strata via '../Humus/lib/humus'. # Then use the Humus helper methods: # * Humus.with_snapshot(name, options = {}) # # Use this in integration tests in a CP project. # # Note: Does not ROLLBACK yet! # # @param [String] name The name of the snapshot. # @param [Hash] options Options: env, seed, rollback (not implemented yet). # # # Do something for which you need snapshot b008. environment = options [ :env ] || ENV [ 'RACK_ENV' ] || 'test' seed = options [ :seed ] || true rollback = options [ :rollback ] && raise ( \"Option :rollback not implemented yet.\" ) # If seed is falsy, just yield. if seed", "del_tokens": "# # Do something for which you needs snapshot b008. environment = options [ :env ] || ENV [ 'RACK_ENV' ] || 'test' load_dump = options [ :load_dump ] || true # If load_dump is falsy, just yield. if load_dump", "commit_type": "add"}
{"commit_tokens": ["add", "disk", "/", "partition", "representations", "&", "specs"], "add_tokens": ":systemctl => '/usr/bin/systemctl' , :parted => '/usr/sbin/parted' , :mount => '/usr/bin/mount' , :umount => '/usr/bin/umount' }", "del_tokens": ":systemctl => '/usr/bin/systemctl' }", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "check_attributes", "method", "in", "order", "to", "verify", "that", "the", "correct", "parameters", "have", "been", "passed", "into", "create_merge_request", "and", "comment_merge_request", ".", "Updating", "tests", "."], "add_tokens": "check_attributes! ( params , [ :source_branch , :target_branch , :title ] ) check_attributes! ( params , [ :note ] ) private def check_attributes! ( options , attrs ) attrs . each do | attr | unless options . has_key? ( attr ) || options . has_key? ( attr . to_s ) raise Gitlab :: Error :: MissingAttributes . new ( \"Missing '#{attr}' parameter\" ) end end end", "del_tokens": "raise ( \"Attribute source_branch is required.\" ) unless params . has_key? ( :source_branch ) raise ( \"Attribute target_branch is required.\" ) unless params . has_key? ( :target_branch ) raise ( \"Attribute title is required.\" ) unless params . has_key? ( :title ) raise ( \"Attribute note is required.\" ) unless params . has_key? ( :note )", "commit_type": "add"}
{"commit_tokens": ["added", "specs", "for", "pad_options", "private", "method"], "add_tokens": "describe \"pad_options (private method)\" do before ( :all ) do @args = [ [ :n ] , [ :n , :name ] , [ :n , :name , \"Desc\" ] , [ :n , :name , \"Desc\" , true ] , [ :name ] , [ :n , \"Desc\" ] , [ :n , true ] , [ :name , \"Desc\" ] , [ :name , true ] ] end it \"always returns an array of 4 elements\" do @args . each do | arr | args = @slop . send ( :pad_options , arr ) args . should be_kind_of ( Array ) args . size . should == 4 end end it \"ends with a true or false class object\" do @args . each do | arr | [ true , false ] . include? ( @slop . send ( :pad_options , arr ) . last ) . should be_true end end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["implement", "HostNode", "number", "reserve", "after", "save"], "add_tokens": "class Error < StandardError end field :node_number , type : Integer after_save :reserve_node_number index ( { node_id : 1 } ) index ( { labels : 1 } ) index ( { grid_id : 1 , node_number : 1 } , { unique : true , sparse : true } ) private def reserve_node_number return unless self . node_number . nil? free_numbers = self . grid . free_node_numbers begin node_number = free_numbers . shift raise Error . new ( 'Node numbers not available. Grid is full?' ) if node_number . nil? self . update_attribute ( :node_number , node_number ) rescue Moped :: Errors :: OperationFailure => exc retry end end", "del_tokens": "index ( { node_id : 1 } ) index ( { labels : 1 } )", "commit_type": "implement"}
{"commit_tokens": ["Moved", "classes", "to", "seperate", "files"], "add_tokens": "", "del_tokens": "", "commit_type": "move"}
{"commit_tokens": ["Added", "origen", "test", "command", "to", "generate", "complete", "test", "coverage", "report"], "add_tokens": "exit RSpec :: Core :: Runner . run ( [ 'spec' ] ) when \"examples\" , \"test\" if @command == \"test\" Origen . app . unload_target! require \"rspec\" result = RSpec :: Core :: Runner . run ( [ 'spec' ] ) status = status == 1 ? 1 : result end specs Run the specs ( unit tests ) , - c will enable coverage examples Run the examples ( acceptance tests ) , - c will enable coverage test Run both specs and examples , - c will enable coverage", "del_tokens": "ARGV . unshift \"spec\" # For some unidentified reason Rspec does not autorun on this version if RSpec :: Core :: Version :: STRING && RSpec :: Core :: Version :: STRING == \"2.11.1\" RSpec :: Core :: Runner . run ARGV else require \"rspec/autorun\" end exit 0 # RSpec will exit 1 automatically if a test fails when \"examples\" specs Run the specs ( tests ) , - c will enable coverage examples Run the examples , - c will enable coverage", "commit_type": "add"}
{"commit_tokens": ["Change", "incremental", "ID", "so", "that", "it", "starts", "with", "1"], "add_tokens": "update_attributes ( incremental_id : job . builds_count + 1 )", "del_tokens": "update_attributes ( incremental_id : job . builds . count )", "commit_type": "change"}
{"commit_tokens": ["Adding", "asset", "compression", "and", "reordering", "initialization"], "add_tokens": "vendor / assets / images vendor / assets / javascripts vendor / assets / stylesheets context \"with a js_compressor set\" do it \"compresses using that compressor\" do within_construct do | c | c . file \"assets/javascripts/main.js\" , \"var app = {};\" c . file \"machined.rb\" , \"config.js_compressor = :packr\" Crush :: Packr . should_receive ( :compress ) . with ( \"var app = {};\\n\" ) . and_return ( \"compressed\" ) machined . assets [ \"main.js\" ] . to_s . should == \"compressed\" end end end", "del_tokens": "vendor / assets / images vendor / assets / javascripts vendor / assets / stylesheets", "commit_type": "add"}
{"commit_tokens": ["Move", "experiment", "to", "separated", "files"], "add_tokens": "puts ( info ) if debug_mode?", "del_tokens": "return unless @debug puts info", "commit_type": "move"}
{"commit_tokens": ["Make", "options", "in", "Analects", "::", "Library", "constructor", "optional"], "add_tokens": "def initialize ( options = { } )", "del_tokens": "def initialize ( options )", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "whitelist", "exceptions", "from", "being", "sent", "to", "the", "Hoptoad", "server", "."], "add_tokens": "IGNORE_DEFAULT = [ \"ActiveRecord::RecordNotFound\" , \"CGI::Session::CookieStore::TamperedWithCookie\" ] attr_accessor :host , :port , :secure , :project_name , :filter_params , :ignore def ignore @ignore || HoptoadNotifier :: IGNORE_DEFAULT end def ignore = ( names ) @ignore = self . ignore + names end def ignore_only = ( names ) @ignore = names end notify ( exception ) unless ignored? ( exception ) def ignored? ( exception ) HoptoadNotifier . ignore . include? ( exception . class . name ) end :error_class => exception . class . name ,", "del_tokens": "attr_accessor :host , :port , :secure , :project_name , :filter_params notify ( exception )", "commit_type": "add"}
{"commit_tokens": ["Fix", "method", "detection", "in", "tests", "."], "add_tokens": "if ENV [ 'FORCE_TESTS' ] || geom_a . respond_to? ( method )", "del_tokens": "if ENV [ 'FORCE_TESTS' ] || Geos :: Geometry . method_defined? ( :methods )", "commit_type": "fix"}
{"commit_tokens": ["Add", "merge", "value", "selector", "to", "Forest#", "[]"], "add_tokens": "def [] ( key , & merger ) fetch ( key , & merger )", "del_tokens": "def [] ( key ) fetch ( key )", "commit_type": "add"}
{"commit_tokens": ["Move", "some", "stuff", "around", "break", "up", "sql", ".", "rb"], "add_tokens": "require File . dirname ( __FILE__ ) + '/../matchers/migration_matchers'", "del_tokens": "require File . dirname ( __FILE__ ) + '/../lib/spec/matchers/migration_matchers'", "commit_type": "move"}
{"commit_tokens": ["changed", "categories", "API", "to", "make", "more", "sense"], "add_tokens": "def category_names_of_subject subject , & block categories_of_subject ( subject ) . keys", "del_tokens": "# find the siblings of a subject if such a category exists def siblings_of_subject subject , & block categories_of_subject ( subject ) . values . first end def category_name_of_subject subject , & block categories_of_subject ( subject ) . keys . first", "commit_type": "change"}
{"commit_tokens": ["Allow", "editing", "of", "wiki", "pages", "."], "add_tokens": "# Edit the wiki page. # @param content [String] the new wiki page contents # @param reason [String, nil] an optional reason for editing the page def edit ( content , reason : nil ) params = { page : @attributes . fetch ( :title ) , content : content } params [ :reason ] = reason if reason @client . post ( \"/r/#{@attributes.fetch(:subreddit).display_name}/api/wiki/edit\" , params ) end sr_name = @attributes [ :subreddit ] . display_name def after_initialize return unless @attributes [ :revision_by ] @attributes [ :revision_by ] = @client . unmarshal ( @attributes [ :revision_by ] ) end", "del_tokens": "sr_name = attributes [ :subreddit ] . display_name", "commit_type": "allow"}
{"commit_tokens": ["Adding", "DataTable", "back", "in", "since", "data", "entry", "seems", "to", "be", "the", "most", "annoying", "thing", "to", "improve"], "add_tokens": "html_options = options . delete ( :html ) || { } safe_val = if col_types [ index ] == \"date\" || entry . is_a? ( Date ) elsif col_types [ index ] == \"datetime\" || entry . is_a? ( Time )", "del_tokens": "html_options = options . delete ( :html ) safe_val = if col_types [ index ] == \"date\" elsif col_types [ index ] == \"datetime\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "Gemfiles", "and", "sandbox", "for", "Rails", "4", "testing"], "add_tokens": "# require \"active_resource/railtie\"", "del_tokens": "require \"active_resource/railtie\"", "commit_type": "fix"}
{"commit_tokens": ["Make", "Resource", ".", "new", "handle", ":", "credentials", "like", "other", "methods"], "add_tokens": "@attribs = { } . with_indifferent_access attribs = attribs . dup . with_indifferent_access creds_attr = attribs . delete ( :credentials ) @api_creds = api_creds || creds_attr", "del_tokens": "@attribs = { } . with_indifferent_access @api_creds = api_creds attribs = attribs . dup . with_indifferent_access", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "collapse", "all", "array", "conversion", "tests"], "add_tokens": "conversions . register ArrayToBooleanConverter . new ( :array , :booleans ) conversions . register ArrayToBooleanConverter . new ( :array , :bools )", "del_tokens": "conversions . register ArrayToBooleanConverter . new ( :array , :boolean )", "commit_type": "change"}
{"commit_tokens": ["Fix", "when", ".", "new", "take", "a", "colorset", "option"], "add_tokens": "opt = { order : :name , dir : :+ } . merge ( opt ) @colorset = opt [ :colorset ] ? opt [ :colorset ] : build_colorset ( opt ) colorset = COLORNAMES . map do | name , _ | Colorable :: Color . new ( name ) . tap { | c | c . mode = mode }", "del_tokens": "opt = { order : :name , dir : :+ , colorset : nil } . merge ( opt ) @colorset = build_colorset ( opt ) colorset = opt [ :colorset ] || begin COLORNAMES . map { | name , _ | Colorable :: Color . new ( name ) . tap { | c | c . mode = mode } }", "commit_type": "fix"}
{"commit_tokens": ["Adds", "rescan_assets", "method", "to", "AssetGroup", "."], "add_tokens": "# @param [Fixnum] id Asset group ID to delete. # Launch adhoc scans against each group of assets per site. # # @param [Connection] connection Connection to console where asset group is configured. # @return [Array[Hash[Fixnum, Fixnum]]] Array of scan ID and engine ID # pairs for each scan launched. # def rescan_assets ( connection ) sites_ids = @devices . collect { | d | d . site_id } . uniq scans = [ ] sites_ids . each do | id | dev_ids = @devices . select { | d | d . site_id == id } . map { | d | d . id } scans << connection . site_device_scan_start ( id , dev_ids ) end scans end", "del_tokens": "# @param [FixNum] id Asset group ID to delete.", "commit_type": "add"}
{"commit_tokens": ["fixed", "specs", "corrected", "default", "attributes", "handling"], "add_tokens": "include Isimud :: Logging self . class . column_names - IGNORED_COLUMNS routing_key = isimud_model_watcher_routing_key ( action ) log \"Isimud::ModelWatcher#publish: exchange #{isimud_model_watcher_exchange} routing_key #{routing_key} payload #{payload.inspect}\" Isimud . client . publish ( isimud_model_watcher_exchange , routing_key , payload . to_json )", "del_tokens": "column_names - IGNORED_COLUMNS Isimud . client . publish ( isimud_model_watcher_exchange , isimud_model_watcher_routing_key ( action ) , payload . to_json )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "railtie", "to", "reload", "abilities", "in", "development", "."], "add_tokens": "Canard . abilities_path ||= File . expand_path ( 'app/abilities' , Rails . root ) Canard . find_abilities initializer \"canard.abilities_reloading\" , :after => \"action_dispatch.configure\" do | app | ActionDispatch :: Reloader . to_prepare { Canard . find_abilities }", "del_tokens": "initializer \"canard.find_abilities\" do | app | Canard . abilities_path ||= File . expand_path ( 'app/abilities' , Rails . root ) Canard . find_abilities", "commit_type": "update"}
{"commit_tokens": ["implement", "rake", "db", ":", "abort_if_pending_migrations"], "add_tokens": "remove_task 'db:abort_if_pending_migrations' desc \"Raises an error if there are pending migrations\" task :abort_if_pending_migrations => :environment do if defined? ActiveRecord pending_migrations = ActiveRecord :: Base . on_shard ( nil ) { ActiveRecord :: Migrator . new ( :up , 'db/migrate' ) . pending_migrations } if pending_migrations . any? puts \"You have #{pending_migrations.size} pending migrations:\" pending_migrations . each do | pending_migration | puts ' %4d %s' % [ pending_migration . version , pending_migration . name ] end abort %{Run \"rake db:migrate\" to update your database then try again.} end end end", "del_tokens": "require 'active_record_shards/migration/shard_migration'", "commit_type": "implement"}
{"commit_tokens": ["add", "batch", "operation", "support", "for", "TableService"], "add_tokens": "signature = super ( signable_string ( method , uri , headers ) ) return \"#{account_name}:#{signature}\"", "del_tokens": "super ( signable_string ( method , uri , headers ) )", "commit_type": "add"}
{"commit_tokens": ["added", "Blobber", "module", "for", "generic", "dump", "/", "load"], "add_tokens": "require 'funl/blobber' \"blob\" => Funl :: Blobber :: MSGPACK_TYPE", "del_tokens": "\"blob\" => \"msgpack\"", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "in", "agent", "handler"], "add_tokens": "if @long_running_agent_task . empty?", "del_tokens": "if @long_running_agent_task . emtpy?", "commit_type": "fix"}
{"commit_tokens": ["Removed", "some", "code", "that", "only", "served", "the", "docs"], "add_tokens": "# @param key [Object,nil] if non-nil, # constrain to elements with the name \"*key*\" # @param collection [Object,nil] if non-nil, # constrain to elements with the name \"*collection*[]\" # @param value_matcher [Object,Regexp,nil] if non-nil, # constrain to elements whose value is Object or matches Regexp # @yieldparam blk_key [Object] # @yieldparam blk_value [Object] # @yieldreturn [Boolean] if the block is present, # constrain to elements for which the block(*blk_key*, *blk_value*) # returns true # @return [Proc{AugeasElement=>Boolean}]", "del_tokens": "# @param key [Object,nil] foo # @param collection [Object,nil] bar # @param value_matcher [Object,nil] baz # @param block [MatcherBinaryPredicate,nil] # @return [Proc] see {#call} for its API # @param element [Hash] containing # * `:key` # * `:value` # @return [Boolean] whether the *element* matched def call ( element ) to_proc . call ( element ) end # An abstract class documenting the block argument to {Matcher#initialize} class MatcherBinaryPredicate < Proc # @param key [Object] # @param value [Object] # @return [Boolean] def call ( key , value ) abstract_method ( key , value ) end end", "commit_type": "remove"}
{"commit_tokens": ["add", "schema_formatter", "to", "handle", "original", "and", "revised", "key", "/", "value", "renderings", "in", "schema", "dump"], "add_tokens": "include MigrationComments :: SchemaFormatter", "del_tokens": "def render_comment ( comment ) \":comment => \\\"#{comment}\\\"\" end", "commit_type": "add"}
{"commit_tokens": ["implemented", ":", "first_at", "and", ":", "first_in", "for", "every", "jobs"], "add_tokens": "# the first time, @last will be nil @at = if @last @last + @frequency else if fi = @params [ :first_in ] Time . now . to_f + Rufus . duration_to_f ( fi ) elsif fa = @params [ :first_at ] Rufus . at_to_f ( fa ) else Time . now . to_f + @frequency end end", "del_tokens": "#@at = Time.now.to_f + @frequency @at = ( @last || Time . now . to_f ) + @frequency", "commit_type": "implement"}
{"commit_tokens": ["Changed", "to", "data", "-", "disable", "-", "tracking"], "add_tokens": "key = \"data-disable-tracking\" if link [ key ] link . remove_attribute ( key )", "del_tokens": "if link [ \"data-no-track\" ] link . remove_attribute ( \"data-no-track\" )", "commit_type": "change"}
{"commit_tokens": ["fixing", "name", "error", "reference", "to", "graphviz"], "add_tokens": "require 'ruby-graphviz'", "del_tokens": "require 'graphviz'", "commit_type": "fix"}
{"commit_tokens": ["Added", "checks", "for", "ruby", "version", "to", "determine", "wether", "or", "not", "to", "set"], "add_tokens": "$KCODE = 'UTF8' if RUBY_VERSION < '1.9' $KCODE = 'UTF8' if RUBY_VERSION < '1.9' $KCODE = 'UTF8' if RUBY_VERSION < '1.9'", "del_tokens": "$KCODE = 'UTF8' $KCODE = 'UTF8' $KCODE = 'UTF8'", "commit_type": "add"}
{"commit_tokens": ["Use", "shallow", "fetch", "when", "retrieving", "tags"], "add_tokens": "res += ` #{ ssh_cmd } git fetch --depth 1 --tags 2>&1 `", "del_tokens": "res += ` #{ ssh_cmd } git fetch --tags 2>&1 `", "commit_type": "use"}
{"commit_tokens": ["fixes", "default", "values", ";", "adds", "recommendation", "for", "caching"], "add_tokens": "@@cache = false @@cache_temp_dir = nil @@cache_expire = nil", "del_tokens": "@@cache = true @@cache_temp_dir = Rails . root . join ( 'tmp' , 'captchas' ) @@cache_expire = 1 . day", "commit_type": "fix"}
{"commit_tokens": ["Allow", "delegating", "fields", "directly", "from", "another", "class", "."], "add_tokens": "require 'flex_columns/dynamic_methods_module' methods_module . define_method ( method_name , & block ) target_module = delegating_class . _included_flex_columns_dynamic_methods_module target_module . define_method ( fcn ) do column_definition . all_fields . each do | field_definition | fdn = field_definition . name target_module . define_method ( fdn ) do flex_contents = send ( fcn ) flex_contents . send ( fdn ) end target_module . define_method ( \"#{fdn}=\" ) do | x | flex_contents = send ( fcn ) raise \"no flex contents for #{fdn.inspect}?\" unless flex_contents flex_contents . send ( \"#{fdn}=\" , x ) end end self . methods_module = FlexColumns :: DynamicMethodsModule . new ( model_class , :FlexColumnsDynamicMethods ) do methods_module . remove_all_methods! @direct_methods_defined ||= [ ]", "del_tokens": "method_name = method_name . to_s . strip . downcase dynamic_methods_defined << method_name unless dynamic_methods_defined . include? ( method_name ) methods_module . send ( :define_method , method_name , & block ) delegating_class . send ( :define_method , fcn ) do fcm = self self . methods_module = Module . new do model_class . const_set ( :FlexColumnsDynamicMethods , methods_module ) model_class . send ( :include , methods_module ) self . dynamic_methods_defined = [ ] @direct_methods_defined ||= [ ] dynamic_methods_defined . each do | method_name | methods_module . module_eval ( \"remove_method :#{method_name}\" ) end", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "the", "top", "-", "level", "static_paths", ".", "rb", "file", "."], "add_tokens": "require 'static_paths/finders' require 'static_paths/static_paths'", "del_tokens": "require 'static_paths/static'", "commit_type": "fix"}
{"commit_tokens": ["Adding", "scanner", "tests", "and", "fixes", "for", "grouped", "expressions", "marking", "as", "complete", "in", "README"], "add_tokens": "[ :capture , :named ] . include? @token", "del_tokens": "@token == :capture", "commit_type": "add"}
{"commit_tokens": ["Add", "explicit", "require", "to", "load", "contentful_model"], "add_tokens": "require 'redcarpet' require 'contentful_model'", "del_tokens": "require 'redcarpet'", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "update", "behavior", "control", "to", "the", "resource", "."], "add_tokens": "def service_template ( path , default_source , & block ) restart_on_update = options . fetch ( 'restart_on_update' , new_resource . restart_on_update ) if restart_on_update && :: File . exists? ( path ) mode = restart_on_update . to_s == 'immediately' ? :immediately : :delayed notifies :restart , new_resource , mode", "del_tokens": "def service_template ( path , default_source , notifies : true , & block ) if notifies && :: File . exists? ( path ) self . notifies ( :restart , new_resource )", "commit_type": "move"}
{"commit_tokens": ["add", "specs", "for", "arity", "logic", "in", "add_command"], "add_tokens": "before ( :each ) do end it \"loads the files in a path, and instance_evals them\" do @ctl . run ( [ \"arity\" ] ) . should == true it \"should let a loaded command declare arity\" do @ctl . run ( [ \"arity\" , \"some-arg\" ] ) . should == true end", "del_tokens": "it \"loads the files in a path, and instance_evals them\" do @ctl . load_files ( File . join ( File . dirname ( __FILE__ ) , \"data\" ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "ordering", "issue", "in", "tests"], "add_tokens": "api . resources . map ( & :name ) . sort_by ( & :to_s ) . must_equal [ :comments , :posts , :users ]", "del_tokens": "api . resources . map ( & :name ) . must_equal [ :users , :comments , :posts ]", "commit_type": "fix"}
{"commit_tokens": ["add", "enable", "/", "disable", "commands"], "add_tokens": "say \"synchronizing: \"", "del_tokens": "output . print \"synchronizing: \"", "commit_type": "add"}
{"commit_tokens": ["allow", "empty", "lines", "in", "env_file"], "add_tokens": "File . readlines ( path ) . delete_if { | line | line . start_with? ( '#' ) || line . empty? }", "del_tokens": "File . readlines ( path ) . delete_if { | line | line . start_with? ( '#' ) }", "commit_type": "allow"}
{"commit_tokens": ["Allow", "custom", "tag", "formats", "when", "searching", "GitHub", "releases"], "add_tokens": "REXML :: XPath . each ( feed , '//entry/title/text()' ) do | tag | match = config . git_tag_format . match ( tag . to_s ) next unless match version = match [ 1 ]", "del_tokens": "REXML :: XPath . each ( feed , '//entry/title[contains(.,\"-rust\")]/text()' ) do | tag | version = tag . to_s . slice ( 1 .. - 6 )", "commit_type": "allow"}
{"commit_tokens": ["change", "File", "::", "FNM_EXTGLOB", "logic"], "add_tokens": "@flags |= File :: FNM_EXTGLOB if defined? File :: FNM_EXTGLOB", "del_tokens": "@flags |= File :: FNM_EXTGLOB if string . include? '{'", "commit_type": "change"}
{"commit_tokens": ["Fixing", "issue", "with", "nested", "comments"], "add_tokens": "xml . map { | node | to_object_notation ( node ) } . compact nil", "del_tokens": "xml . map { | node | to_object_notation ( node ) } { _name : :comment }", "commit_type": "fix"}
{"commit_tokens": ["move", "seiten", "routes", "into", "mapper"], "add_tokens": "raise ActionController :: RoutingError . new ( \"Page /#{params[:page]} not found\" )", "del_tokens": "raise ActionController :: RoutingError . new ( 'Not Found' )", "commit_type": "move"}
{"commit_tokens": ["Fix", "minor", "issue", ":", "a", "question", "mark", "was", "always", "added"], "add_tokens": "if params != { } encoded_params = URI . encode_www_form ( params ) [ path , encoded_params ] . join ( \"?\" ) else path end", "del_tokens": "encoded_params = URI . encode_www_form ( params ) [ path , encoded_params ] . join ( \"?\" )", "commit_type": "fix"}
{"commit_tokens": ["Make", "hooks", "work", "in", "absence", "of", "configuration", "file"], "add_tokens": "excludes = repo_settings [ 'excludes' ] || { }", "del_tokens": "excludes = repo_settings [ 'excludes' ]", "commit_type": "make"}
{"commit_tokens": ["Adds", "specs", "for", "the", "REST", "client"], "add_tokens": "def self . authenticate ( app_id , nonce = nil ) nonce ||= client . post ( '/nonces' ) [ 'nonce' ] response = client . post ( '/sessions' , { identity_token : identity_token , app_id : app_id } ) response [ 'session_token' ] end attr_reader :token , :app_id , :block def initialize ( app_id = self . class . app_id , & block ) @app_id = self . class . normalize_id ( app_id ) @block = block authenticate url = \"https://api.layer.com#{url}\" unless url . start_with? ( 'https://api.layer.com' ) rescue Layer :: Exceptions :: AuthenticationRequired => exception authenticate ( exception . response_json [ 'data' ] [ 'nonce' ] ) retry end def authenticate ( nonce = nil ) @token = self . class . authenticate ( app_id , nonce , & block )", "del_tokens": "attr_reader :token def initialize ( app_id = self . class . app_id ) nonce = client . post ( '/nonces' ) [ 'nonce' ] @token = client . post ( '/sessions' , { identity_token : identity_token , app_id : app_id } ) [ 'session_token' ] url = \"https://api.layer.com/#{url}\" unless url . start_with? ( 'https://api.layer.com' )", "commit_type": "add"}
{"commit_tokens": ["add", "optional", "metadata", "support", "to", "QueueService", ".", "create_queue", "(", "includes", "refactor", "to", "move", "add_metadata_to_headers", "to", "StorageService", "base", "class", ")"], "add_tokens": "# metadata - Hash. A hash of user defined metadata (optional) # def create_queue ( queue_name , metadata = nil ) headers = { } add_metadata_to_headers ( metadata || { } , headers ) response = call ( :put , uri , nil , headers )", "del_tokens": "# def create_queue ( queue_name ) response = call ( :put , uri )", "commit_type": "add"}
{"commit_tokens": ["Fix", "variable", "name", "in", "examples", "/", "diff", ".", "rb"], "add_tokens": "fog = Polisher :: Gem . from_rubygems 'fog' , '1.19.0' puts fog . diff ( other )", "del_tokens": "rails = Polisher :: Gem . from_rubygems 'fog' , '1.19.0' puts rails . diff ( other )", "commit_type": "fix"}
{"commit_tokens": ["Use", "class", "instance", "variables", "instead", "of", "class", "variables", ".", "Fixes", "a", "bug", "."], "add_tokens": "def self . field ( name , type ) @fields ||= { } @fields [ name ] = type attr_reader name end def self . each_field @fields . each do | name , type | yield name , type end end self . class . each_field do | name , type | instance_variable_set \"@#{name}\" , cast ( metadata [ name . to_s ] , type )", "del_tokens": "@@fields = { } @@fields . each do | field , type | instance_variable_set \"@#{field}\" , cast ( metadata [ field . to_s ] , type ) def self . field ( name , type ) @@fields [ name ] = type attr_reader name end", "commit_type": "use"}
{"commit_tokens": ["make", "test", "working", "with", "different", "augeas", "versions"], "add_tokens": "# character possition depends on augeas version msg = / Augeas parsing error: .* at \\/ dev \\/ garbage:2:[08] /", "del_tokens": "msg = / Augeas parsing error: .* at \\/ dev \\/ garbage:2:8 /", "commit_type": "make"}
{"commit_tokens": ["Improve", "#return", "doc", "for", "Span#get_baggage_item"], "add_tokens": "# @return [String] value of the baggage item", "del_tokens": "# @return Value of the baggage item", "commit_type": "improve"}
{"commit_tokens": ["allow", "analyze", "method", "to", "accept", "a", "URL", "as", "a", "string", "check", "if", "valid", "URI"], "add_tokens": "uri? ( content ) ? url ( content ) : text ( content ) def uri? ( string ) uri = URI . parse ( string ) %w( http https ) . include? ( uri . scheme ) rescue URI :: BadURIError false rescue URI :: InvalidURIError false end", "del_tokens": "content . is_a? ( URI ) ? url ( content ) : text ( content )", "commit_type": "allow"}
{"commit_tokens": ["added", "the", "end", "of", "the", "year", "code", "for", "the", "dummy", "fiscal", "year", "cal"], "add_tokens": "def initialize def start_of_year def start_of_quarter def end_of_quarter def end_of_year ( year ) year_end = Date . new ( ( year ) , 7 , - 1 ) # July 31st wday = ( year_end . wday + 1 ) % 7 # 5 if wday > 3 ### this rounds up to the next saturday year_end += 7 - wday else # rounding down to the next saturday year_end -= wday end year_end end def start_of_month def end_of_month def start_of_week def end_of_week def weeks_in_year", "del_tokens": "def weeks_in_year def start_of_week def end_of_week def start_of_month def end_of_month def start_of_quarter def end_of_quarter def start_of_year def end_of_year", "commit_type": "add"}
{"commit_tokens": ["Add", "dependency", "gem", "version", "range", "and", "update", "readme", "doc", "."], "add_tokens": "next unless Object . const_defined? ( \"#{UlePage.module_name}::#{page_module_name}\" ) page_module = Object . const_get ( UlePage . module_name ) . const_get ( page_module_name )", "del_tokens": "next unless Object . const_defined? ( \"Page::#{page_module_name}\" ) page_module = Object . const_get ( \"Page\" ) . const_get ( page_module_name )", "commit_type": "add"}
{"commit_tokens": ["move", "exception", "at", "top", "of", "fil"], "add_tokens": "class IncompleteBufferException < Exception end", "del_tokens": "class IncompleteBufferException < Exception end", "commit_type": "move"}
{"commit_tokens": ["Move", "generated", "index", "file", "to", "stellar", "-", "base", "-", "generated"], "add_tokens": "# Automatically generated on 2015-04-07T11:38:37-07:00", "del_tokens": "# Automatically generated on 2015-04-07T10:52:07-07:00", "commit_type": "move"}
{"commit_tokens": ["added", "server", "-", "profile", "-", "template", "tests"], "add_tokens": "RSpec . describe OneviewSDK :: FCNetwork do", "del_tokens": "RSpec . describe OneviewSDK :: Client do", "commit_type": "add"}
{"commit_tokens": ["Fix", "bugs", "in", "dummy", "publishing", "and", "dummy", "environmenting"], "add_tokens": "raise \"ModernTimes::JMS::Connection has not been initialized\" unless ModernTimes :: JMS :: Connection . inited? || @@dummy_publishing", "del_tokens": "raise \"ModernTimes::JMS::Connection has not been initialized\" unless ModernTimes :: JMS :: Connection . inited?", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "default_subdomainbox", "method", "so", "that", "subdomainboxed", "pages", "cannot", "reach", "out", "to", "non", "-", "boxed", "pages"], "add_tokens": "prepend_before_filter ( lambda { subdomainbox ( :allowed => allowed ) } , options ) end def self . default_subdomainbox ( allowed ) before_filter ( lambda { default_subdomainbox ( :allowed => allowed ) } , { } ) @subdomainbox_applied = true def default_subdomainbox ( options ) subdomainbox ( options ) unless @subdomainbox_applied end", "del_tokens": "before_filter ( lambda { subdomainbox ( :allowed => allowed ) } , options )", "commit_type": "add"}
{"commit_tokens": ["adding", "a", "limit", "option", "to", "fulltext_search"], "add_tokens": "def fulltext_search ( query , max_results = nil ) ids = collection . map_reduce ( map , reduce , options ) . find ( ) . sort ( [ 'value' , - 1 ] ) ids = ids . limit ( max_results ) if ! max_results . nil? self . where ( :_id . in => ids . map { | result | result [ '_id' ] } )", "del_tokens": "def fulltext_search ( query ) ids = collection . map_reduce ( map , reduce , options ) . find ( ) . sort ( [ 'value' , - 1 ] ) . map { | result | result [ '_id' ] } self . where ( :_id . in => ids )", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "configure", "http", "adapter", "."], "add_tokens": "DEFAULT_HTTP_ADAPTER = Faraday . default_adapter", "del_tokens": "DEFAULT_HTTP_ADAPTER = :net_http", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "bug", "that", "ignores", "the", "command", "line", "option", "-", "c", "for", "css"], "add_tokens": "\"Set the path to a css file to be used (default: #{OPTIONS[:css]})\" ) do | css | OPTIONS [ :css ] = css end", "del_tokens": "\"Set the path to a css file to be used (default: #{OPTIONS[:css]})\" ) { | v | }", "commit_type": "fix"}
{"commit_tokens": ["move", "VIM", "/", "XSD", "magic", "to", "library"], "add_tokens": "device : VIM . VirtualLsiLogicController ( device : VIM . VirtualDisk ( backing : VIM . VirtualDiskFlatVer2BackingInfo ( device : VIM . VirtualE1000 ( backing : VIM . VirtualEthernetCardNetworkBackingInfo (", "del_tokens": "module V def self . method_missing sym , arg RbVmomi :: Typed . new sym . to_s , arg end end module XSD def self . method_missing sym , arg RbVmomi :: Typed . new \"xsd:#{sym}\" , arg end end device : V . VirtualLsiLogicController ( device : V . VirtualDisk ( backing : V . VirtualDiskFlatVer2BackingInfo ( device : V . VirtualE1000 ( backing : V . VirtualEthernetCardNetworkBackingInfo (", "commit_type": "move"}
{"commit_tokens": ["Add", "description", "for", "Cleverbot", "::", "Parser", "spec", "of", "support", "for", ":", "html", "format", "."], "add_tokens": "it ( 'should support format :html' ) { should be_supports_format :html }", "del_tokens": "it { should be_supports_format :html }", "commit_type": "add"}
{"commit_tokens": ["Add", "explicit", "support", "for", "HTTP", "basic", "auth", "."], "add_tokens": "query = @endpoint . path query += ( '?' + @endpoint . query ) if @endpoint . query req = Net :: HTTP :: Get . new query req . basic_auth ( @endpoint . user , @endpoint . password ) if @endpoint . user http . start { | h | h . request ( req ) } req = Net :: HTTP :: Post . new @soap . endpoint . path , http_header req . body = @soap . to_xml req . basic_auth ( @soap . endpoint . user , @soap . endpoint . password ) if @soap . endpoint . user @response = http ( @soap . endpoint ) . start { | h | h . request ( req ) }", "del_tokens": "http . get @endpoint . to_s @response = http ( @soap . endpoint ) . request_post @soap . endpoint . path , @soap . to_xml , http_header", "commit_type": "add"}
{"commit_tokens": ["Add", "Resource", "Dump", "Index", "support"], "add_tokens": "ChangeDumpIndex , ResourceDumpIndex", "del_tokens": "ChangeDumpIndex", "commit_type": "add"}
{"commit_tokens": ["Move", "account", "numbers", "to", "the", "right"], "add_tokens": "width : 140 at : [ 21 , 483 - @push_down ] , width : 240 , align : :right width : 140 at : [ 21 , 468 - @push_down ] , width : 240 , align : :right width : 140 at : [ 21 , 468 - push_iban - @push_down ] , width : 240 , align : :right", "del_tokens": "width : 240 at : [ 75 , 483 - @push_down ] , width : 240 width : 240 at : [ 75 , 468 - @push_down ] , width : 240 width : 240 at : [ 75 , 468 - push_iban - @push_down ] , width : 240", "commit_type": "move"}
{"commit_tokens": ["Added", "test", "around", "failure", "to", "send", "email"], "add_tokens": "original_error = exception_data [ :error_string ] log_prefix = \"ExceptionHandling.log_error_email rescued exception while logging #{original_error}\" $stderr . puts ( \"#{log_prefix}:\\n#{ex.class}: #{ex}\\n#{ex.backtrace.join(\"\\n\")}\" ) log_info ( log_prefix )", "del_tokens": "exception_context = exception_data [ :environment ] exception_or_string = exception_data [ :error_string ] $stderr . puts ( \"ExceptionHandling.log_error_email rescued exception while logging #{exception_context}: #{exception_or_string}:\\n#{ex.class}: #{ex}\\n#{ex.backtrace.join(\"\\n\")}\" ) log_info ( ex , \"ExceptionHandling::log_error_email rescued exception while logging #{exception_context}: #{exception_or_string}\" , nil , true )", "commit_type": "add"}
{"commit_tokens": ["Use", "RUBY_VERSION", "instead", "of", "VERSION"], "add_tokens": "if VERSION [ 0 , 3 ] == \"1.8\"", "del_tokens": "if RUBY_VERSION [ 0 , 3 ] == \"1.8\"", "commit_type": "use"}
{"commit_tokens": ["move", "message", "analyze_files", "to", "module", "RailsBestPractices", "so", "that", "others", "can", "call", "it"], "add_tokens": "files = RailsBestPractices :: analyze_files ( ARGV , options )", "del_tokens": "def expand_dirs_to_files * dirs extensions = [ 'rb' , 'erb' , 'haml' , 'builder' ] dirs . flatten . map { | p | if File . directory? p Dir [ File . join ( p , '**' , \"*.{#{extensions.join(',')}}\" ) ] else p end } . flatten end # for law_of_demeter_check def model_first_sort files files . sort { | a , b | if a =~ / models \\/ .*rb / - 1 elsif b =~ / models \\/ .*rb / 1 else a <=> b end } end # for always_add_db_index_check def add_duplicate_migrations files migration_files = files . select { | file | file . index ( \"db/migrate\" ) } ( files << migration_files ) . flatten end def ignore_files files , pattern files . reject { | file | file . index ( pattern ) } end files = expand_dirs_to_files ( ARGV ) files = model_first_sort ( files ) files = add_duplicate_migrations ( files ) [ 'vendor' , 'spec' , 'test' , 'stories' ] . each do | pattern | files = ignore_files ( files , \"#{pattern}/\" ) unless options [ pattern ] end", "commit_type": "move"}
{"commit_tokens": ["added", "short", "no", "-", "daemon", "switch"], "add_tokens": "opts . on ( \"-N\" , \"--no-daemon\" , \"Don't run in the background\" ) do", "del_tokens": "opts . on ( \"--no-daemon\" , \"Don't run in the background\" ) do", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "dependency", "on", "MessagePack", ".", "Stick", "with", "just", "Base64", "JSON", "."], "add_tokens": "urlsafe_encode64 ( to_json ) h = MultiJson . load ( decoded , :symbolize_keys => true )", "del_tokens": "urlsafe_encode64 ( to_json . to_msgpack ) unpacked = MessagePack . unpack ( decoded ) h = MultiJson . load ( unpacked , :symbolize_keys => true )", "commit_type": "remove"}
{"commit_tokens": ["Improve", "data", "integrity", "of", "database", "table"], "add_tokens": "table . integer :priority , :default => 0 , :null => false # Allows some jobs to jump to the front of the queue table . integer :attempts , :default => 0 , :null => false # Provides for retries, but still fail eventually. table . text :handler , :null => false # YAML-encoded string of the object that will do work table . text :last_error # reason for last failure (See Note below) table . datetime :run_at # When to run. Could be Time.zone.now for immediately, or sometime in the future. table . datetime :locked_at # Set when a client is working on this object table . datetime :failed_at # Set when all retries have failed (actually, by default, the record is deleted instead) table . string :locked_by # Who is working on this object (if locked) table . string :queue # The name of the queue this job is in", "del_tokens": "table . integer :priority , :default => 0 # Allows some jobs to jump to the front of the queue table . integer :attempts , :default => 0 # Provides for retries, but still fail eventually. table . text :handler # YAML-encoded string of the object that will do work table . text :last_error # reason for last failure (See Note below) table . datetime :run_at # When to run. Could be Time.zone.now for immediately, or sometime in the future. table . datetime :locked_at # Set when a client is working on this object table . datetime :failed_at # Set when all retries have failed (actually, by default, the record is deleted instead) table . string :locked_by # Who is working on this object (if locked) table . string :queue # The name of the queue this job is in", "commit_type": "improve"}
{"commit_tokens": ["Added", "features", "for", "generate", "command"], "add_tokens": "def read_support_file ( filename ) File . read ( File . join ( SUPPORT_PATH , filename ) ) end write_file filename , read_support_file ( filename ) end Then / ^the default file \"(.*?)\" should exist$ / do | filename | step %Q{a file named \"#{filename}\" should exist} step %Q{the file \"#{filename}\" should contain exactly:} , read_support_file ( filename )", "del_tokens": "write_file filename , File . read ( File . join ( SUPPORT_PATH , filename ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "on", "excon", "adapter"], "add_tokens": ":remaining => nil", "del_tokens": ":remaining => nil .", "commit_type": "fix"}
{"commit_tokens": ["Fix", "target", "for", "callable", "."], "add_tokens": "return CANCELLED unless _transition . conditions . all? { | c | c . call ( env . target ) }", "del_tokens": "return CANCELLED unless _transition . conditions . all? { | c | c . call ( env ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "to", "download", "a", "file", "version"], "add_tokens": "def download download_file || raise ( Ribose :: BadRequest ) end # Download file version # # @param space_id [UUID] The space Id # @param file_id [Integer] The file Id # @param version_id [Hash] The file version Id # @param options [Hash] Options as key and value pair # def self . download ( space_id , file_id , version_id : , ** options ) new ( file_id : file_id , space_id : space_id , resource_id : version_id , * * options , ) . download end attr_reader :output , :file_id , :space_id @output = attributes . delete ( :output ) def download_file data = Ribose :: Request . get ( resource_path , parse : false , headers : { accept : \"text/html\" } ) if data . headers [ \"status\" ] . match? ( / ^30[12] / ) fetch_and_write_to_file ( data ) end end def fetch_and_write_to_file ( data ) File . open ( output || \"download\" , \"w\" ) do | file | file << data . agent . call ( :get , data . headers [ \"location\" ] ) . data end end", "del_tokens": "attr_reader :file_id , :space_id", "commit_type": "add"}
{"commit_tokens": ["Make", "depth", "work", "on", "new", "records"], "add_tokens": "ActiveRecord :: Base . connection . select_all ( \"SELECT NLEVEL('#{ltree_path}')\" ) . cast_values . first", "del_tokens": "ltree_scope . distinct . pluck ( \"NLEVEL('#{ltree_path}')\" ) . first || nil", "commit_type": "make"}
{"commit_tokens": ["removed", "variables", ":", "size", "effect", "for", "pages", "in", "collection", "(", "stick", "to", "vars", "[", ":", "params", "]", "[", ":", "size", "]", ")"], "add_tokens": "( @variables [ :per_page ] || @variables [ :params ] && @variables [ :params ] [ :size ] || 10 ) . to_i", "del_tokens": "( @variables [ :per_page ] || @variables [ :params ] && @variables [ :params ] [ :size ] || @variables [ :size ] || 10 ) . to_i", "commit_type": "remove"}
{"commit_tokens": ["Fix", "dumb", "check", "for", "value", "presence"], "add_tokens": "if value . nil? return @table [ key ] unless @table [ key ] . nil?", "del_tokens": "unless value return @table [ key ] if @table [ key ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "when", "storing", "a", "db", "connection"], "add_tokens": "full_uri = \"#{connection_uri}/#{settings.db_name}?encoding=utf8\" return @clients [ full_uri ] if @clients [ full_uri ] . present? db = Sequel . connect ( full_uri ) @clients [ full_uri ] = db", "del_tokens": "return @clients [ connection_uri ] if @clients [ connection_uri ] . present? db = Sequel . connect ( \"#{connection_uri}/#{settings.db_name}?encoding=utf8\" ) @clients [ connection_uri ] = db", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "few", "extra", "bad", "uri", "specs"], "add_tokens": "context \"(bad uris)\" do [ \"http://\" , \"blah:\" ] . each do | uri | it \"raises an Gitable::URI::InvalidURIError with #{uri.inspect}\" do lambda { Gitable :: URI . parse ( uri ) } . should raise_error ( Gitable :: URI :: InvalidURIError ) end end", "del_tokens": "it \"raises an Gitable::URI::InvalidURIError on a bad uri\" do lambda { Gitable :: URI . parse ( \"http://\" ) } . should raise_error ( Gitable :: URI :: InvalidURIError )", "commit_type": "add"}
{"commit_tokens": ["Remove", "SingleLetterAbbr", "class", "from", "common", "lang"], "add_tokens": "@reformatted_text = text . apply ( Languages :: Common :: PossessiveAbbreviationRule , Languages :: Common :: KommanditgesellschaftRule , Languages :: Common :: SingleLetterAbbreviationRules :: All )", "del_tokens": "@reformatted_text = text . apply ( Languages :: Common :: PossessiveAbbreviationRule ) @reformatted_text = text . apply ( Languages :: Common :: KommanditgesellschaftRule ) @reformatted_text = Languages :: Common :: SingleLetterAbbreviation . new ( text : @reformatted_text ) . replace", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "fk", "lookup", "to", "handle", "singular", "or", "array", "of", "fields"], "add_tokens": "def initialize ( atable , afield , connection = nil ) puts \"table: #{atable.inspect} field:#{afield.inspect}\" @table = atable @field = afield return nil if value . nil? r = nil r = cache [ value ] puts \"resolve failed: #{value.class.name}:#{value.inspect} from: #{@table}.#{@field}\" unless r puts q r = @connection . select_value ( q ) r puts q ck = @field . kind_of? ( Array ) ? record . values_at ( * @field ) : record [ @field ] # puts \"load_cache key: #{ck.class.name}:#{ck.inspect}\" # puts \" #{@field.class.name}:#{@field.inspect}\" # puts \" #{record[@field].class.name}:#{record[@field].inspect}\" cache [ ck ] = record [ 'id' ] if @field . kind_of? ( Array ) @field else [ @field ]", "del_tokens": "def initialize ( table , field , connection = nil ) @table = table @field = field cache [ cache_key ( value ) ] @connection . select_value ( q ) cache [ cache_key ( record . values_at ( * field ) ) ] = record [ 'id' ] unless @field . kind_of? ( Array ) @field = [ @field ] @field end def cache_key ( value ) value . hash", "commit_type": "fix"}
{"commit_tokens": ["added", "arp", "table", "collection", "for", "darwin", "and", "linux"], "add_tokens": "popen4 ( \"/usr/sbin/arp -a\" ) do | pid , stdin , stdout , stderr | stdin . close stdout . each do | line | if line =~ / ^ \\S + \\( ( \\d {1,3} \\. \\d {1,3} \\. \\d {1,3} \\. \\d {1,3}) \\) at ([a-fA-F0-9 \\: ]+) on ([a-zA-Z0-9 \\. \\: \\- ]+) \\[ ( \\w +) \\] / # MAC addr really should be normalized to include all the zeroes. next unless iface [ $3 ] # this should never happen iface [ $3 ] [ :arp ] = Array . new unless iface [ $3 ] [ :arp ] iface [ $3 ] [ :arp ] << { $1 => $2 } end end end settings = Mash . new popen4 ( \"/usr/sbin/sysctl net\" ) do | pid , stdin , stdout , stderr | stdin . close stdout . each do | line | if line =~ / ^([a-zA-Z0-9 \\. \\_ ]+) \\: (.*) / # should be more selective about how these are collected. some are actually counters. should also have # normalized names between platforms for the same settings. settings [ $1 ] = $2 end end end network [ :settings ] = settings network [ :interfaces ] = iface", "del_tokens": "network [ \"interfaces\" ] = iface", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "using", "feed", "slugs", "with", "underscores"], "add_tokens": "raise StreamInputData , \"feed_slug can only contain alphanumeric characters plus underscores\" ! feed_slug [ / ^[a-zA-Z0-9_]+$ / ] . nil?", "del_tokens": "raise StreamInputData , \"feed_slug can only contain alphanumeric characters\" ! feed_slug [ / ^[^_ \\W ]+$ / ] . nil?", "commit_type": "allow"}
{"commit_tokens": ["Fix", "terminal", "resizing", "when", "using", "gusteau", "ssh"], "add_tokens": "VERSION = \"0.4.1\"", "del_tokens": "VERSION = \"0.4.0\"", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "implementation", "of", "send_typing", "and", "send_typing_abort"], "add_tokens": "# @param [TelegramChat] chat Target chat group to add a user # @param [TelegramContact] user User who would be added # @param [Block] callback Callback block that will be called when finished # @yieldparam [Hash] data The raw data of the request # Remove a user from the chat group # @param [TelegramChat] chat Target chat group to remove a user # @param [TelegramContact] user User who would be removed from the chat # @param [Block] callback Callback block that will be called when finished # @yieldparam [Hash] data The raw data of the request # Send typing signal to the chat # # @param [TelegramChat] chat Target chat group to send typing signal # @param [Block] callback Callback block that will be called when finished # @yieldparam [Bool] success The result of the request (true or false) # @yieldparam [Hash] data The raw data of the request # @since [0.1.0] # @example # telegram.send_typing('chat#1234567') do |success, data| # puts success # => true # puts data # => {\"result\": \"SUCCESS\"} # end def send_typing ( chat , & callback ) assert! @connection . communicate ( [ 'send_typing' , chat . to_tg ] , & callback ) end # Abort sendign typing signal # # @param [TelegramChat] chat Target chat group to stop sending typing signal # @param [Block] callback Callback block that will be called when finished # @yieldparam [Bool] success The result of the request (true or false) # @yieldparam [Hash] data The raw data of the request # @since [0.1.0] # @example # telegram.send_typing_abort('chat#1234567') do |success, data| # puts success # => true # puts data # => {\"result\": \"SUCCESS\"} # end def send_typing_abort ( chat , & callback ) assert! @connection . communicate ( [ 'send_typing_abort' , chat . to_tg ] , & callback ) end #", "del_tokens": "# @param [String] chat Target chat group to add a user # @param [String] user User identifier to be added # @yieldparam [Hash] data The data of the request # Remove a user to the chat group # @param [String] chat Target chat group to remove a user # @param [String] user User identifier to be removed # @yieldparam [Hash] data The data of the request", "commit_type": "add"}
{"commit_tokens": ["Add", "authorizations", "api", "commands", "."], "add_tokens": "autoload :Authorizations , 'github_cli/commands/authorizations' autoload :Blobs , 'github_cli/commands/blobs' autoload :Commits , 'github_cli/commands/commits' autoload :Downloads , 'github_cli/commands/downloads' autoload :Forks , 'github_cli/commands/forks' autoload :Hooks , 'github_cli/commands/hooks' autoload :Issues , 'github_cli/commands/issues' autoload :Keys , 'github_cli/commands/keys' autoload :Labels , 'github_cli/commands/labels' autoload :PullRequests , 'github_cli/commands/pull_requests' autoload :References , 'github_cli/commands/references' autoload :Repositories , 'github_cli/commands/repositories' autoload :Tags , 'github_cli/commands/tags' autoload :Trees , 'github_cli/commands/trees' autoload :Watching , 'github_cli/commands/watching'", "del_tokens": "autoload :Blobs , 'github_cli/commands/blobs' autoload :Commits , 'github_cli/commands/commits' autoload :Downloads , 'github_cli/commands/downloads' autoload :Forks , 'github_cli/commands/forks' autoload :Hooks , 'github_cli/commands/hooks' autoload :Issues , 'github_cli/commands/issues' autoload :Keys , 'github_cli/commands/keys' autoload :Labels , 'github_cli/commands/labels' autoload :PullRequests , 'github_cli/commands/pull_requests' autoload :References , 'github_cli/commands/references' autoload :Repositories , 'github_cli/commands/repositories' autoload :Tags , 'github_cli/commands/tags' autoload :Trees , 'github_cli/commands/trees' autoload :Watching , 'github_cli/commands/watching'", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "code", "coverage", "on", "qualified", "command", "names", "."], "add_tokens": "class Command < Minicom :: Delegate ( __FILE__ , __LINE__ ) def run ( * args ) :help end", "del_tokens": "class Command < Minicom :: Command ( __FILE__ , __LINE__ )", "commit_type": "add"}
{"commit_tokens": ["Add", "spec", "example", "to", "make", "sure", "that", "collection", "order", "is", "persevered", "when", "updated"], "add_tokens": "object && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} READ #{key}\" ) result && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} WRITE #{key}\" )", "del_tokens": "object && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} READ #{object.class}:#{object.send(primary_key)} #{key}\" ) result && cached_resource . logger . info ( \"#{CachedResource::Configuration::LOGGER_PREFIX} WRITE #{object.class}:#{object.send(primary_key)} #{key}\" )", "commit_type": "add"}
{"commit_tokens": ["Move", "execution", "of", "cmd", "line", "stuff", "to", "configuration", "add", "codesign", "stuff"], "add_tokens": "cmd << \"xcodebuild\" cmd << \"-sdk #{@target.project.sdk}\" unless @target . project . sdk . nil? cmd << \"-project \\\"#{@target.project.path}\\\"\" execute ( cmd ) end def sign ( identity ) cmd = [ ] cmd << \"codesign\" cmd << \"--force\" cmd << \"--sign \\\"#{identity}\\\"\" cmd << \"--resource-rules=\\\"#{app_path}/ResourceRules.plist\\\"\" cmd << \"--entitlements \\\"#{entitlements_path}\\\"\" cmd << \"\\\"#{ipa_path}\\\"\" execute ( cmd ) end def entitlements_path \"#{File.dirname(@target.project.path)}/build/#{@target.productName}.build/#{name}-#{@target.project.sdk}/#{@target.productName}.build/#{@target.productName}.xcent\" cmd = [ ] cmd << \"xcrun\" cmd << \"-sdk #{@target.project.sdk.nil? ? \"iphoneos\" : @target.project.sdk}\" cmd << \"PackageApplication\" execute ( cmd ) end private def execute ( bits , show_output = true ) out = [ ] cmd = bits . join ( ' ' ) puts \"EXECUTE: #{cmd}\" IO . popen ( cmd ) do | f | f . each do | line | puts line if show_output out << line end end #puts \"RETURN: #{out.inspect}\" out", "del_tokens": "@target . project . execute_xcodebuild ( cmd . join ( ' ' ) ) cmd = [ ] @target . project . execute_package_application ( cmd . join ( ' ' ) )", "commit_type": "move"}
{"commit_tokens": ["fixing", "some", "of", "the", "indentation"], "add_tokens": "# Trends/hourly def trends_hourly ( query = { } ) end # Trends/daily def trends_daily ( query = { } ) end # Trends/weekly def trends_weekly ( query = { } ) end", "del_tokens": "# Trends/hourly def trends_hourly ( query = { } ) end # Trends/daily def trends_daily ( query = { } ) end # Trends/weekly def trends_weekly ( query = { } ) end", "commit_type": "fix"}
{"commit_tokens": ["add", "simplecov", "/", "coveralls", "to", "test", "run"], "add_tokens": "require 'simplecov' SimpleCov . start do add_filter 'test' end require 'coveralls' if ENV [ 'COVERALLS' ] Coveralls . wear! end", "del_tokens": "require 'rubygems'", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "spec", "(", "pointed", "out", "by", "lorennorman", ")"], "add_tokens": "@response = @request . get ( 'http://www.example.com/secure' , { 'HTTP_X_FORWARDED_PROTO' => 'https' } )", "del_tokens": "@response = @request . get ( 'https://www.example.com/secure' , { 'HTTP_X_FORWARDED_PROTO' => 'https' } )", "commit_type": "fix"}
{"commit_tokens": ["Updating", "RelsExtIngester", "to", "test", "fedora", "behavior"], "add_tokens": "let ( :fedora_document ) { nil } let ( :expected_content ) { \"<rdf:RDF xmlns:ns0=\\\"info:fedora/fedora-system:def/model#\\\" xmlns:ns1=\\\"info:fedora/fedora-system:def/relations-external#\\\" xmlns:rdf=\\\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\\\"><rdf:Description rdf:about=\\\"info:fedora/1234\\\"><ns0:hasModel rdf:resource=\\\"info:fedora/afmodel:Shoe\\\"/><ns1:isPartOf rdf:resource=\\\"vecnet:d217qs82g\\\"/></rdf:Description></rdf:RDF>\" } subject { described_class . new ( models : models , item : item , fedora_document : fedora_document ) } context 'without a fedora document' do its ( :call ) { should eq expected_content } end context 'with a fedora document' do let ( :fedora_document ) { double } let ( :rels_ext ) { double } it 'should save the document' do fedora_document . should_receive ( :[] ) . with ( 'RELS-EXT' ) . and_return ( rels_ext ) rels_ext . should_receive ( :content= ) . with ( expected_content ) rels_ext . should_receive ( :mimeType= ) . with ( \"application/rdf+xml\" ) rels_ext . should_receive ( :save ) subject . call end end", "del_tokens": "subject { described_class . new ( models : models , item : item , ) } its ( :call ) { should eq \"<rdf:RDF xmlns:ns0=\\\"info:fedora/fedora-system:def/model#\\\" xmlns:ns1=\\\"info:fedora/fedora-system:def/relations-external#\\\" xmlns:rdf=\\\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\\\"><rdf:Description rdf:about=\\\"info:fedora/1234\\\"><ns0:hasModel rdf:resource=\\\"info:fedora/afmodel:Shoe\\\"/><ns1:isPartOf rdf:resource=\\\"vecnet:d217qs82g\\\"/></rdf:Description></rdf:RDF>\" }", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "git", "user", "email", "to", "the", "author", "."], "add_tokens": "self . author = \"#{git_user} <#{git_email}>\" def git_user def git_email email = [ ] IO . popen ( 'git config -l | grep user.email' ) { | x | email = x . gets } email = email . gsub ( / user.email=( \\w *) / , '\\1' ) . strip end", "del_tokens": "self . author = current_git_user def current_git_user", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "consistently", "render", "content", "."], "add_tokens": "ops = [ ] ops << :escape unless multiline ops << :alignment ops << ( multiline ? :wrapping : :truncation )", "del_tokens": "ops = [ :alignment ] multiline ? ops << :wrapping : ops << :truncation", "commit_type": "change"}
{"commit_tokens": ["fixed", "cookie", "should", "include", "domain", "spec"], "add_tokens": "[ \"localhost\" , \"127.0.0.1\" , \"0.0.0.0\" ] . include? ( cookie . domain ) . should be_true", "del_tokens": "cookie . domain . should == \"localhost\"", "commit_type": "fix"}
{"commit_tokens": ["added", "current", "-", "share", "and", "removed", "some", "minor", "duplication"], "add_tokens": "@recommender ||= ShortProfile . new ( @recommendation . xpath ( './recommender' ) )", "del_tokens": "@recommender ||= Recommender . new ( @recommendation . xpath ( './recommender' ) ) end end class Recommender def initialize ( recommender ) @recommender = recommender end %w[ id first_name last_name ] . each do | f | define_method ( f . to_sym ) do @recommender . xpath ( \"./#{f.gsub(/_/,'-')}\" ) . text end", "commit_type": "add"}
{"commit_tokens": ["Make", "searches", "in", "forests", "lazy"], "add_tokens": "trees . lazy . map { | tree | tree [ key ] } . detect { | value | ! value . nil? } trees . lazy . any? { | tree | tree . key? ( key ) } trees . lazy . any? { | tree | tree . prefix? ( key ) } result = trees . lazy . detect do | tree |", "del_tokens": "tree_with_default_key ( key ) [ key ] rescue KeyError nil trees . any? { | tree | tree . key? ( key ) } trees . any? { | tree_or_forest | tree_or_forest . prefix? ( key ) } result = trees . detect do | tree |", "commit_type": "make"}
{"commit_tokens": ["Use", "correct", "template", "according", "to", "ps", "version"], "add_tokens": "# and use the appropriate template controllerContent = template . template ( \"controller-1.4.php\" , datas ) else controllerContent = template . template ( \"controller.php\" , datas ) f . write ( controllerContent )", "del_tokens": "content = template . template ( \"controller.php\" , datas ) f . write ( content )", "commit_type": "use"}
{"commit_tokens": ["Adding", "basic", "CLI", "support", "with", "the", "Thor", "gem"], "add_tokens": "require 'minimart/version' require 'minimart/mirror'", "del_tokens": "require \"minimart/version\"", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "consistent", "naming"], "add_tokens": "class StringToBooleanArrayConverter < Converter bool_converter = ArrayToBooleanArrayConverter . new ( :array , :boolean ) class ArrayToNumericArrayConverter < Converter class ArrayToBooleanArrayConverter < Converter conversions . register StringToBooleanArrayConverter . new ( :string , :bools ) conversions . register StringToBooleanArrayConverter . new ( :string , :booleans ) conversions . register ArrayToNumericArrayConverter . new ( :array , :numeric ) conversions . register ArrayToBooleanArrayConverter . new ( :array , :booleans ) conversions . register ArrayToBooleanArrayConverter . new ( :array , :bools )", "del_tokens": "class StringToBoolArrayConverter < Converter bool_converter = ArrayToBooleanConverter . new ( :array , :boolean ) class ArrayToNumericConverter < Converter class ArrayToBooleanConverter < Converter conversions . register StringToBoolArrayConverter . new ( :string , :bools ) conversions . register StringToBoolArrayConverter . new ( :string , :booleans ) conversions . register ArrayToNumericConverter . new ( :array , :numeric ) conversions . register ArrayToBooleanConverter . new ( :array , :booleans ) conversions . register ArrayToBooleanConverter . new ( :array , :bools )", "commit_type": "change"}
{"commit_tokens": ["Fix", "logging", "issue", "for", "multi", "cast", "method"], "add_tokens": "log_message ( \"#{ex.message}\" )", "del_tokens": "log ( \"#{ex.message}\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "debug", "page", ".", "Changed", "render", "to", "link", ".", "Fixed", "subheading", "formatting", "issue", "."], "add_tokens": "self << Components :: Form . new ( parent : self , id : id , context : context , ** attributes , & block )", "del_tokens": "self << Components :: Form . new ( parent : self , id : id , context : context , context : context , ** attributes , & block )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "annotated", "tag", "creation", ".", "Update", "tests", "for", "create_tag", "."], "add_tokens": "# @param [String] message Optional message for tag, creates annotated tag if specified. def create_tag ( project , tag_name , ref , message = '' ) post ( \"/projects/#{project}/repository/tags\" , body : { tag_name : tag_name , ref : ref , message : message } )", "del_tokens": "def create_tag ( project , tag_name , ref ) post ( \"/projects/#{project}/repository/tags\" , body : { tag_name : tag_name , ref : ref } )", "commit_type": "add"}
{"commit_tokens": ["add", "delayed", "jobs", "to", "the", "default", "ignored", "tables"], "add_tokens": "ignore_tables = [ / ^sitemap_ / , / _versions$ / , 'schema_migrations' , 'sessions' , 'delayed_jobs' ]", "del_tokens": "ignore_tables = [ / ^sitemap_ / , / _versions$ / , 'schema_migrations' , 'sessions' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "some", ":", "default", "and", ":", "type", "options", "."], "add_tokens": "parameter :scm , :default => DEFAULT_SCM , :type => Symbol parameter :debug , :default => false , :type => true", "del_tokens": "parameter :scm , :default => DEFAULT_SCM parameter :debug , :type => true", "commit_type": "add"}
{"commit_tokens": ["fix", "http", "requests", "according", "to", "grape", "and", "fix", "cache"], "add_tokens": "if @cache . keys . include? ( key ) && @cache [ key ] [ :expire ] >= Time . now return @cache [ key ] [ :val ] end", "del_tokens": "@cache [ key ] [ :val ] if @cache . keys . include? ( key ) && @cache [ key ] [ :expire ] < Time . now", "commit_type": "fix"}
{"commit_tokens": ["Use", "fluent", "s", "default", "port", "(", "24224", ")", "if", "it", "s", "not", "given"], "add_tokens": "FLUENT_DEFAULT_PORT = 24224 port = config . fetch ( :port , ENV [ 'MEGAPHONE_FLUENT_PORT' ] || FLUENT_DEFAULT_PORT )", "del_tokens": "port = config . fetch ( :port , ENV [ 'MEGAPHONE_FLUENT_PORT' ] )", "commit_type": "use"}
{"commit_tokens": ["Allow", "changing", "number", "of", "retries"], "add_tokens": "def self . read ( pin , type = 22 , tries = 50 ) ret = nil 1 . upto ( tries ) do", "del_tokens": "def self . read ( pin , type = 22 ) tries = 50 ret = 0 while tries > 0 do tries -= 1", "commit_type": "allow"}
{"commit_tokens": ["Make", "class_method_call", "feature", "more", "descriptive"], "add_tokens": "describe 'Changing source file with a class method call' do it 'adds class2 example when class1 changes' do", "del_tokens": "describe 'Changing source file' do it 'adds class2 example when class1 changes because of class method call' do", "commit_type": "make"}
{"commit_tokens": ["Remove", "method", "call", "chain", "in", "arabic", "lang"], "add_tokens": "txt . apply ( ReplaceColonBetweenNumbersRule , ReplaceNonSentenceBoundaryCommaRule )", "del_tokens": "txt . apply ( ReplaceColonBetweenNumbersRule ) . apply ( ReplaceNonSentenceBoundaryCommaRule )", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "Multi", "-", "parts", "URL", "params", ".", "Added", "RSpec", "test", "for", "it"], "add_tokens": "path = Rack :: Mount :: Strexp . compile ( compile_path ( path ) , { } , [ '/' ] , true )", "del_tokens": "path = Rack :: Mount :: Strexp . compile ( compile_path ( path ) )", "commit_type": "add"}
{"commit_tokens": ["move", "loading", "respondent", "list", "to", "survey", "object"], "add_tokens": "survey . load_respondents", "del_tokens": "response = Connection . request ( 'get_respondent_list' , { survey_id : survey . sm_survey_id . to_s } ) ( puts \"Error fetching respondents.\" && return ) unless response response [ 'respondents' ] . each do | respondent | SurveyRespondentDetail . parse ( survey , respondent ) end", "commit_type": "move"}
{"commit_tokens": ["add", "proxy", "support", "in", "the", "style", "of", "aws", "-", "s3"], "add_tokens": "attr_accessor :access_key_id , :secret_access_key , :use_ssl , :timeout , :debug , :proxy # * <tt>:proxy</tt> - Hash for Net::HTTP Proxy settings # { :host => \"proxy.mydomain.com\", :port => \"80, :user => \"user_a\", :password => \"secret\" } @proxy = options . fetch ( :proxy , nil ) def proxy_settings @proxy . values_at ( :host , :port , :user , :password ) unless @proxy . blank? end http = Net :: HTTP . new ( host , port , * proxy_settings )", "del_tokens": "attr_accessor :access_key_id , :secret_access_key , :use_ssl , :timeout , :debug http = Net :: HTTP . new ( host , port )", "commit_type": "add"}
{"commit_tokens": ["updating", "documentation", "for", "OAuth", "support"], "add_tokens": "# HTTP Basic Auth example client = Tuiter :: Client . new ( :authentication => :basic , :username => 'screen_name' , :password => 'password' ) # OAuth example client = Tuiter :: Client . new ( :authentication => :oauth , :consumer_key => 'YOUR_KEY' , :consumer_secret => 'YOUR_SECRET' ) rtoken = client . request_token # waits for token # stores token and secret token , secret = rtoken . token , rtoken . secret # redirect to authorize url rtoken . authorize_url # user authenticate in twitter domains # and then Twitter access the callback url with the access token access_token = client . authorize ( token , secret ) # checks if everything's ok if client . authorized? # and have fun 15 . times do client . update ( 'All work and no play makes Jack a dull boy' ) end end", "del_tokens": "client = Tuiter :: Client . new ( :username => 'screen_name' , :password => 'password' )", "commit_type": "update"}
{"commit_tokens": ["Added", "rake", "status", "-", "cat", ":", "cron", "support"], "add_tokens": "# Emails ::failed list if it is not empty def self . cron checkers = self . failed StatusCat :: StatusMailer . failure ( checkers ) . deliver unless checkers . empty? end # Constructs a checker instance given it's name # Returns an array of failed instances of ::all def self . failed self . all . map { | checker | checker . status . nil? ? nil : checker } . compact end", "del_tokens": "# Constructs a checker instance given it's name", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "for", "finding", "and", "creating", "partnership"], "add_tokens": "response = client . get clean_uri client . delete clean_uri response = client . put clean_uri , body : attributes self . client = client", "del_tokens": "response = @client . get clean_uri @client . delete clean_uri response = @client . put clean_uri , body : attributes @client = client", "commit_type": "add"}
{"commit_tokens": ["Move", "script", "command", "to", "@options"], "add_tokens": "VERSION = \"0.1.4\"", "del_tokens": "VERSION = \"0.1.3\"", "commit_type": "move"}
{"commit_tokens": ["Changed", "version", "on", "release", "script"], "add_tokens": "RELEASE = \"1.0.1\" def check_svn_up puts \"Checking svn updated\" out = ` svn up ` unless out =~ / At revision \\d + \\. / puts \"svn up failed:\" puts out exit ( 1 ) end end", "del_tokens": "RELEASE = \"1.0.0\" def check_svn_up puts \"Checking svn updated\" out = ` svn up ` unless out =~ / At revision \\d + \\. / puts \"svn up failed:\" puts out exit ( 1 ) end end", "commit_type": "change"}
{"commit_tokens": ["Added", "better", "support", "for", "uninstantiable", "schema", "classes", "."], "add_tokens": "if property_schema [ '$ref' ] schema_uri = self . uri + Addressable :: URI . parse ( property_schema [ '$ref' ] ) schema = AutoParse . schemas [ schema_uri ] if schema == nil raise ArgumentError , \"Could not find schema: #{property_schema['$ref']} \" + \"Referenced schema must be parsed first.\" end property_schema = schema . data end # Either type 'any' or we don't know what this is, # default to anything goes. define_any_property ( property_name , property_key , property_schema )", "del_tokens": "if property_schema [ '$ref' ] # Externally referenced properties may define their # type in the external schema. define_ref_property ( property_name , property_key , property_schema ) else # Either type 'any' or we don't know what this is, # default to anything goes. define_any_property ( property_name , property_key , property_schema ) end", "commit_type": "add"}
{"commit_tokens": ["Removed", "extra", "call", "to", "create", "File", ".", "Updated", "log", "information", "."], "add_tokens": "\"NCBI Blast\" ,", "del_tokens": "File . new ( @out , \"w\" ) \"Blast\" ,", "commit_type": "remove"}
{"commit_tokens": ["updated", "the", "proxy", "to", "rescue", "exceptions", "thrown", "from", "memcache", "server"], "add_tokens": "@proxied_object = @cache . get ( @cache_key ) rescue nil", "del_tokens": "@proxied_object = @cache . get ( @cache_key )", "commit_type": "update"}
{"commit_tokens": ["Add", "per_page", "param", "to", "User", "search"], "add_tokens": "# @param per_page [Integer] The number of users search result per page. (default: 10, maximum: 30) def search ( query , page = 1 , per_page = 10 ) page : page , per_page : per_page # @param per_page [Integer] The number of results per page. (default: 10, maximum: 30) # @param per_page [Integer] The number of results per page. (default: 10, maximum: 30)", "del_tokens": "def search ( query , page = 1 ) page : page # @param per_page [Integer] The number of results per page. # @param per_page [Integer] The number of results per page.", "commit_type": "add"}
{"commit_tokens": ["adds", "newly", "started", "processes", "to", "their", "own", "process", "group"], "add_tokens": "@pid = :: Process . spawn ( { 'PID_FILE' => pid_file_path } , @process . command , :out => log_file , :err => log_file , :pgroup => true ) Procodile . log ( @process . log_color , description , \"Sending TERM to #{@pid}\" )", "del_tokens": "@pid = :: Process . spawn ( { 'PID_FILE' => pid_file_path } , @process . command , :out => log_file , :err => log_file ) pid = self . pid_from_file Procodile . log ( @process . log_color , description , \"Sending TERM to #{pid}\" )", "commit_type": "add"}
{"commit_tokens": ["Changed", "load", "path", "in", "benchmark", "to", "allow", "execution", "without", "the", "gem"], "add_tokens": "$: . unshift ( File . dirname ( __FILE__ ) + \"/../../lib\" )", "del_tokens": "$: . concat [ './lib' ]", "commit_type": "change"}
{"commit_tokens": ["Add", "#close", "interface", "to", "Connection"], "add_tokens": "# * close # Note that multiple connection instances would be created # when multiple parallel threads are created in Processor class. # close the connection def close end", "del_tokens": "# Note that multiple connections would be created, # one connection for one parallel thread basically.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "controller", "for", "character", "selection"], "add_tokens": "options [ :output ] = RequestLogAnalyzer :: Output :: FixedWidth . new ( STDOUT , :width => arguments [ :report_width ] . to_i , :color => ! arguments [ :boring ] , :characters => ( arguments [ :boring ] ? :ascii : :utf ) )", "del_tokens": "options [ :colorize ] = false options [ :output ] = RequestLogAnalyzer :: Output :: FixedWidth . new ( STDOUT , :width => arguments [ :report_width ] . to_i , :color => ! arguments [ :boring ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "blocking", "mode", "to", "the", "clientAPI"], "add_tokens": "MAX_READ = 10", "del_tokens": "MQTT_CS_CONNECT_ASYNC = 3", "commit_type": "add"}
{"commit_tokens": ["Added", "snippets", "+", "unit", "tests", "."], "add_tokens": "# -- Validations ---------------------------------------------------------- should validate_presence_of ( :label ) should validate_uniqueness_of ( :label ) should_not allow_value ( \"bogus label\" ) . for ( :label ) should_not allow_value ( \"bogus^\" ) . for ( :label ) should allow_value ( \"snippet-label\" ) . for ( :label ) # -- Class Methods -------------------------------------------------------- test \"get snippet content\" do assert_equal cms_snippets ( :default ) . content , CmsSnippet . content_for ( 'default_snippet' ) assert_equal '' , CmsSnippet . content_for ( 'nonexistent_snippet' )", "del_tokens": "# Replace this with your real tests. test \"the truth\" do assert true", "commit_type": "add"}
{"commit_tokens": ["Fix", "parameter", "name", "typo", "in", "#watch_process", "(", "path", "=", ">", "pid", ")"], "add_tokens": "Watcher :: Process . new ( self , pid , flags , callback )", "del_tokens": "Watcher :: Process . new ( self , path , flags , callback )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "cache#load_dir", "as", "loading", "files", "is", "now", "done", "dynamically"], "add_tokens": "alias_method :restore_cache , :reset_cache", "del_tokens": "def restore_cache @cache . reset @cache . load_dir end", "commit_type": "remove"}
{"commit_tokens": ["Added", "#until", "s", "sister", "method", "#from", "."], "add_tokens": "# Used togeter with #each and other iteration methods to specify end of interation. # Used together with #each and other interation methods to specify start of iteration, and end will be current object. def from ( time , & block ) time = time . to_time if time . is_a? ( :: Date ) method , args = @method_chain . pop if block_given? if ! method . nil? time . until ( self ) . send ( method , * args , & block ) else time . until ( self ) end end", "del_tokens": "# Used togeter with #each to specify end of interation.", "commit_type": "add"}
{"commit_tokens": ["Move", "layout", "files", "to", "sub", "-", "folder", "and", "setup", "generic", "table", "partial"], "add_tokens": "m . template \"views/#{view_language}/index.html.#{view_language}\" , \"app/views/approvals/index.html.#{view_language}\" m . template \"views/#{view_language}/_table.html.#{view_language}\" , \"app/views/approvals/_table.html.#{view_language}\" m . directory 'config/initializers' m . template 'initializer.rb' , 'config/initializers/acts_as_approvable.rb' opt . on ( '--base BASE' , 'Base class for ApprovableController.' ) { | v | options [ :base ] = v }", "del_tokens": "m . template \"index.html.#{view_language}\" , \"app/views/approvals/index.html.#{view_language}\"", "commit_type": "move"}
{"commit_tokens": ["Use", "ActiveSupport", "::", "TestCase", "instead", "of", "Test", "::", "Unit", "::", "TestCase"], "add_tokens": "class EncryptedAttributesTest < ActiveSupport :: TestCase class EncryptedAttributesWithDifferentTargetTest < ActiveSupport :: TestCase class EncryptedAttributesWithConditionalsTest < ActiveSupport :: TestCase class ShaEncryptionTest < ActiveSupport :: TestCase class ShaWithCustomSaltEncryptionTest < ActiveSupport :: TestCase class SymmetricEncryptionTest < ActiveSupport :: TestCase class AsymmetricEncryptionTest < ActiveSupport :: TestCase", "del_tokens": "class EncryptedAttributesTest < Test :: Unit :: TestCase class EncryptedAttributesWithDifferentTargetTest < Test :: Unit :: TestCase class EncryptedAttributesWithConditionalsTest < Test :: Unit :: TestCase class ShaEncryptionTest < Test :: Unit :: TestCase class ShaWithCustomSaltEncryptionTest < Test :: Unit :: TestCase class SymmetricEncryptionTest < Test :: Unit :: TestCase class AsymmetricEncryptionTest < Test :: Unit :: TestCase", "commit_type": "use"}
{"commit_tokens": ["added", "basic", "spec", "for", "Imprint", "class"], "add_tokens": "xml_name \"Imprint\" xml_accessor :name_code_type , :from => \"NameCodeType\" , :as => Fixnum , :to_xml => ONIX :: Formatters . two_digit", "del_tokens": "xml_accessor :name_code_type , :from => \"NameCodeType\" , :as => Fixnum # should be a 2 digit num", "commit_type": "add"}
{"commit_tokens": ["Make", "jruby", "invocation", "overridable", "through", "ENV", "variable"], "add_tokens": "@jruby_invocation ||= ( ENV [ \"JRUBY_INVOCATION\" ] || \"jruby\" )", "del_tokens": "@jruby_invocation ||= \"jruby\"", "commit_type": "make"}
{"commit_tokens": ["move", "SimpleCov", "configuration", "to", "start", "block"], "add_tokens": "formatter SimpleCov :: Formatter :: MultiFormatter [ SimpleCov :: Formatter :: HTMLFormatter , Coveralls :: SimpleCov :: Formatter , ] command_name \"Unit Tests\" Coveralls . noisy = true", "del_tokens": "SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter [ SimpleCov :: Formatter :: HTMLFormatter , Coveralls :: SimpleCov :: Formatter ] Coveralls . noisy = true SimpleCov . command_name \"Unit Tests\"", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "the", "default_selector", "is", "always", "reset", "even", "if", "the", "css", "selector", "spec", "fails", "."], "add_tokens": "after do Capybara . default_selector = :xpath end", "del_tokens": "Capybara . default_selector = :xpath", "commit_type": "make"}
{"commit_tokens": ["Removed", "handler", "because", "it", "just", "duplicated", "Rack", "::", "Response", "path", "now", "must", "start", "with", "/", "and", "the", "slash", "from", "end", "is", "removed", "."], "add_tokens": "@path = env [ \"REQUEST_PATH\" ] @path . chomp! ( \"/\" ) if @path . length > 1 # so let the / just if the path is only /", "del_tokens": "@path = env [ \"REQUEST_PATH\" ] . chomp ( \"/\" )", "commit_type": "remove"}
{"commit_tokens": ["improve", "Redmine", "-", "Wiki", "namespace", "handling"], "add_tokens": "# get all projects results_projects = database . query ( \"SELECT id, identifier, name FROM projects;\" ) results_wikis = database . query ( \"SELECT id, project_id FROM wikis;\" ) results_pages = database . query ( \"SELECT id, title, wiki_id FROM wiki_pages;\" ) # get wiki for page wiki_row = nil project_row = nil results_wikis . each do | wiki | wiki_row = wiki if wiki [ \"id\" ] == row_page [ \"wiki_id\" ] end if wiki_row # get project from wiki-id results_projects . each do | project | project_row = project if project [ \"id\" ] == wiki_row [ \"project_id\" ] end end project_identifier = project_row ? project_row [ \"identifier\" ] + '/' : \"\" puts project_identifier title = project_identifier + row_page [ \"title\" ]", "del_tokens": "sql = \"SELECT id, title FROM wiki_pages;\" results_pages = database . query ( sql ) title = row_page [ \"title\" ]", "commit_type": "improve"}
{"commit_tokens": ["Add", "ability", "to", "use", "truth", "accessors", "for", "determing", "the", "identifier", "name", "."], "add_tokens": "# create :id => 1, :name => 'red' # create :id => 2, :name => 'blue' # create :id => 3, :name => 'green' else validates_uniqueness_of :name # Check whether the method is the name of an identifier in this # enumeration def method_missing ( method_id , * arguments ) if match = / ^( \\w *) \\? $ / . match ( method_id . to_s ) if identifier = self . class . find_by_name ( match [ 1 ] ) self == identifier else super end else super end end # Returns the value of the name def to_s self . name end cattr_accessor :identifiers self . identifiers = [ ] def create #:nodoc: self . class . identifiers << self @new_record = false self . id end def update #:nodoc raise NotImplementedError , 'Updates are not allowed for enumerations' end # Allow id to be assigned via ActiveRecord::Base#attributes= def attributes_protected_by_default #:nodoc: [ ]", "del_tokens": "# def self.identifiers # [ # Color.new(:id => 1, :name => 'red'), # Color.new(:id => 2, :name => 'blue') # Color.new(:id => 3, :name => 'green') # ] # end validates_uniqueness_of :name attr_accessor :id , :name # Returns a list of the identifiers being defined. This should include # an a collection of instances of this model. def identifiers [ ] end def initialize ( options = { } ) #:nodoc: options . symbolize_keys! @id , @name = options [ :id ] , options [ :name ]", "commit_type": "add"}
{"commit_tokens": ["Use", "custom", "schema", "for", "posixGroup", "tests"], "add_tokens": "custom_schemas : FIXTURES . join ( 'posixGroup.schema.ldif' ) , user_fixtures : FIXTURES . join ( 'github-with-posixGroups.ldif' ) . to_s , custom_schemas : FIXTURES . join ( 'posixGroup.schema.ldif' ) , user_fixtures : FIXTURES . join ( 'github-with-posixGroups.ldif' ) . to_s ,", "del_tokens": "user_fixtures : FIXTURES . join ( 'github-with-subgroups.ldif' ) . to_s , user_fixtures : FIXTURES . join ( 'github-with-subgroups.ldif' ) . to_s ,", "commit_type": "use"}
{"commit_tokens": ["Add", "integration", "test", "for", "find_vdc_by_name"], "add_tokens": "let ( :vdc_name ) { ENV [ 'VDC_NAME' ] } expect do end . to raise_error expect do end . to raise_error ( RestClient :: Unauthorized , / 401 Unauthorized / ) end describe \"#find_vdc_by_name\" do subject { described_class . new ( url , username , password , { } , logger ) } it \"fail if targeted vdc does not exist\" do expect { subject . find_vdc_by_name ( \"xxxx\" ) } . to raise_error end it \"find targeted vdc if it exists\" do vdc = subject . find_vdc_by_name ( vdc_name ) vdc . should_not be_nil end", "del_tokens": "# TODO: we only have the initialize funtion in client lib code now, # will add more as client lib code grow. expect { } . to raise_error ( SocketError , / nodename nor servname provided , or not known / ) expect { } . to raise_error ( RestClient :: Unauthorized , / 401 Unauthorized / )", "commit_type": "add"}
{"commit_tokens": ["Use", "shared", "code", "rather", "than", "pasted", "code", "."], "add_tokens": "require 'librarian/helpers/debug' include Helpers :: Debug", "del_tokens": "private def relative_path_to ( path ) root_module . project_relative_path_to ( path ) end def debug root_module . ui . debug \"[Librarian] #{yield}\" end", "commit_type": "use"}
{"commit_tokens": ["add", "generator", "for", "db", "migrations"], "add_tokens": "require 'ample_assets/engine' if defined? ( Rails )", "del_tokens": "require \"ample_assets/engine\"", "commit_type": "add"}
{"commit_tokens": ["Adds", "JIRA", "::", "Resource", "::", "Project", ".", "has_one", ":", "lead"], "add_tokens": "require 'jira/resource/user'", "del_tokens": "require 'jira/resource/user'", "commit_type": "add"}
{"commit_tokens": ["Made", "typhoeus", "an", "optional", "dependency", "."], "add_tokens": "hint = ( options [ :gem ] ? \"\" : \" NOTICE: Please install 'typhoeus' gem for optimal performance.\" ) puts hint", "del_tokens": "hint = ( options [ :gem ] ? \"\" : \" Please install 'typhoeus' or net-http-persistent gem for best performance.\" )", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "for", "the", "before", "and", "after", "controller", "methods", "."], "add_tokens": "# RackStep will always execute this method after processing the request # of to the specified method. The user may overwrite this method. # This can be used to check for logging or any piece of code # that must be executed after every request for this controller. def after end # A module for controllers to add basic http authentication helper method.", "del_tokens": "# A module for controllers to add basic http authentication.", "commit_type": "add"}
{"commit_tokens": ["Updated", "code", "to", "use", "autoload", ".", "Added", "primary", "dependencies", "to", "the", "gemspec", ".", "Version", "bump", "."], "add_tokens": "autoload :HashObject , \"gumdrop/hash_object\" autoload :VERSION , \"gumdrop/version\" autoload :ViewHelpers , \"gumdrop/view_helpers\" autoload :Context , \"gumdrop/context\" autoload :Content , \"gumdrop/content\" autoload :Server , \"gumdrop/server\" autoload :Generator , \"gumdrop/generator\" # base= File.dirname(__FILE__) # require \"#{base}/gumdrop/hash_object.rb\" # require \"#{base}/gumdrop/version.rb\" # require \"#{base}/gumdrop/view_helpers.rb\" # require \"#{base}/gumdrop/context.rb\" # require \"#{base}/gumdrop/content.rb\" # require \"#{base}/gumdrop/server.rb\" # require \"#{base}/gumdrop/generator.rb\"", "del_tokens": "base = File . dirname ( __FILE__ ) require \"#{base}/gumdrop/hash_object.rb\" require \"#{base}/gumdrop/version.rb\" require \"#{base}/gumdrop/view_helpers.rb\" require \"#{base}/gumdrop/context.rb\" require \"#{base}/gumdrop/content.rb\" require \"#{base}/gumdrop/server.rb\" require \"#{base}/gumdrop/generator.rb\"", "commit_type": "update"}
{"commit_tokens": ["add", "implementation", "of", "counter", "columns", "for", "Table"], "add_tokens": "COL_SPLITTER = / ,(?=[' \\w +-]*:) / # pr:: precision of number values. # rows:: rows to consider for operation. Rows that don't match the pattern # will be skipped for operation @precision = options [ :pr ] . to_i if options [ :pr ] row [ :cols ] [ column ] = @precision ? value . round ( @precision ) : value", "del_tokens": "COL_SPLITTER = / ,(?=[ \\w +]*:) / # pr:: precision of number values. Default 2 # rows: rows to consider for operation. Rows that don't match the pattern # will be skipped for operation @precision = options [ :pr ] || 2 row [ :cols ] [ column ] = value . round ( @precision )", "commit_type": "add"}
{"commit_tokens": ["Update", "conn", ".", "rb", "rdoc", "to", "yardoc"], "add_tokens": "# @param [Hash] args the arguments to consstruct the connection # @option args [String] :batch the batch options # @option args [String] :cluster the cluster # @option args [String] :config config # @example Torque 2.4.10 # @example Torque 4.2.8 # # @return [String] the name of the torque library used by the connection. # @example Glenn # @example Oakley # @example Ruby # # @return [String] the batch server # @example Glenn/Compute # 8 # @example Glenn/Oxymoron # 1:glenn # @example Oakley/Compute # 12 # @example Oakley/Oxymoron # 1:oakley # @example Ruby/Compute # 20 # # @return [String, Integer] the default ppn of the connection # @example Torque 2.4.10 # @example Torque 4.2.8/vis # # @return [String] the module command used by the connection # # @return [Integer] the connection id # Returns true if the connection id is not nil and is greater than zero. # # @return [Boolean] true if connected", "del_tokens": "# Args: # args[:batch] # args[:cluster] # args[:config] # Examples: # Examples: # Examples: # Glenn/Compute = 8 # Glenn/Oxymoron = 1:glenn # Oakley/Compute = 12 # Oakley/Oxymoron = 1:oakley # Ruby/Compute = 20 # Examples: # Returns true if the connection id is not null and is greater than zero.", "commit_type": "update"}
{"commit_tokens": ["Moving", "some", "requires", "down", "the", "tree", "to", "clean", "up", "mongoid", ".", "rb"], "add_tokens": "require \"mongoid/associations\"", "del_tokens": "require \"mongoid/associations/factory\" require \"mongoid/associations/belongs_to_association\" require \"mongoid/associations/has_many_association\" require \"mongoid/associations/has_one_association\" require \"mongoid/extensions/array/conversions\" require \"mongoid/extensions/object/conversions\"", "commit_type": "move"}
{"commit_tokens": ["Add", "checksum", "and", "multimedia", "to", "metadata", "formats"], "add_tokens": "%w( all exif ocr psd checksum multimedia )", "del_tokens": "%w( all exif ocr psd )", "commit_type": "add"}
{"commit_tokens": ["Add", "object", "removal", "to", "bulk", "operations"], "add_tokens": "if @bulk @bulk . find ( selector ) . remove else q ( selector ) . remove end", "del_tokens": "q ( selector ) . remove", "commit_type": "add"}
{"commit_tokens": ["Adds", "site", "content", "type", "as", "an", "optional", "wrapper", "for", "subpages", "."], "add_tokens": "require_relative \"sodium/site\"", "del_tokens": "require_relative \"sodium/website\"", "commit_type": "add"}
{"commit_tokens": ["Move", "dirty", "attributes", "into", "a", "new", "module", ";", "Use", "ActiveModel", "::", "Dirty", "a", "little", "better", "."], "add_tokens": "if ActiveRecord :: VERSION :: STRING < \"4.1.0\" after_commit :clear_custom_changes end send :include , Dirty :: Attributes", "del_tokens": "after_commit :clear_custom_changes # Use Rails built-in Dirty attributions to get # the easy ones. By the time we're generating # this version, this hash could already # exist with some custom changes. def changes self . custom_changes . reverse_merge super end # Use Rails' `changed?`, plus check our own custom changes # to see if an object has been modified. def changed? super || custom_changes . present? end # Similar to ActiveModel::Dirty#changes, but lets us # pass in some custom changes (such as associations) # which wouldn't be picked up by the built-in method. # # This method should only be used for adding custom changes # to the changes hash. For storing and comparing and whatnot, # use #changes as usual. # # This method basically exists just to get around the behavior # of #changes (since it sends the attribute message to the # object, which we don't always want, for associations for # example). def custom_changes @custom_changes ||= HashWithIndifferentAccess . new end private def clear_custom_changes self . custom_changes . clear end", "commit_type": "move"}
{"commit_tokens": ["Added", "documentation", "and", "some", "missing", "inspects", "."], "add_tokens": "# @param [SwissMatch::Community] agglomeration # @param [Boolean] retain_references # If set to false, :agglomeration will be set to the community_number and # :canton to the canton's license_tag. # # @return [Hash] # All properties of the community as a hash. # @private # @see Object#hash # @private # @see Object#eql?", "del_tokens": "# @param [SwissMatch::Community]", "commit_type": "add"}
{"commit_tokens": ["adding", "httmultiparty", "in", "preparation", "of", "BLOB", "/", "file", "support"], "add_tokens": "include HTTMultiParty # include HTTParty", "del_tokens": "# see https://www.truevault.com/rest-api.html for full documentation include HTTParty", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "allow", "row", "configuration", "for", "a", "single", "spinner"], "add_tokens": "@row = options [ :row ] @row ||= @multispinner . next_row", "del_tokens": "@row = nil @row = @multispinner . next_row", "commit_type": "change"}
{"commit_tokens": ["Removed", "the", "global_methods", "file", "since", "its", "name", "bothered", "me"], "add_tokens": "module OfflineMirror def app_offline? RAILS_ENV == \"offline\" end def app_online? not app_offline? end private class Internal def self . init @@config = YAML . load_file ( File . join ( RAILS_ROOT , \"config\" , \"offline_mirror.yml\" ) ) rescue @@config = { } end def self . current_group_id @@config [ :offline_group_id ] or raise \"No offline group id specified in config\" end def self . note_global_data_model ( cls ) @@global_data_models ||= [ ] @@global_data_models << cls end def self . global_data_models @@global_data_models || [ ] end def self . note_group_base_model ( cls ) raise \"You can only define one group base model\" if defined? ( @@group_base_model ) and @@group_base_model . to_s != cls . to_s @@group_base_model = cls end def self . group_base_model raise \"No group base model was specified\" unless defined? ( @@group_base_model ) @@group_base_model end def self . note_group_owned_model ( cls ) @@group_owned_models ||= [ ] @@group_owned_models << cls end def self . group_owned_models @@group_owned_models || [ ] end end end", "del_tokens": "require 'global_methods'", "commit_type": "remove"}
{"commit_tokens": ["Removing", "_", "from", "partial", "name", "and", "including", "full", "path", "."], "add_tokens": "if scope . respond_to? :logical_path name = self . class . path_translator ( scope . logical_path ) else name = self . class . path_translator ( basename ) end name = remove_underscore_from_partial_name ( name , basename ) \"#{self.class.template_destination}[\\\"#{name}\\\"] = #{self.class.template_compiler}(\\\"#{template.strip.gsub(/(\\r\\n|[\\n\\r\"'])/) { JS_ESCAPE_MAP[$1] }}\\\");\\n\" def remove_underscore_from_partial_name ( name , basename ) translated_basename = self . class . path_translator ( basename ) name . sub ( / #{ translated_basename } $ / , translated_basename [ 1 .. - 1 ] ) end", "del_tokens": "elsif scope . respond_to? :logical_path \"#{self.class.template_destination}[\\\"#{self.class.path_translator(scope.logical_path)}\\\"] = #{self.class.template_compiler}(\\\"#{template.strip.gsub(/(\\r\\n|[\\n\\r\"'])/) { JS_ESCAPE_MAP[$1] }}\\\");\\n\" \"#{self.class.template_destination}[\\\"#{self.class.path_translator(basename)}\\\"] = #{self.class.template_compiler}(\\\"#{template.strip.gsub(/(\\r\\n|[\\n\\r\"'])/) { JS_ESCAPE_MAP[$1] }}\\\");\\n\"", "commit_type": "remove"}
{"commit_tokens": ["Added", ".", "travis", ".", "yml", "revved", "version", "added", "rakefile", "for", "specs"], "add_tokens": "VERSION = \"0.1.3\"", "del_tokens": "VERSION = \"0.1.2\"", "commit_type": "add"}
{"commit_tokens": ["fix", "timediff", "and", "field", "values", "mismatch"], "add_tokens": "# also remove empty units in hqmf and AnyValue entries on TIMEDIFF fix_subset_operators ( dc ) def fix_subset_operators ( dc ) subset . value = nil if subset . type == 'TIMEDIFF' && subset . value . is_a? ( HQMF :: AnyValue )", "del_tokens": "# also remove empty units in hqmf remove_empty_unit ( dc ) def remove_empty_unit ( dc )", "commit_type": "fix"}
{"commit_tokens": ["Change", "install", "generator", "handling", "of", "secrets", ".", "yml", "."], "add_tokens": "%w( development test production ) . each do | section | missing_alias = / \\A (.* \\n )? #{ section } : \\s * \\n /m valid_alias = / \\A (.* \\n )? #{ section } : \\s * \\n <<: \\s * \\* default \\s * \\n /m if contents =~ missing_alias unless contents =~ valid_alias else say_status :missing , \"config/secrets.yml [#{section}]\" , :red", "del_tokens": "%w( development test production ) . each do | env | missing_alias = / \\A (.* \\n )? #{ env } : \\s * \\n /m valid_alias = / \\A (.* \\n )? #{ env } : \\s * \\n <<: \\s * \\* default \\s * \\n /m unless contents =~ valid_alias if contents =~ missing_alias else say_status :missing , \"config/secrets.yml [#{env}]\" , :red", "commit_type": "change"}
{"commit_tokens": ["Remove", "obsolete", "whitespaces", "test", "for", "attributes", "in", "a", "more", "flexible", "way"], "add_tokens": "@spot . respond_to? ( attribute ) . should == true", "del_tokens": "@spot . send ( attribute ) . to_s . should_not be_empty", "commit_type": "remove"}
{"commit_tokens": ["Change", "windows", "size", "detection", "to", "only", "return", "non", "-", "zero", "size"], "add_tokens": "size = [ bottom - top + 1 , right - left + 1 ] return size if nonzero_column? ( size [ 1 ] - 1 )", "del_tokens": "[ bottom - top + 1 , right - left + 1 ]", "commit_type": "change"}
{"commit_tokens": ["Adding", "first", "and", "last", "name", "to", "card", ".", "Removed", "store", "method", "from", "card"], "add_tokens": "attr_accessor :first_name attr_accessor :last_name @first_name = card_hash [ 'first_name' ] @last_name = card_hash [ 'last_name' ] @adapted_card = ActiveMerchant :: Billing :: CreditCard . new ( card_hash )", "del_tokens": "@am_card = ActiveMerchant :: Billing :: CreditCard . new ( card_hash ) def store Jackpot :: Payment . gateway . store_card ( self ) end", "commit_type": "add"}
{"commit_tokens": ["adding", "option", "to", "disable", "a", "job", "by", "setting", "its", "max_leases", "to", "-", "1"], "add_tokens": "@max_leases = 0 if enabled? if requires_lock? semaphore = Semaphore . new ( @queue_name , @@zk ) semaphore . acquire do msg = @queue . receive_messages ( :limit => 10 ) next if msg . nil? || msg . empty? handle_messages ( * msg , & handler ) end else Chore . logger . error { \"LockingSQSConsumer#Consume: #{e.inspect}\" } max_leases > 0 end def enabled? max_leases != - 1 end def max_leases @max_leases = data . to_i @max_leases", "del_tokens": "@requires = false if requires_lock? semaphore = Semaphore . new ( @queue_name , @@zk ) semaphore . acquire do else msg = @queue . receive_messages ( :limit => 10 ) next if msg . nil? || msg . empty? handle_messages ( * msg , & handler ) Chore . logger . error { \"SQSConsumer#Consume: #{e.inspect}\" } @requires = data . to_i > 0 @requires", "commit_type": "add"}
{"commit_tokens": ["Added", "sortability", "to", "the", "table", "builder", "columns"], "add_tokens": "def initialize ( * args , & block ) @options = default_options . merge ( args . last . is_a? ( :: Hash ) ? args . pop : { } ) @title = pretty_title args [ 0 ] @data = args [ 1 ] || args [ 0 ] def sortable? if @data . is_a? ( Proc ) [ String , Symbol ] . include? ( @options [ :sortable ] . class ) else @options [ :sortable ] end end # # Returns the key to be used for sorting this column # # Defaults to the column's method if its a symbol # column :username # # => Sort key will be set to 'username' # # You can set the sort key by passing a string or symbol # to the sortable option: # column :username, :sortable => 'other_column_to_sort_on' # # If you pass a block to be rendered for this column, the column # will not be sortable unless you pass a string to sortable to # sort the column on: # # column('Username', :sortable => 'login'){ @user.pretty_name } # # => Sort key will be 'login' # def sort_key if @options [ :sortable ] == true || @options [ :sortable ] == false @data . to_s else @options [ :sortable ] . to_s end end def default_options { :sortable => true } end end", "del_tokens": "def initialize ( title , data = nil , & block ) @title = pretty_title title @data = data . nil? ? title : data end", "commit_type": "add"}
{"commit_tokens": ["move", "the", "timecop", "console", "layout", "to", "view"], "add_tokens": "def time_travel_to ( date , name = nil ) hour = if date . respond_to? ( :hour ) date . hour else 12 end min = if date . respond_to? ( :min ) date . min else 0 end name ||= date . strftime ( \"%B %d, %Y\" ) 'current_time(4i)' => hour , 'current_time(5i)' => min button_to ( name , update_path ) render :console_layout", "del_tokens": "def time_travel_to ( date ) 'current_time(4i)' => 12 , 'current_time(5i)' => 0 button_to ( date . strftime ( \"%B %d, %Y\" ) , update_path , method : :post ) if Rails . env . development? || Rails . env . staging? content_tag ( :div , id : \"debug-console\" ) do concat ( yield ) if block_given? concat ( content_tag ( :p ) { raw ( \"<-- #{time_travel_to(24.hours.ago)}\" ) + \"The time is #{Time.now.to_s(:db)}\" + raw ( \"#{time_travel_to(24.hours.from_now)} -->\" ) ; } ) concat ( form_tag ( timecop_console . update_path ) { concat ( content_tag ( :p , datetime_select ( \"timecop\" , \"current_time\" ) ) ) ; concat ( content_tag ( :p , submit_tag ( \"Time Travel\" , class : 'btn' ) ) ) ; } ) concat ( link_to ( \"Reset\" , timecop_console . reset_path ) ) end end", "commit_type": "move"}
{"commit_tokens": ["Fix", "set", "data", "type", "correctly"], "add_tokens": "TensorStream :: Evaluator :: OutputGroup . new ( res , res . map { tensor . inputs [ 0 ] . data_type } ) TensorStream :: Evaluator :: OutputGroup . new ( res , res . map { tensor . inputs [ 0 ] . data_type } ) register_op :shape_n do | _context , tensor , inputs | TensorStream :: Evaluator :: OutputGroup . new ( shapes , shapes . map { tensor . options [ :out_type ] } )", "del_tokens": "TensorStream :: Evaluator :: OutputGroup . new ( res ) TensorStream :: Evaluator :: OutputGroup . new ( res ) register_op :shape_n do | _context , _tensor , inputs | TensorStream :: Evaluator :: OutputGroup . new ( shapes )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "the", "editing", "of", "non", "-", "default", "locales"], "add_tokens": "def projects Projects . for_user ( current_user ) . sort { | a , b | b . name <=> a . name } end get '/projects/:api_key/:locale/*' do | api_key , locale , path | @locale = locale encoded = JSON . parse ( redis . get ( \"projects:#{@api_key}:draft_blurbs:#{@key}\" ) ) @blurb = encoded [ locale ] || \"\" post '/projects/:api_key/:locale/*' do | api_key , locale , path | @api_key = api_key @locale = locale @phrase_key = path . gsub ( \"/\" , \".\" ) @key = \"#{locale}.#{@phrase_key}\" @phrase = JSON . parse ( redis . get ( \"projects:#{@api_key}:draft_blurbs:#{@phrase_key}\" ) ) def phrase_list ( api_key , locale = nil ) @locale = locale || @project . default_locale @phrases = @project . draft_phrases if @phrases . size > 0 get '/projects/:api_key' do | api_key | return phrase_list ( api_key ) end get '/projects/:api_key/:locale' do | api_key , locale | return phrase_list ( api_key , locale ) end", "del_tokens": "get '/projects/:api_key/*' do | api_key , path | @blurb = redis . get ( \"projects:#{@api_key}:draft_blurbs:#{@key}\" ) post '/projects/:api_key/*' do | api_key , path | @key = path . gsub ( \"/\" , \".\" ) get '/projects/:api_key' do | api_key | @blurbs = @project . draft_blurbs if @blurbs . size > 0", "commit_type": "allow"}
{"commit_tokens": ["Added", "tests", "for", "link_to_add_association", "."], "add_tokens": "context \"link_to_add_association\" do before ( :each ) do @tester = TestClass . new @post = Post . new @form_obj = stub ( :object => @post ) @tester . stub ( :render_association ) . and_return ( 'form' ) end it \"should accept a name without a block\" do result = @tester . link_to_add_association ( 'add something' , @form_obj , :comments ) result . to_s . should == '<div id=\"comment_fields_template\" style=\"display:none;\">form</div><a href=\"#\" class=\"add_fields\" data-association=\"comment\">add something</a>' end it \"should work with a block\" do result = @tester . link_to_add_association ( @form_obj , :comments ) do \"some long name\" end result . to_s . should == '<div id=\"comment_fields_template\" style=\"display:none;\">form</div><a href=\"#\" class=\"add_fields\" data-association=\"comment\">some long name</a>' end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "some", "minor", "doc", "changes"], "add_tokens": "# Return only the first value from the row. # If multiple rows are returned as in a COUNT against multiple repos # then an array is returned that contains the first value from each row", "del_tokens": "# Return only the first value from the first row.", "commit_type": "add"}
{"commit_tokens": ["Make", "Form", "Html", "-", "Compliant"], "add_tokens": "super << context . div { hidden_fields ( context ) }", "del_tokens": "super << context . span { hidden_fields ( context ) }", "commit_type": "make"}
{"commit_tokens": ["add", "basic", "specs", "for", "SalesRestriction", "class"], "add_tokens": "xml_name \"SalesRestriction\" xml_accessor :sales_restriction_type , :from => \"SalesRestrictionType\" , :as => Fixnum , :to_xml => ONIX :: Formatters . two_digit", "del_tokens": "xml_accessor :sales_restriction_type , :from => \"SalesRestrictionType\" , :as => Fixnum # should be a 2 digit num", "commit_type": "add"}
{"commit_tokens": ["Fix", "deprecation", "warnings", "for", "Sequel", "4", "."], "add_tokens": "hash [ column . to_sym ] = Sequel . function ( :unhex , Sequel . lit ( \"@#{column}\" ) )", "del_tokens": "hash [ column . to_sym ] = :unhex . sql_function ( \"@#{column}\" . lit )", "commit_type": "fix"}
{"commit_tokens": ["add", "getter", "and", "setter", "of", "ionice"], "add_tokens": "# taken from /fs/proc/array.c # ioprio_* constants http://linux.die.net/man/2/ioprio_get IOPRIO_CLASS_NONE = 0 IOPRIO_CLASS_RT = 1 IOPRIO_CLASS_BE = 2 IOPRIO_CLASS_IDLE = 3 attach_function 'get_ionice' , [ :long , :pointer , :pointer ] , :int attach_function 'set_ionice' , [ :long , :int , :int ] , :int ioclass = FFI :: MemoryPointer . new ( :pointer , 1 ) value = FFI :: MemoryPointer . new ( :pointer , 1 ) status = LibPosixPsutil . get_ionice ( @pid , ioclass , value ) raise SystemCallError . new ( 'in get_ionice' , status ) if status != 0 OpenStruct . new ( ioclass : ioclass . read_int , value : value . read_int ) ioclass ||= IOPRIO_CLASS_NONE case ioclass when IOPRIO_CLASS_NONE raise ArgumentError . new ( \"can't specify value with IOPRIO_CLASS_NONE\" ) if value value = 0 when IOPRIO_CLASS_RT , IOPRIO_CLASS_BE value = 4 if value . nil? when IOPRIO_CLASS_IDLE raise ArgumentError . new ( \"can't specify value with IOPRIO_CLASS_IDLE\" ) if value value = 0 else value = 0 end if value < 0 || value > 7 raise ArgumentError . new ( \"value argument range expected is btween 0 and 7\" ) end status = LibPosixPsutil . set_ionice ( @pid , ioclass , value ) raise SystemCallError . new ( 'in set_ionice' , status ) if status != 0", "del_tokens": "# TODO implement it with C # TODO implement it with C", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "to", ":", "using", "and", "release", "a", "new", "gem", "."], "add_tokens": "has_scope :args_paginate , :type => :hash , :using => [ :page , :per_page ] assert_equal ( { } , current_scopes ) hash = { \"page\" => \"1\" , \"per_page\" => \"10\" } def test_scope_of_type_hash_with_using hash = { \"page\" => \"1\" , \"per_page\" => \"10\" } Tree . expects ( :args_paginate ) . with ( \"1\" , \"10\" ) . returns ( Tree ) Tree . expects ( :all ) . returns ( [ mock_tree ] ) get :index , :args_paginate => hash assert_equal ( [ mock_tree ] , assigns ( :trees ) ) assert_equal ( { :args_paginate => hash } , current_scopes ) end", "del_tokens": "assert_equal ( { :only_tall => false } , current_scopes ) hash = { \"page\" => \"1\" , \"per_page\" => \"1\" }", "commit_type": "add"}
{"commit_tokens": ["Make", "injection", "path", "relative", "to", "source", "instead", "of", "build", "path"], "add_tokens": "# # Injection files are relative to the :source_path content = File . read ( release . source_path + injection [ :file ] )", "del_tokens": "content = File . read ( release . build_path + injection [ :file ] )", "commit_type": "make"}
{"commit_tokens": ["Add", "Listing", "association", "to", "Shop"], "add_tokens": "attribute :id , :from => :shop_id @listings ||= Listing . find_all_by_shop_id ( id )", "del_tokens": "# A collection of listings in this user's shop. See Etsy::Listing for # more information # Listing . find_all_by_user_id ( user_id )", "commit_type": "add"}
{"commit_tokens": ["Add", "initial", ".", "slim", "support"], "add_tokens": "require_relative 'parser/slim' ruby : PutText :: Parser :: Ruby , slim : PutText :: Parser :: Slim '.rb' => :ruby , '.slim' => :slim # Filter out supported parsers SUPPORTED_PARSERS = { } PARSERS . each do | name , parser_class | next unless parser_class . supported? SUPPORTED_PARSERS [ name ] = parser_class . new end # Filter out supported file extensions SUPPORTED_EXTENSIONS = { } EXTENSIONS . each do | ext , parser | next unless SUPPORTED_PARSERS [ parser ] SUPPORTED_EXTENSIONS [ ext ] = parser end SUPPORTED_EXTENSIONS . keys . any? { | ext | path . end_with? ( ext ) } SUPPORTED_EXTENSIONS . each do | ext , lang | return SUPPORTED_PARSERS [ lang ] if path . end_with? ( ext )", "del_tokens": "ruby : PutText :: Parser :: Ruby . new '.rb' => :ruby EXTENSIONS . keys . any? { | ext | path . end_with? ( ext ) } EXTENSIONS . each do | ext , lang | return PARSERS [ lang ] if path . end_with? ( ext )", "commit_type": "add"}
{"commit_tokens": ["update", "Gemfile", "to", "work", "with", "rails", "3", "and", "4"], "add_tokens": "super ( attribute , ( text || \"\" ) . html_safe , options )", "del_tokens": "super ( attribute , text , options )", "commit_type": "update"}
{"commit_tokens": ["Changed", "@hash", "-", ">", "@dm_hash", "."], "add_tokens": "pays = self . dm_hash [ \"Report\" ] [ \"Pays\" ] [ \"Pay\" ]", "del_tokens": "pays = self . dm_hash [ \"Report\" ] [ \"Pays\" ]", "commit_type": "change"}
{"commit_tokens": ["fixing", "test", "cases", "(", "need", "to", "stub", "built", "-", "in", "method", ")"], "add_tokens": "File . join ( SYNC_DB_FILE ) File . join ( __rhoGetCurrentDir ( ) , 'db/syncdb.sqlite' )", "del_tokens": "File . join ( __rhoGetCurrentDir ( ) , SYNC_DB_FILE ) File . join ( __rhoGetCurrentDir ( ) , 'db/syncdb.sqlite' )", "commit_type": "fix"}
{"commit_tokens": ["Use", "contextual_show_path", "for", "links", "to", "props"], "add_tokens": "# def ordered_photo_url number unless self . property_photos . length >= number return \"https://placeholdit.imgix.net/~text?txtsize=38&txt=&w=550&h=400&txttrack=0\" end return self . property_photos [ number - 1 ] . image . url end def url_friendly_title # used in constructing seo friendly url if self . title && self . title . length > 2 return self . title . parameterize else return \"show\" end end def contextual_show_path rent_or_sale unless rent_or_sale # where I am displaying items searched by ref number, won't know if its for sale or rent beforehand rent_or_sale = self . for_rent ? \"for_rent\" : \"for_sale\" end if rent_or_sale == \"for_rent\" return Pwb :: Engine . routes . url_helpers . prop_show_for_rent_path ( locale : I18n . locale , id : self . id , url_friendly_title : self . url_friendly_title ) else return Pwb :: Engine . routes . url_helpers . prop_show_for_sale_path ( locale : I18n . locale , id : self . id , url_friendly_title : self . url_friendly_title ) end end", "del_tokens": "# def contextual_show_path rent_or_sale # unless rent_or_sale # # where I am displaying items searched by ref number, won't know if its for sale or rent beforehand # rent_or_sale = self.for_rent ? \"for_rent\" : \"for_sale\" # end # if rent_or_sale == \"for_rent\" # return Rails.application.routes.url_helpers.property_show_for_rent_path(locale: I18n.locale, id: self.id, url_friendly_title: self.url_friendly_title) # else # return Rails.application.routes.url_helpers.property_show_for_sale_path(locale: I18n.locale, id: self.id, url_friendly_title: self.url_friendly_title) # end # end", "commit_type": "use"}
{"commit_tokens": ["Added", "specs", "around", "value", "validation", "for", "Integer", "types", "."], "add_tokens": "@min ||= - ( 2 ** 15 ) @max ||= ( 2 ** 15 ) - 1", "del_tokens": "@min ||= - ( 2 ** 31 ) @max ||= ( 2 ** 31 ) - 1", "commit_type": "add"}
{"commit_tokens": ["Use", "description", "not", "described", "class"], "add_tokens": "klass = example . example_group . top_level_description || example . example_group . described_class", "del_tokens": "klass = example . example_group . described_class || example . example_group . top_level_description", "commit_type": "use"}
{"commit_tokens": ["Allow", "contain_<type", ">", "along", "with", "create_<type", ">"], "add_tokens": "@exp_resource_type = args . shift . to_s . gsub ( / ^(create|contain)_ / , '' ) return RSpec :: Puppet :: Matchers :: CreateGeneric . new ( method , * args , & block ) if method . to_s =~ / ^(create|contain)_ /", "del_tokens": "@exp_resource_type = args . shift . to_s . gsub ( / ^create_ / , '' ) return RSpec :: Puppet :: Matchers :: CreateGeneric . new ( method , * args , & block ) if method . to_s =~ / ^create_ /", "commit_type": "allow"}
{"commit_tokens": ["Use", "compat", "mode", "for", "hashes", "with", "symbol", "keys"], "add_tokens": "Oj . dump ( Extension . bootstrap_data ( self ) , mode : :compat )", "del_tokens": "Oj . dump Extension . bootstrap_data ( self )", "commit_type": "use"}
{"commit_tokens": ["implemented", "OR", "DSL", "queries", "example", "index", ".", "find", "{", "(", "name", "==", "andreas", ")", "|", "(", "age", "==", "30", "..", "40", ")", "}"], "add_tokens": "clause = ( @op == :& ) ? BooleanClause :: Occur :: MUST : BooleanClause :: Occur :: SHOULD query . add ( left_query , clause ) query . add ( right_query , clause ) self end def | ( other ) raise ArgumentError . new ( \"Expected at least two expression on stack, got #{@stack.size}\" ) if @stack . size < 2 right = @stack . pop left = @stack . pop expr = Expression . new_complete ( left , :| , right ) @stack . push expr", "del_tokens": "puts \"== '#{other}' type: #{other.class.to_s}\" puts \"> '#{other}'\" query . add ( left_query , BooleanClause :: Occur :: MUST ) query . add ( right_query , BooleanClause :: Occur :: MUST ) puts \"called '#{methodname}'\" puts \"<=> #{to} type #{to.class.to_s}\" puts \"Stack top #{@stack.last}\" puts \"& '#{other}'\"", "commit_type": "implement"}
{"commit_tokens": ["Remove", "redundant", "#input", "property", "."], "add_tokens": "initial_input . meta || { } target_path . relative_path_from ( initial_input . path . parent )", "del_tokens": "@input = input attr_reader :input input . meta || { } target_path . relative_path_from ( input . path . parent )", "commit_type": "remove"}
{"commit_tokens": ["Use", "host", "instead", "of", "hostname", "for", "URI"], "add_tokens": "client . redirect_uri . should == \"#{current_uri.scheme}://#{current_uri.host}#{current_uri.path}\"", "del_tokens": "client . redirect_uri . should == \"#{current_uri.scheme}://#{current_uri.hostname}#{current_uri.path}\"", "commit_type": "use"}
{"commit_tokens": ["updated", "options", "handling", "to", "keep", "options", "in", "-", "order", "per", "Will", "Green", "s", "pull", "request"], "add_tokens": "VERSION = \"1.0.0\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "update"}
{"commit_tokens": ["Updated", "wording", "for", "compilation", "feature", "."], "add_tokens": "Given / ^a extension named '(.*)'$ / do | extension_name | setup_extension_scaffold setup_extension_task_for extension_name def setup_extension_scaffold def setup_extension_task_for ( extension_name )", "del_tokens": "Given / ^scaffold code for extension '(.*)'$ / do | extension_name | setup_scaffold setup_task_for extension_name def setup_scaffold def setup_task_for ( extension_name )", "commit_type": "update"}
{"commit_tokens": ["Fix", "typo", "test", "null", "servers", "fix"], "add_tokens": "detect_memcached_version # HACK, the server does not appear to have a way to negotiate the protocol. # If you ask for the version in text, the socket is immediately locked to the text # protocol. All we can do is use binary and handle the failure if the server is old. # Alternative suggestions welcome.", "del_tokens": "detect_old_version", "commit_type": "fix"}
{"commit_tokens": ["Add", "excerpt", "to", "posts", "."], "add_tokens": "translates :title , :body , :excerpt attr_accessible :title , :body , :excerpt , :locale", "del_tokens": "translates :title , :body attr_accessible :title , :body , :locale", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "initial", "state", "not", "getting", "set", "when", "the", "state", "attribute", "is", "mass", "-", "assigned", "but", "protected"], "add_tokens": "attributes = remove_attributes_protected_from_mass_assignment ( ( attributes || { } ) . stringify_keys )", "del_tokens": "attributes = ( attributes || { } ) . stringify_keys", "commit_type": "fix"}
{"commit_tokens": ["use", "hamlet", ".", "js", "style", "whitespace"], "add_tokens": "require 'bundler' Bundler . setup $: . unshift ( File . expand_path ( '..' , __FILE__ ) )", "del_tokens": "require 'rubygems'", "commit_type": "use"}
{"commit_tokens": ["Use", "to_sym", "on", "the", "argument", "to", "get_driver", "and", "get_formatter"], "add_tokens": "if known_driver_classes . include? ( klass . to_sym ) if known_formatter_classes . include? ( klass . to_sym )", "del_tokens": "if known_driver_classes . include? ( klass ) if known_formatter_classes . include? ( klass )", "commit_type": "use"}
{"commit_tokens": ["Added", "#remove", "()", "method", "to", "indexer"], "add_tokens": "def remove ( model ) connection . delete ( :: Sunspot :: Adapters . adapt_instance ( model ) . index_id ) end self . for ( model . class , connection ) . add ( model ) end def remove ( connection , model ) self . for ( model . class , connection ) . remove ( model )", "del_tokens": "self . for ( model . class , connection ) . add model", "commit_type": "add"}
{"commit_tokens": ["Fix", "more", "Style", "/", "DotPosition", "offenses"], "add_tokens": "raise Jiralicious :: CaptchaRequired . new ( \"Captacha is required. Try logging into Jira via the web interface\" )", "del_tokens": "raise Jiralicious :: CaptchaRequired . new ( \"Captacha is required. Try logging into Jira via the web interface\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "relative_assets", "to", "default", "config", ".", "rb", "allow", "overriding", "with", "--", "relative", "from", "mm", "-", "build", "command"], "add_tokens": "class_option :relative , :type => :boolean , :aliases => \"-r\" , :default => false , :desc => 'Override the config.rb file and force relative urls' Middleman :: Server . new if options . has_key? ( \"relative\" ) && options [ \"relative\" ] Middleman :: Server . activate :relative_assets end", "del_tokens": "Middleman :: Server . new", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "the", "WebDAV", "COPY", "method", "."], "add_tokens": "VALID_ACTIONS = [ :get , :put , :post , :delete , :head , :copy ] if ! VALID_ACTIONS . include? ( new_action ) raise ArgumentError , \"Action must be one of #{VALID_ACTIONS.join(', ')}\" def action_name @action . to_s . upcase end", "del_tokens": "if ! [ :get , :put , :post , :delete , :head ] . include? ( new_action ) raise ArgumentError , \"Action must be one of :get, :put, :post, :delete or :head\"", "commit_type": "add"}
{"commit_tokens": ["Changed", ":", "experiment", ".", "alternatives", "is", "now", "an", "immutable", "snapshot", "."], "add_tokens": "# Called by Playground to save the experiment definition. def save redis . setnx key ( :created_at ) , Time . now . to_i @created_at = Time . at ( redis [ key ( :created_at ) ] . to_i ) # Reset experiment to its initial state.", "del_tokens": "redis . setnx key ( :created_at ) , Time . now . to_i @created_at = Time . at ( redis [ key ( :created_at ) ] . to_i ) # Called to save the experiment definition. def save #:nodoc: # Reset experiment.", "commit_type": "change"}
{"commit_tokens": ["fix", "total", "value", "on", "api"], "add_tokens": "# save total categories total = categories . length", "del_tokens": "total = categories . length", "commit_type": "fix"}
{"commit_tokens": ["added", "encoding", "for", "multi", "-", "csv"], "add_tokens": "@file = File . open ( filenames . pop , encoding : encoding )", "del_tokens": "@file = File . open ( filenames . pop )", "commit_type": "add"}
{"commit_tokens": ["Add", "accept", "string", "key", "param", "test", "cases", "to", "order_spec", ".", "rb", "and", "shipping_address_spec", ".", "rb"], "add_tokens": "city : \"Mountain View\" , country : \"USA\" , phone : \"1234567\" expect ( shipping_address . public_send ( key . to_sym ) ) . to eq ( valid_attrs [ key ] ) end end it \"accepts string keys\" do stringified_valid_attrs = valid_attrs . each_with_object ( { } ) do | pair , obj | obj [ pair . first . to_s ] = pair . last end shipping_address = WalmartOpen :: ShippingAddress . new ( stringified_valid_attrs ) WalmartOpen :: ShippingAddress :: ATTRIBUTES . each do | attr | expect ( shipping_address . public_send ( attr ) ) . to eq ( valid_attrs [ attr ] )", "del_tokens": "\"city\" => \"Mountain View\" , \"country\" => \"USA\" , \"phone\" => \"1234567\" expect ( shipping_address . public_send ( key . to_sym ) ) . to eq ( valid_attrs [ key ] || valid_attrs [ key . to_s ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "list_items", "method", "to", "Catalog", "OM"], "add_tokens": "context \"catalog has items\" do it \"returns a collection of vapp names\" do VCloudSdk :: Test :: ResponseMapping . set_option catalog_state : :added items = subject . items items . should have ( 2 ) . items items . each do | item | item . should be_an_instance_of VCloudSdk :: CatalogItem end end end context \"catalog has no item\" do before do VCloudSdk :: Test :: ResponseMapping . set_option catalog_state : :not_added end its ( :items ) { should eql [ ] } end end describe \"#list_items\" do context \"catalog has items\" do it \"returns a collection of vapp names\" do VCloudSdk :: Test :: ResponseMapping . set_option catalog_state : :added items_names = subject . list_items items_names . should eql [ VCloudSdk :: Test :: Response :: EXISTING_VAPP_TEMPLATE_NAME , VCloudSdk :: Test :: Response :: EXISTING_MEDIA_NAME ] end end context \"catalog has no item\" do before do VCloudSdk :: Test :: ResponseMapping . set_option catalog_state : :not_added end its ( :list_items ) { should eql [ ] } end", "del_tokens": "its ( :items ) { should have_at_least ( 1 ) . item }", "commit_type": "add"}
{"commit_tokens": ["Add", "Board#is_token?", "to", "help", "classify", "tokens", "i", ".", "e", ".", ":", "x", "and", ":", "o"], "add_tokens": "! self . class . is_token? ( self [ r , c ] ) def self . is_token? ( val ) [ :x , :o ] . include? ( val ) end raise ArgumentError , token unless self . class . is_token? ( token ) if self . class . is_token? ( token )", "del_tokens": "! [ :x , :o ] . include? ( self [ r , c ] ) raise ArgumentError , token unless [ :x , :o ] . include? ( token ) if [ :x , :o ] . include? ( token )", "commit_type": "add"}
{"commit_tokens": ["added", "uniqeness", "tests", "to", "spec"], "add_tokens": "bytes . uniq . length . should == bytes . length chars . uniq . length . should == chars . length", "del_tokens": "#bytes.uniq.length.should == bytes.length #chars.uniq.length.should == chars.length", "commit_type": "add"}
{"commit_tokens": ["add", "computation", "fonctions", "and", "ability", "to", "add", "working", "seconds", "/", "minutes", "/", "hours"], "add_tokens": "config [ :working_hours ] . freeze config [ :holidays ] . freeze compiled = { working_hours : [ ] } config [ :time_zone ] . freeze working_hours : { mon : { '09:00' => '17:00' } , tue : { '09:00' => '17:00' } , wed : { '09:00' => '17:00' } , thu : { '09:00' => '17:00' } , fri : { '09:00' => '17:00' } holidays : [ ] , time_zone : ActiveSupport :: TimeZone [ 'UTC' ]", "del_tokens": "config [ :working_hours ] config [ :holidays ] compiled = { :working_hours => [ ] } config [ :time_zone ] :working_hours => { :mon => { '09:00' => '17:00' } , :tue => { '09:00' => '17:00' } , :wed => { '09:00' => '17:00' } , :thu => { '09:00' => '17:00' } , :fri => { '09:00' => '17:00' } :holidays => [ ] , :time_zone => ActiveSupport :: TimeZone [ 'UTC' ]", "commit_type": "add"}
{"commit_tokens": ["Make", "Color", "return", "hex", ";", "make", "example", "prettier"], "add_tokens": "n = 64 # num leds ws = Ws2812 :: Basic . new ( n , 18 ) # +n+ leds at pin 18, using defaults ws [ ( 1 ... n ) ] = Ws2812 :: Color . new ( 0 , 0xff , 0 ) pp ws [ ( 0 ... n ) ] . reduce ( [ [ ] ] ) { | m , x | m << [ ] if m [ - 1 ] . size >= 8 ; m [ - 1 ] << x ; m } ws [ ( 0 ... n ) ] = Ws2812 :: Color . new ( 0xff , 0 , 0 ) ( 0 ... n ) . each do | i |", "del_tokens": "ws = Ws2812 :: Basic . new ( 64 , 18 ) # 64 leds at pin 18, using defaults ws [ ( 1 .. 63 ) ] = Ws2812 :: Color . new ( 0 , 0xff , 0 ) pp ws [ ( 0 .. 63 ) ] ws [ ( 0 .. 63 ) ] = Ws2812 :: Color . new ( 0xff , 0 , 0 ) ( 0 .. 63 ) . each do | i |", "commit_type": "make"}
{"commit_tokens": ["add", "build", "test", "for", "custom", "builders"], "add_tokens": "unless process_target . call ( target ) $stderr . puts \"Error: failed to build #{target}\" break end", "del_tokens": "break unless process_target . call ( target )", "commit_type": "add"}
{"commit_tokens": ["Fix", "New", "York", "Time", "specs"], "add_tokens": "@pa = NewYorkTimesPageParserV2 . new ( :url => \"http://www.nytimes.com/2012/08/22/us/politics/ignoring-calls-to-quit-akin-appeals-to-voters-in-ad.html?hp\" ) @pa = NewYorkTimesPageParserV2 . new ( :url => \"http://www.nytimes.com/2012/08/21/world/middleeast/syrian-rebels-coalesce-into-a-fighting-force.html?ref=world\" ) @pa = NewYorkTimesPageParserV2 . new ( :url => \"http://www.nytimes.com/2012/08/21/world/middleeast/syrian-rebels-coalesce-into-a-fighting-force.html\" ) \"http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml\" , \"http://rss.nytimes.com/services/xml/rss/nyt/NYRegion.xml\" , next if urls . size > 25 urls . uniq! urls . size . should > 25 @pa = NewYorkTimesPageParserV2 . new ( :url => u )", "del_tokens": "@pa = NewYorkTimesPageParserV1 . new ( :url => \"http://www.nytimes.com/2012/08/22/us/politics/ignoring-calls-to-quit-akin-appeals-to-voters-in-ad.html?hp\" ) @pa = NewYorkTimesPageParserV1 . new ( :url => \"http://www.nytimes.com/2012/08/21/world/middleeast/syrian-rebels-coalesce-into-a-fighting-force.html?ref=world\" ) @pa = NewYorkTimesPageParserV1 . new ( :url => \"http://www.nytimes.com/2012/08/21/world/middleeast/syrian-rebels-coalesce-into-a-fighting-force.html\" ) \"http://feeds.nytimes.com/nyt/rss/HomePage\" , \"http://feeds.nytimes.com/nyt/rss/NYRegion\" , urls . uniq! pending ( \"Failing spec but works in practise. Needs a looksee.\" ) { urls . size . should > 25 } @pa = NewYorkTimesPageParserV1 . new ( :url => u )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "recovery", "heart", "rate"], "add_tokens": "VERSION = '0.0.6'", "del_tokens": "VERSION = '0.0.5'", "commit_type": "add"}
{"commit_tokens": ["add", "initial", "Faraday", "::", "Connection", "with", "#get", "method"], "add_tokens": "require 'context' module Faraday class TestCase < Test :: Unit :: TestCase class FakeConnection < Faraday :: Connection def _get ( uri , headers ) FakeResponse . new ( uri , nil , headers ) end end class FakeResponse < Struct . new ( :uri , :content , :headers ) end end", "del_tokens": "require 'test/unit' class Test :: Unit :: TestCase", "commit_type": "add"}
{"commit_tokens": ["Add", "size", "-", "checking", "for", "the", "parsing", "buffer"], "add_tokens": "let ( :parser ) { } specify \"message containing a too large command\" do parser = Stompede :: Stomp :: Parser . new ( 4 ) expect { parser . parse ( \"CONNECT\\n\\n\\x00\" ) } . to raise_error ( Stompede :: BufferLimitExceeded ) end specify \"message containing a too large header key\" do parser = Stompede :: Stomp :: Parser . new ( 10 ) parser . parse ( \"CONNECT\\n\" ) expect { parser . parse ( \"very-long-header:value\\n\\n\\x00\" ) } . to raise_error ( Stompede :: BufferLimitExceeded ) end specify \"message containing a too large header value\" do parser = Stompede :: Stomp :: Parser . new ( 10 ) parser . parse ( \"CONNECT\\n\" ) expect { parser . parse ( \"key:very-long-header\\n\\n\\x00\" ) } . to raise_error ( Stompede :: BufferLimitExceeded ) end specify \"message containing a too large body\" do parser = Stompede :: Stomp :: Parser . new ( 10 ) parser . parse ( \"CONNECT\\n\\n\" ) expect { parser . parse ( \"a very long body\\x00\" ) } . to raise_error ( Stompede :: BufferLimitExceeded ) end", "del_tokens": "specify \"message containing a too large command\" specify \"message containing a too large header key\" specify \"message containing a too large header value\" specify \"message containing a too large body\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "admin", "loading", "in", "production"], "add_tokens": "config . to_prepare do Engine . reset_helpers! config . to_prepare do Engine . reloader . execute_if_updated", "del_tokens": "initializer \"trestle.reload\" do | app | reloader = self . reloader reloader . execute ActiveSupport :: Reloader . to_prepare do # Force-reload files underneath app/admin folders so that their routes can be loaded reloader . execute_if_updated end initializer \"trestle.reset_helpers\" do | app | engine = self ActiveSupport :: Reloader . to_prepare do engine . reset_helpers! end", "commit_type": "fix"}
{"commit_tokens": ["removed", "check_modules", "made", "create_procedure", "protected"], "add_tokens": "protected", "del_tokens": "# directives # # predicates protected def check_modules modules modules . each do | m | raise ArgumentError , \"#{m.inspect} is not a class or module\" , caller [ 1 .. - 1 ] unless m . is_a? Module end end", "commit_type": "remove"}
{"commit_tokens": ["Remove", "reference", "to", "byebug", "."], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "remove"}
{"commit_tokens": ["added", "the", "option", "to", "authenticate", "via", "auth", "param", "in", "addition", "to", "email", ";", "password"], "add_tokens": "# specify either the :email and :password or the :auth token you got in the past # # [:email] the user's email address for login purposes # # [:password] the user's password for login purposes # # [:auth] the auth token you got from a previous authentication request # if you provide this you do not need to provide the email and password def initialize ( options ) if options [ :auth ] @auth = options [ :auth ] else request_auth ( options [ :email ] , options [ :password ] ) end raise \"something went wrong\" login = GoogleLogin :: ClientLogin . new :service => 'reader' , :source => 'nudded-greader-0.1'", "del_tokens": "def initialize ( email , password ) request_auth ( email , password ) raise \"something went wrong\" login = GoogleLogin :: ClientLogin . new service : 'reader' , source : 'nudded-greader-0.1'", "commit_type": "add"}
{"commit_tokens": ["use", "license_text", "in", "status", "command"], "add_tokens": "warnings << \"missing license text\" if license . license_text . empty?", "del_tokens": "warnings << \"missing license text\" if license . text . strip . empty?", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "rotations", "in", "Transformation#transform"], "add_tokens": "{ Transformation } represents a relationship between two coordinate frames . # @option options [Angle] :angle Rotation angle (assumes planar geometry) rotation_options = options . select { | key , value | [ :angle , :x , :y , :z ] . include? key } @rotation = options [ :rotate ] || rotate || ( ( rotation_options . size > 0 ) ? Geometry :: Rotation . new ( rotation_options ) : nil ) raise ArgumentError , \"Bad translation\" if @translation . is_a? Hash # Transform and return a new {Point}. Rotation is applied before translation. # @param [Point] point the {Point} to transform into the parent coordinate frame point = @rotation . transform ( point ) if @rotation", "del_tokens": "{ Transformation } represents a relationship between two coordinate frames @rotation = options [ :rotate ] || rotate || ( ( options . key? ( :x ) || options . key? ( :y ) || options . key? ( :z ) ) ? Geometry :: Rotation . new ( options ) : nil ) # Transform and return a new {Point} # @param [Point] point The {Point} to transform", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "simple", "inheritance", "to", "Pump", "::", "Encoder", "with", ":", "base", "option"], "add_tokens": "attr_reader :root_name , :encoder_config , :encoder_options , :base if encoder_config . is_a? ( Array ) @encoder_config = encoder_config @encoder_options = encoder_options || { } else merge_base compile_string && instance_eval ( compile_string ) end def compile_string ; end def merge_base return unless @encoder_options [ :base ] @base = @encoder_options . delete ( :base ) merge_base_config merge_base_options end def merge_base_config original_encoder_config = @encoder_config @encoder_config = base . encoder_config . dup original_encoder_config . each do | it | key = it . keys . first index = @encoder_config . index { | config | config . keys . first == key } if index @encoder_config [ index ] = it else @encoder_config . push ( it ) end end end def merge_base_options encoder_options . merge! ( base . encoder_options ) { | key , v1 , v2 | v1 }", "del_tokens": "attr_reader :root_name , :encoder_config , :encoder_options unless Array === encoder_config else @encoder_config = encoder_config @encoder_options = encoder_options instance_eval ( compile_string )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Registry#stop", "without", "a", "valid", "uri"], "add_tokens": "VERSION = '0.3.1'", "del_tokens": "VERSION = '0.3.0'", "commit_type": "fix"}
{"commit_tokens": ["made", "post", "s", "YAML", "front", "matter", "available", "as", "post", ".", "data"], "add_tokens": "\"content\" => self . content , \"data\" => self . data }", "del_tokens": "\"content\" => self . content }", "commit_type": "make"}
{"commit_tokens": ["Added", "min", "and", "max", "to", "input", "cell", "type", "numbe"], "add_tokens": "# Valore che indica il minimo nel caso di input number # * *default*: nil attr_accessor :min # Valore che indica il massimo nel caso di input number # * *default*: nil attr_accessor :max multiple_files : false , birthdate : false , min : nil , max : nil ) @min = min @max = max", "del_tokens": "multiple_files : false , birthdate : false )", "commit_type": "add"}
{"commit_tokens": ["fix", "translation", "lookup", "model_name", "uses"], "add_tokens": "format_type_attr_method = obj . class . respond_to? ( :model_name ) ? :\" format_ #{ obj . class . model_name . underscore } _ #{ attr . to_s } \" : :\" format_ #{ obj . class . name . underscore } _ #{ attr . to_s } \" partial = @virtual_path ? @virtual_path . gsub ( %r{ .*/_? } , \"\" ) : nil variables [ :default ] ||= [ :\" activerecord.associations. #{ assoc . klass . model_name . underscore } . #{ key } \" , :\" activerecord.associations.models. #{ assoc . active_record . model_name . underscore } . #{ assoc . name } . #{ key } \"", "del_tokens": "format_type_attr_method = :\" format_ #{ obj . class . model_name . underscore } _ #{ attr . to_s } \" partial = @_virtual_path ? @_virtual_path . gsub ( %r{ .*/_? } , \"\" ) : nil variables [ :default ] ||= [ :\" activerecord.associations. #{ assoc . klass . name . underscore } . #{ key } \" , :\" activerecord.associations.models. #{ assoc . active_record . name . underscore } . #{ assoc . name } . #{ key } \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "aliyun", "CMS", "(", "metrics", ")"], "add_tokens": "require \"aliyun/services/cms\" require \"aliyun/services/ecs\" require \"aliyun/services/rds\" require \"aliyun/services/slb\" :cms => CMSConfig , :ecs => ECSConfig , :rds => RDSConfig , :slb => SLBConfig ,", "del_tokens": "require \"aliyun/services/ecs\" require \"aliyun/services/slb\" require \"aliyun/services/rds\" :ecs => ECSConfig , :slb => SLBConfig , :rds => RDSConfig ,", "commit_type": "add"}
{"commit_tokens": ["Add", "warnings", "to", "possible", "conflicts", "with", "raw", "sql", "in", "queries", "."], "add_tokens": "context 'multi_get' do it 'runs the correct sql' do connection . sqls . should be_empty query . multi_get ( :id , [ 1 , 2 ] ) connection . sqls . should eq ( [ \"SELECT id, name FROM items WHERE ((name = 'something') AND (id IN (1, 2))) LIMIT 10\" ] ) end context 'execute' do it 'runs the correct sql' do connection . sqls . should be_empty query . execute connection . sqls . should eq ( [ \"SELECT id, name FROM items WHERE (name = 'something') LIMIT 10\" ] ) end context 'with raw sql queries' do it 'warns in _execute if a dataset is passed' do connection . sqls . should be_empty query . should_receive ( :warn ) . with ( \"WARNING: Query::Sequel#_execute ignoring passed dataset due to previously-specified raw SQL\" ) query . _execute ( query . dataset ) connection . sqls . should eq ( [ \"select something from somewhere limit a-few\" ] ) end", "del_tokens": "it 'multi_get' do connection . sqls . should be_empty query . multi_get ( :id , [ 1 , 2 ] ) connection . sqls . should eq ( [ \"SELECT id, name FROM items WHERE ((name = 'something') AND (id IN (1, 2))) LIMIT 10\" ] ) it 'execute' do connection . sqls . should be_empty query . execute connection . sqls . should eq ( [ \"SELECT id, name FROM items WHERE (name = 'something') LIMIT 10\" ] ) context '#raw' do", "commit_type": "add"}
{"commit_tokens": ["using", "assert_in_delta", "for", "floating", "point", "differences"], "add_tokens": "assert_in_delta now , Nodes :: Scalar . new ( formatted ) . to_ruby , 0.000001 assert_in_delta now , Nodes :: Scalar . new ( formatted ) . to_ruby , 0.000001 assert_in_delta now , Nodes :: Scalar . new ( formatted ) . to_ruby , 0.000001", "del_tokens": "assert_equal now , Nodes :: Scalar . new ( formatted ) . to_ruby assert_equal now , Nodes :: Scalar . new ( formatted ) . to_ruby assert_equal now , Nodes :: Scalar . new ( formatted ) . to_ruby", "commit_type": "use"}
{"commit_tokens": ["changing", "IO", "handling", "in", "#consume!", "so", "that", "we", "no", "longer", "call", "request", ".", "body", ".", "read", "but", ".", "string", ".", "there", "have", "been", "some", "issues", "where", "read", "would", "return", "no", "document", "although", "input", "was", "returned", "with", "#string", "."], "add_tokens": "model . send ( compute_parsing_method ( format ) , incoming_string ) # e.g. from_json(\"...\") def incoming_string request . body . string end", "del_tokens": "model . send ( compute_parsing_method ( format ) , request . body . read ) # e.g. from_json(\"...\")", "commit_type": "change"}
{"commit_tokens": ["updated", "the", "readme", "and", "automatically", "modified", "regex", "in", "list", "files", "to", "remove", "parentheses"], "add_tokens": "IO . readlines ( filepath ) . each { | line | line . gsub! ( / \\n / , '' ) ; line . gsub! ( / (?<=[^ \\\\ ]) \\( (?=[^( \\? \\: )]) / , '(?:' ) }", "del_tokens": "IO . readlines ( filepath ) . each { | line | line . gsub! ( / \\n / , '' ) }", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "RecordFilter", "-", "style", "search", "restriction", "DSL"], "add_tokens": "UnrecognizedFieldError = Class . new ( Exception ) UnrecognizedRestrictionError = Class . new ( Exception ) # negated. In the last example above, only +without+ works, as it does not # make sense to search only for an instance you already have. # without current_post", "del_tokens": "# negated; in the last example above, +with+ can be used, but most likely # does not make sense.", "commit_type": "change"}
{"commit_tokens": ["Fix", "display", "of", "client_secret", "in", "debug", "output", "."], "add_tokens": "say_ok ( \"connecting to #{conn_hash.map { |k,v| \"#{k}=>#{(k == :client_secret) ? '*********' : v}\" }}\" ) if @options [ :debug ]", "del_tokens": "say_ok ( \"connecting to #{conn_hash.each { |k,v| \"#{k}=>#{(k == :client_secret) ? '*********' : v}\" }}\" ) if @options [ :debug ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "mocha", "warning", "and", "change", "to", "default", "report"], "add_tokens": "require \"mocha/setup\" MiniTest :: Unit . runner . reporters << MiniTest :: Reporters :: DefaultReporter . new #MiniTest::Unit.runner.reporters << MiniTest::Reporters::SpecReporter.new", "del_tokens": "require \"mocha\" MiniTest :: Unit . runner . reporters << MiniTest :: Reporters :: SpecReporter . new", "commit_type": "fix"}
{"commit_tokens": ["add", "some", "space", "for", "data", "table"], "add_tokens": "@builder . table ( class : 'data_table' , style : 'margin: 10px' ) do", "del_tokens": "@builder . table ( class : 'data_table' ) do", "commit_type": "add"}
{"commit_tokens": ["Improve", "all", "docs", "to", "A", "-", "class"], "add_tokens": "# @return [String] client key provided by Teambition # @return [String] client secret provided by Teambition # @return [String] callback url", "del_tokens": "# Client key provided by Teambition # @return [String] # Client secret provided by Teambition # @return [String] # Customizable callback url # @return [String]", "commit_type": "improve"}
{"commit_tokens": ["fix", "MarkdownString", "ol", "ul", "specs"], "add_tokens": "1 . 1 . 1 .", "del_tokens": "1 . 1 . 1 .", "commit_type": "fix"}
{"commit_tokens": ["Use", "S3", "not", "Github", ".", "Fix", "a", "few", "errors", "on", "the", "lib", "download", "."], "add_tokens": "PROJECT_URL = \"http://bowline.s3.amazonaws.com/#{Platform.type}\"", "del_tokens": "PROJECT_URL = \"http://github.com/maccman/bowline-desktop/raw/master/deploy/#{Platform.type}\"", "commit_type": "use"}
{"commit_tokens": ["create", "pong", "messages", "from", "incoming", "ping", "messages"], "add_tokens": "def self . ping ( payload = '' ) new ( payload , :ping ) def self . pong ( ping = nil ) payload = ping ? ping . payload : '' new ( payload , :pong )", "del_tokens": "def self . ping new ( '' , :ping ) def self . pong new ( '' , :pong )", "commit_type": "create"}
{"commit_tokens": ["added", "filter", ":", "foo", "scope", "=", ">", "true"], "add_tokens": "scope_filter ( s == true ? name : s , options )", "del_tokens": "scope_filter ( name || s , options )", "commit_type": "add"}
{"commit_tokens": ["fix", "another", "bug", "with", "the", "game", "dates"], "add_tokens": "last_rule = @cur_rule @cur_date = next_game_date ( @cur_date += 1 , @cur_rule . wday ) if last_rule . wday != @cur_rule . wday", "del_tokens": "@cur_date = next_game_date ( @cur_date += 1 , @cur_rule . wday ) if @cur_rule . wday != @rules [ @cur_rule_index ] . wday", "commit_type": "fix"}
{"commit_tokens": ["Adds", "explicit", "to_hash", "converter", "."], "add_tokens": "# Returns the Bibliography for chainability. # Returns a Ruby hash representation of the bibliography. def to_hash @entries . values . map ( & :to_hash ) end to_hash . to_yaml to_hash . to_json", "del_tokens": "@entries . values . map ( & :to_hash ) . to_yaml @entries . values . map ( & :to_hash ) . to_json", "commit_type": "add"}
{"commit_tokens": ["move", "skeleton", "output", "into", "its", "own", "class", ".", "add", "the", "auth", "info", "to", "the", "output"], "add_tokens": "require 'chatterbot/version' # Return a directory with the project libraries. def self . libdir t = [ File . expand_path ( File . dirname ( __FILE__ ) ) , \"#{Gem.dir}/gems/chatterbot-#{Chatterbot::VERSION}\" ] t . each { | i | return i if File . readable? ( i ) } raise \"both paths are invalid: #{t}\" end", "del_tokens": "", "commit_type": "move"}
{"commit_tokens": ["Improve", "dumping", "of", "key", "ducktraps", "and", "add", "missing", "error", "returns"], "add_tokens": "return nested_error ( result )", "del_tokens": "nested_error ( result )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "undefined", "method", "gsub", "for", "NilClass", "issue", "bump", "version"], "add_tokens": "match . gsub ( / \\s (?= \\( ) / , \"\\r\" ) . gsub ( / (?<= \\) ) \\s / , \"\\r\" ) match . gsub ( / ! / , '&ᓴ&'). g s ub(/ \\ ? /, ' ᓷ&')", "del_tokens": "match . gsub! ( / \\s (?= \\( ) / , \"\\r\" ) . gsub! ( / (?<= \\) ) \\s / , \"\\r\" ) match . gsub! ( / ! / , '&ᓴ&'). g s ub!(/ \\ ? /, ' ᓷ&')", "commit_type": "fix"}
{"commit_tokens": ["Implement", "a", "mechanism", "to", "change", "icons", "."], "add_tokens": "s . add_display ( :fdate , [ :updated_at , '%Y-%m-%d %H:%M:%S' ] , 'Update Date' , style : 'width: 162px;' ) s . add_display ( :fdate , [ :created_at , '%Y-%m-%d %H:%M:%S' ] , 'Create Date' , style : 'width: 162px;' )", "del_tokens": "s . add_display ( :fdate , [ :updated_at , '%Y-%m-%d %H:%M:%S' ] , 'Update Date' , style : 'width: 154px;' ) s . add_display ( :fdate , [ :created_at , '%Y-%m-%d %H:%M:%S' ] , 'Create Date' , style : 'width: 154px;' )", "commit_type": "implement"}
{"commit_tokens": ["Use", "syntactic", "sugar", "in", "message"], "add_tokens": "%Q{ Feature \" #{ @feature } \" do", "del_tokens": "%Q{ class #{ @missing_class } << Spinach :: FeatureSteps", "commit_type": "use"}
{"commit_tokens": ["adding", "back", "rake", "task", "exception", "reporting", "after", "fixing", "load", "order", "issue"], "add_tokens": "VERSION = \"0.8.2\"", "del_tokens": "VERSION = \"0.8.1\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "and", "gem", "dependencies"], "add_tokens": "VERSION = '0.9.10'", "del_tokens": "VERSION = '0.9.9'", "commit_type": "update"}
{"commit_tokens": ["Added", "missing", "files", "from", "previous", "commit"], "add_tokens": "require 'pact/array_like' array_like_path = \"#{path}[*].*\" # if @matching_rules[array_like]['match'] == 'type' # # handle more than one example # Pact::ArrayLike.new(object) # else # end # def handle_array_like array_rules = @matching_rules [ \"#{path}[*].*\" ] return object unless rules || array_rules # elsif array_rules['match'] == 'type' # handle_array_like(object, path, rules)", "del_tokens": "return object unless rules", "commit_type": "add"}
{"commit_tokens": ["Updated", "me", ".", "json", "to", "match", "the", "new", "A3PI", "object"], "add_tokens": "me . first_name . should eq 'Jeff' me . last_name . should eq 'Fang' me . address . city . should eql \"sfsfsf\" me . address . postal_code . should eql \"12345\"", "del_tokens": "me . first_name . should eq 'John' me . last_name . should eq 'Smith'", "commit_type": "update"}
{"commit_tokens": ["use", "capistrano", "current", "revision", "var"], "add_tokens": "revision = current_revision", "del_tokens": "revision = deployed_revision", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "sanitization", "of", "incoming", "URLs", "."], "add_tokens": "# decode, clean then re-encode the URL link = URI . encode ( URI . decode ( link . to_s ) . gsub ( / #[a-zA-Z0-9_-]*$ / , '' ) )", "del_tokens": "# clean the link link = URI . encode ( link . to_s . gsub ( / #[a-zA-Z0-9_-]*$ / , '' ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "docs", "to", "add", "--", "lang", "flag"], "add_tokens": "c . option 'lang' , '-l' , '--lang LANGUAGE' , \"Set a #{c.name.to_s} language (e.g. en, it) for multi-language sites.\"", "del_tokens": "c . option 'lang' , '-l' , '--lang LANGUAGE' , \"Set a #{c.name.to_s} language (e.g. en, it, du) for multi-language sites.\"", "commit_type": "update"}
{"commit_tokens": ["Allowing", "config", "values", "to", "be", "set", "to", "nil", "."], "add_tokens": "class UndefinedValue def ! true end end if object . is_a? ( UndefinedValue ) object = _set ( meth , Config . new ( ( name ? \"#{name}.\" : '' ) + meth_str ) ) end _set ( key , object . is_a? ( Proc ) ? ProcArray . new : [ ] ) if ! _get ( key ) @_nested ||= Hash . new { | hash , key | hash [ key ] = UndefinedValue . new }", "del_tokens": "object = _set ( meth , Config . new ( ( name ? \"#{name}.\" : '' ) + meth_str ) ) unless object _set ( key , object . is_a? ( Proc ) ? ProcArray . new : [ ] ) unless _get ( key ) @_nested ||= { }", "commit_type": "allow"}
{"commit_tokens": ["Adding", "more", "examples", "to", "ensure", "backpack", "command", "substitution", "is", "being", "flexed", "properly", "."], "add_tokens": "@looking_for_args = true consumed_length_so_far = result . consumed_length + ( md [ 0 ] . length - 1 ) append_result = process_until_separator ( @chunk [ consumed_length_so_far .. - 1 ] ) if append_result . consumed_length > 0 token :EndCommandSubstitution , delimiter , attrs : { concat_with : append_result . str } else token :EndCommandSubstitution , delimiter end return consumed_length_so_far + append_result . consumed_length end end def process_until_separator ( input_str ) str = \"\" i = 0 loop do ch = input_str [ i ] if ch && ch !~ / [ \\s ; \\| &> \\$ <] / str << ch i += 1 else break end OpenStruct . new ( str : str , consumed_length : str . length )", "del_tokens": "token :EndCommandSubstitution , delimiter result . consumed_length + ( md [ 0 ] . length - 1 )", "commit_type": "add"}
{"commit_tokens": ["Added", "customFields", "to", "create_envelope_from_document", "method", "."], "add_tokens": "# customFields - (Optional) A hash of listCustomFields and textCustomFields. # Each contains an array of corresponding customField hashes. # For details, please see: http://bit.ly/1FnmRJx status : \"#{options[:status]}\" , customFields : options [ :custom_fields ]", "del_tokens": "status : \"#{options[:status]}\"", "commit_type": "add"}
{"commit_tokens": ["adding", "verbose", "mode", "and", "continue", "on", "failure", "for", "service", "/", "commands"], "add_tokens": "@debug = false end def debug ( val = true ) @debug = val 'print_command' => false , 'failure_message' => \"required command '#{command}' is not available.\" 'print_command' => false , 'failure_message' => \"required service '#{service_name}' is not running.\" # 'failure_callback' - Proc to execute when the command fails. If a callback returns # true then it will avoid output command if options [ 'print_command' ] || @debug output command_output if @debug result = options [ 'on_failure' ] . call ( command , options ) if options [ 'on_failure' ] . is_a? ( Proc ) return true if result", "del_tokens": "'print_command' => false , 'failure_message' => \"required command '#{command}' is not available.\" 'print_command' => false , 'failure_message' => \"required service '#{service_name}' is not running.\" # 'failure_callback' - Proc to execute when the command fails output command if options [ 'print_command' ] options [ 'on_failure' ] . call ( command , options ) if options [ 'on_failure' ] . is_a? ( Proc )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "use", "custom", "templates"], "add_tokens": "# Returns the path to the custom template if it exists def custom_template_path ( name ) config = ShopConfig . new custom_path = config . get ( 'template' , 'path' ) if File . exists? ( \"#{custom_path}/#{name}\" ) \"#{custom_path}/#{name}\" else false end end custom_path = custom_template_path ( name ) if custom_path custom_path else path = File . expand_path File . dirname ( __FILE__ ) return \"#{path}/../../templates/#{name}\" if name \"#{path}/../../templates\" end file = template_path ( name )", "del_tokens": "path = File . expand_path File . dirname ( __FILE__ ) return \"#{path}/../../templates/#{name}\" if name \"#{path}/../../templates\" file = \"#{template_path}/#{name}\"", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "helper", "methods", "for", "creating", "deploy", "and", "retrieve", "Transactions"], "add_tokens": "Transaction . deployment self , response [ :deploy_response ] [ :result ] [ :id ]", "del_tokens": "Transaction . new self , response [ :deploy_response ] [ :result ] [ :id ] , :deploy", "commit_type": "add"}
{"commit_tokens": ["Change", "puppet", "to", "support", "profiles", "generation", "with", "path", "tree"], "add_tokens": "` rm -rf #{ project_root } /puppet/steps/ #{ step_name ( step ) } /modules/{roles,profiles} ` ` mkdir -p #{ project_root } /puppet/steps/ #{ step_name ( step ) } /modules/{roles,profiles}/manifests ` ` cp #{ project_root } /puppet/roles/ #{ role } /manifests/init.pp #{ project_root } /puppet/steps/ #{ step_name ( step ) } /modules/roles/manifests/ #{ role } .pp ` profile_tree = profile . gsub ( '::' , '/' ) profile_tree_parent = profile_tree . split ( '/' ) [ 0 ... - 1 ] . join ( '/' ) ` mkdir -p #{ project_root } /puppet/steps/ #{ step_name ( step ) } /modules/profiles/manifests/ #{ profile_tree_parent } ` ` cp #{ project_root } /puppet/profiles/ #{ profile_tree } /manifests/init.pp #{ project_root } /puppet/steps/ #{ step_name ( step ) } /modules/profiles/manifests/ #{ profile_tree } .pp ` profile_puppetfile_path = \"#{project_root}/puppet/profiles/#{profile.gsub('::','/')}/Puppetfile\"", "del_tokens": "` rm -rf #{ project_root } /puppet/steps/ #{ Bebox :: Puppet . step_name ( step ) } /modules/{roles,profiles} ` ` mkdir -p #{ project_root } /puppet/steps/ #{ Bebox :: Puppet . step_name ( step ) } /modules/{roles,profiles}/manifests ` ` cp #{ project_root } /puppet/roles/ #{ role } /manifests/init.pp #{ project_root } /puppet/steps/ #{ Bebox :: Puppet . step_name ( step ) } /modules/roles/manifests/ #{ role } .pp ` ` cp #{ project_root } /puppet/profiles/ #{ profile } /manifests/init.pp #{ project_root } /puppet/steps/ #{ Bebox :: Puppet . step_name ( step ) } /modules/profiles/manifests/ #{ profile } .pp ` profile_puppetfile_path = \"#{project_root}/puppet/profiles/#{profile}/Puppetfile\"", "commit_type": "change"}
{"commit_tokens": ["Fix", "param", "name", "in", "doc", "for", "create_season"], "add_tokens": "# @param rates_table [BookingSync::API::Resource|Integer] Rates table", "del_tokens": "# @param rates_table_id [BookingSync::API::Resource|Integer] Rates table", "commit_type": "fix"}
{"commit_tokens": ["Added", "english", "pound", "symbols", "to", "nationwide", "test"], "add_tokens": "07 Nov 2013 , Bank credit , Bank credit , , £500. 0 0, £ 500.0 0 09 Oct 2013 , ATM Withdrawal , Withdrawal , £20. 0 0, , £ 480.0 0 09 Dec 2013 , Visa , Supermarket , £19. 7 7, , £ 460.2 3 10 Dec 2013 , ATM Withdrawal 2 , ATM Withdrawal 4 , £100. 0 0, , £ 360.2 3", "del_tokens": "07 Nov 2013 , Bank credit , Bank credit , , 500.00 , 500.00 09 Oct 2013 , ATM Withdrawal , Withdrawal , 20.00 , , 480.00 09 Dec 2013 , Visa , Supermarket , 19.77 , , 460.23 10 Dec 2013 , ATM Withdrawal 2 , ATM Withdrawal 4 , 100.00 , , 360.23", "commit_type": "add"}
{"commit_tokens": ["allow", "re", "-", "enqueue", "sync", "after", "30", "minutes"], "add_tokens": "if previous_synchronization && previous_synchronization . status == 'RUNNING' && previous_synchronization . created_at > ( Time . now - 30 . minutes )", "del_tokens": "if previous_synchronization && previous_synchronization . status == 'RUNNING'", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "nil", "check", "and", "an", "additional", "test", ".", "There", "were", "issues", "with", "defining", "statistics", "without", "calling", "filter_all_on", "."], "add_tokens": "sql = ( ( @filter_all_on || { } ) . merge ( scoped_options [ :filter_on ] || { } ) ) [ key ] . gsub ( \"?\" , \"'#{value}'\" )", "del_tokens": "sql = ( @filter_all_on . merge ( scoped_options [ :filter_on ] || { } ) ) [ key ] . gsub ( \"?\" , \"'#{value}'\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Rails", "<3", "for", "list_link_helpers", ".", "rb"], "add_tokens": "require File . join ( File . dirname ( __FILE__ ) , * %w[ .. lib contextual_link_helpers ] ) require File . join ( File . dirname ( __FILE__ ) , * %w[ .. lib list_link_helpers.rb ] ) ActionView :: Base . send :include , ListLinkHelpers", "del_tokens": "require File . join ( File . dirname ( __FILE__ ) , * %w[ .. lib contextual_link_helpers ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "http", "timeout", "option", "."], "add_tokens": ":verify_ssl => true , :http_timeout => 5", "del_tokens": ":verify_ssl => true", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "localhost", "proxy", "bump", "version", "to", "beta", ".", "16"], "add_tokens": "conn = Faraday . new do | conn |", "del_tokens": "conn = Faraday . new ( proxy : 'http://localhost:8888' ) do | conn |", "commit_type": "remove"}
{"commit_tokens": ["Allow", "subclassing", ":", "save_rakefile_info", "would", "have", "got", "confused"], "add_tokens": "save_rakefile_info ( block ) def save_rakefile_info ( block ) if RUBY_VERSION < '1.9' # Hack the path from the block String representation @rakefile = block . to_s . match ( / @([^ \\: ]+): / ) [ 1 ] else @rakefile = block . source_location end", "del_tokens": "save_rakefile_info ( caller [ 0 ] ) def save_rakefile_info ( caller ) @rakefile = caller . match ( / ^([^ \\: ]+) / ) [ 1 ]", "commit_type": "allow"}
{"commit_tokens": ["updated", "with", "leave", "and", "follow", "methods", "for", "twitter", "base", "and", "for", "the", "CLI", ".", "also", "updated", "the", "manifest", "."], "add_tokens": "@@commands = [ :post , :timeline , :friends , :friend , :followers , :follower , :featured , :important , :follow , :leave ] def follow config = create_or_find_config if ARGV . size == 0 puts %(\\n You forgot to enter a screen name or id to follow.\\n\\n Usage: twitter follow jnunemaker\\n) exit ( 0 ) end screen_name = ARGV . shift puts found = false begin Twitter :: Base . new ( config [ 'email' ] , config [ 'password' ] ) . follow ( screen_name ) puts \"You are now following notifications for #{screen_name}.\" rescue puts \"FAIL: Somethin went wrong. Sorry.\" end end def leave config = create_or_find_config if ARGV . size == 0 puts %(\\n You forgot to enter a screen name or id to leave.\\n\\n Usage: twitter leave jnunemaker\\n) exit ( 0 ) end screen_name = ARGV . shift puts found = false begin Twitter :: Base . new ( config [ 'email' ] , config [ 'password' ] ) . leave ( screen_name ) puts \"You are no longer following notifications for #{screen_name}.\" rescue puts \"FAIL: Somethin went wrong. Sorry.\" end end", "del_tokens": "@@commands = [ :post , :timeline , :friends , :friend , :followers , :follower , :featured , :important ]", "commit_type": "update"}
{"commit_tokens": ["Removed", "un", "-", "necessary", "require", "Aims", ".", "rb"], "add_tokens": "dir = File . dirname ( File . expand_path ( __FILE__ ) ) require \"#{dir}/Aims/vectorize.rb\" require \"#{dir}/Aims/geometry_parser.rb\" require \"#{dir}/Aims/output.rb\" require \"#{dir}/Aims/zinc_blende.rb\" require \"#{dir}/Aims/wurtzite.rb\" require \"#{dir}/Aims/unit_cell.rb\" require \"#{dir}/Aims/bond.rb\" require \"#{dir}/Aims/atom.rb\" require \"#{dir}/Aims/plane.rb\"", "del_tokens": "require 'Aims/vectorize.rb' require 'Aims/geometry_parser.rb' require 'Aims/output.rb' require 'Aims/zinc_blende.rb' require 'Aims/wurtzite.rb' require 'Aims/unit_cell.rb' require 'Aims/bond.rb' require 'Aims/atom.rb' require 'Aims/plane.rb'", "commit_type": "remove"}
{"commit_tokens": ["fixes", "error", "when", "running", "dashboard", "import", "with", "--", "debug"], "add_tokens": "say_warning ( \"options: #{@options.inspect}\" , output : output ) if @options [ :debug ]", "del_tokens": "say_warning ( \"options: #{@options.inspect}\" , output ) if @options [ :debug ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "use", "kilometers", "for", "distances", "."], "add_tokens": "# +units+ :: <tt>:mi</tt> (default) or <tt>:km</tt> radius *= km_in_mi if options [ :units ] == :km ## # Conversion factor: km to mi. # def km_in_mi 0.621371192 end # Get other geocoded objects within a given radius. # Valid units are defined in <tt>distance_between</tt> class method. def nearbys ( radius = 20 , units = :mi ) options = { :conditions => [ \"id != ?\" , id ] } if units . is_a? Hash \"a future version. The second argument is now called 'units' and \" + \"should be a symbol (:mi or :km, :mi is the default). The 'nearbys' \" + \"method now returns a Rails 3 scope so you should specify more \" + \"scopes and/or conditions via chaining. For example: \" + \"will eventually be discontinued.\" options . reverse_merge! ( units ) else options . reverse_merge! ( :units => units ) conversions = { :mi => 3956 , :km => 6371 } c * conversions [ options [ :units ] ]", "del_tokens": "# Get other geocoded objects within a given radius (in miles). Takes a # radius (in miles) and options for passing to the +near+ scope # (<tt>:order</tt>, <tt>:limit</tt>, and <tt>:offset</tt>). def nearbys ( radius = 20 , options = { } ) if options != { } \"a future version. Nearbys now returns a scope so you should \" + \"specify more scopes and/or conditions via chaining. For example: \" + \"will be discontinued soon.\" options . reverse_merge! ( :conditions => [ \"id != ?\" , id ] ) units = { :mi => 3956 , :km => 6371 } c * units [ options [ :units ] ]", "commit_type": "add"}
{"commit_tokens": ["Adding", "dummy", "test", "for", "creating", "payments"], "add_tokens": "mount Jackpot :: Engine => \"/billing\"", "del_tokens": "mount Jackpot :: Engine => \"/jackpot\"", "commit_type": "add"}
{"commit_tokens": ["Added", "in", "remote", "ssh", "into"], "add_tokens": "\"#{ssh_command} '#{cmd}'\" end def ssh_command ( remote_instance = nil ) \"#{ssh_string} #{remote_instance.ip}\" def ssh_into ( instance = nil ) Kernel . system \"#{ssh_command(instance)}\" if instance end", "del_tokens": "\"#{ssh_string} #{remote_instance.ip} '#{cmd}'\"", "commit_type": "add"}
{"commit_tokens": ["Add", "TODO", "comment", "in", "Gemfile", "class"], "add_tokens": "# Retrieve gems which differ from vendored . each do | dep | # TODO # if dependency specified alternate source (git, path, other) # retrieve, compare against version retrieved from rubygems # (try to extract version from alternate source, # else use bundler to resolve version from Gemfile) end", "del_tokens": "# TODO retrieve gems which differ from", "commit_type": "add"}
{"commit_tokens": ["adding", "[]", "accessor", "to", "durable", "array"], "add_tokens": "def [] ( index ) res = execute ( \"SELECT * FROM items ORDER BY item_id ASC LIMIT 1 OFFSET #{index}\" ) get_one ( res ) end", "del_tokens": "def client_min_messages = ( level ) end", "commit_type": "add"}
{"commit_tokens": ["Add", "hook", "for", "handlers", "to", "create", "default", "configuration", "."], "add_tokens": "default_config = described_class . default_config expect ( default_config . robot . name ) . to eq ( \"Lita\" ) expect ( default_config . robot . adapter ) . to eq ( :shell ) end it \"loads configuration from registered handlers\" do handler = Class . new do def self . default_config ( handler_config ) handler_config . bar = :baz end def self . name \"Lita::Handlers::Foo\" end end allow ( Lita ) . to receive ( :handlers ) . and_return ( [ handler ] ) default_config = described_class . default_config expect ( default_config . handlers . foo . bar ) . to eq ( :baz )", "del_tokens": "expect ( described_class . default_config . robot . name ) . to eq ( \"Lita\" ) expect ( described_class . default_config . robot . adapter ) . to eq ( :shell )", "commit_type": "add"}
{"commit_tokens": ["Updated", "gems", "fixed", "bit", "rot"], "add_tokens": "require 'minitest' require 'minitest/autorun' require 'minitest/reporters' require 'mocha/mini_test' Minitest :: Reporters . use! Minitest :: Reporters :: DefaultReporter . new", "del_tokens": "require 'minitest/unit' require 'turn/autorun' require 'mocha/setup'", "commit_type": "update"}
{"commit_tokens": ["added", "bugfix", "to", "indifferent!", "method", "to", "resolve", "issue", "with", "nested", "arrays", "and", "hashes"], "add_tokens": "unless hash . is_a? ( Hash ) return end if hash [ key ] != nil if hash [ key ] . is_a? ( Hash ) indifferent! ( hash [ key ] ) elsif hash [ key ] . is_a? ( Array ) indifferent_array! ( hash [ key ] ) end def indifferent_array! ( array ) unless array . is_a? ( Array ) return end array . each do | i | if i . is_a? ( Hash ) indifferent! ( i ) elsif i . is_a? ( Array ) indifferent_array! ( i ) end end end", "del_tokens": "if hash [ key ] != nil && hash [ key ] . is_a? ( Hash ) indifferent ( hash [ key ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "simple", "memcache", "backed", "dedup", "mechanism", "."], "add_tokens": "require 'chore/dedupe' @dupes = DuplicateDetector . new ( Chore . config . dedupe_servers || nil ) msg . each { | m | yield m . handle , m . body unless @dupes . found_duplicate? ( msg ) } yield msg . handle , msg . body unless @dupes . found_duplicate? ( msg )", "del_tokens": "msg . each { | m | yield m . handle , m . body } yield msg . handle , msg . body", "commit_type": "add"}
{"commit_tokens": ["removed", "waves", "-", "effect", "class", "from", "active", "link", "like", "documentation", "shows"], "add_tokens": "if page == current_page classes = 'active' else classes = 'waves-effect' end", "del_tokens": "classes = [ 'waves-effect' , ( 'active' if page == current_page ) ] . join ( ' ' )", "commit_type": "remove"}
{"commit_tokens": ["Use", "hash", "syntax", "for", "setting", "properties"], "add_tokens": "queue << [ 'set' , { experiment => variant } ]", "del_tokens": "queue << [ 'set' , experiment , variant ]", "commit_type": "use"}
{"commit_tokens": ["Fix", "param", "name", "for", "demo"], "add_tokens": "pp weather . forecast ( 49.999892 , 36.242392 , extended_hourly : true )", "del_tokens": "pp weather . forecast ( 49.999892 , 36.242392 , hourly : true )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "broken", "file", "system", "spec"], "add_tokens": "it { should == [ \"file:///path/to/file\" , { :file_name => \"file\" } ] }", "del_tokens": "it { should == \"file:///path/to/file\" }", "commit_type": "fix"}
{"commit_tokens": ["changed", "the", "signature", "of", "temp_view", "to", "match", "the", "design", "document", "schemas"], "add_tokens": "def temp_view funcs , type = 'application/json'", "del_tokens": "def temp_view map , reduce = nil , type = 'application/json' funcs = { :map => map } funcs [ :reduce ] = reduce if reduce", "commit_type": "change"}
{"commit_tokens": ["adding", "unsaved", "files", "and", "test", "specs"], "add_tokens": "metadata = AppRepo :: Uploader . new ( options ) . download_manifest_only", "del_tokens": "metadata = AppRepo :: Uploader . new ( options ) . download_metadata", "commit_type": "add"}
{"commit_tokens": ["allow", "easy", "modification", "of", "windows"], "add_tokens": "def update_keys %i( reason title startTimeInSeconds endTimeInSeconds relevantCustomerTags relevantHostTags ) end # @param id [String] a Wavefront maintenance window ID # @param body [Hash] key-value hash of the parameters you wish # to change # @param modify [true, false] if true, use {#describe()} to get # a hash describing the existing object, and modify that with # the new body. If false, pass the new body straight through. def update ( id , body , modify = true ) return api_put ( id , body , 'application/json' ) unless modify api_put ( id , hash_for_update ( describe ( id ) . response , body ) , 'application/json' )", "del_tokens": "# @param body [Hash] a hash of parameters describing the window. # @raise any validation errors from body # def update ( id , body ) api_put ( id , body )", "commit_type": "allow"}
{"commit_tokens": ["Make", "our", "version", "of", "#cache_key", "public"], "add_tokens": "def cache_key ( * timestamp_names ) if timestamp_names . present? raise ArgumentError , \"ContentfulModel::Base models don't support named timestamps.\" end \"#{self.class.to_s.underscore}/#{self.id}-#{self.updated_at.utc.to_s(:usec)}\" end", "del_tokens": "def cache_key ( * timestamp_names ) if timestamp_names . present? raise ArgumentError , \"ContentfulModel::Base models don't support named timestamps.\" end \"#{self.class.to_s.underscore}/#{self.id}-#{self.updated_at.utc.to_s(:number)}\" end", "commit_type": "make"}
{"commit_tokens": ["move", "test_maximum_weight", "out", "of", "private", "section"], "add_tokens": "def test_maximum_weight assert Package . new ( 70 * 16 , [ 5 , 5 , 5 ] , :units => :imperial ) . mass == @carrier . maximum_weight assert Package . new ( ( 70 * 16 ) + 0.01 , [ 5 , 5 , 5 ] , :units => :imperial ) . mass > @carrier . maximum_weight assert Package . new ( ( 70 * 16 ) - 0.01 , [ 5 , 5 , 5 ] , :units => :imperial ) . mass < @carrier . maximum_weight end", "del_tokens": "def test_maximum_weight assert Package . new ( 70 * 16 , [ 5 , 5 , 5 ] , :units => :imperial ) . mass == @carrier . maximum_weight assert Package . new ( ( 70 * 16 ) + 0.01 , [ 5 , 5 , 5 ] , :units => :imperial ) . mass > @carrier . maximum_weight assert Package . new ( ( 70 * 16 ) - 0.01 , [ 5 , 5 , 5 ] , :units => :imperial ) . mass < @carrier . maximum_weight end", "commit_type": "move"}
{"commit_tokens": ["Remove", "save", "and", "save!", "methods", "from", "embedded", "objects", "."], "add_tokens": "__parent . new?", "del_tokens": "__parent . new? # FIXME def save # FIXME: Work with validations, scrivener or hatch? # __parent.save if valid? __parent . save end def save! __parent . save! end # Persist the object in Riak database # def __save__ @attributes [ :_type ] = model . name # __check_unique_indices # __update_indices __parent . save! @attributes . delete :_type self end", "commit_type": "remove"}
{"commit_tokens": ["Updated", "merging", "of", "query", "string", "params", "."], "add_tokens": "queryStringParams = { } queryStringParams [ k ] = v [ 0 ] queryStringParams [ k ] = v controller . params = queryStringParams . merge ( vars )", "del_tokens": "controller . params = vars controller . params [ k ] = v [ 0 ] controller . params [ k ] = v", "commit_type": "update"}
{"commit_tokens": ["Fix", "reify", "on", "has_many", ":", "through", "for", "has_one", "associations", "and", "custom", ":", "source"], "add_tokens": "records = through_model . public_send ( assoc . source_reflection_name ) if records . respond_to? ( :to_a ) # Has Many association records = records . to_a else # Has One association - Nothing more to do end records", "del_tokens": "through_model . public_send ( assoc . name . to_sym ) . to_a", "commit_type": "fix"}
{"commit_tokens": ["added", "new", "features", "improvements", "and", "bug", "fixes"], "add_tokens": "def api_get_request ( url_prefix , tree = nil ) request = Net :: HTTP :: Get . new ( \"#{url_prefix}/api/json?#{tree}\" ) if tree request = Net :: HTTP :: Post . new ( \"#{url_prefix}\" ) request . content_type = 'application/xml'", "del_tokens": "require File . expand_path ( '../views' , __FILE__ ) def api_get_request ( url_prefix ) request = Net :: HTTP :: Post . new ( \"#{url_prefix}/config.xml\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "simple", "cache", "for", "keys"], "add_tokens": "define_key_accessor ( key ) unless value raise MissingSettingError . new ( \"Missing setting in '#{key}' in '#{@path}'.\" ) end define_key_accessor ( key ) unless repond_to? ( key ) value private def define_key_accessor ( key ) define_singleton_method ( key ) { get_value ( key ) } if key =~ / \\A \\w + \\z / end", "del_tokens": "return value unless value . nil? raise MissingSettingError . new ( \"Missing setting in '#{key}' in '#{@path}'.\" ) def has_key? ( key ) ! ! @table [ key ] end", "commit_type": "add"}
{"commit_tokens": ["fix", "tests", "for", "visitor", "with", "separated", "namespace", "bindings"], "add_tokens": "def namespace_bindings_from_defs ( ns_defs ) ( ns_defs || [ ] ) . reduce ( { } ) do | h , ns_def | h [ ns_def . prefix || \"\" ] = ns_def . href h end end ns_bindings = namespace_bindings_from_defs ( element . namespace_definitions )", "del_tokens": "_ , ns_bindings = Rsxml :: Namespace . partition_namespace_decls ( element . namespaces )", "commit_type": "fix"}
{"commit_tokens": ["Added", "spec", "tests", "address", "and", "shipping", "address", "for", "customers"], "add_tokens": "# @return [String] The address of the customer. attr_reader :address # @return [String] The shipping address of the customer. attr_reader :shipping_address @address = node . xpath ( 'cust:addr' ) . text @shipping_address = node . xpath ( 'cust:shipaddr' ) . text %i[ id name guid address shipping_address ]", "del_tokens": "%i[ id name guid ]", "commit_type": "add"}
{"commit_tokens": ["Updated", "styling", "in", "datacenter", ".", "rb"], "add_tokens": "method : :delete , path : \"/datacenters/#{id}\" , expects : 202 path : \"/datacenters/#{id}\" , method : :patch , expects : 202 , body : options . to_json method : :post , path : '/datacenters' , body : { properties : options , entities : entities } . to_json , expects : 202 method : :get , path : '/datacenters' , expects : 200 method : :get , path : \"/datacenters/#{datacenter_id}\" , expects : 200 properties : entity , entities : { volumes : subentities } items << { properties : entity } { items : items }", "del_tokens": "method : :delete , path : \"/datacenters/#{id}\" , expects : 202 path : \"/datacenters/#{id}\" , method : :patch , expects : 202 , body : options . to_json method : :post , path : '/datacenters' , body : { properties : options , entities : entities } . to_json , expects : 202 method : :get , path : '/datacenters' , expects : 200 method : :get , path : \"/datacenters/#{datacenter_id}\" , expects : 200 properties : entity , entities : { volumes : subentities } items << { properties : entity } { items : items }", "commit_type": "update"}
{"commit_tokens": ["Adding", "module", "files", "for", "web", "and", "mirror"], "add_tokens": "require 'minimart/mirror' require 'minimart/web'", "del_tokens": "require 'ridley' require 'minimart/utils/archive' require 'minimart/utils/file_helper' require 'minimart/utils/http' require 'minimart/web/template_helper' require 'minimart/web/cookbooks'", "commit_type": "add"}
{"commit_tokens": ["Updated", "class", "method", "name", "and", "allows", "array", "of", "protected", "attributes", "as", "default", "arguments"], "add_tokens": "def has_sudo_attributes ( * attrs ) raise \"Invalid argument passed to has_sudo_attributes\" unless valid_attributes? attrs set_protected_attributes ( attrs ) unless attrs . empty? attrs . empty? || hash_syntax? ( attrs ) || all_symbols? ( attrs ) end # True if argument is in the form \":protected => :field1\" or \":accessible => :field2\" def hash_syntax? ( attrs ) return false unless attrs . size == 1 hash = attrs . first hash . is_a? ( Hash ) && ( hash . has_key? ( :protected ) || hash . has_key? ( :accessible ) ) end # True if argument is in the form \":field1, :field2, :field3\" def all_symbols? ( attrs ) attrs . all? { | e | e . class == Symbol } if all_symbols? attrs self . attr_protected * attrs else key = attrs [ 0 ] . has_key? ( :protected ) ? :protected : :accessible # Call either attr_protected or attr_accessible self . send ( \"attr_#{key}\" , * attrs [ 0 ] [ key ] ) end # Added to ActiveRecord model only if has_sudo_attributes is called", "del_tokens": "def enable_sudo_attributes ( attrs = nil ) raise \"Invalid argument passed to enable_sudo_attributes\" unless valid_attributes? attrs set_protected_attributes ( attrs ) unless attrs . nil? # Validate that either nil, :protect, or :accessible has been given attrs . nil? || ( attrs . is_a? ( Hash ) && ( attrs . has_key? ( :protected ) || attrs . has_key? ( :accessible ) ) ) key = attrs . has_key? ( :protected ) ? :protected : :accessible # Call either attr_protected or attr_accessible self . send ( \"attr_#{key}\" , * attrs [ key ] ) # Added to ActiveRecord model only if enable_sudo_attributes is called", "commit_type": "update"}
{"commit_tokens": ["Fix", "json", "content", "aware", "diff", "on", "Chef", "objects"], "add_tokens": "new_value = Chef :: JSONCompat . from_json ( new_value ) . to_hash old_value = Chef :: JSONCompat . from_json ( old_value ) . to_hash", "del_tokens": "new_value = Chef :: JSONCompat . from_json ( new_value ) old_value = Chef :: JSONCompat . from_json ( old_value )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "objects", "by", "deleted_ids", "only", "when", "request", "was", "performed"], "add_tokens": "if @only_updated && @request_performed", "del_tokens": "if @only_updated", "commit_type": "remove"}
{"commit_tokens": ["Add", "tests", "for", "resource_name", "label", "."], "add_tokens": "# generic attributes HOSTNAME = Socket . gethostname CUSTOM_HOSTNAME = 'custom.hostname.org' vm_name #{CUSTOM_HOSTNAME} \"#{COMPUTE_SERVICE_NAME}/resource_id\" => VM_ID , \"#{COMPUTE_SERVICE_NAME}/resource_name\" => HOSTNAME \"#{COMPUTE_SERVICE_NAME}/resource_id\" => VM_ID , \"#{COMPUTE_SERVICE_NAME}/resource_name\" => HOSTNAME \"#{COMPUTE_SERVICE_NAME}/resource_id\" => CUSTOM_VM_ID , \"#{COMPUTE_SERVICE_NAME}/resource_name\" => CUSTOM_HOSTNAME \"#{EC2_SERVICE_NAME}/account_id\" => EC2_ACCOUNT_ID , \"#{EC2_SERVICE_NAME}/resource_name\" => HOSTNAME", "del_tokens": "\"#{COMPUTE_SERVICE_NAME}/resource_id\" => VM_ID \"#{COMPUTE_SERVICE_NAME}/resource_id\" => VM_ID \"#{COMPUTE_SERVICE_NAME}/resource_id\" => CUSTOM_VM_ID \"#{EC2_SERVICE_NAME}/account_id\" => EC2_ACCOUNT_ID", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "special", "chars", "like", "\\", "$", ".", "Also", "allowed", "for", "sequencing", "in"], "add_tokens": "it 'should be cool with an empty tag' do html = @parser . parse ( \"\\\\emph{}\" ) . html html . should == \"<div class='document'><p><em></em></p></div>\" end end describe \"#special\" do it 'should escape a special character' do html = @parser . parse ( \"War \\\\& Peace\" ) . html html . should == \"<div class='document'><p>War & Peace</p></div>\" end it 'should allow for special chars and tags in sequence' do html = @parser . parse ( \"War \\\\& Peace \\\\textbf{Tolstoy} \\\\#\" ) . html html . should == \"<div class='document'><p>War & Peace <strong>Tolstoy</strong> #</p></div>\" html = @parser . parse ( \"a \\\\emph{hey} b\" ) . html html . should == \"<div class='document'><p>a <em>hey</em> b</p></div>\" it 'should allow sequences of content within a tag' do html = @parser . parse ( \"\\\\textsc{hey \\\\emph{vibes} \\& times}\" ) . html html . should == \"<div class='document'><p><span class='textsc'>hey <em>vibes</em> & times</span></p></div>\" end it 'should escape special characters in a tag' do html = @parser . parse ( \"\\\\emph{War \\\\& Peace}\" ) . html html . should == \"<div class='document'><p><em>War & Peace</em></p></div>\" end", "del_tokens": "it 'should blow up with an empty tag' do html = @parser . parse ( \"\\\\emph{}\" ) . should be_false html = @parser . parse ( \"\\\\emph{hey}\" ) . html html . should == \"<div class='document'><p><em>hey</em></p></div>\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "columns", "backend", "with", "dirty", "enabled"], "add_tokens": "options [ :locale_accessors ] ||= options [ :dirty ] if options [ :dirty ]", "del_tokens": "options [ :locale_accessors ] ||= options [ :dirty ] if options [ :dirty ]", "commit_type": "fix"}
{"commit_tokens": ["Changed", "AUDIO_FORMAT", "constant", "to", "PCM", "to", "improve", "code", "readability", "."], "add_tokens": "PCM = 1 file_contents += [ PCM ] . pack ( \"v\" ) unless header [ :audio_format ] == PCM", "del_tokens": "AUDIO_FORMAT = 1 file_contents += [ AUDIO_FORMAT ] . pack ( \"v\" ) unless header [ :audio_format ] == AUDIO_FORMAT", "commit_type": "change"}
{"commit_tokens": ["Add", "more", "attributes", "to", "the", "user", "."], "add_tokens": "# A little prosa about this user attr_reader :description # When this user was created attr_reader :account_created # All languages the user can speak attr_reader :languages # Lat/Lon Coordinates of the users home. attr_reader :lat , :lon # A picture from this user attr_reader :img @id = attrs [ 'id' ] . to_i if attrs [ 'id' ] @display_name = attrs [ 'display_name' ] @lat = attrs [ 'home' ] [ 'lat' ] . to_f @lon = attrs [ 'home' ] [ 'lon' ] . to_f @languages = attrs [ 'languages' ] [ 'lang' ] if attrs [ 'languages' ] @description = attrs [ 'description' ] @account_created = Time . parse ( attrs [ 'account_created' ] ) rescue nil @img = attrs [ 'img' ] [ 'href' ] if attrs [ 'img' ]", "del_tokens": "@id = attrs [ 'id' ] . to_i if attrs [ 'id' ] @display_name = attrs [ 'display_name' ]", "commit_type": "add"}
{"commit_tokens": ["Remove", "deprecated", "method", "log", "a", "lot"], "add_tokens": "# Called by PgCharmer::Railtie after active_record.initialize_database or manually if", "del_tokens": "# Called by PgCharmer::Railtie after active_record.initialize_database or manually if", "commit_type": "remove"}
{"commit_tokens": ["Move", "dashboard", "to", "application", "controller"], "add_tokens": "root 'application#dashboard'", "del_tokens": "root 'dashboard#index'", "commit_type": "move"}
{"commit_tokens": ["updated", "connection", "settings", "to", "apply", "user", "-", "agent", "header"], "add_tokens": "end end # @param [String] keywords response = self . connection . get ( uri ) do | request | request . headers [ 'Content-Type' ] = 'application/json' request . headers [ 'Accept' ] = 'application/json' request . headers [ 'User-Agent' ] = 'Newegg iPhone App / 4.1.2' end request . headers [ 'User-Agent' ] = 'Newegg iPhone App / 4.1.2'", "del_tokens": "end end # @param [String] keywords response = self . connection . get ( uri ) request . headers [ 'Api-Version' ] = '2.2'", "commit_type": "update"}
{"commit_tokens": ["add", "mailgun", "raw", "mime", "option", "don", "t", "need", "to", "set", "mandrill", "api", "key"], "add_tokens": "# @option opts [Float] :spamassassin_threshold the maximum SpamAssassin # score for a message to be ham", "del_tokens": "# @return [String] the Mandrill API key requires :mandrill_api_key # @return [Float] the minimum SpamAssassin score to be spam # @option opts [String] :mandrill_api_key a Mandrill API key @mandrill_api_key = options [ :mandrill_api_key ]", "commit_type": "add"}
{"commit_tokens": ["added", "cert", "type", "for", "curb"], "add_tokens": "CERT_TYPES = [ :pem , :der ] # Returns the cert type to validate SSL certificates PEM|DER. def cert_type @cert_type ||= :pem end # Sets the cert type to validate SSL certificates PEM|DER. def cert_type = ( type ) raise ArgumentError , \"Invalid SSL cert type: #{type}\" unless CERT_TYPES . include? type @cert_type = type end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "Wait4", ".", "wait4_nonblock", "."], "add_tokens": "describe '#wait4_nonblock' do describe 'churn.rb' do before do @pid = Kernel . fork { Process . exec bin_fixture ( :churn ) , '' , '1' } end after do begin ExecSandbox :: Wait4 . wait4 @pid rescue Errno :: ECHILD # The child's status has already been reaped. end end it 'returns nil when wait4 would block' do ExecSandbox :: Wait4 . wait4_nonblock ( @pid ) . should == nil end it 'does not block' do t_start = Time . now ExecSandbox :: Wait4 . wait4_nonblock @pid t_end = Time . now ( t_end - t_start ) . should < 0.1 end it 'returns resource usage data if called after the process ends' do sleep 2 status = ExecSandbox :: Wait4 . wait4_nonblock @pid status [ :user_time ] . should > 0.5 status [ :user_time ] . should < 2 end end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "TextLine", "::", "scan", "method", "."], "add_tokens": "require 'ffi/aspell' require_relative 'configuration' results = [ ] FFI :: Aspell :: Speller . open ( Configuration [ :language ] ) do | speller | TextLine . scan ( document ) . each do | line | line . words . each do | word | unless speller . correct? word results << Typo . new ( line , word , speller . suggestions ( word ) ) end end end end results", "del_tokens": "[ ]", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "content", "option", "."], "add_tokens": "apipie_options :without => [ :content ]", "del_tokens": "apipie_options", "commit_type": "remove"}
{"commit_tokens": ["Updated", "readme", "version", "bump", "and", "addin", "auto", "mount", "."], "add_tokens": "# Auto Mount Plugin initializer \"phccontactor\" , before : :load_config_initializers do | app | Rails . application . routes . append do mount PHCContactor :: Engine , at : \"/\" end end", "del_tokens": "# Main Dependencies require 'figaro'", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "cache", "constant", "as", "well"], "add_tokens": "check_size ( :size_from_default ) # Default size for the terminal # # @return [Array[Integer, Integer]] # # @api private def size_from_default DEFAULT_SIZE end module_function :size_from_default", "del_tokens": "DEFAULT_SIZE", "commit_type": "change"}
{"commit_tokens": ["Added", "form", "error", "messages", "."], "add_tokens": "@blast . sequence << file if file render :action => \"new\"", "del_tokens": "@blast . sequence = file if @blast . sequence . blank? set_flash_message ( :error , :save_error ) redirect_to :action => \"new\"", "commit_type": "add"}
{"commit_tokens": ["Added", "date", "to", "the", "timestamp"], "add_tokens": "message = Time . now . strftime ( '%Y-%m-%d %T' ) + ' ' + message if filter [ :timestamp ]", "del_tokens": "message = Time . now . strftime ( '%T' ) + ' ' + message if filter [ :timestamp ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "specs", "-", "we", "need", "to", "run", "migrations", "before", "calling", "state_machine", "."], "add_tokens": "CreateTrafficLights . migrate ( :up )", "del_tokens": "ActiveRecord :: Base . establish_connection ( :adapter => \"sqlite3\" , :database => \":memory:\" ) ActiveRecord :: Migration . verbose = false CreateTrafficLights . migrate ( :up )", "commit_type": "fix"}
{"commit_tokens": ["update", "the", "core", "and", "parameter_builder"], "add_tokens": "attr_accessor :params , :data PARAMETERS [ 'match' ] . keys . each do | param_name | if BOOLEAN_PARAMS . include? ( param_name ) define_method param_name do | value = true | @params [ PARAMETERS [ 'match' ] [ param_name ] ] = value ? 'yes' : 'no' self end else define_method param_name do | value | @params [ PARAMETERS [ 'match' ] [ param_name ] ] = value self end end def process_data ( data ) OptaSD :: MatchWrapper . new ( data )", "del_tokens": "attr_accessor :params def resource ( resource_id ) @resource = resource_id self end # Params def live ( value = true ) @params [ 'live' ] = value ? 'yes' : 'no' self def lineups ( value = true ) @params [ 'lineups' ] = value ? 'yes' : 'no' self", "commit_type": "update"}
{"commit_tokens": ["fixes", "typos", "in", "calendar", ".", "rb", "s", "examples"], "add_tokens": "# Calendar.new(:username => 'some.guy@gmail.com', :password => 'ilovepie!') # Calendar.new(:username => 'some.guy@gmail.com', :password => 'ilovepie!', :calendar => 'my.company@gmail.com') # Calendar.new(:username => 'some.guy@gmail.com', :password => 'ilovepie!', :app_name => 'mycompany.com-googlecalendar-integration')", "del_tokens": "# Calendar.new(username: => 'some.guy@gmail.com', :password => 'ilovepie!') # Calendar.new(username: => 'some.guy@gmail.com', :password => 'ilovepie!', :calendar => 'my.company@gmail.com') # Calendar.new(username: => 'some.guy@gmail.com', :password => 'ilovepie!', :app_name => 'mycompany.com-googlecalendar-integration')", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "n", "-", "dimensional", "facets"], "add_tokens": "it \"merges the results in the outer facets\" do { id : 1 , views : 150 , user_id : 1 , state : \"\" } , { id : 4 , views : 3003 , user_id : 1 , state : \"\" } ] end it \"merges the results in the inner facets\" do results [ :facets ] [ :popular ] [ :facets ] [ :with_foxes ] [ :records ] . should == [ { id : 1 , views : 150 , user_id : 1 , state : \"\" }", "del_tokens": "it \"merges the results in the outer facet\" do { id : 1 , views : 150 , user_id : 1 , status : \"\" } , { id : 4 , views : 3002 , user_id : 1 , status : \"\" } ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "where", "namespace", "was", "included", "twice", "in", "config", "key"], "add_tokens": "namespace_name = find_namespace ( key ) || :default namespace = @namespaces [ namespace_name ] if value . respond_to? ( :keys ) namespace [ rest_of_key ( key , namespace_name ) ] = value", "del_tokens": "namespace = @namespaces [ find_namespace ( key ) || :default ] if value . respond_to? :keys namespace [ key ] = value", "commit_type": "fix"}
{"commit_tokens": ["Added", "text", "normalization", "specs", "truncate_title", "does", "not", "add", "page", "title", "when", "site", "title", "is", "too", "long"], "add_tokens": "limit = MetaTags . config . title_limit - separator . length if limit > site_title . length title = truncate_array ( title , limit - site_title . length , separator ) else site_title = truncate ( site_title , limit ) # Site title is too long, we have to skip page title title = [ ] end limit_left = limit - length - ( result . any? ? separator . length : 0 )", "del_tokens": "limit = MetaTags . config . title_limit - site_title . length - separator . length title = truncate_array ( title , limit , separator ) limit_left = limit - length - separator . length", "commit_type": "add"}
{"commit_tokens": ["Use", "protected", "password", "with", "configuration", "name"], "add_tokens": "errors . add ( login_field , \"can not be blank\" ) if send ( login_field ) . blank? errors . add ( password_field , \"can not be blank\" ) if send ( \"protected_#{password_field}\" ) . blank? unless temp_record . send ( verify_password_method , send ( \"protected_#{password_field}\" ) ) private # The password should not be accessible publicly. This way forms using form_for don't fill the password with the attempted password. The prevent this we just create this method that is private. def protected_ #{password_field} @ #{ password_field } end", "del_tokens": "errors . add ( login_field , \"can not be blank\" ) if login . blank? errors . add ( password_field , \"can not be blank\" ) if protected_password . blank? unless temp_record . send ( verify_password_method , protected_password ) # The password should not be accessible publicly. This way forms using form_for don't fill the password with the attempted password. The prevent this we just create this method that is private. def protected_password @password end", "commit_type": "use"}
{"commit_tokens": ["Change", "page_count", "method", "to", "be", "just", "named", "count", "."], "add_tokens": "def count @count ||= begin", "del_tokens": "def page_count @page_count ||= begin", "commit_type": "change"}
{"commit_tokens": ["improve", "the", "views", "for", "index", "/", "new", "/", "edit"], "add_tokens": "model_class . name . titleize . gsub ( '/' , ' / ' )", "del_tokens": "model_class . name . gsub '::' , ' '", "commit_type": "improve"}
{"commit_tokens": ["fix", "erb", "rendering", "require", "directory", "to", "clone", "app", "into"], "add_tokens": ":require => [ reference ( :user , \"rails\" ) , reference ( :file , \"/srv/rails\" ) ] :content => ERB . new ( File . read ( File . join ( File . dirname ( __FILE__ ) , '..' , '..' , 'templates' , 'vhost.conf.erb' ) ) ) . result ( binding ) ,", "del_tokens": ":require => reference ( :user , \"rails\" ) :content => ERB . new ( File . join ( File . dirname ( __FILE__ ) , '..' , '..' , 'templates' , 'vhost.conf.erb' ) ) . result ( binding ) ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "wikipedia", "search", "for", "legislators"], "add_tokens": "module GovKit :: SearchEngines autoload :Wikipedia , 'gov_kit/search_engines/wikipedia'", "del_tokens": "module GovKit :: SearchEngines", "commit_type": "add"}
{"commit_tokens": ["Adding", "the", "subject_id", "and", "_type", "columns", "to", "tests"], "add_tokens": "main_category_title : p . main_category_title , subject_id : p . subject_id , subject_type : p . subject_type", "del_tokens": "main_category_title : p . main_category_title", "commit_type": "add"}
{"commit_tokens": ["Add", "Derelict", "::", "Logger", "module"], "add_tokens": "autoload :Logger , \"derelict/logger\" # Include \"logger\" method to get a logger for this class extend Logger # Enables (or disables) Derelict's debug mode # # When in debug mode, Derelict will log to stderr. The debug level # can be controlled as well (which affects the verbosity of the # logging). def debug! ( options = { } ) :: Log4r :: Logger [ \"root\" ] # creates the level constants (INFO, etc). options = { :enabled => true , :level => :: Log4r :: INFO , } . merge options if options [ :enabled ] stderr = :: Log4r :: Outputter . stderr logger . add stderr unless logger . outputters . include? stderr logger . level = options [ :level ] logger . info \"enabling debug mode\" else logger . info \"disabling debug mode\" logger . remove \"stderr\" logger . level = :: Log4r :: OFF end self end", "del_tokens": "# Retrieves the base Log4r::Logger used by Derelict def logger :: Log4r :: Logger [ \"derelict\" ] || :: Log4r :: Logger . new ( \"derelict\" ) end", "commit_type": "add"}
{"commit_tokens": ["fixed", "form", "design", "and", "signup", "process"], "add_tokens": "resource . password ||= Devise . friendly_token", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Fix", "JSON", "tests", "so", "key", "order", "doesn", "t", "matter"], "add_tokens": "include JSONMatchers instance . to_json . should be_json '{\"be\":\"brief\"}' include JSONMatchers instance . to_json . should be_json '{\"latitude\":37.422,\"longitude\":-122.084}' include JSONMatchers include JSONMatchers instance . to_json . should be_json '{\"name\":\"Bob Aman\",\"age\":29}' include JSONMatchers instance . to_json . should be_json '{\"name\":\"Bob Aman\",\"age\":29}' include JSONMatchers instance . to_json . should be_json ( include JSONMatchers include JSONMatchers instance . to_json . should be_json '{\"accountNumber\":\"12345\",\"balance\":1000}' include JSONMatchers instance . to_json . should be_json '{\"givenName\":\"Robert\",\"familyName\":\"Aman\"}' include JSONMatchers instance . to_json . should be_json ( include JSONMatchers instance . to_json . should be_json '{\"left\":null,\"value\":42,\"right\":null}'", "del_tokens": "instance . to_json . should == '{\"be\":\"brief\"}' instance . to_json . should == '{\"latitude\":37.422,\"longitude\":-122.084}' instance . to_json . should == '{\"name\":\"Bob Aman\",\"age\":29}' instance . to_json . should == '{\"name\":\"Bob Aman\",\"age\":29}' instance . to_json . should == ( instance . to_json . should == '{\"accountNumber\":\"12345\",\"balance\":1000}' instance . to_json . should == '{\"givenName\":\"Robert\",\"familyName\":\"Aman\"}' instance . to_json . should == ( instance . to_json . should == '{\"left\":null,\"value\":42,\"right\":null}'", "commit_type": "fix"}
{"commit_tokens": ["Removed", "dependency", "on", "active_support", "(", "not", "needed", ")", "and", "socket", "(", "included", "in", "Ruby", ")", ";", "Added", "random", "creation", "of", "transaction", "ID", "for", "<login", ">", "and", "<logout", ">", "transactions", ";"], "add_tokens": "require 'uuidtools'", "del_tokens": "require 'socket' require 'active_support'", "commit_type": "remove"}
{"commit_tokens": ["Add", "spec", "to", "ensure", "that", "predictor", "works", "with", "renamed", "files"], "add_tokens": "subject ( :forecast ) { Crystalball . foresee ( workdir : root , map_path : root . join ( 'execution_map.yml' ) ) } include_context 'simple git repository'", "del_tokens": "subject ( :forecast ) { Crystalball . foresee ( root , root . join ( 'execution_map.yml' ) ) } let ( :simple_app_path ) { Pathname ( __dir__ ) . join ( 'fixtures' , 'simple_app' ) } let ( :tmp_path ) { Pathname ( __dir__ ) . join ( 'tmp' ) } let ( :root ) { tmp_path . join ( 'simple_app' ) } let ( :lib_path ) { root . join ( 'lib' ) } let ( :class1_path ) { lib_path . join ( 'class1.rb' ) } let ( :class2_path ) { lib_path . join ( 'class2.rb' ) } after do root . rmtree end before do tmp_path . mkpath FileUtils . cp_r ( simple_app_path , tmp_path ) git = Git . init ( root . to_s ) git . add ( all : true ) git . commit ( 'First commit' ) system ( \"cd #{root} && rspec spec\" ) # Generate crystalball map end", "commit_type": "add"}
{"commit_tokens": ["added", "byte", "array", "to", "the", "filter"], "add_tokens": "[ \"character\" , \"varchar\" , \"text\" , \"text[]\" , \"bytea\" ] => [ :nil , :text , :text_delimited ] ,", "del_tokens": "[ \"character\" , \"varchar\" , \"text\" , \"text[]\" ] => [ :nil , :text , :text_delimited ] ,", "commit_type": "add"}
{"commit_tokens": ["Improve", "human", "output", "used", "to", "report", "progress"], "add_tokens": "format '%3d%% Host: %s' , progress * 100 , input [ :host ] [ :name ]", "del_tokens": "format '%3d%% %s' , progress * 100 , input [ :host ] [ :name ]", "commit_type": "improve"}
{"commit_tokens": ["fixed", "old", "icon", "and", "stylesheets"], "add_tokens": "html << \"<img align=\\\"top\\\" alt=\\\"select date\\\" border=\\\"0\\\" src=\\\"/images/mf_calendar.png\\\" />\"", "del_tokens": "html << \"<img align=\\\"top\\\" alt=\\\"select date\\\" border=\\\"0\\\" src=\\\"/images/calendar_icon.png\\\" />\"", "commit_type": "fix"}
{"commit_tokens": ["change", "signature", "of", "setup_call", "move", "into", "ZookeeperCommon"], "add_tokens": "req_id = setup_call ( :get , options ) req_id = setup_call ( :set , options ) req_id = setup_call ( :get_children , options ) req_id = setup_call ( :stat , options ) req_id = setup_call ( :create , options ) req_id = setup_call ( :delete , options ) req_id = setup_call ( :set_acl , options ) req_id = setup_call ( :get_acl , options )", "del_tokens": "req_id = setup_call ( options ) req_id = setup_call ( options ) req_id = setup_call ( options ) req_id = setup_call ( options ) req_id = setup_call ( options ) req_id = setup_call ( options ) req_id = setup_call ( options ) req_id = setup_call ( options ) def setup_call ( opts ) req_id = nil @req_mutex . synchronize { req_id = @current_req_id @current_req_id += 1 setup_completion ( req_id , opts ) if opts [ :callback ] setup_watcher ( req_id , opts ) if opts [ :watcher ] } req_id end def setup_watcher ( req_id , call_opts ) @watcher_reqs [ req_id ] = { :watcher => call_opts [ :watcher ] , :context => call_opts [ :watcher_context ] } end", "commit_type": "change"}
{"commit_tokens": ["removed", "history", "improved", "README", "and", "moved", "files", "into", "folder", "reflecting", "module"], "add_tokens": "VERSION = '1.2.0' require 'geokit/geocoders' require 'geokit/mappable'", "del_tokens": "VERSION = '1.1.0' require 'geocoders' require 'mappable'", "commit_type": "remove"}
{"commit_tokens": ["Added", "option", "to", "ForkedComponent", "not", "to", "reopen", "the", "stdio", "."], "add_tokens": "attr_accessor :reopen_stdio @reopen_stdio = true if @reopen_stdio fn = File . join ( @output_basedir , \"#{@name}.#{Process.pid}.out\" ) outfile = File . new ( fn , 'w+' ) $stderr . reopen ( outfile ) $stdout . reopen ( outfile ) end", "del_tokens": "fn = File . join ( @output_basedir , \"#{@name}.#{Process.pid}.out\" ) outfile = File . new ( fn , 'w+' ) $stderr . reopen ( outfile ) $stdout . reopen ( outfile )", "commit_type": "add"}
{"commit_tokens": ["uses", ":", "get", "as", "the", "default", "HTTP", "method", "if", "not", "specified"], "add_tokens": "self . class . http_method || @api . class . http_method || :get", "del_tokens": "self . class . http_method || @api . class . http_method", "commit_type": "use"}
{"commit_tokens": ["improved", "guatd", "detection", "more", "tests", "better", "test", "matching", "in", "guard"], "add_tokens": "gem 'fake-gem-name-a' RUBY_VERSION == \"2.0.0\" && # check Gemfile $0 != \"-e\" # do not do that in guard require 'minitest/autorun' unless $0 == \"-e\" # skip in guard", "del_tokens": "RUBY_VERSION == \"2.0.0\" # check Gemfile require 'minitest/autorun'", "commit_type": "improve"}
{"commit_tokens": ["Using", "sqlite3", "as", "default", "test", "database", "."], "add_tokens": "ActiveRecord :: Base . establish_connection ( ENV [ 'DB' ] || 'sqlite3' )", "del_tokens": "ActiveRecord :: Base . establish_connection ( ENV [ 'DB' ] || 'mysql' )", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "async_push_to_global_registry", "passes", "parent", "to", "update", "method"], "add_tokens": "update_in_global_registry ( parent_id , parent_type , parent )", "del_tokens": "update_in_global_registry ( parent_id , parent_type )", "commit_type": "make"}
{"commit_tokens": ["fixed", "up", "test", "to", "use", "the", "new", "API"], "add_tokens": "n = Flapjack :: NotifierCLI . new ( :logger => MockLogger . new ) n . setup_config ( :yaml => { :notifiers => { } } ) n . setup_recipients ( :filename => File . join ( File . dirname ( __FILE__ ) , 'fixtures' , 'recipients.yaml' ) ) n . setup_database ( :database_uri => \"sqlite3://#{File.expand_path(File.dirname(__FILE__))}/test.db\" ) n . setup_notifier # create a dummy check DataMapper . auto_migrate!", "del_tokens": "n = Flapjack :: NotifierCLI . new n . notifier = Flapjack :: Notifier . new ( :logger => n . log , :recipients => n . recipients )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "with", "database", "config"], "add_tokens": "if VALID_EXTRA_KEY . include? ( key )", "del_tokens": "if VALID_EXTRA_KEY . includ? ( key )", "commit_type": "fix"}
{"commit_tokens": ["updates", "errors", "and", "error", "messages"], "add_tokens": "class RateLimitExceededError < LinkedInError ; end class UnauthorizedError < LinkedInError ; end class GeneralError < LinkedInError ; end class UnavailableError < StandardError ; end class InformLinkedInError < StandardError ; end class NotFoundError < StandardError ; end", "del_tokens": "class RateLimitExceeded < LinkedInError ; end class Unauthorized < LinkedInError ; end class General < LinkedInError ; end class Unavailable < StandardError ; end class InformLinkedIn < StandardError ; end class NotFound < StandardError ; end", "commit_type": "update"}
{"commit_tokens": ["fix", "search", "&", "replace", "bug"], "add_tokens": "require 'dohmysql/typed_row_builder'", "del_tokens": "require 'dohmysql/typed_build_arg'", "commit_type": "fix"}
{"commit_tokens": ["Add", "NONE", "to", "disable", "all", "logs"], "add_tokens": "when 'error' then Logging :: ERROR when 'warn' then Logging :: WARN when 'info' then Logging :: INFO when 'debug' then Logging :: DEBUG when 'trace' then Logging :: TRACE when 'none' then Logging :: NONE", "del_tokens": "when 'error' then Logging :: ERROR when 'warn' then Logging :: WARN when 'info' then Logging :: INFO when 'debug' then Logging :: DEBUG when 'trace' then Logging :: TRACE", "commit_type": "add"}
{"commit_tokens": ["remove", "staging", "integration", "after", "release"], "add_tokens": "jira_server . getIssuesFromJqlSearch \"project = 'SCWEBAPP' and 'Git Branch' ~ '#{branch}'\" , 1000", "del_tokens": "jira_server . getIssuesFromJqlSearch ( \"project = 'SCWEBAPP' and 'Git Branch' ~ '#{branch}'\" )", "commit_type": "remove"}
{"commit_tokens": ["added", "logging", "messages", "when", "loading", "notifiers"], "add_tokens": "@log . debug ( \"Loading the #{notifier.to_s.capitalize} notifier\" ) else end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Added", "handling", "of", "Authorization", "::", "AuthorizationInController", "::", "ClassMethods", ".", "filter_access_to", "parameters", "that", "are", "of", "the", "form", "[", ":", "show", ":", "update", "]", "instead", "of", "just", ":", "show", ":", "update", ".", "[", "jeremyf", "]"], "add_tokens": "actions = args . flatten", "del_tokens": "actions = args", "commit_type": "add"}
{"commit_tokens": ["Make", "initial", "ordering", "work", "and", "work", "simpler"], "add_tokens": "class_attribute :initial_order def initial_ordering ( orderings ) self . initial_order = orderings end if params [ :bUseDefaultSort ] == 'true' and self . initial_order . present? column = self . columns . select { | c | c . name == self . initial_order . keys . first . to_s } . first direction = self . initial_order . values . first . to_s == \"asc\" ? 1 : - 1", "del_tokens": "class_attribute :initial_ordering # def initial_ordering(orderings) # self.set_initial_orderings orderings # end # def set_initial_orderings(orderings) # self.initial_orderings = {} if self.initial_orderings.nil? # self.initial_orderings.merge! orderings # end binding . pry if params [ :bUseDefaultSort ] == 'true' column = self . columns . select { | c | c . name == self . initial_ordering . keys . first . to_s } . first directions = self . initial_ordering . values . first . to_s == \"asc\" ? 1 : - 1", "commit_type": "make"}
{"commit_tokens": ["Add", "alias_style", "like", "alias_color", "but", "with", "multiple", "colors", "."], "add_tokens": ":enabled? , :colored? , :alias_color , :alias_style , :lookup", "del_tokens": ":enabled? , :colored? , :alias_color , :lookup", "commit_type": "add"}
{"commit_tokens": ["Improve", "the", "way", "it", "turns", "ActiveRecord", "models", "into", "resources"], "add_tokens": "unless JSONAPI . configuration . default_paginator == :none end records . respond_to? ( :to_ary ) ? records . map { | record | turn_into_resource ( record , options ) } : [ ]", "del_tokens": "return [ ] if records . nil? || records . empty? JSONAPI . configuration . default_paginator == :none || records . map { | record | turn_into_resource ( record , options ) }", "commit_type": "improve"}
{"commit_tokens": ["Remove", "verbose", "option", "from", "normal", "logger"], "add_tokens": "puts ( text )", "del_tokens": "def initialize ( verbose : true ) @verbose = verbose end puts ( text ) if verbose private attr_reader :verbose", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "to", "use", "tracking", "domain", "."], "add_tokens": "describe '#tracking_domain' do it 'takes a tracking_domain' do mail = mail ( tracking_domain : 'tracking_domain.com' ) message = described_class . new ( mail ) expect ( message . tracking_domain ) . to eq ( 'tracking_domain.com' ) end it 'does not take tracking_domain value' do mail = mail ( ) message = described_class . new ( mail ) expect ( message . tracking_domain ) . to be_nil end end", "del_tokens": "pending '#tracking_domain'", "commit_type": "add"}
{"commit_tokens": ["make", "it", "possible", "to", "disable", "in", "block"], "add_tokens": "instance_eval ( & block ) instance_eval ( & block )", "del_tokens": "instance_eval ( & block ) instance_eval ( & block )", "commit_type": "make"}
{"commit_tokens": ["Use", "assert_row_size", "method", "in", "TTY", "::", "Table#<<"], "add_tokens": "assert_row_size ( row , rows )", "del_tokens": "rows_copy = rows . dup assert_row_sizes rows_copy << row", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "arbitrary", "HTML", "attributes", "in", "a", "tag"], "add_tokens": "t << \"<#{html_attribute}\" options . select { | k , v | k != :close_tag } . each do | k , v | t << \" #{k}='#{v}'\" end t << \"</#{html_attribute}>\" unless options [ :close_tag ] == false", "del_tokens": "t << \"<\" + html_attribute t << \" id='\" + options [ :id ] + \"'\" if options [ :id ] t << \" class='\" + options [ :class ] + \"'\" if options [ :class ] t << \" href='\" + options [ :href ] + \"'\" if options [ :href ] t << \"</\" + html_attribute + \">\" unless options [ :close_tag ] == false", "commit_type": "add"}
{"commit_tokens": ["Add", "status", "endpoint", "for", "Alerting", "client"], "add_tokens": "describe 'Alerts' , vcr : { decode_compressed_response : true } do before ( :each ) do @client = Hawkular :: Alerts :: AlertsClient . new ( ALERTS_BASE , creds ) end it 'Should return the version' do data = @client . fetch_version_and_status expect ( data ) . not_to be_nil end end", "del_tokens": "# TODO: enable when alerts supports it # describe 'Alerts' do # it 'Should return the version' do # data = @client.get_version_and_status # expect(data).not_to be_nil # end # end", "commit_type": "add"}
{"commit_tokens": ["use", "request", "timestamp", "returned", "from", "server", "to", "update", "synced_all_at"], "add_tokens": "raise MissingTimestampError . new unless first_request_timestamp @timestamp_strategy . update ( first_request_timestamp ) def first_request_timestamp if first_response_headers && first_response_headers [ \"x-updated-since-request-synced-at\" ] Time . zone . parse ( first_response_headers [ \"x-updated-since-request-synced-at\" ] ) end end def first_response_headers remote_objects @first_response_headers ||= api . pagination_first_response . headers end class MissingTimestampError < StandardError def message \"Synchronization failed. API response is missing 'x-updated-since-request-synced-at' header.\" end end", "del_tokens": "@timestamp_strategy . update ( Time . now )", "commit_type": "use"}
{"commit_tokens": ["Move", "everything", "inside", "Open3", ".", "popen3", "block"], "add_tokens": "raise ArgumentError . new ( error ) unless error . empty? return output", "del_tokens": "output = '' error = '' raise ArgumentError . new ( error ) unless error . empty? output", "commit_type": "move"}
{"commit_tokens": ["added", "specs", "for", "new", "methods"], "add_tokens": "it \"checks if a user has any connection with another user\" do @john . is_connected_with? ( @jane ) . should == true @jane . is_connected_with? ( @john ) . should == true @john . is_connected_with? ( @peter ) . should == true @peter . is_connected_with? ( @john ) . should == true @victoria . is_connected_with? ( @john ) . should == false @john . is_connected_with? ( @victoria ) . should == false end it \"checks if a user has invited another user\" do @john . has_invited? ( @jane ) . should == true @john . has_invited? ( @james ) . should == true @jane . has_invited? ( @john ) . should == false @james . has_invited? ( @john ) . should == false @victoria . has_invited? ( @john ) . should == false @john . has_invited? ( @victoria ) . should == false end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["updates", "pid", "file", "tests", "to", "not", "assume", "running", "out", "of", "the", "root", "dir"], "add_tokens": "@pid_file_path = File . join ( ROOT , \"tmp/my.pid\" ) @pid_file = Sanford :: Manager :: PIDFile . new ( @pid_file_path ) FileUtils . rm_rf ( @pid_file_path ) assert_equal @pid_file_path , subject . to_s assert_file_exists @pid_file_path assert_equal \"#{Process.pid}\\n\" , File . read ( @pid_file_path ) assert_not File . exists? ( @pid_file_path )", "del_tokens": "@pid_file = Sanford :: Manager :: PIDFile . new ( \"tmp/my.pid\" ) FileUtils . rm_rf ( \"tmp/my.pid\" ) assert_equal \"tmp/my.pid\" , subject . to_s assert File . exists? ( \"tmp/my.pid\" ) assert_equal \"#{Process.pid}\\n\" , File . read ( \"tmp/my.pid\" ) assert_not File . exists? ( \"tmp/my.pid\" )", "commit_type": "update"}
{"commit_tokens": ["Adding", "Sid", "derieved", "plugins", "specs", "for", "plugins"], "add_tokens": "cpuinfo = Mash . new real_cpu = Mash . new cpuinfo [ $1 ] = Mash . new", "del_tokens": "cpuinfo = Hash . new real_cpu = Hash . new cpuinfo [ $1 ] = Hash . new", "commit_type": "add"}
{"commit_tokens": ["add", "server", "cert", "gen", "support"], "add_tokens": "end @ca_cert = ca_crt end @cert . version = 2 def get_extensions extensions = Hash . new cert = OpenSSL :: X509 :: Certificate . new @cert . to_pem cert . extensions . each do | ext | extensions [ ext . oid ] = ext . value end extensions end if @certtype . eql? EasyRSA :: Certificate :: Client @cert . add_extension ef . create_extension ( 'nsComment' , 'Easy-RSA Generated Certificate' ) @cert . add_extension ef . create_extension ( 'nsCertType' , 'client, objsign' ) elsif @certtype . eql? EasyRSA :: Certificate :: Server @cert . add_extension ef . create_extension ( 'nsComment' , 'Easy-RSA Generated Server Certificate' ) @cert . add_extension ef . create_extension ( 'nsCertType' , 'server' )", "del_tokens": "end @ca_cert = ca_crt end @cert . version = 2 ef . create_extension ( 'nsComment' , 'Easy-RSA Generated Certificate' ) , if @certtype == EasyRSA :: Certificate :: Client ef . create_extension ( 'nsCertType' , 'client, objsign' ) elsif @certtype == EasyRSA :: Certificate :: Server ef . create_extension ( 'nsCertType' , 'server' )", "commit_type": "add"}
{"commit_tokens": ["Add", "data", "store", "to", "register", "network", "ports"], "add_tokens": "exception = nil begin @log . info \"Pre-execution setup\" pre_script ( job , job_paths , script ) @log . info \"Running execution script\" state = script . run rescue = > e exception = e end begin @log . info \"Post-execution cleanup\" post_script ( job , job_paths , script ) # Upload results # TODO: Do this outside of the execute_job method job_paths . finalise_results_directory upload_files ( job , job_paths . results_path , job_paths . logs_path ) results = gather_results ( job_paths ) if results @log . info ( \"The results are ...\" ) @log . info ( results . inspect ) job . update_results ( results ) end rescue = > e raise exception || e raise exception if exception", "del_tokens": "@log . info \"Pre-execution setup\" pre_script ( job , job_paths , script ) @log . info \"Running execution script\" state = script . run @log . info \"Post-execution cleanup\" post_script ( job , job_paths , script ) # Upload results # TODO: Do this outside of the execute_job method job_paths . finalise_results_directory upload_files ( job , job_paths . results_path , job_paths . logs_path ) results = gather_results ( job_paths ) if results @log . info ( \"The results are ...\" ) @log . info ( results . inspect ) job . update_results ( results )", "commit_type": "add"}
{"commit_tokens": ["Move", "all", "variables", "to", "constants", ".", "rb"], "add_tokens": "require_relative 'constants' value1 = exec_command \"git log --tags --simplify-by-decoration --pretty=\\\"format:%ci %d\\\" | grep tag\" scan_results = value1 . scan ( / .*tag.* / ) if @oauth_token . length github = Github . new oauth_token : @oauth_token else github = Github . new end issues = github . pull_requests . list @github_user , @github_repo_name , :state => 'closed' json = issues . body json . each { | dict | # print_json dict # puts \"##{dict[:number]} - #{dict[:title]} (#{dict[:closed_at]})\" } json end def compund_changelog ( tag_time , pull_requests ) log += \"- #{merge}\" compund_changelog tag_time , pull_requests", "del_tokens": "@project_path = '/Users/petrkorolev/repo/ActionSheetPicker-3.0' @github_user = 'skywinder' @github_repo_name = 'ActionSheetPicker-3.0' tag1 = '1.1.21' tag2 = '1.2.0' value1 = exec_command \"git log --tags --simplify-by-decoration --pretty=\\\"format:%ci %d\\\" | grep tag\" scan_results = value1 . scan ( / .*tag.* / ) github = Github . new oauth_token : '8587bb22f6bf125454768a4a19dbcc774ea68d48' issues = github . pull_requests . list 'skywinder' , 'ActionSheetPicker-3.0' , :state => 'closed' json = issues . body json . each { | dict | # print_json dict # puts \"##{dict[:number]} - #{dict[:title]} (#{dict[:closed_at]})\" } json end def compund_changelog ( tag_time , pull_requests ) log += \"- #{merge}\" compund_changelog ( tag_time , pull_requests )", "commit_type": "move"}
{"commit_tokens": ["updated", "data", "and", "bumped", "version"], "add_tokens": "VERSION = '0.3.2'", "del_tokens": "VERSION = '0.3.1'", "commit_type": "update"}
{"commit_tokens": ["Adds", "synchronization", "with", "local", "in", "-", "memory", "collection"], "add_tokens": "msg : 'collection_add' ,", "del_tokens": "msg : 'add_collection' ,", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "attribute_dirty?", "check", "for", "validates_is_confirmed", "."], "add_tokens": "property :size , Integer it \"should only validate if the attribute is dirty\" do class Transformer include DataMapper :: Resource property :id , Integer , :serial => true property :name , String property :assoc , String validates_is_confirmed :name attr_accessor :name_confirmation end Transformer . auto_migrate! # attribute_dirty? tf = Transformer . new ( :name => \"Optimus Prime\" , :name_confirmation => \"Optimus Prime\" , :assoc => \"Autobot\" ) tf . should be_valid tf . save . should == true tf = Transformer . first tf . update_attributes ( :assoc => \"Autobot!\" ) . should == true end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "prevent", "redecoration", "with", "the", "same", "color", "."], "add_tokens": "ansi_colors = lookup ( * colors . dup . uniq )", "del_tokens": "ansi_colors = lookup ( * colors )", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "UPNP", "unsubscribe", "method", "+", "timeouts"], "add_tokens": "TIMEOUT = 600 response = client . request ( :subscribe , event_uri , header : { 'CALLBACK' => \"<#{callback_url}>\" , 'NT' => 'upnp:event' , 'Timeout' => \"Seconds-#{TIMEOUT}\" } ) def unsubscribe_from_upnp_events ( sid ) HTTPClient . new . request ( :subscribe , event_uri , header : { 'SID' => sid } ) end private def event_uri \"http://#{self.ip}:#{Sonos::PORT}/MediaServer/ContentDirectory/Event\" end", "del_tokens": "uri = \"http://#{self.ip}:#{Sonos::PORT}/MediaServer/ContentDirectory/Event\" response = client . request ( :subscribe , uri , header : { 'CALLBACK' => \"<#{callback_url}>\" , 'NT' => 'upnp:event' } )", "commit_type": "add"}
{"commit_tokens": ["Move", "file", "to", "lib", "dir"], "add_tokens": "require_relative './lib/lightstep.rb'", "del_tokens": "require './lightstep.rb'", "commit_type": "move"}
{"commit_tokens": ["Made", "CommandReply", "instances", "an", "array", "instance", "variable", "on", "Session"], "add_tokens": "# Either as a Session, a continuation of a Session, or as a Session's last CommandReply if @session . initiated? @session << data reply_received ( @session . replies . last ) if @session . replies . last . complete? else @session << data session_initiated ( @session ) if @session . initiated? end @data = data @data << data attr_accessor :replies def initialize ( data ) super @replies = [ ] end def << ( data ) if initiated? if @replies . empty? or @replies . last . complete? @replies << CommandReply . new ( data ) else @replies . last << data end else super end end # Set this to true for now, fill it in when we know what completed a reply def complete? true end", "del_tokens": "# Either as a Session, a continuation of a Session, or as a CommandReply @session . initiated? ? reply_received ( CommandReply . new ( data ) ) : @session << data @data = \"\" @data << data", "commit_type": "make"}
{"commit_tokens": ["allows", "any", "number", "of", "args", "to", "Heritage#record", "."], "add_tokens": "def record ( method , name , options = nil , & block ) # FIXME: dup all additional args? self [ method ] << { args : [ name , options ? options . dup : nil ] . compact , block : block } # DISCUSS: options.dup.", "del_tokens": "def record ( method , name , options , & block ) self [ method ] << { args : [ name , options . dup ] , block : block } # DISCUSS: options.dup.", "commit_type": "allow"}
{"commit_tokens": ["Add", "(", "optional", ")", "org", "-", "guid", "to", "Gateway", "provision", "request"], "add_tokens": "optional :organization_guid , String", "del_tokens": "optional :user_guid , String", "commit_type": "add"}
{"commit_tokens": ["Add", "functionnals", "tests", "for", "client", "class"], "add_tokens": "expect ( songs . first ) . to be_a ( Grooveshark :: Song ) it 'should return playlist' do playlists = @gs . search ( 'Playlists' , 'CruciAGoT' ) expect ( playlists ) . to be_a ( Array ) expect ( playlists . first ) . to be_a ( Grooveshark :: Playlist ) expect ( playlists . size ) . to_not eq ( 0 ) end it 'should return result' do artists = @gs . search ( 'Artists' , 'Nirvana' ) expect ( artists ) . to be_a ( Array ) expect ( artists . first ) . to be_a ( Hash ) expect ( artists . size ) . to_not eq ( 0 ) end end", "del_tokens": "end # context 'download' do # it 'should download without being banned' do # gs = Grooveshark::Client.new # # Usually IP is banned after about 15 minutes # ten_minutes_later = Time.new + 15 * 60 # while Time.new < ten_minutes_later # # Try with a short song (this one is about a minute long) # song = gs.search_songs('Alan Reeves The Chase').first # url = gs.get_song_url(song) # file = RestClient::Request # .execute(method: :post, url: url, raw_response: true).file # case mime_type = `file -b --mime-type #{file.path}`.strip # when /^audio\\// # # This is the expected type # when /^application\\/octet-stream$/ # # Sometimes the file type can't be detected and this type # # is returned. At least we check it's big enough # # to be an audio file. # file.size.should >= 500 * 1024 # else # fail RSpec::Expectations::ExpectationNotMetError, # \"Unknown MIME type (#{mime_type})\" # end # end # end # end", "commit_type": "add"}
{"commit_tokens": ["Allow", "passing", "a", "block", "to", "any", "attribute", "."], "add_tokens": "define_method ( name ) do | arg = nil , & block | set_or_return ( name , arg || block , opts )", "del_tokens": "define_method ( name ) do | arg = nil | set_or_return ( name , arg , opts )", "commit_type": "allow"}
{"commit_tokens": ["Use", "the", "same", "test", "cache", "in", "a", "TestGemstashServer", "otherwise", "it", "won", "t", "get", "cleared", "in", "between", "specs"], "add_tokens": "def initialize ( config = nil , cache : nil ) @cache = cache", "del_tokens": "def initialize ( config = nil )", "commit_type": "use"}
{"commit_tokens": ["Added", "an", "extra", "check", "to", "tournament", "validation", "-", "the", "opponent", "numbers"], "add_tokens": "# Rerank the tournament by score, resolving ties using name. @player . each do | num , p | raise \"player #{num} has no results\" if p . results . size == 0 p . results . each do | r | next unless r . opponent raise \"opponent #{r.opponent} of player #{num} is not in the tournament\" unless @player [ r . opponent ] end end", "del_tokens": "# Rerank the tournament. @player . each { | num , p | raise \"player #{num} has no results\" if p . results . size == 0 }", "commit_type": "add"}
{"commit_tokens": ["Add", "memoization", "for", "one", "-", "to", "-", "one", "associations"], "add_tokens": "define_method ( association_id ) do | * params | get_association ( association_id , params ) do has_one_associate ( association_id ) end set_association ( association_id , associate ) do set_has_one_associate ( association_id , associate ) end define_method ( association_id ) do | * params | get_association ( association_id , params ) do belongs_to_associate ( association_id ) end set_association ( association_id , associate ) do set_belongs_to_associate ( association_id , associate ) end", "del_tokens": "define_method ( association_id ) do has_one_associate ( association_id ) set_has_one_associate ( association_id , associate ) define_method ( association_id ) do belongs_to_associate ( association_id ) set_belongs_to_associate ( association_id , associate )", "commit_type": "add"}
{"commit_tokens": ["Use", "indifferent", "-", "access", "hashes", "store", "everything", "as", "strings", "cfn", "-", "style", "."], "add_tokens": "method_sym = method_sym . to_s . camelize @_options [ method_sym ] ||= HashWithIndifferentAccess . new @_options = HashWithIndifferentAccess . new", "del_tokens": "method_sym = method_sym . to_s . camelize . to_sym @_options [ method_sym ] ||= { } @_options = Hash . new", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "selenium", "node"], "add_tokens": "module Remote class Bridge if browser == :chrome ChromedriverScreenshot :: Platforms . create_platform ( self ) page = ChromedriverScreenshot :: Page . new page . full_screenshot else window_screenshot end", "del_tokens": "module Chrome class Bridge < Remote :: Bridge ChromedriverScreenshot :: Platforms . create_platform ( self ) page = ChromedriverScreenshot :: Page . new page . full_screenshot", "commit_type": "add"}
{"commit_tokens": ["Made", "it", "possible", "to", "write", "a", "WHERE", "not", "(", "x", "-", "[", ":", "friends", "]", "-", ">", "y", ")", "as", "Neo4j", ".", "rb", "Cypher", "DSL", "(", "x", ">", ":", "friends", ">", "y", ")", ".", "not"], "add_tokens": "def not expressions . delete ( self ) ExprOp . new ( left , nil , \"not\" ) . binary! end if RUBY_VERSION > \"1.9.0\" eval %{ def ! expressions . delete ( self ) ExprOp . new ( left , nil , \"not\" ) . binary! end } end if val . respond_to? ( :var_name ) && ! val . kind_of? ( Match )", "del_tokens": "if val . respond_to? ( :var_name )", "commit_type": "make"}
{"commit_tokens": ["Fix", "rubocop", "Style", "/", "RedundantSelf"], "add_tokens": "load_config load_translations", "del_tokens": "self . load_config self . load_translations", "commit_type": "fix"}
{"commit_tokens": ["Update", "test_choice", "to", "use", "the", "new", "[", "=", "ARG", "]", "format"], "add_tokens": "long \"--utencil[=UTENCIL]\" - u , - - utencil [ = UTENCIL ] Your favorite eating utencil . long \"--utencil[=UTENCIL]\" - u , - - utencil [ = UTENCIL ] Your favorite eating utencil .", "del_tokens": "long \"--utencil=[UTENCIL]\" - u , - - utencil = [ UTENCIL ] Your favorite eating utencil . long \"--utencil=[UTENCIL]\" - u , - - utencil = [ UTENCIL ] Your favorite eating utencil .", "commit_type": "update"}
{"commit_tokens": ["Add", "system", "log", "viewer", "."], "add_tokens": "include Comparable SEVERITY_LIST = %w( DEBUG INFO WARN ERROR FATAL ) ## # Creates a LogEntry. # # The args can either be a JSON string or a Hash. if arg . is_a? ( String ) arg = JSON . parse ( arg ) . symbolize_keys rescue nil end ## # Gets the index in the log file. def index @index ||= 0 end @level_id ||= SEVERITY_LIST . index ( level . to_s . upcase ) || 5 \"#<#{self.class.name} #{level} #{time} [#{app_name} #{app_version} (#{process_id})] #{message.length > 32 ? (message[0...32] + '...') : message}>\" end # :nodoc: def to_s \"#{level} #{time} [#{app_name} #{app_version} (#{process_id})] #{message}\" # :nodoc: def <=> ( other ) return 1 unless other . is_a? ( LogEntry ) if index == other . index time <=> other . time else index <=> other . index end end File . foreach ( log_file , \"\\n\" ) . with_index do | line , index | ret << LogEntry . new ( line . symbolize_keys . merge ( index : index ) ) if line . is_a? ( Hash )", "del_tokens": "# :nodoc: @level_id ||= %w( DEBUG INFO WARN ERROR FATAL ) . index ( level . to_s . upcase ) || 5 \"#<#{self.class.name} #{level} #{time} #{app_name} #{app_version} [#{process_id}] #{message.length > 32 ? (message[0...32] + '...') : message}>\" File . foreach ( log_file , \"\\n\" ) do | line | ret << LogEntry . new ( line . symbolize_keys ) if line . is_a? ( Hash )", "commit_type": "add"}
{"commit_tokens": ["Removed", "logging", "and", "bumped", "minor", "version", ".", "Added", "markdown", "file", "instead", "of", "rdoc", "file", "."], "add_tokens": "def self . authorized? ( user , pass ) resp = self . get ( \"#{AUTH_URL}\" , { :basic_auth => { :username => user , :password => pass } } )", "del_tokens": "def self . authorized? ( u , p ) resp = self . get ( \"#{AUTH_URL}\" , { :basic_auth => { :username => u , :password => p } } )", "commit_type": "remove"}
{"commit_tokens": ["fixing", "package", "&", "errata", "name"], "add_tokens": "PACKAGE = 'telnet-server-0.17-47.el6-x86_64' ERRATA = 'RHSA-2010:0862' [ { :id => \"upload_manifest\" , :sleep_after => 600 ,", "del_tokens": "PACKAGE = 'telnet-server-0.17-47.el6' ERRATA = 'RHBA-2011:0923' [ { :id => \"upload_manifest\" ,", "commit_type": "fix"}
{"commit_tokens": ["Create", "the", "directory", "in", "PATH", "if", "it", "doesn", "t", "exist"], "add_tokens": "# If the directory specified doesn't exist, it will be created. create_dir ( File . basename ( location ) ) if location != Dir . pwd && File . directory? ( location ) Mako . logger . info \"Created new Mako installation in #{location}\" # @private # Copies source templates to specified path. def self . copy_templates ( path ) FileUtils . cp_r \"#{Mako.config.source_templates}/.\" , path end # If the directory does not exist, create the specified directory. def self . create_dir ( path ) FileUtils . mkdir path", "del_tokens": "Mako . logger . info \"Created new Mako instalation in #{location}\" def copy_templates ( path ) FileUtils . cp_r Mako . config . source_templates , path", "commit_type": "create"}
{"commit_tokens": ["Fix", "URL", "building", "for", "when", "the", "base", "URL", "already", "has", "query", "parameters", "and", "add", "test", "."], "add_tokens": "url += \"#{URI.parse(url).query ? '&' : '?'}#{query_string}\"", "del_tokens": "url += \"?#{query_string}\"", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "options", "for", "non", "-", "geokit", "finds"], "add_tokens": "# Restore options minus the extra options that we used for the # Geokit API. args . push ( options )", "del_tokens": "# Restore options minus the extra options that we used for the # Geokit API. args . push ( options )", "commit_type": "fix"}
{"commit_tokens": ["Added", "examples", "to", "README", "."], "add_tokens": "def puts ( * a ) end # Generating a private key # Computing the public key for a private key # Encoding a public key as a binary string # Decoding a public key from a binary string public_key = ECDSA :: Format :: PointOctetString . decode ( public_key_string , group ) # Signing a message # Encoding a signature as a DER string # Decoding a signature from a DER string # Verifying a signature", "del_tokens": "puts 'public key, compressed (hex): ' + public_key_string . unpack ( 'H*' ) [ 0 ] puts 'signature, DER (hex): ' + signature_der_string . unpack ( 'H*' ) [ 0 ] public_key = ECDSA :: Format :: PointOctetString . decode ( public_key_string , group )", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "names", "to", "protect", "the", "innocent", "and", "avoid", "confusion"], "add_tokens": "require 'rs-deploy-mule/cli'", "del_tokens": "require 'mule/cli'", "commit_type": "change"}
{"commit_tokens": ["Added", "MIME", "type", "(", "s", ")"], "add_tokens": "require 'mime/types' attr_reader :mime_type def initialize ( # rubocop:disable Metrics/MethodLength, Metrics/ParameterLists length : nil , mime_type : nil @mime_type = mime_type_or_nil ( mime_type ) def mime_type_or_nil ( mime_type ) return nil unless mime_type return mime_type if mime_type . is_a? ( MIME :: Type ) mt = MIME :: Types [ mime_type ] . first return mt if mt MIME :: Type . new ( mime_type ) end", "del_tokens": "def initialize ( # rubocop:disable Metrics/MethodLength, Metrics/ParameterLists length : nil", "commit_type": "add"}
{"commit_tokens": ["added", "complex", "set", "method", "equality", "and", "associated", "methods", "better", "coverage", "on", "atomic", "file", "locking", "bump", "version"], "add_tokens": "stored_hash = current_hash # Check if all objects in the Threshold Instance report .valid? # Printer # Pass (true) to_s to skip the printing of InternalObjects.comment # The calculated hash of the threshold.conf file at load time. def to_a @thresholds end # Returns a new Threshold Object # Returns a new Threshold Object # Returns a new Threshold Object # Returns a new Threshold Object # Returns a new Threshold Object # Returns a new Threshold Object ## Complex SET Methods ## &(union), | (intersect), + (concat), - (Difference) # + (concat) # Returns a new Threshold Object def + ( an0ther ) Thresholds . new ( @thresholds + an0ther . to_a ) end # | (intersect) # Returns a new Threshold Object def | ( an0ther ) Thresholds . new ( @thresholds | an0ther . to_a ) end # & (union) # Returns a new Threshold Object def & ( an0ther ) Thresholds . new ( @thresholds & an0ther . to_a ) end # - (Difference) # Returns a new Threshold Object def - ( an0ther ) Thresholds . new ( @thresholds - an0ther . to_a ) end", "del_tokens": "## Complex Methods ## &(union), | (intersect), + (concat) ## Should rework to perform to_s before comparison.. ## include?, index", "commit_type": "add"}
{"commit_tokens": ["Added", "resque", "-", "scheduler", "support", "and", "assertions"], "add_tokens": "assert_block ( message || \"#{klass} should not have been queued in #{queue}.\" ) do ! matching_jobs ( queue , klass , args ) . empty? end def matching_jobs ( queue , klass , args = nil ) if args # retrieve the elements that match klass and args in the queue Resque . queue ( queue ) . select { | e | e [ :klass ] == klass && e [ :args ] == args } else # if no args were passed, retrieve all queued jobs that match klass Resque . queue ( queue ) . select { | e | e [ :klass ] == klass }", "del_tokens": "assert_block ( message || \"#{klass} should have been queued in #{queue}.\" ) do if args # verify the klass and args match some element in the queue ! Resque . queue ( queue ) . select { | e | e [ :klass ] == klass && e [ :args ] == args } . empty? else # if no args were passed, just verify the job is in the queue ! Resque . queue ( queue ) . select { | e | e [ :klass ] == klass } . empty?", "commit_type": "add"}
{"commit_tokens": ["Fix", "sequel", "compat", "assuming", "associations", "always", "respond", "to", "primary_key"], "add_tokens": "if v . respond_to? ( :primary_key ) v [ :primary_key ] = v . primary_key else # FIXME: figure out exactly what to do here. # not super critical, as we can't track these associations # directly, but it would be nice to traverse these # properly. v [ :primary_key ] = :unsupported end", "del_tokens": "v [ :primary_key ] = v . primary_key", "commit_type": "fix"}
{"commit_tokens": ["Use", "Time", ".", "current", "instead", "of", "Time", ".", "now", ".", "utc"], "add_tokens": "SELECT id , '#{self.base_class.name}' , '#{Time.current.to_s(:db)}' ReadMark . create! :readable_type => self . base_class . name , :user_id => user . id , :timestamp => Time . current", "del_tokens": "SELECT id , '#{self.base_class.name}' , '#{Time.now.utc.to_s(:db)}' ReadMark . create! :readable_type => self . base_class . name , :user_id => user . id , :timestamp => Time . now . utc", "commit_type": "use"}
{"commit_tokens": ["Removing", "deprecated", "rails", "/", "init", ".", "rb"], "add_tokens": "require File . join ( File . dirname ( __FILE__ ) , \"lib\" , \"govkit\" ) require 'gov_kit/railtie' GovKit :: Railtie . insert", "del_tokens": "require File . join ( File . dirname ( __FILE__ ) , \"lib\" , \"govkit\" )", "commit_type": "remove"}
{"commit_tokens": ["change", "log", "level", "for", "config", "module"], "add_tokens": "logger . info ( 'Instantiate main objects..' ) logger . info ( 'Defining home directory..' ) logger . info ( 'Creating home directory..' ) logger . info ( 'Defining default consumer..' ) logger . info ( 'Defining log directory..' ) logger . info ( 'Creating log directory..' ) logger . info ( 'Define file log devices..' ) logger . info ( 'Defining logger..' ) logger . info ( 'Loading GoGetIt default configuration..' ) logger . info ( 'Copying GoGetIt default configuration..' )", "del_tokens": "logger . debug ( 'Instantiate main objects..' ) logger . debug ( 'Defining home directory..' ) logger . debug ( 'Creating home directory..' ) logger . debug ( 'Defining default consumer..' ) logger . debug ( 'Defining log directory..' ) logger . debug ( 'Creating log directory..' ) logger . debug ( 'Define file log devices..' ) logger . debug ( 'Defining logger..' ) logger . debug ( 'Loading GoGetIt default configuration..' ) logger . debug ( 'Copying GoGetIt default configuration..' )", "commit_type": "change"}
{"commit_tokens": ["Adds", "entitiy", ".", "entities_list", "method"], "add_tokens": "Maestrano :: Connector :: Rails :: Entity . entities_list . each do | entity |", "del_tokens": "# Define all the entities that the connector can synchronize # If you add new entities, you need to generate # a migration to add them to existing organizations ENTITIES = %w( organization person ) ENTITIES . each do | entity |", "commit_type": "add"}
{"commit_tokens": ["add", "subjects", "api", "endpoint", "with", "new", "configuration", "interface"], "add_tokens": "# Contacts the WaniKani API and returns the data specified. # # @param resource [String] the resource to access. # @param parameters [Hash] optional arguments for the specified resource. # @return [Hash] the parsed API response. def get ( resource , parameters = nil ) raise ArgumentError , \"You must define a resource to query WaniKani\" if resource . nil? || resource . empty? begin res = client . get ( \"/#{@api_version}/#{resource}\" , parameters ) if ! res . success? || res . body . has_key? ( \"error\" ) raise_exception ( res ) else return res . body end rescue = > error raise Exception , \"There was an error: #{error.message}\" end end", "del_tokens": "# Contacts the WaniKani API and returns the data specified. # # @param resource [String] the resource to access. # @param optional_arg [String] optional arguments for the specified resource. # @return [Hash] the parsed API response. def api_response ( resource , optional_arg = nil ) raise ArgumentError , \"You must define a resource to query WaniKani\" if resource . nil? || resource . empty? begin res = client . get ( \"/#{@api_version}/#{resource}\" ) if ! res . success? || res . body . has_key? ( \"error\" ) raise_exception ( res ) else return res . body end rescue = > error raise Exception , \"There was an error: #{error.message}\" end end", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "webhooks", "controller", "RESTful", "as", "far", "as", "possible"], "add_tokens": "resources :webhooks , only : [ :create ] do collection do scope constraints : ContentfulRails :: DevelopmentConstraint do get \"/debug\" , to : \"webhooks#debug\" end end", "del_tokens": "scope constraints : ContentfulRails :: DevelopmentConstraint do get \"/debug\" , to : \"webhooks#debug\"", "commit_type": "make"}
{"commit_tokens": ["Remove", "symlink", "trickery", "from", "BaseHook"], "add_tokens": "plugin_dirs = [ File . expand_path ( '../plugins' , __FILE__ ) ] repo_specific = Utils . repo_path ( '.githooks' ) plugin_dirs << repo_specific if File . directory? ( repo_specific ) Dir [ File . join ( dir , Utils . hook_name , '*.rb' ) ] . each do | plugin |", "del_tokens": "require 'pathname' # File.expand_path takes one more '..' than you're used to... we want to # go two directories up from the caller (which will be .git/hooks/something) # to the root of the git repo, then down into .githooks REPO_SPECIFIC_DIR = File . expand_path ( '../../../.githooks' , $0 ) # Relative paths + symlinks == great fun plugin_dirs = [ File . join ( File . dirname ( Pathname . new ( __FILE__ ) . realpath ) , 'plugins' ) ] plugin_dirs << REPO_SPECIFIC_DIR if File . directory? ( REPO_SPECIFIC_DIR ) Dir [ File . join ( dir , Overcommit :: Utils . hook_name , '*.rb' ) ] . each do | plugin |", "commit_type": "remove"}
{"commit_tokens": ["Added", "new", "timeout", "and", "bury", "rate", "statistics"], "add_tokens": "datum [ \"label\" ] = tube", "del_tokens": "datum [ \"label\" ] = \"#{tube} - #{total_jobs}\"", "commit_type": "add"}
{"commit_tokens": ["Fixing", "has_many", "routing", "declaration", ".", "Specifying", "two", "calls", "to", "has_many", "meant", "that", "only", "the", "last", "one", "took", "effect", ".", "Use", "has_many", "=", ">", "Arrary", "of", "values", "instead", "."], "add_tokens": "map . resources :repositories , :path_prefix => ':urlified_name' , :has_many => [ :shelf_locations , :tracking_lists ]", "del_tokens": "map . resources :repositories , :path_prefix => ':urlified_name' , :has_many => :shelf_locations , :has_many => :tracking_lists", "commit_type": "fix"}
{"commit_tokens": ["add", "extra", "param", "to", "exclude", "chef_environments", "add", "chef_environment", "to", "report"], "add_tokens": "def initialize ( api_token , room_name , excluded_envs = [ ] , notify_users = false , report_success = false ) @excluded_envs = excluded_envs unless excluded_envs . include? ( node . chef_environment ) msg = if run_status . failed? then \"Failure on \\\"#{node.name}\\\" (\\\"#{node.chef_environment}\\\" env): #{run_status.formatted_exception}\" elsif run_status . success? && @report_success \"Chef run on \\\"#{node.name}\\\" completed in #{run_status.elapsed_time.round(2)} seconds\" else nil color = if run_status . success? then 'green' else 'red' end if msg client = HipChat :: Client . new ( @api_token ) client [ @room_name ] . send ( 'Chef' , msg , :notify => @notify_users , :color => color ) end", "del_tokens": "def initialize ( api_token , room_name , notify_users = false , report_success = false ) msg = if run_status . failed? then \"Failure on \\\"#{node.name}\\\": #{run_status.formatted_exception}\" elsif run_status . success? && @report_success \"Chef run on \\\"#{node.name}\\\" completed in #{run_status.elapsed_time.round(2)} seconds\" else nil end color = if run_status . success? then 'green' else 'red' if msg client = HipChat :: Client . new ( @api_token ) client [ @room_name ] . send ( 'Chef' , msg , :notify => @notify_users , :color => color )", "commit_type": "add"}
{"commit_tokens": ["Added", "output", "when", "no", "vulnerabilities", "are", "found", "."], "add_tokens": "color = :red else message = \"No vulnerabilities found.\" color = :green UI . info ( UI . send ( :color , message , color ) )", "del_tokens": "UI . info ( UI . send ( :color , message , :red ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "#numeric", "and", "#numeric_args", "rename", "#numeric_name", "to", "#name"], "add_tokens": "# @return [String] The name of the IRC command numeric (e.g. RPL_WELCOME). attr_accessor :name @name = IRCSupport :: Numerics . numeric_to_name ( @command ) @type = @command . to_sym return @name =~ / ^ERR / ? true : false", "del_tokens": "# @return [String] The IRC command numeric. attr_accessor :numeric # @return [String] The name of the IRC command numeric. attr_accessor :numeric_name # @return [String] The arguments to the numeric command. attr_accessor :numeric_args @numeric = args [ :command ] @numeric_args = args [ :args ] @numeric_name = IRCSupport :: Numerics . numeric_to_name ( @numeric ) @type = @numeric . to_sym return @numeric_name =~ / ^ERR / ? true : false", "commit_type": "remove"}
{"commit_tokens": ["add", "the", "low", "level", "SyncService", "service", "to", "BaseCRM", "::", "Client"], "add_tokens": "require 'basecrm/services/sync_service' # Access all Accounts related actions. # @see AccountsService # # Access all AssociatedContacts related actions. # @see AssociatedContactsService # # Access all Contacts related actions. # @see ContactsService # # Access all Deals related actions. # @see DealsService # # Access all Leads related actions. # @see LeadsService # # Access all LossReasons related actions. # @see LossReasonsService # # Access all Notes related actions. # @see NotesService # # Access all Pipelines related actions. # @see PipelinesService # # Access all Sources related actions. # @see SourcesService # # Access all Stages related actions. # @see StagesService # # Access all Tags related actions. # @see TagsService # # Access all Tasks related actions. # @see TasksService # # Access all Users related actions. # @see UsersService # # Access Sync API related low-level actions. # @see SyncService # # @return [SyncService] Service object for Sync API. def sync @sync ||= SyncService . new ( @http_client ) end", "del_tokens": "# Access all Accounts related actions. # @see AccountsService # # Access all AssociatedContacts related actions. # @see AssociatedContactsService # # Access all Contacts related actions. # @see ContactsService # # Access all Deals related actions. # @see DealsService # # Access all Leads related actions. # @see LeadsService # # Access all LossReasons related actions. # @see LossReasonsService # # Access all Notes related actions. # @see NotesService # # Access all Pipelines related actions. # @see PipelinesService # # Access all Sources related actions. # @see SourcesService # # Access all Stages related actions. # @see StagesService # # Access all Tags related actions. # @see TagsService # # Access all Tasks related actions. # @see TasksService # # Access all Users related actions. # @see UsersService #", "commit_type": "add"}
{"commit_tokens": ["change", "@config", "to", "@options", "to", "correctly", "match", "superclass"], "add_tokens": "def initialize ( options = { } ) requires! ( options , :login , :password , :signature , :appid ) @options = options . dup \"X-PAYPAL-SECURITY-USERID\" => @options [ :login ] , \"X-PAYPAL-SECURITY-PASSWORD\" => @options [ :password ] , \"X-PAYPAL-SECURITY-SIGNATURE\" => @options [ :signature ] , \"X-PAYPAL-APPLICATION-ID\" => @options [ :appid ] , @options [ :test ] || Base . gateway_mode == :test", "del_tokens": "def initialize ( config = { } ) requires! ( config , :login , :password , :signature , :appid ) @config = config . dup \"X-PAYPAL-SECURITY-USERID\" => @config [ :login ] , \"X-PAYPAL-SECURITY-PASSWORD\" => @config [ :password ] , \"X-PAYPAL-SECURITY-SIGNATURE\" => @config [ :signature ] , \"X-PAYPAL-APPLICATION-ID\" => @config [ :appid ] , @config [ :test ] || Base . gateway_mode == :test", "commit_type": "change"}
{"commit_tokens": ["add", "more", "options", "to", "env", "building"], "add_tokens": "attr_reader :autolink , :inline_img , :sandbox def initialize ( autolink : %w[ http https ftp mailto ] , inline_img : false , sandbox : false , ** opts ) @autolink = autolink @inline_img = inline_img @sandbox = sandbox elsif @sandbox @macros = SANDBOX_MACROS @hi = nil # current syntax hiliter", "del_tokens": "def initialize opts @options = { } @hi = nil", "commit_type": "add"}
{"commit_tokens": ["Added", "kaminari", "kaminari", "images", "and", "helpers", ".", "Added", "helper", "specs", "."], "add_tokens": "def set_flash_message ( key , kind , options = { } ) # # Validate Model's sortable columns and direction. # def check_kaminari_sort ( klass , column = nil , dir = nil ) if ( column . nil? && dir . nil? ) return klass :: DEFAULT_ORDER end begin unless klass :: SORTABLE_COLUMNS . include? column raise ArgumentError , \"Column (#{column.to_s}) is not sortable \" << \"for model #{klass.to_s}. See #{klass.to_s}::SORTABLE_COLUMNS\" end rescue ArgumentError => e puts e . message return klass :: DEFAULT_ORDER end safe_col = column safe_dir = ( dir == \"asc\" ) ? \"asc\" : \"desc\" return \"%s %s\" % [ safe_col , safe_dir ] # sql order by clause end", "del_tokens": "def set_flash_message ( key , kind , options = { } )", "commit_type": "add"}
{"commit_tokens": ["Added", "description", "to", "spec", "matcher", "."], "add_tokens": "@actual = Class === actual ? actual : actual . class result = @actual . ancestors . include? ( FriendlyAttributes ) && @attributes . all? { | attr | @actual . friendly_model . attributes . include? ( attr ) && @actual . friendly_model . attributes [ attr ] . type == @type def description \"have [#{@actual}] friendly_attributes of type #{@type} => #{@attributes.inspect}\" end", "del_tokens": "@actual = actual actual = Class === actual ? actual : actual . class result = actual . ancestors . include? ( FriendlyAttributes ) && @attributes . all? { | attr | actual . friendly_model . attributes . include? ( attr ) && actual . friendly_model . attributes [ attr ] . type == @type", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "LICENCE", "Manifest", "README", ".", "rdoc", "Rakefile", "lib", "pkg", "simpleidn", ".", "gemspec", "spec", "in", "domain", "name", "would", "give", "wrong", "results", "."], "add_tokens": "out << ( s =~ / [^A-Z0-9 \\- *] /i ? \"xn--\" + Punycode . encode ( s ) : s )", "del_tokens": "out << ( s =~ / [^A-Z0-9 \\- ] /i ? \"xn--\" + Punycode . encode ( s ) : s )", "commit_type": "fix"}
{"commit_tokens": ["added", "feature", "to", "wait", "for", "3", "successful", "health", "checks", "before", "continuing"], "add_tokens": "def self . wait_until_server_running server , count , successes = 0 if successes > 0 puts \"Server: #{server} passed health check, #{successes} checks to go...\" self . wait_until_server_running server , count + 1 , successes - 1 else puts \"Server: #{server} healthy\" end", "del_tokens": "def self . wait_until_server_running server , count puts \"Server: #{server} healthy\"", "commit_type": "add"}
{"commit_tokens": ["Make", "Geocoder", ".", "search", "return", "nil", "on", "bad", "response", "."], "add_tokens": "# Returns a REXML document representing a valid geocoder response. # Returns nil if non-200 HTTP response, timeout, or other error. doc = _fetch_document ( query ) e = doc . elements [ 'GeocodeResponse/status' ] ( e and e . text == \"OK\" ) ? doc : nil # Returns a parsed Google geocoder search result (REXML document). # This method is not intended for general use (prefer Geocoder.search). # def self . _fetch_document ( query ) if doc = _fetch_xml ( query ) REXML :: Document . new ( doc ) end end ## # Returns a raw Google geocoder search result (XML). # build URL params = { :address => query , :sensor => \"false\" } # query geocoder and make sure it responds quickly", "del_tokens": "if doc = _fetch_xml ( query ) REXML :: Document . new ( doc ) end # make sure search found a result e = doc . elements [ 'GeocodeResponse/status' ] return nil unless ( e and e . text == \"OK\" ) # Request an XML geo search result from Google. params = { :address => query , :sensor => \"false\" } # Query geocoder and make sure it responds quickly.", "commit_type": "make"}
{"commit_tokens": ["Updated", "has", "no", "body", "test"], "add_tokens": "expect { Parser . new ( empty_body ) . parse } . to_not raise_error", "del_tokens": "expect ( Parser . new ( empty_body ) . parse ) . to be_nil", "commit_type": "update"}
{"commit_tokens": ["fix", "spec", "for", "slight", "nokogiri", "api", "change"], "add_tokens": "r [ \"foo:bar\" ] . should == \"1\" r [ \"foo:baz\" ] . should == \"baz\"", "del_tokens": "r [ \"bar\" ] . should == \"1\" r [ \"baz\" ] . should == \"baz\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "railtie", "and", "re", "-", "release"], "add_tokens": ":: Filemaker . load! ( config_file , Rails . env ) fail :: Filemaker :: Error :: ConfigurationError , 'No config file provided'", "del_tokens": "Filemaker . load! ( config_file , Rails . env ) fail Error :: ConfigurationError , 'No config file provided'", "commit_type": "fix"}
{"commit_tokens": ["use", "url", "parser", "to", "parse", "database!", "urls"], "add_tokens": "parsed = parse url cr = CouchRest . new ( parsed [ :host ] ) cr . database! ( parsed [ :database ] ) parsed = parse url cr = CouchRest . new ( parsed [ :host ] ) cr . database ( parsed [ :database ] )", "del_tokens": "uri = URI . parse url path = uri . path uri . path = '' cr = CouchRest . new ( uri . to_s ) cr . database! ( path ) uri = URI . parse url path = uri . path uri . path = '' cr = CouchRest . new ( uri . to_s ) cr . database ( path )", "commit_type": "use"}
{"commit_tokens": ["Updated", "README", "with", "instructions", ".", "Minimal", "refactor", "of", "Graph"], "add_tokens": "# Errors # Graph Node # Dependency Graph return @resolved # Return the graph to its virgin state @resolved = [ ] # Recurse through nodes @nodes . each { | node | return node if node . key == key } node = Node . new key @nodes . each { | node | node . seen = false }", "del_tokens": "attr_accessor :dependee @resolved = [ ] @nodes . each do | node | if node . key == key return node end end node = Node . new ( key ) @nodes . each do | node | node . seen = false end", "commit_type": "update"}
{"commit_tokens": ["Added", "the", "vpc", "configuration", "check", "."], "add_tokens": "# check if vpc_subnet_ids and vpc_security_group_ids are empty and set accordingly to null vpc_Configuration = [ ] if ( vpc_subnet_ids . empty? && vpc_security_group_ids . empty? ) vpc_Configuration = nil else vpc_Configuration = { subnet_ids : vpc_subnet_ids , security_group_ids : vpc_security_group_ids } end vpc_config : vpc_Configuration", "del_tokens": "vpc_config : { subnet_ids : vpc_subnet_ids , security_group_ids : vpc_security_group_ids }", "commit_type": "add"}
{"commit_tokens": ["Updated", "gem", "version", "for", "release", "with", "DST", "bug", "fix", "."], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "update"}
{"commit_tokens": ["Added", "an", "disallow_replace", "setting", "which", "stops", "you", "from", "replacing", "gems", "that", "already", "exist", "on", "the", "filesystem"], "add_tokens": "set :disallow_replace , false class << self alias :disallow_replace :disallow_replace? end dest_filename = File . join ( options . data , \"gems\" , File . basename ( name ) ) if Geminabox . disallow_replace? && File . exist? ( dest_filename ) return error_response ( 409 , \"Gem already exists\" ) end File . open ( dest_filename , \"wb\" ) do | f | def error_response ( code , message ) html = <<HTML < html > < head > < title > Error - #{code}</title></head> < body > < h1 > Error - #{code}</h1> < p > #{message}</p> < / body > < / html > HTML [ code , html ] end", "del_tokens": "File . open ( File . join ( options . data , \"gems\" , File . basename ( name ) ) , \"wb\" ) do | f |", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "pass", "username", "and", "password", "as", "contructor", "arguments", "-", "This", "will", "allow", "username", "and", "password", "input", "field", "data", "from", "gui", "app", "to", "be", "used", "when", "creating", "new", "client", "instance", "."], "add_tokens": "def initialize ( url , un , pw ) @username = un @password = pw u = @username p = @password # Update username and password if needed def self . get_instance ( url , un , pw ) self . new ( url , un , pw )", "del_tokens": "def initialize ( url ) @username = '' @password = '' u = @username || '' p = @password || '' def self . get_instance ( url ) self . new ( url )", "commit_type": "add"}
{"commit_tokens": ["move", "routing", "logic", "to", "router"], "add_tokens": "@router = Monet :: PathRouter . new ( @config . base_url , @config . capture_dir ) visit @router . build_url ( path ) page . driver . render ( @router . route_url_path ( path , width ) , full : true )", "del_tokens": "url = normalize_path ( path ) visit url page . driver . render ( image_name ( url , width ) , full : true ) end private def capture_path @config . capture_dir end def normalize_path ( path ) \"#{@config.base_url}#{path}\" end def image_name ( path , width ) name = path . gsub ( / https?: \\/ \\/ / , '' ) . gsub ( / \\/ / , '_' ) \"#{capture_path}/#{@config.base_url.host}/#{name}-#{width}.png\"", "commit_type": "move"}
{"commit_tokens": ["Adding", "SSLV3", "compatibility", "for", "Bitstap", "API", "connection", "."], "add_tokens": "\"https://www.bitstamp.net/api#{path}/\" rest path rest path , :post , bitstamp_options ( options ) rest path , :put , bitstamp_options ( options ) rest path , :delete , bitstamp_options ( options ) def self . rest ( path , method = :get , options = { } ) RestClient :: Request . execute ( method : method , url : to_uri ( path ) , payload : options , ssl_version : 'SSLv23' ) end", "del_tokens": "return \"https://www.bitstamp.net/api#{path}/\" RestClient . get ( self . to_uri ( path ) ) RestClient . post ( self . to_uri ( path ) , self . bitstamp_options ( options ) ) RestClient . put ( self . to_uri ( path ) , self . bitstamp_options ( options ) ) RestClient . delete ( self . to_uri ( path ) , self . bitstamp_options ( options ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "class", "call", "in", "helper"], "add_tokens": "redirect_to_unauth notice : params [ :message ]", "del_tokens": "redirect_to_unauth , notice : params [ :message ]", "commit_type": "fix"}
{"commit_tokens": ["use", "css", "selectors", "for", "fill_in", "and", "select_date"], "add_tokens": "browser . type ( \"css=#{element}\" , value ) browser . select \"css=#{element}_#{suffixes[:year]}\" , date . year browser . select \"css=#{element}_#{suffixes[:month]}\" , date . strftime ( '%B' ) browser . select \"css=#{element}_#{suffixes[:day]}\" , date . day", "del_tokens": "browser . type ( element , value ) browser . select \"#{element}_#{suffixes[:year]}\" , date . year browser . select \"#{element}_#{suffixes[:month]}\" , date . strftime ( '%B' ) browser . select \"#{element}_#{suffixes[:day]}\" , date . day", "commit_type": "use"}
{"commit_tokens": ["Make", "gem", "work", "with", "all", "Ruby", "2", ".", "x", "versions"], "add_tokens": "return if word . is_a? ( String ) && ( i . is_a? ( IntClass ) || i . is_a? ( Float ) )", "del_tokens": "return if word . is_a? ( String ) && ( i . is_a? ( Fixnum ) || i . is_a? ( Float ) )", "commit_type": "make"}
{"commit_tokens": ["improved", "file", "detection", "added", "check", "for", "if", "a", "class", "has", "already", "been", "moved"], "add_tokens": "at_the_top = from_mod . parent == from_mod return load_missing_constant_error ( from_mod . parent , const_name , e ) unless at_the_top raise e", "del_tokens": "load_missing_constant_error ( from_mod . parent , const_name , e )", "commit_type": "improve"}
{"commit_tokens": ["fix", "typo", "in", "default", "notification", "rules"], "add_tokens": ":success => { :email => :change , :webhooks => :always , :irc => :always } , :failure => { :email => :always , :webhooks => :always , :irc => :always }", "del_tokens": ":success => { :email => :change , :webhook => :always , :irc => :always } , :failure => { :email => :always , :webhook => :always , :irc => :always }", "commit_type": "fix"}
{"commit_tokens": ["Move", "some", "shared", "archive", "information", "gathering", "into", "a", "module", "called", "ArchiveInfo"], "add_tokens": "include ArchiveInfo", "del_tokens": "# Recent page is considered page 0, invalid pages return -1 def get_page_from_problem_id ( id ) if id . between? ( @num_problems - 9 , @num_problems ) 0 elsif id . between? ( 1 , @num_problems - 10 ) ( id - 1 ) / 50 + 1 else - 1 end end def lookup_totals html = open ( \"https://projecteuler.net/recent\" ) fragment = Nokogiri :: HTML ( html ) id_col = fragment . css ( '#problems_table td.id_column' ) # The newest problem is the first one listed on the recent page. The ID of this # problem will always equal the total number of problems. @num_problems = id_col . first . text . to_i # The last problem on the recent page has an ID that is one larger than the # last problem in the archive pages. The total number of pages can be calculated # from its ID. @num_pages = get_page_from_problem_id ( id_col . last . text . to_i - 1 ) end", "commit_type": "move"}
{"commit_tokens": ["Use", "colors", "just", "for", "an", "interactive", "sessions"], "add_tokens": "", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["add", "read", "all", "w", "include", "path"], "add_tokens": "text = open ( path , 'r:bom|utf-8' ) do | file | ### for convenience for now convert fancy dash to \"plain\" dash ## todo: check char codes for \"fancy\" dash alternatives text . gsub! ( / —|–/ ) d _| puts \"*** warning: convert fancy dash to 'plain' dash\" '-' end text", "del_tokens": "open ( path , 'r:bom|utf-8' ) do | file |", "commit_type": "add"}
{"commit_tokens": ["add", "Kharoshthi", "and", "Phoenician", "to", "rtl", "scripts"], "add_tokens": "RTL_SCRIPTS = %w[ Arabic Hebrew Nko Kharoshthi Phoenician Syriac Thaana Tifinagh ]", "del_tokens": "RTL_SCRIPTS = %w[ Arabic Hebrew Nko Syriac Thaana Tifinagh ]", "commit_type": "add"}
{"commit_tokens": ["Add", "votesmart", "Bill", ".", "find_recent_by_state"], "add_tokens": "response = get ( '/Votes.getBill' , :query => { 'billId' => bill_id } ) response = get ( '/Votes.getBillsByYearState' , :query => { 'year' => year , 'stateId' => state_abbrev } ) instantiate_record ( response [ 'bills' ] ) rescue return nil if response . parsed_response && response . parsed_response [ 'error' ] [ 'errorMessage' ] == 'No bills for this state and year.' raise end def self . find_recent_by_state ( state_abbrev ) response = get ( '/Votes.getBillsByStateRecent' , :query => { 'stateId' => state_abbrev } ) response = get ( '/Committee.getCommitteesByTypeState' , :query => { 'typeId' => type_id , 'stateId' => state_abbrev } ) response = get ( '/Committee.getCommittee' , :query => { 'committeeId' => committee_id } )", "del_tokens": "response = get ( \"/Votes.getBill\" , :query => { \"billId\" => bill_id } ) response = get ( \"/Votes.getBillsByYearState\" , :query => { \"year\" => year , \"stateId\" => state_abbrev } ) response = get ( \"/Committee.getCommitteesByTypeState\" , :query => { \"typeId\" => type_id , \"stateId\" => state_abbrev } ) response = get ( \"/Committee.getCommittee\" , :query => { \"committeeId\" => committee_id } )", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "logic", "in", "#pop"], "add_tokens": "__each { | node | next_to_tail = node if @tail == node . next } tail , @tail = @tail , next_to_tail if next_to_tail @tail . next = nil else @head = nil end", "del_tokens": "node = @head while ( node = node . next ) next_to_tail = node unless node . next end @head = nil unless next_to_tail tail = @tail @tail = next_to_tail", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "code", "smells", "in", "reek", "source"], "add_tokens": "@config = SmellConfig . new if File . exists? ( src ) @source = IO . readlines ( src ) . join @config . load_local ( src ) else @source = src end smells = @config . smell_listeners CodeParser . new ( report , smells ) . check_source ( @source )", "del_tokens": "@source = src config = SmellConfig . new if File . exists? ( @source ) source = IO . readlines ( @source ) . join config . load_local ( @source ) else source = @source end smells = config . smell_listeners CodeParser . new ( report , smells ) . check_source ( source )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "contact_type", "in", "Contact", "finder", "methids"], "add_tokens": "options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :required , :contact_type ) options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :contact_type ) options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :contact_type )", "del_tokens": "options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :required ) options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email ) options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email )", "commit_type": "add"}
{"commit_tokens": ["use", "new", "passed", "status", "value"], "add_tokens": "delegate :submitted? , :completed? , :passed? , :failed? , :active? , to : :status if current_status . completed? current_status = results_valid? ? OSC :: Machete :: Status . passed : OSC :: Machete :: Status . failed", "del_tokens": "delegate :submitted? , :completed? , :failed? , :active? , to : :status if current_status . completed? || current_status . failed? current_status = results_valid? ? OSC :: Machete :: Status . completed : OSC :: Machete :: Status . failed", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "coverage", "for", "auth", "header", "prefixability"], "add_tokens": "AUTH_HEADER_PATTERN = / APIAuth ([^:]+):(.+)$ /", "del_tokens": "AUTH_HEADER_PATTERN = / ^APIAuth ([^:]+):(.+)$ /", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "differ", "in", "the", "spec", "helpers"], "add_tokens": "def self . differ @_differ ||= RSpec :: Expectations :: Differ . new end message = \"expected api to have exposed #{normalised_response.inspect}, got #{@decoded.inspect} instead.\" message << \"\\n\\nDiff: #{RSpecMatchers.differ.diff_as_object(@decoded, normalised_response)}\" message", "del_tokens": "\"expected api to have exposed #{normalised_response.inspect}, got #{@decoded.inspect} instead\"", "commit_type": "use"}
{"commit_tokens": ["Remove", "SingleLetterAbbr", "class", "from", "deutsch", "lanf"], "add_tokens": "@reformatted_text = @reformatted_text . apply ( Languages :: Common :: SingleLetterAbbreviationRules :: All , SingleLowerCaseLetterRule , SingleLowerCaseLetterAtStartOfLineRule )", "del_tokens": "class SingleLetterAbbreviation < Common :: SingleLetterAbbreviation def replace super @formatted_text . apply SingleLowerCaseLetterRule , SingleLowerCaseLetterAtStartOfLineRule end end @reformatted_text = Deutsch :: SingleLetterAbbreviation . new ( text : @reformatted_text ) . replace", "commit_type": "remove"}
{"commit_tokens": ["Use", "a", "transaction", "when", "saving", "models"], "add_tokens": "ActiveRecord :: Base . transaction do changed_models . each do | model | next if model . destroyed? if model . marked_for_destruction? model . destroy else model . save! end changed_models . reject ( & :destroyed? ) . each ( & :reload ) end", "del_tokens": "changed_models . each do | model | next if model . destroyed? if model . marked_for_destruction? model . destroy else model . save! end changed_models . reject ( & :destroyed? ) . each ( & :reload )", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "-", "r", "/", "--", "repository", "option", "."], "add_tokens": "\"-rREPOSITORY\" , \"--repository=REPOSITORY\" ,", "del_tokens": "\"-r\" , \"--repository\" ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "forwarded", "on_create_menu", "method", "to", "PMScreen"], "add_tokens": "options [ :show ] ||= :always", "del_tokens": "option [ :show ] ||= :always", "commit_type": "fix"}
{"commit_tokens": ["adds", "more", "specs", "for", "Vnstat", "::", "Interface"], "add_tokens": "reload if Utils . call_executable_returning_status ( '--reset' , '-i' , id ) self", "del_tokens": "Utils . call_executable_returning_status ( '--reset' , '-i' , id ) reload", "commit_type": "add"}
{"commit_tokens": ["Added", "create", "value", "for", "selectize", "input"], "add_tokens": "# Valore che indica se il create è attivo nel caso di input select", "del_tokens": "# Valore che indica il massimo se il create è attivo nel caso di input select", "commit_type": "add"}
{"commit_tokens": ["Improved", "RDoc", "documentation", "and", "expanded", "specs", "."], "add_tokens": "# The Base HTTP status exception class is used as superclass for every # exception class that is constructed. It implements some shared functionality # for finding the status code and determining the template path to render. @status = self . class . name . split ( \"::\" ) . last . underscore . to_sym rescue :internal_server_error # Include the HTTPStatus module into ActionController to enable its functionality", "del_tokens": "@status = self . class . to_s . split ( \"::\" ) . last . underscore . to_sym rescue :internal_server_error", "commit_type": "improve"}
{"commit_tokens": ["Made", "the", "venue", "/", "edit", "endpoint", "method", "name", "look", "more", "informative", "."], "add_tokens": "def edit_venue ( venue_id , options = { } )", "del_tokens": "def edit ( venue_id , options = { } )", "commit_type": "make"}
{"commit_tokens": ["fixed", "finding", "of", "ojdbc14", ".", "jar", "in", "Windows", "PATH"], "add_tokens": "if ojdbc_jar_path = ENV [ \"PATH\" ] . split ( / [:;] / ) . find { | d | File . exists? ( File . join ( d , ojdbc_jar ) ) }", "del_tokens": "if ojdbc_jar_path = ENV [ \"PATH\" ] . split ( \":\" ) . find { | d | File . exists? ( File . join ( d , ojdbc_jar ) ) }", "commit_type": "fix"}
{"commit_tokens": ["Use", "internal", "logger", "for", "overly", "chatty", "messages"], "add_tokens": "require 'log4r' @logger = Log4r :: Logger . new ( 'vagrant::auto_network::filter_networks' ) @logger . info \"Reassigning #{addr.inspect} to existing machine #{machine.id}\"", "del_tokens": "@env [ :ui ] . info \"Reassigning #{addr.inspect} to #{machine.id}\" , :prefix => true", "commit_type": "use"}
{"commit_tokens": ["Added", "text_wrapper", ".", "rb", "to", "Cork", "to", "present", "as", "help", "."], "add_tokens": "# @param [String] message The message to print. end #terminal is to small a width of 80 is assumed.", "del_tokens": "# @param [String] message The message to print. end #terminal is to samll a width of 80 is assumed.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "the", "new", "hash", "comprehension", "unpacking", ";", "The", "new", "code"], "add_tokens": "unpack_str = unpack_vars . count > 1 ? \"(#{args_str})\" : args_str res += \".each_with_object({}){|#{unpack_str}, _h#{hid}| \" +", "del_tokens": "res += \".each_with_object({}){|(#{args_str}), _h#{hid}| \" +", "commit_type": "fix"}
{"commit_tokens": ["added", "div", "back", "to", "showAd", "()", "function", "changed", "order"], "add_tokens": "keyword = params [ :key ] @div = params [ :div ] @size = params [ :size ]", "del_tokens": "keyword = params [ :id ] @size = params [ :size ] @div = params [ :div ]", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "global", "search", "endpoint"], "add_tokens": "parts << \"/\" + self . class . to_s . split ( '::' ) . last . downcase", "del_tokens": "parts << \"/\" + self . class . to_s . split ( '::' ) . last . downcase . pluralize", "commit_type": "add"}
{"commit_tokens": ["Make", "helpers", "available", "from", "a", "decorator", "s", "class", "methods"], "add_tokens": "self . class . helpers # Access the helpers proxy to call built-in and user-defined # Rails helpers from a class context. # # @return [Object] proxy class << self def helpers Thread . current [ :current_view_context ] end alias :h :helpers end", "del_tokens": "Thread . current [ :current_view_context ]", "commit_type": "make"}
{"commit_tokens": ["use", "redis", "hash", "as", "canonical", "presence", "reference", "so", "that", "when", "a", "connection", "to", "a", "channel", "goes", "to", "a", "slanger", "instance", "that", "does", "not", "have", "that", "particular", "in", "memory", "and", "therefore", "is", "not", "subscribed", "to", "pubsub", "updates", "for", "it", "can", "build", "the", "initial", "presence", "state", "internally", "using", "the", "hash", "and", "subscribe", "to", "updates", "using", "pubsub"], "add_tokens": "require 'fiber' roster_add public_subscription_id , channel_data roster_remove public_subscription_id def get_roster Fiber . new do f = Fiber . current Slanger :: Redis . hgetall ( channel_id ) . callback { | res | f . resume res } Fiber . yield end . resume end def roster_add ( key , value ) Slanger :: Redis . hset ( channel_id , key , value ) end def roster_remove ( key ) Slanger :: Redis . hdel ( channel_id , key ) end @subscriptions = @subscriptions || get_roster || Hash . new", "del_tokens": "@subscriptions ||= { }", "commit_type": "use"}
{"commit_tokens": ["Add", "config", "option", "to", "disable", "user", "validations"], "add_tokens": "access_denied_view : 'sessions/access_denied' , api_key_enabled : false , cookie_prefix : 'challah' , email_validator : 'challah/email' , password_validator : PasswordValidator , skip_routes : false , skip_user_validations : false , storage_class : SimpleCookieStore", "del_tokens": "access_denied_view : 'sessions/access_denied' , api_key_enabled : false , cookie_prefix : 'challah' , email_validator : 'challah/email' , password_validator : PasswordValidator , skip_routes : false , storage_class : SimpleCookieStore", "commit_type": "add"}
{"commit_tokens": ["Use", "Active", "Job", "and", "remove", "delayed", "job", "dependency"], "add_tokens": "ImportProductsJob . perform_later ( @product_import )", "del_tokens": "Delayed :: Job . enqueue ImportProducts :: ImportJob . new ( @product_import , spree_current_user )", "commit_type": "use"}
{"commit_tokens": ["Adding", "some", "tests", "to", "EnvironmentBuilder"], "add_tokens": "protected", "del_tokens": "uri = @request . url", "commit_type": "add"}
{"commit_tokens": ["Add", "bang", "-", "method", "array", "transformations"], "add_tokens": "Transproc ( :map_array! , fn ) [ array . dup ] end register ( :map_array! ) do | array , fn | array . map! { | value | fn [ value ] }", "del_tokens": "array . map { | value | fn [ value ] }", "commit_type": "add"}
{"commit_tokens": ["Change", "internal", "API", "to", "be", "more", "flexible"], "add_tokens": "lang . extract file do | tbl , key , args | @tables [ tbl ] ||= { } @tables [ tbl ] [ key ] ||= [ ] @tables [ tbl ] [ key ] << StarScope :: Datum . build ( key , file , args ) val . delete_if { | dat | dat [ :file ] == file }", "del_tokens": "lang . extract file do | tblname , fqn , lineno | datum = StarScope :: Datum . new ( fqn , file , lineno ) @tables [ tblname ] ||= { } @tables [ tblname ] [ datum . key ] ||= [ ] @tables [ tblname ] [ datum . key ] << datum val . delete_if { | dat | dat . file == file }", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "funcion", "status", "now", "it", "works", "correctly"], "add_tokens": "lastconnerror )", "del_tokens": "lastconnerror ) != 0", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unneeded", "method", "and", "call", "to", "Sanitize", "::", "array"], "add_tokens": "if header . nil? || header . empty? fail ( MissingCSVHeaderError , \"CSV header can't be empty.\" ) end @column_names = header @columns = Columns . new ( header , valid : valid , converter : converter )", "del_tokens": "@column_names = build_header ( header ) @columns = Columns . new ( @column_names , valid : valid , converter : converter ) private def build_header ( header ) if header . nil? || header . empty? fail ( MissingCSVHeaderError , \"CSV header can't be empty.\" ) end Sanitize . array! ( header ) end", "commit_type": "remove"}
{"commit_tokens": ["add", "base64", "encode", "/", "decode", "like", "php", "example"], "add_tokens": "signature = OpenSSL :: HMAC . hexdigest ( 'sha512' , Base64 . decode64 ( MtGox . secret ) , request . to_param ) { 'Rest-Key' => MtGox . key , 'Rest-Sign' => Base64 . encode64 ( signature ) }", "del_tokens": "signature = OpenSSL :: HMAC . hexdigest ( 'sha512' , MtGox . secret , request . to_param ) { 'Rest-Key' => MtGox . key , 'Rest-Sign' => signature }", "commit_type": "add"}
{"commit_tokens": ["Added", "CVE", "-", "2012", "-", "2660", "to", "knowledge", "base"], "add_tokens": "it \"must have test for CVE_2012_2660\" do sc = kb . find ( \"CVE-2012-2660\" ) sc . should_not be_nil sc . class . should == Codesake :: Dawn :: Kb :: CVE_2012_2660 end", "del_tokens": "it \"must have test for CVE_2012_2660\"", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "valid", "command", "-", "line", "options"], "add_tokens": "before do $stdout = StringIO . new end it \"does not emit an error when option -n 3 is supplied\" do expect ( CLI ) . not_to receive ( :handle_error ) CLI . parse ( [ \"-n\" , \"3\" ] ) end it \"does not emit an error when option -r is supplied\" do expect ( CLI ) . not_to receive ( :handle_error ) CLI . parse ( [ \"-r\" ] ) end it \"does not emit an error when option -h is supplied\" do expect { CLI . parse ( [ \"-h\" ] ) } . to raise_error ( SystemExit ) end it \"does not emit an error when option -v is supplied\" do expect { CLI . parse ( [ \"-v\" ] ) } . to raise_error ( SystemExit ) end invalid_option = [ \"-x\" ] CLI . parse ( invalid_option )", "del_tokens": "bad_option = [ \"-x\" ] CLI . parse ( bad_option )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "bug", "that", "the", "args", "will", "be", "overwritten", "by", "the", "default", "values", "."], "add_tokens": "default_args = { } args = default_args . merge! ( args )", "del_tokens": "args . merge! ( { } )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "uneccessary", "@respond_to_performed", "and", "chain", "of", "respond_to", "which", "means", "that", "erase_render_results", "will", "just", "work", "without", "any", "tinkering"], "add_tokens": "# return the responses defined by response_for for the current action def action_responses self . class . action_responses [ action_name ] || [ ] end # respond_to sets the content type on the response, so we use that to tell # if respond_to has been performed def respond_to_performed? ( response && response . content_type ) ? true : false action_responses . any? || template_exists_without_response_for? # if the response.content_type has not been set (if it has, then responthere are responses for the current action, then respond_to them if ! respond_to_performed? && action_responses . any? action_responses . each { | response | instance_exec ( responder , & response ) }", "del_tokens": "alias_method_chain :respond_to , :response_for # does a response exist for the current action? def response_exists? self . class . action_responses . keys . include? ( action_name . to_s ) response_exists? || template_exists_without_response_for? # if there are responses for the current action, then respond_to them if ! @respond_to_performed && ( responses = self . class . action_responses [ action_name ] ) && responses . any? responses . each { | response | instance_exec ( responder , & response ) } def respond_to_with_response_for ( * args , & block ) @respond_to_performed = true respond_to_without_response_for ( * args , & block ) end", "commit_type": "remove"}
{"commit_tokens": ["Improve", "the", "Yard", "setup", "and", "fix", "a", "few", "docs", "nitpicks"], "add_tokens": "# @param [Block] block the block to execute for the underlying contracts # Allows for the inheritance of contracts in subclasses # @api private", "del_tokens": "# @params [Block] block the block to execute for the underlying contracts # Sets contract to given one and calls hooks # define_promises_hook and define_expectations_hook # @api semipublic", "commit_type": "improve"}
{"commit_tokens": ["Add", "a", "seed_once", "with", "specs", "to", "test", "it", "."], "add_tokens": "it \"should update, not create, if constraints are met\" do SeededModel . seed ( :id ) do | s | s . id = 1 s . login = \"bob\" s . first_name = \"Bob\" s . last_name = \"Bobson\" s . title = \"Peon\" end SeededModel . seed ( :id ) do | s | s . id = 1 s . login = \"bob\" s . first_name = \"Robert\" s . last_name = \"Bobson\" s . title = \"Peon\" end bob = SeededModel . find_by_id ( 1 ) bob . first_name . should == \"Robert\" bob . last_name . should == \"Bobson\" end it \"should create but not update with seed_once\" do SeededModel . seed_once ( :id ) do | s | s . id = 1 s . login = \"bob\" s . first_name = \"Bob\" s . last_name = \"Bobson\" s . title = \"Peon\" end SeededModel . seed_once ( :id ) do | s | s . id = 1 s . login = \"bob\" s . first_name = \"Robert\" s . last_name = \"Bobson\" s . title = \"Peon\" end bob = SeededModel . find_by_id ( 1 ) bob . first_name . should == \"Bob\" bob . last_name . should == \"Bobson\" end", "del_tokens": "it \"should update, not create, if constraints are met\"", "commit_type": "add"}
{"commit_tokens": ["remove", "warnings", "about", "ambiguous", "arguments"], "add_tokens": "assert_match ( / private constant / , error . message ) assert_match ( / private constant / , error . message ) assert_match ( / private constant / , error . message )", "del_tokens": "assert_match / private constant / , error . message assert_match / private constant / , error . message assert_match / private constant / , error . message", "commit_type": "remove"}
{"commit_tokens": ["Allowed", "update_attributes", "to", "be", "optionally", "transactional"], "add_tokens": "def update_attributes ( attributes , opts = { } ) save ( opts )", "del_tokens": "def update_attributes ( attributes = { } ) save", "commit_type": "allow"}
{"commit_tokens": ["Add", "the", "ability", "for", "an", "event", "to", "access", "its", "watcher", "."], "add_tokens": "end . map { | c | c . sub ( \"#{prefix}_\" , \"\" ) . downcase . to_sym } end def self . to_flag ( prefix , flag ) const_get ( \"#{prefix}_#{flag.to_s.upcase}\" ) end def self . from_flag ( prefix , flag ) re = / ^ #{ Regexp . quote prefix } _ / constants . each do | c | next unless c =~ re return c . sub ( \"#{prefix}_\" , \"\" ) . downcase . to_sym if const_get ( c ) == flag end", "del_tokens": "end . map { | c | c . sub ( \"#{prefix}_\" , \"\" ) . downcase . to_sym } - [ :all_events ]", "commit_type": "add"}
{"commit_tokens": ["removed", "a", "bug", "for", "google", "images", "scraper"], "add_tokens": "@params = create_params def create_params string += \"&tbs=#{@options[\"size\"]}\" if @options [ \"size\" ] string += \"&safe=off\" unless @options [ \"safe\" ] string", "del_tokens": "@params = create_params ( @options ) def create_params ( options ) string += \"&tbs=#{options[\"size\"]}\" if options [ \"size\" ] string += \"&safe=off\" unless options [ \"safe\" ]", "commit_type": "remove"}
{"commit_tokens": ["Add", "more", "descriptive", "failure", "message"], "add_tokens": "begin require 'mock_redis' rescue raise 'To test using Sidekiq::Testing.inline!' ' Please add `gem \"mock_redis\" to your gemfile.' end", "del_tokens": "require 'mock_redis'", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "caused", "by", "locale", "thread", "persistence"], "add_tokens": "I18n . locale = options [ :locale ] || I18n . default_locale if defined? ( I18n ) # sets the locale to nil for default behavior even if the locale was set by a previous action - removed: # && options[:locale]", "del_tokens": "I18n . locale = options [ :locale ] if defined? ( I18n ) && options [ :locale ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "off", "-", "by", "-", "one", "error", "in", "indexer", "output"], "add_tokens": "# rubocop:disable Metrics/LineLength . info ( \"[#{index + 1}/#{gems.size}]: Processing #{gemfile.split('/')[-1]}\" ) # rubocop:enable Metrics/LineLength", "del_tokens": ". info ( \"[#{index}/#{gems.size}]: Processing #{gemfile.split('/')[-1]}\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "btc", "usd", "attribute", "to", "user", "transactions"], "add_tokens": "attr_accessor :datetime , :id , :type , :usd , :btc , :fee , :order_id , :btc_usd", "del_tokens": "attr_accessor :datetime , :id , :type , :usd , :btc , :fee , :order_id", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "to", "include", "the", "env", "vars", "."], "add_tokens": "cmd = shell_out ( [ python_binary , '-m' , 'venv' , '-h' ] , environment : python_environment )", "del_tokens": "cmd = shell_out ( [ python_binary , '-m' , 'venv' , '-h' ] )", "commit_type": "make"}
{"commit_tokens": ["Fixing", "the", "automatic", "path", "construction"], "add_tokens": "@sv_path = File . join ( @base_path , \"sv\" ) @service_path = File . join ( @base_path , \"service\" )", "del_tokens": "@sv_path = File . join ( base_path , \"sv\" ) @service_path = File . join ( base_path , \"service\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "self", "-", "update", "capabilities", "."], "add_tokens": "VERSION = '0.4.0'", "del_tokens": "VERSION = '0.3.2'", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "opentok", "/", "Opentok", "-", "Ruby", "-", "SDK", "/", "issues", "/", "54"], "add_tokens": "# Returns an ArchiveList, which is an array of archives that are completed and in-progress, # for your API key.", "del_tokens": "# Returns an ArchiveList. The `items()` method of this object returns a list of # archives that are completed and in-progress, for your API key.", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "Amazon", "third", "party", "items", "and", "out", "-", "of", "-", "stock", "items"], "add_tokens": "%w{ amazon amazon2 amazon3 amazon4 } . each do | name |", "del_tokens": "%w{ amazon amazon2 amazon3 } . each do | name |", "commit_type": "add"}
{"commit_tokens": ["Fix", "rdoc", "issue", "with", "encoding", "::"], "add_tokens": "# out :: Object receiving the markup. +out+ must respond to # <tt><<</tt>. # indent :: Number of spaces used for indentation (0 implies no # indentation and no line breaks). # initial :: Level of initial indentation. # encoding :: When <tt>encoding</tt> and $KCODE are set to 'utf-8' # characters aren't converted to character entities in # the output stream.", "del_tokens": "# out:: Object receiving the markup. +out+ must respond to # <tt><<</tt>. # indent:: Number of spaces used for indentation (0 implies no # indentation and no line breaks). # initial:: Level of initial indentation. # encoding:: When <tt>encoding</tt> and $KCODE are set to 'utf-8' # characters aren't converted to character entities in # the output stream.", "commit_type": "fix"}
{"commit_tokens": ["Remove", "memoization", "from", "Matcher#prefix", "."], "add_tokens": "new ( Prefix . all , method ) . alternative", "del_tokens": "@prefix_codes ||= new ( Prefix . all , method ) . alternative", "commit_type": "remove"}
{"commit_tokens": ["fixing", "a", "bug", "in", "the", "treatment", "of", "word", "separators", "adding", "newlines", "tabs", "and", "dashes", "into", "the", "set", "of", "default", "word", "separators"], "add_tokens": ":word_separators => \"- \\n\\t\" , if config [ :index_short_prefixes ] or config [ :index_full_words ] split_regex_def = config [ :word_separators ] . keys . map { | k | Regexp . escape ( k ) } . join split_regex = Regexp . compile ( \"[#{split_regex_def}]\" ) all_words = filtered_str . split ( split_regex ) end all_words . each do | word | all_words . each do | word |", "del_tokens": ":word_separators => ' ' , filtered_str . split ( Regexp . compile ( config [ :word_separators ] . keys . join ) ) . each do | word | filtered_str . split ( Regexp . compile ( config [ :word_separators ] . keys . join ) ) . each do | word |", "commit_type": "fix"}
{"commit_tokens": ["Add", "-", "i", "--", "include", "-", "linters", "option"], "add_tokens": "included_linters = LinterRegistry . extract_linters_from ( options . fetch ( :included_linters , [ ] ) ) included_linters = LinterRegistry . linters if included_linters . empty? @linters = ( included_linters - excluded_linters ) . map ( & :new )", "del_tokens": "@linters = LinterRegistry . linters . reject do | linter | excluded_linters . include? ( linter ) end . map do | linter_class | linter_class . new end", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "<<", "Array", "feature"], "add_tokens": "case when obj . is_a? ( Array ) obj . each do | e | self << e end when obj . is_a? ( String ) type = :NewText safe_str = obj . gsub ( / & / , '&amp;' ) . gsub ( / < / , '&lt;' ) . gsub ( / > / , '&gt;' ) super ( safe_str ) else type = :Add super ( obj ) if nodes . last . count_observers < 1 && @observer_peers nodes . last . add_observer ( @observer_peers . first . first ) end", "del_tokens": "if obj . is_a? ( String ) type = :NewText safe_str = obj . gsub ( / & / , '&amp;' ) . gsub ( / < / , '&lt;' ) . gsub ( / > / , '&gt;' ) super ( safe_str ) else type = :Add super ( obj ) if nodes . last . count_observers < 1 && @observer_peers nodes . last . add_observer ( @observer_peers . first . first ) end", "commit_type": "add"}
{"commit_tokens": ["remove", "been_built", "tracking", "on", "Colors", "objects"], "add_tokens": "attr_reader :name , :build , :scheme @name , @build , @scheme = name , build , nil self . instance_exec ( * args , & @build ) @properties = properties . map { | p | self . send ( p ) } @method = self . method_name @level_settings = levels . map { | l | self . send ( l ) } @line_settings = levels . map { | l | self . send ( \"#{l}_line\" ) } @scheme = Logging . color_scheme ( @name , self . to_scheme_opts )", "del_tokens": "attr_reader :name , :build , :been_built , :scheme @name , @build , @been_built , @scheme = name , build , false , nil if ! @been_built self . instance_exec ( * args , & @build ) @properties = properties . map { | p | self . send ( p ) } @method = self . method_name @level_settings = levels . map { | l | self . send ( l ) } @line_settings = levels . map { | l | self . send ( \"#{l}_line\" ) } @been_built = true end @scheme ||= Logging . color_scheme ( @name , self . to_scheme_opts )", "commit_type": "remove"}
{"commit_tokens": ["make", "Jellyfish", "::", "Sinatra", "a", "module", "instead", "of", "a", "Jellyfish", "::", "Controller", ":"], "add_tokens": "module Call def call env @env = env block_call ( * dispatch ) end def block_call argument , block ret = instance_exec ( argument , & block ) body ret if body . nil? # prefer explicitly set values body '' if body . nil? # at least give an empty string [ status || 200 , headers || { } , body ] rescue LocalJumpError jellyfish . log ( \"Use `next' if you're trying to `return' or `break' from the block.\" , env [ 'rack.errors' ] ) raise end end include Call", "del_tokens": "def call env @env = env block_call ( * dispatch ) end def block_call argument , block ret = instance_exec ( argument , & block ) body ret if body . nil? # prefer explicitly set values body '' if body . nil? # at least give an empty string [ status || 200 , headers || { } , body ] rescue LocalJumpError jellyfish . log ( \"Use `next' if you're trying to `return' or `break' from the block.\" , env [ 'rack.errors' ] ) raise end", "commit_type": "make"}
{"commit_tokens": ["Change", "lookup", "for", "local", "and", "global", "config", "file", "."], "add_tokens": "COMMAND_HELP = 'help' def initialize ( root ) @root = root @local_config = local_options_file @global_config = global_options_file data [ key ] #|| data[COMMAND_KEY][key] def keys data . keys end if ! cmd . namespace . empty? && cmd . name != COMMAND_HELP if File . exists? ( local_options_file ) local_options_file else File . exists? global_options_file global_options_file end end private def local_options_file Pathname . new \"#{@root}/.githubrc\" end def global_options_file begin Pathname . new File . join ( Thor :: Util . user_home , \".githubrc\" ) rescue ArgumentError GithubCLI . ui . warn \"Unable to find ~/.githubrc because the HOME environment variable is not set\" nil", "del_tokens": "def initialize ( config_filename = nil ) @filename = config_filename || '.githubrc' data [ key ] || data [ COMMAND_KEY ] [ key ] if ! cmd . namespace . empty? && cmd . name != 'help' require 'pathname' if Pathname . new ( @filename ) . absolute? @filename else File . join Thor :: Util . user_home , \"/#{@filename}\"", "commit_type": "change"}
{"commit_tokens": ["added", "outfile", "option", "for", "now", "but", "it", "is", "disabled"], "add_tokens": "#max_value = incremental_export_into_outfile(metadata) return max_value cmd = SqlCommands . mysql_export_outfile ( :db => @export_obj . source_schema , :filepath => filepath , return max_value", "del_tokens": "sql = SqlCommands . mysql_export_outfile ( :db => @export_obj . source_schema , cmd = SqlCommands . mysql_export ( :db => @export_obj . source_schema , :filepath => filepath , :sql => sql )", "commit_type": "add"}
{"commit_tokens": ["Fix", "cookie", "serialization", "in", "controller", "tests"], "add_tokens": "def rescue_action ( e ) raise e end ; @request . cookies [ 'geo_location' ] = @success . to_yaml assert_equal @success , YAML . load ( cookies [ 'geo_location' ] )", "del_tokens": "# Re-raise errors caught by the controller. class LocationAwareController #:nodoc: all def rescue_action ( e ) raise e end ; end @request . cookies [ 'geo_location' ] = CGI :: Cookie . new ( 'geo_location' , @success . to_yaml ) assert_equal @success , YAML . load ( cookies [ 'geo_location' ] . join )", "commit_type": "fix"}
{"commit_tokens": ["updated", "rackspace", "support", "and", "bumped", "version"], "add_tokens": "# Access the host (e.g. https://storage.clouddrive.com/container) for a storage service. directory = connection . directories . get ( self . container ) directory ||= connection . directories . create ( self . permissions . merge ( :key => self . container ) ) directory = connection . directories . get ( self . container ) directory ||= connection . directories . create ( self . permissions . merge ( :key => self . container ) )", "del_tokens": "# Access the host (e.g. bucket.s3.amazonaws.com) for a storage service. directory = connection . directories . get ( self . bucket ) directory ||= connection . directories . create ( self . permissions . merge ( :key => self . bucket ) ) directory = connection . directories . get ( self . bucket ) directory ||= connection . directories . create ( self . permissions . merge ( :key => self . bucket ) )", "commit_type": "update"}
{"commit_tokens": ["changes", "number", "of", "replication", "retries", "to", "5", "by", "default"], "add_tokens": "after ( :all ) { Dotenv . load File . expand_path ( \"../spec/dummy/.env\" , __FILE__ ) ; RailsRedshiftReplicator . reload } RailsRedshiftReplicator . reload after ( :all ) { Dotenv . load File . expand_path ( \"../spec/dummy/.env\" , __FILE__ ) ; RailsRedshiftReplicator . reload }", "del_tokens": "after ( :all ) { Dotenv . load File . expand_path ( \"../spec/dummy/.env\" , __FILE__ ) ; RailsRedshiftReplicator . redefine_defaults } RailsRedshiftReplicator . redefine_defaults after ( :all ) { Dotenv . load File . expand_path ( \"../spec/dummy/.env\" , __FILE__ ) ; RailsRedshiftReplicator . redefine_defaults }", "commit_type": "change"}
{"commit_tokens": ["Add", "context", "attribute", "for", "ability"], "add_tokens": "attr_accessor :context context = @context context ||= @context", "del_tokens": "context = nil", "commit_type": "add"}
{"commit_tokens": ["Add", "emitter", "for", "case", "statement"], "add_tokens": "context 'case statement' do assert_source <<-RUBY case when bar baz when baz bar end RUBY assert_source <<-RUBY case foo when bar baz when baz bar end RUBY assert_source <<-RUBY case foo when bar , baz :other end RUBY assert_source <<-RUBY case foo when * bar :value end RUBY assert_source <<-RUBY case foo when bar baz else :foo end RUBY end", "del_tokens": "context 'case statement' do context 'without else branch' do assert_source <<-RUBY case when bar baz when baz bar end RUBY end end context 'receiver case statement' do context 'without else branch' do assert_source <<-RUBY case foo when bar baz when baz bar end RUBY end context 'with multivalued conditions' do assert_source <<-RUBY case foo when bar , baz :other end RUBY end context 'with splat operator' do assert_source <<-RUBY case foo when * bar :value end RUBY end context 'with else branch' do assert_source <<-RUBY case foo when bar baz else :foo end RUBY end end", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "explicit", "and", "implicit", "config", "blocks", "."], "add_tokens": "it 'should be able to use an explicit configuration block' do it 'should be able to use an implicit configuration block' do @options . configure do walrus = 'haswalrus' end assert_equal 'haswalrus' , @options . store [ :walrus ] end", "del_tokens": "it 'should be able to use a configuration block' do", "commit_type": "add"}
{"commit_tokens": ["use", "original", "env", "when", "retrying", "requests"], "add_tokens": "orig_env = env . dup params = orig_env [ :url ] . query_values || { } orig_env [ :url ] . query_values = params . merge ( 'oauth_token' => podio_client . oauth_token . access_token ) @app . call ( orig_env )", "del_tokens": "params = env [ :url ] . query_values || { } env [ :url ] . query_values = params . merge ( 'oauth_token' => podio_client . oauth_token . access_token ) @app . call ( env )", "commit_type": "use"}
{"commit_tokens": ["added", "specs", "(", "stubs", ")", "for", "api"], "add_tokens": "period && FAT_PERIODS . include? ( period ) period && WEIGHT_PERIODS . include? ( period )", "del_tokens": "return period && FAT_PERIODS . include? ( period ) return period && WEIGHT_PERIODS . include? ( period )", "commit_type": "add"}
{"commit_tokens": ["use", "nullobject", "pattern", "for", "default", "logger"], "add_tokens": "class NullLogger def debug ( s ) ; end def info ( s ) ; end def warn ( s ) ; end def error ( s ) ; end def fatal ( s ) ; end end @logger = NullLogger . new DEVS . logger . debug ( string ) DEVS . logger . info ( string ) DEVS . logger . warn ( string ) DEVS . logger . error ( string )", "del_tokens": "@logger = Logger . new ( STDOUT ) DEVS . logger . debug ( string ) if DEVS . logger DEVS . logger . info ( string ) if DEVS . logger DEVS . logger . warn ( string ) if DEVS . logger DEVS . logger . error ( string ) if DEVS . logger", "commit_type": "use"}
{"commit_tokens": ["Allow", "indifferent", "hash", "access", "for", "Environment#config", "."], "add_tokens": "require 'active_support/core_ext/hash' # components: # base: _components # paths: # externals: # server: \"https://github.com/razor-x\" # repositories: # - name: my_app # path: apps/my_app # - name: sub_app # path: apps/my_app/sub_app # reference: v1.0.0 # server: apps/my_app # excludes: # assets: # options: # src_pre: \"[%\" # src_post: \"%]\" # output: compiled # cdn: https://cdn.example.com/ # hash: false # sources: # javascripts: # options: # js_compressor: :uglifier # paths: # stylesheets: # options: # css_compressor: :sass # paths: # images: # options: # image_compression: true # output: images # paths: @config = ActiveSupport :: HashWithIndifferentAccess . new @config", "del_tokens": "# :components: # :base: _components # :paths: # :externals: # :server: \"https://github.com/razor-x\" # :repositories: # - :name: my_app # :path: apps/my_app # - :name: sub_app # :path: apps/my_app/sub_app # :reference: v1.0.0 # :server: apps/my_app # :excludes: # :assets: # :options: # :src_pre: \"[%\" # :src_post: \"%]\" # :output: compiled # :cdn: https://cdn.example.com/ # :hash: false # :sources: # :javascripts: # :options: # :js_compressor: :uglifier # :paths: # :stylesheets: # :options: # :css_compressor: :sass # :paths: # :images: # :options: # :image_compression: true # :output: images # :paths:", "commit_type": "allow"}
{"commit_tokens": ["adding", "back", "in", "changes", "after", "testing"], "add_tokens": "deleted_nodes = remove_nodes ( nodes ) deleted_nodes . each do | deleted_node | active_nodes . delete_if { | n | n . id == deleted_node . id } end deleted_nodes = [ ] deleted_nodes . push ( nodes . find { | n | n . ipaddress == instance . ipaddress } ) deleted_nodes", "del_tokens": "remove_nodes ( nodes ) @active_nodes -= nodes", "commit_type": "add"}
{"commit_tokens": ["Added", "extra", "test", "for", "linking", "to", "namespace", "and", "non", "-", "namespace", "rule", "names"], "add_tokens": "expect ( tree [ 3 ] [ :rule ] [ :group_rule ] [ 0 ] [ :target_rule_name ] [ :namespace_alias ] ) . to eq ( \"rfcXXXX\" ) it 'should parse groups of values with non-namespaced rule names' do ex12 = <<EX12 # import http://ietf.org/rfcXXXX.JCR as rfcXXXX encodings : ( :\" base32 \" | :\" base64 \" ) more_encodings : ( :\" base32hex \" | :\" base64url \" | :\" base16 \" ) all_encodings ( more_encodings | rfcXXXX . encodings ) EX12 tree = JCR . parse ( ex12 ) expect ( tree [ 3 ] [ :rule ] [ :rule_name ] ) . to eq ( \"all_encodings\" ) # expect(tree[3][:rule][:group_rule][0][:target_rule_name][:namespace_alias]).to eq(nil) expect ( tree [ 3 ] [ :rule ] [ :group_rule ] [ 0 ] [ :target_rule_name ] [ :rule_name ] ) . to eq ( \"more_encodings\" ) end", "del_tokens": "expect ( tree [ 3 ] [ :rule ] [ :group_rule ] [ 0 ] [ :target_rule_name ] [ :alias_name ] ) . to eq ( \"rfcXXXX\" )", "commit_type": "add"}
{"commit_tokens": ["Make", "dots", "test", "faster", "-", "small", "delay"], "add_tokens": "SpinningCursor :: Cursor . new ( \"\" ) . spin :dots , 1 sleep 1", "del_tokens": "SpinningCursor :: Cursor . new ( \"\" ) . spin :dots , 2 sleep 2", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "for", "resource", "existence", "based", "on", "path"], "add_tokens": "#user can override base return @opts [ :base ] if @opts [ :base ] #no override and no location, so return nil #work out base directory or uri resources . each do | resource | if ! resource_exists? ( resource [ \"path\" ] ) messages [ :errors ] << \"Resource #{resource[\"path\"]} does not exist\" end end return false unless base if local?", "del_tokens": "if @location && local?", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "issue", "of", "case", "sensitivity"], "add_tokens": "elsif options . secret . to_s . chars . any? { | c | ROTP :: Base32 :: CHARS . index ( c . downcase ) == nil }", "del_tokens": "elsif options . secret . to_s . chars . any? { | c | ROTP :: Base32 :: CHARS . index ( c ) == nil }", "commit_type": "fix"}
{"commit_tokens": ["remove", "from", "PK", "index", "on", "delete"], "add_tokens": "remove_from_index ( :id , id )", "del_tokens": "redis . zrem ( self . class . primary_key_index_key , id )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "number", "of", "channels", "validation", "for", "initialize", "()", "and", "num_channels", "=", "()", "."], "add_tokens": "class InvalidNumChannelsError < RuntimeError ; end MAX_NUM_CHANNELS = 65535 validate_num_channels ( num_channels ) validate_num_channels ( new_num_channels ) unless ( 1 .. MAX_NUM_CHANNELS ) === header [ :num_channels ] errors << \"Invalid number of channels. Must be between 1 and #{MAX_NUM_CHANNELS}.\" def validate_num_channels ( candidate_num_channels ) unless candidate_num_channels == :mono || candidate_num_channels == :stereo || ( 1 .. MAX_NUM_CHANNELS ) === candidate_num_channels raise InvalidNumChannelsError , \"Invalid number of channels. Must be between 1 and #{MAX_NUM_CHANNELS}.\" end end", "del_tokens": "unless ( 1 .. 65535 ) === header [ :num_channels ] errors << \"Invalid number of channels. Must be between 1 and 65535.\"", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "and", "fixed", ":", "if", "/", ":", "unless", "conditionals", "."], "add_tokens": "# match if it is still valid. If it returns false, the rule will not # match. If a proc if given, it will be passed the current subject and # binding. A method will be called without any arguments. # @option options [Symbol, String, Proc] :unless code to evaluate at the end of # the match if it is still valid. If it returns true, the rule will not # match. If a proc if given, it will be passed the current subject and # binding. A method will be called without any arguments. passed_conditionals = matched ? passes_conditionals? ( person , context_binding ) : false def passes_conditionals? ( person , context_binding ) return false unless eval_conditional @if , true , person , context_binding return false if eval_conditional @unless , false , person , context_binding def eval_conditional ( condition , default , person , context_binding ) return ( String === condition ? eval ( condition , context_binding ) : condition . call ( person , context_binding ) )", "del_tokens": "# match if it is still valid. If it returns false, the rule will not match. # @option options [Symbol, String, Proc] :unless code to evaluate at the end # of the match if it is still valid. If it returns true, the rule will not # match. passed_conditionals = matched ? passes_conditionals? ( context_binding ) : false def passes_conditionals? ( context_binding ) return false unless eval_conditional @if , true , context_binding return false if eval_conditional @unless , false , context_binding def eval_conditional ( condition , default , context_binding ) return ( String === condition ? eval ( condition , context_binding ) : condition . call )", "commit_type": "add"}
{"commit_tokens": ["Add", "spec", "for", "serialize_backtrace", "of", "Readable"], "add_tokens": "raise NotImplementedError , 'Not support serialize_backtrace'", "del_tokens": "# @option opts [String] :serialize_backtrace (true) the value of serialize_backtrace attribute raise RuntimeError , 'Not support serialize_backtrace'", "commit_type": "add"}
{"commit_tokens": ["Add", "sub", "properties", "for", "definition"], "add_tokens": "def properties ( text = nil , & block ) @properties = if block_given? { @required . first => SubProperties . new ( & block ) . construct } else text end require 'swagger_docs_generator/parser/sub_definition'", "del_tokens": "def properties ( text ) @properties = text", "commit_type": "add"}
{"commit_tokens": ["Add", "writethrough", "hash", "and", "fix", "to_h", "conversions", "."], "add_tokens": "require 'forwardable' def_delegators :@_lazer_model , :to_h , :inspect , :read_attribute , :write_attribute , :delete_attribute , :fully_loaded? , :fully_loaded! , :not_fully_loaded! , :invalidate , :exists_locally?", "del_tokens": "def_delegators :@_lazer_model , :to_h , :inspect , :read_attribute , :write_attribute , :fully_loaded? , :fully_loaded! , :not_fully_loaded! , :invalidate , :exists_locally?", "commit_type": "add"}
{"commit_tokens": ["Use", "Adamantium", "::", "Flat", "instead", "of", "Adamantium"], "add_tokens": "include Adamantium :: Flat , Equalizer . new ( :verb , :path , :body , :params )", "del_tokens": "include Adamantium , Equalizer . new ( :verb , :path , :body , :params )", "commit_type": "use"}
{"commit_tokens": ["Add", "length", "check", "to", "Array", "contract"], "add_tokens": "return false unless arg . is_a? ( Array ) && arg . length == contract . length", "del_tokens": "return false unless arg . is_a? ( Array )", "commit_type": "add"}
{"commit_tokens": ["added", "fetch", "view", "by", "name", "feature", "to", "frame", "helpers", "that", "accept", "a", "view"], "add_tokens": "@layout = TestEmptyLayout . new top_view = @controller . view @layout . root = top_view @view . motion_kit_id = :view @another_view . motion_kit_id = :another_view it 'should support setting the frame via `from_top_left(:view)`' do @layout . context ( @view ) do retval = @layout . frame @layout . from_top_left ( :another_view , x : 1 , y : 1 ) retval . should == @view . frame end @view . frame . origin . x . should == @another_view . frame . origin . x + 1 @view . frame . origin . y . should == @another_view . frame . origin . y + 1 @view . frame . size . width . should == @view_size . width @view . frame . size . height . should == @view_size . height end", "del_tokens": "@layout = MK :: Layout . new top_view = @controller . view", "commit_type": "add"}
{"commit_tokens": ["Fix", "depth", "method", "to", "works", "with", "new", "record", "without", "calculated", "attributes"], "add_tokens": "if new_record? if parent_id . nil? return 0 else return parent . depth + 1 end else n = 0 p , q = lftp , lftq while p != 0 x = p . inverse ( q ) p , q = ( x * p - 1 ) / q , x n += 1 end return n", "del_tokens": "n = 0 p , q = lftp , lftq while p != 0 x = p . inverse ( q ) p , q = ( x * p - 1 ) / q , x n += 1 n", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "Checkbox", "stepdef"], "add_tokens": "World ( Kelp :: Checkbox ) checkbox_should_be_checked ( checkbox , :within => selector ) checkbox_should_not_be_checked ( checkbox , :within => selector )", "del_tokens": "checkbox_should_be_checked ( checkbox , text , :within => selector ) checkbox_should_not_be_checked ( checkbox , text , :within => selector )", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "example", "with", "the", "new", "features", "of", "WDM"], "add_tokens": "monitor . watch_recursively ( 'C:\\Users\\Maher\\Desktop\\test' ) do | change | puts \"#{change.type.to_s.upcase}: '#{change.path}'\" end puts \"Running the monitor...\" puts \"Stopping the monitor...\" monitor . stop thread . join", "del_tokens": "monitor . watch ( 'C:\\Users\\Maher\\Desktop\\test' ) { puts \"change 1!\" } monitor . watch ( 'C:\\Users\\Maher\\Desktop\\psds' ) { puts \"change 2!\" } monitor . stop", "commit_type": "update"}
{"commit_tokens": ["Fixed", "bugs", "updated", "specs", "."], "add_tokens": "def reload! ( conditions = { } ) reloaded_object = self . class . find ( client , primary_key , scope_parameters , conditions ) self . attributes . clear mark_as_saved!", "del_tokens": "def reload! reloaded_object = self . class . find ( client , primary_key , scope_parameters )", "commit_type": "fix"}
{"commit_tokens": ["Add", "indifferent", "access", "to", "params", "hash"], "add_tokens": "@params = Hash . new { | hash , key | hash [ key . to_sym ] if key . respond_to? ( :to_sym ) } # allows indifferent access via string and symbol", "del_tokens": "@params = { }", "commit_type": "add"}
{"commit_tokens": ["Add", "defaults", "to", "route", "helper"], "add_tokens": "get \"/:id/:region/:size/:rotation/:quality.:format\" => \"images#show\" , constraints : { rotation : ALLOW_DOTS , size : SIZES } , defaults : { format : 'jpg' , rotation : '0' , region : 'full' , quality : 'native' } , as : 'image'", "del_tokens": "get \"/:id/:region/:size/:rotation/:quality(.:format)\" => \"images#show\" , constraints : { rotation : ALLOW_DOTS , size : SIZES }", "commit_type": "add"}
{"commit_tokens": ["use", "en", "just", "in", "case"], "add_tokens": "@locale [ :default ] || 'en'", "del_tokens": "@locale [ :default ]", "commit_type": "use"}
{"commit_tokens": ["move", "hindi", "up", "to", "make", "it", "in", "alphabetical", "order"], "add_tokens": "autoload :Hindi , \"babosa/transliterator/hindi\"", "del_tokens": "autoload :Hindi , \"babosa/transliterator/hindi\"", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "that", "locals", "is", "always", "initialized", "in", "render_association", ".", "If", "it", "is", "not", "the", "call", "to", "Hash#merge", "will", "fail", "."], "add_tokens": "locals = render_options . delete ( :locals ) || { }", "del_tokens": "locals = render_options . delete ( :locals )", "commit_type": "make"}
{"commit_tokens": ["fixed", "erroneous", "self", ".", "class", "."], "add_tokens": "s = joins ( <<-SQL ) ON #{quoted_table_name}.#{primary_key} = descendants.descendant_id", "del_tokens": "s = self . class . joins ( <<-SQL ) ON #{quoted_table_name}.#{self.class.primary_key} = descendants.descendant_id", "commit_type": "fix"}
{"commit_tokens": ["Add", "meta", "data", "to", "trees"], "add_tokens": "require 'key_tree/meta_data' include MetaData", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["changed", "to", "adapter", "loading", "process"], "add_tokens": "# # level = Symbol === messages . first ? messages . shift : log_level logger . send level , messages . join ( \" \" ) if log? adapter , adapter_class = Adapter . load adapter log :debug , \"HTTPI executes HTTP #{method.to_s.upcase} using the #{adapter} adapter\"", "del_tokens": "# # logger . send log_level , messages . join ( \" \" ) if log? adapter ||= Adapter . use adapter , adapter_class = Adapter . find adapter HTTPI . logger . debug \"HTTPI executes HTTP #{method.to_s.upcase} using the #{adapter} adapter\"", "commit_type": "change"}
{"commit_tokens": ["fix", "bug", "in", "map", "markup"], "add_tokens": "\"<div class=\\\"map\\\"><iframe width=\\\"200\\\" height=\\\"200\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" marginheight=\\\"0\\\" marginwidth=\\\"0\\\" src=\\\"#{body.strip}&output=embed\\\"></iframe><br /><small><a href=\\\"#{body.strip}\\\">View Larger Map</a></small></div>\" wrap_with_div ( 'information' , '$I' , Govspeak :: Document ) \"<li><p>#{$2.strip}</p></li>\\n\" \"<ol class=\\\"steps\\\">\\n#{body}</ol>\"", "del_tokens": "\"<div class=\\\"map\\\"><iframe width=\\\"200\\\" height=\\\"200\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" marginheight=\\\"0\\\" marginwidth=\\\"0\\\" src=\\\"#{body.strip}&output=embed\\\"></iframe><br /><small><a href=\\\"#{body.strip}\\\">View Larger Map</a></small></div></div>\" wrap_with_div ( 'information' , '$I' ) steps = steps + 1 \"<p class=\\\"step-label\\\"><span class=\\\"step-number\\\">#{steps}</span><span class=\\\"step-total\\\" > of [ [ TOTAL_STEPS ] ] < / span>< /p > < p > #{$2.strip}</p>\\n\" body . gsub! ( \"[[TOTAL_STEPS]]\" , steps . to_s ) \"<div class=\\\"answer-step\\\">\\n#{body}</div>\"", "commit_type": "fix"}
{"commit_tokens": ["fixed", "resource_path", "when", "no", "path"], "add_tokens": "if controller_path . rindex ( '/' ) path = controller_path [ 0 .. controller_path . rindex ( '/' ) - 1 ] @resource_path = path . split ( '/' ) . map { | i | i . to_sym } else @resource_path = String . new end", "del_tokens": "path = controller_path [ 0 .. controller_path . rindex ( '/' ) - 1 ] @resource_path = path . split ( '/' ) . map { | i | i . to_sym }", "commit_type": "fix"}
{"commit_tokens": ["Create", "Juicy", "::", "App", "as", "a", "class", "variable", "only", "once"], "add_tokens": "@@juicy = nil def juicy @@juicy end @@juicy = App . new", "del_tokens": "attr_reader :juicy def initialize ( * args ) @juicy = Juicy :: App . new super ( * args ) end", "commit_type": "create"}
{"commit_tokens": ["Use", "select", "to", "return", "more", "than", "one", "duplicate"], "add_tokens": "duplicate_locations = * locations . select { | location | locations . count ( location ) > 1 } . uniq", "del_tokens": "duplicate_locations = * locations . detect { | location | locations . count ( location ) > 1 }", "commit_type": "use"}
{"commit_tokens": ["Move", "planets", "mocking", "into", "shared", "context"], "add_tokens": "describe Codependency :: Parser , :files => :planets do", "del_tokens": "describe Codependency :: Parser do before do IO . stub ( :readlines ) do | arg | case File . basename ( arg , '.rb' ) . to_sym when :body \"\" \" class Body end \"\" \" when :earth \"\" \" # require planet class Earth end \"\" \" when :mars \"\" \" # require planet class Mars end \"\" \" when :phobos \"\" \" # require body # require mars class Phobos end \"\" \" when :planet \"\" \" # require body class Planet end \"\" \" end . strip . split ( / ^ \\s + / ) end end", "commit_type": "move"}
{"commit_tokens": ["Update", "checkout", "nav", "styles", ";", "improved", "namespacing", "on", "checkout", "nav", "#checkout", "-", "nav", "vs", "#nav"], "add_tokens": "str << \"<div id='checkout-nav'>\"", "del_tokens": "str << \"<div id='nav'>\"", "commit_type": "update"}
{"commit_tokens": ["fix", "logging", "ids", "and", "uuids", "test"], "add_tokens": "sep = / (?: \\b | \\W |_) / body_object . reject { | key , value | ! ( key =~ / #{ sep } (uu)?id #{ sep } / && value . is_a? ( String ) ) }", "del_tokens": "body_object . reject { | key , value | ! ( key =~ / \\b (uu)?id \\b / && value . is_a? ( String ) ) }", "commit_type": "fix"}
{"commit_tokens": ["create", "a", "File", "object", "and", "then", "call", "readline", ".", "File", ".", "read", "(", "file", ")", "was", "resulting", "in", "undefined", "method", "first", "for", "#<String", ":", "0x00000100a07b88", ">", "(", "NoMethodError", ")"], "add_tokens": "first_line = File . new ( file ) . readline . gsub ( / \\n $ / , '' )", "del_tokens": "first_line = File . read ( file ) . first", "commit_type": "create"}
{"commit_tokens": ["Change", "to", "bump", "patch", "version", "up"], "add_tokens": "VERSION = '0.7.4'", "del_tokens": "VERSION = '0.7.3'", "commit_type": "change"}
{"commit_tokens": ["Making", "ArgumentNode", "more", "explicit", "and", "adding", "CommandSubstitutionNode", "to", "the", "parse", "tree", "."], "add_tokens": "class ArgumentNode include Visitor attr_reader :lvalue def initialize ( lvalue ) @lvalue = lvalue end def inspect to_s end def to_s \"ArgumentNode(#{lvalue.inspect})\" end end class ConcatenationNode include Visitor attr_reader :left , :right def initialize ( left , right ) @left = left @right = right end def to_s ( indent : 0 ) \"ConcatenationNode(left: #{left.to_s}, right: #{right.to_s})\" end def inspect to_s end end attr_accessor :tail \"CommandSubstitutionNode(#{@node.to_s}, tail: #{tail.inspect})\"", "del_tokens": "\"CommandSubstitutionNode(#{@node.to_s})\"", "commit_type": "make"}
{"commit_tokens": ["change", "the", "emoji", "source", "url"], "add_tokens": "img_src = \"https://github.githubassets.com/images/icons/emoji/#{name}.png\"", "del_tokens": "img_src = \"https://github.global.ssl.fastly.net/images/icons/emoji/#{name}.png\"", "commit_type": "change"}
{"commit_tokens": ["remove", "Gemfile", ".", "lock", "from", "tracking", "and", "add", "eager", "loading", "to", "subscriber", "using", "auto_pop!"], "add_tokens": "nil_pops = 0 # Each \"turn\" of the timer should look at the available threads # and attempt to fill them in with work, if it gets a nil pop # (which means no jobs are avail) then we will track it and # return from the method after 2; this allows us to make the # timer interval greater because auto_pop! is more \"eager\" while :: ActionSubscriber :: Threadpool . ready? && nil_pops < 2 queues . each do | queue | next unless :: ActionSubscriber :: Threadpool . ready? else nil_pops = nil_pops + 1", "del_tokens": "queues . each do | queue | if :: ActionSubscriber :: Threadpool . ready?", "commit_type": "remove"}
{"commit_tokens": ["Add", "Orange", "Theme", "fix", "to", "the", "old", "themes"], "add_tokens": "VIEW_TEMPLATES = %w( base black mauve orange )", "del_tokens": "VIEW_TEMPLATES = %w( base black mauve )", "commit_type": "add"}
{"commit_tokens": ["Moved", "the", "rejection", "to", "a", "reject", "block", "on", "@queue"], "add_tokens": "next if head . content_type != \"text/html\" # If the page retrieved is not an HTML document, we'll choke on it anyway. Skip it @queue = @queue . reject { | u | @crawled . include? ( u ) or u == uri or ! ( u . kind_of? ( URI :: HTTP ) ) or ( u . host != uri . host and ! @options [ :external ] ) } puts \"****\" puts @queue", "del_tokens": "next if head . content_type != \"text/html\" next_uri unless @crawled . include? ( next_uri ) or next_uri == uri or ! ( next_uri . kind_of? ( URI :: HTTP ) ) or ( next_uri . host != uri . host and ! @options [ :external ] )", "commit_type": "move"}
{"commit_tokens": ["Update", "README", "and", "tests", "with", "optional", "options", "mumbo", "jumbo"], "add_tokens": "options . delete ( option ) return options", "del_tokens": "options . delete ( option ) and return options", "commit_type": "update"}
{"commit_tokens": ["Updated", "readme", ".", "Removed", "syntax", "error"], "add_tokens": ":redirect_uri => 'https://localhost/callback'", "del_tokens": ":redirect_uri => 'https://localhost/callback' ,", "commit_type": "update"}
{"commit_tokens": ["fixes", "a", "bug", "where", "JWT", "enterprise", "or", "user", "token", "requests", "that", "needed", "client_secret", "could", "not", "accept", "it", "as", "a", "parameter"], "add_tokens": "enterprise_id : ENV [ 'BOX_ENTERPRISE_ID' ] , client_id : ENV [ 'BOX_CLIENT_ID' ] , client_secret : ENV [ 'BOX_CLIENT_SECRET' ] ) assertion = jwt_assertion ( unlocked_private_key , client_id , enterprise_id , \"enterprise\" ) get_token ( grant_type : JWT_GRANT_TYPE , assertion : assertion , client_id : client_id , client_secret : client_secret ) client_id : ENV [ 'BOX_CLIENT_ID' ] , client_secret : ENV [ 'BOX_CLIENT_SECRET' ] ) assertion = jwt_assertion ( unlocked_private_key , client_id , user_id , \"user\" ) get_token ( grant_type : JWT_GRANT_TYPE , assertion : assertion , client_id : client_id , client_secret : client_secret ) def self . jwt_assertion ( private_key , iss , sub , box_sub_type ) JWT . encode ( payload , private_key , \"RS256\" )", "del_tokens": "enterprise_id : ENV [ 'BOX_ENTERPRISE_ID' ] , client_id : ENV [ 'BOX_CLIENT_ID' ] ) jwt_auth_post ( unlocked_private_key , client_id , enterprise_id , \"enterprise\" ) client_id : ENV [ 'BOX_CLIENT_ID' ] ) jwt_auth_post ( unlocked_private_key , client_id , user_id , \"user\" ) def self . jwt_auth_post ( private_key , iss , sub , box_sub_type ) assertion = JWT . encode ( payload , private_key , \"RS256\" ) get_token ( grant_type : JWT_GRANT_TYPE , assertion : assertion )", "commit_type": "fix"}
{"commit_tokens": ["removed", "bad", "from", "generator", "banner", "strings"], "add_tokens": "USAGE : #{ spec . name } name", "del_tokens": "USAGE : #{ spec . name } name \"", "commit_type": "remove"}
{"commit_tokens": ["Fix", "broken", "unit", "test", "for", "Repository", ".", "all"], "add_tokens": "let ( :response ) do [ { 'key' => 'a' } , { 'key' => 'b' } , { 'key' => 'c' } , ] end before do described_class . stub ( :find ) . with ( name : 'a' , client : client ) . and_return ( 'a' ) described_class . stub ( :find ) . with ( name : 'b' , client : client ) . and_return ( 'b' ) described_class . stub ( :find ) . with ( name : 'c' , client : client ) . and_return ( 'c' ) end", "del_tokens": "let ( :response ) { [ 'a' , 'b' , 'c' ] }", "commit_type": "fix"}
{"commit_tokens": ["Add", "feedback", "to", "integration", "command"], "add_tokens": "IntegrationManager . new ( core . config ) . destroy ( name , options )", "del_tokens": "IntegrationManager . new ( core . config ) . destroy ( name )", "commit_type": "add"}
{"commit_tokens": ["Update", "dummy", "app", "to", "fully", "bring", "in", "a", "tandem", "install", "with", "assets", "and", "migrations", "from", "the", "tandem", "generator"], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20120228202451 ) do", "del_tokens": "ActiveRecord :: Schema . define ( :version => 30000000000000 ) do", "commit_type": "update"}
{"commit_tokens": ["added", "comments", "going", "to", "add", "a", "separate", "test", "to", "start", "from", "ground", "0", "for", "fiscal", "calendar"], "add_tokens": "p \"fy_quarter_offset #{@fy_quarter_offset}\" # @param [Fixnum] year - the fiscal year def weeks_in_year ( year ) # 2013 @retail_calendar . weeks_in_year ( offset_year ( year ) ) #2012", "del_tokens": "def weeks_in_year ( year ) @retail_calendar . weeks_in_year ( offset_year ( year ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "Utils", ".", "literal_string?", "and", "don", "t", "call", ".", "to_s", "in", "StringBuffer", "on", "literal", "strings"], "add_tokens": "if Utils . literal_string? ( code ) buffer \" << (#{code})\" else buffer \" << (#{code}).to_s\" end", "del_tokens": "buffer \" << (#{code}).to_s\"", "commit_type": "add"}
{"commit_tokens": ["fix", "writting", "entry", "which", "switch", "single", "entry", "to", "collection"], "add_tokens": "path_after ( preceding ) end # Finds path immediately after preceding entry # @param preceding [LocatedEntry] def path_after ( preceding ) paths = aug . match ( preceding . prefix + \"/*\" ) preceding_index = paths . index ( preceding . path ) # it can happen, that insertion change previous entry from # e.g. #comment to #comment[1]. Can happen only if it switch from # single entry to collection preceding_index ||= paths . index ( preceding . path + \"[1]\" ) paths [ preceding_index + 1 ]", "del_tokens": "paths = aug . match ( located_entry . prefix + \"/*\" ) paths_index = paths . index ( preceding . path ) + 1 paths [ paths_index ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "exceptions", "in", "keepalive", "timer", "causing", "the", "EM", "reactor", "to", "be", "shut", "down"], "add_tokens": "on ( :session_ended ) { on_session_ended } # @note This will only open a new connection if the client isn't already connected to the given url # Disable reconnects if specified reconnect = @reconnect @reconnect = reconnect && allow_reconnect # Clean up timers / connections # Revert change to reconnect config once the final signal is received @reconnect = reconnect @keepalive_timer = EM :: Synchrony . add_periodic_timer ( interval ) do Turntabler . run { user . update ( :status => user . status ) } end def on_session_ended if @reconnect logger . debug 'Attempting to reconnect' begin room ? room . enter : connect ( url ) trigger ( :reconnected ) rescue Exception => ex logger . debug \"Socket closed: #{ex.message}\" on_session_ended end", "del_tokens": "# @note This wil only open a new connection if the client isn't already connected to the given url on_session_ended ( allow_reconnect ) @keepalive_timer = EM :: Synchrony . add_periodic_timer ( interval ) { user . update ( :status => user . status ) } def on_session_ended ( allow_reconnect ) if @reconnect && allow_reconnect room ? room . enter : connect ( url ) trigger ( :reconnected )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "count", "with", "non", "-", "string", "selects"], "add_tokens": "# So, building a select for a count query in ActiveRecord is # pretty heavily dependent on select_values containing strings. # I'd initially expected that I could just hack together a fix # to select_for_count and everything would fall in line, but # unfortunately, pretty much everything from that point on # in ActiveRecord::Calculations#perform_calculation expects # the column to be a string, or at worst, a symbol. # # In the long term, I would like to refactor the code in # Rails core, but for now, I'm going to settle for this hack # that tries really hard to coerce things to a string. def select_for_count visited_values = attribute_visitor . accept ( select_values . uniq ) if visited_values . size == 1 select = visited_values . first str_select = case select when String select when Symbol select . to_s else select . to_sql if select . respond_to? ( :to_sql ) end str_select if str_select && str_select !~ / [,*] / end end end", "del_tokens": "end", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "Base32", "encoding", "in", "magnet", "links"], "add_tokens": "require 'base32' # Base32 encoded result = Base32 . decode hash", "del_tokens": "raise \"Base32 encoding of magnet links is not supported\"", "commit_type": "add"}
{"commit_tokens": ["use", "the", "configured", "auth", "scheme", "in", "specs"], "add_tokens": "headers [ \"Authorization\" ] = \"#{Stitches.configuration.custom_http_auth_scheme} key=#{api_client_key}\"", "del_tokens": "headers [ \"Authorization\" ] = \"CustomKeyAuth key=#{api_client_key}\"", "commit_type": "use"}
{"commit_tokens": ["Changed", "AABB", "to", "AaBb", "to", "be", "more", "kosher", "and", "avoid", "toxicgem", "clash"], "add_tokens": "# Axis aligned bounding box class (AABB would clash with Toxicgem) class AaBb", "del_tokens": "# Axis aligned bounding box class AABB", "commit_type": "change"}
{"commit_tokens": ["Add", "specs", "for", "Configurable", ".", "config_name"], "add_tokens": "it_behaves_like 'Configurable' do describe '.config_name' do subject { described_class . config_name } it { should be ( :integer ) } end end", "del_tokens": "it_behaves_like 'Configurable'", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "compare", "XML", "-", "Fragments", "in", "Strings"], "add_tokens": "result = Nokogiri :: XML . fragment ( data ) if result . respond_to? ( :root ) && result . root . nil?", "del_tokens": "result = Nokogiri :: XML ( data ) if result . root . nil?", "commit_type": "allow"}
{"commit_tokens": ["fixes", "the", "position", "and", "output", "of", "logging", "in", "client"], "add_tokens": "logger . error ( \"[#{response.code.to_i} #{name.upcase} #{uri}]: #{response.body}\" )", "del_tokens": "logger . error ( \"[#{response.code.to_i} GET #{uri}]: #{response.body}\" )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "quotation", "marks", "arround", "runner", "s", "url"], "add_tokens": "commands . push quoted ( url ) def quoted ( url ) \"\\\"#{url}\\\"\" end", "del_tokens": "commands . push url", "commit_type": "add"}
{"commit_tokens": ["Add", "script", "/", "generate", "command"], "add_tokens": "require 'bowline/generators' Bowline :: Generators . run_cli ( APP_ROOT , 'bowline' , Bowline :: Version :: STRING , ARGV )", "del_tokens": "# todo", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "returned", "Response", "object"], "add_tokens": "def params @params . dup end", "del_tokens": "def params @params . dup end", "commit_type": "add"}
{"commit_tokens": ["Added", "user", "photos", "endpoint", "."], "add_tokens": "# @return [Hashie::Mash] A map of badge ids or badge unlock ids to a badge or a hierarchical groups of badge ids or, for unlocked badges, badge unlock ids, as they are intended for display. # @option options [String] sort How to sort the returned checkeins. Can be newestfirst or oldestfirst. # Returns photos from a user. # # @param id [String] Identity of the user to get photos for. Pass self to get photos of the acting user. # @param options [Hash] A customizable set of options. # @option options [Integer] limit Number of results to return, up to 500. # @option options [Integer] offset Used to page through results # @return [Hashie::Mash] A count and items of photos. # @requires_acting_user Yes # @see https://developer.foursquare.com/docs/users/photos def user_photos ( id = 'self' , options = { } ) get ( \"/users/#{id}/photos\" , options ) . photos end get ( 'users/search' , options ) end", "del_tokens": "# @return [Hashie::Mash] A map of badge ids or badge unlock ids to a badge. get ( 'users/search' , options ) . results end", "commit_type": "add"}
{"commit_tokens": ["Adds", "Git", "::", "AbstractMergeErrorBuilder", "support", "for", "more", "than", "modification", "merges", "."], "add_tokens": "@unresolved_files ||= ( unmerged - resolved_files ) unless resolved_files . empty? or lib . rerere_autoupdate? mergeable = unresolved_files & modified commands << \"git mergetool #{shell_escaped_files(mergeable)}\" unless mergeable . empty? mergeable . each do | f | ( unresolved_files & added ) . each do | f | commands << \"# '#{f}' was added in both branches; Fix the conflict.\" end commands << \"git add #{shell_escaped_files(unresolved_files)}\"", "del_tokens": "@unresolved_files ||= find_unresolved_files def find_unresolved_files if unmerged . length != resolved_files . length unmerged . find_all { | f | ! resolved_files . include? ( f ) } . sort else [ ] end end unless lib . rerere_autoupdate? escaped_files = shell_escaped_files ( unresolved_files ) commands << \"git mergetool #{escaped_files}\" unresolved_files . each do | f | commands << \"git add #{escaped_files}\"", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "n", "+", "1", "query", "in", "order", ".", "num_items", ".", "label", "tweaks", "."], "add_tokens": "default_scope includes ( :user ) . includes ( :order_items => :purchasable ) . order ( 'created_at DESC' ) order_items . to_a . sum ( & :quantity )", "del_tokens": "default_scope includes ( :order_items => :purchasable ) . order ( 'created_at DESC' ) order_items . sum ( & :quantity )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "tzdata", "version", "2006p", "(", "http", ":", "//", "article", ".", "gmane", ".", "org", "/", "gmane", ".", "comp", ".", "time", ".", "tz", "/", "1358", ")", "."], "add_tokens": "c . timezone 'Europe/Jersey' , 246 , 5 , - 127 , 60 c . timezone 'Europe/Podgorica' , 1273 , 30 , 289 , 15", "del_tokens": "c . timezone 'Europe/Jersey' , 246 , 5 , - 157 , 60 c . timezone 'Europe/Podgorica' , 2567 , 60 , 292 , 15", "commit_type": "update"}
{"commit_tokens": ["fixing", "a", "bug", "in", "responsive_background_image", "helper"], "add_tokens": "VERSION = \"0.0.4\"", "del_tokens": "VERSION = \"0.0.3\"", "commit_type": "fix"}
{"commit_tokens": ["Updated", "app", "version", "and", "history"], "add_tokens": "MINOR = 2 BUGFIX = 0", "del_tokens": "MINOR = 1 BUGFIX = 3", "commit_type": "update"}
{"commit_tokens": ["Create", "new", "branches", "if", "necessary", "."], "add_tokens": "prepare # Get local and remote branches ready to create a new request. def prepare # People should work on local branches, but especially for single commit changes, # more often than not, they don't. Therefore we create a branch for them, # to be able to use code review the way it is intended. if source_branch == target_branch # Unless a branch name is already provided, ask for one. if ( branch_name = @args . shift ) . nil? puts 'Please provide a name for the branch:' branch_name = gets . chomp . gsub ( / \\W + / , '_' ) . downcase end # Create the new branch (as a copy of the current one). git \"checkout -b --track review_#{Time.now.strftime(\"%y%m%d\")}_#{branch_name}\" # Go back to master and get rid of pending commits (as these are now on the new branch). local_branch = source_branch git \"checkout #{target_branch}\" git \"reset --hard origin/#{target_branch}\" git \"checkout #{local_branch}\" end # Push latest commits to the remote branch (and by that, create it if necessary). git \"push origin\" end", "del_tokens": "# Push latest commits to the remote branch (create it if necessary). git \"push origin review_#{Time.now.strftime(\"%y%m%d\")}_#{source_branch}\"", "commit_type": "create"}
{"commit_tokens": ["Fix", "spec", "to", "work", "under", "ruby", "-", "head"], "add_tokens": "Dir [ File . expand_path ( '../{support,shared}/**/*.rb' , __FILE__ ) ] . each do | file | require file end if RUBY_VERSION >= '1.9' and ENV [ 'COVERAGE' ] == 'true' require 'simplecov' SimpleCov . start do command_name 'spec:unit' add_filter 'spec' end end # change the heckle timeout to be 5 seconds if defined? ( :: Heckle ) class :: Heckle @@timeout = 5 end end", "del_tokens": "Dir [ File . expand_path ( '../{support,shared}/**/*.rb' , __FILE__ ) ] . each { | f | require f }", "commit_type": "fix"}
{"commit_tokens": ["change", "variable", "name", ".", "minimize", "get_snippet", "method"], "add_tokens": "ERB . new ( SUNIPPET_TEMPLATE ) . result ( binding ) def get_args_names ( method ) args = method . args", "del_tokens": "erb = ERB . new ( SUNIPPET_TEMPLATE ) snippet = erb . result ( binding ) snippet def get_args_names ( _method ) args = _method . args", "commit_type": "change"}
{"commit_tokens": ["added", "handling", "of", "view", "params", "like", "count", "etc"], "add_tokens": "def view name , params = nil url = \"#{@root}/_view/#{name}\" if params query = params . collect do | k , v | v = JSON . unparse ( v ) if %w{ key startkey endkey } . include? ( k . to_s ) \"#{k}=#{CGI.escape(v.to_s)}\" end . join ( \"&\" ) url = \"#{url}?#{query}\" end CouchRest . get url", "del_tokens": "def view name CouchRest . get \"#{@root}/_view/#{name}\"", "commit_type": "add"}
{"commit_tokens": ["Remove", ":", "id", "from", "default", "list", "of", "columns", "for", "forms"], "add_tokens": "( Haiku . crushyform_schema . keys - [ :id ] ) . each do | k | form . should . not . match ( / #{ Haiku . new . crushyid_for ( :id ) } / )", "del_tokens": "Haiku . crushyform_schema . keys . each do | k |", "commit_type": "remove"}
{"commit_tokens": ["Allow", "swapping", "deploy_revision", "for", "something", "else", "."], "add_tokens": "@deploy_resource = send ( new_resource . strategy . to_sym , new_resource . id ) do", "del_tokens": "@deploy_resource = deploy_revision new_resource . id do", "commit_type": "allow"}
{"commit_tokens": ["Add", "Kairos", "::", "Client", ".", "gallery_list_all", "method", "and", "specs", "."], "add_tokens": "# List all Galleries # # Example Usage: # - require 'kairos' # - client = Kairos::Client.new(:app_id => '1234', :app_key => 'abcde1234') # - client.gallery_list_all def gallery_list_all post_to_api ( Kairos :: Configuration :: GALLERY_LIST_ALL ) end def post_to_api ( endpoint , options = { } ) response = options . empty? ? api_post ( connection ) : api_post ( connection , options ) def api_post ( connection , options = { } ) request . body = options . empty? ? nil : options . to_json", "del_tokens": "def post_to_api ( endpoint , options ) response = api_post ( connection , options ) def api_post ( connection , options ) request . body = options . to_json", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "has_one_attached", "associations", "."], "add_tokens": "assert :: ActiveStorageDragAndDrop :: VERSION != nil", "del_tokens": "assert_not_nil :: ActiveStorageDragAndDrop :: VERSION end def test_it_does_something_useful assert false", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "migration", "in", "dummy"], "add_tokens": "def self . mysqldump \"mysqldump -u#{} \"", "del_tokens": "def self . export_cmd \"mysqldump \"", "commit_type": "fix"}
{"commit_tokens": ["Added", "info", "about", "init", "to", "docs"], "add_tokens": "description : \"Clash is an integration test framework designed for Jekyll developers\" ,", "del_tokens": "description : \"A super simple testing framework for static sites.\" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "Hexp", "::", "Node#attr", "method"], "add_tokens": "# Create new Hexp::List # # @example # Hexp::List.new([H[:p], H[:div]]) # # @param nodes [#to_ary] List of nodes # # @api public # super Hexp . deep_freeze nodes . to_ary # Convenience constructor # # @example # Hexp::List[ # Hexp::Node[:marquee, \"Try Hexp for instanst satisfaction!\"], # Hexp::Node[:hr], # ] # # @param args [Array] individual nodes # # @api public # # String representation # # This delegates to the underlying array, so it's not obvious from the output # that this is a wrapping class. This is convenient when inspecting nested # hexps, but probably something we want to solve differently. # # @api private # @return string #", "del_tokens": "# @example # Hexp::List[ # Hexp::Node[:marquee, \"Try Hexp for instanst satisfaction!\"], # Hexp::Node[:hr], # ] super Hexp . deep_freeze nodes", "commit_type": "add"}
{"commit_tokens": ["Fix", "alignment", "of", "hash", "elements"], "add_tokens": "\"Location\" => location , \"Expires\" => ( Time . now + cache_time ) . httpdate", "del_tokens": "\"Location\" => location , \"Expires\" => ( Time . now + cache_time ) . httpdate", "commit_type": "fix"}
{"commit_tokens": ["Add", "dummy", "classes", "as", "fixtures"], "add_tokens": "let ( :dummy_task ) { DummyTask } let ( :argv ) { [ ] } before { subject . should_receive ( :print_help ) }", "del_tokens": "let ( :dummy_task ) { DummyTask = Class . new ( Alfred :: Task ) } let ( :argv ) { [ ] } before { subject . should_receive ( :print_help ) }", "commit_type": "add"}
{"commit_tokens": ["adding", "forward", "slash", "to", "dir", "path", "for", "validation", "checking", "command"], "add_tokens": "part_path = \"#{Dir.pwd}\" + \"/\" + \"#{part_path}\" || Dir . pwd", "del_tokens": "part_path = \"#{Dir.pwd}#{part_path}\" || Dir . pwd", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "transactions", "start", "date", "."], "add_tokens": "params . require ( :account ) . permit ( :token , :access_token , :type , :name , :owner_id , :owner_type , :transactions_start_date , account_ids :[] )", "del_tokens": "params . require ( :account ) . permit ( :token , :access_token , :type , :name , :owner_id , :owner_type , account_ids : [ ] )", "commit_type": "add"}
{"commit_tokens": ["Use", "ordered", "has", "for", "orderby", "in", "QueryMessage", ".", "Accept", "a", "single", "string", "for", "the", "order_by", "value", "."], "add_tokens": "if query . order_by && query . order_by . length > 0 when String { query . order_by => 1 } h = OrderedHash . new query . order_by . each { | ob | h [ ob ] = 1 } h query . order_by else raise \"illegal order_by: is a #{query.order_by.class.name}, must be String, Array, Hash, or OrderedHash\"", "del_tokens": "if query . order_by if query . order_by . empty? # Empty array of order_by values [ ] else case query . order_by [ 0 ] when Hash # Array of hashes query . order_by else # ['a', 'b'] query . order_by . collect { | v | { v => 1 } } # Assume ascending order for all values end end a = [ ] query . order_by . each { | k , v | a << { k => v } } a", "commit_type": "use"}
{"commit_tokens": ["Allow", "loading", "a", "custom", "binding"], "add_tokens": "@binding = nil o . on ( \"-b\" , \"--binding BINDING\" , \"Load BINDING as the binding\" , \"for the loaded template\" ) do | b | @binding = b end template = Template . new ( arguments , @arguments , nomodify : @nomodify , bind : @binding )", "del_tokens": "template = Template . new ( arguments , @arguments , nomodify : @nomodify )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "the", "hack", "for", "tns", "namespaces"], "add_tokens": "namespace = node . namespaces . fetch ( \"xmlns:#{prefix}\" )", "del_tokens": "if prefix == 'tns' && schema = node . at_xpath ( 'ancestor::xs:schema' , ns ) namespace = schema . attribute ( 'targetNamespace' ) . to_s else namespace = node . namespaces . fetch ( \"xmlns:#{prefix}\" ) end", "commit_type": "remove"}
{"commit_tokens": ["Updating", "spec", ".", "opts", "for", "pretty", "output"], "add_tokens": "", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Add", "singletons", "for", "performance", "."], "add_tokens": "def self . wkb_reader_singleton @@wkb_reader_singleton ||= WkbReader . new end def self . wkt_reader_singleton @@wkt_reader_singleton ||= WktReader . new end self . wkb_reader_singleton . read ( wkb ) self . wkb_reader_singleton . read_hex ( wkb ) geom = self . wkt_reader_singleton . read ( raw_wkt ) @upper_left ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(0)} #{cs.get_y(0)})\" ) @upper_right ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(1)} #{cs.get_y(1)})\" ) @lower_right ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(2)} #{cs.get_y(2)})\" ) @lower_left ||= Geos :: wkt_reader_singleton . read ( \"POINT(#{cs.get_x(3)} #{cs.get_y(3)})\" )", "del_tokens": "WkbReader . new . read ( wkb ) WkbReader . new . read_hex ( wkb ) geom = WktReader . new . read ( raw_wkt ) WktReader . new . read ( \"POINT(#{cs.get_x(0)} #{cs.get_y(0)})\" ) WktReader . new . read ( \"POINT(#{cs.get_x(1)} #{cs.get_y(1)})\" ) WktReader . new . read ( \"POINT(#{cs.get_x(2)} #{cs.get_y(2)})\" ) WktReader . new . read ( \"POINT(#{cs.get_x(3)} #{cs.get_y(3)})\" )", "commit_type": "add"}
{"commit_tokens": ["Removing", "old", "connection", "code", "from", "Video", "initializing", "it", "like", "other", "objects", "."], "add_tokens": "def initialize ( hash ) parse ( hash ) end def self . get ( id ) json = connection . get ( \"videos/#{id}\" ) new ( json ) include Connection Channel . new ( connection . get ( \"channels/#{@channel_name}\" ) )", "del_tokens": "def initialize ( arg , connection ) @connection = connection case arg when Hash parse ( arg ) when String json = @connection . get ( \"videos/#{arg}\" ) parse ( json ) else raise ArgumentError end def initialize ( arg ) super ( arg , Connection . instance ) end Channel . new ( @conn . get ( \"channels/#{@channel_name}\" ) , @conn ) @conn = conn", "commit_type": "remove"}
{"commit_tokens": ["move", "role", "mapping", "to", "a", "specific", "task", "during", "initialization"], "add_tokens": "role_object_array = setup_args . zip ( args ) map_roles ( role_object_array ) role_object_array . each { | role , object | def map_roles ( role_object_array ) role_object_array . each do | role , object | role_map << [ role , role_behavior ( role ) , object ] end end", "del_tokens": "setup_args . zip ( args ) . each { | role , object | role_map << [ role , role_behavior ( role ) , obj ]", "commit_type": "move"}
{"commit_tokens": ["Removed", "dependency", "on", "Highline", "s", "terminal_size", "to", "get", "width"], "add_tokens": "require 'io/console' # Highline 1.7's terminal_size cannot be trusted to return the values in # the correct order so just use IO.console.winsize directly @window_width = IO . console . winsize [ 1 ]", "del_tokens": "@window_width = @h . terminal_size [ 0 ]", "commit_type": "remove"}
{"commit_tokens": ["add", "spec", "for", "when", "presenter", "class", "isn", "t", "defined", "but", "the", "file", "exists"], "add_tokens": "# Try to find the presenter class (Not guaranteed, # for example if the presenter class wasn't defined # or if the file wasn't found) def presenter_base_dir File . join ( Rails . root , \"app\" , \"presenters\" ) end", "del_tokens": "# Try to find the class (That's not guaranteed, for example # if the presenter class was not defined or the file wasn't found). # TODO: make the presenters path configurable def presenter_base_dir File . join ( Rails . root , \"app\" , \"presenters\" ) end", "commit_type": "add"}
{"commit_tokens": ["Remove", "numbering", "from", "alignment", "editing", "rules"], "add_tokens": "When / ^I apply island rule with max_gap_size ( \\d +)$ / do | arg1 |", "del_tokens": "When / ^I apply rule ( \\d +) masking with X and max_gap_size ( \\d +)$ / do | arg1 , arg2 |", "commit_type": "remove"}
{"commit_tokens": ["Adding", "excon", "dependency", "configuration", "and", "some", "adapter", "stuff"], "add_tokens": "require \"da_face/configuration\" require \"da_face/api/push\" require \"excon\" class << self attr_accessor :configuration end def self . configuration @configuration ||= Configuration . new end def self . configure yield ( configuration ) end def self . reset_config @configuration = Configuration . new end", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["remove", "unnecessary", "*", "...", "flatten", "when", "initialising", "Hashes", "from", "Hash", ".", "maps"], "add_tokens": "ns_attrs = Hash [ ns_prefixes . map do | prefix , href | end ] Hash [ attrs . map do | n , attr | end ] Hash [ namespaces . map do | prefix , href | end . compact ]", "del_tokens": "ns_attrs = Hash [ * ns_prefixes . map do | prefix , href | end . flatten ] Hash [ * attrs . map do | n , attr | end . flatten ] Hash [ * namespaces . map do | prefix , href | end . compact . flatten ]", "commit_type": "remove"}
{"commit_tokens": ["Changed", "so", "StatusController", "inherits", "from", "main", "ApplicationController", "rather", "than", "it", "s", "own", "so", "it", "uses", "the", "includer", "s", "layout", "."], "add_tokens": "class StatusCat :: StatusController < ApplicationController", "del_tokens": "class StatusCat :: StatusController < StatusCat :: ApplicationController", "commit_type": "change"}
{"commit_tokens": ["fix", "releasing", "master", "publishing", "integrate", "into", "staging", "message"], "add_tokens": "message_parts = [ ] message_parts << \"#worklog resetting #{bad_branch} branch to #{good_branch} #scgitx\" if removed_branches . any? message_parts << \"\" message_parts << \"the following branches were affected:\" messgae_parts += removed_branches . map { | b | '* ' + b } end post message_parts . join ( \"\\n\" ) integrate_branch ( 'master' , 'staging' )", "del_tokens": "post \"#worklog resetting #{bad_branch} branch to #{good_branch} #scgitx\\n\\nthe following branches were affected:\\n#{removed_branches.map{|b| '* ' + b}.join(\"\\n\") }\" invoke :integrate , [ 'staging' , '--quiet' ]", "commit_type": "fix"}
{"commit_tokens": ["change", "POST", "from", "/", "input", "to", "/"], "add_tokens": "post '/' do", "del_tokens": "post '/input' do", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "faulty", "attempt", "to", "automate", "requires", "."], "add_tokens": "require \"gaapi/access_token.rb\" require \"gaapi/main.rb\" require \"gaapi/query.rb\" require \"gaapi/report.rb\" require \"gaapi/response.rb\" require \"gaapi/row.rb\"", "del_tokens": "# require \"gaapi/access_token.rb\" # require \"gaapi/main.rb\" # require \"gaapi/query.rb\" # require \"gaapi/response.rb\" Dir . glob ( \"lib/gaapi/**/*.rb\" ) . each { | f | require f . gsub ( %r{ lib/ } , \"\" ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "embargo", "dates", "to", "right", "section", "."], "add_tokens": "content += %Q{ <embargo>\\n <human/>\\n} if rights [ \"embargo-date\" ] content += %Q{ <machine>\\n} content += %Q{ <date>#{rights[\"embargo-date\"]}</date>\\n} content += %Q{ </machine>\\n} else content += %Q{ <machine/>\\n} end content += %Q{ </embargo>\\n}", "del_tokens": "content += %Q{ <embargo>\\n <human/>\\n <machine/>\\n </embargo>\\n}", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "_NGrams_", "and", "_NGramReferences_", "."], "add_tokens": "assert_raise ( WLAPI :: ExternalError ) do assert_raise ( WLAPI :: ExternalError ) do", "del_tokens": "assert_raise ( NotImplementedError ) do assert_raise ( NotImplementedError ) do", "commit_type": "add"}
{"commit_tokens": ["use", "simplecov", "for", "coverage", "reports"], "add_tokens": "require 'simplecov' SimpleCov . start", "del_tokens": "require 'cover_me' CoverMe . config do | c | c . project . root = File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '..' ) ) c . file_pattern = [ / #{ CoverMe . config . project . root } \\/ lib \\/ .+ \\. rb / ] end", "commit_type": "use"}
{"commit_tokens": ["remove", "final", "references", "to", "calabash"], "add_tokens": "context \"when using Brazenhead\" do", "del_tokens": "context \"when using Calabash\" do", "commit_type": "remove"}
{"commit_tokens": ["adding", "support", "for", "deprecated", "add_private_type", "function"], "add_tokens": "key = \"tag:#{key}\" unless key =~ / ^(tag:|x-private) /", "del_tokens": "key = \"tag:#{key}\" unless key . start_with? ( 'tag:' )", "commit_type": "add"}
{"commit_tokens": ["Created", "and", "destroyed", "records", "waits", "for", "server", "response", "before", "updating", "UI"], "add_tokens": "if fields . present? if ! record . persisted? error = \"No fields were provided\" transmit response transmit response transmit response", "del_tokens": "tmp_id = params [ :tmp_id ] rescue nil if tmp_id if record . persisted? response = { collection : data [ :model ] . model_name . collection , msg : 'create' , tmp_id : tmp_id , id : record . id , data : record } # Send creation notification to the client transmit_packet response else error = \"Tracking _id must be provided\" transmit_packet response transmit_packet response transmit_packet response", "commit_type": "create"}
{"commit_tokens": ["Use", "attr", "reader", "a", "bit"], "add_tokens": "attr_reader :result , :errors , :inputs", "del_tokens": "def result @result end def errors @errors end def inputs @inputs end", "commit_type": "use"}
{"commit_tokens": ["add", "more", "specs", "to", "time_travel_to"], "add_tokens": "it 'should return a button with timecop console route' do it 'should set the hour to default of 12' do helper . time_travel_to ( date ) . should include ( \"current_time%284i%29%5D=12\" ) end context \"when a custom name is passed\" do let ( :name ) { \"important_event\" } it \"should pass the name as the button name\" do helper . time_travel_to ( date , name ) . should include ( \"value=\\\"important_event\\\"\" ) end end end context \"when a DateTime object is passed\" do let ( :date ) { DateTime . parse ( '2001-02-03T04:05:06+07:00' ) } it \"should set the hour accordingly\" do helper . time_travel_to ( date ) . should include ( \"current_time%284i%29%5D=4\" ) end it \"should set the minute accordingly\" do helper . time_travel_to ( date ) . should include ( \"current_time%285i%29%5D=5\" ) end", "del_tokens": "it 'should return a link with timecop console route' do", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "unitialized", "ENV"], "add_tokens": "require \"blankslate\" class OS < BlankSlate", "del_tokens": "class OS < BasicObject", "commit_type": "fix"}
{"commit_tokens": ["Add", "context", "to", "support", "orthography", "exceptions", "."], "add_tokens": "when vocalic? then 5 when liquid? then 3 when nasal? then 2 when fricative? then 1 # A sound which begins plosive and finishes fricative.", "del_tokens": "when vocalic? then 5 when liquid? then 3 when nasal? then 2 when fricative? then 1 # A sound which begins plosive and finished fricative.", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "on", "the", "current", "todo", "list"], "add_tokens": "def nameservers = ( nameservers ) end def registrant_contact end def registrant_contact = ( contact ) end def technical_contact end def technical_contact = ( contact ) end def administrative_contact end def administrative_contact = ( contact )", "del_tokens": "def nameservers = ( nameservers ) set_collection_of_items ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "synchronously", "flush", "AsyncEmitter"], "add_tokens": "@threads = [ ] def _flush ( sync = false ) def _flush ( sync = false ) @threads . select! { | thread | thread . alive? } @threads . push ( t ) if sync @threads . each ( & :join ) end", "del_tokens": "def _flush def _flush", "commit_type": "add"}
{"commit_tokens": ["added", "more", "examples", "to", "readme"], "add_tokens": "encoded_url_args = url_args . collect { | k , v | \"#{CGI.escape k.to_s}=#{CGI.escape v.to_s}\" } . join ( \"&\" ) encoded_post_args = post_args . collect { | k , v | \"#{CGI.escape k.to_s}=#{CGI.escape v.to_s}\" } . join ( \"&\" )", "del_tokens": "encoded_url_args = url_args . collect { | k , v | \"#{CGI.escape k}=#{CGI.escape v}\" } . join ( \"&\" ) encoded_post_args = post_args . collect { | k , v | \"#{CGI.escape k}=#{CGI.escape v}\" } . join ( \"&\" )", "commit_type": "add"}
{"commit_tokens": ["use", "table", "creation", "in", "metaschema", ".", "rb"], "add_tokens": "# require_relative 'schema' def self . create_meta_schema ( db ) db . create_table :schema_entities do db . create_table :schema_attributes do # class TableDefinition < Sequel::Model # one_to_many :schema_attributes # in lib/schema_attribute # end", "del_tokens": "require_relative 'schema' self . create_meta_schema ( db ) db . create_table :table_definitions do db . create_table :column_definitions do class TableDefinition < Sequel :: Model one_to_many :schema_attributes # in lib/schema_attribute end", "commit_type": "use"}
{"commit_tokens": ["Fix", "missing", "v", "term", "from", "delta"], "add_tokens": "delta2 = ( @delta_pre * v ) ** 2", "del_tokens": "delta2 = @delta_pre ** 2", "commit_type": "fix"}
{"commit_tokens": ["Updated", "syntax", "in", "method", "modify_element", "()"], "add_tokens": "modify_element ( value , pos [ 0 ] , :bin => bin ) modify_element ( value , pos [ 0 ] , :bin => bin ) add_msg ( \"Error. Unable to encode data element value of unknown type (Value Representation)!\" ) def modify_element ( value , pos , opts = { } )", "del_tokens": "modify_element ( value , :bin => bin , :pos => pos [ 0 ] ) modify_element ( value , :bin => bin , :pos => pos ) add_msg ( \"Error. Unable to encode data element value of unknown type!\" ) def modify_element ( value , opts = { } ) pos = opts [ :pos ] pos = pos [ 0 ] if pos . is_a? ( Array )", "commit_type": "update"}
{"commit_tokens": ["Added", "check", "to", "see", "if", "entries", "are", "empty", "in", "highest_ranking", ".", "Test", "case", "also", "written", "."], "add_tokens": "entries . empty? ? [ ] : entries . group_by { | _ , value | value } . sort . last . last", "del_tokens": "entries . group_by { | _ , value | value } . sort . last . last", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "new", "plugin", "-", "level", "class", "method", ":", "plugin_description"], "add_tokens": "def description ( new_description ) @description = new_description def plugin_description @description ||= \"This plugin doesn't provide a :description\" def provides ( * list ) @features = list end def provides? ( feature ) @features . include? ( feature ) end", "del_tokens": "def provides ( * list ) @features = list def provides? ( feature ) @features . include? ( feature )", "commit_type": "add"}
{"commit_tokens": ["Changed", "name", "of", "Paginatedsheet", "to", "Sheetpage"], "add_tokens": "class Sheetpage < Xlsheet", "del_tokens": "class Paginatedsheet < Xlsheet", "commit_type": "change"}
{"commit_tokens": ["Change", "GitHub", "organization", "and", "update", "badge"], "add_tokens": "VERSION = \"0.1.5\"", "del_tokens": "VERSION = \"0.1.4\"", "commit_type": "change"}
{"commit_tokens": ["fix", "clone", "and", "test", "both", "dup", "and", "clone"], "add_tokens": "def self . copy_clone_states ( from , to ) to . taint if from . tainted? && ! to . tainted? to . freeze if from . frozen? && ! to . frozen? to end dup . tap do | newobj | newobj . instance_variable_set ( \"@collection\" , self . class . copy_clone_states ( @collection , @collection . dup ) ) self . class . copy_clone_states ( self , newobj )", "del_tokens": "super . tap do | newobj | newobj . instance_variable_set ( \"@collection\" , @collection . clone )", "commit_type": "fix"}
{"commit_tokens": ["improved", "performance", "of", "indexes", "and", "pk_and_sequence_for", "methods", "to", "make", "schema", "dump", "a", "little", "bit", "faster"], "add_tokens": "( owner , table_name ) = @connection . describe ( table_name ) FROM all_indexes i , all_ind_columns c WHERE i . table_name = '#{table_name}' AND i . owner = '#{owner}' AND i . table_owner = '#{owner}' AND c . index_owner = i . owner AND NOT EXISTS ( SELECT uc . index_name FROM all_constraints uc WHERE uc . index_name = i . index_name AND uc . owner = i . owner AND uc . constraint_type = 'P' ) indexes << IndexDefinition . new ( table_name . downcase , row [ 'index_name' ] , row [ 'uniqueness' ] == \"UNIQUE\" , [ ] ) from user_constraints c , user_cons_columns cc", "del_tokens": "FROM all_indexes i , user_ind_columns c WHERE i . table_name = '#{table_name.to_s.upcase}' AND i . index_name NOT IN ( SELECT uc . index_name FROM user_constraints uc WHERE uc . constraint_type = 'P' ) AND i . owner = sys_context ( 'userenv' , 'session_user' ) indexes << IndexDefinition . new ( table_name , row [ 'index_name' ] , row [ 'uniqueness' ] == \"UNIQUE\" , [ ] ) from user_constraints c , all_cons_columns cc", "commit_type": "improve"}
{"commit_tokens": ["Add", "Scope", "to", "act", "as", "root", "template", "scope", "and", "clarify", "partial", "rendering", "behavior"], "add_tokens": "require 'dry/view/scope' Scope . new (", "del_tokens": "require 'dry/view/part' Part . new (", "commit_type": "add"}
{"commit_tokens": ["Add", "nil", "to", "Tracer#extract", "@return", "doc"], "add_tokens": "# @return [SpanContext, nil] the extracted SpanContext or nil if none could be found", "del_tokens": "# @return [SpanContext] the extracted SpanContext or nil if none could be found", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplicate", "copy", "of", "ssh_tunnel", ".", "rb"], "add_tokens": "# if @gateway # say \"Shutting down ssh reverse tunnel\" # @gateway.close(@port) if @port # @gateway.shutdown! if @gateway # end", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "sitemap_for", "relation", "config", "method", "that", "requires", "find_each"], "add_tokens": "attr_reader :name , :collection , :block , :host , :folder @collection = options [ :collection ]", "del_tokens": "attr_accessor :name , :collection , :block attr_reader :host , :folder end if args . first . respond_to? ( :find_each ) || args . first . respond_to? ( :each ) @collection = args . shift @name ||= begin @collection . table_name if @collection . respond_to? ( :table_name ) end", "commit_type": "add"}
{"commit_tokens": ["Make", "dynamic", "/", "fixed", "body", "state", "machine", "more", "intuitive"], "add_tokens": "specify \"total message size being too large with content-size\" do expect { parser . parse ( \"other:val\\n\" ) # 31 } . to raise_error ( Stompede :: MessageSizeExceeded ) end specify \"message size being too large without content-size\" do Stompede :: Stomp :: Parser . stub ( max_message_size : 30 ) parser = Stompede :: Stomp :: Parser . new parser . parse ( \"CONNECT\\n\" ) # 8 parser . parse ( \"content-size:30\\n\" ) # 24 expect { parser . parse ( \"hi:hoy\\n\" ) # 31 } . to raise_error ( Stompede :: MessageSizeExceeded )", "del_tokens": "specify \"total message size being too large\" do expect { parser . parse ( \"other:val\\n\" ) } . to raise_error ( Stompede :: MessageSizeExceeded )", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "return", "event", "class", "."], "add_tokens": "def self . to_s event_name end define_method ( event . event_name ) { event }", "del_tokens": "define_method ( event . event_name ) { event . event_name }", "commit_type": "change"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.6.0\"", "del_tokens": "VERSION = \"0.5.0\"", "commit_type": "change"}
{"commit_tokens": ["added", "the", "container", "class", "support", "(", "even", "when", "specifying", "non", "-", "container", "elements", ")"], "add_tokens": "options [ :container ] ||= { } options [ :container ] [ :class ] = arrayorize ( options [ :container ] [ :class ] ) << :: Formula . block_class components << @template . content_tag ( :: Formula . hint_tag , options [ :hint ] , :class => :: Formula . hint_class ) if options [ :hint ] @template . content_tag ( :: Formula . block_tag , options [ :container ] ) do # Create an array from a string, a symbol, or an undefined value. The default is to return # the value and assume it has already is valid. def arrayorize ( value ) case value when nil then return [ ] when String then value . to_s . split when Symbol then value . to_s . split else value end end", "del_tokens": "components << @template . content_tag ( :: Formula . hint_tag , options [ :hint ] , :class => :: Formula . hint_class ) if options [ :hint ] @template . content_tag ( :: Formula . block_tag , options [ :container ] , :class => :: Formula . block_class ) do # # Returns: # # * \"name \" # * :email - for string columns named 'email' # * :phone - for string columns named 'phone' # * :password - for string columns named 'password' # * :number - for integer, float, or decimal columns # * :text - for all other cases", "commit_type": "add"}
{"commit_tokens": ["allow", "UploadIO", "to", "be", "passed", "in", "to", "post_io_streaming"], "add_tokens": "payload [ :file ] = file . is_a? ( UploadIO ) ? file : UploadIO . new ( file , content_type ) end", "del_tokens": "payload [ :file ] = UploadIO . new ( file , content_type ) end", "commit_type": "allow"}
{"commit_tokens": ["Add", "test", "for", "Pkgr", "::", "Config", "."], "add_tokens": "\"--target \\\"#{target}\\\"\" , \"--description \\\"#{description}\\\"\" , args", "del_tokens": "\"--target \\\"#{target}\\\"\" args . join ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "usage", "of", "export_default", "at", "top", "of", "file"], "add_tokens": "if export_default transform_export_default_value ( export_default , m ) else module_facade ( m ) end end # Returns exported value for a default export # If the given value is a symbol, returns the value of the corresponding # constant. # @param value [any] export_default value # @param mod [Module] module # @return [any] exported value def self . transform_export_default_value ( value , mod ) if value . is_a? ( Symbol ) && mod . const_defined? ( value ) mod . const_get ( value ) else value end # defined on self and its value is returned. This is essential to", "del_tokens": "export_default || module_facade ( m ) # defined on self and its value is returned. This is essential to v = const_get ( v ) if v . is_a? ( Symbol ) && const_defined? ( v )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "RSpec", "-", "they", "all", "now", "work"], "add_tokens": "# Called when the neo4j shutdown in order to release references to indexes def on_neo4j_shutdown @indexes . clear end # Called from the event handler when a new node or relationships is about to be committed. def update_index_on ( node , field , old_val , new_val ) if @via_relationships . include? ( field ) dsl = @via_relationships [ field ] target_class = dsl . target_class dsl . _all_relationships ( node ) . each do | rel | other = rel . _start_node target_class . _indexer . update_single_index_on ( other , field , old_val , new_val ) end end update_single_index_on ( node , field , old_val , new_val ) end", "del_tokens": "def update_index_on ( node , field , old_val , new_val ) #:nodoc: if @via_relationships . include? ( field ) dsl = @via_relationships [ field ] target_class = dsl . target_class dsl . _all_relationships ( node ) . each do | rel | other = rel . _start_node target_class . _indexer . update_single_index_on ( other , field , old_val , new_val ) end end update_single_index_on ( node , field , old_val , new_val ) end def on_neo4j_shutdown # Since we might start the database again we must make sure that we don't keep any references to # an old lucene index in memory. @indexes . clear end", "commit_type": "fix"}
{"commit_tokens": ["Added", "logging", "of", "bugs", "in", "blocks"], "add_tokens": "#Caboose.log(\"Block #{block} is a string, finding block object... self.id = #{self.id}\") begin rescue ActionView :: MissingTemplate str = view . render ( :partial => \"caboose/blocks/#{block.block_type.name}\" , :locals => options2 ) rescue ActionView :: MissingTemplate begin str = view . render ( :partial => \"caboose/blocks/#{block.block_type.field_type}\" , :locals => options2 ) rescue Exception => ex Caboose . log ( ex . message ) end rescue Exception => ex Caboose . log ( ex . message ) rescue Exception => ex Caboose . log ( ex . message )", "del_tokens": "Caboose . log ( \"Block #{block} is a string, finding block object... self.id = #{self.id}\" ) begin #str = view.render(:partial => \"caboose/blocks/#{block.name}\", :locals => options2) rescue str = view . render ( :partial => \"caboose/blocks/#{block.block_type.name}\" , :locals => options2 ) #str = view.render(:partial => \"caboose/blocks/#{block.name}\", :locals => options2) rescue str = view . render ( :partial => \"caboose/blocks/#{block.block_type.field_type}\" , :locals => options2 )", "commit_type": "add"}
{"commit_tokens": ["Allows", "#initials", "if", "name", "is", "a", "single", "letter"], "add_tokens": "@initials ||= remove ( / ( \\( | \\[ ).*( \\) | \\] ) / ) . scan ( / ([[:word:]])[[:word:]]* /i ) . join", "del_tokens": "@initials ||= remove ( / ( \\( | \\[ ).*( \\) | \\] ) / ) . scan ( / ([[:word:]])[[:word:]]+ /i ) . join", "commit_type": "allow"}
{"commit_tokens": ["Change", "how", "the", "base", "module", "is", "included", "to", "prevent", "namespacing", "conflicts"], "add_tokens": "def self . extended ( base ) #:nodoc: base . class_eval do # Tracks which attributes represent enumerations class_inheritable_accessor :enumeration_associations self . enumeration_associations = { } end end extend PluginAWeek :: ActsAsEnumeration :: MacroMethods", "del_tokens": "def self . included ( base ) #:nodoc: base . class_eval do # Tracks which attributes represent enumerations class_inheritable_accessor :enumeration_associations self . enumeration_associations = { } extend PluginAWeek :: ActsAsEnumeration :: MacroMethods end end include PluginAWeek :: ActsAsEnumeration", "commit_type": "change"}
{"commit_tokens": ["Fix", "sprockets", "-", "sass", "support"], "add_tokens": "if defined? ( Sass :: Rails ) or defined? ( Sprockets :: Sass )", "del_tokens": "if defined? ( Sass :: Rails )", "commit_type": "fix"}
{"commit_tokens": ["Make", "raw_response", "and", "attributes", "readers", "not", "accessors"], "add_tokens": "attr_reader :attributes attr_reader :raw_response", "del_tokens": "attr_accessor :attributes attr_accessor :raw_response", "commit_type": "make"}
{"commit_tokens": ["Improve", "assembly", "of", "the", "clone", "description"], "add_tokens": "clone_description << \"\\n\\n\" clone_description << \"*\" * 70 clone_description << \"\\n\\n\" clone_description << comment [ 'text' ]", "del_tokens": "clone_description << \"\\n\\n\" + \"*\" * 70 clone_description << \"\\n\\n\" + comment [ 'text' ]", "commit_type": "improve"}
{"commit_tokens": ["Remove", "code", "duplication", "in", "DSL", "implementation", "."], "add_tokens": "def create_attr_methods ( meth , & block ) self . input_filters . send ( meth , & block ) keys = self . input_filters . send ( \"#{meth}_keys\" ) keys . each do | key | def required ( & block ) create_attr_methods ( :required , & block ) end def optional ( & block ) create_attr_methods ( :optional , & block )", "del_tokens": "def required ( & block ) self . input_filters . required ( & block ) self . input_filters . required_keys . each do | key | def optional ( & block ) self . input_filters . optional ( & block ) self . input_filters . optional_keys . each do | key | define_method ( key ) do @filtered_input [ key ] end define_method ( \"#{key}_present?\" ) do @filtered_input . has_key? ( key ) end define_method ( \"#{key}=\" ) do | v | @filtered_input [ key ] = v end end", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "in", "retrieve_apikey", "(", "wrong", "syntax", "for", "multiple", "parameters", ")"], "add_tokens": "api . call Interface :: Command :: RETRIEVE_APIKEY , \"providerkey=#{providerkey}&token=#{token}\"", "del_tokens": "api . call Interface :: Command :: RETRIEVE_APIKEY , \"providerkey=#{providerkey},token=#{token}\"", "commit_type": "fix"}
{"commit_tokens": ["Create", "shims", "for", "gem", "executables"], "add_tokens": "class BaseShim def initialize ( command ) @command = command exec \"$SELF_DIR/lib/ruby/bin/ruby\" - rbundler / setup #{@command} # @private class Shim < BaseShim def initialize ( dirpath , name ) super ( %(\"$SELF_DIR/#{dirpath}/#{name}\" \"$@\") ) end end # @private class GemShim < BaseShim def initialize ( gem_name , exec_name ) super ( %(-e \"load Gem.bin_path('#{gem_name}', '#{exec_name}')\" -- \"$@\") ) end end", "del_tokens": "class Shim def initialize ( dirpath , name ) @dirpath = dirpath @name = name exec \"$SELF_DIR/lib/ruby/bin/ruby\" - rbundler / setup \"$SELF_DIR/#{@dirpath}/#{@name}\" \"$@\"", "commit_type": "create"}
{"commit_tokens": ["Use", "shared_examples", "in", "the", "test", "to", "raise"], "add_tokens": "subject { Date . new ( 1868 , 9 , 7 ) } include_examples \"1868,9,7\"", "del_tokens": "it { expect { Date . new ( 1868 , 9 , 7 ) . to_era } . to raise_error ( RuntimeError , \"#to_era is expeted later in 1868,9,8\" ) }", "commit_type": "use"}
{"commit_tokens": ["changed", "to", "delete", "files", "after", "upload", "is", "complete"], "add_tokens": "def save self . purge . each do | path | self . storage . destroy ( path ) end", "del_tokens": "def save self . purge . each do | path | self . storage . destroy ( path ) end", "commit_type": "change"}
{"commit_tokens": ["Change", "to", "make", "similar", "to", "other", "api", "calls", "."], "add_tokens": "# The text to align # # @ api private attr_reader :text width_diff = width - display_width ( text ) width_diff = width - display_width ( text ) text_width = display_width ( text ) def display_width ( text )", "del_tokens": "width_diff = width - actual_width ( text ) width_diff = width - actual_width ( text ) text_width = actual_width ( text ) def actual_width ( text ) attr_reader :text", "commit_type": "change"}
{"commit_tokens": ["Remove", "reference", "to", "non", "-", "existant", "variable"], "add_tokens": "ap \"AUTH USERNAME: #{CabooseStore::payscape_username}\" ap \"AUTH PASSWORD: #{CabooseStore::payscape_password}\"", "del_tokens": "ap \"AUTH URL: https://secure.payscapegateway.com/api/query.php?username=#{CabooseStore::payscape_username}&password=#{CabooseStore::payscape_password}&transaction_id=#{order.transaction_id}\"", "commit_type": "remove"}
{"commit_tokens": ["Remove", "flavor", "auto", "-", "creation", "after", "node", "registration"], "add_tokens": "def create_node ( node_parameters ) def create_nodes_from_csv ( csv_file ) node = create_node ( node_parameters ) finished = Fog :: JSON . decode ( response . body ) [ 'finished' ] if finished create_flavor_from_node ( get_node ( node_uuid ) ) end finished", "del_tokens": "def create_node ( node_parameters , create_flavor = false ) create_flavor_from_node ( node ) if create_flavor def create_nodes_from_csv ( csv_file , create_flavor = false ) node = create_node ( node_parameters , create_flavor ) Fog :: JSON . decode ( response . body ) [ 'finished' ]", "commit_type": "remove"}
{"commit_tokens": ["fixed", "before", "filters", "between", "tests"], "add_tokens": "require File . join ( File . dirname ( __FILE__ ) , 'filters' ) # oauth get '/auth_at_provider_test' do auth_at_provider ( :twitter ) end get '/test_login_from_access_token' do if @user = login_from_access_token ( :twitter ) erb \"Success!\" else erb \"Failed!\" end end", "del_tokens": "# --- before filters [ '/test_logout' , '/some_action' , '/test_should_be_logged_in' ] . each do | patt | before patt do require_login end end before '/test_http_basic_auth' do require_login_from_http_basic end # -----", "commit_type": "fix"}
{"commit_tokens": ["Use", "poltergeist", "instead", "of", "selenium", "."], "add_tokens": "expect ( page ) . to have_selector ( \"input[value='#{Setting['base.first_setting']}']\" ) expect ( page ) . to have_selector ( \"input[value='#{Setting['second.second_setting']}']\" )", "del_tokens": "expect ( page ) . to have_selector ( \"input[value='#{Setting['base.first_setting']}'\" ) expect ( page ) . to have_selector ( \"input[value='#{Setting['second.second_setting']}'\" )", "commit_type": "use"}
{"commit_tokens": ["Added", "quick", "start", "template", "tests"], "add_tokens": "require 'ruby-debug' @servers . select { | s | s . nickname =~ / App Server / || s . nickname =~ / PHP App Server / } raise \"No app servers in deployment\" if @servers . count == 0 @servers . select { | s | s . nickname =~ / Front End / || s . nickname =~ / FrontEnd / || s . nickname =~ / Apache with HAproxy / } puts \"getting lb_hostname\" puts \"this is the fe.setting: #{fe.settings['private-dns-name']}\" lb_hostname_input << fe . settings [ 'private-dns-name' ] + \" \"", "del_tokens": "@servers . select { | s | s . nickname =~ / App Server / } @servers . select { | s | s . nickname =~ / Front End / || s . nickname =~ / FrontEnd / } lb_hostname_input << fe . settings [ 'private-dns-name' ] + \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "find", "catalog", "via", "name", "&", "type", "(", "type", "is", "optional", ")", "."], "add_tokens": "find_item ( name , Xml :: MEDIA_TYPE [ :VAPP_TEMPLATE ] ) # Find catalog item from catalog by name and type. # If item_type is set to nil, returns catalog item as long as its name match. # Raises an exception if catalog is not found. # Returns nil if an item matching the name and type is not found. # Otherwise, returns the catalog item. def find_item ( name , item_type = nil ) fail ObjectNotFoundError , \"Catalog item name cannot be nil\" unless name items . each do | item | catalog_item = connection . get ( \"/api/catalogItem/#{item.href_id}\" ) return catalog_item if catalog_item . name == name && ( ! item_type || catalog_item . entity [ \"type\" ] == item_type ) end nil end", "del_tokens": "find_catalog_item ( name , Xml :: MEDIA_TYPE [ :VAPP_TEMPLATE ] ) # Find catalog item from catalog by name and type. # Raises an exception if catalog is not found. # Returns nil if an item matching the name and type is not found. # Otherwise, returns the catalog item. def find_catalog_item ( name , item_type ) raise ObjectNotFoundError , \"Catalog item name cannot be nil\" unless name items . each do | catalog_item_xml_obj | catalog_item = connection . get ( \"/api/catalogItem/#{catalog_item_xml_obj.href_id}\" ) return catalog_item if catalog_item . name == name && catalog_item . entity [ \"type\" ] == item_type end nil end", "commit_type": "add"}
{"commit_tokens": ["remove", "multiple", "spaces", "and", "dashes", "from", "tag"], "add_tokens": "tags = ( tag_string << opts [ :tags ] ) . compact . join ( '/' ) . squeeze ( \" -\" ) . split ( '/' )", "del_tokens": "tags = ( tag_string << opts [ :tags ] ) . compact . join ( '/' ) . split ( '/' )", "commit_type": "remove"}
{"commit_tokens": ["allow", "https", "in", "cloud", "controller", "url"], "add_tokens": "uri = \"http://#{uri}\" unless ( uri . index ( 'http://' ) == 0 || uri . index ( 'https://' ) == 0 )", "del_tokens": "uri = \"http://#{uri}\" if ( uri . index ( 'http://' ) != 0 )", "commit_type": "allow"}
{"commit_tokens": ["removed", "nesting", "limit", "causing", "this", "error", "NestingError", ":", "nesting", "of", "20", "is", "too", "deep"], "add_tokens": "response = JSON :: parse ( response . body , :max_nesting => false )", "del_tokens": "response = JSON :: parse ( response . body )", "commit_type": "remove"}
{"commit_tokens": ["Move", "validation", "to", "separate", "file", "and", "class"], "add_tokens": "require \"isbm/validation\" class << self include Isbm :: Validation end channels = channels unless channels . is_a? ( Array )", "del_tokens": "channels = [ channels ] unless channels . is_a? ( Array )", "commit_type": "move"}
{"commit_tokens": ["Added", "Model#delete", "and", "specs", "."], "add_tokens": "@m_author . should . not . be . nil @m_post . should . not . be . nil o . should . not . be . nil o . should . not . be . nil o . should . be . nil posts . should . not . be . nil posts . should . not . be . nil a . should . not . be . nil a_ . should . not . be . nil a . should . not . be . nil p = @m_post [ 3 ] p . should . not . be . nil successfully_deleted = p . delete successfully_deleted . should . be . true @m_post [ 3 ] . should . be . nil", "del_tokens": "@m_author . should . not . equal nil @m_post . should . not . equal nil o . should . not . equal nil o . should . not . equal nil o . should . equal nil posts . should . not . equal nil posts . should . not . equal nil a . should . not . equal nil a_ . should . not . equal nil a . should . not . equal nil", "commit_type": "add"}
{"commit_tokens": ["Add", "finalizer", "to", "SharedMemory", "."], "add_tokens": "# Memory block shared across processes.", "del_tokens": "# Memory block shared across processes. TODO: finalizer that closes...", "commit_type": "add"}
{"commit_tokens": ["added", "realms", "to", "basic", "auth"], "add_tokens": "Config . module_eval do class << self attr_accessor :controller_to_realm_map # how many failed logins allowed. def merge_http_basic_auth_defaults! @defaults . merge! ( :@controller_to_realm_map => { \"application\" => \"Application\" } ) end end merge_http_basic_auth_defaults! end protected request_http_basic_authentication ( realm_name_by_controller ) and ( session [ :http_authentication_used ] = true ) and return if request . authorization . nil? || session [ :http_authentication_used ] . nil? def realm_name_by_controller current_controller = self . class while current_controller != ActionController :: Base result = Config . controller_to_realm_map [ current_controller . controller_name ] return result if result current_controller = self . class . superclass end nil end", "del_tokens": "request_http_basic_authentication and ( session [ :http_authentication_used ] = true ) and return if request . authorization . nil? || session [ :http_authentication_used ] . nil? protected", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "runner", "to", "handle", "list", "of", "expressiosn"], "add_tokens": "syntax = parser . parse_with_debug ( string ) parts = Parser :: Transform . new . apply ( syntax ) # file is a list of expressions, al but the last must be a function # and the last is wrapped as a main expr = part . compile ( program . context ) program . add_function expr", "del_tokens": "parts = string . split \"SPLIT\" syntax = parser . parse_with_debug ( part ) funct = Parser :: Transform . new . apply ( syntax ) expr = funct . compile ( program . context )", "commit_type": "fix"}
{"commit_tokens": ["Add", "alias", "for", "define", "."], "add_tokens": "alias_method :new , :define", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "text", "value", "to", "a", "options", "sting", "to", "be", "hashed", "that", "will", "be", "produce", "filename", ".", "Added", "mp3", "extension", "to", "generated", "files", "."], "add_tokens": "filename = Digest :: SHA1 . hexdigest ( textrm + options . to_s + \".mp3\" )", "del_tokens": "filename = Digest :: SHA1 . hexdigest ( options . to_s )", "commit_type": "add"}
{"commit_tokens": ["added", "dicom", "information", "arrays", "to", "attr_reader"], "add_tokens": "attr_reader :read_success , :write_success , :modality , :names , :labels , :types , :lengths , :values , :raw , :levels # in an invalid position, and as such, this method will also return false:", "del_tokens": "attr_reader :read_success , :write_success , :modality # in an invalid position, and as such, this method should also return false:", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "@failed", "list", "of", "URLs", "."], "add_tokens": "# List of unreachable URLs attr_reader :failed @failed = [ ] begin response = sess . get ( path , headers ) rescue = > e @failed << url end new_page = Page . new ( url , response )", "del_tokens": "new_page = Page . new ( url , sess . get ( path , headers ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "underline", "headers"], "add_tokens": "level = node . name . match ( / \\A h( \\d ) \\Z / ) [ 1 ] . to_i if @options [ :underline_headers ] && level < 3 content = parse_content ( node ) output << content + \"\\n\" character = level == 1 ? '=' : '-' content . length . times { output << character } else hashes = '' level . times { hashes << '#' } output << \"#{hashes} #{parse_content(node)}\" end", "del_tokens": "hashes = '' node . name . match ( / \\A h( \\d ) \\Z / ) [ 1 ] . to_i . times { hashes << '#' } output << \"#{hashes} #{parse_content(node)}\\n\\n\"", "commit_type": "add"}
{"commit_tokens": ["added", "single", "file", "to", "require"], "add_tokens": "require 'lib/amberbit-config'", "del_tokens": "require 'yaml' require 'lib/hash_struct' require 'lib/amber_bit_app_config.rb'", "commit_type": "add"}
{"commit_tokens": ["Add", "proper", "test", "cases", "to", "test", "all", "the", "features"], "add_tokens": "require 'settings_on_rails' RSpec . configure do | config | config . order = :random end", "del_tokens": "require 'settings_on_rails'", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", ":", "name", "=", ">", ":", "mount_under", "option", "for", "the", "Thin", "--", "prefix", "option", "."], "add_tokens": "long_option :flag => '--prefix'", "del_tokens": "long_option :flag => '--prefix' , :name => :mount_under", "commit_type": "remove"}
{"commit_tokens": ["removed", "some", "excessive", "debug", "log", "statements", ";", "corrected", "a", "few", "debug", "log", "statements", "that", "should", "of", "been", "info", "log", "statements"], "add_tokens": "log ( :info ) { \"console(#{console_command.inspect})\" } log ( :info ) { \"exec(#{command.inspect}, #{options.inspect})\" }", "del_tokens": "log ( :debug ) { \"console\" } log ( :debug ) { \"exec(#{command.inspect}, #{options.inspect})\" } log ( :debug ) { \"ssh(#{@ssh.inspect})\" } log ( :debug ) { \"sftp(#{@sftp.inspect})\" } log ( :debug ) { \"sftp(#{@sftp.inspect})\" }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "rubocop", "problems", "with", "the", "build", "."], "add_tokens": "@client . authorization . expiry = 3600 # 3600s is the max allowed value", "del_tokens": "@client . authorization . expiry = 3600 # 3600s is the max allowed value", "commit_type": "fix"}
{"commit_tokens": ["Add", ":", "find_attribute", "option", "to", "Authorizer"], "add_tokens": "field ||= options . fetch ( :find_attribute , :id )", "del_tokens": "field ||= :id", "commit_type": "add"}
{"commit_tokens": ["Add", "check", "for", "empty", "dictionary", "when", "generating", "sentences"], "add_tokens": "# @private class EmptyDictionaryError < Exception # :nodoc: end if @dictionary . dictionary . empty? raise EmptyDictionaryError . new ( \"The dictionary is empty! Parse a source file/string!\" ) end def generate_sentence ( sentencecount ) if @dictionary . dictionary . empty? raise EmptyDictionaryError . new ( \"The dictionary is empty! Parse a source file/string!\" ) end", "del_tokens": "def generate_sentence ( sentencecount )", "commit_type": "add"}
{"commit_tokens": ["Remove", "warning", "while", "looking", "up", "project_id"], "add_tokens": "# Finds project_id from gcloud CLI configuration nil", "del_tokens": "warn 'Unable to determine project id.'", "commit_type": "remove"}
{"commit_tokens": ["added", "ability", "to", "read", "chunks", "at", "a", "time", "within", "codeblock"], "add_tokens": "readchunks ( remotepath ) { | chunk | dest . write chunk # yeild chunksize of path one chunk at a time def readchunks ( path , chunksize = 1048576 ) open ( path ) { | source | size = source . length index = 0 while index < size yield source . read ( index , chunksize ) index += chunksize end } end", "del_tokens": "open ( remotepath ) { | source | size = source . length index = 0 while index < size dest . write ( source . read ( index , 1048576 ) ) index += 1048576 end", "commit_type": "add"}
{"commit_tokens": ["added", "ability", "to", "define", "custom", "validate", "method", "in", "commands"], "add_tokens": "new ( * args ) . validate_all vo = validate_all return vo if has_errors? def validate_all validate def validate # Meant to be overridden end", "del_tokens": "new ( * args ) . validate return validation_outcome if has_errors? def validate", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "sanitize", "tag", "attributes", "text", "values"], "add_tokens": "t_attrs = attrs . map { | k , v | v . nil? ? \" #{k}\" : \" #{k}=\\\"#{h(v)}\\\"\" }", "del_tokens": "t_attrs = attrs . map { | k , v | v . nil? ? \" #{k}\" : \" #{k}=\\\"#{(v)}\\\"\" }", "commit_type": "fix"}
{"commit_tokens": ["add", "links", "to", "examples", "&", "check", "for", "Procfile"], "add_tokens": "if File . exists? \"Procfile\" append_file \"Procfile\" , \"webpack: ./node_modules/.bin/webpack-dev-server --config config/webpack.config.js\" else copy_file \"Procfile\" , \"Procfile\" end", "del_tokens": "copy_file \"Procfile\" , \"Procfile\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "test", "for", "using", "Typhoeus"], "add_tokens": "@url = \"https://www.google.com/recaptcha/api/siteverify\" @url = nil Typhoeus . expects ( :post ) . with ( @url , body : @body ) . returns ( response ) Typhoeus . expects ( :post ) . with ( @url , body : @body ) . returns ( response )", "del_tokens": "@uri = URI ( \"https://www.google.com/recaptcha/api/siteverify\" ) @uri = nil Net :: HTTP . expects ( :post_form ) . with ( @uri , @body ) . returns ( response ) Net :: HTTP . expects ( :post_form ) . with ( @uri , @body ) . returns ( response )", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "making", "any", "class", "a", "Hoptoad", "catcher", "not", "just", "ActionController", "::", "Base", "."], "add_tokens": "if base . instance_methods . include? 'rescue_action_in_public' and ! base . instance_methods . include? 'rescue_action_in_public_without_hoptoad' base . alias_method_chain :rescue_action_in_public , :hoptoad end", "del_tokens": "return if base . instance_methods . include? 'rescue_action_in_public_without_hoptoad' base . alias_method_chain :rescue_action_in_public , :hoptoad", "commit_type": "add"}
{"commit_tokens": ["fix", "block", "initialization", "style", "by", "adding", "init", "methods"], "add_tokens": "puts \"Invalid #{arg1.inspect}\" raise Asm :: AssemblyError . new ( Asm :: ERRSTR_INVALID_ARG , arg1 . inspect )", "del_tokens": "raise Asm :: AssemblyError . new ( Asm :: ERRSTR_INVALID_ARG , arg1 )", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "pathnames", "to", "the", "db", "and", "logfile"], "add_tokens": "database_path : '/var/tmp/db/foreman_hooks-host_rename.db' , log_path : '/var/tmp/foreman_hooks-host_rename.log' ,", "del_tokens": "database_path : prefix + '/db/foreman_hook_rename.db' , log_path : '/var/tmp/foreman_hook_rename.log' ,", "commit_type": "fix"}
{"commit_tokens": ["updated", "link", "spec", "added", "LinkRelation", "which", "was", "removed", "meanwhile"], "add_tokens": "link = Halibut :: HAL :: Link . new tmpl_uri , templated : true link1 = Halibut :: HAL :: Link . new normal_uri , { link2 = Halibut :: HAL :: Link . new normal_uri , {", "del_tokens": "link = Halibut :: HAL :: Link . new tmpl_uri , true link1 = Halibut :: HAL :: Link . new normal_uri , false , { link2 = Halibut :: HAL :: Link . new normal_uri , false , {", "commit_type": "update"}
{"commit_tokens": ["Added", "class", "analyzer", "basis", "find", "class", "token", "in", "sexp", "and", "extract", "its", "first", "line"], "add_tokens": "def test_file_path ( file_name ) File . join ( File . dirname ( __FILE__ ) , \"test_classes/#{file_name}.rb\" ) end def read_test_file ( file_name ) test_file_path ( file_name )", "del_tokens": "def read_test_file file_name File . join ( File . dirname ( __FILE__ ) , \"test_classes/#{file_name}.rb\" )", "commit_type": "add"}
{"commit_tokens": ["added", "year", "to", "fix", "failing", "tests"], "add_tokens": "time = Time . parse ( 'Sat Jan 01 2011 00:00:00 -0800' )", "del_tokens": "time = Time . parse ( 'Sat Jan 01 00:00:00 -0800' )", "commit_type": "add"}
{"commit_tokens": ["Use", "lambdas", "for", "model", "scopes"], "add_tokens": "scope :active , -> { where ( active : true ) } scope :inactive , -> { where ( active : false ) }", "del_tokens": "scope :active , where ( active : true ) scope :inactive , where ( active : false )", "commit_type": "use"}
{"commit_tokens": ["Added", "missing", "test", "case", "for", "poorly", "defined", "initialize", "methods"], "add_tokens": "raise \"User-defined initialize method defined with #{arg_count} parameters; must either be 0, other wise 1 or -1 (varargs) to receive the component map.\"", "del_tokens": "raise \"User-defined initialize method defined with #{arg_count} paramters; must either be 0, other wise 1 or -1 (varargs) to receive the component map.\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "spec", "that", "broke", "with", "RM", "s", "block", "variable", "changes"], "add_tokens": "@exit_action_called = false @exit_action_called = true @exit_action_called . should == false @exit_action_called . should == true @entry_action_called = false @entry_action_called = true @entry_action_called . should == false @entry_action_called . should == true", "del_tokens": "exit_action_called = false exit_action_called = true exit_action_called . should == false exit_action_called . should == true entry_action_called = false entry_action_called = true entry_action_called . should == false entry_action_called . should == true", "commit_type": "fix"}
{"commit_tokens": ["Add", "travis", "-", "ci", "build", "status", "bump", "version", "."], "add_tokens": "VERSION = \"0.1.0\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "typos", "improving", "readme", "a", "little", "updating", "todo", "."], "add_tokens": "# exists than the component will be rendered, otherwise will be skipped.", "del_tokens": "# exists then the component will be rendered, otherwise will be skipped.", "commit_type": "fix"}
{"commit_tokens": ["Add", "documentation", "and", "rename", "column", "to", "column_name"], "add_tokens": "# Returns the name of settings column for that instance def self . column_name ( instance ) # Check for the validity of the settings column # Returns the column name if valid settings_column_name = column_name ( instance ) raise NoSettingsColumnError unless settings_column_name raise ColumnNotExistError unless instance . has_attribute? ( settings_column_name ) raise InvalidColumnTypeError if column_type_not_text? ( instance , settings_column_name ) settings_column_name", "del_tokens": "def self . column ( instance ) settings_column = column ( instance ) raise NoSettingsColumnError unless settings_column raise ColumnNotExistError unless instance . has_attribute? ( settings_column ) raise InvalidColumnTypeError if column_type_not_text? ( instance , settings_column ) settings_column", "commit_type": "add"}
{"commit_tokens": ["fixed", "file", "upload", "to", "allow", "custom", "name"], "add_tokens": "def upload_file ( path_to_file , parent , name : nil , content_created_at : nil , content_modified_at : nil , filename = name ? name : File . basename ( path_to_file ) preflight_check ( path_to_file , filename , parent_id ) if preflight_check attributes = { name : filename , parent : { id : parent_id } } body = { attributes : Oj . dump ( attributes ) , file : file } file_info , response = post ( FILES_UPLOAD_URI , body , process_body : false , content_md5 : content_md5 ) def preflight_check ( path_to_file , filename , parent_id ) attributes = { name : filename , parent : { id : \"#{parent_id}\" } , size : size } attributes = { size : size }", "del_tokens": "def upload_file ( path_to_file , parent , content_created_at : nil , content_modified_at : nil , preflight_check ( path_to_file , parent_id ) if preflight_check attributes = { filename : file , parent_id : parent_id } file_info , response = post ( FILES_UPLOAD_URI , attributes , process_body : false , content_md5 : content_md5 ) def preflight_check ( path_to_file , parent_id ) filename = File . basename ( path_to_file ) attributes = { \"name\" => filename , \"parent\" => { \"id\" => \"#{parent_id}\" } , \"size\" => size } attributes = { \"size\" => size }", "commit_type": "fix"}
{"commit_tokens": ["Add", "optional", "steps", "via", "required", ":", "false", "option", "to", "setup"], "add_tokens": "@options = options . reverse_merge required : true run if run_step? def run_step? return true if options [ :required ] choice \"This step is optional, would you like to perform it?\" end", "del_tokens": "@options = options run", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "button", "elements", "in", "forms", "and", "selecting"], "add_tokens": "def matches_text? ( text ) @element . innerHTML =~ / #{ Regexp . escape ( text . to_s ) } /i end @element [ \"value\" ] =~ / ^ \\W * #{ Regexp . escape ( value . to_s ) } /i || matches_text? ( value )", "del_tokens": "@element [ \"value\" ] =~ / ^ \\W * #{ Regexp . escape ( value . to_s ) } /i", "commit_type": "add"}
{"commit_tokens": ["fix", "placement", "of", "dereference", "when", "building", "serialization"], "add_tokens": "value = schema . dereference ( value ) if value . has_key? ( 'properties' ) else serialization [ key ] = value [ 'example' ]", "del_tokens": "unless value . has_key? ( 'properties' ) serialization [ key ] = schema . dereference ( value ) [ 'example' ] else", "commit_type": "fix"}
{"commit_tokens": ["make", "configure", "option", "on", "startup", "work"], "add_tokens": "@configure = config [ \"configure\" ]", "del_tokens": "@configure = false", "commit_type": "make"}
{"commit_tokens": ["Create", "Subscription", "with", "deadline", "and", "endpoint"], "add_tokens": "def create_subscription topic , subscription_name = nil , options = { } data = subscription_data topic , options def subscription_data topic , options = { } deadline = options [ :deadline ] endpoint = options [ :endpoint ] attributes = options [ :attributes ] . to_h data = { topic : topic } data [ :ackDeadlineSeconds ] = deadline if deadline data [ :pushConfig ] = { pushEndpoint : endpoint , attributes : attributes }", "del_tokens": "def create_subscription topic , subscription_name = nil , deadline = nil , endpoint = nil data = subscription_data topic , deadline , endpoint def subscription_data topic , deadline = nil , endpoint = nil , attributes = { } data = { \"topic\" => topic } data [ \"ackDeadlineSeconds\" ] = deadline if deadline data [ \"pushConfig\" ] = { \"pushEndpoint\" => endpoint , \"attributes\" => attributes }", "commit_type": "create"}
{"commit_tokens": ["Make", "the", "content_for", "to", "very", "simple", "."], "add_tokens": "def initialize ( config , type , name , options = { } )", "del_tokens": "attr_reader :content_for_name def initialize ( config , type , content_for_name , options = { } ) @options = options @content_for_name = content_for_name name = @options [ :attribute_name ] ? @options [ :attribute_name ] : content_for_name def wrapper? return true unless @options . key? :wrapper ! ! @options [ :wrapper ] end", "commit_type": "make"}
{"commit_tokens": ["Move", "all", "errors", "in", "to", "a", "single", "file"], "add_tokens": "require 'hexp/errors'", "del_tokens": "require 'hexp/format_error.rb' require 'hexp/illegal_request_error.rb'", "commit_type": "move"}
{"commit_tokens": ["Change", "to", "use", "native", "win", "api", "before", "io", "-", "console", "due", "to", "stale", "values", "when", "resizing", "termainal", "window"], "add_tokens": "size ||= from_ioctl size ||= from_io_console", "del_tokens": "size ||= from_io_console size ||= from_ioctl", "commit_type": "change"}
{"commit_tokens": ["Allow", "logout", ".", "Handle", "responses", "from", "web", "service", "."], "add_tokens": "@session = nil begin handle_response ( response ) { | r | @session = r . session } rescue Jiralicious :: AuthenticationError raise Jiralicious :: InvalidLogin end end def logout return unless @session response = @faraday_connection . delete do | req | req . path = @session_path req . headers = req . headers . merge ( { :\" set-cookie \" => session_cookie } ) end handle_response ( response ) @session = nil end def logged_in? ! @session . nil? end private def handle_response ( response , & block ) case response . status when 200 then body = response . body if body =~ / \\w + / body = Hashie :: Mash . new ( JSON . parse ( response . body ) ) end yield body if block_given? when 401 then raise Jiralicious :: AuthenticationError raise Jiralicious :: JiraError end def session_cookie \"#{@session.name}=#{@session.value}\"", "del_tokens": "def logged_in? ! @session . nil? end if response . status == 200 login_json = Hashie :: Mash . new ( JSON . parse ( response . body ) ) @session = login_json . session @session = nil raise Jiralicious :: InvalidLogin unless @session", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "check", "in", "extract_medialib_info", "for", "an", "absent", "info", "response"], "add_tokens": "if ! infos . nil? fields = fields . map! { | f | f . to_sym } fields . each do | field | values = infos [ field ] if not values . nil? my_value = values . first [ 1 ] # actual value from the top source [0] if field == :url my_value = Xmms :: decode_xmms2_url ( my_value ) end res [ field ] = my_value . to_s . force_encoding ( \"utf-8\" )", "del_tokens": "fields = fields . map! { | f | f . to_sym } fields . each do | field | values = infos [ field ] if not values . nil? my_value = values . first [ 1 ] # actual value from the top source [0] if field == :url my_value = Xmms :: decode_xmms2_url ( my_value ) res [ field ] = my_value . to_s . force_encoding ( \"utf-8\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "endpoints", "documentation", "for", "#data_by_time_range"], "add_tokens": "# /foods/log/water # /sleep/startTime # /sleep/timeInBed # /sleep/minutesAwake # /sleep/minutesToFallAsleep # /sleep/minutesAfterWakeup # /sleep/efficiency", "del_tokens": "# /sleep/minutesAwake # /sleep/timeInBed", "commit_type": "add"}
{"commit_tokens": ["Fixing", "gem", "file", "order", "problem"], "add_tokens": "require 'bluepotion' insert_point = app . files . find_index { | file | file =~ / ^(?: \\. \\/ )?app \\/ / } || 0 Dir . glob ( File . join ( lib_dir_path , \"project/**/*.rb\" ) ) . reverse . each do | file | app . files . insert ( insert_point , file ) end", "del_tokens": "app . files . unshift ( Dir . glob ( File . join ( lib_dir_path , \"project/**/*.rb\" ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "comment", "about", "kicking", "lazy", "queries"], "add_tokens": "input . inspect # forces evaluation of a lazy query from AR", "del_tokens": "input . inspect", "commit_type": "add"}
{"commit_tokens": ["created", "a", "cleaner", "wrapper", "for", "the", "regular", "heart", "rate", "series", "API"], "add_tokens": "400 => lambda { raise FitgemOauth2 :: BadRequestError } , 401 => lambda { raise FitgemOauth2 :: UnauthorizedError } , 403 => lambda { raise FitgemOauth2 :: ForbiddenError } , 404 => lambda { raise FitgemOauth2 :: NotFoundError } ,", "del_tokens": "400 => lambda { raise FitgemOauth2 :: BadRequestError , JSON . parse ( response . body ) } , 401 => lambda { raise FitgemOauth2 :: UnauthorizedError , JSON . parse ( response . body ) } , 403 => lambda { raise FitgemOauth2 :: ForbiddenError , JSON . parse ( response . body ) } , 404 => lambda { raise FitgemOauth2 :: NotFoundError , JSON . parse ( response . body ) } ,", "commit_type": "create"}
{"commit_tokens": ["Added", "several", "little", "convenience", "aliases", "to", "DatabaseHandle", "and", "Model"], "add_tokens": "posts = @m_post . s ( no_posts = @m_post . s ( \"SELECT * FROM posts WHERE FALSE\" ) post = @m_post . s1 ( no_post = @m_post . s1 ( \"SELECT * FROM posts WHERE FALSE\" )", "del_tokens": "posts = @m_post . select_all ( no_posts = @m_post . select_all ( \"SELECT * FROM posts WHERE FALSE\" ) post = @m_post . select_one ( no_post = @m_post . select_one ( \"SELECT * FROM posts WHERE FALSE\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "using", "a", "git", "branch", "when", "checking", "out", "a", "cookbook", "repository", "."], "add_tokens": "case repo . protocol res = ` #{ ssh_cmd } git clone --quiet --depth 1 #{ repo . url } #{ cookbook_dir } 2>&1 ` success = $? == 0 if repo . tag && success Dir . chdir ( cookbook_dir ) do res += ` #{ ssh_cmd } git fetch --tags 2>&1 ` is_tag = ` git tag ` . split ( \"\\n\" ) . include? ( repo . tag ) is_branch = ` #{ ssh_cmd } git branch -r ` . split ( \"\\n\" ) . map { | t | t . strip } . include? ( \"origin/#{repo.tag}\" ) if is_tag && is_branch res = 'Repository tag ambiguous: could be git tag or git branch' success = false elsif is_branch res += ` #{ ssh_cmd } git branch #{ repo . tag } origin/ #{ repo . tag } 2>&1 ` success = $? == 0 end if success res += ` git checkout #{ repo . tag } 2>&1 ` success = $? == 0 end end end svn_cmd = \"svn export #{repo.url} #{cookbook_dir} --non-interactive\" + res = ` #{ svn_cmd } ` success = $? == 0", "del_tokens": "cmd = case repo . protocol \"#{ssh_cmd} git clone --quiet --depth 1 #{repo.url} #{cookbook_dir} 2>&1\" + ( repo . tag ? \" && cd #{cookbook_dir} && #{ssh_cmd} git pull 2>&1 && git checkout #{repo.tag} 2>&1 && cd -\" : '' ) \"svn export #{repo.url} #{cookbook_dir} --non-interactive\" + res = ` #{ cmd } ` success = $? == 0", "commit_type": "add"}
{"commit_tokens": ["move", "capture", "validation", "logic", "to", "method"], "add_tokens": "translate ( :capture , :variable , :named_splat ) { t . check_name ( name ) } # @raises [Mustermann::CompileError] if name is not acceptable # @!visibility private def check_name ( name ) raise CompileError , \"can't use the same capture name twice\" if names . include? name names << name", "del_tokens": "translate ( :capture , :variable , :named_splat ) do raise CompileError , \"can't use the same capture name twice\" if t . names . include? name t . names << name", "commit_type": "move"}
{"commit_tokens": ["added", "notes", "to", "education", "resource"], "add_tokens": "%w[ id school_name degree field_of_study activities notes ] . each do | f |", "del_tokens": "%w[ id school_name degree field_of_study activities ] . each do | f |", "commit_type": "add"}
{"commit_tokens": ["add", "template", "spec", "and", "fix", "code", "typo"], "add_tokens": "\"#{@path}/#{@filename}\\n\"", "del_tokens": "\"#{@path/@filename}\\n\"", "commit_type": "add"}
{"commit_tokens": ["move", "encoding", "and", "decoding", "to", "own", "modules"], "add_tokens": "require \"secret_sharing/encoder\" require \"secret_sharing/decoder\" Encoder . encode ( secret_string , share_threshold , num_shares ) Decoder . decode ( shares )", "del_tokens": "encoder = Charset . new ( secret_string ) secret_int = encoder . s_to_i ( secret_string ) points = Point . points_from_secret ( secret_int , share_threshold , num_shares ) shares = [ ] points . each do | point | shares << encoder . to_s + '-' + point . to_share end shares points = [ ] shares . each do | share | points << Point . from_share ( share ) end secret_int = Point . to_secret_int ( points ) number_of_dashes = 0 charset = \"\" shares . first . split ( / / ) . reverse . each do | char | if number_of_dashes >= 2 charset . prepend ( char ) end number_of_dashes += 1 if char == '-' end secret_string = Charset . new ( charset ) . i_to_s ( secret_int )", "commit_type": "move"}
{"commit_tokens": ["fixes", "Versionfile", ".", "fixed", "images", "attachment", "."], "add_tokens": ":url => \"/spree/banner/:id/:style_:basename.:extension\" , :path => \":rails_root/public/spree/banner/:id/:style_:basename.:extension\" ,", "del_tokens": ":url => \"/assets/banner/:id/:style_:basename.:extension\" , :path => \":rails_root/public/assets/banner/:id/:style_:basename.:extension\" ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "MBeanProxy", "have", "invoke", "for", "cases", "when", "operation", "already", "exists", "(", "e", ".", "g", ".", "bean", ".", "invoke", "(", ":", "initialize", "1", "))", ".", "Separate", "classes", "into", "their", "own", "files", "a", "bit", "more"], "add_tokens": "require 'jmx/object_name' name = ObjectName . make object_name name = ObjectName . make object_name object_name = name . nil? ? nil : ObjectName . make ( name ) @server . unregisterMBean ( ObjectName . make ( object_name ) ) name = ObjectName . make ( object_name )", "del_tokens": "name = make_object_name object_name name = make_object_name object_name object_name = name . nil? ? nil : make_object_name ( name ) name = make_object_name object_name @server . unregisterMBean ( name ) name = make_object_name object_name private def make_object_name ( object_name ) return object_name if object_name . kind_of? ObjectName ObjectName . new object_name rescue Exception raise ArgumentError . new ( \"Invalid ObjectName #{$!.message}\" ) end", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "configurable", "resolve_before_precompile", "option", "for", "BowerRails"], "add_tokens": "require 'bower-rails/dsl' class << self # If set to true then rake bower:install && rake bower:resolve tasks # are invoked before assets precompilation attr_accessor :resolve_before_precompile def configure & block yield self if block_given? end end # Set default values for options @resolve_before_precompile = false", "del_tokens": "require \"bower-rails/dsl\"", "commit_type": "add"}
{"commit_tokens": ["added", "expression", "equality", "pattern", "-", "matching"], "add_tokens": "case n when Atomo :: AST :: Primitive if n . value == :self Atomo :: Patterns :: Quote . new ( Atomo :: AST :: Primitive . new ( :self ) ) else n end else Atomo :: Patterns . from_node ( n ) end", "del_tokens": "Atomo :: Patterns . from_node ( n )", "commit_type": "add"}
{"commit_tokens": ["create", "a", "check", "from", "a", "Results", "wrapper", "so", "we", "don", "t", "conflict", "with", "the", "dm", "models"], "add_tokens": "# FIXME: maybe wrap Result as Job now that Check is reserved? check = Result . new ( YAML :: load ( job . body ) )", "del_tokens": "check = Check . new ( YAML :: load ( job . body ) )", "commit_type": "create"}
{"commit_tokens": ["Add", "test", "cases", "for", "repo", "commits", "as", "well", ".", "Travis", "git", "commit", "is", "not", "working", "."], "add_tokens": "post_file = params [ :splat ] . first full_path = post_path ( post_file ) repo . remove ( [ full_path ] ) data = repo . commit_index \"Deleted #{post_file}\" redirect \"/\" filename = create_new_post ( params ) log_message = \"Created #{filename}\" log_message = \"Changed #{filename}\" data = repo . commit_index log_message", "del_tokens": "filename = params [ :splat ] . first full_file = File . join ( jekyll_site . source , * %w[ _posts ] , filename ) repo . remove ( [ full_file ] ) data = repo . commit_index \"Deleted #{filename}\" redirect '/' filename = create_new_post ( params ) data = repo . commit_index \"Changed #{filename}\"", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "on", "custom", "type"], "add_tokens": "'passage of time'", "del_tokens": "'passage of time' , 'document'", "commit_type": "update"}
{"commit_tokens": ["Add", "flatten", "option", "to", "fill_form", "with", "tests", "updates", "README"], "add_tokens": "def fill_form ( template , destination , data = { } , options = { } ) command += \" flatten\" if options [ :flatten ]", "del_tokens": "def fill_form ( template , destination , data = { } )", "commit_type": "add"}
{"commit_tokens": ["Use", "relative", "path", "in", "append_view_path"], "add_tokens": "self . append_view_path \"#{File.dirname(__FILE__)}/../views\"", "del_tokens": "self . append_view_path \"views\"", "commit_type": "use"}
{"commit_tokens": ["added", "SSL", "cert", "support", "updated", "docs", "bumped", "the", "version"], "add_tokens": "def verify_ssl = ( verify ) @connection . verify_ssl = verify", "del_tokens": "def verify_peer = ( verify ) @connection . verify_peer = verify", "commit_type": "add"}
{"commit_tokens": ["updated", "google", "data", "file", "and", "bumped", "version"], "add_tokens": "VERSION = \"0.1.1\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "update"}
{"commit_tokens": ["added", "auto", "-", "registration", "of", "user", "class", "in", "controller", "config"], "add_tokens": ":: Sorcery :: Controller :: Config . user_class = self before_save :encrypt_password , :if => Proc . new { | record | record . send ( sorcery_config . password_attribute_name ) . present? } after_save :clear_virtual_password , :if => Proc . new { | record | record . valid? && record . send ( sorcery_config . password_attribute_name ) . present? } # creates new salt and saves it. # encrypts password with salt and save it. # calls the requested email method on the configured mailer # supports both the ActionMailer 3 way of calling, and the plain old Ruby object way. # Random code, used for salt and temporary tokens. salt = user . send ( @sorcery_config . salt_attribute_name ) if user && ! @sorcery_config . salt_attribute_name . nil? # This is used to prevent non-active users to login, for example.", "del_tokens": "before_save :encrypt_password , :if => Proc . new { | record | record . send ( sorcery_config . password_attribute_name ) . present? } after_save :clear_virtual_password , :if => Proc . new { | record | record . valid? && record . send ( sorcery_config . password_attribute_name ) } if user salt = user . send ( @sorcery_config . salt_attribute_name ) if ! @sorcery_config . salt_attribute_name . nil? end", "commit_type": "add"}
{"commit_tokens": ["Allow", "ERB", "in", "YAML", "files"], "add_tokens": "@config = Framework :: Config . new ( YAML . load ( erb ( CONFIG_PATH ) . result ) [ env ] ) @database_config = YAML . load ( erb ( 'config/databases.yml' ) . result ) end # @param [String] path def erb ( path ) ERB . new ( File . read ( root . join ( path ) ) )", "del_tokens": "@config = Framework :: Config . new ( YAML . load_file ( root . join ( CONFIG_PATH ) ) [ env ] ) @database_config = YAML . load_file ( root . join ( 'config/databases.yml' ) )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "some", "outputs", "for", "used", "during", "testing"], "add_tokens": "File . delete ( sqlite_connection . database ) if File . exists? ( sqlite_connection . database )", "del_tokens": "puts \">\\n\\n>>sqlite_connection.database: #{sqlite_connection.database} :: Exists? #{File.exists?(sqlite_connection.database)}\" puts ( \"DELETING>>>>\" ) && File . delete ( sqlite_connection . database ) if File . exists? ( sqlite_connection . database )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "default", "platform", "handling", ":", "there", "is", "no", "default", "platform", "anymore", "."], "add_tokens": "@platform = ENV [ 'TOOLCHAIN_ENV' ] . nil? ? '' : ENV [ 'TOOLCHAIN_ENV' ]", "del_tokens": "@platform = ENV [ 'TOOLCHAIN_ENV' ] . nil? ? RakeOE :: DEFAULT_PLATFORM : ENV [ 'TOOLCHAIN_ENV' ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "duration", "method", "to", "Event", "."], "add_tokens": "duration == 24 * 60 * 60 # Exactly one day end # Duration in seconds def duration Time . parse ( end_time ) - Time . parse ( start_time )", "del_tokens": "( Time . parse ( end_time ) - Time . parse ( start_time ) ) == 24 * 60 * 60 # Exactly one day", "commit_type": "add"}
{"commit_tokens": ["added", "documentation", "for", "the", "empty", "assertion"], "add_tokens": "# Asserts the result is empty # asserts(\"a string\") { \"\" }.empty # asserts(\"an array\") { [] }.empty # asserts(\"a hash\") { Hash.new }.empty", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "specs", ":", "use", "Minitest", "and", "relocate", "into", "filterrific", "namespace"], "add_tokens": "ENV [ \"RAILS_ENV\" ] = \"test\" require 'minitest/autorun' require 'rails' require 'filterrific' #MiniTest::Unit.autorun", "del_tokens": "require 'rubygems' RSpec . configure do | config | # Nothing to do end", "commit_type": "update"}
{"commit_tokens": ["Fixed", "the", "way", "on_reply", "was", "checked"], "add_tokens": "unless @on_reply . nil?", "del_tokens": "unless on_reply . nil?", "commit_type": "fix"}
{"commit_tokens": ["Change", "fetch_multi", "to", "use", "write_multi"], "add_tokens": "results = read_multi ( * keys ) extracted = extract_options! ( keys ) missing = { } missing [ key ] = value write_multi ( missing , extracted ) if missing . any? results", "del_tokens": "results = read_multi ( * keys ) options = merged_options ( extract_options! ( keys ) ) write_entity ( key , value , store , options ) results", "commit_type": "change"}
{"commit_tokens": ["Use", "human", "-", "readable", "error", "messages"], "add_tokens": "if size && max_size && size > max_size raise Down :: TooLarge , \"file is too large (max is #{max_size/1024/1024}MB)\" end if max_size && current_size > max_size raise Down :: TooLarge , \"file is too large (max is #{max_size/1024/1024}MB)\" end raise Down :: NotFound , \"file not found\"", "del_tokens": "raise Down :: TooLarge if size && max_size && size > max_size raise Down :: TooLarge if max_size && current_size > max_size raise Down :: NotFound , \"#{error.class}: #{error.message}\"", "commit_type": "use"}
{"commit_tokens": ["Fix", "name", "error", "for", "order", "not", "found"], "add_tokens": "when 106 then NotFound", "del_tokens": "when 106 then OrderNotFound", "commit_type": "fix"}
{"commit_tokens": ["allow", "nil", "false", "or", "empty", "string", "as", ":", "filetype", "meaning", "<no", "extension", ">"], "add_tokens": "def options ; @options ||= { :filetype => :jpg } end extension = ( ext = url_options . delete ( :filetype ) and ext != '' ) ? \".#{ext || 'jpg'}\" : ''", "del_tokens": "def options ; @options ||= { } end extension = url_options [ :filetype ] == false ? '' : \".#{url_options.delete(:filetype) || 'jpg'}\"", "commit_type": "allow"}
{"commit_tokens": ["Move", "version", "into", "Opster", "::", "VERSION", "."], "add_tokens": "VERSION = '0.1.0'", "del_tokens": "module Version MAJOR = 0 MINOR = 1 PATCH = 0 BUILD = nil STRING = [ MAJOR , MINOR , PATCH , BUILD ] . compact . join '.' end", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "page", "without", "host", "class", "to", "host", "class", "without", "attribute_names", "method"], "add_tokens": "set_type_name ( base ) get_attribute_names def self . set_type_name ( base ) @base_name = base . to_s . gsub ( 'Page' , '' ) @type = @base_name . underscore end def self . get_attribute_names begin @host_class = @base_name . constantize @attributes = @host_class . attribute_names . clone @attributes . delete ( 'id' ) # id is a special case attribute rescue NameError @attributes = [ ] end end", "del_tokens": "@base_name = base . to_s . gsub ( 'Page' , '' ) @type = @base_name . underscore @host_class = @base_name . constantize @attributes = @host_class . attribute_names . clone @attributes . delete ( 'id' ) # id is a special case attribute", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "simple", "lotus", "console", "command"], "add_tokens": "module MiniTest class Spec class << self alias_method :context , :describe end end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Change", "#pad", "to", "account", "for", "line", "endings"], "add_tokens": "SPACE = \" \" . freeze LINE_BREAK = %r{ \\r \\n | \\r | \\n } . freeze def pad ( text , padding , fill : SPACE , separator : nil ) sep = separator || text [ LINE_BREAK ] || NEWLINE line_width = max_line_length ( text , sep ) text_copy . split ( sep ) . each do | line | line = line . empty? ? filler_line : line output . join ( sep )", "del_tokens": "SPACE = ' ' . freeze def pad ( text , padding , fill : SPACE , separator : NEWLINE ) line_width = max_line_length ( text , separator ) text_copy . split ( separator ) . each do | line | output . join ( separator )", "commit_type": "change"}
{"commit_tokens": ["Change", "to", "freeze", "ansi", "attributes", "."], "add_tokens": "} . freeze", "del_tokens": "}", "commit_type": "change"}
{"commit_tokens": ["Improve", "resolver", "documentation", "and", "test", "coverage"], "add_tokens": "# Resolve a domain name using IPSocket.getaddress. This uses getaddrinfo(3) # on POSIX operating systems. # # @param hostname [String] name of the host whose IP address we'd like to obtain # @return [IPAddr] resolved IP address # @raise [Socketry::Resolver::Error] an error occurred resolving the domain name # @raise [Socketry::TimeoutError] a timeout occured before the name could be resolved # @raise [Socketry::AddressError] the name was resolved to an unsupported address raise Socketry :: Resolver :: Error , ex . message , ex . backtrace", "del_tokens": "raise Resolver :: Error , ex . message , ex . backtrace", "commit_type": "improve"}
{"commit_tokens": ["Add", "typed", "property", "setter", "."], "add_tokens": "prop = self . class . property ( attribute ) if prop . domain? and prop . collection? then clear_attribute ( attribute ) merge_attribute ( attribute , value ) else set_typed_property_value ( prop , value ) end # @param [Property] property the property to set # @param value the new value # @raise [TypeError] if the value is incompatible with the property def set_typed_property_value ( property , value ) begin send ( property . writer , value ) rescue TypeError # Add the attribute to the error message. raise TypeError . new ( \"Cannot set #{self.class.qp} #{property} to #{value.qp} - \" + $1 ) end end", "del_tokens": "# bail out if the value argument is the current value return value if value . equal? ( send ( attribute ) ) clear_attribute ( attribute ) merge_attribute ( attribute , value )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "Repo#history", "because", "structs", "are", "reused", "."], "add_tokens": "# returns the revision number # returns whether this revision has children # returns a Hash of the revision's changed paths @changed_paths ||= ( self [ :changed_paths ] . null? ? nil : self [ :changed_paths ] . to_h . tap { | by_path | by_path . each_key { | k | by_path [ k ] = by_path [ k ] . to_h } } # returns a Hash of the revision's properties @props ||= ( self [ :rev_props ] . null? ? nil : self [ :rev_props ] . to_h ) # return the revision's log message props [ LOG_PROP_NAME ] if props # return the revision's author props [ AUTHOR_PROP_NAME ] if props # return the Time that this revision was committed Time . parse ( props [ TIMESTAMP_PROP_NAME ] ) if props end # get the contents of this log entry as a multi-level hash def to_h { :rev => rev , :log => message , :author => author , :timestamp => timestamp , :has_children? => has_children? , :changed_paths => changed_paths }", "del_tokens": "@changed ||= ( self [ :changed_paths ] . null? ? nil : self [ :changed_paths ] . to_h self [ :rev_props ] props [ LOG_PROP_NAME ] props [ AUTHOR_PROP_NAME ] Time . parse ( props [ TIMESTAMP_PROP_NAME ] )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "alteration", "of", "the", "Gem", "Specification", "when", "cross", "compiling", ".", "Closes", "GH", "-", "3"], "add_tokens": "@cross_compiling = nil def cross_compiling ( & block ) @cross_compiling = block if block_given? end def define_native_tasks ( for_platform = nil , ruby_ver = RUBY_VERSION , callback = nil ) # expose gem specification for customization if callback callback . call ( spec ) end if @gem_spec && @gem_spec . platform == 'ruby' then define_native_tasks ( for_platform , ruby_ver , @cross_compiling ) end", "del_tokens": "def define_native_tasks ( for_platform = nil , ruby_ver = RUBY_VERSION ) define_native_tasks ( for_platform , ruby_ver ) if @gem_spec && @gem_spec . platform == 'ruby'", "commit_type": "allow"}
{"commit_tokens": ["added", "in", "debug", "mode", "along", "with", "inlining", "all", "scripts", "into", "the", "html", "before", "being", "sent", "to", "phantom", "so", "phantom", "doesnt", "have", "to", "inject", "the", "script", "also", "removing", "script", "tags", "with", "nokogiri", ".", "less", "time", "in", "phantom", "the", "better"], "add_tokens": "VERSION = \"0.0.6\"", "del_tokens": "VERSION = \"0.0.4\"", "commit_type": "add"}
{"commit_tokens": ["Change", "this", "test", "yet", "again", "to", "not", "rely", "on", "ps", "and", "make", "it", "allow", "up", "to", "a", "second", "for", "the", "executable", "to", "be", "called", "."], "add_tokens": "file = File . expand_path ( '../../support/custom_phantomjs_called' , __FILE__ ) path = File . expand_path ( '../../support/custom_phantomjs' , __FILE__ ) FileUtils . rm_f file # If the correct custom path is called, it will touch the file. We allow at # least 1 sec for this to happen before failing. tries = 0 until File . exist? ( file ) || tries == 10 sleep 0.1 tries += 1 end File . exist? ( file ) . should == true", "del_tokens": "path = File . expand_path ( '../../support/custom_phantomjs' , __FILE__ ) ` ps -o command= ` . should include ( path )", "commit_type": "change"}
{"commit_tokens": ["add", "CardTable", ".", "create_sql", "&", "CardTable", ".", "attributes_names_insert_sql"], "add_tokens": "CREATE TABLE IF NOT EXISTS #{self.table_name} ( #{self.create_sql} ) #using .first array method to return only the first nested array #the object after its creation is concluded. def self . create_sql #will apply the column names ('key') and their schemas ('value') into sql strings without having to hard code them #the collect method returns the revised array and then we concatenate it into a string separating the contents with a comma ATTRS . collect { | key , value | \"#{key} #{value}\" } . join ( \", \" ) end def self . attributes_names_insert_sql #same idea as self.create_sql only it's returning the 'key' for sql insertions ATTRS . keys [ 1 .. - 1 ] . join ( \", \" ) end", "del_tokens": "CREATE TABLE IF NOT EXISTS #{self.table_name} ( id INTEGER PRIMARY KEY , card TEXT , sets TEXT , market_price INTEGER , price_fluctuate TEXT , image TEXT ) #using first array method to return only the first nested array #the object after it's creation is concluded.", "commit_type": "add"}
{"commit_tokens": ["Using", "excon", "for", "HTTP", "connections", "instead", "of", "net", "-", "http", "-", "persistent"], "add_tokens": "@adapter = opts . fetch :adapter , :excon", "del_tokens": "@adapter = opts . fetch :adapter , :net_http_persistent", "commit_type": "use"}
{"commit_tokens": ["Added", "tests", "for", "lccn", "validity"], "add_tokens": "StdNum :: LCCN . valid? ( \"n078-890351\" ) . must_equal false , \"n078-890351 should start with two letters or two digits\" StdNum :: LCCN . valid? ( \"na078-890351\" ) . must_equal false , \"naa78-890351 should start with three letters or digits\" StdNum :: LCCN . valid? ( \"0an78-890351\" ) . must_equal false , \"naa78-890351 should start with three letters or digits\" StdNum :: LCCN . valid? ( \"n78-89c0351\" ) . must_equal false , \"n78-89c0351 has a letter after the dash\"", "del_tokens": "StdNum :: LCCN . valid? ( \"na78-890351\" ) . must_equal false StdNum :: LCCN . valid? ( \"naa78-890351\" ) . must_equal false StdNum :: LCCN . valid? ( \"n78-89c0351\" ) . must_equal false", "commit_type": "add"}
{"commit_tokens": ["Removed", "newlines", "from", "inserted", "script", "/", "style", "tags"], "add_tokens": "to_inline << [ stylesheet_tag , \"<style>\" + stylesheet_contents + \"</style>\" ] to_inline << [ script_tag , \"<script>\" + script_contents + \"</script>\" ]", "del_tokens": "to_inline << [ stylesheet_tag , \"<style>\\n\" + stylesheet_contents + \"</style>\\n\" ] to_inline << [ script_tag , \"<script>\\n\" + script_contents + \"</script>\\n\" ]", "commit_type": "remove"}
{"commit_tokens": ["added", "feature", "to", "test", "pressing", "radio", "button", "by", "id"], "add_tokens": "radio_button ( :radio_button_id , :id => 'radio2' )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "useless", "error", "message", "when", "trying", "to", "load", "missing", "file"], "add_tokens": "if _file . is_a? ( String ) raise Exception , \"File #{_file} does not exist.\" unless File . exists? ( _file ) @file = _file end", "del_tokens": "@file = _file if _file . is_a? ( String ) and File . exists? ( _file )", "commit_type": "fix"}
{"commit_tokens": ["Make", "Scope#_render", "private", "and", "add", "unit", "tests"], "add_tokens": "require 'dry-equalizer' include Dry :: Equalizer ( :_renderer , :_data ) attr_reader :_data def initialize ( renderer , data = { } ) @_data = data _template? ( name ) || _data . key? ( name ) _render ( template_path , * args , & block ) elsif _data . key? ( name ) _data [ name ] def _render ( path , * args , & block ) _renderer . render ( path , _render_args ( * args ) , & block ) end", "del_tokens": "attr_reader :_scope def initialize ( renderer , scope = { } ) @_scope = scope end def render ( path , * args , & block ) _renderer . render ( path , _render_args ( * args ) , & block ) _template? ( name ) || _scope . key? ( name ) render ( template_path , * args , & block ) elsif _scope . key? ( name ) _scope [ name ]", "commit_type": "make"}
{"commit_tokens": ["Use", "gethostbyname", "but", "fall", "back", "to", "hostname"], "add_tokens": "# Sometimes OS X gets upset with Socket.gethostbyname, so fall back # to plain old hostname if it fails. hostname = Socket . gethostname @server_name = options [ :server_name ] || Socket . gethostbyname ( hostname ) rescue hostname", "del_tokens": "@server_name = options [ :server_name ] || Socket . gethostname", "commit_type": "use"}
{"commit_tokens": ["fixed", "filename", "error", "for", "layouts", "by", "expanding", "file", "path"], "add_tokens": "File . join ( File . expand_path ( RAILS_ROOT ) , 'app' , 'layouts' , \"#{@controller.active_layout.to_s.underscore}.html.erb\" ) . sub ( '/layouts/layouts/' , '/views/layouts/' )", "del_tokens": "@controller . active_layout . filename", "commit_type": "fix"}
{"commit_tokens": ["Move", "request", "callbacks", "to", "defaults"], "add_tokens": "base . defaults do | req | req . before_process { before_process } if callback? ( :before_process ) req . after_process { after_process } if callback? ( :after_process ) req . failure { | code , url | failure ( code , url ) } if callback? ( :failure ) req . error { | e | error ( e ) } if callback? ( :error ) end", "del_tokens": "req . before_process { before_process } if callback? ( :before_process ) req . after_process { after_process } if callback? ( :after_process ) req . failure { | code , url | failure ( code , url ) } if callback? ( :failure ) req . error { | e | error ( e ) } if callback? ( :error )", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "auditor", "proxy", "unit", "test", "can", "be", "run", "individually"], "add_tokens": "require 'right_link_log' RightScale :: RightLinkLog . logger . should_receive ( :error ) . once . with ( \"AUDIT *ERROR> ERROR\" ) RightScale :: RightLinkLog . logger . should_receive ( :info ) . once . with ( \"AUDIT *RS> STATUS\" ) RightScale :: RightLinkLog . logger . should_receive ( :info ) . once . with ( \"AUDIT OUTPUT\" ) RightScale :: RightLinkLog . logger . should_receive ( :info ) . once . with ( 'AUDIT RAW OUTPUT' ) RightScale :: RightLinkLog . logger . should_receive ( :info ) . once . with ( \"AUDIT #{ '****' * 20 }\\n*RS>#{ 'SECTION'.center(72) }****\" ) RightScale :: RightLinkLog . logger . should_receive ( :info ) . once . with ( \"AUDIT *RS> INFO\" )", "del_tokens": "Nanite :: Log . logger . should_receive ( :error ) . once . with ( \"AUDIT *ERROR> ERROR\" ) Nanite :: Log . logger . should_receive ( :info ) . once . with ( \"AUDIT *RS> STATUS\" ) Nanite :: Log . logger . should_receive ( :info ) . once . with ( \"AUDIT OUTPUT\" ) Nanite :: Log . logger . should_receive ( :info ) . once . with ( 'AUDIT RAW OUTPUT' ) Nanite :: Log . logger . should_receive ( :info ) . once . with ( \"AUDIT #{ '****' * 20 }\\n*RS>#{ 'SECTION'.center(72) }****\" ) Nanite :: Log . logger . should_receive ( :info ) . once . with ( \"AUDIT *RS> INFO\" )", "commit_type": "make"}
{"commit_tokens": ["fixed", "confusion", "with", "parser", "game", "class", "function"], "add_tokens": "@parser_class . game lines . first", "del_tokens": "@parser_class . game [ / [^ \\n ]+ / ]", "commit_type": "fix"}
{"commit_tokens": ["Changing", "to", "iso8661", "-", "fixes", "CHEF", "-", "2161"], "add_tokens": "sprintf ( \"[%s] %s: %s\\n\" , time . iso8601 ( ) , severity , msg2str ( msg ) ) end", "del_tokens": "sprintf ( \"[%s] %s: %s\\n\" , time . rfc2822 ( ) , severity , msg2str ( msg ) ) end", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "to", "recursive", "variations", "."], "add_tokens": "class MoveText attr_accessor :notation , :variations def initialize ( notation , variations = nil ) @notation = notation @variations = variations end def == ( m ) self . to_s == m . to_s end def eql? ( m ) self == m end def hash @notation . hash end def to_s @notation end end @moves = moves . map do | m | if m . is_a? String MoveText . new ( m . gsub ( \"0\" , \"O\" ) ) else MoveText . new ( m . notation . gsub ( \"0\" , \"O\" ) , m . variations ) end end new_pos = position . move ( move . notation )", "del_tokens": "@moves = moves . map { | m | m . gsub ( \"0\" , \"O\" ) } new_pos = position . move ( move )", "commit_type": "add"}
{"commit_tokens": ["Removed", "optional", "strict", "argument", "within", "Require", ".", "resolve"], "add_tokens": "def resolve ( path ) path", "del_tokens": "def resolve ( path , strict = false ) path unless strict", "commit_type": "remove"}
{"commit_tokens": ["remove", "dashes", "from", "Word", "comment", "dates"], "add_tokens": "\"mso-comment-date:#{node['date'].gsub(/[:-]+/, '')}\" }", "del_tokens": "\"mso-comment-date:#{node['date']}\" }", "commit_type": "remove"}
{"commit_tokens": ["Allow", "passing", "parameters", "to", "association", "has", "many"], "add_tokens": "define_method ( association_name ) do | * query | # TODO: Support a more generic version of lazy-loading begin association_class = association_name . to_s . singularize . classify . constantize rescue NameError => ex raise ArgumentError . new ( \"Association #{association_name} in #{self.class} is invalid because #{association_name.to_s.classify} does not exist\" ) end if query . empty? # Ex: Books.all, so we want to cache it. ivar = \"@#{association_name}\" if instance_variable_defined? ( ivar ) instance_variable_get ( ivar ) elsif association_class . respond_to? ( :all ) instance_variable_set ( ivar , Array ( association_class . all ( \"#{self.class.name.underscore}_id\" => id ) ) ) else # Ex: Book.all(:name => \"The...\"), so we do not want to cache it Array ( association_class . all ( { \"#{self.class.name.underscore}_id\" => id } . merge ( query . first ) ) )", "del_tokens": "define_method ( association_name ) do ivar = \"@#{association_name}\" if instance_variable_defined? ( ivar ) instance_variable_get ( ivar ) else # TODO: Support a more generic version of lazy-loading begin association_class = association_name . to_s . singularize . classify . constantize rescue NameError => ex raise ArgumentError . new ( \"Association #{association_name} in #{self.class} is invalid because #{association_name.to_s.classify} does not exist\" ) instance_variable_set ( ivar , Array ( association_class . all ( \"#{self.class.name.underscore}_id\" => id ) ) )", "commit_type": "allow"}
{"commit_tokens": ["Adding", "specs", "around", "Teams", ".", "all", "."], "add_tokens": "require 'common'", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "String#prepend", "instead", "of", "interpolation"], "add_tokens": "command = \"#{k}:#{v}\" command . prepend ( \"#{prefix}.\" ) if prefix", "del_tokens": "command = \"#{self.prefix + '.' if self.prefix}#{k}:#{v}\"", "commit_type": "use"}
{"commit_tokens": ["updated", "to", "new", "version", "of", "lev"], "add_tokens": "lev_handler", "del_tokens": "include Lev :: Handler", "commit_type": "update"}
{"commit_tokens": ["fixed", "scriptable", "error", "add", "ring", "property", "to", "counter"], "add_tokens": "return @factory . script ( #{constant}[:id], #{constant}[:source]).eval(keys: keys, argv: argv)", "del_tokens": "return @factory . script ( #{constant}[:id], #{constant}[:source]).eval(keys: keys, argv: values)", "commit_type": "fix"}
{"commit_tokens": ["Use", "internal", "parsing", "of", "Size"], "add_tokens": "page_properties . size = Size . parse ( pg_sz )", "del_tokens": "page_properties . size = Size . new page_properties . size . orientation = pg_sz . attribute ( 'orient' ) . value . to_sym unless pg_sz . attribute ( 'orient' ) . nil? page_properties . size . height = pg_sz . attribute ( 'h' ) . value page_properties . size . width = pg_sz . attribute ( 'w' ) . value", "commit_type": "use"}
{"commit_tokens": ["Make", "code", "more", "concise", "avoid", "fence", "-", "posting", "."], "add_tokens": "( 0 ... self . length ) . to_a . collect do | p | ( 0 ... self . num_interior_rings ) . to_a . each do | n |", "del_tokens": "( 0 .. ( self . length - 1 ) ) . to_a . collect do | p | ( 0 .. ( self . num_interior_rings ) - 1 ) . to_a . each do | n |", "commit_type": "make"}
{"commit_tokens": ["Added", "autocomplete", "form", "helper", "."], "add_tokens": "return collection_scope . total_count if params [ :per_page ] == 'all'", "del_tokens": "return collection_scope . count if params [ :per_page ] == 'all'", "commit_type": "add"}
{"commit_tokens": ["Remove", "unecessary", "Veritas", "::", "prefix", "from", "specs"], "add_tokens": "@attribute = Attribute . new ( @name , Integer )", "del_tokens": "@attribute = Veritas :: Attribute . new ( @name , Integer )", "commit_type": "remove"}
{"commit_tokens": ["Add", "FIXME", "note", "to", "unfinished", "spec"], "add_tokens": "# FIXME: Evaluations should be able to signal error also # evaluation = evaluator.evaluation(invalid)", "del_tokens": "evaluation = evaluator . evaluation ( invalid )", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "namespaces", "are", "inherited"], "add_tokens": "def self . inherited ( base ) super base . instance_variable_set ( :@namespaces , @namespaces . dup ) unless @namespaces . nil? end # Sets or returns namespaces in which to look for fetch modules. # If namespaces haven't been set on the particular fetcher, default # namespaces from the Fetch configuration will be returned. # # namespaces :sites, :merchants # namespaces [:sites, :merchants] # # namespaces # => [:sites, :merchants] def self . namespaces ( * names ) if names . any? @namespaces = names . flatten else @namespaces || Fetch . config . namespaces end end # Convenience method for setting a single namespace. # # namespace :sites # namespaces # => [:sites] def self . namespace ( name ) namespaces ( name ) end", "del_tokens": "class << self # Sets or returns namespaces in which to look for fetch modules. # If namespaces haven't been set on the particular fetcher, default # namespaces from the Fetch configuration will be returned. # # namespaces :sites, :merchants # namespaces [:sites, :merchants] # # namespaces # => [:sites, :merchants] def namespaces ( * names ) if names . any? @namespaces = names . flatten else @namespaces || Fetch . config . namespaces end end # Convenience method for setting a single namespace. # # namespace :sites # namespaces # => [:sites] def namespace ( name ) namespaces ( name ) end end", "commit_type": "make"}
{"commit_tokens": ["removing", "dead", "code", "making", "tests", "more", "robust"], "add_tokens": "# return true if installation succeeded # return false if either no git repo or hook already present # an alternative would be to backup the old hook # FileUtils.mv(pre_commit_path, # git_root.join('hooks', 'pre-commit.bkp'), # :force => true)", "del_tokens": "FileUtils . mv ( pre_commit_path , git_root . join ( 'hooks' , 'pre-commit.bkp' ) , :force => true )", "commit_type": "remove"}
{"commit_tokens": ["Added", "version", "and", "documented", "convenience", "methods", "in", "Mockingbird", "module"], "add_tokens": "# External dependencies require 'rubygems' require 'eventmachine' # Mockingbird code require 'mockingbird/version' # Convenience method for starting a mockingbird server during a test. # This will be most users' primary interface to mockingbird. The mockingbird # server will be forked as a separate process. Ensure that your test code # always calls teardown at some point after setup, or the separate process # will not be terminated. # # Options are # :host - The host to listen on. 0.0.0.0 by default # :port - The port to listen on. 4879 by default # # The block is a Mockingbird configuration (see README). sleep ( 1 ) # Necessary to make sure the forked proc is up and running @pid # Terminates the mockingbird server created by a call to setup. Make sure # to always pair this call with setup to ensure that mockingbird server # processes don't linger. If you're using test/unit, the recommended # pattern is to actually call setup and teardown here during the setup and # teardown phase of your unit tests. Otherwise, use the following pattern: # # def test_something # Mockingbird.setup(:port=>NNNN) do # # config here # end # # do tests # ensure # Mockingbird.teardown # end", "del_tokens": "$LOAD_PATH . unshift File . expand_path ( File . dirname ( __FILE__ ) + '/lib' ) sleep ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Added", "methods", "for", "tracking", "active", "sources", "and", "joining", "them", "up", "at", "a", "later", "time"], "add_tokens": "@@active_sources = [ ] attr_reader :active_sources def join ( sources = [ ] ) @items = get_sources . map { | source | source [ 1 ] } end def activate ( name , source ) @@active_sources << { name => source } end def active_sources @@active_sources end private def get_sources ( sources = [ ] ) active_sources . find_all { | k , v | sources . include? ( k ) } end require 'smoke/delayed_block'", "del_tokens": "require 'smoke/item'", "commit_type": "add"}
{"commit_tokens": ["Move", "EventQueue", "to", "the", "correct", "WebsocketRails", "module", "."], "add_tokens": "module WebsocketRails class EventQueue attr_reader :queue def initialize @queue = [ ] end def enqueue ( event ) @queue << event end alias :<< :enqueue def last @queue . last end def flush ( & block ) unless block . nil? @queue . each do | item | block . call item end @queue = [ ] end", "del_tokens": "class EventQueue attr_reader :queue def initialize @queue = [ ] end def enqueue ( event ) @queue << event end alias :<< :enqueue def last @queue . last end def flush ( & block ) unless block . nil? @queue . each do | item | block . call item @queue = [ ] end", "commit_type": "move"}
{"commit_tokens": ["Updated", "README", ".", "md", "and", "sire", ".", "rb", "."], "add_tokens": "require 'pp' if ARGV [ 0 ] == 'old' require 'readline' puts \"\\nOption(old). Loaded the standard readline gem.\" elsif ARGV [ 0 ] == 'local' require './lib/mini_readline' puts \"\\nOption(local). Loaded mini_readline from the local code folder.\" elsif defined? ( MiniReadline )", "del_tokens": "puts if defined? ( MiniReadline ) require 'pp'", "commit_type": "update"}
{"commit_tokens": ["add", "support", "two", "digit", "scores", "e", ".", "g", ".", "10", "-", "0"], "add_tokens": "VERSION = '1.7.7'", "del_tokens": "VERSION = '1.7.6'", "commit_type": "add"}
{"commit_tokens": ["Using", "new", "DRY", "method", "for", "setting", "Kete", ".", "extensions", "."], "add_tokens": "Kete . add_code_to_extensions_for ( key , Proc . new { Kernel . load ( ext_path ) } )", "del_tokens": "Kete . extensions [ :blocks ] ||= Hash . new Kete . extensions [ :blocks ] [ key ] ||= Array . new Kete . extensions [ :blocks ] [ key ] << Proc . new { Kernel . load ( ext_path ) }", "commit_type": "use"}
{"commit_tokens": ["made", "IndifferentAccess", "extend", "duplicates", "with", "IndifferentAccess", ".", "developed", "Utils#dump_file", "."], "add_tokens": "# Ensures duplicates use indifferent access. def dup super ( ) . extend IndifferentAccess end", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Adding", "aliases", "for", "the", "the", "helpers", "similar", "to", "the", "ones", "in", "Rails"], "add_tokens": "File . join @options [ :prefix ] . to_s , path", "del_tokens": "File . join @options [ :prefix ] , path", "commit_type": "add"}
{"commit_tokens": ["fix", "helper", "target", "added", "some", "docs"], "add_tokens": "# Add helpers to the Base renedering class, which allows them to be called # target - What class should receive the helpers -- defaults to Gopher::Rendering::Base, which will make it available when rendering def helpers ( target = Gopher :: Rendering :: Base , & block )", "del_tokens": "# Add helpers to the Application class, which allows them to be called # target - What class should receive the helpers -- defaults to Gopher::Application, which will make it generally available def helpers ( target = Gopher :: Application , & block )", "commit_type": "fix"}
{"commit_tokens": ["added", "specs", "for", "unsubscribe", "and", "complaints"], "add_tokens": "@complaints ||= Mailgun :: Complaint . new ( self )", "del_tokens": "@complaints || = Mailgun :: Complaint . new ( self )", "commit_type": "add"}
{"commit_tokens": ["added", ":", "force", "option", "to", "refspec", "parser"], "add_tokens": "# @overload [](*args) # @param args [RefSpec, String, Hash, Range, ...] # @return [Array<RefSpec>] # # @overload [](*args, options) # @param args [RefSpec, String, Hash, Range, ...] # @param options [Hash] # @option options [Boolean] :forced (false) # @return [Array<RefSpec>] forced = false if args . last . kind_of? Hash options = args . last forced = options . fetch ( :forced , false ) end [ parse_string ( arg , forced ) ] arg . map { | k , v | parse_pair ( k , v , forced ) } [ parse_pair ( arg . begin , arg . end , forced ) ] def parse_string ( string , forced ) RefSpec . new ( from , to , forced || ( ma [ 1 ] == '+' ) ) def parse_pair ( a , b , forced ) RefSpec . new ( normalize ( from_base , a . to_s ) , normalize ( to_base , b . to_s ) , forced )", "del_tokens": "# # @param args [RefSpec, String, Hash, Range, ...] # @return [Array<RefSpec>] [ parse_string ( arg ) ] arg . map { | k , v | parse_pair ( k , v ) } [ parse_pair ( arg . begin , arg . end ) ] def parse_string ( string ) RefSpec . new ( from , to , ma [ 1 ] == '+' ) def parse_pair ( a , b ) RefSpec . new ( normalize ( from_base , a . to_s ) , normalize ( to_base , b . to_s ) )", "commit_type": "add"}
{"commit_tokens": ["Implement", "ruby_expect", "version", "of", "execute"], "add_tokens": "# Rtasklib::Execute.task(\"rc.data.location=#{@data_location}\", \"_version\") exit , raw_version = Rtasklib :: Execute . task ( @create_new , \"rc.data.location=#{@data_location}\" , gem_version = Gem :: Version . new ( raw_version [ 0 ] . chomp ) if exit == 0", "del_tokens": "# @taskrc = # raw_version = Open3.capture2( # \"task rc.data.location=#{@data_location} _version\") raw_version = Rtasklib :: Execute . task ( \"rc.data.location=#{@data_location}\" , gem_version = Gem :: Version . new ( raw_version [ 0 ] . chomp )", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "to", "tests", "to", "use", "be", "true", "instead", "of", "be_true"], "add_tokens": "column . state . deleted? . should be true column10 . each do | element | list [ 0 .. 10 ] . should ==", "del_tokens": "column . state . deleted? . should be_true column10 . each do | element | list [ 0 .. 10 ] . should ==", "commit_type": "fix"}
{"commit_tokens": ["add", "casting", "support", "in", "the", "AR", "driver", "specifically", "for", "handling", "default", "column", "values", "-", "this", "is", "a", "temporary", "(", "but", "working", ")", "fix", "as", "I", "m", "looking", "into", "how", "I", "can", "do", "this", "in", "C"], "add_tokens": "BOOL = \"tinyint(1)\" . freeze return nil if value . nil? case type when :string then value when :text then value when :integer then value . to_i rescue value ? 1 : 0 unless value . is_a? ( Fixnum ) when :float then value . to_f unless value . is_a? ( Float ) when :decimal then self . class . value_to_decimal ( value ) unless value . class == BigDecimal when :datetime then self . class . string_to_time ( value ) unless value . class == Time when :timestamp then self . class . string_to_time ( value ) unless value . class == Time when :time then self . class . string_to_dummy_time ( value ) unless value . class == Time when :date then self . class . string_to_date ( value ) unless value . class == Date when :binary then value when :boolean then self . class . value_to_boolean ( value ) else value return :boolean if Mysql2Adapter . emulate_booleans && field_type . downcase . index ( BOOL ) return :integer if field_type =~ / year /i", "del_tokens": "if type == :boolean self . class . value_to_boolean ( value ) else value return :boolean if Mysql2Adapter . emulate_booleans && field_type . downcase . index ( \"tinyint(1)\" )", "commit_type": "add"}
{"commit_tokens": ["Adding", "event", "vendor", "argument", "back", "in"], "add_tokens": "Contract String , Hash , Maybe [ String ] , Maybe [ Hash ] , Maybe [ Num ] => [ Bool , Num ] def track_unstruct_event ( name , event_json , event_vendor = nil , context = nil , tstamp = nil ) if event_vendor pb . add ( 'evn' , event_vendor ) end", "del_tokens": "Contract String , Hash , Maybe [ Hash ] , Maybe [ Num ] => [ Bool , Num ] def track_unstruct_event ( name , event_json , context = nil , tstamp = nil )", "commit_type": "add"}
{"commit_tokens": ["added", "human", "readable", "logging", "for", "rake"], "add_tokens": "require 'logger' # by default, use human logging if a logger is enabled. args [ :logger ] = Logger . new ( STDOUT ) unless args . key? ( :logger ) args [ :log_format ] = :human unless args . key? ( :log_format ) logger = params [ :logger ] logger = @@logger unless logger log_format = :json log_format = params [ :log_format ] if params . key? ( :log_format ) result . configure_logger ( logger , log_format )", "del_tokens": "result . logger = params [ :logger ] result . logger = @@logger unless params [ :logger ]", "commit_type": "add"}
{"commit_tokens": ["Use", "single", "quotes", "to", "prevent", "early", "escaping"], "add_tokens": "if line . start_with? ( '*' ) elsif line . start_with? ( '+' ) elsif line . start_with? ( '-' ) elsif line . match ( '[0-9]+\\.' ) elsif line . match ( '[0-9]+\\)' )", "del_tokens": "if line . start_with? ( \"*\" ) elsif line . start_with? ( \"+\" ) elsif line . start_with? ( \"-\" ) elsif line . match ( \"[0-9]+\\.\" ) elsif line . match ( \"[0-9]+\\)\" )", "commit_type": "use"}
{"commit_tokens": ["Move", "lazy", "initialization", "of", "methods", "to", "ActiveSupport", "::", "Concern", "include", "block"], "add_tokens": "# Rails uses lazy initialization to wrap methods, so make sure we pre-initialize any deprecated attributes if defined? ( ActiveRecord ) && ancestors . include? ( ActiveRecord :: Base ) new ( Hash [ attributes . zip ( attributes . map { } ) ] , without_protection : true ) end", "del_tokens": "# Ensure the attribute is initialized if defined? ( ActiveRecord ) && self . ancestors . include? ( ActiveRecord :: Base ) new ( { attribute . to_sym => nil } , without_protection : true ) end", "commit_type": "move"}
{"commit_tokens": ["Allow", "extra", "scheduler", "options", "to", "be", "passed", "."], "add_tokens": "out [ :extra_opts ] = task_schedule [ 2 ] if task_schedule . length > 2 opts = { :overlap => false , :job => true , :mutex => task_id } opts . merge! ( schedule [ :extra_opts ] ) if schedule . key? ( :extra_opts ) scheduler . send ( schedule [ :type ] , schedule [ :schedule ] , opts ) do | job |", "del_tokens": "scheduler . send ( schedule [ :type ] , schedule [ :schedule ] , :overlap => false , :job => true , :mutex => task_id ) do | job |", "commit_type": "allow"}
{"commit_tokens": ["Changed", ":", "A", "/", "B", "test", "experiments", "alternatives", "now", "handled", "using", "Alternatives"], "add_tokens": "def key ( name = nil ) #:nodoc: def redis #:nodoc:", "del_tokens": "protected def key ( name = nil ) def redis", "commit_type": "change"}
{"commit_tokens": ["Allow", "for", "arguments", "in", "to_json"], "add_tokens": "def to_json ( * args ) to_hash . to_json ( * args )", "del_tokens": "def to_json to_hash . to_json", "commit_type": "allow"}
{"commit_tokens": ["Remove", ".", "git", "from", "the", "end", "of", "the", "urls", "if", "present", "."], "add_tokens": "GitCloneUrl . parse ( key ) . to_s . gsub ( / \\. git$ / , '' )", "del_tokens": "GitCloneUrl . parse ( key ) . to_s", "commit_type": "remove"}
{"commit_tokens": ["add", "method", "to", "delete", "item", "from", "a", "list"], "add_tokens": "item = @client . add_list_item ( @list_id , :venueId => venue_id ) item . venue . id . should == venue_id should \"delete an item from a list\" do item_id = 'v4ba19cb0f964a520c2c337e3' stub_post ( \"https://api.foursquare.com/v2/lists/#{@list_id}/deleteitem?oauth_token=#{@client.oauth_token}&itemId=#{item_id}\" , \"list_item.json\" ) item = @client . delete_list_item ( @list_id , item_id ) item . id . should == item_id end", "del_tokens": "list_item = @client . add_list_item ( @list_id , :venueId => venue_id ) list_item . venue . id . should == venue_id", "commit_type": "add"}
{"commit_tokens": ["moved", "gpio", "into", "beaglebone", "module", "as", "intended"], "add_tokens": "ret = fd . write ( data ) ret", "del_tokens": "fd . write ( data )", "commit_type": "move"}
{"commit_tokens": ["Added", "an", "option", "in", "the", "Anonymizer", "class", "to", "remove", "all", "private", "tags", "from", "the", "selected", "DICOM", "dataset"], "add_tokens": "attr_accessor :blank , :enumeration , :identity_file , :remove_private , :verbose , :write_path # Replace all values with a blank string? # Enumerate selected replacement values? # All private tags may be removed if desired: @remove_private = false # A separate path may be selected for writing the anonymized files: # Folders that will be skipped: # Remove private tags? obj . remove_private if @remove_private", "del_tokens": "attr_accessor :blank , :enumeration , :identity_file , :verbose , :write_path", "commit_type": "add"}
{"commit_tokens": ["Use", "an", "options", "hash", "to", "initialize", "an", "instance"], "add_tokens": "# prowler = Prowler.new(:application => 'application', :api_key => 'apikey') new . notify ( event , message , * args ) new . verify # Pass any of the following options to override the global configuration: # * +:application+: The name of your application. # * +:provider_key+: Key to override the rate limit of 1000 requests per hour. # * +:api_key+: Your API key. def new ( * args ) Prowler :: Application . new ( * args )", "del_tokens": "# prowler = Prowler.new('apikey', 'application') app = new ( api_key , application , provider_key ) app . notify ( event , message , * args ) app = new ( api_key , application , provider_key ) app . verify # * api_key: Your API key. # * application: The name of your application. # * provider_key: Key to override the rate limit of 1000 requests per hour. (Optional) def new ( api_key , application , provider_key = nil ) Prowler :: Application . new ( api_key , application , provider_key )", "commit_type": "use"}
{"commit_tokens": ["Add", "initial", "version", "of", "Record", ".", "create", "with", "no", "hooks", "."], "add_tokens": "def new ( attributes = { } ) if attributes [ :id ] Prequel . session [ table . name ] [ attributes [ :id ] ] ||= super def create ( attributes ) new ( attributes ) . save end def save self . id = ( DB [ table . name ] << field_values_without_id ) Prequel . session [ table . name ] [ id ] = self end def field_values_without_id field_values . tap do | field_values | field_values . delete ( :id ) end end", "del_tokens": "def new ( field_values = { } ) if field_values [ :id ] Prequel . session [ table . name ] [ field_values [ :id ] ] ||= super", "commit_type": "add"}
{"commit_tokens": ["added", "spec", "data", "file", "to", "gem", "contents"], "add_tokens": "test FileList [ \"spec/**/*.{rb,yml}\" , \"test/**/*.rb\" ]", "del_tokens": "test FileList [ \"spec/**/*.rb\" , \"test/**/*.rb\" ]", "commit_type": "add"}
{"commit_tokens": ["allow", "mock", "command", "to", "support", "sha256", "mocking", "of", "commands"], "add_tokens": "@commands [ cmd ] || @commands [ Digest :: SHA256 . hexdigest cmd ] || mock_command ( cmd )", "del_tokens": "@commands [ cmd ] || mock_command ( cmd )", "commit_type": "allow"}
{"commit_tokens": ["implement", "ColumnTypeFilter", "and", "Sorter", ".", "Not", "completely", "tested", "yet"], "add_tokens": "@out_file = File . join ( File . dirname ( __FILE__ ) , \"files/out.csv\" ) it \"should sort by one column\" do rows = \"1-30\" cols = \"s:0\" df = \"%d.%m.%Y\" sorter = Sorter . new ( infile : @in_file , outfile : @out_file , rows : rows , cols : cols , df : df ) sorter . execute result = [ \"Fink;1234;20.12.2015;f1;con123;dri222\" , \"Fink;1234;30.12.2016;f2;con333;dri321\" , \"Gent;4323;1.3.2014;g1;con123;dri111\" , \"Haas;3322;1.10.2011;h1;con332;dri111\" , \"Klig;4432;;k1;con332;dri222\" , \"Rank;3232;1.5.2013;r1;con332;dri321\" , \"fink;1234;;f3;con332;dri321\" ] File . open ( @out_file ) . each_with_index do | line , index | line . chomp . should eq result [ index ] end end", "del_tokens": "@out_file = File . join ( File . dirname ( __FILE__ ) , \"file/out.csv\" ) it \"should sort by on column\"", "commit_type": "implement"}
{"commit_tokens": ["fixed", "search", "parameters", "for", "datacenters"], "add_tokens": "search = opts [ :search ] || ( \"datacenter=%s\" % current_datacenter . name ) http_get ( \"/vms?search=%s\" % CGI . escape ( search ) , headers ) . xpath ( '/vms/vm' ) . collect do | vm |", "del_tokens": "search = opts [ :search ] || ( \"datacenter=$s\" % current_datacenter . name ) http_get ( \"/vms?search=%s\" % search , headers ) . xpath ( '/vms/vm' ) . collect do | vm |", "commit_type": "fix"}
{"commit_tokens": ["added", "before_tests", "callback", "used", "in", "megalookups"], "add_tokens": "## this runs after request returns, but before tests ## use it to munge response body from json string into a hash before_tests do | r | if r [ 'Content-Type' ] . respond_to? ( :match ) and r [ 'Content-Type' ] . match / application \\/ json / begin r . body = JSON . parse ( r . body ) rescue JSON :: ParserError puts \"error parsing JSON in response body\" end end end lookups = %w[ FacebookEmailLookup FacebookWebsiteLookup FoursquarePhoneLookup FoursquareFacebookIdLookup FoursquareEmailLookup TwitterWebsiteLookup GooglePlusLookup GoogleSocialLookup TwitterScreenNameLookup ] lookups . each do | lookup | test \"#{lookup} last successful response\" do | r | if r . body . is_a? Hash r . body [ 'lookups' ] [ lookup ] [ 'last_successful_response' ] else false end", "del_tokens": "# name should correspond to the hash key, value to the hash key. # if you want to add tests that pick up key/value pairs that are # nested somewhere other than under :lookups, # you're on your own! # Keep in mind that right each test is re-parsing the output. t = { FacebookEmailLookup : \"last_successful_response\" , FacebookWebsiteLookup : \"last_successful_response\" , FoursquarePhoneLookup : \"last_successful_response\" , FoursquareFacebookIdLookup : \"last_successful_response\" , FoursquareEmailLookup : \"last_successful_response\" , TwitterWebsiteLookup : \"last_successful_response\" , GooglePlusLookup : \"last_successful_response\" , GoogleSocialLookup : \"last_successful_response\" , TwitterScreenNameLookup : \"last_successful_response\" , } t . each do | name , test | test \"#{name} - #{test}\" do | r | h = JSON . parse ( r . body ) \"#{h['lookups'][\"#{name}\"][\"#{test}\"]}\"", "commit_type": "add"}
{"commit_tokens": ["Made", "shared", "checker", "example", "a", "bit", "better", "."], "add_tokens": "describe 'status' do context 'pass' do it 'passes if it can execute a query against the database' do ActiveRecord :: Base . connection . stub! ( :execute ) @checker = StatusCat :: Checkers :: ActiveRecordChecker . new @checker . status . should be_nil end context 'fail' do it 'returns an error message if it fails to query the database' do ActiveRecord :: Base . connection . should_receive ( :execute ) . and_raise ( @fail ) @checker = StatusCat :: Checkers :: ActiveRecordChecker . new @checker . status . to_s . should eql ( @fail )", "del_tokens": "context 'instance' do it 'has a value, and status accessor' do @checker . value . should eql ( @value ) @checker . status . should be_nil end describe 'status' do context 'pass' do it 'passes if it can execute a query against the database' do ActiveRecord :: Base . connection . stub! ( :execute ) @checker = StatusCat :: Checkers :: ActiveRecordChecker . new @checker . status . should be_nil end context 'fail' do it 'returns an error message if it fails to query the database' do ActiveRecord :: Base . connection . should_receive ( :execute ) . and_raise ( @fail ) @checker = StatusCat :: Checkers :: ActiveRecordChecker . new @checker . status . to_s . should eql ( @fail ) end", "commit_type": "make"}
{"commit_tokens": ["Added", "MonsterNames", "-", "CSV", "-", "Generator"], "add_tokens": "string :affix_name , string :name ,", "del_tokens": "string :name , string :name2 ,", "commit_type": "add"}
{"commit_tokens": ["Add", "interaction", "with", "cached", "metadata", "for", "Entry#update_metadata"], "add_tokens": "@cached_metadata = nil if options . delete ( :ignore_cache ) or options [ :force ] return @cached_metadata if @cached_metadata @previous_metadata ||= @cached_metadata @cached_metadata = @previous_metadata @cached_metadata = new_metadata", "del_tokens": "@metadata = nil if options . delete ( :ignore_cache ) or options [ :force ] return @metadata if @metadata # Use this method to update cached @metadata hash # # Not sure about this. Maybe it should be in #metadata ? @metadata = @previous_metadata @metadata = new_metadata", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "update", "to", "use", "new", "names", "."], "add_tokens": "TTY :: Formats :: FORMATS . keys . each do | token | options = { format : token , hide_cursor : true } spinner = TTY :: Spinner . new ( \"#{token}: :spinner\" , options )", "del_tokens": "TTY :: Formats :: FORMATS . size . times do | i | format = \"spin_#{i+1}\" options = { format : format . to_sym , hide_cursor : true } spinner = TTY :: Spinner . new ( \"#{format}: :spinner\" , options )", "commit_type": "change"}
{"commit_tokens": ["fix", "major", "encoding", "perf", "bug"], "add_tokens": "# Perf Fix: mutate state hash rather than creating new copy state [ :processing_key ] = true key . ffi_yajl ( yajl_gen , state ) state [ :processing_key ] = false", "del_tokens": "key . ffi_yajl ( yajl_gen , state . merge ( { :processing_key => true } ) )", "commit_type": "fix"}
{"commit_tokens": ["Move", "color", "related", "stuff", "into", "Color", "class"], "add_tokens": "require 'lifx/color' @label = payload . label . to_s @color = payload . color . snapshot LOG . info ( \"#{self}: Queuing: #{params.merge(target: id).inspect}\" ) MSEC_PER_SEC = 1000 def set_color ( color , duration = default_duration ) color : color . to_hsbk , duration : ( duration * MSEC_PER_SEC ) . to_i , ) )", "del_tokens": "@label = payload . label @color = payload . color UINT16_MAX = 65_535 MSEC_PER_SEC = 1000 DEFAULT_KELVIN = 3500 def set_hsbk ( hue , saturation , brightness , kelvin , duration = default_duration ) hsbk = build_hsbk ( hue , saturation , brightness , kelvin ) duration = ( duration * MSEC_PER_SEC ) . to_i duration : duration , color : hsbk ) ) end def set_hsb ( hue , saturation , brightness , duration = default_duration ) set_hsbk ( hue , saturation , brightness , DEFAULT_KELVIN , duration ) end def set_white ( brightness = 1 , kelvin = DEFAULT_KELVIN , duration = default_duration ) set_hsbk ( 0 , 0 , brightness , kelvin , duration )", "commit_type": "move"}
{"commit_tokens": ["fix", "madness", "surounding", "annotations", "(", "in", "particular", "policies", "get", "them", "now", "too", ")"], "add_tokens": "record = record . roleid ( default_account ) unless record . kind_of? ( String ) account , kind , id = record . split ( ':' , 3 ) record = record . resourceid ( default_account ) unless record . kind_of? ( String ) account , kind , id = record . split ( ':' , 3 ) # And this is why we don't name a class Array. current = record . annotations . kind_of? ( :: Array ) ? record . annotations [ 0 ] : record . annotations ( current || { } ) . keys . each do | attr | new_value = current [ attr ] current . delete attr", "del_tokens": "account , kind , id = record . roleid ( default_account ) . split ( ':' , 3 ) account , kind , id = record . resourceid ( default_account ) . split ( ':' , 3 ) ( record . annotations || { } ) . keys . each do | attr | new_value = record . annotations [ attr ] record . annotations . delete attr", "commit_type": "fix"}
{"commit_tokens": ["Added", "cxxflags", "option", "to", "#parse"], "add_tokens": "options . merge! ( :files => files ) @parser = Parser . new options", "del_tokens": "@parser = Parser . new :files => files , :includes => options [ :includes ]", "commit_type": "add"}
{"commit_tokens": ["Add", "management", "of", "puppet", "templates", "for", "node", "creation", "/", "deletion"], "add_tokens": "subject . create_node_checkpoint it 'should create hiera data template' do subject . create_hiera_template Bebox :: PUPPET_STEPS . each do | step | content = File . read ( \"spec/fixtures/puppet/steps/#{step}/hiera/data/#{subject.hostname}.yaml.test\" ) . strip output = File . read ( \"#{subject.project_root}/puppet/steps/#{Bebox::Puppet.step_name(step)}/hiera/data/#{subject.hostname}.yaml\" ) . strip expect ( output ) . to eq ( content ) end end it 'should create node in manifests file' do subject . create_manifests_node Bebox :: PUPPET_STEPS . each do | step | content = File . read ( \"spec/fixtures/puppet/steps/#{step}/manifests/site_with_node.pp.test\" ) . strip output = File . read ( \"#{subject.project_root}/puppet/steps/#{Bebox::Puppet.step_name(step)}/manifests/site.pp\" ) . strip expect ( output ) . to eq ( content ) end end subject . remove_checkpoints it 'should remove hiera data' do subject . remove_hiera_template Bebox :: PUPPET_STEPS . each do | step | expect ( File . exist? ( \"#{subject.project_root}/puppet/steps/#{Bebox::Puppet.step_name(step)}/hiera/data/#{subject.hostname}.yaml\" ) ) . to be ( false ) end end it 'should remove node from manifests' do subject . remove_manifests_node Bebox :: PUPPET_STEPS . each do | step | content = File . read ( \"spec/fixtures/puppet/steps/#{step}/manifests/site.pp.test\" ) . strip output = File . read ( \"#{subject.project_root}/puppet/steps/#{Bebox::Puppet.step_name(step)}/manifests/site.pp\" ) . strip expect ( output ) . to eq ( content ) end end", "del_tokens": "subject . create subject . remove", "commit_type": "add"}
{"commit_tokens": ["Updating", "version", "CHANGELOG", "and", "README", "for", "the", "all", "call", "."], "add_tokens": "VERSION = '2.0.1'", "del_tokens": "VERSION = '2.0.0'", "commit_type": "update"}
{"commit_tokens": ["removed", "debug", "print", "statement", ";", "added", "check", "in", "adjust_min_size", "method", "to", "check", "if", "desired_capacity", "-", "nodes", ".", "length", "<", "=", "0", ";", "if", "so", "set", "desired_min_size", "to", "0"], "add_tokens": "( desired_capacity - nodes . length ) <= 0 ? 0 : ( desired_capacity - nodes . length )", "del_tokens": "desired_capacity - nodes . length say_status 'Debug' , \"min_size = #{min_size}, desired_capacity = #{desired_capacity}, desired_min_size = #{desired_min_size}\" , :magenta", "commit_type": "remove"}
{"commit_tokens": ["Allow", "Project", ".", "find", "to", "be", "passed", "a", "root", "directory", "."], "add_tokens": "# @param [String] root # The project root directory to search within. # def Project . find ( root = Dir . pwd ) File . directory? ( File . join ( root , dir , CONFIG_FILE ) )", "del_tokens": "def Project . find File . directory? ( File . join ( dir , CONFIG_FILE ) )", "commit_type": "allow"}
{"commit_tokens": ["Remove", "mocking", "of", "role", "/", "system"], "add_tokens": "'systems' => { }", "del_tokens": "'systems' => { } , 'system' => nil , 'role' => nil", "commit_type": "remove"}
{"commit_tokens": ["Fix", "mass", "assignment", "protection", "in", "Rails", "4"], "add_tokens": "def attributes_with_attr_encrypted = ( * args ) perform_attribute_assignment :attributes_without_attr_encrypted= , * args end alias_method_chain :attributes= , :attr_encrypted", "del_tokens": "else def attributes_with_attr_encrypted = ( * args ) perform_attribute_assignment :attributes_without_attr_encrypted= , * args end alias_method_chain :attributes= , :attr_encrypted", "commit_type": "fix"}
{"commit_tokens": ["added", "Class", ".", "run_hook", "to", "run", "hooks", "on", "class", "layer", "."], "add_tokens": "context \"Hooks#run_hook\" do end context \"in class context\" do should \"run a callback block\" do executed = [ ] @klass . after_eight do executed << :klass end @klass . run_hook :after_eight assert_equal [ :klass ] , executed end should \"run a class methods\" do executed = [ ] @klass . instance_eval do after_eight :have_dinner def have_dinner ( executed ) executed << :have_dinner end end @klass . run_hook :after_eight , executed assert_equal [ :have_dinner ] , executed end end", "del_tokens": "context \"Hooks.run_hook\" do end", "commit_type": "add"}
{"commit_tokens": ["fix", "wrong", "constant", "value", "for", "CPU_TYPE_POWERPC"], "add_tokens": "CPU_TYPE_POWERPC = 0x12", "del_tokens": "CPU_TYPE_POWERPC = 0x24", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "multiple", "use", "of", "user_data", "change", "output", "to", "not", "include", "the", "surrounding", "brackets"], "add_tokens": "json = output . to_json json [ 0 ] = '' # remove first char: [ json . chop! # remove last char: ]", "del_tokens": "output . to_json", "commit_type": "add"}
{"commit_tokens": ["Add", "add", "a", "failing", "state", "to", "the", "dash", "spec"], "add_tokens": "self [ prop ] = value", "del_tokens": "self . send ( \"#{prop}=\" , value )", "commit_type": "add"}
{"commit_tokens": ["Add", "Rule", "module", "to", "NthDayOfMonth"], "add_tokens": "include Montrose :: Rule", "del_tokens": "def advance! ( time ) end def break? end", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "tests", "including", "failing", "test", "for", "unimplemented", "re", "-", "roll", "syntax"], "add_tokens": "rule ( :space ) { match ( '\\s' ) . repeat ( 1 ) } rule ( :space? ) { space . maybe } rule ( :comparison_op ) { str ( '>=' ) | str ( '<=' ) | str ( '==' ) | str ( '>' ) | str ( '<' ) } rule ( :ctl_string ) { match ( '[a-z_]' ) . repeat ( 1 ) } rule ( :opint_int_or_string ) { ( :comparison_op >> :integer ) | :integer | :ctl_string } rule ( :comma ) { str ( ',' ) } rule ( :param ) { :opint_int_or_string . as ( :param_value ) } rule ( :stop ) { str ( '.' ) } rule ( :complex_modifier ) { modifier_label >> str ( ':' ) >> stop } # TODO: param extraction rule ( :bunch_modifier ) { ( single_modifier >> stop . maybe ) | ( simple_modifier >> stop . maybe ) | complex_modifier }", "del_tokens": "rule ( :complex_modifier ) { modifier_label >> str ( '[' ) >> str ( ']' ) } # TODO: param extraction rule ( :bunch_modifier ) { single_modifier | simple_modifier } rule ( :space ) { match ( '\\s' ) . repeat ( 1 ) } rule ( :space? ) { space . maybe }", "commit_type": "add"}
{"commit_tokens": ["change", "the", "dsl", "to", "be", "a", "bit", "cleaner"], "add_tokens": "action :some_global_action do run 'touch test.txt' strategy :update , 'Update the code base on the server' do strategy :deploy , 'Full deployment to the server' do strategy :restart , 'Restart application' do", "del_tokens": "prerequisite :setup , :for => :update action :restart do run 'touch tmp/restert.txt' strategy :update do desc 'Update the code base on the server' strategy :deploy do desc 'Full deployment to the server' strategy :restart do desc 'Restart application'", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "partial", "reads", "from", "Subprocess#communicate"], "add_tokens": "# @yield [Array<String>] Called whenever data is read from stdout or stderr. # Arguments are an array of two elements: the data read from the # child's standard output and standard error since the last call, respectively. # @return [Array<String>, nil] An array of two elements: the data read from the # Returns nil if a block is provided. read_output = false read_output = true read_output = true if read_output && block_given? yield stdout , stderr stdout , stderr = \"\" , \"\" end if block_given? nil else [ stdout , stderr ] end", "del_tokens": "# @return [Array<String>] An array of two elements: the data read from the [ stdout , stderr ]", "commit_type": "add"}
{"commit_tokens": ["added", "spec", "for", "call", "chain"], "add_tokens": "attr_accessor :backend self . backend = I18n :: Backend :: Simple . new ( * args ) backend . translate locale , key , options backend . send ( method , * args )", "del_tokens": "@backend = I18n :: Backend :: Simple . new ( * args ) @backend . translate locale , key , options @backend . call ( method , * args )", "commit_type": "add"}
{"commit_tokens": ["remove", "global", "variable", "from", "specs", "[", "Michael", "Klishin", "]"], "add_tokens": "fixtures_dir = File . expand_path ( File . dirname ( __FILE__ ) + '/fixtures/' ) @svn_info_fixture_path = File . join ( fixtures_dir , 'svninfo' ) @diff_fixture_path = File . join ( fixtures_dir , 'some.diff' ) @info = YAML . load_file ( @svn_info_fixture_path ) @diff = File . read ( @diff_fixture_path )", "del_tokens": "@info = YAML . load_file ( $svninfo ) @diff = File . read ( $somediff )", "commit_type": "remove"}
{"commit_tokens": ["removed", "rospack", "and", "use", "rospack", "cache", "file", "or", "original", "search", "logic", "."], "add_tokens": "# ros.rb ROS :: load_manifest ( 'rosruby' )", "del_tokens": "# ros.rb this_package = ROS :: Package . new ( ROS :: Package . find_this_package ) this_package . add_path_with_depend_packages", "commit_type": "remove"}
{"commit_tokens": ["Use", "attr_reader", "for", "metadata", "of", "Crystalball", "::", "ExecutionMap"], "add_tokens": "attr_reader :commit , :type , :version delegate %i[ commit version ] => :metadata", "del_tokens": "attr_accessor :commit , :type , :version delegate %i[ commit commit= version version= ] => :metadata", "commit_type": "use"}
{"commit_tokens": ["Add", "notification", "subscription", "to", "default", "action", "bar", "content"], "add_tokens": "action_name == 'index' || action_name == 'show'", "del_tokens": "action_name == 'index'", "commit_type": "add"}
{"commit_tokens": ["update", "the", "payload", "with", "the", "proper", "contribution", "definitions", "url"], "add_tokens": "uri : \"#{MyJohnDeere.configuration.endpoint}/contributionDefinitions/#{MyJohnDeere.configuration.contribution_definition_id}\"", "del_tokens": "uri : \"#{MyJohnDeere.configuration.endpoint}/#{MyJohnDeere.configuration.contribution_definition_id}\"", "commit_type": "update"}
{"commit_tokens": ["Removed", "all", ".", "DS_Store", "files", "from", "the", "repository", ".", "Added", "ability", "to", "override", ":", "builder", "option", "."], "add_tokens": "options [ :builder ] ||= BootstrapBuilder :: Builder", "del_tokens": "options . merge! ( :builder => BootstrapBuilder :: Builder )", "commit_type": "remove"}
{"commit_tokens": ["Add", "an", "available", "locales", "accessor"], "add_tokens": "def alternate_locales available_locales - [ current_locale ] def available_locales I18n . available_locales def default_locale I18n . default_locale end", "del_tokens": "def available_locales I18n . available_locales def default_locale I18n . default_locale", "commit_type": "add"}
{"commit_tokens": ["Updated", "for", "Savon", "v2", "latest", "ruby", "via", "rvm"], "add_tokens": "require 'laundry/version' if Savon :: VERSION =~ / ^[01] \\. / Savon . configure do | config | config . log = false config . log_level = :error HTTPI . log = false end else # Savon v2 Savon . client ( log_level : :error ) Savon . client ( log : false )", "del_tokens": "require \"laundry/version\" # Don't log Laundry xmls to STDOUT. Savon . configure do | config | config . log = false config . log_level = :error HTTPI . log = false", "commit_type": "update"}
{"commit_tokens": ["Fixing", "bug", "with", "path", "name", "for", "mounted", "objects", "."], "add_tokens": "mounts [ klass . name [ start .. - 1 ] . pluralize . underscore ] = klass", "del_tokens": "mounts [ klass . name [ start .. - 1 ] . underscore ] = klass", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "install", "generator", "and", "update", "README"], "add_tokens": "# HTTP methods allowed by the WebDavRequests controller. options get put delete copy move mkcol propfind proppatch lock unlock # The realm used in HTTP Digest Authentication. @@lock_timeout_period = 86400 # The HTTP actions Calligraphy uses to create mappings between WebDAV # HTTP verbs and URLs and WebDAV controller actions. # Run `rails generate calligraphy:install` to generate a", "del_tokens": "# HTTP methods allowed by the WebDavRequestsController. options head get put delete copy move mkcol propfind proppatch lock unlock # The realm used in HTTP Basic Authentication. @@lock_timeout_period = 24 * 60 * 60 # The HTTP actions Calligraphy is responsible for handling. # Run `rails generate calligraphy_install` to generate a", "commit_type": "add"}
{"commit_tokens": ["Using", "the", "growlnotify", "utility", "instead", "of", "Eric", "Hodel", "s", "socket", "based", "version", "."], "add_tokens": "# +growlnotify+ must be installed somewhere in the path in order for the # appender to function properly. # # Mac OS X machine. @growl = \"growlnotify -n '#{@name}' -t '%s' -m '%s' -p %d\" getopt = :: Logging . options ( opts ) @coalesce = getopt [ :coalesce , false ] map = getopt [ :map ] self . map = map unless map . nil? growl ( title , message , priority ) sync { growl ( title , message , 0 ) } # call-seq: # growl( title, message, priority ) # def growl ( title , message , priority ) system @growl % [ title , message , priority ] end", "del_tokens": "require 'logging/stelan/ruby-growl' # Mac OS X machine. The options that can be used to configure the # appender are as follows: # # :host => where to send Growl notifications (localhost) # :password => password for Growl (if needed) host = opts [ :host ] || opts [ 'host' ] || 'localhost' password = opts [ :password ] || opts [ 'password' ] || nil @type = \"#{name} Notification\" @growl = :: Growl . new ( host , name , [ @type ] , [ @type ] , password ) if opts . has_key? ( 'map' ) or opts . has_key? ( :map ) self . map = opts [ :map ] || opts [ 'map' ] end @growl . notify ( @type , title , message , priority , false ) sync { @growl . notify ( @type , title , message , 0 , false ) }", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "workable", "Layout", "class"], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Change", "wrap", "to", "preserve", "newline", "character", "breaks"], "add_tokens": "def wrap ( text , wrap_at = DEFAULT_WIDTH , separator : NEWLINE ) text . lines . map do | line | format_line ( line , wrap_at , ansi_stack ) . join ( separator ) end . join # Format line to be maximum of wrap_at length # @param [String] text_line # the line to format # the maximum length to wrap the line def format_line ( text_line , wrap_at , ansi_stack ) text_length = display_width ( text_line ) UnicodeUtils . each_grapheme ( text_line ) do | char | module_function :format_line if output . end_with? ( NEWLINE ) output . insert ( - 2 , ansi_reset ) else output . insert ( - 1 , ansi_reset ) # add reset at the end end", "del_tokens": "require_relative 'fold' def wrap ( text , wrap_at = DEFAULT_WIDTH , separator : nil ) sep = separator || text [ LINE_BREAK ] || NEWLINE text . split ( %r{ #{ LINE_BREAKS } } , - 1 ) . map do | paragraph | format_paragraph ( paragraph , wrap_at , ansi_stack ) end * sep # Format paragraph to be maximum of wrap_at length # @param [String] paragraph # the paragraph to format # the maximum length to wrap the paragraph def format_paragraph ( paragraph , wrap_at , ansi_stack ) cleared_para = Fold . fold ( paragraph ) text_length = display_width ( cleared_para ) UnicodeUtils . each_grapheme ( cleared_para ) do | char | module_function :format_paragraph output . insert ( - 1 , ansi_reset ) # add reset at the end", "commit_type": "change"}
{"commit_tokens": ["updates", "to", "non", "-", "resque", "crawler"], "add_tokens": "crawler = CobwebCrawler . new ( { :cache => false , :quiet => false , :debug => false , :crawl_limit => 5 } ) it \"should take a block\" do crawler = CobwebCrawler . new ( { :cache => false , :quiet => false , :debug => false , :crawl_limit => 5 } ) statistics = crawler . crawl ( \"http://www.boeing.com/\" ) do | content | ap content [ :url ] end ap statistics end", "del_tokens": "crawler = CobwebCrawler . new ( { :cache => false , :quiet => false , :debug => false , :crawl_limit => 10 } )", "commit_type": "update"}
{"commit_tokens": ["added", "all", "the", "default", "actions", ":", ")"], "add_tokens": "@description = \"Installing Gems with Bundler\" end def call ( configuration ) @config = configuration commands", "del_tokens": "@description = \"Installing Gems with Bundler\"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "custom", "channel_data"], "add_tokens": "def subscribe ( channel_name , user_data = nil ) if user_data . is_a? Hash @user_data = user_data . to_json elsif not user_data . nil? @user_data = { :user_id => user_data } . to_json end", "del_tokens": "def subscribe ( channel_name , user_id = nil ) @user_data = { :user_id => user_id } . to_json unless user_id . nil?", "commit_type": "add"}
{"commit_tokens": ["Fix", "Capture#set_options", ":", "if", "@parse", "is", "already", "set", "to", "false", "do", "not"], "add_tokens": "if options [ :parse ] . nil? @parse = true if @parse . nil? else @parse = options [ :parse ] end", "del_tokens": "@parse = options [ :parse ] . nil? ? true : options [ :parse ]", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "typo", "(", "thanks", "ColMcp", ")", "."], "add_tokens": "Hexdump . dump ( DATA , :ascii => true ) { | index , hex , print | } Hexdump . dump ( DATA , :ascii => true , :output => OUTPUT )", "del_tokens": "Hexdump . dump ( DATA , :ascci => true ) { | index , hex , print | } Hexdump . dump ( DATA , :ascci => true , :output => OUTPUT )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "setting", "action", "custom", "properties", "via", "block", "when", "testing"], "add_tokens": "def trigger ( action_class , * args , & block ) # for setting up additional fiels, such as input yield @triggered_action if block @action_class = action_class", "del_tokens": "def trigger ( action_class , * args ) @action_class = acting_class", "commit_type": "allow"}
{"commit_tokens": ["Fix", "all", "mentions", "of", "#run_on_change"], "add_tokens": "run_on_changes ( Watcher . match_files ( self , Dir . glob ( '{,**/}*{,.*}' ) . uniq ) )", "del_tokens": "run_on_change ( Watcher . match_files ( self , Dir . glob ( '{,**/}*{,.*}' ) . uniq ) )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "to", "skip", "the", "iscsi", "disk", "lun", "in", "scanning"], "add_tokens": "$log . info \"Disk <#{disk[:name]}> is skipped due to unassigned storage domain\"", "del_tokens": "$log . warn \"Disk <#{disk[:name]}> is skipped due to unassigned storage domain\"", "commit_type": "change"}
{"commit_tokens": ["make", "sure", "num_terms", "is", "never", "less", "then", "a", "term", "index"], "add_tokens": "@all_terms += doc . words @all_terms += d . words indices . sort! { | x , y | - ( topic [ x ] <=> topic [ y ] ) }", "del_tokens": "@all_terms = @all_terms + doc . words @all_terms = @all_terms + d . words # indices.sort! {|x, y| -(topic[x] <=> topic[y])}", "commit_type": "make"}
{"commit_tokens": ["Make", "position", "attribute", "accessible", "in", "Rails", "3"], "add_tokens": "attr_accessible :survey , :question_text , :position , :validation_rules , :answer_options", "del_tokens": "attr_accessible :survey , :question_text , :validation_rules , :answer_options", "commit_type": "make"}
{"commit_tokens": ["Use", "mysql2", "because", "sqlite", "is", "weird", "on", "datetime"], "add_tokens": "ActiveRecord :: Base . establish_connection adapter : \"mysql2\" , database : \"job_iteration_test\" , username : 'root'", "del_tokens": "ActiveRecord :: Base . establish_connection adapter : \"sqlite3\" , database : \":memory:\"", "commit_type": "use"}
{"commit_tokens": ["Fix", "excessive", "post", "-", "scan", "processing", "times", "for", "very", "large", "mailboxes", "."], "add_tokens": "APP_VERSION = '1.0.0.4'", "del_tokens": "APP_VERSION = '1.0.0.3'", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "unique", "expiration", "to", "be", "a", "period", "after", "the", "at", "time", "of", "a", "job"], "add_tokens": "expires_at = ( ( Time . at ( item [ 'at' ] ) - Time . now . utc ) + expires_at ) . to_i if item [ 'at' ]", "del_tokens": "expires_at = ( ( Time . at ( item [ 'at' ] ) - Time . now . utc ) * 24 * 60 * 60 ) . to_i if item [ 'at' ]", "commit_type": "change"}
{"commit_tokens": ["allow", "for", "nil", "in", "caches"], "add_tokens": "return biblio unless if ! filename . nil? && Pathname . new ( filename ) . file? File . open ( filename , \"r\" ) do | f | biblio = JSON . parse ( f . read ) biblio [ k ] &. fetch ( \"bib\" ) and biblio [ k ] [ \"bib\" ] = from_xml ( biblio [ k ] [ \"bib\" ] ) biblio [ k ] &. fetch ( \"bib\" ) &. respond_to? :to_xml and", "del_tokens": "if ! filename . nil? && Pathname . new ( filename ) . file? File . open ( filename , \"r\" ) do | f | biblio = JSON . parse ( f . read ) end biblio [ k ] [ \"bib\" ] = from_xml ( biblio [ k ] [ \"bib\" ] ) biblio [ k ] [ \"bib\" ] . respond_to? :to_xml and", "commit_type": "allow"}
{"commit_tokens": ["Add", "notices", "for", "resources", "controller"], "add_tokens": "redirect_to send ( \"#{ @resource.model_name.route_key }_path\" ) , notice : 'Successfully Created.' redirect_to send ( \"#{ @resource.model_name.route_key }_path\" ) , notice : 'Successfully Updated.' redirect_to send ( \"#{ @resource.model_name.route_key }_path\" ) , notice : 'Successfully Destroyed.'", "del_tokens": "redirect_to send ( \"#{ @resource.model_name.route_key }_path\" ) redirect_to send ( \"#{ @resource.model_name.route_key }_path\" ) redirect_to send ( \"#{ @resource.model_name.route_key }_path\" )", "commit_type": "add"}
{"commit_tokens": ["Uses", "double", "-", "precision", "floats", "for", "sums", "(", "Sequel", "adapter", ")"], "add_tokens": "Double :sum_lat Double :sum_lng Double :ssq_lat Double :ssq_lng", "del_tokens": "Float :sum_lat Float :sum_lng Float :ssq_lat Float :ssq_lng", "commit_type": "use"}
{"commit_tokens": ["Make", "callbacks", "take", "fixed", "values"], "add_tokens": "define_singleton_method name do | * values , & block | create_callback_for ( name , * values , & block ) def create_callback_for ( name , * values , & block ) add_callback ( name ) { values } if values . any? add_callback ( name , & block ) if block end", "del_tokens": "define_singleton_method name do | & block | add_callback ( name , & block )", "commit_type": "make"}
{"commit_tokens": ["Make", "required", "attribute", "default", "to", "true", "for", "URI", "parameters", "."], "add_tokens": "def validate # required default to true for URI parameters @required = true if required . nil? super end", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Add", "video", "support", "to", "the", "string", "render"], "add_tokens": "module XmlSitemap", "del_tokens": "module XmlSitemap", "commit_type": "add"}
{"commit_tokens": ["Fix", "<nowiki", "/", ">", "parsing"], "add_tokens": "nowiki ( $1 ) def nowiki ( tag_rest ) if tag_rest . end_with? ( '/' ) Text . new ( '' ) else Text . new ( @context . scan_continued_until ( / < \\/ nowiki> / ) ) end", "del_tokens": "nowiki def nowiki Text . new ( @context . scan_continued_until ( / < \\/ nowiki> / ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "overloaded", "method", "call", "on", "MetaObject"], "add_tokens": "it 'should call the method with the same arity' do expect ( @obj . overloadedMethod ( 1 , 'foo' ) ) . to eq ( '2 params' ) end context 'when multiple methods with the same arity are provided' do it 'should call the method defined last' do expect ( @obj . overloadedMethod ( 'hoge' ) ) . to eq ( 'last' ) end", "del_tokens": "it 'should call the method that is defined last' do expect ( @obj . overloadedMethod ( 'hoge' ) ) . to eq ( 'last' )", "commit_type": "add"}
{"commit_tokens": ["change", "working", "folder", "before", "pak", "merge"], "add_tokens": "### todo: use File.expand_path( xx, relative_to ) always with second arg ## do NOT default to cwd (because cwd will change!) dirname = File . dirname ( fn ) # check: assume pwd is always absolute?? check for home dir e.g. will use ~/ ?? or not? # todo: use for File.expand_path # fix: use ordir n srcdir etec instead of newcwd and oldcwd - srcdir_restore = File . expand_path ( dirname ) orgdir_restore = File . expand_path ( Dir . pwd ) #### pak merge # nb: change cwd to template pak root @pakdir = File . dirname ( manifestsrc ) # template pak root - make availabe too in erb via binding logger . debug \" pakdir=>#{@pakdir}<\" # todo/fix: change current work dir (cwd) in pakman gem itself # for now lets do it here logger . debug \"changing cwd to pak dir - oldcwd=>#{Dir.pwd}<, newcwd=>#{@pakdir}<\" Dir . chdir ( @pakdir ) # expand output path in current dir and make sure output path exists pakpath = File . expand_path ( pakpath , orgdir_restore ) logger . debug \"pakpath=#{pakpath}\" FileUtils . makedirs ( pakpath ) unless File . directory? pakpath logger . debug \"restoring cwd to src dir - oldcwd=>#{Dir.pwd}<, newcwd=>#{srcdir_restore}<\" Dir . chdir ( srcdir_restore ) ## pop/restore org (original) working folder/dir logger . debug \"restoring cwd to org dir - oldcwd=>#{oldcwd}<, newcwd=>#{newcwd}<\" end # method create_slideshow", "del_tokens": "dirname = File . dirname ( fn ) ## pop/restore working folder/dir logger . debug \"oldcwd=>#{oldcwd}<, newcwd=>#{newcwd}<\" end", "commit_type": "change"}
{"commit_tokens": ["Added", "initial", "#to_s", "methods", "to", "Expression", "and", "one", "test"], "add_tokens": "def to_s s = @text s << @quantifier if quantified? s end def to_s @expressions . join end def to_s @text end alias :to_str :to_s def quantify ( token , text , min = nil , max = nil , mode = :greedy ) if @expressions . last . is_a? ( Sequence ) @expressions . last . last . quantify ( token , text , min , max , mode ) else @expressions . last . quantify ( token , text , min , max , mode ) end end def to_s s = @expressions . map { | e | e . to_s } . join ( '|' ) end def to_s s = @expressions . map { | e | e . to_s } . join ( '|' ) end def comment? ; false end def to_s s = @text s << @expressions . join s << ')' s << @quantifier . to_s if quantified? s # special case inheritance, for to_s class Comment < Regexp :: Expression :: Base def comment? ; true end end", "del_tokens": "#def to_s # @text #end def comment? @token == :comment class Comment < Group :: Base ; end", "commit_type": "add"}
{"commit_tokens": ["add", "options", "to", "Ref#commit", "and", "document", "it"], "add_tokens": "# Shorthand for deleting this ref. # @return [Ref] # Shorthand method to directly create a commit and update the given ref. # # @example # # setup: # dir = `mktemp -d` # repository = MultiGit.open(dir, init: true) # # insert a commit: # repository.head.commit do # tree['a_file'] = 'some_content' # end # # check result: # repository.head['a_file'].content #=> eql 'some_content' # # teardown: # `rm -rf #{dir}` # # @option options :lock [:optimistic, :pessimistic] How to lock during the commit. # @yield # @return [Ref] def commit ( options = { } , & block ) resolve . update ( options . fetch ( :lock , :optimistic ) ) do | current |", "del_tokens": "def commit ( & block ) resolve . update do | current |", "commit_type": "add"}
{"commit_tokens": ["remove", "meta", "arg", "for", "init"], "add_tokens": "schema [ 'title' ] = \" #{ FIXME - #{resource[0...1].upcase}#{resource[1..-1]}\"", "del_tokens": "if options [ :meta ] && File . exists? ( options [ :meta ] ) data . merge! ( JSON . parse ( File . read ( options [ :meta ] ) ) ) end schema [ 'title' ] = \"#{schema['title']} - #{resource[0...1].upcase}#{resource[1..-1]}\"", "commit_type": "remove"}
{"commit_tokens": ["move", "logging", "into", "its", "own", "protocol", "layer"], "add_tokens": "def initialize ( server , http_endpoint ) protocol = LIS :: Transfer :: ApplicationProtocol . new ( LIS :: Transfer :: Logging . new ( LIS :: Transfer :: ASTM :: E1394 . new ( server ) ) )", "del_tokens": "def initialize ( server , http_endpoint , protocol_stack = [ LIS :: Transfer :: ASTM :: E1394 , LIS :: Transfer :: ApplicationProtocol ] ) protocol = protocol_stack . inject ( server ) { | i , klass | klass . new ( i ) }", "commit_type": "move"}
{"commit_tokens": ["updated", "race", "and", "ethnicity", "to", "be", "hashes", "on", "Record"], "add_tokens": "field :race , type : Hash field :ethnicity , type : Hash", "del_tokens": "field :race , type : String field :ethnicity , type : String", "commit_type": "update"}
{"commit_tokens": ["fix", "tcp_port", "initialization", "in", "address"], "add_tokens": "def initialize ( ip , udp_port , tcp_port = nil , from_binary = false ) @tcp_port = addr . tcp_port if @tcp_port . nil? || @tcp_port == 0", "del_tokens": "def initialize ( ip , udp_port , tcp_port = 0 , from_binary = false ) @tcp_port = addr . tcp_port if @tcp_port == 0", "commit_type": "fix"}
{"commit_tokens": ["Added", "validate", "for", "variable", "specs", "."], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["improved", "bmp", "encoding", "by", "writing", "entire", "lines"], "add_tokens": "index = ( y * width ) * 3 output << image . pixel_data [ index .. index + width * 3 - 1 ]", "del_tokens": "width . times do | x | index = ( y * width + x ) * 3 output << image . pixel_data [ index .. index + 2 ] end", "commit_type": "improve"}
{"commit_tokens": ["added", "actual", "hashing", "of", "some", "sort", "tests", "passing", "seems", "to", "work"], "add_tokens": "require 'obfuscate_id/scatter_swap' ScatterSwap . hash ( id ) ScatterSwap . reverse_hash id", "del_tokens": "id . to_i + 100 id . to_i - 100", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Google", "Places", "API", "premium", "data"], "add_tokens": "zagat_selected = options . delete ( :zagat_selected ) || false :retry_options => retry_options , :zagat_selected => zagat_selected @zagat_reviewed = json_result_object [ 'zagat_reviewed' ] || false @zagat_selected = json_result_object [ 'zagat_selected' ] || false @aspects = aspects_component ( json_result_object [ 'aspects' ] ) def aspects_component ( json_aspects ) json_aspects . to_a . map { | r | { :type => r [ 'type' ] , :rating => r [ 'rating' ] } } end", "del_tokens": ":retry_options => retry_options", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "other", "tasks", "in", "#scaffold"], "add_tokens": "endpoint ( name ) model ( name ) schema ( name ) serializer ( name )", "del_tokens": "ep = Endpoint . new ( name , options ) ep . create_endpoint ep . create_endpoint_test ep . create_endpoint_acceptance_test md = Model . new ( name , options ) md . create_model md . create_model_migration md . create_model_test sc = Schema . new ( name , options ) sc . create_schema sc . rebuild_schema se = Serializer . new ( name , options ) se . create_serializer se . create_serializer_test", "commit_type": "use"}
{"commit_tokens": ["Make", "at", "an", "optional", "arg", "to", "passwordless_for"], "add_tokens": "def passwordless_for ( resource , at : nil , as : nil ) as : as || resource . to_s ,", "del_tokens": "def passwordless_for ( resource , at : nil ) as : resource . to_s ,", "commit_type": "make"}
{"commit_tokens": ["Fixed", "defining", "an", "alias", "before", "the", "global", "option"], "add_tokens": "@global_parameters [ alias_name ] = option_name", "del_tokens": "@global_parameters [ option_name ] = option_name", "commit_type": "fix"}
{"commit_tokens": ["added", "name", "version", "release", "defaults", "to", "wizard", "and", "image", "-", "builder"], "add_tokens": "require 'yaml' def initialize ( config = Hash . new ) @options . name = config [ :name ] || \"JBoss-Cloud Support\" @options . version = config [ :version ] || \"1.0.0.Beta3\" @options . release = config [ :release ] || \"1\" @options . dir_appliances = config [ :dir_appliances ] || \"appliances\"", "del_tokens": "DEFAULT_CONFIG = { :dir_appliances => 'appliances' } def initialize ( config ) @options . name = config [ :name ] @options . version = config [ :version ] @options . release = config [ :release ] @options . dir_appliances = config [ :dir_appliances ] || DEFAULT_CONFIG [ :dir_appliances ]", "commit_type": "add"}
{"commit_tokens": ["remove", "object", "extension", "code", "from", "threaded", "test"], "add_tokens": "", "del_tokens": "role_map . each do | _ , mod , object | if self . class . const_defined? ( mod ) object . extend ( self . class . const_get ( mod ) ) end end", "commit_type": "remove"}
{"commit_tokens": ["fixed", "issues", "with", "current", "user", "parsing"], "add_tokens": "new ( :id => result . body [ :id ] , :name => result . body [ :name ] , :email => result . body [ :email ] )", "del_tokens": "parsed_result = JSON . parse ( result . body ) new ( :id => parsed_result [ \"id\" ] . to_i , :name => parsed_result [ \"name\" ] , :email => parsed_result [ \"email\" ] )", "commit_type": "fix"}
{"commit_tokens": ["added", "new", "feature", "-", "accepts", "a", "path", "to", "a", "folder", "or", "to", "a", "filename"], "add_tokens": "@search_path = ENV [ PATH_NAMES . detect { | h | ENV [ h ] != nil } ] def search_in ( * path ) @search_path = path . first if path . any? puts \"looking for schema.rb in #{@search_path}\" @schema_paths = Array . new Find . find ( @search_path ) do | s_p | @schema_paths <<s_p if s_p [ / schema \\. rb$ / ]", "del_tokens": "@paths = PATH_NAMES . detect { | h | ENV [ h ] != nil } def search puts 'looking for schema.rb in ' + ENV [ @paths ] @schema_paths = Array . new Find . find ( ENV [ @paths ] ) do | path | @schema_paths <<path if path [ / schema \\. rb$ / ]", "commit_type": "add"}
{"commit_tokens": ["make", "analyze", "-", "xsd", "work", "on", "wsdl", "too"], "add_tokens": "when 'element' fail unless t . children . size <= 1 fail unless t [ 'name' ] if c = t . children . first ret [ 'vim25:' + t [ 'name' ] ] = analyze_complex_type c , true else fail unless t [ 'type' ] ret [ 'vim25:' + t [ 'name' ] ] = t [ 'type' ] end else fail t . name def analyze_complex_type t , nameless = false fail unless t . attributes . keys . sort == %w( name ) or nameless child = t . children . first or return XSDTypes :: Complex . new nil , { } schemas << analyze_schema ( nk . at_xpath ( './/xsd:schema' , nk . root . namespaces ) )", "del_tokens": "else fail def analyze_complex_type t fail unless t . attributes . keys . sort == %w( name ) child = t . children . first schemas << analyze_schema ( nk . at ( 'schema' ) )", "commit_type": "make"}
{"commit_tokens": ["Fix", "logic", "with", "recursive", "reference", "guard", "in", "StructuredFormatter"], "add_tokens": "object = { name : \"object\" , children : [ ] , v1 : true , v2 : true } expect ( formatted ) . to eq ( { \"name\" => \"object\" , \"children\" => [ { \"name\" => \"child_1\" } , { \"name\" => \"child_2\" , \"parent\" => { \"name\" => \"child_1\" } } ] , \"v1\" => true , \"v2\" => true } )", "del_tokens": "object = { name : \"object\" , children : [ ] } expect ( formatted ) . to eq ( { \"name\" => \"object\" , \"children\" => [ { \"name\" => \"child_1\" } , { \"name\" => \"child_2\" , \"parent\" => { \"name\" => \"child_1\" } } ] } )", "commit_type": "fix"}
{"commit_tokens": ["move", "previous", "linkedin", "api", "modeling", "classes", "to", "an", "old", "directory", "while", "I", "sort", "out", "the", "specs", "and", "new", "mashie", "/", "json", "code"], "add_tokens": "new ( doc )", "del_tokens": "new ( Nokogiri :: XML ( doc ) )", "commit_type": "move"}
{"commit_tokens": ["Adds", "test", "coverage", "for", "title"], "add_tokens": "puts_title ( title , verbose_prefix ) if block_given? @indentation_level += relative_indentation @title_level += 1 yield @indentation_level -= relative_indentation @title_level -= 1 end def puts_title ( title , verbose_prefix ) title = verbose_prefix + title if verbose? title = \"\\n#{title}\" if @title_level < 2 if ansi? && ( color = @title_colors [ title_level ] ) title = title . send ( color ) end puts \"#{title}\" end # Prints a message respecting the current indentation level and # wrapping it to the terminal width if necessary. # def puts_indented ( message = '' ) indented = wrap_string ( message , @indentation_level ) puts ( indented ) end # Prints a verbose message taking an optional verbose prefix and # a relative indentation valid for the UI action in the passed # block. # # @todo Clean interface. # def message ( message , verbose_prefix = '' , relative_indentation = 2 ) message = verbose_prefix + message if verbose? puts_indented message if verbose? @indentation_level += relative_indentation yield if block_given? @indentation_level -= relative_indentation end", "del_tokens": "title = verbose_prefix + title if verbose? title = \"\\n#{title}\" if @title_level < 2 if ( color = @title_colors [ title_level ] ) title = title . send ( color ) end puts \"#{title}\" self . indentation_level += relative_indentation self . title_level += 1 yield if block_given? self . indentation_level -= relative_indenation self . title_level -= 1", "commit_type": "add"}
{"commit_tokens": ["Remove", "ability", "upload", "to", "google", "drive", "."], "add_tokens": "URI ( request . uri ) . host == 's3.amazonaws.com'", "del_tokens": "URI ( request . uri ) . host == 's3.amazonaws.com' || URI ( request . uri ) . host . include? ( 'google' )", "commit_type": "remove"}
{"commit_tokens": ["Add", "close", "method", "to", "BufferedIO"], "add_tokens": "close # Close the BufferedIO stream def close detach if attached? @writer . detach if @writer and @writer . attached? @io . close on_close end", "del_tokens": "handle_eof def handle_eof detach if attached? @writer . detach if @writer and @writer . attached? @io . close on_close end", "commit_type": "add"}
{"commit_tokens": ["fixing", "issues", "with", "different", "db"], "add_tokens": "assert importer . result . ok? , \"Import successfull?\"", "del_tokens": "assert importer . result . ok?", "commit_type": "fix"}
{"commit_tokens": ["add", "--", "inencoding", "and", "--", "outencoding", "option"], "add_tokens": "if @@outencoding =~ / ^EUC$ /i @output . print ( NKF . nkf ( \"-W, -e\" , * s ) ) elsif @@outencoding =~ / ^SJIS$ /i @output . print ( NKF . nkf ( \"-W, -s\" , * s ) ) else @output . print ( * s ) end if @@outencoding =~ / ^EUC$ /i @output . puts ( NKF . nkf ( \"-W, -e\" , * s ) ) elsif @@outencoding =~ / ^SJIS$ /i @output . puts ( NKF . nkf ( \"-W, -s\" , * s ) ) else @output . puts ( * s ) end", "del_tokens": "@output . print ( * s ) @output . puts ( * s )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "duck", "type", "to", "handle", "methods", "that", "need", "to", "respond", "to", "certain", "methods"], "add_tokens": "def duck ( name , options = { } ) @current_inputs [ name . to_sym ] = DuckFilter . new ( options ) end", "del_tokens": "# Advanced types", "commit_type": "add"}
{"commit_tokens": ["Fix", "wrong", "style", "for", "DateTime", "columns"], "add_tokens": "when DateTime , Time %'<c r=\"#{cid}\" s=\"2\"><v>#{time_to_oa_date value}</v></c>' when Date %'<c r=\"#{cid}\" s=\"1\"><v>#{time_to_oa_date value}</v></c>'", "del_tokens": "when Date , Time , DateTime style = value . is_a? ( Date ) ? 1 : 2 %'<c r=\"#{cid}\" s=\"#{style}\"><v>#{time_to_oa_date value}</v></c>'", "commit_type": "fix"}
{"commit_tokens": ["Add", "news", "to", "the", "list", "of", "tracked", "changelog", "names"], "add_tokens": "base_names = %w( changelog history changes news )", "del_tokens": "base_names = %w( changelog history changes )", "commit_type": "add"}
{"commit_tokens": ["Updating", "maintainer", "email", "to", "remove", "beta", "since", "Workstation", "is", "going", "GA"], "add_tokens": "maintainer_email \"workstation@chef.io\"", "del_tokens": "maintainer_email \"beta@chef.io\"", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "escaped", "attribute", "values", "."], "add_tokens": "# # # :escape_attrs=><em>true_or_false</em>:: # If true, attributes will automatically be escaped in the # output. If false (the default), attributes will not be # escaped. # @escape_attrs = options [ :escape_attrs ] || false @target << %{ #{k}=\"#{_attr_value(v)}\"} if v @target << %{ #{k}=\"#{_attr_value(v)}\"} unless order . member? ( k ) def _attr_value ( value ) @escape_attrs ? _escape_quote ( value ) : value end", "del_tokens": "@target << %{ #{k}=\"#{v}\"} if v @target << %{ #{k}=\"#{v}\"} unless order . member? ( k )", "commit_type": "add"}
{"commit_tokens": ["Fix", "spec", "that", "might", "be", "causing", "ruby", "-", "head", "failures"], "add_tokens": "let ( :bad_signature ) { sig = signature ; sig [ 0 ] = ( sig [ 0 ] . ord + 1 ) . chr ; sig } end", "del_tokens": "let ( :bad_signature ) { signature [ 0 ... 63 ] + \"X\" } end", "commit_type": "fix"}
{"commit_tokens": ["Use", "regular", "expressions", "to", "split", "methods", "from", "signatures", "."], "add_tokens": "# TODO: Experimental loading of all gems #Bundler.load.specs.each { |s| # unless used.include?(s.name) # used.push s.name # gy = YARD::Registry.yardoc_file_for_gem(s.name) # yardocs.push gy unless gy.nil? # end #} n = m . to_s . split ( / [ \\. #] / ) . last n = m . to_s . split ( / [ \\. #] / ) . last", "del_tokens": "n = m . to_s . split ( '.' ) . last n = m . to_s . split ( '#' ) . last", "commit_type": "use"}
{"commit_tokens": ["Change", "indentation", "to", "stop", "mutating", "input"], "add_tokens": "line = Array ( line ) [ 0 ] ' ' * indentation + line . to_s if line", "del_tokens": "# encoding: utf-8 line = line . is_a? ( Array ) ? line [ 0 ] : line line . insert ( 0 , ' ' * indentation ) if line", "commit_type": "change"}
{"commit_tokens": ["Added", "separator", "as", "second", "arg", "of", "split_commandline_args"], "add_tokens": "# Splits an array `args` a separator, the option separator # '--' by default. def self . split_commandline_args ( args , separator = '--' ) if ( x = args . shift ) == separator", "del_tokens": "# Splits an array `args` on '--' option separator. def self . split_commandline_args ( args ) if ( x = args . shift ) == \"--\"", "commit_type": "add"}
{"commit_tokens": ["added", ":", "track", "to", "the", "default", "options", "hash"], "add_tokens": "access_token_secret : '' , track : [ ]", "del_tokens": "access_token_secret : ''", "commit_type": "add"}
{"commit_tokens": ["fix", "tests", "for", "older", "rubies"], "add_tokens": "candidate : lambda { | input | input . marshal_dump }", "del_tokens": "candidate : Proc . new { | input | input . to_h }", "commit_type": "fix"}
{"commit_tokens": ["moved", "faraday", "middleware", "into", "the", "zipkin", "client", "gem"], "add_tokens": "VERSION = \"0.5.0\"", "del_tokens": "VERSION = \"0.4.0\"", "commit_type": "move"}
{"commit_tokens": ["Add", "clear_char", "for", "erasing", "characters", "."], "add_tokens": "# Erase n characters from the current cursor position # @api public def clear_char ( n = nil ) ECMA_CSI + \"#{n}X\" end # Erase the entire current line and return to beginning of the line", "del_tokens": "# Clear current line", "commit_type": "add"}
{"commit_tokens": ["Added", "basic", "index", "-", "access", "to", "vertices", "and", "edges"], "add_tokens": "d . vertices . size . should eq ( 1 ) end it \"should allow connecting trough indexes\" do v0 , v1 , edge = nil , nil , nil d = Digraph . new { | d | v0 , v1 = d . add_n_vertices ( 2 ) edge = d . connect ( v0 , v1 ) } edge . source . should eq ( v0 ) edge . target . should eq ( v1 ) end it \"should have a ith_vertex and ith_edge methods\" do d = Digraph . new { | d | d . add_n_vertices ( 2 ) ; d . connect ( 0 , 1 ) } d . ith_vertex ( 0 ) . index . should eq ( 0 ) d . ith_vertex ( 1 ) . index . should eq ( 1 ) d . ith_edge ( 0 ) . index . should eq ( 0 ) end it \"should accept integers as vertices selectors\" do d = Digraph . new { | d | d . add_n_vertices ( 2 ) ; d . connect ( 0 , 1 ) } d . vertices ( 1 ) . collect { | v | v . index } . should eq ( [ 1 ] )", "del_tokens": "d . vertices . size . should == 1", "commit_type": "add"}
{"commit_tokens": ["Removed", "active", "support", "dependencies", "in", "Logger"], "add_tokens": "def logger CrashLog . logger end", "del_tokens": "require 'active_support/core_ext/module/delegation' require 'active_support/core_ext/module/aliasing' delegate :logger , :to => CrashLog", "commit_type": "remove"}
{"commit_tokens": ["fix", "some", "ZMQ", "regressions", "after", "refactoring"], "add_tokens": "ZMachine . logger . debug ( \"zmachine:connection:#{__method__}\" , connection : self ) if ZMachine . debug", "del_tokens": "ZMachine . logger . debug ( \"zmachine:connection:#{__method__}\" , connection : self , data : data ) if ZMachine . debug", "commit_type": "fix"}
{"commit_tokens": ["add", ".", "inspect", "to", "source", "debug", "message"], "add_tokens": "Engine . logger . debug \"Processing source #{source.inspect}\" end", "del_tokens": "Engine . logger . debug \"Processing source #{source}\" end", "commit_type": "add"}
{"commit_tokens": ["Added", "block", "to", "sort_by_ancestry", "class", "method", "."], "add_tokens": "# for ordering nodes within a rank provide block, eg. Node.sort_by_ancestry(Node.all) {|a, b| a.rank <=> b.rank}. def sort_by_ancestry ( nodes , & block ) arranged = nodes if nodes . is_a? ( Hash ) unless arranged presorted_nodes = nodes . sort do | a , b | a_cestry , b_cestry = a . ancestry || '0' , b . ancestry || '0' if block_given? && a_cestry == b_cestry yield a , b else a_cestry <=> b_cestry end end arranged = arrange_nodes ( presorted_nodes ) end sorted_nodes += sort_by_ancestry ( children , & block ) unless children . blank?", "del_tokens": "# but the ordering of nodes within a rank depends on their order in the # array that gets passed in def sort_by_ancestry ( nodes ) arranged = nodes . is_a? ( Hash ) ? nodes : arrange_nodes ( nodes . sort_by { | n | n . ancestry || '0' } ) sorted_nodes += sort_by_ancestry ( children ) unless children . blank?", "commit_type": "add"}
{"commit_tokens": ["Remove", "top", "-", "level", "concept", "of", "form", "groups"], "add_tokens": "# Use the map to set up form groups Metadata :: Ingest :: Form . internal_groups = translation_map . keys . collect ( & :to_s )", "del_tokens": "# This has WAY too much setup - figure out something better!", "commit_type": "remove"}
{"commit_tokens": ["Added", "test", "to", "check", "order", "added", "has", "no", "effect", "."], "add_tokens": "it 'should correctly order interdependent objects regardless of order added' do # Add dependencies @graph . add_dependency @dependency_a @graph . add_dependency @dependency_b , [ @dependency_a ] @graph . add_dependency @dependency_c , [ @dependency_b , @dependency_a ] # Check order sorted_objects = @graph . resolved_dependencies sorted_objects [ 0 ] . should == @dependency_a sorted_objects [ 1 ] . should == @dependency_b sorted_objects [ 2 ] . should == @dependency_c end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["change", "DSL", "to", "get", "included", "to", "Profile"], "add_tokens": "module Dsl @in_file = File . expand_path ( file ) @out_file = File . expand_path ( file ) puts @out_file puts @in_file key = Hash . new ( 0 ) File . foreach ( @in_file ) do | line | next if line . chomp . empty? values = line . split ( ';' ) key_column = options [ :key_column ] data_columns = options [ :data_columns ] yield values [ key_column ] , values . values_at ( * data_columns ) end", "del_tokens": "module Sycsvpro key_column = options [ :key_column ] data_columns = options [ :data_columns ] yield", "commit_type": "change"}
{"commit_tokens": ["Remove", "verbose", "output", "from", "rack", "/", "cache", "and", "add", "verbose", "output", "for", "test", "/", "unit"], "add_tokens": ":verbose => false ,", "del_tokens": ":verbose => true ,", "commit_type": "remove"}
{"commit_tokens": ["Add", "test", "for", "pre_block", "k", "/", "v", "pairs"], "add_tokens": "def pre_block k \"l\" end def post_block super expect ( h [ :Resources ] [ :R ] ) . to have_key :K expect ( h [ :Resources ] [ :R ] [ :K ] ) . to eq ( \"l\" )", "del_tokens": "def post_block", "commit_type": "add"}
{"commit_tokens": ["Add", "array", "transformations", "(", "ported", "from", "rom", ")"], "add_tokens": "self . class . new ( -> * result { other [ fn [ * result ] ] } , args )", "del_tokens": "self . class . new ( -> value { other [ fn [ value ] ] } )", "commit_type": "add"}
{"commit_tokens": ["Use", "#each", "instead", "of", "for", "."], "add_tokens": "patterns . each do | pattern | if match = pattern [ \"regex\" ] . match ( value ) return [ pattern , match ]", "del_tokens": "for p in patterns if m = p [ \"regex\" ] . match ( value ) return [ p , m ]", "commit_type": "use"}
{"commit_tokens": ["Allow", "the", "path", "to", "the", "Xcode", "project", "file", "to", "be", "customized", "."], "add_tokens": ":xcodebuild_path => \"xcodebuild\" , :project_file_path => nil args = \"-target '#{target}' -configuration '#{configuration}' -sdk iphoneos\" args << \" -project #{project_file_path}\" if project_file_path", "del_tokens": ":xcodebuild_path => \"xcodebuild\" \"-target '#{target}' -configuration '#{configuration}' -sdk iphoneos\"", "commit_type": "allow"}
{"commit_tokens": ["use", "autoload", "to", "load", "MiniTests", "emulation", "of", "TestUnit"], "add_tokens": "autoload \"Test\" , 'test/unit' #Test = MiniTest", "del_tokens": "Test = MiniTest", "commit_type": "use"}
{"commit_tokens": ["remove", "block", "form", "#run", "definition"], "add_tokens": "def run ( manifest , prefix , source , destination , tag , type , config )", "del_tokens": "def run ( manifest , prefix , source , destination , tag , type , config , & block )", "commit_type": "remove"}
{"commit_tokens": ["Added", "spec", "for", "urls", "with", "no", "scheme", ".", "Added", "wordpress", "page", "for", "meta", "generator", "test"], "add_tokens": "FakeWeb . register_uri ( :get , \"pagerankalert.com\" , :response => fixture_file ( \"pagerankalert.com.response\" ) ) FakeWeb . register_uri ( :get , \"http://www.inkthemes.com/\" , :response => fixture_file ( \"wordpress_site.response\" ) ) MetaInspector . new ( 'pagerankalert.com' ) . scheme . should == 'http' MetaInspector . new ( 'pagerankalert.com' ) . host . should == 'pagerankalert.com' MetaInspector . new ( 'pagerankalert.com' ) . root_url . should == 'http://pagerankalert.com/' it \"should get the generator meta tag\" do @m = MetaInspector . new ( 'http://www.inkthemes.com/' ) @m . meta_generator . should == 'WordPress 3.4.2' end good = MetaInspector . new ( 'https://www.markupvalidator.com/' )", "del_tokens": "it \"should get the generator meta tag\" do pending \"mocks\" @m . meta_generator . should == 'WordPress 2.8.4' end good = MetaInspector . new ( 'https://www.w3clove.com' )", "commit_type": "add"}
{"commit_tokens": ["Remove", "options", "from", "origin", "as", "underlying", "drivers", "will", "differ"], "add_tokens": "attr_reader :selector selector == other . selector @selector = Selector . new @selector = other . selector . __deep_copy__", "del_tokens": "require \"origin/optional\" require \"origin/options\" include Optional attr_reader :options , :selector selector == other . selector && options == other . options @options , @selector = Options . new , Selector . new @options , @selector = other . options . __deep_copy__ , other . selector . __deep_copy__", "commit_type": "remove"}
{"commit_tokens": ["added", "hours_without_timer", "property", "added", "to", "time_etry"], "add_tokens": "property :hours_without_timer end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "breakage", "with", "renaming", "api", "calls", "and", "compilation", "errors"], "add_tokens": "Dep_gecode . GetPackageAFC ( problem , packageId ) . should == 0 Dep_gecode . GetPackageMax ( problem , packageId ) . should == 2 Dep_gecode . GetPackageMin ( problem , packageId ) . should == 0 Dep_gecode . GetPakageAFC ( problem , packageId ) . should == 0 Dep_gecode . GetPackageMax ( problem , packageId ) . should == 6 Dep_gecode . GetPackageMin ( problem , packageId ) . should == 1", "del_tokens": "Dep_gecode . GetAFC ( problem , packageId ) . should == 0 Dep_gecode . GetMax ( problem , packageId ) . should == 2 Dep_gecode . GetMin ( problem , packageId ) . should == 0 Dep_gecode . GetAFC ( problem , packageId ) . should == 0 Dep_gecode . GetMax ( problem , packageId ) . should == 6 Dep_gecode . GetMin ( problem , packageId ) . should == 1", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "providing", "pem", "file", "at", "unexpanded", "path"], "add_tokens": "if key =~ / (.+) \\. pem$ / || File . exists? ( File . expand_path ( key ) )", "del_tokens": "if key =~ / (.+) \\. pem$ / || File . exists? ( key )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "for", "declaring", "a", "view", "path"], "add_tokens": "# Rabl::Engine.new(\"...source...\", { :format => \"xml\", :root => true, :view_path => \"/path/to/views\" }) self . copy_instance_variables_from ( @_scope , [ :@assigns , :@helpers ] ) view_path = @_options [ :view_path ] || File . join ( root_path , \"app/views/\" )", "del_tokens": "# Rabl::Engine.new(\"...source...\", { :format => \"xml\" }) self . copy_instance_variables_from ( @_scope , [ :@assigns , :@helpers ] ) ; view_path = File . join ( root_path , \"app/views/\" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "customize", "CSS", "classes", "."], "add_tokens": "@css_class ||= { highlight : \"highlight\" , plain : \"plain\" , key : \"key\" , keyword : \"keyword\" , string : \"string\" , numeric : \"numeric\" , comment : \"comment\" , } attr_accessor :css_class @output << \"<div class=\\\"#{css_class[:highlight]}\\\"><pre>\" result << span ( css_class [ :key ] , key . to_s . inspect ) << plain_text ( \":\" ) << \" \" css_class [ :keyword ] css_class [ :string ] css_class [ :numeric ] css_class [ :plain ] span ( css_class [ :plain ] , text ) span ( css_class [ :comment ] , \"// #{s}\" )", "del_tokens": "@output << %q{<div class=\"highlight\"><pre>} result << span ( \"key\" , key . to_s . inspect ) << plain_text ( \":\" ) << \" \" \"keyword\" \"string\" \"numeric\" \"plain\" span ( \"plain\" , text ) span ( \"comment\" , \"// #{s}\" )", "commit_type": "allow"}
{"commit_tokens": ["added", "hints", "about", "using", "StringIO"], "add_tokens": "# +file+ is a filename or an IO object. Hint: use StringIO when working with slurped data like blobs.", "del_tokens": "# +file+ is a filename or an IO object.", "commit_type": "add"}
{"commit_tokens": ["allow", "Spy#and_return", "s", "blocks", "accept", "blocks"], "add_tokens": "def and_return ( value = nil ) raise ArgumentError . new ( \"value and block conflict. Choose one\" ) if block_given? elsif block_given? @plan = Proc . new else self if @plan @plan . call ( * args , & block ) end", "del_tokens": "def and_return ( value = nil , & block ) raise ArgumentError . new ( \"value and block conflict. Choose one\" ) if block elsif block @plan = block self @plan . call ( * args , & block ) if @plan", "commit_type": "allow"}
{"commit_tokens": ["Add", "a", "custom", "label", "test", "."], "add_tokens": "test 'builder should allow overriding default input type for text' do test 'builder should use custom label' do with_form_for :name , :label => 'Yay!' assert_no_select 'form label' , 'Yay!' end", "del_tokens": "test 'builder should allow overriding default input type' do", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "storing", "tokens", "as", "hashes", "in", "the", "database"], "add_tokens": "attr_accessor :temporary_token self . temporary_token = SecureRandom . base64 ( 32 ) self . token_hash = self . class . hash_token ( self . temporary_token ) :value => self . temporary_token , if cookies [ :user_session ] && session = self . active . where ( :token_hash => self . hash_token ( cookies [ :user_session ] ) ) . first session . temporary_token = cookies [ :user_session ] # Return a hash of a given token def self . hash_token ( token ) Digest :: SHA256 . hexdigest ( token ) end", "del_tokens": "self . token = SecureRandom . base64 ( 32 ) :value => token , if cookies [ :user_session ] && session = self . active . where ( :token => cookies [ :user_session ] ) . first", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "tzdata", "version", "2006n", "."], "add_tokens": "tz . transition 2006 , 10 , :o2 , 1159682400", "del_tokens": "tz . transition 2006 , 10 , :o2 , 1159678800", "commit_type": "update"}
{"commit_tokens": ["allow", "usage", "with", "missing", "lono", "params", "file"], "add_tokens": "allow_no_file : true ) errors , warns = check_files puts \"ERROR: #{errors.join(\"\\n\")}\" . colorize ( :red ) unless errors . empty? puts \"Please double check the command you ran. There were some warnings.\" puts \"WARN: #{errors.join(\"\\n\")}\" . colorize ( :yellow ) end errors , warns = [ ] , [ ] warns << \"Parameters file missing: could not find #{@params_path}\" [ errors , warns ] format = detect_format \"#{@project_root}/output/#{name}.#{format}\" # Returns String with value of \"yml\" or \"json\". def detect_format formats = Dir . glob ( \"#{@project_root}/output/**/*\" ) . map { | path | path } . reject { | s | s =~ %r{ /params/ } } . # reject output/params folder map { | path | File . extname ( path ) } . reject { | s | s . empty? } . # reject \"\" uniq if formats . size > 1 puts \"ERROR: Detected multiple formats: #{formats.join(\", \")}\" . colorize ( :red ) puts \"All the output files must use the same format. Either all json or all yml.\" exit 1 else formats . first . sub ( / ^ \\. / , '' ) end end", "del_tokens": "allow_no_file : false ) errors = check_files puts \"#{errors.join(\"\\n\")}\" errors = [ ] errors << \"Parameters file missing: could not find #{@params_path}\" errors \"#{@project_root}/output/#{name}.json\"", "commit_type": "allow"}
{"commit_tokens": ["Made", "instantiate", "public", "(", "but", "undocumented", ")"], "add_tokens": "def instantiate ( attributes ) #:nodoc: return subclass . instantiate ( attributes ) # private :instantiate", "del_tokens": "def instantiate ( attributes , namespace = nil ) #:nodoc: return subclass . send ( :instantiate , attributes , namespace ) private :instantiate", "commit_type": "make"}
{"commit_tokens": ["Removed", "comments", "from", "RSpec", "configuration", "in", "spec", "/", "spec_helper", ".", "rb", "."], "add_tokens": "config . profile_examples = 3", "del_tokens": "# Print the 10 slowest examples and example groups at the # end of the spec run, to help surface which specs are running # particularly slow. config . profile_examples = 10 # Run specs in random order to surface order dependencies. If you find an # order dependency and want to debug it, you can fix the order by providing # the seed, which is printed after each run. # --seed 1234 # Seed global randomization in this process using the `--seed` CLI option. # Setting this allows you to use `--seed` to deterministically reproduce # test failures related to randomization by passing the same `--seed` value # as the one that triggered the failure. # rspec-expectations config goes here. You can use an alternate # assertion/expectation library such as wrong or the stdlib/minitest # assertions if you prefer. # Enable only the newer, non-monkey-patching expect syntax. # For more details, see: # - http://myronmars.to/n/dev-blog/2012/06/rspecs-new-expectation-syntax # rspec-mocks config goes here. You can use an alternate test double # library (such as bogus or mocha) by changing the `mock_with` option here. # Enable only the newer, non-monkey-patching expect syntax. # For more details, see: # - http://teaisaweso.me/blog/2013/05/27/rspecs-new-message-expectation-syntax/ # Prevents you from mocking or stubbing a method that does not exist on # a real object. This is generally recommended.", "commit_type": "remove"}
{"commit_tokens": ["Add", "changelog", "and", "bump", "version", "number"], "add_tokens": "VERSION = \"0.4.0\"", "del_tokens": "VERSION = \"0.3.2\"", "commit_type": "add"}
{"commit_tokens": ["Added", "empty_table", "to", "test", "schema", "."], "add_tokens": "def self . from_rows ( rows ) rows . map { | r | self . new ( r ) } end self . from_rows ( dbh . select_all ( sql , * params ) ) end def self . all self . from_rows ( dbh . select_all ( \"SELECT * FROM #{table}\" ) )", "del_tokens": "dbh . select_all ( sql , * params ) . map { | r | self . new ( r ) }", "commit_type": "add"}
{"commit_tokens": ["Create", "environment", "index", "in", "after", "initializer"], "add_tokens": "attr_writer :assets # No more configuration changes at this point. # With cache classes on, Sprockets won't check the FS when files # change. Preferable in production when the FS only changes on # deploys when the app restarts. if app . config . cache_classes app . assets = app . assets . index end", "del_tokens": "if config . cache_classes @assets = @assets . index end", "commit_type": "create"}
{"commit_tokens": ["Making", "sure", "no", "unnecessary", "params", "are", "passed", "to", "the", "Request"], "add_tokens": "option_hash = \"options ||= {} \\n\" code << option_hash code << %Q{ options[:query] = params unless params.empty? \\n } code << option_hash code << %Q{ options[:body] = params \\n } if hash [ key ] [ :with ] with = \"[\" hash [ key ] [ :with ] . each { | x | with << \":#{x},\" } with << \"]\" code << %Q{ unnecessary = params.keys - #{with} \\n } code << %Q{ unnecessary.each { |x| params.delete(x) } \\n} end code << %Q{ raise ArgumentError, \":#{required} is a required parameter.\" unless params.has_key?(:#{required}) \\n } code << %Q{ p :#{hash[key][:via]} \\n }", "del_tokens": "code << %Q{ options ||= {} \\n } code << %Q{ options[:query] = params unless params.empty? \\n} code << %Q{ options ||= {} \\n } code << %Q{ options[:body] = params \\n} code << %Q{ raise ArgumentError, \"Lacks Required: :#{required}\" unless params.has_key?(\"#{required}\".to_sym) \\n } code << %Q{ p \"#{hash[key][:via]}\".to_sym \\n }", "commit_type": "make"}
{"commit_tokens": ["allow", "using", "preexisting", "struct", "class"], "add_tokens": "module ValueExtensions attribute_klass = if options . key? ( :class_name ) _klass = options [ :class_name ] . constantize _klass . include ( ValueExtensions ) _klass else :: Trax :: Core :: NamedClass . new ( klass_name , Value , :parent_definition => klass , & block ) end include ValueExtensions", "del_tokens": "module ValueMethods attribute_klass = :: Trax :: Core :: NamedClass . new ( klass_name , Value , :parent_definition => klass , & block ) include ValueMethods", "commit_type": "allow"}
{"commit_tokens": ["fixed", "typo", "in", "module", "include"], "add_tokens": "include Elephrame :: AllInteractions", "del_tokens": "include Elephrame :: Interacter", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "incorrect", "mkdir_p", "call", "with", "correct", "path", "before", "creating", "the", "zip", "file", ".", "Normally", "on", "non", "-", "Windows", "platform", "this", "does", "not", "cause", "trouble", "(", "just", "extra", "sub", "-", "directories", "created", ")", ".", "But", "on", "Windows", "since", "the", "path", "would", "contain", "drive", "like", "C", ":", "which", "would", "failed", "the", "call", "to", "mkdir_p", "."], "add_tokens": "FileUtils . mkdir_p ( dirpath )", "del_tokens": "FileUtils . mkdir_p ( File . join ( dirpath , zippath ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "WebClient", ".", "escape", "method", "see", "method", "comment"], "add_tokens": "self . class . escape ( s ) # Fuckin 1C is bad understand of CGI.escape. # From escaping exclude: =& # and ' ' replaced on '%20' def self . escape ( string ) string . gsub ( / ([^ a-zA-Z0-9_. \\- =&]+) / ) do '%' + $1 . unpack ( 'H2' * $1 . bytesize ) . join ( '%' ) . upcase end . gsub ( ' ' , '%20' ) end", "del_tokens": "s . gsub ( / \\s / , '%20' )", "commit_type": "add"}
{"commit_tokens": ["fixed", "spec", ";", ":", "uniqueness", "validator", "not", "working", "with", "tenant", "scope"], "add_tokens": "create_table :countries , :force => true do | t | t . column :name , :string end class Country < ActiveRecord :: Base acts_as_tenant :account class City < ActiveRecord :: Base validates_uniqueness_of :name #validates :name, :uniqueness => true end describe 'When using validates :uniqueness => true in a aat model' do before do @account = Account . create! ( :name => 'foo' ) ActsAsTenant . current_tenant = @account @country1 = Country . create! ( :name => 'bar' ) end it 'should not be possible to create a duplicate within the same tenant' do @project2 = Country . create ( :name => 'bar' ) . valid? . should == false end it 'should be possible to create a duplicate outside the tenant scope' do @other_account = Account . create! ( :name => 'baz' ) ActsAsTenant . current_tenant = @other_account @country2 = Country . create ( :name => 'bar' ) . valid? . should == true end end", "del_tokens": "class City < ActiveRecord :: Base #validates_uniqueness_of :name", "commit_type": "fix"}
{"commit_tokens": ["add", "which", "method", "to", "File"], "add_tokens": "class File # extend the File class to add File::which method. # returns the full path to the supplied cmd, # if it exists in any location in PATH def self . which ( cmd ) exts = ENV [ 'PATHEXT' ] ? ENV [ 'PATHEXT' ] . split ( ';' ) : [ '' ] ENV [ 'PATH' ] . split ( File :: PATH_SEPARATOR ) . each do | path | exts . each { | ext | exe = File . join ( path , \"#{cmd}#{ext}\" ) return exe if File . executable? exe } end return nil end", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["Fix", "JSON", "serialization", "and", "absolute", "URIs"], "add_tokens": "# If an absolute URI already if ( uri = parts . first ) && uri . is_a? ( URI ) return uri if uri . host end def as_json ( * ) to_hash end", "del_tokens": "alias_method :as_json , :to_hash", "commit_type": "fix"}
{"commit_tokens": ["Change", "repository", "commands", "to", "new", "dsl", "update", "documentation", "."], "add_tokens": "github_api . repos . list params github_api . repos . get user , repo , params def create ( params ) github_api . repos . create user , repo , params def edit ( user , repo , params ) github_api . repos . edit user , repo , params", "del_tokens": "github_api . repos . repos ( params ) github_api . repos . get_repo user , repo , params def create ( user , repo , params ) github_api . repos . create_repo user , repo , params def edit github_api . repos . edit_repo user , repo , params", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "respond_to?", "def", "on", "Company"], "add_tokens": "def respond_to? ( method , include_private = false )", "del_tokens": "def respond_to? ( method )", "commit_type": "fix"}
{"commit_tokens": ["Create", "Request", ".", "to_s", "which", "returns", "an", "indented", "copy", "of", "the", "eBay", "API", "response", "body", "."], "add_tokens": "@xml_response = response . body end # Get a String representation of the response XML with indentation. # @return [String] the response XML. def to_s ( indent = xml_tab_width ) xml = '' ox_doc = Ox . parse ( xml_response ) xml = Ox . dump ( ox_doc , indent : indent ) rexml_doc = REXML :: Document . new ( xml_response ) rexml_doc . write ( xml , indent ) xml", "del_tokens": "ox_doc = Ox . parse ( response . body ) @xml_response = Ox . dump ( ox_doc , indent : xml_tab_width ) rexml_doc = REXML :: Document . new ( response . body ) rexml_doc . write ( @xml_response , xml_tab_width )", "commit_type": "create"}
{"commit_tokens": ["Fix", "alignment", "in", "GLPK", "struct"], "add_tokens": "# Integer optimization control parameters :br_tech , :int , :bt_tech , :int , :tol_int , :double , :tol_obj , :double , :tm_lim , :int , :out_frq , :int , :out_dly , :int , :cb_func , callback ( [ :pointer , :pointer ] , :void ) , :cb_info , :pointer , :cb_size , :int , :pp_tech , :int , :mip_gap , :double , :mir_cuts , :int , :gmi_cuts , :int , :cov_cuts , :int , :clq_cuts , :int , :presolve , :int , :binarize , :int , :fp_heur , :int , :alien , :int , :foo_bar , [ :double , 29 ]", "del_tokens": ":br_tech , :int , :bt_tech , :int , :tol_int , :double , :tol_obj , :double , :tm_lim , :int , :out_frq , :int , :out_dly , :int , :cb_func , callback ( [ :pointer , :pointer ] , :void ) , :cb_info , :pointer , :cb_size , :int , :pp_tech , :int , :mip_gap , :double , :mir_cuts , :int , :gmi_cuts , :int , :cov_cuts , :int , :clq_cuts , :int , :presolve , :int , :binarize , :int , :fp_heur , :int , :alien , :int , :foo_bar , [ :double , 29 ]", "commit_type": "fix"}
{"commit_tokens": ["make", "the", "StreamReader", "return", "the", "Header", "as", "well"], "add_tokens": "@in_header = false @fragment = StringIO . new when \"Header\" @in_header = true @fragment = StringIO . new @fragment << \"<Header>\" @fragment = StringIO . new @fragment << \"<Product>\" @fragment << \"<#{name}>\" if @in_product || @in_header @fragment << CGI :: escapeHTML ( text ) if @in_product || @in_header when \"Header\" # The header tag is finished, so add it to the queue @fragment << \"</Header>\" begin element = REXML :: Document . new ( @fragment . string ) . root header = ONIX :: Header . load_from_xml ( element ) @queue . push ( header ) unless header . nil? rescue Exception => e # error occurred while building the product from an XML fragment # pop the error on the queue so it can be raised by the thread # reading items off the queue @queue . push ( e ) end @in_header = false @fragment << \"</Product>\" element = REXML :: Document . new ( @fragment . string ) . root @fragment << \"</#{name}>\" if @in_product || @in_header Thread . abort_on_exception = true", "del_tokens": "@product_fragment = StringIO . new @product_fragment << \"<Product>\" @product_fragment << \"<#{name}>\" if @in_product @product_fragment << CGI :: escapeHTML ( text ) if @in_product @product_fragment << \"</Product>\" element = REXML :: Document . new ( @product_fragment . string ) . root @product_fragment << \"</#{name}>\" if @in_product", "commit_type": "make"}
{"commit_tokens": ["Made", "the", "Lotus", "::", "Application", ".", "configure", "block", "to", "be", "evaluated", "only", "when", "an", "application", "is", "being", "loaded"], "add_tokens": "@blk = blk || Proc . new { } end # @api private def load! instance_eval ( & @blk ) self @root = value Utils :: Kernel . Pathname ( @root || Dir . pwd ) . realpath", "del_tokens": "instance_eval ( & blk ) if block_given? @root = Utils :: Kernel . Pathname ( value ) . realpath @root", "commit_type": "make"}
{"commit_tokens": ["Remove", "semi", "colon", "and", "correct", "some", "indentation"], "add_tokens": "stub_request ( :get , \"https://api.digitalocean.com/droplets?api_key=#{api_key}&client_id=#{client_key}\" ) . to_return ( :status => 200 , :body => \"<html>You are being redirected...</html>\" )", "del_tokens": "stub_request ( :get , \"https://api.digitalocean.com/droplets?api_key=#{api_key}&client_id=#{client_key}\" ) . to_return ( :status => 200 , :body => \"<html>You are being redirected...</html>\" )", "commit_type": "remove"}
{"commit_tokens": ["Use", "lambda", "instead", "of", "Proc", ".", "new"], "add_tokens": "User . encrypts :password , :if => lambda { false } User . encrypts :password , :if => lambda { true } User . encrypts :password , :unless => lambda { true } User . encrypts :password , :unless => lambda { false }", "del_tokens": "User . encrypts :password , :if => Proc . new { false } User . encrypts :password , :if => Proc . new { true } User . encrypts :password , :unless => Proc . new { true } User . encrypts :password , :unless => Proc . new { false }", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "raise", "of", "NotImplementedError", "in", "ObjectManager"], "add_tokens": "raise NotImplementedError , 'The ObjectManager class should be inherited and its methods overriden' raise NotImplementedError , 'You must implement ObjectManager#store' raise NotImplementedError , 'You must implement ObjectManager#retrieve' raise NotImplementedError , 'You must implement ObjectManager#include?'", "del_tokens": "raise NotImplementedError ( 'The ObjectManager class should be inherited and its methods overriden' ) raise NotImplementedError ( 'You must implement ObjectManager#store' ) raise NotImplementedError ( 'You must implement ObjectManager#retrieve' ) raise NotImplementedError ( 'You must implement ObjectManager#include?' )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "how", "Component#install", "mv", "works", "."], "add_tokens": "FileUtils . mv source_path , install_path", "del_tokens": "FileUtils . mv \"#{source_path}/.\" , install_path", "commit_type": "fix"}
{"commit_tokens": ["changed", "the", "restart", "shorcut", "from", "r!", "to", "rs"], "add_tokens": "alias_method :rs , :restart", "del_tokens": "alias_method :r! , :restart", "commit_type": "change"}
{"commit_tokens": ["adding", "file", "checkbox", ".", "rb", "and", "initial", "commit"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "Rack", "::", "Accept", "::", "MediaType", "for", "mime", "type", "check"], "add_tokens": "accept = Rack :: Accept :: MediaType . new ( env [ 'HTTP_ACCEPT' ] )", "del_tokens": "accept = Rack :: Accept :: Charset . new ( env [ 'HTTP_ACCEPT' ] )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "typo", "in", "comment", "."], "add_tokens": "# Shorthand method to write a string to disk. By default the path is created if it doesn't exist.", "del_tokens": "# Shorthand method to write a string to dist. By default the path is created if it doesn't exist.", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "sync", "dsl", "and", "observer", "."], "add_tokens": "include Threadable attr_threadsafe :machine self . machine = machine sync_exclusive { instance_eval ( & block ) } attr_threadsafe :defer attr_threadsafe :initial_event self . defer = true state , name , self . defer = parse ( value ) self . initial_event = name sync_exclusive do _transition = Transition . new ( machine , attrs . merge! ( name : name ) ) _transition . define _transition . define_event end", "del_tokens": "@machine = machine instance_eval ( & block ) attr_reader :machine attr_reader :defer attr_reader :initial_event @defer = true state , name , @defer = parse ( value ) @initial_event = name _transition = Transition . new ( machine , attrs . merge! ( name : name ) ) _transition . define _transition . define_event", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "Array", "and", "Hash", "attributes"], "add_tokens": "VERSION = \"0.9.0\"", "del_tokens": "VERSION = \"0.8.0\"", "commit_type": "add"}
{"commit_tokens": ["fix", "double", "definition", "of", "USB", "::", "DevHandle#usb_release_interface"], "add_tokens": "# # #", "del_tokens": "# # # def usb_release_interface ( c ) ; @dev . release_interface ( c ) ; end def usb_release_interface ( c ) ; @dev . release_interface ( c ) ; end", "commit_type": "fix"}
{"commit_tokens": ["move", "log", "user", "to", "a", "better", "place"], "add_tokens": "send ( \"calculate_user_data_#{self.class.user_details}\" . to_sym , login , data ) log \"user: #{login}\"", "del_tokens": "user_data = send ( \"calculate_user_data_#{self.class.user_details}\" . to_sym , login , data ) log \"user: #{login} - #{user_data['contributions']}\" user_data", "commit_type": "move"}
{"commit_tokens": ["allows", "sql", "to", "be", "required", "in", "non", "-", "java", "env"], "add_tokens": "require 'jdbc-helper/sql'", "del_tokens": "require 'jdbc-helper/sql/sql' require 'jdbc-helper/sql/sql_prepared' require 'jdbc-helper/sql/expression'", "commit_type": "allow"}
{"commit_tokens": ["fixed", "off", "by", "one", "error"], "add_tokens": "result += \"#{screen.GetString(row+1, 1, columns)}\\\\n\"", "del_tokens": "result += \"#{screen.GetString(row, 1, columns)}\\\\n\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "deprecation", "warning", "on", "newer", "MultiJson", "versions"], "add_tokens": "MultiJson . respond_to? ( :adapter ) ? MultiJson . adapter : MultiJson . engine require 'uri/file'", "del_tokens": "MultiJson . engine require 'uri/file'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "incorrect", "log", "message", "for", "URL", "appending"], "add_tokens": "log . debug \"Appending #{path} to #{endpoint}\"", "del_tokens": "log . debug \"Appending #{endpoint} to #{path}\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "ActsAsPurchasable", ".", "not_purchased", "scope"], "add_tokens": "scope :not_purchased , -> { where ( 'id NOT IN (?)' , purchased . pluck ( :id ) . presence || [ 0 ] ) }", "del_tokens": "scope :not_purchased , -> { where ( 'id NOT IN (?)' , purchased . map ( & :id ) ) }", "commit_type": "fix"}
{"commit_tokens": ["removed", "find_by_", "methods", "and", "converted", "to", "where"], "add_tokens": "@system_code ||= selection . where ( system_code : system_code_name . to_s ) . first @system_code ||= selection . where ( system_code : \"#{form.object_name}_#{system_code_name}\" ) . first items . where ( :is_default => true ) . first . try ( :id ) . to_s", "del_tokens": "#TODO convert to using where @system_code ||= selection . find_by_system_code ( system_code_name . to_s ) @system_code ||= selection . find_by_system_code ( form . object_name . to_s + \"_\" + system_code_name . to_s ) #TODO convert to where items . find_by_is_default ( true ) . try ( :id ) . to_s", "commit_type": "remove"}
{"commit_tokens": ["Use", "RSpec", "3", "describe", "syntax", "in", "spec", "/", "models", "/", "tokenizer_spec", "."], "add_tokens": "RSpec . describe OpenNlp :: Model :: Tokenizer do", "del_tokens": "describe OpenNlp :: Model :: Tokenizer do", "commit_type": "use"}
{"commit_tokens": ["fix", "error", "messages", "on", "enum", "and", "add", "default", "value", "option"], "add_tokens": "def define_scopes_for_trax_enum ( enum_name ) end def as_enum ( enum_name , args , options = { } ) options . assert_valid_keys ( :prefix , :source , :message , :default ) options [ :message ] ||= \"Invalid value selected for #{enum_name}\" options [ :prefix ] ||= true options [ :source ] ||= enum_name enum_values = args . is_a? ( Hash ) ? args . keys : args validation_options = { :in => enum_values , :message => options . extract! ( :message ) [ :message ] } self . validates_inclusion_of ( enum_name , validation_options ) define_scopes_for_trax_enum ( enum_name ) self . default_value_for ( enum_name ) { options . extract! ( :default ) [ :default ] } if options . key? ( :default )", "del_tokens": "def as_enum ( enum_name , args , options = { } ) options . assert_valid_keys ( :prefix , :source , :message ) options [ :message ] ||= \"Is not a valid value for #{enum_name}\" options [ :prefix ] ||= true options [ :source ] ||= enum_name enum_values = args . is_a? ( Hash ) ? args . keys : args validation_options = { :in => enum_values , :message => options . extract! ( :message ) } self . validates_inclusion_of ( enum_name , validation_options )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "SEGV", "on", "32", "-", "bit", "architectures"], "add_tokens": "attach_function :crypto_hash_sha256_ref , [ :pointer , :string , :long_long ] , :int attach_function :crypto_box_curve25519xsalsa20poly1305_ref_afternm , [ :pointer , :pointer , :long_long , :pointer , :pointer ] , :int attach_function :crypto_box_curve25519xsalsa20poly1305_ref_open_afternm , [ :pointer , :pointer , :long_long , :pointer , :pointer ] , :int", "del_tokens": "attach_function :crypto_hash_sha256_ref , [ :pointer , :string , :int ] , :int attach_function :crypto_box_curve25519xsalsa20poly1305_ref_afternm , [ :pointer , :pointer , :int , :pointer , :pointer ] , :int attach_function :crypto_box_curve25519xsalsa20poly1305_ref_open_afternm , [ :pointer , :pointer , :int , :pointer , :pointer ] , :int", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "common", "api", "methods", "and", "use", "attach", "for", "EM"], "add_tokens": "# Using 'attach' to get access to a Ruby socket if needed socket = TCPSocket . new ( options [ :host ] , options [ :port ] ) EM . attach ( socket , self , socket , options )", "del_tokens": "# socket = TCPSocket.new(options[:host], options[:port]) # EM.attach(socket, self, socket, options) EM . connect ( options [ :host ] , options [ :port ] , self , nil , options ) # Called after the EM.connect def connection_completed log_debug '[client-cnxn] Established server connection, sending request' _send_request unless error? # @socket.close_write rescue fail ( :RPC_ERROR , 'Connection error: %s' % $! . message ) end", "commit_type": "add"}
{"commit_tokens": ["use", "Processes", ".", "processes", "to", "replace", "Processes", ".", "process_iter", "."], "add_tokens": "# instances use process_iter() or processes() which pre-emptively checks def self . processes # Like self.processes(), but return next Processes instance in each iteration. # To imitate Python's iterator, use Enumerator to implement this method, which # means it will raise StopIteration when it reaches the end. def self . process_iter processes = [ ] pids ( ) . each do | pid | begin unless @@pmap . key? ( pid ) && @@pmap [ pid ] . is_running p = Processes . new ( pid ) @@pmap [ p . pid ] = p end processes . push @@pmap [ pid ] rescue NoSuchProcess @@pmap . delete ( pid ) rescue AccessDenied next end end processes . to_enum end self . class . processes . each do | p | self . class . processes ( ) . each do | p |", "del_tokens": "# instances use process_iter() which pre-emptively checks def self . process_iter self . class . process_iter ( ) . each do | p | self . class . process_iter ( ) . each do | p |", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "passing", "columns", "as", "Set", "object", "to", "RowBuilder"], "add_tokens": "attributes = columns & attributes if columns", "del_tokens": "attributes = attributes & columns if columns", "commit_type": "add"}
{"commit_tokens": ["Add", "translations", "for", "actions", "previous", "and", "next", "."], "add_tokens": "# The translation file comes with the plugin supports the following actions # by default: index, edit, show, new, delete, back, next, previous", "del_tokens": "# The translation file comming with the plugin supports the following actions # by default: index, edit, show, new, delete, back", "commit_type": "add"}
{"commit_tokens": ["Adding", "test", "for", "entry", "with", "undefined", "mail", "field", "."], "add_tokens": "context 'with all fields available' do subject { Cul :: LDAP :: Entry . new ( ldap_entry ) } its ( :name ) { is_expected . to eql 'Jane Doe' } its ( :email ) { is_expected . to eql 'janedoe@columbia.edu' } its ( :first_name ) { is_expected . to eql 'Jane' } its ( :last_name ) { is_expected . to eql 'Doe' } its ( :uni ) { is_expected . to eql 'abc123' } its ( :title ) { is_expected . to eql 'Librarian' } its ( :organizational_unit ) { is_expected . to eql 'Columbia University Libraries' } end context 'without mail field' do subject { Cul :: LDAP :: Entry . new ( ldap_entry_without_mail ) } its ( :email ) { is_expected . to eql 'abc123@columbia.edu' } end", "del_tokens": "subject { Cul :: LDAP :: Entry . new ( ldap_entry ) } its ( :name ) { is_expected . to eql 'Jane Doe' } its ( :email ) { is_expected . to eql 'janedoe@columbia.edu' } its ( :first_name ) { is_expected . to eql 'Jane' } its ( :last_name ) { is_expected . to eql 'Doe' } its ( :uni ) { is_expected . to eql 'abc123' } its ( :title ) { is_expected . to eql 'Librarian' } its ( :organizational_unit ) { is_expected . to eql 'Columbia University Libraries' }", "commit_type": "add"}
{"commit_tokens": ["Remove", "check", "for", "older", "version", "of", "Jekyll"], "add_tokens": "File . exist? @site . in_source_dir ( file_path )", "del_tokens": "if @site . respond_to? ( :in_source_dir ) File . exist? @site . in_source_dir ( file_path ) else File . exist? Jekyll . sanitized_path ( @site . source , file_path ) end", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "Historics", "unit", "test", "."], "add_tokens": "setResponseToSingleHistoric ( { } ) setResponseToSingleHistoric ( { } ) setResponseToSingleHistoric ( { } ) setResponseToSingleHistoric ( { } ) setResponseToSingleHistoric ( { } ) setResponseToSingleHistoric ( { } ) setResponseToSingleHistoric ( { } )", "del_tokens": "@user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 ) @user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 ) @user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 ) @user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 ) @user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 ) @user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 ) @user . api_client . setResponse ( 200 , { 'id' => @testdata [ 'historic_playback_id' ] , } , 200 , 150 )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "timeout", "when", "connecting", "to", "a", "broker"], "add_tokens": "# @param connect_timeout [Integer] the socket timeout for connecting to the broker, # in milliseconds. Default is 10 seconds. def initialize ( host : , port : , client_id : , logger : , connect_timeout : 10_000 ) # The `connect_timeout` argument is in seconds, but our value is in milliseconds. @socket = Socket . tcp ( host , port , connect_timeout : connect_timeout / 1000.0 ) rescue Errno :: ETIMEDOUT @logger . error \"Timed out while trying to connect to #{host}:#{port}: #{e}\" raise ConnectionError , e", "del_tokens": "def initialize ( host : , port : , client_id : , logger : ) @socket = TCPSocket . new ( host , port )", "commit_type": "use"}
{"commit_tokens": ["change", "expiry", "default", "to", "1", "hour"], "add_tokens": "GOOGLE_CERTS_EXPIRY = 3600 # 1 hour def initialize ( options = { } ) if options [ :x509_cert ] @certs = { :_ => options [ :x509_cert ] } # elsif options[:jwk_uri] # TODO @certs_expiry = options . fetch ( :expiry , GOOGLE_CERTS_EXPIRY )", "del_tokens": "GOOGLE_CERTS_EXPIRY = 86400 # 1 day def initialize ( keyopts = { } ) if keyopts [ :x509_cert ] @certs = { :_ => keyopts [ :x509_cert ] } # elsif keyopts[:jwk_uri] # TODO @certs_expiry = keyopts . fetch ( :expiry , GOOGLE_CERTS_EXPIRY )", "commit_type": "change"}
{"commit_tokens": ["Add", "menu", "define", "command", "for", "enterprise", "account", "."], "add_tokens": "def menu get ( 'menu/get' , params : { agentid : agentid } ) end def menu_delete get ( 'menu/delete' , params : { agentid : agentid } ) end def menu_create ( menu )", "del_tokens": "def menu_create ( menu , agentid )", "commit_type": "add"}
{"commit_tokens": ["Improve", "auto", "name", "detection", "refactor", "and", "update", "test", "suite", "."], "add_tokens": "EXCLUDED_VARS = [ :@default_layout , :@preferred_extension , :@app , :@template_cache , :@template_cache , :@env , :@request , :@response , :@params ] Configuration = Struct . new ( :request_path , :route_matchers , :view_variables ) Configuration . new ( request_path , route_matchers , view_variables ) # All user defined instance variables for current request. # Walk through all instance variables and fetch value. # Ignore pre-existing Sinatra instance variables.", "del_tokens": "EXCLUDED_VARS = [ :@default_layout , :@preferred_extension , :@app , :@template_cache , :@template_cache , :@env , :@request , :@response , :@params ] . freeze { request_path : request_path , route_matchers : route_matchers , view_variables : view_variables }", "commit_type": "improve"}
{"commit_tokens": ["Makes", "Zencoder", "path", "configurable", "."], "add_tokens": "cattr_accessor :default_options self . default_options = { path : \"/:zencoder_asset_version/:host/:class/:id_partition/:filename\" , url : \":zencoder_protocol://:zencoder_host_alias:zencoder_path\" , hls_url : \":zencoder_protocol://:zencoder_hls_host_alias:zencoder_path\" , hls_origin_url : \":zencoder_protocol://:zencoder_hls_origin_host_alias:zencoder_path\" } @options = options . merge ( default_options ) Paperclip :: Interpolations . interpolate ( options [ :path ] , self , 'default' ) options [ :hls_url ] options [ :hls_origin_url ] options [ :url ]", "del_tokens": "PATH = \"/:zencoder_asset_version/:host/:class/:id_partition/:filename\" URL = \":zencoder_protocol://:zencoder_host_alias#{PATH}\" HLS_URL = \":zencoder_protocol://:zencoder_hls_host_alias#{PATH}\" HLS_ORIGIN_URL = \":zencoder_protocol://:zencoder_hls_origin_host_alias#{PATH}\" @options = options Paperclip :: Interpolations . interpolate ( PATH , self , 'default' ) HLS_URL HLS_ORIGIN_URL URL", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "ability", "to", "stitch", "a", "pedigree", "one", "person", "at", "a", "time", "(", "with", "people", "from", "a", "person", "read", ")", "."], "add_tokens": "def initialize ( pedigree = nil , person = nil ) if person @id = person . id # @version = person.version if person.version @assertions = person . assertions if person . assertions @families = person . families if person . families @parents = person . parents if person . parents end if pedigree @pedigree = pedigree end end def << ( person ) p = PedigreePerson . new ( self , person ) @persons << p @person_hash [ p . id ] = p end", "del_tokens": "def father_id parent_id ( 'Male' ) end def mother_id parent_id ( 'Female' ) end private def parent_id ( gender ) id = nil if self . parents && self . parents [ 0 ] parent = self . parents [ 0 ] . parents . find do | p | p . gender == gender end id = ( parent . nil? ) ? nil : parent . id end return id end", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "parameters", "to", "Trace", "::", "TraceId", ".", "new"], "add_tokens": "B3_REQUIRED_HEADERS = %w[ HTTP_X_B3_TRACEID HTTP_X_B3_PARENTSPANID HTTP_X_B3_SPANID HTTP_X_B3_SAMPLED ] B3_HEADERS = B3_REQUIRED_HEADERS + %w[ HTTP_X_B3_FLAGS ] def get_or_create_trace_id ( env , default_flags = :: Trace :: Flags :: EMPTY ) trace_parameters = if B3_REQUIRED_HEADERS . all? { | key | env . has_key? ( key ) } [ new_id , nil , new_id , ( \"true\" if Trace . should_sample? ) , default_flags ] trace_parameters [ 4 ] = ( trace_parameters [ 4 ] || default_flags ) . to_i", "del_tokens": "B3_HEADERS = %w[ HTTP_X_B3_TRACEID, HTTP_X_B3_PARENTSPANID, HTTP_X_B3_SPANID, HTTP_X_B3_SAMPLED ] def get_or_create_trace_id ( env ) trace_parameters = if B3_HEADERS . all? { | key | env . has_key? ( key ) } [ new_id , nil , new_id , \"true\" if Trace . should_sample? ]", "commit_type": "fix"}
{"commit_tokens": ["use", "modified", "logger", "to", "output", "data", "only"], "add_tokens": "Jekyll . logger . debug \"Reading:\" , \"Theme Data Files...\" @theme_data_files . each { | file | Jekyll . logger . debug \"\" , file } Jekyll . logger . debug \"Merging:\" , \"Theme Data Hash...\" Jekyll . logger . debug \"\" , \"use --show-data with --verbose to output \" \"merged Data Hash.\" . cyan Jekyll . logger . debug \"Inspecting:\" , \"Site Data >>\" # Redefine Jekyll Loggers to have the [topic] indented by 30. # (rjust by just 29 to accomodate the additional whitespace added # by Jekyll) def print ( topic , message = \"\" ) Jekyll . logger . debug topic . rjust ( 29 ) , message", "del_tokens": "print \"Reading:\" , \"Theme Data Files...\" @theme_data_files . each { | file | print_value file } print \"Merging:\" , \"Theme Data Hash...\" print_value \"use --show-data with --verbose to output merged \" \"Data Hash.\" . cyan print \"Inspecting:\" , \"Site Data >>\" # Redefine Jekyll Loggers def print ( arg1 , arg2 = \"\" ) Jekyll . logger . debug arg1 , arg2", "commit_type": "use"}
{"commit_tokens": ["add", "clobber", "assets", "to", "cc"], "add_tokens": "VERSION = \"0.0.1.beta2\"", "del_tokens": "VERSION = \"0.0.1.pre\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "change", "broadcasting", "name", "when", "registering", "model", "notifications"], "add_tokens": "broadcasting : model . model_name . collection model_name = model . model_name . collection self . ActionCableNotifications [ model_name ] = options", "del_tokens": "options [ :broadcasting ] = model . model_name . collection self . ActionCableNotifications [ options [ :broadcasting ] ] = options", "commit_type": "allow"}
{"commit_tokens": ["Make", "check_box", "work", "properly", "with", "nested", "forms", "."], "add_tokens": "default_html_options = default_html_options_for_collection ( item , value , options , html_options ) default_html_options = default_html_options_for_collection ( item , value , options , html_options ) default_html_options [ :multiple ] = true def default_html_options_for_collection ( item , value , options , html_options ) #:nodoc: accept = if options [ option ] . is_a? ( Proc ) options [ option ] . call ( item ) else Array ( options [ option ] ) . include? ( value ) end default_html_options [ option ] = true if accept", "del_tokens": "default_html_options = default_html_options_for_collection ( value , options , html_options ) input_name = \"#{object_name}[#{attribute}][]\" input_id = \"#{object_name}_#{attribute}_#{value}\" default_html_options = default_html_options_for_collection ( value , options , html_options ) # We need to force :id and :name in html default_html_options [ :id ] = input_id default_html_options [ :name ] = input_name def default_html_options_for_collection ( value , options , html_options ) #:nodoc: valid_option = Array ( options [ option ] ) . include? ( value ) default_html_options [ option ] = true if valid_option", "commit_type": "make"}
{"commit_tokens": ["Update", "device", "to", "capture", "video", "orientation", "mappings"], "add_tokens": "UIDeviceOrientationLandscapeRight = > AVCaptureVideoOrientationLandscapeLeft , UIDeviceOrientationLandscapeLeft = > AVCaptureVideoOrientationLandscapeRight }", "del_tokens": "UIDeviceOrientationLandscapeRight = > AVCaptureVideoOrientationLandscapeRight , UIDeviceOrientationLandscapeLeft = > AVCaptureVideoOrientationLandscapeLeft }", "commit_type": "update"}
{"commit_tokens": ["Add", "first", "attempt", "of", "unnesting", "AD"], "add_tokens": "# Used to restrict searches' to just this object", "del_tokens": "# Used to restrict searches to just this object", "commit_type": "add"}
{"commit_tokens": ["Update", "default", "conversion", "from", "XSD", "to", "Ruby"], "add_tokens": "# **************************** NEED TO BE VERIFIED ************************************", "del_tokens": "# **************************** TO VERIFY ************************************", "commit_type": "update"}
{"commit_tokens": ["Remove", "debugger", "stuff", "from", "RC", "CelerityViewer", "."], "add_tokens": "# debugger", "del_tokens": "debugger", "commit_type": "remove"}
{"commit_tokens": ["Removed", "pending", "spec", "for", "settings", "view", "."], "add_tokens": "", "del_tokens": "pending \"add some examples to (or delete) #{__FILE__}\"", "commit_type": "remove"}
{"commit_tokens": ["Adding", "in", "Don", "Petersen", "s", "patch", ".", "There", "was", "a", "problem", "in", "the", "response", "for", "destroy", ".", "Doink!", "He", "also", "added", "in", "much", "needed", "tests", "for", "failing", "destroy", "calls", "."], "add_tokens": "def response_for_destroy_fails", "del_tokens": "def response_for_destroy_failed", "commit_type": "add"}
{"commit_tokens": ["Moving", "the", "medications", "importer", "over", "from", "hQuery"], "add_tokens": "@section_importers [ :medications ] = MedicationImporter . new", "del_tokens": "@section_importers [ :medications ] = SectionImporter . new ( \"//cda:section[cda:templateId/@root='2.16.840.1.113883.3.88.11.83.112']/cda:entry/cda:substanceAdministration\" , \"./cda:consumable/cda:manufacturedProduct/cda:manufacturedMaterial/cda:code\" , nil , \"./cda:consumable/cda:manufacturedProduct/cda:manufacturedMaterial/cda:code/cda:originalText/cda:reference[@value]\" )", "commit_type": "move"}
{"commit_tokens": ["Implement", "--", "install", "flag", "for", "pry", "-", "theme"], "add_tokens": "require 'net/https' require 'base64' require 'json' Show a list with currently installed themes . opt . on :i , \"install\" , \"Install a theme from Pry Theme Collection\" elsif opts . i? install_theme def install_theme return unless args [ 0 ] uri = URI . parse ( \"https://api.github.com/repos/kyrylo/pry-theme-collection/contents/#{args[0]}/#{args[0]}.prytheme\" ) http = Net :: HTTP . new ( uri . host , uri . port ) http . use_ssl = true output . puts \"Fetching theme from the collection...\" response = http . request ( Net :: HTTP :: Get . new ( uri . request_uri ) ) body = JSON . parse ( response . body ) if body [ \"message\" ] output . puts \"Cannot find theme: #{args[0]}\" return end theme = Base64 . decode64 ( body [ \"content\" ] ) File . open ( local_theme ( \"#{args[0]}.prytheme\" ) , \"w\" ) do | f | f . puts theme end output . puts \"Successfully installed #{args[0]}!\" rescue output . puts \"An error occurred!\" end", "del_tokens": "Show a list with currently installed themes", "commit_type": "implement"}
{"commit_tokens": ["Fix", "test", "broken", "by", "previous", "commit"], "add_tokens": "assert_equal \"ijones@webmail.com\" , Random . email", "del_tokens": "assert_equal \"ijohnson@webmail.com\" , Random . email", "commit_type": "fix"}
{"commit_tokens": ["moved", "less", "to", "assets", "group"], "add_tokens": "if defined? ( Bundler ) # If you precompile assets before deploying to production, use this line Bundler . require * Rails . groups ( :assets => %w( development test ) ) # If you want your assets lazily compiled in production, use this line # Bundler.require(:default, :assets, Rails.env) end", "del_tokens": "# If you have a Gemfile, require the gems listed there, including any gems # you've limited to :test, :development, or :production. Bundler . require ( :default , Rails . env ) if defined? ( Bundler )", "commit_type": "move"}
{"commit_tokens": ["add", "some", "missing", "assertion", "messages"], "add_tokens": "assert_instance_of ( Time , ret . first [ :foo ] , \"the result should be a timestamp\" ) assert_equal ( nil , ret . first [ :nothing ] , \"the result should be nil\" ) assert_instance_of ( String , ret . first [ :something ] , \"the result should be a string\" )", "del_tokens": "assert_instance_of ( Time , ret . first [ :foo ] ) assert_equal ( nil , ret . first [ :nothing ] ) assert_instance_of ( String , ret . first [ :something ] )", "commit_type": "add"}
{"commit_tokens": ["Updated", "controller", "for", "scriturls", "with", "minor", "fix", "."], "add_tokens": "@scriptcdn_script = Scriptcdn :: Scriptcdn_script . find ( params [ :script_id ] )", "del_tokens": "@scriptcdn_script = Scriptcdn_script . find ( params [ :script_id ] )", "commit_type": "update"}
{"commit_tokens": ["Add", "tests", "for", "argv_parser", "and", "data_formatter", "+", "refactoring"], "add_tokens": "def self . parse ( argv ) opts . on ( '-u' , '--user ID' , 'Pandora email or webname' ) do | id | options [ :user_id ] = id opts . on ( '-F' , '--followers' , 'Get all ID\\'s followers' ) do opts . on ( '-f' , '--following' , 'Get all users being followed by ID' ) do end . parse ( argv ) :bookmarked_artists , :liked_stations ,", "del_tokens": "def self . parse opts . on ( '-i' , '--identifier ID' , 'Pandora email or webname' ) do | id | options [ :id ] = id opts . on ( '-f' , '--followers' , 'Get all ID\\'s followers' ) do opts . on ( '-F' , '--following' , 'Get all users being followed by ID' ) do end . parse! :bookmarked_artists , :liked_stations ,", "commit_type": "add"}
{"commit_tokens": ["Updated", "unit", "test", "for", "specifications", "to", "be", "less", "sensitive", "to", "small", "text", "changes", "by", "NewEgg"], "add_tokens": "specs = @api . specifications ( \"N82E16823201044\" ) expect ( specs [ 'SpecificationGroupList' ] . length ) . to eq ( response [ 'SpecificationGroupList' ] . length ) res_group_names = response [ 'SpecificationGroupList' ] . collect { | s | s [ 'GroupName' ] } specs [ 'SpecificationGroupList' ] . each { | s | expect ( res_group_names ) . to include s [ 'GroupName' ] }", "del_tokens": "@api . specifications ( \"N82E16823201044\" ) . should eq ( response )", "commit_type": "update"}
{"commit_tokens": ["move", "extension_path", "to", "subclasses", "of", "Connection"], "add_tokens": "path = @target . extension_path name load path if File . exists? path", "del_tokens": "extension_path = File . join ( File . dirname ( __FILE__ ) , \"vim\" , \"#{name}.rb\" ) load extension_path if File . exists? extension_path", "commit_type": "move"}
{"commit_tokens": ["Fix", "radiant", ":", "update", ":", "configs", "task", "to", "properly", "evaluate", "environment", ".", "rb", "."], "add_tokens": ":secret => < % require 'digest/sha1' %>'<%= Digest::SHA1.hexdigest(\"--#{app_name}--#{Time.now.to_s}--#{rand(10000000)}--\") %> '", "del_tokens": ":secret => < % require 'digest/sha1' - %>'<%= Digest::SHA1.hexdigest(\"--#{app_name}--#{Time.now.to_s}--#{rand(10000000)}--\") %> '", "commit_type": "fix"}
{"commit_tokens": ["Implement", "tests", "and", "functionality", "for", "custom", "notices", "redirect", "blocks"], "add_tokens": "def respond_with_dual ( object , options , & block ) args = [ object , options ] set_flash options case block . try ( :arity ) when 2 respond_with ( * args ) do | responder | dummy_responder = Resourceful :: DummyResponder . new if get_resource_ivar . errors . empty? block . call responder , dummy_responder else block . call dummy_responder , responder end end when 1 respond_with * args , & block else options [ :location ] = block . call if block respond_with * args end end def set_flash ( options = { } ) if options . has_key? ( :notice ) flash [ :notice ] = options [ :notice ] elsif options . has_key? ( :alert ) flash [ :alert ] = options [ :alert ] end", "del_tokens": "def respond_with_dual ( * resources , & block ) respond_with * resources , & block", "commit_type": "implement"}
{"commit_tokens": ["Adding", "new", "TaskType", "parameter", "on", "SaveTaskStatus", "call", "."], "add_tokens": "VERSION = \"1.3.3\"", "del_tokens": "VERSION = \"1.3.2\"", "commit_type": "add"}
{"commit_tokens": ["fixed", "backwards", "compatibility", "they", "were", "pointing", "to", "the", "wrong", "module"], "add_tokens": "class RestClient :: Request Redirect = RestClient :: Redirect Unauthorized = RestClient :: Unauthorized RequestFailed = RestClient :: RequestFailed end", "del_tokens": "RestClient :: Resource :: Redirect = RestClient :: Redirect RestClient :: Resource :: Unauthorized = RestClient :: Unauthorized RestClient :: Resource :: RequestFailed = RestClient :: RequestFailed", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "setup", "of", "config"], "add_tokens": "File . open ( CONFIG_FILE , 'w' ) { | f | YAML :: dump ( { 'main' => main } , f ) }", "del_tokens": "File . open ( CONFIG_FILE , 'w' ) { | f | YAML :: dump ( main , f ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "PaginatedCollection#next_page", "error", "when", "no", "initial", "params", "."], "add_tokens": "collection . original_params = options . fetch ( 'params' , { } )", "del_tokens": "collection . original_params = options [ 'params' ]", "commit_type": "fix"}
{"commit_tokens": ["Change", "no", "-", "option", "behaviour"], "add_tokens": "if @options [ :major ] || @options [ :minor ] || @options [ :patch ] || @options [ :commit ] return :bump # command without options invokes info action return :info", "del_tokens": "if ! @options [ :major ] && ! @options [ :minor ] && ! @options [ :patch ] && ! @options [ :commit ] return :help return :bump", "commit_type": "change"}
{"commit_tokens": ["updated", "dependencies", "and", "documentation", "."], "add_tokens": "VERSION = \"9.0.0\"", "del_tokens": "VERSION = \"8.0.0\"", "commit_type": "update"}
{"commit_tokens": ["Added", "code", "to", "geometry", ".", "correct", "to", "repeat", "atoms", "on", "border", "of", "unit", "cell", "."], "add_tokens": "# atoms on the border will be repeated with # periodicity of lattice vectors for better rendering border_atoms = { } end # This part repeats atoms on the unit cell boundaries # useful for drawing pictures, but these atoms are really repeats if p . distance_to_point ( atom . x , atom . y , atom . z ) == 0 if border_atoms [ atom ] border_atoms [ atom ] << v else border_atoms [ atom ] = [ v ] end end # Add more border atoms for each combination of lattice planes border_atoms . each_pair { | atom , planes | planes . size . times { | i | combos = Volume . choose ( planes , i + 1 ) combos . each { | combo | x = combo . inject ( 0 ) { | sum , v | sum = sum + v [ 0 ] } y = combo . inject ( 0 ) { | sum , v | sum = sum + v [ 1 ] } z = combo . inject ( 0 ) { | sum , v | sum = sum + v [ 2 ] } puts [ x , y , z ] new_unit_cell . atoms ( :allAtoms ) << atom . displace ( x , y , z ) } } }", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Changing", "so", "that", "errors", "are", "returned", "for", "unauthorized", "attribute", "access"], "add_tokens": "context . authorize! ( :read , model )", "del_tokens": "return nil unless context . can? ( :read , model )", "commit_type": "change"}
{"commit_tokens": ["Add", "instance", "methods", "for", "each", "mapped", "value"], "add_tokens": "define_class_methods ( name , column_name , mapping ) define_instante_methods ( name , column_name , mapping ) end def define_class_methods ( name , column_name , mapping ) define_singleton_method ( \"with_#{name}\" ) do | * keys | where ( column_name => bitwise_union ( keys , name ) ) define_singleton_method ( \"with_all_#{name}\" ) do | * keys | where ( column_name => bitwise_intersection ( keys , name ) ) # Defines a class method for each key of the mapping, returning records that have *at least* # the corresponding value. mapping . keys . each do | key | define_singleton_method ( key ) do send ( \"with_#{key}\" ) end end end def define_instante_methods ( name , column_name , mapping )", "del_tokens": "define_singleton_method ( \"with_#{name}\" ) do | * vals | where ( column_name => bitwise_union ( vals , name ) ) define_singleton_method ( \"with_all_#{name}\" ) do | * vals | where ( column_name => bitwise_intersection ( vals , name ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "5", "more", "spinners", "for", "total", "of", "15"], "add_tokens": "spin_10 : '╫╪'.fre e ze, spin_11 : '▁▃▅▆▇█▇▆▅▃'.freeze, spin_12 : '◢◣◤◥'.freeze, spin_13 : '.oO@*' . freeze , spin_14 : '←↖↑↗→↘↓↙'.freeze, spin_15 : '-◡⊙-◠'.freez e", "del_tokens": "spin_10 : '╫╪'.fre e ze", "commit_type": "add"}
{"commit_tokens": ["Added", "extra", "options", "array", "so", "optional", "params", "like", ":", "reminder_time", "reminder_template", "and", "date", "can", "also", "be", "added"], "add_tokens": "# options, Hash def purchase ( email , items , incomplete = nil , message_id = nil , options = { } ) data = options", "del_tokens": "def purchase ( email , items , incomplete = nil , message_id = nil ) data = { }", "commit_type": "add"}
{"commit_tokens": ["Moved", "around", "where", "models", "are", "loaded", "from", "added", "a", "rand", "to", "DataMapper", "::", "Collection", "."], "add_tokens": "%w{ file image } . each do | f | require \"/home/ebrodeur/Projects/bin_snippets/lib/models/dm/#{f}.rb\" module DataMapper class Collection def rand all [ Random . rand ( all . count ) ] end end end", "del_tokens": "require 'dm-types' %w{ file } . each do | f | require \"models/dm/#{f}\"", "commit_type": "move"}
{"commit_tokens": ["Make", "yajl", "-", "ruby", "an", "optional", "dependency"], "add_tokens": "begin require 'yajl' rescue LoadError require 'json' end if defined? ( :: Yajl ) def format ( tag ) Yajl . dump ( tag ) end else def format ( tag ) JSON . dump ( tag ) end", "del_tokens": "require 'yajl' def format ( tag ) Yajl . dump ( tag )", "commit_type": "make"}
{"commit_tokens": ["Fixed", "Singer", "to", "work", "with", "Faraday"], "add_tokens": "uri = parse_url ( url ) uri = parse_url ( url ) #parse url if url parameter is string do nothing if parameter is URI def parse_url ( url ) return url if url . is_a? ( URI ) URI . parse ( url ) end", "del_tokens": "uri = URI . parse ( url ) uri = URI . parse ( url )", "commit_type": "fix"}
{"commit_tokens": ["remove", "comment", "and", "rename", "label_delimiter", "to", "label_separator"], "add_tokens": "Field . message_proc ( fields , setting . labeled , setting . delimiter , setting . label_delimiter ) def self . message_proc ( fields , labeled , delimiter , label_delimiter ) format_proc = format_proc ( labeled , delimiter , label_delimiter ) def self . format_proc ( labeled , delimiter , label_delimiter ) Proc . new { | fields | \"#{fields.map {|key, val| \"#{key}#{label_delimiter}#{val}\" }.join(delimiter)}\\n\" }", "del_tokens": "Field . message_proc ( fields , setting . labeled , setting . delimiter , setting . label_separator ) def self . message_proc ( fields , labeled , delimiter , label_separator ) format_proc = format_proc ( labeled , delimiter , label_separator ) def self . format_proc ( labeled , delimiter , label_separator ) # Proc.new {|fields| \"#{fields.map {|key, val| \"#{key}:#{val}\" }.join(delimiter)}\\n\" } Proc . new { | fields | \"#{fields.map {|key, val| \"#{key}\" + label_separator + \"#{val}\" }.join(delimiter)}\\n\" }", "commit_type": "remove"}
{"commit_tokens": ["Create", "the", "concept", "of", "a", "separate", "outcome", "in", "order", "to", "be", "clear", "about", "the", "API"], "add_tokens": "errors = ErrorHash . new sub_error = ErrorAtom . new ( key , sub_error ) if sub_error . is_a? ( Symbol ) errors [ key ] = ErrorAtom . new ( key , :required )", "del_tokens": "def lookup_attribute ( name ) @required_inputs [ name . to_sym ] || @optional_inputs [ name . to_sym ] end errors = { } errors [ key ] = :required", "commit_type": "create"}
{"commit_tokens": ["improve", "syntax", "of", "standalone", "request"], "add_tokens": "def run ( request ) method = request . http_method parse ( request . klass , ( Typhoeus :: Request . send method , request . request_uri , request . options ) )", "del_tokens": "def fetch ( request ) parse ( request . klass , Typhoeus :: Request . get ( request . request_uri , request . options ) )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "object", "equality", "check", "when", "same", "object_id"], "add_tokens": "object . class == self . class && ( object . key . present? && object . key == self . key || object . object_id == self . object_id )", "del_tokens": "object . class == self . class && object . key . present? && object . key == self . key", "commit_type": "fix"}
{"commit_tokens": ["add", "exit", "command", "to", "shell"], "add_tokens": "while buf = Readline . readline ( 'gitlab> ' , true ) break if buf == 'exit'", "del_tokens": "while buf = Readline . readline ( \"gitlab> \" , true )", "commit_type": "add"}
{"commit_tokens": ["Changed", "order", "of", "names", "in", "full_name"], "add_tokens": "\"#{surname}, #{forename}\"", "del_tokens": "\"#{forename} #{surname}\"", "commit_type": "change"}
{"commit_tokens": ["Added", "network", "awareness", "to", "MultiWallet", "/", "Node"], "add_tokens": ":bitcoin_testnet => :bitcoin_testnet , self . new ( :private => masters , :network => network ) @network = NetworkMap [ options . include? :network ? options [ :network ] : :testnet3 ] :public => { } , :network => @network @network = options [ :network ] # m of n Script . new ( :public_keys => keys , :needed => m , :network => @network ) Script . new ( :address => self . script . p2sh_address , :network => @network )", "del_tokens": "self . new ( :private => masters ) :public => { } # m of n Script . new ( :public_keys => keys , :needed => m ) Script . new ( :address => self . script . p2sh_address )", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "system", "register", "code", "to", "use", "owner", "instead", "of", "org", ")", "name"], "add_tokens": "org = Organization . find_by_name ( params [ :owner ] )", "del_tokens": "org = Organization . find_by_name ( params [ :org_name ] )", "commit_type": "change"}
{"commit_tokens": ["Improve", "error", "swallowing", "of", "non", "-", "JSON", "responses"], "add_tokens": "if ( response . content_type || '' ) . include? ( 'json' ) # Attempt to parse the error as JSON begin json = JSON . parse ( response . body ) if json [ 'errors' ] && json [ 'errors' ] . first raise Error :: HTTPError . new ( json [ 'errors' ] . first ) end rescue JSON :: ParserError ; end end", "del_tokens": "error = JSON . parse ( response . body ) [ 'errors' ] . first raise Error :: HTTPError . new ( error ) rescue JSON :: ParserError", "commit_type": "improve"}
{"commit_tokens": ["Use", "Open3", ".", "capture2e", "than", "Kernel", ".", "system"], "add_tokens": "require \"open3\" attr_reader :script output , status = Open3 . capture2e ( script ) { output : output , status : status . success? }", "del_tokens": "require \"tempfile\" { status : status , output : output } end private def tempfile @tempfile ||= Tempfile . new ( \"\" ) end def status system ( @script , out : tempfile , err : tempfile ) end def output tempfile . tap ( & :close ) . open . read", "commit_type": "use"}
{"commit_tokens": ["add", "node", "label", "based", "affinity", "filter"], "add_tokens": "elsif key == 'label' unless label_match? ( node , comparator , value ) candidates . delete ( node ) end def label_match? ( node , compare , value ) if compare == '==' node . labels . include? ( value ) elsif compare == '!=' ! node . labels . include? ( value ) else false end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", "spec", "for", "Point", ".", "srid!", "(", "and", "remove", "try", "usage", ")"], "add_tokens": "from_x_y points . sum ( & :x ) / 2 , points . sum ( & :y ) / 2 , srid! ( points ) GeoRuby :: SimpleFeatures :: Polygon . from_points ( [ points ] , srid! ( points ) ) . centroid def self . srid! ( points ) points . first . srid . tap do | srid | raise \"SRIDs are not uniq in #{points.inspect}\" if points . any? { | point | point . srid != srid } end unless points . blank?", "del_tokens": "require 'active_support/core_ext/object/try' from_x_y points . sum ( & :x ) / 2 , points . sum ( & :y ) / 2 , points . first . srid GeoRuby :: SimpleFeatures :: Polygon . from_points ( [ points ] , points . first . srid ) . centroid def self . srid ( points ) points . first . try ( :srid )", "commit_type": "add"}
{"commit_tokens": ["Use", "VCR", "for", "recommender", "-", "api", "requests"], "add_tokens": "require 'vcr' require 'webmock/rspec' WebMock . allow_net_connect! VCR . turn_off! VCR . configure do | c | c . cassette_library_dir = 'spec/fixtures/tapes' c . hook_into :webmock c . filter_sensitive_data ( '<API_KEY>' ) { ENV [ 'API_KEY' ] } end # Turn VCR on and off as required VCR . extend Module . new { def use_cassette ( * args ) VCR . turn_on! super VCR . turn_off! end }", "del_tokens": "# require 'vcr' # require 'webmock/rspec' # VCR.configure do |c| # c.cassette_library_dir = 'spec/fixtures/tapes' # c.hook_into :webmock # c.filter_sensitive_data('<API_KEY>') { ENV['API_KEY'] } # end", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "failing", "test", "."], "add_tokens": "region = options [ :region ] || PhoneNumber . region", "del_tokens": "region = PhoneNumber . region", "commit_type": "add"}
{"commit_tokens": ["Use", "import", "to", "insert", "multiple", "groups", "at", "once"], "add_tokens": "@next_group_id = 1 @next_group_mutex = Mutex . new Integer :group_id def next_group_id result = nil @next_group_mutex . synchronize do result = @next_group_id @next_group_id += 1 end result end", "del_tokens": "foreign_key :group_id , :groups", "commit_type": "use"}
{"commit_tokens": ["Moved", "FSR", "::", "Event", "to", "FSR", "::", "Listener", "::", "Inbound", "::", "Event", "namespace"], "add_tokens": "event = Event . from ( data ) on_event ( event ) def on_event ( event ) event end", "del_tokens": "pp event = Event . from ( data )", "commit_type": "move"}
{"commit_tokens": ["Fix", "adding", "close", "method", "on", "broadcast", "building"], "add_tokens": "VERSION = \"1.4.1\"", "del_tokens": "VERSION = \"1.4.0\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "comment", "about", "followx", "limitation"], "add_tokens": "# Returns the *public* users being followed by the user.", "del_tokens": "# Returns the users being followed by the user.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "describing", "C", "++", "in", "the", "docs", "."], "add_tokens": "result . gsub! ( / ( \\A |[^ \\\\ ]) \\+ ([^ \\+ ]+) \\+ / , '\\1`\\2`' )", "del_tokens": "result . gsub! ( / ( \\A |[^ \\\\ ]) \\+ ([^ \\+ ]*) \\+ / , '\\1`\\2`' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "fail", "a", "running", "or", "queued", "job", "."], "add_tokens": "[ :pause , :resume , :abort , :retry , :fail ] . each do | state |", "del_tokens": "[ :pause , :resume , :abort , :retry ] . each do | state |", "commit_type": "add"}
{"commit_tokens": ["Updated", "code", "to", "use", "Model", "and", "not", "Resource", "::", "ClassMethods"], "add_tokens": "Model . send ( :include , self )", "del_tokens": "module ClassMethods include Validate :: ClassMethods end # module ClassMethods", "commit_type": "update"}
{"commit_tokens": ["Updated", "travis", "config", ".", "Added", "Coveralls", "coverage", "."], "add_tokens": "require 'simplecov' require 'coveralls' SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter [ SimpleCov :: Formatter :: HTMLFormatter , Coveralls :: SimpleCov :: Formatter ] SimpleCov . start require 'oauth2' WebMock . disable_net_connect! ( :allow => 'coveralls.io' )", "del_tokens": "# require 'simplecov' # SimpleCov.start require 'oauth2'", "commit_type": "update"}
{"commit_tokens": ["Adding", "full", "unit", "tests", "for", "Configurator", "and", "DRYing", "up", "code"], "add_tokens": "get_or_set ( :user , val , :to_s ) get_or_set ( :group , val , :to_s ) get_or_set ( :daemonise , val ) get_or_set ( :driver , klass ) get_or_set ( :name , val , :to_s ) get_or_set ( :pid_file , val , :to_s ) get_or_set ( :port , val , :to_i ) def get_or_set ( attribute , value , coercion_method = nil ) if value converted_value = coercion_method ? value . send ( coercion_method ) : value instance_variable_set ( variable_name_for ( attribute ) , converted_value ) else instance_variable_get ( variable_name_for ( attribute ) ) end end def variable_name_for ( attribute ) :\" @ #{ attribute } \" end", "del_tokens": "if val @user = val . to_s else @user end if val @group = val . to_s else @group end if val @daemonise = val else @daemonise end if klass @driver = klass else @driver end if val @name = val . to_s else @name end if val @pid_file = val . to_s else @pid_file end if val @port = val . to_i else @port end", "commit_type": "add"}
{"commit_tokens": ["Remove", "leading", "and", "trailing", "underscores", "from", "generated", "filenames"], "add_tokens": "string . downcase . gsub ( / \\W + / , '_' ) . gsub ( / ^_|_$ / , '' )", "del_tokens": "string . downcase . gsub / \\W + / , '_'", "commit_type": "remove"}
{"commit_tokens": ["Add", "VdcStorageProfile", ".", "available_storage", "method"], "add_tokens": "VCloudSdk :: VdcStorageProfile . new ( storage_profile )", "del_tokens": "VCloudSdk :: VdcStorageProfile . new ( @connection , storage_profile )", "commit_type": "add"}
{"commit_tokens": ["Use", "built", "-", "in", "Array", "function", "to", "array", "-", "ify", "args", "in", "Options", "class"], "add_tokens": "Array ( arg ) . map ( & block ) return nil unless time Array ( time ) . compact . flat_map { | d | as_time ( d ) }", "del_tokens": "array = case arg when Range arg . to_a else [ * arg ] end array . map ( & block ) when time . is_a? ( Array ) [ time ] . compact . flat_map { | d | as_time ( d ) } time", "commit_type": "use"}
{"commit_tokens": ["make", "PseudoHikiInlineParser#parse", "a", "delegation", "to", "InlineStack#parse"], "add_tokens": "def initialize ( tokens ) @tokens = tokens super ( ) end def parse while token = @tokens . shift next if TAIL [ token ] and treated_as_node_end ( token ) next if HEAD [ token ] and self . push HEAD [ token ] . new self . push InlineLeaf . create ( token ) end self end @stack = InlineStack . new ( split_into_tokens ( str ) ) @stack . parse", "del_tokens": "@stack = InlineStack . new while token = @tokens . shift next if TAIL [ token ] and @stack . treated_as_node_end ( token ) next if HEAD [ token ] and @stack . push HEAD [ token ] . new @stack . push InlineLeaf . create ( token ) end @stack", "commit_type": "make"}
{"commit_tokens": ["Add", "checks", "for", "getters", "and", "setters", "."], "add_tokens": "'Array#select.last is slower than Array#reverse.detect' , getter_vs_attr_reader : 'Use attr_reader for reading ivars' , setter_vs_attr_writer : 'Use attr_writer for writing to ivars'", "del_tokens": "'Array#select.last is slower than Array#reverse.detect'", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", "of", "negative", "indexes"], "add_tokens": "image [ x , y ] . should be == data [ ( x + 10 ) * 10 + ( y + 10 ) ]", "del_tokens": "image . get_pixel ( x , y ) . should be == data [ ( x + 10 ) * 10 + ( y + 10 ) ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "make", "arbitrary", "calls", "against", "the", "API", "with", "the", "library", ".", "I", "m", "now", "able", "to", "properly", "search", "for", "users", "by", "email", "address", "though", "the", "data", "is", "not", "being", "stored", "in", "the", "User", "object", "and", "an", "exception", "will", "be", "thrown", "if", "the", "user", "doesn", "t", "exist"], "add_tokens": "def call ( command , args = { } ) @connection . call ( command , args ) end call ( \"version\" )", "del_tokens": "@connection . call ( \"version\" )", "commit_type": "add"}
{"commit_tokens": ["updated", "middleware", "to", "automatically", "fire", "500", "and", "400", "events", "to", "dailycred"], "add_tokens": "#{\", type: \\\"#{@status.to_s}\\\"\" if @status == 500 || @status == 400}", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Remove", "license", "warning", "and", "release", "version", "."], "add_tokens": "VERSION = '0.1.6' . freeze", "del_tokens": "VERSION = '0.1.5' . freeze", "commit_type": "remove"}
{"commit_tokens": ["fix", "spec", "broken", "by", "recent", "commits"], "add_tokens": "node . instance_variable_get ( :@thread_pool ) . running? . should be_true", "del_tokens": "node . instance_variable_get ( :@thread_pool ) . running? . should be_true #node.terminate #node.instance_variable_get(:@thread_pool).running?.should be_false", "commit_type": "fix"}
{"commit_tokens": ["Fix", "giant", "log", "messages", "."], "add_tokens": "@logger . debug ( \"Unprovision orphan instance #{ins} and its #{bindings.size} bindings\" )", "del_tokens": "@logger . debug ( \"Unprovision orphan instance #{ins} and its bindings #{bindings.inspect}\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "display", "number", "instead", "of", "First", "/", "Last"], "add_tokens": ":first_last => true , when 1 ; \"<div class=\\\"#{setting[:active_class]}\\\" style=\\\"display: inline;\\\">#{setting[:first_last] ? setting[:first_text] : i}</div>\" when size ; \"<div class=\\\"#{setting[:active_class]}\\\" style=\\\"display: inline;\\\">#{setting[:first_last] ? setting[ :last_text] : i}</div>\" else ; \"<div class=\\\"#{setting[:active_class]}\\\" style=\\\"display: inline;\\\">#{i}</div>\" when 1 ; \"<a href=\\\"#{yield(i)}\\\"#{attrs}>#{setting[:first_last] ? setting[:first_text] : i}</a>\" when size ; \"<a href=\\\"#{yield(i)}\\\"#{attrs}>#{setting[:first_last] ? setting[ :last_text] : i}</a>\"", "del_tokens": "when 1 ; \"<div class=\\\"#{setting[:active_class]}\\\" style=\\\"display: inline;\\\">#{setting[:first_text]}</div>\" when size ; \"<div class=\\\"#{setting[:active_class]}\\\" style=\\\"display: inline;\\\">#{setting[ :last_text]}</div>\" else ; \"<div class=\\\"#{setting[:active_class]}\\\" style=\\\"display: inline;\\\">#{page}</div>\" when 1 ; \"<a href=\\\"#{yield(i)}\\\"#{attrs}>#{setting[:first_text]}</a>\" when size ; \"<a href=\\\"#{yield(i)}\\\"#{attrs}>#{setting[ :last_text]}</a>\"", "commit_type": "add"}
{"commit_tokens": ["Use", ":", "scope", "as", "option"], "add_tokens": "ScopedSerializer . for ( object , { :scope => serializer_scope , :super => true } . merge ( options . merge ( default_serializer_options ) ) )", "del_tokens": "ScopedSerializer . for ( object , serializer_scope , options . merge ( default_serializer_options . merge ( :super => true ) ) )", "commit_type": "use"}
{"commit_tokens": ["fix", "correct", "number", "of", "secret", "creation"], "add_tokens": "( 1 .. num_points ) . each do | x |", "del_tokens": "( 1 .. num_points + 1 ) . each do | x |", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "Philtre", ".", "grind", "method"], "add_tokens": "def self . new ( * filter_parameters , & blk ) Filter . new * filter_parameters , & blk # Create a grinder with the parameters, and # use it on the dataset. Return the result. # # dataset should have placeholders, otherwise calling this # method just warms your cpu. def self . grind ( dataset : nil , with : { } , ** kwargs ) filter = new ( with . merge kwargs ) Philtre :: Grinder . new ( filter ) . transform ( dataset )", "del_tokens": "def self . new ( * args , & blk ) Filter . new * args , & blk # same as # dataset = YourModel.filter( :name.lieu, ) def self . grind ( dataset , with : { } ) alias filter new", "commit_type": "fix"}
{"commit_tokens": ["added", "Campfire#rooms", "to", "get", "a", "list", "of", "available", "rooms"], "add_tokens": "# Get an array of all the available rooms # TODO: detect rooms that are full (no link) def rooms Hpricot ( get . body ) . search ( \"//h2/a\" ) . collect do | a | Room . new ( self , room_id_from_url ( a . attributes [ 'href' ] ) , a . inner_html ) end end # Find a campfire room by name def find_room_by_name ( name ) rooms . detect { | room | room . name == name } end", "del_tokens": "# Find a campfire room by name def find_room_by_name ( name ) link = Hpricot ( get . body ) . search ( \"//h2/a\" ) . detect { | a | a . inner_html == name } link . blank? ? nil : Room . new ( self , room_id_from_url ( link . attributes [ 'href' ] ) , name ) end", "commit_type": "add"}
{"commit_tokens": ["Use", "R10K", "to", "install", "test", "modules"], "add_tokens": ":r10k_install_modules , task :r10k_install_modules do r10k_install_modules def r10k_install_modules info 'Updating modules with R10K' rescue SystemExit # because R10K::CLI.command.run calls `exit 0` info 'Modules have been updated'", "del_tokens": "# Must clear as it will not override the existing puppet-lint rake task task :install_modules do install_modules def install_modules", "commit_type": "use"}
{"commit_tokens": ["Use", "rstrip", "to", "deal", "with", "table", "mode", "."], "add_tokens": "res = res . rstrip if res . class == String res", "del_tokens": "res = res [ 0 .. - 2 ]", "commit_type": "use"}
{"commit_tokens": ["Fix", "two", "rubocop", "objections", "."], "add_tokens": "# @param metric_type [String] metric type (one of \"counter\", \"gauge\", \"availability\") def initialize ( client , metric_type , resource ) @type = metric_type # @param metric_definition [MetricDefinition] def update_tags ( metric_definition ) @client . http_put ( \"/#{@resource}/#{metric_definition.id}/tags\" , metric_definition . hash [ :tags ] )", "del_tokens": "# @param metricType [String] metric type (one of \"counter\", \"gauge\", \"availability\") def initialize ( client , metricType , resource ) @type = metricType # @param metricDefinition [MetricDefinition] def update_tags ( metricDefinition ) @client . http_put ( \"/#{@resource}/#{metricDefinition.id}/tags\" , metricDefinition . hash [ :tags ] )", "commit_type": "fix"}
{"commit_tokens": ["Make", "specs", "tolerant", "to", "DB", "default", "selection", "order"], "add_tokens": "expect ( record . class ) . not_to exist ( record )", "del_tokens": "expect ( record . class . exists? ( record ) ) . to be_false", "commit_type": "make"}
{"commit_tokens": ["fix", "completion", "of", "empty", "string", "and", "/"], "add_tokens": "if path . empty? return [ [ ] , false , false ] elsif path == '/' return [ [ ] , true , true ] else els = path . split '/' trailing_slash = path [ - 1 .. - 1 ] == '/' absolute = ! els [ 0 ] . nil? && els [ 0 ] . empty? els . shift if absolute [ els , absolute , trailing_slash ] end", "del_tokens": "els = path . split '/' trailing_slash = path [ - 1 .. - 1 ] == '/' absolute = els [ 0 ] . nil? || els [ 0 ] . empty? els . shift if absolute [ els , absolute , trailing_slash ]", "commit_type": "fix"}
{"commit_tokens": ["added", "cookie", "-", "jar", ";", "add", "better", "support", "for", "authentication", "(", "still", "being", "reject", "from", "request", "abuse", ")", ";", "updated", "tests", "for", "cookie", "-", "jar"], "add_tokens": "ASPXAUTH_COOKIE_NAME = \".ASPXAUTH\" ASP_NET_SESSION_ID_COOKIE_NAME = \"ASP.NET_SessionId\" GROUP_ID_COOKIE_NAME = \"GroupId\"", "del_tokens": "ASPXAUTH_TOKEN_FROM_COOKIE_REGEX = / .ASPXAUTH=([a-zA-Z0-9]*); /", "commit_type": "add"}
{"commit_tokens": ["fix", "to_param", "for", "nestled", "params"], "add_tokens": "def to_param ( value , key = nil ) case value when Hash then value . map { | k , v | to_param ( v , append_key ( key , k ) ) } . join ( '&' ) when Array then value . map { | v | to_param ( v , \"#{key}[]\" ) } . join ( '&' ) when nil then '' \"#{key}=#{CGI.escape(value.to_s)}\" protected def append_key ( root_key , key ) root_key . nil? ? key : \"#{root_key}[#{key.to_s}]\" end", "del_tokens": "def to_param ( object , namespace = nil ) case object when Hash object . map do | key , value | key = \"#{namespace}[#{key}]\" if namespace \"#{CGI.escape(to_param(key))}=#{CGI.escape(to_param(value, key))}\" end . join ( '&' ) when Array object . each do | value | to_param ( value ) end . join ( '/' ) object . to_s", "commit_type": "fix"}
{"commit_tokens": ["added", "attr_reader", ":", "name", "(", "bot", "s", "username", ")"], "add_tokens": "VERSION = \"1.1.3\" attr_reader :name @name = secrets [ :login ] t = json :get , \"/comments/#{post[\"data\"][\"id\"]}\" , depth : 1 , limit : 100500 #, sort: \"top\"", "del_tokens": "VERSION = \"1.1.2\" t = BOT . json :get , \"/comments/#{post[\"data\"][\"id\"]}\" , # sort: \"top\", depth : 1 , limit : 100500", "commit_type": "add"}
{"commit_tokens": ["Added", "options", "to", "authorize_url", "."], "add_tokens": "# * :display - page (default), popup, wap, touch. See: http://developers.facebook.com/docs/authentication/. # # All other options in the options Hash will be put in the authorize_url. scope = options . delete ( :scope ) url += \"&scope=#{scope.join(',')}\" unless scope . blank? url += options . to_query unless options . blank? # Add other options. FIXME: to_query method requires Rails?!", "del_tokens": "url += \"&scope=#{options[:scope].join(',')}\" unless options [ :scope ] . blank?", "commit_type": "add"}
{"commit_tokens": ["Using", "contest", "-", "syntax", "in", "TestDataGrouping", "."], "add_tokens": "setup do test 'bracket access' do test 'method access' do test 'mixed access' do", "del_tokens": "def setup def test_bracket_access def test_method_access def test_mixed_access", "commit_type": "use"}
{"commit_tokens": ["added", "wait", "for", "host", "after", "send_keys", "with", "extra"], "add_tokens": "quiet_period quiet_period def quiet_period screen . WaitHostQuiet ( max_wait_time ) end", "del_tokens": "screen . WaitHostQuiet ( max_wait_time )", "commit_type": "add"}
{"commit_tokens": ["Add", "hash", "rockets", "in", "tests"], "add_tokens": ":type => \"us_citizen\" , :date_of_birth => \"1975-01-01\" , :identification => { :ssn => \"0000\" :name => { :first => \"John\" , :middle => \"P\" , :last => \"Doe\" :address => { :street1 => \"1 Infinite Loop\" , :street2 => nil , :city => \"Cupertino\" , :state => \"CA\" , :postal_code => \"95014\" , :country => \"US\" :question_id => 1 , :answer_id => 1 :question_id => 2 , :answer_id => 1 :question_id => 3 , :answer_id => 1 :question_id => 4 , :answer_id => 1 :question_id => 5 , :answer_id => 1", "del_tokens": "type : \"us_citizen\" , date_of_birth : \"1975-01-01\" , identification : { ssn : \"0000\" name : { first : \"John\" , middle : \"P\" , last : \"Doe\" address : { street1 : \"1 Infinite Loop\" , street2 : nil , city : \"Cupertino\" , state : \"CA\" , postal_code : \"95014\" , country : \"US\" question_id : 1 , answer_id : 1 question_id : 2 , answer_id : 1 question_id : 3 , answer_id : 1 question_id : 4 , answer_id : 1 question_id : 5 , answer_id : 1", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "define", "private", "functions"], "add_tokens": "# Helper to define private functions def self . private_module_function ( name ) module_function ( name ) private_class_method ( name ) end private_module_function :run_command private_module_function :nonzero_column? private_module_function :jruby?", "del_tokens": "module_function :run_command module_function :nonzero_column? module_function :jruby?", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "most", "formats", "in", "the", "possessive", "method"], "add_tokens": "def possessive ( method = :full ) whitelist = %i[ full first last abbreviated sorted initials ] unless whitelist . include? ( method . to_sym ) raise ArgumentError , 'Please provide a valid method' end name = public_send ( method ) @possessive ||= \"#{name}'#{'s' unless name.downcase.end_with?('s')}\"", "del_tokens": "def possessive @possessive ||= \"#{self}'#{\"s\" unless end_with?(\"s\")}\"", "commit_type": "add"}
{"commit_tokens": ["Add", "send_asset", "usage", "document", ".", "version", "increment", "."], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "add"}
{"commit_tokens": ["Use", "command", "line", "for", "unzipping", "on", "rake", "update", "instead", "of", "broken", "rubyzip"], "add_tokens": "puts \"Unzipping...\" unzip File . open ( \"resources/#{@@TMP_ZIP}\" , 'wb+' ) do | save_file | def self . unzip Dir . chdir ( './resources/' ) do ` unzip -o game-icons.net.svg.zip ` end end", "del_tokens": "require 'zip' puts \"Unzipping won't work because rubyzip is dumb...\" # unzip File . open ( @@TMP_ZIP , 'w+' ) do | save_file | # def self.unzip # zf = Zip::File.open('game-icons.net.svg.zip') # FAIL!! # # puts zf.get_next_entry # end", "commit_type": "use"}
{"commit_tokens": ["fixed", "sorting", "so", "that", "it", "resets", "properly", "in", "production", "mode"], "add_tokens": "@sorting ||= ActiveScaffold :: DataStructures :: Sorting . new ( @core . columns ) if @session [ 'sort' ] sorting = @conf . sorting . clone sorting . set ( * @session [ 'sort' ] ) return sorting else return @conf . sorting end", "del_tokens": "@sorting ||= ActiveScaffold :: DataStructures :: Sorting ( @core . columns ) @conf . sorting . set ( * @session [ 'sort' ] ) if @session [ 'sort' ] @conf . sorting", "commit_type": "fix"}
{"commit_tokens": ["updated", "documentation", "and", "bumped", "version"], "add_tokens": "VERSION = \"0.2.1\"", "del_tokens": "VERSION = \"0.2.0\"", "commit_type": "update"}
{"commit_tokens": ["Fixed", "possibly", "broken", "markup", "when", "using", "quotes", "in", "refresh", "meta", "tag", "added", "documentation"], "add_tokens": "# refresh \"5;url=http://www.example.com/\" result << tag ( :meta , 'http-equiv' => 'refresh' , :content => refresh . to_s ) unless refresh . blank?", "del_tokens": "# refresh \"5;URL='http://www.example.com/'\" result << tag ( :meta , \"http-equiv\" => \"refresh\" , \"content\" => refresh . to_s . html_safe ) unless refresh . blank?", "commit_type": "fix"}
{"commit_tokens": ["fix", "callbacks", "for", "inherited", "controllers", "append", "to", "controller", "registry", "using", "implements", "method"], "add_tokens": "require 'active_support/all' module Praxis class_attribute :before_callbacks , :after_callbacks , :around_callbacks self . before_callbacks = Hash . new self . after_callbacks = Hash . new self . around_callbacks = Hash . new Application . instance . controllers << self before_callbacks [ stage_path ] ||= Array . new before_callbacks [ stage_path ] << [ conditions , block ] after_callbacks [ stage_path ] ||= Array . new after_callbacks [ stage_path ] << [ conditions , block ] around_callbacks [ stage_path ] ||= Array . new around_callbacks [ stage_path ] << [ conditions , block ] def request @request end def response @response end def response = ( value ) @response = value end", "del_tokens": "module Praxis attr_reader :request attr_accessor :response Application . instance . controllers << self @before_callbacks = Hash . new @after_callbacks = Hash . new @around_callbacks = Hash . new attr_reader :before_callbacks , :after_callbacks , :around_callbacks @before_callbacks [ stage_path ] ||= Array . new @before_callbacks [ stage_path ] << [ conditions , block ] @after_callbacks [ stage_path ] ||= Array . new @after_callbacks [ stage_path ] << [ conditions , block ] @around_callbacks [ stage_path ] ||= Array . new @around_callbacks [ stage_path ] << [ conditions , block ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "rudimentary", "ability", "definitions", "to", "the", "generator", "."], "add_tokens": "require_relative '../../ability_definition' argument :ability_definitions , :type => :array , :default => [ ] , :banner => \"can:abilities:models cannot:abilities:models\" template \"abilities.rb.erb\" , \"app/abilities/#{file_name.pluralize}.rb\" private def definitions ( & block ) ability_definitions . each { | definition | AbilityDefinition . parse ( definition ) } AbilityDefinition . models . sort . each do | model , definition | yield model , definition end end", "del_tokens": "argument :abilities , :type => :array , :default => [ ] , :banner => \"ability:model ability:model\" template \"abilities.rb.erb\" , \"app/abilities/#{file_name}.rb\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", ".", "Fixed", "a", "bug", "which", "prevented", "saving", "a", "slugged", "model", "with"], "add_tokens": "previous_slug = slugs . find_by_name ( slug_text ) previous_slug . destroy if previous_slug # Remove diacritics from the string.", "del_tokens": "# Remove diacritis from the string.", "commit_type": "update"}
{"commit_tokens": ["fix", "client#me", "-", ">", "client#current_user", "test", ".", "move", "live", "collection", "spec", "to", "live", "/"], "add_tokens": "context \"#current_user\" , :vcr_off do client . current_user . should be_instance_of ( Zendesk :: User )", "del_tokens": "context \"#me\" , :vcr_off do client . me . should be_instance_of ( Zendesk :: User )", "commit_type": "fix"}
{"commit_tokens": ["Added", "working", "dir", "and", "user", "to", "varnishd"], "add_tokens": "attr_accessor :listen , :telnet , :sbin_path , :storage , :working_dir , :user , :params self . listen , self . telnet , self . sbin_path , self . storage , self . working_dir , self . user , self . params = settings . values_at ( \"listen\" , \"telnet\" , \"sbin_path\" , \"storage\" , \"working_dir\" , \"user\" , \"params\" ) \"-n\" => working_dir , \"-u\" => user ,", "del_tokens": "attr_accessor :listen , :telnet , :sbin_path , :storage , :params self . listen , self . telnet , self . sbin_path , self . storage , self . params = settings . values_at ( \"listen\" , \"telnet\" , \"sbin_path\" , \"storage\" , \"params\" )", "commit_type": "add"}
{"commit_tokens": ["Improve", "backtrace", "cleaner", "silencers", "for", ":", "app", "level"], "add_tokens": "class CustomLogSubscriber < ActiveRecord :: LogSubscriber # rubocop:disable Metrics/ClassLength return if ActiveRecordQueryTrace . level == :full remove_filters_and_silencers case ActiveRecordQueryTrace . level when :app Rails . backtrace_cleaner . add_silencer { | line | ! line . match ( rails_root_regexp ) } when :rails Rails . backtrace_cleaner . add_silencer { | line | line . match ( rails_root_regexp ) } def remove_filters_and_silencers Rails . backtrace_cleaner . remove_filters! Rails . backtrace_cleaner . remove_silencers! end # This cannot be set in a constant as Rails.root is not yet available when # this file is loaded. def rails_root_regexp %r{ #{ Regexp . escape ( Rails . root . to_s ) } (?! \\/ vendor) } end", "del_tokens": "class CustomLogSubscriber < ActiveRecord :: LogSubscriber return unless ActiveRecordQueryTrace . level == :rails Rails . backtrace_cleaner . remove_filters! Rails . backtrace_cleaner . remove_silencers! Rails . backtrace_cleaner . add_silencer do | line | line . match ( %r{ #{ Regexp . escape ( Rails . root . to_s ) } (?!/vendor) } )", "commit_type": "improve"}
{"commit_tokens": ["Remove", "find", "by", "id", "."], "add_tokens": "@page = Page . find_by_link_url ( params [ :path ] . to_s . split ( '/' ) . last ) #(params[:path] ? params[:path].to_s.split('/').last : params[:id])", "del_tokens": "if params [ :id ] @page = Page . find ( params [ :id ] ) else @page = Page . find_by_link_url ( params [ :path ] . to_s . split ( '/' ) . last ) #(params[:path] ? params[:path].to_s.split('/').last : params[:id]) end", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "date", "rollover", "error", "in", "usage", "tracker"], "add_tokens": "year = now . year year += 1 if nextMonth == 1 Time . local ( year , nextMonth , @resetDay )", "del_tokens": "Time . local ( now . year , nextMonth , @resetDay )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "nonce", "so", "it", "s", "not", "time", "-", "based"], "add_tokens": "len = 16 SecureRandom . random_number ( 10 ** len ) . to_s . ljust ( len , '0' )", "del_tokens": "Time . now . to_i . to_s . ljust ( 16 , '0' )", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "has_raw_char?", "method", "."], "add_tokens": "# Is there a character waiting? def self . has_raw_char? kbhit != 0 end # Get a uncooked character keystroke.", "del_tokens": "#Get a uncooked character keystroke.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "dns", "reserve", "retry", ".", "Use", "deployment", "href", "for", "sbd", "key", ".", "Reuse", "DNS", "entry", "if", "already", "reserved"], "add_tokens": "server . spot_check_command ( \"service mysqld start\" ) #TODO the service name depends on the OS # server.spot_check_command(\"service mysql start\") # TODO should we just use the ID instead of the full href? owner = @deployment . href", "del_tokens": "server . spot_check_command ( \"service mysql start\" ) owner = \"Erik\"", "commit_type": "fix"}
{"commit_tokens": ["move", "RoundPlayer", "to", "Round", "::", "Player"], "add_tokens": "require 'ruby_holdem/round/player'", "del_tokens": "require 'ruby_holdem/round_player'", "commit_type": "move"}
{"commit_tokens": ["Use", "ENV", "[", "https_proxy", "]", "only", "for", "https", ":", "//"], "add_tokens": "if URI :: HTTPS === URI . parse ( req [ :url ] ) RestClient . proxy = ENV [ 'https_proxy' ] || ENV [ 'http_proxy' ] else RestClient . proxy = ENV [ 'http_proxy' ] end", "del_tokens": "RestClient . proxy = ENV [ 'https_proxy' ] || ENV [ 'http_proxy' ]", "commit_type": "use"}
{"commit_tokens": ["Improved", "the", "Request", "class", "and", "related", "specs"], "add_tokens": "# Adds another line to the request # Checks whether the given line type was parsed from the log file for this request def has_line_type? ( line_type ) @lines . detect { | l | l [ :line_type ] == line_type . to_sym } end alias :=~ :has_line_type? # Returns the value that was captured for the \"field\" of this request. # This function will return the first value that was captured if the field # was captured in multiple lines for a combined request. def first ( field ) alias :[] :first # Returns an array of all the \"field\" values that were captured for this request def every ( field ) @lines . inject ( [ ] ) { | result , fields | result << fields [ field ] if fields . has_key? ( field ) ; result } end", "del_tokens": "def =~ ( line_type ) @lines . detect { | l | l [ :line_type ] == line_type . to_sym } end def [] ( field )", "commit_type": "improve"}
{"commit_tokens": ["Make", "sure", "#to_set", "and", "#to_ary", "returned", "Set", "and", "Array", "instances", "only"], "add_tokens": "it { should be_instance_of ( Set ) }", "del_tokens": "it { should be_kind_of ( Set ) }", "commit_type": "make"}
{"commit_tokens": ["Allow", "passing", "of", "the", "deployed", "environment", "for", "capistrano", "."], "add_tokens": "rake = fetch ( :rake , \"rake\" ) rails_env = fetch ( :rails_env , \"production\" ) bugsnag_env = fetch ( :bugsnag_env , rails_env ) rake_command = \"cd '#{current_path}' && RAILS_ENV=#{rails_env} #{rake} bugsnag:deploy\" \"BUGSNAG_RELEASE_STAGE\" => bugsnag_env , \"BUGSNAG_REVISION\" => fetch ( :current_revision , nil ) , \"BUGSNAG_REPOSITORY\" => fetch ( :repository , nil ) , \"BUGSNAG_BRANCH\" => fetch ( :branch , nil ) } . reject { | _ , v | v . nil? }", "del_tokens": "rake = fetch ( :rake , \"rake\" ) rails_env = fetch ( :rails_env , \"production\" ) rake_command = \"cd '#{current_path}' && #{rake} bugsnag:deploy RAILS_ENV=#{rails_env}\" \"BUGSNAG_RELEASE_STAGE\" => rails_env , \"BUGSNAG_REVISION\" => fetch ( :current_revision , nil ) , \"BUGSNAG_REPOSITORY\" => fetch ( :repository , nil ) , \"BUGSNAG_BRANCH\" => fetch ( :branch , nil ) } . reject { | k , v | v . nil? }", "commit_type": "allow"}
{"commit_tokens": ["Remove", "before", "and", "after", "transfer", "message"], "add_tokens": "attr_reader :current_state , :state_names , :extra_names @extra_names = args [ :extra_names ] || [ ]", "del_tokens": "attr_reader :current_state , :state_names", "commit_type": "remove"}
{"commit_tokens": ["Add", "callbacks", "to", "make", "sure", "we", "have", "an", "open", "changeset", "."], "add_tokens": "xit \"should produce xml\" do", "del_tokens": "it \"should produce xml\" do", "commit_type": "add"}
{"commit_tokens": ["added", "lexical", "information", "for", "synsets", "and", "added", "examples", "to", "examples", ".", "rb"], "add_tokens": "puts wordnet . find ( 'bat' ) . synsets ( 'verb' ) . first . lexical . inspect puts wordnet . find ( 'bat' ) . synsets ( 'verb' ) . first . lexical_description", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "basic", "support", "for", "sorting", "to", "VeritasMapper", ".", "find"], "add_tokens": "query = conditions . dup order = query . delete ( :order ) query . inject ( TAUTOLOGY ) do | predicate , ( attribute , value ) | predicate . and ( r . send ( attributes . field_name ( attribute ) ) . eq ( value ) ) end end if order restriction = restriction . sort_by do | r | # TODO: automatically fill in missing attributes as veritas requires # all attributes from the header order . map { | attribute | r . send ( attributes . field_name ( attribute ) ) }", "del_tokens": "conditions . inject ( TAUTOLOGY ) do | predicate , ( attribute , value ) | field = attributes [ attribute ] . field predicate . and ( r . send ( field ) . eq ( value ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "word", "left", "and", "right", "commands", "."], "add_tokens": "VERSION = \"0.0.4\"", "del_tokens": "VERSION = \"0.0.3\"", "commit_type": "add"}
{"commit_tokens": ["fix", "timeout", "/", "ssl", "options"], "add_tokens": "VERSION = \"1.0.2\"", "del_tokens": "VERSION = \"1.0.1\"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "DSL", "for", "module", "inclusion"], "add_tokens": "builder = Builder . new Hash ( config )", "del_tokens": "builder = Builder . new", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "to", "override", "default", "form", "fields", "using", "helper", "methods"], "add_tokens": "val = render_field item , field def render_field item , field if self . respond_to? ( helper = \"#{params[:action]}_#{field}\" ) || self . respond_to? ( helper = \"#{field}\" ) send helper , item # ============================================================================= def render_form_field form , field if self . respond_to? ( helper = \"#{params[:action]}_form_#{field.name}\" ) || self . respond_to? ( helper = \"form_#{field.name}\" ) send helper , form elsif field . association? form . association field . name else form . input field . name end end", "del_tokens": "val = display_field_value item , field def display_field_value item , field if self . respond_to? \"#{params[:action]}_#{field}\" send \"#{params[:action]}_#{field}\" , item elsif self . respond_to? \"#{field}\" send \"#{field}\" , item", "commit_type": "add"}
{"commit_tokens": ["Move", "GL", "accounts", "to", "common", "hash"], "add_tokens": "# Do freshly created SKUs default to being backorderable? config_option :skus_backorder_default , true # The code for a Sku that represents tax config_option :tax_sku_code , 'TAX' # Code for a Sku that represents shipping charges config_option :ship_sku_code , 'SHIP' config_option :default_gl_accounts , { # The Accounts Receivable (AR) GL account number to use for freshly created Customers ar : '1200' , # The Accounts Payable (AP) GL account number to use for freshly created Vendors ap : '2200' , # The Freight GL account number to use for freshly created Vendors freight : '6420' , # The Asset GL account number to use for freshly created SKUs asset : '1100' , # Clearing account for inventory that's been inventory_receipts_clearing : '2600' }", "del_tokens": "# The Accounts Payable (AP) GL account number to use for freshly created Vendors config_option :default_gl_ap_account_number , '2200' # The Accounts Receivable (AR) GL account number to use for freshly created Customers config_option :default_gl_ar_account_number , '1200'", "commit_type": "move"}
{"commit_tokens": ["fix", "xmlId", "references", "and", "method", "to", "local_method"], "add_tokens": "return item . resource if item . id == id || item . resource . id == id", "del_tokens": "return item . resource if item . xmlId == id || item . resource . xmlId == id", "commit_type": "fix"}
{"commit_tokens": ["added", "ability", "to", "inject", "javascript", "SDK"], "add_tokens": "if opts [ :js ] js_opts = opts [ :js ] . is_a? ( Hash ) ? opts [ :js ] : { } js_host = js_opts [ :host ] || 'https://tools.translationexchange.com/tml/stable/tml.min.js' html = [ ] html << \"<script src='#{js_host}'></script>\" html << '<script>' html << 'tml.init({' html << \" key: '#{tml_application.key}', \" html << \" token: '#{tml_application.token}', \" html << \" debug: #{js_opts[:debug] || false},\" if js_opts [ :onload ] html << ' onLoad: function() {' html << \" #{js_opts[:onload]}\" html << ' }' end html << '});' html << '</script>' return html . join . html_safe end agent_config = Tml . config . respond_to? ( :agent ) ? Tml . config . agent : { }", "del_tokens": "agent_config = Tml . config . respond_to? ( :agent ) ? Tml . config . agent : { }", "commit_type": "add"}
{"commit_tokens": ["adding", ".", "each", "and", ".", "to_json", "to", "Snort", "::", "Rule"], "add_tokens": "VERSION = \"1.5.5\"", "del_tokens": "VERSION = \"1.5.4\"", "commit_type": "add"}
{"commit_tokens": ["Changed", "Blast", "exit_status", "to", "0", "if", "report", "is", "empty", ".", "Added", "empty", "arg", "to", "quorum", ":", "blastdb", ":", "build", "task", "spec", "."], "add_tokens": "@logger . log ( \"ActiveRecord\" , e . message , 1 ) \"Unable to save #{@algorithm} results to database.\" , 1 , \"Unable to save #{@algorithm} results to database.\" , 1 , \"#{@algorithm} report empty.\" , 0 , \"Unable to save #{@algorithm} results to database.\" , 1 ,", "del_tokens": "@logger . log ( \"ActiveRecord\" , e . message , 80 ) \"Unable to save Blast results to database.\" , 81 , \"Unable to save Blast results to database.\" , 81 , \"Blast Report empty.\" , 71 , \"Unable to save Blast results to database.\" , 81 ,", "commit_type": "change"}
{"commit_tokens": ["Add", "submodule", "for", "qless", "-", "core", "."], "add_tokens": "LUA_SCRIPT_DIR = File . expand_path ( \"../qless-core/\" , __FILE__ ) @sha = @redis . script ( :load , File . read ( File . join ( LUA_SCRIPT_DIR , \"#{@name}.lua\" ) ) )", "del_tokens": "require 'qless/core' @sha = @redis . script ( :load , Qless :: Core . script_contents ( @name ) )", "commit_type": "add"}
{"commit_tokens": ["updated", "tests", "to", "include", "updating", "a", "serialized", "field", "through", "a", "nested", "association"], "add_tokens": "", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Move", "existing", "Template", "exporter", "under", ":", "v1"], "add_tokens": "exporter = Dradis :: Plugins :: Projects :: Export :: V1 :: Template . new (", "del_tokens": "exporter = Dradis :: Plugins :: Projects :: Export :: Template . new (", "commit_type": "move"}
{"commit_tokens": ["Improve", "formatting", "with", "Rubocop", "suggestions"], "add_tokens": "Bundler . setup", "del_tokens": "require File . expand_path '../simplify_test_data.rb' , __FILE__ Bundler . setup", "commit_type": "improve"}
{"commit_tokens": ["Fix", "issues", "arising", "when", "ActiveSupport", "mangles", "the", "Date", ".", "xmlschema", "method"], "add_tokens": "text = value . iso8601 # use iso8601 instead of xmlschema in case of ActiveSupport shenanigans ( zulu && ! text . end_with? ( 'Z' ) ) ? \"#{text}Z\" : text", "del_tokens": "text = value . xmlschema zulu ? \"#{text}Z\" : text", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "friendly_id", "generation", "crapout", "when", "generated", "slug", "appears", "to", "end", "in"], "add_tokens": "def test_should_ensure_truncated_slugs_are_unique def test_should_not_give_up_damnit p = Post . create! ( :name => \"Post 2/4\" ) q = Post . create! ( :name => \"Post\" ) end", "del_tokens": "def test_should_ensure_truncate_slugs_are_unique", "commit_type": "fix"}
{"commit_tokens": ["add", "missing", "module", "prefix", "to", "Location", "use"], "add_tokens": "OSC :: Machete :: Location . new ( staged_dir ) . render ( template_view )", "del_tokens": "Location . new ( staged_dir ) . render ( template_view )", "commit_type": "add"}
{"commit_tokens": ["removed", "isolated", "namespace", "all", "together"], "add_tokens": "VERSION = \"0.0.11\"", "del_tokens": "VERSION = \"0.0.10\"", "commit_type": "remove"}
{"commit_tokens": ["Fix", "a", "bug", "in", "Mapper", ";", "rename", "parameters", "to", "avoid", "confusion"], "add_tokens": "mapper = self . new ( session , net_info . docker_routable_ip , strict : strict ) # @param [String] docker_host DNS hostnrame or IPv4 address of the host # that is publishing Docker services (i.e. the `DOCKER_HOST` hostname or # IP if you are using a non-clustered Docker environment) # syntax is passed to #map; if false, simply return unrecognized # values without substituting anything def initialize ( session , docker_host , strict : true ) @docker_host = docker_host uri . host = @docker_host return @docker_host return \"#{@docker_host}:#{port}\"", "del_tokens": "mapper = self . new ( session , net_info . host_routable_ip , strict : strict ) # @param [String] host_ip IPv4 address of the host that is publishing # Docker services (i.e. the `DOCKER_HOST` hostname or IP if you are using # a non-clustered Docker environment) # syntax is passed to #map; if false, simply return the value without # substituting anything def initialize ( session , host_ip , strict : true ) @host_ip = host_ip uri . host = @host_ip return @host_ip return \"#{@host_ip}:#{port}\"", "commit_type": "fix"}
{"commit_tokens": ["Remove", "from", "stale", "and", "incorrect", "path", "mangling", "from", "add_job_keys", "()", "."], "add_tokens": "data = obj_paths . join ( \"\\n\" )", "del_tokens": "data = obj_paths . map { | p | '/' + @user + '/stor' + p } . join ( \"\\n\" )", "commit_type": "remove"}
{"commit_tokens": ["change", "the", "name", "of", "class", "InlineStack", "to", "InlineParser"], "add_tokens": "class InlineParser < TreeStack class InlineNode < InlineParser :: Node ; end class InlineLeaf < InlineParser :: Leaf ; end include InlineParser :: InlineElement include InlineParser :: InlineElement", "del_tokens": "class InlineStack < TreeStack class InlineNode < InlineStack :: Node ; end class InlineLeaf < InlineStack :: Leaf ; end include InlineStack :: InlineElement include InlineStack :: InlineElement", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "RT", "Plan", "attributes"], "add_tokens": "# The RT Plan Label. attr_accessor :label # The RT Plan Name. attr_accessor :name # The RT Plan Description. attr_accessor :plan_description label = dcm . value ( RT_PLAN_LABEL ) name = dcm . value ( RT_PLAN_NAME ) plan_description = dcm . value ( RT_PLAN_DESCR ) plan = self . new ( sop_uid , struct , :class_uid => class_uid , :date => date , :time => time , :description => description , :series_uid => series_uid , :label => label , :name => name , :plan_description => plan_description ) @label = options [ :label ] @name = options [ :name ] @plan_description = options [ :plan_description ] [ @beams , @rt_doses , @rt_images , @setup , @sop_uid ]", "del_tokens": "# The patient position. attr_reader :patient_position plan = self . new ( sop_uid , struct , :class_uid => class_uid , :date => date , :time => time , :description => description , :series_uid => series_uid ) [ @beams , @patient_position , @rt_doses , @rt_images , @setup , @sop_uid ]", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "specify", "the", "colorspace", "used", "with", "image", "magic"], "add_tokens": "colorspace = options . fetch ( :colorspace , Grim :: COLORSPACE ) \"-quality\" , quality . to_s , \"-colorspace\" , colorspace , end", "del_tokens": "\"-quality\" , quality . to_s , \"-colorspace\" , \"RGB\" , end", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "the", "pid", "and", "socket", "directories", "exist"], "add_tokens": "require 'fileutils' FileUtils . mkdir_p ( options [ :pid_dir ] ) FileUtils . mkdir_p ( File . dirname ( socket_path ) ) :: Dynflow :: Listeners :: Socket . new ( world , socket_path )", "del_tokens": ":: Dynflow :: Listeners :: Socket . new ( world , socket_path )", "commit_type": "make"}
{"commit_tokens": ["Added", "valid_read_file!", "robustness", "utility", "and", "IOAccessError", "."], "add_tokens": "# found (typically by delegators). # # This error can be raised to indicate that some file/dir # access has failed. # # Default exit code: # -1 # # Default reaction: # raise Exit.new(code), message, backtrace # class IOAccessError < Error def initialize ( * args ) super ( * ( args + [ - 1 ] ) ) end def react! raise Exit . new ( self . exit_code ) , self . message , backtrace end end # class IOAccessError", "del_tokens": "# found (typically by delegates).", "commit_type": "add"}
{"commit_tokens": ["Fix", "search_form_for", "fail", "to", "assign", "new", ":", "class", "and", ":", "id", "in", "options", "so", "now", "search_form_for", "works", "with", "Bootstrap", "."], "add_tokens": ":class => options [ :class ] . present? ? \"#{options[:class]}\" : \"#{search.klass.to_s.underscore}_search\" , :id => options [ :id ] . present? ? \"#{options[:id]}\" : \"#{search.klass.to_s.underscore}_search\" ,", "del_tokens": ":class => options [ :as ] ? \"#{options[:as]}_search\" : \"#{search.klass.to_s.underscore}_search\" , :id => options [ :as ] ? \"#{options[:as]}_search\" : \"#{search.klass.to_s.underscore}_search\" ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "keywords", "not", "properly", "updated"], "add_tokens": "keyword = Nokogiri :: XML :: Node . new ( 'keyword' , @data ) keyword . content = word", "del_tokens": "keyword = Nokogiri :: XML :: Node . new ( 'Keyword' , @data )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ruby_dll_path", "to", "use", "GetModuleFileName"], "add_tokens": "dlload \"kernel32\" extern \"int GetModuleFileNameA(int, char *, int)\" ruby_bin_path_buf = Fiddle :: Pointer . malloc ( 1000 ) GetModuleFileNameA ( 0 , ruby_bin_path_buf , ruby_bin_path_buf . size ) ruby_bin_path = ruby_bin_path_buf . to_s . gsub ( / \\\\ / , '/' ) ruby_dll_paths = File . dirname ( ruby_bin_path ) + '/msvcr*ruby*.dll' ruby_dll_path = Dir . glob ( ruby_dll_paths ) . first dlload ruby_dll_path", "del_tokens": "rubydll_path = Dir . glob ( RbConfig . expand ( \"$(bindir)\" ) + \"/msvcr*ruby*.dll\" ) . first dlload rubydll_path", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "support", "different", "slave", "instances", "for", "all", "clients"], "add_tokens": "@slave = TCPClient . new ( '127.0.0.1' , 1502 ) . with_slave ( 1 ) @slave . debug = true @slave . query ( request ) @slave . query ( request ) @adu = @slave . transaction . next . to_word + \"\\x0\\x0\\x0\\x9\" + UID . chr + request @slave = RTUClient . new ( \"/dev/port1\" , 9600 , :data_bits => 7 , :stop_bits => 2 , :parity => SerialPort :: ODD ) . with_slave ( 1 ) @slave . read_retries = 0 @slave . debug = true @slave . query ( request ) . should == \"\\xff\\xff\"", "del_tokens": "UID = 1 @mb_client = TCPClient . new ( '127.0.0.1' , 1502 ) @mb_client . debug = true @mb_client . query ( request ) @mb_client . query ( request ) @adu = @mb_client . transaction . next . to_word + \"\\x0\\x0\\x0\\x9\" + UID . chr + request @mb_client = RTUClient . new ( \"/dev/port1\" , 9600 , 1 , :data_bits => 7 , :stop_bits => 2 , :parity => SerialPort :: ODD ) @mb_client . read_retries = 0 @mb_client . debug = true @mb_client . query ( request ) . should == \"\\xff\\xff\"", "commit_type": "add"}
{"commit_tokens": ["Use", "Mail#", "{", "html", "text", "}", "_part", "instead", "of", "finding", "them"], "add_tokens": "email . html_part . body . decoded . should == 'html' email . text_part . body . decoded . should == 'Hello Text'", "del_tokens": "email . parts . find { | part | part . mime_type == 'text/html' } . body . decoded . should == 'html' email . parts . find { | part | part . mime_type == 'text/plain' } . body . decoded . should == 'Hello Text'", "commit_type": "use"}
{"commit_tokens": ["Adding", "the", "ability", "to", "write", "GPX", "to", "a", "string", "in", "addition", "to", "a", "file", ".", "Thanks", "to", "Douglas", "Robertson", "for", "the", "patch", "."], "add_tokens": "@time = Time . now if ( @time . nil? or update_time ) @name ||= File . basename ( filename ) doc = generate_xml_doc doc . save ( filename , :indent => true ) end def to_s ( update_time = true ) @time = Time . now if ( @time . nil? or update_time ) doc = generate_xml_doc doc . to_s end private def generate_xml_doc name_elem << @name time_elem << @time . xmlschema return doc", "del_tokens": "name_elem << File . basename ( filename ) @time = Time . now if ( @time . nil? or update_time ) time_elem << @time . xmlschema doc . save ( filename , :indent => true ) private", "commit_type": "add"}
{"commit_tokens": ["Add", "rubocop", "in", "rakefile", "default", "task"], "add_tokens": "preload_regex = / gsPreloadAjax \\( \\{ url: ' \\/ preload.php \\? (.*)&hash=' \\+ clientPage \\} \\) / # rubocop:disable Metrics/LineLength", "del_tokens": "preload_regex = / gsPreloadAjax \\( \\{ url: ' \\/ preload.php \\? (.*)&hash=' \\+ clientPage \\} \\) / # rubocop:disable gnore Metrics/LineLength", "commit_type": "add"}
{"commit_tokens": ["Add", "data", "bag", "item", "encryption"], "add_tokens": "def json_differences ( old_json , new_json , print_values = true , name = '' , result = nil ) result ||= [ ] json_differences_internal ( old_json , new_json , print_values , name , result ) result end def json_differences_internal ( old_json , new_json , print_values , name , result ) json_differences_internal ( old_json [ new_key ] , new_value , print_values , name == '' ? new_key : \"#{name}.#{new_key}\" , result ) if print_values result << \"add #{name == '' ? new_key : \"#{name}.#{new_key}\"} = #{new_value.inspect}\" else result << \"add #{name == '' ? new_key : \"#{name}.#{new_key}\"}\" end elsif old_json != new_json if print_values result << \"update #{name} from #{old_json.inspect} to #{new_json.inspect}\" else result << \"update #{name}\" end", "del_tokens": "def json_differences ( old_json , new_json , name = '' ) result = [ ] result += json_differences ( old_json [ new_key ] , new_value , name == '' ? new_key : \"#{name}.#{new_key}\" ) result << \"add #{name == '' ? new_key : \"#{name}.#{new_key}\"} = #{new_value.inspect}\" result elsif old_json == new_json [ ] else [ \"update #{name} from #{old_json.inspect} to #{new_json.inspect}\" ]", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "instance", "level", "configuration"], "add_tokens": "class Prowler attr_accessor :api_key , :provider_key attr_accessor :application , :send_notifications # Create an instance for sending to different accounts within a single Rails application # * api_key: Your API key. # * application: The name of your application. # * provider_key: Key to override the rate limit of 1000 requests per hour. (Optional) def initialize ( api_key , application , provider_key = nil ) @api_key , @application , @provider_key = api_key , application , provider_key end # Send a notification to your iPhone: # * event: The title of notification you want to send. # * message: The text of the notification message you want to send. # * priority: The priority of the notification - see Prowler::Priority. (Optional) def notify ( event , message , priority = Priority :: NORMAL ) raise ConfigurationError , \"You must provide an API key to send notifications\" if api_key . nil? raise ConfigurationError , \"You must provide an application name to send notifications\" if application . nil? self . class . perform ( :add , api_key , provider_key , { :application => application , :event => event , :description => message , :priority => priority } ) end # Verify the configured API key is valid def verify raise ConfigurationError , \"You must provide an API key to verify\" if api_key . nil? self . class . perform ( :verify , api_key , provider_key , { } , :get ) end", "del_tokens": "module Prowler", "commit_type": "add"}
{"commit_tokens": ["Add", "hive", "job", "id", "and", "application", "version"], "add_tokens": ":optional => [ :hive_job_id , :queue , :cert , :cacert , :ssl_verify_mode , :device_type , :version ] , :version => config . version , :hive_job_id => config . hive_job_id ,", "del_tokens": ":optional => [ :hive_job_id , :queue , :cert , :cacert , :ssl_verify_mode , :device_type ] ,", "commit_type": "add"}
{"commit_tokens": ["added", ":", "input_blank", "=", ">", "true", "supprot", "to", "date", "time", "datetime", "and", "boolean_select"], "add_tokens": "input_label ( method , options ) + template . select ( @object_name , method , choices , options ) template . send ( \"select_#{input}\" . intern , @object . send ( method ) , :prefix => @object_name , :field_name => \"#{method}(#{position[input]}i)\" , :include_blank => options [ :include_blank ] ) input_label ( method , options ) + template . select ( @object_name , method , choices , options )", "del_tokens": "options [ :include_blank ] ||= false options [ :prompt ] ||= nil input_label ( method , options ) + template . select ( @object_name , method , choices , { :include_blank => options [ :include_blank ] , :prompt => options [ :prompt ] } ) template . send ( \"select_#{input}\" . intern , @object . send ( method ) , :prefix => @object_name , :field_name => \"#{method}(#{position[input]}i)\" ) input_label ( method , options ) + template . select ( @object_name , method , choices )", "commit_type": "add"}
{"commit_tokens": ["Updated", "classes", "and", "fixed", "some", "bugs", "."], "add_tokens": "url = \"projects/#{project_id}/todos/#{todo_id}.json\" response = Basecampeverest :: Connect . get url # find a specific todo via the Basecamp API # # @param [Basecampeverest::TodoItem] # @return [Basecampeverest::TodoItem] all todo lists for all projects from the Basecamp API def self . new ( project_id , todo_id , options = { } ) post_params = { :body => options . to_json , :headers => Basecampeverest :: Connect . headers . merge ( { 'Content-Type' => 'application/json' } ) } url = \"/projects/#{project_id}/todolists/#{todo_id}/todos.json\" # make the http basecamp call response = Basecampeverest :: Connect . post url , post_params # parse the response to remove HTTParty info response . parsed_response end", "del_tokens": "response = Basecampeverest :: Connect . get \"/todolists.json\"", "commit_type": "update"}
{"commit_tokens": ["Fix", "success", "/", "failure", "feature", "status", "bug"], "add_tokens": "success = Scenario . new ( feature_name , scenario ) . run @failed = true unless success @failed = true run_hook :after_run , data return ! @failed", "del_tokens": "@success = Scenario . new ( feature_name , scenario ) . run run_hook :after_run , data return ! ! @success", "commit_type": "fix"}
{"commit_tokens": ["Removed", "the", "access_key", "/", "secret_access_key", "from", "the", "actionable", "options", "on", "the", "base"], "add_tokens": "@options ||= default_options . merge ( h )", "del_tokens": "def actionable_default_options default_options . merge! ( { :access_key => self . access_key , :secret_access_key => secret_access_key } ) end @options ||= actionable_default_options . merge ( h )", "commit_type": "remove"}
{"commit_tokens": ["Upgrade", "to", "HPACK", "-", "09", "."], "add_tokens": "bytes . should_not match ( 'www.example.org' ) # should be huffman encoded ':authority' => 'www.example.org' ,", "del_tokens": "@conn . ping ( \"12345678\" ) bytes . should match ( 'www.example.org' ) ':host' => 'www.example.org' ,", "commit_type": "upgrade"}
{"commit_tokens": ["Make", "random_example_spec", ".", "rb", "tests", "time", "-", "safe"], "add_tokens": "require \"timecop\" # freeze time to avoid inconsistent `public_updated_at` values between runs Timecop . freeze do srand ( 777 ) # these srand calls would be in the upstream application first_payload = GovukSchemas :: RandomExample . new ( schema : schema ) . payload srand ( 777 ) second_payload = GovukSchemas :: RandomExample . new ( schema : schema ) . payload expect ( first_payload ) . to eql ( second_payload ) end", "del_tokens": "srand ( 777 ) # these srand calls would be in the upstream application first_payload = GovukSchemas :: RandomExample . new ( schema : schema ) . payload srand ( 777 ) second_payload = GovukSchemas :: RandomExample . new ( schema : schema ) . payload expect ( first_payload ) . to eql ( second_payload )", "commit_type": "make"}
{"commit_tokens": ["fixed", "block", "passing", "in", "execute_download"], "add_tokens": "execute_internal ( json_request , & block ) req . on_body ( & block )", "del_tokens": "execute_internal ( json_request , block ) req . on_body ( block )", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "@announce", "tag", "which", "is", "useful", "for", "seeing", "what", "s", "outputted", ".", "Also", "properly", "escaped", "newlines", "."], "add_tokens": "def run ( command , world = nil , announce = nil ) if ( announce ) world ? world . announce ( command ) : STDOUT . puts ( command ) end", "del_tokens": "def run ( command )", "commit_type": "add"}
{"commit_tokens": ["added", "#activate", "and", "#active?", "for", "FFI", "adapter"], "add_tokens": "restore if minimized? Functions . activate_window ( hwnd ) sleep 1 Functions . foreground_window == hwnd", "del_tokens": "#@@autoit.WinWait(locator_hwnd, \"\", 1) #@@autoit.WinActivate(locator_hwnd) #sleep 1 #@@autoit.WinActive(locator_hwnd) == 1", "commit_type": "add"}
{"commit_tokens": ["added", "parse", "method", "to", "packagist"], "add_tokens": "PLATFORM_NAME = 'Packagist' def self . parse ( filename , file_contents ) json = JSON . parse ( file_contents ) if filename . match ( / ^composer \\. json$ / ) parse_manifest ( json ) elsif filename . match ( / ^composer \\. lock$ / ) parse_lockfile ( json ) else [ ] end end platform : PLATFORM_NAME , platform : PLATFORM_NAME ,", "del_tokens": "platform : 'Packagist' , platform : 'Packagist' ,", "commit_type": "add"}
{"commit_tokens": ["moved", "that", "time_range", "code", "over", "to", "an", "helper", "method", "so", "it", "s", "easier", "to", "switch", "from", "cookies", "to", "params", "without", "much", "change", "in", "dashboard", ".", "rb"], "add_tokens": "@range = time_range", "del_tokens": "@range = ( request . cookies [ \"_rarng\" ] || RedisAnalytics . default_range ) . to_sym # should first try to fetch from cookie what the default range is # @data[range] = DataStore.fetch_data_for_range(time_range)", "commit_type": "move"}
{"commit_tokens": ["updated", "test", "formats", "and", "added", "a", "desired", "extension"], "add_tokens": ":full => { :preset => \"320kbps\" , :extension => \".wav\" } , :large => { :preset => \"256kbps\" , :extension => \".wav\" } , :small => { :preset => \"128kbps\" , :extension => \".wav\" } ,", "del_tokens": ":small => { :preset => \"128kbps\" } , :large => { :preset => \"256kbps\" } ,", "commit_type": "update"}
{"commit_tokens": ["Implement", "feedback", "suggestions", "and", "add", "tests", "."], "add_tokens": "raise ActionViewHelperError , \"Error occured while contacting gateway : #{json['error']}\" if json [ 'error' ] rescue JSON :: ParserError raise ActionViewHelperError , 'Invalid response from gateway. Please try again.'", "del_tokens": "raise ActionViewHelperError , \"Response invalid %s\" % data if json . nil? raise ActionViewHelperError , \"JSON error %s\" % JSON . pretty_generate ( json ) unless json [ 'success' ]", "commit_type": "implement"}
{"commit_tokens": ["Add", "Bunny", "::", "Channel#basic_publish", "functionality"], "add_tokens": "@connection . register_exchange xchg_find_or_create ( name , opts ) ## # Mocks Bunny::Channel#basic_publish # # @param [String] payload Message payload. It will never be modified by Bunny or RabbitMQ in any way. # @param [String] exchange Exchange to publish to # @param [String] routing_key Routing key # @param [Hash] opts Publishing options # @return [BunnyMock::Channel] Self def basic_publish ( payload , xchg , routing_key , opts = { } ) xchg = xchg_find_or_create ( xchg ) unless xchg . respond_to? :name xchg . publish payload , opts . merge ( routing_key : routing_key ) self end private def xchg_find_or_create ( name , opts = { } ) @connection . find_exchange ( name ) || Exchange . declare ( self , name , opts ) end", "del_tokens": "xchg = @connection . find_exchange ( name ) || Exchange . declare ( self , name , opts ) @connection . register_exchange xchg", "commit_type": "add"}
{"commit_tokens": ["Add", "rspec", "test", "for", "LetsEncrypt"], "add_tokens": "return File . open ( private_key_path ) if File . exist? ( private_key_path )", "del_tokens": "return File . open ( private_key_path ) if private_key_path . exist?", "commit_type": "add"}
{"commit_tokens": ["fixing", "errors", "with", "test", "suite"], "add_tokens": "raise \"Confirmation Failed: #{response.inspect}\" end @@templates = Dir . glob ( File . expand_path ( File . join ( File . dirname ( __FILE__ ) , 'templates' , '*.haml' ) ) ) raise \"Missing @@config File! Please add sms.yml to ./config or the 4info directory\" @@config = YAML . load ( ERB . new ( File . read ( config_file ) ) . render ) [ '4info' ] xml = template ( :confirm ) . render ( @@config . merge ( :number => format_number ( number ) ) ) file = @@templates . detect { | t | File . basename ( t ) . chomp ( '.haml' ) == name }", "del_tokens": "Templates = Dir . glob ( File . expand_path ( File . join ( File . dirname ( __FILE__ ) , 'templates' , '*.haml' ) ) ) raise \"Missing Config File! Please add sms.yml to ./config or the 4info directory\" Config = YAML . load ( ERB . new ( File . read ( config_file ) ) . render ) [ '4info' ] xml = template ( :confirm ) . render ( Config . merge ( :number => format_number ( number ) ) ) file = Templates . detect { | t | File . basename ( t ) . chomp ( '.haml' ) == name }", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "handle", "new", "retrospec", "template", "rendering"], "add_tokens": "templates = Find . find ( File . join ( template_dir , 'module_files' ) ) . sort dest = template . gsub ( File . join ( template_dir , 'module_files' ) , module_path ) # because some plugins contain erb files themselves any erb file will be copied only # so we need to designate which files should be rendered with .retrospec.erb if template =~ / \\. retrospec \\. erb / # render any file ending in .retrospec_erb as a template dest = dest . gsub ( / \\. retrospec \\. erb / , '' ) safe_create_template_file ( dest , template , context ) else safe_copy_file ( template , dest ) end def safe_create_resource_spec_files ( type , template = File . join ( template_dir , 'resource_spec_file.retrospec.erb' ) ) def safe_create_acceptance_tests ( type , template = File . join ( template_dir , 'acceptance_spec_test.retrospec.erb' ) )", "del_tokens": "templates = Find . find ( File . join ( template_dir , 'module_files' ) ) . find_all { | f | ! File . directory? ( f ) } . sort dest = template . gsub ( File . join ( template_dir , 'module_files' ) , module_path ) . gsub ( '.erb' , '' ) safe_create_template_file ( dest , template , context ) def safe_create_resource_spec_files ( type , template = File . join ( template_dir , 'resource_spec_file.erb' ) ) def safe_create_acceptance_tests ( type , template = File . join ( template_dir , 'acceptance_spec_test.erb' ) )", "commit_type": "update"}
{"commit_tokens": ["Added", "fried", "struct", "and", "data", "entity", "schemas"], "add_tokens": "# Holds defined attributes for a given {Class} private attr_reader :attributes public def initialize @attributes = { } end # @param attribute_definition [Attribute::Definition] # @return [Attribute::Definition] def add_attribute ( definition ) name = definition . name attributes [ name ] = definition # List all attributes. If no block is passed, returns an enumerator, # otherwise it returns the last value returned by the block # @return [Enumerator, Object] def each_attribute ( & block ) return attributes_enumerator if block . nil? attributes_enumerator . each ( & block ) end private def attributes_enumerator Enumerator . new ( attributes . size ) do | yielder | attributes . each { | _ , definition | yielder << definition } end", "del_tokens": "def initialize ( strict : false ) @strict = strict def strict? @strict", "commit_type": "add"}
{"commit_tokens": ["removed", "debugging", "and", "switched", "get_access_token", "back", "to", ":", "get", "so", "that", "tests", "pass"], "add_tokens": "response = @client . request ( :get , @client . access_token_url , access_token_params ( code , options ) )", "del_tokens": "response = @client . request ( :post , @client . access_token_url , access_token_params ( code , options ) )", "commit_type": "remove"}
{"commit_tokens": ["use", "direct", "exchanges", "for", "results", "and", "checks"], "add_tokens": "result = amq . direct ( '' )", "del_tokens": "result = AMQP :: Exchange . default", "commit_type": "use"}
{"commit_tokens": ["Remove", "some", "Rails", "-", "isms", "from", "error", "handling", "."], "add_tokens": ":model_map => proc { | s | const_get \"::#{s}\" } this . update :run_at => Time . now + ( count ** 4 + 3 ) , :data => JSON . dump ( :error_count => count , :error_message => error . message , :error_backtrace => error . backtrace . join ( \"\\n\" ) )", "del_tokens": ":model_map => proc ( & method ( :const_get ) ) this . update :run_at => ( count ** 4 + 3 ) . seconds . from_now , :data => { :error_count => count , :error_message => error . message , :error_backtrace => error . backtrace . join ( \"\\n\" ) } . pg_json", "commit_type": "remove"}
{"commit_tokens": ["make", "Raca", "::", "Container#download", "return", "the", "number", "of", "downloaded", "bytes"], "add_tokens": "# Download the object at key into a local file at filepath. # # Returns the number of downloaded bytes. # response = storage_request ( Net :: HTTP :: Get . new ( File . join ( container_path , key ) ) ) do | response | response [ \"Content-Length\" ] . to_i", "del_tokens": "storage_request ( Net :: HTTP :: Get . new ( File . join ( container_path , key ) ) ) do | response |", "commit_type": "make"}
{"commit_tokens": ["Added", "add", "function", ".", "Arrays", "and", "single", "file", "names", "are", "acceptable", "."], "add_tokens": "def add ( * filenames ) filenames . each do | fn | case fn when Array fn . each { | f | self << f } else self << fn end end end def add_matching ( * patterns ) patterns . each do | pattern | Dir [ pattern ] . each { | fn | self << fn } if pattern end", "del_tokens": "def add_matching ( pattern ) Dir [ pattern ] . each { | fn | self << fn } if pattern", "commit_type": "add"}
{"commit_tokens": ["Use", "Pickle", "::", "Config", ".", "default", "for", "pickle", "to", "avoid", "loading", "pickle", "to", "pre", "-", "configure"], "add_tokens": "returning ( @default ||= new ) do | config | yield ( config ) if block_given? end def map ( * args ) options = args . extract_options! raise ArgumentError , \"Usage: map 'search' [, 'search2', ...] :to => 'replace'\" unless args . any? && options [ :to ] . is_a? ( String ) search = args . size == 1 ? args . first . to_s : \"(?:#{args.join('|')})\"", "del_tokens": "@default ||= new def map ( search , options ) raise ArgumentError , \"Usage: map 'search', :to => 'replace'\" unless search . is_a? ( String ) && options [ :to ] . is_a? ( String )", "commit_type": "use"}
{"commit_tokens": ["fixes", "errors", "when", "running", "method", "after", "where"], "add_tokens": "def is ( hash ) raise PBS :: Error , \"`where' method not called before\" if where_procs . empty? || where_procs [ - 1 ] raise PBS :: Error , \"`where' method not called before\" if where_procs . empty? || where_procs [ - 1 ] raise PBS :: Error , \"`where' method not called before\" if where_procs . empty? || where_procs [ - 1 ]", "del_tokens": "def is ( hash ) raise PBS :: Error , \"`where' method not called before\" unless where_procs [ - 1 ] raise PBS :: Error , \"`where' method not called before\" unless where_procs [ - 1 ] raise PBS :: Error , \"`where' method not called before\" unless where_procs [ - 1 ]", "commit_type": "fix"}
{"commit_tokens": ["Changed", "Util", "to", "a", "module"], "add_tokens": "module Util", "del_tokens": "class Util", "commit_type": "change"}
{"commit_tokens": ["Add", ":", "method", "option", "to", "HTTPRequest"], "add_tokens": "# @option options [Symbol] :method (:get) The HTTP method to use. @method = options . fetch :method , :get net_http_class = Object . const_get \"Net::HTTP::#{@method.capitalize}\" @http_request ||= net_http_class . new uri . request_uri curl << \" -X #{http_request.method}\"", "del_tokens": "@http_request ||= Net :: HTTP :: Get . new uri . request_uri", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "bunch", "of", "tiny", "things", "should", "have", "committed", "more", "but", "I", "got", "in", "the", "groove", "."], "add_tokens": "$: . unshift ( File . join ( File . dirname ( __FILE__ ) ) ) require 'twitter/rate_limit_status' module Twitter class Unavailable < StandardError ; end class CantConnect < StandardError ; end class BadResponse < StandardError ; end class UnknownTimeline < ArgumentError ; end class RateExceeded < StandardError ; end SourceName = 'twittergem' end", "del_tokens": "require 'twitter/rate_limit_status'", "commit_type": "add"}
{"commit_tokens": ["Update", "Tokyo", "to", "use", "Base64", "encoding"], "add_tokens": "Marshal . load ( val . unpack ( \"m\" ) [ 0 ] ) super ( key , [ Marshal . dump ( value ) ] . pack ( \"m\" ) )", "del_tokens": "Marshal . load ( val ) super ( key , Marshal . dump ( value ) )", "commit_type": "update"}
{"commit_tokens": ["updated", "Jar", "and", "moving", "to", "BRING", "CSL", "TO", "THE", "GEM"], "add_tokens": "VERSION = \"2.0.0\"", "del_tokens": "VERSION = \"1.2.0\"", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "general", "error", "callback"], "add_tokens": ":progress , :error rescue = > e raise e unless callback? ( :error ) error ( e ) false", "del_tokens": ":progress", "commit_type": "add"}
{"commit_tokens": ["fixing", "the", "--", "help", "option", "by", "removing", "functions", "that", "are", "conflicting", "and", "changing", "color", "output", "to", "default"], "add_tokens": "object_fields << ui . color ( \"Name:\" , :cyan ) object_fields << ui . color ( \"Public IP:\" , :cyan ) object_fields << ui . color ( \"Service:\" , :cyan ) object_fields << ui . color ( \"Template:\" , :cyan ) object_fields << ui . color ( \"Domain:\" , :cyan ) object_fields << ui . color ( \"Zone:\" , :cyan ) object_fields << ui . color ( \"State:\" , :cyan )", "del_tokens": "object_fields << ui . color ( \"Name\" , :yellow , :bold ) object_fields << ui . color ( \"Public IP\" , :yellow , :bold ) object_fields << ui . color ( \"Service\" , :yellow , :bold ) object_fields << ui . color ( \"Template\" , :yellow , :bold ) object_fields << ui . color ( \"Domain\" , :yellow , :bold ) object_fields << ui . color ( \"Zone\" , :yellow , :bold ) object_fields << ui . color ( \"State\" , :yellow , :bold ) def msg ( label , value ) if value && ! value . empty? puts \"#{ui.color(label, :cyan)}: #{value}\" end end", "commit_type": "fix"}
{"commit_tokens": ["Add", "Variation", "model", "and", "related", "integrations"], "add_tokens": "attr_accessor :id , :name , :slug , :web_link , :description , :foundry , :variations , :libraries # Typekit::Family.new isn't expected usage private :initialize family = Family . new Client . get ( \"/families/#{id}\" ) family . variations . map! { | v | Variation . send ( :new , v ) } family", "del_tokens": "attr_accessor :id , :name , :slug , :web_link , :foundry , :variations , :libraries # @todo Handle variations appropriately Family . new Client . get ( \"/families/#{id}\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "specs", "for", "controller", "extensions", "."], "add_tokens": "end # ClassMethods def clear_breadcrumbs", "del_tokens": "def _process_url ( url ) end end def clear_crumbs", "commit_type": "add"}
{"commit_tokens": ["fixed", "y", "coord", "handling", "in", "bitmap", "representation"], "add_tokens": "pointindex = ( ( height - 1 - y ) * @width + x ) * 3 pointindex = ( ( height - 1 - y ) * @width + x ) * 3 pointindex = ( ( height - 1 - y ) * @width + x ) * 3", "del_tokens": "pointindex = ( y * @width + x ) * 3 pointindex = ( y * @width + x ) * 3 pointindex = ( y * @width + x ) * 3", "commit_type": "fix"}
{"commit_tokens": ["Fix", "invalid", "toc", "HTML", "(", "Element", "ul", "not", "allowed", "as", "child", "of", "element", "ul", "in", "this", "context", ".", ")"], "add_tokens": "SIMPLE_HTML = <<-HTML . freeze < h1 > Simple H1 < / h1 > < h2 > Simple H2 < / h2 > < h3 > Simple H3 < / h3 > < h4 > Simple H4 < / h4 > < h5 > Simple H5 < / h5 > < h6 > Simple H6 < / h6 >", "del_tokens": "SIMPLE_HTML = <<-HTML < h1 > Simple H1 < / h1 > < h2 > Simple H2 < / h2 > < h3 > Simple H3 < / h3 > < h4 > Simple H4 < / h4 > < h5 > Simple H5 < / h5 > < h6 > Simple H6 < / h6 > assert_match ( / Simple H1 / , @parser . doc . inner_html )", "commit_type": "fix"}
{"commit_tokens": ["Move", "keys_for", "to", "a", "class", "method", "of", "SpamClassifier"], "add_tokens": "require_relative 'support/spam_classifier' @mat = CrossValidation :: ConfusionMatrix . new ( SpamClassifier . method ( :keys_for ) )", "del_tokens": "@mat = CrossValidation :: ConfusionMatrix . new ( method ( :keys_for ) )", "commit_type": "move"}
{"commit_tokens": ["Move", "Index#sections", "into", "IndexWriter", ".", "sections"], "add_tokens": "IndexWriter . sections ( examples )", "del_tokens": "@index . sections", "commit_type": "move"}
{"commit_tokens": ["updated", "active", "serializer", "to", "stable", "version"], "add_tokens": "VERSION = '3.0.1'", "del_tokens": "VERSION = '3.0.0'", "commit_type": "update"}
{"commit_tokens": ["Fix", "error", "handling", "for", "request", "params"], "add_tokens": "unless options . has_key? ( :json ) raise ArgumentError . new ( '\":json\" key must be set to JSONAPI::Utils#jsonapi_render' ) end setup_request if @request . errors . present? render_errors ( @request . errors ) body = jsonapi_serialize ( options [ :json ] , options [ :options ] || { } ) render json : body , status : options [ :status ] || :ok if response . body . size > 0 response . headers [ 'Content-Type' ] = JSONAPI :: MEDIA_TYPE end", "del_tokens": "if options . has_key? ( :json ) response = jsonapi_serialize ( options [ :json ] , options [ :options ] || { } ) render json : response , status : options [ :status ] || :ok raise ArgumentError . new ( '\":json\" key must be set to JSONAPI::Utils#jsonapi_render' ) raise e unless e . class . name . starts_with? ( 'JSONAPI::Exceptions' ) headers [ 'Content-Type' ] = JSONAPI :: MEDIA_TYPE setup_request", "commit_type": "fix"}
{"commit_tokens": ["fix", "datastore", "folder", "parent", "links"], "add_tokens": "'files' => RVC :: FakeDatastoreFolder . new ( self , \"\" ) , def initialize datastore , path [ x . path , RVC :: FakeDatastoreFolder . new ( @datastore , \"#{@path}/#{x.path}\" ) ] [ x . path , RVC :: FakeDatastoreFile . new ( @datastore , \"#{@path}/#{x.path}\" , x ) ] els = path . split '/' if els . empty? @datastore else parent_path = els [ 0 ... - 1 ] . join '/' RVC :: FakeDatastoreFolder . new ( @datastore , parent_path ) end def initialize datastore , path , info els = path . split '/' parent_path = els [ 0 ... - 1 ] . join '/' RVC :: FakeDatastoreFolder . new ( @datastore , parent_path )", "del_tokens": "'files' => RVC :: FakeDatastoreFolder . new ( self , self , \"\" ) , def initialize datastore , parent , path @parent = parent [ x . path , RVC :: FakeDatastoreFolder . new ( @datastore , self , \"#{@path}/#{x.path}\" ) ] [ x . path , RVC :: FakeDatastoreFile . new ( @datastore , self , \"#{@path}/#{x.path}\" , x ) ] @parent def initialize datastore , parent , path , info @parent = parent @parent", "commit_type": "fix"}
{"commit_tokens": ["Fix", "documentation", "of", "abstract", "data", "types", "."], "add_tokens": "# # The RGB contract converter, an object that responds to `call` to # # convert from a valid Hash[r: Fixnum, ...] to a ColorImpl instance.", "del_tokens": "# # The RGB contract, an object that responds to `rgb` to convert from # # a valid Hash[r: Fixnum, ...] to a ColorImpl instance. The latter is # # is expected to respond to :to_rgb", "commit_type": "fix"}
{"commit_tokens": ["removed", "wip", "and", "save_and_open_page", "from", "previous", "test"], "add_tokens": "#save_and_open_page", "del_tokens": "save_and_open_page", "commit_type": "remove"}
{"commit_tokens": ["add", "Spy", "::", "Mock", "to", "replace", "Spy", "::", "Double"], "add_tokens": "require 'test_helper' require 'spy/test_subroutine' class BluePen < Pen def write_hello ( other ) end end @pen = Spy :: Mock . new ( BluePen ) end def teardown Spy :: Agency . instance . dissolve! def test_class_methods assert @pen . kind_of? ( BluePen ) assert @pen . is_a? ( BluePen ) assert @pen . instance_of? ( BluePen ) assert_equal BluePen , @pen . class end def test_raises_error_on_unstubbed_method assert_raises Spy :: NeverHookedError do @pen . write ( nil ) end end def test_mimics_visibility assert @pen . singleton_class . public_method_defined? :public_method assert @pen . singleton_class . protected_method_defined? :protected_method assert @pen . singleton_class . private_method_defined? :private_method end def test_that_method_spy_keeps_arity assert_raises ArgumentError do @pen . write end assert_raises ArgumentError do @pen . write ( \"hello\" , \"world\" ) end assert_raises ArgumentError do @pen . write_hello end assert_raises ArgumentError do @pen . greet end assert_raises ArgumentError do @pen . greet ( \"hello\" , \"bob\" , \"error\" ) end", "del_tokens": "@pen = Spy :: Mock . new ( Pen ) def test_mock_class_methods assert @pen . instance_of? ( Pen ) assert_equal Pen , @pen . class", "commit_type": "add"}
{"commit_tokens": ["Add", "specs", "for", "configuration", "initialization", "and", "fix", "bugs", "."], "add_tokens": "options . each do | k , v | case k when :retries raise ArgumentError , \"#{k} must be positive integer\" unless v . is_a? ( Integer ) && v . positive? when :time_to_sleep raise ArgumentError , \"#{k} must be positive number\" unless ( v . is_a? ( Integer ) || v . is_a? ( Float ) ) && v >= 0 when :retriable raise ArgumentError , \"#{k} must be array of retriable errors\" unless v . is_a? ( Array ) when :retry_proc , :retry_condition_proc raise ArgumentError , \"#{k} must be Proc\" unless v . is_a? ( Proc ) end", "del_tokens": "options . each do | k , v | raise ArgumentError , \"#{k} must be positive integer\" unless v . is_a? ( Integer ) && v . positive? raise ArgumentError , \"#{k} must be positive number\" unless ( v . is_a? ( Integer ) || v . is_a? ( Float ) ) && v . positive?", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "special", "property", "renaming", "of", "ignore_time"], "add_tokens": "PERSON_REQUEST_PROPERTIES = %w{ token distinct_id ip ignore_time }", "del_tokens": "PERSON_REQUEST_PROPERTIES = %w{ token distinct_id ip }", "commit_type": "add"}
{"commit_tokens": ["remove", "explicit", "return", "in", "method_missing"], "add_tokens": "deferred", "del_tokens": "return deferred", "commit_type": "remove"}
{"commit_tokens": ["Fix", "in", "I18n", ".", "l", ":", "better", "handling", "of", ":", "default", "option"], "add_tokens": "if args . first . nil? && args . second . is_a? ( Hash ) && args . second . key? ( :default )", "del_tokens": "if args . first . nil? && args . second . is_a? ( Hash ) && args . second [ :default ] . present?", "commit_type": "fix"}
{"commit_tokens": ["added", "1", "depth", "level", "to", "storage", "wider", "."], "add_tokens": "Dir [ File . join ( d , '**' , '*.json' ) ] . inject ( [ ] ) { | a , fn | } . sort { | doc0 , doc1 | doc0 [ '_id' ] <=> doc1 [ '_id' ] } File . join ( @dir , Cloche . neutralize ( type || 'no_type' ) ) nkey = Cloche . neutralize ( key ) [ File . join ( dir_for ( type ) , nkey [ - 2 , 2 ] || nkey ) , \"#{nkey}.json\" ]", "del_tokens": "Dir [ File . join ( d , '*.json' ) ] . inject ( [ ] ) do | a , fn | end File . join ( @dir , self . class . neutralize ( type || 'no_type' ) ) [ dir_for ( type ) , \"#{self.class.neutralize(key)}.json\" ]", "commit_type": "add"}
{"commit_tokens": ["allow", "switching", "to", "a", "particular", "board", "for", "compilation"], "add_tokens": "puts \"Setting additional URLs\" puts \"Installing arduino:sam\" puts \"Installing USBHost\" puts \"checking that library is indexed\" puts \"setting compiler warning level\" puts \"use board! (install board)\" got_problem = true unless arduino_cmd . use_board! ( \"arduino:samd:zero\" ) puts \"verify that board has been installed\" got_problem = true unless arduino_cmd . board_installed? ( \"arduino:samd:zero\" )", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["added", "support", "for", "editing", "symbol", "metadata"], "add_tokens": "module ISE VERSION = \"0.5.0\"", "del_tokens": "module Ruby module Ise VERSION = \"0.4.0\" end", "commit_type": "add"}
{"commit_tokens": ["update", "action", "helper", "documentation", "."], "add_tokens": "# Render the template and layout for a path. # # @param path [String] a path without a leading / # @param options [Hash] passed through to underlying `render` # # @!visibility public def render_path ( path , options = { } ) render options . merge ( template : 'simplec/pages/show' , layout : layout ( @page ) ) # Determine the layout for a page. # # @param page [Simplec::Page] # # @return [String] layout name # @!visibility public # @!visibility private", "del_tokens": "def render_path ( path ) render template : 'simplec/pages/show' , layout : layout ( @page )", "commit_type": "update"}
{"commit_tokens": ["Allow", "fetching", "more", "than", "15", "images", "(", "the", "default", ")"], "add_tokens": "def images ( options = { results : 15 } ) response = get_response ( results : options [ :results ] , name : @name )", "del_tokens": "def images response = get_response ( name : @name )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "for", "update", "and", "create"], "add_tokens": "before_filter :setup_image_template , :only => [ :new , :edit , :create , :update ] def setup_image_template @empty_blog_post = BlogPost . new @empty_blog_post . blog_images . build end", "del_tokens": "@empty_blog_post = BlogPost . new @empty_blog_post . blog_images . build @empty_blog_post = BlogPost . new @empty_blog_post . blog_images . build", "commit_type": "fix"}
{"commit_tokens": ["Added", "User", "Key", "on", "index", "&", "validity"], "add_tokens": "# @param validity the number of seconds after which the key will be automatically removed (0 means no time limit for this key) def Algolia . add_user_key ( acls , validity = 0 ) Algolia . client . post ( Protocol . keys_uri , { \"acl\" => acls , \"validity\" => validity } . to_json )", "del_tokens": "def Algolia . add_user_key ( acls ) Algolia . client . post ( Protocol . keys_uri , { \"acl\" => acls } . to_json )", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "on", "grouped", "root", "nested", "mlhs"], "add_tokens": "if parent_type == :mlhs", "del_tokens": "if parent . node . type == :mlhs", "commit_type": "fix"}
{"commit_tokens": ["Adds", "result_key", "feature", "for", "config", "files"], "add_tokens": "attr_accessor :result_key each { | config_file | result . deep_merge! ( config_file . parse ( opts ) ) } result = result . dig ( result_key ) || { } if result_key", "del_tokens": "each { | option_file | result . deep_merge! ( option_file . parse ( opts ) ) }", "commit_type": "add"}
{"commit_tokens": ["Changed", "around", "empty", "data", "."], "add_tokens": "unless frame . data . nil?", "del_tokens": "unless frame . data . nil? || frame . data . to_s . empty?", "commit_type": "change"}
{"commit_tokens": ["Fixed", "the", "unit", "tests", "for", "sync", "schedule", "controller"], "add_tokens": "@plan = SyncPlan . create! ( :name => 'some plan_' + i . to_s , :sync_date => DateTime . now , :interval => 'daily' , :organization => @org ) describe \"POST 'apply'\" do it \"should receive a notice\" do post 'apply' , { :data => { :plans => plans , :products => products } . to_json }", "del_tokens": "@plan = SyncPlan . create! ( { :name => 'some plan_' + i . to_s , :organization => @org } ) describe \"POST 'apply_schedules'\" do it \"should recieve a notice\" do post 'apply_schedules' , { :selected_items => { :plans => plans , :products => products } }", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "in", "re", "-", "opening", "logic"], "add_tokens": "@mysqlh = nil reopen reopen def reopen close if ! closed? log_config = @config . dup log_config . delete ( :password ) DohDb . logger . call ( 'connection' , \"creating connection with config: #{log_config}\" ) @mysqlh = Mysql2 :: Client . new ( @config ) DohDb . logger . call ( 'connection' , \"new connection created: id #{@mysqlh.thread_id}\" ) end", "del_tokens": "log_config = @config . dup log_config . delete ( :password ) DohDb . logger . call ( 'connection' , \"creating connection with config: #{log_config}\" ) @mysqlh = Mysql2 :: Client . new ( @config ) DohDb . logger . call ( 'connection' , \"new connection created: id #{@mysqlh.thread_id}\" ) close", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "in", "creating", "steps"], "add_tokens": "class Step < Dry :: Pipeline", "del_tokens": "class Step include Dry :: Pipeline :: Mixin", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "validations", "to", "be", "specified", "in", "array", "format"], "add_tokens": "@schema . validations . each do | field , validation_options | validations = ( validation_options . class == Array ) ? validation_options : [ validation_options ] validations . each do | validation | validation = ( validation . class == Hash ) ? validation : { validation => true } self . validates ( field , validation ) end", "del_tokens": "@schema . validations . each do | field , validation | validation = ( validation . class == Hash ) ? validation : { validation => true } self . validates ( field , validation )", "commit_type": "allow"}
{"commit_tokens": ["Changed", "the", "way", "the", "docroot", "path", "is", "constructed"], "add_tokens": "www_root = File . join ( File . dirname ( __FILE__ ) , '..' , 'fixtures' )", "del_tokens": "www_root = File . dirname ( __FILE__ ) + '/../fixtures/'", "commit_type": "change"}
{"commit_tokens": ["changing", "configuration", "file", "adding", "available", "countries", "method"], "add_tokens": "Yourub :: Config . load! ( File . join ( \"config\" , \"yourub.yml\" ) , 'yourub_defaults' )", "del_tokens": "Yourub :: Config . load! ( File . join ( \"config\" , \"yourub.yml\" ) , 'yourub' )", "commit_type": "change"}
{"commit_tokens": ["Added", "controllers_route", "in", "config", "."], "add_tokens": "if @@config and @@config [ 'controllers_route' ] controller_dir = File . join ( :: Rails . root . to_s , @@config [ 'controllers_route' ] ) else controller_dir ||= File . join ( :: Rails . root . to_s , 'app/controllers' ) end", "del_tokens": "controller_dir ||= File . join ( :: Rails . root . to_s , 'app/controllers' )", "commit_type": "add"}
{"commit_tokens": ["Fix", "reference", "to", "DSL", "in", "the", "specs"], "add_tokens": "let ( :dsl ) { Rake :: Pipeline :: DSL :: PipelineDSL . new ( pipeline ) }", "del_tokens": "let ( :dsl ) { Rake :: Pipeline :: DSL . new ( pipeline ) }", "commit_type": "fix"}
{"commit_tokens": ["updated", "gem", "dependencies", "and", "bumped", "version"], "add_tokens": "VERSION = \"0.1.1\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "update"}
{"commit_tokens": ["Add", "save", "and", "destroy", "methods", "to", "order", "."], "add_tokens": "ATTRIBUTES_NAMES = [ :order_id , :customer_id , :status , :total_price , :total_discounts , :currency , :canceled_shiped , :canceled_shop_fault , :order_created_at ] ATTRIBUTES_NAMES . each do | attrib | attr_accessor attrib end def attributes ATTRIBUTES_NAMES . inject ( { } ) do | attribs , attrib_name | attribs [ attrib_name ] = self . send ( attrib_name ) attribs end end def save res = Api . post ( \"/orders/#{order_id}\" , attributes ) end def destroy res = Api . delete ( \"/orders/#{order_id}\" ) end", "del_tokens": "attr_accessor :order_id , :customer_id , :status , :total_price , :total_discounts , :currency , :canceled_shiped , :canceled_shop_fault , :order_created_at", "commit_type": "add"}
{"commit_tokens": ["Add", "to_s", "to", "respond_to_missing", "check"], "add_tokens": "method_name . to_s . end_with? ( '=' ) || spec . respond_to? ( method_name )", "del_tokens": "method_name . end_with? ( '=' ) || spec . respond_to? ( method_name )", "commit_type": "add"}
{"commit_tokens": ["added", "acquirer_name", "to", "get", "fees", "when", "is", "cielo", "fee", "should", "be", "null"], "add_tokens": "def get_fee ( payment_method , acquirer_name = nil ) if acquirer_name != 'cielo' ( self . contribution . value * CatarsePagarme . configuration . credit_card_tax . to_f ) + CatarsePagarme . configuration . credit_card_cents_fee . to_f end", "del_tokens": "def get_fee ( payment_method ) ( self . contribution . value * CatarsePagarme . configuration . credit_card_tax . to_f ) + CatarsePagarme . configuration . credit_card_cents_fee . to_f", "commit_type": "add"}
{"commit_tokens": ["Add", ":", "select", "option", "to", "approx_near_scope_options", "."], "add_tokens": ":select => options [ :select ] || nil lat_attr = geocoder_options [ :latitude ] lon_attr = geocoder_options [ :longitude ] :offset => options [ :offset ] , :conditions => [ \"#{lat_attr} BETWEEN ? AND ? AND #{lon_attr} BETWEEN ? AND ?\" ] + coordinate_bounds ( latitude , longitude , radius )", "del_tokens": ":conditions => [ \"#{lat_attr} BETWEEN ? AND ? AND #{lon_attr} BETWEEN ? AND ?\" ] + coordinate_bounds ( latitude , longitude , radius ) , lat_attr = geocoder_options [ :latitude ] lon_attr = geocoder_options [ :longitude ] :conditions => [ \"#{lat_attr} BETWEEN ? AND ? AND #{lon_attr} BETWEEN ? AND ?\" ] + coordinate_bounds ( latitude , longitude , radius ) :offset => options [ :offset ]", "commit_type": "add"}
{"commit_tokens": ["using", "rand", "instead", "of", "sample", "for", "fetching", "random", "words"], "add_tokens": "else range . to_a [ rand ( range . to_a . size ) ] ( 1 .. interpret_value ( total ) ) . map { WORDS [ rand ( WORDS . size ) ] } . join ( ' ' ) when Array then value [ rand ( value . size ) ]", "del_tokens": "else range . to_a [ rand ( range . to_a . length ) ] ( 1 .. interpret_value ( total ) ) . map { WORDS . sample } . join ( ' ' ) when Array then value [ rand ( value . length ) ]", "commit_type": "use"}
{"commit_tokens": ["Allow", "existing", "MD5", "values", "for", "email", "password", "and", "username"], "add_tokens": "@email = md5_digest ( email ) @username = md5_digest ( username ) @password = md5_digest ( password ) def md5_digest ( value ) if value =~ / ^[0-9a-f]{32}$ /i value else Digest :: MD5 . hexdigest ( value . downcase ) end end", "del_tokens": "@email = Digest :: MD5 . hexdigest ( email . downcase ) @username = Digest :: MD5 . hexdigest ( username . downcase ) @password = Digest :: MD5 . hexdigest ( password . downcase )", "commit_type": "allow"}
{"commit_tokens": ["Added", "task", "to", "generate", "admin", "sample", "user", "to", "initial", "admin", "interface", "access", "."], "add_tokens": "let ( :rake ) { Rake :: Application . new } let ( :user ) { FactoryGirl . build ( :user ) } let ( :valid_args ) { { :first_name => \"Example\" , :last_name => \"User\" , :email => \"sample-user@dealsiteredemptions.com\" , :password => \"password\" } } let ( :unvalid_args ) { { :first_name => \"Example\" , :last_name => \"User\" , :email => \"ewfewf\" , :password => \"password\" } } Rake . application = rake describe 'deal_redemptions:install:config' do subject { rake [ 'deal_redemptions:install:config' ] } describe 'deal_redemptions:install:admin' do subject { rake [ 'deal_redemptions:install:admin' ] } context 'generates admin user' do it 'successful message' do allow ( DealRedemptions :: User ) . to receive ( :find_by_email ) . and_return ( nil ) expect ( STDOUT ) . to receive ( :puts ) . with ( 'Admin user was created. Email: sample-user@dealsiteredemptions.com, Password: password' ) subject . invoke end end context 'already generated admin user' do it 'outputs admin already exists' do allow ( DealRedemptions :: User ) . to receive ( :find_by_email ) . and_return ( user ) expect ( STDOUT ) . to receive ( :puts ) . with ( 'Admin user already exists. Email: sample-user@dealsiteredemptions.com, Password: password' ) subject . invoke end end end", "del_tokens": "@rake = Rake :: Application . new Rake . application = @rake context 'deal_redemptions:install:config' do subject { @rake [ 'deal_redemptions:install:config' ] }", "commit_type": "add"}
{"commit_tokens": ["Fixed", ".", "org", "parse", "error"], "add_tokens": "@ast [ \"field:disclaimer\" ] = _scan_lines_to_array ( / ^(.+)( \\n +) / ) . join ( \" \" )", "del_tokens": "@ast [ \"field:disclaimer\" ] = _scan_lines_to_array ( / ^(.+) \\n / ) . join ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "warning", "for", "partial", "implementation", "of", "Marker"], "add_tokens": "def initialize ( ** args ) warn ( \"WARNING: Maker is not fully implemented yet due to the lack of ILS\" ) super end", "del_tokens": "# def initialize(*args) # fail(NotImplementedError, \"Marker are not fully implemented yet\") # end", "commit_type": "add"}
{"commit_tokens": ["Add", "nary", "AND", "operation", "node"], "add_tokens": "def delimited ( nodes , delimiter = ', ' ) append ( delimiter ) if index < max", "del_tokens": "def delimited ( nodes ) delimiter if index < max private # Emit delimiter # # @return [undefined] # # @api private # def delimiter append ( ', ' ) end", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "optional", "quotaUser", "parameter", ".", "For", "documented", "usage", "see", ":", "https", ":", "//", "developers", ".", "google", ".", "com", "/", "analytics", "/", "devguides", "/", "reporting", "/", "core", "/", "v3", "/", "reference#quotaUser"], "add_tokens": "attr_accessor :sort , :limit , :offset , :quota_user #, :segment # individual, overwritten [ :sort , :limit , :offset , :start_date , :end_date , :quota_user ] . each do | key | #:segment # 'fields' => REQUEST_FIELDS , 'quotaUser' => quota_user", "del_tokens": "attr_accessor :sort , :limit , :offset #, :segment # individual, overwritten [ :sort , :limit , :offset , :start_date , :end_date ] . each do | key | #:segment # 'fields' => REQUEST_FIELDS", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "test", "and", "added", "some", "CVE", "I", "had", "to", "implement", "in", "the", "very", "close"], "add_tokens": "@check . attack_pattern . should == [ \"sanitize_css\" ]", "del_tokens": "@check . attack_pattern . should == \"sanitize_css\"", "commit_type": "fix"}
{"commit_tokens": ["Remove", "remaining", "Zip", "-", "prefixed", "constants"], "add_tokens": "Zip :: File . open ( filename , Zip :: File :: CREATE ) do | zipfile | Zip :: File . open ( filename , Zip :: File :: CREATE ) do | zipfile |", "del_tokens": "Zip :: File . open ( filename , Zip :: ZipFile :: CREATE ) do | zipfile | Zip :: File . open ( filename , Zip :: ZipFile :: CREATE ) do | zipfile |", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "foreign", "keys", "for", "mysql"], "add_tokens": "t . belongs_to :block , index : true add_foreign_key :no_cms_blocks_blocks , :no_cms_blocks_blocks , column : 'parent_id'", "del_tokens": "t . belongs_to :block , index : true , foreign_key : true", "commit_type": "fix"}
{"commit_tokens": ["Add", "log", "field", "in", "transactions", "for", "report", "method"], "add_tokens": "'transactions[0][log][request]' => 'foo' , 'transactions[0][log][response]' => 'bar' , 'transactions[0][log][code]' => '200' , :timestamp => '2010-04-27 15:42:17 0200' , :log => { 'request' => 'foo' , 'response' => 'bar' , 'code' => 200 , } } ,", "del_tokens": ":timestamp => '2010-04-27 15:42:17 0200' } ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "a", "message", "to", "be", "passed", "to", "the", "rake", "task", "."], "add_tokens": "task :send , [ :message ] do | t , args | argument_options = { :message => args . message } . reject { | k , v | v . blank? } options . merge! argument_options", "del_tokens": "task :send do", "commit_type": "allow"}
{"commit_tokens": ["Add", "lon", "as", "a", "helpful", "alias", "as", "well"], "add_tokens": "alias :lat :y alias :lat= :y= alias :lng :x alias :lng= :x= alias :lon :x alias :lon= :x=", "del_tokens": "alias :lat :y alias :lat= :y= alias :lng :x alias :lng= :x=", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "the", "first", "argument", "to", "jeweler", "was", "lost"], "add_tokens": "options [ :jeweler ] = exception . recover ( ARGV ) jeweler_options = options [ :jeweler ] . inject ( '' ) do | mem , j | j = \"'#{j}'\" if j . include? ( ' ' ) mem + j + ' ' end puts \"Running jeweler #{jeweler_options} #{options[:provider_dir]}\" puts ` jeweler #{ jeweler_options } #{ options [ :provider_dir ] } `", "del_tokens": "options [ :jeweler ] = ARGV puts \"Running jeweler #{options[:jeweler].join(' ')} #{options[:provider_dir]}\" puts ` jeweler #{ options [ :jeweler ] . join ( ' ' ) } #{ options [ :provider_dir ] } `", "commit_type": "fix"}
{"commit_tokens": ["Remove", "method", "footprint", "of", "adamantium"], "add_tokens": "memory . fetch ( method ) do frozen = freezer . call ( value ) store_memory ( method , frozen )", "del_tokens": "access ( method ) do freezer . call ( value )", "commit_type": "remove"}
{"commit_tokens": ["Added", "better", "notes", "to", "install", ".", "rb"], "add_tokens": "# This file is run when the plugin is installed puts %Q( Gvis === = Ruby wrapper for easily loading the Google Visualization API , and simple generation of the javascript required to plot the graphs Installation === === === === script / plugin install git :/ / github . com / jeremyolliver / gvis . git # Include the GoogleVisualization module in app/helpers/application_helper.rb module ApplicationHelper include GoogleVisualization end # Load the API, and render any graphs by placing these methods inside your layout # app/views/layouts/application.html.erb < head > < %= include_visualisation_api %> < %= render_visualisations %> ... < / head > see vendor / plugins / gvis / README for usage information )", "del_tokens": "# This file is run puts \"include GoogleVisualisation in ApplicationHelper\"", "commit_type": "add"}
{"commit_tokens": ["added", ":", "decimal", "type", "to", "mysql", "spec"], "add_tokens": "tp [ :decimal ] = { :name => \"decimal\" }", "del_tokens": "tp [ :decimal ] = { :name => \"datetime\" }", "commit_type": "add"}
{"commit_tokens": ["Add", "smallint", "data", "type", "conversion"], "add_tokens": "when 'tinyint' , 'smallint' , 'int' , 'bigint'", "del_tokens": "when 'tinyint' , 'int' , 'bigint'", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "to", "spec", "/", "status_message_spec", ".", "rb"], "add_tokens": "context \"when status_message == 'I am happy' \" do status_message = SadPanda :: StatusMessage . new \"I am happy\" status_message = SadPanda :: StatusMessage . new \"I am fearful\"", "del_tokens": "context \"when status_message == 'I am paralyzed by happinesss' \" do status_message = SadPanda :: StatusMessage . new \"I am paralyzed by happinesss\" status_message = SadPanda :: StatusMessage . new \"I am terrified\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "customization", "of", "MD026", "punctuation"], "add_tokens": "params :punctuation => '.,;:!?' doc . find_type ( :header ) . select { | h | h [ :raw_text ] . match ( / [ #{ params [ :punctuation ] } ]$ / ) } . map {", "del_tokens": "doc . find_type ( :header ) . select { | h | h [ :raw_text ] . match ( / [.,;:!?]$ / ) } . map {", "commit_type": "allow"}
{"commit_tokens": ["Add", "Logger#<<", "to", "ad", "a", "raw", "unformatted", "message", "to", "the", "buffer"], "add_tokens": "message = Rackstash :: Message . new ( StandardError . new ( 'An error' ) ) message = Rackstash :: Message . new ( :symbol ) expect ( message . to_s ) . to eql ':symbol'", "del_tokens": "exception = StandardError . new ( 'An error' ) message = Rackstash :: Message . new ( exception )", "commit_type": "add"}
{"commit_tokens": ["Fix", "up", "some", "observable", "/", "resizable", "view", "issues"], "add_tokens": "self . instance . send ( method , * args , & block )", "del_tokens": "if self . instance . respond_to? method self . instance . send ( method , * args ) else super end", "commit_type": "fix"}
{"commit_tokens": ["Added", "specs", "and", "methods", "to", "allow", "for", "#migrate_up!", "(", "level", ")", "and", "#migrate_down!", "(", "level", ")"], "add_tokens": "# # has an optional argument 'level' which if supplied, only performs the migrations # with a position less than or equal to the level. def migrate_up! ( level = nil ) if level . nil? migration . perform_up ( ) else migration . perform_up ( ) if migration . position <= level end # # has an optional argument 'level' which, if supplied, only performs the # down migrations with a postion greater than the level. def migrate_down! ( level = nil ) if level . nil? migration . perform_down ( ) else migration . perform_down ( ) if migration . position > level end", "del_tokens": "def migrate_up! migration . perform_up ( ) def migrate_down! migration . perform_down ( )", "commit_type": "add"}
{"commit_tokens": ["Create", "base", "message", "class", "and", "test", "client", "."], "add_tokens": "require 'outbox/errors' require 'outbox/version' autoload 'MessageClients' , 'outbox/message_clients' autoload 'MessageFields' , 'outbox/message_fields' module Clients autoload 'TestClient' , 'outbox/clients/test_client' end module Messages autoload 'Base' , 'outbox/messages/base' end", "del_tokens": "require 'outbox/version'", "commit_type": "create"}
{"commit_tokens": ["fix", "deprecation", "message", "for", "data", "-", "confirm"], "add_tokens": ":data => { :confirm => ti ( :confirm_delete ) , :method => :delete } ) :data => { :confirm => ti ( :confirm_delete ) , :method => :delete }", "del_tokens": ":confirm => ti ( :confirm_delete ) , :method => :delete ) :confirm => ti ( :confirm_delete ) , :method => :delete", "commit_type": "fix"}
{"commit_tokens": ["added", "errors", "and", "utils", "files"], "add_tokens": "class InvalidDateArgument < ArgumentError end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["changed", "maxDiff", "to", "ruby", "naming", "convention"], "add_tokens": "max_diff = $epsilon + 1 while max_diff > $epsilon do max_diff = ( 1 .. matrix_height ) . to_a pp max_diff", "del_tokens": "maxDiff = $epsilon + 1 while maxDiff > $epsilon do maxDiff = ( 1 .. matrix_height ) . to_a pp maxDiff", "commit_type": "change"}
{"commit_tokens": ["Updating", "the", "documentation", "for", "Site#transform_pages"], "add_tokens": "# Copy all regular files from <source> to <dest>/ ignoring # any files/directories that are hidden (start with \".\") or contain # site content (start with \"_\") # The +dir+ String is a relative path used to call this method # recursively as it descends through directories", "del_tokens": "# Recursively transform and write all non-post pages to <dest>/ # +dir+ is the String path part representing the path from # <source> to the currently processing dir (default '')", "commit_type": "update"}
{"commit_tokens": ["Use", "ENV", "[", "HOME", "]", "instead", "of", "Ronin", "::", "Config", "::", "HOME", "."], "add_tokens": "unless ENV [ 'HOME' ] warn \"cd: HOME not set\" return false end ENV [ 'HOME' ]", "del_tokens": "Config :: HOME", "commit_type": "use"}
{"commit_tokens": ["added", "gemspec", "and", "modified", "require", "statements"], "add_tokens": "require 'aasm'", "del_tokens": "require 'assm'", "commit_type": "add"}
{"commit_tokens": ["add", "some", "TODO", "thoughts", ".", "there", "s", "still", "much", "to", "do"], "add_tokens": "# TODO: this would be tricky to show the desired error message :( # do we care about orders? shall we inject methods one by one? defi . original_method # restore original method", "del_tokens": "defi . original_method # restore original method", "commit_type": "add"}
{"commit_tokens": ["make", "NullContext", "inherit", "from", "Object", "so", "debugging", "is", "easier", "(", "with", "inspect", ")"], "add_tokens": "class NullContext", "del_tokens": "class NullContext < BasicObject", "commit_type": "make"}
{"commit_tokens": ["fixed", "build", ";", "changed", "button"], "add_tokens": "its ( :render ) { should match / Problem 1 / }", "del_tokens": "its ( :render ) { should match / Problem 0 / }", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "rspec", "helper", "class", "FakeCounter"], "add_tokens": "class FakeCounter def initialize ( & block ) @block = block end def increment ( * args ) @block . call ( * args ) end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Move", "expected", "JSON", "response", "to", "a", "file", "."], "add_tokens": "expected_report = open ( 'data/how_is_spec/generate_report--generates-a-correct-JSON-report.json' ) . read . strip", "del_tokens": "expected_report = { \"repository\" => \"rubygems/rubygems\" , \"number_of_issues\" => 30 , \"number_of_pulls\" => 30 , \"issues_with_label\" => { \"triage\" => 7 , \"bug report\" => 9 , \"feedback\" => 4 , \"osx\" => 1 , \"bug fix\" => 4 , \"category - install\" => 5 , \"feature implementation\" => 2 , \"major bump\" => 2 , \"windows\" => 1 , \"feature request\" => 1 , \"cleanup\" => 1 , \"accepted\" => 2 , \"category - #gem or #require\" => 1 , \"ready for work\" => 1 , \"question\" => 3 , \"administrative\" => 1 } , \"issues_with_no_label\" => 0 , \"average_issue_age\" => \"approximately 3 months and 1 week\" , \"average_pull_age\" => \"approximately 11 months and 3 days\" , \"oldest_issue_date\" => \"2016-01-31T21:28:02+00:00\" , \"oldest_pull_date\" => \"2013-09-16T15:04:07+00:00\" } . to_json", "commit_type": "move"}
{"commit_tokens": ["Make", "responders", "controller", "generator", "more", "compatible", "with", "defaut", "rails", "scaffold", "is", "FLashResponder", "is", "not", "being", "used", "."], "add_tokens": "< %= \"flash[:notice] = '#{class_name} was successfully created.' if \" if flash? %>@<%= orm_instance.save %> < %= \"flash[:notice] = '#{class_name} was successfully updated.' if \" if flash? %>@<%= orm_instance.update_attributes(\"params[:#{file_name}]\") %>", "del_tokens": "@ < %= orm_instance . save %> @ < %= orm_instance . update_attributes ( \"params[:#{file_name}]\" ) % >", "commit_type": "make"}
{"commit_tokens": ["Added", "shortcut", "for", "REDay", "expressions", "and", "tests"], "add_tokens": "DAYS = '(sunday|monday|tuesday|wednesday|thursday|friday|saturday)' ORDINALS = '(first|second|third|fourth|last|second_to_last)' when Regexp . new ( '^' + DAYS + '$' ) when Regexp . new ( ORDINALS + '_' + DAYS ) when Regexp . new ( '^weekly_' + DAYS + '_to_' + DAYS + '$' ) st_day , end_day = $1 , $2 return REWeek . new ( Runt . const ( st_day ) , Runt . const ( end_day ) )", "del_tokens": "ORDINALS = [ 'first' , 'second' , 'third' , 'fourth' , 'last' , 'second_to_last' ] days = '(monday|tuesday|wednesday|thursday|friday|saturday|sunday)' ordinals = '(first|second|third|fourth|last|second_to_last)' when Regexp . new ( '^' + days + '$' ) when Regexp . new ( ordinals + '_' + days )", "commit_type": "add"}
{"commit_tokens": ["Added", "Pling", "::", "Gateway#discover", "to", "find", "gateways", "for", "a", "given", "device"], "add_tokens": "class Error < StandardError ; end class AuthenticationFailed < Error ; end class DeliveryFailed < Error ; end class NoGatewayFound < Error ; end", "del_tokens": "class Error < StandardError end class AuthenticationFailed < Error end class DeliveryFailed < Error end", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "s", "and", "-", "f", "flags", "to", "jgrep"], "add_tokens": "return result", "del_tokens": "return result . to_json", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "condition", "on", "close", "()", "."], "add_tokens": "setup_dispatch_thread! # To close a Zk handle, first shutdown the dispatcher thread; this is done by # signalling the waiting thread that there is a pending close. We then release # the C-land Zk state. def close signal_pending_close @dispatcher . join super end hash = get_next_event break if hash . nil? # Pending close => exit dispatcher thread dispatch_event ( hash ) def dispatch_event ( hash )", "del_tokens": "setup_dispatch_thread! dispatch_next_callback def dispatch_next_callback hash = get_next_event", "commit_type": "fix"}
{"commit_tokens": ["updated", "query", "and", "query", "activerecord", "helpers"], "add_tokens": "def self . as_json ( _query , _parameters , except : [ ] , only : [ ] ) def self . as_string ( _query , _parameters , except : [ ] , only : [ ] ) raise NotImplementedError , 'As string method should be implemented on Query subclasses' end def self . as_bytes ( _query , _parameters , except : [ ] , only : [ ] ) raise NotImplementedError , 'As bytes method should be implemented on Query subclasses' end", "del_tokens": "def self . as_json ( query , parameters , except : [ ] , only : [ ] )", "commit_type": "update"}
{"commit_tokens": ["Use", "config", "file", "with", "module", "bootstraping"], "add_tokens": "return config if command == 'config' config = ShopConfig . new \"name\" => major , \"author\" => config . get ( 'module' , 'author' ) , \"tab\" => config . get ( 'module' , 'tab' )", "del_tokens": "\"name\" => major", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "Resources", "get", "the", "proxy", "too", "."], "add_tokens": ":headers => headers , :proxy => RestClient . proxy ) :headers => headers , :proxy => RestClient . proxy ) :headers => headers , :proxy => RestClient . proxy ) :headers => headers , :proxy => RestClient . proxy )", "del_tokens": ":headers => headers ) :headers => headers ) :headers => headers ) :headers => headers )", "commit_type": "make"}
{"commit_tokens": ["use", "union", "scope", "on", "segments"], "add_tokens": "@segments = Segment . union_scope ( @app . segments . all , Segment . where ( \"app_id is null\" ) ) . order ( \"id asc\" )", "del_tokens": "@segments = @app . segments . all + Segment . where ( \"app_id is null\" )", "commit_type": "use"}
{"commit_tokens": ["Added", "glob_data_paths", "which", "accepts", "a", "block", "."], "add_tokens": "# @yield [path] # If a block is given, it will be passed every matching path. # # @yieldparam [String] path # The path of a matching file within a data directory. # # If no block is given, the matching paths found within all data # directories will be returned. # @since 0.3.0 # def glob_data_paths ( pattern , & block ) return enum_for ( :glob_data_paths , pattern ) . to_a unless block_given? Dir . glob ( File . join ( path , pattern ) , & block ) end # # @deprecated # Will be removed in 1.0.0, please use {#glob_data_paths} instead. # def data_glob ( pattern ) STDERR . puts \"DEPRECATED: please use glob_data_paths instead.\" glob_data_paths ( pattern )", "del_tokens": "# The matching paths found within all data directories. def data_glob ( pattern ) paths = [ ] paths += Dir [ File . join ( path , pattern ) ] return paths", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "assertions", "helpers"], "add_tokens": "def capture_statsd_metrics ( & block ) metrics = capture_statsd_metrics ( & block ) . select { | m | m . name == metric_name } assert_statsd_call ( :c , metric_name , options , & block ) assert_statsd_call ( :ms , metric_name , options , & block ) assert_statsd_call ( :g , metric_name , options , & block ) def assert_statsd_call ( metric_type , metric_name , options = { } , & block ) metrics = capture_statsd_metrics ( & block ) assert options [ :times ] === metrics . length , \"The amount of StatsD calls for metric #{metric_name} was unexpected\"", "del_tokens": "def collect_metrics ( & block ) metrics = collect_metrics ( & block ) . select { | m | m . name == metric_name } assert_statsd_metric ( :c , metric_name , options , & block ) assert_statsd_metric ( :ms , metric_name , options , & block ) assert_statsd_metric ( :g , metric_name , options , & block ) def assert_statsd_metric ( metric_type , metric_name , options = { } , & block ) metrics = collect_metrics ( & block ) assert_equal options [ :times ] , metrics . length , \"The amount of StatsD calls for metric #{metric_name} was unexpected\"", "commit_type": "add"}
{"commit_tokens": ["add", "polarity", "methods", "to", "status_messages", ".", "rb"], "add_tokens": "@polarity_score = polarity_score word , strength , polarity = l . split ( \",\" ) if strength == \"strongsubj\" strength = 1 else strength = 2 end if polarity == \"positive\" polarity = 1 else polarity = - 1 end @polarities [ word ] ||= 0 @polarities [ word ] = polarity * strength polarity_hash . keys . each do | k | if k . include? ( key ) @polarity_score [ k ] += polarity_hash [ k ] * value # if algorithm == \"bayes\" # @polarity_score.keys.each do |key| # @polarity_score[key] = Math.log(@prior/@polarity_score[key]).abs # end # end @polarity_score . max_by { | k , v | v } [ 1 ]", "del_tokens": "lines = lines [ 0 ] . split ( \"\\n\" ) word , polarity = l . split ( \",\" ) @polarities [ polarity ] ||= [ ] @polarities [ polarity ] << word polarities_hash . keys . each do | k | if polarities_hash [ k ] . include? ( key ) @polarity_score [ k ] += value if algorithm == \"bayes\" @polarity_score . keys . each do | key | @polarity_score [ key ] = Math . log ( @prior / @polarity_score [ key ] ) . abs end end @polarity_score . max_by { | k , v | v } [ 0 ]", "commit_type": "add"}
{"commit_tokens": ["Add", "template", "for", "submit", "button", "."], "add_tokens": "# Submit button with smart default text (if +value+ is nil uses \"Create\" # for new record or \"Update\" for old record). all_options = options . clone remove_custom_options! ( options ) build_shell ( value , all_options , 'submit_button' ) { super } ## # Render submit button template. # def submit_button_template ( l = { } ) <<-END < div class = \"button\" > #{l[:element]}</div> END end ## # Render submit button template. # def submit_button_template ( l = { } ) <<-END < tr id = \"#{l[:div_id]}\" class = \"field\" > < td > < / td > < td class = \"button\" > #{l[:element]}</td> < / tr > END end", "del_tokens": "# Submit button with smart text and +submit+ class. options [ :class ] = \"options[:class]} submit\" \"<div class=\\\"button\\\">#{super}</div>\"", "commit_type": "add"}
{"commit_tokens": ["adding", "a", "dogpile", "-", "driven", "import", "method", "--", "imported", "65", "pdfs", "in", "about", "90", "seconds", "with", "8", "workers"], "add_tokens": "fire_callback if callback_url end end # If a callback_url is defined, post the Job's JSON to it upon completion. def fire_callback begin RestClient . post ( callback_url , { :job => self . to_json } ) rescue RestClient :: Exception => e puts \"Failed to fire job callback. Hmmm, what should happen here?\" ins = units . inject ( { } ) { | memo , u | memo [ u . input ] = Dogpile . display_status ( u . status ) ; memo }", "del_tokens": "ins = units . inject ( { } ) { | memo , u | memo [ u . input ] = u . status ; memo }", "commit_type": "add"}
{"commit_tokens": ["Add", "division", "method", "to", "Datomic", "::", "Client"], "add_tokens": "args = args_or_dbname . is_a? ( String ) ? [ self / args_or_dbname ] : args_or_dbname def / ( dbname ) { :\" db/alias \" => \"#@storage/#{dbname}\" } end", "del_tokens": "args = args_or_dbname . is_a? ( String ) ? [ { :\" db/alias \" => [ @storage , args_or_dbname ] . join ( '/' ) } ] : args_or_dbname", "commit_type": "add"}
{"commit_tokens": ["add", "method", "to", "get", "custom", "params", "from", "message"], "add_tokens": "params . each { | k , v | k . to_s . start_with? ( 'custom_' ) ? @custom_params [ k . to_s ] = v : @custom_params [ \"custom_#{k.to_s}\" ] = v } end def get_custom_params @custom_params . inject ( { } ) { | hash , ( k , v ) | hash [ k . gsub ( / \\A custom_ / , '' ) ] = v ; hash }", "del_tokens": "params . each { | k , v | @custom_params [ \"custom_#{k}\" ] = v }", "commit_type": "add"}
{"commit_tokens": ["Fix", "misstypo", "quote_column_name", "to", "quote_table_name"], "add_tokens": "quotedTableName = :: ActiveRecord :: Base . connection . quote_table_name ( self . table_name )", "del_tokens": "quotedTableName = :: ActiveRecord :: Base . connection . quote_column_name ( self . table_name )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "set", "the", "own", "XMLRPC", "timeout"], "add_tokens": "def initialize ( host , port = 443 , path = '/xmlrpc.cgi' , proxy_host = nil , proxy_port = nil , timeout = 60 ) @xmlrpc = :: XMLRPC :: Client . new ( host , path , port , proxy_host , proxy_port , nil , nil , use_ssl , timeout )", "del_tokens": "def initialize ( host , port = 443 , path = '/xmlrpc.cgi' , proxy_host = nil , proxy_port = nil ) @xmlrpc = :: XMLRPC :: Client . new ( host , path , port , proxy_host , proxy_port , nil , nil , use_ssl , 60 )", "commit_type": "allow"}
{"commit_tokens": ["add", "network", "to", "fee", "calling", "output"], "add_tokens": "payees << Output . new ( value : nominal_change , network : network )", "del_tokens": "payees << Output . new ( :value => nominal_change )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "disabled", "fields", "would", "be", "submitted", "."], "add_tokens": "return nil if disabled? def disabled? @element . attributes . has_key? \"disabled\" end", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Make", "fields", "obey", ":", "delegate", "options", "properly", "."], "add_tokens": "validate_options! if should_define_methods_on_model_class? column_definition . define_dynamic_method_on_model_class! ( name_for_delegated_method ) do contents = send ( flex_column_name ) contents . send ( field_name ) end column_definition . define_dynamic_method_on_model_class! ( \"#{name_for_delegated_method}=\" ) do | x | contents = send ( flex_column_name ) contents . send ( \"#{field_name}=\" , x ) end attr_reader :column_definition , :options def should_define_methods_on_model_class? ! ( options . has_key? ( :delegate ) && ( ! options [ :delegate ] ) ) end def name_for_delegated_method prefix = options [ :delegate ] [ :prefix ] if options [ :delegate ] . kind_of? ( Hash ) if prefix \"#{prefix}_#{name}\" else name end end def validate_options! options . assert_valid_keys ( :delegate ) if options [ :delegate ] && ( options [ :delegate ] != true ) if ( ! options [ :delegate ] . kind_of? ( Hash ) ) raise ArgumentError , \"Argument to :delegate must be true/false/nil, or a Hash\" else options [ :delegate ] . assert_valid_keys ( :prefix ) end end end", "del_tokens": "column_definition . define_dynamic_method_on_model_class! ( field_name ) do contents = send ( flex_column_name ) contents . send ( field_name ) end column_definition . define_dynamic_method_on_model_class! ( \"#{field_name}=\" ) do | x | contents = send ( flex_column_name ) contents . send ( \"#{field_name}=\" , x ) attr_reader :column_definition", "commit_type": "make"}
{"commit_tokens": ["Move", "deactivation", "methods", "to", "base", "component", "class"], "add_tokens": "QUIT_CONTROLS = [ 27 ] # 27 = ESC", "del_tokens": "QUIT_CONTROLS = [ 27 , 'q' . ord , 'Q' . ord ] # 27 = ESC # Flag indicating that this component should # be deactivated def deactivate? ! ! ( @deactivate ||= false ) end # Make this component as decativated def deactivate! @deactivate = true end # Reset deactivation def reactivate! @deactivate = false end", "commit_type": "move"}
{"commit_tokens": ["add", "response", "accessor", "to", "request"], "add_tokens": "attr_accessor :response HideMyAss . log \"#{request.options[:proxy]} : #{response.code}\"", "del_tokens": "HideMyAss . log options [ :proxy ]", "commit_type": "add"}
{"commit_tokens": ["Added", "options", "to", "error", "/", "debug", "UI", "method"], "add_tokens": "def error ( message , options = { } ) reset_line if options [ :reset ] def debug ( message , options = { } ) reset_line if options [ :reset ]", "del_tokens": "def error ( message ) def debug ( message )", "commit_type": "add"}
{"commit_tokens": ["update", "the", "workbook", "model", "to", "support", "style", "and", "template", "definition"], "add_tokens": "# return the template set for the named element def for ( element , name ) # push the template onto the key set # verify the template, init the key set, and return the key string # otherwise ArgumentError it up", "del_tokens": "def templates ( element , name ) # return the named template set for the element # push the template onto the key set # verify the template, init the key set, and return the key string # otherwise ArgumentError it up", "commit_type": "update"}
{"commit_tokens": ["Make", "it", "possible", "to", "specify", "all", "address", "fields", "for", "debtor", "when", "creating", "invoice", "."], "add_tokens": "has_properties :id , :debtor_handle , :debtor_name , :debtor_address , :debtor_postal_code , :debtor_city , :debtor_country , :date , :term_of_payment_handle , :due_date , :currency_handle , :exchange_rate , :is_vat_included , :layout_handle , :delivery_date , :net_amount , :vat_amount , :gross_amount , :margin , :margin_as_percent data [ 'DebtorAddress' ] = debtor_address unless debtor_address . blank? data [ 'DebtorPostalCode' ] = debtor_postal_code unless debtor_postal_code . blank? data [ 'DebtorCity' ] = debtor_city unless debtor_city . blank? data [ 'DebtorCountry' ] = debtor_country unless debtor_country . blank?", "del_tokens": "has_properties :id , :debtor_handle , :debtor_name , :date , :term_of_payment_handle , :due_date , :currency_handle , :exchange_rate , :is_vat_included , :layout_handle , :delivery_date , :net_amount , :vat_amount , :gross_amount , :margin , :margin_as_percent", "commit_type": "make"}
{"commit_tokens": ["Improve", "release", "name", "detection", "on", "install"], "add_tokens": "path = \"/downloads/elasticsearch/elasticsearch/#{version.archive_name}\" destination_name = @destination_dir . join File . basename ( version . archive_name )", "del_tokens": "path = \"/downloads/elasticsearch/elasticsearch/#{version.name}\" destination_name = @destination_dir . join File . basename ( version . name )", "commit_type": "improve"}
{"commit_tokens": ["fix", "bug", "getting", "charset", "from", "incorrect", "meta", "tags", "via"], "add_tokens": "if html =~ / <meta[^>]*HTTP-EQUIV=[\"']?Content-Type[\"']?[^>]*content=[\"']([^'\"]*)[\"'] /i && $1 =~ / charset=([ \\w \\d -]+);? /i out = $1 elsif html =~ / <meta \\s +charset=[\"']([ \\w \\d -]+)? /i out = $1 out . upcase! unless out . nil?", "del_tokens": "if html =~ / <meta[^>]*HTTP-EQUIV=[\"']Content-Type[\"'][^>]*content=[\"']([^'\"]*)[\"'] /i && $1 =~ / charset=([ \\w \\d -]+);? /i out = $1 . upcase", "commit_type": "fix"}
{"commit_tokens": ["Move", "parsing", "of", "search", "results", "into", "Artist", "class"], "add_tokens": "require_relative 'foreign_id' attr_accessor :id , :name , :foreign_ids def initialize ( api_key , name = nil , foreign_ids = nil ) @foreign_ids = ForeignId . parse_array ( foreign_ids ) if foreign_ids artists = [ ] get_response ( options ) [ :artists ] . each do | a | artists << Artist . new ( @api_key , a [ :name ] , a [ :foreign_ids ] ) end artists", "del_tokens": "require_relative 'artist_result' def initialize ( api_key , name = nil ) end def name @name response = get_response ( options ) [ :artists ] ArtistResult . parse_array ( response )", "commit_type": "move"}
{"commit_tokens": ["Add", "default", "user", "id", "as", "fallback", "for", "activity", "user"], "add_tokens": "@users [ email ] || @default_user_id", "del_tokens": "@users [ email ] || - 1", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "RuleList", "lookup", "is", "only", "performed", "once", "."], "add_tokens": "@name = name @ruled = false @parsed = false return @rule if @ruled # Returns whether <tt>domain</tt> is a valid domain # according to default <tt>RuleList</tt>.", "del_tokens": "@name = name # Returns whether <tt>domain</tt> is a valid domain.", "commit_type": "make"}
{"commit_tokens": ["Add", "output", "asset_definition_url", "output", "for", "list_unspent", "get_balance"], "add_tokens": "'asset_amount' => out . output . asset_amount . to_s , 'asset_definition_url' => out . output . asset_definition_url 'asset_definition_url' => outputs [ 0 ] . asset_definition_url", "del_tokens": "'asset_amount' => out . output . asset_amount . to_s", "commit_type": "add"}
{"commit_tokens": ["Removing", "unneeded", "requirement", "for", "the", "active_support", "module", "."], "add_tokens": "", "del_tokens": "require 'active_support'", "commit_type": "remove"}
{"commit_tokens": ["fixed", "creation", "of", "pid", "files"], "add_tokens": "@pidfile . write ( Process . pid . to_s )", "del_tokens": "pidfile . write ( Process . pid . to_s )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "fix", "enumeration", "on", "old", "ruby"], "add_tokens": "update ( total : collection . count )", "del_tokens": "update ( total : collection . size )", "commit_type": "change"}
{"commit_tokens": ["fixing", "step", "so", "you", "can", "still", "say", "an", "in", "the", "receive", "email", "step"], "add_tokens": "Then / ^I should receive (an| \\d +) emails?$ / do | amount | When / ^I click the first link in the email$ / do click_first_link_in_email end", "del_tokens": "Then / ^I should receive (.+) emails?$ / do | amount |", "commit_type": "fix"}
{"commit_tokens": ["fixing", "specs", "up", "moving", "tapjoy", "specific", "code", "into", "a", "module", "to", "isolate", "it", "and", "make", "adding", "the", "handlers", "explicit"], "add_tokens": "module Chore module Tapjoy def self . register_tapjoy_handlers! Watcher :: Metric . publisher = Watcher :: Publisher :: Statsd . new ( 'localhost' , '8127' ) Watcher :: Metric . default_scope = \"jobs\" after_message = Proc . new do | state | metric = Watcher :: Metric . new ( \"finished\" , attributes : { state : state } ) metric . increment end Chore . add_hook :on_failure do after_message . call \"failed\" end Chore . add_hook :on_timeout do after_message . call \"timeout\" end Chore . add_hook :on_rejected do after_message . call \"rejected\" end Chore . add_hook :after_perform do after_message . call \"completed\" end Chore . add_hook :on_fetch_tell_monitoring do metric = Watcher :: Metric . new ( \"fetch\" ) metric . increment end end end", "del_tokens": "Watcher :: Metric . publisher = Watcher :: Publisher :: Statsd . new Watcher :: Metric . default_scope = \"jobs\" %w{ finished failed timeout } . each do | state | Chore . add_hook :\" after_perform_ #{ state } \" do metric = Watcher :: Metric . new ( \"finished\" , attributes : { state : state } ) metric . increment end end Chore . add_hook :on_fetch_tell_monitoring do metric = Watcher :: Metric . new ( \"fetch\" ) metric . increment", "commit_type": "fix"}
{"commit_tokens": ["add", "errors", "around", "event", "names", "that", "are", "not", "valid", "method", "names"], "add_tokens": "describe \".subscribe_to\" do it \"raises if invalid event name and nothing routed\" do expect { class InvalidEventNameSubscriber < Maitredee :: Subscriber subscribe_to :invalid_event_name do event \"this is an method name\" end end } . to raise_error ArgumentError , / not a valid method name /", "del_tokens": "describe \"#subscribe_to#shoryuken_options\" do class NoOptionsSubscriber < Maitredee :: Subscriber subscribe_to :no_options do default_event to : :default end", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "separate", "keyword", "for", "defining", "private", "exposures"], "add_tokens": "def self . expose ( name , & block ) exposures . add ( name , block ) end def self . private_expose ( name , & block ) exposures . add ( name , block , to_view : false )", "del_tokens": "def self . expose ( name , options = { } , & block ) exposures . add ( name , block , ** options )", "commit_type": "use"}
{"commit_tokens": ["Updated", "google", "signed", "key", "in", "test", "."], "add_tokens": "expect ( subject . url ) . to include \"signature=DIUgkQ_BaVBJU6hwhzH3GLeMdeo=\"", "del_tokens": "expect ( subject . url ) . to include \"signature=R6dKSHc7EZ7uzmpXKngJCX9i2_E=\"", "commit_type": "update"}
{"commit_tokens": ["Fix", "up", "the", "CoordinateSequence", "constructor", "."], "add_tokens": "size , dims = if ! args . length . between? ( 1 , 2 ) raise ArgumentError . new ( \"wrong number of arguments (#{args.length} for 1-2)\" ) else [ args [ 0 ] , args [ 1 ] || 0 ] end [ FFIGeos . GEOSCoordSeq_create_r ( Geos . current_handle , size , dims ) , true ]", "del_tokens": "[ FFIGeos . GEOSCoordSeq_create_r ( Geos . current_handle , * args ) , true ]", "commit_type": "fix"}
{"commit_tokens": ["Remove", "dollar", "sign", "in", "number"], "add_tokens": "value . delete ( '$,' )", "del_tokens": "value . delete ( ',' )", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "array", "form", "of", "Tempfile", ".", "open", "to", "enforce", "extension"], "add_tokens": "require \"spec_helper\" require \"build_status_server\" require \"tempfile\" config . udp_server . should == { \"address\" => \"127.0.0.1\" , \"port\" => 1234 } Tempfile . open ( [ \"config\" , \".yml\" ] ) do | f | Tempfile . open ( [ \"config\" , \".yml\" ] ) do | f | Tempfile . open ( [ \"base\" , \".yml\" ] ) do | f |", "del_tokens": "require 'spec_helper' require 'build_status_server' require 'tempfile' config . udp_server . should == { 'address' => '127.0.0.1' , 'port' => 1234 } Tempfile . open ( 'config' ) do | f | Tempfile . open ( \"config\" ) do | f | Tempfile . open ( \"base\" ) do | f |", "commit_type": "use"}
{"commit_tokens": ["make", "tend", "interval", "configurable", "via", "client", "policy"], "add_tokens": "@tend_interval = policy . tend_interval if @tend_interval < 10 Aerospike . logger . warn ( 'Minimum tend interval is 10 milliseconds.' ) @tend_interval = 10 end sleep ( @tend_interval / 1000.0 )", "del_tokens": "sleep 1 # 1 second", "commit_type": "make"}
{"commit_tokens": ["Change", "role", "to", "support", "profiles", "with", "path", "tree"], "add_tokens": "line << \"\\n\\tinclude profiles::#{profile.gsub('/','::')}\\n\" if line . start_with? ( 'class' ) regexp = / ^ \\s *include \\s +profiles:: #{ profile . gsub ( '/' , '::' ) } \\s *$ / profiles << row . split ( '::' ) . drop ( 1 ) . join ( '/' ) if row . start_with? ( 'include' )", "del_tokens": "line << \"\\n\\tinclude profiles::#{profile}\\n\" if line . start_with? ( 'class' ) regexp = / ^ \\s *include \\s +profiles:: #{ profile } \\s *$ / profiles << row . split ( '::' ) . last if row . start_with? ( 'include' )", "commit_type": "change"}
{"commit_tokens": ["add", "auto", "-", "increment", "and", "+", "/", "-", "method", "."], "add_tokens": "# plus object. # # @param value [Integer] plus value.(call to_i in this method.) # @return [Inum::Base] object after plus value. def + ( value ) self . class . parse ( @value + value . to_i ) end # minus object. # # @param value [Integer] plus value.(call to_i in this method.) # @return [Inum::Base] object after plus value. def - ( value ) self . class . parse ( @value - value . to_i ) end # get Enum length. # # @return [Integer] count of Enums. def self . length defined_enums . length end # @param value [Integer,Fixnum] value of Enum.(default:autoincrement for 0.) def self . define_enum ( name , value = defined_enums . size )", "del_tokens": "# @param value [Integer,Fixnum] value of Enum. def self . define_enum ( name , value )", "commit_type": "add"}
{"commit_tokens": ["Remove", "short", "sequences", "from", "alignment"], "add_tokens": "print new_aln . to_s @aln2 . rows [ 0 ] . state . deleted? . should == false @aln2 . rows [ 4 ] . state . deleted? . should == true", "del_tokens": "@aln2 . rows [ 0 ] . state . deleted? . should_be false @aln2 . rows [ 8 ] . state . deleted? . should_be true", "commit_type": "remove"}
{"commit_tokens": ["Update", "README", ".", "md", "and", "gem", "s", "version"], "add_tokens": "require 'jsonapi/utils/version'", "del_tokens": "require \"jsonapi/utils/version\"", "commit_type": "update"}
{"commit_tokens": ["removed", "deprecated", "stuff", "in", "specs"], "add_tokens": "rete = double 'rete'", "del_tokens": "rete = mock 'rete'", "commit_type": "remove"}
{"commit_tokens": ["Add", "tree", "&", "blob", "apis", "to", "commands", "clarify", "config", "initialization", "."], "add_tokens": "autoload :Blob , 'github_cli/blob' autoload :Blobs , 'github_cli/blobs' autoload :Tree , 'github_cli/tree' autoload :Trees , 'github_cli/trees'", "del_tokens": "require \"github_cli/repositories\"", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "dependent", "=", ">", ":", "destroy", "to", "has_many", "slug", "relation", ".", "Thanks", "to", "Emilio"], "add_tokens": "has_many :slugs , :order => \"id DESC\" , :as => :sluggable , :dependent => :destroy", "del_tokens": "has_many :slugs , :order => \"id DESC\" , :as => :sluggable", "commit_type": "add"}
{"commit_tokens": ["Remove", "extra", "element", "around", "highlighted", "lines"], "add_tokens": "# @param highlight_lines [Array<Integer>] a list of line numbers # (1-based) to be highlighted (i.e. added _highlight_class_ to a line # wrapper element). Defaults to empty array. # @param highlight_class [String] CSS class to use on a line wrapper # element for highlighted lines (see above). Defaults to \"highlighted\". classes = [ @line_class , ( @highlight_class if highlighted? lno ) , ] . compact . join ( ' ' ) %(<span id=#{sprintf(@line_id, lno).inspect} class=#{classes.inspect}>) def highlighted? ( lno ) @highlight_lines . include? ( lno )", "del_tokens": "# @param highlight_lines [Array<Integer>] a list of line numbers (1-based) # to be highlighted (i.e. wrapped in +<strong></strong>+). Defaults to # empty array. # @param highlight_class [String] CSS class to use on an element wrapping # highlighted lines (see above). Defaults to \"highlighted\". highlighted = @highlight_lines . include? ( lno ) yield highlight_open if highlighted yield highlight_close if highlighted %(<span id=#{sprintf(@line_id, lno).inspect} class=#{@line_class.inspect}>) def highlight_open %(<strong class=#{@highlight_class.inspect}>) end def highlight_close %(</strong>)", "commit_type": "remove"}
{"commit_tokens": ["add", "methods", "to", "get", "a", "product", "s", "related", "rules", "skus", "options", "videos", "discountrules", "configurable", "fields", "and"], "add_tokens": "def get_product_discountrules ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/discountrules\" , options ) end def get_product_configurablefields ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/configurablefields\" , options ) end def get_product_customfields ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/customfields\" , options ) end def get_product_options ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/options\" , options ) end def get_product_rules ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/rules\" , options ) end def get_product_skus ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/skus\" , options ) end def get_product_videos ( product_id , options = { } ) @connection . get ( \"/products/#{product_id}/videos\" , options ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "Hash#adjust_values!", "to", "be", "recursive", "."], "add_tokens": "# Recursively adjusts the values of the Hash in place. def adjust_values! ( & block ) each do | key , value | if value . respond_to? ( :adjust_values! ) value . adjust_values! ( & block ) else self [ key ] = yield ( value ) end end self", "del_tokens": "# Adjusts the values of the Hash in place. def adjust_values! each { | k , v | self [ k ] = yield ( v ) }", "commit_type": "update"}
{"commit_tokens": ["Moved", "component", "methods", "up", "."], "add_tokens": "# @return [Array<Component>] components with paths loaded from config def components return @components if @components return [ ] if config [ :components ] . nil? @components = [ ] base = directory base += config [ :components ] [ :base ] . nil? ? '' : '/' + config [ :components ] [ :base ] config [ :components ] [ :paths ] . each do | paths | @components << Component . new ( source_path : \"#{base}/#{paths[0]}\" , install_path : \"#{directory}/#{paths[1]}\" ) end unless config [ :components ] . nil? @components end # Install all components. # @return [Environment] the current environment instance def install_components components . each { | c | c . install } self end", "del_tokens": "# @return [Array<Component>] components with paths loaded from config def components return @components if @components return [ ] if config [ :components ] . nil? @components = [ ] base = directory base += config [ :components ] [ :base ] . nil? ? '' : '/' + config [ :components ] [ :base ] config [ :components ] [ :paths ] . each do | paths | @components << Component . new ( source_path : \"#{base}/#{paths[0]}\" , install_path : \"#{directory}/#{paths[1]}\" ) end unless config [ :components ] . nil? @components end # Install all components. # @return [Environment] the current environment instance def install_components components . each { | c | c . install } self end", "commit_type": "move"}
{"commit_tokens": ["Changed", "the", "title", "so", "that", "I", "can", "get", "the", "title", "of", "each", "page", "."], "add_tokens": "class Title attr_accessor :name def initialize ( name ) @name = name end def index I18n . t ( 'dynamic_scaffold.title.index' , model : @name ) end def edit I18n . t ( 'dynamic_scaffold.title.edit' , model : @name ) end def update I18n . t ( 'dynamic_scaffold.title.edit' , model : @name ) end def new I18n . t ( 'dynamic_scaffold.title.new' , model : @name ) end def create I18n . t ( 'dynamic_scaffold.title.new' , model : @name ) end end attr_reader :model , :form , :list , :title @title = Title . new ( @model . model_name . human )", "del_tokens": "attr_reader :model , :form , :list def title = ( value ) @title = value end def title return @title unless @title . nil? @model . model_name . human end", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "bad", "digest", "grace", "period", "."], "add_tokens": "sign_destination : true , digest : true , digest_grace_period : 300", "del_tokens": "sign_destination : true , digest : true", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "a", "default", "error", "state"], "add_tokens": "attr_writer :default_error_state , :state_method , :subject , :decorator , :decorator_class def default_error_state @default_error_state && @default_error_state . to_s end # When an error occurs, it uses the error to determine next state. # If no next state can be determined it transitions to the default error # state if defined, otherwise the error is re-raised. error_state = error_state ( event_name , e ) || state_machine_definition . default_error_state if error_state", "del_tokens": "attr_writer :state_method , :subject , :decorator , :decorator_class if error_state = error_state ( event_name , e )", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "TTL", "in", "UPDATE", "queries", "."], "add_tokens": "def update! ( table , selection , value_hash , options = { } ) query = \"UPDATE #{table}\" if options [ :ttl ] query += \" USING TTL #{options[:ttl]}\" end query += \" SET #{set_terms.join(', ')} WHERE #{selection}\" execute ( query )", "del_tokens": "def update! ( table , selection , value_hash ) execute ( \"UPDATE #{table} SET #{set_terms.join(', ')} WHERE #{selection}\" )", "commit_type": "add"}
{"commit_tokens": ["move", "#normalize_translation_keys", "to", "I18n", "and", "add", "#process_translation_arguments"], "add_tokens": "key , locale , options = process_translate_arguments * args def process_translate_arguments ( * args ) options = args . last . is_a? ( Hash ) ? args . pop : { } key = args . shift locale = args . shift || options . delete ( :locale ) || I18n . locale [ key , locale , options ] end # Merges the given locale, key and scope into a single array of keys. # Splits keys that contain dots into multiple keys. Makes sure all # keys are Symbols. def normalize_translation_keys ( locale , key , scope ) keys = [ locale ] + Array ( scope ) + [ key ] keys = keys . map { | key | key . to_s . split ( / \\. / ) } keys . flatten . map { | key | key . to_sym } end", "del_tokens": "options = args . last . is_a? ( Hash ) ? args . pop : { } key = args . shift locale = args . shift || options . delete ( :locale ) || I18n . locale", "commit_type": "move"}
{"commit_tokens": ["Made", "Git#version_line", "usable", "on", "non", "-", "repositories"], "add_tokens": "# Raised when trying to get the revision number from a non-repository class GitError < RuntimeError end begin r = self . revision ( path ) rescue GitError r = nil end return tb . push ( p , v , r ) . to_s . strip return system ( \"git -C #{path} rev-parse &> /dev/null\" )", "del_tokens": "r = self . revision ( path ) return tb . push ( p , 'v' ) . add ( v ) . push ( r ) . to_s . strip return system ( \"git -C #{path} rev-parse\" )", "commit_type": "make"}
{"commit_tokens": ["Fix", "translations", "when", "search", "attribute", "is", "a", "lambda", "scope", "(", "not", "related", "with", "a", "meta_search", "where"], "add_tokens": "options . reverse_merge! :count => 1 , :default => defaults , :attribute => klass . human_attribute_name ( predicate_attribute || attribute )", "del_tokens": "options . reverse_merge! :count => 1 , :default => defaults , :attribute => klass . human_attribute_name ( predicate_attribute )", "commit_type": "fix"}
{"commit_tokens": ["Add", "atom", "to", "common", "editors", "update", "sublime", "command", "and", "remove", "nano", "-", "tiny"], "add_tokens": "[ \"nano -w\" , \"notepad\" , \"vim\" , \"vi\" , \"emacs\" , \"pico\" , \" subl - n - w \", \" mate - w \", \" atom \" ]", "del_tokens": "[ \"nano\" , \"nano-tiny\" , \"notepad\" , \"vim\" , \"vi\" , \"emacs\" , \"pico\" , \" sublime \", \" mate - w \" ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "rubocop", "and", "add", "song", "spec", "tests"], "add_tokens": "'songIDs' => %w( 10 11 ) ) [ Grooveshark :: Song . new ( 'song_id' => '10' ) , 11 ] ) ) expect ( user . add_favorite ( Grooveshark :: Song . new ( 'song_id' => '2' ) ) ) . to eq ( true ) expect ( user . remove_favorite ( Grooveshark :: Song . new ( 'song_id' => '2' ) ) ) . to eq ( true )", "del_tokens": "'songIDs' => [ '10' , '11' ] ) [ Grooveshark :: Song . new ( { 'song_id' => '10' } ) , 11 ] ) ) expect ( user . add_favorite ( Grooveshark :: Song . new ( 'song_id' => '2' ) ) ) . to eq ( true ) expect ( user . remove_favorite ( Grooveshark :: Song . new ( 'song_id' => '2' ) ) ) . to eq ( true )", "commit_type": "fix"}
{"commit_tokens": ["Added", "additional", "field", "attributes", "with", "support", "for", "handling", "unknown", "or", "unmapped", "field", "attributes"], "add_tokens": "# # Represenation of a PDF Form Field else key , value = line . chomp . split ( ':' ) . map ( & :strip ) var_name = key . gsub ( / Field / , '' ) . downcase unless self . respond_to? ( var_name ) self . class . send ( :define_method , var_name . to_sym , Proc . new { instance_variable_get ( \"@#{var_name}\" . to_sym ) } ) # in case new or unknown fields crop up... end instance_variable_set ( \"@#{key.gsub(/Field/, '').downcase}\" . to_sym , value ) # Common Fields attr_reader :name , :type , :options , :flags , :justification , :value , :valuedefault", "del_tokens": "when / FieldType: \\s *(.+?) \\s *$ / @type = $1 when / FieldName: \\s *(.+?) \\s *$ / @name = $1 attr_reader :name , :type , :options", "commit_type": "add"}
{"commit_tokens": ["Creates", "module", "for", "transition", "helper", "methods"], "add_tokens": "require \"active_support/core_ext/hash/slice.rb\" require \"police_state/transition_helpers\" include TransitionHelpers", "del_tokens": "require \"active_support/core_ext/array/wrap.rb\" def attribute_transitioned_to? ( attr_name , state ) attribute_changed? ( attr_name , to : state ) end def attribute_transitioned_from_any_of? ( attr_name , states ) Array . wrap ( states ) . any? { | state | attribute_changed? ( attr_name , from : state ) } end", "commit_type": "create"}
{"commit_tokens": ["Moving", "over", "the", "vital", "sign", "importer", "from", "hQuery"], "add_tokens": "@section_importers [ :vital_signs ] = VitalSignImporter . new", "del_tokens": "@section_importers [ :vital_signs ] = SectionImporter . new ( \"//cda:observation[cda:templateId/@root='2.16.840.1.113883.3.88.11.83.14']\" )", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "multiple", "stylesheets", "and", "javascripts"], "add_tokens": "render :json => cat . api_hash", "del_tokens": "render :json => cat . api_hash", "commit_type": "add"}
{"commit_tokens": ["changed", "table", "to", "use", "UI", "Automation"], "add_tokens": "table = RAutomation :: Window . new ( :title => \"DataEntryForm\" ) . table ( :id => \"personListView\" ) table = RAutomation :: Window . new ( :title => \"DataEntryForm\" ) . table ( :id => \"personListView\" ) table = RAutomation :: Window . new ( :title => \"DataEntryForm\" ) . table ( :id => \"personListView\" )", "del_tokens": "table = RAutomation :: Window . new ( :title => \"DataEntryForm\" ) . table ( :class => / SysListView32 /i ) table = RAutomation :: Window . new ( :title => \"DataEntryForm\" ) . table ( :class => / SysListView32 /i ) table = RAutomation :: Window . new ( :title => \"DataEntryForm\" ) . table ( :class => / SysListView32 /i )", "commit_type": "change"}
{"commit_tokens": ["Added", "teardown", "to", "context", ".", "Nested", "teardowns", "supported", ".", "Will", "document"], "add_tokens": "RootContext = Struct . new ( :setups , :teardowns ) def initialize ( description , parent = RootContext . new ( [ ] , [ ] ) , & definition ) @contexts , @setups , @assertions , @teardowns = [ ] , [ ] , [ ] , [ ] def teardown ( & definition ) @teardowns << Setup . new ( & definition ) end def teardowns @parent . teardowns + @teardowns end runnables = setups + @assertions + teardowns", "del_tokens": "RootContext = Struct . new ( :setups ) def initialize ( description , parent = RootContext . new ( [ ] ) , & definition ) @contexts , @setups , @assertions = [ ] , [ ] , [ ] runnables = setups + @assertions", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "default", "behavior", "for", "rect", "|", "nil", "=", ">", "now", "returns", "rect"], "add_tokens": "return self unless b", "del_tokens": "return rect unless b", "commit_type": "change"}
{"commit_tokens": ["Using", "ruby", "-", "progressbar", "to", "show", "progress", "..."], "add_tokens": "require 'ruby-progressbar' progress_bar = ProgressBar . create ( total : paths . length ) progress_bar . increment", "del_tokens": "print '.'", "commit_type": "use"}
{"commit_tokens": ["Add", "main", "gists", "api", "."], "add_tokens": "def _update_user_repo_params ( user_name , repo_name = nil ) _normalize_params_keys ( params [ k . to_s ] )", "del_tokens": "def _update_user_repo_params ( user_name , repo_name ) #_normalize_params_keys(params[k.to_s])", "commit_type": "add"}
{"commit_tokens": ["Change", "#wrap", "to", "account", "for", "line", "endings", "and", "empty", "lines"], "add_tokens": "SPACE = \" \" . freeze LINE_BREAK = %r{ \\r \\n | \\r | \\n } . freeze LINE_BREAKS = \"\\r\\n+|\\r+|\\n+\" . freeze def wrap ( text , wrap_at = DEFAULT_WIDTH , separator : nil ) if text . scan ( / [[:print:]] / ) . length < wrap_at . to_i || wrap_at . to_i . zero? sep = separator || text [ LINE_BREAK ] || NEWLINE text . split ( %r{ #{ LINE_BREAKS } } , - 1 ) . map do | paragraph | end * sep", "del_tokens": "SPACE = ' ' . freeze LINE_BREAK = \"\\r\\n+|\\r+|\\n+\" . freeze def wrap ( text , wrap_at = DEFAULT_WIDTH ) if text . length < wrap_at . to_i || wrap_at . to_i . zero? text . split ( %r{ #{ LINE_BREAK } } , - 1 ) . map do | paragraph | end * NEWLINE", "commit_type": "change"}
{"commit_tokens": ["Move", "the", "#box", "and", "#open", "specs", "to", "be", "shared", "."], "add_tokens": "require 'rbnacl' require 'shared/box'", "del_tokens": "require 'rbnacl'", "commit_type": "move"}
{"commit_tokens": ["fixed", "manifest", "and", "added", "History", ".", "txt"], "add_tokens": "VERSION = '1.2.5'", "del_tokens": "VERSION = '1.2.0'", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "simple", "statistics", "tracking", "package", "to", "the", "logging", "gem", ".", "This", "allows", "for", "simple", "statistics", "and", "timing", "information", "to", "be", "gathered", "and", "logged", "at", "a", "fixed", "interval", ".", "Logging", "will", "now", "use", "the", "fastthread", "library", "if", "it", "is", "available", "."], "add_tokens": "require 'thread' begin require 'fastthread' ; rescue LoadError ; end VERSION = '0.9.3'", "del_tokens": "VERSION = '0.9.2'", "commit_type": "add"}
{"commit_tokens": ["added", "tilt", "as", "a", "dependency", "to", "turnout", "for", "rendering", "maintenance", "pages"], "add_tokens": "page = page_class . new ( settings . reason , env : env )", "del_tokens": "page = page_class . new ( settings . reason , env )", "commit_type": "add"}
{"commit_tokens": ["fixed", "require", "path", "in", "spec_helper"], "add_tokens": "require 'redlander'", "del_tokens": "require 'lib/redlander'", "commit_type": "fix"}
{"commit_tokens": ["Allow", "constants", "that", "begin", "with", "number"], "add_tokens": "resource_name = name . to_s . gsub ( / ^_ / , '' ) . gsub ( / ^( \\d ) / , \"n#{$1}\" ) . gsub ( / \\s / , '' ) . camelize", "del_tokens": "resource_name = name . to_s . gsub ( / ^_ / , '' ) . gsub ( / ^( \\d ) / , \"n#{$1}\" ) . camelize", "commit_type": "allow"}
{"commit_tokens": ["Move", "everything", "to", "spec", "/", ";", "gitignore", "rspec", ".", "failures"], "add_tokens": "Pedant . config [ :config_file ] = 'spec/support/pedant.rb'", "del_tokens": "Pedant . config [ :config_file ] = 'test/support/pedant.rb'", "commit_type": "move"}
{"commit_tokens": ["Change", "to", "render", "answer", "and", "header", "on", "the", "same", "line", "."], "add_tokens": "# Render question with instructions and menu header = @question + Codes :: SPACE + render_header @prompt . output . puts ( header ) @first_render = false render_menu unless @done end # Render initial help and selected choice # # @return [String] # # @api private def render_header selected_item = \"#{@choices[@active - 1].name}\" @pastel . decorate ( selected_item , @color ) elsif @first_render @pastel . decorate ( @help , :bright_black ) ''", "del_tokens": "# Render actual question with menu message = @question message += Codes :: SPACE + @help if @first_render @prompt . output . puts ( message ) selected_item = \"#{@choices[@active - 1].value}\" colored = @pastel . decorate ( selected_item , @color ) @prompt . output . puts ( colored ) render_menu @first_render = false", "commit_type": "change"}
{"commit_tokens": ["Moved", "the", "schema", "into", "dummy", "application", "and", "added", "initialize_db", "migration", "."], "add_tokens": "load ( File . expand_path ( '../dummy/db/schema.rb' , __FILE__ ) )", "del_tokens": "load ( File . dirname ( __FILE__ ) + '/schema.rb' )", "commit_type": "move"}
{"commit_tokens": ["changed", "impl", "to", "use", "and", "expose", "the", "#raw_body"], "add_tokens": "self . raw_body = body attr_accessor :code , :headers , :raw_body @body ||= gzipped_response? ? decoded_body : raw_body headers [ \"Content-Encoding\" ] == \"gzip\" || raw_body [ 0 .. 1 ] == \"\\x1f\\x8b\" gzip = Zlib :: GzipReader . new StringIO . new ( raw_body )", "del_tokens": "self . body = body attr_accessor :code , :headers gzipped_response? ? decoded_body : @body headers [ \"Content-Encoding\" ] == \"gzip\" || @body [ 0 .. 1 ] == \"\\x1f\\x8b\" gzip = Zlib :: GzipReader . new StringIO . new ( @body )", "commit_type": "change"}
{"commit_tokens": ["Allow", "to", "configure", "token_file", "and", "status_file", "in", "config"], "add_tokens": "op . on ( '-s' , '--status VALUE' , \"Status stroage file (default: status.yml)\" ) { | v | op . on ( '-t' , '--token VALUE' , \"Triglav access token storage file (default: token.yml)\" ) { | v |", "del_tokens": "status : 'status.yml' , token : 'token.yml' , op . on ( '-s' , '--status VALUE' , \"Status stroage file (default: #{opts[:status]})\" ) { | v | op . on ( '-t' , '--token VALUE' , \"Triglav access token storage file (default: #{opts[:token]})\" ) { | v |", "commit_type": "allow"}
{"commit_tokens": ["Fix", "upload", "for", "empty", "checksum"], "add_tokens": "params = { 'Content-Type' => guess_content_type ( io ) } params [ 'ETag' ] = convert_base64digest_to_hexdigest ( checksum ) if checksum", "del_tokens": "params = { 'Content-Type' => guess_content_type ( io ) , 'ETag' => convert_base64digest_to_hexdigest ( checksum ) }", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "CHANGELOG", ".", "Added", "belongs_to", "assertion", "macro", ".", "Broke", "down", "AR", "macros", "into", "scoped", "files"], "add_tokens": "end . equals ( [ :fail , \"expected :windows to be a has_many association\" ] )", "del_tokens": "end . equals ( [ :fail , \"expected :windows to be a has_many association, but was not\" ] )", "commit_type": "add"}
{"commit_tokens": ["allow", "require", "to", "complete", "in", "any", "gem"], "add_tokens": "require_paths . select { | e | File . directory? ( e ) } . inject ( [ ] ) do | t , dir | def require_paths $: + Gem . path . map { | e | Dir [ \"#{e}/gems/*/lib\" ] } . flatten . uniq rescue $: end", "del_tokens": "$: . select { | e | File . directory? ( e ) } . inject ( [ ] ) do | t , dir |", "commit_type": "allow"}
{"commit_tokens": ["fixed", "bug", "where", ":", "alt", "couldn", "t", "be", "overriden", "globaly", "with", "Gravatarify", "::", "Helper", ".", "html_options"], "add_tokens": "def self . html_options ; @html_options ||= { :alt => '' } end", "del_tokens": "def self . html_options ; @html_options ||= { } end options [ :alt ] ||= \"\" # no longer use e-mail as alt attribute, but instead an empty alt attribute", "commit_type": "fix"}
{"commit_tokens": ["Make", "nearbys", "instance", "method", "accept", "options", "hash", "."], "add_tokens": "# Get other geocoded objects within a given radius (in miles). This method # calls the +near+ named scope with the object's coordinates as the first # argument (the object must be geocoded before this method is called). # # You may pass the radius and options arguments as well, but if you # specify <tt>:conditions</tt> in the options hash you must manually # omit +self+ from the list of results. You should try to avoid this # anyway, and use other named scopes to apply further conditions, eg: # # venue.nearbys(10).open_on_mondays # venue.nearbys.with_capacity(2000) def nearbys ( radius = 20 , options = { } ) coords = self . class . _get_coordinates ( self ) options = { :conditions => [ \"id != ?\" , id ] } . merge ( options ) self . class . near ( coords , radius , options ) # Returns an array <tt>[lat, lon]</tt>.", "del_tokens": "# Get other geocoded objects within a given radius. # The object must be geocoded before this method is called. def nearbys ( radius = 20 ) lat , lon = self . class . _get_coordinates ( self ) self . class . near ( [ lat , lon ] , radius ) - [ self ] # Returns an array <tt>[lat,lon]</tt>.", "commit_type": "make"}
{"commit_tokens": ["Remove", "extra", "whitespace", "in", "test_pandoc", "-", "ruby"], "add_tokens": "", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["add", "null", "rule", "so", "that", "we", "always", "get", "a", "duck", "when", "parsing", "invalid", "or", "unsupported", "rules"], "add_tokens": "NULL_RULE = 0 def parse_css_text", "del_tokens": "def parse_css_text ( css_text )", "commit_type": "add"}
{"commit_tokens": ["add", ":", "Ctrl", "-", "C", "trap", "handler"], "add_tokens": "# try to gracefully shutdown on Ctrl-C trap ( \"INT\" ) { puts \"Interrupted, exit now...\" exit 0 } # stop all threads and connections gracefully puts \"#{Time.now}: MySmtpd down!\\n\"", "del_tokens": "# gracefully connections down server . shutdown # check once if some connection(s) need(s) more time sleep 2 unless server . connections == 0 # stop all threads and connections puts \"#{Time.now}: MySmtpd down!\"", "commit_type": "add"}
{"commit_tokens": ["Use", "LEFT", "JOIN", "instead", "of", "INNER", "JOIN"], "add_tokens": "counts_query = counts_query . joins ( \"LEFT JOIN #{reflect.active_record.table_name} ON #{reflect.table_name}.id = #{reflect.active_record.table_name}.#{reflect.foreign_key}\" )", "del_tokens": "counts_query = counts_query . joins ( \"JOIN #{reflect.active_record.table_name} ON #{reflect.table_name}.id = #{reflect.active_record.table_name}.#{reflect.foreign_key}\" )", "commit_type": "use"}
{"commit_tokens": ["fix", "specs", "in", "Rails", "4"], "add_tokens": "attr_protected :first_name if ActiveRecord :: VERSION :: MAJOR < 4", "del_tokens": "attr_protected :first_name", "commit_type": "fix"}
{"commit_tokens": ["removed", "session_id", "fro", "the", "message", "format"], "add_tokens": "'session' => message [ 'session' ]", "del_tokens": "# 2. *session_id*: identifier for session 'session' => message [ 'session' ] , 'session_id' => message [ 'session_id' ]", "commit_type": "remove"}
{"commit_tokens": ["Add", "globalise", "migration", "to", "tranlate", "contents"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20161108132035 ) do create_table \"pwb_content_translations\" , force : :cascade do | t | t . integer \"pwb_content_id\" , null : false t . string \"locale\" , null : false t . datetime \"created_at\" , null : false t . datetime \"updated_at\" , null : false t . text \"raw\" t . index [ \"locale\" ] , name : \"index_pwb_content_translations_on_locale\" , using : :btree t . index [ \"pwb_content_id\" ] , name : \"index_pwb_content_translations_on_pwb_content_id\" , using : :btree end", "del_tokens": "ActiveRecord :: Schema . define ( version : 20161107210046 ) do", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "the", "framework", "name"], "add_tokens": "ActiveSupport . on_load ( :active_resource ) do self . instantiate_observers", "del_tokens": "ActiveSupport . on_load ( :active_resourse ) do ActiveResource :: Base . instantiate_observers", "commit_type": "fix"}
{"commit_tokens": ["Use", "router", "domain", "suffix", "for", "basic", "networking"], "add_tokens": "if network \"#{server['name']}.#{network['networkdomain']}\" else domain = get_router_networkdomain ( server [ 'domainid' ] ) \"#{server['name']}.#{domain}\" end end def get_router_networkdomain ( domainid ) routers = list_routers || [ ] routers . each do | router | return router [ 'networkdomain' ] if router [ 'domainid' ] == domainid end ## # Lists all the routers available to your account. def list_routers params = { \"command\" => 'listRouters' } json = send_request ( params ) json [ 'router' ] || [ ] end", "del_tokens": "return nil unless network \"#{server['name']}.#{network['networkdomain']}\"", "commit_type": "use"}
{"commit_tokens": ["Fixed", "the", "return", "values", "of", "#append", "and", "#prepend"], "add_tokens": "it 'returns the item that was added' do assert_same sibling , item . append ( sibling ) end ret = item_a . append item_b assert_same item_c , ret it 'returns the added item' do assert_same sibling , item . prepend ( sibling ) end ret = item_c . prepend item_b assert_same item_a , ret", "del_tokens": "item_a . append item_b item_c . prepend item_b", "commit_type": "fix"}
{"commit_tokens": ["Fix", "fv_search", "to", "put", "parens", "around", "ssearch", "terms"], "add_tokens": "update ( hash_or_hashes . flatten )", "del_tokens": "update ( hash_or_hashes )", "commit_type": "fix"}
{"commit_tokens": ["Use", "Rails", ".", "root", "instead", "of", "RAILS_ROOT"], "add_tokens": "kaltura_yml = File . join ( Rails . root , 'config' , 'kaltura.yml' )", "del_tokens": "kaltura_yml = File . join ( RAILS_ROOT , 'config' , 'kaltura.yml' )", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "canonical", "name", "column", "for", "ITIS", "."], "add_tokens": "canonical_name = name . clone canonical_name = canonical_name . join ( ' ' ) . strip . gsub ( / \\s + / , ' ' ) canonical_name : canonical_name , 'http://rs.tdwg.org/ontology/voc/TaxonName#nameComplete' , row = [ k , parent_id , accepted_id , d [ :name ] , d [ :canonical_name ] , d [ :status ] , d [ :rank ] ]", "del_tokens": "row = [ k , parent_id , accepted_id , d [ :name ] , d [ :status ] , d [ :rank ] ]", "commit_type": "add"}
{"commit_tokens": ["Removes", "a", "global", "api", "version", "config", "from", "pagseguro", "module"], "add_tokens": "api : \"https://ws.pagseguro.uol.com.br/\" , site : \"https://pagseguro.uol.com.br/\" site : 'https://sandbox.pagseguro.uol.com.br/' , api : 'https://ws.sandbox.pagseguro.uol.com.br/'", "del_tokens": "api : \"https://ws.pagseguro.uol.com.br/v2\" , site : \"https://pagseguro.uol.com.br/v2\" site : 'https://sandbox.pagseguro.uol.com.br/v2' , api : 'https://ws.sandbox.pagseguro.uol.com.br/v2'", "commit_type": "remove"}
{"commit_tokens": ["Allow", "overriding", "server", "/", "options", "for", "K8s", "::", "Client", ".", "config"], "add_tokens": "def self . config ( config , namespace : nil , ** options ) new ( Transport . config ( config , ** options ) , namespace : namespace , )", "del_tokens": "def self . config ( config ) new ( Transport . config ( config ) )", "commit_type": "allow"}
{"commit_tokens": ["Remove", "unused", "code", "and", "add", "documentation", "."], "add_tokens": "# Raw body of the response. Typically only used for diagnostic purposes. # Raw code of the response. Typically only used for diagnostic purposes. result = to_json @csv ||= CSV . generate do | csv | @pp ||= JSON . pretty_generate ( to_json ) # Return true if the request was successful. # @return [Boolean] True if the request was successful (response code 200). # Return the body of the response # @return [String] JSON-formatted response in a String. def to_json @to_json ||= JSON . parse ( to_s ) end # Return the body of the response # @return [String] JSON-formatted response in a String.", "del_tokens": "# Raw body of the response, possibly only for transition purposes. # Raw code of the response, possibly only for transition purposes. result = JSON . parse ( to_s ) CSV . generate do | csv | JSON . pretty_generate ( JSON . parse ( to_s ) ) end def status code", "commit_type": "remove"}
{"commit_tokens": ["Add", "accept", "header", "for", "request", "methods"], "add_tokens": "request = HTTP_VERBS [ http_method ] . new ( full_path , 'accept' => 'application/json' ) request = HTTP_VERBS [ http_method ] . new ( path , 'accept' => 'application/json' )", "del_tokens": "request = HTTP_VERBS [ http_method ] . new ( full_path ) request = HTTP_VERBS [ http_method ] . new ( path )", "commit_type": "add"}
{"commit_tokens": ["Allow", "spaces", "in", "template", "variable", "names"], "add_tokens": "if @context . check ( / \\s *([^=}|<]+) \\s *= \\s * / ) name = @context . scan ( / \\s *([^=]+) / ) . strip", "del_tokens": "if @context . check ( / \\s *([^ =}|<]+) \\s *= \\s * / ) name = @context . scan ( / \\s *([^ =]+) / ) . strip", "commit_type": "allow"}
{"commit_tokens": ["added", "ghost", "attributes", "meaning", "you", "can", "read", "access", "attributes", "that", "are", "in", "the", "couchdb", "document", "but", "not", "defined", "as", "a", "property", "added", "CHANGES", "file"], "add_tokens": "require File . dirname ( __FILE__ ) + '/persistence/ghost_attributes' base . send :include , DirtyAttributes , GhostAttributes", "del_tokens": "base . send :include , DirtyAttributes", "commit_type": "add"}
{"commit_tokens": ["Add", "temporarily", ":", "entity_type", "to", "attr_accessible", "list", "for", "HydraAttribute", "model"], "add_tokens": "attr_accessible :entity_type , :name , :backend_type , :default_value", "del_tokens": "attr_accessible :name , :backend_type , :default_value", "commit_type": "add"}
{"commit_tokens": ["allow", "the", "plugin", "loader", "to", "take", "symbols"], "add_tokens": "include Roy :: Plugins ( Before , :after )", "del_tokens": "require 'roy/after' include Roy :: Plugins ( Before , After )", "commit_type": "allow"}
{"commit_tokens": ["Use", "middleman", "s", "build_dir", "variable", "."], "add_tokens": "local_files = ( Dir [ options . build_dir + \"/**/*\" ] + Dir [ options . build_dir + \"/**/.*\" ] ) . map { | f | f . gsub ( / ^ #{ options . build_dir } \\/ / , '' ) } local_mtime = File . mtime ( \"#{options.build_dir}/#{f}\" ) local_md5 = Digest :: MD5 . hexdigest ( File . read ( \"#{options.build_dir}/#{f}\" ) ) file . body = File . open ( \"#{options.build_dir}/#{f}\" ) :body => File . open ( \"#{options.build_dir}/#{f}\" ) ,", "del_tokens": "local_files = ( Dir [ options . public_path + \"/**/*\" ] + Dir [ options . public_path + \"/**/.*\" ] ) . map { | f | f . gsub ( / ^build \\/ / , '' ) } local_mtime = File . mtime ( \"build/#{f}\" ) local_md5 = Digest :: MD5 . hexdigest ( File . read ( \"build/#{f}\" ) ) file . body = File . open ( \"build/#{f}\" ) :body => File . open ( \"build/#{f}\" ) ,", "commit_type": "use"}
{"commit_tokens": ["add", "run!", "to", "raise", "errors", "when", "needed"], "add_tokens": "shared_examples 'validations pass' do | method | context 'validations pass' do subject ( :outcome ) { SubBase . send ( method , valid : true ) } it 'sets `response` to the value of `execute`' do expect ( outcome . response ) . to eq 'Execute!' end end end it_behaves_like 'validations pass' , :run describe '.run!(options = {})' do it_behaves_like 'validations pass' , :run! context 'validations fail' do it 'throws an error' do expect { SubBase . run! ( valid : false ) } . to raise_error ActiveInteraction :: InteractionInvalid end end end", "del_tokens": "context 'validations pass' do subject ( :outcome ) { SubBase . run ( valid : true ) } it 'sets `response` to the value of `execute`' do expect ( outcome . response ) . to eq 'Execute!' end end", "commit_type": "add"}
{"commit_tokens": ["Added", "words", "criss", "-", "cross", "check"], "add_tokens": "$stats = Hash . new { | h , k | h [ k ] = 0 } if rects . any? { | r | r . criss_cross? ( rect ) } $stats [ :criss_cross ] += 1 # no point to try drawing criss-crossed words # even if they will not collide pixel-per-pixel return true end # then find which of placed sprites rectangles tag intersects", "del_tokens": "$stats = { rect_no : 0 , px_yes : 0 , px_prev_yes : 0 , px_no : 0 } # first find which of placed sprites rectangles tag intersects", "commit_type": "add"}
{"commit_tokens": ["Added", "paid_at", "accessor", "to", "the", "bill", "resource"], "add_tokens": "date_accessor :created_at , :paid_at", "del_tokens": "date_accessor :created_at", "commit_type": "add"}
{"commit_tokens": ["Added", "collection_view_controller", "template", "color", ".", "random", "updated", "readme"], "add_tokens": "VERSION = \"0.4.1\"", "del_tokens": "VERSION = \"0.4.1b\"", "commit_type": "add"}
{"commit_tokens": ["moved", "crypto", "to", "subdir", ";", "cleanup"], "add_tokens": "require AGENT_ROOT + \"/agent/http_client\" require AGENT_ROOT + \"/agent/handshake\" require AGENT_ROOT + \"/agent/remote_exec\" require AGENT_ROOT + \"/agent/config\"", "del_tokens": "require 'uuidtools' require AGENT_ROOT + \"/operation\" require AGENT_ROOT + \"/http_client\" require AGENT_ROOT + \"/handshake\" require AGENT_ROOT + \"/remote_exec\" require AGENT_ROOT + \"/config\"", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "an", "OPTIONAL", "state", "param", "for", "the", "/", "authorize", "endpoint"], "add_tokens": "def test_index_contains_hidden_fields_for_client_id_and_redirect_uri_and_response_type_and_state :response_type => ' code ', :state => ' some - state ' assert_select \"#state[value='some-state']\" def test_authorize_should_return_authorization_code_with_expiry_if_user_authorizes_it_and_state_param_is_not_provided def test_authorize_should_return_authorization_code_with_expiry_and_state_if_user_authorizes_it_and_state_param_is_provided session [ :user_id ] = '13' post :authorize , :redirect_uri => 'http://example.com/cb' , :client_id => @client . client_id , :authorize => '1' , :response_type => 'code' , :state => 'foo&bar' assert_response :redirect @client . reload token = @client . oauth_tokens . first assert_equal \"http://example.com/cb?code=#{token.authorization_code}&expires_in=#{token.authorization_code_expires_in}&state=foo%26bar\" , @response . redirected_to end", "del_tokens": "def test_index_contains_hidden_fields_for_client_id_and_redirect_uri_and_response_type :response_type => 'code' def test_authorize_should_return_authorization_code_with_expiry_if_user_authorizes_it", "commit_type": "add"}
{"commit_tokens": ["fix", "code", "that", "ran", "in", "O", "(", "n^2", ")", "to", "run", "in", "O", "(", "n", ")"], "add_tokens": "inverse = { } objects . each do | id , object | ( inverse [ object ] ||= [ ] ) << id end inverse . values . each do | ids | ids . drop ( 1 ) . each do | id | map [ id ] = ids [ 0 ]", "del_tokens": "# We don't need to iterate on the last item in the hash, but skipping # the last item is more effort than running the last item. objects . each_with_index do | ( id1 , object1 ) , index | unless map . key? ( id1 ) # Don't search for duplicates of duplicates. objects . drop ( index + 1 ) . each do | id2 , object2 | if object1 == object2 map [ id2 ] = id1 end end", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "couple", "of", "missed", "file", "renames"], "add_tokens": "require 'archive/zip/data_descriptor'", "del_tokens": "require 'archive/zip/datadescriptor'", "commit_type": "fix"}
{"commit_tokens": ["Fix", "constant", "call", "name", "Objcect", "instead", "of", "Object"], "add_tokens": "Object . const_get name", "del_tokens": "Objcect . const_get name", "commit_type": "fix"}
{"commit_tokens": ["Use", "class", "instance", "variable", "for", "internal", "state"], "add_tokens": "@stately_machine = Stately :: Machine . new ( options [ :attr ] , options [ :start ] ) @stately_machine . instance_eval ( & block ) if block_given? self . instance_variable_get ( :@stately_machine ) @stately_machine = obj def stately_machine self . class . stately_machine end", "del_tokens": "self . stately_machine = Stately :: Machine . new ( options [ :attr ] , options [ :start ] ) self . stately_machine . instance_eval ( & block ) if block_given? @@stately_machine @@stately_machine = obj", "commit_type": "use"}
{"commit_tokens": ["Fix", "failing", "build", ";", "task", "for", "running", "in", "all", "versions", "of", "active", "support"], "add_tokens": "let ( :client ) { double ( 'TMS::Client' ) }", "del_tokens": "let ( :client ) { stub ( 'TMS::Client' ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "detach", "color", "combination", "."], "add_tokens": "if base . to_a . last == :detach Detached . new ( color , * base . to_a [ 0 ... - 1 ] ) else color . decorate ( unprocessed_string , * base ) end", "del_tokens": "color . decorate ( unprocessed_string , * base )", "commit_type": "add"}
{"commit_tokens": ["use", "a", "real", "windows", "1252", "fixture"], "add_tokens": "if @params [ key ] . respond_to? ( :force_encoding )", "del_tokens": "if RUBY_VERSION >= '1.9'", "commit_type": "use"}
{"commit_tokens": ["move", "ensure_dir", "up", "above", "validation", "so", "folder", "gets", "created", "even", "with", "bad", "json"], "add_tokens": "validate ( json , path )", "del_tokens": "validate ( json , path )", "commit_type": "move"}
{"commit_tokens": ["added", "rdoc", "for", "instance", "methods", "of", "Sandbox", "class"], "add_tokens": "# Used internally, switch to privileged state in a block and returns to previous state # Used internally, switch to unprivileged state in a block and returns to previous state #Run the code in sandbox with the given privileges # #Example: # # sandbox = Sandbox.new # sandbox.privileges.allow_method :print # sandbox.run('print \"hello world\\n\"')", "del_tokens": "# Run the code in sandbox with the given privileges", "commit_type": "add"}
{"commit_tokens": ["Updated", "spec_helper", "to", "latest", "rspec", "defaults"], "add_tokens": "# Requires supporting files with custom matchers and macros, etc, # in ./support/ and its subdirectories. Dir [ \"#{File.dirname(__FILE__)}/spec_helpers/**/*.rb\" ] . each { | f | require f } # See http://rubydoc.info/gems/rspec-core/RSpec/Core/Configuration config . treat_symbols_as_metadata_keys_with_true_values = true config . run_all_when_everything_filtered = true #config.filter_run :focus # Run specs in random order to surface order dependencies. If you find an # order dependency and want to debug it, you can fix the order by providing # the seed, which is printed after each run. # --seed 1234 config . order = 'random'", "del_tokens": "#require 'spec' require 'rspec/core' $LOAD_PATH . unshift ( File . dirname ( __FILE__ ) ) # require all files inside spec_helpers Dir [ File . join ( File . dirname ( __FILE__ ) , \"spec_helpers/*.rb\" ) ] . each { | file | require file }", "commit_type": "update"}
{"commit_tokens": ["Move", "bootstrap", "scripts", "into", "the", "gem"], "add_tokens": "def initialize ( server , platform , dest_dir = '/etc/chef' ) @dest_dir = dest_dir upload_bureau dna [ :path ] , @dest_dir @server . run \"sh /etc/chef/bootstrap/#{@platform}.sh\" if bootstrap @server . run \"chef-solo -c #{@dest_dir}/bootstrap/solo.rb -j #{@dest_dir + dna[:path]}\" end private def upload_bureau ( dna_path , dest_dir ) @server . run \"rm -rf #{dest_dir} && mkdir #{dest_dir}\" #{dna_path} #{File.expand_path(\"#{File.dirname(__FILE__)}/../../bootstrap\")} ) , dest_dir # move bootstrap directory to the top level @server . run \"cd #{dest_dir} && mv `find . -type d -name bootstrap -print0` .\"", "del_tokens": "def initialize ( server , platform ) @server . run \"rm -rf /{etc,tmp}/chef && mkdir /{etc,tmp}/chef\" #{dna[:path]} . / bootstrap ) , '/etc/chef' @server . run \"sh /etc/chef/bootstrap/#{@platform}.sh\" if bootstrap @server . run \"chef-solo -c /etc/chef/bootstrap/solo.rb -j /etc/chef/tmp/dna.json\"", "commit_type": "move"}
{"commit_tokens": ["use", "mongo", "mapper", "move", "code", "from", "server", "into", "mixins"], "add_tokens": "require 'meme_captain/image_list' require 'meme_captain/meme_data'", "del_tokens": "require 'meme_captain/mime_type_ext' require 'meme_captain/watermark'", "commit_type": "use"}
{"commit_tokens": ["Add", "fetcher", "working", "with", "the", "caching", "strategy"], "add_tokens": "require \"faraday\" require \"faraday_middleware\" #:nodoc: gem = fetch_gem ( id ) rescue GemNotFoundError app . halt 404 end def fetch_gem ( id ) gem = @storage . get ( id ) fetched_gem = @gem_fetcher . fetch ( id ) gem . save ( fetched_gem . headers , fetched_gem . body ) def initialize ( http_client : nil , server_url : nil ) @client = http_client @client ||= Faraday . new ( server_url || Gemstash :: Env . rubygems_url ) do | c | c . use FaradayMiddleware :: FollowRedirects c . adapter :net_http end end response = @client . get ( \"/gems/#{id}\" ) do | req | req . options . open_timeout = 2 end raise GemNotFoundError , id if response . status == 404 FetchedGem . new ( response . headers , response . body ) FetchedGem = Struct . new ( :headers , :body ) class GemNotFoundError < StandardError ; end", "del_tokens": "gem = @storage . get ( id ) unless gem . exist? headers , content = @gem_fetcher . fetch ( id ) gem . save ( headers , content ) end [ { \"CONTENT-TYPE\" => \"octet/stream\" } , \"zapatito\" ]", "commit_type": "add"}
{"commit_tokens": ["Updated", "passing", "specs", "with", "newly", "scraped", "pages"], "add_tokens": "@page . parser . css ( 'tr' ) . select { | r | r [ 'id' ] =~ / ^sku- / && r . css ( 'td' ) . size == 13 } . each do | row |", "del_tokens": "@page . parser . css ( 'tr' ) . select { | r | r [ 'id' ] =~ / ^sku- / && r . css ( 'td' ) . size == 12 } . each do | row |", "commit_type": "update"}
{"commit_tokens": ["Allow", "skipping", "the", "functional", "specs"], "add_tokens": "describe \"Producer API\" , type : :functional do before do require \"test_cluster\" end", "del_tokens": "require \"test_cluster\" describe \"Producer API\" do", "commit_type": "allow"}
{"commit_tokens": ["added", "to", "support", "inpage", "pageid", "plugin", "."], "add_tokens": "assert_match %r{ </script> \\n </head> } , last_response . body assert_equal \"504\" , last_response . headers [ 'Content-Length' ] assert_equal \"551\" , last_response . headers [ 'Content-Length' ] context \"with in-page page id\" do setup { mock_app :async => true , :tracker => 'happy' , :inpage_pageid => true } should \"embedded plugin script\" do get \"/\" assert_match %r{ inpage_linkid.js } , last_response . body end end", "del_tokens": "assert_match %r{ </script></head> } , last_response . body assert_equal \"501\" , last_response . headers [ 'Content-Length' ] assert_equal \"548\" , last_response . headers [ 'Content-Length' ]", "commit_type": "add"}
{"commit_tokens": ["Using", "correct", "(", "?", ")", "locale", "again"], "add_tokens": "before { @d = Collator . new ( \"no\" ) }", "del_tokens": "before { @d = Collator . new ( \"nb_NO\" ) }", "commit_type": "use"}
{"commit_tokens": ["Use", "geocoded_by", "method", "instead", "of", "include", "Geocoder", "for", "flexibility", "and", "cleaner", "syntax", "."], "add_tokens": "ActiveRecord :: Base . class_eval do ## # Include the Geocoder module and set the method name which returns # the geo-search string. # def self . geocoded_by ( method_name = :location ) include Geocoder @geocoder_method_name = method_name end end", "del_tokens": "# Include hook code here", "commit_type": "use"}
{"commit_tokens": ["Updated", "to", "tzdata", "version", "2007j", "(", "http", ":", "//", "article", ".", "gmane", ".", "org", "/", "gmane", ".", "comp", ".", "time", ".", "tz", "/", "1991", ")", "."], "add_tokens": "tz . transition 2007 , 12 , :o2 , 1197183600", "del_tokens": "tz . transition 2008 , 1 , :o2 , 1199160000", "commit_type": "update"}
{"commit_tokens": ["Fix", "multi", "-", "currency", "we", "should", "use", "payments", "currency", "rather", "than", "config", "option", "."], "add_tokens": "value = { currency : gateway_options [ :currency ] , value : amount } amount = { currency : gateway_options [ :currency ] , value : amount } { currency : payment . currency , value : payment . money . money . cents } amount = { currency : gateway_options [ :currency ] , value : amount }", "del_tokens": "value = { :currency => Config . currency , :value => amount } amount = { :currency => Config . currency , :value => credit_cents } { :currency => Config . currency , :value => payment . money . money . cents } amount = { :currency => Config . currency , :value => amount }", "commit_type": "fix"}
{"commit_tokens": ["Making", "net", "methods", "more", "debugable"], "add_tokens": "uri = \"/#{@api_version}#{path}\" oauth_response = access_token . get ( uri , headers ) uri = \"/#{@api_version}#{path}\" oauth_response = access_token . post ( uri , body , headers ) uri = \"/#{@api_version}#{path}\" oauth_response = access_token . delete ( uri , headers )", "del_tokens": "oauth_response = access_token . get ( \"/#{@api_version}#{path}\" , headers ) oauth_response = access_token . post ( \"/#{@api_version}#{path}\" , body , headers ) p path p headers oauth_response = access_token . delete ( \"/#{@api_version}#{path}\" , headers )", "commit_type": "make"}
{"commit_tokens": ["Use", "merge", "-", "base", "for", "diff"], "add_tokens": "@diff ||= begin ancestor = repo . merge_base ( from , to || 'HEAD' ) . sha repo . diff ( ancestor , to ) end", "del_tokens": "repo . diff ( from , to )", "commit_type": "use"}
{"commit_tokens": ["Allow", "settable", "installable", "tmp", "root", "-", "because", "of", "pkg", "json", "extract", "and", "then", "extract", "again"], "add_tokens": "def self . tmp_root @tmp_root ||= Pathname . new ( '/tmp/jim' ) end def self . tmp_root = ( new_tmp_root ) @tmp_root = Pathname . new ( new_tmp_root ) end @fetched_path = Downlow . get ( fetch_path , tmp_path ) final_path = ( fetched_path . to_s =~ / \\. js$ / ) ? final_dir + \"#{name}.js\" : final_dir final_path final_path self . class . tmp_root", "del_tokens": "@fetched_path = Downlow . fetch ( fetch_path , :destination => tmp_path ) final_path = ( fetched_path . to_s =~ / \\. js$ / ) ? final_dir + \"#{name}.js\" : final_dir return final_path @tmp_root ||= Pathname . new ( 'tmp' )", "commit_type": "allow"}
{"commit_tokens": ["Change", "to", "properly", "pass", "event", "information", "."], "add_tokens": "notify :enteraction , _transition , * args", "del_tokens": "notify :enteraction , _transition , * args", "commit_type": "change"}
{"commit_tokens": ["Made", "layout", "render", "block", "more", "optional"], "add_tokens": "yield if block_given?", "del_tokens": "yield", "commit_type": "make"}
{"commit_tokens": ["Add", "integration", "test", "for", "named", "capture", "routes"], "add_tokens": "match \"/nested/serviceworker.js\" , asset : \"another/serviceworker.js\" match \"/captures/*named/serviceworker.js\" => \"captures/%{named}-serviceworker.js\"", "del_tokens": "match \"/nested/serviceworker.js\" , asset : \"another/serviceworker.js\"", "commit_type": "add"}
{"commit_tokens": ["Move", "embed", "transformer", "code", "into", "main", "formatter", "class", "."], "add_tokens": "transformers : transformers def transformers [ embed_transformer ] end def embed_transformer lambda do | env | node = env [ :node ] node_name = env [ :node_name ] # We're fine with a bunch of stuff -- but not <iframe> and <embed> tags. return if env [ :is_whitelisted ] || ! env [ :node ] . element? return unless %w[ iframe embed ] . include? env [ :node_name ] # We're dealing with an <iframe> or <embed> tag! Let's check its src attribute. # If its host name matches our regular expression, we can whitelist it. uri = URI ( env [ :node ] [ 'src' ] ) return unless uri . host =~ allowed_iframe_hosts Sanitize . clean_node! ( node , { elements : %w[ iframe embed ] , attributes : { all : %w[ allowfullscreen frameborder height src width ] } } ) { node_whitelist : [ node ] } end end", "del_tokens": "transformers : EmbedTransformer . new ( allowed_iframe_hosts : allowed_iframe_hosts )", "commit_type": "move"}
{"commit_tokens": ["Fixed", "seconds", "seconds", "for", "RSpec1", "formatter", "."], "add_tokens": "@output . puts \"\\nYou've Nyaned for #{format_duration(duration)}\\n\" . each_char . map { | c | rainbowify ( c ) } . join", "del_tokens": "@output . puts \"\\nYou've Nyaned for #{format_duration(duration)} seconds\\n\" . each_char . map { | c | rainbowify ( c ) } . join", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "use", "mimi", "/", "core"], "add_tokens": "default_options ( ) opts = self . class . module_options . deep_merge ( opts )", "del_tokens": "DEFAULT_OPTS = { } . freeze opts = DEFAULT_OPTS . merge ( opts )", "commit_type": "update"}
{"commit_tokens": ["updated", "the", "regex", "apparently", "it", "wasnt", "detected", "three", "nested", "braces"], "add_tokens": "$BIBTEX_REGEX = / @[^{]+{(?:[^{}]|{[^{}]*}|{{[^{}]*}})*} /", "del_tokens": "$BIBTEX_REGEX = / @[^ \\{ ]+ \\{ (?:[^ \\{ \\} ]| \\{ [^ \\{ \\} ]* \\} )* \\} /", "commit_type": "update"}
{"commit_tokens": ["Remove", "global", "logging", "level", "variable", "."], "add_tokens": "require 'rainbow/color' reset def reset @level = FATAL def set_widths file , line , function @format = Logue :: LocationFormat . new file : file , line : line , function : function", "del_tokens": "$LOGGING_LEVEL = nil attr_accessor :quiet set_defaults def set_defaults $LOGGING_LEVEL = @level = FATAL @quiet = false def set_widths file_width , line_width , function_width @format = Logue :: LocationFormat . new file : file_width , line : line_width , function : function_width", "commit_type": "remove"}
{"commit_tokens": ["Remove", "meta", "-", "tags", "gem", "/", "add", "content", "block", "modals", "on", "articles", "edit"], "add_tokens": "# validates :image, blob: { content_type: ['image/png', 'image/jpg', 'image/jpeg'], size_range: 0..5.megabytes }", "del_tokens": "validates :image , blob : { content_type : [ 'image/png' , 'image/jpg' , 'image/jpeg' ] , size_range : 0 .. 5 . megabytes }", "commit_type": "remove"}
{"commit_tokens": ["Added", "ability", "to", "accept", "a", "URL", "for", "the", "image", "file", "as", "well"], "add_tokens": "# # You can also assign a URL to an image, which will make the plugin go # and fetch the image at the provided URL. The image will be stored # locally as a master image for that record form then on. # # @photo.image_file = 'http://foo.com/bar.jpg' file = open ( file ) if file =~ %r{ ^https?:// } def image_file if new_record? nil else if File . exists? ( file_path ) File . open ( file_path , 'r+' ) else nil end end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "to", "file", "method", "."], "add_tokens": "match = case @attribute . to_s when / password / then :password when / time_zone / then :time_zone when / country / then :country end match || input_type || file_method? || :string # Checks if attribute is a file_method. def file_method? #:nodoc: file = @object . send ( @attribute ) if @object . respond_to? ( @attribute ) :file if file && SimpleForm . file_methods . any? { | m | file . respond_to? ( m ) } end", "del_tokens": "@attribute . to_s =~ / password / ? :password : :string", "commit_type": "add"}
{"commit_tokens": ["Fix", "type", "in", "error", "being", "raised", "."], "add_tokens": "raise Shells :: ShellError , \"The #{use_method} binary is not available with this shell.\" unless which ( use_method ) raise Shells :: ShellError , \"The #{use_method} binary is not available with this shell.\" unless which ( use_method )", "del_tokens": "raise Shells :: ShellErro , \"The #{use_method} binary is not available with this shell.\" unless which ( use_method ) raise Shells :: ShellErro , \"The #{use_method} binary is not available with this shell.\" unless which ( use_method )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "tests", "to", "take", "a", "schema_url_prefix"], "add_tokens": "def routes? ( method , path , options = { } ) path = options [ :prefix ] + path if options [ :prefix ] def routes_request? ( request , options = { } ) routes? ( request . request_method , request . path_info , options )", "del_tokens": "def routes? ( method , path ) def routes_request? ( request ) routes? ( request . request_method , request . path_info )", "commit_type": "allow"}
{"commit_tokens": ["Add", "StringIsXml", "middleware", "for", "assuming", "that", "string", "bodies", "are", "XML", "if", "not", "otherwise", "specified", "."], "add_tokens": "autoload :HttpBasic , 'psc/faraday/http_basic' autoload :PscToken , 'psc/faraday/psc_token' autoload :StringIsXml , 'psc/faraday/string_is_xml'", "del_tokens": "autoload :HttpBasic , 'psc/faraday/http_basic' autoload :PscToken , 'psc/faraday/psc_token'", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "commit_comment", "events"], "add_tokens": "commit_comment", "del_tokens": "# TODO: Support for commit_comment", "commit_type": "add"}
{"commit_tokens": ["Use", "formated", "versions", "of", "Author#loc", "#commits", "and", "#files", "in", "table"], "add_tokens": "table ( authors , fields : [ :name , :f_loc , :f_commits , :f_files , :percent ] )", "del_tokens": "table ( authors , fields : [ :name , :loc , :commits , :files , :percent ] )", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "where", "the", "update", "script", "is", "automatically", "called", "."], "add_tokens": "@master_whitelist = JSON . parse ( IO . readlines ( File . expand_path ( \"emojis.json\" , File . dirname ( __FILE__ ) ) ) . join )", "del_tokens": "@master_whitelist = JSON . parse ( IO . readlines ( \"emojis.json\" ) . join )", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "extract", "fit", "types"], "add_tokens": "# the trends to consider FIT_TYPES = [ :exponential , :power , :linear , :logarithmic ] FIT_TYPES . each do | fit | if rr > best_residual && aic > best_aic", "del_tokens": "# the trends to consider fit_types = [ :exponential , :power , :linear , :logarithmic ] fit_types . each do | fit | if rr > best_residual && aic >= best_aic", "commit_type": "change"}
{"commit_tokens": ["Fix", "multiline", "issue", "in", "Dockerfile"], "add_tokens": "multiline << line . chop", "del_tokens": "multiline << line . chomp", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "for", "global", "tags", "handling", "of", "nil", "global", "tags", "and", "docs"], "add_tokens": "# @param [Array<String>] tags tags to be added to every metric ts = ( tags || [ ] ) + ( opts [ :tags ] || [ ] )", "del_tokens": "ts = tags + ( opts [ :tags ] || [ ] )", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "defined", "names"], "add_tokens": ":worksheet_rels , :printer_settings , :macros , :colors , :shared_strings_XML , :defined_names @defined_names = nil", "del_tokens": ":worksheet_rels , :printer_settings , :macros , :colors , :shared_strings_XML", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "top", "-", "level", "enums"], "add_tokens": "repeated :message_type , DescriptorProto , 4 ; repeated :enum_type , EnumDescriptorProto , 5 ; Array ( file . enum_type ) . each do | et | enum! ( et ) end", "del_tokens": "repeated :message_type , DescriptorProto , 4 ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "file", "on", "Open", ".", "write", "if", "the", "command", "raises", "an", "exception"], "add_tokens": "File . open ( file , 'w' ) do | f | f . flock ( File :: LOCK_EX ) f . write content f . flock ( File :: LOCK_UN ) end begin File . open ( file , 'w' ) do | f | f . flock ( File :: LOCK_EX ) while l = content . gets f . write l end f . flock ( File :: LOCK_UN ) rescue FileUtils . rm file if File . exists? file", "del_tokens": "File . open ( file , 'w' ) do | f | f . write content end File . open ( file , 'w' ) do | f | while l = content . gets f . write l", "commit_type": "remove"}
{"commit_tokens": ["Allow", "publisher", "to", "be", "redefined", "."], "add_tokens": "@_exchange_names += names . flatten return @_exchange_names . compact . uniq @_remote_application_name = name if name @_remote_application_name", "del_tokens": "@_exchange_names += names return @_exchange_names @_remote_application_name ||= name", "commit_type": "allow"}
{"commit_tokens": ["Add", "allow_extra", "option", "for", "Committee", "::", "Middleware", "::", "RequestValidation"], "add_tokens": "@allow_extra = options [ :allow_extra ] Committee :: ParamValidator . new ( env [ @params_key ] , @schema , link , allow_extra : @allow_extra ) . call", "del_tokens": "Committee :: ParamValidator . new ( env [ @params_key ] , @schema , link ) . call", "commit_type": "add"}
{"commit_tokens": ["Add", "symbol", "-", "keys", "for", "Dispatcher", ".", "params"], "add_tokens": "halt 403 unless params [ :access ] == 'true'", "del_tokens": "halt 403 unless params [ 'access' ] == 'true'", "commit_type": "add"}
{"commit_tokens": ["creating", "a", "directory", "is", "now", "supported"], "add_tokens": "attr_accessor :name , :id , :type , :size , :mimetype , :parent_id def file? @type == File :: Type :: FILE end file = File . new ( json [ 'name' ] , json [ 'fileid' ] , json [ 'type' ] . to_i ) file . parent_id = json [ 'parentid' ]", "del_tokens": "attr_accessor :name , :id , :type , :size , :mimetype file = File . new ( json [ 'name' ] , json [ 'fileid' ] , json [ 'type' ] )", "commit_type": "create"}
{"commit_tokens": ["Adding", "support", "for", "paging", "of", "results", "on", "unsubscribed", "and", "bounced", "subscribers", "."], "add_tokens": "def bounced ( date , page = 1 , page_size = 1000 , order_field = \"email\" , order_direction = \"asc\" ) options = { :query => { :date => date , :page => page , :pagesize => page_size , :orderfield => order_field , :orderdirection => order_direction } } Hashie :: Mash . new ( response ) def unsubscribed ( date , page = 1 , page_size = 1000 , order_field = \"email\" , order_direction = \"asc\" ) options = { :query => { :date => date , :page => page , :pagesize => page_size , :orderfield => order_field , :orderdirection => order_direction } } Hashie :: Mash . new ( response )", "del_tokens": "def bounced ( date ) options = { :query => { :date => date } } response . map { | item | Hashie :: Mash . new ( item ) } def unsubscribed ( date ) options = { :query => { :date => date } } response . map { | item | Hashie :: Mash . new ( item ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "Contact", "endpoints", "to", "Client"], "add_tokens": "require 'messagebird/contact' require 'messagebird/list' require 'messagebird/lookup' require 'messagebird/verify' return if response_body . empty? def contact_create ( phoneNumber , params = { } ) Contact . new ( request ( :post , 'contacts' , params . merge ( { :msisdn => phoneNumber . to_s } ) ) ) end def contact ( id ) Contact . new ( request ( :get , \"contacts/#{id}\" ) ) end def contact_delete ( id ) request ( :delete , \"contacts/#{id}\" ) end def contact_update ( id , params = { } ) request ( :patch , \"contacts/#{id}\" , params ) end def contact_list ( params = { } ) List . new ( Contact , request ( :get , 'contacts' , params ) ) end", "del_tokens": "require 'messagebird/verify' require 'messagebird/lookup'", "commit_type": "add"}
{"commit_tokens": ["fix", "failing", "specs", "due", "to", "endless", "rebasing!"], "add_tokens": "surveys_path", "del_tokens": "question_groups_path", "commit_type": "fix"}
{"commit_tokens": ["Remove", "object", "delegation", "from", "vertices"], "add_tokens": "# When +vertices+ is a hash, it contains initialization kwargs as # values and vertex names as keys. When +vertices+ is an array of # initialization kwargs, the vertices will be be anonymous. # Any kwarg supported by Graph.new is also allowed. # vertices . each do | kwargs | add_vertex ( ** kwargs ) vertices . each do | name , kwargs | add_vertex ( name : name , ** kwargs )", "del_tokens": "# When +vertices+ is a hash, it contains the objects as values and # their names as keys. When +vertices+ is an array the objects will # get assigned unique names (within the graph). # # +vertices+ can contain anything, and the Vertex object that is created # will delegate all missing methods to its content. # Graph.new(vertices: +array_or_hash+) => Graph # Graph.new(vertices: +array_or_hash+, edges: +array_or_hash+) => Graph # When +array_or_hash+ is a hash, it contains the objects as values and # their names as keys. When +array_or_hash+ is an array the objects will # get assigned unique names (within the graph). # # +vertices+ can contain anything, and the Vertex object that is created # will delegate all missing methods to its content. # # +edges+ can contain an array of exactly two, either names of vertices # or vertices. # # contents: delegate object for missing methods vertices . each do | delegate | add_vertex ( delegate : delegate ) vertices . each do | name , delegate | add_vertex ( name : name , delegate : delegate )", "commit_type": "remove"}
{"commit_tokens": ["use", "the", "right", "id", "here"], "add_tokens": "Resque . enqueue ( DeployJob , deploy_id : deploy . id )", "del_tokens": "Resque . enqueue ( DeployJob , deploy_id : id )", "commit_type": "use"}
{"commit_tokens": ["Add", "gem", "badge", "to", "README", ".", "md"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "child", "tasks", "improved", "rake", "installation"], "add_tokens": "attr_accessor :name , :no_output io . input ( :no_output , 'If true, intentionally produces no output' , ActionCommand :: OPTIONAL ) io . output ( :greeting , 'Greeting for the person' ) def initialize ( args ) @no_output = false super ( args ) end result [ :greeting ] = \"Hello #{@name}\" unless no_output", "del_tokens": "attr_accessor :name result [ :greeting ] = \"Hello #{@name}\"", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "for", "return", "value", "on", "transmit"], "add_tokens": "# @param {String} bits This must be a binary string. Use `Array#pack('C*')` to generate the string. # @return [Boolean] Returns true if all the data was sent and received by the NXT. def transmit bits bytes_sent = @handle . bulk_transfer dataOut : bits , endpoint : USB_ENDPOINT_OUT bytes_sent == bits . length", "del_tokens": "# @param {String} bits This must be a binary string. Use `Array#pack` to generate the string. # @return [nil] def send_bits bits @handle . bulk_transfer dataOut : bits , endpoint : USB_ENDPOINT_OUT nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "up", "the", "dependency", "on", "GMapsLineEncoder", "."], "add_tokens": "# # Encoding only works if the GMapsLineEncoder plugin is available. if options [ :encoded ] && defined? ( GMapsLineEncoder ) # # Encoding only works if the GMapsLineEncoder plugin is available. if options [ :encoded ] && defined? ( GMapsLineEncoder )", "del_tokens": "require 'geos' require 'g_maps_line_encoder' if options [ :encoded ] if options [ :encoded ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "around", "connection", "closes"], "add_tokens": "context 'when an error is raised' do subject { transmitter . send_message! ( payload , routing_key ) } let ( :error ) { 'oh no' } before do allow ( topic_exchange ) . to receive ( :publish ) . and_raise ( error ) end it 'should raise the error' do expect { subject } . to raise_error ( error ) end it 'should close the channel connector' do begin ; subject ; rescue ; end expect ( channel_connector ) . to have_received ( :connection_close ) end end context \"with only basic required arguments\" do context 'when an error is raised' do subject { transmitter . send_delayed_message! ( payload , routing_key ) } let ( :error ) { 'oh no' } before do allow ( delayed_exchange ) . to receive ( :publish ) . and_raise ( error ) end it 'should raise the error' do expect { subject } . to raise_error ( error ) end it 'should close the channel connector' do begin ; subject ; rescue ; end expect ( channel_connector ) . to have_received ( :connection_close ) end end", "del_tokens": "context \"with only basic required arguments\" do", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "missing", "intraday", "series", "arguments"], "add_tokens": "'Must specify the start_date to fetch intraday time series data'", "del_tokens": "'Must specify the date to fetch intraday time series data for.'", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "to", "blog_category_test", ".", "rb"], "add_tokens": "sub_test_case 'attribute \"fixed\" is \"yes\"' do setup do File . open ( 'test/fixture/categories_1.xml' ) do | f | @xml = f . read end @sut = BlogCategory . load_xml ( @xml ) test 'get the categories list' do assert_equal [ 'Perl' , 'Scala' , 'Ruby' ] , @sut . categories end test 'changing the categories array does not influence to the original categories array' do end test 'get each category' do categories = [ ] @sut . each do | category | categories << category end assert_equal [ 'Perl' , 'Scala' , 'Ruby' ] , categories end test 'the categories list is fixed' do assert_true @sut . fixed? sub_test_case 'attribute \"fixed\" is not exist' do setup do File . open ( 'test/fixture/categories_2.xml' ) do | f | @xml = f . read end @sut = BlogCategory . load_xml ( @xml ) end test 'the categories list is not fixed' do assert_false @sut . fixed? end", "del_tokens": "def setup File . open ( 'test/fixture/categories.xml' ) do | f | @xml = f . read @sut = BlogCategory . load_xml ( @xml ) end test 'get the categories list' do assert_equal [ 'Perl' , 'Scala' , 'Ruby' ] , @sut . categories end test 'changing the categories array does not influence to the original categories array' do end test 'get each category' do categories = [ ] @sut . each do | category | categories << category assert_equal [ 'Perl' , 'Scala' , 'Ruby' ] , categories test 'the categories list is fixed' do assert_true @sut . fixed?", "commit_type": "add"}
{"commit_tokens": ["Fix", "rspec", "dummy", "app", "config", "path"], "add_tokens": "require File . expand_path ( '../dummy/config/environment.rb' , __FILE__ )", "del_tokens": "require File . expand_path ( '../../config/environment' , __FILE__ )", "commit_type": "fix"}
{"commit_tokens": ["use", "correct", "method", "for", "invoking", "the", "notification"], "add_tokens": "def notify ( opts = { } )", "del_tokens": "def notify! ( opts = { } )", "commit_type": "use"}
{"commit_tokens": ["Remove", "non", "-", "informative", "sequences"], "add_tokens": "# Function for marking rows (sequences) and returning a newly # cloned alignment module MarkRow # Mark each seq def mark_rows # clone row state, or add a state object end module DelNonInformativeSequences include MarkRow # Return a new alignment with rows marked for deletion, i.e. mark rows # that mostly contain undefined elements and gaps (threshold # +percentage+). The alignment returned is a cloned copy def mark_non_informative_sequences percentage = 30 mark_row end", "del_tokens": "module DelNonInformativeSequences # Return a new alignment with rows marked for deletion, i.e. mark rows # that mostly contain undefined elements and gaps (threshold # +percentage+). The alignment returned is a cloned copy def mark_non_informative_sequences percentage = 30 # clone row state", "commit_type": "remove"}
{"commit_tokens": ["Moved", "the", "configuration", "to", "the", "module"], "add_tokens": "# # TODO TODO TODO FIXME # Refactorings incomming. # * extract to publisher and subscriber base classes # * only keep the neccassary code in Base", "del_tokens": "# TODO: move to module def self . configuration yield Bandersnatch . config end", "commit_type": "move"}
{"commit_tokens": ["allow", "for", "paths", "with", "spaces", "in", "them", "for", "the", "executable", "yikes"], "add_tokens": "cmd = '\"' + which ( ENV [ 'RB_GNUPLOT' ] || 'gnuplot' ) + '\"'", "del_tokens": "cmd = which ( ENV [ 'RB_GNUPLOT' ] || 'gnuplot' )", "commit_type": "allow"}
{"commit_tokens": ["Change", "to", "obey", "method", "visiblity"], "add_tokens": "class StringIO undef_method :tty? def tty? true end", "del_tokens": "StringIO . undef_method :tty? StringIO . define_method :tty? do true", "commit_type": "change"}
{"commit_tokens": ["add", "window", ".", "inspect", "for", "child", "window", "information"], "add_tokens": "it \"should have the title 'Calculator' that matches the main_window title\" do @calculator . main_window . title . should == @calculator . title end it \"should have an inspect method showing child window information\" do @calculator . inspect . should match ( / @children=@window_class: Edit / ) it \"should open the 'About' menu\" do # TODO: need to set the foreground window first #@calculator.keystroke(VK_MENU, VK_H, VK_A) #sleep 1 #p @calculator end", "del_tokens": "it \"should have the title 'Calculator'\" do", "commit_type": "add"}
{"commit_tokens": ["Added", "link", "to", "warning", "note", "for", "dos2unix", "methods", "."], "add_tokens": "# This method may need to be modified. An example of a more complex # implementation is at: # http://dos2unix.sourcearchive.com/documentation/5.0-1/dos2unix_8c-source.html.", "del_tokens": "# This method may need to be modified.", "commit_type": "add"}
{"commit_tokens": ["fix", "cops", "in", "data", "ordering"], "add_tokens": "outliers . take ( max . score - mean < 6 || max . score < 15 ? 1 : 3 )", "del_tokens": "outliers . take ( 6 > max . score - mean || 15 > max . score ? 1 : 3 )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "fallback", "in", "cases", "where", "included", "queries", "are", "a", "mix", "of", "relations", "and", "methods"], "add_tokens": "render json : show_json # The response for show action, which can be a fieldset # or a full response of attributes def show_json if params [ :select ] . present? @object . to_json ( include : parsed_include , only : parsed_select ) else @object . to_json ( include : parsed_include ) end end rescue ActiveRecord :: AssociationNotFoundError @records = JSON . parse ( @records . to_json ( include : parsed_include ) )", "del_tokens": "render json : @object . to_json ( include : parsed_include )", "commit_type": "add"}
{"commit_tokens": ["fixed", "to_s", "for", "if", "a", "banner", "doesnt", "exist"], "add_tokens": "( banner || '' ) + options . map ( & :to_s ) . join ( \"\\n\" )", "del_tokens": "banner + options . map ( & :to_s ) . join ( \"\\n\" )", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "that", "the", "user", "knows", "that", "they", "re", "doing", "something", "stupid", "when", "they", "enable", "helpers", "."], "add_tokens": "if defined? :: Rails def self . enable_rails_helpers! ( Rails . env == 'development' ? Logger . new ( STDOUT ) : Rails . logger ) . warn \"WARNING (hamlbars): Enabling helpers in assets can have unintended consequences and violates separation of concerns. You have been warned.\" alias_method :evaluate_without_rails_helpers , :evaluate alias_method :evaluate , :evaluate_with_rails_helpers end end def evaluate_with_rails_helpers ( scope , locals , & block ) evaluate_without_rails_helpers ( scope , locals , & block ) end def evaluate ( scope , locals , & block )", "del_tokens": "def evaluate ( scope , locals , & block )", "commit_type": "make"}
{"commit_tokens": ["Added", "new", "unicode", "properties", "to", "the", "parser", "and", "updated", "related", "tests"], "add_tokens": "def name @text [ / [^ \\\\ pP{}]+ / ] end class Newline < Base ; end class Age < CharacterProperty :: Base ; end class Derived < CharacterProperty :: Base ; end class Script < CharacterProperty :: Base ; end", "del_tokens": "module Derived class Base < CharacterProperty :: Base ; end class Math < Derived :: Base ; end class Alphabetic < Derived :: Base ; end class Lowercase < Derived :: Base ; end class Uppercase < Derived :: Base ; end class IDStart < Derived :: Base ; end class IDContinue < Derived :: Base ; end class GraphemeBase < Derived :: Base ; end class GraphemeExtend < Derived :: Base ; end class DefaultIgnorableCP < Derived :: Base ; end class XIDStart < Derived :: Base ; end class XIDContinue < Derived :: Base ; end end", "commit_type": "add"}
{"commit_tokens": ["Use", "Rack", "::", "Request", "extension", "method", "http?", "and", "http?"], "add_tokens": "require \"rack/secure_only/request\" if secure? && req . http? ( @use_http_x_forward ) elsif not_secure? && req . https? ( @use_http_x_forward )", "del_tokens": "if secure? && on_http? ( env ) elsif not_secure? && on_https? ( env )", "commit_type": "use"}
{"commit_tokens": ["changing", "the", "way", "of", "delegation"], "add_tokens": "eval \"def #{ß}( *aa, &b ); puts '%s, %s' % '#{ß}', self; self.y_petri_manipulator.send #{ß}, *aa, &b end\"", "del_tokens": "eval \"def #{ß}( *aa, &b ); puts '%s, %s' % ß, self; self.y_petri_manipulator.send #{ß}, *aa, &b end\"", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "small", "bug", "when", "used", "Filters", "with", "conditions"], "add_tokens": "mock_controller = OpenStruct . new mock_controller . action_name = action filter . options [ :if ] = nil #remove conditions (this would call a Proc on the mock_controller)", "del_tokens": "mock_controller = OpenStruct . new ( :action_name => action )", "commit_type": "fix"}
{"commit_tokens": ["update", "time", "and", "timestamp", "for", "relocation", "of", "pack", "directives"], "add_tokens": "new ( * bson . read ( 8 ) . unpack ( Int32 :: PACK * 2 ) . reverse )", "del_tokens": "new ( * bson . read ( 8 ) . unpack ( INT32_PACK * 2 ) . reverse )", "commit_type": "update"}
{"commit_tokens": ["implement", "cut", "method", "for", "cutting", "length", "of", "table"], "add_tokens": "puts cut ( sprintf ( formatter , * header ) , 80 ) puts cut ( widths . map { | width | line * width } . join ( separator ) , 80 ) columns . transpose . each { | row | puts cut ( sprintf ( formatter , * row ) , 80 ) } def cut ( string , size ) string [ 0 .. size - 1 ] end", "del_tokens": "puts sprintf ( formatter , * header ) puts widths . map { | width | line * width } . join ( separator ) columns . transpose . each { | row | puts sprintf ( formatter , * row ) }", "commit_type": "implement"}
{"commit_tokens": ["Use", "real", "representer", "module", "in", "hypermedia", "responder", "tests"], "add_tokens": "include Garage :: Representer param :key1", "del_tokens": "attr_accessor :params , :default_url_options , :partial , :selector def self . params [ :key1 ] end", "commit_type": "use"}
{"commit_tokens": ["move", "code", "-", "climate", "test", "reporter", "to", "first", "line", "of", "spec_helper"], "add_tokens": "require \"codeclimate-test-reporter\" CodeClimate :: TestReporter . start", "del_tokens": "require \"codeclimate-test-reporter\" CodeClimate :: TestReporter . start", "commit_type": "move"}
{"commit_tokens": ["Changed", "the", "style", "to", "km", ".", "record", "instead", "of", "km_record"], "add_tokens": "km . identify ( params [ :snog ] [ :who ] ) km . record ( 'want_to_snog' , :whom => params [ :snog ] [ :whom ] )", "del_tokens": "km_identify ( params [ :snog ] [ :who ] ) km_record ( 'want_to_snog' , :whom => params [ :snog ] [ :whom ] )", "commit_type": "change"}
{"commit_tokens": ["allow", "reference", "to", "instance", "variables", "from", "evalhooked", "code"], "add_tokens": "class N def foo ( hook_handler ) @a = 5 hook_handler . evalhook ( \"@a\" ) end end N . new . foo ( hook_handler ) . should be == 5", "del_tokens": "@a = 5 hook_handler . evalhook ( \"@a\" ) . should be == @a", "commit_type": "allow"}
{"commit_tokens": ["Use", "object", "files", "of", "application", "instead", "of", "the", "app", "-", "lib", "when", "building", "the"], "add_tokens": ":objects => objs ,", "del_tokens": ":objects => @app_main_obj ,", "commit_type": "use"}
{"commit_tokens": ["use", "the", "changes", "I", "ve", "made", "to", "ROXML", "and", "register", "2", "new", "types", ":", "yyyymmdd", "and", "two_digit"], "add_tokens": "require File . join ( File . dirname ( __FILE__ ) , \"onix\" , \"two_digit_type\" ) require File . join ( File . dirname ( __FILE__ ) , \"onix\" , \"date_type\" )", "del_tokens": "#require File.join(File.dirname(__FILE__), \"onix\", \"two_digit_node\") #require File.join(File.dirname(__FILE__), \"onix\", \"date_node\")", "commit_type": "use"}
{"commit_tokens": ["Allow", "to", "redefine", "api_url", "if", "already", "set"], "add_tokens": "class << self attr_accessor :http_client end self . class . http_client = Excon . new ( @api_url , omit_default_port : true ) @api_url || ENV [ 'KONG_URI' ] || 'http://localhost:8001' @http_client = Excon . new ( self . api_url , omit_default_port : true ) end def http_client self . class . http_client self . class . api_url", "del_tokens": "attr_reader :http_client @http_client = Excon . new ( @api_url , omit_default_port : true ) @api_url @api_url ||= self . class . api_url || ENV [ 'KONG_URI' ] || 'http://localhost:8001'", "commit_type": "allow"}
{"commit_tokens": ["use", "display_name", "instead", "of", "private", "chef"], "add_tokens": ":desc => \"Delete *all* #{display_name} data, and start from scratch.\" ,", "del_tokens": ":desc => \"Delete *all* private chef data, and start from scratch.\" ,", "commit_type": "use"}
{"commit_tokens": ["Remove", "jruby", "hack", "needs", "proper", "solution", "."], "add_tokens": "pid = Process . spanw ( cmd . to_command , opts )", "del_tokens": "pid = _spawn ( cmd . to_command , opts ) def jruby? RUBY_PLATFORM =~ / java / end def _spawn ( cmd , opts ) Process . spawn ( cmd , jruby? ? { } : opts ) end", "commit_type": "remove"}
{"commit_tokens": ["adding", "a", "method", "for", "fetching", "private", "instance", "variables"], "add_tokens": "tag = [ '!ruby/exception' , o . class . name ] . join ':' { 'message' => private_iv_get ( o , 'mesg' ) , 'backtrace' => private_iv_get ( o , 'backtrace' ) , } . each do | k , v | next unless v append Nodes :: Scalar . new k accept v", "del_tokens": "tag = [ '!ruby/exception' , o . class . name ] . compact . join ( ':' ) [ 'message' , o . message ] . each do | m | accept m", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "for", "GetJobErrors", "."], "add_tokens": "# and errors that are specific to this class: # Gets errors that occured during the execution of a job in Manta at a given # path. # # The path must start with /<user>/jobs and point at an actual job. # # Returns an array of hashes, each hash containing information about an # error; this information is best-effort by Manta, so it may not be complete. # Also returns received HTTP headers. # # If there was an unrecoverable error, throws an exception. On connection or # corruption errors, more attempts will be made; the number of attempts can # be altered by passing in :attempts. def get_job_errors ( job_path , opts = { } ) url = job_url ( job_path , '/err' ) headers = gen_headers ( ) attempt ( opts [ :attempts ] ) do result = @client . get ( url , nil , headers ) raise unless result . is_a? HTTP :: Message raise unless result . headers [ 'Content-Type' ] == 'application/x-json-stream; type=job-error' if result . status == 200 json_chunks = result . body . split ( \"\\r\\n\" ) # sent_num_entries = result.headers['Result-Set-Size'] # raise CorruptResultError if json_chunks.size != sent_num_entries.to_i errors = json_chunks . map { | i | JSON . parse ( i ) } return errors , result . headers end raise_error ( result ) end end host = 'https://10.2.121.146' sleep ( 5 ) manta_client . cancel_job ( path )", "del_tokens": "host = 'https://10.2.121.184' state , _ = manta_client . cancel_job ( path )", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "changefreq", "gets", "covered"], "add_tokens": "it 'can round-trip to XML' do < changefreq > daily < / changefreq > modified = \"2013-01-03T18:00changefreq:00Z\" / >", "del_tokens": "it 'can round-trip to XML with namespaces' do modified = \"2013-01-03T18:00:00Z\" / >", "commit_type": "make"}
{"commit_tokens": ["Move", "setup", "/", "cleanup", "to", "before", "/", "after", "blocks", "."], "add_tokens": "@topic = 'some-topic' @consumer = Nsq :: Consumer . new ( topic : @topic , after do @consumer . terminate @cluster . destroy end @nsqd . pub ( @topic , 'some-message' ) msg = @consumer . messages . pop", "del_tokens": "end after do consumer . terminate @cluster . destroy end let ( :topic ) { 'some-topic' } subject ( :consumer ) do Nsq :: Consumer . new ( topic : topic , @nsqd . pub ( topic , 'some-message' ) msg = consumer . messages . pop", "commit_type": "move"}
{"commit_tokens": ["Update", "to", "the", "latest", "DatTCP", "using", "common", "DatWorkerPool"], "add_tokens": "# `serve!` can be called at the same time by multiple threads. Thus we # create a new instance of the handler for every request. def serve! ( socket )", "del_tokens": "# `serve` can be called at the same time by multiple threads. Thus we create # a new instance of the handler for every request. def serve ( socket )", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "conform", "to", "update", "of", "RSpec"], "add_tokens": "expect ( Cha . respond_to? ( :new , true ) ) . to be_truthy", "del_tokens": "require 'spec_helper' expect ( Cha . respond_to? ( :new , true ) ) . to be_true", "commit_type": "change"}
{"commit_tokens": ["added", "logging", "feature", ":", "fresh", "is", "now", ":", "created", "for", "code", "simplicity", "|", "reversed", "recent", "task", "order", "and", "only", "showing", "3", "instead", "of", "5"], "add_tokens": "sort_by { | e | e [ :completed_at ] } [ 0 .. 3 ] . reverse . each do | e | # Show task history @db . map do | entity | Entity :: Status . map do | status | { title : entity [ :title ] , action : status , time : entity [ :\" #{ status } _at \" ] } if entity [ :\" #{ status } _at \" ] end . compact end . flatten . sort_by { | e | e [ :time ] } . reverse . each do | entry | out \"##{entry[:time]}# ^#{entry[:action]}^ ''#{entry[:title]}''\" end Status = [ :created , :completed , :removed ] self . replace status : :created ,", "del_tokens": "sort_by { | e | e [ :completed_at ] } [ 0 .. 5 ] . each do | e | # Show completed tasks Status = [ :completed , :fresh , :removed ] self . replace status : :fresh ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "defining", "setup", "steps", "with", "blocks", "and", "setting", "step", "names", "on", "instances", "of", "Step", "rather", "than", "only", "on", "the", "class"], "add_tokens": "stairs_info \"\\n== Running #{step_title}\" stairs_info \"== Completed #{step_title}\\n\" attr_writer :step_title , :step_description class_attribute :step_title , :step_description self . step_title = title self . step_description = description end def step_title @step_title || self . class . step_title end def step_description @step_description || self . class . step_description # Set or update env var # in Stairs::Steps or a block is provided to be executed in an instance # of Step def setup ( step_name , & block ) if block_given? Step . new . tap do | step | step . define_singleton_method :run , & block step . step_title = step_name . to_s . titleize end . run! else klass = \"Stairs::Steps::#{step_name.to_s.camelize}\" . constantize klass . new . run! end", "del_tokens": "stairs_info \"\\n== Running #{self.class.title}\" stairs_info \"== Completed #{self.class.title}\\n\" class_attribute :title , :description self . title = title self . description = description # Set or update env var in .rbenv-vars # in Stairs::Steps def setup ( step_name ) klass = \"Stairs::Steps::#{step_name.to_s.camelize}\" . constantize klass . new . run!", "commit_type": "allow"}
{"commit_tokens": ["Used", "&&", "instead", "of", "and", "where", "it", "was", "not", "needed"], "add_tokens": "current_date . diff_in_months ( date ) < - 4 && date = date . add_years ( 1 ) current_date . day > date . day && date = date . add_months ( 1 )", "del_tokens": "current_date . diff_in_months ( date ) < - 4 and date = date . add_years ( 1 ) current_date . day > date . day and date = date . add_months ( 1 )", "commit_type": "use"}
{"commit_tokens": ["Add", "elapsed", "time", "to", "execution", "result"], "add_tokens": "elapsed_time_s = measurements . reduce ( :+ ) [ Stats . average ( measurements ) , Stats . std_dev ( measurements ) , elapsed_time_s ]", "del_tokens": "[ Stats . average ( measurements ) , Stats . std_dev ( measurements ) ]", "commit_type": "add"}
{"commit_tokens": ["making", "fm", "boot_spec", "actually", "test", "that", "exceptions", "get", "bubbled", "up", "to", "log"], "add_tokens": "error : e . inspect , at_rescue . call ( rescued_e . to_s ) error : e . inspect , at_rescue . call ( rescued_e . to_s )", "del_tokens": "error : e . to_s , at_rescue . call ( rescued_e ) error : e . to_s , at_rescue . call ( rescued_e ) # at_exit.call(child_pids) if at_exit", "commit_type": "make"}
{"commit_tokens": ["Updated", "version", "and", "gem", "dependencies"], "add_tokens": "gem lib , '>=0.9.7'", "del_tokens": "gem lib , '>=0.9.5'", "commit_type": "update"}
{"commit_tokens": ["Added", "accessor", "to", "help", "debug", "local", "issue", "in", "another", "gem"], "add_tokens": "attr_reader :resolved_dependencies", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["made", "Finder", ".", "create_conditions_for_columns", "take", "a", "string", "as", "first", "argument"], "add_tokens": "expected_conditions = [ '(LOWER(model_stubs.a) LIKE ? OR LOWER(model_stubs.b) LIKE ?) AND (LOWER(model_stubs.a) LIKE ? OR LOWER(model_stubs.b) LIKE ?)' , 'foo%' , ' foo %', ' bar %', ' bar %' ] expected_conditions = [ '(LOWER(model_stubs.a) LIKE ? OR LOWER(model_stubs.b) LIKE ?)' , 'foo%' , 'foo%' ] assert_equal expected_conditions , ActiveScaffold :: Finder . create_conditions_for_columns ( 'foo' , columns )", "del_tokens": "expected_conditions = [ '(LOWER(model_stubs.a) LIKE ? OR LOWER(model_stubs.b) LIKE ?) AND (LOWER(model_stubs.a) LIKE ? OR LOWER(model_stubs.b) LIKE ?)' , 'foo%' , 'foo%' , 'bar%' , 'bar%' ]", "commit_type": "make"}
{"commit_tokens": ["added", "real", "tests", "for", "client", "invoice", "product", "credit_note", ".", "Note", "that", "test", "might", "fail", "until", "sk", "-", "live", "server", "has", "been", "updated", "because", "we", "fixed", "a", "bug", "in", "adding", "editing", "addresses", "+", "line_items"], "add_tokens": "require 'spec/resources_spec_helper'", "del_tokens": "before :all do SK :: SDK :: ArCli . make ( :client ) Client . set_connection ( CONNECTION ) end", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "allow", "additional", "statuses", "such", "as", "404"], "add_tokens": "File . delete output if File . exist? output assert File . exist? output File . delete output if File . exist? output assert File . exist? output File . delete output if File . exist? output assert File . exist? output def test_allowed_404_status %w( en.wikipedia.org/wiki/THIS_PAGE_DOES_NOT_EXIST ) . each do | name | output = thumb ( '404_example' ) File . delete output if File . exist? output @webshot . capture \"https://#{name}/\" , output , allowed_status_codes : [ 404 ] assert File . exist? output end end", "del_tokens": "File . delete output if File . exists? output assert File . exists? output File . delete output if File . exists? output assert File . exists? output File . delete output if File . exists? output assert File . exists? output", "commit_type": "add"}
{"commit_tokens": ["removing", "access_token", "from", "customer", "create"], "add_tokens": "email : backer . payer_email ,", "del_tokens": "{ email : backer . payer_email , } , access_token", "commit_type": "remove"}
{"commit_tokens": ["Added", "basic", "tests", "and", "updated", "readme"], "add_tokens": "AUDIO = \"100\" VIDEO = \"200\" APPLICATIONS = \"300\" GAMES = \"400\" PORN = \"500\" OTHER = \"600\"", "del_tokens": "Audio = \"100\" Video = \"200\" Applications = \"300\" Games = \"400\" Porn = \"500\" Other = \"600\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "dumping", "seccomp", "filters", "of", "existing", "processes"], "add_tokens": "require 'shellwords' option [ :pid ] = nil opt . on ( '-p' , '--pid PID' , 'Dump seccomp filters of the existing process.' , 'You must have CAP_SYS_ADMIN (e.g. be root) in order to use this option.' , Integer ) do | p | option [ :pid ] = p end block = lambda do | bpf , arch | if option [ :pid ] . nil? option [ :command ] = argv . shift unless argv . empty? SeccompTools :: Dumper . dump ( '/bin/sh' , '-c' , option [ :command ] , limit : option [ :limit ] , & block ) else begin SeccompTools :: Dumper . dump_by_pid ( option [ :pid ] , option [ :limit ] , & block ) rescue Errno :: EPERM , Errno :: EACCES => e warn ( e ) warn ( 'PTRACE_SECCOMP_GET_FILTER requires CAP_SYS_ADMIN' ) warn ( \"Try this: sudo #{([$PROGRAM_NAME] + ARGV).shelljoin}\" ) exit ( 1 ) end end", "del_tokens": "option [ :command ] = argv . shift unless argv . empty? SeccompTools :: Dumper . dump ( '/bin/sh' , '-c' , option [ :command ] , limit : option [ :limit ] ) do | bpf , arch |", "commit_type": "allow"}
{"commit_tokens": ["fixing", "mechanism", "to", "get", "the", "queues", "and", "exchange", "names", "from", "the", "config"], "add_tokens": "def queue_name_for_message_name ( message_name ) ( ( m = @amqp_config [ \"messages\" ] [ message_name ] ) && m [ \"queue\" ] ) || message_name end def exchange_name_for_queue_name ( queue_name ) ( ( q = @amqp_config [ \"queues\" ] [ queue_name ] ) && q [ \"exchange\" ] ) || queue_name end def exchange_name_for_message_name ( message_name ) exchange_name_for_queue_name ( queue_name_for_message_name ( message_name ) ) end messages . each do | message | create_exchange ( exchange_name_for_message_name ( message ) )", "del_tokens": "messages . each do | name | create_exchange ( name )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "new", "and", "delete", "page", "buttons"], "add_tokens": "@parent_id = params [ :parent_id ] ? params [ :parent_id ] : 1 resp . redirect = \"/admin/pages/#{page.id}/edit\" # GET /admin/pages/1/delete def admin_delete_form return unless user_is_allowed ( 'pages' , 'delete' ) @page = Page . find ( params [ :id ] ) render :layout => 'caboose/admin' end def admin_delete p = Page . find ( params [ :id ] ) p . destroy 'redirect' => '/admin/pages'", "del_tokens": "@parent_id = params [ :parent_id ] . nil? ? params [ :parent_id ] : 1 resp . redirect = \"/pages/#{page.id}/edit\" def admin_destroy user = Page . find ( params [ :id ] ) user . destroy 'redirect' => '/pages'", "commit_type": "fix"}
{"commit_tokens": ["added", "silly", "test", "for", "xml", "writing"], "add_tokens": "elsif file . respond_to? ( 'write' )", "del_tokens": "elsif file . respond_to? ( file )", "commit_type": "add"}
{"commit_tokens": ["Adding", "state", "as", "option", "for", "Oauth2", "Client", "as", "they", "are", "used", "to", "identify", "user", "details", "on", "callback"], "add_tokens": ":redirect_url => params [ :redirect_url ] , :state => params [ :state ]", "del_tokens": ":redirect_url => params [ :redirect_url ]", "commit_type": "add"}
{"commit_tokens": ["Updated", "example", "/", "tutorial", "script", "(", "and", "documentation", ")"], "add_tokens": "# So, let's make our search a bit more complex. Let's search for articles whose titles begin # such as published date or product price? We can do that. # We search for articles tagged “ruby”. query { all } # Often, you want to highlight the snippets matching your query in the # displayed results. # _ElasticSearch_ provides rich # [highlighting](http://www.elasticsearch.org/guide/reference/api/search/highlighting.html) # features, and Slingshot makes them trivial to use. # # Let's suppose that we want to highlight terms of our query. # # Let's search for documents containing word “Two” in their titles, # and instruct _ElasticSearch_ to highlight relevant snippets. # We can configure many options for highlighting, such as: # • or specifying global highlighting options, such as the wrapper tag", "del_tokens": "# So, let's make out search a bit complex. Let's search for articles whose titles begin # such as published date, price, etc? We can do that. # We search for articles tagged “ruby” query { string '*' } # Often, you want to highlight the matched snippets in your text. # _ElasticSearch_ provides many features for # [highlighting](http://www.elasticsearch.org/guide/reference/api/search/highlighting.html), # # Let's search for documents containing “Two” in their titles. # And use the `highlight` method. # Slingshot allows you to specify options for the highlighting, such as: # • or specifying highlighting options, such as the wrapper tag", "commit_type": "update"}
{"commit_tokens": ["Updated", "MD5", "hashes", "for", "latest", "Flash", "9", "Player", "Releases"], "add_tokens": "MINOR = 151", "del_tokens": "MINOR = 124", "commit_type": "update"}
{"commit_tokens": ["Added", "spec", "for", "tag!", "method"], "add_tokens": "it 'should allow names with spaces using tag!' do json . tag! ( \"foo foo\" ) do json . tag! ( \"bar bar\" ) do json . tag! ( 'buzz buzz' , 'goo goo' ) end end json . compile! . should == \"{\\\"foo foo\\\":{\\\"bar bar\\\":{\\\"buzz buzz\\\":\\\"goo goo\\\"}}}\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "field", "to", "/", "pact", "request", "body", "to", "specify", "the", "pact", "directory"], "add_tokens": "class ConsumerContractWriterError < StandardError ; end file_path consumer_name , provider_name , pact_dir def pact_dir unless consumer_contract_details [ :pact_dir ] raise ConsumerContractWriterError . new ( \"Please indicate the directory to write the pact to by specifying the pact_dir field\" ) end consumer_contract_details [ :pact_dir ] end", "del_tokens": "file_path consumer_name , provider_name , Pact . configuration . pact_dir", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "boxen", "gem", "s", "lib", "to", "Puppet", "s", "libdir"], "add_tokens": "flags << [ \"--libdir\" , \"#{config.repodir}/lib:#{root}/lib\" ]", "del_tokens": "flags << [ \"--libdir\" , \"#{config.repodir}/lib\" ]", "commit_type": "add"}
{"commit_tokens": ["allow", "baseless", "to", "return", "an", "image"], "add_tokens": "def image Monet :: Image . new @path end end", "del_tokens": "end", "commit_type": "allow"}
{"commit_tokens": ["Add", "defaults", "method", "for", "controller", "mounting"], "add_tokens": "# get '/', :index defaults", "del_tokens": "get '/' , :index", "commit_type": "add"}
{"commit_tokens": ["Allow", "attribute", "keys", "to", "be", "strings"], "add_tokens": "hash [ symbol ] or hash [ symbol . to_s ] or raise NoMethodError", "del_tokens": "hash [ symbol ] or raise NoMethodError", "commit_type": "allow"}
{"commit_tokens": ["Added", "support", "for", "explicit", "grid", "padding", "."], "add_tokens": "attr_accessor :columns , :color , :padded @padded = attribs . delete ( :padded )", "del_tokens": "attr_accessor :columns , :color", "commit_type": "add"}
{"commit_tokens": ["fixed", "tests", "for", "date", "type", "validator"], "add_tokens": "VERSION = '3.0'", "del_tokens": "VERSION = '2.1.6'", "commit_type": "fix"}
{"commit_tokens": ["Adding", "the", "method", "for", "an", "explicit", "file", "close"], "add_tokens": "close end ## # An explicit file close. def close @file . close!", "del_tokens": "@file . close true", "commit_type": "add"}
{"commit_tokens": ["Add", "generator", "for", "Rails", "3"], "add_tokens": "ActiveRecord :: Schema . define ( :version => 20101028213553 ) do", "del_tokens": "ActiveRecord :: Schema . define ( :version => 20101028205511 ) do", "commit_type": "add"}
{"commit_tokens": ["Fix", "room_name", "of", "invite", "message"], "add_tokens": "@element . elements [ \"//name/text()\" ] . to_s", "del_tokens": "@element [ \"name/text()\" ] . to_s", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "define", "which", "branch", "to", "reset", "-", "staging", "to", "instead", "of", "always", "using", "master"], "add_tokens": "def reset_branch ( branch , head_branch = 'master' ) run_cmd \"git checkout #{head_branch}\" run_cmd \"git checkout #{head_branch}\"", "del_tokens": "def reset_branch ( branch ) run_cmd \"git checkout master\" run_cmd \"git checkout master\"", "commit_type": "add"}
{"commit_tokens": ["made", "caesar", "cipher", "whitespace", "aware"], "add_tokens": "message . split ( \"\" ) . map do | part | part == \" \" ? part : CryptBuffer . new ( part ) . add ( real_shift , mod : 91 , offset : 65 ) . str end . join message . split ( \"\" ) . map do | part | # first reduce by 65 to map A to 0 ; then mod-sub with \"A\"(91)-65; and re-add the 65 to convert back to real ascii A value part == \" \" ? part : CryptBuffer ( part ) . sub ( 65 ) . mod_sub ( real_shift , mod : 91 - 65 ) . add ( 65 ) . str end . join", "del_tokens": "CryptBuffer . new ( message ) . add ( real_shift , mod : 91 , offset : 65 ) . str # first reduce by 65 to map A to 0 ; then mod-sub with \"A\"(91)-65; and re-add the 65 to convert back to real ascii A value result = CryptBuffer ( message ) . sub ( 65 ) . mod_sub ( real_shift , mod : 91 - 65 ) . add ( 65 ) result . str", "commit_type": "make"}
{"commit_tokens": ["Added", "specification", "for", "which", "warnings", "to", "use"], "add_tokens": "class Settings < Struct . new ( :libs , :extras , :options , :using ) self . using ||= [ ] @settings . using = [ :all ] if @settings . using . empty? runner = Wool :: Runner . new ( self . settings . options . split ( / \\n / ) + files ) runner . using = self . settings . using runner . run", "del_tokens": "class Settings < Struct . new ( :libs , :extras , :options ) Wool :: Runner . new ( self . settings . options . split ( / \\n / ) + files ) . run", "commit_type": "add"}
{"commit_tokens": ["Add", "speed", "warning", "to", "probabilities", "documentation"], "add_tokens": "# returns a hash of value (Integer) => probability (Float) pairs. Warning: Some dice schemes # cause this method to take a long time, and use a lot of memory. The worst-case offenders are # dice schemes with a #keep_mode of :keep_best or :keep_worst.", "del_tokens": "# returns a hash of value (Integer) => probability (Float) pairs. For efficiency with re-rolls, the calculation may cut # short based on depth of recursion or closeness to total 1.0 probability. Therefore low probabilities # (less than one in a billion) in open-ended re-rolls are not always represented in the hash.", "commit_type": "add"}
{"commit_tokens": ["make", "browser", "window", "start", "maximized", "bump", "gemspec"], "add_tokens": "module Pyrite def browser #:nodoc: browser . get_eval \"window.moveTo(1,0)\" browser . window_maximize", "del_tokens": "module Pyrite def browser #:nodoc:", "commit_type": "make"}
{"commit_tokens": ["Fix", "broken", "parts", "of", "get_timezone"], "add_tokens": "@timezone = get_timezone def get_timezone if feed . present? && feed . first . x_properties [ \"X-WR-TIMEZONE\" ] . present? feed . first . x_properties [ \"X-WR-TIMEZONE\" ] . first . value", "del_tokens": "@timezone = get_timzone def get_timzone if @feed . present? && @feed . first . x_properties [ \"X-WR-TIMEZONE\" ] . first @feed . first . x_properties [ \"X-WR-TIMEZONE\" ] . first . value", "commit_type": "fix"}
{"commit_tokens": ["Use", "emit_defaults", ":", "true", "by", "deafult", "with", "JSON", "encoding", "to", "be", "in", "sync", "with", "the", "Go", "implementation"], "add_tokens": "when JSON , JSON_STRICT then msg_class . encode_json ( msg_obj , emit_defaults : true )", "del_tokens": "when JSON then msg_class . encode_json ( msg_obj , emit_defaults : false ) when JSON_STRICT then msg_class . encode_json ( msg_obj , emit_defaults : true )", "commit_type": "use"}
{"commit_tokens": ["Make", "the", "custom", "message", "and", "username", "an", "optional"], "add_tokens": "description : \"The username which is used to publish to slack\" , optional : true description : \"The message which is published together with a successful report\" , optional : true", "del_tokens": "description : \"The username which is used to publish to slack\" description : \"The message which is published together with a successful report\"", "commit_type": "make"}
{"commit_tokens": ["Fix", "the", "fucking", "bug", "(", "inverted", "invert", ")"], "add_tokens": "@channel . invert = invert ? 1 : 0", "del_tokens": "( 0 .. 1 ) . each do | channum | chan = ws2811_channel_get ( @leds , channum ) chan . count = 0 chan . gpionum = 0 chan . invert = 0 chan . brightness = 0 end @channel . invert = invert ? 0 : 1", "commit_type": "fix"}
{"commit_tokens": ["use", "a", "more", "memorable", "base", "URI"], "add_tokens": "base_uri 'http://statsapi.mlb.com'", "del_tokens": "base_uri 'http://statsapi-default-elb-prod-876255662.us-east-1.elb.amazonaws.com'", "commit_type": "use"}
{"commit_tokens": ["make", "home", "actually", "contain", "something"], "add_tokens": "home = \"/home/#{name}\"", "del_tokens": "home = \"#{home}\"", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "prince_options", "[", "debug", "]", "."], "add_tokens": "# Enable Prince debug mode. attr_accessor :debug :' debug ' => :' debug ' , :' debug ' => :' BOOLEAN ' , if attributes [ :' debug ' ] self . debug = attributes [ :' debug ' ] end debug == o . debug && [ baseurl , no_xinclude , no_network , http_user , http_password , http_proxy , http_timeout , insecure , media , no_author_style , no_default_style , no_embed_fonts , no_subset_fonts , no_compress , encrypt , key_bits , user_password , owner_password , disallow_print , disallow_copy , disallow_annotate , disallow_modify , debug , input , version , javascript , css_dpi , profile ] . hash", "del_tokens": "[ baseurl , no_xinclude , no_network , http_user , http_password , http_proxy , http_timeout , insecure , media , no_author_style , no_default_style , no_embed_fonts , no_subset_fonts , no_compress , encrypt , key_bits , user_password , owner_password , disallow_print , disallow_copy , disallow_annotate , disallow_modify , input , version , javascript , css_dpi , profile ] . hash", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "right", "websocket", "class", "."], "add_tokens": "@connection = PusherWebSocket . new ( url , options )", "del_tokens": "@connection = WebSocket . new ( url , options )", "commit_type": "use"}
{"commit_tokens": ["Remove", "test", "-", "unit", "and", "simplify", "library", "loading"], "add_tokens": "require 'test_helper'", "del_tokens": "require File . expand_path ( File . dirname ( __FILE__ ) + '/test_helper' )", "commit_type": "remove"}
{"commit_tokens": ["added", "error", "checking", "for", "really", "long", "omission", "text"], "add_tokens": "no_html_end_string = strip_tags ( end_string ) stop_index = text . rindex ( ' ' , length - no_html_end_string . length ) raise \"End string (omission text) was longer than the allowed length for the entire string. Please use a shorter omission string - ie '...'\" if stop_index . blank?", "del_tokens": "stop_index = text . rindex ( ' ' , length - end_string . length )", "commit_type": "add"}
{"commit_tokens": ["create", "requisite", "output", "directories", "for", "build", "targets", ";", "refactor", "common", "buile", "functionality", "into", "Builder#standard_build", "()"], "add_tokens": "standard_build ( \"AR #{target}\" , target , command , objects , env , cache )", "del_tokens": "unless cache . up_to_date? ( target , command , objects ) FileUtils . rm_f ( target ) return false unless env . execute ( \"AR #{target}\" , command ) cache . register_build ( target , command , objects ) end target", "commit_type": "create"}
{"commit_tokens": ["make", "socket", "read", "timeout", "raise", "a", "BERTRPC", "::", "ReadTimeoutError", "and", "enhance", "readme"], "add_tokens": "rescue Errno :: ECONNREFUSED rescue Timeout :: Error raise ReadTimeoutError . new ( \"No response from #{@svc.host}:#{@svc.port} in #{@svc.timeout}s\" )", "del_tokens": "rescue Errno :: ECONNREFUSED , Timeout :: Error", "commit_type": "make"}
{"commit_tokens": ["making", "re", "-", "raise", "only", "happen", "in", "test"], "add_tokens": "raise e if Moona . env == \"test\"", "del_tokens": "raise e", "commit_type": "make"}
{"commit_tokens": ["Allow", "clear", "to", "directly", "run", "show", ";", "add", "WS2812", "alias"], "add_tokens": "# Clears all pixels (sets them to black) and calls +show+ if +do_show+ def clear ( do_show = true ) show if do_show", "del_tokens": "# Clears all pixels (sets them to black) # # You still have to call +show+ to make the changes visible. def clear", "commit_type": "allow"}
{"commit_tokens": ["Change", "conditional", "request", "semantic", "so", "that", "nil", "is", "returned", "when", "a", "304"], "add_tokens": "return nil , result . headers", "del_tokens": "return true , result . headers", "commit_type": "change"}
{"commit_tokens": ["Added", "rename", "method", "to", "hash", "for", "simple", "hash", "key", "renaming"], "add_tokens": "def rename ( candidates ) candidates . each do | old_key , new_key | self [ new_key ] = self . delete ( old_key ) if self . has_key? ( old_key ) return self", "del_tokens": "class Transform # :nodoc: def initialize ( hash , key ) @hash = hash @key = key def to ( new_name ) @hash [ new_name ] = @hash . delete ( @key ) return @hash end end def rename ( key ) Transform . new ( self , key )", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "gemfile", "to", "use", "the", "newest", "versions", "of", "micro_mock", "&", "micro_test", "."], "add_tokens": "VERSION = \"0.1.7\"", "del_tokens": "VERSION = \"0.1.6\"", "commit_type": "update"}
{"commit_tokens": ["fix", "tests", "after", "target", "update"], "add_tokens": "assert ! @target . check_constructor ( 'target_test' ) , \"missing constructor is invalid\" assert ! @target . check_constructor ( 'target_test' ) , \"invalid ruby is invalid\"", "del_tokens": "assert ! @target . check_constructor , \"missing constructor is invalid\" assert ! @target . check_constructor , \"invalid ruby is invalid\"", "commit_type": "fix"}
{"commit_tokens": ["Change", "BAD", "to", "BHD", "in", "NBE", "results"], "add_tokens": "currency = row [ 2 ] . strip . to_sym # Bahraini Dinar is BHD not BAD # Also Qatar Rial is QAR not QTR # Changing them for consistency if currency == :BAD currency = :BHD elsif currency == :QTR currency = :QAR end", "del_tokens": "currency = row [ 2 ] . strip . to_sym", "commit_type": "change"}
{"commit_tokens": ["Use", "a", "uniform", "API", "that", "matches", "the", "one", "in", "Bychar"], "add_tokens": "VERSION = '2.1.6'", "del_tokens": "VERSION = '2.1.5'", "commit_type": "use"}
{"commit_tokens": ["Allow", "nil", "assignments", "for", "quantity", ".", "value", "=", "and", "quantity", ".", "unit", "="], "add_tokens": "if value . nil? @value = nil else @value = Float ( value ) end if unit . nil? @unit = Unit . for ( :unity ) else @unit = Unit . for ( unit ) end", "del_tokens": "@value = Float ( value ) @unit = Unit . for ( unit )", "commit_type": "allow"}
{"commit_tokens": ["Use", "Array", ".", "wrap", "instead", "of", "use", "alternative", "variables"], "add_tokens": "Array . wrap ( response ) . map do | hash | new ( {", "del_tokens": "response , result = [ ] , [ ] # We want an array to loop response = [ response ] if response . is_a? Hash response . map do | hash | result << new ( { result", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "multi", "-", "row", "headings"], "add_tokens": "def headings = arrays arrays = [ arrays ] unless arrays . first . is_a? ( Array ) @headings = arrays . map do | array | row = Row . new ( self , array ) recalc_column_widths row row end @headings . each do | row | unless row . cells . empty? buffer << row buffer << separator end @headings + rows", "del_tokens": "def headings = array @headings = Row . new ( self , array ) recalc_column_widths @headings unless @headings . cells . empty? buffer << @headings buffer << separator [ @headings ] + rows", "commit_type": "add"}
{"commit_tokens": ["Adds", "an", "example", "for", "the", "--", "headers", "option"], "add_tokens": "its ( :help_messages ) do should eql [ \"Separator to use between the headers: '; '\" , \"Examples: 'X-Forwarded-For: 127.0.0.1', 'X-Forwarded-For: 127.0.0.1; Another: aaa'\" ] end", "del_tokens": "its ( :help_messages ) { should eql [ \"Separator to use between the headers: '; '\" ] }", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "use", "relationships", "with", "names", "that", "don", "t", "match", "the", "class", "name"], "add_tokens": "filename = File . join ( NSBundle . mainBundle . resourcePath , \"fixtures\" , \"#{type.to_s.underscore.gsub('nskvo_notifying_', '').pluralize}.json\" ) file = File . read ( filename )", "del_tokens": "file = File . read ( File . join ( NSBundle . mainBundle . resourcePath , \"fixtures\" , \"#{type.to_s.underscore.pluralize}.json\" ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "backwards", "compatibility", "for", "Sidekiq", "2", ".", "x", ".", "x", "."], "add_tokens": "i = :: Sidekiq :: VERSION >= \"3.0.0\" ? 2 : 1 memo += 1 if queues . include? ( job [ i ] [ \"queue\" ] ) && job [ i ] [ \"run_at\" ] <= Time . now . to_i", "del_tokens": "memo += 1 if queues . include? ( job [ 2 ] [ \"queue\" ] ) && job [ 2 ] [ \"run_at\" ] <= Time . now . to_i", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "prioritise", "env", "editors", "and", "include", "windows", "notepad", "."], "add_tokens": "# Check editor from environment variables # # @return [Array[String]] # # @api public def self . from_env [ ENV [ 'VISUAL' ] , ENV [ 'EDITOR' ] ] . compact end # @api public [ 'vim' , 'vi' , 'emacs' , 'nano' , 'nano-tiny' , 'pico' , 'mate -w' ] return commands unless commands . empty? if ! from_env . all? ( & :empty? ) [ from_env . find { | e | ! e . empty? } ] elsif windows? [ 'notepad' ] else executables . uniq . select ( & method ( :exist? ) ) end", "del_tokens": "# @api private [ ENV [ 'VISUAL' ] , ENV [ 'EDITOR' ] , 'vim' , ' vi ', ' emacs ', ' nano ', ' nano - tiny ' , 'pico' , 'mate -w' ] . compact commands = commands . empty? ? executables : commands commands . uniq . select ( & method ( :exist? ) )", "commit_type": "change"}
{"commit_tokens": ["Change", "multiple", "selections", "to", "create", "a", "has_many", "relationship"], "add_tokens": "if multiple has_many target , options . reject { | k , v | [ :system_code , :multiple , :scopes , :predicates ] . include? ( k ) } . merge ( class_name : \"Selection\" , primary_key : \"#{target}_ids\" , foreign_key : :id ) else belongs_to target , options . reject { | k , v | [ :system_code , :multiple , :scopes , :predicates ] . include? ( k ) } . merge ( class_name : \"Selection\" ) end target_id = multiple ? \"#{target}_ids\" . to_sym : \"#{target}_id\" . to_sym method [ - 1 ] == '?' && self . class . reflect_on_all_associations . any? do | relationship | self . reflect_on_all_associations . any? do | relationship |", "del_tokens": "belongs_to target , options . reject { | k , v | [ :system_code , :multiple , :scopes , :predicates ] . include? ( k ) } . merge ( :class_name => \"Selection\" ) target_id = multiple ? target . to_sym : \"#{target}_id\" . to_sym method [ - 1 ] == '?' && self . class . reflect_on_all_associations ( :belongs_to ) . any? do | relationship | self . reflect_on_all_associations ( :belongs_to ) . any? do | relationship |", "commit_type": "change"}
{"commit_tokens": ["Add", "more", "acceptable", "cases", "to", "AcceptanceValidator"], "add_tokens": "@options [ :accept ] ||= [ \"1\" , 1 , \"true\" , true , \"t\" ]", "del_tokens": "@options [ :accept ] ||= \"1\"", "commit_type": "add"}
{"commit_tokens": ["Making", "patient", "indicator", "a", "boolean", "adding", "checkbox"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20141023123657 ) do t . boolean \"paediatric_patient_indicator\"", "del_tokens": "ActiveRecord :: Schema . define ( version : 20141023111249 ) do t . string \"paediatric_patient_indicator\"", "commit_type": "make"}
{"commit_tokens": ["Make", "generation", "of", "map", "file", "and", "creation", "of", "app", "2", "seperate", "steps", "."], "add_tokens": "sh \"#{@settings['CXX']} #{incs} #{objs} #{ldflags} #{libs} -o #{params[:app]}\" sh \"#{@settings['CXX']} #{incs} #{objs} #{ldflags} #{libs} -Wl,-Map,#{params[:app]}.map\" if @config . generate_map", "del_tokens": "sh \"#{@settings['CXX']} #{incs} #{objs} #{ldflags} #{libs} -o #{params[:app]} -Wl,-Map,#{params[:app]}.map\" if @config . generate_map", "commit_type": "make"}
{"commit_tokens": ["Remove", ".", "gem", "from", "the", "caching", "folder"], "add_tokens": "@folder = folder . join ( File . basename ( name , \".gem\" ) )", "del_tokens": "@folder = folder . join ( File . basename ( name ) )", "commit_type": "remove"}
{"commit_tokens": ["use", "explicit", "inherit_from", "definition", "then", "implicit", "inherit", "from", "common"], "add_tokens": "inherit_format = format_config [ :inherit_from ] if inherit_format inherit_config = all_configs [ inherit_format . to_sym ] inheirt_fields = inherit_config ? inherit_config [ :fields ] : [ ] inheirt_fields . each do | field | format_fields << field if format_fields . select { | f | f [ :name ] == field [ :name ] } . empty? end puts 'scanning for unique values' puts 'scan done' puts 'done' puts \"#{Time.now} - #{@current_row}\" if @current_row % 1000 == 0", "del_tokens": "puts '...parse rules ...' common_config = all_configs [ :common ] common_fields = common_config ? common_config [ :fields ] : [ ] common_fields . each do | field | format_fields << field if format_fields . select { | f | f [ :name ] == field [ :name ] } . empty?", "commit_type": "use"}
{"commit_tokens": ["add", "additional", "deprecated", "params", "and", "lti1", "xml", "config", "builder"], "add_tokens": ":tool_consumer_instance_contact_email , :tool_consumer_info_version", "del_tokens": ":tool_consumer_instance_contact_email", "commit_type": "add"}
{"commit_tokens": ["fix", "var", "names", ".", "add", "initial", "support", "for", "using", "priority", "queue"], "add_tokens": "# :pqueue:: use a priority queue (defaults to false) if ( args [ :pqueue ] ) ActionPool . enable_priority_q @queue = ActionPool :: PQueue . new else @queue = ActionPool :: Queue . new end @threads . each { | x | x . join } t = @threads . find { | x | x . waiting? }", "del_tokens": "# Raised when pool is closed @queue = ActionPool :: Queue . new @threads . each { | t | t . join } t = @threads . find { | t | t . waiting? }", "commit_type": "fix"}
{"commit_tokens": ["Added", "filters", "to", "the", "2", "presenters"], "add_tokens": "#{table_filters} def table_filters <<-HTML if table_builder . filters < div class = 'table-filters' > < h3 > Filters < / h3 > #{table_builder.filters.map do |filter| filter . display end . join ( \"\\n\" ) } < / div > HTML end # it would ne nicer to encapsulate this into the column class, but then we have # to set it up like a view so capture works. For now, I'll leave this here, I'm not # sure if the encapsulation is worth the overhead @builder ||= TableMe :: Builder . new ( options )", "del_tokens": "@builder ||= TableMe :: Builder . new", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "EM", "::", "SystemCommand", "::", "Builder#to_s"], "add_tokens": "param , value = arg . first . to_s , arg . last", "del_tokens": "param = arg . shift param = param . to_s if param . is_a? ( Symbol ) value = arg . shift", "commit_type": "fix"}
{"commit_tokens": ["Create", "a", "solr", "variable", "pointing", "to", "the", "solr", "client"], "add_tokens": "# Time of last modification # Total documents alias_method :numDocs , :number_of_documents alias_method :num_docs , :number_of_documents # The (local to the server) data directory # Get the index size in megabytes str = index [ 'size' ]", "del_tokens": "def default? core_data_hash [ 'isDefaultCore' ] end str = core_data_hash [ 'index' ] [ 'size' ]", "commit_type": "create"}
{"commit_tokens": ["Fixed", "out", "of", "date", "failing", "specs"], "add_tokens": "@n . occurrences . first . start_date . should == Date . new ( 2009 , 10 , 15 ) @occurs . start_time . to_s . should == \"11:00:00\" @occurs . start_time . to_s . should == \"17:00:00\" @n . occurrences [ 0 ] . start_time . to_s . should == \"14:00:00\" @n . occurrences [ 1 ] . start_time . to_s . should == \"14:00:00\" n . occurrences . first . start_date . should == Date . new ( 2009 , 5 , 31 )", "del_tokens": "@n . occurrences . first . start_date . date . should == \"20091015\" @occurs . start_time . time . should == \"110000\" @occurs . start_time . time . should == \"170000\" @n . occurrences [ 0 ] . start_time . time . should == \"140000\" @n . occurrences [ 1 ] . start_time . time . should == \"140000\" n . occurrences . first . start_date . date . should == \"20090531\"", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "#rmq", "problem", "in", "Stylesheets"], "add_tokens": "if @controller . nil? RMQ . new @controller . rmq", "del_tokens": "if @controller @controller . rmq RMQ", "commit_type": "fix"}
{"commit_tokens": ["Allow", "numeric", "string", "for", "retry", "settings", "."], "add_tokens": "max_tries : '60' , base_sleep_seconds : '2' , max_sleep_seconds : '2'", "del_tokens": "max_tries : 60 , base_sleep_seconds : 2 , max_sleep_seconds : 2", "commit_type": "allow"}
{"commit_tokens": ["added", "additional", "specifications", "in", "the", "gemspec", "and", "made", "sure", "it", "installed", "properly"], "add_tokens": "tiny = 1", "del_tokens": "tiny = 0", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "accept", "attributes", "."], "add_tokens": "attr_threadsafe :attrs # Initialize a generic DSL # # @api public def initialize ( machine , attrs = { } ) self . attrs = attrs # A class responsible for adding state machine specific dsl def initialize ( machine , attrs = { } ) super ( machine , attrs ) self . defer = true initialize_attrs # Attach state machine to an object # # This allows state machine to initiate events in the context # of a particular object # # @example # FiniteMachine.define do # target :red # end # @return [FiniteMachine::StateMachine] # # @return [FiniteMachine::StateMachine] # @return [FiniteMachine::StateMachine] # # Initialize state machine properties based off attributes # # @api private def initialize_attrs attrs [ :initial ] and initial ( attrs [ :initial ] ) attrs [ :target ] and target ( attrs [ :target ] ) attrs [ :terminal ] and terminal ( attrs [ :terminal ] ) end", "del_tokens": "def initialize ( machine ) def initialize ( machine ) super ( machine ) self . defer = true # Attach state machine to an object. This allows state machine # to initiate events in the context of a particular object. # @return [StateMachine]", "commit_type": "change"}
{"commit_tokens": ["Made", "Point#inspect", "work", "for", "infinity", "."], "add_tokens": "# leave @x and @y nil @y = y end return self if point . infinity? if infinity? '#<%s: %s, infinity>' % [ self . class , group . name ] else '#<%s: %s, 0x%x, 0x%x>' % [ self . class , group . name , x , y ] end", "del_tokens": "# leave @x and @y nil @y = y end return self if point . infinity? \"<%s: %s, 0x%x, 0x%x>\" % [ self . class , group . name , x , y ]", "commit_type": "make"}
{"commit_tokens": ["Fixed", "failing", "DataMapper", "::", "Scope", "specs"], "add_tokens": "DataMapper :: Query . should_receive ( :new ) . with ( Article , :blog_id => 1 ) . once . and_return ( @dm_query ) DataMapper :: Query . should_receive ( :new ) . with ( Article , :blog_id => 1 ) . once . ordered . and_return ( @dm_query ) DataMapper :: Query . should_receive ( :new ) . with ( Article , :blog_id => 1 ) . once . ordered . and_return ( @dm_query ) DataMapper :: Query . should_receive ( :new ) . with ( Article , :author => 'dkubb' ) . once . ordered . and_return ( exclusive_query )", "del_tokens": "DataMapper :: Query . should_receive ( :new ) . with ( :blog_id => 1 ) . once . and_return ( @dm_query ) DataMapper :: Query . should_receive ( :new ) . with ( :blog_id => 1 ) . once . ordered . and_return ( @dm_query ) DataMapper :: Query . should_receive ( :new ) . with ( :blog_id => 1 ) . once . ordered . and_return ( @dm_query ) DataMapper :: Query . should_receive ( :new ) . with ( :author => 'dkubb' ) . once . ordered . and_return ( exclusive_query )", "commit_type": "fix"}
{"commit_tokens": ["added", "ability", "to", "provide", "expected", "headers", "and", "body", "for", "requests"], "add_tokens": "get_mock_and_run_handlers ( method , @remote_mocks [ method ] [ url ] , options ) get_mock_and_run_handlers ( method , @remote_mocks [ method ] [ :catch_all ] , options ) def get_mock_and_run_handlers ( method , response_args , options ) if response_args . has_key? :expected_body raise \"#{method} expected body of \\\"#{response_args[:expected_body]}\\\" but received #{options[:body]}\" if response_args [ :expected_body ] != options [ :body ] end if response_args . has_key? :expected_headers raise \"#{method} expected body of \\\"#{response_args[:expected_headers].inspect}\\\" but received #{options[:headers].inspect}\" if response_args [ :expected_headers ] != options [ :headers ] end easy . headers = options [ :headers ] if options . has_key? :headers", "del_tokens": "get_mock_and_run_handlers ( @remote_mocks [ method ] [ url ] , options ) get_mock_and_run_handlers ( @remote_mocks [ method ] [ :catch_all ] , options ) def get_mock_and_run_handlers ( response_args , options )", "commit_type": "add"}
{"commit_tokens": ["add", "error", "with", "argument", "line"], "add_tokens": "def add_error ( error , line = nil ) line = @node . line if line . nil? @errors << RailsBestPractices :: Core :: Error . new ( \"#{@node.file}\" , \"#{line}\" , error )", "del_tokens": "def add_error ( error ) @errors << RailsBestPractices :: Core :: Error . new ( \"#{@node.file}\" , \"#{@node.line}\" , error )", "commit_type": "add"}
{"commit_tokens": ["Use", "fork", "to", "start", "integration", "server"], "add_tokens": "puts \"== Starting #{@app.inspect}\" @pid_server = fork do self end def shutdown puts \"== Stopping #{@app.inspect}\\n\\n\" Process . kill ( :INT , @pid_server ) # send ctrl+c to webrick Process . waitpid ( @pid_server ) # waiting his life go to void ...", "del_tokens": "Thread . new do true", "commit_type": "use"}
{"commit_tokens": ["Adding", "git", "commit", "hook", "."], "add_tokens": "VERSION = \"0.9.3-hotfix-0.9.4-c1cf37e++\"", "del_tokens": "VERSION = \"0.9.3-hotfix-0.9.4-961d4ee++\"", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "and", "bump", "version"], "add_tokens": "VERSION = \"0.6.0\"", "del_tokens": "VERSION = \"0.5.0\"", "commit_type": "update"}
{"commit_tokens": ["moved", "uniq", "from", "end", "too", "beginning", "to", "encur", "DISTINCT"], "add_tokens": "uniq . pluck ( pbt_type_sym )", "del_tokens": "pluck ( pbt_type_sym ) . uniq", "commit_type": "move"}
{"commit_tokens": ["Use", "the", "preferred", "configuration", "method", "in", "CommandRouter", "specs", "."], "add_tokens": "let ( :router ) { described_class . new ( routes ) } let ( :routes ) { { } } let ( :routes ) do { change_item_name : Item } context 'with valid custom handler' do let ( :routes ) do { change_item_name : handler } end let ( :handler ) do lambda do | _command , aggregate_id , _options , ** data |", "del_tokens": "let ( :router ) { described_class . new } before do router . register_default_route ( :change_item_name , Item ) context 'with valid custom target' do before do router . register_route ( :change_item_name ) do | _command , aggregate_id , _options , ** data |", "commit_type": "use"}
{"commit_tokens": ["Add", "some", "docs", "for", "payment", "and", "change_trust"], "add_tokens": "Operation class Operation # # Helper method to create a valid PaymentOp, wrapped # in the nexessary XDR structs to be included within a # transactions `operations` array. # # @see Stellar::Currency # # @param [Hash] attributes the attributes to create the operation with # @option attributes [Stellar::KeyPair] :destination the receiver of the payment # @option attributes [Array] :amount the amount to pay # @option attributes [Array<Stellar::Currency>] :path the payment path to use # # @return [Stellar::Operation] the built operation, containing a # Stellar::PaymentOp body # # Helper method to create a valid ChangeTrustOp, wrapped # in the nexessary XDR structs to be included within a # transactions `operations` array. # # @param [Hash] attributes the attributes to create the operation with # @option attributes [Stellar::Currrency] :line the currency to trust # @option attributes [Fixnum] :limit the maximum amount to trust # # @return [Stellar::Operation] the built operation, containing a # Stellar::ChangeTrustOp body", "del_tokens": "Operation . class_eval do", "commit_type": "add"}
{"commit_tokens": ["add", "Pa", ".", "shorten", "method"], "add_tokens": "# @param [String,Pa] path # @param [String,Pa] path # shorten a path, # convert /home/user/file to ~/file # # @param [String,Pa] path # @return [String] def shorten ( path ) ; get ( path ) . sub ( %r! ^ #{ Regexp . escape ( ENV [ \"HOME\" ] ) } ! , \"~\" ) end # @param [String,Pa] path # @param [String,Pa] path # @param [String,Pa] path # @param [String,Pa] name # @param [String,Pa] name # @param [String,Pa] path # @param [String,Pa] dest # @param [String,Pa] path", "del_tokens": "# @param [String] path # @param [String] path # @param [String] path # @param [String] path # @param [String] path # @param [String] name # @param [String] name # @param [String] path # @param [String] dest # @param [String] path", "commit_type": "add"}
{"commit_tokens": ["Fixed", "get", "with", "query", "string", "pagination", "should", "now", "work", "."], "add_tokens": "@request = Net :: HTTP :: Get . new ( uri . request_uri )", "del_tokens": "#uri = URI(instance_variable_get(\"@#{endpoint.to_s}\") + \"/#{id}\") @request = Net :: HTTP :: Get . new ( uri . path )", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "metaclass", "on", "a", "vanilla", "object", "rather", "than", "an", "anonymous", "class", "for", "Shame", ".", "define"], "add_tokens": "# create an anonymous context that pumps everything through to Sham, useful # for defining a bunch of shams at once returning Object . new do | definer | class << definer end . instance_eval ( & block )", "del_tokens": "# create an anonymous context that pumps everything through to Sham returning Class . new do | definer | definer . class_eval do end . new . instance_eval ( & block )", "commit_type": "use"}
{"commit_tokens": ["Add", "description", "and", "types", "to", "new", "cli", "options", "."], "add_tokens": "option :nodes , type : :array , desc : 'A comma separated list of node IDs to drain' option :number , type : :numeric , desc : 'The number of nodes to drain' option :continue , type : :boolean , default : true , desc : 'Whether to continue draining nodes once the first iteration of --number is complete' options [ :nodes ] . include? ( instance_id )", "del_tokens": "option :nodes option :number option :continue , type : :boolean , default : true options [ :nodes ] . split ( ',' ) . include? ( instance_id )", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "more", "tests", "fix", "some", "bugs"], "add_tokens": "attribute = Attribute . get ( name ) attribute ||= name . to_s =~ / \\A on_ / ? Attribute . nearest_rgb_on_color ( name ) : Attribute . nearest_rgb_color ( name ) attribute or raise ArgumentError , \"unknown attribute #{name.inspect}\"", "del_tokens": "attribute = Attribute . get ( name ) || Attribute . nearest_rgb ( name ) or raise ArgumentError , \"unknown attribute #{name.inspect}\"", "commit_type": "add"}
{"commit_tokens": ["Change", "404", "response", "status", "to", "be", "a", "failure", ".", "Handy", "for", "client", "code", "trying", "to", "identify", "inexisting", "items", "."], "add_tokens": "expect ( result . is_failure? ) . to be ( true )", "del_tokens": "expect ( result . is_success? ) . to be ( true ) expect ( result . is_success? ) . to be ( true )", "commit_type": "change"}
{"commit_tokens": ["Update", "example", "/", "example", ".", "rb"], "add_tokens": "config = TriglavClient :: Configuration . new do | config | api_client = TriglavClient :: ApiClient . new ( config ) auth_api = TriglavClient :: AuthApi . new ( api_client ) api_client . config . api_key [ 'Authorization' ] = access_token if e . code == 0 puts \"Could not connect\" else puts \"Exception when calling AuthApi->create_token: #{e}\" end resources_api = TriglavClient :: ResourcesApi . new ( api_client ) if e . code == 0 puts \"Could not connect\" else puts \"Exception when calling AuthApi->create_token: #{e}\" end", "del_tokens": "TriglavClient . configure do | config | auth_api = TriglavClient :: AuthApi . new resources_api = TriglavClient :: ResourcesApi . new # TriglavClient.configure do |config| # config.api_key['Authorization'] = access_token # end require 'pry' binding . pry puts \"Exception when calling AuthApi->create_token: #{e}\" puts \"Exception when calling AuthApi->create_token: #{e}\"", "commit_type": "update"}
{"commit_tokens": ["Add", "user", "-", "friendly", "handling", "of", "deprecated", "gem"], "add_tokens": "with_checks_and_rescues do with_checks_and_rescues do with_checks_and_rescues do def with_checks_and_rescues ( & block ) with_authorization ( & block ) rescue Gemfury :: InvalidGemVersion => e shell . say \"You have a deprecated Gemfury gem\" , :red if shell . yes? \"Would you like to update this gem now? [yN]\" exec ( \"gem update gemfury\" ) else shell . say %q(No problem. You can also run \"gem update gemfury\") end end", "del_tokens": "with_authorization do with_authorization do with_authorization do", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "endpoint", "method", "to", "Application", "."], "add_tokens": "# Returns a Hash with two keys @current_application = KynetxAmApi :: Application . new ( self , options [ :application_id ] ) @current_application ||= KynetxAmApi :: Application . new ( self , options [ :application_id ] ) end", "del_tokens": "# Returns a has with two keys # - :version => Version of application to obtain options [ :version ] ||= \"development\" @current_application = KynetxAmApi :: Application . new ( self , options [ :application_id ] , options [ :version ] ) @current_application ||= KynetxAmApi :: Application . new ( self , options [ :application_id ] , options [ :version ] ) end", "commit_type": "add"}
{"commit_tokens": ["remove", "base_tokenize", "method", "and", "move", "tokenizing", "logic", "into", "its", "own", "tokenize", "()", "method"], "add_tokens": "# tokenize words @tokens = self . tokenize ( text ) def tokenize ( text ) #:nodoc: tokens = text . split ( ' ' ) . map { | word | Token . new ( word ) } [ Repeater , Grabber , Pointer , Scalar , Ordinal , Separator , TimeZone ] . each do | tok | tokens = tok . scan ( tokens ) end tokens . delete_if { | token | ! token . tagged? }", "del_tokens": "# get base tokens for each word @tokens = self . base_tokenize ( text ) # scan the tokens with each token scanner [ Repeater , Grabber , Pointer , Scalar , Ordinal , Separator , TimeZone ] . each do | tokenizer | @tokens = tokenizer . scan ( @tokens ) end # strip any non-tagged tokens @tokens . delete_if { | token | ! token . tagged? } # Split the text on spaces and convert each word into # a Token def base_tokenize ( text ) #:nodoc: text . split ( ' ' ) . map { | word | Token . new ( word ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "register", "to", "ensure", "all", "connections", "created", "by", "hot_tub", "can", "be", "tracked", "and", "closed", "even", "when", "in", "checkout", "from", "pool"], "add_tokens": "@pool = [ ] # stores available connection @register = [ ] # stores all connections at all times @current_size = 0 @pool_mutex = ( fiber_mutex? ? EM :: Synchrony :: Thread :: Mutex . new : Mutex . new ) @last_activity = Time . now @fetching_client = false @pool_mutex . synchronize do while clnt = @register . pop @pool . delete ( clnt ) # Safely add client back to pool, only if # that clnt is registered @pool_mutex . synchronize do if @register . include? ( clnt ) @pool << clnt else close_client ( clnt ) end @pool_mutex . synchronize do @pool_mutex . synchronize do @register . delete ( clnt ) # _add is volatile; and may cause theading issues # if called outside @pool_mutex.synchronize {} def _add @last_activity = Time . now @current_size += 1 nc = new_client HotTub . logger . info \"Adding HotTub client: #{nc.class.name} to pool\" @register << nc @pool << nc end # end volatile", "del_tokens": "@pool = [ ] @current_size = 0 @mutex = ( fiber_mutex? ? EM :: Synchrony :: Thread :: Mutex . new : Mutex . new ) @last_activity = Time . now @fetching_client = false @mutex . synchronize do while clnt = @pool . pop # Safely add client back to pool @mutex . synchronize do @pool << clnt @mutex . synchronize do def _add @last_activity = Time . now @current_size += 1 nc = new_client HotTub . logger . info \"Adding HotTub client: #{nc.class.name} to pool\" @pool << nc end @mutex . synchronize do", "commit_type": "add"}
{"commit_tokens": ["Use", "ActiveRecord", "s", "after", "initialize", "callback", "instead", "of", "overwriting", "the", "initializer", "to", "set", "default", "values", "on", "record", "retrieval", "too", ".", "Removes", "obsolete", "mass", "assignment", "check", "."], "add_tokens": "if ! method_defined? ( :set_default_values ) after_initialize :set_default_values def set_default_values self . class . _all_default_attribute_values . each do | attribute , container | connection_default_value_defined = new_record? && respond_to? ( \"#{attribute}_changed?\" ) && ! __send__ ( \"#{attribute}_changed?\" ) next unless connection_default_value_defined || self . attributes [ attribute ] . blank? __send__ ( \"#{attribute}=\" , container . evaluate ( self ) ) changed_attributes . delete ( attribute ) end end", "del_tokens": "if ! method_defined? ( :initialize_with_defaults ) alias_method_chain :initialize , :defaults def initialize_with_defaults ( attrs = nil , * args , & block ) initialize_without_defaults ( attrs , * args , & block ) if attrs stringified_attrs = attrs . stringify_keys safe_attrs = if respond_to? :sanitize_for_mass_assignment sanitize_for_mass_assignment ( stringified_attrs ) else remove_attributes_protected_from_mass_assignment ( stringified_attrs ) end safe_attribute_names = safe_attrs . keys . map do | x | x . to_s end end self . class . _all_default_attribute_values . each do | attribute , container | if safe_attribute_names . nil? || ! safe_attribute_names . any? { | attr_name | attr_name =~ / ^ #{ attribute } ($| \\( ) / } __send__ ( \"#{attribute}=\" , container . evaluate ( self ) ) changed_attributes . delete ( attribute ) end end yield ( self ) if block_given? end", "commit_type": "use"}
{"commit_tokens": ["Added", "documentation", "about", "default", "values"], "add_tokens": "@default_value = Attrio :: DefaultValue . new ( self . klass , self . name , self . options [ :default ] )", "del_tokens": "@default_value = Attrio :: DefaultValue . new ( self . klass , self . name , ( self . options [ :default ] || self . options [ :default_value ] ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "key?", "method", "to", "match", "Ruby", "hash"], "add_tokens": "def key? ( name ) alias_method :has_key? , :key?", "del_tokens": "def has_key? ( name )", "commit_type": "add"}
{"commit_tokens": ["fix", "tests", "so", "they", "can", "pass", "on", "travis", "ci"], "add_tokens": "! ! ( ` bzr nick 2>&1 ` && cmd_success? ) def self . cmd_success? $? . success? end", "del_tokens": "! ! ( ` bzr nick 2>&1 ` && $? . success? )", "commit_type": "fix"}
{"commit_tokens": ["Add", "Bootstrap", "and", "HAML", "sexiness", ";", "fix", "old", "d2_", "lib", "names", ";", "fix", "MODS", "title", "/", "creator", "mapping", ";", "add", "facet", "filtering", "(", "incomplete", ")"], "add_tokens": "Ladder . controllers :resource do render 'resource/index'", "del_tokens": "Ladder . controllers :resources do render 'resources/index'", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "temp", "directory", "for", "the", "fedora", "home", "directory"], "add_tokens": "if options [ :fcrepo_home_dir ] options [ :fcrepo_home_dir ] elsif defined? Rails File . join ( Rails . root , 'tmp' , 'fcrepo4-data' ) else Dir . mktmpdir end", "del_tokens": "options [ :fcrepo_home_dir ]", "commit_type": "use"}
{"commit_tokens": ["Add", "default", "paths", "to", "be", "excluded", "in", "the", "puppet", "task"], "add_tokens": "@exclude_paths ||= options . fetch ( :exclude_paths , [ 'bundle/**/*' , 'modules/**/*' , 'pkg/**/*' , 'spec/**/*' , 'tmp/**/*' , 'vendor/**/*' ] )", "del_tokens": "@exclude_paths ||= options . fetch ( :exclude_paths ) unless options . empty?", "commit_type": "add"}
{"commit_tokens": ["moving", "from", "svn", "repository", "(", "dreamhost", ")", "to", "git"], "add_tokens": "if @prefix_path @path_from_root = @prefix_path else @path_from_root = \"\" end", "del_tokens": "@path_from_root = \"\"", "commit_type": "move"}
{"commit_tokens": ["added", "#load", "&", "#loaded?", "to", "DeskApi", "::", "Resource", "aliased", "#load!", "to", "@reload!"], "add_tokens": "self . load self . load self . load alias_method :load! , :reload! def load self . exec! unless @_loaded end def loaded? @_loaded end self . load", "del_tokens": "self . exec! unless @_loaded self . exec! unless @_loaded self . exec! unless @_loaded self . exec! unless @_loaded", "commit_type": "add"}
{"commit_tokens": ["moved", "schema", "entity", "from", "xml", "to", "schema"], "add_tokens": "def default_for ( field_def ) field_def . attributes [ 'default' ] &. value end def is_core_for ( xml ) def key_column_for ( xml ) key_tag = is_core_for ( xml ) ? 'id' : 'coreid' xml . css ( key_tag ) . first . attributes [ 'index' ] . value . to_i end term = term_for xml # the xml is a file definition if no term is found but a location return is_file . text if is_file && ! term # the xml is a table or column definition", "del_tokens": "def self . core_node? ( xml ) def self . key_column ( xml ) key_tag = core_node? ( xml ) ? 'id' : 'coreid' xml . css ( key_tag ) . first . attributes [ 'index' ] . value . to_i end def default_for ( field_def ) field_def . attributes [ 'default' ] &. value end # if the xml is a file definition return is_file . text if is_file # if the xml is a table or column definition term = term_for xml", "commit_type": "move"}
{"commit_tokens": ["updated", "validator", "class", "+", "added", "new", "validation", "options"], "add_tokens": "validator = Evnt :: Validator . new ( params [ val [ :param ] ] , val [ :options ] ) if validator . passed? @params [ val [ :param ] ] = validator . value else", "del_tokens": "result = Evnt :: Validator . validates ( params [ val [ :param ] ] , val [ :options ] ) if result == :ERROR else @params [ val [ :param ] ] = result", "commit_type": "update"}
{"commit_tokens": ["Added", "more", "attributes", "to", "SurveyCampaign"], "add_tokens": "attribute :id , Integer attribute :name , String attribute :type , String attribute :_subtype , String attribute :__subtype , String attribute :status , String attribute :uri , String attribute :SSL , Boolean attribute :slug , String attribute :language , String attribute :close_message , String attribute :limit_responses , String # attribute :tokenvariables, String attribute :survey_id , Integer attribute :datecreated , DateTime attribute :datemodified , DateTime collection :tokenvariables", "del_tokens": "attribute :id , Integer attribute :name , String attribute :type , String attribute :status , String attribute :slug , String attribute :language , String attribute :survey_id , Integer alias_attribute :_subtype , :type collection :options", "commit_type": "add"}
{"commit_tokens": ["use", "scan_for", "when", "scanning", "and", "building", "Grabbers"], "add_tokens": "# module Chronic", "del_tokens": "#module Chronic", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "multipart", "post"], "add_tokens": "attr_accessor :url , :username , :password , :file_name , :proxy , :auth_type , :insecure , :multipart self . multipart ? data : hash_to_string ( data )", "del_tokens": "attr_accessor :url , :username , :password , :file_name , :proxy , :auth_type , :insecure hash_to_string ( data )", "commit_type": "add"}
{"commit_tokens": ["Made", "quoting", "methods", "publicly", "available"], "add_tokens": "def self . quote_name ( name ) if name . to_s =~ / ^[A-Z$_][A-Z0-9$_]*$ /i name . to_s else \"`\" + name . to_s . gsub ( \"`\" , \"``\" ) + \"`\" end end def self . quote_value ( value ) '\"' + value . to_s . gsub ( / \" / , '\"\"' ) + '\"' end self . class . quote_name ( name ) self . class . quote_value ( value )", "del_tokens": "if name . to_s =~ / ^[A-Z$_][A-Z0-9$_]*$ /i name . to_s else \"`\" + name . to_s . gsub ( \"`\" , \"``\" ) + \"`\" end '\"' + value . to_s . gsub ( / \" / , '\"\"' ) + '\"'", "commit_type": "make"}
{"commit_tokens": ["moved", "#parse_youtube_id", "(", "url", ")", "into", "the", "TagSifter", "class", "...", "but", "my", "OS", "just", "crashed", "soft", "so", "the", "unit", "tests", "aren", "t", "working", "yet"], "add_tokens": "param = parse_youtube_id ( param ) if @ti [ :tag ] . to_sym == :youtube # note: this line isn't ever used because @@tags don't allow it param = parse_youtube_id ( param ) if @bbtree . current_node [ :tag ] == :youtube # Parses a youtube video url and extracts the ID def parse_youtube_id ( url ) url =~ / [vV]=([^&]*) / id = $1 if id . nil? # when there is no match for v=blah, then maybe they just # provided us with the ID the way the system used to work... # just \"E4Fbk52Mk1w\" return url else # else we got a match for an id and we can return that ID... return id end end", "del_tokens": "param = RubyBBCode . parse_youtube_id ( param ) if @ti [ :tag ] . to_sym == :youtube # note: this line isn't ever used because @@tags don't allow it param = RubyBBCode . parse_youtube_id ( param ) if @bbtree . current_node [ :tag ] == :youtube", "commit_type": "move"}
{"commit_tokens": ["Making", "the", "ShellCmd", "output", "level", "configurable"], "add_tokens": "# @option opts [Boolean] :out_level To which log level to print the output # [default: :info]. @out_level = :info # The function will block until the command has finished. log ( @out_level , line )", "del_tokens": "# The function will blog until the command has finished. log ( :info , line )", "commit_type": "make"}
{"commit_tokens": ["added", "spec", "files", "for", "each", "class", ".", "need", "to", "build", "each", "out", ".", "main", "CrmFormatter", "spec", "completed", "and", "passed", "."], "add_tokens": "# require \"bundler/setup\" require \"active_support/all\" $LOAD_PATH . unshift File . expand_path ( \"../../lib\" , __FILE__ )", "del_tokens": "require \"bundler/setup\" RSpec . configure do | config | # Enable flags like --only-failures and --next-failure config . example_status_persistence_file_path = \".rspec_status\" # Disable RSpec exposing methods globally on `Module` and `main` config . disable_monkey_patching! config . expect_with :rspec do | c | c . syntax = :expect end end", "commit_type": "add"}
{"commit_tokens": ["add", "run", "wrapper", "that", "does", "not", "capture", "but", "with", "the", "same", "signture", "as", "run_with_capture"], "add_tokens": "# @return [Hash] {:out => String, :err => String, :success => bool} # run a command and don't capture its output, but use the same signature # @return [Hash] {:out => String, :err => String, :success => bool} def run_wrap ( * args , ** kwargs ) success = run ( * args , ** kwargs ) { out : \"NOPE, use run_and_capture\" , err : \"NOPE, use run_and_capture\" , success : success } end", "del_tokens": "# @return [Hash] {:out => StringIO, :err => StringIO, :success => bool}", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "and", "fix", "bug", "."], "add_tokens": "return true if have_lock?", "del_tokens": "return true if have_lock?", "commit_type": "add"}
{"commit_tokens": ["Added", "deprecated", "warning", "when", "setting", "key", "on", "a", "map", "."], "add_tokens": "@map = GoogleStaticMapsHelper :: Map . new ( :size => @size , :sensor => @sensor ) @key = @map = GoogleStaticMapsHelper :: Map . new ( :size => @size , :sensor => @sensor ) @map . key_without_warning = 'MY_GOOGLE_KEY' @map . url . should include ( \"key=MY_GOOGLE_KEY\" ) @map . key_without_warning = nil", "del_tokens": "@map = GoogleStaticMapsHelper :: Map . new ( :key => @key , :size => @size , :sensor => @sensor ) @key = 'MY_GOOGLE_KEY' @map = GoogleStaticMapsHelper :: Map . new ( :key => @key , :size => @size , :sensor => @sensor ) @map . url . should include ( \"key=#{@key}\" ) @map . key = nil [ 'key' , 'MY_GOOGLE_KEY' ] , [ 'key' , 'MY_GOOGLE_KEY' ] , [ 'key' , 'MY_GOOGLE_KEY' ] ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "more", "Style", "/", "Alias", "offenses"], "add_tokens": "alias all find_all", "del_tokens": "alias :all :find_all", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "more", "sensible", "defaults"], "add_tokens": "# item - the Item just before the item to start from. protected def first_item_after ( item , n , items_left = @item_count ) n = items_left if n > items_left protected def last_item_before ( item , n , items_left = @item_count ) n = items_left if n > items_left", "del_tokens": "# item - the Item just before the item to start from protected def first_item_after ( item , n , items_left = nil ) n = ( n > items_left ? items_left : n ) if items_left protected def last_item_before ( item , n , items_left = nil ) # Things can be sped up if we know how many items are # left n = ( n > items_left ? items_left : n ) if items_left # If items_left was not known, or wrong, we end up # here. We know for a fact that the array contains # nil elements.", "commit_type": "add"}
{"commit_tokens": ["Moving", "collection", "accessors", "back", "into", "Document"], "add_tokens": "extend Finders # Get the Mongo::Collection associated with this Document. def collection @collection_name = self . to_s . demodulize . tableize @collection ||= Mongoid . database . collection ( @collection_name ) end # Get the Mongo::Collection associated with this Document. def collection self . class . collection end", "del_tokens": "include Finders", "commit_type": "move"}
{"commit_tokens": ["Add", "coveralls", "as", "a", "dev", "dependency"], "add_tokens": "require 'coveralls' Coveralls . wear!", "del_tokens": "# Set up simplecov", "commit_type": "add"}
{"commit_tokens": ["Remove", "category", "manager", "other", "refactoring"], "add_tokens": "require \"versed/schedule_view\" # create models schedule_view = Versed :: ScheduleView . new ( schedule ) html = Mustache . render ( IO . read ( main_template_path ) , schedule_view . to_hash )", "del_tokens": "html = Mustache . render ( IO . read ( main_template_path ) , schedule . to_hash )", "commit_type": "remove"}
{"commit_tokens": ["fix", "issue", "with", "the", "display", "of", "side", "bar", "stacked", "graphs"], "add_tokens": "# if a data point is 0 it can result in weird really thing lines # that shouldn't even be there being drawn on top of the existing # bar - this is bad if data_point != 0 @d = @d . rectangle ( left_x , left_y , right_x , right_y ) # Calculate center based on bar_width and current row label_center = @graph_top + ( @bar_width * point_index ) + ( @bar_width * spacing_factor / 2.0 ) + padding draw_label ( label_center , point_index ) end", "del_tokens": "@d = @d . rectangle ( left_x , left_y , right_x , right_y ) # Calculate center based on bar_width and current row label_center = @graph_top + ( @bar_width * point_index ) + ( @bar_width * spacing_factor / 2.0 ) + padding draw_label ( label_center , point_index )", "commit_type": "fix"}
{"commit_tokens": ["moved", "version", "back", "into", "version", ".", "rb"], "add_tokens": "VERSION = \"0.1.7\"", "del_tokens": "VERSION = \"0.0.2\"", "commit_type": "move"}
{"commit_tokens": ["Adds", "ability", "to", "toggle", "step", "preview"], "add_tokens": "before_action :set_step , only : [ :show , :edit , :update , :destroy , :preview , :toggle ] if @step . preview_enabled original_headers = request . headers . to_h . select { | k , v | k . starts_with? \"HTTP_\" } . map { | k , v | [ k . downcase . gsub ( / ^http_ / , \"\" ) , v ] } request_headers = Hash [ original_headers ] definition = @step . definition_hash @use_case = :: Riddler :: UseCases :: PreviewStep . new definition , params : params . to_unsafe_h , headers : request_headers else render json : { status : 'disabled' } . to_json end end def toggle @step . update_attributes ( preview_enabled : ! @step . preview_enabled ) redirect_to @step", "del_tokens": "before_action :set_step , only : [ :show , :edit , :update , :destroy , :preview ] original_headers = request . headers . to_h . select { | k , v | k . starts_with? \"HTTP_\" } . map { | k , v | [ k . downcase . gsub ( / ^http_ / , \"\" ) , v ] } request_headers = Hash [ original_headers ] definition = @step . definition_hash @use_case = :: Riddler :: UseCases :: PreviewStep . new definition , params : params . to_unsafe_h , headers : request_headers", "commit_type": "add"}
{"commit_tokens": ["Adds", "conversion", "tests", "for", "Values"], "add_tokens": "when filter . respond_to? ( :to_s ) c . name == filter . to_s || c . name . split ( / :: / ) [ - 1 ] =~ / ^ #{ filter } $ /i", "del_tokens": "when filter . is_a? ( :: String ) || filter . is_a? ( Symbol ) c . name . split ( / :: / ) [ - 1 ] =~ / ^ #{ filter } $ /i", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "defaults", "for", "droplet", "creation"], "add_tokens": ":default => 66 , :default => 284203 ,", "del_tokens": ":default => 64 , :default => 2676 ,", "commit_type": "update"}
{"commit_tokens": ["make", "creds", "and", "options", "visible", "to", "class"], "add_tokens": "attr_reader :api , :update_keys , :logger , :creds , :opts @creds = creds @opts = opts @s_api = setup_api ( creds , opts )", "del_tokens": "attr_reader :api , :update_keys , :logger", "commit_type": "make"}
{"commit_tokens": ["Add", "missing", "specs", "for", "Integer", "coercer"], "add_tokens": "# FIXME: Remove after Rubinius 2.0 is released config . datetime_format , config . datetime_proc = if Coercible . rbx? [ '%Q' , Proc . new { | value | \"#{value * 10**3}\" } ] else [ '%s' , Proc . new { | value | \"#{value}\" } ] end", "del_tokens": "# FIXME: Remove after Rubinius 2.0 is released is_rbx = defined? ( RUBY_ENGINE ) && RUBY_ENGINE == 'rbx' config . datetime_format = is_rbx ? '%Q' : '%s' config . datetime_proc = is_rbx ? Proc . new { | value | \"#{value * 10**3}\" } : Proc . new { | value | \"#{value}\" }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "creating", "database", "users", "."], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "single", "option", "bug", "in", "Delegator"], "add_tokens": "while argv . first =~ / ^- /", "del_tokens": "while argv . first =~ / ^-- /", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "the", "_item", "partial", "within", "the", "_table", "partial"], "add_tokens": "require 'action_view/test_case' def create_mock_user ( expectations = { } ) tests UsersController mock_user_1 = create_mock_user mock_user_2 = create_mock_user User . expects ( :find ) . with ( :all ) . returns ( [ mock_user_1 , mock_user_2 ] ) mock_user_1 . stubs ( :username => \"john.doe\" , :first_name => \"John\" , :last_name => \"Doe\" ) mock_user_2 . stubs ( :username => \"jane.doe\" , :first_name => \"Jane\" , :last_name => \"Doe\" ) assert_select \"td\" , \"jane.doe\" assert_select \"td\" , \"Jane\" assert_select \"tr.even\" test \"should render using the table partial\" do assert_template :partial => \"_table\" , :count => 1 end test \"should render the item partial for each resource in the table\" do assert_template :partial => \"_item\" , :count => 2 end", "del_tokens": "def setup @controller = UsersController . new @controller . request = @request = ActionController :: TestRequest . new @controller . response = @response = ActionController :: TestResponse . new @controller . stubs ( :user_url ) . returns ( \"/\" ) end protected def mock_user ( expectations = { } ) @mock_user ||= begin end User . expects ( :find ) . with ( :all ) . returns ( [ mock_user ] ) mock_user . stubs ( :username => \"john.doe\" , :first_name => \"John\" , :last_name => \"Doe\" )", "commit_type": "implement"}
{"commit_tokens": ["moved", "resque", "to", "handlers", "folder", "added", "stale", "workers", "bumped", "version"], "add_tokens": "require \"mobilize-base/handlers/resque\"", "del_tokens": "require \"mobilize-base/extensions/resque\"", "commit_type": "move"}
{"commit_tokens": ["add", "explizit", "test", "file", "for", "Object", "Changed", "tests", "to", "ReadOnly", "sessions", "and", "session", "objects", "add", "tests", "for", "Session#create_object", "()"], "add_tokens": "flags = PKCS11 :: CKF_SERIAL_SESSION #| PKCS11::CKF_RW_SESSION { :ENCRYPT => true , :WRAP => true , :DECRYPT => true , :UNWRAP => true , :TOKEN => false } ) { :ENCRYPT => true , :VERIFY => true , :WRAP => true , :MODULUS_BITS => 768 , :PUBLIC_EXPONENT => [ 3 ] . pack ( \"N\" ) , :TOKEN => false } , { :PRIVATE => true , :SUBJECT => 'test' , :ID => [ 123 ] . pack ( \"n\" ) , :SENSITIVE => true , :DECRYPT => true , :SIGN => true , :UNWRAP => true , :TOKEN => false } )", "del_tokens": "flags = PKCS11 :: CKF_SERIAL_SESSION | PKCS11 :: CKF_RW_SESSION { :ENCRYPT => true , :WRAP => true , :DECRYPT => true , :UNWRAP => true } ) { :ENCRYPT => true , :VERIFY => true , :WRAP => true , :MODULUS_BITS => 768 , :PUBLIC_EXPONENT => [ 3 ] . pack ( \"N\" ) } , { :TOKEN => true , :PRIVATE => true , :SUBJECT => 'test' , :ID => [ 123 ] . pack ( \"n\" ) , :SENSITIVE => true , :DECRYPT => true , :SIGN => true , :UNWRAP => true } )", "commit_type": "add"}
{"commit_tokens": ["Use", "consumer", "id", "to", "retrieve", "auth", "keys", "and", "tokens"], "add_tokens": "response = client . get ( \"#{@api_end_point}#{self.id}/oauth2\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.id}/basic-auth\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.id}/key-auth\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.id}/acls\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.id}/jwt\" ) rescue nil", "del_tokens": "response = client . get ( \"#{@api_end_point}#{self.username}/oauth2\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.username}/basic-auth\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.username}/key-auth\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.username}/acls\" ) rescue nil response = client . get ( \"#{@api_end_point}#{self.username}/jwt\" ) rescue nil", "commit_type": "use"}
{"commit_tokens": ["Add", "encoding", "param", "for", "Table"], "add_tokens": "# @param filepath [String, nil] create an empty {Table} if nil # @param encoding [String] def initialize ( filepath = nil , encoding : Encoding . default_external ) case filepath File . open ( filepath , \"r:#{encoding}\" ) . read . to_table ( self )", "del_tokens": "# @param arg [String, nil] filepath, or create an empty {Table} if nil def initialize ( arg = nil ) case arg File . open ( arg ) . read . to_table ( self )", "commit_type": "add"}
{"commit_tokens": ["moved", "generated", "class", "methods", "to", "Accessors", "module"], "add_tokens": "require 'gametel/accessors' require 'gametel/version' cls . extend Gametel :: Accessors", "del_tokens": "require 'gametel/version' cls . extend Gametel :: ClassMethods module ClassMethods def text ( name , locator ) define_method ( \"#{name}=\" ) do | value | action = locator . kind_of? ( String ) ? 'enter_text_into_named_field' : 'enter_text_into_numbered_field' performAction ( action , value , locator ) end define_method ( name ) do # get the value from the text thingy end end def button ( name , locator ) define_method ( name ) do action = locator . kind_of? ( String ) ? 'press_button_with_text' : 'press_button_number' performAction ( action , locator ) end end end", "commit_type": "move"}
{"commit_tokens": ["move", "type", "to", "a", "class", "method"], "add_tokens": "def self . type \"dep\" def initialize ( config ) @config = config go_dep_available? next if @config . ignored? ( \"type\" => Dep . type , \"name\" => package [ :name ] ) \"type\" => Dep . type ,", "del_tokens": "def initialize ( config ) @config = config def type \"dep\" @config . enabled? ( type ) && go_dep_available? next if @config . ignored? ( \"type\" => type , \"name\" => package [ :name ] ) \"type\" => type ,", "commit_type": "move"}
{"commit_tokens": ["Fix", "a", "bug", "and", "fix", "another", "bug", "that", "relied", "on", "this", "bug"], "add_tokens": "key_content_type = key_metadata ( path , options ) . rundeck_content_type if key_content_type == content_type ( 'private' )", "del_tokens": "if key_metadata ( path , options ) . rundeck_key_type == 'private'", "commit_type": "fix"}
{"commit_tokens": ["Add", ".", "scope", "to", "API", "to", "allow", "for", "scoping", "without", "modifying", "the", "URL", "."], "add_tokens": "# The API class is the primary entry point for # creating Grape APIs. Users should subclass this # class in order to build an API. alias_method :group , :namespace alias_method :resource , :namespace alias_method :resources , :namespace # Create a scope without affecting the URL. # # @param name [Symbol] Purely placebo, just allows to to name the scope to make the code more readable. def scope ( name = nil , & block ) nest ( block ) end protected instance_eval & block if block_given?", "del_tokens": "module Helpers ; end instance_eval & block alias_method :group , :namespace alias_method :resource , :namespace alias_method :resources , :namespace protected", "commit_type": "add"}
{"commit_tokens": ["Updated", "code", "to", "use", "Model", "and", "not", "Resource", "::", "ClassMethods"], "add_tokens": "Model . send ( :include , self )", "del_tokens": "module ClassMethods include Validate :: ClassMethods end # module ClassMethods", "commit_type": "update"}
{"commit_tokens": ["Added", "disqus_shortname", "app", "config", "attribute"], "add_tokens": ":user_aliases , :release_externally , :gem_name , :disqus_shortname", "del_tokens": ":user_aliases , :release_externally , :gem_name", "commit_type": "add"}
{"commit_tokens": ["added", "the", "Model", ".", "all", "view"], "add_tokens": "d = WithTemplate . design_doc d [ 'views' ] [ 'all' ] [ 'map' ] . should include ( 'WithTemplate' ) rs = WithTemplate . all", "del_tokens": "puts d = WithTemplate . design_doc . to_json d . should == 'xs' rs = WithTemplate . all :raw => true rs . should == 'x'", "commit_type": "add"}
{"commit_tokens": ["Adding", "attachment", "(", "image", ")", "field", "to", "blog", "posts"], "add_tokens": "belongs_to_attachment def set_attachment_file_path # The default behavior is use /attachments/file.txt for the attachment path, # assuming file.txt was the name of the file the user uploaded # You should override this with your own strategy for setting the attachment path super end def set_attachment_section # The default behavior is to put all attachments in the root section # Override this method if you would like to change that super end after_publish_without_set_published_at if respond_to? :after_publish_without_set_published_at", "del_tokens": "debugger", "commit_type": "add"}
{"commit_tokens": ["Allow", "options", "to", "be", "set", "on", "WkbWriter", "and", "WktWriter", "more", "easily", "."], "add_tokens": "def initialize ( options = { } ) options = { :include_srid => false } . merge ( options ) ptr = FFIGeos . GEOSWKBWriter_create_r ( Geos . current_handle ) set_options ( options ) def set_options ( options = { } ) #:nodoc: [ :include_srid ] . each do | k | self . send ( \"#{k}=\" , options [ k ] ) if options . has_key? ( k ) end end private :set_options # Options can be set temporarily for individual writes using an options # Hash. The only option currently available is :include_srid. def write ( geom , options = nil ) unless options . nil? old_options = { :include_srid => self . include_srid } set_options ( options ) end ensure set_options ( old_options ) unless old_options . nil? def write_hex ( geom , options = nil ) unless options . nil? old_options = { :include_srid => self . include_srid } set_options ( options ) end ensure set_options ( old_options ) unless old_options . nil?", "del_tokens": "def initialize ( * args ) ptr = if args . first . is_a? ( FFI :: Pointer ) args . first else FFIGeos . GEOSWKBWriter_create_r ( Geos . current_handle , * args ) end def write ( geom ) def write_hex ( geom )", "commit_type": "allow"}
{"commit_tokens": ["Moved", "ADT_help_requireables", "to", "seperate", "file"], "add_tokens": "require_relative 'ADT_help_requireables.rb'", "del_tokens": "require_relative 'zadt/HelpModules/HelpMessages/adt_help.rb' require_relative 'zadt/HelpModules/HelpMessages/adt_stackqueue_help.rb' require_relative 'zadt/HelpModules/HelpMessages/adt_graph_help.rb' require_relative 'zadt/HelpModules/HelpMessages/adt_geometrics_help.rb' require_relative 'zadt/HelpModules/HelpMessages/adt_linkedlist_help.rb' require_relative 'zadt/HelpModules/Functionality/StackQueue/queue.rb' require_relative 'zadt/HelpModules/Functionality/StackQueue/stack.rb' require_relative 'zadt/HelpModules/Functionality/StackQueue/stack_queue.rb' require_relative 'zadt/HelpModules/Functionality/StackQueue/min_max_stack.rb' require_relative 'zadt/HelpModules/Functionality/StackQueue/min_max_stack_queue.rb' require_relative 'zadt/HelpModules/Functionality/Geometrics/circle.rb' require_relative 'zadt/HelpModules/Functionality/Geometrics/hypersphere.rb' require_relative 'zadt/HelpModules/Functionality/Geometrics/point.rb' require_relative 'zadt/HelpModules/Functionality/Geometrics/sphere.rb' require_relative 'zadt/HelpModules/Functionality/Geometrics/universe.rb' require_relative 'zadt/HelpModules/Functionality/Graph/face_graph.rb' require_relative 'zadt/HelpModules/Functionality/Graph/graph.rb' require_relative 'zadt/HelpModules/Functionality/LinkedList/linked_list.rb' require_relative 'zadt/HelpModules/Functionality/LinkedList/doubly_linked_list.rb'", "commit_type": "move"}
{"commit_tokens": ["Add", "namespaced", "and", "registered", "partials", "to", "layout", "."], "add_tokens": "VERSION = '1.5.0.0'", "del_tokens": "VERSION = '1.4.1.0'", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "term", "threshold", "instead", "of", "minimum"], "add_tokens": "attr_reader :threshold # Create a new Readthis::Compressor object that pivots on the provided # threshold value. # # @param threshold [Number] the threshold size required for compression def initialize ( threshold : 1024 ) @threshold = threshold # Compress a value if its size is greater or equal to the current threshold. # # @param value [String] a string to compress if value . size >= threshold # Decompress a previously compressed object. It will attempt to decode a # value regardless of whether it has been compressed, but will rescue # decoding errors. # # @param value [String] a possibly compressed string to decompress if value . size >= threshold", "del_tokens": "attr_reader :minimum def initialize ( minimum : 1024 ) @minimum = minimum if value . size >= minimum if value . size >= minimum", "commit_type": "use"}
{"commit_tokens": ["Add", "pkgr", ".", "yml", "fixture", "file", "."], "add_tokens": "config = Pkgr :: Config . load_file ( fixture ( \"pkgr.yml\" ) , \"debian-squeeze\" ) config2 = Pkgr :: Config . load_file ( fixture ( \"pkgr.yml\" ) , \"debian-squeeze\" )", "del_tokens": "config = Pkgr :: Config . load_file ( fixture ( \"pkgr.yml\" ) , \"squeeze\" ) config2 = Pkgr :: Config . load_file ( fixture ( \"pkgr.yml\" ) , \"squeeze\" )", "commit_type": "add"}
{"commit_tokens": ["fixing", "up", "example", "rackup", "files"], "add_tokens": "require 'stickler/middleware/index' module Stickler :: Middleware class Mirror < :: Stickler :: Middleware :: Index @repo = :: Stickler :: Repository :: Mirror . new ( options [ :repo_root ] ) rescue :: Stickler :: Repository :: Mirror :: Error => e", "del_tokens": "module Stickler class MirrorServer < :: Sinatra :: Base # The root directory all local mirrors of upstream repos will be stored. # Each mirror will have a directory within the mirror_root attr_reader :mirror_root @app = app @repo = Repository :: Mirror . new ( options [ :mirror_root ] ) rescue Stickler :: Repository :: Mirror :: Error => e", "commit_type": "fix"}
{"commit_tokens": ["upgraded", "internal", "files", "to", "support", "latest", "newgem", "(", "removed", "config", "/", "folder", "moved", "config", "to", "Rakefile", ")"], "add_tokens": "stdout . print \"overwrite #{destination}? (enter \\\"h\\\" for help) [Ynaiqd] \" else $stdout . puts <<-HELP . gsub ( / ^ / , '' ) Y - yes , overwrite n - no , do not overwrite a - all , overwrite this and all others i - ignore , skip any conflicts q - quit , abort d - diff , show the differences between the old and the new h - help , show this help HELP raise 'retry'", "del_tokens": "stdout . print \"overwrite #{destination}? [Ynaiqd] \" else force_file_collision? ( destination , src , dst , file_options , & block )", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "void", "refuned", "and", "resend", "confirmation", "functionality"], "add_tokens": "body [ 'api-key' ] = if false #test or Rails.env == 'development' response = self . api 'void' , { 'transaction-id' => order . transaction_id } , order . test? response = self . api 'capture' , { 'transaction-id' => order . transaction_id } , order . test? 'transaction-id' => order . transaction_id ,", "del_tokens": "body [ 'api-key' ] = if test or Rails . env == 'development' response = self . api 'void' , { 'transaction-id' => order . transaction_token . to_s } , order . test? response = self . api 'capture' , { 'transaction-id' => order . transaction_id . to_s } , order . test? 'transaction-id' => order . transaction_id . to_s ,", "commit_type": "add"}
{"commit_tokens": ["creating", "executable", "file", "that", "loads", "the", "command"], "add_tokens": "@lib_path = \"#{s_path}/lib\" cp \"#{s_path}/bin/#{@program_name}\" , exec_path if exec_path end ## # if set any program created will be put in this folder def exec_path YAML . load_file ( @config_file ) [ :exec_path ]", "del_tokens": "File . symlink \"#{s_path}/bin/#{@program_name}\" , File . expand_path ( \"~/bin/#{@program_name}2\" )", "commit_type": "create"}
{"commit_tokens": ["removed", "requirement", "statements", "for", "deleted", "files"], "add_tokens": "require 'eventhub/components'", "del_tokens": "require_relative 'eventhub/multi_logger' require_relative 'eventhub/pidfile'", "commit_type": "remove"}
{"commit_tokens": ["Allow", "geocoder", "search", "method", "to", "be", "something", "other", "than", "an", "ActiveRecord", "attribute", "."], "add_tokens": "# Returns an array <tt>[lat,lon]</tt>.search location = send ( self . class . geocoder_options [ :method_name ] )", "del_tokens": "# Returns an array <tt>[lat,lon]</tt>. location = read_attribute ( self . class . geocoder_options [ :method_name ] )", "commit_type": "allow"}
{"commit_tokens": ["add", "basic", "file", "input", "with", "specs", ".", "This", "is", "a", "very", "simple", "addition", "that", "allow", "the", "use", "of", ":", "as", "=", ">", ":", "file", "to", "get", "a", "file", "input"], "add_tokens": "[ :select , :radio , :password , :text , :date , :datetime , :time , :boolean , :boolean_select , :string , :numeric , :file ] . each do | input_style | describe ':as => :file' do setup do @new_post . stub! ( :some_file ) @new_post . stub! ( :column_for_attribute ) . and_return ( mock ( 'column' , :type => :string , :limit => 50 ) ) semantic_form_for ( @new_post ) do | builder | concat ( builder . input ( :some_file , :as => :file ) ) end end it 'should have a file class on the wrapper' do output_buffer . should have_tag ( 'form li.file' ) end it 'should have a post_some_file_input id on the wrapper' do output_buffer . should have_tag ( 'form li#post_some_file_input' ) end it 'should generate a label for the input' do output_buffer . should have_tag ( 'form li label' ) output_buffer . should have_tag ( 'form li label[@for=\"post_some_file\"' ) output_buffer . should have_tag ( 'form li label' , / Some file / ) end it 'should generate a file input' do output_buffer . should have_tag ( 'form li input' ) output_buffer . should have_tag ( 'form li input#post_some_file' ) output_buffer . should have_tag ( 'form li input[@type=\"file\"]' ) output_buffer . should have_tag ( 'form li input[@name=\"post[some_file]\"]' ) end end", "del_tokens": "[ :select , :radio , :password , :text , :date , :datetime , :time , :boolean , :boolean_select , :string , :numeric ] . each do | input_style |", "commit_type": "add"}
{"commit_tokens": ["Add", "non", "-", "recursive", "option", "to", "find_type", "and", "find_type_elements"], "add_tokens": "# # If +nested+ is set to false, this returns only top level elements of a # given type. def find_type ( type , nested = true ) find_type_elements ( type , nested ) . map { | e | e . options } # # If +nested+ is set to false, this returns only top level elements of a # given type. def find_type_elements ( type , nested = true , elements = @elements ) if nested and not e . children . empty? results . concat ( find_type_elements ( type , nested , e . children ) )", "del_tokens": "def find_type ( type ) find_type_elements ( type ) . map { | e | e . options } def find_type_elements ( type , elements = @elements ) if not e . children . empty? results . concat ( find_type_elements ( type , e . children ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "spin_4", ":", "interval", "property", "typo", ".", "Add", "test", "."], "add_tokens": "interval : 10 ,", "del_tokens": "inteval : 10 ,", "commit_type": "fix"}
{"commit_tokens": ["Change", "a", "few", "CLI", "options"], "add_tokens": "method_option :tayfile , :type => :string , method_option 'built-directory' , :type => :string , :default => 'build' , build_dir = File . expand_path ( options [ 'built-directory' ] , File . dirname ( tayfile_path ) ) method_option 'output-dir' , :type => :string , :default => 'build' , method_option :tayfile , :type => :string , builder = Builder . new ( spec , File . dirname ( tayfile_path ) , File . expand_path ( options [ 'output-dir' ] ) )", "del_tokens": "method_option 'tayfile' , :type => :string , method_option :built_directory , :type => :string , :default => 'build' , build_dir = File . expand_path ( options [ :built_directory ] , File . dirname ( tayfile_path ) ) method_option :output_dir , :type => :string , :default => 'build' , method_option 'tayfile' , :type => :string , builder = Builder . new ( spec , File . dirname ( tayfile_path ) , File . expand_path ( options [ :output_dir ] ) )", "commit_type": "change"}
{"commit_tokens": ["Create", "producer", "by", "connection", "name", "too"], "add_tokens": "BackgroundBunnies :: configure ( :default , connection ) producer = BackgroundBunnies :: Workers :: IncrementCounter . create_producer :default", "del_tokens": "connection . start producer = BackgroundBunnies :: Workers :: IncrementCounter . create_producer connection", "commit_type": "create"}
{"commit_tokens": ["move", "prefix", "builder", "to", "core_controller"], "add_tokens": "lookup_context . prefixes = Wallaby :: PrefixesBuilder . new ( self ) . build", "del_tokens": "lookup_context . prefixes = self . class :: PrefixesBuilder . new ( self ) . build", "commit_type": "move"}
{"commit_tokens": ["Fix", "serve_index", "in", "case", "of", "error"], "add_tokens": "return send_error ( e . message )", "del_tokens": "return send_error ( e . message , 500 , true )", "commit_type": "fix"}
{"commit_tokens": ["made", "code", "convention", "refactoring", "in", "email_spec", ".", "rb"], "add_tokens": "before do end describe \".find\" do before do stub_const ( \"MailClient\" , double ) allow ( MailClient ) . to receive ( :by_email ) . and_return ( mail_client ) allow ( mail_client ) . to receive ( :find_mail ) . and_return ( messages ) allow ( message ) . to receive ( :subject ) . and_return ( 'test_subject' ) end context \"when messages.first present\" do let ( :messages ) { [ message ] } it { expect ( subject ) . to be_kind_of ( Email ) } end context \"when messages.first not present\" do let ( :messages ) { [ ] } it do end", "del_tokens": "before do end describe \".find\" do before do stub_const ( \"MailClient\" , double ) allow ( MailClient ) . to receive ( :by_email ) . and_return ( mail_client ) allow ( mail_client ) . to receive ( :find_mail ) . and_return ( messages ) allow ( message ) . to receive ( :subject ) . and_return ( 'test_subject' ) end context \"when messages.first present\" do let ( :messages ) { [ message ] } it { expect ( subject ) . to be_kind_of ( Email ) } end context \"when messages.first not present\" do let ( :messages ) { [ ] } it do end", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "case", "where", "you", "don", "t", "send", "an", "ssl", "option", "in", "that", "case", "it", "just", "Hash", ".", "new"], "add_tokens": "@ssl = options [ :ssl ] . nil? ? Hash . new : options [ :ssl ]", "del_tokens": "@ssl = options [ :ssl ]", "commit_type": "add"}
{"commit_tokens": ["Add", "(", "unimplemented", ")", "shippable", "flag", "to", "OLI"], "add_tokens": "attribute :freeform , Boolean attribute :shippable , Boolean", "del_tokens": "attribute :freeform , Boolean", "commit_type": "add"}
{"commit_tokens": ["moving", "ssh", "helper", "methods", "to", "another", "file", "cleaning"], "add_tokens": "", "del_tokens": "define_precursors end def define_precursors", "commit_type": "move"}
{"commit_tokens": ["fixed", "bug", "in", "datacite_json", "writer"], "add_tokens": "VERSION = \"0.9.87\"", "del_tokens": "VERSION = \"0.9.86\"", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "unregister_static_dir!", "and", "unregister_static_dirs!", "."], "add_tokens": "StaticPaths . paths . reject! { | dir | dir == path } StaticPaths . paths . reject! { | dir | self . static_paths . include? ( dir ) }", "del_tokens": "StaticPaths . reject! { | dir | dir == path } StaticPaths . reject! { | dir | self . static_paths . include? ( dir ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "compose", "method"], "add_tokens": "result = if result . is_a? ( Enumerable ) && ! result . is_a? ( Hash )", "del_tokens": "result = if result . is_a? ( Enumerable )", "commit_type": "fix"}
{"commit_tokens": ["fix", "skipping", "warden", "and", "devise", ".", "mapping", "request", "headers"], "add_tokens": "warden devise . mapping", "del_tokens": "Warden Devise . mapping", "commit_type": "fix"}
{"commit_tokens": ["Make", "all", "paths", "relative", "to", "the", "working", "directory"], "add_tokens": "root = Pathname . getwd file = Pathname ( string ) . expand_path . relative_path_from ( root ) path [ short ] . relative_path_from ( root )", "del_tokens": "file = Pathname ( string ) . expand_path path [ short ]", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "OpenCNAM", "API", "v2"], "add_tokens": "module Opencnam SUPPORTED_PROTOCOLS = %w( http https ) def process_response ( response , name_only ) if response . kind_of? ( Net :: HTTPOK ) return { :name => response . body } if name_only # Parse JSON to Hash hash = JSON . parse ( response . body , :symbolize_names => true ) # Convert hash[:created] and hash[:updated] from String to Time hash . merge ( { :created => DateTime . iso8601 ( hash [ :created ] ) . to_time , :updated => DateTime . iso8601 ( hash [ :updated ] ) . to_time , } ) else raise OpencnamError . new response . message end end # Converts protocol to string, stripped and downcased. Returns protocol # if protocol is supported. def sanitize_protocol ( protocol ) protocol = protocol . to_s . strip . downcase return protocol if SUPPORTED_PROTOCOLS . include? ( protocol ) raise ArgumentError . new \"Only #{SUPPORTED_PROTOCOLS.join(', ')} allowed\"", "del_tokens": "module OpenCNAM def self . clean_phone_number ( number ) # Drop all characters except integers clean_number = number . to_s clean_number . tr! ( '^0-9' , '' ) clean_number = clean_number [ - 10 .. - 1 ] raise InvalidPhoneNumberError . new ( number ) if ! clean_number || clean_number . length < 10 clean_number", "commit_type": "add"}
{"commit_tokens": ["Add", "Filepreviews", "::", "Utils", ".", "validate_pages"], "add_tokens": "if metadata . class . eql? ( Array ) metadata . join ( ',' ) else metadata end end # Validates page parameters # @param pages [Array] page parameters # @return [String] page thumbnail parameters def validate_pages ( pages ) if ! ! ( pages =~ / , / ) || ! ! ( pages =~ / - / ) || pages . eql? ( 'all' ) || pages =~ / \\d / pages end", "del_tokens": "metadata . join ( ',' )", "commit_type": "add"}
{"commit_tokens": ["Adds", "rake", "task", "and", "DRYs", "up", "API"], "add_tokens": "Faraday . new ( :url => URL ) :history => History . data", "del_tokens": "connection = Faraday . new ( :url => URL ) do | faraday | faraday . request :url_encoded faraday . adapter Faraday . default_adapter end connection :history => History . data , :completed => Completed . data", "commit_type": "add"}
{"commit_tokens": ["Move", "valid", "response", "codes", "to", "a", "constant"], "add_tokens": "VALID_RESPONSE_CODES = [ 200 , 201 , 202 , 204 , 401 , 404 , 405 , 422 ] . freeze", "del_tokens": "expected_codes = [ 200 , 201 , 202 , 204 , 401 , 404 , 405 , 422 ]", "commit_type": "move"}
{"commit_tokens": ["adding", "more", "helper", "fns", "in", "db"], "add_tokens": "def hash_form ( keys_subset = nil ) full_hash = values pass_to_orm_instance ( name ) ? @orm_instance . send ( name , * args , & block ) : super pass_to_orm_instance ( name ) || super end def pass_to_orm_instance ( name ) SupportedOrmMethods . include? ( name ) end private :method_missing , :respond_to? , :pass_to_orm_instance SupportedOrmMethods = [ :values ] def hash_form ( ) @orm_instance . values ( ) hash = sequel_record . values hash . each_key { | k | hash . delete ( k ) if hash [ k ] . nil? } hash [ json_field ] = convert_json_to_hash? ( hash [ json_field ] ) end if opts [ :hash_form ] hash else sequel_record . set_values ( hash ) #TODO: this may not be needed since making changes anyways through side effect if changing hash new ( sequel_record )", "del_tokens": "def to_hash ( keys_subset = nil ) full_hash = super ( ) @orm_instance . respond_to? ( name ) ? @orm_instance . send ( name , * args , & block ) : super @orm_instance . respond_to? ( name ) || super private :method_missing , :respond_to? return new ( sequel_record ) ret = sequel_record . values ret . each_key { | k | ret . delete ( k ) if ret [ k ] . nil? } ret [ json_field ] = convert_json_to_hash? ( ret [ json_field ] ) ret", "commit_type": "add"}
{"commit_tokens": ["Move", "Librarian", "::", "Chef", "::", "Source", "::", "Path", "and", "Librarian", "::", "Chef", "::", "Source", "::", "Path", "into", "their", "own", "files", "."], "add_tokens": "require 'librarian/chef/source/path' require 'librarian/chef/source/git'", "del_tokens": "require 'librarian/source' require 'librarian/chef/source/local' require 'librarian/chef/particularity' module Librarian module Chef module Source class Path < Librarian :: Source :: Path include Particularity include Local end class Git < Librarian :: Source :: Git include Particularity include Local end end end end", "commit_type": "move"}
{"commit_tokens": ["Add", "save", "add_resource", "and", "remove_resource", "to", "Package"], "add_tokens": "attr_reader :opts , :errors , :profile , :dead_resources def resource_names update_resources! @resources . map { | res | res . name } alias :valid :valid? def add_resource ( resource ) resource = load_resource ( resource ) @resources . push ( resource ) begin self . validate resource rescue DataPackage :: ValidationError @resources . pop nil end end def remove_resource ( resource_name ) resource = get_resource ( resource_name ) @resources . reject! { | resource | resource . name == resource_name } resource def get_resource ( resource_name ) @resources . find { | resource | resource . name == resource_name } end def save ( target = @location ) update_resources! File . open ( target , \"w\" ) { | file | file << JSON . pretty_generate ( self ) } true end def property ( property , default = nil ) self [ property ] || default @dead_resources << resource nil end . compact!", "del_tokens": "attr_reader :opts , :errors , :profile def property ( property , default = nil ) self [ property ] || default def resource_exists? ( location ) @dead_resources . include? ( location ) def to_json self . to_json @dead_resources << resource [ 'path' ] end", "commit_type": "add"}
{"commit_tokens": ["Add", "errors", "for", "whitespace", "and", "quoting"], "add_tokens": "ERROR_MATCHERS = { \"Missing or stray quote\" => :quoting , \"Illegal quoting\" => :whitespace , \"Unclosed quoted field\" => :quoting , } rescue CSV :: MalformedCSVError => e type = fetch_error ( e ) build_errors ( type , current_line ) def fetch_error ( error ) e = error . message . match ( / ^([a-z ]+) (i|o)n line ([0-9]+) \\. $ /i ) ERROR_MATCHERS . fetch ( e [ 1 ] , :unknown_error ) end", "del_tokens": "rescue CSV :: MalformedCSVError false # [ # { # :type => :ragged_rows # :position => 1 # } # ]", "commit_type": "add"}
{"commit_tokens": ["Fixed", "intended", "behavior", "when", "special", "support", "is", "on"], "add_tokens": "rest << options . parse! ( args )", "del_tokens": "rest << \"--\" unless rest . empty? rest += options . parse! ( args )", "commit_type": "fix"}
{"commit_tokens": ["Updating", "README", "with", "include_deleted", "parameter", "for", "users_list"], "add_tokens": "# Set a room's topic. Useful for displaying statistics, important links, server status, you name it! # @param topic [String] The topic body. 250 characters max. # Undelete a user. They will be sent an email requiring them to click a link to reactivate the account.", "del_tokens": "# Set a room's topic. Useful for displaying statistics, important links, server status, you name it! # @param topic [String] The topic body. 250 characters max. # Undelete a user. They will be sent an email requiring them to click a link to reactivate the account.", "commit_type": "update"}
{"commit_tokens": ["Allow", "created", "objects", "to", "be", "decorated", "via", "a", "callable", "option", "."], "add_tokens": "wrap_object = html_options . delete ( :wrap_object ) if wrap_object . respond_to? ( :call ) new_object = wrap_object . call ( create_object ( f , association ) ) else new_object = create_object ( f , association ) end", "del_tokens": "new_object = create_object ( f , association )", "commit_type": "allow"}
{"commit_tokens": ["changed", "the", "shutdown", "to", "poweroff", "instead", "of", "halt"], "add_tokens": ":shutdown_cmd => \"shutdown -P now\" ,", "del_tokens": ":shutdown_cmd => \"shutdown -H now\" ,", "commit_type": "change"}
{"commit_tokens": ["Created", "index", "page", "to", "show", "all", "result", "summaries"], "add_tokens": "\"url\" => @path . to_p . file_name . to_s + '.html' , \"source\" => File . readlines ( @path ) ,", "del_tokens": "lines = File . readlines ( @path ) #lines.collect! {|l| l.gsub(' ', '&nbsp;')} \"source\" => lines ,", "commit_type": "create"}
{"commit_tokens": ["changing", "the", "development", "-", "reloading", "before_filter", "to", "hopefully", "avoid", "defining", "the", "ApplicationController", "constant", "before", "it", "s", "time"], "add_tokens": "VERSION = \"0.1.2\"", "del_tokens": "VERSION = \"0.1.1\"", "commit_type": "change"}
{"commit_tokens": ["Updated", "edit", "form", "with", "formpatch", "."], "add_tokens": "VERSION = \"0.5.5\"", "del_tokens": "VERSION = \"0.5.0\"", "commit_type": "update"}
{"commit_tokens": ["Move", "linters", "from", "TravisCI", "to", "Code", "Climate"], "add_tokens": "# frozen_string_literal: true USERS_NEW_TEMPLATE = <<-HTML", "del_tokens": "USERS_NEW_TEMPLATE = <<-HTML . freeze", "commit_type": "move"}
{"commit_tokens": ["use", "fiddle", "instead", "of", "DL", "if", "we", "find", "it"], "add_tokens": "begin require 'fiddle' rescue LoadError require 'dl' end if defined? ( Fiddle ) :: Fiddle . dlopen ( libpath ) else :: DL . dlopen ( libpath ) end if defined? ( Fiddle ) :: Fiddle . dlopen ( libpath ) else :: DL . dlopen ( libpath ) end", "del_tokens": "require 'dl' :: DL . dlopen ( libpath ) :: DL . dlopen ( libpath )", "commit_type": "use"}
{"commit_tokens": ["Added", "test", "for", "facet", "/", "net_http", "rework", "lambda_runtime_request", "method"], "add_tokens": "# HTTP requests to AWS Lambda Ruby Runtime will have the address and port # matching the value set in ENV['AWS_LAMBDA_RUNTIME_API'] def lambda_runtime_request? ENV [ 'AWS_LAMBDA_RUNTIME_API' ] == \"#{address}:#{port}\" if xray_sampling_request? ( req ) || lambda_runtime_request?", "del_tokens": "# HTTP requests to AWS Lambda Ruby Runtime will begin with the # value set in ENV['AWS_LAMBDA_RUNTIME_API'] def lambda_runtime_request? ( req ) ENV [ 'AWS_LAMBDA_RUNTIME_API' ] && req . uri && req . uri . to_s . start_with? ( 'http://' + ENV [ 'AWS_LAMBDA_RUNTIME_API' ] + '/' ) if xray_sampling_request? ( req ) || lambda_runtime_request? ( req )", "commit_type": "add"}
{"commit_tokens": ["Fix", "virtual", "group", "search", "."], "add_tokens": "include Filter @ldap . virtual_attributes . virtual_membership", "del_tokens": "@ldap . virual_attributes . virtual_membership", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "handling", "nil", "offset"], "add_tokens": "Date . parse ( date ) Time . parse ( time ) DateTime . parse ( \"#{date}T#{time}#{offset}\" )", "del_tokens": "Date . parse ( tpitDT [ \"date\" ] ) Time . parse ( tpitDT [ \"time\" ] ) DateTime . parse ( tpitDT [ \"date\" ] + \"T\" + tpitDT [ \"time\" ] + tpitDT [ \"utc_offset\" ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "underscores", "to", "large", "numeric", "literal", "to", "improve", "readability", "."], "add_tokens": "@timeout ||= 31_557_600 # A year should be enough?", "del_tokens": "@timeout ||= 31557600 # A year should be enough?", "commit_type": "add"}
{"commit_tokens": ["Fix", "rendering", "of", "hidden", "fields", "."], "add_tokens": "add_hidden_fields_output ( output , hidden_fields , normal_row , row_ender ) def add_hidden_fields_output ( output , hidden_fields , normal_row , row_ender ) # :nodoc:", "del_tokens": "add_hidden_fields_output ( output , hidden_fields , row_ender ) def add_hidden_fields_output ( output , hidden_fields , row_ender ) # :nodoc:", "commit_type": "fix"}
{"commit_tokens": ["adds", "the", "concern", "aproach", "and", "explanation"], "add_tokens": "# include the magic (setup and parse -> test method translation), see there include ParserHelper @string_input = '42 ' @string_input = 'foo ' @string_input = <<HERE", "del_tokens": "include ParserTest # this creates test methods dynamically , one for each file in runners directory def self . runnable_methods tests = [ ] public_instance_methods ( true ) . grep ( / ^parse_ / ) . map ( & :to_s ) . each do | parse | [ \"ast\" , \"transform\" , \"parse\" ] . each do | what | name = \"parse_#{what}\" tests << name self . send ( :define_method , name ) do send ( parse ) send ( \"check_#{what}\" ) end end end tests end @input = '42 ' @input = 'foo ' @input = <<HERE", "commit_type": "add"}
{"commit_tokens": ["Fixed", "improper", "require", "path", "for", "local_asset_pipleline", "plugin"], "add_tokens": "require 'octopress-ink/plugins/local_asset_pipeline'", "del_tokens": "require 'octopress-ink/plugins/asset_pipeline'", "commit_type": "fix"}
{"commit_tokens": ["fixed", "Validation", "for", "encrypted", "data", "bag", "secret", "should", "expand", "path", "https", ":", "//", "github", ".", "com", "/", "mattray", "/", "spiceweasel", "/", "issues", "/", "13"], "add_tokens": "if secret && ! File . exists? ( File . expand_path ( secret ) ) && ! Spiceweasel :: Config [ :novalidation ]", "del_tokens": "if secret && ! File . exists? ( secret ) && ! Spiceweasel :: Config [ :novalidation ]", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "few", "bugs", "in", "rcat", "and", "the", "app", ".", "rb", "."], "add_tokens": "puts e if $DEBUG", "del_tokens": "puts e", "commit_type": "fix"}
{"commit_tokens": ["Add", "DeliveryBoy", ".", "clear_buffer", "method", "."], "add_tokens": "clear_buffer def clear_buffer sync_producer . clear_buffer end", "del_tokens": "sync_producer . clear_buffer", "commit_type": "add"}
{"commit_tokens": ["Making", "params", "strict", "by", "default", "."], "add_tokens": "method_params [ method_name . to_sym ] = ( @_next_params || Params . new ( strict : false ) ) . freeze", "del_tokens": "method_params [ method_name . to_sym ] = ( @_next_params || Params . new ) . freeze", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "clear", "Filter", "button", "to", "the", "filters", "area"], "add_tokens": "< div class = 'table-me' > < div class = \"table-me-table\" > #{table_pagination.pagination_info} < table > < thead > < tr > #{create_header}</tr> < / thead > < tbody > #{table_rows} < / tbody > < / table > #{table_pagination.pagination_controls} < / div > #{table_builder.clear_filter}", "del_tokens": "< div class = \"table-me-table\" > #{table_pagination.pagination_info} < table > < thead > < tr > #{create_header}</tr> < / thead > < tbody > #{table_rows} < / tbody > < / table > #{table_pagination.pagination_controls}", "commit_type": "add"}
{"commit_tokens": ["Added", "contracts", "for", "non", "-", "tracking", "methods"], "add_tokens": "require 'contracts' include Contracts Contract String , Or [ String , Bool , Num , nil ] => Or [ String , Bool , Num , nil ] Contract Hash => Hash Contract Or [ Hash , nil ] , Bool , String , String => Or [ String , nil ]", "del_tokens": "@context [ 'test' ] = 9", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "to", "request", "objects", "."], "add_tokens": ":form_recipients , :form_sender , :form_captcha , :form_headers , :form_appendable ] write_inheritable_array :form_appendable , [ ]", "del_tokens": ":form_recipients , :form_sender , :form_captcha , :form_headers ]", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "temporary", "filename", "generation", "method", "for", "the", "atomic", "output", "mode", "."], "add_tokens": "# is the target filename with `.handbraking` inserted before the # extension. Any `:overwrite` checking will be applied to the # target filename both before and after the transcode happens # (the temporary file will always be overwritten). This option # is intended to aid in writing automatically resumable batch # scripts. partial_filename ( filename ) def partial_filename ( name ) dot_at = name . rindex '.' if dot_at name . dup . insert dot_at , '.handbraking' else name + '.handbraking' end end private :partial_filename", "del_tokens": "# is the target filename with `.handbrake` appended. Any # `:overwrite` checking will be applied to the target filename # both before and after the transcode happens (the temporary # file will always be overwritten). This option is intended to # aid in writing automatically resumable batch scripts. \"#{filename}.handbrake\"", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "adding", "metadata", "to", "documents", "."], "add_tokens": "@source = extract_metadata ( source . to_s ) @current = @source # Return a hash with the extracted metadata # def metadata @metadata end def extract_metadata ( source ) @metadata = { } source . each_line . drop_while do | line | next false if line !~ / ^# \\+ ([a-z_]+): (.*) / key , value = $1 , $2 @metadata [ key . to_sym ] = value end . join ( '' ) end", "del_tokens": "@current = @source = source . to_s", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "list", "command", "and", "a", "--", "force", "option", "to", "the", "init", "command"], "add_tokens": "def list ( filter = nil )", "del_tokens": "def list", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "add", "via", "FormBuilder", "instead", "of", "add_form", "."], "add_tokens": "def initialize ( type , name , label , html_attributes = { } )", "del_tokens": "def initialize ( name , type , label , html_attributes = { } )", "commit_type": "change"}
{"commit_tokens": ["Make", "deploy", "subcommand", "work", "."], "add_tokens": "parameter \"TEMPLATE\" , \"CloudFormation template (.json)\" , :attribute_name => :template_file template = File . read ( template_file ) stack . deploy ( template )", "del_tokens": "parameter \"TEMPLATE\" , \"CloudFormation template (.json)\" , :attribute_name => :template parameter \"PARAMETERS\" , \"CloudFormation parameters (.json)\" , :attribute_name => :parameters params = JSON . parse ( parameters ) stack . create ( template , { } )", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "rounding", "was", "splitting", "up", "the", "results", "more", "than", "I", "would", "like", "using", "rational", "numbers", "now", "to", "match", "to", "16", "/", "9", "."], "add_tokens": "require 'mixins' # I get back everything here, I'm more interested in accurate results. # also, I rationalize the number to 'scrub' near-like floats into the same known ratios, ie: 16/9, 4/3. new_f = ErnieBrodeur :: DM :: Models :: Image . all ( :fields => [ :filename , :ratio ] ) . select { | x | x . ratio . rationalize ( 0.01 ) == 1.77 . rationalize ( 0.01 ) } . rand . filename def stats e = ErnieBrodeur :: DM :: Models :: Image . all sizes = e . map { | x | x . ratio } . uniq . sort end", "del_tokens": "new_f = ErnieBrodeur :: DM :: Models :: Image . all ( :fields => [ :filename , :ratio ] , :ratio => 1.778 ) . rand . filename", "commit_type": "fix"}
{"commit_tokens": ["use", "match_array", "to", "ignore", "order", "of", "@yardoc", ".", "files"], "add_tokens": "expect ( @yardoc . files ) . to match_array ( %w{ mrblib/**/*.rb src/**/*.c include/**/*.h } )", "del_tokens": "expect ( @yardoc . files ) . to eq %w{ mrblib/**/*.rb src/**/*.c include/**/*.h }", "commit_type": "use"}
{"commit_tokens": ["add", "pending", "spec", "for", "CLIENT", "socket"], "add_tokens": "Given ( :socket ) { described_class . new } it \"instanciates\" do begin socket flunk \"REMOVE ME and enable code below\" rescue skip \"ZMQ_CLIENT disabled\" end end", "del_tokens": "# TODO", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "around", "the", "apn", "certificate"], "add_tokens": "apn . tap do | apn | File . join ( :: Rails . root , 'config' , 'certificates' , \"push-notification-#{APNCertificate.environment_string}.pem\" ) ) if :: Rails . env . production? if :: Rails . env . production?", "del_tokens": "APNCertificate . apn . tap do | apn | File . join ( Rails . root , 'config' , 'certificates' , \"push-notification-#{APNCertificate.environment_string}.pem\" ) ) if Rails . env . production? if Rails . env . production?", "commit_type": "add"}
{"commit_tokens": ["Add", "step", ".", "Start", "break", "."], "add_tokens": "class Trepan :: Command :: SetBreakPointCommand < Trepan :: Command ALIASES = %w( b brk ) CATEGORY = 'running' NAME = File . basename ( __FILE__ , '.rb' ) HELP = <<-HELP Trepan . start :4 SHORT_HELP = 'Set a breakpoint at a point in a method' arg_str = args [ 1 .. - 1 ] . join ( ' ' ) m = / ([A-Z] \\w *(?:::[A-Z] \\w *)*)([.#])( \\w +)(?:[:]( \\d +))? / . match ( arg_str ) errmsg \"Unrecognized position: '#{arg_str}'\" errmsg \"Unable to find class/module: #{m[1]}\" bp = @proc . dbgr . set_breakpoint_method args . strip , method , line if confirm ( 'Would you like to defer this breakpoint to later?' , false ) @proc . dbgr . add_deferred_breakpoint ( klass_name , which , name , line ) msg 'Deferred breakpoint created.' else msg 'Not confirmed.'", "del_tokens": "class RBDebug :: Command :: SetBreakPoint < RBDebug :: Command pattern \"b\" , \"break\" , \"brk\" help \"Set a breakpoint at a point in a method\" ext_help <<-HELP RBDebug . start :4 m = / ([A-Z] \\w *(?:::[A-Z] \\w *)*)([.#])( \\w +)(?:[:]( \\d +))? / . match ( args ) error \"Unrecognized position: '#{args}'\" error \"Unable to find class/module: #{m[1]}\" bp = @debugger . set_breakpoint_method args . strip , method , line answer = ask \"Would you like to defer this breakpoint to later? [y/n] \" if answer . strip . downcase [ 0 ] == ?y @debugger . add_deferred_breakpoint ( klass_name , which , name , line ) info \"Deferred breakpoint created.\"", "commit_type": "add"}
{"commit_tokens": ["Use", "consistent", "names", "when", "referring", "to", "partitions"], "add_tokens": "@logger . warn \"Replica not available for #{topic.topic_name}/#{partition.partition_id}\"", "del_tokens": "@logger . warn \"Replica not available for topic #{topic.topic_name}, partition #{partition.partition_id}\"", "commit_type": "use"}
{"commit_tokens": ["Update", "Wanikani", "::", "Level", "to", "be", "explicit", "instead", "of", "using", "method_missing"], "add_tokens": "# @return [Hash] progress and total of radicals and Kanji for the user's current level. # Gets the user's full list of radicals and stats. # # @param levels [Integer, Array<Integer>] a specific level or array of # levels to fetch items for. # @return [Hash] radicals with the user's stats. def radicals_list ( levels = nil ) return level_items_list ( \"radicals\" , levels ) end # Gets the user's full list of kanji and stats. # # @param levels [Integer, Array<Integer>] a specific level or array of # levels to fetch items for. # @return [Hash] kanji with the user's stats. def kanji_list ( levels = nil ) return level_items_list ( \"kanji\" , levels ) end # Gets the user's full list of vocabulary and stats. # # @param levels [Integer, Array<Integer>] a specific level or array of # levels to fetch items for. # @return [Hash] vocabulary with the user's stats. def vocabulary_list ( levels = nil ) return level_items_list ( \"vocabulary\" , levels ) end # @return [Hash] full response from the Level Progression API call. # Fetches the specified item type list from WaniKani's API # # @param type [String] The type of item to fetch. # @param levels [Integer, Array<Integer>] a specific level or array of # levels to fetch items for. # @return [Hash] list of items of the specified type and levels. def level_items_list ( type , levels ) response = api_response ( type , levels )", "del_tokens": "# @return [Hash] Progress and total of radicals and Kanji for the user's current level. # @return [Hash] Full response from the Level Progression API call. def method_missing ( name , * args ) super unless [ :radicals_list , :kanji_list , :vocabulary_list ] . include? ( name ) levels = args . push response = api_response ( name . to_s . gsub ( \"_list\" , \"\" ) , levels )", "commit_type": "update"}
{"commit_tokens": ["Move", "error", "to", "end", "of", "log", "line"], "add_tokens": "logf \"ERROR Transmitting Message on %{routing_key} -> %{payload} : %{error}\" , routing_key : routing_key , payload : payload , error : e , at : :error", "del_tokens": "logf \"ERROR %{error} Transmitting Message on %{routing_key} -> %{payload}\" , error : e , routing_key : routing_key , payload : payload , at : :error", "commit_type": "move"}
{"commit_tokens": ["Fix", "a", "couple", "type", "declarations", "."], "add_tokens": "attach_function :inotify_add_watch , [ :int , :string , :uint32 ] , :int attach_function :inotify_rm_watch , [ :int , :uint32 ] , :int", "del_tokens": "attach_function :inotify_add_watch , [ :int , :string , :int ] , :int attach_function :inotify_rm_watch , [ :int , :int ] , :int", "commit_type": "fix"}
{"commit_tokens": ["Remove", "Arabic", "::", "SentenceBoundaryPunctation", "class"], "add_tokens": "txt = txt . apply ( ReplaceColonBetweenNumbersRule , ReplaceNonSentenceBoundaryCommaRule ) txt . scan ( SENTENCE_BOUNDARY )", "del_tokens": "Arabic :: SentenceBoundaryPunctuation . new ( text : txt ) . split class SentenceBoundaryPunctuation < PragmaticSegmenter :: SentenceBoundaryPunctuation def split txt = replace_non_sentence_boundary_punctuation ( text ) txt . scan ( SENTENCE_BOUNDARY ) end private def replace_non_sentence_boundary_punctuation ( txt ) txt . apply ( ReplaceColonBetweenNumbersRule , ReplaceNonSentenceBoundaryCommaRule ) end end", "commit_type": "remove"}
{"commit_tokens": ["Fix", "1904", "-", "based", "date", "handling", "(", "don", "t", "need", "the", "1900", "leap", "year", "bug", "adjustment", "code", ")", "."], "add_tokens": "compare_date = DateTime . parse ( 'January 1, 1904' ) date . ajd - compare_date . ajd # add one day to compare date for erroneous 1900 leap year compatibility # only for 1900 based dates! date . ajd + 1 - compare_date . ajd compare_date = DateTime . parse ( 'January 1, 1904' ) compare_date + num # subtract one day to compare date for erroneous 1900 leap year compatibility # only for 1900 based dates! compare_date - 1 + num", "del_tokens": "compare_date = DateTime . parse ( 'December 31, 1903' ) # add one day to compare date for erroneous 1900 leap year compatibility date . ajd + 1 - compare_date . ajd compare_date = DateTime . parse ( 'December 31, 1903' ) # subtract one day to compare date for erroneous 1900 leap year compatibility compare_date - 1 + num", "commit_type": "fix"}
{"commit_tokens": ["Adding", "the", "beginnings", "of", "the", "people", "api"], "add_tokens": "require 'harvest/robust_client' %w( clients contacts projects tasks people ) . each { | a | require \"harvest/#{a}\" } %w( client contact project task person ) . each { | a | require \"harvest/#{a}\" } @api_methods = %w( clients contacts projects tasks people ) def people @people ||= Harvest :: People . new ( credentials ) end", "del_tokens": "require 'harvest/clients' require 'harvest/contacts' require 'harvest/projects' require 'harvest/tasks' require 'harvest/client' require 'harvest/contact' require 'harvest/project' require 'harvest/task' require 'harvest/robust_client' @api_methods = %w( clients contacts projects tasks )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "RuleParser", "spec", "to", "use", "start", "rule", "return", "value"], "add_tokens": "productions = p . parse ( s ) productions . length . should == 4 productions [ 0 ] . should == [ :expression , [ :expression , '+' , :expression ] ] productions [ 1 ] . should == [ :expression , [ :expression , '-' , :expression ] ] productions [ 2 ] . should == [ :expression , [ :expression , '*' , :expression ] ] productions [ 3 ] . should == [ :expression , [ :expression , '/' , :expression ] ]", "del_tokens": "p . parse ( s ) p . productions . length . should == 4 p . productions [ 0 ] . should == [ :expression , [ :expression , '+' , :expression ] ] p . productions [ 1 ] . should == [ :expression , [ :expression , '-' , :expression ] ] p . productions [ 2 ] . should == [ :expression , [ :expression , '*' , :expression ] ] p . productions [ 3 ] . should == [ :expression , [ :expression , '/' , :expression ] ]", "commit_type": "fix"}
{"commit_tokens": ["Remove", "postprocessors", "and", "keep", "right", "order"], "add_tokens": "preprocessors = environment . preprocessors ( content_type ) # Remove all postprocessors and engines except ERB to return unprocessed source file processors = preprocessors + ( allowed_engines & attributes . engines ) processors = preprocessors + ( allowed_engines & attributes . engines )", "del_tokens": "# Remove all engine processors except ERB to return unprocessed source file processors = attributes . processors - ( attributes . engines - allowed_engines ) processors = attributes . processors - ( attributes . engines - allowed_engines )", "commit_type": "remove"}
{"commit_tokens": ["updating", "the", "api", "to", "use", "new", "job", "queueing", "methods"], "add_tokens": "def enqueue ( job , params ) Queue . enqueue ( job , params ) Queue . dequeue ( args ) def work ( job ) klass = job . klass method = job . method klass . send ( method )", "del_tokens": "def enqueue ( * args ) queue . enqueue ( args ) queue . dequeue ( args ) def queue @queue ||= Queue . setup", "commit_type": "update"}
{"commit_tokens": ["implemented", "basic", "decode", "process", "for", "bmp", "files"], "add_tokens": "# read bmp header header = data [ 0 .. 13 ] dib_header = data [ 14 .. 54 ] magic = header [ 0 .. 1 ] # check magic unless magic == \"BM\" raise UnableToDecodeException end pixeldata_offset = header [ 10 .. 13 ] . unpack ( \"L\" ) . first width = dib_header [ 4 .. 7 ] . unpack ( \"L\" ) . first height = dib_header [ 8 .. 11 ] . unpack ( \"L\" ) . first # create image object image = Image . new ( width , height ) # read pixel data width . times do | x | height . times do | y | offset = pixeldata_offset + ( y * width ) + x color_triplet = data [ offset .. offset + 2 ] image [ x , y ] = Color . from_rgb ( color_triplet [ 0 ] , color_triplet [ 1 ] , color_triplet [ 2 ] ) end end image", "del_tokens": "Image . new ( 10 , 10 )", "commit_type": "implement"}
{"commit_tokens": ["Added", "spec", "for", "testing", "resources", "through", "Sync", "Api", "."], "add_tokens": "attr_accessor :connection", "del_tokens": "attr_reader :connection private attr_writer :connection", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "case", "source", ".", "kind_of?", "(", "Hash", ")"], "add_tokens": "# if extend_existig_arrays == true && destination.kind_of?(Array) && source element is neither array nor hash, push source to destionation # if extend_existig_arrays == true && destination.kind_of?(Array) && source.kind_of(Hash), push source to destionation hash_src = { \"property\" => { :number => \"3\" } } hash_dst = { \"property\" => [ { :number => \"1\" } , { :number => \"2\" } ] } DeepMerge :: deep_merge! ( hash_src , hash_dst , :extend_existing_arrays => true ) assert_equal ( { \"property\" => [ { :number => \"1\" } , { :number => \"2\" } , { :number => \"3\" } ] } , hash_dst )", "del_tokens": "# if destination element is an array and source element is not, push source element to destination array", "commit_type": "add"}
{"commit_tokens": ["Fixing", "incorrect", "passing", "of", "String", "representation", "of", "Dependency", "constraint", "instead", "of", "VersionConstraint", "in", "spec_helper", "."], "add_tokens": "cb_version [ 'value' ] . each_pair do | dep_name , constraint_str | constraint = DepSelector :: VersionConstraint . new ( constraint_str )", "del_tokens": "cb_version [ 'value' ] . each_pair do | dep_name , constraint |", "commit_type": "fix"}
{"commit_tokens": ["Add", "homogenous", "variable", "arity", "support", "."], "add_tokens": "( check v ) ? v : ( raise \"Value #{v.inspect} does not match contract #{self}\" ) # Checks rest args after first n args (positional) against contract c. def rest ( n , c ) ctc = RDL . convert c arg_name = define_method_gensym ( \"rest\" ) do | * args , & blk | raise \"At least #{n} arguments expected, got #{args.length}\" if args . length < n args [ n .. - 1 ] = args [ n .. - 1 ] . map { | i | ctc . apply i } { args : args , block : blk } end pre do | * args , & blk | self . __send__ arg_name , * args , & blk end end", "del_tokens": "( check v ) ? v : ( raise \"Value #{v} does not match contract #{self}\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "step", "to", "view", "and", "accept", "a", "project", "s", "license", "to", "reconfigure", "command", ".", "This", "step", "can", "be", "skipped", "by", "passing", "--", "accept", "-", "license", "command", "line", "option", "to", "reconfigure", "."], "add_tokens": "# For license checks require 'io/console' require 'io/wait' :arity => 2 def reconfigure ( * args ) # args being passed to this command does not include the ones that are # starting with \"-\". See #is_option? method. If it is starting with \"-\" # then it is treated as a option and we need to look for them in ARGV. check_license_acceptance ( ARGV . include? ( \"--accept-license\" ) ) def check_license_acceptance ( override_accept = false ) license_guard_file_path = File . join ( data_path , \".license.accepted\" ) # If the project does not have a license we do not have # any license to accept. return unless File . exist? ( project_license_path ) if ! File . exist? ( license_guard_file_path ) if override_accept || ask_license_acceptance FileUtils . mkdir_p ( data_path ) FileUtils . touch ( license_guard_file_path ) else log \"Please accept the software license agreement to continue.\" exit ( 1 ) end end end def ask_license_acceptance log \"To use this software, you must agree to the terms of the software license agreement.\" if ! STDIN . tty? log \"Please view and accept the software license agreement, or pass --accept-license.\" exit ( 1 ) end log \"Press any key to continue.\" user_input = STDIN . getch user_input << STDIN . getch while STDIN . ready? # No need to check for user input system ( \"less #{project_license_path}\" ) loop do log \"Type 'yes' to accept the software license agreement, or anything else to cancel.\" user_input = STDIN . gets . chomp . downcase case user_input when \"yes\" return true else log \"You have not accepted the software license agreement.\" return false end end end def project_license_path File . join ( base_path , \"LICENSE\" ) end", "del_tokens": ":arity => 1 def reconfigure ( exit_on_success = true )", "commit_type": "add"}
{"commit_tokens": ["added", "new", "exception", "for", "values", "that", "cannot", "be", "set", "for", "a", "certain", "property"], "add_tokens": "[ :notify ] => lambda { | v | i = NOTIFY_LEVELS . index ( v ) i or raise Exception :: InvalidPropertyValue . new ( v . to_s ) } ,", "del_tokens": "[ :notify ] => lambda { | v | NOTIFY_LEVELS . index ( v ) } ,", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "strip", "on", "urls", "-", "making", "the", "head", "method", "more", "robust", "on", "redirects", "and", "bringing", "it", "closer", "to", "the", "get", "method", "."], "add_tokens": "uri = Addressable :: URI . parse ( url )", "del_tokens": "uri = Addressable :: URI . parse ( url . strip )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "some", "simple", "instance", "variable", "caching", "."], "add_tokens": "@extractors ||= Cocaine :: CommandLine . new ( usable_executable_path_for ( 'youtube-dl' ) , '--list-extractors' ) . run . split ( \"\\n\" ) @binary_version ||= Cocaine :: CommandLine . new ( usable_executable_path_for ( 'youtube-dl' ) , '--version' ) . run . chomp", "del_tokens": "Cocaine :: CommandLine . new ( usable_executable_path_for ( 'youtube-dl' ) , '--list-extractors' ) . run . split ( \"\\n\" ) Cocaine :: CommandLine . new ( usable_executable_path_for ( 'youtube-dl' ) , '--version' ) . run . chomp", "commit_type": "add"}
{"commit_tokens": ["Add", "publish", "method", "to", "Broker", "and", "Hutch"], "add_tokens": "Hutch . connect @worker = Hutch :: Worker . new ( Hutch . broker , Hutch . consumers )", "del_tokens": "broker = Hutch :: Broker . new broker . connect @worker = Hutch :: Worker . new ( broker , Hutch . consumers )", "commit_type": "add"}
{"commit_tokens": ["Make", "JSONAPI", "::", "Utils#", "(", "filter|sort", ")", "_params", "public"], "add_tokens": "def filter_params @_filter_params ||= if params [ :filter ] . is_a? ( Hash ) params [ :filter ] . keys . each_with_object ( { } ) do | resource , hash | hash [ resource ] = params [ :filter ] [ resource ] end end end def sort_params @_sort_params ||= if params [ :sort ] . present? params [ :sort ] . split ( ',' ) . each_with_object ( { } ) do | criteria , hash | order , field = criteria . match ( / ( \\- ?)( \\w +) /i ) [ 1 .. 2 ] hash [ field ] = order == '-' ? :desc : :asc end end end", "del_tokens": "def filter_params @_filter_params ||= params [ :filter ] . keys . each_with_object ( { } ) do | resource , hash | hash [ resource ] = params [ :filter ] [ resource ] end end def sort_params @_sort_params ||= params [ :sort ] . split ( ',' ) . each_with_object ( { } ) do | criteria , hash | order , field = criteria . match ( / ( \\- ?)( \\w +) /i ) [ 1 .. 2 ] hash [ field ] = order == '-' ? :desc : :asc end end", "commit_type": "make"}
{"commit_tokens": ["fixed", "class", "name", "of", "test", "class", "(", "copy", "&", "past", "error", "=", "D", ")"], "add_tokens": "class PrefixesTest < ActiveSupport :: TestCase", "del_tokens": "class SimpleEnumTest < ActiveSupport :: TestCase", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "few", "more", "mongo", "mapper", "extension", "tests"], "add_tokens": "person = MongoMapperPerson . create assert_equal person , MongoMapperPerson . _t_find ( person . id ) transaction_1 = ActiveRecordTransaction . create transaction_2 = ActiveRecordTransaction . create transaction_3 = ActiveRecordTransaction . create person = MongoMapperPerson . create person . _t_associate_many ( :active_record_transactions , [ transaction_1 . id , transaction_2 . id , transaction_3 . id ] ) assert_set_equal [ transaction_1 . id , transaction_2 . id , transaction_3 . id ] , person . _t_active_record_transaction_ids transaction_1 = ActiveRecordTransaction . create transaction_2 = ActiveRecordTransaction . create transaction_3 = ActiveRecordTransaction . create person = MongoMapperPerson . create person . _t_associate_many ( :active_record_transactions , [ transaction_1 . id , transaction_2 . id , transaction_3 . id ] ) assert_set_equal [ transaction_1 . id , transaction_2 . id , transaction_3 . id ] , person . _t_get_associate_ids ( :active_record_transactions )", "del_tokens": "@person = MongoMapperPerson . create assert_equal @person , MongoMapperPerson . _t_find ( @person . id )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "browserifyinc", "detection"], "add_tokens": "if Open3 . capture3 ( \"npm ls browserify-incremental\" ) [ 1 ] . empty? system \"browserifyinc --cachefile #{Cyborg.rails_path(\"tmp/cache/assets/.browserify-cache.json\")} #{file} -t babelify --standalone #{plugin.module_name} -o #{dest}.js -d -p [ minifyify --map #{url(file).sub(/\\.js$/,'')}.map.json --output #{dest}.map.json ]\" abort \"JS BUILD FAILED: browserifyinc NPM module not found.\\n\" << \"Please add browserifyinc to your package.json and run `npm install`\"", "del_tokens": "if find_node_module \"browserify\" npm_command \"browserify #{file} -t babelify --standalone #{plugin.module_name} -o #{dest}.js -d -p [ minifyify --map #{url(file)}.map.json --output #{dest}.map.json ]\" abort \"JS BUILD FAILED: browserify NPM module not found.\\n\" << \"Please add browserify to your package.json and run `npm install`\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "aliased", "attribute", "methods", "in", "EventCalendar"], "add_tokens": "if self . all_day self . start_at = self . start_at . beginning_of_day if self . end_at self . end_at = self . end_at . beginning_of_day + 1 . day - 1 . second self . end_at = self . start_at + 1 . day - 1 . second", "del_tokens": "if self [ :all_day ] self [ :start_at ] = self [ :start_at ] . beginning_of_day if self [ :end_at ] self [ :end_at ] = self [ :end_at ] . beginning_of_day + 1 . day - 1 . second self [ :end_at ] = self [ :start_at ] . beginning_of_day + 1 . day - 1 . second", "commit_type": "use"}
{"commit_tokens": ["Add", "allocated_ips", "method", "to", "Network", "OM"], "add_tokens": "ALLOCATED_NETWORK_ADDRESS_LINK = \"#{URL}/api/network/#{ORG_NETWORK_ID}/allocatedAddresses/\" ORG_NETWORK_LINK , URL , ORG_NETWORK_ID , ALLOCATED_NETWORK_ADDRESS_LINK ] ) . strip ALLOCATED_NETWORK_ADDRESS_RESPONSE = ( File . read ( Test . spec_asset ( \"allocated_ip_addresses_response.xml\" ) ) % [ ALLOCATED_NETWORK_ADDRESS_LINK , ORG_NETWORK_NAME ] ) . strip", "del_tokens": "ORG_NETWORK_LINK , URL , ORG_NETWORK_ID , URL , ORG_NETWORK_ID ] ) . strip", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "class", "method", "to", "get", "and", "set", "the", "@@base_uri", "with", "tests"], "add_tokens": "@@base_uri = 'https://api.hasoffers.com/Api' def base_uri = ( uri ) @@base_uri = uri end def base_uri @@base_uri end uri = URI . parse base_uri uri = URI . parse ( \"#{base_uri}?#{query_string(data)}\" ) end", "del_tokens": "BaseUri = 'https://api.hasoffers.com/Api' uri = URI . parse BaseUri uri = URI . parse ( \"#{BaseUri}?#{query_string(data)}\" ) end", "commit_type": "create"}
{"commit_tokens": ["add", "column", "options", "to", "rename_column"], "add_tokens": "add_column ( table_name , new_column_name , column . type , column . instance_values ) execute ( \"UPDATE #{quote_table_name(table_name)} SET #{quote_column_name(new_column_name)} = #{quote_column_name(column_name)}\" )", "del_tokens": "add_column ( table_name , new_column_name , column . type ) execute ( \"UPDATE #{table_name} SET #{new_column_name} = #{column_name}\" )", "commit_type": "add"}
{"commit_tokens": ["Add", "descriptive", "messages", "to", "the", "XO", "::", "Engine", "::", "IllegalStateError", "exceptions"], "add_tokens": "raise IllegalStateError , \"must be in the :init state but state = :#{state}\" raise IllegalStateError , \"must be in the :playing or :game_over state but state = :#{state}\" raise IllegalStateError , \"must be in the :playing state but state = :#{state}\" raise IllegalStateError , \"must be in the :game_over state but state = :#{state}\"", "del_tokens": "raise IllegalStateError raise IllegalStateError raise IllegalStateError raise IllegalStateError", "commit_type": "add"}
{"commit_tokens": ["Updated", "API", "now", "uses", "https", "instead", "of", "http", "."], "add_tokens": "ENROLL = 'https://api.kairos.com/enroll' RECOGNIZE = 'https://api.kairos.com/recognize' DETECT = 'https://api.kairos.com/detect' GALLERY_LIST_ALL = 'https://api.kairos.com/gallery/list_all' GALLERY_VIEW = 'https://api.kairos.com/gallery/view' GALLERY_REMOVE_SUBJECT = 'https://api.kairos.com/gallery/remove_subject'", "del_tokens": "ENROLL = 'http://api.kairos.com/enroll' RECOGNIZE = 'http://api.kairos.com/recognize' DETECT = 'http://api.kairos.com/detect' GALLERY_LIST_ALL = 'http://api.kairos.com/gallery/list_all' GALLERY_VIEW = 'http://api.kairos.com/gallery/view' GALLERY_REMOVE_SUBJECT = 'http://api.kairos.com/gallery/remove_subject'", "commit_type": "update"}
{"commit_tokens": ["Move", "finalizer", "to", "dedicated", "file"], "add_tokens": "# make it easy for zombie require 'unparser/finalize'", "del_tokens": "Unparser :: Emitter :: REGISTRY . freeze", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "documentation", "formatting", "error", "for", "Archive", "::", "Zip#closed?"], "add_tokens": "# Returns +true+ if the ZIP archive is closed, +false+ otherwise.", "del_tokens": "# Returns +true+ if the ZIP archive is closed, false otherwise.", "commit_type": "fix"}
{"commit_tokens": ["made", "everything", "in", "the", "publisher", "private"], "add_tokens": "def bunny @bunnies [ @server ] ||= new_bunny end def new_bunny b = Bunny . new ( :host => current_host , :port => current_port , :logging => ! ! @options [ :logging ] ) b . start b end", "del_tokens": "def bunny @bunnies [ @server ] ||= new_bunny end def new_bunny b = Bunny . new ( :host => current_host , :port => current_port , :logging => ! ! @options [ :logging ] ) b . start b end", "commit_type": "make"}
{"commit_tokens": ["Adds", "static", "file", "middleware", "to", "short", "stacks"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "a", "migration", "to", "fae", "and", "fixed", "migrations", "so", "that", "fae", "migrations", "werent", "living", "in", "dummy", "app"], "add_tokens": "ActiveRecord :: Schema . define ( version : 20141013212642 ) do t . integer \"file_size\"", "del_tokens": "ActiveRecord :: Schema . define ( version : 20141009200746 ) do t . boolean \"has_mobile\" , default : false t . boolean \"has_tablet\" , default : false", "commit_type": "add"}
{"commit_tokens": ["allow", "setting", "name", "on", "v1", "App"], "add_tokens": "attr_accessor :name", "del_tokens": "attr_reader :name", "commit_type": "allow"}
{"commit_tokens": ["make", "sure", "dev", "lib", "has", "priority", "over", "gem"], "add_tokens": "$: . unshift ( File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '..' , 'lib' ) ) )", "del_tokens": "$: . push File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '..' , 'lib' ) )", "commit_type": "make"}
{"commit_tokens": ["Make", "extracting", "heading", "number", "from", "node", "name", "more", "readable", "and", "place", "nested", "lists", "between", "li", "tags"], "add_tokens": "toc = %Q{<ul class=\"section-nav\" id=\"test\">\\n} h_num = entry [ :node_name ] . delete ( \"h\" ) . to_i curr_h_num = entry [ :node_name ] . delete ( \"h\" ) . to_i # If the current entry should not be indented in the list, add the entry to the list lis << %Q{<li class=\"toc-entry toc-#{entry[:node_name]}\"><a href=\"##{entry[:id]}#{entry[:uniq]}\">#{entry[:text]}</a>} # If the next entry should be indented in the list, generate a sublist if i + 1 < entries . length next_entry = entries [ i + 1 ] next_h_num = next_entry [ :node_name ] . delete ( \"h\" ) . to_i if next_h_num > min_h_num lis << %Q{\\n} lis << %Q{<ul>\\n} nest_entries = get_nest_entries ( entries [ i + 1 , entries . length ] , min_h_num ) lis << build_lis ( nest_entries , min_h_num + 1 ) lis << %Q{</ul>\\n} i += nest_entries . length end end # Add the closing tag for the current entry in the list lis << %Q{</li>\\n} # If the current entry should be indented in the list, generate a sublist nest_h_num = nest_entry [ :node_name ] . delete ( \"h\" ) . to_i", "del_tokens": "toc = %Q{<ul class=\"section-nav\">\\n} h_num = entry [ :node_name ] [ 1 ] . to_i curr_h_num = entry [ :node_name ] [ 1 ] . to_i lis << %Q{<li class=\"toc-entry toc-#{entry[:node_name]}\"><a href=\"##{entry[:id]}#{entry[:uniq]}\">#{entry[:text]}</a></li>\\n} nest_h_num = nest_entry [ :node_name ] [ 1 ] . to_i", "commit_type": "make"}
{"commit_tokens": ["add", "feature", "to", "actually", "calculate", "the", "LCA"], "add_tokens": "before_filter :set_params , only : [ :single , :lca ] def calculate_lca @sequences = params [ :sequences ] . map ( & :upcase ) respond_with ( :api , @sequences ) end", "del_tokens": "before_filter :set_params", "commit_type": "add"}
{"commit_tokens": ["Add", "user", "method", "to", "WalletAccount", "model"], "add_tokens": "describe 'wallet_account methods' do it 'can be accessed' do expect ( client . wallet_accounts . respond_to? ( :user ) ) . to be ( true ) end end", "del_tokens": "# describe 'wallet_account methods' do # it 'can be accessed' do # expect(client.wallet_accounts.respond_to?(:user)).to be(true) # end # end", "commit_type": "add"}
{"commit_tokens": ["Use", "bangs", "for", "VM", "manipulation", "commands"], "add_tokens": "def up! ( options = { } ) def halt! ( options = { } ) def destroy! ( options = { } ) def reload! ( options = { } )", "del_tokens": "def up ( options = { } ) def halt ( options = { } ) def destroy ( options = { } ) def reload ( options = { } )", "commit_type": "use"}
{"commit_tokens": ["Move", "errors", "into", "separate", "file"], "add_tokens": "require \"lxc/errors\"", "del_tokens": "class Error < StandardError ; end class ContainerError < Error ; end class ConfigurationError < Error ; end", "commit_type": "move"}
{"commit_tokens": ["Add", "views", "to", "example", "app"], "add_tokens": "view :index view 'users/index' view 'users/create' view 'users/show' , locals : { id : id } view 'users/update' delete '/users/:id' do view 'users/delete' view :hello , name : name", "del_tokens": "'index' 'Index of users' '<form action=\"/users\" method=\"POST\">' '<input type=\"submit\" value=\"Create\" />' '</form>' 'Create new user' \"Show user by id = #{params[:id]}\" \"<form action=\\\"/users/#{id}\\\" method=\\\"POST\\\">\" '<input type=\"hidden\" name=\"_method\" value=\"PUT\" />' '<input type=\"submit\" value=\"Update\" />' '</form>' \"<form action=\\\"/users/#{id}\\\" method=\\\"POST\\\">\" '<input type=\"hidden\" name=\"_method\" value=\"DELETE\" />' '<input type=\"submit\" value=\"Delete\" />' '</form>' \"Update user by id = #{params[:id]}\" delete '/users/:id' do | id | \"Delete user by id = #{id}\" \"Hello, #{name}\"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Rails", "plugin", "task", "and", "simplified", "rakeconfig", "."], "add_tokens": "dir = File . dirname ( folder_name ) . gsub ( \"#{@dest}\" , \".\" ) . gsub ( \"./\" , \"\" ) puts \". #{fn}\" if verbose add_folder ( \"#{fn}/\" ) puts \" + Creating #{@dest}/#{folder}/index.html\" if @verbose", "del_tokens": "dir = File . dirname ( folder_name ) . gsub ( \"#{@dest}\" , \".\" ) puts \" + Publishing #{@dest}/#{folder}/index.html\" if @verbose", "commit_type": "fix"}
{"commit_tokens": ["fixed", "incorrect", "work", "with", "validations"], "add_tokens": "args = [ { } ] if args . empty? if object && ! object . new? && @expire", "del_tokens": "if ! object . new? && @expire", "commit_type": "fix"}
{"commit_tokens": ["moving", "gotfan247", "bot", "to", "GCP"], "add_tokens": "Hearthbeat . beat \"u_gotfan247_r_yayornay\" , 310 unless Gem :: Platform . local . os == \"darwin\" p [ post [ \"id\" ] , yay , nay ] if Gem :: Platform . local . os == \"darwin\"", "del_tokens": "# SUBREDDIT = \"test___________\" AWSStatus :: touch p [ post [ \"id\" ] , yay , nay ] if ENV [ \"LOGNAME\" ] == \"nakilon\"", "commit_type": "move"}
{"commit_tokens": ["use", "native", "net", "/", "http", "persistence", "when", "available"], "add_tokens": "class ThreeScale :: NetHttpPersistentClientTest < ThreeScale :: ClientTest ThreeScale :: Client :: HTTPClient . persistent_backend = ThreeScale :: Client :: HTTPClient :: NetHttpPersistent class ThreeScale :: NetHttpKeepAliveClientTest < ThreeScale :: NetHttpPersistentClientTest def client ( options = { } ) ThreeScale :: Client :: HTTPClient . persistent_backend = ThreeScale :: Client :: HTTPClient :: NetHttpKeepAlive super end end", "del_tokens": "class ThreeScale :: PersistentClientTest < ThreeScale :: ClientTest", "commit_type": "use"}
{"commit_tokens": ["Add", "write", "method", "restoring", "legacy", "behavior"], "add_tokens": "VERSION = '1.0.17'", "del_tokens": "VERSION = '1.0.16'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "stub", "out", "directory", "expansion", "."], "add_tokens": "File . stub! ( :expand_path ) . and_return ( '/home/user' )", "del_tokens": "File . should_receive ( :expand_path ) . and_return ( '/home/user' )", "commit_type": "change"}
{"commit_tokens": ["Made", "error", "messages", "for", "no", "accounts", "and", "no", "active", "account", "work", "."], "add_tokens": "class NoActiveAccount < StandardError ; end class NoAccounts < StandardError ; end @current_account ||= Account . active raise Account . count == 0 ? NoAccounts : NoActiveAccount if @current_account . blank? rescue Twitter :: CLI :: Helpers :: NoActiveAccount say ( \"You have not set an active account. Use 'twitter change' to set one now.\" ) rescue Twitter :: CLI :: Helpers :: NoAccounts say ( \"You have not created any accounts. Use 'twitter add' to create one now.\" )", "del_tokens": "@current_account ||= Account . active exit ( 'No current account.' ) if @current_account . blank?", "commit_type": "make"}
{"commit_tokens": ["adding", "new", "un", "-", "finished", "specs"], "add_tokens": "NextTaskSQL = \"(locked_by = ?) OR (run_at <= ? AND (locked_at IS NULL OR locked_at < ?))\" NextTaskOrder = \"priority DESC, run_at ASC\" affected_rows = if locked_by != worker self . class . update_all ( [ \"locked_at = ?, locked_by = ?\" , now , worker ] , [ \"id = ? and (locked_at is null or locked_at < ?)\" , id , ( now - max_run_time . to_i ) ] ) self . class . update_all ( [ \"locked_at = ?\" , now ] , [ \"id = ? and (locked_by = ?)\" , id , worker ] )", "del_tokens": "NextTaskSQL = '(locked_by = ?) OR (run_at <= ? AND (locked_at IS NULL OR locked_at < ?))' NextTaskOrder = 'priority DESC, run_at ASC' if locked_by != worker affected_rows = self . class . update_all ( [ \"locked_at = ?, locked_by = ?\" , now , worker ] , [ \"id = ? and (locked_at is null or locked_at < ?)\" , id , ( now - max_run_time . to_i ) ] ) affected_rows = self . class . update_all ( [ \"locked_at = ?\" , now ] , [ \"id = ? and (locked_by = ?)\" , id , worker ] )", "commit_type": "add"}
{"commit_tokens": ["Fix", "pause", "spec", "on", "JRuby"], "add_tokens": "describe \"#pause\" , :focus do sleep 0.01", "del_tokens": "describe \"#pause\" do sleep 0.0001", "commit_type": "fix"}
{"commit_tokens": ["allow", "duplicate", "keys", "to", "be", "treated", "as", "unique"], "add_tokens": "urls . each_with_object ( { } . compare_by_identity ) do | link , pairs | pairs [ root_url ( link ) ] = link end", "del_tokens": "urls . map { | link | [ root_url ( link ) , link ] } . to_h", "commit_type": "allow"}
{"commit_tokens": ["updated", "locals", "handling", "to", "make", "sure", "the", "specified", "locals", "don", "t", "conflict", "with", "public", "methods"], "add_tokens": "should have_instance_method :to_s , :escape_html class LocalsTest < BasicTest should \"complain if trying to set locals that conflict with public methods\" do assert_raises ArgumentError do Undies :: Template . new ( :_ => \"yay!\" ) { } end end should \"respond to each locals key with its value\" do should \"be able to access its locals in the template definition\" do", "del_tokens": "should have_instance_method :to_s class DataTest < BasicTest should \"respond to each data key with its value\" do should \"be able to access its data in the template definition\" do", "commit_type": "update"}
{"commit_tokens": ["create", "barcodes", "and", "labels", "if", "gbarcode", "gem", "and", "imagemagick", "convert", "is", "installed"], "add_tokens": "# if gbarcode and rmagick can both be loaded then load mead/barcode begin require 'gbarcode' begin require 'RMagick' require 'tempfile' require 'mead/barcode' rescue end rescue end", "del_tokens": "VERSION = '0.0.7'", "commit_type": "create"}
{"commit_tokens": ["Add", "speakerdeck", ".", "com", "endpoint"], "add_tokens": "/ photobucket \\. com / => 'http://photobucket.com/oembed' , / speakerdeck \\. com / => 'https://speakerdeck.com/oembed.{format}'", "del_tokens": "/ photobucket \\. com / => 'http://photobucket.com/oembed'", "commit_type": "add"}
{"commit_tokens": ["Move", "style", "functionality", "into", "style", "module"], "add_tokens": "def self . load ( style_file , rules ) unless style_file . include? ( \"/\" ) or style_file . end_with? ( \".rb\" ) style_file = File . expand_path ( \"../styles/#{style_file}.rb\" , __FILE__ ) end style = new ( rules ) rules . select! { | r | style . rules . include? ( r ) }", "del_tokens": "def self . load ( style_file , all_rules ) style = new ( all_rules )", "commit_type": "move"}
{"commit_tokens": ["added", "include_whitespace", "(", "many", ")", "test", "-", "works"], "add_tokens": "it \"should work to include_whitespace(:rule)\" do rule :parameters , include_whitespace ( / [ \\t ]* / ) , include_whitespace ( :identifier ) it \"should work to include_whitespace(many)\" do new_parser do ignore_whitespace rule :all , :identifier , :parameters? , :identifier rule :parameters , include_whitespace ( / [ \\t ]* / ) , include_whitespace ( many ( :identifier , \",\" ) ) rule :identifier , / [_a-zA-Z][_a-zA-Z0-9]* / end test_parse <<ENDCODE fred foo , bar bar ENDCODE end", "del_tokens": "it \"should work to include_whitespace-many\" do rule :parameters , include_whitespace ( / [ \\t ]* / ) , include_whitespace ( :identifier ) do # this doesn't # rule :parameters, include_whitespace(/[ \\t]*/), include_whitespace(/[_a-zA-Z][_a-zA-Z0-9]*/) do # this works def matched puts \"matched: #{self.class} #{prewhitespace.inspect} #{text.inspect} #{postwhitespace.inspect}\" end end", "commit_type": "add"}
{"commit_tokens": ["Use", "consistent", "language", "for", "asset", "host", "."], "add_tokens": "def initialize ( asset_host = nil , template_path = nil ) @asset_host = asset_host", "del_tokens": "def initialize ( template_host = nil , template_path = nil ) @template_host = template_host", "commit_type": "use"}
{"commit_tokens": ["Removed", "extraneous", "docs", "added", "test", "for", "oversized", "values", "."], "add_tokens": "# MultiBitField creates convenience methods for using private raise ArgumentError , \"Attempted value: #{value} is too large for selected filum\"", "del_tokens": "# MultiBitField create convenience methods for using # MultiBitField extends an integer field of the database, and # allows the user to specify multiple columns on that field. # This can be useful when managing multiple boolean options (with single bit columns,) # or multiple bit counters. This can be useful when sorting based on a combination of # fields. For instance, you may have daily, weekly and monthly counters, and wan to # sort on each of these with greater weight given to the \"daily\" counts. For this # usecase, you could specify the following columns: # # +----------+---------+---------+---------+----------------------+ # | daily | daily | weekly | monthly | all columns together | # +----------+---------+---------+---------+----------------------+ # | bits | 00011 | 00101 | 00001 | 000110010100001 | # | values | 3 | 5 | 1 | 3_233 | # | weighted | 3072 | 160 | 1 | - | # | maxval | 31 | 31 | 31 | 32_767 | # +----------+---------+---------+---------+----------------------+ # # As you can see, the individual counters can be used individually, or all as one # number. This can be useful when doing sort operations. The column order also changes # the relative weight of each. This can be useful when sorting based on multiple # weighted fields, or comparing related values simply and efficiently. # raise \"Attempted value: #{value} is too large for selected filum\"", "commit_type": "remove"}
{"commit_tokens": ["Fix", "confusing", "url", "build", "err", "and", "spec", "warnings"], "add_tokens": "expect { subject . validate! } . not_to raise_error expect { subject . validate! } . not_to raise_error expect { subject . validate! } . not_to raise_error", "del_tokens": "expect { subject . validate! } . not_to raise_error ( Exception ) expect { subject . validate! } . not_to raise_error ( ArgumentError ) expect { subject . validate! } . not_to raise_error ( ArgumentError )", "commit_type": "fix"}
{"commit_tokens": ["remove", "select", "from", "facet#data", "to", "avoid", "issues", "with", "polymorphic", "assocs"], "add_tokens": "#dv = scope.select(attr).uniq.map(&:\"#{attribute}\").uniq dv = scope . map ( & :\" #{ attribute } \" ) . uniq dv", "del_tokens": "scope . select ( attr ) . uniq . map ( & :\" #{ attribute } \" ) . uniq", "commit_type": "remove"}
{"commit_tokens": ["fixed", "nested", "index", "not", "working", "with", "json"], "add_tokens": "@parent_collection_name ||= default ( :parent_collection_name ) || resource_name_u . pluralize . to_sym @parent_resource_name ||= default ( :parent_resource_name ) || resource_name_u . to_sym index!", "del_tokens": "default ( :parent_collection_name ) || resource_name_u . pluralize . to_sym default ( :parent_resource_name ) || resource_name_u . to_sym", "commit_type": "fix"}
{"commit_tokens": ["Adding", "shipment", "voiding", "but", "test", "server", "not", "working", "with", "voids"], "add_tokens": ":shipaccept => 'ups.app/xml/ShipAccept' , :shipvoid => 'ups.app/xml/Void' ship_void_request = build_void_request ( tracking_number ) response = commit ( :shipvoid , save_request ( access_request + ship_void_request ) , ( options [ :test ] || true ) ) packaging_type << XmlNode . new ( \"Code\" , package . options [ :package_type ] ) def build_void_request ( tracking_number ) request << XmlNode . new ( 'RequestAction' , 'Void' ) end root_node << XmlNode . new ( 'ExpandedVoidShipment' ) do | void | void << XmlNode . new ( 'ShipmentIdentificationNumber' , tracking_number ) success = root . elements [ 'Response/ResponseStatusCode' ] if success == 1 @void = \"Shipment successfully voided!\" else @void = \"Voiding shipment failed!\" return @void", "del_tokens": ":shipaccept => 'ups.app/xml/ShipAccept' ship_void_request = build_void_request response = commit ( :shipvoid , save_request ( access_request + ship_void_request ) ) packaging_type << XmlNode . new ( \"Code\" , :package_type ) def build_ship_void ( tracking_number ) request << XmlNode . new ( 'RequestAction' , '1' ) root_node << XmlNode . new ( 'ShipmentIdentificationNumber' , tracking_number ) success = response_success? ( xml ) if success return nil", "commit_type": "add"}
{"commit_tokens": ["Updated", "GoDaddy", "parser", "to", "the", "new", "response"], "add_tokens": "node ( \"Creation Date\" ) do | value | node ( \"Updated Date\" ) do | value | node ( \"Registrar Registration Expiration Date\" ) do | value |", "del_tokens": "node ( 'Creation Date' ) do | value | node ( 'Updated Date' ) do | value | node ( 'Registrar Registration Expiration Date' ) do | value |", "commit_type": "update"}
{"commit_tokens": ["Make", "requirements", "for", "#show", "more", "lax"], "add_tokens": "# If we have no user to get, use the timeline instead return timeline ( args ) if args . nil? || args . count == 0 target_user = args [ 0 ] load_default_token # for private tweets return failtown ( \"show :: #{res['error']}\" ) if ! res || res . include? ( 'error' ) if default_hash [ :token ] && default_hash [ :secret ] @client = TwitterOAuth :: Client . new ( :consumer_key => ConsumerKey , :consumer_secret => ConsumerSecret , :token => default_hash [ :token ] , :secret => default_hash [ :secret ] ) end else @client = TwitterOAuth :: Client . new ( :consumer_key => ConsumerKey , :consumer_secret => ConsumerSecret )", "del_tokens": "load_default_token target_user = '' target_user = args [ 0 ] unless args . nil? return failtown ( \"show :: #{res['error']}\" ) if res . include? ( 'error' ) @client = TwitterOAuth :: Client . new ( :consumer_key => ConsumerKey , :consumer_secret => ConsumerSecret , :token => default_hash [ :token ] , :secret => default_hash [ :secret ] )", "commit_type": "make"}
{"commit_tokens": ["Use", "new", "log", "methods", "for", "legacy", "SSHKit", "version", "flow"], "add_tokens": "log_command_start ( obj ) log_command_exit ( obj ) if obj . finished? log_command_data ( command , stream , line )", "del_tokens": "write_command_start ( obj ) write_command_exit ( obj ) if obj . finished? write_command_output_line ( command , stream , line )", "commit_type": "use"}
{"commit_tokens": ["Allow", "auth", "configuration", "to", "be", "set", "from", "environment", "variables"], "add_tokens": "{ :consumer_key => ENV [ \"chatterbot_consumer_key\" ] , :consumer_secret => ENV [ \"chatterbot_consumer_secret\" ] , :token => ENV [ \"chatterbot_token\" ] , :secret => ENV [ \"chatterbot_secret\" ] } . merge ( slurp_file ( config_file ) || { } )", "del_tokens": "slurp_file ( config_file ) || { }", "commit_type": "allow"}
{"commit_tokens": ["Add", "specs", "for", "repo", "forks", "api", "."], "add_tokens": "github . get_token code a_request ( :post , \"https://github.com/login/oauth/access_token\" ) . should have_been_made", "del_tokens": "github . get_token code a_request ( :post , \"https://github.com/login/oauth/access_token\" ) . should have_been_made", "commit_type": "add"}
{"commit_tokens": ["fix", "specs", "for", "changes", "made", "to", "Table"], "add_tokens": "table . should_receive ( :search_information ) . and_return ( 1234 ) table . should_receive ( :search_information ) table . should_receive ( :search_information )", "del_tokens": "table . should_receive ( :hwnd ) . and_return ( 1234 ) table . should_receive ( :hwnd ) table . should_receive ( :hwnd )", "commit_type": "fix"}
{"commit_tokens": ["Use", "correct", "line", "numbers", "for", "case", "/", "when", "statements", "."], "add_tokens": "source = code ( statement . line ) source = code ( statement [ 0 ] . line )", "del_tokens": "source = code ( lineno ) source = code ( lineno )", "commit_type": "use"}
{"commit_tokens": ["fixed", "the", "broken", "server", "select", "logic", "for", "redundant", "publishing"], "add_tokens": "published = [ ] break if published . size == 2 || @servers . empty? || published == @servers next if published . include? @server published << @server case published . size published . size", "del_tokens": "published = 0 break if published == 2 || @servers . size < 2 published += 1 case published published", "commit_type": "fix"}
{"commit_tokens": ["adding", "deferred_server", "file", "fixing", "rake", "missing", "ignore_files", "issue"], "add_tokens": "@ignore_files = ( options . fetch ( :ignore_files ) { \"\" } ) . to_s . split ( ',' ) . map ( & :strip )", "del_tokens": "@ignore_files = ( options . fetch ( :ignore_files ) { \"\" } ) . split ( ',' ) . map ( & :strip )", "commit_type": "add"}
{"commit_tokens": ["Add", "sorting", "of", "taxons", "and", "related", "links", "in", "taxonomy", "sidebar"], "add_tokens": "return taxons . map { | taxon | ContentItem . new ( taxon ) } . sort_by ( & :title ) if taxons . any? parent_taxons . map { | taxon | ContentItem . new ( taxon ) } . sort_by ( & :title )", "del_tokens": "return taxons . map { | taxon | ContentItem . new ( taxon ) } if taxons . any? parent_taxons . map { | taxon | ContentItem . new ( taxon ) }", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "+", "bump", "version", "."], "add_tokens": "VERSION = \"1.0.2\"", "del_tokens": "VERSION = \"1.0.1\"", "commit_type": "update"}
{"commit_tokens": ["add", "basic", "implementation", "of", "other", "commands"], "add_tokens": "before_filter :set_params , only : [ :single , :lca , :pept2pro ] @taxon_ids = params [ :taxon_ids ] . map ( & :chomp ) @equate_il = ( ! params [ :equate_il ] . blank? && params [ :equate_il ] == 'true' ) name = @equate_il ? :lca_il : :lca @result = Taxon . includes ( :lineage ) . find ( @taxon_ids ) respond_with ( @result ) end def pept2pro @result = { } @sequences . map do | s | peptides = Sequence . single_search ( s . upcase , @equate_il ) @result [ s ] = peptides . peptides . map ( & :uniprot_entry ) if peptides end respond_with ( @result )", "del_tokens": "before_filter :set_params , only : [ :single , :lca ]", "commit_type": "add"}
{"commit_tokens": ["Make", "access", "token", "expiration", "date", "optional", "for", "offline_access", "privilege", "usage"], "add_tokens": "# Take the oauth2 request token and turn it into an access token # which can be used to access private data # The expiration date is not necessarily set, as the app might have # requested offline_access to the data match_data = data . match ( / expires=([^&]+) / ) @expires = match_data && match_data [ 1 ] || nil # Extract the access token", "del_tokens": "@expires = data . match ( / expires=([^&]+) / ) [ 1 ]", "commit_type": "make"}
{"commit_tokens": ["Fix", "#to_dcm", "crash", "with", "missing", "control", "points"], "add_tokens": "if field . control_points . length > 0 create_beam_limiting_device_positions ( cp_item , field . control_points . first ) else create_beam_limiting_device_positions_from_field ( cp_item , field ) end # Creates a beam limiting device positions sequence in the given DICOM object. # # @param [DICOM::Item] cp_item the DICOM control point item in which to insert the sequence # @param [Field] field the RTP treatment field to fetch device parameters from # @return [DICOM::Sequence] the constructed beam limiting device positions sequence # def create_beam_limiting_device_positions_from_field ( cp_item , field ) dp_seq = DICOM :: Sequence . new ( '300A,011A' , :parent => cp_item ) # ASYMX: dp_item_x = DICOM :: Item . new ( :parent => dp_seq ) DICOM :: Element . new ( '300A,00B8' , \"ASYMX\" , :parent => dp_item_x ) DICOM :: Element . new ( '300A,011C' , \"#{field.collimator_x1}\\\\#{field.collimator_x2}\" , :parent => dp_item_x ) # ASYMY: dp_item_y = DICOM :: Item . new ( :parent => dp_seq ) DICOM :: Element . new ( '300A,00B8' , \"ASYMY\" , :parent => dp_item_y ) DICOM :: Element . new ( '300A,011C' , \"#{field.collimator_y1}\\\\#{field.collimator_y2}\" , :parent => dp_item_y ) dp_seq end", "del_tokens": "create_beam_limiting_device_positions ( cp_item , field . control_points . first )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "on", "text", "diff", "operation"], "add_tokens": "before_elements [ position ] = \"#{before_elements[position]}<ins>#{element}</ins>\"", "del_tokens": "before_elements [ position ] += \"<ins>#{element}</ins>\"", "commit_type": "fix"}
{"commit_tokens": ["added", "case_insensitive_email", "to", "template", "used", "by", "install", "generator"], "add_tokens": "# config.case_sensitive_email = true", "del_tokens": "# config.url_after_invite = '/'", "commit_type": "add"}
{"commit_tokens": ["Implement", "controller", ".", "requested_by?", "(", "user", ")"], "add_tokens": "# Check if the current resource is the same as the requester. # The resource must respond to `resource.id` method. def requested_by? ( resource ) case when current_resource_owner . nil? false when ! resource . is_a? ( current_resource_owner . class ) false when current_resource_owner . id == resource . id true else false end", "del_tokens": "# Hack: returns if the current resource is the same as the requester def request_by? ( resource ) true # FIXME # resource.is_a?(User) && current_resource_owner.try(:id) == resource.id", "commit_type": "implement"}
{"commit_tokens": ["move", "constant", "into", "plugin", "dont", "reuse", "in", "tests"], "add_tokens": "DEFAULT_KEYWORDS = %w( TODO FIXME ) . freeze DEFAULT_KEYWORDS", "del_tokens": "Danger :: DiffTodoFinder :: DEFAULT_KEYWORDS", "commit_type": "move"}
{"commit_tokens": ["Fix", "handling", "of", "quotation", "marks", "in", "key", "value", "reader"], "add_tokens": "if value . empty? if prev_key && ! line . include? ( '=' ) # multiline value: treat key as value and add to previous found key env [ prev_key ] = \"#{env[prev_key]} #{key}\" end else val = value . join ( '=' ) . strip val . gsub! ( / ^[\"']* / , '' ) val . gsub! ( / [\"']$ / , '' ) val . gsub! ( / [ \\n ]* / , '' )", "del_tokens": "unless value . empty? val = value . join ( '=' ) val . gsub! ( / [\"' \\n ]* / , '' ) else if prev_key && ! line . include? ( '=' ) # multiline value: treat key as value and add to previous found key env [ prev_key ] = \"#{env[prev_key]} #{key}\" end", "commit_type": "fix"}
{"commit_tokens": ["Add", "spec", "/", "implementation", "for", "CLI", "draft"], "add_tokens": "options = do_creation_options options = do_creation_options options . title ||= @params . first @helper . draft_usage unless options . title @tasks . draft ( options . title , options . slug ) def do_creation_options options = OpenStruct . new options . slug = nil options . title = nil opt_parser = OptionParser . new do | opts | opts . on ( '-s' , '--slug [SLUG]' , \"Use custom slug\" ) do | s | options . slug = s end opts . on ( '-t' , '--title [TITLE]' , \"Specifiy title\" ) do | t | options . title = t end end opt_parser . parse! @params options end", "del_tokens": "options = OpenStruct . new options . slug = nil options . title = nil opt_parser = OptionParser . new do | opts | opts . banner = 'Usage: poole post [options]' opts . separator '' opts . separator \"Options: \" opts . on ( '-s' , '--slug [SLUG]' , \"Use custom slug\" ) do | s | options . slug = s end opts . on ( '-t' , '--title [TITLE]' , \"Specifiy title\" ) do | t | options . title = t end end opt_parser . parse! @params", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "remove", "unnecessary", "string", "interpolation"], "add_tokens": "content << '' unless values . empty? object . each do | key , val | end content << '' @env_prefix == '' ? env_key : \"#{@env_prefix.to_s.upcase}_#{env_key}\" raise ArgumentError , 'Alias matches setting key' raise ArgumentError , 'Setting already exists with an alias ' raise ReadError , 'No file found to read configuration from!' 'Use :force option to overwrite.' raise ArgumentError , 'Need to set either value or block' raise ArgumentError , 'Need to set env var in block'", "del_tokens": "content << \"\" unless values . empty? object . each { | key , val | } content << \"\" @env_prefix == '' ? env_key : @env_prefix . to_s . upcase + \"_\" + env_key raise ArgumentError , \"Alias matches setting key\" raise ArgumentError , \"Setting already exists with an alias \" raise ReadError , \"No file found to read configuration from!\" \"Use :force option to overwrite.\" raise ArgumentError , \"Need to set either value or block\" raise ArgumentError , \"Need to set env var in block\"", "commit_type": "change"}
{"commit_tokens": ["add", "structure", "to", "build", "parent", "stack"], "add_tokens": "build_class_cfn_template ( deducer ) build_parent_cfn_template def build_class_cfn_template ( deducer ) def build_parent_cfn_template parent = Jets :: Cfn :: Builder :: Parent . new parent . compose! end", "del_tokens": "build_cfn_templates ( deducer ) def build_cfn_templates ( deducer )", "commit_type": "add"}
{"commit_tokens": ["Removes", "unused", "code", "in", "species_file", "dumps", ".", "Minor", "refactoring", "of", "Name", "initialization", "and", "name", "collection", "handling", "."], "add_tokens": "# The original description reference attr_accessor :original_description_reference @@ATTRIBUTES = [ :name , :rank , :year , :parens , :author , :related_name ] @original_description_reference = opts [ :original_description_reference ] if ( ! opts [ :original_description_reference ] . nil? && opts [ :original_description_reference ] . class == Taxonifi :: Model :: Ref )", "del_tokens": "@@ATTRIBUTES = [ :name , :rank , :year , :parens , :parent , :author , :related_name ]", "commit_type": "remove"}
{"commit_tokens": ["Add", "expires_at", "date", "stamp", "to", "authorizations", "table", "."], "add_tokens": "provider = options . fetch ( :provider ) user_id = options . fetch ( :user_id ) . to_i uid = options . fetch ( :uid ) token = options . fetch ( :token ) expires_at = options . fetch ( :expires_at , nil ) provider : provider , user_id : user_id , uid : uid , token : token , expires_at : expires_at", "del_tokens": "provider = options . fetch ( :provider ) user_id = options . fetch ( :user_id ) uid = options . fetch ( :uid ) token = options . fetch ( :token ) provider : provider , user_id : user_id , uid : uid , token : token", "commit_type": "add"}
{"commit_tokens": ["Moving", "to", "better", "error", "reporting", "when", "compilation", "fails"], "add_tokens": "if css_file == file UI . info \"Guard::Less: Skipping #{file} since the output would overwrite the original file\" else UI . info \"Guard::Less: #{file} -> #{css_file}\\n\" begin parser = :: Less :: Parser . new :paths => [ './public/stylesheets' ] , :filename => file File . open ( file , 'r' ) do | infile | File . open ( css_file , 'w' ) do | outfile | tree = parser . parse ( infile . read ) outfile << tree . to_css end end true rescue Exception => e UI . info \"Guard::Less: Compiling #{file} failed with message: #{e.message}\" false", "del_tokens": "raise 'Output css file would overwrite less input file' if css_file == file UI . info \"Guard::Less: #{file} -> #{css_file}\\n\" parser = :: Less :: Parser . new :paths => [ './public/stylesheets' ] , :filename => file File . open ( file , 'r' ) do | infile | File . open ( css_file , 'w' ) do | outfile | tree = parser . parse ( infile . read ) outfile << tree . to_css", "commit_type": "move"}
{"commit_tokens": ["moved", "more", "instance", "variables", "to", "initialize"], "add_tokens": "attr_accessor :project_name , :template_name , :existing_projects , :config_file , :install_path , :template_path , :install_command , :install_command_options attr_reader :dir_list , :whole_templates , :append_templates , :line_templates , :nginx_local_template , :nginx_remote_template @install_command = @config_file [ :install_command ] @install_command_options = @config_file [ :install_command_options ]", "del_tokens": "attr_reader :project_name , :template_name , :existing_projects , :config_file , :install_path , :template_path , :install_command , :install_command_options , :dir_list , :whole_templates , :append_templates , :line_templates , :nginx_local_template , :nginx_remote_template @install_command = @config_file [ :install_command ] @install_command_options = @config_file [ :install_command_options ]", "commit_type": "move"}
{"commit_tokens": ["Fix", "regression", ":", "should", "accept", "attributes", "and", "normal", "as", "synonyms"], "add_tokens": "new_data [ 'id' ] ||= ( new_data [ 'name' ] || 'undefined' ) new_data [ 'nodes' ] ||= [ ] super ( normalize ( new_data ) ) # clean up some variations so we only have to process one way # in particular, allow 'attributes' as a synonym for 'normal' def normalize ( data ) data [ 'nodes' ] = data [ 'nodes' ] . map do | n | if n . key? ( 'attributes' ) n [ 'normal' ] = Chef :: Mixin :: DeepMerge . merge ( n [ 'normal' ] , n [ 'attributes' ] ) n . delete ( 'attributes' ) end n end data end raw_data [ 'name' ] raw_data [ 'nodes' ]", "del_tokens": "new_data [ 'id' ] ||= new_data [ 'name' ] super raw_data [ 'name' ] || 'undefined' raw_data [ 'nodes' ] || [ ]", "commit_type": "fix"}
{"commit_tokens": ["Move", "the", ":", "fields", "find", "()", "parameter", "into", "the", "options", "hash", "."], "add_tokens": "# Options: # * <tt>:fields</tt> - Array of collection field names; only those will be returned (plus _id if defined) # * <tt>:offset</tt> - Start at this record when returning records # * <tt>:limit</tt> - Maximum number of records to return # * <tt>:sort</tt> - Hash of field names as keys and 1/-1 as values; 1 == ascending, -1 == descending # <tt> def find ( selector = { } , options = { } ) fields = options . delete ( :fields )", "del_tokens": "def find ( selector = { } , fields = nil , options = { } )", "commit_type": "move"}
{"commit_tokens": ["made", "sure", "neg", "rules", "cause", "feedback", "loops", "before", "fixing", "this", "properly"], "add_tokens": "# order matters for proper invalidation token . delete_children #if token.neg_join_results.empty? # TODO why was this check here? it seems to break things", "del_tokens": "token . delete_children if token . neg_join_results . empty?", "commit_type": "make"}
{"commit_tokens": ["Remove", "unnecessary", "transliterator", "keep", "polish", "characters", "test"], "add_tokens": "describe Babosa :: Transliterator :: Latin do", "del_tokens": "describe Babosa :: Transliterator :: Polish do", "commit_type": "remove"}
{"commit_tokens": ["Moved", "the", "group", "parameters", "out", "of", "the", "creation", "to", "a", "Module", "method"], "add_tokens": "# # Return the hash that maps to the properties for a logical group # # @param [String] name of the logical group # def self . properties_for_logical_group ( name ) { 'isa' => 'PBXGroup' , 'name' => name , 'sourceTree' => ' < group > ' , 'children' => [ ] } end new_identifier = @registry . add_object Group . properties_for_logical_group ( name )", "del_tokens": "# Add a new group to the registry # @todo the creation of the group with defaults here feels wrong and # should likely be part of the PBXGroup module. new_identifier = @registry . add_object 'isa' => 'PBXGroup' , 'name' => name , 'sourceTree' => ' < group > ' , 'children' => [ ]", "commit_type": "move"}
{"commit_tokens": ["add", "blank", "line", "after", "header"], "add_tokens": "\"# #{header}\\n\\n\"", "del_tokens": "\"# #{header}\"", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "define", "parser", "-", "specs", "and", "docs"], "add_tokens": "VERSION = '0.1.11' . freeze", "del_tokens": "VERSION = '0.1.10' . freeze", "commit_type": "add"}
{"commit_tokens": ["Add", "spec", "for", "Extensions", "DateRange", "and", "bump", "coverage"], "add_tokens": "MINIMUM_COVERAGE = 66", "del_tokens": "MINIMUM_COVERAGE = 63", "commit_type": "add"}
{"commit_tokens": ["change", "the", "directories", "to", "have", "the", "right", "case!"], "add_tokens": "class AccountController < RhoController", "del_tokens": "class AccountsController < RhoController", "commit_type": "change"}
{"commit_tokens": ["Use", "Naming", "methods", "in", "Generator", "."], "add_tokens": "@modules = modules_of ( @name ) @namespace = namespace_of ( @name ) @namespace_dir = namespace_dir_of ( @name )", "del_tokens": "@modules = @name . split ( '-' ) . map do | words | words . split ( '_' ) . map { | word | word . capitalize } . join end @namespace = @modules . join ( '::' ) @namespace_dir = File . join ( @name . split ( '-' ) )", "commit_type": "use"}
{"commit_tokens": ["Make", "fax", "a", "normal", "resource"], "add_tokens": "class Fax < Resource", "del_tokens": "class Fax class Collection attr_accessor :raw_data def initialize raw_data self . raw_data = raw_data end end def response_record response Fax . new response end def response_collection response Fax :: Collection . new response end", "commit_type": "make"}
{"commit_tokens": ["Use", "respons", ".", "plain_body", "in", "AccessToken", "Service"], "add_tokens": "result = Quickbooks :: Model :: AccessTokenResponse . from_xml ( response . plain_body ) result = Quickbooks :: Model :: AccessTokenResponse . from_xml ( response . plain_body )", "del_tokens": "result = Quickbooks :: Model :: AccessTokenResponse . from_xml ( response . body ) result = Quickbooks :: Model :: AccessTokenResponse . from_xml ( response . body )", "commit_type": "use"}
{"commit_tokens": ["added", "most", "used", "hashtags", "list"], "add_tokens": "puts \"#{sprintf \"%2d\", i + 1}. #{parsed[:mentions][i][1][:name]} (#{parsed[:mentions][i][1][:count]} times)\" end puts \"Your most used hashtags:\" ( 0 ... 10 ) . each do | i | puts \"#{sprintf \"%2d\", i + 1}. ##{parsed[:hashtags][i][1][:hashtag]} (#{parsed[:hashtags][i][1][:count]} times)\"", "del_tokens": "puts \"#{sprintf \"%2d\", i + 1}. #{parsed[:mentions][i][0]} (#{parsed[:mentions][i][1][:count]} tweets)\"", "commit_type": "add"}
{"commit_tokens": ["adding", "a", "total", "elapsed", "job", "time"], "add_tokens": "if all_work_units_done? update_attributes ( { :status => Dogpile :: COMPLETE , :time => Time . now - self . created_at } ) end", "del_tokens": "update_attributes ( :status => Dogpile :: COMPLETE ) if all_work_units_done?", "commit_type": "add"}
{"commit_tokens": ["adding", "scaffold", "for", "creating", "users", "and", "managing", "user", "sessions", "."], "add_tokens": "# protect_from_forgery # See ActionController::RequestForgeryProtection for details include SimplestAuth :: Controller", "del_tokens": "protect_from_forgery # See ActionController::RequestForgeryProtection for details", "commit_type": "add"}
{"commit_tokens": ["removing", "the", ":", "returns", "option", "from", "the", "README", "for", "now"], "add_tokens": "if args . last . is_a? ( Hash ) hash_args = args . pop self . external_index = hash_args [ :external_index ]", "del_tokens": "if args . last . is_a? ( Hash ) and args . last . has_key? ( :external_index ) self . external_index = args . pop [ :external_index ]", "commit_type": "remove"}
{"commit_tokens": ["Make", "real", "check", "for", "upload", "module", "helper", "test", "."], "add_tokens": "dest . execute ( \"git push --all #{@remote_path}\" )", "del_tokens": "dest . execute ( \"git push --all\" )", "commit_type": "make"}
{"commit_tokens": ["Add", "covenience", "method", "for", "successfully", "running", "stuff"], "add_tokens": "world ? world . announce ( \"$ #{cmd}\" ) : STDOUT . puts ( \"$ #{cmd}\" ) if ( announce ) world ? world . announce ( @last_stdout ) : STDOUT . puts ( @last_stdout ) end", "del_tokens": "world ? world . announce ( cmd ) : STDOUT . puts ( cmd )", "commit_type": "add"}
{"commit_tokens": ["Improve", "docs", "and", "refactor", "code"], "add_tokens": "VERSION = '0.6.4'", "del_tokens": "VERSION = '0.6.3'", "commit_type": "improve"}
{"commit_tokens": ["added", "a", "raw", "tiny_mce_init", "method", "for", "use", "in", "javascript", "methods", "."], "add_tokens": "def raw_tiny_mce_init ( options = @tiny_mce_options ) end def tiny_mce_init ( options = @tiny_mce_options ) javascript_tag raw_tiny_mce_init ( options )", "del_tokens": "def tiny_mce_init ( options = @tiny_mce_options ) javascript_tag tinymce_js", "commit_type": "add"}
{"commit_tokens": ["Fixed", "+", "Client", ".", "connections", "+", "it", "did", "not", "stringify", "fields", "properly", "."], "add_tokens": "# use the verifier is the pin that LinkedIn gives users. path += \":(#{options[:fields].map{|f| f.to_s.gsub(\"_\",\"-\")}.join(',')})\"", "del_tokens": "# use the verifier is the pin that twitter gives users. path += \":(#{options[:fields].map{|f| f.to_s}.join(',')})\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "test", "for", "the", "camelizer", "and", "fixed", "a", "bug", "with", "the", "callbackData"], "add_tokens": "options [ :callbackData ] = options [ :callback_data ]", "del_tokens": "params [ :callbackData ] = options [ :callback_data ]", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "require", "call", "in", "some", "classes"], "add_tokens": "end", "del_tokens": "require 'sightstone/stat' end", "commit_type": "fix"}
{"commit_tokens": ["Fix", "automatic", "login", "support", "."], "add_tokens": "require 'fileutils' require 'tempfile' login cookies_file_entry = '.' + bugzilla_request_hostname if File . exists? ( COOKIES_FILE ) Tempfile . open ( 'ruby_bugzilla' ) do | out_file | File . open ( COOKIES_FILE , 'r' ) . each do | line | out_file . print line unless line . include? cookies_file_entry end out_file . close ( unlink_now = false ) FileUtils . mv ( out_file . path , COOKIES_FILE ) end end def login", "del_tokens": "def self . logged_in? File . exists? ( COOKIES_FILE ) end def self . clear_login! File . delete ( COOKIES_FILE ) if File . exists? ( COOKIES_FILE ) end def logged_in? self . class . logged_in? end self . class . clear_login! end def login if logged_in? self . last_command = nil return \"Already Logged In\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "Git", ".", "new", "instead", "of", "Git", ".", "clone"], "add_tokens": "@git ||= Git . new ENV [ 'PWD' ]", "del_tokens": "@git ||= Git . clone ENV [ 'PWD' ]", "commit_type": "use"}
{"commit_tokens": ["Allow", "passing", "in", "a", "spec", "or", "dep", "to", "Gem", "."], "add_tokens": "# name can be either a string name, Gem::Dependency, or Gem::Specification name = name . to_spec if name . is_a? ( :: Gem :: Dependency ) # Allow passing either if name . is_a? ( :: Gem :: Specification ) raise Error . new ( \"Cannot pass version when using an explicit specficiation\" ) if version @spec = name @name = spec . name @version = spec . version . to_s else @name = name @version = version raise Error . new ( \"Gem #{name}#{version ? \" v#{version}\" : ''} not found\" ) unless spec end", "del_tokens": "@name = name @version = version raise \"Gem #{name}#{version ? \" v#{version}\" : ''} not found\" unless spec", "commit_type": "allow"}
{"commit_tokens": ["fixed", "spec", "of", "redir", "handling"], "add_tokens": "def nested_handler_1 . handle_method ( klass , recv , m ) RedirectHelper :: Redirect . new ( klass , recv , :bar ) end", "del_tokens": "redir = RedirectHelper :: Redirect . new ( X_ , x , :bar )", "commit_type": "fix"}
{"commit_tokens": ["Move", "mocks", "down", "to", "test", "dir"], "add_tokens": "require \"test/mocks\"", "del_tokens": "require \"test/mocks/mocks\"", "commit_type": "move"}
{"commit_tokens": ["adding", "name", "to", "the", "user_info", "hash", "for", "ldap"], "add_tokens": "@@config = { 'name' => 'cn' , 'first_name' => 'givenName' , 'last_name' => 'sn' , 'email' => [ 'mail' , \"email\" , 'userPrincipalName' ] , end", "del_tokens": "@@config = { 'first_name' => 'givenName' , 'last_name' => 'sn' , 'email' => [ 'mail' , \"email\" , 'userPrincipalName' ] , end", "commit_type": "add"}
{"commit_tokens": ["Created", "ArgumentEqualityExpectation#", "==", "method", "."], "add_tokens": "before do @expectation = ArgumentEqualityExpectation . new ( 1 , 2 , 3 ) end it \"returns true when passed in expected_arguments are equal\" do @expectation . should == ArgumentEqualityExpectation . new ( 1 , 2 , 3 ) end it \"returns false when passed in expected_arguments are not equal\" do @expectation . should_not == ArgumentEqualityExpectation . new ( 1 , 2 ) @expectation . should_not == ArgumentEqualityExpectation . new ( 1 ) @expectation . should_not == ArgumentEqualityExpectation . new ( :something ) @expectation . should_not == ArgumentEqualityExpectation . new ( ) end", "del_tokens": "it \"returns true when passed in expected_arguments are equal\"", "commit_type": "create"}
{"commit_tokens": ["Made", "a", "start", "registering", "files", "and", "files_dependencies", "to", "Motion", "::", "Project", "::", "App", "during", "MotionBundler", ".", "setup"], "add_tokens": "Require . trace do Motion :: Project :: App . setup do | app | app . files += [ ] #Require::Tracer.log.files app . files_dependencies Hash . new #Require::Tracer.log.files_dependencies end", "del_tokens": "MotionBundler :: Require . trace do", "commit_type": "make"}
{"commit_tokens": ["Fixed", "bug", "where", "records", "weren", "t", "being", "marked", "as", "dirty", "."], "add_tokens": "wid = Widget . create! name : 'Flower' , thumbnail : example_image ( 1 ) , photo : example_image ( 2 ) wid . reload wid . thumbnail = example_image ( 2 ) assert wid . attribute_changed? ( :thumbnail ) wid . reload wid . attributes = { thumbnail : example_image ( 2 ) } assert wid . attribute_changed? ( :thumbnail )", "del_tokens": "skip # http://api.rubyonrails.org/classes/ActiveModel/Dirty.html", "commit_type": "fix"}
{"commit_tokens": ["Make", "subscription", "payment", "available", "through", "Subscription#payment"], "add_tokens": ":trial_start , :trial_end , :next_capture_at , :payment", "del_tokens": ":trial_start , :trial_end , :next_capture_at", "commit_type": "make"}
{"commit_tokens": ["add", "validation", "errors", "using", "(", "i18n", "translatable", ")", "symbols"], "add_tokens": "record . errors . add ( :iban , :invalid ) record . errors . add ( :bic , :invalid ) record . errors . add ( :creditor_identifier , :invalid )", "del_tokens": "record . errors . add ( :iban , 'is invalid' ) record . errors . add ( :bic , 'is invalid' ) record . errors . add ( :creditor_identifier , 'is invalid' )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "publishing", "for", "snapshots", "and", "repos", "."], "add_tokens": "raise AptlyError . new \"Snapshot '#{name}' exists\" end if type == 'mirror' && ! list_mirrors . include? ( resource_name ) raise AptlyError . new \"Mirror '#{resource_name}' does not exist\" end if type == 'repo' && ! list_repos . include? ( resource_name ) raise AptlyError . new \"Repo '#{resource_name}' does not exist\" Snapshot . new name # Shortcut method to publish a snapshot from an Aptly::Snapshot instance. def publish * args Aptly :: publish 'snapshot' , @name , * args end", "del_tokens": "raise AptlyError . new \"Snapshot '#{name}' already exists\" return Snapshot . new name", "commit_type": "implement"}
{"commit_tokens": ["Adding", "the", "ability", "to", "preload", "parameters", "on", "plugin", "objects"], "add_tokens": "# @param hash params def Plugg . source ( path , params = { } ) Dispatcher . start ( load_path , params ) def Plugg . send ( evt ) Dispatcher . instance . on ( evt ) @@params = { } # @param mixed path # @param hash params def self . start ( path , params = { } ) @@params = params instance = Object . const_get ( File . basename ( f , '.rb' ) ) . new if instance . respond_to? ( :set_params ) instance . send ( :set_params , @@params ) end instance instance = nil puts \"#{f} Initialization Exception: #{e}\" if [ :initialize , :set_params ] . include? method raise \"#{method} should not be called this way\" end", "del_tokens": "def Plugg . source ( path ) Dispatcher . plugin_path = load_path def Plugg . send ( evt , params = { } ) Dispatcher . instance . on ( evt , params ) # @param string path def self . plugin_path = ( path ) Object . const_get ( File . basename ( f , '.rb' ) ) . new puts \"#{f} Initialization Exception.\"", "commit_type": "add"}
{"commit_tokens": ["added", "amit", "dataset", "parsing", "static", "lazar", "feature", "modifier"], "add_tokens": "raise \"Please edit #{user_file} and restart your application. Create at least one user with password.\"", "del_tokens": "puts \"Please edit #{user_file} and restart your application. Create at least one user with password.\" exit", "commit_type": "add"}
{"commit_tokens": ["Use", "nil", "instead", "of", "false"], "add_tokens": ":log_actions => nil , :log_responses => nil , :raise_on_401 => nil", "del_tokens": ":log_actions => false , :log_responses => false , :raise_on_401 => false", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "US", "ACH", "calendar"], "add_tokens": "VERSION = \"1.16.1\"", "del_tokens": "VERSION = \"1.16.0\"", "commit_type": "fix"}
{"commit_tokens": ["Removing", "ANSIColor", "and", "add", "a", "rescue", "option", "for", "people", "that", "don", "t", "use", "rubygems"], "add_tokens": "begin require 'terminal-table/import' rescue LoadError require 'rubygems' require 'terminal-table/import' end extend SpecI18n :: Parser", "del_tokens": "require 'rubygems' require 'term/ansicolor' require 'terminal-table/import' include SpecI18n :: Parser include Term :: ANSIColor", "commit_type": "remove"}
{"commit_tokens": ["Make", "sure", "from", "and", "end", "states", "are", "uniq"], "add_tokens": "end . uniq end . uniq", "del_tokens": "end end", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "for", "extracting", "and", "assigning", "sub", "-", "arrays"], "add_tokens": "s = S ( I , 4 ) . indgen ( 1 ) [ ] assert_equal [ 2 , 3 ] , s [ 1 .. 2 ] . to_a assert_equal [ 2 , 3 ] , s [ 1 ... 3 ] . to_a s [ 1 .. 2 ] = 0 assert_equal [ 1 , 0 , 0 , 4 ] , s . to_a s [ 1 ... 3 ] = 5 assert_equal [ 1 , 5 , 5 , 4 ] , s . to_a s [ 1 .. 2 ] = S [ 6 , 7 ] assert_equal [ 1 , 6 , 7 , 4 ] , s . to_a s [ 1 ... 3 ] = S [ 8 , 9 ] assert_equal [ 1 , 8 , 9 , 4 ] , s . to_a", "del_tokens": "assert_equal [ 2 , 3 ] , S [ 1 , 2 , 3 , 4 ] [ 1 .. 2 ] . to_a", "commit_type": "add"}
{"commit_tokens": ["use", "DATABASE_URL", "or", "SHARED_DATABASE_URL", "for", "database", "config", "if", "present"], "add_tokens": "config . database . should == { :adapter => 'postgresql' , :database => 'travis_test' , :encoding => 'unicode' , :min_messages => 'warning' } end end describe 'using DATABASE_URL for database configuration if present' do before :each do @database_url = ENV [ 'DATABASE_URL' ] end after :each do ENV [ 'DATABASE_URL' ] = @database_url end it 'works when given a url with a port' do ENV [ 'DATABASE_URL' ] = 'postgres://username:password@hostname:port/database' config . database . should == { :adapter => 'postgresql' , :host => 'hostname' , :port => 'port' , :database => 'database' , :username => 'username' , :password => 'password' , :encoding => 'unicode' , :min_messages => 'warning' } end it 'works when given a url without a port' do ENV [ 'DATABASE_URL' ] = 'postgres://username:password@hostname/database' config . database . should == { :adapter => 'postgresql' , :host => 'hostname' , :database => 'database' , :username => 'username' , :password => 'password' , :encoding => 'unicode' , :min_messages => 'warning' }", "del_tokens": "config . database . should == { :adapter => 'postgresql' , :database => 'travis_test' , :encoding => 'unicode' , :min_messages => 'warning' }", "commit_type": "use"}
{"commit_tokens": ["updated", "the", "content", "editable", "proxy", ".", "range", "object", "is", "now", "returned", "for", "methods", "that", "set", "the", "cursor", "position", ".", "Also", "added", "insert", "methods", "to", "the", "content", "editable", "proxy", "object", "itself"], "add_tokens": "return range return range def insert_content_at_start ( content ) range = set_cursor_to_start range . insert_content content end def insert_content_at_end ( content ) range = set_cursor_to_end range . insert_content content end return range return range return range range = set_cursor_before range = set_cursor_after", "del_tokens": "range = @view . create_range range . set_start_before self range . set_end_before self range = @view . create_range range . set_start_after self range . set_end_after self", "commit_type": "update"}
{"commit_tokens": ["Make", "VendorTxCode", "unique", "with", "truncated", "timestamp", "."], "add_tokens": "attr_reader :identifier def initialize ( order , account , options = { } ) super @identifier = rand ( 0 .. 99999 ) . to_s . rjust ( 5 , '0' ) add_field 'VendorTxCode' , \"#{order}#{@identifier}\" end", "del_tokens": "mapping :order , 'VendorTxCode'", "commit_type": "make"}
{"commit_tokens": ["Fix", "typo", "with", "instance", "variable"], "add_tokens": "@_context . respond_to? ( name ) ? @_context . send ( name , * args , & block ) : super", "del_tokens": "@context . respond_to? ( name ) ? @context . send ( name , * args , & block ) : super", "commit_type": "fix"}
{"commit_tokens": ["add", "case", "for", "validation", "of", "cursor", "argument", "to", "use", "default", "values"], "add_tokens": "return true if [ :keyreq , :key ] . include? ( parameter_type )", "del_tokens": "return true if parameter_type == :keyreq", "commit_type": "add"}
{"commit_tokens": ["Made", "expression", "a", "required", "field", "on", "RubyEdit", "::", "CLI", "#grep", "and", "#edit"], "add_tokens": "desc : 'the grep expression' , required : true desc : 'the grep expression' , required : true", "del_tokens": "method_option :help , aliases : '-h' , type : :boolean , desc : 'Display usage information' desc : 'the grep expression' method_option :help , aliases : '-h' , type : :boolean , desc : 'Display usage information' desc : 'the grep expression'", "commit_type": "make"}
{"commit_tokens": ["Add", "common", "attributes", "for", "resources", "."], "add_tokens": "include AttributeMethods { 'Type' => self . class . aws_name , 'Properties' => props_cf } . merge ( common_attributes )", "del_tokens": "{ 'Type' => self . class . aws_name , 'Properties' => props_cf }", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "Message", "::", "valid?", "::", "recv", "returns", "Message", "object", "instead", "of", "string"], "add_tokens": "mesg_str = \"\" until mesg_str . match ( / \\r \\n $ / ) do mesg_str << @socket . gets return Message . parse mesg_str", "del_tokens": "message = \"\" until message . match ( / \\r \\n $ / ) do message << @socket . gets return message", "commit_type": "add"}
{"commit_tokens": ["added", "method", "to", "retrun", "the", "link", "element"], "add_tokens": "# adds two methods - one to select a link and another # to return a PageObject::Elements::Link object representing # the link. # will generate the 'add_to_cart' and 'add_to_cart_link' # method. define_method ( \"#{name}_link\" ) do driver . link_for identifier end", "del_tokens": "# adds a methods to select a link. # will generate the 'add_to_cart' method that will click the link.", "commit_type": "add"}
{"commit_tokens": ["Adding", "server", "method", "to", "CLI"], "add_tokens": "Machined :: Environment . should_receive ( :new ) . with ( :root => \".\" , :output_path => \"public\" , :environment => \"production\" ) . and_return ( machined ) machined_cli \"compile -e production\" it \"should start a Rack server\" do app = machined Machined :: Environment . should_receive ( :new ) . with ( :root => \".\" , :output_path => \"site\" , :environment => \"production\" ) . and_return ( app ) Rack :: Server . should_receive ( :start ) . with ( hash_including ( :app => app , :environment => \"production\" , :Port => 5000 ) ) machined_cli \"server -o site -e production -p 5000\" end", "del_tokens": "Machined :: Environment . should_receive ( :new ) . and_return ( machined ) machined_cli \"compile\"", "commit_type": "add"}
{"commit_tokens": ["Added", "list", "yardocs", "and", "helper", "methods", "for", "pages"], "add_tokens": "# @raise [ComicVineAPIError] indicating the api request code received", "del_tokens": "# @raise [ComicVineAPIError] indicating the api request code recived", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "bcrypt", "-", "ruby", "dependency", ".", "(", "thanks", "to", "GarPit", ")"], "add_tokens": "VERSION = \"0.4.6.3\"", "del_tokens": "VERSION = \"0.4.6.2\"", "commit_type": "add"}
{"commit_tokens": ["Use", "bundler", "if", "present", "to", "load", "gems", "in", "standalone", "mode"], "add_tokens": "require 'semantic_logger' logger . info \"Loading Rails environment: #{environment}\" boot_file = Pathname . new ( directory ) . join ( 'config/environment.rb' ) . expand_path require ( boot_file . to_s ) # Try to load bundler if present begin require 'bundler/setup' Bundler . require ( environment ) rescue LoadError end require 'rocketjob' begin require 'rocketjob_pro' rescue LoadError end # Log to file except when booting rails, when it will add the log file path path = log_file ? Pathname . new ( log_file ) : Pathname . pwd . join ( \"log/#{environment}.log\" ) path . dirname . mkpath SemanticLogger . add_appender ( path . to_s , & SemanticLogger :: Appender :: Base . colorized_formatter )", "del_tokens": "require 'mongo_mapper' logger . info \"Loading Rails environment: #{environment}\" boot_file = Pathname . new ( directory ) . join ( 'config/environment.rb' ) . expand_path require ( boot_file . to_s ) # Log to file except when booting rails, when it will add the log file path unless rails? path = log_file ? Pathname . new ( log_file ) : Pathname . pwd . join ( \"log/#{environment}.log\" ) path . dirname . mkpath SemanticLogger . add_appender ( path . to_s , & SemanticLogger :: Appender :: Base . colorized_formatter ) end", "commit_type": "use"}
{"commit_tokens": ["make", "sure", "buffered", "IO", "is", "thread", "-", "safe"], "add_tokens": "require 'thread' input_mutex . synchronize do input . consume! data = recv ( n ) trace { \"read #{data.length} bytes\" } input . append ( data ) return data . length end input_mutex . synchronize { input . read ( length ) } input_mutex . synchronize { input . available } output_mutex . synchronize { output . append ( data ) } output_mutex . synchronize { output . length > 0 } output_mutex . synchronize do if output . length > 0 sent = send ( output . to_s , 0 ) trace { \"sent #{sent} bytes\" } output . consume! ( sent ) end while output . length > 0 attr_reader :input , :output , :input_mutex , :output_mutex @input_mutex = Mutex . new @output_mutex = Mutex . new", "del_tokens": "attr_reader :input , :output input . consume! data = recv ( n ) trace { \"read #{data.length} bytes\" } input . append ( data ) return data . length input . read ( length ) input . available output . append ( data ) output . length > 0 if pending_write? sent = send ( output . to_s , 0 ) trace { \"sent #{sent} bytes\" } output . consume! ( sent ) while pending_write?", "commit_type": "make"}
{"commit_tokens": ["Added", "rsymc", "to", "status", "dialog", ".", "also", "refactor", "."], "add_tokens": "def mark_rsync_installed @rsync_label . text = @rsync_label . text + \"<br>found: #{$device.rsync_path}\" @layout . addWidget installed_check_mark , 7 , 1 setFixedHeight ( sizeHint ( ) . height ( ) ) ; end @layout . addWidget @close_button , 8 , 2 ####################### ### rsync ####################### @rsync_label = Qt :: Label . new \"<b>rsync</b><br>(folder synchronization)\" @layout . addWidget @rsync_label , 7 , 0 if $device . rsync_installed? mark_rsync_installed else @install_rsync = Qt :: PushButton . new \"Install\" @install_rsync . connect ( SIGNAL ( :released ) ) { $device . install_rsync if $device . rsync_installed? @install_rsync . hide mark_rsync_installed end } @layout . addWidget @install_rsync , 7 , 1 end", "del_tokens": "@layout . addWidget @close_button , 7 , 2", "commit_type": "add"}
{"commit_tokens": ["Makes", "auth", "non", "destructive", "on", "rack", "clients", ".", "Also", "makes", "md5", "orrect", "on", "rest", "client", "."], "add_tokens": "body = @request . payload . read @request . payload . instance_variable_get ( :@stream ) . seek ( 0 ) value . nil? ? \"\" : value", "del_tokens": "body = @request . payload . inspect value . nil? ? \"text/plain\" : value", "commit_type": "make"}
{"commit_tokens": ["use", "ThreadSafe", "::", "Cache", "for", "threaded", "Session"], "add_tokens": "class EmCache < Hash def initialize @mutex = EM :: Synchrony :: Thread :: Mutex . new super end def [] ( key ) @mutex . synchronize do super end end def []= ( key , val ) @mutex . synchronize do super end end end @sessions = ( em_client? ? EmCache . new : ThreadSafe :: Cache . new ) #@mutex.synchronize do #end @sessions . each_pair do | key , clnt | #@mutex.synchronize do #end", "del_tokens": "@sessions = Hash . new @mutex = ( em_client? ? EM :: Synchrony :: Thread :: Mutex . new : Mutex . new ) @mutex . synchronize do end @sessions . each do | key , clnt | @mutex . synchronize do end", "commit_type": "use"}
{"commit_tokens": ["Add", "in", "hook", "to", "only", "provide", "the", "deprecated", "API", "when", "the", "client", "doesn", "t", "require", "thrift", "directly"], "add_tokens": "module Thrift # prevent the deprecation layer from being loaded if you require 'thrift' DEPRECATION = false unless const_defined? :DEPRECATION end require 'thrift/deprecation' require 'thrift/exceptions'", "del_tokens": "require 'thrift/exceptions' TException = Thrift :: Exception TApplicationException = Thrift :: ApplicationException TType = Thrift :: Types TMessageType = Thrift :: MessageTypes TProcessor = Thrift :: Processor ThriftClient = Thrift :: Client ThriftStruct = Thrift :: Struct TProtocol = Thrift :: Protocol TProtocolException = Thrift :: ProtocolException", "commit_type": "add"}
{"commit_tokens": ["Fix", "case", "of", "entry", "point", "with", "more", "than", "one", "arg"], "add_tokens": "use_case_object = args . empty? ? new : new ( * args )", "del_tokens": "use_case_object = args . empty? ? new : new ( args )", "commit_type": "fix"}
{"commit_tokens": ["Add", "optional", "parse_mode", "attribute", "to", "text", "message"], "add_tokens": "# @param parse_mode [String] \"Markdown\" or \"HTML\", Optional def send_message ( chat_id : , text : , disable_web_page_preview : false , reply_to_message_id : nil , reply_markup : nil , parse_mode : nil ) reply_markup : reply_markup , parse_mode : parse_mode", "del_tokens": "def send_message ( chat_id : , text : , disable_web_page_preview : false , reply_to_message_id : nil , reply_markup : nil ) reply_markup : reply_markup", "commit_type": "add"}
{"commit_tokens": ["Changed", "default", "logo", "name", "and", "added", "margin", "to", "image", "in", "UI"], "add_tokens": "@@config . logo = '/assets/deal-redemptions-logo.png'", "del_tokens": "@@config . logo = '/assets/logo.png'", "commit_type": "change"}
{"commit_tokens": ["added", "node", "validations", "/", "errors"], "add_tokens": "class ParentlessNodeError < StandardError ; end @nodes = input_nodes . map { | e | Node . new ( e ) } validate_nodes if options [ :validate ] def validate_nodes @nodes . each do | e | raise ParentlessNodeError if ( e [ :level ] > e . previous [ :level ] ) && ( e [ :level ] - e . previous [ :level ] ) . abs > 1 end end class MissingLevelError < StandardError ; end class MissingValueError < StandardError ; end raise MissingLevelError unless hash . has_key? ( :level ) raise MissingValueError unless hash . has_key? ( :value )", "del_tokens": "@nodes = input_nodes", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "link", "to", "the", "original", "scales", "description", "."], "add_tokens": "# Source: https://github.com/d3/d3-scale/blob/master/README.md#category-scales", "del_tokens": "# Source: https://github.com/mbostock/d3/wiki/Ordinal-Scales#categorical-colors", "commit_type": "change"}
{"commit_tokens": ["Use", "SSL", "for", "connection", "to", "campfire", "API", "."], "add_tokens": "\"https://#{subdomain}.campfirenow.com\"", "del_tokens": "\"http://#{subdomain}.campfirenow.com\"", "commit_type": "use"}
{"commit_tokens": ["add", "scopes", "to", "the", "collection"], "add_tokens": "def self . collection_scope lambda @@collection_scope = lambda end filtered_collection = end_of_association_chain if @@collection_scope filtered_collection = @@collection_scope . call ( filtered_collection ) end assocation = filtered_collection . page ( params [ :page ] || 1 )", "del_tokens": "assocation = end_of_association_chain . page ( params [ :page ] || 1 )", "commit_type": "add"}
{"commit_tokens": ["use", "coveralls", "when", "COVERAGE", "is", "enabled"], "add_tokens": "if ENV [ \"COVERAGE\" ] require 'coveralls' Coveralls . wear! end", "del_tokens": "require 'coveralls' Coveralls . wear!", "commit_type": "use"}
{"commit_tokens": ["move", "some", "unused", "parse", "related", "classes", "out", "of", "the", "way"], "add_tokens": "require \"asm/nodes\"", "del_tokens": "require \"asm/parser\"", "commit_type": "move"}
{"commit_tokens": ["Updated", "to", "use", "the", "new", "module_creation_helper", "."], "add_tokens": "def test_state_deadline_class def test_subclassed_state_deadline_class assert_not_equal Car :: StateDeadline , Vehicle :: StateDeadline end", "del_tokens": "def test_deadline_class", "commit_type": "update"}
{"commit_tokens": ["Add", "both", "force_bind", "and", "force_bind_rbx", "as", "dependencies", "in", "the", "gemspec"], "add_tokens": "case RUBY_ENGINE when 'ruby' require 'force_bind' when 'rbx' require 'force_bind_rbx' else fail \"force binding is not supported on #{RUBY_ENGINE}\" end", "del_tokens": "require 'force_bind'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "parsing", "in", "XML#tasks", "."], "add_tokens": "task_end = task_begin . xpath ( 'following-sibling::taskend' ) . first", "del_tokens": "task_end = task_begin . next", "commit_type": "fix"}
{"commit_tokens": ["Make", "it", "possible", "to", "declare", "a", "base", "class", "for", "the", "exception"], "add_tokens": "base_klass = options [ :base ] || Error klass = Class . new ( base_klass )", "del_tokens": "klass = Class . new ( Error )", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "to", "use", "view", "content", "link", "."], "add_tokens": "describe '#view_content_link' do it 'takes a view_content_link with true' do mail = mail ( view_content_link : true ) message = described_class . new ( mail ) expect ( message . view_content_link ) . to be true end it 'takes a view_content_link with false' do mail = mail ( view_content_link : false ) message = described_class . new ( mail ) expect ( message . view_content_link ) . to be false end it 'does not take view_content_link value' do mail = mail ( ) message = described_class . new ( mail ) expect ( message . view_content_link ) . to be_nil end end", "del_tokens": "pending '#view_content_link'", "commit_type": "add"}
{"commit_tokens": ["Creating", "basic", "dsl", "integration", "test"], "add_tokens": "require 'outpost/scouts/http_scout' depends Outpost :: Scouts :: HttpScout => 'master http server' do options :host => 'example.com'", "del_tokens": "depends Object => 'master http server' do options :host => 'localhost'", "commit_type": "create"}
{"commit_tokens": ["Added", "public", "/", "protected", "/", "private", "as", "things", "that", "don", "t", "need", "an", "empty", "line", "."], "add_tokens": "when / ^[ \\t ]*(#|private \\b |public \\b |protected \\b ) /", "del_tokens": "when / ^# /", "commit_type": "add"}
{"commit_tokens": ["Updated", "HelloWorld", "sample", "to", "be", "able", "to", "choose", "whether", "to", "use", "the", "gem", "or", "the", "development", "code"], "add_tokens": "# # This code is free software; you can redistribute it and/or modify it under the # terms of the new BSD License. # # Copyright (c) 2009, Sebastian Staudt if ENV [ 'RUBIKON_DEV' ] require File . join ( File . dirname ( __FILE__ ) , '..' , 'lib' , 'rubikon' ) else require 'rubygems' require 'rubikon' end", "del_tokens": "require 'rubygems' require 'rubikon'", "commit_type": "update"}
{"commit_tokens": ["Added", "description", "for", "MongoDb", "plugin"], "add_tokens": "VERSION = \"0.4.5\"", "del_tokens": "VERSION = \"0.4.4\"", "commit_type": "add"}
{"commit_tokens": ["Add", "special", "exception", "for", "non", "-", "equality", "comparisons", "between", "two", "non", "-", "static", "data", "sources"], "add_tokens": "raise ArgumentError , \"argument #{i + 1} (#{arg.object.inspect}) was not one of the expected values: #{parameter_options[:values].inspect}\"", "del_tokens": "raise ArgumentError , \"argument #{i + 1} was not one of the expected values: #{paramters_options[:values].inspect}\"", "commit_type": "add"}
{"commit_tokens": ["Created", "repository", "test", "to", "verify", "if", "adapter", "type", "is", "correct"], "add_tokens": "attr_reader :adapter EventEntity . new . tap do | event |", "del_tokens": "attr_reader :adapter Models :: EventEntity . new . tap do | event |", "commit_type": "create"}
{"commit_tokens": ["Fix", "for", "Faraday", "constant", "references", "in", "the", "staccato", "faraday", "adapter"], "add_tokens": "require 'faraday' @connection = :: Faraday . new ( uri ) do | faraday | faraday . adapter :: Faraday . default_adapter # make requests with Net::HTTP", "del_tokens": "@connection = Faraday . new ( uri ) do | faraday | faraday . adapter Faraday . default_adapter # make requests with Net::HTTP", "commit_type": "fix"}
{"commit_tokens": ["add", "negation", "to", "the", "trigger", "agent"], "add_tokens": "VALID_COMPARISON_TYPES = %w[ regex !regex field<value field<=value field==value field!=value field>=value field>value ] when \"!regex\" value_at_path . to_s !~ Regexp . new ( rule [ :value ] , Regexp :: IGNORECASE ) when \"field!=value\" value_at_path . to_s != rule [ :value ] . to_s", "del_tokens": "VALID_COMPARISON_TYPES = %w[ regex field<value field<=value field==value field>=value field>value ]", "commit_type": "add"}
{"commit_tokens": ["Adding", "--", "quiet", "cli", "option", "quick", "and", "dirty", "for", "now"], "add_tokens": "puts \"Processing complete!\" unless options [ :quiet ] puts \"Packer file generated: #{options[:output]}\" unless options [ :quiet ] templates : [ ] , quiet : false , opts . on ( '-q' , '--quiet' , 'Disable unnecessary output' ) do | v | options [ :quiet ] = v || '~~' end", "del_tokens": "puts \"Processing complete! Packer file generated: #{options[:output]}\" templates : [ ] ,", "commit_type": "add"}
{"commit_tokens": ["remove", "require", "of", "date", "temporaly"], "add_tokens": "#require 'date'", "del_tokens": "require 'date'", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "view_permission", "calculated", "at", "the", "instance", "level", "."], "add_tokens": "class << self attr_accessor :view_permission end def self . extended ( base ) # Delegate view_permission to permission_link def view_permission permission_link . try ( :component_view_permission ) end def recurse_to_inherit_custom_view_permission ( current_view_permission = self . class . view_permission ) if current_view_permission . respond_to? ( :call ) return current_view_permission . call ( self ) else return current_view_permission || :view end", "del_tokens": "def self . extended ( base ) base . cattr_accessor :view_permission def recurse_to_inherit_custom_view_permission ( current_view_permission = self . view_permission ) return ( current_view_permission || :view ) . to_s def view_permission @view_permission || self . class . view_permission end attr_writer :view_permission", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "that", "case", "of", "without", "labels", "option"], "add_tokens": "def create_pr ( title : , body : , base : , labels : nil ) return false unless git_condition_valid? github . add_labels ( pr_number , labels ) unless labels . nil? def git_condition_valid? ! git . current_sha1? ( initial_sha1 ) && git . current_branch? ( topic_branch ) end", "del_tokens": "def create_pr ( title : , body : , base : , labels : [ ] ) return false if git . current_sha1? ( initial_sha1 ) return false unless git . current_branch? ( topic_branch ) github . add_labels ( pr_number , labels )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Security", "/", "YAMLLoad", "rubocop", "offense"], "add_tokens": "YAML . safe_load ( yaml_data )", "del_tokens": "YAML . load ( yaml_data )", "commit_type": "fix"}
{"commit_tokens": ["using", "primary_key", "instead", "of", "literal", "id", "so", "custom", "primary", "key", "works"], "add_tokens": "@attributes = { model_class . primary_key . to_sym => id } name_without_equal = name . sub ( '=' , '' ) if @columns . include? ( name_without_equal ) || @attributes . has_key? ( name_without_equal . to_sym ) @attributes [ name_without_equal . to_sym ] = Populator . interpret_value ( args . first )", "del_tokens": "@attributes = { :id => id } if @columns . include? ( name . sub ( '=' , '' ) ) @attributes [ name . sub ( '=' , '' ) . to_sym ] = Populator . interpret_value ( args . first )", "commit_type": "use"}
{"commit_tokens": ["fixed", "a", "bug", "in", "string", "unification", "removed", "rubylog_variables_hash"], "add_tokens": "rubylog_get_string_variable ( $1 , $2 ) . rubylog_deep_dereference . to_s # returns a list of substrings which are before, between and after the # rubylog # string variables, and the list of variabes in between vars << rubylog_get_string_variable ( match [ 1 ] , match [ 2 ] ) # def rubylog_get_string_variable name , guards_index name = name . to_sym raise Rubylog :: InvalidStateError , \"Variables not matched\" unless @rubylog_variables @rubylog_variables . find { | v | v . name == name } || Rubylog :: Variable . new [ * RubylogStringVariableGuards [ guards_index . to_i ] ]", "del_tokens": "rubylog_get_string_variable ( $1 ) . rubylog_deep_dereference . to_s # returns a list of substrings which are before, between and after the rubylog # string variables vars << rubylog_get_string_variable ( match [ 1 ] ) def rubylog_get_string_variable s s = s . to_sym if @rubylog_variables @rubylog_variables . find { | v | v . name == s } else raise Rubylog :: InvalidStateError , \"Variables not matched\" end", "commit_type": "fix"}
{"commit_tokens": ["Add", "method", "to", "alter", "table", "options", "with", "a", "migration"], "add_tokens": "it 'should produce a valid CQL create statement' do @migration . up expected_cql = \"CREATE TABLE collection_lists (id uuid, a_decimal decimal, PRIMARY KEY(id)) WITH gc_grace_seconds = 43200\" expect ( @migration . cql ) . to eq ( expected_cql ) it 'should produce a valid CQL alter table statement' do @migration = ChangePropertyMigration . new expected_cql = \"ALTER TABLE collection_lists WITH gc_grace_seconds = 20000\"", "del_tokens": "before do it 'should produce a valid CQL create statement' do expected_cql = \"CREATE TABLE collection_lists (id uuid, a_decimal decimal, PRIMARY KEY(id)) WITH gc_grace_seconds = 43200\"", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "save", "name_servers", "in", "systems"], "add_tokens": ":virt_file_size , :virt_path , :virt_ram , :virt_auto_boot , :virt_type , :gateway , :hostname , :name_servers , :timeout", "del_tokens": ":virt_file_size , :virt_path , :virt_ram , :virt_auto_boot , :virt_type , :gateway , :hostname , :timeout", "commit_type": "add"}
{"commit_tokens": ["use", "curl", "to", "download", "files"], "add_tokens": "def download remote_path , local_path url = \"http#{@soap.http.use_ssl? ? 's' : ''}://#{@soap.http.address}:#{@soap.http.port}#{mkuripath(remote_path)}\" pid = spawn CURLBIN , \"-k\" , '--noproxy' , '*' , '-f' , \"-o\" , local_path , \"-b\" , @soap . cookie , url , out : '/dev/null' Process . waitpid ( pid , 0 ) fail \"download failed\" unless $? . success? pid = spawn CURLBIN , \"-k\" , '--noproxy' , '*' , '-f' ,", "del_tokens": "def get path , io req = Net :: HTTP :: Get . new mkuripath ( path ) req . initialize_http_header 'cookie' => @soap . cookie resp = @soap . http . request ( req ) case resp when Net :: HTTPSuccess io . write resp . body if resp . is_a? Net :: HTTPSuccess true else fail resp . inspect end pid = spawn CURLBIN , \"-k\" , '--noproxy' , '*' ,", "commit_type": "use"}
{"commit_tokens": ["Allow", "serializing", "a", "Fridge", "token", "instantiated", "by", "a", "client"], "add_tokens": "attr_accessor :id , :issuer , :subject , :scope , :expires_at , :jwt # rubocop:disable MethodLength self . jwt = jwt_or_options # rubocop:enable MethodLength def to_s serialize end return jwt if jwt", "del_tokens": "attr_accessor :id , :issuer , :subject , :scope , :expires_at", "commit_type": "allow"}
{"commit_tokens": ["Fix", "regression", "in", "performance", "introduced", "in", "#a26a47f"], "add_tokens": "enter 'trace on' , 'show linetrace' , 'trace off' enter 'cont' , \"show autolist\" debug_file 'post_mortem' check_output_includes \"autolist is off.\"", "del_tokens": "enter 'trace on' , 'show linetrace' #enter 'cont', \"show autolist\" #debug_file 'post_mortem' #check_output_includes \"autolist is off.\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "rails", "5"], "add_tokens": "require 'gb_dispatch/active_record_patch' if Rails :: VERSION :: MAJOR < 5 begin ActiveRecord :: Base . connection_pool . force_new_connection do block ? block . call : yield end ensure ActiveRecord :: Base . clear_active_connections! end else Rails . application . executor . wrap do ActiveRecord :: Base . connection_pool . force_new_connection do block ? block . call : yield end", "del_tokens": "begin ActiveRecord :: Base . connection_pool . with_connection do block ? block . call : yield ensure ActiveRecord :: Base . clear_active_connections!", "commit_type": "add"}
{"commit_tokens": ["Move", "Maliq", "::", "Builder", "to", "a", "file"], "add_tokens": "%w( system_extensions file_utils converter builder ) . each { | lib | require_relative 'maliq/' + lib }", "del_tokens": "%w( system_extensions file_utils converter ) . each { | lib | require_relative 'maliq/' + lib }", "commit_type": "move"}
{"commit_tokens": ["Remove", "upgrading", "packages", "for", "LXD", ".", "It", "is", "better", "to", "use", "daily", "-", "updated", "image", "."], "add_tokens": "VERSION = \"0.1.13\"", "del_tokens": "VERSION = \"0.1.12\"", "commit_type": "remove"}
{"commit_tokens": ["Making", "the", "execution", "result", "explicit", "and", "parseable", "and", "introducing", "basic", "directory", "handling", "."], "add_tokens": "message = Console . queue . deq puts \"DEQ'd #{message.inspect}\" if ENV [ \"DEBUG\" ] result = ExecutionResult . parse message if result Dir . chdir result . directory shell . puts \"cd #{result.directory.shellescape}\" break if result . n == result . of", "del_tokens": "v = Console . queue . deq puts \"DEQ'd #{v}\" if ENV [ \"DEBUG\" ] if v =~ / ^( \\d +) \\/ ( \\d +) / a , b = $1 . to_i , $2 . to_i break if a == b # last command in chain", "commit_type": "make"}
{"commit_tokens": ["add", "rspec", "new", "syntax", "snippet"], "add_tokens": "if evaluated . size > 0 source = evaluated . first . loc . expression . source_buffer . source source [ evaluated . first . loc . expression . begin_pos ... evaluated . last . loc . expression . end_pos ] end when NilClass 'nil'", "del_tokens": "source = evaluated . first . loc . expression . source_buffer . source source [ evaluated . first . loc . expression . begin_pos ... evaluated . last . loc . expression . end_pos ]", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "objects", "that", "are", "Surrounded"], "add_tokens": "if mod = klass . const_defined? ( role_module_name ) && ! mod . is_a? ( Class ) return obj if mod . is_a? ( Class )", "del_tokens": "if klass . const_defined? ( role_module_name )", "commit_type": "add"}
{"commit_tokens": ["fixing", "bug", "causing", "problem", "during", "initialization", "from", "console"], "add_tokens": "#Yourub::Config.load!(File.join(\"config\", \"yourub.yml\"), 'yourub_defaults')", "del_tokens": "Yourub :: Config . load! ( File . join ( \"config\" , \"yourub.yml\" ) , 'yourub_defaults' )", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "render_with_fallback", "helper", "method", ".", "this", "allows", "a", "finer"], "add_tokens": "# Fix for engines with shared namespace for some reason main_app.url_for doesn't find the route without this \"/\" # It consider the route inside of engine instead of main app. def index_default_actions # ============================================================================= # Tries to render the action/partial \"namespaced\" with the current action name # if it fails, then simply calls render with whatever args that got passed in. # # Ex: # # on get to '/admin/some_resource/new' # render_with_fallback 'form' # this will to render 'new_form', if it fails, # # then it will just call \"render 'form'\" def render_with_fallback * args render \"#{params[:action]}_#{args.first}\" , * args [ 1 .. - 1 ] rescue ActionView :: MissingTemplate render * args end", "del_tokens": "# Fix for engines with shared namespace for some reason main_app.url_for doesn't find the route without this \"/\" # It consider the route inside of engine instead of main app. def index_default_actions", "commit_type": "add"}
{"commit_tokens": ["Fix", "usage", "card", "message", "in", "Readme"], "add_tokens": "sections = [ { widgets : [ { keyValue : { topLabel : 'Order No.' , content : '12345' } } , { keyValue : { topLabel : 'Status' , content : 'In Delivery' } } ] } ]", "del_tokens": "sections = [ { keyValue : { topLabel : 'Order No.' , content : '12345' } } , { keyValue : { topLabel : 'Status' , content : 'In Delivery' } } ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "Database#clean", "to", "specs", "support"], "add_tokens": "config . include ModelMacros Database . setup Database . clean", "del_tokens": "config . before ( :suite ) do Database . setup end", "commit_type": "add"}
{"commit_tokens": ["add", "basic", "support", "for", "SQL", "operators", "(", "such", "as", "LIKE", "IS", "NOT", "etc", ".", ")", "in", "queries"], "add_tokens": "# parse operator in cases where (e.g.) :attribute => '>= some_value', :attribute => \"LIKE '%value%'\", fallback to '=' operator as default operator = value . to_s [ / ^([!<>=]*(LIKE|IS|NOT| \\s )*)(.*)$ / , 1 ] operator . strip! if operator operator = '=' if operator . nil? || operator == '' value = $3 # extract value from query value = value . strip [ / '?([^']*)'? / , 1 ] # strip single quotes around value, if present", "del_tokens": "# parse operator in cases where (e.g.) :attribute => '>= some_value', fallback to '=' operator as default operator = value . to_s [ / ^([<>=]*)(.*)$ / , 1 ] operator = '=' if operator . nil? || operator . strip == '' value = $2 # strip the operator from value passed to query value = value . strip [ / '?([^']*)'? / , 1 ]", "commit_type": "add"}
{"commit_tokens": ["remove", "trailing", "slash", "on", "url", "for", "get_categories_count"], "add_tokens": "@connection . get '/categories/count'", "del_tokens": "@connection . get '/categories/count/'", "commit_type": "remove"}
{"commit_tokens": ["added", "tests", "for", "setting", "up", "config"], "add_tokens": "it \"should setup a config\" do n = Flapjack :: NotifierCLI . new n . setup_config ( :filename => File . join ( File . dirname ( __FILE__ ) , 'fixtures' , 'flapjack-notifier.yaml' ) ) n . config . should_not be_nil end it \"should setup a config with a passed in yaml fragment\" do n = Flapjack :: NotifierCLI . new yaml = YAML :: load ( File . read ( File . join ( File . dirname ( __FILE__ ) , 'fixtures' , 'flapjack-notifier.yaml' ) ) ) n . setup_config ( :yaml => yaml ) n . config . should_not be_nil end yaml = YAML :: load ( File . read ( File . join ( File . dirname ( __FILE__ ) , 'fixtures' , 'recipients.yaml' ) ) ) n . recipients . each do | r | r . should respond_to ( :name ) end", "del_tokens": "yaml = File . join ( File . dirname ( __FILE__ ) , 'fixtures' , 'recipients.yaml' )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "simple", "VS2010", "website", "that", "the", "tests", "can", "use", "and", "changed", "tests", "to", "use", "that", "schema"], "add_tokens": "RestClient . post \"http://localhost:8888/SampleService/Entities.svc/CleanDatabaseForTesting\" , { }", "del_tokens": "RestClient . post \"http://127.0.0.1:2301/services/entities.svc/CleanDatabaseForTesting\" , { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "unmatched", "selectors", "due", "to", "different", "whitespacing"], "add_tokens": "# @param [String] name the selector's name @name = name . strip copy . name = name . strip", "del_tokens": "# @param [String] name of the selector @name = name copy . name = name", "commit_type": "fix"}
{"commit_tokens": ["Adding", "scheduler_task", "to", "schedulder", "generator", "changed", "example_task", "to", "be", "a", "class", "instead", "of", "module"], "add_tokens": "class < %= class_name %> Task < SchedulerTask", "del_tokens": "module < %= class_name %> Task < SchedulerTask", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "testing", "stupid", "random", "attributes"], "add_tokens": "assert_kind_of PinPayment :: Card , card assert_kind_of Hash , card . to_hash", "del_tokens": "assert_equal @card_hash [ :address_country ] , card . address_country assert_equal @card_hash [ :address_country ] , card . to_hash [ :address_country ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "taxon", "full", "path", "tag"], "add_tokens": "parent_path_tag ( self , name ) return string unless taxon . parent parent_path_tag ( taxon . parent , \"#{taxon.parent.name} -> #{string}\" )", "del_tokens": "parent_path_tag ( parent , '' ) if taxon if string . blank? parent_path_tag ( taxon . parent , \"#{taxon.name}\" ) else parent_path_tag ( taxon . parent , \"#{taxon.name} -> #{string}\" ) end else \"#{taxonomy.name} -> #{string}\" end", "commit_type": "fix"}
{"commit_tokens": ["fixed", "activity", "list", "method", "by", "adding", "arguments"], "add_tokens": "def activity_list ( date , sort , limit ) date_param = format_date ( date ) if sort == \"asc\" date_param = \"afterDate=#{date_param}\" elsif sort == \"desc\" date_param = \"beforeDate=#{date_param}\" else raise FitgemOauth2 :: InvalidArgumentError , \"sort can either be asc or desc\" end get_call ( \"user/#{user_id}/activities/list.json?offset=0&limit=#{limit}&sort=#{sort}&#{date_param}\" )", "del_tokens": "def activity_list get_call ( \"user/#{user_id}/activities/list.json\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "docs", "for", "other", "outputters", "too"], "add_tokens": "#Annotates a PDFWriter document with the barcode # #Registers the annotate_pdf method #Annotate a PDFWriter document with the barcode # #Valid options are: # #x, y - The point in the document to start rendering from #height - The height of the bars in PDF units #xdim - The X dimension in PDF units private def widths widths = [ ] count = nil booleans . inject nil do | previous , current | if current != previous widths << count if count count = [ current ] else count << current end current widths << count widths end", "del_tokens": "def widths widths = [ ] count = nil booleans . inject nil do | previous , current | if current != previous widths << count if count count = [ current ] else count << current current end widths << count widths end", "commit_type": "add"}
{"commit_tokens": ["Add", "Twirp", "::", "Service", ".", "error_response", "(", "twerr", ")", "method", "to", "easily", "make", "valid", "error", "responses", "from", "Rack", "middleware"], "add_tokens": "# Code constructors to ensure valid error codes. Example: # Twirp::Error.invalid_argument(\"foo is mandatory\", mymeta: \"foobar\") # Twirp::Error.permission_denied(\"Thou shall not pass!\", target: \"Balrog\") twerr . cause = err # availabe in error hook for inspection, but not in the response # Key-value representation of the error. Can be directly serialized into JSON.", "del_tokens": "# Use this constructors to ensure the errors have valid error codes. Example: # Twirp::Error.invalid_argument(\"foo is mandatory\", argument: \"foo\") # Twirp::Error.permission_denied(\"thou shall not pass!\", target: \"Balrog\") twerr . cause = err", "commit_type": "add"}
{"commit_tokens": ["Add", "request_head", "option", "to", "http", "scout", ".", "Tests", "are", "somewhat", "sloppy", "but", "it", "works", "."], "add_tokens": "@request_head = options . has_key? ( :request_head ) ? options [ :request_head ] : false if @request_head response = @http_class . request_head ( @host , @path , @port ) else response = @http_class . get_response ( @host , @path , @port ) end", "del_tokens": "response = @http_class . get_response ( @host , @path , @port )", "commit_type": "add"}
{"commit_tokens": ["add", "cross", "compilation", "for", "win32", "with", "libusb", "from", "http", ":", "//", "git", ".", "libusb", ".", "org"], "add_tokens": "dir_config ( \"libusb\" ) if enable_config ( \"win32-static-build\" ) have_library 'ole32' , 'CLSIDFromString' have_library 'setupapi' , 'SetupDiEnumDeviceInfo' , 'setupapi.h' abort \"libusb-1.0 not found\" unless have_header ( 'libusb.h' ) && have_library ( 'usb-1.0' , 'libusb_open' , 'libusb.h' ) else pkg_config ( \"libusb-1.0\" ) end have_func 'rb_hash_lookup'", "del_tokens": "dir_config ( \"ribusb\" ) pkg_config ( \"libusb-1.0\" )", "commit_type": "add"}
{"commit_tokens": ["Adding", "tag", "support", "and", "tag", "list"], "add_tokens": "member do get :tag end map . resources :blog_posts , :collection => { :drafts => :any } , :member => { :tag => :any } , :has_many => :blog_comments", "del_tokens": "map . resources :blog_posts , :collection => { :drafts => :any } , :has_many => :blog_comments", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "format", "of", "the", "results", "of", "the", "Alignment", "validation"], "add_tokens": "\"#{(consensus*100).round(0)}%&nbsp;conserved; #{(extra_seq*100).round(0)}%&nbsp;extra; #{(gaps*100).round(0)}%&nbsp;missing.\"", "del_tokens": "\"#{(gaps*100).round(0)}% missing, #{(extra_seq*100).round(0)}% extra, #{(consensus*100).round(0)}% conserved\"", "commit_type": "change"}
{"commit_tokens": ["changing", "initialize", "to", "sensible", "defaults"], "add_tokens": "def initialize value , anchor = nil , tag = nil , plain = true , quoted = false , style = ANY", "del_tokens": "def initialize value , anchor = nil , tag = nil , plain = true , quoted = true , style = ANY", "commit_type": "change"}
{"commit_tokens": ["Added", "Table", "::", "rename_column", "validation"], "add_tokens": "validate_column_exist ( * columns ) validate_column_exist ( * header ) validate_column_absence ( name ) validate_column_exist ( * names ) validate_column_exist ( from ) validate_column_absence ( to ) def validate_column_exist ( * names ) def validate_column_absence ( name ) raise \"Column '#{name}' already exists\" if @metadata . keys . include? ( name ) end", "del_tokens": "validate_column_names ( * columns ) validate_column_names ( * header ) raise \"Column '#{name}' already exists\" if @metadata . keys . include? ( name ) validate_column_names ( * names ) # todo validate from # todo validate to def validate_column_names ( * names )", "commit_type": "add"}
{"commit_tokens": ["made", "the", "timeout", "and", "wait_event", "work", "again"], "add_tokens": "VERSION = \"0.0.14\"", "del_tokens": "VERSION = \"0.0.13\"", "commit_type": "make"}
{"commit_tokens": ["Add", "arel", "predicate", "sql", "tests"], "add_tokens": "def contained_in_array ( other ) Nodes :: ContainedInArray . new self , Nodes . build_quoted ( other , self ) end", "del_tokens": "def inet_contained_in_array ( other ) Nodes :: Inet :: ContainedInArray . new self , Nodes . build_quoted ( other , self ) end", "commit_type": "add"}
{"commit_tokens": ["Added", "drop", "item", "type", "boolean", "matchers", "."], "add_tokens": "# Is the drop an image? # # @return [Boolean] def image? item_type == 'image' end # Is the drop a text file? def text? item_type == 'text' end # Is the drop an archive? # # @return [Boolean] def archive? item_type == 'archive' # Is the drop an audio file? # # @return [Boolean] def audio? item_type == 'audio' end # Is the drop a video file? # # @return [Boolean] def video? item_type == 'video' end # Is the drop an unknown file type? # # @return [Boolean] def unknown? item_type == 'unknown' end # Return the drops raw data as a string, useful for returning the text of documents # # @return [String] def raw @raw ||= HTTParty . get ( content_url ) . to_s end private def extension File . extname ( content_url ) [ 1 .. - 1 ] . to_s . downcase if content_url end", "del_tokens": "# Is the drop an image? def image? item_type == 'image'", "commit_type": "add"}
{"commit_tokens": ["removed", "buffers", "from", "connectors", "/", "common"], "add_tokens": "module Rpc module Common fail ( :RPC_ERROR , \"Invalid stats configuration. #{ex.message}\" ) response_wrapper . parse_from_string ( @response_data ) ensure", "del_tokens": "module Rpc module Common fail ( :RPC_ERROR , \"Invalid stats configuration. #{ex.message}\" ) @stats . response_size = @response_buffer . size response_wrapper . parse_from_string ( @response_buffer . data ) @response_buffer = Protobuf :: Rpc :: Buffer . new ( :read ) @request_buffer = Protobuf :: Rpc :: Buffer . new ( :write ) @request_buffer . set_data ( request_wrapper ) ensure", "commit_type": "remove"}
{"commit_tokens": ["added", "#changed_attributes", "to", "get", "access", "to", "the", "changes", "before", "a", "save", "[", "Chris", "Parker", "]"], "add_tokens": "def changed_attributes @changed_attributes ||= { } end attr_name ? changed_attributes . include? ( attr_name . to_s ) : ! changed_attributes . empty? self . audits . create :changes => changed_attributes , :action => action . to_s , :user => user old_value = changed_attributes [ attr_name ] ? changed_attributes [ attr_name ] . first : self [ attr_name ] changed_attributes [ attr_name ] = [ old_value , new_value ] if new_value != old_value", "del_tokens": "@changed_attributes ||= { } attr_name ? @changed_attributes . include? ( attr_name . to_s ) : ! @changed_attributes . empty? self . audits . create :changes => @changed_attributes , :action => action . to_s , :user => user @changed_attributes ||= { } old_value = @changed_attributes [ attr_name ] ? @changed_attributes [ attr_name ] . first : self [ attr_name ] @changed_attributes [ attr_name ] = [ old_value , new_value ] if new_value != old_value", "commit_type": "add"}
{"commit_tokens": ["Use", "Bundler", "to", "declare", "dependencies", "."], "add_tokens": "require 'bundler' Bundler . setup ( :default , :test )", "del_tokens": "gem 'rails' , '~>2.3.5' gem 'mocha' , '~>0.9.8' # Remember! Due to some Mocha internal changes, # Rails 2.2.x requires Mocha 0.9.5 and # Rails 2.3.x requires Mocha 0.9.7 # gem 'rails', '2.2.2' # gem 'mocha', '0.9.5'", "commit_type": "use"}
{"commit_tokens": ["Adding", "back", "table", "and", "database", "name", "lowercasing"], "add_tokens": "output = execute ( \"SELECT count(*) as table_count FROM dbc.tables WHERE LOWER(TableName) = '#{table}' AND LOWER(DatabaseName) = '#{schema}'\" )", "del_tokens": "output = execute ( \"SELECT count(*) as table_count FROM dbc.tables WHERE TableName = '#{table}' AND DatabaseName = '#{schema}'\" )", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "environment", "filters", "remove", "the", "attr_accessor", "and", "put", "the", "filter_params", "back", "to", "what", "it", "was"], "add_tokens": "attr_accessor :host , :port , :secure , :api_key , :filter_params", "del_tokens": "attr_accessor :host , :port , :secure , :api_key , :params_filters , :environment_filters", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "Backup", ":", "Logger", "."], "add_tokens": "LOG_PATH = File . join ( ENV [ 'HOME' ] , 'Backup' , 'log' ) TMP_PATH = File . join ( ENV [ 'HOME' ] , 'Backup' , '.tmp' ) autoload :Logger , File . join ( LIBRARY_PATH , 'logger' )", "del_tokens": "TMP_PATH = File . join ( ENV [ 'HOME' ] , 'Backup' , '.tmp' )", "commit_type": "add"}
{"commit_tokens": ["Added", "optional", "image", "compression", "with", "sprockets", "."], "add_tokens": "# # requires the sprockets-image_compressor gem # :image_compression: true # # options can be overridden per type", "del_tokens": "# # options can be overridden per type", "commit_type": "add"}
{"commit_tokens": ["added", "p", "into", "address", "and", "changed", "classes", "to", "use", "-"], "add_tokens": "wrap_with_div ( 'form-download' , '$D' ) wrap_with_div ( 'additional-information' , '$AI' ) \"<div class=\\\"address vcard\\\"><div class=\\\"adr org fn\\\"><p>\\n#{body.sub(\"\\n\", \"\").gsub(\"\\n\", \"<br />\")}\\n</p></div></div>\\n\"", "del_tokens": "wrap_with_div ( 'form_download' , '$D' ) wrap_with_div ( 'additional_information' , '$AI' ) \"<div class=\\\"address vcard\\\"><div class=\\\"adr org fn\\\">\\n#{body.sub(\"\\n\", \"\").gsub(\"\\n\", \"<br />\")}\\n</div></div>\\n\"", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "limits", "can", "be", "nested", "inside", "of", "joins"], "add_tokens": "delegate :create , :create! , :secure_create , :find_or_create , :new , :infer_join_columns , :to => :operand", "del_tokens": "delegate :create , :create! , :secure_create , :find_or_create , :new , :to => :operand", "commit_type": "make"}
{"commit_tokens": ["Added", "null", "check", "to", "decrypt"], "add_tokens": "if data == nil return nil end if doc == nil", "del_tokens": "if ( doc == nil )", "commit_type": "add"}
{"commit_tokens": ["Added", "keypair", "generation", "for", "cloud", "/", "pool"], "add_tokens": ":keypair => ( ENV [ \"KEYPAIR_NAME\" ] . nil? || ENV [ \"KEYPAIR_NAME\" ] . empty? ) ? nil : ENV [ \"KEYPAIR_NAME\" ] , # Keypairs # If the parent (pool) doesn't have a keypair defined on it, then generate one based on the # pool_name and the cloud_name def keypair ( * args ) has_keypair? ? options [ :keypair ] : generate_keypair ( * args ) end def has_keypair? options . has_key? ( :keypair ) && options [ :keypair ] end def generate_keypair ( * args ) options [ :keypair ] = args . length > 0 ? args [ 0 ] : \"#{@parent.name}_#{@name}\" end", "del_tokens": ":keypair => ( ENV [ \"KEYPAIR_NAME\" ] . nil? || ENV [ \"KEYPAIR_NAME\" ] . empty? ) ? \"pool\" : ENV [ \"KEYPAIR_NAME\" ] ,", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "called", "add_entry_mapping", "which", "adds", "the", "content", "type", "/", "class", "relationship", "into", "the", "config"], "add_tokens": "def add_entry_mapping unless ContentfulModel . configuration . entry_mapping . has_key? ( @content_type_id ) ContentfulModel . configuration . entry_mapping [ @content_type_id ] = Object . const_get ( self . to_s . to_sym ) end end", "del_tokens": "def inherited ( subclass ) unless ContentfulModel . configuration . entry_mapping . has_key? ( @content_type_id ) ContentfulModel . configuration . entry_mapping [ @content_type_id ] = Object . const_get ( subclass . to_s . to_sym ) end end", "commit_type": "add"}
{"commit_tokens": ["removing", "extraneous", "logger", ".", "debug", "calls"], "add_tokens": "content . to_a [ 13 .. - 1 ] . join # remove the layout div", "del_tokens": "content = content . to_a [ 13 .. - 1 ] . join # remove the layout div logger . debug ( content ) content", "commit_type": "remove"}
{"commit_tokens": ["Add", "access", "token", "logic", "."], "add_tokens": "require 'cru_lib/version' require_dependency 'cru_lib/access_token' require 'cru_lib/access_token_serializer' require 'cru_lib/access_token_protected_concern' require 'cru_lib/api_error' require 'cru_lib/api_error_serializer' require 'redis' class << self attr_accessor :redis_host , :redis_port , :redis_db , :redis_client def configure yield self end def redis_host @redis_host ||= 'localhost' end def redis_port @redis_port ||= '6379' end def redis_db @redis_db ||= 2 end def redis_client Redis . new ( :host => CruLib . redis_host , :port => CruLib . redis_port , :db => CruLib . redis_db ) end end", "del_tokens": "require \"cru_lib/version\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "account", ".", "playlists", ".", "find", "{", "|p|", "...", "}"], "add_tokens": "delegate :count , :first , :any? , :each , :map , :find , to : :list", "del_tokens": "delegate :count , :first , :any? , :each , :map , to : :list", "commit_type": "allow"}
{"commit_tokens": ["Implemented", "smart", "-", "autoloading", "for", "different", "VCSs"], "add_tokens": "@@vcs_types [ type ] . init # This module provided class methods for VCS implementation +Module+s that # implement smart auto-loading of dependencies and classes. module ClassMethods # Missing constants may indicate # # Trying to access either the +Actor+, +Commit+ or +Repository+ class # in a VCS +Module+ will trigger auto-loading first. # # @param [Symbol] The symbolic name of the missing constant # @see #init def const_missing ( const ) init if [ :Actor , :Commit , :Repository ] . include? ( const ) super unless const_defined? const const_get const end # This initializes the VCS's implementation +Module+ # # First the corresponding Bundler group is loaded so all dependencies are # met. Afterwards the +Actor+, +Commit+ and +Repository+ classes are # required. # # @see Bundler.setup def init Bundler . setup self :: NAME path = self :: NAME . to_s require \"metior/#{path}/actor\" require \"metior/#{path}/commit\" require \"metior/#{path}/repository\" self end end # @see Metior.vcs_types mod . extend ClassMethods", "del_tokens": "@@vcs_types [ type ] # @see Metior#vcs_types", "commit_type": "implement"}
{"commit_tokens": ["add", "spec", "for", "handling", "array", "in", "yaml"], "add_tokens": "let ( :hash_string ) { { :test1 => \"string1\" , :test2 => \"string2\" , :array1 => [ \"first\" , \"second\" ] } } let ( :hash_output ) { [ { :string_key => \"test1\" , :string => \"string1\" } , { :string_key => \"test2\" , :string => \"string2\" } , { :string_key => \"array1\" , :string => \"first\" , :context => 0 } , { :string_key => \"array1\" , :string => \"second\" , :context => 1 } , ] } it \"transform an hash of strings\" do translation . should_receive ( :input_strings ) . with ( hash_output , { } ) translation . input_phrases ( hash_string ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["made", "scraper", "more", "resilient", "to", "missing", "/", "moved", "elements"], "add_tokens": "h [ :url ] = url . gsub ( \"[\" , \"%5B\" ) . gsub ( \"]\" , \"%5D\" ) h [ :uploader ] = Pirata :: User . new ( row . search ( '.detDesc a' ) [ 0 ] . text )", "del_tokens": "h [ :url ] = url . sub ( \"[\" , \"%5B\" ) . sub ( \"]\" , \"%5D\" ) h [ :uploader ] = Pirata :: User . new ( row . search ( 'td a' ) [ 5 ] . text )", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "fix", "spec", "var", "shadowing"], "add_tokens": "work = proc { | sp | called << sp }", "del_tokens": "work = proc { | spinner | called << spinner }", "commit_type": "change"}
{"commit_tokens": ["add", "a", "spec", "for", "creating", "things", "within", "a", "YAML", "list"], "add_tokens": "raise Invalid . new ( $! . message || \"(no message)\" , filename , parser . mark )", "del_tokens": "raise Invalid . new ( $! . message , filename , parser . mark )", "commit_type": "add"}
{"commit_tokens": ["implemented", "Rufus", "::", "Jig", "::", "Couch#attach", "and", "#detach"], "add_tokens": "return nil unless data data = if data . is_a? ( String ) data elsif ( opts [ 'Content-Type' ] || '' ) . match ( / ^application \\/ json / ) Rufus :: Json . encode ( data ) else data . to_s end #opts['Content-Length'] = # (data.respond_to?(:bytesize) ? data.bytesize : data.size).to_s # # Patron doesn't play well with custom lengths : \"56, 56\" issue data", "del_tokens": "return data if data . nil? || data . is_a? ( String ) return Rufus :: Json . encode ( data ) if ( opts [ 'Content-Type' ] || '' ) . match ( / ^application \\/ json / ) data . to_s", "commit_type": "implement"}
{"commit_tokens": ["Made", "protected", "strategy", "compliant", "with", "the", "new", "DSL", "."], "add_tokens": "class Protected < WineBouncer :: BaseStrategy def endpoint_protected? has_authorizations? def has_auth_scopes? endpoint_authorizations && endpoint_authorizations . has_key? ( :scopes ) && endpoint_authorizations [ :scopes ] . any? def auth_scopes endpoint_authorizations [ :scopes ] . map ( & :to_sym ) def nil_authorizations? endpoint_authorizations . nil? def has_authorizations? nil_authorizations? || endpoint_authorizations def endpoint_authorizations api_context . options [ :route_options ] [ :auth ]", "del_tokens": "class Protected def endpoint_protected? ( context ) has_authorizations? ( context ) def has_auth_scopes? ( context ) endpoint_authorizations ( context ) && endpoint_authorizations ( context ) . has_key? ( :scopes ) && endpoint_authorizations ( context ) [ :scopes ] . any? def auth_scopes ( context ) endpoint_authorizations ( context ) [ :scopes ] . map ( & :to_sym ) def nil_authorizations? ( context ) endpoint_authorizations ( context ) . nil? def has_authorizations? ( context ) nil_authorizations? ( context ) || endpoint_authorizations ( context ) def endpoint_authorizations ( context ) context [ :auth ]", "commit_type": "make"}
{"commit_tokens": ["Update", "to", "latest", "bundler", "gem", "conventions", "."], "add_tokens": "require 'statsd/instrument/version'", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Add", "model", "and", "other", "stuff"], "add_tokens": "$PATH_SENSOR = \"../components/sensors/\" attr_reader :name , :proxy_iface , :value @dependencies = meas_ [ \"depends\" ] @interface = nil # Parse Yaml correponding to the model of sensor if meas_ [ \"model\" ] #parse yaml #--- # FIXME : model's yaml will be change, maybe #+++ model = YAML :: load ( File . read ( $PATH_SENSOR + meas_ [ \"model\" ] + \".yaml\" ) ) [ meas_ [ \"model\" ] ] # create the defined interface @interface = Dbus_interface . new ( model [ \"driver\" ] [ \"interface\" ] ) . dup if model [ \"driver\" ] [ \"option\" ] @option = model [ \"driver\" ] [ \"option\" ] . dup else @option = Hash . new end @ttl = model [ \"driver\" ] [ \"ttl\" ] end @last_mesure = 0 @value = nil @dependencies . each_value { | dep | # Plug the measure to the proxy with defined interface def plug ( proxy ) @proxy_iface = proxy [ @interface . get_name ] end #measure from sensor def get_value if ( Time . new . to_f - @last_mesure ) > @ttl @last_mesure = Time . new . to_f @value = @proxy_iface . read ( @option ) end return @value end", "del_tokens": "require 'dbus' include REXML @dependencies = meas_ [ \"plug\" ] @dependencies . each { | dep |", "commit_type": "add"}
{"commit_tokens": ["added", "min", "required", "subscribed", "fields", "for", "messenger", "bot"], "add_tokens": "log . progname = name if %i[ message postback ] . include? ( event ) Facebook :: Messenger :: Subscriptions . subscribe ( access_token : token , subscribed_fields : %w[ messages messaging_postbacks ] )", "del_tokens": "log . progname = self . name if [ :message , :postback ] . include? ( event ) Facebook :: Messenger :: Subscriptions . subscribe ( access_token : token )", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "around", "accessing", "env", "variables", "."], "add_tokens": "info \"Running command: #{command}\" File . open ( script_path , 'w+' ) { | file | file . write ( @build . script ) } export = environment . any? ? \"export #{environment};\" : \"\" \"#{export} chmod +x #{script_path} && #{script_path}\"", "del_tokens": "%{echo #{@build.script.inspect} > #{script_path}; chmod +x #{script_path}; #{environment} exec #{script_path}}", "commit_type": "add"}
{"commit_tokens": ["added", "MMETools", "::", "ArgsProc", "to", "process", "arguments"], "add_tokens": "YAML . dump ( self , f )", "del_tokens": "YAML . dump ( @data , f )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Performance", "/", "StringReplacement", "offenses"], "add_tokens": "k = k . tr ( \"-\" , \"_\" )", "del_tokens": "k = k . gsub ( \"-\" , \"_\" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "indentation", "to", "satisfy", "rubocop"], "add_tokens": "# Provides support for UI output. Cork provides support for nested # sections of information and for a verbose mode. # # @return [Podfile] The Podfile specification that contains the # information of the Pods that should be installed. # attr_reader :podfile class Board end", "del_tokens": "# Provides support for UI output. Cork provides support for nested # sections of information and for a verbose mode. # # @return [Podfile] The Podfile specification that contains the # information of the Pods that should be installed. # attr_reader :podfile class Board end", "commit_type": "add"}
{"commit_tokens": ["implement", "get_load_commands", "add", "documentation", "tweak", "cstruct", "to", "add", "(", "u", ")", "int64"], "add_tokens": "@load_commands = get_load_commands # is the file executable? # is the file a dynamically bound shared object? # is the file a dynamically bound bundle? # string representation of the header's magic bytes # string representation of the header's filetype field # string representation of the header's cputype field # string representation of the header's cpusubtype field # number of load commands in the header # size of each load command # various execution flags def get_load_commands offset = header . bytesize load_commands = [ ] header [ :ncmds ] . times do cmd , cmdsize = @raw_data . slice ( offset , 8 ) . unpack ( \"VV\" ) load_commands << LoadCommand . new ( cmd , cmdsize ) offset += cmdsize end load_commands end", "del_tokens": "# @load_commands = get_load_commands", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "for", "Faraday", "::", "Request"], "add_tokens": "# Curb (Curl::Easy), RestClient object or Faraday::Request. begin", "del_tokens": "# Curb (Curl::Easy) or a RestClient object. begin", "commit_type": "add"}
{"commit_tokens": ["Fixing", "module", "Termable", "into", "term", ".", "rb", "file", "n", "order", "to", "add", "wp", "options", "needed", "to", "add", "taxonomies", "."], "add_tokens": "def add_term ( term , taxonomy , description , count ) term_taxonomy = WPDB :: TermTaxonomy . create ( term_id : term_id , taxonomy : taxonomy , description : description , count : count ) else term_taxonomy . count += count", "del_tokens": "def add_term ( term , taxonomy ) term_taxonomy = WPDB :: TermTaxonomy . create ( term_id : term_id , taxonomy : taxonomy )", "commit_type": "fix"}
{"commit_tokens": ["Add", "documentation", "for", "map", "generation", "strategies"], "add_tokens": "# Manages map generation strategies # Calls every strategy on the given case map and returns the modified case map # @param [Crystalball::CaseMap] initial case map # @return [Crystalball::CaseMap] case map augmented by each strategy", "del_tokens": "# Map generator strategy based on harvesting Coverage information during example execution", "commit_type": "add"}
{"commit_tokens": ["Adding", "GetMedicationInfo", "magic", "helper", "."], "add_tokens": "VERSION = \"1.3.1\"", "del_tokens": "VERSION = \"1.3.0\"", "commit_type": "add"}
{"commit_tokens": ["Removed", "deep_merge", ".", "gem", "requirement", "for", "Rails", "Apps", "."], "add_tokens": "require 'psych' require 'json' require 'erb' require 'deep_merge'", "del_tokens": "require 'deep_merge/rails_compat'", "commit_type": "remove"}
{"commit_tokens": ["Add", "thor", "task", "for", "updating", "amcharts", "assets"], "add_tokens": "end if defined? ( ActiveSupport )", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", ".", "env", ".", "test", "file", "so", "Travis", "builds", "pass", "without", "config"], "add_tokens": "Dotenv . load ( \".env.test\" )", "del_tokens": "Dotenv . load", "commit_type": "add"}
{"commit_tokens": ["fix", "standalone", "failure", "and", "remove", "launch", "hard", "dependency"], "add_tokens": "end", "del_tokens": "Rails . application . assets . logger = Logger . new ( '/dev/null' ) end", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "and", "fix", "for", "creating", "customer", "with", "card", "hash"], "add_tokens": "hash [ 'card' ] = card if card card = options . delete ( 'card' ) if options [ 'card' ] return options unless card and card . is_a? ( Card ) return options . merge ( card_token : card . token ) if card . token # Ruby's Net::HTTP#set_form_data doesn't deal with nested hashes :( card . to_hash . each { | k , v | options [ \"card[#{k}]\" ] = v } options", "del_tokens": "# TODO: Accept card as a hash that would create the card at the same time as the charge card = options . delete ( :card ) || options . delete ( 'card' ) options . delete ( 'card' ) return options unless card card . token ? options . merge ( card_token : card . token ) : options . merge ( card : card . to_hash )", "commit_type": "add"}
{"commit_tokens": ["Add", "heartbeat", "support", "to", "amqp"], "add_tokens": ":heartbeat => @settings [ :heartbeat ] || 0 ) when Frame :: Heartbeat @last_server_heartbeat = Time . now if heartbeat = @settings [ :heartbeat ] init_heartbeat if ( @settings [ :heartbeat ] = heartbeat . to_i ) > 0 end end def init_heartbeat @last_server_heartbeat = Time . now @timer . cancel if @timer @timer = EM :: PeriodicTimer . new ( @settings [ :heartbeat ] ) do if connected? if @last_server_heartbeat < ( Time . now - ( @settings [ :heartbeat ] * 2 ) ) log \"Reconnecting due to missing server heartbeats\" reconnect ( true ) else @last_server_heartbeat = Time . now send AMQP :: Frame :: Heartbeat . new , :channel => 0 end end end", "del_tokens": ":heartbeat => 0 )", "commit_type": "add"}
{"commit_tokens": ["Added", "params", "to", "merchant", "index", "methods"], "add_tokens": "def api_get ( path , params = { } ) request ( :get , \"#{API_PATH}#{path}\" , :params => params ) . parsed request ( :post , \"#{API_PATH}#{path}\" , :data => data ) . parsed request ( :put , \"#{API_PATH}#{path}\" , :data => data ) . parsed def request ( method , path , opts = { } ) opts [ :headers ] = { 'Accept' => 'application/json' } opts [ :headers ] [ 'Content-Type' ] = 'application/json' unless method == :get opts [ :body ] = JSON . generate ( opts [ :data ] ) if ! opts [ :data ] . nil? @access_token . send ( method , path , opts )", "del_tokens": "def api_get ( path ) request ( :get , \"#{API_PATH}#{path}\" ) . parsed request ( :post , \"#{API_PATH}#{path}\" , data ) . parsed request ( :put , \"#{API_PATH}#{path}\" , data ) . parsed def request ( method , path , data = nil ) headers = { 'Accept' => 'application/json' } headers [ 'Content-Type' ] = 'application/json' unless method == :get body = JSON . generate ( data ) if ! data . nil? @access_token . send ( method , path , :headers => headers , :body => body )", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "additional", "inline", "documentation", ".", "[", "ci", "skip", "]"], "add_tokens": "# Looks for config/odata.yml and loads the configuration. # TODO Implement Rails configuration loading # Examines the loaded configuration and populates the # OData::ServiceRegistry accordingly. # TODO Populate OData::ServiceRegistry based on configuration", "del_tokens": "# load environment config from config/odata.yml # use configuration to setup registry of OData::Services", "commit_type": "add"}
{"commit_tokens": ["Fix", "native", "endian", "parsing", "in", "frame", "header"], "add_tokens": "HEADERPACK = \"nCCN\"", "del_tokens": "HEADERPACK = \"SCCL\"", "commit_type": "fix"}
{"commit_tokens": ["add", "starting", "point", "for", "fasta", "parsing"], "add_tokens": "if peptides . first . start_with? '>' # FASTA MODE ENGAGED peptides . each_slice ( batch_size ) . with_index do | sub , i | fasta_mapper = { } j = 0 while j < sub . size if sub [ j ] . start_with? '>' fasta_header = sub . delete_at j else fasta_mapper [ sub [ j ] ] = fasta_header end j += 1 end block . call ( sub , i , fasta_mapper ) end else peptides . each_slice ( batch_size ) . with_index ( & block ) end", "del_tokens": "peptides . each_slice ( batch_size ) . with_index ( & block )", "commit_type": "add"}
{"commit_tokens": ["Add", "HTTP", "proxy", "specs", "to", "test", "new", "servers", "and", "endpoint"], "add_tokens": "let ( :test_endpoint ) { \"http://127.0.0.1:#{ExampleService::PORT}/\" } let ( :proxy_endpoint ) { \"#{test_endpoint}proxy\" } response = Http . via ( \"127.0.0.1\" , 8080 ) . get proxy_endpoint response . should match ( / Proxy! / ) response = Http . via ( \"127.0.0.1\" , 8081 , \"username\" , \"password\" ) . get proxy_endpoint response . should match ( / Proxy! / ) end end context \"with http proxy address, port, with wrong username and password\" do it \"should proxy the request\" do response = Http . via ( \"127.0.0.1\" , 8081 , \"user\" , \"pass\" ) . get proxy_endpoint response . should match ( / Proxy Authentication Required / )", "del_tokens": "let ( :test_endpoint ) { \"http://127.0.0.1:#{ExampleService::PORT}/\" } response = Http . via ( \"127.0.0.1\" , 65432 ) . get test_endpoint response . should match ( / <!doctype html> / ) response = Http . via ( \"127.0.0.1\" , 65432 , \"username\" , \"password\" ) . get test_endpoint response . should match ( / <!doctype html> / )", "commit_type": "add"}
{"commit_tokens": ["remove", "misunderstood", "session", "id", "header", "stuff"], "add_tokens": "http . expects ( :get ) . with ( '' , { 'User-Agent' => @rets . user_agent , 'RETS-Version' => \"RETS/#{@rets.rets_version}\" , 'Accept' => '*/*' } ) . at_least_once . returns ( response ) http . expects ( :post ) . with ( '' , '' , { 'User-Agent' => @rets . user_agent , 'RETS-Version' => \"RETS/#{@rets.rets_version}\" , 'Accept' => '*/*' } ) . at_least_once . returns ( response )", "del_tokens": "http . expects ( :get ) . with ( '' , { 'RETS-Session-ID' => '0' , 'User-Agent' => @rets . user_agent , 'RETS-Version' => \"RETS/#{@rets.rets_version}\" , 'Accept' => '*/*' } ) . at_least_once . returns ( response ) http . expects ( :post ) . with ( '' , '' , { 'RETS-Session-ID' => '0' , 'User-Agent' => @rets . user_agent , 'RETS-Version' => \"RETS/#{@rets.rets_version}\" , 'Accept' => '*/*' } ) . at_least_once . returns ( response )", "commit_type": "remove"}
{"commit_tokens": ["Move", "AR", "include", "into", "engine", "file", "."], "add_tokens": "class Engine < Rails :: Engine ActiveRecord :: Base . send ( :include , Impressionist :: Impressionable )", "del_tokens": "class Engine < Rails :: Engine ActiveRecord :: Base . extend Impressionist :: Impressionable", "commit_type": "move"}
{"commit_tokens": ["Change", "exception", "handler", "to", "be", "pluggable"], "add_tokens": "'exception_handler' => 'RailsLogger' ,", "del_tokens": "'exception_handler' => 'rails_logger' ,", "commit_type": "change"}
{"commit_tokens": ["Add", "mechanism", "to", "suppress", "stub", "calls", "completely"], "add_tokens": "call_status , call_headers , call_body = @app . call ( env ) # a committee.suppress signal initiates a direct pass through if env [ \"committee.suppress\" ] == true return call_status , call_headers , call_body end # otherwise keep the headers and whatever data manipulations were # made, and stub normally", "del_tokens": "_ , call_headers , _ = @app . call ( env )", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplication", "between", "Type#update", "and", "Type#insert"], "add_tokens": "perform_document_action ( id , document , :create , 201 ) perform_document_action ( id , document , :index , 200 ) # Perform document action # # @param [String] id # @param [Hash] document # @param [Symbol] action # @param [Fixnum] status # # @return [undefined] # # @api private # def perform_document_action ( id , document , action , status ) pure_connection . post ( \"#{index.name}/#{name}/#{id}?op_type=#{action}\" ) do | request | options = request . options options [ :expect_status ] = status options [ :convert_json ] = true request . body = document end end", "del_tokens": "index = self . index pure_connection . post ( \"#{index.name}/#{name}/#{id}?op_type=create\" ) do | request | options = request . options options [ :expect_status ] = 201 options [ :convert_json ] = 201 request . body = document end index = self . index pure_connection . post ( \"#{index.name}/#{name}/#{id}?op_type=index\" ) do | request | options = request . options options [ :expect_status ] = 200 options [ :convert_json ] = 200 request . body = document end", "commit_type": "remove"}
{"commit_tokens": ["Allow", "zipkin_kafka_tracer", "to", "use", "an", "injected", "Kafka", "producer", "instead", "of", "Hermann", "."], "add_tokens": "# IF hermann isn't present, we might be providing another kafka producer begin require 'hermann/producer' require 'hermann/discovery/zookeeper' rescue LoadError => e end if options [ :producer ] && options [ :producer ] . respond_to? ( :push ) @producer = options [ :producer ] elsif options [ :zookeepers ] initialize_hermann_producer ( options [ :zookeepers ] ) else raise ArgumentError , \"No (kafka) :producer option (accepting #push) and no :zookeeper option provided.\" end def initialize_hermann_producer ( zookeepers ) broker_ids = Hermann :: Discovery :: Zookeeper . new ( zookeepers ) . get_brokers @producer = Hermann :: Producer . new ( nil , broker_ids ) end private :initialize_hermann_producer retval = @producer . push ( buf , topic : @topic ) # If @producer#push returns a promise/promise-like object, block until it # resolves retval . value! if retval . respond_to? ( :value! ) retval", "del_tokens": "require 'hermann/producer' require 'hermann/discovery/zookeeper' broker_ids = Hermann :: Discovery :: Zookeeper . new ( options [ :zookeepers ] ) . get_brokers @producer = Hermann :: Producer . new ( nil , broker_ids ) @producer . push ( buf , topic : @topic ) . value!", "commit_type": "allow"}
{"commit_tokens": ["allow", "addition", "of", "info", "to", "a", "colorscheme"], "add_tokens": "# Adds info to the header of the scheme, or retrieves the info hash. # # @return [Hash,String] def info ( args = { } ) ( @info ||= { } ) . merge! ( args ) if args . respond_to? :merge end # The colorscheme header #{info.to_a.map do |pair| pair . join ( \": \" ) . tap { | s | s [ 0 ] = '\" ' + s [ 0 ] . upcase } end . join ( \"\\n\" ) } # Creates the colorscheme file", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Add", "CLI", "command", "to", "print", "managed", "SwiftLint", "version"], "add_tokens": "VERSION = \"0.4.0\" . freeze", "del_tokens": "VERSION = \"0.16.1\" . freeze", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "verified", "owner", "mark", "and", "vendored", "framework", "bool"], "add_tokens": "migrate_to :trunk , version : 14 migrate_to :cocoadocs , version : 11", "del_tokens": "migrate_to :trunk , version : 13 migrate_to :cocoadocs , version : 10", "commit_type": "add"}
{"commit_tokens": ["add", "fluent", "handling", "of", "path"], "add_tokens": "def self . endpoint_path ( sum ) @@cal_counter += 1 sum . must_equal '/the-path' end @@cal_counter == 7 :path => '/the-path' ,", "del_tokens": "@@cal_counter == 6", "commit_type": "add"}
{"commit_tokens": ["Removed", "some", "of", "the", "dependency", "on", "ActiveRecord"], "add_tokens": "def initialize ( object = new_object ) @object = object end def new_object self . class . model_class . new def update ( attributes ) @object . update ( attributes ) end define_method \"#{key}=\" do | values | @object . send \"#{key}=\" , values end unless method_defined? ( \"#{key}=\" ) define_method \"#{key}=\" do | values | @object . send \"#{key}=\" , values end unless method_defined? ( \"#{key}=\" )", "del_tokens": "def initialize ( object ) @object = object", "commit_type": "remove"}
{"commit_tokens": ["Adding", "Gecko", "::", "Record", "::", "Location"], "add_tokens": "belongs_to :billing_contact , class_name : \"User\" belongs_to :primary_location , class_name : \"Location\" belongs_to :primary_billing_location , class_name : \"Location\" # belongs_to :default_currency, class_name: \"Currency\" # belongs_to :default_payment_term, class_name: \"PaymentTerm\" # belongs_to :default_purchase_order_price_type, class_name: \"PriceList\" # belongs_to :default_order_price_type, class_name: \"PriceList\"", "del_tokens": "# has_one :default_purchase_order_price_type, class_name: \"PriceList\" # has_one :default_order_price_type, class_name: \"PriceList\" # has_one :primary_location, class_name: \"Location\" # has_one :primary_billing_location, class_name: \"Location\" # has_one :default_currency, class_name: \"Currency\" # has_one :default_payment_term, class_name: \"PaymentTerm\" belongs_to :billing_contact , class_name : \"User\"", "commit_type": "add"}
{"commit_tokens": ["move", "Verbs", "include", "into", "DataResource"], "add_tokens": "extend Verbs", "del_tokens": "extend Verbs", "commit_type": "move"}
{"commit_tokens": ["Improve", "clarity", "of", "signing", "specs", "somewhat"], "add_tokens": "@signature = \"3b237953a5ba6619875cbb2a2d43e8da9ef5824e8a2c689f6284ac85bc1ea0db\" it \"should generate signature correctly\" do @request . sign ( @token ) string = @request . send ( :string_to_sign ) string . should == \"POST\\n/some/path\\nauth_key=key&auth_timestamp=1234&auth_version=1.0&go=here&query=params\" digest = OpenSSL :: Digest :: SHA256 . new signature = OpenSSL :: HMAC . hexdigest ( digest , @token . secret , string ) signature . should == @signature @request . query_hash = { } @request . auth_hash @request . sign ( @token ) @request . auth_hash . should == {", "del_tokens": "@signature = @request . sign ( @token ) [ :auth_signature ] it \"should generate base64 encoded signature from correct key\" do @request . send ( :string_to_sign ) . should == \"POST\\n/some/path\\nauth_key=key&auth_timestamp=1234&auth_version=1.0&go=here&query=params\" @signature . should == '3b237953a5ba6619875cbb2a2d43e8da9ef5824e8a2c689f6284ac85bc1ea0db' request = Signature :: Request . new ( 'POST' , '/some/path' , { } ) request . auth_hash request . sign ( @token ) request . auth_hash . should == {", "commit_type": "improve"}
{"commit_tokens": ["added", "support", "for", "crlf", "lineendings"], "add_tokens": "file = File . open ( path , \"r\" ) if ( file . gets =~ / \\r $ / ) # detected windows line ending file . close file = File . open ( path , \"rt\" ) end file . each_line ( \"\\n\\n\" ) do | block |", "del_tokens": "File . open ( path , 'r' ) . each_line ( \"\\n\\n\" ) do | block |", "commit_type": "add"}
{"commit_tokens": ["allow", "passing", ":", "_nested_builder", "into", "Schema", "::", "property", "."], "add_tokens": "# :_nested_builder if options [ :_nested_builder ] # Run builder to create nested schema (or twin, or representer, or whatever). options [ :_nested_builder ] . ( options )", "del_tokens": "if block nested = options [ :_nested_builder ] . ( options )", "commit_type": "allow"}
{"commit_tokens": ["Change", "to", "fix", "namespacing", "."], "add_tokens": "if object . is_a? ( :: String ) && :: File . exists? ( object ) tmp = :: Tempfile . new ( :: SecureRandom . uuid . split ( '-' ) [ 0 ] )", "del_tokens": "if object . is_a? ( :: String ) && File . exists? ( object ) tmp = Tempfile . new ( SecureRandom . uuid . split ( '-' ) [ 0 ] )", "commit_type": "change"}
{"commit_tokens": ["Fix", "suite", "failures", "with", "new", "RSpec", "."], "add_tokens": "@influxdb . use_ssl . should be_falsey @influxdb . use_ssl . should be_truthy", "del_tokens": "@influxdb . use_ssl . should be_false @influxdb . use_ssl . should be_true", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "environment", "detection"], "add_tokens": "connection_string = ENV [ 'STATSD_ADDR' ] StatsD :: Instrument :: Backends :: UDPBackend . new ( connection_string , implementation )", "del_tokens": "server = ENV [ 'STATSD_ADDR' ] StatsD :: Instrument :: Backends :: UDPBackend . new ( server , implementation )", "commit_type": "add"}
{"commit_tokens": ["Fix", "token", "expiry", "and", "make", "it", "actually", "work", "as", "advertised", "."], "add_tokens": "def initialize json = { } super @expires_at = Time . now + @ttl end def self . attrs %w| token ttl user_id | end include Model def valid? ttl > 0", "del_tokens": "def ttl = i sel . expires_at = Time . now + i end def self . attrs %w| token ttl user_id | include Model", "commit_type": "fix"}
{"commit_tokens": ["Changed", "index", "names", "from", "symbols", "to", "strings", "."], "add_tokens": "add_index :tr8n_translation_key_comments , [ :language_id ] , :name => \"tr8n_tkey_msgs_lang_id\" add_index :tr8n_translation_key_comments , [ :translator_id ] , :name => \"tr8n_tkey_msgs_translator_id\" add_index :tr8n_translation_key_comments , [ :language_id , :translation_key_id ] , :name => \"tr8n_tkey_msgs_lang_id_tkey_id\"", "del_tokens": "add_index :tr8n_translation_key_comments , [ :language_id ] , :name => :tr8n_tkey_msgs_lang_id add_index :tr8n_translation_key_comments , [ :translator_id ] , :name => :tr8n_tkey_msgs_translator_id add_index :tr8n_translation_key_comments , [ :language_id , :translation_key_id ] , :name => :tr8n_tkey_msgs_lang_id_tkey_id", "commit_type": "change"}
{"commit_tokens": ["added", "label", "in", "alert", "message"], "add_tokens": "* Last update : 2014 - 04 - 19 19 :04 alert \"This ( #{self.class} ) does not respond to #{blk.to_s} [PROCESS-KEY]\"", "del_tokens": "* Last update : 2014 - 04 - 17 21 :21 alert \"This ( #{self.class} ) does not respond to #{blk.to_s} \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "avatar", "upload", "with", "paperclip", ">", "3"], "add_tokens": "precrop_path = File . join ( Avatar . images_tmp_path , @name ) self . name = @name self . logo = File . open ( precrop_path )", "del_tokens": "precrop_path = File . join ( Avatar . images_tmp_path , @name ) @avatar = Avatar . new :logo => File . open ( precrop_path ) , :name => @name self . logo = @avatar . logo", "commit_type": "fix"}
{"commit_tokens": ["Move", "custom", "formatter", "code", "into", "modules", "to", "allow", "multiple", "inheritance", "."], "add_tokens": "require 'nyan_cat_format/wide' include NyanCatFormat :: Wide", "del_tokens": "def example_width ( example = current ) net_width_for ( example ) - net_width_for ( example - 1 ) end def net_width_for ( example ) @net_width ||= { } @net_width [ example ] ||= begin return 0 if example < 0 net_width = terminal_width - padding_width - cat_length rough_example_width = ( net_width * example . to_f / @example_count . to_f ) rough_example_width . round end end", "commit_type": "move"}
{"commit_tokens": ["Use", "dummy", "termfiles", "to", "init", "the", "core"], "add_tokens": "f = EmptyTermfile . new core = Consular :: Terminator . new f . path f = EmptyTermfile . new core = Consular :: Terminator . new f . path", "del_tokens": "core = Consular :: Terminator . new '' core = Consular :: Terminator . new ''", "commit_type": "use"}
{"commit_tokens": ["Added", "new", "external", "queue", "to", "allow", "for", "tracking", "byebye", "devices", "."], "add_tokens": "@new_device_queue = EventMachine :: Queue . new @old_device_queue = EventMachine :: Queue . new blk . call ( @new_device_queue , @old_device_queue ) @old_device_queue << advertisement # Do I need to do this? @new_device_queue . push ( built_device )", "del_tokens": "@device_queue = EventMachine :: Queue . new blk . call ( @device_queue ) @devices . each { | d | @device_queue << d } @device_queue . push ( built_device )", "commit_type": "add"}
{"commit_tokens": ["add", "#is_read?", "predicates", "to", "match", "#is_unread?"], "add_tokens": "#@conversation.move_to_trash(@entity1) @conversation . mark_as_read ( @entity1 ) @conversation . should be_is_read ( @entity ) @conversation . mark_as_read ( @entity1 ) @conversation . mark_as_unread ( @entity1 ) @conversation . should be_is_unread ( @entity1 )", "del_tokens": "@conversation . move_to_trash ( @entity1 ) @conversation . move_to_trash ( @entity1 ) @conversation . untrash ( @entity1 )", "commit_type": "add"}
{"commit_tokens": ["fixed", "getParts", "api", "and", "upload", "api"], "add_tokens": "begin puts RestClient . post \"http://localhost:3000/upload\" , :name => part_name , :description => specsJson [ \"description\" ] , :version => specsJson [ \"version\" ] , :authors => specsJson [ \"authors\" ] , :email => specsJson [ \"email\" ] , :homepage => specsJson [ \"homepage\" ] , :dependencies => specsJson [ \"dependencies\" ] rescue RestClient :: ExceptionWithResponse => e puts e . response end", "del_tokens": "# binding.pry resp = RestClient . post \"http://localhost:3000/upload\" , :name => part_name , :description => specsJson [ \"description\" ] , :version => specsJson [ \"version\" ] , :authors => specsJson [ \"authors\" ] , :email => specsJson [ \"email\" ] , :homepage => specsJson [ \"homepage\" ] , :dependencies => specsJson [ \"dependencies\" ] body = JSON . parse ( resp ) if body . code == 200 puts body [ \"success\" ] else puts body [ \"error\" ] end", "commit_type": "fix"}
{"commit_tokens": ["added", "option", "to", "load", "XML", "file"], "add_tokens": "attr_reader :g_path , :d_path , :g def test_dita_option load ( Doc . new , :dita ) assert_equal GrammarClass , meta . grammar . class assert_equal 373 , meta . grammar . nodes . size end def test_load_new load Doc . new assert_equal GrammarClass , meta . grammar . class assert_equal 0 , meta . grammar . nodes . size assert_equal HistoryClass , meta . history . class assert_equal 0 , meta . history . nodes . size", "del_tokens": "attr_reader :g_path , :d_path def test_load_new", "commit_type": "add"}
{"commit_tokens": ["add", "initial", "Ledger", "and", "capability", "to", "open", "a", "gnucash", "file"], "add_tokens": "require \"gnucash/ledger\" def self . open ( fname ) Ledger . new ( fname ) end", "del_tokens": "# Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Domain", "and", "IP", "reports", "and", "retrieving", "comments"], "add_tokens": "GET_URL = Uirusu :: VT_API + \"/comments/get\" params = { apikey : api_key , resource : resource , comment : comment } Uirusu . query_api POST_URL , params end # Retrieve a list of comments to Virustotal.com for a specific resource # # @param [String] api_key Virustotal.com API key # @param [String] resource MD5/sha1/sha256/scan_id/URL to search for # @param [DateTime] before A datetime token that allows you to iterate over all comments on a specific item whenever it has been commented on more than 25 times # # @return [JSON] Parsed response def self . get_comments ( api_key , resource , before = nil ) if resource == nil raise \"Invalid resource, must be a valid url\" params = { apikey : api_key , resource : resource } params [ :before ] = before unless before . nil? Uirusu . query_api GET_URL , params", "del_tokens": "if api_key == nil raise \"Invalid API Key\" end response = RestClient . post POST_URL , :apikey => api_key , :resource => resource , :comment => comment case response . code when 429 , 204 raise \"Virustotal limit reached. Try again later.\" when 403 raise \"Invalid privileges, please check your API key.\" when 200 JSON . parse ( response ) else raise \"Unknown Server error.\"", "commit_type": "add"}
{"commit_tokens": ["added", "a", "test", "for", "agent", "registration", "using", "webmock"], "add_tokens": "Given / ^a port of \"(.*?)\"$ / do | str | @port = str end @agent = Agent . create ( @manager_uri , @root_dir , @port ) When / ^I register the agent$ / do stub_request ( :post , \"http://localhost:3000/api\" ) . to_return ( :body => '{\"data\":null,\"code\":null,\"status\":\"success\",\"message\":null}' , :status => 200 ) @response = @agent . register_agent end Then / ^stdout should contain \"(.*?)\"$ / do | str | Then / ^it should return \"(.*?)\"$ / do | str | assert @response . status == str end", "del_tokens": "@agent = Agent . create ( @manager_uri , @root_dir ) Then / ^stdout should contain \"([^\"]*)\"$ / do | str |", "commit_type": "add"}
{"commit_tokens": ["Fix", "more", "Style", "/", "PercentLiteralDelimiters", "offenses"], "add_tokens": "response = %( } )", "del_tokens": "response = %| } |", "commit_type": "fix"}
{"commit_tokens": ["added", "Xml", ".", "has_many_proxied", "."], "add_tokens": "has_one ( name , { :class => EntityProxy . class_for ( options ) } ) def has_many_proxied ( name , options = { } ) has_many ( name , { :class => EntityProxy . class_for ( options ) } ) end collection = [ collection ] unless collection . kind_of? ( Array ) # FIXME: do that IN # DISCUSS: we could also run a hook here.", "del_tokens": "has_one ( name , { :class => EntityProxy . class_for ( options ) } ) collection = [ collection ] unless collection . kind_of? ( Array )", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "default", "underline", "style", "for", "cell"], "add_tokens": "font . font_style . underlined = Underline . new ( :single )", "del_tokens": "unless font_style_node_child . attribute ( 'val' ) . value == 'none' && font_style_node_child font . font_style . underlined = Underline . new ( ( font_style_node_child . attribute ( 'val' ) . value || :single ) . to_sym ) end", "commit_type": "fix"}
{"commit_tokens": ["Allow", "track", "()", "to", "be", "passed", "an", "array", "of", "values"], "add_tokens": "query_params [ param ] = query_params [ param ] . flatten . collect { | q | q . to_s } . join ( ',' )", "del_tokens": "query_params [ param ] = query_params [ param ] . collect { | q | q . to_s } . join ( ',' )", "commit_type": "allow"}
{"commit_tokens": ["add", "Session#expired?", "and", "Session#inactive?", "methods"], "add_tokens": "if self . expired? if self . inactive? # Has this persistent session expired? def expired? self . expires_at && self . expires_at < Time . now end # Has a non-persistent session become inactive? def inactive? self . expires_at . nil? && self . last_activity_at && self . last_activity_at < Authie . config . session_inactivity_timeout . ago end", "del_tokens": "if self . expires_at && self . expires_at < Time . now if self . expires_at . nil? && self . last_activity_at && self . last_activity_at < Authie . config . session_inactivity_timeout . ago", "commit_type": "add"}
{"commit_tokens": ["fixed", "minor", "bug", "in", "the", "IMDB", "example"], "add_tokens": "actors += 1 puts \"Parse new actor no. #{actors} '#{current_actor.name}'\"", "del_tokens": "actors += 1", "commit_type": "fix"}
{"commit_tokens": ["added", "status", "and", "legacy", "data", "to", "asset"], "add_tokens": "alias descriptionType description_type", "del_tokens": "require 'active/identity'", "commit_type": "add"}
{"commit_tokens": ["Updated", "tests", "typecast", "start", "and", "end", "months", "and", "years", "as", "integers"], "add_tokens": "xml_reader :start_year , :from => \"start-date/year\" , :as => Integer xml_reader :start_month , :from => \"start-date/month\" , :as => Integer xml_reader :end_year , :from => \"end-date/year\" , :as => Integer xml_reader :end_month , :from => \"end-date/month\" , :as => Integer", "del_tokens": "xml_reader :start_year , :from => \"start-date/year\" xml_reader :start_month , :from => \"start-date/month\" xml_reader :end_year , :from => \"end-date/year\" xml_reader :end_month , :from => \"end-date/month\"", "commit_type": "update"}
{"commit_tokens": ["Fixed", "spec", "for", "shuffling", "token", "list"], "add_tokens": "equal_lists = 0 10 . times do list2 = subject . map { | t | t . value . name } expect ( list1 ) . to match_array list2 if list1 == list2 equal_lists += 1 end end expect ( equal_lists ) . to be < 10", "del_tokens": "list2 = subject . map { | t | t . value . name } expect ( list1 ) . to match_array list2 expect ( list1 ) . not_to eq list2", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "prevent", "color", "detection", "."], "add_tokens": "unless options . key? ( :enabled ) options . merge! ( enabled : TTY :: Color . color? ) end color = Color . new ( options )", "del_tokens": "defaults = { enabled : TTY :: Color . color? } color = Color . new ( defaults . merge ( options ) )", "commit_type": "change"}
{"commit_tokens": ["Changed", "SimpleUUID", "::", "UUID", "to", "JSON", "::", "Util", "::", "UUID", ".", "Smart", "of", "me", "to", "check", "if", "a", "SimpleUUID", "module", "was", "already", "in", "the", "wild", "..."], "add_tokens": "@@fake_uri_generator = lambda { | s | JSON :: Util :: UUID . create_v5 ( s , JSON :: Util :: UUID :: Nil ) . to_s }", "del_tokens": "@@fake_uri_generator = lambda { | s | SimpleUUID :: UUID . create_v5 ( s , SimpleUUID :: UUID :: Nil ) . to_s }", "commit_type": "change"}
{"commit_tokens": ["Added", "the", "ability", "to", "scope", "in", "request", "levels"], "add_tokens": "query = self level . scopes . each { | s , args | query = query . send ( s , * args ) } records = query . all ( :select => level . select_field . join ( ', ' ) , :include => level . include_field )", "del_tokens": "records = self . all ( :select => level . select_field . join ( ', ' ) , :include => level . include_field )", "commit_type": "add"}
{"commit_tokens": ["Move", "checks", "for", "python", "-", "bugzilla", "into", "python_bugzilla_installed?", "method", "."], "add_tokens": "def self . python_bugzilla_installed? File . exists? ( File . expand_path ( CMD ) ) end raise \"Please install python-bugzilla\" unless python_bugzilla_installed? raise \"Please install python-bugzilla\" unless python_bugzilla_installed? raise \"Please install python-bugzilla\" unless python_bugzilla_installed?", "del_tokens": "raise \"Please install python-bugzilla\" unless File . exists? ( File . expand_path ( CMD ) ) raise \"Please install python-bugzilla\" unless File . exists? ( File . expand_path ( CMD ) ) raise \"Please install python-bugzilla\" unless File . exists? ( File . expand_path ( CMD ) ) private private", "commit_type": "move"}
{"commit_tokens": ["fixing", "commit", "message", "hooks", "updating", "tests"], "add_tokens": "COMMIT_FORMAT = / ^(?:(?:BugId: |Story: B+-|Epic: E-0)[1-9] \\d * \\| )(.*) / check_commit_message_format ( message ) def check_commit_message_format_error 'You must include a valid BugId, Story or Epic number' 'BugId: 12345 | Helpful comment describing bug fix\\n' 'Story: B-12345 | Helpful comment describing story\\n' 'Epic: E-12345 | Epic comment\\n\\n' end # Check commit message contains no non-ASCII characters def check_commit_message_format ( message ) check_label = 'Includes a valid BugId, Story or Epic number' matches = COMMIT_FORMAT . match ( message ) if matches Status . report ( check_label , true ) check_commit_message_length ( matches [ 1 ] ) else Status . report ( check_label , false ) check_commit_message_length ( message ) @errors . push check_commit_message_format_error end end", "del_tokens": "check_commit_message_length ( message )", "commit_type": "fix"}
{"commit_tokens": ["Use", "full", "qualified", "constant", "name"], "add_tokens": "app . middleware . insert 0 , XRay :: Rack :: Middleware", "del_tokens": "app . middleware . insert 0 , Rack :: Middleware", "commit_type": "use"}
{"commit_tokens": ["Changed", "the", "way", "files", "are", "required"], "add_tokens": "if c . validates? ( env ) self . ci_source = c . new ( env ) break end", "del_tokens": "puts \"ask: #{c}: #{c.validates?(env)}\" self . ci_source = c . new ( env ) if c . validates? ( env )", "commit_type": "change"}
{"commit_tokens": ["fixed", "select", "filter", "to", "handle", "symbols", "as", "values"], "add_tokens": "require 'active_support/hash_with_indifferent_access' @filters , @values , @facets = { } . with_indifferent_access , { } . with_indifferent_access , { } . with_indifferent_access else filter name , column : column BlockFilter . new ( self , name , opts ) { | scope | create_driver ( scope ) . named_scope ( name ) . scope }", "del_tokens": "@filters , @values , @facets = { } , { } , { } else filter name , :column => column BlockFilter . new ( self , name , opts ) { | scope | create_driver ( scope ) . named_scope ( name ) . scope }", "commit_type": "fix"}
{"commit_tokens": ["added", "ModelMethods", "for", "quickly", "making", "objects", "ROAR", "-", "compatible", "."], "add_tokens": "require 'roar/client/model_methods' include Roar :: Client :: ModelMethods # gives us #attributes.", "del_tokens": "attr_accessor :attributes def initialize ( attributes = { } ) @attributes = attributes end", "commit_type": "add"}
{"commit_tokens": ["Add", "jars", "using", "require", "."], "add_tokens": "# @param [String] path the colon or semi-colon separated directories dirs . each { | dir | add_to_classpath ( dir ) } # @param [<String>] directories the directories containing jars to add Dir [ File . join ( dir , \"**\" , \"*.jar\" ) ] . each { | jar | add_to_classpath ( jar ) } end end # Adds the given jar file or directory to the classpath. # # @param [String] file the jar file or directory to add def self . add_to_classpath ( file ) if file =~ / .jar$ / then # require is preferred to classpath append for a jar file require file else # A directory must end in a slash since JRuby uses an URLClassLoader. if File . directory? ( file ) and not file =~ / \\/ $ / then file = file + '/' end $CLASSPATH << file", "del_tokens": "# @param path the colon or semi-colon separated directories dirs . each { | dir | $CLASSPATH << dir } # @param directories the directories containing jars to add Dir [ File . join ( dir , \"**\" , \"*.jar\" ) ] . each { | jar | $CLASSPATH << jar }", "commit_type": "add"}
{"commit_tokens": ["Fix", "missing", "abbreviations", "bump", "version"], "add_tokens": "VERSION = \"0.1.4\"", "del_tokens": "VERSION = \"0.1.3\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "recalculate_nested_set", "method", "to", "fix", "broken", "nested", "sets", ".", "In", "the", "process", "of", "this", "I", "have", "also", "turned", ".", "descendants", "into", "a", "named_scope", "so", "that", "options", "can", "be", "used", "with", "it", "."], "add_tokens": "# Recalculates the left and right values for the entire tree def recalculate_nested_set transaction do left = 1 roots . each do | root | left = root . recalculate_nested_set ( left ) end end end base_class . descendants ( self ) def recalculate_nested_set ( left ) child_left = left + 1 children . each do | child | child_left = child . recalculate_nested_set ( child_left ) end set_boundaries ( left , child_left ) save_without_validation! right + 1 end named_scope :descendants , lambda { | node | left , right = find_boundaries ( node . id ) { :conditions => [ \"#{nested_set_column(:left)} > ? and #{nested_set_column(:right)} < ?\" , left , right ] , :order => \"#{nested_set_column(:left)} asc\" } }", "del_tokens": "def find_descendants ( node ) transaction do left , right = base_class . find_boundaries ( node . id ) find ( :all , :order => \"#{nested_set_column(:left)} ASC\" , :conditions => [ \"#{nested_set_column(:left)} > ? AND #{nested_set_column(:right)} < ?\" , left , right ] ) end end base_class . find_descendants ( self )", "commit_type": "add"}
{"commit_tokens": ["Fix", "small", "typo", "in", "specs"], "add_tokens": "context 'when the optional logger was constructed with a nil' do", "del_tokens": "context 'when the optional laggor was constructed with a nil' do", "commit_type": "fix"}
{"commit_tokens": ["add", "the", "ability", "to", "refine", "all", "instances", "of", "a", "class"], "add_tokens": "require 'casting/missing_method_client_class' def base . delegate_missing_methods ( * which ) Casting :: Client . set_delegation_strategy ( self , * which . reverse ) def delegate_missing_methods ( * which ) Casting :: Client . set_delegation_strategy ( self . singleton_class , * which . reverse ) def self . set_delegation_strategy ( base , * which ) which = [ :instance ] if which . empty? which . map! { | selection | selection == :instance && selection = self . method ( :set_method_missing_client ) selection == :class && selection = self . method ( :set_method_missing_client_class ) selection } . map { | meth | meth . call ( base ) } end def self . set_method_missing_client ( base ) base . send ( :include , :: Casting :: MissingMethodClient ) end def self . set_method_missing_client_class ( base ) base . send ( :extend , :: Casting :: MissingMethodClientClass ) end", "del_tokens": "def base . delegate_missing_methods self . send ( :include , :: Casting :: MissingMethodClient ) def delegate_missing_methods self . extend :: Casting :: MissingMethodClient", "commit_type": "add"}
{"commit_tokens": ["Change", "some", "variable", "names", "to", "be", "more", "descriptive"], "add_tokens": "json_representation = { } json_representation [ field ] = send ( field ) . mongoize json_representation data_element = QDM :: DataElement . new data_element . attribute_names . each do | field | data_element . send ( field + '=' , object [ field . to_sym ] ) data_element data_element = QDM :: DataElement . new data_element . attribute_names . each do | field | data_element . send ( field + '=' , object [ field . to_sym ] ) data_element . mongoize", "del_tokens": "json_rep = { } json_rep [ field ] = send ( field ) . mongoize json_rep de = QDM :: DataElement . new de . attribute_names . each do | field | de . send ( field + '=' , object [ field . to_sym ] ) de de = QDM :: DataElement . new de . attribute_names . each do | field | de . send ( field + '=' , object [ field . to_sym ] ) de . mongoize", "commit_type": "change"}
{"commit_tokens": ["Make", "Connection#send_request", "and", "#fetch_response", "public", "and", "documented", "."], "add_tokens": "@connection . send_request ( @id , req_type , properties ) @connection . fetch_response ( @id , expect )", "del_tokens": "Util . error_check :\" sending a request on a channel \" , @connection . send ( :send_method , @id , req_type , properties ) @connection . send ( :fetch_response , @id , expect )", "commit_type": "make"}
{"commit_tokens": ["Make", "parser", "file", "naming", "more", "obvious"], "add_tokens": "require \"stompede/stomp/parser\"", "del_tokens": "require \"stompede/stomp\"", "commit_type": "make"}
{"commit_tokens": ["Added", "channels", "playlist", "playlist", "items", "no", "tests"], "add_tokens": "require 'yourub/rest/channels' require 'yourub/rest/playlists' require 'yourub/rest/playlist_items' include Yourub :: REST :: Playlists include Yourub :: REST :: PlaylistItems include Yourub :: REST :: Channels", "del_tokens": "# include Yourub::REST::Playlists # include Yourub::REST::Channels", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "log", "step", "errors", "."], "add_tokens": "log_step ( :info , :before , step , context , options ) begin step . last . call ( context , options ) rescue Exception => ex log_step ( :error , :after , step , context , options ) raise ex end log_step ( :info , :after , step , context , options ) private def log_step ( level , id , step , context , options ) Hero . logger . send level , \"HERO #{id.to_s.ljust(6)} #{formula_name} -> #{step.first} Context: #{context.inspect} Options: #{options.inspect}\"", "del_tokens": "log_step ( :before , step , context , options ) step . last . call ( context , options ) log_step ( :after , step , context , options ) private def log_step ( id , step , context , options ) Hero . logger . info \"HERO #{id.to_s.ljust(6)} #{formula_name} -> #{step.first} Context: #{context.inspect} Options: #{options.inspect}\"", "commit_type": "update"}
{"commit_tokens": ["Fix", "spec", "for", "underscore", "support", "for", "feed", "slugs"], "add_tokens": "it \"should not refuse feed_slug with underscores\" do expect { Stream :: Feed . new ( nil , \"feed_slug\" , \"user_id\" , \"\" ) } . to_not raise_error Stream :: StreamInputData", "del_tokens": "it \"should refuse feed_slug with underscores\" do expect { Stream :: Feed . new ( nil , \"feed_slug\" , \"user_id\" , \"\" ) } . to raise_error Stream :: StreamInputData", "commit_type": "fix"}
{"commit_tokens": ["added", "namespaced", "rule", "names", "with", "dot"], "add_tokens": "rule ( :rule_name ) { ( match ( '[a-zA-Z]' ) >> match ( '[a-zA-Z0-9\\-_\\.]' ) . repeat ) . as ( :rule_name ) }", "del_tokens": "rule ( :rule_name ) { ( match ( '[a-zA-Z]' ) >> match ( '[a-zA-Z0-9\\-_]' ) . repeat ) . as ( :rule_name ) }", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "use", "newer", "RSpec", "expect", "syntax"], "add_tokens": "matches = bz . query ( 94897099 ) expect ( matches ) . to be_kind_of ( Array ) expect ( matches ) . to be_empty expect ( bz . last_command ) . to include ( \"Bug.get\" ) expect ( existing_bz [ \"priority\" ] ) . to eq ( \"unspecified\" ) expect ( existing_bz [ \"keywords\" ] ) . to eq ( [ \"ZStream\" ] ) expect ( existing_bz [ \"cc\" ] ) . to eq ( [ \"calvin@redhat.com\" , \"hobbes@RedHat.com\" ] ) expect ( bz . last_command ) . to include ( \"Bug.create\" ) expect ( new_bz_id ) . to eq ( output [ \"id\" ] ) expect ( bz . last_command ) . to include ( \"Bug.create\" ) expect ( new_bz_id ) . to eq ( output [ \"id\" ] )", "del_tokens": "matches = bz . query ( 94_897_099 ) matches . should be_kind_of ( Array ) matches . should be_empty bz . last_command . should include ( \"Bug.get\" ) existing_bz [ \"priority\" ] . should == \"unspecified\" existing_bz [ \"keywords\" ] . should == [ \"ZStream\" ] existing_bz [ \"cc\" ] . should == [ \"calvin@redhat.com\" , \"hobbes@RedHat.com\" ] bz . last_command . should include ( \"Bug.create\" ) new_bz_id . should == output [ \"id\" ] bz . last_command . should include ( \"Bug.create\" ) new_bz_id . should == output [ \"id\" ]", "commit_type": "change"}
{"commit_tokens": ["added", "table_name", "as", "argument", "in", "set_table_capacity", "function", "call"], "add_tokens": "table_details = get_table_details ( table_name ) set_table_capacity ( table_name , read_capacity , write_capacity )", "del_tokens": "set_table_capacity ( read_capacity , write_capacity )", "commit_type": "add"}
{"commit_tokens": ["Allow", "disabling", "of", "connecting", "to", "user", "and", "tweet", "streams"], "add_tokens": "method_option :stream , type : :boolean , desc : \"Enable or disable the streaming API connection\" , default : true bot = Twittbot :: Bot . new ( options )", "del_tokens": "bot = Twittbot :: Bot . new", "commit_type": "allow"}
{"commit_tokens": ["Fix", "up", "how", "we", "load", "in", "our", "files", "using", "autoload", "and", "such", "."], "add_tokens": "GEOS_BASE = File . join ( File . dirname ( __FILE__ ) ) require 'geos' require File . join ( GEOS_BASE , 'geos_helper' ) autoload :ActiveRecord , File . join ( GEOS_BASE , * %w{ active_record_extensions } ) autoload :GoogleMaps , File . join ( GEOS_BASE , * %w{ google_maps } )", "del_tokens": "begin require 'google_maps/polyline_encoder' rescue LoadError # do nothing end require File . join ( File . dirname ( __FILE__ ) , 'geos_helper' )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "ERB", "in", "patch", "text"], "add_tokens": "require \"erb\" patch_text = text if options [ :binding ] patch_text = ERB . new ( text , nil , nil , \"@template\" ) . result ( options [ :binding ] ) end patch_text , patch_text = text if options [ :binding ] patch_text = ERB . new ( text , nil , nil , \"@template\" ) . result ( options [ :binding ] ) end patch_text ,", "del_tokens": "text , text ,", "commit_type": "allow"}
{"commit_tokens": ["add", "feature", "to", "find", "nearby", "stations"], "add_tokens": "Oeffi . provider . send ( method , * args ) result = super :autocompleteStations , [ @string ] class NearbyQuery < Query attr_accessor :lat , :lon def initialize ( opts ) @lat = opts [ :lat ] @lon = opts [ :lon ] end def perform factor = 1000000 location = Java :: DeSchildbachPteDto :: Location . new Queries :: get_type ( :ANY ) , ( @lat * factor ) . to_i , ( @lon * factor ) . to_i result = super :queryNearbyStations , [ location , 5000 , 100 ] return [ ] unless result . status . to_s == \"OK\" result . stations . to_a . map do | station | Locations :: Location . new station end end end def self . get_type ( identifier ) Java :: DeSchildbachPteDto :: LocationType :: const_get identifier . to_s end", "del_tokens": "Oeffi . provider . send ( method , args ) result = super :autocompleteStations , @string", "commit_type": "add"}
{"commit_tokens": ["Fix", "typos", "in", "Devise", "descriptions"], "add_tokens": "# Initial descriptions for devise specific columns :encrypted_password => \"Devise encrypted password\" , :confirmation_sent_at => \"Devise Confirmable module\" ,", "del_tokens": "# Initila descriptions for devise specific columns :confiramtion_sent_at => \"Devise Confirmable module\" ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "this", "spec", "pattern", "instead"], "add_tokens": "require 'spec_helper'", "del_tokens": "require File . expand_path ( '../spec_helper' , __FILE__ )", "commit_type": "use"}
{"commit_tokens": ["add", "some", "more", "yard", "doc"], "add_tokens": "# This module contains ruby mixins that are used within multiple classes to share code. # Applications using common libraries to concentrate on things that are new # and no solved by existing software. Therefore there are similar deploy # tasks that are needed for applications. # # Cany groups common deploy aspects in recipes. This recipes can be included # and used by the application. Normally there exists one recipe for every # important software that is used by the application and influences directly # the way the applications needs to be installed. # # Central recipes are bundler as gem package manager and rails as popular # web framework. # # To support starting the applications there is also a collection of recipes # deploying ruby web server or background services. module Recipes require 'cany/recipes/bundler' require 'cany/recipes/bundler/gem' require 'cany/recipes/bundler/gem_db' require 'cany/recipes/rails' require 'cany/recipes/web_server' require 'cany/recipes/thin' end # Cany is designed to be able to pack applications for multiple package # managers. Although there is currently only support for debian/ubuntu. # All DPKG specific things are group into the Dpkg namespace. module Dpkg require 'cany/dpkg' require 'cany/dpkg/creator' require 'cany/dpkg/builder' require 'cany/dpkg/deb_helper_recipe' end", "del_tokens": "require 'cany/recipes/bundler' require 'cany/recipes/bundler/gem' require 'cany/recipes/bundler/gem_db' require 'cany/recipes/rails' require 'cany/recipes/web_server' require 'cany/recipes/thin' require 'cany/dpkg' require 'cany/dpkg/creator' require 'cany/dpkg/builder' require 'cany/dpkg/deb_helper_recipe'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "{", "match", ":", "regex", "}", "matching", "rule", "was", "being", "logged", "as", "being", "ignored", "."], "add_tokens": "handle_match_type ( object , path , rules ) handle_regex ( object , path , rules ) log_ignored_rules ( path , rules , { } ) def handle_match_type object , path , rules log_ignored_rules ( path , rules , { 'match' => 'type' } ) Pact :: SomethingLike . new ( object ) end def handle_regex object , path , rules log_ignored_rules ( path , rules , { 'match' => 'regex' , 'regex' => rules [ 'regex' ] } ) Pact :: Term . new ( generate : object , matcher : Regexp . new ( rules [ 'regex' ] ) ) end def log_ignored_rules path , rules , used_rules used_rules . each_pair do | used_key , used_value | dup_rules . delete ( used_key ) if dup_rules [ used_key ] == used_value end", "del_tokens": "log_ignored_rules ( path , rules , 'match' , 'type' ) Pact :: SomethingLike . new ( object ) log_ignored_rules ( path , rules , 'regex' , rules [ 'regex' ] ) Pact :: Term . new ( generate : object , matcher : Regexp . new ( rules [ 'regex' ] ) ) log_ignored_rules ( path , rules , nil , nil ) def log_ignored_rules path , rules , used_key , used_value dup_rules . delete ( used_key ) if used_key && dup_rules [ used_key ] == used_value", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "Mxit", "headers", "to", "emulator"], "add_tokens": "VERSION = \"0.3.2\"", "del_tokens": "VERSION = \"0.3.1\"", "commit_type": "add"}
{"commit_tokens": ["add", "more", "specs", "for", "default", "sat", "solver"], "add_tokens": "let ( :a ) { PropLogic :: Variable . new 'a' } let ( :b ) { PropLogic :: Variable . new 'b' } let ( :c ) { PropLogic :: Variable . new 'c' } describe '#sat?' do context '(satisfiable)' do it 'returns satisfied term' do s = PropLogic :: DefaultIncrementalSolver . new a s << ( b | c ) sat = s . sat? expect ( s . term & sat ) . to be_sat end end context '(unsatisfiable)' do it 'returns false' do s = PropLogic :: DefaultIncrementalSolver . new a s << ~ a expect ( s . sat? ) . to be false end end end", "del_tokens": "let ( :a ) { PropLogic :: Variable . new 'a' } let ( :b ) { PropLogic :: Variable . new 'b' } let ( :c ) { PropLogic :: Variable . new 'c' } let ( :d ) { PropLogic :: Variable . new 'd' }", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Last", "Will", "and", "Testament", "feature", "in", "MQTT", "::", "Client", "."], "add_tokens": "attr_accessor :will_topic # The topic that the Will message is published to attr_accessor :will_payload # Contents of message that is sent by broker when client disconnect attr_accessor :will_qos # The QoS level of the will message sent by the broker attr_accessor :will_retain # If the Will message should be retain by the broker after it is sent :password => nil , :will_topic => nil , :will_payload => nil , :will_qos => 0 , :will_retain => false def set_will ( topic , payload , retain = false , qos = 0 ) self . will_topic = topic self . will_payload = payload self . will_retain = retain self . will_qos = qos end :password => @password , :will_topic => @will_topic , :will_payload => @will_payload , :will_qos => @will_qos , :will_retain => @will_retain", "del_tokens": ":password => nil :password => @password", "commit_type": "implement"}
{"commit_tokens": ["Updated", "valid", "keys", "assertions", "on", "two", "Contact", "finder", "methods"], "add_tokens": "options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :required , :contact_type , :exclude_self ) options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :required , :contact_type , :exclude_self )", "del_tokens": "options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :required , :contact_type ) options . assert_valid_keys ( :key , :value , :limit , :offset , :type , :order , :name , :email , :contact_type , :exclude_self )", "commit_type": "update"}
{"commit_tokens": ["Added", "verbosity", "option", "for", "debugging", "purposes", "."], "add_tokens": "attr_reader :verbose def initialize ( accesskey , secret , api = '2010-10-01' , endpoint = 'https://route53.amazonaws.com/' , verbose = false ) @verbose = verbose puts \"URL: #{url}\" if @verbose puts \"Type: #{type}\" if @verbose puts \"Req: #{data}\" if type != \"GET\" && @verbose #puts \"Resp:\"+resp.to_s if @verbose #puts \"XML_RESP:\"+raw_resp if @verbose puts \"Making Date Request\" if @verbose puts \"Received Date.\" if @verbose #puts \"XML:\\n#{xml_str}\" if @conn.verbose #puts \"Name:\"+record.search(\"Name\").first.innerText if @conn.verbose #puts \"Type:\"+record.search(\"Type\").first.innerText if @conn.verbose #puts \"TTL:\"+record.search(\"TTL\").first.innerText if @conn.verbose #puts \"Val:\"+val.innerText if @conn.verbose #puts \"XML:\\n#{xml_str}\" if @conn.verbose puts \"Raw: #{@raw_data}\" if @conn . verbose", "del_tokens": "def initialize ( accesskey , secret , api = '2010-10-01' , endpoint = 'https://route53.amazonaws.com/' ) puts \"URL: #{url}\" puts \"Type: #{type}\" puts \"Req: #{data}\" if type != \"GET\" #puts \"Resp:\"+resp.to_s #puts \"XML_RESP:\"+raw_resp puts \"Making Date Request\" puts \"Received Date.\" #puts \"XML:\\n#{xml_str}\" #puts \"Name:\"+record.search(\"Name\").first.innerText #puts \"Type:\"+record.search(\"Type\").first.innerText #puts \"TTL:\"+record.search(\"TTL\").first.innerText #puts \"Val:\"+val.innerText #puts \"XML:\\n#{xml_str}\" puts \"Raw: #{@raw_data}\"", "commit_type": "add"}
{"commit_tokens": ["make", "the", "report_coverage", "file", "return", "false", "if", "it", "cannot", "run", "due", "to", "misconfig", "/", "etc"], "add_tokens": "# Returns false if unsuccessful # Returns true if successful return false return false unless current_node . zero? true", "del_tokens": "return return unless current_node . zero?", "commit_type": "make"}
{"commit_tokens": ["moved", "code", "from", "the", "cookbook"], "add_tokens": "module ILO_SDK", "del_tokens": "module iloSDK", "commit_type": "move"}
{"commit_tokens": ["Added", "uniquess", "parameter", "to", "random", "generator"], "add_tokens": "def generate ( seed = Time . now . utc . to_i , test_uniquess = true ) break if ! test_uniquess || unique? ( seed , index )", "del_tokens": "def generate ( seed = Time . now . utc . to_i ) break if unique? ( seed , index )", "commit_type": "add"}
{"commit_tokens": ["Create", "Xrc", "::", "User", "class", "for", "users", "in", "given", "roster", "information"], "add_tokens": "User . new (", "del_tokens": "OpenStruct . new (", "commit_type": "create"}
{"commit_tokens": ["Implement", "a", "RiakJson", "persistence", "strategy", "pass", "test"], "add_tokens": "User . persistence_strategy . must_equal Riagent :: Persistence :: RiakJsonStrategy", "del_tokens": "User . persistence_strategy . must_be_kind_of Riagent :: Persistence :: RiakJsonStrategy", "commit_type": "implement"}
{"commit_tokens": ["add", "support", "for", "the", "cancel", "fax", "api", "call"], "add_tokens": "def cancel_fax ( options ) options . merge! ( { api_key : api_key , api_secret : api_secret } ) self . class . post ( \"/faxCancel\" , options ) end", "del_tokens": "def cancel_fax ( options ) # @path = \"/faxCancel\" # add cancel logic here end", "commit_type": "add"}
{"commit_tokens": ["Fix", "call", "to", "AddressBook", ".", "address_book", "recusively", "when", "request", "access", "on", "iOS", "6"], "add_tokens": "@address_book = ABAddressBookCreateWithOptions ( nil , error ) @address_book ABAddressBookRequestAccessWithCompletion @address_book , access_callback", "del_tokens": "address_book = ABAddressBookCreateWithOptions ( nil , error ) address_book ABAddressBookRequestAccessWithCompletion address_book , access_callback", "commit_type": "fix"}
{"commit_tokens": ["added", "term", "semantics", "parser", "(", "test", "driver", ")"], "add_tokens": "class VariantSignature # TODO: More strict prefix validation for variant namespace? prefix ( any ) ,", "del_tokens": "class Variant prefix ( identifier ( has_namespace , namespace_of ( :* ) ) ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "helper", "for", "generating", "RestServiceProfiles", "from", "RestServices"], "add_tokens": "def initialize ( attributes = { } ) super ( attributes ) end def profile RestServiceProfile . new ( service : endpoint , action : action )", "del_tokens": "def initialize", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "coverage", "for", "PTR"], "add_tokens": "[ '-' , '.' , '@' ]", "del_tokens": "[ '-' , '.' ]", "commit_type": "add"}
{"commit_tokens": ["Use", "active_support", "/", "test_case", "instead", "of", "test", "/", "unit", "/", "test_case"], "add_tokens": "class ValidatesCaptchaTest < ValidatesCaptcha :: TestCase test \"defines a class level #version method\" do end test \"class level #version method returns a valid version\" do", "del_tokens": "class ValidatesCaptchaTest < Test :: Unit :: TestCase def test_version", "commit_type": "use"}
{"commit_tokens": ["Fix", "my", "broken", "attempt", "at", "the", "parenthesization", "thing", "."], "add_tokens": "parse ( \"<%= link_to \\\"mom\\\" %>\" ) . convert . should == \"rawtext(link_to \\\"mom\\\")\\n\" it \"wraps printlets in parens if necessary, to avoid warning: parenthesize argument(s) for future version\" do parse ( \"<%= h \\\"mom\\\" %>\" ) . convert . should == \"text \\\"mom\\\"\\n\" parse ( \"<%= h hi \\\"mom\\\" %>\" ) . convert . should == \"text(hi \\\"mom\\\")\\n\" parse ( \"<%= link_to blah %>\" ) . convert . should == \"rawtext(link_to blah)\\n\" parse ( \"<%= link_to(blah) %>\" ) . convert . should == \"rawtext link_to(blah)\\n\" end it \"won't parenthesize because of spaces within string constants\" do # Is this fancier than needed? Where do we draw the line? pending { parse ( \"<%= h \\\"a string\\\" %>\" ) . convert . should == \"text \\\"a string\\\"\\n\" } end", "del_tokens": "parse ( \"<%= link_to \\\"mom\\\" %>\" ) . convert . should == \"rawtext link_to \\\"mom\\\"\\n\" it \"wraps printlets in parens if necessary, to avoid warning: parenthesize argument(s) for future version\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "prism", "mapping", ";", "add", "search", "filtering", ";", "UI", "tweaks", ";"], "add_tokens": "@facets = { :dcterms => %w[ format language issued creator publisher subject DDC LCC ] } @fields = [ :heading , :dcterms ] #:issued, :format, :language, :creator, :publisher, :subject search . fields @fields", "del_tokens": "# @filters = params[:fi] || JSON.load(session[:filters]) || {} # session[:filters] = JSON.dump(@filters) @facets = { 'dcterms' => [ 'format' , 'language' , 'issued' , # descriptive facets 'creator' , 'publisher' , # agent facets 'subject' , ' spatial ', ' DDC ', ' LCC ' ] } # concept facets # @fields = {:dcterms => [:issued, :format, :language, :creator, :publisher, :subject]} # search.fields @fields", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "number", ";", "forgot", "again", "..."], "add_tokens": "VERSION = [ 0 , 2 , 4 , 6 ]", "del_tokens": "VERSION = [ 0 , 2 , 4 , 5 ]", "commit_type": "update"}
{"commit_tokens": ["Use", "Object", ".", "send", "instead", "of", "Object", ".", "class_eval"], "add_tokens": "Object . send ( :remove_const , :Rails )", "del_tokens": "Object . class_eval do remove_const ( :Rails ) end", "commit_type": "use"}
{"commit_tokens": ["Make", "env", "not", "nil", "in", "Command", "request"], "add_tokens": "# We don't have path/headers information here, # but we still want `connection.env` to work socket = build_socket ( env : base_rack_env ) env = base_rack_env env . merge! ( \"rack.url_scheme\" => uri . scheme ) def base_rack_env # Minimum required variables according to Rack Spec # (not all of them though, just those enough for Action Cable to work) # See https://rubydoc.info/github/rack/rack/master/file/SPEC { \"REQUEST_METHOD\" => \"GET\" , \"SCRIPT_NAME\" => \"\" , \"PATH_INFO\" => \" / \" , \"QUERY_STRING\" => \"\" , \"SERVER_NAME\" => \"\" , \"SERVER_PORT\" => \"80\" , \"rack.url_scheme\" => \"http\" , \"rack.input\" => \"\" } end", "del_tokens": "socket = build_socket # Minimum required variables according to Rack Spec env = { \"REQUEST_METHOD\" => \"GET\" , \"SCRIPT_NAME\" => \"\" , \"rack.url_scheme\" => uri . scheme , \"rack.input\" => \"\" }", "commit_type": "make"}
{"commit_tokens": ["allow", "to_d", "to", "be", "called", "on", "decimal", "inputs"], "add_tokens": "cast_number ( value , :to_i ) cast_number ( value , :to_f ) cast_number ( value , :to_d , :to_f ) def cast_number ( value , * meths ) return nil if value . blank? meth = meths . detect { | m | value . respond_to? ( m ) } meth ? value . send ( meth ) : value", "del_tokens": "cast_number ( value ) . try ( :to_i ) cast_number ( value ) . try ( :to_f ) d = cast_number ( value ) d ? BigDecimal ( d . to_s ) : nil def cast_number ( value ) val = cast_string ( value ) . strip return nil if val . blank? val", "commit_type": "allow"}
{"commit_tokens": ["Allow", "Photo#search", "to", "recieve", "orientation", "parameter"], "add_tokens": "def random ( count : nil , categories : nil , collections : nil , featured : nil , user : nil , query : nil , width : nil , height : nil , orientation : nil ) # @param orientation [String] Filter by orientation of the photo. Valid values are landscape, portrait, and squarish. def search ( query , page = 1 , per_page = 10 , orientation = nil ) per_page : per_page , orientation : orientation", "del_tokens": "def random ( count : nil , categories : nil , collections : nil , featured : nil , user : nil , query : nil , width : nil , height : nil , orientation : nil ) def search ( query , page = 1 , per_page = 10 ) per_page : per_page", "commit_type": "allow"}
{"commit_tokens": ["Fix", "small", "RuboCop", "issue", "prep", "for", "new", "gem", "release"], "add_tokens": "PROJECT_PATTERN = '[a-zA-Z0-9]{1,10}'", "del_tokens": "PROJECT_PATTERN = \"[a-zA-Z0-9]{1,10}\"", "commit_type": "fix"}
{"commit_tokens": ["fixed", "pretty", "xml", "with", "stylesheet", "option"], "add_tokens": "@fh . write ( \"<?xml version='1.0'?>\\n\" ) %Q{<?xml-stylesheet type=\"text/xsl\" href=\"#{opts[:stylesheet]}\"?>\\n} )", "del_tokens": "@fh . write ( \"<?xml version='1.0'?>\" ) %Q{<?xml-stylesheet type=\"text/xsl\" href=\"#{opts[:stylesheet]}\"?>} )", "commit_type": "fix"}
{"commit_tokens": ["Added", "max", "and", "min", "value", "checking", "on", "integer", "types", "and", "implemented", "Byte", "and", "SByte", "types", "."], "add_tokens": "validate ( new_value . to_i ) private def validate ( value ) if value > max_value || value < min_value raise :: ArgumentError , \"Value is outside accepted range: #{min_value} to #{max_value}\" end end def min_value @min ||= - ( 2 ** 63 ) end def max_value @max ||= ( 2 ** 63 ) - 1 end private def min_value @min ||= - ( 2 ** 31 ) end def max_value @max ||= ( 2 ** 31 ) - 1 end private def min_value @min ||= - ( 2 ** 15 ) end def max_value @max ||= ( 2 ** 15 ) - 1 end class Int64 < Integer ; end class Byte < Integer def type 'Edm.Byte' end private def min_value 0 end def max_value @max ||= ( 2 ** 8 ) - 1 end end class SByte < Integer def type 'Edm.SByte' end private def min_value @min ||= - ( 2 ** 7 ) end def max_value @max ||= ( 2 ** 7 ) - 1 end", "del_tokens": "class Int64 < Integer # def type # 'Edm.Int64' # end", "commit_type": "add"}
{"commit_tokens": ["added", "functionality", "to", "add", "js", "methods", "into", "the", "options"], "add_tokens": "options_collection = [ generate_json_from_hash ( object . options ) ] options = { #{options_collection.join(',')} }; private def generate_json_from_hash hash hash . each_pair . map do | key , value | k = key . to_s . camelize . gsub! ( / \\b \\w / ) { $& . downcase } if value . is_a? Hash %|\"#{k}\": { #{generate_json_from_hash(value)} }| else if value . respond_to? ( :js_code ) && value . js_code? %|\"#{k}\": #{value}| else %|\"#{k}\": #{value.to_json}| end end end . flatten . join ( ',' ) end", "del_tokens": "options_collection = [ ] object . options . keys . each do | key | k = key . to_s . camelize . gsub! ( / \\b \\w / ) { $& . downcase } options_collection << \"#{k}: #{object.options[key].to_json}\" end options = { #{options_collection.join(\",\")} };", "commit_type": "add"}
{"commit_tokens": ["Changed", "how", "Output", "gets", "the", "filename", "to", "be", "ffmpeg", "independent"], "add_tokens": "output . scan ( / \\[ download \\] Destination: \\s (.*)$ / ) [ 0 ] [ 0 ]", "del_tokens": "output . scan ( / Merging formats into \\\" (.*) \\\" / ) [ 0 ] [ 0 ]", "commit_type": "change"}
{"commit_tokens": ["fixed", "rune", "page", "class", ":", "the", "writer", "methods", "weren", "t", "in", "the", "right", "scope"], "add_tokens": "private attr_writer :id , :name , :current def slots = * runeslots @slots = runeslots . flatten . map { | slot | RuneSlot . new slot } end", "del_tokens": "end private attr_writer :id , :name , :current def slots = * runeslots @slots = runeslots . flatten . map { | slot | RuneSlot . new slot }", "commit_type": "fix"}
{"commit_tokens": ["added", "nil", "check", "for", "facilityLocations"], "add_tokens": "unless facilityLocations . nil? shiftedFacilityLocations = [ ] facilityLocations . each do | location | # Need to convert to a QDM::FacilityLocation because it is being passed in as a Hash facilityLocation = QDM :: FacilityLocation . new ( location ) shift_facility_location_years ( facilityLocation , year_shift ) shiftedFacilityLocations << facilityLocation end send ( field + '=' , shiftedFacilityLocations )", "del_tokens": "shiftedFacilityLocations = [ ] facilityLocations . each do | location | # Need to convert to a QDM::FacilityLocation because it is being passed in as a Hash facilityLocation = QDM :: FacilityLocation . new ( location ) shift_facility_location_years ( facilityLocation , year_shift ) shiftedFacilityLocations << facilityLocation send ( field + '=' , shiftedFacilityLocations )", "commit_type": "add"}
{"commit_tokens": ["Allow", "configuration", "of", "jruby", "invocation", "to", "allow", "easy", "use", "of", "e", ".", "g", ".", "RVM"], "add_tokens": "def self . jruby_invocation @jruby_invocation ||= \"jruby\" end def self . jruby_invocation = ( invocation ) @jruby_invocation = invocation IO . popen ( %{#{jruby_invocation} -e \"#{celerity_invocation}\"} , 'r+' ) . extend ( ServerCommands )", "del_tokens": "def self . jruby_path \"jruby\" IO . popen ( %{#{jruby_path} -e \"#{celerity_invocation}\"} , 'r+' ) . extend ( ServerCommands )", "commit_type": "allow"}
{"commit_tokens": ["Change", "creation", "of", "the", "perm", "hash", "to", "use", "a", "lambda"], "add_tokens": "#Store the perm hash in a lambda since we have to create a new one on every deny rule @perm_hash_lambda = lambda { Hash . new { | k , v | k [ v ] = Hash . new { | k2 , v2 | k2 [ v2 ] = [ ] } } } @permissions = Array . new . push ( @perm_hash_lambda . call ) @permissions . push ( @perm_hash_lambda . call )", "del_tokens": "@permissions = Array . new . push ( Hash . new { | k , v | k [ v ] = Hash . new { | k2 , v2 | k2 [ v2 ] = [ ] } } ) @permissions . push ( Hash . new { | k , v | k [ v ] = Hash . new { | k2 , v2 | k2 [ v2 ] = [ ] } } )", "commit_type": "change"}
{"commit_tokens": ["adding", "new", "routing", "for", "hte", "collection", "of", "clips", ".", "two", "new", "routes", "so", "we", "can", "maintain", "the", "list_clips_path", "helper"], "add_tokens": "resources :clips , :path => \"/\" do collection do get 'list' , :action => :list get 'list(/:lang)' , :action => :list end end", "del_tokens": "get \"list\" , :to => \"clips#list\" resources :clips , :path => \"/\"", "commit_type": "add"}
{"commit_tokens": ["add", "a", "config", "file", "option", "and", "a", "sample", "config", "file", ".", "make", "syslog", "logging"], "add_tokens": "require 'yaml' def load_config_file ( filename ) YAML . load ( File . open ( filename ) ) [ 'starling' ] . each do | key , value | # alias some keys case key when \"queue_path\" then key = \"path\" when \"log_file\" then key = \"logger\" end options [ key . to_sym ] = value if options [ :log_level ] . instance_of? ( String ) options [ :log_level ] = Logger . const_get ( options [ :log_level ] ) end end end \"usage: starling [options...]\\n\" , opts . on ( \"-f\" , \"--config FILENAME\" , \"Config file (yaml) to load\" ) do | filename | load_config_file ( filename ) end opts . on ( \"-PFILE\" , \"--pid FILENAME\" , \"save PID in FILENAME when using -d option.\" , \"(default: #{options[:pid_file]})\" ) do | pid_file | opts . on ( \"--syslog CHANNEL\" , \"Write logs to the syslog instead of a log file.\" ) do | channel | options [ :syslog_channel ] = channel end", "del_tokens": "\"usage: starling [-v] [-q path] [-h host] [-p port]\\n\" , \" [-d [-P pidfile]] [-u user] [-g group] [-l log] [-t timeout]\\n\" , opts . on ( \"-PFILE\" , \"--pid FILE\" , \"save PID in FILE when using -d option.\" , \"(default: #{options[:pid_file]})\" ) do | pid_file |", "commit_type": "add"}
{"commit_tokens": ["updated", "gems", "changed", "delete", "callback"], "add_tokens": "def before_delete", "del_tokens": "def after_delete", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "command", "line", "tool", "."], "add_tokens": "# Array of command line arguments attr_reader :argv @argv = argv begin unless self . symbology . nil? unless self . options [ :ascii ] Barcodes :: Renderer :: Pdf . new ( Barcodes . create ( self . symbology , self . options ) ) . render ( self . target ) else Barcodes :: Renderer :: Ascii . new ( Barcodes . create ( self . symbology , self . options ) ) . render ( self . target ) end rescue Exception => e puts e . message self . parser . parse! ( self . argv ) @symbology = self . argv . shift @target = self . argv . shift", "del_tokens": "# Array of command line arguments attr_reader :arguments @arguments = arguments unless self . symbology . nil? unless self . options [ :ascii ] Barcodes :: Renderer :: Pdf . new ( Barcodes . create ( self . symbology , self . options ) ) . render ( self . target ) else Barcodes :: Renderer :: Ascii . new ( Barcodes . create ( self . symbology , self . options ) ) . render ( self . target ) self . parser . parse! ( self . arguments ) @symbology = self . arguments . shift @target = self . arguments . shift", "commit_type": "fix"}
{"commit_tokens": ["added", "Gemfile", "back", "cleaned", "up", "tests", "a", "bit"], "add_tokens": "[ NestedForm :: Builder , NestedForm :: SimpleBuilder , NestedForm :: FormtasticBuilder ] . each do | builder |", "del_tokens": "$builders . each do | builder |", "commit_type": "add"}
{"commit_tokens": ["Update", "usage", "of", "string", "-", "utility", "to", "latest", "version", "."], "add_tokens": "using StringUtility countstring = count . to_s . separate", "del_tokens": "countstring = StringUtility . separate_with ( count . to_s )", "commit_type": "update"}
{"commit_tokens": ["remove", "all", "mentions", "of", "doting"], "add_tokens": "# require 'dotenv' # Dotenv::Railtie.load # Dotenv.load", "del_tokens": "require 'dotenv' Dotenv :: Railtie . load Dotenv . load", "commit_type": "remove"}
{"commit_tokens": ["Fix", "error", "when", "receiving", "code", "204"], "add_tokens": "if response . body sio = StringIO . new ( response . body ) gz = Zlib :: GzipReader . new ( sio ) page = gz . read ( ) @body = page else @body = nil end", "del_tokens": "sio = StringIO . new ( response . body ) gz = Zlib :: GzipReader . new ( sio ) page = gz . read ( ) @body = page", "commit_type": "fix"}
{"commit_tokens": ["Make", "action", "for", "Dispatcher", ".", "path_to", ":", "index", "by", "default"], "add_tokens": "def path_to ( ctrl , action = :index , args = { } )", "del_tokens": "def path_to ( ctrl , action , args = { } )", "commit_type": "make"}
{"commit_tokens": ["Added", "method", "to", "test", "if", "the", "refresh", "token", "has", "expired", "."], "add_tokens": "attr_reader :access_token , :type , :expires_in , :refresh_token , :expires_at , :refresh_token_expires_at # If there isn't a refresh token `has_refresh_token_expired?` must always return true. @refresh_token_expires_at = @refresh_token ? Time . now + 24 . hours : Time . now def has_refresh_token_expired? @refresh_token_expires_at - Time . now <= 3.0 end", "del_tokens": "attr_reader :access_token , :type , :expires_in , :refresh_token , :expires_at", "commit_type": "add"}
{"commit_tokens": ["Add", "Channel#views", "(", "no", "options", "no", "errors", ")"], "add_tokens": "it 'returns valid data limiting the number of HTTP requests' do expect ( Net :: HTTP ) . to receive ( :start ) . once . and_call_original", "del_tokens": "it 'returns valid data' do", "commit_type": "add"}
{"commit_tokens": ["Moved", "pixel", "ratio", "logic", "and", "tracking", "to", "Source"], "add_tokens": "files = { } # Pixel ratios are keys, values are the generated files. files [ p ] = GeneratedImage . new ( raise \"Preset #{@instructions.preset_name}:\" \" source #{name} must include either a width or a height.\" width : source_preset [ 'width' ] * pixel_ratio , height : source_preset [ 'height' ] * pixel_ratio # Filename relative to source directory: image = @instructions . source_images [ name ] # Complete filename: filename = File . join ( @instructions . source_dir , image ) # Only return image if it exists: return image if File . exist? ( filename ) set = files . each_pair do | pixel_ratio , file | url = Pathname . join ( @instructions . url_prefix , file . name ) \"#{url} #{pixel_ratio}x\"", "del_tokens": "files = [ ] files << GeneratedImage . new ( raise \"#{@instructions.preset_name}:\" \" #{name} must include either a width or a height.\" width : source_preset [ 'width' ] , height : source_preset [ 'height' ] , pixel_ratio : pixel_ratio file_array = [ @instructions . source_dir , @instructions . source_images [ name ] ] filename = File . join ( * file_array ) return file_array if File . exist? ( filename ) set = files . collect do | f | url = Pathname . join ( @instructions . url_prefix , f . name ) \"#{url} #{f.pixel_ratio}x\"", "commit_type": "move"}
{"commit_tokens": ["Improve", "handling", "of", "composite", "keys", "in", "SequelCompat", "module", "."], "add_tokens": "v [ :primary_key ] = v . primary_key val = if key . kind_of? ( Array ) @values . values_at ( * key ) else @values [ key ] end", "del_tokens": "unrestrict_primary_key plugin :dirty val = @values [ key ]", "commit_type": "improve"}
{"commit_tokens": ["Make", "form", "helper", "method", "definitions", "a", "little", "bit", "more", "dynamic", "."], "add_tokens": "[ :form_for , :fields_for , :remote_form_for ] . each do | helper | class_eval <<-METHOD , __FILE__ , __LINE__ def simple_ #{helper}(*args, &block) options = args . extract_options! options [ :builder ] = SimpleForm :: FormBuilder #{helper}(*(args << options), &block) end METHOD", "del_tokens": "def simple_form_for ( * args , & block ) build_simple_form ( :form_for , * args , & block ) def simple_fields_for ( * args , & block ) build_simple_form ( :fields_for , * args , & block ) end def simple_remote_form_for ( * args , & block ) build_simple_form ( :remote_form_for , * args , & block ) end private def build_simple_form ( form_method , * args , & block ) options = args . extract_options! options [ :builder ] = SimpleForm :: FormBuilder send ( form_method , * ( args << options ) , & block ) end", "commit_type": "make"}
{"commit_tokens": ["use", "respond_to", "instead", "of", "relying", "on", "exceptions", "for", "Collection#method_missing"], "add_tokens": "if Array . new . respond_to? ( name ) to_a . send ( name , * args , & blk ) else opts = args . last . is_a? ( Hash ) ? args . last : { } opts . merge! ( :collection_path => @collection_path . dup . push ( name ) ) self . class . new ( @client , @resource_class , @options . merge ( opts ) ) end", "del_tokens": "to_a . send ( name , * args , & blk ) rescue NameError opts = args . last . is_a? ( Hash ) ? args . last : { } opts . merge! ( :collection_path => @collection_path . dup . push ( name ) ) self . class . new ( @client , @resource_class , @options . merge ( opts ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "global", "before", "/", "after", "that", "sets", "default", "settings", "for", "VCR", "and", "fakeweb", "so", "our", "specs", "don", "t", "have", "to", "keep", "setting", "things", "back", "to", "the", "defaults", "in", "their", "own", "before", "and", "after", "blocks", "."], "add_tokens": "VCR . stub! ( :current_cassette ) . and_return ( @current_cassette = mock )", "del_tokens": "before ( :all ) do @orig_allow_net_connect = FakeWeb . allow_net_connect? FakeWeb . allow_net_connect = true end after ( :all ) do FakeWeb . allow_net_connect = @orig_allow_net_connect end @current_cassette = mock VCR . stub! ( :current_cassette ) . and_return ( @current_cassette ) FakeWeb . clean_registry", "commit_type": "add"}
{"commit_tokens": ["adding", "some", "documentation", "to", "methods"], "add_tokens": "# Resets the configuration to the default (empty hash) # Loads the configuration from a given YAML file and environment (such as production) # Publish the given data to a specific channel. This ends up sending # a Net::HTTP POST request to the Faye server. # Sends the given message hash to the Faye server using Net::HTTP. def publish_message ( message ) Net :: HTTP . post_form ( URI . parse ( config [ :server ] ) , :message => message . to_json ) end # Returns a message hash for sending to Faye # Returns a subscription hash to pass to the PrivatePub.sign call in JavaScript. def subscription sub = { :server => config [ :server ] , :timestamp => ( Time . now . to_f * 1000 ) . round } . merge ( options ) sub [ :signature ] = Digest :: SHA1 . hexdigest ( [ config [ :secret_token ] , sub [ :channel ] , sub [ :timestamp ] ] . join ) sub # Determine if the signature has expired given a timestamp. # Returns the Faye Rack application. # Any options given are passed to the Faye::RackAdapter.", "del_tokens": "def subscription ( options = { } ) sub = { :server => config [ :server ] , :timestamp => ( Time . now . to_f * 1000 ) . round } . merge ( options ) sub [ :signature ] = Digest :: SHA1 . hexdigest ( [ config [ :secret_token ] , sub [ :channel ] , sub [ :timestamp ] ] . join ) sub end def publish_message ( message ) Net :: HTTP . post_form ( URI . parse ( config [ :server ] ) , :message => message . to_json )", "commit_type": "add"}
{"commit_tokens": ["Allows", "a", "base", "format", "to", "be", "used"], "add_tokens": "# @return [ String ] The underscored format to use as a base def base_format ; end # @return [ Array<String> ] def formats [ format , base_format ] . compact end formats . each do | format | potential_file = File . join ( dir , format , \"#{tpl}.erb\" ) return potential_file if File . exist? ( potential_file ) end", "del_tokens": "potential_file = File . join ( dir , format , \"#{tpl}.erb\" ) return potential_file if File . exist? ( potential_file )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "a", "typo", "in", "the", "documentation"], "add_tokens": "# <b>NOTE:</b> No attempt is made to prevent adding multiple entries with # <b>NOTE:</b> No attempt is made to prevent adding multiple entries with # <b>NOTE:</b> No attempt is made to prevent adding multiple entries with", "del_tokens": "# <b>NOTE:</b> No attempt it made to prevent adding multiple entries with # <b>NOTE:</b> No attempt it made to prevent adding multiple entries with # <b>NOTE:</b> No attempt it made to prevent adding multiple entries with", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "for", "another", "extends", "/", "additionalProperties", "scenario", "."], "add_tokens": "%w[ extends_nested - 1 - filename extends_nested - 1 - ref extends_nested - 2 - filename extends_nested - 2 - ref ] . each do | schema_name | test_prefix = 'test_' + schema_name . gsub ( '-' , '_' ) def #{test_prefix}_valid_outer def #{test_prefix}_valid_outer_extended def #{test_prefix}_valid_inner def #{test_prefix}_invalid_inner if schema_name [ 'extends_nested-1' ] class_eval <<-EOB def #{test_prefix}_invalid_outer refute_valid '#{schema_name}' , { \"whaaaaat\" => true } , \"Outer defn allowing anything when it shouldn't.\" end EOB end", "del_tokens": "%w[ extends_nested-filename extends_nested-ref ] . each do | schema_name | def test_ #{schema_name.sub /^.+-/,''}_valid_outer def test_ #{schema_name.sub /^.+-/,''}_valid_outer_extended def test_ #{schema_name.sub /^.+-/,''}_valid_inner def test_ #{schema_name.sub /^.+-/,''}_invalid_outer refute_valid '#{schema_name}' , { \"whaaaaat\" => true } , \"Outer defn allowing anything when it shouldn't.\" end def test_ #{schema_name.sub /^.+-/,''}_invalid_inner", "commit_type": "add"}
{"commit_tokens": ["add", "save", "and", "destroy", "wrappers", "error", "on", "#!", "fails"], "add_tokens": "def success? ! resource_exception end save method raise resource_exception unless success? destroy raise resource_exception unless success? end def save ( method = nil ) request_and_load do Typhoeus :: Request . send save_http_method ( method ) , save_request . request_uri , save_request . options end end def destroy request_and_load do Typhoeus :: Request . delete ( delete_request . request_uri , delete_request . options ) end def request_and_load ( & block ) self . resource_exception = nil response = yield self . class . load_values ( self , response ) success? end", "del_tokens": "response = Typhoeus :: Request . send save_http_method ( method ) , save_request . request_uri , save_request . options self . class . load_values ( self , response ) response = Typhoeus :: Request . delete ( delete_request . request_uri , delete_request . options ) self . class . load_values ( self , response )", "commit_type": "add"}
{"commit_tokens": ["add", "options", "to", "list", "fuction"], "add_tokens": "method_option :out , :aliases => '-o' , :type => :string , :default => ' ', :desc => ' to list from all remotes ' case options [ :out ] when 'custom' lxd . list_all_containers when 'all' config [ :lxd ] [ :nodes ] . each do | node | puts \"Listing LXD containers on #{node[:url]}..\" system ( \"lxc list #{node[:name]}:\" ) end when '' puts \"Listing LXD containers on #{config[:lxd][:nodes][0][:url]}..\" system ( \"lxc list #{config[:lxd][:nodes][0][:name]}:\" ) puts '' else puts \"Invalid option or command\" end", "del_tokens": "puts \"Listing LXD containers on #{config[:lxd][:nodes][0][:url]}..\" system ( \"lxc list #{config[:lxd][:nodes][0][:name]}:\" ) puts ''", "commit_type": "add"}
{"commit_tokens": ["Fix", "html4", "validation", "by", "falling", "back", "to", "dtd", "validation"], "add_tokens": "@errors = [ ] document = @page . body . sub ( @dtd_uri . to_s , @namespace + '.dtd' ) document = @page . body Nokogiri :: XML ( document ) { | cfg | if @xsd # have the xsd so use it @errors = @xsd . validate ( @doc ) else # dont have xsd fall back to dtd @doc = Dir . chdir ( XHTML_PATH ) do Nokogiri :: HTML . parse ( document ) end @errors = @doc . errors end @errors << 'Unknown Document' # http://nokogiri.org/tutorials/ensuring_well_formed_markup.html @errors << e", "del_tokens": "fixed_dtd = @page . body . sub ( @dtd_uri . to_s , @namespace + '.dtd' ) fixed_dtd = @page . body Nokogiri :: XML ( fixed_dtd ) { | cfg | @errors = @xsd ? @xsd . validate ( @doc ) : [ \"XSD unknown\" ] @errors = [ 'Unknown Document' ] @errors = [ e ]", "commit_type": "fix"}
{"commit_tokens": ["Use", "rbnacl", "for", "hash", "and", "hmac", "to", "allow", "for", "greater", "interoperability", ".", "Backwards", "incompatible", "change", "."], "add_tokens": "rand_hex = RbNaCl :: Util . bin2hex ( RbNaCl :: Random . random_bytes ( byte_length ) ) rand = OpenSSL :: BN . new ( rand_hex , 16 )", "del_tokens": "rand_hex = OpenSSL :: Random . random_bytes ( byte_length ) . each_byte . to_a . map { | a | sprintf ( '%02x' , a ) } . join ( '' ) rand = OpenSSL :: BN . new ( rand_hex , 16 )", "commit_type": "use"}
{"commit_tokens": ["add", "length", "rule", "with", "min", "max", "exact", "params"], "add_tokens": "string = string . sub ( / ^[a-z \\d ]* / ) { $& . capitalize }", "del_tokens": "string . sub! ( / ^[a-z \\d ]* / ) { $& . capitalize }", "commit_type": "add"}
{"commit_tokens": ["fixed", "debug", "bug", "and", "removed", "crawl_finished_job", ".", "rb"], "add_tokens": "puts \"Matched as #{link} as internal\" if content_request [ :debug ]", "del_tokens": "puts \"Matched as #{link} as internal\"", "commit_type": "fix"}
{"commit_tokens": ["added", "single", "explicit", "revision", "input", "option", "to", "status", "command"], "add_tokens": "opts . banner = \"Usage: rim status [<options>] [<to-rev>|<from-rev>..<to-rev>]\" opts . separator \"With a single <to-rev> checks that revision and all local ancestors.\" rev_arg = ARGV . shift if rev_arg if rev_arg =~ / \\. \\. / from_rev , to_rev = rev_arg . split ( \"..\" ) else from_rev , to_rev = nil , rev_arg end", "del_tokens": "opts . banner = \"Usage: rim status [<options>] [<from-rev>..<to-rev>]\" rev_range = ARGV . shift if rev_range from_rev , to_rev = rev_range . split ( \"..\" )", "commit_type": "add"}
{"commit_tokens": ["fixing", "the", "remove", "unused", "column", "feature"], "add_tokens": "erb = ERB . new ( template_file , 0 , '>' ) erb = ERB . new ( template_file , 0 , '>' ) erb = ERB . new ( template_file , 0 , '>' )", "del_tokens": "erb = ERB . new ( template_file ) erb = ERB . new ( template_file ) erb = ERB . new ( template_file )", "commit_type": "fix"}
{"commit_tokens": ["Removing", "simple", "counting", "methods", "."], "add_tokens": "scenarios . count + outlines . reduce ( 0 ) { | outline_sum , outline |", "del_tokens": "# Returns the number of scenarios contained in the feature. def scenario_count scenarios . count end # Returns the number of outlines contained in the feature. def outline_count outlines . count end # Returns the number of tests contained in the feature. def test_count @tests . count end scenario_count + outlines . reduce ( 0 ) { | outline_sum , outline |", "commit_type": "remove"}
{"commit_tokens": ["Use", "8", "characters", "for", "EsrRecord", ".", "client_id", "."], "add_tokens": "reference [ 0 .. 7 ] reference [ 8 .. 18 ] . to_i", "del_tokens": "reference [ 0 .. 5 ] reference [ 6 .. 18 ] . to_i", "commit_type": "use"}
{"commit_tokens": ["allow", "searchable", "to", "be", "an", "array"], "add_tokens": "searchable_fields . concat ( Array . wrap ( searchable_field ) ) if searchable_field", "del_tokens": "searchable_fields << searchable_field if searchable_field", "commit_type": "allow"}
{"commit_tokens": ["Adding", "an", "LEFT", "OUTER", "JOIN", "option", "to", "outermost", "self", "join"], "add_tokens": "# join using an outer join if specified if ( @join_options [ :outer_join ] ) relation = @relation . joins ( outer_join . to_sql ) else relation = @relation . joins ( inner_join . to_sql ) end def outer_join Arel :: Nodes :: OuterJoin . new ( aliased_subquery , constraint ) end", "del_tokens": "relation = @relation . joins ( inner_join . to_sql )", "commit_type": "add"}
{"commit_tokens": ["Change", "version", "quotes", "and", "parenthesis"], "add_tokens": "if self . class . instance_variable_get ( :@_verifiable_routes ) . include? ( current_action )", "del_tokens": "if self . class . instance_variable_get ( :@_verifiable_routes ) . include? current_action", "commit_type": "change"}
{"commit_tokens": ["Added", "new", "navbar", "and", "submenu", "for", "admin", "article", "listing"], "add_tokens": "#content_tag(:span, link_to('', admin_articles_path), class: 'backlink', title: 'Dashboard') + content_tag(:span, action_link, class: 'actionlink') + content_tag(:span, class: 'buttons', &block) + content_tag(:span, link_to('Logout', logout_path), class: 'logout') + content_tag(:span, \"Logged in as #{current_lines_user.email}\", class: 'logged-in-as') content_tag ( :span , class : 'buttons' , & block ) + \"<div class='btn-menu'><dic class='stripes'></div></div>\" . html_safe + \" < div class = 'submenu' > < div class = 'submenu-inner' > < ul > < li > #{link_to(\"All Articles\", admin_articles_path)}</li> < li > #{link_to(\"Authors\", admin_authors_path)}</li> < / ul > < ul > < li > Logged in as #{current_lines_user.email}</li> < li > #{link_to(\"Logout\", logout_path)}</li> < / ul > < ul > < li > #{link_to(\"Formatting Help\", \"#\")}</li> < li > #{link_to(\"About Lines\", \"#\")}</li> < / ul > < / div > < / div > \" . html_safe", "del_tokens": "content_tag ( :span , link_to ( '' , admin_articles_path ) , class : 'backlink' , title : 'Dashboard' ) + content_tag ( :span , action_link , class : 'actionlink' ) + content_tag ( :span , class : 'buttons' , & block ) + content_tag ( :span , link_to ( 'Logout' , logout_path ) , class : 'logout' ) + content_tag ( :span , \"Logged in as #{current_lines_user.email}\" , class : 'logged-in-as' )", "commit_type": "add"}
{"commit_tokens": ["Updated", "platform", "strings", "based", "on", "comments", "."], "add_tokens": "'platform' => 'cisco-5-x86_64' , 'platform' => 'cisco-7-x86_64' ,", "del_tokens": "'platform' => 'cisconxos-9-x86_64' , 'platform' => 'ciscoexr-9-x86_64' ,", "commit_type": "update"}
{"commit_tokens": ["adding", ":", "input", "option", "to", "exclude", "the", "input", "dir", "from", "the", "output"], "add_tokens": "@input_dir = options . delete ( :input ) @input_dir += '/' if @input_dir && @input_dir [ @input_dir . length - 1 ] != '/' file_dir = File . dirname ( file ) file_dir = file_dir . sub! ( @input_dir , '' ) if @input_dir output_folder = File . join ( @options [ :output ] , file_dir )", "del_tokens": "output_folder = File . join ( @options [ :output ] , '..' , File . dirname ( file ) )", "commit_type": "add"}
{"commit_tokens": ["added", "withdraw_bitcoins", "functionality", "and", "fixed", "the", "spec", "so", "everything", "passes"], "add_tokens": "def self . withdraw_bitcoins ( options = { } ) self . sanity_check! if options [ :amount ] . nil? || options [ :address ] . nil? raise MissingConfigExeception . new ( \"Required parameters not supplied, :amount, :address\" ) end if Bitstamp :: Net . post ( '/bitcoin_withdrawal' , options ) . body_str != 'true' return JSON . parse Bitstamp :: Net . post ( '/bitcoin_withdrawal' , options ) . body_str else return Bitstamp :: Net . post ( '/bitcoin_withdrawal' , options ) . body_str end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "url", "generation", "for", "v2m", "requests"], "add_tokens": "client . make_request ( :post , client . concat_user_path ( MESSAGE_PATH ) , data , 'api/v2' , 'https://messaging.bandwidth.com' ) [ 0 ]", "del_tokens": "client . make_request ( :post , client . concat_user_path ( MESSAGE_PATH ) , data , 'v2' , 'https://messaging.bandwidth.com/api' ) [ 0 ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "passing", ":", "mono", "and", ":", "stereo", "into", "the", "num_channels", "argument", "of", "the", "constructor", "to", "allow", "for", "more", "readable", "code"], "add_tokens": "if num_channels == :mono @num_channels = 1 elsif num_channels == :stereo @num_channels = 2 else @num_channels = num_channels end @byte_rate = sample_rate * @num_channels * ( bits_per_sample / 8 ) @block_align = @num_channels * ( bits_per_sample / 8 )", "del_tokens": "@num_channels = num_channels @byte_rate = sample_rate * num_channels * ( bits_per_sample / 8 ) @block_align = num_channels * ( bits_per_sample / 8 )", "commit_type": "add"}
{"commit_tokens": ["Using", "ENV", "instead", "of", "hard", "-", "coded", "values", "in", "tests", "."], "add_tokens": "config . log = false require 'vcr_setup'", "del_tokens": "# config.log = false end require 'vcr' VCR . config do | c | c . cassette_library_dir = 'test/cassettes' c . stub_with :webmock c . filter_sensitive_data ( 'api-login-id' ) { TaxCloud . configuration . api_login_id } c . filter_sensitive_data ( 'api-key' ) { TaxCloud . configuration . api_key } c . filter_sensitive_data ( 'usps-username' ) { TaxCloud . configuration . usps_username }", "commit_type": "use"}
{"commit_tokens": ["Added", "--", "consumer", "and", "--", "provider", "options", "to", "CLI", ".", "Automatically", "write", "pact", "if", "both", "options", "are", "given", "at", "startup", "."], "add_tokens": "require 'support/integration_spec_support' include Pact :: IntegrationTestSupport @pid = nil @pid = fork do if @pid Process . kill \"INT\" , @pid", "del_tokens": "let ( :expected_interaction ) do { description : \"a request for a greeting\" , request : { method : :get , path : '/greeting' } , response : { status : 200 , headers : { 'Content-Type' => 'text/plain' } , body : \"Hello world\" } } . to_json end let ( :mock_service_headers ) do { 'Content-Type' => 'application/json' , 'X-Pact-Mock-Service' => 'true' } end let ( :pact_details ) do { consumer : { name : 'Consumer' } , provider : { name : 'Provider' } } . to_json end FileUtils . rm_rf 'tmp/integration.log' FileUtils . rm_rf 'tmp/pacts' @@ssl_pid = nil @@ssl_pid = fork do if @@ssl_pid Process . kill \"INT\" , @@ssl_pid", "commit_type": "add"}
{"commit_tokens": ["Added", "extra", "tests", "for", "all", "inline", "and", "block", "elements", ":", "inner_markdown", "=", "inner_markdown", "should", "work", "for", "all", "of", "them"], "add_tokens": "def reformat ( input ) def assert_filtered_input_equals_input ( dir ) def test_inline_elements ( ) Paru :: PANDOC_INLINE . each do | node_name | filter_file_and_equal_file ( \"test/pandoc_input/all_node_types_in_pandoc.md\" , \"test/pandoc_output/all_node_types_in_pandoc.md\" ) do with \"#{node_name}\" do | node | #node.inner_markdown = node.inner_markdown end end end def test_block_elements ( ) Paru :: PANDOC_BLOCK . select { | n | n != \"Plain\" and n != \"LineBlock\" and n != \"CodeBlock\" and n != \"RawBlock\" and n != \"OrderedList\" and n != \"BulletList\" and n != \"DefinitionList\" and n != \"Table\" } . each do | node_name | filter_file_and_equal_file ( \"test/pandoc_input/all_node_types_in_pandoc.md\" , \"test/pandoc_output/all_node_types_in_pandoc.md\" ) do with \"#{node_name}\" do | node | node . inner_markdown = node . inner_markdown end end end def test_metadata_elements ( ) def test_capitalize_first_sentence ( ) def test_number_figures ( ) def test_number_figures_per_chapter ( ) def test_example_blocks ( ) def test_insert_code_block ( ) def test_insert_document ( ) def test_delete_horizontal_rules ( )", "del_tokens": "def reformat input def assert_filtered_input_equals_input dir def test_inline_elements def test_block_elements def test_metadata_elements def test_capitalize_first_sentence def test_number_figures def test_number_figures_per_chapter def test_example_blocks def test_insert_code_block def test_insert_document def test_delete_horizontal_rules", "commit_type": "add"}
{"commit_tokens": ["use", "a", "safer", "PRNG", "for", "RandomGenerator", "model"], "add_tokens": "require 'securerandom' messages_count = ( 1 + SecureRandom . random_number * output_ports . count ) . round selected_ports . each { | port | post ( ( @min + SecureRandom . random_number * @max ) . round , port ) }", "del_tokens": "messages_count = ( 1 + rand * output_ports . count ) . round selected_ports . each { | port | post ( ( @min + rand * @max ) . round , port ) }", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "Fog", "::", "<provider", ">", "::", "Storage", "as", "well", "as", "Fog", "::", "Storage", "::", "<provider", ">", "."], "add_tokens": "begin Fog :: Storage . const_get ( Fog . providers [ provider ] ) rescue Fog :: const_get ( Fog . providers [ provider ] ) :: Storage end . new ( attributes ) else raise ArgumentError . new ( \"#{provider} is not a recognized storage provider\" )", "del_tokens": "return Fog :: Storage . const_get ( Fog . providers [ provider ] ) . new ( attributes ) raise ArgumentError . new ( \"#{provider} is not a recognized storage provider\" )", "commit_type": "allow"}
{"commit_tokens": ["fixed", "specs", "updated", "to", "new", "sample", "pages", "etc"], "add_tokens": "v = @page . search ( \".//div[@id='ila-page-next']\" ) v . first && v . first . attributes [ \"class\" ] . value !~ / ila-page-nextDisabled /", "del_tokens": "v = ( @page . search ( \".//div[@id='ila-page-next']\" ) v . first && v . attributes [ \"class\" ] . value !~ / ila-page-nextDisabled /", "commit_type": "fix"}
{"commit_tokens": ["Allow", "rending", "a", "static", "error", "page"], "add_tokens": "VERSION = '1.1.12'", "del_tokens": "VERSION = '1.1.11'", "commit_type": "allow"}
{"commit_tokens": ["added", "an", "rspec", "spec", "to", "test", "the", "rspec", "spec", "matchers", ".", "spec", "."], "add_tokens": "next true if actual_default_value == @expected_default_value error_lines \"Expected the chain option `:#{option_name}`\" , \"of the class `#{instance.class}`\" , \"to have the default value `#{@expected_default_value.inspect}`\" , \"but the actual default value is `#{actual_default_value.inspect}`\" @error . to_s", "del_tokens": "if actual_default_value != @expected_default_value error_lines \"Expected the chain option `:#{option_name}`\" , \"of the class `#{instance.class}`\" , \"to have the default value `#{@expected_default_value.inspect}`\" , \"but the actual default value is `#{actual_default_value.inspect}`\" end @error", "commit_type": "add"}
{"commit_tokens": ["update", "tests", "to", "minitest", "."], "add_tokens": "require 'minitest/autorun'", "del_tokens": "require 'rubygems' # wycats says... require 'bundler' Bundler . setup require 'test/unit' require 'shoulda' $: . unshift File . dirname ( __FILE__ ) # add current dir to LOAD_PATHS", "commit_type": "update"}
{"commit_tokens": ["using", "requeststore", "and", "added", "set_redirect_params", "method", "in", "the", "require_no_authentication", "also", "added", "provider_id", "provider_secret", "and", "redirect_url", "to", "the", "permitted", "params", "in", "all", "devise", "actions", "added", "json", "to", "devise", "config", "in", "the", "engine", "added", "the", "return", "if", "no", "provider", "in", "the", "require", "no", "auth", "where", "request", "type", "is", "json", "need", "to", "sort", "out", "json", "responses", "in", "the", "after_sign_in_path_for"], "add_tokens": "##oauth identities. ##redirect_urls field :redirect_urls , type : Array , default : [ ] ##provider_id field :provider_id , type : String field :provider_secret , type : String ##fields for remote provider. field :provider_id , type : String field :provider_secret , type : String before_save do | document | if document . provider_id . blank? document . provider_id = SecureRandom . hex ( 32 ) document . provider_secret = SecureRandom . hex ( 32 ) end end", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["Add", "prefix", "to", "FilesystemProvider", "as", "well"], "add_tokens": "# config.roadie.provider = AssetPipelineProvider.new('prefix')", "del_tokens": "# config.roadie.provider = AssetPipelineProvider.new # The prefix is whatever is prepended to your stylesheets when referenced inside markup. # # The prefix is stripped away from any URLs before they are looked up in the Asset Pipeline: # find(\"/assets/posts/comment.css\") # # Same as: (if prefix == \"/assets\" # find(\"posts/comment.css\") attr_reader :prefix # @param [String] prefix Prefix of assets as seen from the browser # @see #prefix def initialize ( prefix = \"/assets\" ) super ( ) @prefix = prefix @quoted_prefix = Regexp . quote ( prefix ) end def remove_prefix ( name ) name . sub ( / ^ #{ @quoted_prefix } \\/ ? / , '' ) . sub ( %r{ ^/ } , '' ) . gsub ( %r{ //+ } , '/' ) end", "commit_type": "add"}
{"commit_tokens": ["Fix", "dm", "-", "migration", "quoting", "tests", "these", "shouldn", "t", "break", "when", "the", "adapter", "changes"], "add_tokens": "@migration_info_table ||= quote_table_name ( 'migration_info' ) @migration_name_column ||= quote_column_name ( 'migration_name' ) # TODO: Fix this for 1.9 - can't use this hack to access a private method # TODO: Fix this for 1.9 - can't use this hack to access a private method", "del_tokens": "@migration_info_table ||= @adapter . send ( :quote_table_name , 'migration_info' ) @migration_name_column ||= @adapter . send ( :quote_column_name , 'migration_name' )", "commit_type": "fix"}
{"commit_tokens": ["make", "click", "only", "accept", "CSS", "locator"], "add_tokens": "browser . click ( \"css=#{locator}\" )", "del_tokens": "browser . click ( locator )", "commit_type": "make"}
{"commit_tokens": ["Make", "belongs_to", "dependencies", "on", "OperationTemplate", "optional"], "add_tokens": "belongs_to :assignment , polymorphic : true , required : false", "del_tokens": "belongs_to :assignment , polymorphic : true", "commit_type": "make"}
{"commit_tokens": ["Remove", "configurable", "options", "for", "OAuth", "consumer", "."], "add_tokens": "options . each do | key , value |", "del_tokens": "@options ||= DEFAULT_OPTIONS . dup @options . merge! ( options ) @options . each do | key , value |", "commit_type": "remove"}
{"commit_tokens": ["Fix", "parent_network", "retrieval", "in", "vapp", "show"], "add_tokens": "parent_network = parent_network . attribute ( 'name' ) . text unless parent_network . empty? parent_network = nil if parent_network . empty?", "del_tokens": "if parent_network parent_network = parent_network . attribute ( 'name' ) . text end", "commit_type": "fix"}
{"commit_tokens": ["Add", "enough", "extra", "file", "system", "functions", "to", "pass", "about", "half", "of", "the", "zip", "tests", "."], "add_tokens": "# what am i supposed to do about pos < 0, or > size? case whence when IO :: SEEK_SET @pos = pos when IO :: SEEK_CUR @pos += pos when IO :: SEEN_END @pos = @size - pos else raise NotImplementedError , \"#{whence.inspect} not supported\" unless whence == IO :: SEEK_SET end # using explicit forward instead of an alias now for overriding. # should override truncate. def size = size truncate size end # i can wrap it in a buffered io stream that # provides gets, and appropriately handle pos, # truncate. def gets s = read 1024 i = s . index \"\\n\" @pos -= s . length - ( i + 1 ) s [ 0 .. i ] end alias readline :gets", "del_tokens": "# FIXME support other whence values raise NotImplementedError , \"#{whence.inspect} not supported\" unless whence == IO :: SEEK_SET # why not? :) alias size = :truncate", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "includes", "/", "preload", "for", "each_instance"], "add_tokens": "require 'active_record/associations/preloader' block_size ||= @block_size ||= @options . fetch ( :block_size ) { 1000 } preloads = klass . preload_values | klass . includes_values preloader = :: ActiveRecord :: Associations :: Preloader . new self . to_enum ( :each_tuple ) . each_slice ( block_size ) do | slice | records = slice . map do | row | if :: ActiveRecord :: VERSION :: MAJOR < 4 klass . send ( :instantiate , row ) else @column_types ||= column_types klass . send ( :instantiate , row , @column_types ) end end preloads . each do | associations | preloader . preload ( records , associations ) end records . each do | record | block . call ( record )", "del_tokens": "self . each_tuple do | row | if :: ActiveRecord :: VERSION :: MAJOR < 4 model = klass . send ( :instantiate , row ) else @column_types ||= column_types model = klass . send ( :instantiate , row , @column_types ) block . call ( model )", "commit_type": "add"}
{"commit_tokens": ["fixed", "can?", "to", "use", "authorized?"], "add_tokens": "Trust :: Authorization . authorized? ( action_name , subject , parent )", "del_tokens": "Trust :: Authorization . authorize! ( action_name , subject , parent )", "commit_type": "fix"}
{"commit_tokens": ["Use", "String#bytesize", "for", "Content", "-", "Length"], "add_tokens": "@headers [ 'Content-Length' ] ||= @body . bytesize", "del_tokens": "@headers [ 'Content-Length' ] ||= @body . length", "commit_type": "use"}
{"commit_tokens": ["Made", "sure", "#login", "always", "calls", "#logout", "if", "called", "with", "a", "block", ".", "#login", "returns", "the", "block", "s", "value", "instead", "of", "results", "."], "add_tokens": "# # If called with a block, the results of the login action are yielded, # and logout is called when the block returns. In that case, #login # returns the block's value. If called without a block, returns the # result. # # As specified in the RETS specification, the Action URL is called and # the results made available in the #secondary_results accessor of the # results object. # We only yield begin yield results ensure self . logout end else results", "del_tokens": "# We only yield if yield results self . logout return results", "commit_type": "make"}
{"commit_tokens": ["Updated", "reporters", "lookup", "key", "for", "application", "name"], "add_tokens": "JSON . load ( response . body ) . symbolize_keys . fetch ( :application_name , 'Default' )", "del_tokens": "JSON . load ( response . body ) . symbolize_keys . fetch ( :application , 'Default' )", "commit_type": "update"}
{"commit_tokens": ["Remove", "note", "about", "using", "+", "init", "for", "creating", "CRS", "s", "because", "its", "incorrect", "."], "add_tokens": "# Notice when using the old-style Proj4 string, the addition of the \"+type=crs\" value. pointer = Api . proj_create ( context || Context . current , value )", "del_tokens": "# Notice when using the old-style Proj4 string, the addition of the \"+type=crs\" value. If you'd like to use old-style # init parameters, then do this: # # @example # crs = Proj::Crs.new('+init=epsg:4326') # Check for old style init strings if ! context if value . match ( / \\W init \\W / ) && Api . method_defined? ( :use_proj4_init_rules ) context = Context . new context . use_proj4_init_rules = true else context = Context . current end end pointer = Api . proj_create ( context , value )", "commit_type": "remove"}
{"commit_tokens": ["Uses", "new", "dependencies", "with", "Beardley", "::", "XML"], "add_tokens": "require \"beardley/xml\" Rjb :: load ( ( [ \".\" ] + Beardley :: Core . classpath + Beardley :: Groovy . classpath + Beardley :: Barcode . classpath + Beardley :: XML . classpath + Beardley :: Batik . classpath ) . join ( File :: PATH_SEPARATOR ) , [ '-Djava.awt.headless=true' , '-Xms128M' , '-Xmx256M' ] )", "del_tokens": "Rjb :: load ( ( [ \".\" ] + Beardley :: Core . classpath + Beardley :: Groovy . classpath + Beardley :: Barcode . classpath + Beardley :: Batik . classpath ) . join ( File :: PATH_SEPARATOR ) , [ '-Djava.awt.headless=true' , '-Xms128M' , '-Xmx256M' ] )", "commit_type": "use"}
{"commit_tokens": ["Added", "some", "notes", "regardin", "wordpress", "oembed", "endpoint", "and", "removed", "nowrap", "from"], "add_tokens": "# NOTE: # When calling Oembedr#fetch set the `for` parameter with your ID # Example: { :params => {:for => 'oembedr.com'} } # NOTE: # When calling Oembedr#fetch set the `nowrap` parameter to avoid # noembed.com wrapper # Example: { :params => {:nowrap => 'on'} } / (thedailyshow \\. com|funnyordie \\. com|ted \\. com|livejournal \\. com|github \\. com|metacafe \\. com|wikipedia \\. org|xkcd \\. com|imdb \\. com) / => 'http://noembed.com/embed'", "del_tokens": "/ (thedailyshow \\. com|funnyordie \\. com|ted \\. com|livejournal \\. com|github \\. com|metacafe \\. com|wikipedia \\. org|xkcd \\. com|imdb \\. com) / => 'http://noembed.com/embed?nowrap=on'", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "singleton", "class", "to", "hold", "and", "cache", "the", "liner_keys", "."], "add_tokens": "Beer . liner_keys . must_equal [ :hops , :yeast ] Pizza . liner_keys . must_equal [ :crust , :sauce ] Cheeseburger . liner_keys . must_equal [ :bun , :meat , :cheese ]", "del_tokens": "beer . liner_keys . must_equal [ :hops , :yeast ] pizza . liner_keys . must_equal [ :crust , :sauce ] cheeseburger . liner_keys . must_equal [ :bun , :meat , :cheese ]", "commit_type": "use"}
{"commit_tokens": ["added", "ControllerStub", "as", "an", "external", "test", "object"], "add_tokens": "require File . expand_path ( '../../test_helper' , __FILE__ )", "del_tokens": "require File . expand_path ( '../../../test_helper' , __FILE__ )", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "pretty", "print", "json"], "add_tokens": "@pretty = options [ :pretty ] . nil? ? false : options [ :pretty ] @pretty ? JSON . pretty_generate ( JSON . parse ( result ) ) : result", "del_tokens": "result", "commit_type": "add"}
{"commit_tokens": ["Implement", "Hexp", "::", "Node#rewrite", "(", "css", "selector", ")", "{", "...", "}"], "add_tokens": "def rewrite ( css_selector = nil , & block ) if css_selector CssSelection . new ( self , css_selector ) . rewrite ( & block ) else Rewriter . new ( self , block ) end", "del_tokens": "def rewrite ( & block ) Rewriter . new ( self , block )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "regression", "introduced", "by", "de6b338", "."], "add_tokens": "VERSION = \"1.0.11\"", "del_tokens": "VERSION = \"1.0.10\"", "commit_type": "fix"}
{"commit_tokens": ["allow", "user", "to", "set", "optional", "parameters", "as", "well"], "add_tokens": "upload_params = { :format => outputformat }", "del_tokens": "upload_params = { :format => outputformat , :options => options }", "commit_type": "allow"}
{"commit_tokens": ["Add", "string", "to", "array", "of", "numerics", "conversion"], "add_tokens": "ARRAY_MATCHER = / ^(.+?( \\s *(?<sep>(,|-)) \\s *))+ /x . freeze if match = value . to_s . match ( ARRAY_MATCHER ) class StringToNumericArrayConverter < Converter # Convert string value to array with numeric values # # @example # converter.call(\"1,2.0,3\") # => [1, 2.0, 3] # # @api public def call ( string , strict : config . strict ) array_converter = StringToArrayConverter . new ( :string , :array ) array = array_converter . ( string , strict : strict ) num_converter = ArrayToNumericArrayConverter . new ( :array , :numeric ) num_converter . ( array , strict : strict ) end end StringToNumericArrayConverter . new ( :string , :numerics ) , StringToNumericArrayConverter . new ( :string , :nums ) ,", "del_tokens": "if match = value . to_s . match ( / ^(.+?( \\s *(?<sep>(,|-)) \\s *))+ / )", "commit_type": "add"}
{"commit_tokens": ["Fix", "getting", "colors", "and", "modes", "."], "add_tokens": "MODES . keys COLORS . keys", "del_tokens": "keys = [ ] MODES . each_key do | key | keys << key end keys keys = [ ] COLORS . each_key do | key | keys << key end keys", "commit_type": "fix"}
{"commit_tokens": ["remove", "version", "lock", "for", "json", "dependency"], "add_tokens": "VERSION = \"0.2.1\"", "del_tokens": "VERSION = \"0.2.0\"", "commit_type": "remove"}
{"commit_tokens": ["Remove", "restrictions", "on", "special", "keys", "update", "our", "to_s", "and", "inspect", "formats", "."], "add_tokens": "VERSION = '1.6.0'", "del_tokens": "VERSION = '1.5.26'", "commit_type": "remove"}
{"commit_tokens": ["Add", "specs", "for", "weight", "conversion"], "add_tokens": "def in_lb ( @value * 2.20462 ) . round ( 3 )", "del_tokens": "def in_lbs @value * 2.20462", "commit_type": "add"}
{"commit_tokens": ["use", "application", "name", "instead", "of", "hard", "-", "coded", "Marty", "in", "main", "template", ";"], "add_tokens": "VERSION = \"0.0.12\"", "del_tokens": "VERSION = \"0.0.11\"", "commit_type": "use"}
{"commit_tokens": ["add", "new", "way", "of", "using", "TIMES", "and", "SPEND"], "add_tokens": "def SPEND ( bit_length , name , klass = nil , & block ) klass ||= NamelessTemplateMaker . new ( self , block ) def TIMES ( times , name , klass = nil , & block ) klass ||= NamelessTemplateMaker . new ( self , block )", "del_tokens": "def SPEND ( bit_length , name , & block ) klass = NamelessTemplateMaker . new ( self , block ) def TIMES ( times , name , & block ) klass = NamelessTemplateMaker . new ( self , block )", "commit_type": "add"}
{"commit_tokens": ["Allow", "be_valid_css", "to", "accept", "a", "response", "object", "as", "well", "as", "a", "string", "."], "add_tokens": "it \"should validate a valid response\" do response = MockResponse . new ( get_file ( 'valid.css' ) ) response . should be_valid_css end it \"should validate if body is not a string but can be converted to valid string\" do response = MockResponse . new ( stub ( \"CSS\" , :to_s => get_file ( 'valid.css' ) ) ) response . should be_valid_css end it \"should not validate an invalid response\" do response = MockResponse . new ( get_file ( 'invalid.css' ) ) lambda { response . should be_valid_css } . should raise_error ( SpecFailed ) { | e | e . message . should match ( / expected css to be valid, but validation produced these errors / ) e . message . should match ( / Invalid css: line 8: Property wibble doesn't exist / ) } end", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Fix", "tests", ":", "items", "in", "test", "playlist", "have", "changed"], "add_tokens": "expect ( playlist . item_count ) . to be 52", "del_tokens": "expect ( playlist . item_count ) . to be 3", "commit_type": "fix"}
{"commit_tokens": ["Adding", "discount", "line", "detail", "option", "to", "Line"], "add_tokens": "end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["removed", "an", "erronius", "\\", "character"], "add_tokens": "markdown message", "del_tokens": "m arkdown message", "commit_type": "remove"}
{"commit_tokens": ["updated", "jquery", "-", "rails", "and", "phchelpers", "."], "add_tokens": "VERSION = \"2.1.2\"", "del_tokens": "VERSION = \"2.1.1\"", "commit_type": "update"}
{"commit_tokens": ["make", "valid", "a", "private", "method"], "add_tokens": "private", "del_tokens": "private", "commit_type": "make"}
{"commit_tokens": ["Use", "name", "tag", "for", "create", "temporary", "file"], "add_tokens": "File . join ( SwaggerDocsGenerator . temporary_folder , tmp_json ) def tmp_json \"#{@tag_name}.json\"", "del_tokens": "File . join ( SwaggerDocsGenerator . temporary_folder , controller_json ) def controller_json \"#{controller_name}.json\"", "commit_type": "use"}
{"commit_tokens": ["Removing", "memoization", "of", "the", "element", "class", "name"], "add_tokens": "hash [ :type ] = self . class . name . demodulize", "del_tokens": "def name @name ||= self . class . name . demodulize end hash [ :type ] = name", "commit_type": "remove"}
{"commit_tokens": ["fixed", "issue", "23", "bug", "added", "test", "for", "commit", "added", "mocha", "to", "mock", "api", "requests"], "add_tokens": "if id [ 'status' ] raise TimeZone :: Error :: GeoNames , \"api limit reached\" if id [ 'status' ] [ 'value' ] == 18 end return id", "del_tokens": "raise TimeZone :: Error :: GeoNames , \"api limit reached\" if id [ 'status' ] [ 'value' ] == 18", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "fix", "alias", "."], "add_tokens": "alias add_file create_file module_function :add_file module_function :diff_files content = ( block . arity . nonzero? ? block [ content ] : block [ ] )", "del_tokens": "content = ( block . arity == 1 ? block [ content ] : block [ ] )", "commit_type": "change"}
{"commit_tokens": ["removed", "test", "functions", "as", "it", "is", "going", "to", "be", "merged", "to", "master", "now"], "add_tokens": "puts @client . node . list", "del_tokens": "puts @client . node . list_all #====== test desc \"is_offline\" , \"is_offline\" def is_offline ( node ) @client = Helper . setup ( parent_options ) puts @client . node . is_offline? ( node ) end", "commit_type": "remove"}
{"commit_tokens": ["Use", "specific", "name", "translation", "rather", "than", "generaic", "many_of_instance"], "add_tokens": "adder : proc { | translation | translation . update ( translatable_id : pk , translatable_type : self . class . to_s ) } , remover : proc { | translation | translation . update ( translatable_id : nil , translatable_type : nil ) } ,", "del_tokens": "adder : proc { | many_of_instance | many_of_instance . update ( translatable_id : pk , translatable_type : self . class . to_s ) } , remover : proc { | many_of_instance | many_of_instance . update ( translatable_id : nil , translatable_type : nil ) } ,", "commit_type": "use"}
{"commit_tokens": ["changed", "some", "defaults", "for", "html", "generator", ".", "added", "test", "for", "desired", "result", "."], "add_tokens": ":outer_links => 2 , :step => 3 , :separator => ' ' }", "del_tokens": ":outer_links => 1 , :separator => ' ' , :param_name => 'page' }", "commit_type": "change"}
{"commit_tokens": ["Add", "withdraw", "and", "deposit", "wallet", "operations", "(", "not", "ready", "yet", ")"], "add_tokens": "let ( :user ) { PromisepayFactory . create_user } let ( :wallet_account ) { user . wallet_account } # describe 'operations' do # let(:bank_account) { PromisepayFactory.create_bank_account({}, user) } # before { user.disbursement_account(bank_account.id) } # describe 'withdraw', vcr: { cassette_name: 'wallet_accounts_withdraw' } do # it 'returns a disbursement' do # disbursement = wallet_account.withdraw(account_id: bank_account.id, amount: 500) # expect(disbursement).to be_a(Hash) # expect(disbursement).to have_key('id') # expect(disbursement).to have_key('amount') # expect(disbursement).to have_key('currency') # expect(disbursement['state']).to eq('pending') # expect(disbursement['to']).to eq('Bank Account') # end # end # describe 'deposit', vcr: { cassette_name: 'wallet_accounts_deposit' } do # it 'returns a disbursement' do # disbursement = wallet_account.deposit(account_id: bank_account.id, amount: 500) # expect(disbursement).to be_a(Hash) # expect(disbursement).to have_key('id') # expect(disbursement).to have_key('amount') # expect(disbursement).to have_key('currency') # expect(disbursement['state']).to eq('pending') # end # end # end", "del_tokens": "let ( :wallet_account ) { PromisepayFactory . create_user . wallet_account }", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "way", "to", "set", "the", "sleep", "timer", "."], "add_tokens": "# Set a sleep timer up to 23:59:59 # E.g. '00:11:00' for 11 minutes. # @param duration [String] Duration of timer or nil to clear. def set_sleep_timer ( duration ) if duration . nil? duration = '' elsif duration . gsub ( ':' , '' ) . to_i > 235959 duration = '23:59:59' end parse_response send_transport_message ( 'ConfigureSleepTimer' , \"<NewSleepTimerDuration>#{duration}</NewSleepTimerDuration>\" ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "timeout", "on", "dhcp", "client", "call", "."], "add_tokens": "if ( ret == 0 ) ret = 1 while ( ret == 1 ) # 1 - In process to attach ret = adapter . dhcp_client_check break ret = TIMEOUT unless ( time >= Time . now ) end", "del_tokens": "while ( ret == 1 ) # 1 - In process to attach ret = self . dhcp_client_check return TIMEOUT if ( time >= Time . now )", "commit_type": "fix"}
{"commit_tokens": ["remove", "query", "file", "and", "use", "CGI", "::", "Parse"], "add_tokens": "require 'cgi' index_response factory_name , options . fetch ( 'count' , [ 5 ] ) . first . to_i def parse_query ( query ) if query . nil? { } else CGI :: parse query end end", "del_tokens": "require File . expand_path ( File . join ( File . dirname ( __FILE__ ) , '../support/query' ) ) index_response factory_name , options . fetch ( :count , 5 ) . to_i", "commit_type": "remove"}
{"commit_tokens": ["Changed", "the", "param", "for", "sorting", "from", "sort", "to", "order"], "add_tokens": "if params [ :order ] && params [ :order ] =~ / ^([ \\w \\_ ]+)_(desc|asc)$ /", "del_tokens": "if params [ :sort ] && params [ :sort ] =~ / ^([ \\w \\_ ]+)_(desc|asc)$ /", "commit_type": "change"}
{"commit_tokens": ["Added", "exceptions", "for", "transliteration", "/", "detection", "methods", ".", "Also", "allow", "3", "-", "arity", "Sanscript", ".", "transliterate", "method", "to", "provide", "detection", "."], "add_tokens": "require \"sanscript/exceptions\" # @param from [Symbol, nil] the name of the scheme to transliterate from, or Nil to detect # @option opts [Symbol] :default_scheme a default scheme to fall-back to if detection fails # @raise [DetectionError] if scheme detection and fallback fail # @raise [SchemeNotSupportedError] if a provided transliteration scheme is not supported # # @return [String] the transliterated String # # @raise [DetectionError] if scheme detection and fallback fail # @raise [SchemeNotSupportedError] if a provided transliteration scheme is not supported # from = nil end if from . nil? from = Detect . detect_scheme ( text ) || opts [ :default_scheme ] || raise ( DetectionError , \"String detection and fallback failed.\" )", "del_tokens": "# @param from [Symbol] the name of the scheme to transliterate from # @return [String, nil] the transliterated String, or nil if detection and fallback fail from = Detect . detect_scheme ( text ) || opts [ :default_scheme ] || return", "commit_type": "add"}
{"commit_tokens": ["Added", "select_spouse_summary", "method", "to", "Person", ".", "Also", "finished", "testing", "that", "person", ".", "birth", "and", "perosn", ".", "death", "will", "return", "the", "summary", "if", "selected", "."], "add_tokens": "@person . births [ 1 ] . selected = Org :: Familysearch :: Ws :: Familytree :: V2 :: Schema :: ValueSelection . new @person . deaths [ 1 ] . selected = Org :: Familysearch :: Ws :: Familytree :: V2 :: Schema :: ValueSelection . new describe \"select_spouse_summary\" do it \"should accept a spouse's ID\" do @person . select_spouse_summary ( 'KWQS-BBB' ) end it \"should set the families with given spouse as a selected parent\" do @person . select_spouse_summary ( 'KWQS-BBB' ) @person . families [ 0 ] . parents [ 0 ] . id . should == 'KWQS-BBB' @person . families [ 0 ] . action . should == 'Select' end end", "del_tokens": "pending @person . births [ 1 ] . selected = true pending @person . deaths [ 1 ] . selected = true", "commit_type": "add"}
{"commit_tokens": ["Fixed", "form_builder", "tests", "for", "regExp"], "add_tokens": "it_should_have_dojo_props ( :regExp => '\\\\d{5}' ) @emailRe = '^[\\\\w!#%$*+=?`{|}~^-]+(?:[\\\\w!#%$*+=?`{|}~^.-])*@(?:[a-zA-Z0-9-]+\\\\.)+[a-zA-Z]{2,6}$' @phoneRe = '^[\\\\d(.)+\\\\s-]+$'", "del_tokens": "it_should_have_dojo_props ( :regExp => '\\\\\\d{5}' ) @emailRe = '^[\\\\\\w!#%$*+=?`{|}~^-]+(?:[\\\\\\w!#%$*+=?`{|}~^.-])*@(?:[a-zA-Z0-9-]+\\\\\\.)+[a-zA-Z]{2,6}$' @phoneRe = '^[\\\\\\d(.)+\\\\\\s-]+$'", "commit_type": "fix"}
{"commit_tokens": ["Removed", "unused", "part", "of", "conditional", "statement", "from", "URI"], "add_tokens": "normalized_uri . port = normalized_uri . inferred_port unless normalized_uri . port", "del_tokens": "normalized_uri . port = normalized_uri . inferred_port unless normalized_uri . port && normalized_uri . inferred_port", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "add_file", "to", "use", "absolute", "pathnames"], "add_tokens": "@file = ErnieBrodeur :: DM :: Models :: Image . first_or_new ( :filename => :: File . absolute_path ( filename ) )", "del_tokens": "@file = ErnieBrodeur :: DM :: Models :: Image . first_or_new ( :filename => filename )", "commit_type": "fix"}
{"commit_tokens": ["move", "APP_PATH", "and", "altered", "application", "classes", "into", "helper", "to", "be", "used", "by", "other", "tests"], "add_tokens": "context \"New Application\" do setup do em_setup { @application = NueteredBootingApplication . new ( \"/some/path\" ) } end should \"store startup path\" do assert_equal \"/some/path\" , @application . app_path should \"boot application\" do assert @application . booted end end", "del_tokens": "APP_PATH = \"#{File.expand_path(File.dirname(__FILE__))}/fastr_app\" context \"New Application\" do setup do em_setup { @application = NueteredBootingApplication . new ( \"/some/path\" ) } end should \"store startup path\" do assert_equal \"/some/path\" , @application . app_path end should \"boot application\" do assert @application . booted end end class NueteredBootingApplication < Fastr :: Application attr_reader :booted def boot @booted = true end end class ManualBootingApplication < Fastr :: Application include Fastr :: Log def initialize ( path ) self . app_path = path @booting = true end", "commit_type": "move"}
{"commit_tokens": ["Allows", "custom", "rack", "response", "or", "array", "returns", "from", "a", "short", "stack", "action"], "add_tokens": "result = self . send ( params [ 'action' ] ) case result when Array result when Rack :: Response result . finish else Rack :: Response . new ( self . send ( params [ \"action\" ] ) , status , headers ) . finish end if Pancake . handle_errors? server_error = Errors :: Server . new server_error . exceptions << e else server_error = e end", "del_tokens": "Rack :: Response . new ( self . send ( params [ \"action\" ] ) , status , headers ) . finish server_error = Errors :: Server . new server_error . exceptions << e", "commit_type": "allow"}
{"commit_tokens": ["Added", "check", "for", "cookies", "before", "calling", "in", "log_helpers", "so", "it", "does", "not", "throw", "exceptions", ".", "Added", "printing", "of", "exception", "information", "so", "we", "are", "not", "blind", "when", "an", "exception", "is", "thrown", "."], "add_tokens": "if defined? cookies cookies_whitelist . each do | cookie_key | cookie_val = cookies [ cookie_key ] ? cookies [ cookie_key ] : 'nil' data_append << \" #{cookie_key}=\\\"#{cookie_val}\\\"\" end end rescue = > e logger . error \"error logging log_entrypoint for request: #{e.inspect}\" logger . error e . backtrace . take ( 10 )", "del_tokens": "cookies_whitelist . each do | cookie_key | cookie_val = cookies [ cookie_key ] ? cookies [ cookie_key ] : 'nil' data_append << \" #{cookie_key}=\\\"#{cookie_val}\\\"\" end rescue logger . error \"error logging log_entrypoint for request\"", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "require_dependency", "is", "called", "only", "once", "for", "every", "action"], "add_tokens": "unless loaded_paths . include? ( file ) require_dependency file loaded_paths << file end def loaded_paths @loaded_paths ||= Set . new end", "del_tokens": "require_dependency file", "commit_type": "make"}
{"commit_tokens": ["fix", "failing", "test", "&", "fix", "move_to_child_of"], "add_tokens": "new_siblings = node . try ( :children ) || self . class . roots . delete_if { | root_node | root_node == self } # already root node position = if self [ parent_column ] == parent_id && self [ position_column ] # already children of target node self [ position_column ] else target . children . maximum ( position_column ) . try ( :succ ) || 1 end", "del_tokens": "new_siblings = node . try ( :children ) || self . class . roots position = target . children . maximum ( position_column ) . try ( :succ ) || 1", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "load", "component", "files", "individually", "-", "21", "/", "11", "/", "2014"], "add_tokens": "VERSION = \"0.5\"", "del_tokens": "VERSION = \"0.4.1\"", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "set", "a", "connection_name", "and", "using", "queue", "name", "for", "receivers"], "add_tokens": "def initialize ( prefetch : nil , connection_name : nil ) connection_options = { client_properties : { connection_name : connection_name } } . merge ( connection_options ) if connection_name", "del_tokens": "def initialize ( prefetch : nil )", "commit_type": "add"}
{"commit_tokens": ["Changed", "user", "/", "group", "for", "unicorn"], "add_tokens": "user 'deploy' , 'users'", "del_tokens": "user 'shipit2' , 'shipit2'", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "success", "/", "failure", "blocks", "(", "thanks", "grosser", "for", "the", "idea!", ")"], "add_tokens": "block . call args_for_block ( block , format , true ) if block_given? block . call args_for_block ( block , format , false ) if block_given? block . call args_for_block ( block , format , true ) if block_given? block . call args_for_block ( block , format , false ) if block_given? def destroy", "del_tokens": "yield ( format ) if block_given? yield ( format ) if block_given? yield ( format ) if block_given? yield ( format ) if block_given? def destroy ( & block )", "commit_type": "add"}
{"commit_tokens": ["fixed", "payload", "escaping", "using", "a", "more", "complete", "set", "of", "unsafe", "chars"], "add_tokens": "p . keys . map { | k | v = URI . escape ( p [ k ] . to_s , Regexp . new ( \"[^#{URI::PATTERN::UNRESERVED}]\" ) ) \"#{k}=#{v}\" } . join ( \"&\" )", "del_tokens": "p . keys . map { | k | \"#{k}=#{URI.escape(p[k].to_s)}\" } . join ( \"&\" )", "commit_type": "fix"}
{"commit_tokens": ["updated", "ruby", "and", "neo4j", "versions", "for", "travis"], "add_tokens": "VERSION = \"2.2.6\"", "del_tokens": "VERSION = \"2.2.5\"", "commit_type": "update"}
{"commit_tokens": ["Added", "unhandled", "exception", "warnings", "and", "bumped", "version"], "add_tokens": "warn \"\\nUnhandled exception: #{e.message}\\n#{e.backtrace.join(\"\\n\")}\\n\" warn \"Unhandled exception: #{e.message}\\n#{e.backtrace.join(\"\\n\")}\\n\"", "del_tokens": "# # TODO:: add debugging output here # # # TODO:: add debugging output here #", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "way", "Bundler", "is", "used", "to", "require", "dependencies"], "add_tokens": "# Returns the Bundler runtime to access Metior's dependencies # # @return [Bundler::Runtime] The Bundler runtime instance def self . runtime @@runtime ||= Bundler :: Runtime . new File . dirname ( __FILE__ ) , Bundler . definition end", "del_tokens": "libdir = File . dirname ( __FILE__ ) Dir . chdir libdir do Bundler . setup end $LOAD_PATH . unshift ( libdir ) unless $LOAD_PATH . include? ( libdir )", "commit_type": "fix"}
{"commit_tokens": ["update", "README", ".", "md", "and", "examples"], "add_tokens": "# this example demonstrate LightIO low-level API # how to use ruby 'raw'(unpatched) socket with LightIO", "del_tokens": "# this example demonstrate how to use ruby 'raw' socket with LightIO", "commit_type": "update"}
{"commit_tokens": ["Added", "ability", "to", "accept", "microformats", "that", "are", "not", "at", "the", "beginning", "of", "a", "class", "string", "for", "attributes"], "add_tokens": "mf . css ( \"*[class*=#{letter}-]\" ) . each do | property | if css_class [ 0 .. 1 ] == \"#{letter}-\"", "del_tokens": "mf . css ( \"*[class|=#{letter}]\" ) . each do | property | if css_class =~ / ^[pnei] /", "commit_type": "add"}
{"commit_tokens": ["Implemented", "lazy", "loading", "for", "endpoints"], "add_tokens": "require 'lotus/routing/endpoint' return Routing :: Endpoint . new ( result ) if result . respond_to? ( :call ) return constantize ( result ) Routing :: Endpoint . new ( -> ( env ) { [ 404 , { 'X-Cascade' => 'pass' } , 'Not Found' ] } ) end def constantize ( string ) begin Routing :: ClassEndpoint . new ( @namespace . const_get ( string ) ) rescue NameError Routing :: LazyEndpoint . new ( string , @namespace ) end", "del_tokens": "return result if result . respond_to? ( :call ) return @namespace . const_get ( result ) . new -> ( env ) { [ 404 , { 'X-Cascade' => 'pass' } , 'Not Found' ] }", "commit_type": "implement"}
{"commit_tokens": ["Add", "support", "for", "sending", "custom", "&", "additional", "variables", "with", "the", "request", "."], "add_tokens": "VERSION = \"1.2.0beta\"", "del_tokens": "VERSION = \"1.1.1\"", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "default", "sort", "order"], "add_tokens": ":per_page => 50 , :default_sort_order => 'id_desc' params [ :order ] ||= active_admin_config [ :default_sort_order ]", "del_tokens": ":per_page => 50", "commit_type": "add"}
{"commit_tokens": ["Make", "has_errors", "code", "more", "readable"], "add_tokens": "has_errors = ( output != warnings )", "del_tokens": "has_errors = ( not output == warnings )", "commit_type": "make"}
{"commit_tokens": ["fix", "timezone", "handling", "in", "the", "AR", "adapter"], "add_tokens": "when :datetime , :timestamp then value . class == Time ? value . in_time_zone ( Base . default_timezone ) : self . class . string_to_time ( value ) when :time then value . class == Time ? value . in_time_zone ( Base . default_timezone ) : self . class . string_to_dummy_time ( value ) when :datetime , :timestamp then \"#{var_name}.class == Time ? #{var_name}.in_time_zone(Base.default_timezone) : #{self.class.name}.string_to_time(#{var_name})\" when :time then \"#{var_name}.class == Time ? #{var_name}.in_time_zone(Base.default_timezone) : #{self.class.name}.string_to_dummy_time(#{var_name})\"", "del_tokens": "when :datetime , :timestamp then value . class == Time ? value : self . class . string_to_time ( value ) when :time then value . class == Time ? value : self . class . string_to_dummy_time ( value ) when :datetime , :timestamp then \"#{var_name}.class == Time ? #{var_name} : #{self.class.name}.string_to_time(#{var_name})\" when :time then \"#{var_name}.class == Time ? #{var_name} : #{self.class.name}.string_to_dummy_time(#{var_name})\"", "commit_type": "fix"}
{"commit_tokens": ["added", "random_distinct_string", "and", "random_distinct_chars", "methods", "to", "the", "chars", "library"], "add_tokens": "VERSION = '0.1.2'", "del_tokens": "VERSION = '0.1.1'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "split", "codes", "up", "."], "add_tokens": "require 'tty/prompt/symbols'", "del_tokens": "require 'tty/prompt/codes'", "commit_type": "change"}
{"commit_tokens": ["Use", "custom", "person_method", "first", "fallback", "to", "current_user"], "add_tokens": "user = begin send ( Ratchetio . configuration . person_method ) rescue current_user end if user { :id => user . id , :username => user . send ( Ratchetio . configuration . person_username_method ) , :email => user . send ( Ratchetio . configuration . person_email_method ) } else { } end", "del_tokens": "user = begin current_user rescue send Ratchetio . configuration . person_method end { :id => user . id , :username => user . send ( Ratchetio . configuration . person_username_method ) , :email => user . send ( Ratchetio . configuration . person_email_method ) }", "commit_type": "use"}
{"commit_tokens": ["Add", "enums", "indifferent", "strings", "attempt", "blankness"], "add_tokens": "VERSION = \"0.3.0\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "add"}
{"commit_tokens": ["adding", "means", "to", "create", "a", "parser", "as", "an", "instance", "object", "as", "opposed", "to", "a", "static", "class"], "add_tokens": "outfile = File . join ( \"#{RESULTS_DIR}\" , \"#{measure_name}_crit_diff.json\" ) File . open ( outfile , 'w' ) { | f | f . puts ( ( hqmf_model . all_data_criteria - hqmf_model . source_data_criteria ) . collect { | dc | dc . id } ) f . puts f . puts ( ( simple_xml_model . all_data_criteria - simple_xml_model . source_data_criteria ) . collect { | dc | dc . id } ) f . puts f . puts ( ( hqmf_v1_model . all_data_criteria ) . collect { | dc | dc . id } ) } #puts \"#{measure_name} -- #{hqmf_model.derived_data_criteria.count} -- #{simple_xml_model.derived_data_criteria.count} -- #{(hqmf_model.derived_data_criteria.count.to_f/simple_xml_model.derived_data_criteria.count.to_f).to_f}\" #puts \"#{measure_name} -- #{hqmf_model.source_data_criteria.count} -- #{simple_xml_model.source_data_criteria.count} -- #{(hqmf_model.source_data_criteria.count.to_f/simple_xml_model.source_data_criteria.count.to_f).to_f}\" # puts \"#{measure_name} -- #{hqmf_model.all_data_criteria.count} -- #{simple_xml_model.all_data_criteria.count} -- #{(hqmf_model.all_data_criteria.count.to_f/simple_xml_model.all_data_criteria.count.to_f).to_f}\"", "del_tokens": "# parse the model from the simple XML", "commit_type": "add"}
{"commit_tokens": ["Remove", "setter", "accessor", "method", "for", "ArchiveSearcher", "::", "results"], "add_tokens": "( id - 1 ) / 50 + 1", "del_tokens": "( id - 1 ) / 50 + 1", "commit_type": "remove"}
{"commit_tokens": ["Change", "to", "use", "extracted", "generator"], "add_tokens": "require_relative \"../generator\" TTY :: Config :: Generator . generate ( data )", "del_tokens": "TTY :: Config . generate ( data )", "commit_type": "change"}
{"commit_tokens": ["change", "where", "exception", "is", "caught", "also", "ensure", "that", "send_command", "s", "return", "value", "informs", "what", "happened", "to", "message"], "add_tokens": "if valid? ( metric , value , time ) && send_command ( \"gauge\" , metric , value , time . to_i ) value else nil rescue Exception => e report_exception ( e ) nil if valid? ( metric , value , time ) && send_command ( \"increment\" , metric , value , time . to_i ) value else nil rescue Exception => e report_exception ( e ) nil def report_exception ( e ) logger . error \"Exception occurred: #{e.message}\" logger . error e . backtrace . join ( \"\\n\" ) end", "del_tokens": "if valid? ( metric , value , time ) send_command ( \"gauge\" , metric , value , time . to_i ) value if valid? ( metric , value , time ) send_command ( \"increment\" , metric , value , time . to_i ) value rescue Exception => e logger . error \"Exception occurred: #{e.message}\" logger . error e . backtrace . join ( \"\\n\" ) nil", "commit_type": "change"}
{"commit_tokens": ["Use", "faraday", "instead", "of", "httparty"], "add_tokens": "require 'json' require 'faraday' @base_uri = webhook_url conn = Faraday . new ( url : @base_uri ) response = conn . post ( '' , payload : body . to_json )", "del_tokens": "require 'httparty' include HTTParty # The format of the response. This comes back as 'ok' from slack. format :plain # Disable the use of rails query string format. # # With rails query string format enabled: # => get '/', :query => {:selected_ids => [1,2,3]} # # Would translate to this: # => /?selected_ids[]=1&selected_ids[]=2&selected_ids[]=3 disable_rails_query_string_format self . class . base_uri ( webhook_url ) response = self . class . post ( '' , body : { payload : body . to_json } )", "commit_type": "use"}
{"commit_tokens": ["fix", "writting", "new", "entry", "with", "same", "key", "as", "remove", "one"], "add_tokens": "when :remove then remove_entry ( operation [ :path ] ) # Removes entry from tree. If path do not exist, then try if it don't # change to collection # @example of such collection change # \"test\" => remove, \"lest\" => remove, \"test\" => add # in this case it change after first add # \"test[1]\" => remove, \"lest\" => remove, \"test[2]\" => already added # so in this case try to append [1] to path def remove_entry ( path ) if aug . match ( path ) . size == 1 aug . rm ( path ) elsif ! aug . match ( path + \"[1]\" ) . empty? aug . rm ( path + \"[1]\" ) else raise \"Unknown augeas path #{path}\" end end", "del_tokens": "when :remove then aug . rm ( operation [ :path ] )", "commit_type": "fix"}
{"commit_tokens": ["Change", "some", "field", "names", "."], "add_tokens": "attr_reader :title , :slug , :poll_count , :last_updated , :url , :estimates , :state , :topic data [ :last_updated ] = Time . parse ( data [ :last_updated ] )", "del_tokens": "attr_reader :title , :slug , :pollcount , :last_updated , :url , :estimates , :state , :topic data [ :last_updated ] = Time . parse ( data [ :lastupdated ] )", "commit_type": "change"}
{"commit_tokens": ["Making", "Culerity", "return", "actual", "Array", "objects", "rather", "than", "a", "RemoteProxy", "object", "."], "add_tokens": "if [ String , TrueClass , FalseClass , Fixnum , Float , NilClass , Array ] . include? ( result . class )", "del_tokens": "if [ String , TrueClass , FalseClass , Fixnum , Float , NilClass ] . include? ( result . class )", "commit_type": "make"}
{"commit_tokens": ["added", "support", "for", "mapped", "&", "tagged", "in", "SLF4J", "logger", "using", "MDC"], "add_tokens": "require 'loggr/slf4j/mdc' attr_reader :java_logger , :java_marker , :java_mdc @java_mdc = options [ :mdc ] || Loggr :: SLF4J :: MDC # Uses the mapped diagnostic context to add tags, like # ActiveSupport 3.2's TaggedLogger. # def tagged ( * new_tags ) old_tags = java_mdc [ :tags ] . to_s java_mdc [ :tags ] = ( old_tags . split ( ', ' ) + new_tags . flatten ) . join ( ', ' ) yield ensure java_mdc [ :tags ] = old_tags . length == 0 ? nil : old_tags end # A more describtive alternative to tagged is mapped, which just makes # use of the MDC directly, basically. def mapped ( hash = { } ) old_keys = hash . keys . inject ( { } ) { | hsh , k | hsh [ k ] = java_mdc [ k ] ; hsh } hash . each { | key , value | java_mdc [ key ] = value } yield ensure old_keys . each { | key , value | java_mdc [ key ] = value } end", "del_tokens": "require 'logger/slf4j/mdc' attr_reader :java_logger , :java_marker", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "Data", "module", "and", "endpoint", "for", "appending", "/", "replacing", "data", "in", "a", "graph", "."], "add_tokens": "require 'tripod/errors/validations' require 'tripod/errors/rdf_parse_failed'", "del_tokens": "require 'tripod/errors/validations'", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "fix", "frozen", "strings"], "add_tokens": "# frozen_string_literal: true", "del_tokens": "# encoding: utf-8", "commit_type": "change"}
{"commit_tokens": ["remove", "all", "object", "allocation", "that", "occurs", "between", "the", "GC", "and", "the", "retained", "objects", "analysis"], "add_tokens": "GC . start while new_count = decreased_count ( new_count )", "del_tokens": "GC . start ( full_mark : true ) while new_count = decreased_count ( new_count )", "commit_type": "remove"}
{"commit_tokens": ["Allow", "use", "of", "%", "in", "the", "message", "string", "."], "add_tokens": "# Since the Ruby Syslog API supports sprintf format strings, double up all existing '%' message = formatter . call ( log ) . gsub \"%\" , \"%%\" :: Syslog . log @level_map [ log . level ] , message end", "del_tokens": ":: Syslog . log @level_map [ log . level ] , formatter . call ( log ) end", "commit_type": "allow"}
{"commit_tokens": ["Use", "forwardable", "in", "OffenseCollector", "."], "add_tokens": "output ( analyzer ) if analyzer . errors . any?", "del_tokens": "output ( analyzer ) if analyzer . error_occurrence . any?", "commit_type": "use"}
{"commit_tokens": ["Allow", "minor", "version", "upgrades", "for", "rayyan", "-", "core"], "add_tokens": "VERSION = \"0.1.4\"", "del_tokens": "VERSION = \"0.1.3\"", "commit_type": "allow"}
{"commit_tokens": ["add", "new", "rspec", "style", "assertion", "use", "implicit", "assertions", "for", "method?s"], "add_tokens": "expect ( conf . content ) . to be_a Hash expect ( conf . attributes ) . to be_an Array expect ( conf . attributes ) . to_not be_empty expect ( conf . utsname ) . to_not be_nil expect ( conf [ 'utsname' ] ) . to_not be_nil expect ( conf [ :utsname ] ) . to_not be_nil expect ( conf . network_ipv4 ) . to_not be_nil expect ( c1 . content ) . to eq ( c2 . content ) end", "del_tokens": "conf . content . should be_a Hash conf . attributes . should be_an Array conf . attributes . should_not be_empty conf . utsname . should_not be_nil conf [ 'utsname' ] . should_not be_nil conf [ :utsname ] . should_not be_nil conf . network_ipv4 . should_not be_nil c1 . content . should eq ( c2 . content ) end", "commit_type": "add"}
{"commit_tokens": ["make", "the", "generate", "message", "method", "dynamic"], "add_tokens": "def inherited ( klass ) @descendants ||= Set . new @descendants << klass superclass . inherited ( klass ) unless ( self == Message ) end def descendants @descendants || Set . new end MESSAGE_TYPE = \"\" . freeze klass = self . descendants . select { | d | d :: MESSAGE_TYPE == params [ 'lti_message_type' ] } . first klass ? klass . new ( params ) : Message . new ( params )", "del_tokens": "case params [ 'lti_message_type' ] when BasicLTILaunchRequest :: MESSAGE_TYPE BasicLTILaunchRequest . new ( params ) when RegistrationRequest :: MESSAGE_TYPE RegistrationRequest . new ( params ) when ContentItemSelectionRequest :: MESSAGE_TYPE ContentItemSelectionRequest . new ( params ) when ContentItemSelection :: MESSAGE_TYPE ContentItemSelection . new ( params ) when ToolProxyReregistrationRequest :: MESSAGE_TYPE ToolProxyReregistrationRequest . new ( params ) else self . new ( params ) end", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "use", "load", "helper", "to", "lazy", "load", "dependencies"], "add_tokens": "unless defined? ( Fiddle ) load_dep ( \"fiddle\" , \"no native fiddle module found\" , verbose : verbose ) end load_dep ( \"io/console\" , \"no native io/console support or io-console gem\" , verbose : verbose ) if @output . tty? && IO . method_defined? ( :winsize ) size = @output . winsize size if nonzero_column? ( size [ 1 ] ) rescue Errno :: EOPNOTSUPP # no support for winsize on output", "del_tokens": "require 'fiddle' unless defined? ( Fiddle ) rescue LoadError warn 'no native fiddle module found' if verbose require 'io/console' begin if @output . tty? && IO . method_defined? ( :winsize ) size = @output . winsize size if nonzero_column? ( size [ 1 ] ) end rescue Errno :: EOPNOTSUPP # no support for winsize on output rescue LoadError warn 'no native io/console support or io-console gem' if verbose", "commit_type": "change"}
{"commit_tokens": ["use", "searchIndex", "in", "folder", "find"], "add_tokens": "x = @soap . searchIndex . FindChild ( entity : self , name : name ) x if x . is_a? type", "del_tokens": "childEntity . grep ( type ) . find { | x | x . name == name }", "commit_type": "use"}
{"commit_tokens": ["Move", "relationship", "code", "into", "a", "relationships", "directory"], "add_tokens": "require 'tenacity/relationships/has_many' require 'tenacity/relationships/belongs_to'", "del_tokens": "require 'tenacity/has_many' require 'tenacity/belongs_to'", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "explicit", "options", "parameter", "can", "override", "custom", "defaults"], "add_tokens": "} } # Merge custom defaults and let explicit options parameter override them. merge_custom_defaults! merge_options! ( options ) # Update @options by first merging the :color hash and then the remaining keys. #------------------------------------------------------------------------------ def merge_options! ( options = { } ) @options [ :color ] . merge! ( options . delete ( :color ) || { } ) @options . merge! ( options ) end # Load ~/.aprc file with custom defaults that override default options. def merge_custom_defaults! merge_options! ( self . class . defaults )", "del_tokens": "} . merge ( options . delete ( :color ) || { } ) } . merge ( options ) load_custom_defaults #------------------------------------------------------------------------------ #------------------------------------------------------------------------------ # Load ~/.aprc file that can store custom defaults, for example: # # AwesomePrint.defaults = { # :indent => -2, # :color => { # :trueclass => :red # } # } def load_custom_defaults @options [ :color ] . merge! ( self . class . defaults . delete ( :color ) || { } ) @options . merge! ( self . class . defaults )", "commit_type": "make"}
{"commit_tokens": ["Removing", "wrong", "comment", "header", "for", "the", "VERSION", "module", "."], "add_tokens": "# Module that encapsulates the version number.", "del_tokens": "# Part of the Sigimera Platform # # Author:: Alex Oberhauser (mailto:alex.oberhauser@sigimera.org) # Copyright:: Copyright (c) 2012 Sigimera # License:: Closed Source", "commit_type": "remove"}
{"commit_tokens": ["Added", "fix", "for", "multiphrase", "query"], "add_tokens": "if i = @positions . index ( position ) term_arrays [ i ] += terms else @term_arrays << terms @positions << position end bq . add_query ( TermQuery . new ( term ) , BooleanClause :: Occur :: SHOULD ) return bq", "del_tokens": "@term_arrays << terms @positions << position bq . add ( TermQuery . new ( term ) , BooleanClause :: Occur :: SHOULD ) return boq", "commit_type": "add"}
{"commit_tokens": ["Use", "our", "own", "version", "number"], "add_tokens": "VERSION = \"1.0.0\"", "del_tokens": "VERSION = \"4.1.0\"", "commit_type": "use"}
{"commit_tokens": ["Added", "csv", "rendering", "to", "the", "index"], "add_tokens": "self . active_admin_config = { :per_page => 50 } respond_to :html , :xml , :json respond_to :csv , :only => :index before_filter :setup_pagination_for_csv def default_per_page = ( per_page ) read_inheritable_attribute ( :active_admin_config ) [ :per_page ] = per_page end def default_per_page read_inheritable_attribute ( :active_admin_config ) [ :per_page ] end # # Actions # def index index! do | format | format . html { render_or_default 'index' } format . csv { @csv_columns = resource_class . columns . collect { | column | column . name . to_sym } render_or_default 'index' } end end # Allow more records for csv files def setup_pagination_for_csv @per_page = 10_000 if request . format == 'text/csv' end chain . paginate ( :page => params [ :page ] , :per_page => @per_page || self . class . default_per_page )", "del_tokens": "self . active_admin_config = { } chain . paginate ( :page => params [ :page ] )", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "parallelize", "http", "requests"], "add_tokens": "if defined? ( Typhoeus ) connection . adapter :typhoeus else connection . adapter Faraday . default_adapter # must be last end", "del_tokens": "connection . adapter Faraday . default_adapter # must be last", "commit_type": "add"}
{"commit_tokens": ["Add", "filename", "to", "Sass", "options"], "add_tokens": "output . write Sass . compile ( input . read , sass_options_for_file ( input ) ) # @return the Sass options for the current Compass # configuration. # @return the Sass options for the given +file+. # Adds a +:syntax+ option if the filter's options # don't already include one. def sass_options_for_file ( file ) added_opts = { :filename => file . fullpath , :syntax => file . path . match ( / \\. sass$ / ) ? :sass : :scss } added_opts . merge ( @options ) end", "del_tokens": "sass_opts = if input . path . match ( / \\. sass$ / ) options . merge ( :syntax => :sass ) else options end output . write Sass . compile ( input . read , sass_opts )", "commit_type": "add"}
{"commit_tokens": ["add", "methods", "to", "kong", "api", "base", "attributes"], "add_tokens": "https_only http_if_terminated methods", "del_tokens": "https_only http_if_terminated", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "unlikely", "classes", "regex", "case", "insensitive", "."], "add_tokens": "require \"ruby-debug\" UNLIKELY_CLASSES = / combx|comment|disqus|foot|header|menu|meta|nav|rss|shoutbox|sidebar|sponsor /i", "del_tokens": "UNLIKELY_CLASSES = / combx|comment|disqus|foot|header|menu|meta|nav|rss|shoutbox|sidebar|sponsor /", "commit_type": "make"}
{"commit_tokens": ["adding", "back", "subscriptions", "to", "provider", "filter"], "add_tokens": "before_filter :find_provider , :only => [ :subscriptions , :edit , :update , :destroy ]", "del_tokens": "before_filter :find_provider , :only => [ :edit , :update , :destroy ]", "commit_type": "add"}
{"commit_tokens": ["fix", "off", "-", "by", "-", "one", "for", "quartile", "calc"], "add_tokens": "range = ( 1 .. top ) . to_a", "del_tokens": "range = ( 0 .. top ) . to_a", "commit_type": "fix"}
{"commit_tokens": ["Move", "exception", "rescue", "into", "a", "wrapper"], "add_tokens": "def self . with_friendly_errors yield rescue FatalDeploymentError => error KubernetesDeploy . logger . fatal <<-MSG #{error.class}: #{error.message} #{error.backtrace && error.backtrace.join(\"\\n \")} MSG exit 1 end", "del_tokens": "rescue FatalDeploymentError => error KubernetesDeploy . logger . fatal ( error . message ) exit 1", "commit_type": "move"}
{"commit_tokens": ["Updated", "the", "description", "of", "the", "project", "in", "the", "gemspec", "file", "."], "add_tokens": "# color_mode_id = ChunkyPNG.const_get(\"COLOR_#{color_mode.to_s.upcase}\")", "del_tokens": "# color_mode_id = ChunkyPNG::Chunk::Header.const_get(\"COLOR_#{color_mode.to_s.upcase}\")", "commit_type": "update"}
{"commit_tokens": ["fixes", "the", "appearance", "of", "new", "commands"], "add_tokens": "# This command is already in our list. Add it. Procodile . log nil , 'system' , \"#{name} has been added to the Procfile. Adding it.\" @processes [ name ] = Process . new ( self , name , command , process_options [ name ] || { } ) @processes [ name ] . log_color = COLORS [ @processes . size . divmod ( COLORS . size ) [ 1 ] ]", "del_tokens": "# Update the commands for processes Procodile . log nil , 'system' , \"#{name} is no longer in the Procfile. Removing it.\" @process . delete ( name )", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "default", "error", "code", "to", "match", "the", "OAuth2", "Spec"], "add_tokens": "# Returns the http status code of this error, defaulting to 400 (Bad Request). @http_status ||= 400", "del_tokens": "# Returns the http status code of this error, defaulting to 500. @http_status ||= 500", "commit_type": "change"}
{"commit_tokens": ["Make", "Job", "more", "like", "Beaneater", "::", "Job"], "add_tokens": "seeds . map { | job | job . delete if job . exists? }", "del_tokens": "seeds . map ( & :delete )", "commit_type": "make"}
{"commit_tokens": ["Added", "basic", "inspector", "for", "class", "and", "recrord"], "add_tokens": "expect { subject } . not_to raise_error", "del_tokens": "expect { subject } . not_to raise_error ( PageRecord :: NotInputField ) # TODO: can we make it better?", "commit_type": "add"}
{"commit_tokens": ["change", "visibility", "of", "connecting?", "and", "associating?", "methods"], "add_tokens": "def connecting? super end def associating? super end", "del_tokens": "def connecting? super end def associating? super end", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "few", "bugs", "and", "hopefully", "included", "stylesheet", "in", "partial"], "add_tokens": "@commontator_name = commontator_name ( @comment )", "del_tokens": "@commontator_name = commontator_name ( @commontator )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "README", ".", "Fixed", "file_rel", "when", "in", "IRB", "."], "add_tokens": "# NOTE: May be lacking file information, e.g. when in an irb session. file , line = caller . first . split ( \":\" ) :file => file , :line => line , :file_base => ( begin ; File . basename ( file ) ; rescue ; file ; end ) , :file_rel => ( begin ; Pathname ( file ) . relative_path_from ( Rails . root ) . to_s ; rescue ; file ; end ) ,", "del_tokens": "c = caller . first . split ( \":\" ) :file => c [ 0 ] , :line => c [ 1 ] , :file_base => File . basename ( c [ 0 ] ) , :file_rel => Pathname ( c [ 0 ] ) . relative_path_from ( Rails . root ) . to_s ,", "commit_type": "fix"}
{"commit_tokens": ["Adds", "listing", "and", "getting", "for", "Volume", "Types", "in", "Volumes", "API", "v1"], "add_tokens": "param :id , required : true def http_method :get end \"#{ service_spec[:endpoints][0][:publicURL] }/types/#{ params[:id] }\"", "del_tokens": "param :id , required : true \"#{ service_spec[:endpoints][0][:publicURL] }/type/#{ params[:id] }\"", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "pass", "a", "scope", "with", "procs", "when", "merging", "Tags"], "add_tokens": "@raw . merge normalize_tags ( tags , scope : scope ) value = value . map { | tag | normalize_tags ( tag , scope : scope ) } value = value . to_ary . map { | tag | normalize_tags ( tag , scope : scope ) }", "del_tokens": "@raw . merge normalize_tags ( tags ) value = value . map { | tag | normalize_tags ( tag ) } value = value . to_ary . map { | tag | normalize_tags ( tag ) }", "commit_type": "allow"}
{"commit_tokens": ["Use", "timeout", "for", "Redis", "connections", "and", "reads"], "add_tokens": "connection = Redis . new url : Attention . options [ :redis_url ] , connect_timeout : Attention . options [ :timeout ] , timeout : Attention . options [ :timeout ]", "del_tokens": "connection = Redis . new url : Attention . options [ :redis_url ]", "commit_type": "use"}
{"commit_tokens": ["changed", "order", "of", "arguments", "in", "Timer#initialize"], "add_tokens": "def initialize ( interval , max = 0 , align = 0 , & block )", "del_tokens": "def initialize ( interval , align = 0 , max = 0 , & block )", "commit_type": "change"}
{"commit_tokens": ["Updated", "parser", "to", "avoid", "instance", "variables"], "add_tokens": "def parse_tag_params ( raw_params , context ) params = liquid_lookup ( raw_params , context ) . split instructions = { source_images : { } } instructions [ :preset_name ] = params . shift instructions [ :source_images ] . default = params . shift instructions [ :source_images ] [ source_key ] = params . shift instructions [ :html_attributes ] = params . join ' ' instructions def liquid_lookup ( params , context ) Liquid :: Template . parse ( params )", "del_tokens": "def parse_tag_params params = liquid_lookup . split @instructions [ :preset_name ] = params . shift @instructions [ :source_image ] = params . shift @instructions [ :alt_source_images ] << { source_key => params . shift } @instructions [ :html_attributes ] = params . shift . join ' ' def liquid_lookup Liquid :: Template . parse ( @raw_params )", "commit_type": "update"}
{"commit_tokens": ["added", "add_columns", "although", "you", "can", "still", "use", "replace_columns", "as", "it", "only", "modifies", "table", "schema"], "add_tokens": "def replace_columns_statement alter_columns_statement ( \"REPLACE\" ) end def add_columns_statement alter_columns_statement ( \"ADD\" ) def alter_columns_statement ( add_or_replace ) %[ALTER TABLE `#{name}` #{add_or_replace} COLUMNS #{column_statement}] end", "del_tokens": "def replace_columns_statement ( ) %[ALTER TABLE `#{name}` REPLACE COLUMNS #{column_statement}]", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "config", "version", "for", "mauth", "routing", "and", "a", "default", "to", "v1"], "add_tokens": "@version = config [ :version ] || \"v1\" URI . parse ( @mauth_baseurl + \"/mauth/#{@version}/authentication_tickets.json\" ) \"/mauth/#{@version}/security_tokens/#{app_uuid}.json\"", "del_tokens": "URI . parse ( @mauth_baseurl + \"/mauth/v1/authentication_tickets.json\" ) \"/mauth/v1/security_tokens/#{app_uuid}.json\"", "commit_type": "add"}
{"commit_tokens": ["add", "second", "arg", "options", "to", "notify", "verify?", "method"], "add_tokens": "def self . verify? ( params , options = { } ) pid = options [ :pid ] || Alipay . pid Sign . verify? ( params , options ) && verify_notify_id? ( pid , params [ 'notify_id' ] ) def self . verify_notify_id? ( pid , notify_id ) uri = URI ( \"https://mapi.alipay.com/gateway.do\" ) uri . query = URI . encode_www_form ( 'service' => 'notify_verify' , 'partner' => pid , 'notify_id' => notify_id ) Net :: HTTP . get ( uri ) == 'true'", "del_tokens": "def self . verify? ( params ) Sign . verify? ( params ) && verify_notify_id? ( params [ 'notify_id' ] ) def self . verify_notify_id? ( notify_id ) Net :: HTTP . get ( URI ( \"https://mapi.alipay.com/gateway.do?service=notify_verify&partner=#{Alipay.pid}&notify_id=#{CGI.escape(notify_id.to_s)}\" ) ) == 'true'", "commit_type": "add"}
{"commit_tokens": ["Added", "Project#exclude", "for", "specifying", "rspec", "--", "exclude", "patterns", "."], "add_tokens": "# The file-path patterns to exclude from deployment attr_reader :exclude @exclude = Set [ ] options = [ '-a' , '--delete-after' ] # add --exclude options @exclude . each { | pattern | options << \"--exclude=#{pattern}\" } sh ( 'rsync' , * options , local_copy , @dest )", "del_tokens": "sh 'rsync' , '-a' , '--delete-after' , local_copy , @dest", "commit_type": "add"}
{"commit_tokens": ["change", "results_link", "to", "results_url", "&", "json_link", "to", "json_url"], "add_tokens": "@json_url = produce_json_url_link ( url ) { parsed_json : parse_output_json , json_url : @json_url , # Reuturns the URL of the results page. def produce_json_url_link ( url ) url . gsub ( / input / , '' ) . gsub ( %r{ /*$ } , '' ) + \"/GeneValidator/#{@unique_id}/input_file.fa.json\" end", "del_tokens": "{ parsed_json : parse_output_json , json_url : output_json_file_path ,", "commit_type": "change"}
{"commit_tokens": ["Add", "Diameter", "application", "handler", "functionality"], "add_tokens": "def create_answer", "del_tokens": "def create_answer ( _origin_host = nil )", "commit_type": "add"}
{"commit_tokens": ["Implement", "Stream", "::", "Feed#update_activities", "and", "Stream", "::", "Feed#update_activity"], "add_tokens": "@client = Stream :: Client . new ( \"82s68q7ggw7a\" , \"pk85fb4947cd5j3r9ms2ayhjm5zth8vwq3tgyvw77ttpmf34fdm62dn7wcvhbadk\" , nil , :location => \"us-east\" ) example \"updating many feed activities\" do activities = [ ] [ 0 .. 10 ] . each do | i | activities << { \"actor\" : \"user:1\" , \"verb\" : \"do\" , \"object\" : \"object:#{i}\" , \"foreign_id\" : \"object:#{i}\" , \"time\" : DateTime . now } end created_activities = @feed42 . add_activities ( activities ) [ \"activities\" ] activities = Marshal . load ( Marshal . dump ( created_activities ) ) sleep 3 activities . each do | activity | activity . delete ( \"id\" ) activity [ \"popularity\" ] = 100 end @feed42 . update_activities ( activities ) updated_activities = @feed42 . get ( limit : activities . length ) [ \"results\" ] . reverse updated_activities . each_with_index do | activity , idx | expect ( created_activities [ idx ] [ \"id\" ] ) . to eql activity [ \"id\" ] expect ( activity [ \"popularity\" ] ) . to eql 100 end end", "del_tokens": "@client = Stream :: Client . new ( \"ahj2ndz7gsan\" , \"gthc2t9gh7pzq52f6cky8w4r4up9dr6rju9w3fjgmkv6cdvvav2ufe5fv7e2r9qy\" , nil , :location => \"us-east\" )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "generators", "on", "Rails", "master", "."], "add_tokens": "require 'rails/generators/rails/scaffold_controller/scaffold_controller_generator'", "del_tokens": "require 'generators/rails/scaffold_controller/scaffold_controller_generator'", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "exposures", "to", "be", "defined", "at", "once"], "add_tokens": "def self . expose ( * names , ** options , & block ) if names . length == 1 exposures . add ( names . first , block , ** options ) else names . each do | name | exposures . add ( name , nil , ** options ) end end def self . private_expose ( * names , & block ) expose ( * names , to_view : false , & block )", "del_tokens": "def self . expose ( name , & block ) exposures . add ( name , block ) def self . private_expose ( name , & block ) exposures . add ( name , block , to_view : false )", "commit_type": "allow"}
{"commit_tokens": ["Change", "the", "points", "logic", "to", "split", "on", "comma", "and", "take", "that", "length", "to", "more", "closely", "mirror", "readability", "."], "add_tokens": "# # TODO: Convert text nodes to <p> as well points += paragraph . text . split ( ',' ) . length", "del_tokens": "points += paragraph . text . count ( ',' )", "commit_type": "change"}
{"commit_tokens": ["Fix", "spec", "(", "timezone", "bug", ")"], "add_tokens": "update_date : Time . new ( 2015 , 1 , 2 , 10 , 00 , 00 , '+00:00' )", "del_tokens": "update_date : Time . new ( 2015 )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "random", "spec", "ordering", "with", "null", "entities"], "add_tokens": "if null_klass = ( entity_class . const_defined? ( :NullEntity , false ) && entity_class . const_get ( :NullEntity , false ) )", "del_tokens": "if null_klass = ( entity_class . const_defined? ( :NullEntity ) && entity_class . const_get ( :NullEntity , false ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "first", "bit", "of", "Model", "Layer", "documentation", "and", "renamed", "the", "Contribution", "Guide", "placeholder", "."], "add_tokens": "## # Subclasses should implement this method as part of enabling the # refresh_details fuctionality The implementation should make a request # to the SoftLayer API and retrieve an up-to-date SoftLayer hash # representation of this object. That hash should be the return value # of this routine. # def softlayer_properties ( object_mask = nil ) raise \"Abstract method softlayer_properties in ModelBase was called\" end", "del_tokens": "## # Subclasses should implement this method as part of enabling the # refresh_details fuctionality The implementation should make a request # to the SoftLayer API and retrieve an up-to-date SoftLayer hash # representation of this object. That hash should be the return value # of this routine. # def softlayer_properties ( object_mask = nil ) raise \"Abstract method softlayer_properties in ModelBase was called\" end", "commit_type": "add"}
{"commit_tokens": ["add", "generator", "for", "QuickSearch", "engine", "installation"], "add_tokens": "config_file = File . join ( Rails . root , \"/config/quick_search_config.yml\" ) if File . exist? ( config_file ) APP_CONFIG = YAML . load_file ( config_file ) [ Rails . env ] ActiveSupport . on_load ( :action_controller ) do theme_engine_class = \"#{QuickSearch::Engine::APP_CONFIG['theme'].classify}::Engine\" . constantize prepend_view_path theme_engine_class . root . join ( 'app' , 'views' , QuickSearch :: Engine :: APP_CONFIG [ 'theme' ] ) end", "del_tokens": "config_file = File . join ( Rails . root , \"/config/quicksearch_config.yml\" ) APP_CONFIG = YAML . load_file ( config_file ) [ Rails . env ] ActiveSupport . on_load ( :action_controller ) do theme_engine_class = \"#{QuickSearch::Engine::APP_CONFIG['theme'].classify}::Engine\" . constantize prepend_view_path theme_engine_class . root . join ( 'app' , 'views' , QuickSearch :: Engine :: APP_CONFIG [ 'theme' ] )", "commit_type": "add"}
{"commit_tokens": ["fixed", "an", "issue", "related", "to", "ignored", "paths"], "add_tokens": "self . ignore_paths = options [ :ignore_paths ] || [ ] self . tidy_options = DEFAULT_TIDY_OPTS . merge ( options )", "del_tokens": "@ignore_paths = options . delete ( :ignore_paths ) || [ ] @tidy_options = DEFAULT_TIDY_OPTS . merge ( options )", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "option", "hash", "of", "format_time", "to", "include", "the", "timezone", "in", "the", "output", "of", "the", "time", "."], "add_tokens": "# @option opts [DateTime, Time, String] :time Time of the alarm opts [ :time ] = format_time opts [ :time ] , include_timezone : true", "del_tokens": "# @option opts [String] :time Time of the alarm in the format XX:XX+XX:XX, time # with timezone", "commit_type": "use"}
{"commit_tokens": ["added", "testing", "for", "remove", "option"], "add_tokens": "describe \"remove\" do before { subject . process ( %w{ google root@74.12.32.42 -p 30 } ) } let ( :input ) { \"google -r\" } let ( :output ) { subject . process ( input . split ( \" \" ) ) } it 'ends with 30' do expect ( output ) . to end_with \"30\\n\" end end", "del_tokens": "describe \"not implemented\" do let ( :input ) { 'google root@74.125.224.72 -p 80 -t -r' } let ( :output ) { subject . process ( input . split ( \" \" ) ) } it 'prints sad face' do expect ( output ) . to end_with 'Not implemented :(' end end", "commit_type": "add"}
{"commit_tokens": ["Added", "nil", "check", "on", "classname"], "add_tokens": "suite [ index ] [ \"classname\" ] = node . attributes [ :classname ] if suite [ index ] [ \"classname\" ] != nil", "del_tokens": "suite [ index ] [ \"classname\" ] = node . attributes [ :classname ]", "commit_type": "add"}
{"commit_tokens": ["fix", "old", "dates", "parsing", "assertions", "to", "work", "with", "new", "year", "building", "method"], "add_tokens": "assert_equal Time . local ( 2040 , 5 , 16 , 12 , 0 , 0 ) , time assert_equal Time . local ( 2040 , 5 , 27 , 12 , 0 , 0 ) , time", "del_tokens": "assert_equal Time . local ( 40 , 5 , 16 , 12 , 0 , 0 ) , time assert_equal Time . local ( 40 , 5 , 27 , 12 , 0 , 0 ) , time", "commit_type": "fix"}
{"commit_tokens": ["added", "the", "possibility", "to", "use", "imagemagick", "s", "-", "alpha", "option"], "add_tokens": "alpha = options . fetch ( :alpha , Grim :: ALPHA ) command = [ @imagemagick_path , \"-resize\" , width . to_s , \"-alpha\" , alpha , \"-antialias\" , \"-render\" ,", "del_tokens": "command = [ @imagemagick_path , \"-resize\" , width . to_s , \"-antialias\" , \"-render\" ,", "commit_type": "add"}
{"commit_tokens": ["fix", "off", "by", "1", "(", "3", "retries", "instead", "of", "2", ")"], "add_tokens": "retries_remaining ||= 4", "del_tokens": "retries_remaining ||= 3", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "primary", "deployment", "couldn", "t", "be", "fetched"], "add_tokens": "description = begin Ecs . describe_services ( cluster . name , [ @name ] ) puts \"Error: #{e}\" nil end if description . nil? puts <<EOD service = description . fetch ( \"services\" ) [ 0 ]", "del_tokens": "begin service = Ecs . describe_services ( cluster . name , [ @name ] ) . fetch ( \"services\" ) [ 0 ] puts <<EOD Error : #{ e }", "commit_type": "fix"}
{"commit_tokens": ["use", "eql", "to", "tests", "for", "the", "correct", "type", "and", "value"], "add_tokens": "expect ( described_class . prepare ( '1' ) ) . to eql 1 expect ( described_class . prepare ( 1 ) ) . to eql 1", "del_tokens": "expect ( described_class . prepare ( '1' ) ) . to eq 1 expect ( described_class . prepare ( 1 ) ) . to eq 1", "commit_type": "use"}
{"commit_tokens": ["Add", "first", "test", "for", "#deploy", "."], "add_tokens": "let ( :cf_client ) do client_options = { :stub_responses => true } if ENV . key? ( \"AWS_DEBUG\" ) client_options [ :logger ] = Logger . new ( STDOUT ) client_options [ :log_level ] = :debug end Aws :: CloudFormation :: Client . new ( client_options ) end describe \"#deploy\" do let ( :template ) { \"stack template\" } context \"successful\" do let ( :describe_stacks_responses ) do super ( ) + [ stack_description ( \"CREATE_IN_PROGRESS\" ) , stack_description ( \"CREATE_COMPLETE\" ) ] end let! ( :return_value ) do stack . deploy ( template ) end it \"calls :create_stack\" do expect ( cf_client ) . to have_received ( :create_stack ) end end end", "del_tokens": "let ( :cf_client ) { Aws :: CloudFormation :: Client . new ( :stub_responses => true ) }", "commit_type": "add"}
{"commit_tokens": ["Change", "test", "-", "Parameters", "are", "now", "required", "by", "default"], "add_tokens": "assert_equal :required , @parameter . use", "del_tokens": "assert_equal :undefined , @parameter . use", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "an", "optional", "buildstamp", "in", "the", "topology", "file"], "add_tokens": "msg = \"Topology already exists - do you want to update it\" msg = msg + \" to version \" + topo [ 'version' ] if topo [ 'version' ] ui . info ( \"Build information: \" + topo_hash [ 'buildstamp' ] ) if topo_hash [ 'buildstamp' ]", "del_tokens": "msg = \"Topology already exists - do you want to update it\" ; msg + \" to version \" + topo [ 'version' ] if topo [ 'version' ]", "commit_type": "add"}
{"commit_tokens": ["Use", "all", "parent", "modules", "to", "generate", "namespace", "name"], "add_tokens": "modules [ 0 .. - 2 ] . map ( & :singularize ) . join ( '__' )", "del_tokens": "modules . first . singularize", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "where", "cannot", "post", "json"], "add_tokens": "case headers [ \"format\" ]", "del_tokens": "case headers [ :format ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "documentation", "to", "the", "run", "method", "."], "add_tokens": "# This run method is a pretty important method when using command lion typically. # # Under the hood, an application object is initialized. The block of code passed to # this method is then used as the code that is ran in the context of a application # object. So all of those methods will be available. # # Initialize an instance of an App object. # Evaluate the block of code within the context of that App object. # Parse the application logic out. # Sometimes a command-line application is run without being given any arguments. # Default to a help menu. # Use the default help menu for the application unless that's been # explictly removed by the author for whatever reason.", "del_tokens": "#binding.pry binding . pry #binding.pry # #binding.pry", "commit_type": "add"}
{"commit_tokens": ["Add", "boolean", "as", "a", "column", "type", "."], "add_tokens": "return nil if arg . nil? && ! [ :boolean , :bool ] . include? ( type ( column_name ) ) when :boolean , :bool case arg when NilClass then false when TrueClass , FalseClass then arg when Integer then arg != 0 when String then ( arg =~ / ^true /i ) != nil else raise ArgumentError . new ( \"type #{column_name} : #{type(column_name)} is not possible to cast.\" ) end", "del_tokens": "return nil if arg . nil?", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "only", "option", "to", "timeline", "fetching", "/", "API", "cleanup"], "add_tokens": "# @param options (see Storage#find_timeline) def timeline_selector ( timeline_kind , recipient_id , options = { } ) result = { 'rcpt' => recipient_id } if ! options [ :only ] . blank? result [ '$or' ] = options [ :only ] . map do | route | { 'routing' => route . routing_kind , 'activity.kind' => route . activity_class . kind } end end result # @param options (see Storage#find_timeline) def find_timeline_entries ( timeline_kind , recipient_id , limit , options = { } ) self . find ( self . timeline_collection ( timeline_kind ) , self . timeline_selector ( timeline_kind , recipient_id , options ) , limit , options [ :skip ] , 'activity.at' ) # @param options (see Storage#find_timeline) def count_timeline_entries ( timeline_kind , recipient_id , options = { } ) self . count ( self . timeline_collection ( timeline_kind ) , self . timeline_selector ( timeline_kind , recipient_id , options ) )", "del_tokens": "def timeline_selector ( timeline_kind , recipient_id ) { 'rcpt' => recipient_id , } # @param skip [Integer] Number of entries to skip (default: 0) def find_timeline_entries ( timeline_kind , recipient_id , limit , skip = 0 ) self . find ( self . timeline_collection ( timeline_kind ) , self . timeline_selector ( timeline_kind , recipient_id ) , limit , skip , 'activity.at' ) def count_timeline_entries ( timeline_kind , recipient_id ) self . count ( self . timeline_collection ( timeline_kind ) , self . timeline_selector ( timeline_kind , recipient_id ) )", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "define", "loggers", "by", "including", "a", "module"], "add_tokens": "# name of top level logger (can't be root as you can't have outputters on root) BASE_LOGGER = 'rails' Object . const_set ( 'RAILS_DEFAULT_LOGGER' , Log4r :: Logger [ BASE_LOGGER ] )", "del_tokens": "Object . const_set ( 'RAILS_DEFAULT_LOGGER' , Log4r :: Logger [ 'rails' ] )", "commit_type": "add"}
{"commit_tokens": ["fix", "connection", "monitor", "start", "problem"], "add_tokens": "@proto = proto monitor = Actor . current @proto . receive_hello_callbacks . push ( -> ( p , ** kwargs ) { monitor . start } ) @logger ||= Logger . new ( \"#{@proto.peer.config[:p2p][:listen_port]}.p2p.ctxmonitor.#{object_id}\" )", "del_tokens": "@proto = proto @proto . receive_hello_callbacks . push ( -> ( p , ** kwargs ) { start } ) @logger ||= Logger . new ( 'p2p.ctxmonitor' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "specify", "custom", "frames", "."], "add_tokens": "@frames = options . fetch ( :frames ) { FORMATS [ @format . to_sym ] }", "del_tokens": "@frames = FORMATS [ @format . to_sym ]", "commit_type": "add"}
{"commit_tokens": ["added", "teardown", "functions", "for", "broker"], "add_tokens": "ensure @broker . teardown if ( @broker ) end if ( @threads )", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "Message#to_mail", "method", "that", "returns", "an", "object", "of", "type", "Mail", "."], "add_tokens": "# These are some methods which may not always exist, but we don't want to say that they don't if ( m . match ( / cc_recipients|to_recipients / ) ) return [ ] else warn \"!!! No such method: #{m}\" nil end", "del_tokens": "warn \"!!! No such method: #{m}\"", "commit_type": "add"}
{"commit_tokens": ["Adding", "implementation", "of", "/", "icd", "/", "convert", "/", "and", "its", "corresponding", "test"], "add_tokens": "describe 'ICD Convert endpoint' do it 'should expose the icd convert endpoint' do stub_request ( :get , MATCH_NETWORK_LOCATION ) . to_return ( status : 200 , body : '{ \"string\" : \"\" }' ) @icd = @pokitdok . icd_convert ( code : '250.12' ) refute_nil ( @icd ) end end", "del_tokens": "# TODO: ICD Convert Tests", "commit_type": "add"}
{"commit_tokens": ["Create", "setting", "model", "on", "install"], "add_tokens": "migration_template 'migrations/create_settings.rb' , 'db/migrate/create_settings.rb' end def install_models %w[ settings ] . each do | model | template \"models/#{model}.rb\" , \"app/models/#{model}.rb\" end", "del_tokens": "", "commit_type": "create"}
{"commit_tokens": ["Fix", "rspec", "error", "with", "mocking", "http", "library"], "add_tokens": "faye = stub_request ( :post , \"http://localhost/\" ) . with ( :body => { \"message\" => \"\\\"foo\\\"\" } , :headers => { ' Accept '=>' * / *', 'Content-Type'=>'application /x - www - form - urlencoded ' , 'User-Agent' => 'Ruby' } ) . to_return ( :status => 200 , :body => \"\" , :headers => { } ) PrivatePub . publish_message ( message ) faye . should have_been_made . once", "del_tokens": "form = mock ( :post ) . as_null_object http = mock ( :http ) . as_null_object Net :: HTTP :: Post . should_receive ( :new ) . with ( '/' ) . and_return ( form ) form . should_receive ( :set_form_data ) . with ( message : 'foo' . to_json ) Net :: HTTP . should_receive ( :new ) . with ( 'localhost' , 80 ) . and_return ( http ) http . should_receive ( :start ) . and_yield ( http ) http . should_receive ( :request ) . with ( form ) . and_return ( :result ) PrivatePub . publish_message ( message ) . should eq ( :result )", "commit_type": "fix"}
{"commit_tokens": ["Add", "use", "of", "Any", "for", "code", "for", "arrays", "of", "codes"], "add_tokens": "'list<System.Code>' : '[Any]' ,", "del_tokens": "'list<System.Code>' : '[]' ,", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "imperial", "units", "for", "weight", "from", "using", "ounces", "to", "pounds"], "add_tokens": "attr_reader :options , : :value , :currency @unit_system == :imperial ? m . in_pounds : m", "del_tokens": "attr_reader :options , :value , :currency @unit_system == :imperial ? m . in_ounces : m", "commit_type": "change"}
{"commit_tokens": ["fix", "another", "bug", "involving", "metadata", "bump", "patch", "level"], "add_tokens": "VERSION = \"0.2.2\"", "del_tokens": "VERSION = \"0.2.1\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "teardown", "to", "clear", "Fakeweb", "fix", "incorrect", "test"], "add_tokens": "v = ShopifyAPI :: Variant . find ( 808950810 , :params => { :product_id => 632910392 } )", "del_tokens": "v = ShopifyAPI :: Variant . find ( 808950810 )", "commit_type": "add"}
{"commit_tokens": ["Use", "file", "path", "for", "instance_eval", "to", "get", "correct", "stack", "traces"], "add_tokens": "instance_eval open ( DynamicSitemaps . config_path ) . read , DynamicSitemaps . config_path", "del_tokens": "instance_eval open ( DynamicSitemaps . config_path ) . read", "commit_type": "use"}
{"commit_tokens": ["Use", "location", "under", "/", "tmp", "for", "testing"], "add_tokens": "require 'tempfile' require 'securerandom' let ( :data_dir ) { File . join ( Dir . tmpdir , 'analects-' + SecureRandom . hex ( 16 ) ) } { data_dir : data_dir } subject . cedict . data_dir . should == data_dir", "del_tokens": "{ data_dir : '/test/123' } subject . cedict . data_dir . should == '/test/123'", "commit_type": "use"}
{"commit_tokens": ["Fixed", "small", "problem", "while", "filling", "in", "the", "%param%", "part", "of", "the", "error", "description"], "add_tokens": "return [ tag [ :tag_param_description ] . gsub ( '%param%' , ti [ :params ] [ :tag_param ] ) ] if ti [ :params ] [ :tag_param ] . match ( tag [ :tag_param ] ) . nil?", "del_tokens": "return [ tag [ :tag_param_description ] . gsub ( '%param%' , ti [ :params ] [ :tag_params ] ) ] if ti [ :params ] [ :tag_param ] . match ( tag [ :tag_param ] ) . nil?", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "check", "for", "HTTP_CONTENT_MD5", "in", "the", "ActionController", "driver", "for", "the", "MD5", "hash"], "add_tokens": "value = find_header ( %w( CONTENT-MD5 CONTENT_MD5 HTTP_CONTENT_MD5 ) )", "del_tokens": "value = find_header ( %w( CONTENT-MD5 CONTENT_MD5 ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "detection", "of", "when", "to", "exclude", "no_ci", "tests"], "add_tokens": "c . filter_run_excluding :no_ci if ENV [ 'CI' ] == 'true' && ENV [ 'ADAPTER' ] && ENV [ 'ADAPTER' ] . starts_with? ( 'bunny' )", "del_tokens": "#c.filter_run_excluding :no_ci if ENV['CI']=='true' && ENV['ADAPTER'] && ENV['ADAPTER'].starts_with?('bunny')", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "few", "nice", "URL", "accessors", "and", "made", "a", "bunch", "of", "stuff", "accessible", "to", "views", "."], "add_tokens": "instance_path ( current_model_name . underscore , object ) collection_path ( current_model_name . pluralize . underscore ) end def new_object_path collection_path ( \"new_#{current_model_name.underscore}\" ) end def edit_object_path ( object = current_object ) instance_path ( \"edit_#{current_model_name.underscore}\" , object ) def instance_path ( name , object ) send ( \"#{namespace_prefix}#{name}_path\" , * ( parent_objects + [ object ] ) ) end def collection_path ( name ) send ( \"#{namespace_prefix}#{name}_path\" , * parent_objects ) end", "del_tokens": "send ( \"#{namespace_prefix}#{current_model_name.underscore}_path\" , * ( parent_objects + [ object ] ) ) send ( \"#{namespace_prefix}#{current_model_name.pluralize.underscore}_path\" , * parent_objects )", "commit_type": "add"}
{"commit_tokens": ["Add", "attachment", "endpoints", "to", "expenses"], "add_tokens": "[ :created_at , :updated_at , :deleted_at ] . each { | n | attribute n , DateTime }", "del_tokens": "[ :created_at , :updated_at , :deleted_at ] . each { | n | attribute n , String }", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "easier", "to", "use", "panes", "powered", "by", "custom", "classes"], "add_tokens": "if args . any? && args . first . is_a? Pane @panes [ name ] = args . first else @panes [ name ] = Pane . new ( self , * args , & blck ) end", "del_tokens": "@panes [ name ] = Pane . new ( self , * args , & blck )", "commit_type": "make"}
{"commit_tokens": ["Adding", "donation", "push", "support", "to", "API", "."], "add_tokens": "VERSION = '0.2.0'", "del_tokens": "VERSION = '0.1.4'", "commit_type": "add"}
{"commit_tokens": ["Adding", "more", "tests", "and", "filling", "out", "more", "resources", "."], "add_tokens": "build :index , :show", "del_tokens": "build :index", "commit_type": "add"}
{"commit_tokens": ["Fix", "erroneous", "warning", "when", "loading", "capistrano"], "add_tokens": "return if %w( set namespace task ) . all? { | m | dsl . respond_to? ( m , true ) }", "del_tokens": "return if %w( set namespace task ) . all? { | m | dsl . respond_to? ( m ) }", "commit_type": "fix"}
{"commit_tokens": ["remove", "before_destroy", "on", "statuasble", "+", "superfluous", "check"], "add_tokens": "update ( status : OSC :: Machete :: Status . failed ) if update", "del_tokens": "update ( status : OSC :: Machete :: Status . failed ) if status . active? && update # before we destroy ActiveRecord qdel any jobs running # Workflow normally takes care of this, but this is harmless # because stop won't do anything unless the job is active # this way if you delete a job from the rails console it will delete the # corresponding batch job if obj . respond_to? ( :before_destroy ) obj . before_destroy do | simple_job | simple_job . stop update : false end end", "commit_type": "remove"}
{"commit_tokens": ["Moving", "over", "the", "procedure", "importer", "from", "hQuery"], "add_tokens": "@section_importers [ :procedures ] = ProcedureImporter . new", "del_tokens": "@section_importers [ :procedures ] = SectionImporter . new ( \"//cda:procedure[cda:templateId/@root='2.16.840.1.113883.10.20.1.29']\" )", "commit_type": "move"}
{"commit_tokens": ["removed", "the", ".", "project", "file"], "add_tokens": "file = File . open ( \"C:/Users/1bi/git/gestordereservas/db/schema.rb\" , \"r\" )", "del_tokens": "file = File . open ( \"C:/Users/hpinto/git/gestorreservas/db/schema.rb\" , \"r\" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "use", "case", "of", "multiple", "cookbooks", "i", ".", "e", ".", "cookbook", "list", "specified"], "add_tokens": "raise StandardError . new ( \"I was crafted from Chef::Knife::VERSION == '11.6.2'. Please verify that #{self.class.name}.run is still relevant in your version '#{Chef::VERSION}'!\" ) unless Chef :: VERSION . match ( %r/ ^11 \\. / ) @cookbooks_to_upload = nil", "del_tokens": "raise StandardError . new ( \"I was crafted from Chef::Knife::VERSION == '11.6.2'. Please verify that #{self.class.name}.run is still relevant in your version '#{Chef::VERSION}'!\" ) unless Chef :: VERSION . match ( %r/ ^11 \\. 6 \\. 2 / )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "up", "where", "clause", "requirment", "to", "hopefully", "semi", "-", "future", "proof"], "add_tokens": "if ActiveRecord :: VERSION :: MAJOR >= 5 && ActiveRecord :: VERSION :: MINOR == 1 require \"active_record_extended/patch/5_1/where_clause\" elsif ActiveRecord :: VERSION :: MAJOR >= 5 require \"active_record_extended/patch/5_2/where_clause\"", "del_tokens": "if ActiveRecord :: VERSION :: MAJOR >= 5 if ActiveRecord :: VERSION :: MINOR >= 2 require \"active_record_extended/patch/5_2/where_clause\" else require \"active_record_extended/patch/5_1/where_clause\" end", "commit_type": "fix"}
{"commit_tokens": ["Moves", "the", "rspec3", "checker", "into", "a", "helper", "module", "."], "add_tokens": "require 'nyan_cat_format/helpers' extend NyanCatFormat :: Helpers :example_failed , :start_dump , :start ) if rspec_3_or_greater?", "del_tokens": "rspec_3_or_greater = Gem :: Version . new ( RSpec :: Core :: Version :: STRING ) . release >= Gem :: Version . new ( '3.0.0' ) :example_failed , :start_dump , :start ) if rspec_3_or_greater", "commit_type": "move"}
{"commit_tokens": ["allow", "defaults", "for", "nested", "attributes"], "add_tokens": "add_attribute ( name , options . slice ( :default ) ) association = build_association ( name , one_or_many == :one , options . except ( :default ) ) def add_attribute ( name , options ) @owner . attribute ( name , options )", "del_tokens": "add_attribute ( name ) association = build_association ( name , one_or_many == :one , options ) def add_attribute ( name ) @owner . attribute ( name )", "commit_type": "allow"}
{"commit_tokens": ["Move", "private", "visibility", "declaration", "so", "that", "only", "initialize", "and", "run_all_updates", "are", "publically", "visible", "."], "add_tokens": "def run_all_updates project . git :init update_gitignore commit 'Initial commit with updated .gitignore' clean_gemfile use_pg use_12_factor_gem add_test_gems add_ruby_version commit 'add gems' remove_turbo_links commit 'remove turbolinks' create_database_sample commit 'add database.sample file' create_readme commit 'add readme' create_app_env_var_sample commit 'add app environment variable sample file' install_rspec commit 'install rspec' create_spec_folders update_rails_helper_spec commit 'customize rspec for basic usage' springify commit 'springify app' checkout_develop_branch # Don't setup Heroku or BitBucket if user runs 'rails new' with '--pretend' # TODO: Doug: Consider extending Thor::Actions(?) to get behavior simillar to project.run unless project . options [ :pretend ] setup_heroku if project . yes? ( 'Setup Heroku (y/n)?' ) setup_bitbucket if project . yes? ( 'Setup BitBucket repo (y/n)?' ) end end private", "del_tokens": "# TODO: Doug: make this function the only private member def run_all_updates project . git :init update_gitignore commit 'Initial commit with updated .gitignore' clean_gemfile use_pg use_12_factor_gem add_test_gems add_ruby_version commit 'add gems' remove_turbo_links commit 'remove turbolinks' create_database_sample commit 'add database.sample file' create_readme commit 'add readme' create_app_env_var_sample commit 'add app environment variable sample file' install_rspec commit 'install rspec' create_spec_folders update_rails_helper_spec commit 'customize rspec for basic usage' springify commit 'springify app' checkout_develop_branch # Don't setup Heroku or BitBucket if user runs 'rails new' with '--pretend' # TODO: Doug: Consider extending Thor::Actions(?) to get behavior simillar to project.run unless project . options [ :pretend ] setup_heroku if project . yes? ( 'Setup Heroku (y/n)?' ) setup_bitbucket if project . yes? ( 'Setup BitBucket repo (y/n)?' ) end end private", "commit_type": "move"}
{"commit_tokens": ["Add", "Virtus", "::", "Typecast", "::", "String", "for", "consistency"], "add_tokens": "# @see Virtus::Typecast::String.call Virtus :: Typecast :: String . call ( value )", "del_tokens": "# Typecast the given value to a string # # @param [Object] # # @return [String] value . to_s", "commit_type": "add"}
{"commit_tokens": ["remove", "--", "type", "git", "from", "spec_helper", ".", "cfg"], "add_tokens": "c . setup ( [ preserve , fresh_nodes , '--hosts' , nodesetfile ] )", "del_tokens": "c . setup ( [ preserve , fresh_nodes , '--type' , 'git' , '--hosts' , nodesetfile ] )", "commit_type": "remove"}
{"commit_tokens": ["Allow", "assert_no_statsd_calls", "without", "metric", "name"], "add_tokens": "def assert_no_statsd_calls ( metric_name = nil , & block ) metrics = capture_statsd_metrics ( & block ) metrics . select! { | m | m . name == metric_name } if metric_name", "del_tokens": "def assert_no_statsd_calls ( metric_name , & block ) metrics = capture_statsd_metrics ( & block ) . select { | m | m . name == metric_name }", "commit_type": "allow"}
{"commit_tokens": ["added", "environment", "to", "the", "options", "for", "crowd", "server"], "add_tokens": "exec \"thin -e #{@options[:environment]} -p #{@options[:port]} -R #{rackup_path} start\" exec \"rackup -E #{@options[:environment]} -p #{@options[:port]} #{rackup_path}\" :environment => 'production' , opts . on ( '-e' , '--environment ENV' , 'Sinatra environment (code reloading)' ) do | env | @options [ :environment ] = env end", "del_tokens": "exec \"thin -e production -p #{@options[:port]} -R #{rackup_path} start\" exec \"rackup -E production -p #{@options[:port]} #{rackup_path}\"", "commit_type": "add"}
{"commit_tokens": ["Move", "breadcrumbs", "code", "into", "own", "class"], "add_tokens": "require \"govuk_navigation_helpers/breadcrumbs\" Breadcrumbs . new ( content_item ) . breadcrumbs", "del_tokens": "direct_parent = content_item . dig ( \"links\" , \"parent\" , 0 ) ordered_parents = [ ] while direct_parent ordered_parents << { title : direct_parent [ \"title\" ] , url : direct_parent [ \"base_path\" ] , } direct_parent = direct_parent . dig ( \"links\" , \"parent\" , 0 ) end ordered_parents << { title : \"Home\" , url : \"/\" } ordered_parents . reverse", "commit_type": "move"}
{"commit_tokens": ["Removed", "the", "abilitiy", "to", "fetch", "versions", "using", "a", "Symbol", "argument", "."], "add_tokens": "when Date , Time then at ( value ) . try ( :number )", "del_tokens": "when Symbol then respond_to? ( value ) ? send ( value ) : nil when Symbol , Date , Time then at ( value ) . try ( :number )", "commit_type": "remove"}
{"commit_tokens": ["added", "documentation", "to", "Slop", "::", "Option", "[", "s", "]"], "add_tokens": "# @param [Boolean] symbols true to cast hash keys to symbols # @return [Hash] # @param [Object] flag # @return [Option] the option assoiated with this flag def [] ( flag ) item = flag . to_s # @return [String, #to_s] # @return [String, #to_s] # @return [String] # @return [Proc, #call] # @param [Slop] slop # @param [String, #to_s] short # @param [String, #to_s] long # @param [String] description # @param [Boolean] argument # @param [Hash] options # @option options [Boolean] :optional # @option options [Boolean] :argument # @option options [Object] :default # @option options [Proc, #call] :callback # @option options [String, #to_s] :delimiter # @option options [Integer] :limit # @return [Boolean] true if this option expects an argument # @return [Boolean] true if this option expects an optional argument # @return [String] either the long or short flag for this option # @return [Object] # @return [Object] the argument value after it's been case # according to the `:as` option end", "del_tokens": "def [] ( item ) item = item . to_s end", "commit_type": "add"}
{"commit_tokens": ["Added", "non", "-", "editable", "queries"], "add_tokens": "unless @query . editable? ( blazer_user ) @query . errors . add ( :base , \"Sorry, permission denied\" ) end if @query . errors . empty? && @query . update ( query_params ) @query . destroy if @query . editable? ( blazer_user ) queries = Blazer :: Query . where ( \"name <> ''\" ) . where ( id : recent_query_ids ) . index_by ( & :id ) @queries = Blazer :: Query . where ( \"name <> ''\" ) . order ( :name )", "del_tokens": "if @query . update ( query_params ) @query . destroy queries = Blazer :: Query . where ( id : recent_query_ids ) . index_by ( & :id ) @queries = Blazer :: Query . order ( :name )", "commit_type": "add"}
{"commit_tokens": ["make", "patches", "more", "naive", "by", "using", "super", "and", "splat", "args"], "add_tokens": "setup_callbacks_for_habtm ( options [ :join_tables ] )", "del_tokens": "setup_associations ( options ) setup_callbacks_for_habtm options [ :join_tables ] def setup_associations ( options ) @model_class . class_attribute :version_association_name @model_class . version_association_name = options [ :version ] || :version # The version this instance was reified from. @model_class . send :attr_accessor , @model_class . version_association_name @model_class . class_attribute :version_class_name @model_class . version_class_name = options [ :class_name ] || \"PaperTrail::Version\" @model_class . class_attribute :versions_association_name @model_class . versions_association_name = options [ :versions ] || :versions @model_class . send :attr_accessor , :paper_trail_event assert_concrete_activerecord_class ( @model_class . version_class_name ) @model_class . has_many ( @model_class . versions_association_name , -> { order ( model . timestamp_sort_order ) } , class_name : @model_class . version_class_name , as : :item ) end @model_class . after_rollback { paper_trail . clear_rolled_back_versions }", "commit_type": "make"}
{"commit_tokens": ["add", "group_by", "option", "to", "excel", "source", "fix", "tests"], "add_tokens": "VERSION = \"0.1.32\"", "del_tokens": "VERSION = \"0.1.30\"", "commit_type": "add"}
{"commit_tokens": ["Add", "read_attribute", "and", "write_attributes", "to", "the", "base", "class", "API", "that", "wraps", "transforms", "and", "redis", "future", "conversions"], "add_tokens": "read_attribute ( name ) write_attribute ( name , val ) def read_attribute ( name ) if attributes . is_a? ( Redis :: Future ) value = attributes . value self . attributes = value ? Hash [ * self . class . fields . keys . zip ( value ) . flatten ] : { } end self . class . transform ( :from , name , attributes [ name ] ) end def write_attribute ( name , val ) attributes [ name ] = self . class . transform ( :to , name , val ) end", "del_tokens": "if attributes . is_a? ( Redis :: Future ) value = attributes . value self . attributes = value ? Hash [ * self . class . fields . keys . zip ( value ) . flatten ] : { } end self . class . transform ( :from , name , attributes [ name ] ) attributes [ name ] = self . class . transform ( :to , name , val )", "commit_type": "add"}
{"commit_tokens": ["Implement", "JIRA", "::", "Resource", "::", "HasManyProxy"], "add_tokens": "collection = attribute . map do | child_attributes | HasManyProxy . new ( self , child_class , collection )", "del_tokens": "attribute . map do | child_attributes |", "commit_type": "implement"}
{"commit_tokens": ["Use", "relation", "commands", ":", "tada", ":"], "add_tokens": "result = relation . command ( :create ) . call ( tuple ) struct ( result )", "del_tokens": "# FIXME: This relies on rom-sql but instead adapter-specific code must be in a plugin/extension if relation . class . adapter == :sql && relation . dataset . supports_returning? ( :insert ) pk = relation . dataset . returning ( primary_key ) . insert ( tuple ) [ 0 ] [ primary_key ] else pk = relation . insert ( tuple ) end struct ( tuple . merge ( primary_key => pk ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "dynamic", "selection", "matching", "methods", "."], "add_tokens": "# Example # class Thing < ActiveRecord::Base # belongs_to_selection :priority # # This macro also adds a number of methods onto the class if there is a selection # named as the class underscore name (eg: \"thing_priority\"), then methods are created # for all of the selection values under that parent. For example: # # thing = Thing.find(x) # thing.priority = Selection.thing_priority_high # thing.priority_high? #=> true # thing.priority_low? #=> false # # thing.priority_high? is equivalent to thing.priority == Selection.thing_priority_high # except that the id of the selection is cached at the time the class is loaded. # # Note that this is only appropriate to use for system selection values that are known # at development time, and not to values that the users can edit in the live system. prefix = self . name . downcase parent = Selection . where ( system_code : \"#{prefix}_#{target}\" ) . first if parent target_id = \"#{target}_id\" . to_sym parent . children . each do | s | method_name = \"#{s.system_code.sub(\"#{prefix}_\", '')}?\" . to_sym class_eval do define_method method_name do send ( target_id ) == s . id end end end end end", "del_tokens": "#Example # belongs_to_selection :priority end", "commit_type": "add"}
{"commit_tokens": ["Changed", "order", "to", "text", "-", ">", "whitespace", "-", ">", "escape", "."], "add_tokens": "# Check if the text or print node is escaped or unescaped escaped = accept ( :unescaped_value ) ? false : true", "del_tokens": "# Check if the text or print node is escaped or unescaped escaped = accept ( :unescaped_value ) ? false : true", "commit_type": "change"}
{"commit_tokens": ["Add", "uri", "to", "transformed", "data"], "add_tokens": "transformed_response . merge ( uri : @uri , root_domain : @root_domain )", "del_tokens": "transformed_response . merge ( root_domain : @root_domain )", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "the", "new", "rate_limit_status", "method", "."], "add_tokens": "require 'twitter/direct_message' require 'twitter/rate_limit_status'", "del_tokens": "require 'twitter/direct_message'", "commit_type": "add"}
{"commit_tokens": ["use", "new", "close", "method", "for", "disconnecting", "where", "we", "can"], "add_tokens": "c . close", "del_tokens": "c = nil", "commit_type": "use"}
{"commit_tokens": ["removed", "the", "all", "-", "members", "-", "optional", "thing"], "add_tokens": "rule ( :group_def ) { ( str ( '?' ) | array_repetition ) . maybe >> spcCmnt? >> ( group_rule | array_rule | object_rule | value_rule | rule_name ) . as ( :target_rule_name ) rule ( :directive_def ) { ignore_unknown_members | language_compatible_members | include_d }", "del_tokens": "rule ( :group_def ) { group_rule | array_rule | object_rule | value_rule | rule_name . as ( :target_rule_name ) rule ( :all_members_optional ) { str ( 'all-members-optional' ) . as ( :all_members_optional ) } rule ( :directive_def ) { ignore_unknown_members | language_compatible_members | all_members_optional | include_d }", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "the", "deleted", "list", "on", "endpoints"], "add_tokens": "request ( :GET , '/deleted' , params , & method ( :build_for_deleted ) ) end def build_for_deleted ( response ) TicketEvolution :: Collection . build_from_response ( response , self . class . name . demodulize . downcase , singular_class )", "del_tokens": "request ( :GET , '/deleted' , params )", "commit_type": "implement"}
{"commit_tokens": ["Add", "ssl", "-", "support", "and", "tests"], "add_tokens": "options = { host : Slanger :: Config [ :websocket_host ] , port : Slanger :: Config [ :websocket_port ] , debug : Slanger :: Config [ :debug ] , app_key : Slanger :: Config [ :app_key ] } if Slanger :: Config [ :tls_options ] options . merge! secure : true , tls_options : Slanger :: Config [ :tls_options ] end EM :: WebSocket . start options do | ws |", "del_tokens": "EM :: WebSocket . start host : Slanger :: Config [ :websocket_host ] , port : Slanger :: Config [ :websocket_port ] , debug : Slanger :: Config [ :debug ] , app_key : Slanger :: Config [ :app_key ] do | ws |", "commit_type": "add"}
{"commit_tokens": ["removed", "code", "the", "caused", "a", "dependency", "on", "andand"], "add_tokens": "tmp_num_fmt = @workbook . num_fmts [ :numFmt ] . select { | f | f [ :attributes ] [ :numFmtId ] == num_fmt_id } [ 0 ] num_fmt = ( tmp && tmp [ :attributes ] && tmp [ :attributes ] [ :formatCode ] ) ? tmp [ :attributes ] [ :formatCode ] : nil", "del_tokens": "num_fmt = @workbook . num_fmts [ :numFmt ] . select { | f | f [ :attributes ] [ :numFmtId ] == num_fmt_id } [ 0 ] . andand [ :attributes ] . andand [ :formatCode ]", "commit_type": "remove"}
{"commit_tokens": ["add", "api_key", "helper", ";", "clean", "up", "signed", "request", "logging", ";", "further", "squash", "the", "old", "name", ";", "bump", "version"], "add_tokens": "# Return the current working version of DoesFacebook from VERSION file:", "del_tokens": "# Return the current working version of DoFacebook from VERSION file:", "commit_type": "add"}
{"commit_tokens": ["Fix", "reloading", "of", "lotus", "console"], "add_tokens": "Kernel . exec \"#{$0} console\"", "del_tokens": "Kernel . exec $0", "commit_type": "fix"}
{"commit_tokens": ["Remove", "comments", "and", "unused", "code"], "add_tokens": "", "del_tokens": "# cli = HtmlMockup::Cli.new # cli.invoke(:extract, [self.source_path, self.build_path]) # Inject banners inject_banners! def inject_banners! end", "commit_type": "remove"}
{"commit_tokens": ["Adding", "rspec", "structure", "and", "a", "first", "working", "call", "to", "the", "REST", "API", "(", "get_latest_crises", ")", "."], "add_tokens": "include Sigimera :: HttpHelper # The authentication token that is used for the API calls. attr_reader :auth_token def initialize ( auth_token = nil ) @auth_token = auth_token end def get_latest_crises get ( \"/v1/crises?auth_token=#{@auth_token}\" )", "del_tokens": "def initialize", "commit_type": "add"}
{"commit_tokens": ["add", "version", "/", "extensions", "on", "the", "url", "form", "add", "date", "to", "urls", "and", "adjusted", "urls", "controller", "."], "add_tokens": "params . require ( :script_url ) . permit ( :scripturl , :scripturlrelease , :scripturlcdnupdate , :listing_id , :version_id , :extension_id )", "del_tokens": "params . require ( :script_url ) . permit ( :scripturl , :listing_id )", "commit_type": "add"}
{"commit_tokens": ["fix", "cops", "without", "breaking", "code"], "add_tokens": "expect ( store . clear! ) . to eql ( { } )", "del_tokens": "expect ( store . clear! ) . to eql { }", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "target", "to", "GoogleApps", "::", "Transport#method_missing"], "add_tokens": "it \"sends a POST request to the User endpoint\" do transporter . add_user user_doc transporter . instance_eval { @request } . should be_a Net :: HTTP :: Post transporter . instance_eval { @request . body } . should include user_doc . to_s", "del_tokens": "it \"creates a user in the Google Apps environment\" do", "commit_type": "add"}
{"commit_tokens": ["removing", "redgreen", "since", "it", "seems", "dead"], "add_tokens": "", "del_tokens": "require 'redgreen'", "commit_type": "remove"}
{"commit_tokens": ["Updating", "everything", "to", "start", "development", "."], "add_tokens": "require 'tealeaves/moving_average'", "del_tokens": "Dir [ File . dirname ( __FILE__ ) + \"/tea_leaves/*.rb\" ] . each { | f | require f }", "commit_type": "update"}
{"commit_tokens": ["add", "all", "method", "to", "context"], "add_tokens": "def to ( target ) @locale . translate ( @translator , to : target ) end def all ( targets ) targets . map { | target | @locale . translate ( @translator , to : target ) }", "del_tokens": "def to ( lang ) @locale . translate ( @translator , to : lang )", "commit_type": "add"}
{"commit_tokens": ["Add", "up", "and", "down", "subcommands", "."], "add_tokens": "subcommand \"up\" , \"Create/update the stack\" do subcommand [ \"down\" , \"delete\" ] , \"Remove the stack.\" do", "del_tokens": "subcommand \"deploy\" , \"Create/update the stack\" do subcommand \"delete\" , \"Remove the stack.\" do", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "command", "file"], "add_tokens": "exit ( ) if button_down? ( Gosu :: KbEscape )", "del_tokens": "exit ( ) if @input . button_down? ( Gosu :: KbEscape )", "commit_type": "fix"}
{"commit_tokens": ["Added", "page", "to", "DSL", "for", "more", "expressive", "tests"], "add_tokens": "def page Webcat . current_session end page . #{method}(*args, &block)", "del_tokens": "Webcat . current_session . #{method}(*args, &block)", "commit_type": "add"}
{"commit_tokens": ["implemented", "together", "keyword", "+", "tests"], "add_tokens": "require 'eldritch/together' describe '#together' do it 'should create a new together' do expect ( Eldritch :: Together ) . to receive ( :new ) . and_return ( double ( 'together' ) . as_null_object ) klass . together { } end it 'should set the current thread together' do together = double ( 'together' ) . as_null_object allow ( Eldritch :: Together ) . to receive ( :new ) . and_return ( together ) allow ( Thread . current ) . to receive ( :together= ) . with ( nil ) expect ( Thread . current ) . to receive ( :together= ) . with ( together ) klass . together { } end it 'should wait on all tasks' do together = double ( 'together' ) . as_null_object allow ( Eldritch :: Together ) . to receive ( :new ) . and_return ( together ) expect ( together ) . to receive ( :wait_all ) klass . together { } end it 'should leave current thread together nil' do together = double ( 'together' ) . as_null_object allow ( Eldritch :: Together ) . to receive ( :new ) . and_return ( together ) klass . together { } expect ( Thread . current . together ) . to be_nil end end", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Add", "debugger", "irb", "command", "and", "set", "/", "show", "autoirb", "."], "add_tokens": "cmdproc . frame = dbgr . frame ( 0 )", "del_tokens": "cmdproc . frame = Rubinius :: VM . backtrace ( 0 ) [ 1 ]", "commit_type": "add"}
{"commit_tokens": ["Add", "negative", "options", "for", "--", "hiera", "-", "path", "and", "--", "hiera", "-", "path", "-", "strip"], "add_tokens": "if options . key? ( :hiera_path_strip ) && options [ :hiera_path_strip ] != :none raise ArgumentError , '--hiera-path and --hiera-path-strip are mutually exclusive' end if options [ :hiera_path ] == :none raise ArgumentError , '--hiera-path and --no-hiera-path are mutually exclusive' end parser . on ( '--no-hiera-path' , 'Do not use any default hiera path settings' ) do if options [ :hiera_path ] . is_a? ( String ) raise ArgumentError , '--hiera-path and --no-hiera-path are mutually exclusive' end options [ :hiera_path ] = :none end", "del_tokens": "raise ArgumentError , '--hiera-path and --hiera-path-strip are mutually exclusive' if options . key? ( :hiera_path_strip )", "commit_type": "add"}
{"commit_tokens": ["Updated", "specs", "to", "match", "new", "ActiveRecord", "extension"], "add_tokens": "ActiveRecord :: Base . extend Filterrific :: ActiveRecordExtension", "del_tokens": "ActiveRecord :: Base . extend Filterrific :: ActiveRecordExtension :: ClassMethods", "commit_type": "update"}
{"commit_tokens": ["Use", "database", ".", "yml", "files", "for", "configurability", "."], "add_tokens": "'arunit' => { } %w{ database . yml local_database . yml } . each do | file | file = File . join ( 'test' , file ) next unless File . exists? ( file ) configuration = YAML . load ( File . read ( file ) ) if configuration [ 'arunit' ] ActiveRecord :: Base . configurations [ 'arunit' ] . merge! ( configuration [ 'arunit' ] ) end if defined? ( JRUBY_VERSION ) && configuration [ 'jdbc' ] ActiveRecord :: Base . configurations [ 'arunit' ] . merge! ( configuration [ 'jdbc' ] ) end end", "del_tokens": "'arunit' => { :adapter => 'postgresql' , :database => 'postgresql_cursors_unit_tests' , :min_messages => 'warning' , :schema_search_path => 'public' }", "commit_type": "use"}
{"commit_tokens": ["use", "acts_as_translator", "in", "the", "dummy", "app"], "add_tokens": "acts_as_translator", "del_tokens": "# TODO move to acts_as_translator has_many :translations , class_name : 'TranslationCenter::Translation' # returns the translation a user has made for a certain key in a certain language def translation_for ( key , lang ) self . translations . find_or_initialize_by_translation_key_id_and_lang ( key . id , lang . to_s ) end # returns truy if the user can admin translations def can_admin_translations? self . email == 'khaled@badrit.com' end", "commit_type": "use"}
{"commit_tokens": ["Change", "Flame", "::", "Render", "working", "(", "scope", "in", "layout", "fix", ")"], "add_tokens": "def view ( path , options = { } ) Flame :: Render . new ( self , path , options ) . render end alias_method :render , :view", "del_tokens": "include Flame :: Render", "commit_type": "change"}
{"commit_tokens": ["Use", "redis", "config", "when", "constructing", "qless", "clients", "in", "the", "tests", "."], "add_tokens": "let ( :pubsub ) { new_client }", "del_tokens": "let ( :pubsub ) { Qless :: Client . new }", "commit_type": "use"}
{"commit_tokens": ["Add", "thrift", "client", "options", "when", "setting", "up", "connection"], "add_tokens": "thrift_options = configuration [ :thrift ] || { } { :keyspace => configuration [ :keyspace ] } , thrift_options . symbolize_keys", "del_tokens": ":keyspace => configuration [ :keyspace ]", "commit_type": "add"}
{"commit_tokens": ["Add", "misc", ".", "test", "helpers"], "add_tokens": "Integer ( params [ :version ] )", "del_tokens": "Integer ( request . path_parameters [ :version ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "custom", "attributes", "to", "outgoing", "links", "."], "add_tokens": "response . headers [ \"Ajax-Layout\" ] = default_layout . to_s", "del_tokens": "response . headers [ \"Ajax-Layout\" ] = default_layout . name", "commit_type": "add"}
{"commit_tokens": ["add", "blocked?", "&", "blocked_by?", "methods"], "add_tokens": "# Returns true if this instance has been blocked as favoritor of the object passed as an argument. def blocked_by? favoritable , options = { } if options . has_key? ( :multiple_scopes ) == false options [ :parameter ] = favoritable validate_scopes __method__ , options elsif options [ :multiple_scopes ] results = { } options [ :scope ] . each do | scope | results [ scope ] = 0 < Favorite . blocked . send ( scope + '_list' ) . for_favoritor ( self ) . for_favoritable ( favoritable ) . count end return results else return 0 < Favorite . blocked . send ( options [ :scope ] + '_list' ) . for_favoritor ( self ) . for_favoritable ( favoritable ) . count end end if options . has_key? ( :multiple_scopes ) == false validate_scopes __method__ , options elsif options [ :multiple_scopes ] results = { } options [ :scope ] . each do | scope | results [ scope ] = all_favorites ( options ) . collect { | f | f . favoritable } end return results else return all_favorites ( options ) . collect { | f | f . favoritable } end", "del_tokens": "return all_favorites ( options ) . collect { | f | f . favoritable }", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "spec", "typo", "*", "whistles", "*"], "add_tokens": "describe Redistat :: Summary do", "del_tokens": "describe Redistat :: Label do", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "GZip", "compressor", ".", "Now", "the", "file", "extension", "will", "dynamically", "change", "as", "a", "class", "variable", ".", "Every", "time", "a", "compression", "occurs", "it", "ll", "append", "another", "extension", "to", "the", "stack", "."], "add_tokens": "## # The compressors attr_accessor holds an array of compressor objects attr_accessor :compressors attr_accessor :all , :extension ## # Contains the current file extension (should change after each compression or encryption) @extension = String . new @trigger = trigger @label = label @databases = Array . new @archives = Array . new @compressors = Array . new @storages = Array . new @time = TIME Backup :: Model . extension = 'tar' ## # Adds a compressor to the array of compressors to use # during the backup process def compress_with ( name , & block ) @compressors << Backup :: Compressor . const_get ( name ) . new ( & block ) end # [Compression] # Optionally compresses the packaged file with one of the available compressors ## compressors . each do | compressor | compressor . perform! end # run(\"#{ utility(:rm) } -rf '#{ File.join(TMP_PATH, TRIGGER) }' '#{ File.join(TMP_PATH, \"#{TIME}.#{TRIGGER}.tar\") }'*\") run ( \"#{ utility(:rm) } -rf '#{ File.join(TMP_PATH, TRIGGER) }' '#{ File.join(TMP_PATH, \"#{TIME}.#{TRIGGER}.#{Backup::Model.extension}\") }'\" )", "del_tokens": "attr_accessor :all @trigger = trigger @label = label @databases = Array . new @archives = Array . new @storages = Array . new @time = TIME run ( \"#{ utility(:rm) } -rf '#{ File.join(TMP_PATH, TRIGGER) }' '#{ File.join(TMP_PATH, \"#{TIME}.#{TRIGGER}.tar\") }'*\" )", "commit_type": "add"}
{"commit_tokens": ["added", "option", "support", "to", "pager_command", "option"], "add_tokens": "commands . compact . uniq . find { | e | Util . command_exists? ( e [ / \\w + / ] ) }", "del_tokens": "commands . compact . uniq . find { | e | Util . command_exists? ( e ) }", "commit_type": "add"}
{"commit_tokens": ["Make", "proxy", "configuration", "more", "verbose"], "add_tokens": ":proxy_address , :proxy_password , :proxy_port , :proxy_username ,", "del_tokens": ":proxy ,", "commit_type": "make"}
{"commit_tokens": ["Changed", "require", "to", "use", "local", "copy", "of", "module"], "add_tokens": "require File . expand_path ( '../lib/android-adb' , File . dirname ( __FILE__ ) )", "del_tokens": "require \"android-adb\"", "commit_type": "change"}
{"commit_tokens": ["Add", "new", "sequencer", ":", "Barrage"], "add_tokens": "autoload :Barrage , \"active_record/turntable/sequencer/barrage\" :mysql => Mysql , :barrage => Barrage", "del_tokens": ":mysql => Mysql", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "pass", "required", "params", "."], "add_tokens": "@operations . add ( :padding , Operation :: Padding . new ( padding ) )", "del_tokens": "@operations . add ( :padding , Operation :: Padding . new ( padding , widths ) )", "commit_type": "change"}
{"commit_tokens": ["use", "test", "source", "in", "list", "command", "tests"], "add_tokens": "let ( :source ) { TestSource . new } before do config . apps . each do | app | app . sources . clear app . sources << source end end assert_match ( / dependency / , out ) config . ignore ( \"type\" => \"test\" , \"name\" => \"dependency\" ) refute_match ( / dependency / , out ) let ( :fixtures ) { File . expand_path ( \"../../fixtures\" , __FILE__ ) } source . dependencies_hook = -> { assert_equal fixtures , Dir . pwd } capture_io { command . run }", "del_tokens": "assert_match ( / licensee / , out ) config . ignore ( \"type\" => \"rubygem\" , \"name\" => \"licensee\" ) refute_match ( / licensee / , out ) let ( :fixtures ) { File . expand_path ( \"../../fixtures/npm\" , __FILE__ ) } out , = config . stub ( :enabled? , -> ( type ) { type == \"npm\" } ) do capture_io { command . run } end assert_match ( / Found autoprefixer / , out )", "commit_type": "use"}
{"commit_tokens": ["fix", "typo", "in", "line", "133"], "add_tokens": "link_queue << page . location if page . location =~ @pattern", "del_tokens": "link_queue << page . location if link =~ @pattern", "commit_type": "fix"}
{"commit_tokens": ["Add", "check", "for", "$GSL", "when", "calling", "Matrix", ".", "diag", "to", "ensure", "GSL", "::", "Matrix", "is", "used", "."], "add_tokens": "u * ( $GSL ? GSL :: Matrix : :: Matrix ) . diag ( s ) * v . trans", "del_tokens": "u * Matrix . diag ( s ) * v . trans", "commit_type": "add"}
{"commit_tokens": ["add", "a", "metadata", "value", "to", "force", "static", "parsing"], "add_tokens": "if Usmu :: Template :: Layout . is_valid_file? ( 'source' , filename ) && ( ! metadata [ 'static' ] )", "del_tokens": "if Usmu :: Template :: Layout . is_valid_file? 'source' , filename", "commit_type": "add"}
{"commit_tokens": ["Add", "color", "option", "for", "VM", "manipulation", "commands"], "add_tokens": "options = { :log => false , :color => false } . merge args . first args = [ command , name , * arguments_for ( command ) ] args << \"--color\" if options [ :color ] connection . execute! * args , & log_block", "del_tokens": "options = { :log => false } . merge args . first connection . execute! command , name , * arguments_for ( command ) , & log_block", "commit_type": "add"}
{"commit_tokens": ["added", "debug", "options", "for", "anemone", "and", "verbose", "option", "for", "validator", "errors"], "add_tokens": ":debug => false , o . on ( \"-v\" , \"--verbose\" , \"show detail of validator errors\" ) { | v | @options [ :verbose ] = v } o . on ( \"-d\" , \"--debug\" , \"show anemone log\" ) { | v | @options [ :debug ] = v } puts error ( validator . errors ) if opts [ :error_verbose ]", "del_tokens": "o . on ( \"-v\" , \"--verbose\" , \"Verbose\" ) { | v | @options [ :verbose ] = v }", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "global", "content", "types", "stepping", "on", "each", "other"], "add_tokens": "@content_types = Parts :: ContentTypes . new ( presets . defaults . dup , presets . overrides . dup )", "del_tokens": "@content_types = Parts :: ContentTypes . new ( presets . defaults , presets . overrides )", "commit_type": "fix"}
{"commit_tokens": ["moved", "operation", "class", "to", "own", "file"], "add_tokens": "require \"operation\"", "del_tokens": "class Operation attr_accessor :operation_script def initialize ( script ) @operation_script = script end def execute data = ` sh -c #{ operation_script } ` returnCode = $? return Response . new ( returnCode , data ) . to_json end end", "commit_type": "move"}
{"commit_tokens": ["Add", "tests", "for", "rook", "moving", "before", "castling"], "add_tokens": "def test_king_cannot_castle_to_right_after_right_rook_has_moved move_piece ( \"G2\" , \"G4\" ) # black pawn move_piece ( \"A7\" , \"A5\" ) # red pawn move_piece ( \"F1\" , \"H3\" ) # black bishop move_piece ( \"A8\" , \"A6\" ) # red rook move_piece ( \"G1\" , \"F3\" ) # black knight move_piece ( \"A5\" , \"A4\" ) # red pawn move_piece ( \"H1\" , \"G1\" ) # move right rook left one position move_piece ( \"H7\" , \"H6\" ) # red pawn move_piece ( \"G1\" , \"H1\" ) # move right rook back to its original position assert_equal ( [ \"F1\" ] , valid_piece_movement ( \"E1\" ) , \"King should not be allowed to castle right after right rook has moved\" ) def test_king_cannot_castle_to_left_after_left_rook_has_moved move_piece ( \"B1\" , \"A3\" ) # move_piece ( \"A7\" , \"A6\" ) # move_piece ( \"D2\" , \"D4\" ) # move_piece ( \"B7\" , \"B6\" ) # move_piece ( \"C1\" , \"F4\" ) # move_piece ( \"C7\" , \"C6\" ) # move_piece ( \"D1\" , \"D2\" ) # move_piece ( \"D7\" , \"D6\" ) # move_piece ( \"A1\" , \"B1\" ) # Move left rook right one position move_piece ( \"H7\" , \"H6\" ) # red pawn move_piece ( \"B1\" , \"A1\" ) # Move left rook back to original position assert_equal ( [ \"D1\" ] , valid_piece_movement ( \"E1\" ) , \"King should not be allowed to castle left after left rook has moved\" )", "del_tokens": "def test_king_cannot_castle_to_left_after_left_rook_has_moved # TODO pass def test_king_cannot_castle_to_right_after_right_rook_has_moved pass", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "object", "inspection", "via", "awesome_print", "."], "add_tokens": "if LogBuddy . use_awesome_print? obj . respond_to? ( :ai ) ? obj . ai : obj . inspect else obj . inspect end", "del_tokens": "obj . inspect", "commit_type": "add"}
{"commit_tokens": ["adding", "RS_SERVER", "to", "api_url", "for", "spec", "test"], "add_tokens": "@client = RightApi :: Client . new ( :instance_token => token , :account_id => account_id , :api_url => \"https://#{ENV['RS_SERVER']}\" )", "del_tokens": "@client = RightApi :: Client . new ( :instance_token => token , :account_id => account_id )", "commit_type": "add"}
{"commit_tokens": ["Make", "lrange", "return", "an", "array", "if", "nothing", "matches"], "add_tokens": "( @data [ key ] && @data [ key ] [ startidx .. endidx ] ) || [ ]", "del_tokens": "@data [ key ] && @data [ key ] [ startidx .. endidx ]", "commit_type": "make"}
{"commit_tokens": ["Updating", "travis", ".", "yml", "and", "updating", "specs", "to", "use", "env", "variables"], "add_tokens": "let ( :guidebox ) { GuideboxWrapper :: Movie . new ( ENV [ \"MY_API_KEY\" ] , \"all\" ) }", "del_tokens": "let ( :guidebox ) { GuideboxWrapper :: Movie . new ( CredentialsHelper . key , \"all\" ) }", "commit_type": "update"}
{"commit_tokens": ["Add", "Decorator#part_class", "to", "make", "it", "easy", "to", "provide", "custom", "part", "classes"], "add_tokens": "object . to_ary . map { | obj | part_class ( name , options ) . new ( obj , renderer : renderer , context : context ) } part_class ( name , options ) . new ( object , renderer : renderer , context : context ) def part_class ( name , options ) options . fetch ( :as ) { Part } end", "del_tokens": "# Default decorator, wraps everything in Parts object . to_ary . map { | obj | Part . new ( obj , renderer : renderer , context : context ) } Part . new ( object , renderer : renderer , context : context )", "commit_type": "add"}
{"commit_tokens": ["Add", "special", "handling", "for", "affiliate_summary", "response"], "add_tokens": "VERSION = '0.2.1'", "del_tokens": "VERSION = '0.2.0'", "commit_type": "add"}
{"commit_tokens": ["add", "mongodb", "and", "postgres", "examples", "to", "help", "message"], "add_tokens": "opts . on ( '-d' , '--database_url' , 'The database URL (e.g. mongodb://USER:PASSWORD@localhost:27017/pupa or postgres://USER:PASSWORD@localhost:5432/pupa' ) do | v |", "del_tokens": "opts . on ( '-d' , '--database_url SCHEME://USERNAME:PASSWORD@HOST:PORT/DATABASE' , 'The database URL' ) do | v |", "commit_type": "add"}
{"commit_tokens": ["Add", "round", "trip", "object", "spec"], "add_tokens": "# Fetches data from the cache, using the given key. If there is data in # the cache with the given key, then that data is returned. Otherwise, nil # is returned. # # @param [String] Key for lookup # @param [Hash] Optional overrides # # @example # # cache.read('missing') # => nil # cache.read('matched') # => 'some value' # # @param [String] Key for lookup # @param [String] Key for lookup", "del_tokens": "# @param [String] Key of the value # @param [String] Key of the value", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "context", "/", "type", "/", "tags", "in", "Triggers", "."], "add_tokens": "attr_accessor :auto_resolve , :auto_resolve_alerts , :tags , :type @context = trigger_hash [ 'context' ] @type = trigger_hash [ 'type' ] @tags = trigger_hash [ 'tags' ] trigger_hash [ 'context' ] = @context unless @context . nil? trigger_hash [ 'type' ] = @type unless @type . nil? trigger_hash [ 'tags' ] = @tags unless @tags . nil?", "del_tokens": "attr_accessor :auto_resolve , :auto_resolve_alerts", "commit_type": "add"}
{"commit_tokens": ["Implemented", "user_defined", "foreign", "key", "for", "tenant", "on", "scoped", "models", ".", "Cleaned", "up", "tests", "."], "add_tokens": "", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Added", "the", "Gitter", "class", "to", "requires"], "add_tokens": "require_relative 'autoversion/versioner' require_relative 'autoversion/gitter'", "del_tokens": "require_relative 'autoversion/versioner'", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "Collection", "s", "member_attribute", "to", "validate", "its", "members", "."], "add_tokens": "# @param values [Array] Array of values to validate def self . validate ( values , context , attribute ) values . each_with_index . collect do | value , i | subcontext = \"#{context}[#{i}]\" self . member_attribute . validate ( value , subcontext ) end . flatten . compact", "del_tokens": "# @param value [Array] currently an array of native types def self . validate ( value , context , attribute ) errors = [ ] # All members in the collection Array must be of type Attributor::Type value . each_with_index do | member , i | errors << \"Collection #{context}[#{i}] is not an Attributor::Type\" unless member . is_a? ( Attributor :: Type ) end errors", "commit_type": "use"}
{"commit_tokens": ["Add", "fast", "-", "s", "to", "search", "for", "similar", "code"], "add_tokens": "def expression_from ( node ) if node . children . any? children_expression = node . children . map ( & Fast . method ( :expression_from ) ) . join ( ' ' ) \"(#{node.type} #{children_expression})\" else \"(#{node.type})\" end '_'", "del_tokens": "def similarity ( node , level : 0 ) children = if node . children . any? \" #{node.children.map { |e| Fast.similarity(e, level: level) }.join(' ')}\" end \"(#{node.type}#{children})\" [ '_' , node . to_s ] [ level ]", "commit_type": "add"}
{"commit_tokens": ["making", "balances", "method", "can", "handle", "parameters"], "add_tokens": "def balances args = { } . get ( \"v1/accounts/#{@address}/balances\" , args ) [ \"balances\" ]", "del_tokens": "def balances . get ( \"v1/accounts/#{@address}/balances\" ) [ \"balances\" ]", "commit_type": "make"}
{"commit_tokens": ["move", "arity_range", "to", "spy", "object", "instead", "of", "scope"], "add_tokens": "@arity_range = get_arity_range ( @original_method . parameters ) __insult_spy . called_with ( self , args , block ) @arity_range = nil def called_with ( object , args , block ) check_arity! ( args . size ) @original_method = nil @arity_range = nil private def check_arity! ( arity ) return unless @arity_range if arity < @arity_range . min raise ArgumentError . new ( \"wrong number of arguments (#{arity} for #{@arity_range.min})\" ) elsif arity > @arity_range . max raise ArgumentError . new ( \"wrong number of arguments (#{arity} for #{@arity_range.max})\" )", "del_tokens": "__insult_arity_range = get_arity_range ( @original_method . parameters ) __insult_spy . check_arity! ( __insult_arity_range , args . size ) __insult_spy . called_with ( self , args , & block ) def called_with ( object , args , & block ) def check_arity! ( arity_range , arity ) if arity < arity_range . min raise ArgumentError . new ( \"wrong number of arguments (#{arity} for #{arity_range.min})\" ) elsif arity > arity_range . max raise ArgumentError . new ( \"wrong number of arguments (#{arity} for #{arity_range.max})\" ) private", "commit_type": "move"}
{"commit_tokens": ["Add", "shortcut", "form", "to", "#rescue"], "add_tokens": "def rescue ( ex_class , handler = nil , & bl ) @rescue_clauses [ ex_class ] = handler || bl || NIL_HANDLER", "del_tokens": "def rescue ( ex_class , & bl ) @rescue_clauses [ ex_class ] = bl || NIL_HANDLER", "commit_type": "add"}
{"commit_tokens": ["Move", "variable", "parsing", "to", "sub_tree", "level", "handle", "data", "criteria", "variables"], "add_tokens": "convert_to_variable if attr_val ( '@qdmVariable' ) def convert_to_variable # wrap a reference precondition with a parent @precondition = ParsedPrecondition . new ( HQMF :: Counter . instance . next , [ @precondition ] , nil , HQMF :: Precondition :: ALL_TRUE , false ) if @precondition . reference # create the grouping data criteria for the variable criteria = DataCriteria . convert_precondition_to_criteria ( @precondition , @doc , 'variable' ) criteria . instance_variable_set ( '@variable' , true ) criteria . instance_variable_set ( '@description' , @entry . attributes [ 'displayName' ] . value || attr_val ( '@displayName' ) ) criteria . derivation_operator = ( @precondition . conjunction_code == HQMF :: Precondition :: ALL_TRUE ) ? HQMF :: DataCriteria :: INTERSECT : HQMF :: DataCriteria :: UNION if criteria . children_criteria # put variable in source data criteria sdc = criteria . dup sdc . subset_operators = nil if sdc . subset_operators sdc . remove_instance_variable ( '@temporal_references' ) if sdc . temporal_references sdc . instance_variable_set ( '@variable' , true ) sdc . children_criteria = criteria . children_criteria if criteria . children_criteria sdc . instance_variable_set ( '@description' , @entry . attributes [ 'displayName' ] . value || attr_val ( '@displayName' ) ) @doc . source_data_criteria << sdc # update the reference to the variable data criteria @precondition . preconditions = [ ] @precondition . reference = Reference . new ( criteria . id ) end", "del_tokens": "", "commit_type": "move"}
{"commit_tokens": ["Change", "to", "one", "-", "line", "array"], "add_tokens": "ITCSS_FILES = [ \"settings\" , \"tools\" , \"generic\" , \"base\" , \"objects\" , \"components\" , \"trumps\" ] new_itcss_file ( type , file , template )", "del_tokens": "ITCSS_FILES = [ \"settings\" , \"tools\" , \"generic\" , \"base\" , \"objects\" , \"components\" , \"trumps\" ] new_itcss_file ( type , file , template )", "commit_type": "change"}
{"commit_tokens": ["make", "sure", "it", "handles", "no", "file", "extension"], "add_tokens": "ct = mime_magic_content_type ( path ) ct = file_content_type ( path ) if ( ct . nil? || ct . length == 0 ) ct", "del_tokens": "mime_magic_content_type ( path ) || file_content_type ( path )", "commit_type": "make"}
{"commit_tokens": ["Add", "ability", "to", "add", "ot", "exclude", "issues", "wothout", "any", "labels"], "add_tokens": "log += \"\\n\\n\\\\* *This changelog was generated by [github_changelog_generator](https://github.com/skywinder/Github-Changelog-Generator)*\" issues_req = @github . issues . list user : @options [ :user ] , repo : @options [ :project ] , state : 'closed' , filter : 'all' , labels : nil filtered_issues = issues_req . body . select { | issues | ( issues . labels . map { | issue | issue . name } & @options [ :labels ] ) . any? } if @options [ :add_issues_wo_labels ] issues_wo_labels = issues_req . body . select { | issues | ! issues . labels . map { | issue | issue . name } . any? } filtered_issues . concat ( issues_wo_labels ) end filtered_issues", "del_tokens": "log += \"\\n\\n* *This changelog was generated by [github_changelog_generator](https://github.com/skywinder/Github-Changelog-Generator)*\" @options [ :labels ] . each { | label | issues = @github . issues . list user : @options [ :user ] , repo : @options [ :project ] , state : 'closed' , filter : 'all' , labels : label all_issues = all_issues . concat ( issues . body ) } all_issues", "commit_type": "add"}
{"commit_tokens": ["add", "babel", "-", "brunch", "to", "required", "packages"], "add_tokens": "run \"yarn add --dev brunch babel babel-brunch clean-css-brunch sass-brunch uglify-js-brunch\"", "del_tokens": "run \"yarn add --dev brunch babel brunch clean-css-brunch sass-brunch uglify-js-brunch\"", "commit_type": "add"}
{"commit_tokens": ["Add", "interface", "to", "retrieve", "a", "space", "details"], "add_tokens": "response = Ribose :: Request . get ( resources , options ) # Resources Key # # This value represents the root element in the API response. # Currently, Ribose is using the plural resource name as the # the key. # # By default we will use that to extract the details, but if # some resource are different then we can override this and # that will be used instead. # # @return [String] # def resources_key resources . to_s unless resources_key . nil? response [ resources_key ] # Temporary - Not to break everything right away def resources resource_path end new . all ( query : options )", "del_tokens": "response = Ribose :: Request . get ( resource_path , query : options ) def resource_key resource_path unless resource_key . nil? response [ resource_key . to_s ] new . all ( options )", "commit_type": "add"}
{"commit_tokens": ["Remove", "shoulda", "-", "matchers", "dependency"], "add_tokens": "describe \".default_fallbacks\" do it \"delegates to config\" do fallbacks = double ( \"fallbacks\" ) expect ( Mobility . config ) . to receive ( :default_fallbacks ) . and_return ( fallbacks ) expect ( Mobility . default_fallbacks ) . to eq ( fallbacks ) end end", "del_tokens": "it { should delegate_method ( :default_fallbacks ) . to ( :config ) }", "commit_type": "remove"}
{"commit_tokens": ["Change", "the", "imperial", "units", "for", "weight", "from", "using", "ounces", "to", "pounds"], "add_tokens": "@weight = attribute_from_metric_or_imperial ( grams_or_ounces , Mass , :grams , :pounds )", "del_tokens": "@weight = attribute_from_metric_or_imperial ( grams_or_ounces , Mass , :grams , :ounces )", "commit_type": "change"}
{"commit_tokens": ["Fix", "rental", "agreements", "create", "methods", "."], "add_tokens": "# List rental agreements. # Returns rental agreements for the rentals of the account # user is authenticated with. # Create a new rental agreement for a booking. # @param booking [BookingSync::API::Resource|Integer] Booking or ID of # the booking for which rental agreement will be created. # @param options [Hash] Rental agreement's attributes. # @return [BookingSync::API::Resource] Newly created rental agreement. def create_rental_agreement_for_booking ( booking , options = { } ) post ( \"bookings/#{booking}/rental_agreements\" , rental_agreements : [ options ] ) . pop # Create a new rental agreement for a rental. # @param rental [BookingSync::API::Resource|Integer] Rental or ID of # the rental for which rental agreement will be created. # @param options [Hash] Rental agreement's attributes. # @return [BookingSync::API::Resource] Newly created rental agreement def create_rental_agreement_for_rental ( rental , options = { } ) post ( \"rentals/#{rental}/rental_agreements\" , rental_agreements : [ options ] ) . pop # Create a new rental agreement for an account. # @param options [Hash] Rental agreement's attributes. # @return [BookingSync::API::Resource] Newly created rental agreement.", "del_tokens": "# List rental agreements # Returns rental agreements for the rentals of the account user is authenticated with. # Create a new rental agreement for a booking # @param booking_id [Integer] ID of the booking # @param options [Hash] rental agreement attributes # @return [BookingSync::API::Response] Newly created rental agreement def create_rental_agreement_for_booking ( booking_id , options = { } ) post ( :rental_agreements , booking_id : booking_id , rental_agreements : [ options ] ) . pop # Create a new rental agreement for a rental # @param rental_id [Integer] ID of the rental # @param options [Hash] rental agreement attributes # @return [BookingSync::API::Response] Newly created rental agreement def create_rental_agreement_for_rental ( rental_id , options = { } ) post ( :rental_agreements , rental_id : rental_id , rental_agreements : [ options ] ) . pop # Create a new rental agreement for an account # @param options [Hash] rental agreement attributes # @return [BookingSync::API::Response] Newly created rental agreement", "commit_type": "fix"}
{"commit_tokens": ["Change", "default", "value", "for", "config", ".", "silence_reporting", "to", "nil", "as", "opposed", "to", "false", "so", "it", "can", "be", "overridden", "by", "the", "Raltie"], "add_tokens": "@silence_reporting = nil", "del_tokens": "@silence_reporting = false", "commit_type": "change"}
{"commit_tokens": ["move", "wait", "functions", "out", "to", "module", "."], "add_tokens": "module Filterable", "del_tokens": "module Filtering", "commit_type": "move"}
{"commit_tokens": ["Implement", "url", "for", "Hoptoad", "backend"], "add_tokens": "# config.subdomain = 'your_hoptoad_subdomain' attr_accessor :secure , :api_key , :subdomain end def self . url \"http://#{subdomain}.hoptoadapp.com/\" if subdomain", "del_tokens": "attr_accessor :secure , :api_key", "commit_type": "implement"}
{"commit_tokens": ["Remove", "the", "func", "to", "pass", "arguments", "to", "methods", "on", "add_display", "."], "add_tokens": "@label = args [ 1 ] record . public_send ( @attribute_name )", "del_tokens": "if args [ 1 ] . is_a? Array @args = args [ 1 ] @label = args [ 2 ] else @args = [ ] @label = args [ 1 ] end record . public_send ( @attribute_name , * @args )", "commit_type": "remove"}
{"commit_tokens": ["Add", "test", "for", "near_id", "arXiv"], "add_tokens": "it 'gets recommendations from text' do it 'gets recommendations from text in movies' do it 'gets recommendations from text in news' do it 'gets recommendations from text in wikipedia' do it 'gets recommendations from text in pubmed' do it 'gets recommendations from text in arxiv' do it 'gets recommendations by ID in arxiv' do api = LateralRecommender :: API . new ENV [ 'API_KEY' ] , 'arxiv' VCR . use_cassette ( 'near_id_arxiv' ) do response = api . near_id 'arxiv-http://arxiv.org/abs/1403.2165' expect ( response . length ) . to eq ( 10 ) expect ( response . first [ 'title' ] ) . to include ( 'Set-valued sorting index' ) end end", "del_tokens": "it 'gets recommendations' do it 'gets recommendations from movies' do it 'gets recommendations from news' do it 'gets recommendations from wikipedia' do it 'gets recommendations from pubmed' do it 'gets recommendations from arxiv' do", "commit_type": "add"}
{"commit_tokens": ["Change", "example", "to", "use", "cli", "exec"], "add_tokens": "require 'pathname' cli = Pathname . new ( 'examples/cli.rb' ) out , _ = cmd . run ( cli , :in => stdin )", "del_tokens": "out , _ = cmd . run ( :cat , :in => stdin )", "commit_type": "change"}
{"commit_tokens": ["Implement", "#title", "and", "#member_name", "add", "spec"], "add_tokens": "lazy_attr_reader ( :member_name ) { at! ( '.profile_area a' ) [ 'title' ] } lazy_attr_reader ( :title ) { at! ( 'h1.title' ) . inner_text }", "del_tokens": "lazy_attr_reader ( :member_name ) { raise NotImplementError . new ( 'XXX' ) } lazy_attr_reader ( :title ) { raise NotImplementError . new ( 'XXX' ) }", "commit_type": "implement"}
{"commit_tokens": ["Update", "post", "-", "installation", "instructions", "."], "add_tokens": "puts 'You have chosen wisely.'", "del_tokens": "puts 'Thank you for installing Brocade. You can visit http://github.com/airblade/brocade to read the documentation.'", "commit_type": "update"}
{"commit_tokens": ["Allow", "extra", "javascript", "to", "be", "provided", "on", "chart", "initialization"], "add_tokens": "attr_reader :titles , :labels , :graphs , :legends , :data , :settings , :listeners , :legend_div , :export , :functions @functions = [ ] def call_function ( fn ) @functions << fn end", "del_tokens": "attr_reader :titles , :labels , :graphs , :legends , :data , :settings , :listeners , :legend_div , :export", "commit_type": "allow"}
{"commit_tokens": ["Changed", "the", "format", "of", "the", "cassettes", ".", "Use", "a", "VCR", "structured", "object", "rather", "than", "a", "Net", "::", "HTTP", "response", "as", "that", "is", "tied", "directly", "to", "net", "/", "http", "and", "I", "hope", "to", "get", "this", "to", "work", "with", "other", "http", "libraries", "eventually", "."], "add_tokens": "require 'vcr/structs'", "del_tokens": "require 'vcr/recorded_response'", "commit_type": "change"}
{"commit_tokens": ["Add", "some", "documentation", "about", "programmatic", "usage", "."], "add_tokens": "require \"forwardable\" # Allow use of `Stackup.stacks` rather than `Stackup().stacks` # module Stackup class << self def service ( client = { } ) Stackup :: Service . new ( client ) end extend Forwardable def_delegators :service , :stack , :stack_names end end def Stackup ( * args ) Stackup . service ( * args )", "del_tokens": "def Stackup ( client = { } ) Stackup :: Service . new ( client )", "commit_type": "add"}
{"commit_tokens": ["Added", "tdiff_recursive", "for", "only", "recursively", "traversing", "and", "diffing", "children", "nodes", "."], "add_tokens": "yield ' ' , self tdiff_recursive ( tree , & block ) return self end protected # # Recursively compares the differences between the children nodes. # # @param [#tdiff_each_child] tree # The other tree. # # @yield [change, node] # The given block will be passed the added or removed nodes. # # @yieldparam [' ', '+', '-'] change # The state-change of the node. # # @yieldparam [Object] node # A node from one of the two trees. # # @since 0.3.2 # def tdiff_recursive ( tree , & block ) unchanged . each { | x , y | x . tdiff_recursive ( y , & block ) }", "del_tokens": "unchanged . each { | x , y | x . tdiff ( y , & block ) } return self", "commit_type": "add"}
{"commit_tokens": ["Fixed", "few", "style", "issues", "."], "add_tokens": "cli . files . each do | filename |", "del_tokens": "# Scan directories recursively for markdown files. cli . cli_arguments . each_with_index do | filename , index | if Dir . exist? ( filename ) cli . cli_arguments [ index ] = Dir [ \"#{filename}/**/*.md\" ] end end cli . cli_arguments . flatten! cli . cli_arguments . each do | filename |", "commit_type": "fix"}
{"commit_tokens": ["updated", "tests", "for", "belongs_to", "attributes"], "add_tokens": "it \"the latest audit should be the audit we want to rollback\" do it \"the latest audit after a rollback should contain the changed values\" do describe \"#rollback belongs_to attribute\" do before do class Car < ActiveRecord :: Base audit_enabled belongs_to :auto_maker end class AutoMaker < ActiveRecord :: Base has_many :cars end @automaker = AutoMaker . create ( :name => 'maker of fast cars' ) @new_automaker = AutoMaker . create ( :name => 'maker of safe cars' ) @car = Car . create ( :name => 'fast car' , :auto_maker => @automaker ) @car . update_attributes ( :auto_maker => @new_automaker ) @audit = @car . audits . first end it \"the latest audit should be the audit we want to rollback\" do @audit . action . should == 'updated' @audit . new_value . should == @new_automaker . id @audit . old_value . should == @automaker . id @audit . association . should == nil @car . auto_maker . should == @new_automaker end it \"performs the rollback\" do @audit . rollback @car . reload @car . auto_maker . should == @automaker end it \"creates an audit when a rollback is performed\" do lambda { @audit . rollback } . should change { Audit . count } . by ( 1 ) end it \"the latest audit after a rollback should contain the changed values\" do @audit . rollback @car . reload @car . audits . first . old_value . should == @new_automaker . id @car . audits . first . new_value . should == @automaker . id end end", "del_tokens": "it \"the first audit should be the audit we want to rollback\" do it \"the first audit after a rollback should contain the changed values\" do", "commit_type": "update"}
{"commit_tokens": ["Make", "the", "edit", "support", "to", "the", "scope", "."], "add_tokens": "target_params = key_params target_params = target_params . merge ( scope_params ) if @dynamic_scaffold . scope @record = @dynamic_scaffold . model . find_by ( target_params ) raise ActiveRecord :: RecordNotFound if @record . nil? update_params = record_params target_params = extract_pkeys ( update_params ) target_params = target_params . merge ( scope_params ) if @dynamic_scaffold . scope @record = @dynamic_scaffold . model . find_by ( target_params ) @record . attributes = update_params def extract_pkeys ( values ) [ * @dynamic_scaffold . model . primary_key ] . each_with_object ( { } ) { | col , res | res [ col ] = values [ col ] } end", "del_tokens": "@record = @dynamic_scaffold . model . find_by ( key_params ) rec_params = record_params ar = @dynamic_scaffold . model . all [ * @dynamic_scaffold . model . primary_key ] . each do | pkey | ar = ar . where ( pkey => rec_params [ pkey ] ) end @record = ar . first @record . attributes = rec_params", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "to", "other", "log", "mechanisms", "on", "LogNotes"], "add_tokens": "filename = if RAILS_DEFAULT_LOGGER . instance_variable_get ( '@log' ) RAILS_DEFAULT_LOGGER . instance_variable_get ( '@log' ) . path else RAILS_DEFAULT_LOGGER . instance_variable_get ( '@logdev' ) . filename end file_string = File . open ( filename ) . read . to_s", "del_tokens": "file_string = File . open ( RAILS_DEFAULT_LOGGER . instance_variable_get ( '@log' ) . path ) . read . to_s", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "to", "expel", "run", "variables", "as", "csv"], "add_tokens": "VERSION = \"0.0.4\"", "del_tokens": "VERSION = \"0.0.3\"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "the", "@config", "was", "improperly", "set", "."], "add_tokens": "@config , @config [ :email ] , @config [ :password ] = options , email , password end", "del_tokens": "@config , @config [ :email ] , @config [ :password ] = { } , email , password end", "commit_type": "fix"}
{"commit_tokens": ["Implement", "Polisher", "::", "Gem#from_rubygems", "/", "flush", "out", "gem", "/", "diff", "comparison"], "add_tokens": "# Download the specified gem / version from rubygems and # return instance of Polisher::Gem class corresponding to it def self . from_rubygems ( name , version ) download_gem name , version self . from_gem downloaded_gem_path ( name , version ) end def self . downloaded_gem_path ( name , version ) self . download_gem ( name , version ) GemCache . path_for ( name , version ) end # Return path to downloaded gem def downloaded_gem_path self . class . downloaded_gem_path @name , @version other_dir = other . is_a? ( Polisher :: Gem ) ? other . unpack : ( other . is_a? ( Polisher :: Git :: Repo ) ? other . path : other )", "del_tokens": "def downloaded_gem_path self . download_gem GemCache . path_for ( @name , @version ) other_dir = other . is_a? ( Polisher :: Gem ) ? other . unpack : other", "commit_type": "implement"}
{"commit_tokens": ["Use", "StringIO", "instead", "of", "Tempfile", "for", "testing"], "add_tokens": "@ostream = StringIO . new @istream = StringIO . new", "del_tokens": "@ostream = Tempfile . new 'rubikon_test_ostream' @istream = Tempfile . new 'rubikon_test_istream' @istream . delete teardown do @ostream . delete end", "commit_type": "use"}
{"commit_tokens": ["update", "README", "and", "rm", "and", "ignore", "output", "files"], "add_tokens": "require \"lono-params\" template_name = options [ :template ] || @stack_name params_name = options [ :params ] || template_name @template_path = get_source_path ( template_name , :template ) @params_path = get_source_path ( params_name , :params ) puts \"Using template: #{@template_path}\" puts \"Using parameters: #{@params_path}\" check_for_errors def generate_params generator = LonoParams :: Generator . new ( @stack_name , project_root : @project_root , path : @params_path , allow_blank : true ) generator . generate # Writes the json file in CamelCase keys format generator . params # Returns Array in underscore keys format end errors << \"Template file missing: could not find #{@template_path}\" if @options [ :params ] && ! File . exist? ( @params_path ) errors << \"Parameters file missing: could not find #{@params_path}\" return default_convention_path if path . nil? convention_path ( path , type )", "del_tokens": "# hack require until I gemify lono-params puts \"REMEMBER TO PACKAGE LONO-PARAMS AS GEM\" @template_path = get_source_path ( options [ :template ] , :template ) @params_path = get_source_path ( options [ :params ] , :params ) check_for_errors puts \"Using template: #{@template_path}\" puts \"Using parameters: #{@params_path}\" def generate_params generator = LonoParams :: Generator . new ( @stack_name , project_root : @project_root , path : @params_path ) generator . generate # Writes the json file in CamelCase keys format generator . params # Returns Array in underscore keys format end errors << \"Template file missing: could not find output/#{@template_path}.json\" unless File . exist? ( @params_path ) errors << \"Parameters file missing: could not find params/#{@params_path}.txt\" return default_convention_path if path . nil? convention_path = convention_path ( path , type ) File . exist? ( convention_path ) ? convention_path : path", "commit_type": "update"}
{"commit_tokens": ["Fix", "Gem", ".", "source_index", "issue"], "add_tokens": "begin Gem . source_index rescue NoMethodError Gem :: Specification . all end", "del_tokens": "Gem . source_index", "commit_type": "fix"}
{"commit_tokens": ["Make", "expectations", "more", "explicit", "update", "log", "."], "add_tokens": "Dir . stub! ( :tmpdir ) . and_return ( '/tmp' ) @git . should_receive ( :system ) . with ( \"cd /tmp; git clone http://localhost/ example\" ) . ordered @git . should_receive ( :system ) . with ( \"cd /tmp/example; git submodule init && git submodule update\" ) . ordered", "del_tokens": "@git . should_receive ( :system ) . with ( \"cd #{Dir.tmpdir}; #{@git.checkout_command}\" ) . ordered @git . should_receive ( :system ) . with ( / git submodule init && git submodule update / ) . ordered", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "call", "next_page", "on", "device", "listing", "."], "add_tokens": "List . new ( Dirigible . get ( '/device_tokens' ) ) List . new ( Dirigible . get ( '/apids' ) ) List . new ( Dirigible . get ( '/device_pins' ) ) class List def initialize ( response ) @response = response end def [] ( value ) @response [ value ] end # Fetch the next page for this device listing. Returns # nil if next_page is nil. def next_page return nil if @response [ :next_page ] . nil? uri = URI . parse ( @response [ :next_page ] ) path = \"/#{uri.path.gsub(/\\/api|\\//, '')}\" params = CGI . parse ( uri . query ) List . new ( Dirigible . get ( path , params ) ) end end", "del_tokens": "Dirigible . get ( '/device_tokens' ) Dirigible . get ( '/apids' ) Dirigible . get ( '/device_pins' )", "commit_type": "add"}
{"commit_tokens": ["Remove", "deprecated", "analytics", "option", "for", "kit", "endpoints"], "add_tokens": "attr_accessor :name , :domains , :families , :badge @@defaults = { :badge => false } lazy_load :name , :badge , :domains , :families attributes = [ :name , :badge , :domains ] . inject ( { } ) { | attributes , x | attributes [ x ] = instance_variable_get ( \"@#{x}\" ) ; attributes }", "del_tokens": "attr_accessor :name , :domains , :families , :analytics , :badge @@defaults = { :analytics => false , :badge => false } # @option params [Boolean] :analytics (false) Allow Typekit to collect kit-usage data via Google Analytics lazy_load :name , :analytics , :badge , :domains , :families attributes = [ :name , :analytics , :badge , :domains ] . inject ( { } ) { | attributes , x | attributes [ x ] = instance_variable_get ( \"@#{x}\" ) ; attributes }", "commit_type": "remove"}
{"commit_tokens": ["Add", "map", "test", "specs", "for", "video", "support", "on", "the", "string", "render"], "add_tokens": "# Format and image tag specifications found at http://support.google.com/webmasters/bin/answer.py?hl=en&answer=178636 # Format and video tag specifications found at http://support.google.com/webmasters/bin/answer.py?hl=en&answer=80472&topic=10079&ctx=topic#2 if item . video_thumbnail_location && item . video_title && item . video_description && ( item . video_content_location || item . video_player_location ) item_string << \" <video:duration>#{CGI::escapeHTML(item.video_duration.to_s)}</video:duration>\\n\" if item . video_duration item_string << \" <video:rating>#{CGI::escapeHTML(item.video_rating.to_s)}</video:rating>\\n\" if item . video_rating item_string << \" <video:view_count>#{CGI::escapeHTML(item.video_view_count.to_s)}</video:view_count>\\n\" if item . video_view_count item_string << \" <video:restriction relationship=\\\"allow\\\">#{CGI::escapeHTML(item.video_restriction)}</video:restriction>\\n\" if item . video_restriction item_string << \" <video:price currency=\\\"USD\\\">#{CGI::escapeHTML(item.video_price.to_s)}</video:price>\\n\" if item . video_price item_string << \" <video:platform relationship=\\\"allow\\\">#{CGI::escapeHTML(item.video_platform)}</video:platform>\\n\" if item . video_platform", "del_tokens": "# Format and image tag specifications found in http://support.google.com/webmasters/bin/answer.py?hl=en&answer=178636 if item . video_thumbnail_location && item . video_title && item . video_description item_string << \" <video:duration>#{CGI::escapeHTML(item.video_duration)}</video:duration>\\n\" if item . video_duration item_string << \" <video:rating>#{CGI::escapeHTML(item.video_rating)}</video:rating>\\n\" if item . video_rating item_string << \" <video:view_count>#{CGI::escapeHTML(item.video_view_count)}</video:view_count>\\n\" if item . video_view_count item_string << \" <video:restriction>#{CGI::escapeHTML(item.video_restriction)}</video:restriction>\\n\" if item . video_restriction item_string << \" <video:price>#{CGI::escapeHTML(item.video_price)}</video:price>\\n\" if item . video_price item_string << \" <video:platform>#{CGI::escapeHTML(item.video_platform)}</video:platform>\\n\" if item . video_platform", "commit_type": "add"}
{"commit_tokens": ["Make", "with_environment", "/", "with_data_bag", "with", "no", "args", "apply", "to", "*", "everything", "*", "after", "them"], "add_tokens": "if block begin block . call ensure Cheffish . enclosing_data_bag = old_enclosing_data_bag end if block begin block . call ensure Cheffish . enclosing_environment = old_enclosing_environment end", "del_tokens": "begin block . call if block ensure Cheffish . enclosing_data_bag = old_enclosing_data_bag begin block . call if block ensure Cheffish . enclosing_environment = old_enclosing_environment", "commit_type": "make"}
{"commit_tokens": ["use", "the", "correct", "Namespace", "class", "in", "Model", "module"], "add_tokens": "items extend : NamespaceResourceJSON , class : OpenBEL :: Model :: Namespace items extend : NamespaceResourceXML , class : OpenBEL :: Model :: Namespace items extend : NamespaceResourceHTML , class : OpenBEL :: Model :: Namespace", "del_tokens": "items extend : NamespaceResourceJSON , class : OpenBEL :: Namespace :: Namespace items extend : NamespaceResourceXML , class : OpenBEL :: Namespace :: Namespace items extend : NamespaceResourceHTML , class : OpenBEL :: Namespace :: Namespace", "commit_type": "use"}
{"commit_tokens": ["updated", "documentaion", "to", "include", "google", "client"], "add_tokens": "uri = @google_client . webserver_authorization_url ( :scope => 'https://www.googleapis.com/auth/userinfo.email' , :state => '/profile' , :redirect_uri => 'https://oauth2-login-demo.appspot.com/code' , :approval_prompt => 'force' ) puts uri uri = @google_client . clientside_authorization_url ( :scope => 'https://www.googleapis.com/auth/userinfo.email' , :state => '/profile' , :redirect_uri => 'https://oauth2-login-demo.appspot.com/token' , :approval_prompt => 'force' ) puts uri", "del_tokens": "uri = @google_client . webserver_authorization_url ( params ) uri = @google_client . clientside_authorization_url ( params )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "selecting", "tagged", "regions", "(", "attribute", "tags", ")"], "add_tokens": "require 'asciidoctor/include_ext/tag_lines_selector' def initialize ( selectors : [ LinenoLinesSelector , TagLinesSelector ] ,", "del_tokens": "def initialize ( selectors : [ LinenoLinesSelector ] ,", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "new", "test", "case", "wherein", "we", "have", "a", "table", "with", "no", "auto", "-", "incremented", "primary", "key", ".", "Fix", "bug", "in", "adapter", "code", "that", "looks", "up", "PK", "based", "on", "the", "SQL", "when", "it", "should", "be", "passing", "the", "table", "name"], "add_tokens": "( @connection . execute_insert ( sql ) or last_insert_id ( _table_name_from_insert ( sql ) ) ) . to_i", "del_tokens": "( @connection . execute_insert ( sql ) or last_insert_id ( sql ) ) . to_i", "commit_type": "create"}
{"commit_tokens": ["added", ":", "represent_with", "and", ":", "represent_items_with", "to", "implement", "the", "new", "API", ".", "started", "deprecating", "old", "API", "."], "add_tokens": "class_name = model . class . name \"#{class_name}Representer\" . constantize # DISCUSS: why THE FUCK is options not passed as a method argument but kept as an internal instance variable in the responder? this is something i will never understand about Rails. def display ( model , * args ) if representer = options . delete ( :represent_with ) # this is the new behaviour. model . extend ( representer ) # FIXME: move to method. return super end representer = options . delete ( :with_representer ) and ActiveSupport :: Deprecation . warn ( \":with_representer is deprecated and will be removed in roar-rails 1.0. Use :represent_with or :represent_items_with.\" ) representer ||= options . delete ( :represent_items_with ) # new API.", "del_tokens": "( model . class . name + \"Representer\" ) . constantize def display ( model , given_options = { } ) # TODO: remove the [] semantics, this should be done with a Collection representer. representer = options . delete ( :with_representer )", "commit_type": "add"}
{"commit_tokens": ["added", "readme", "tools", "and", "example"], "add_tokens": "logger . level = Logger :: ERROR", "del_tokens": "logger . level = Logger :: INFO", "commit_type": "add"}
{"commit_tokens": ["fix", "improper", "encoding", "of", "packed", "info"], "add_tokens": "buf . append_info ( fld . fn , Buffer . wire_for ( fld . type ) )", "del_tokens": "buf . append_info ( Buffer . wire_for ( fld . type ) , fld . fn )", "commit_type": "fix"}
{"commit_tokens": ["Make", "logging", "an", "option", ".", "Logging", "is", "turned", "on", "by", "default", "."], "add_tokens": "app = application app = Rack :: Session :: Cookie . new ( app ) if Sinatra . options . sessions == true app = Rack :: CommonLogger . new ( app ) if Sinatra . options . logging == true :logging => true ,", "del_tokens": "app = if Sinatra . options . sessions == true Rack :: Session :: Cookie . new ( application ) else application end Rack :: CommonLogger . new ( app )", "commit_type": "make"}
{"commit_tokens": ["Made", "syntax", "more", "stringent", "."], "add_tokens": "Console . log ( \" Your AppDelegate (usually in app_delegate.rb) needs an on_load(options) method.\" , withColor : Console :: RED_COLOR ) unless self . respond_to? ( :on_load )", "del_tokens": "Console . log ( \" Your AppDelegate (usually in app_delegate.rb) needs an on_load(options) method.\" , withColor : Console :: RED_COLOR ) unless self . respond_to? :on_load", "commit_type": "make"}
{"commit_tokens": ["Make", "jar", "-", "dependencies", "a", "non", "-", "runtime", "dependency"], "add_tokens": "VERSION = '0.18.1'", "del_tokens": "VERSION = '0.18.0'", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "viewing", "one", "day"], "add_tokens": ":event_margin => 2 , :link_to_day => false if options [ :link_to_day ] cal << \"<td #{cell_attrs}>#{day_link(cell_text, cur)}</td>\" else cal << \"<td #{cell_attrs}>#{cell_text}</td>\" end def day_link ( text , date ) link_to ( text , \"/calendar/#{date.year}/#{date.month}/#{date.day}\" end", "del_tokens": ":event_margin => 2 cal << \"<td #{cell_attrs}>#{cell_text}</td>\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "blocks", "in", "elements", "example", "to", "not", "take", "the", "row", "parameter"], "add_tokens": "elements :list , 'ul.list' , 'li' do element :title , '.title' element :details , '.details'", "del_tokens": "elements :list , 'ul.list' , 'li' do | row | row . element :title , '.title' row . element :details , '.details'", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", ":", "name", "=", ">", "str", "in", "attributes"], "add_tokens": "attr . attributes :name => \"Contact\" do", "del_tokens": "attr . attributes \"Contact\" do", "commit_type": "add"}
{"commit_tokens": ["make", "default", "password", "in", "header", "message"], "add_tokens": "has_field 4 , :access_password", "del_tokens": "has_field 4 , :access_password , :default => \"PASSWORD\"", "commit_type": "make"}
{"commit_tokens": ["Improve", "documentation", "comments", "for", "#attribute"], "add_tokens": "# @option options [Symbol,Object] :value If it's Symbol, then it's used as either name of hash key to use on attribute # (if it's hash) or method name to call on attribute. Otherwise it's used as value to use instead of # actual attribute's. # @option options [Symbol,false,nil] :format (nil) Type of formatter to use to display attribute's value. If it's false, # then don't format at all (just call #to_s). If it's nil, then use default formatting (#l for dates, # #number_with_precision/#number_with_delimiter for floats/integers). If it's Symbol, then use it to select # view helper method and pass aattribute's value to it to format. # @example # <%= attr.attribute :avatar, :value => :url, :format => :image_tag %> #", "del_tokens": "# @option options [String] :value Value of attribute entry, overrides default value from record. If it's a symbol it's used a the hash key or method depending on the type of the attribute.", "commit_type": "improve"}
{"commit_tokens": ["Fix", "support", "for", "a", "file", "input", "which", "is", "not", "filled", "in", "."], "add_tokens": "if input [ 'value' ] . to_s . any? if multipart? agg << [ input [ 'name' ] . to_s , Rack :: Test :: UploadedFile . new ( input [ 'value' ] . to_s ) ] else agg << [ input [ 'name' ] . to_s , File . basename ( input [ 'value' ] . to_s ) ] end", "del_tokens": "if multipart? agg << [ input [ 'name' ] . to_s , Rack :: Test :: UploadedFile . new ( input [ 'value' ] . to_s ) ] else agg << [ input [ 'name' ] . to_s , File . basename ( input [ 'value' ] . to_s ) ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "CURIE", "for", "post_type", "previously", "missing"], "add_tokens": "\"https://api.w.org/featuredmedia\" => \"wp:featuredmedia\" , \"http://api.w.org/v2/post_type\" => \"wp:post_type\"", "del_tokens": "\"https://api.w.org/featuredmedia\" => \"wp:featuredmedia\"", "commit_type": "add"}
{"commit_tokens": ["Make", "HowBad", "::", "Fetcher#call", "have", "a", "stricter", "contract", "."], "add_tokens": "Contract String , C :: RespondTo [ :issues , :pulls ] => { issues : C :: ArrayOf [ Hash ] , pulls : C :: ArrayOf [ Hash ] }", "del_tokens": "Contract String , C :: Any => { issues : C :: Not [ nil ] , pulls : C :: Not [ nil ] }", "commit_type": "make"}
{"commit_tokens": ["Removing", "old", "objects", "from", "indexes", "so", "they", "do", "not", "appear", "in", "queries", "erroneously"], "add_tokens": "define_attribute_methods ( self . attributes . keys ) # Write an attribute on the object. Also marks the previous value as dirty. self . send ( \"#{name}_will_change!\" . to_sym ) unless self . read_attribute ( name ) == value", "del_tokens": "# Write an attribute on the object.", "commit_type": "remove"}
{"commit_tokens": ["remove", "has_callback?", "and", "assume", "it", "will", "response", "to", "call"], "add_tokens": "option . callback . call ( option . argument_value ) if option . callback option . callback . call ( nil ) if option . callback elsif option . callback", "del_tokens": "option . callback . call ( option . argument_value ) if option . has_callback? option . callback . call ( nil ) if option . has_callback? elsif option . has_callback?", "commit_type": "remove"}
{"commit_tokens": ["added", "uniq", "and", "map", "option", "to", "column"], "add_tokens": "puts \"AAAAAAAAAA scope=#{scope.to_sql}\" def models scope = self . scope t . arity == 2 ? t . call ( scope , self ) : t . call ( scope )", "del_tokens": "def models _scope = self . scope t . arity == 2 ? t . call ( _scope , self ) : t . call ( _scope )", "commit_type": "add"}
{"commit_tokens": ["Added", "caboose", "command", "line", "helper"], "add_tokens": "VERSION = \"0.1.8\"", "del_tokens": "VERSION = \"0.1.7\"", "commit_type": "add"}
{"commit_tokens": ["Remove", "bundler", "and", "add", "very", "basic", "support", "for", "manually", "vendored", "libs"], "add_tokens": "# Add any vendored libraries into search path Dir . glob ( File . join ( File . dirname ( __FILE__ ) , '../../vendor/*' ) ) . each do | f | $: . unshift File . join ( f , 'lib' ) end", "del_tokens": "require \"bundler/setup\"", "commit_type": "remove"}
{"commit_tokens": ["add", "rel", "-", "urls", "and", "switch", "to", "microformats", "test", "suite"], "add_tokens": "@rel_urls = { } hash = { items : [ ] , rels : @rels , 'rel-urls' : @rel_urls }", "del_tokens": "hash = { items : [ ] } #unless @rels.empty? hash [ :rels ] = @rels #end", "commit_type": "add"}
{"commit_tokens": ["Make", "error", "messages", "the", "same", "when", "key", "is", "missing"], "add_tokens": "", "del_tokens": "def test_init # Store.init end", "commit_type": "make"}
{"commit_tokens": ["upgrade", "to", "webpack2", "add", "scss", "postcss", "support"], "add_tokens": "VERSION = \"2.3.0\"", "del_tokens": "VERSION = \"2.2.1\"", "commit_type": "upgrade"}
{"commit_tokens": ["moves", "DSL", "to", "respective", "classes", "and", "removes", "DSL", "module", "also", "starts", "on", "app", "start", "function"], "add_tokens": "def for_context context # TODO need to see if this works, a it's based on pure JS [ Context . collection [ @current_context ] . handlers [ route [ :handle ] ] ] . flatten . ( & :call , match , url )", "del_tokens": "def using_context context Context . collection [ @current_context ] . handlers [ route [ :handle ] ] . call match , url", "commit_type": "move"}
{"commit_tokens": ["Implement", "case", "when", "owner", "was", "not", "changed"], "add_tokens": "time = owner . logidze_requested_ts", "del_tokens": "time = owner . log_data . current_version . time", "commit_type": "implement"}
{"commit_tokens": ["Use", "the", "apache", "mirror", "selector", "to", "choose", "an", "appropriate", "download", "mirror"], "add_tokens": "require 'json' @default_url ||= begin mirror_url = \"http://www.apache.org/dyn/closer.cgi/lucene/solr/#{version}/solr-#{version}.zip?asjson=true\" json = open ( mirror_url ) . read doc = JSON . parse ( json ) doc [ 'preferred' ] + doc [ 'path_info' ] end", "del_tokens": "\"http://mirrors.ibiblio.org/apache/lucene/solr/#{version}/solr-#{version}.zip\"", "commit_type": "use"}
{"commit_tokens": ["Add", "annotation", "test", "cases", "."], "add_tokens": "def test_exposure_annotation exp = CaTissue :: Participant :: Clinical :: EnvironmentalExposuresHealthAnnotation . new exp . merge_attributes ( :years_agent_free => 2 , :participant => @pnt ) exps = @pnt . clinical . environmental_exposures_health_annotations assert_not_nil ( exps . first , \"Exposures not added to participant annotations\" ) assert_same ( exp , exps . first , \"Exposures incorrect\" ) assert_same ( @pnt , exp . hook , \"Exposure proxy hook not set\" ) end def test_alcohol_annotation alc = CaTissue :: Participant :: Clinical :: AlcoholHealthAnnotation . new alc . merge_attributes ( :drinks_per_week => 4 , :years_agent_free => 2 , :participant => @pnt ) alcs = @pnt . clinical . alcohol_health_annotations assert_not_nil ( alcs . first , \"Alcohol health not added to participant annotations\" ) assert_same ( alc , alcs . first , \"Alcohol health incorrect\" ) assert_same ( @pnt , alc . hook , \"Alcohol health proxy hook not set\" ) exps = @pnt . clinical . environmental_exposures_health_annotations assert ( ! exps . include? ( alc ) , \"Alcohol health redundantly added to exposure annotations\" ) end labs = @pnt . clinical . lab_annotations labs = @pnt . clinical . lab_annotations assert_same ( @pnt , lab . hook , \"Lab proxy hook not set\" )", "del_tokens": "labs = @pnt . lab_annotations labs = @pnt . lab_annotations assert_same ( @pnt , lab . owner , \"Lab proxy hook not set\" )", "commit_type": "add"}
{"commit_tokens": ["fix", "stack_exists?", "query", "for", "both", "sdks"], "add_tokens": "def stack_exists? ( * ) raise NotImplementedError , 'Implemented in subclass'", "del_tokens": "def stack_exists? ( stack ) base_module :: CloudFormation . stacks [ stack . name ] . exists?", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "keep", "only", "latest", "version"], "add_tokens": "return [ available . last ] if gem . only_latest? satisfied = if gem . only_latest? true else gem . requirement . satisfied_by? ( version ) end satisfied = if gem . only_latest? true else gem . requirement . satisfied_by? ( version ) end", "del_tokens": "satisfied = gem . requirement . satisfied_by? ( version ) satisfied = gem . requirement . satisfied_by? ( version )", "commit_type": "allow"}
{"commit_tokens": ["Added", "ability", "for", "model", "names", "to", "appear", "in", "field", "definititions", "."], "add_tokens": "def parse_field_with_model ( field ) if field =~ / ^( \\w +): ( #{ Match :: Model } )$ / { $1 => model ( $2 ) } else parse_field_without_model ( field ) end end alias_method_chain :parse_field , :model store_record ( canonical ( record . class . name ) , name , record ) if canonical ( record . class . name ) != factory", "del_tokens": "store_record ( pickle_name ( record . class . name ) , name , record ) if pickle_name ( record . class . name ) != factory", "commit_type": "add"}
{"commit_tokens": ["add", "readme", "for", "tests", "and", "version", "bump"], "add_tokens": "VERSION = \"0.5.3\"", "del_tokens": "VERSION = \"0.5.2\"", "commit_type": "add"}
{"commit_tokens": ["Move", "responder", "to", "action_controller", "folder", "which", "is", "more", "suitable"], "add_tokens": "autoload :Responder , 'action_controller/responder'", "del_tokens": "autoload :Responder , 'wechat/responder'", "commit_type": "move"}
{"commit_tokens": ["Made", "RUBY_CC_VERSION", "stick", "to", ":", "instead"], "add_tokens": "ruby_vers = ENV [ 'RUBY_CC_VERSION' ] . split ( ':' )", "del_tokens": "ruby_vers = ENV [ 'RUBY_CC_VERSION' ] . split ( File :: PATH_SEPARATOR )", "commit_type": "make"}
{"commit_tokens": ["Adds", "build", "class", "method", "to", "Commands", "."], "add_tokens": "raise ArgumentError , @request . full_error_messages self . build ( request , * args ) . call end def self . build ( request , * args ) self . new ( request , * args )", "del_tokens": "raise ArgumentError , @request . errors . full_messages . join ( '. ' ) self . new ( request , * args ) . call", "commit_type": "add"}
{"commit_tokens": ["Use", "after_destroy", "to", "trigger", "model", "changes"], "add_tokens": "after_destroy :notify_destroy", "del_tokens": "before_destroy :notify_destroy", "commit_type": "use"}
{"commit_tokens": ["Allow", "private", "key", "to", "be", "passed", "as", "a", "Base64", "string"], "add_tokens": "if encoded_key = Gxapi . config . google . private_key key = OpenSSL :: PKey :: RSA . new Base64 . decode64 ( encoded_key ) , 'notasecret' else key = Google :: APIClient :: KeyUtils . load_from_pkcs12 ( Gxapi . config . google . private_key_path , 'notasecret' ) end", "del_tokens": "key = Google :: APIClient :: KeyUtils . load_from_pkcs12 ( Gxapi . config . google . private_key_path , 'notasecret' )", "commit_type": "allow"}
{"commit_tokens": ["fix", "admin", "page", "and", "add", "reprocess", "method"], "add_tokens": "# Reprocess Invoice and update order status # def refresh payment = Spree :: Payment . find ( params [ :payment ] ) # Retrieve payment by ID invoice = payment . source . find_invoice # Get associated invoice process_invoice ( invoice ) # Re-process invoice redirect_to request . referrer , notice : Spree . t ( :bitpay_payment_updated ) end # Call Bitpay API and return new JSON invoice object # # Accepts BitPay JSON invoice object #", "del_tokens": "# # Returns the PaymentMethod object # def bitpay(pmid) # pm = Spree::PaymentMethod.find(pmid) # if !(pm.is_a? Spree::PaymentMethod::Bitpay) # raise \"Not a BitPay payment type\" # end # pm # end", "commit_type": "fix"}
{"commit_tokens": ["fixed", "some", "very", "odd", "code", "...", "I", "wonder", "if", "I", "ve", "broken", "something", "though", "..."], "add_tokens": "@bbtree_current_node = @bbtree_current_node [ :nodes ] . last if @bbtree_depth > 0", "del_tokens": "@bbtree_depth . times { @bbtree_current_node = @bbtree_current_node [ :nodes ] . last } # FIXME: fuck... I wonder what this shit's about... I think I need @bbtree[:nodes] to actually be a hash... but contain BBTree elements??...", "commit_type": "fix"}
{"commit_tokens": ["Adds", "capability", "of", "wrapping", "slides", "with", "DZSlides", "template"], "add_tokens": "def self . convert ( template_file , presentation_file ) Prezio :: Converter . convert ( template_file , presentation_file ) end end Dir [ File . expand_path ( \"../**/*.rb\" , __FILE__ ) ] . each do | file | require file", "del_tokens": "require \"prezio/version\" # Your code goes here...", "commit_type": "add"}
{"commit_tokens": ["add", "five", "methods", "(", "Xyml_element", "::", "gdn", "gdfn", "gdna", "gda", "gdfna", ")"], "add_tokens": "VERSION = \"0.0.2\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "the", "file_field", "spec", "(", "for", "Watir", ")"], "add_tokens": "path = File . expand_path ( __FILE__ ) browser . file_field ( :name , \"new_user_portrait\" ) . set path browser . file_field ( :name , \"new_user_portrait\" ) . value . should == path messages . first . should == path", "del_tokens": "browser . file_field ( :name , \"new_user_portrait\" ) . set ( __FILE__ ) browser . file_field ( :name , \"new_user_portrait\" ) . value . should == __FILE__ messages . first . should == __FILE__", "commit_type": "fix"}
{"commit_tokens": ["removed", "broken", "DSL", "migration", "path"], "add_tokens": "include Wongi :: Engine :: DSL puts ds . wmes . to_a puts ds . wmes . to_a", "del_tokens": "puts ds . wmes puts ds . wmes", "commit_type": "remove"}
{"commit_tokens": ["Added", "ability", "to", "send", "manual", "notifications", "."], "add_tokens": "assert HoptoadNotifier . params_filters . include? ( \"abc\" ) assert HoptoadNotifier . params_filters . include? ( \"def\" ) context \"Sending a notification without an exception\" do should \"send sensible defaults\" do sender = HoptoadNotifier :: Sender . new backtrace = caller options = HoptoadNotifier . default_notification_options . merge ( :error_message => \"123\" , :backtrace => backtrace ) HoptoadNotifier :: Sender . expects ( :new ) . returns ( sender ) sender . expects ( :inform_hoptoad ) . with ( options ) HoptoadNotifier . notify ( :error_message => \"123\" , :backtrace => backtrace ) end end", "del_tokens": "assert HoptoadNotifier . params_filters . include? \"abc\" assert HoptoadNotifier . params_filters . include? \"def\"", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "RubyFsStack", ".", "version", "method", "which", "pulls", "the", "version", "from", "the", "VERSION", "file", "(", "and", "caches", "it", "in", "memory", ")", "."], "add_tokens": "require 'ruby-fs-stack/familytree' module RubyFsStack def self . version @@version ||= File . read ( File . join ( File . dirname ( __FILE__ ) , '..' , 'VERSION' ) ) . strip end end", "del_tokens": "require 'ruby-fs-stack/familytree'", "commit_type": "add"}
{"commit_tokens": ["add", "last_response", "and", "client", "=", "method"], "add_tokens": "attr_accessor :client def client @client ||= HTTPClient . new end def last_response @res end @res = client . get ( \"#{@base_uri}#{path}\" ) handle_error ( @res ) JSON . parse ( @res . body ) @res = client . post ( \"#{@base_uri}#{path}\" , json ) handle_error ( @res ) JSON . parse ( @res . body ) @res = client . post ( \"#{@base_uri}#{path}\" , data ) handle_error ( @res ) JSON . parse ( @res . body )", "del_tokens": "res = client . get ( \"#{@base_uri}#{path}\" ) handle_error ( res ) JSON . parse ( res . body ) res = client . post ( \"#{@base_uri}#{path}\" , json ) handle_error ( res ) JSON . parse ( res . body ) res = client . post ( \"#{@base_uri}#{path}\" , data ) handle_error ( res ) JSON . parse ( res . body ) def client @client ||= HTTPClient . new end", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", ":", "serailizer", "-", ">", "serializer"], "add_tokens": "it \"supports serializer inheritance\" do", "del_tokens": "it \"supports serailizer inheritance\" do", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "stupid", "bug", "where", "all", "of", "the", "files", "were", "deleted", ".", "Doh", "."], "add_tokens": "unless @source . files . include? object . key block . call ( object ) object . destroy end", "del_tokens": "block . call ( object ) unless @source . files . include? object . key object . destroy", "commit_type": "fix"}
{"commit_tokens": ["Add", "integration", "test", "for", "config", "file", "reading"], "add_tokens": "require 'yaml' FileUtils . rm_rf File . join ( test_project_dir , '.humboldt.yml' ) FileUtils . rm_rf File . join ( test_project_dir , 'data/another_job_config/output' ) jar_entries . should include ( \"another_job_config.rb\" ) context 'Running the project jobs' do context 'Running with a project configuration' do CONFIG = { job_config : 'another_job_config' } before :all do File . open ( File . join ( test_project_dir , '.humboldt.yml' ) , 'w' ) do | f | YAML . dump ( CONFIG , f ) end isolated_run ( test_project_dir , \"bundle exec humboldt run-local --cleanup-before --skip-package --data-path=data --input='input/combined_text' 2>&1 | tee data/log\" ) end after :all do FileUtils . rm_rf File . join ( test_project_dir , '.humboldt.yml' ) end it 'uses the job config directive from the configuration file' do expect ( File . directory? ( 'data/another_job_config/output' ) ) . to be_true end end", "del_tokens": "context 'Running the project' do", "commit_type": "add"}
{"commit_tokens": ["Allow", "options", "to", "be", "required"], "add_tokens": "opts [ :required ] = false unless opts . key? :required opt name . to_sym , opts [ :description ] , type : opts [ :type ] , default : opts [ :default ] , required : opts [ :required ]", "del_tokens": "opt name . to_sym , opts [ :description ] , type : opts [ :type ] , default : opts [ :default ]", "commit_type": "allow"}
{"commit_tokens": ["Fix", "missing", "firing_match", "and", "auto_resolve_match", "fields", "on", "Trigger"], "add_tokens": "attr_accessor :enabled , :actions , :firing_match , :auto_resolve_match @firing_match = trigger_hash [ 'firingMatch' ] @auto_resolve_match = trigger_hash [ 'autoResolveMatch' ] :description , :auto_enable , :auto_disable , :context , :type , :tags , :member_of , :data_id_map , :firing_match , :auto_resolve_match ]", "del_tokens": "attr_accessor :enabled , :actions :description , :auto_enable , :auto_disable , :context , :type , :tags , :member_of , :data_id_map ]", "commit_type": "fix"}
{"commit_tokens": ["Using", "a", "constant", "instead", "of", "case", "logic"], "add_tokens": "RESPONSE_BODY_MAPPING = { :match => \" =~ \" , :not_match => \" !~ \" , :equals => \" == \" , :differs => \"!=\" } . freeze scout . response_body . send ( RESPONSE_BODY_MAPPING [ rule ] , comparison )", "del_tokens": "operator = case rule when :match \"=~\" when :not_match \"!~\" when :equals \"==\" when :differs \"!=\" end scout . response_body . send ( operator , comparison )", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "output", "issue", "."], "add_tokens": "puts \"All keys are disabled by default. Use `istats enable [key]` to enable specific keys or `istats enable all`.\"", "del_tokens": "puts \"All keys are disabled by default. Use `istats set [key]` to enable specific keys or `istats enable all`.\"", "commit_type": "fix"}
{"commit_tokens": ["Change", "order", "of", "arguments", "for", "Echochamber", "::", "Agreement", ".", "new"], "add_tokens": "# @param [Hash] params SYMBOL-referenced Hash containing: # @param [String] user_id ID of the user whom this agreement is made for # @param [String] user_email Email of the user whom this agreement is made for def initialize ( params , user_id = nil , user_email = nil )", "del_tokens": "# @param [String] user_id ID of the user whom this agreement is made for # @param [String] user_email Email of the user whom this agreement is made for # @param [Hash] params SYMBOL-referenced Hash containing: def initialize ( user_id , user_email , params )", "commit_type": "change"}
{"commit_tokens": ["Add", "boolean", "attributes", "to", "html", "builder"], "add_tokens": "BOOL_ATTRIBUTES = %i| allowfullscreen async autofocus autoplay checked compact controls declare default defaultchecked defaultmuted defaultselected defer disabled draggable enabled formnovalidate hidden indeterminate inert ismap itemscope loop multiple muted nohref noresize noshade novalidate nowrap open pauseonexit readonly required reversed scoped seamless selected sortable spellcheck translate truespeed typemustmatch visible | . map { | k , v | attr_string ( k , v ) } def attr_string ( k , v ) if BOOL_ATTRIBUTES . include? ( k ) attr_key ( k ) if v else %Q|#{attr_key(k)}=\"#{v}\"| end end", "del_tokens": ". map { | k , v | %Q|#{attr_key(k)}=\"#{v}\"| }", "commit_type": "add"}
{"commit_tokens": ["Fix", "incompatibility", "with", "rails_stdout_logging", "gem"], "add_tokens": ":: Rails . logger . formatter = Shog :: Formatter . new . configure & block end", "del_tokens": ":: Rails . logger . formatter . configure & block end", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "config", ".", "command_output"], "add_tokens": "attr_accessor :log_file , :monkey_patch_rake , :color , :truncate , :banner , :command_output self . command_output = false end def command_output_stdout? command_output_include? ( :stdout ) end def command_output_stderr? command_output_include? ( :stderr ) end private def command_output_include? ( sym ) command_output == true || Array ( command_output ) . include? ( sym )", "del_tokens": "attr_accessor :log_file , :monkey_patch_rake , :color , :truncate , :banner", "commit_type": "add"}
{"commit_tokens": ["Added", "example", "of", "extending", "NodeBase"], "add_tokens": "class LaTeXRationalNode < NodeBase def to_value ( xml_text ) match_data = / \\\\ frac \\{ ([0-9.]+) \\} \\{ ([0-9.]+) \\} / . match ( xml_text ) Rational ( \"#{match_data[1]}/#{match_data[2]}\" ) end def to_xml_text ( value ) \"\\\\frac{#{value.numerator}}{#{value.denominator}}\" end end it 'forwards to #to_value' do node = LaTeXRationalNode . new ( SomeMappingClass , :attr_name , 'attr_name' ) expect ( node . to_value ( '\\frac{1}{2}' ) ) . to eq ( Rational ( '1/2' ) ) end it 'forwards to #to_xml_text' do node = LaTeXRationalNode . new ( SomeMappingClass , :attr_name , 'attr_name' ) expect ( node . to_xml_text ( Rational ( '1/2' ) ) ) . to eq ( '\\frac{1}{2}' ) end", "del_tokens": "it 'forwards to #to_value' it 'forwards to #to_xml_text'", "commit_type": "add"}
{"commit_tokens": ["Fixed", "FFI", "destroy", "object", "messages", "during", "chef", "run"], "add_tokens": "proc { \"#{certstore_handler}\" }", "del_tokens": "proc { puts \"DESTROY OBJECT #{certstore_handler}\" }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "rubocop", "Style", "/", "SpaceInsideHashLiteralBraces"], "add_tokens": "'b' => '4' }", "del_tokens": "'b' => '4' }", "commit_type": "fix"}
{"commit_tokens": ["Added", "write", "command", "to", "print", "selected", "nodes", "to", "the", "console"], "add_tokens": "# @return [Boolean] Suppress automatic output of result attr_accessor :suppress_output when_called self , :execute def execute ( args , options ) before args , options if @suppress_output then $tool . print = false $tool . save = false end selection . send name , * parameters # Parameters for command execution # # @return [Array] Parameters def parameters [ ] end # Invoked before the command is executed # # @param args [Array<String>] Arguments from the command line # @param options [Commander::Command::Options] Options from the command line def before ( args , options ) end # @return [Boolean] Supplying an expression is optional attr_accessor :optional_expression @optional_expression = false # Check if an expression is set def before ( args , options ) if not @optional_expression and @template . nil? then raise SystemExit , 'Please specify a value with --string or --template.' # Return the template as parameter def parameters [ @template ] end global_option ( '-q' , '--quiet' , 'Do not print nodes' ) do | value | $tool . print = ! value end modify_command :write do | c | c . description = 'Write selected nodes to the console' c . suppress_output = true c . optional_expression = true end", "del_tokens": "when_called self , :perform def perform ( args , options ) selection . send name def perform ( args , options ) raise SystemExit , 'Please specify a value with --string or --template.' if @template . nil? $tool . work ( args ) do @selectors . each do | selector | selection = instance_eval ( & selector ) selection . send name , @template end", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "other", "warnings", "too"], "add_tokens": "def initialize ( name , supplied_values ) @optional_values = { } if @supplied_values . last . is_a? Hash @optional_values = @supplied_values . last @supplied_values . delete_at ( - 1 ) end", "del_tokens": "def initialize ( name , * args , ** options ) @supplied_values = args @optional_values = options", "commit_type": "fix"}
{"commit_tokens": ["Allow", "Down", ".", "open", "to", "accept", "request", "headers"], "add_tokens": "request_headers = options . select { | key , value | key . is_a? ( String ) } http . request_get ( uri . request_uri , request_headers ) do | response |", "del_tokens": "http . request_get ( uri . request_uri ) do | response |", "commit_type": "allow"}
{"commit_tokens": ["Fix", "running", "with", "--", "web"], "add_tokens": "Executable . execute_command ( :open , [ url ] )", "del_tokens": "open! ( url )", "commit_type": "fix"}
{"commit_tokens": ["Use", "Bundler", "instead", "of", "ore"], "add_tokens": "require 'bundler' Bundler . setup :default", "del_tokens": "require 'grit'", "commit_type": "use"}
{"commit_tokens": ["Fix", "method", "defining", "in", "runtime", "for", "new", "tableless", "classes"], "add_tokens": "return result . #{@inspect_id}();", "del_tokens": "else if ( ! result . $m ) { return \"<error: result does not have a method table>\" ; } return result . $m . #{@inspect_id}(result, #{@inspect_id.inspect});", "commit_type": "fix"}
{"commit_tokens": ["Fix", "wrong", "type", "of", "accent", "in", "doc", "comment"], "add_tokens": "# otherwise `nil`.", "del_tokens": "# otherwise ´nil´.", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "ensure", "field", "length", "for", "ansi", "."], "add_tokens": "( lines . map do | line | display_width ( self . class . color . strip ( line ) ) end << 0 ) . max # @api public def self . color @color ||= Pastel . new ( enabled : true ) end # @api public", "del_tokens": "display_width ( lines . max_by { | line | display_width ( line ) } || '' )", "commit_type": "change"}
{"commit_tokens": ["Add", "in_app", "and", "generic", "Rails", "filters", "to", "stacktraces"], "add_tokens": "in_app = frame_in_app? ( trace_line ) def frame_in_app? ( trace_line ) @silencers . any? do | s | s . call ( trace_line ) end end", "del_tokens": "in_app = @silencers . any? do | s | s . call ( line ) end", "commit_type": "add"}
{"commit_tokens": ["Add", "logging", "support", "to", "Xero", "gateway"], "add_tokens": "attr_accessor :client , :xero_url , :logger", "del_tokens": "attr_accessor :client , :xero_url", "commit_type": "add"}
{"commit_tokens": ["Allow", "access", "to", "formatted", "addresses"], "add_tokens": ":longitude , :raw_data , :short_formatted , :formatted", "del_tokens": ":longitude , :raw_data", "commit_type": "allow"}
{"commit_tokens": ["moved", "specs", "so", "the", "autotest", "filemapping", "works", "better"], "add_tokens": "require File . dirname ( __FILE__ ) + '/../../spec_helper'", "del_tokens": "require File . dirname ( __FILE__ ) + '/spec_helper'", "commit_type": "move"}
{"commit_tokens": ["Changing", "from", "REXML", "to", "Nokogiri"], "add_tokens": "builder = Nokogiri :: XML :: Builder . new do | xml | xml . AccessRequest { xml . AccessLicenseNumber @options [ :key ] xml . UserId @options [ :login ] xml . Password @options [ :password ] } end builder . to_xml builder = Nokogiri :: XML :: Builder . new do | xml | xml . ShipmentConfirmRequest { xml . Request { xml . RequestAction 'ShipConfirm' xml . RequestOption 'validate' } xml . Shipment { xml . #TODO", "del_tokens": "xml_request = XmlNode . new ( 'AccessRequest' ) do | access_request | access_request << XmlNode . new ( 'AccessLicenseNumber' , @options [ :key ] ) access_request << XmlNode . new ( 'UserId' , @options [ :login ] ) access_request << XmlNode . new ( 'Password' , @options [ :password ] ) end xml_request . to_s", "commit_type": "change"}
{"commit_tokens": ["Add", "ability", "to", "have", "default", "config", "file", "in", "/", "etc", "/", "minicron", ".", "toml"], "add_tokens": "DEFAULT_CONFIG_FILE = '/etc/minicron.toml' file_path ||= DEFAULT_CONFIG_FILE rescue Errno :: ENOENT # Fail if the file doesn't exist unless it's the default config file if file_path != DEFAULT_CONFIG_FILE raise Exception . new ( \"Unable to the load the file '#{file_path}', are you sure it exists?\" ) end rescue Errno :: EACCES raise Exception . new ( \"Unable to the readthe file '#{file_path}', check it has the right permissions.\" ) raise Exception . new ( \"An error occured parsing the config file '#{file_path}', please check it uses valid TOML syntax.\" )", "del_tokens": "raise Exception . new ( \"An error occured parsing the config file '#{file_path}', please check it exists and uses valid TOML syntax.\" )", "commit_type": "add"}
{"commit_tokens": ["Move", "UIViews", "to", "Loco", "::", "UI", "module"], "add_tokens": "NSLog ( '%@<Loco::UI::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::UI::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::UI::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::UI::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::UI::View> `top`, `bottom`, and `height` may conflict with each other. Only two of the three should be set.' , self . class ) NSLog ( '%@<Loco::UI::View> top: %@, bottom: %@, height: %@' , self . class , self . top , self . bottom , self . height ) NSLog ( '%@<Loco::UI::View> `left`, `right`, and `width` may conflict with each other. Only two of the three should be set.' , self . class ) NSLog ( '%@<Loco::UI::View> left: %@, right: %@, width: %@' , self . class , self . left , self . right , self . width )", "del_tokens": "NSLog ( '%@<Loco::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::View> Not enough params to position and size the view.' , self . class ) NSLog ( '%@<Loco::View> `top`, `bottom`, and `height` may conflict with each other. Only two of the three should be set.' , self . class ) NSLog ( '%@<Loco::View> top: %@, bottom: %@, height: %@' , self . class , self . top , self . bottom , self . height ) NSLog ( '%@<Loco::View> `left`, `right`, and `width` may conflict with each other. Only two of the three should be set.' , self . class ) NSLog ( '%@<Loco::View> left: %@, right: %@, width: %@' , self . class , self . left , self . right , self . width )", "commit_type": "move"}
{"commit_tokens": ["Move", "query", "methods", "to", "separate", "module"], "add_tokens": "require 'hydra_attribute/active_record/relation/query_methods' require 'hydra_attribute/active_record/relation'", "del_tokens": "require 'hydra_attribute/active_record/relation'", "commit_type": "move"}
{"commit_tokens": ["Fixed", "more", "typo", "s", "."], "add_tokens": "it 'should set the default Redis configuration' do", "del_tokens": "it 'should set the default MongoDB configuration' do", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "odd", "errors", "I", "was", "getting", ".", "Heading#delta", "s", "to", "was", "sometimes", "not"], "add_tokens": "to . to_f < self . to_f ? - diff : diff end", "del_tokens": "to < self ? - diff : diff end", "commit_type": "fix"}
{"commit_tokens": ["Add", "template", "helper", "documentation", "and", "refactor", "."], "add_tokens": "require 'japr/template'", "del_tokens": "require 'japr/template'", "commit_type": "add"}
{"commit_tokens": ["make", "requiring", "tenant", "scope", "optional", "via", "extra", "method", "call"], "add_tokens": "def tenant_required? Thread . current [ :tenant_required ] end def require_tenant Thread . current [ :tenant_required ] = true end if ActsAsTenant . tenant_required? raise \"Scope not set! [ActsAsTenant]\" unless ActsAsTenant . current_tenant end where ( { fkey => ActsAsTenant . current_tenant . id } ) if ActsAsTenant . current_tenant", "del_tokens": "raise \"Scope not set! [ActsAsTenant]\" unless ActsAsTenant . current_tenant where ( { fkey => ActsAsTenant . current_tenant . id } )", "commit_type": "make"}
{"commit_tokens": ["fixed", "return", "of", "values", "from", "evaluated", "code", "in", "evalhook"], "add_tokens": "retvalue = nil retvalue = begin #{args[0]} end retvalue", "del_tokens": "#{args[0]} end def evalhook ( * args ) args [ 0 ] = \" EvalHook . double_run do | run | ( if ( run ) #{args[0]} EvalHook :: FakeEvalHook else EvalHook end ) . hook_block end \" eval ( * args )", "commit_type": "fix"}
{"commit_tokens": ["Moved", "gui_state", "into", "the", "states", "folder", "."], "add_tokens": "require_relative 'fidgit/states/gui_state'", "del_tokens": "require_relative 'fidgit/gui_state'", "commit_type": "move"}
{"commit_tokens": ["adding", "support", "for", "listDevices", "operation"], "add_tokens": "devices = [ ] response . parsed_response [ 'devices' ] . each do | d | device = Device . new ( d [ 'name' ] , d [ 'deviceid' ] ) d [ 'services' ] . each do | s | device . services << Service . new ( s [ 'name' ] , s [ 'serviceid' ] ) end devices << device end devices", "del_tokens": "response . parsed_response [ 'devices' ]", "commit_type": "add"}
{"commit_tokens": ["Added", "params", "to", "#find_devices", "to", "pass", "on", "to", "SSDP", ".", "search", "."], "add_tokens": "# @param [Fixnum] max_wait_time The MX value to use for searching. # @param [Fixnum] ttl def find_devices ( search_type , max_wait_time , ttl = 4 ) @devices = SSDP . search ( search_type , max_wait_time , ttl )", "del_tokens": "def find_devices ( search_type = \"ssdp:all\" ) @devices = SSDP . search ( search_type ) puts \"location\"", "commit_type": "add"}
{"commit_tokens": ["added", "custom", "proxy", "params", "and", "version", "bump"], "add_tokens": "proxy_port : nil , proxy_user : nil , proxy_pass : nil , proxy_custom_headers : nil ) @proxy_addr = proxy_addr @proxy_user = proxy_user @proxy_pass = proxy_pass @proxy_custom_headers = proxy_custom_headers @request_client = @proxy_addr . nil? ? Net :: HTTP :: Proxy ( @proxy_addr , @proxy_port &. to_i , @proxy_user , @proxy_pass ) : Net :: HTTP res = @request_client . start ( uri . hostname , uri . port , use_ssl : uri . scheme == 'https' ) { | http | http . request ( req ) } headers_to_add = headers_to_add . merge ( @proxy_custom_headers ) if @proxy_custom_headers", "del_tokens": "proxy_port : nil ) @proxy_addr = proxy_addr res = Net :: HTTP . new ( uri . hostname , uri . port , @proxy_addr , @proxy_port &. to_i , use_ssl : uri . scheme == 'https' ) . start { | http | http . request ( req ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "remote", "lookup", ".", "Version", "bump", "."], "add_tokens": "require 'json' require 'pathname' url = \"https://raw.github.com/customink/fauxhai/master/lib/fauxhai/platforms/#{platform}/#{version}.json\" response = HTTParty . get ( url ) if response . code . to_i == 200 path = Pathname . new ( filepath ) FileUtils . mkdir_p ( path . dirname )", "del_tokens": "require 'json' response = HTTParty . get ( \"https://raw.github.com/customink/fauxhai/master/lib/fauxhai/platforms/#{platform}/#{version}.json\" ) if response . code == 200", "commit_type": "fix"}
{"commit_tokens": ["Fix", "missed", "WPF", "sale", "operation", "merchant_cheque", "param"], "add_tokens": "merchant_cheque", "del_tokens": "cheque", "commit_type": "fix"}
{"commit_tokens": ["Add", "reply_to", "and", "errors_to", "fields", "to", "TMS", "::", "EmailMessage", "bump", "version"], "add_tokens": "# @attr from_name [String] The name of the person or entity sending the email. # @attr from_email [String] Optional - the email address of the person or entity sending the email. Must be configured in TMS beforehand. Defaults to the account default from address. # @attr reply_to [String] Optional - the email address used for the Reply-To header of this email. Defaults to the account default reply_to_email address (which itself defaults to the default from address if not specified). # @attr errors_to [String] Optional - the email address used for the Errors-To header of this email. Defaults to the account default bounce_email address (which itself defaults to the default from address if not specified). # @attr subject [String] The subject of the email. # @attr body [String] The body of the email. # @attr open_tracking_enabled [Boolean] Optional - Whether to track opens on this message. Defaults to true. # @attr click_tracking_enabled [Boolean] Optional - Whether to track clicks on links in this message. Defaults to true. # @attr macros [Hash] Optional - A dictionary of key/value pairs to use in the subject and body as default macros. # The message-level macros are used when a recipient has no value for a given macro key. # @!parse attr_accessor :body, :from_name, :from_email, :reply_to, :errors_to, :subject, :open_tracking_enabled, :click_tracking_enabled, :macros writeable_attributes :body , :click_tracking_enabled , :errors_to , :from_email , :from_name , :macros , :open_tracking_enabled , :reply_to , :subject", "del_tokens": "# @attr from_name [String] The name of the person or entity sending the email. # @attr from_email [String] The email adderess of the person or entity sending the email. Must be configured in TMS beforehand. Defaults to the account default from address. # @attr subject [String] The subject of the email # @attr body [String] The body of the email # @attr open_tracking_enabled [Boolean] Whether to track opens on this message. Optional, defaults to true. # @attr click_tracking_enabled [Boolean] Whether to track clicks on links in this message. Optional, defaults to true. # @attr macros [Hash] A dictionary of key/value pairs to use in the subject and body as default macros. # The message-level macros are used when a recipient has no value for a given macro key. # @!parse attr_accessor :body, :from_name, :from_email, :subject, :open_tracking_enabled, :click_tracking_enabled, :macros writeable_attributes :body , :from_name , :from_email , :subject , :open_tracking_enabled , :click_tracking_enabled , :macros", "commit_type": "add"}
{"commit_tokens": ["add", "catch", "statement", "to", "handle", "string", "body"], "add_tokens": "begin response . body = JSON . parse ( response . body , max_nesting : false ) response . body = if response . body . is_a? Array rescue raise \"JSON parse error\" ensure return response end", "del_tokens": "response . body = JSON . parse ( response . body , max_nesting : false ) response . body = if response . body . is_a? Array response", "commit_type": "add"}
{"commit_tokens": ["Adding", "Erlang", "Plugin", "-", "Thanks", "to", "Joe", "Williams", ".", "OHAI", "-", "18"], "add_tokens": "# # Author:: Joe Williams (<joe@joetify.com>) # Copyright:: Copyright (c) 2008 Opscode, Inc. # License:: Apache License, Version 2.0 # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # popen4 ( \"erl +V\" ) do | pid , stdin , stdout , stderr | stdin . close output = stderr . gets . split options = output [ 1 ] options . gsub! ( / ( \\( | \\) ) / , '' ) languages [ :erlang ] [ :version ] = output [ 5 ] languages [ :erlang ] [ :options ] = options . split ( ',' ) languages [ :erlang ] [ :emulator ] = output [ 2 ] . gsub! ( / ( \\( | \\) ) / , '' ) end", "del_tokens": "require \"open3\" stdin , stdout , stderr = Open3 . popen3 ( 'erl +V' ) output = stderr . gets . split languages [ :erlang ] [ :version ] = output [ 5 ] languages [ :erlang ] [ :options ] = output [ 1 ] languages [ :erlang ] [ :emulator ] = output [ 2 ]", "commit_type": "add"}
{"commit_tokens": ["Fixing", "a", "failing", "spec", "from", "last", "commit"], "add_tokens": "change { article . keywords } . to array", "del_tokens": "change { article . keyphrases } . to array", "commit_type": "fix"}
{"commit_tokens": ["Add", "codeclimate", "-", "test", "-", "reporter"], "add_tokens": "require 'simplecov' require 'codeclimate-test-reporter' SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter [ CodeClimate :: TestReporter :: Formatter , Coveralls :: SimpleCov :: Formatter ] SimpleCov . start do %w( spec ) . each do | ignore_path | add_filter ( ignore_path ) end end", "del_tokens": "Coveralls . wear!", "commit_type": "add"}
{"commit_tokens": ["Add", "check", "if", "file", "s3", ".", "yml", "exist"], "add_tokens": "if ( FileTest . exist? ( Rails . root . join ( 'config' , 's3.yml' ) ) && ! YAML . load_file ( Rails . root . join ( 'config' , 's3.yml' ) ) [ Rails . env ] . blank? ) elsif ( FileTest . exist? ( Rails . root . join ( 'config' , 's3.yml' ) ) && ENV [ 'S3_KEY' ] && ENV [ 'S3_SECRET' ] && ENV [ 'S3_BUCKET' ] )", "del_tokens": "if ( ! YAML . load_file ( Rails . root . join ( 'config' , 's3.yml' ) ) [ Rails . env ] . blank? ) elsif ( ENV [ 'S3_KEY' ] && ENV [ 'S3_SECRET' ] && ENV [ 'S3_BUCKET' ] )", "commit_type": "add"}
{"commit_tokens": ["add", "error", "catching", "for", "source", "validation"], "add_tokens": "begin rescue end", "del_tokens": "#begin #rescue #end", "commit_type": "add"}
{"commit_tokens": ["Added", "#d", "command", "line", "functionality", ".", "Also", "d", "now", "takes", "stdin", "for", "message", "."], "add_tokens": "post = ARGV . size > 1 ? ARGV . join ( \" \" ) : ARGV . shift mode 'd' do argument ( 'username' ) { required description 'username or id of twitterrer to direct message' } def run do_work do username = params [ 'username' ] . value post = ARGV . size > 1 ? ARGV . join ( \" \" ) : ARGV . shift base . d ( username , post ) say \"Direct message sent to #{username}\" end end end", "del_tokens": "post = if ARGV . size > 1 ARGV . join \" \" else ARGV . shift end", "commit_type": "add"}
{"commit_tokens": ["add", ":", "omit_parameters", "option", "to", "Event#as_json"], "add_tokens": "DEFAULT_TYPE = :model self . type = options . delete ( :type ) . try ( :to_sym ) || DEFAULT_TYPE self . action = options . delete ( :action ) . try ( :to_sym ) self . user_id = options . delete ( :user_id ) self . parameters = options . delete ( :parameters ) || options # Return hash of data to be serialized to JSON # @option options [Boolean] :omit_parameters when set, do not include parameters in data # @return [Hash] data to serialize def as_json ( options = { } ) data = { type : type , action : action , user_id : user_id , occurred_at : occurred_at , eventful_type : eventful_type , eventful_id : eventful_id , parameters : parameters , session_id : session_id } data [ :parameters ] = parameters unless options [ :omit_parameters ] data", "del_tokens": "DEFAULT_TYPE = :model self . type = options . delete ( :type ) . try ( :to_sym ) || DEFAULT_TYPE self . action = options . delete ( :action ) . try ( :to_sym ) self . user_id = options . delete ( :user_id ) self . parameters = options . delete ( :parameters ) || options def as_json ( _ignored = nil ) { :type => type , :action => action , :user_id => user_id , :occurred_at => occurred_at , :eventful_type => eventful_type , :eventful_id => eventful_id , :parameters => parameters , :session_id => session_id }", "commit_type": "add"}
{"commit_tokens": ["implemented", ":", "on_error", "=", ">", ":", "redo"], "add_tokens": "tree = handler . to_s == 'redo' ? exp . tree : [ handler , { } , [ ] ] apply ( tree , exp . fei , exp . parent , eargs [ :workitem ] , { } )", "del_tokens": "apply ( [ handler , { } , [ ] ] , exp . fei , exp . parent , eargs [ :workitem ] , { } )", "commit_type": "implement"}
{"commit_tokens": ["Uses", "wisper", "in", "place", "of", "custom", "subscription"], "add_tokens": "require 'wisper' include Wisper :: Publisher if options [ :handler ] warn 'the :handler option is deprecated, listen to the :events_received event instead' @handler = options [ :handler ] end @handler . on_events ( payload ) if @handler publish ( :events_received , payload )", "del_tokens": "@handler = options [ :handler ] @handler . on_events ( payload )", "commit_type": "use"}
{"commit_tokens": ["added", "can?", "method", "in", "controller"], "add_tokens": "should 'call authorized?' do user = User . new account = Account . new resource = stub ( 'Resource' ) resource . expects ( :parent ) . returns ( nil ) @controller . expects ( :resource ) . returns ( resource ) Trust :: Authorization . expects ( :authorized? ) . with ( :manage , account , nil ) . returns ( true ) @controller . can? :manage , account should 'should have default parameters' do resource = stub ( 'Resource' ) @controller . expects ( :resource ) . returns ( resource ) . at_least_once resource . expects ( :instance ) . returns ( :instance ) resource . expects ( :parent ) . returns ( :parent ) Trust :: Authorization . expects ( :authorize! ) . with ( :manage , :instance , :parent ) @controller . can? :manage resource . expects ( :instance ) . returns ( nil ) resource . expects ( :klass ) . returns ( :klass ) resource . expects ( :parent ) . returns ( :parent ) Trust :: Authorization . expects ( :authorize! ) . with ( :manage , :klass , :parent ) @controller . can? :manage should 'be exposed as helper' do assert @controller . class . _helper_methods . include? ( :can? )", "del_tokens": "should_eventually 'call authorized?' do should_eventually 'should have default parameters' do should_eventually 'be exposed as helper' do", "commit_type": "add"}
{"commit_tokens": ["remove", "commas", "followed", "by", "3", "digits", "to", "remove", "thousand", "separators", "in", "IPay88"], "add_tokens": "params [ \"Amount\" ] . try ( :gsub , / ,(?= \\d {3} \\b ) / , '' )", "del_tokens": "params [ \"Amount\" ]", "commit_type": "remove"}
{"commit_tokens": ["implemented", "hook", "of", "global", "vars", "assignments"], "add_tokens": "class HookGasgn def initialize ( global_id , hook_handler ) @global_id = global_id @hook_handler = hook_handler end def set_value ( value ) global_id = @global_id ret = @hook_handler . handle_gasgn ( @global_id , value ) if ret then global_id = ret . global_id value = ret . value end eval ( \"#{global_id} = value\" ) end end HookCdecl . new ( context , self ) def hooked_gasgn ( global_id ) HookGasgn . new ( global_id , self ) end def handle_gasgn ( * args ) nil end", "del_tokens": "return HookCdecl . new ( context , self )", "commit_type": "implement"}
{"commit_tokens": ["Added", "increment", "argument", "to", "SineFactory", "initializer", ".", "Removed", "SkipGenerator", "from", "main", "example", "."], "add_tokens": "#A skip factory, in charge of randomly resetting the meta factory.", "del_tokens": "#This is an additional skip factory, in charge of randomly resetting the meta factory.", "commit_type": "add"}
{"commit_tokens": ["Fix", "default", "value", "of", "logdev", "in", "HTTP", "client"], "add_tokens": "def self . new ( cache_dir : nil , expires_in : 86400 , value_max_bytes : 1048576 , level : 'INFO' , logdev : STDOUT ) # 1 day", "del_tokens": "def self . new ( cache_dir : nil , expires_in : 86400 , value_max_bytes : 1048576 , level : 'INFO' , logdev : logdev ) # 1 day", "commit_type": "fix"}
{"commit_tokens": ["Added", "test_output", "rake", "task", "that", "renders", "then", "opens", "FileMerge", "."], "add_tokens": "` cd #{ Gumdrop . site . root } && bundle exec gumdrop build `", "del_tokens": "` cd #{ Gumdrop . site . root } && ruby ../../../bin/gumdrop build `", "commit_type": "add"}
{"commit_tokens": ["removed", "unneeded", "params", "inside", "Faker", "::", "NameRU", ".", "name"], "add_tokens": "when 0 then \"#{last_name} #{first_name} #{patronymic}\" else \"#{first_name} #{last_name}\"", "del_tokens": "when 0 then \"#{last_name(for_sex)} #{first_name(for_sex)} #{patronymic(for_sex)}\" else \"#{first_name(for_sex)} #{last_name(for_sex)}\"", "commit_type": "remove"}
{"commit_tokens": ["removed", "compileinline", "()", "on", "tables", "."], "add_tokens": "tr rows . shift . map { | s | th ( s ) } tr cols . map { | s | td ( s ) } tr [ th ( h ) ] + cs . map { | s | td ( s ) }", "del_tokens": "tr rows . shift . map { | s | th ( compile_inline ( s ) ) } tr cols . map { | s | td ( compile_inline ( s ) ) } tr [ th ( compile_inline ( h ) ) ] + cs . map { | s | td ( compile_inline ( s ) ) }", "commit_type": "remove"}
{"commit_tokens": ["Added", "additional", "validation", "on", "Http", "::", "Response#code", "=", "."], "add_tokens": "INVALID_CODE = 'must be a numeric HTTP status code from 100..599' # @return [Integer, nil] def code @code end # @param [Integer, number] code Must be a valid HTTP status code. def code = code code = code . to_i raise ArgumentError , INVALID_CODE unless code > 99 && code < 600 @code = code . to_i end", "del_tokens": "# @return [Integer,nil] attr_accessor :code", "commit_type": "add"}
{"commit_tokens": ["Moved", "override", "check", "to", "StopContext", "to", "avoid", "defect", "in", "MethodContext"], "add_tokens": "attr_reader :calls , :refs @depends_on_self = false @depends_on_self || is_overriding_method? ( @name )", "del_tokens": "attr_reader :outer , :calls , :refs @depends_on_self or is_overriding_method? ( @name )", "commit_type": "move"}
{"commit_tokens": ["Add", "config", "for", "JSON", "default"], "add_tokens": "hash [ :view ] = render_to_string ( render_args ( :layout => false ) ) . gsub ( / \\n / , '' ) . presence result = ( Emerson . response_config [ :json_default ] || :full ) . intern", "del_tokens": "hash [ :view ] = render_to_string ( render_args ( :layout => false ) ) . gsub ( / \\n / , '' ) . presence result = false", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "Thread", ".", "current", "[", ":", "mq", "]", "state", "is", "cleaned", "after", "each", "example"], "add_tokens": "describe EventMachine , \" when running failing examples\" do", "del_tokens": "describe MQ , \" when MQ.queue or MQ.fanout etc is trying to access Thread-local mq across examples\" do it 'sends data to queue' do amqp do q = MQ . new . queue ( \"test_sink\" ) q . subscribe do | hdr , data | p hdr , data EM . next_tick { q . unsubscribe ; q . delete done } end EM . add_timer ( 0.2 ) do p Thread . current , Thread . current [ :mq ] MQ . queue ( 'test_sink' ) . publish 'data' # MQ.new. !!!!!!!!!!! end end end it 'sends data to queue' do amqp do q = MQ . new . queue ( \"test_sink\" ) q . subscribe do | hdr , data | p hdr , data EM . next_tick { q . unsubscribe ; q . delete done } end EM . add_timer ( 0.2 ) do p Thread . current , Thread . current [ :mq ] MQ . queue ( 'test_sink' ) . publish 'data' # MQ.new. !!!!!!!!!!! end end end end describe EventMachine , \" when running failing examples\" do include AMQP :: SpecHelper", "commit_type": "make"}
{"commit_tokens": ["added", "street_address", "and", "fixed", "zipcode"], "add_tokens": "ZIP_FORMATS = k [ '####' ] def street_address \"#{Faker::AddressDA.street_address} #{rand(100)}\" end", "del_tokens": "ZIP_FORMATS = k [ '#####' ]", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "version", "and", "the", "gem", "name", "everywhere"], "add_tokens": "st . frame = { t : 10 , w : 200 , h : 95.5 }", "del_tokens": "st . frame = { t : 10 , w : 200 , h : 96 }", "commit_type": "update"}
{"commit_tokens": ["Fix", "to", "new", "button", "on", "scripturls", "."], "add_tokens": "VERSION = \"0.9.8\"", "del_tokens": "VERSION = \"0.9.7\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "logger", "instead", "of", "puts"], "add_tokens": "HornetQ . logger . ifno \"Caught #{signal_name}, stopping server\"", "del_tokens": "puts \"caught #{signal_name}\"", "commit_type": "use"}
{"commit_tokens": ["Remove", "newlines", "from", "find_master_for", "sql"], "add_tokens": "hostname = database . host . hostname port = database . host . port || root_config [ 'port' ] 'host' => hostname , 'port' => port )", "del_tokens": "'host' => database . host . hostname )", "commit_type": "remove"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = '0.5.1'", "del_tokens": "VERSION = '0.5.0'", "commit_type": "change"}
{"commit_tokens": ["updated", "the", "renderer", "to", "use", "the", "new", "source", "stack", "class"], "add_tokens": "require 'undies/source_stack' attr_accessor :source_stack self . source = source def source = ( source ) self . source_stack = SourceStack . new ( source )", "del_tokens": "# require 'undies/source_stack' def source_stack", "commit_type": "update"}
{"commit_tokens": ["added", "validation", "of", "shared", "folders", "functionality"], "add_tokens": "#Set a shared folder for validation command = \"#{@vboxcmd} sharedfolder add '#{boxname}' --name 'veewee-validation' --hostpath '#{File.expand_path(@veewee_dir)}/validation' --automount\" Veewee :: Shell . execute ( \"#{command}\" ) puts \"Step [#{current_step_nr}] was succesfully - saving state\"", "del_tokens": "puts \"Step [#{current_step_nr}] was succesfull - saving state\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "DataMapper", "::", "Scope", "specs", "to", "use", "a", "real", "DataMapper", "::", "Query", "object", "instead", "of", "a", "mock"], "add_tokens": "# TODO: define exception classes instead of using ArgumentError everywhere # XXX: since :fields and :conditions are plural, shouldn't :link and :include # also be pluralized? Not sure :order can be pluralized and still make sense tho @conditions = [ ] # must be an Array of triplets (or pairs when passing in raw String queries) @offset = other . offset unless other . offset == 0 @limit = other . limit unless other . limit . nil? def == ( other ) @resource == other . resource && @reload == other . reload && @offset == other . offset && @limit == other . limit && @order == other . order && @fields == other . fields && @link == other . link && @include == other . include && @conditions . sort_by { | c | [ c [ 0 ] . to_s , c [ 1 ] . to_s , c [ 2 ] ] } == other . conditions . sort_by { | c | [ c [ 0 ] . to_s , c [ 1 ] . to_s , c [ 2 ] ] } end # deep-copy the condition tuples when copying the object", "del_tokens": "@conditions = [ ] # must be an Array of triplit (or pairs when passing in raw String queries) @offset = other . offset if other . offset > 0 @limit = other . limit if other . limit", "commit_type": "update"}
{"commit_tokens": ["make", "sure", "type", "is", "always", "a", "string", "and", "mark", "association", "fields"], "add_tokens": "type : column . type . to_s , type = extract_type_from reflection is_association : true ,", "del_tokens": "type : column . type , type = extract_type_from ( reflection )", "commit_type": "make"}
{"commit_tokens": ["Allow", "load_subclasses", "to", "work", "when", "multiple", "apps", "are", "on", "the", "same", "database", ":", "such", "as", "with", "schemas", "in", "PostgeSQL"], "add_tokens": "if ActiveRecord :: Base . connection . tables . include? ( 'pages' ) # Assume that we have bootstrapped", "del_tokens": "unless Page . connection . tables . empty? # Haven't bootstrapped yet", "commit_type": "allow"}
{"commit_tokens": ["Add", "an", "integration", "test", "for", "broken", "broker", "connections"], "add_tokens": "attr_reader :broker , :zookeeper end def without_process stop begin yield ensure start sleep 5 end def without_process @jr . without_process { yield } end", "del_tokens": "#@pid = run #Process.kill(:TERM, @pid) #cmd = \"#{self.class.kafka_path}/#{@start_cmd} #{config_path} &>> #{log_path} & echo pid:$! > #{pid_path}\" #`#{cmd}` #IO.read(pid_path).split(\":\")[1].to_i", "commit_type": "add"}
{"commit_tokens": ["removed", "include", "Eldritch", "::", "DSL", "from", "all", "examples"], "add_tokens": "puts \"starting long running task with #{arg}\"", "del_tokens": "include Eldritch :: DSL puts \"starting long running task with #{stuff}\"", "commit_type": "remove"}
{"commit_tokens": ["added", "final", "command", "modify", "with", "tests"], "add_tokens": "# Modify a user's information # user_id def user_modify ( attributes ) defaults = { user_name : \"!\" , min_bal : \"!\" , email : \"!\" , dept_name : \"!\" , pimary_pin : \"!\" , secondary_pin : \"!\" , quota : \"!\" , alternate_pin : \"!\" , home_server : \"!\" , locked : \"!\" , location : \"!\" , default_bc : \"!\" , additional_info : \"!\" , home_folder : \"!\" } attr = defaults . merge ( attributes ) \"modify ur #{attr[:user_id]} \\\"#{attr[:user_name]}\\\" #{attr[:min_bal]}\" + \" #{attr[:email]} #{attr[:dept_name]} #{attr[:primary_pin]}\" + \" #{attr[:secondary_pin]} #{attr[:quota]} #{attr[:alternate_pin]}\" + \" #{attr[:home_server]} #{attr[:locked]} #{attr[:location]}\" + \" #{attr[:default_bc]} #{attr[:additional_info]} #{attr[:home_folder]}\" end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "where", "incorrect", "keywords", "were", "returning", "nil"], "add_tokens": "if keyword && ! keyword . blank? && ! Keyword . find_by_name ( keyword ) . nil?", "del_tokens": "if keyword && ! keyword . blank?", "commit_type": "fix"}
{"commit_tokens": ["Improve", "name", "for", "legacy", "command", "output", "clearing", "logging", "method"], "add_tokens": "log_and_clear_command_output ( obj , :stderr ) log_and_clear_command_output ( obj , :stdout ) # the specified command and stream if enabled and clear the stream. def log_and_clear_command_output ( command , stream )", "del_tokens": "write_command_output ( obj , :stderr ) write_command_output ( obj , :stdout ) # the specified command and stream if enabled def write_command_output ( command , stream )", "commit_type": "improve"}
{"commit_tokens": ["make", "the", "host", "matching", "more", "strict"], "add_tokens": "hostlist = scanner . scan ( / \\S + / ) . split ( / , / ) next unless entries . all? { | entry | hostlist . include? ( entry ) }", "del_tokens": "hostlist = scanner . scan ( / \\S + / ) next unless ( hostlist . split ( / , / ) & entries ) . any?", "commit_type": "make"}
{"commit_tokens": ["Allow", "simplecov", "to", "be", "run", "locally", "(", "w", "/", "o", "Coveralls", ")"], "add_tokens": "# Simplecov has to be loaded first require_relative ( \"./support/simplecov\" )", "del_tokens": "# Coveralls has to be loaded first require_relative ( \"./support/coveralls\" )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "dependency", "on", "algorithms", "and", "added", "vectorize", ".", "rb", "to", "repo", "."], "add_tokens": "require 'Aims/vectorize.rb'", "del_tokens": "require 'algorithms.rb' require 'vectorize.rb' begin require 'rubygems' require 'opengl' require 'Aims/Visualizer/appearance.rb' require 'Aims/Visualizer/viewer.rb' require 'Aims/Visualizer/viewer_controls.rb' rescue end", "commit_type": "remove"}
{"commit_tokens": ["Add", "delegators", "for", "log", "methods"], "add_tokens": "ary . concat acc_methods . collect { | am | accessors ( am ) } . flatten! :set_color , :set_default_widths , :set_widths ,", "del_tokens": "require 'rainbow' acc_methods . each do | am | ary . concat accessors ( am ) end instmeth << \" puts 'self: \" + self . class . to_s + \"'\" instmeth << \" puts 'INSTMETH, from \" + color + \"'\" def self . set_default_widths logger . set_default_widths end def self . set_color lvl , color logger . set_color lvl , color end", "commit_type": "add"}
{"commit_tokens": ["Update", "for", "ongoing", "development", "."], "add_tokens": "VERSION = '0.0.3.pre'", "del_tokens": "VERSION = '0.0.2'", "commit_type": "update"}
{"commit_tokens": ["Use", "Util", ".", "check_length", "for", "Points"], "add_tokens": "@point = Encoder [ encoding ] . decode ( value ) Util . check_length ( @point , NaCl :: SCALARBYTES , \"group element\" )", "del_tokens": "value = Encoder [ encoding ] . decode ( value ) if value . bytesize != NaCl :: SCALARBYTES raise ArgumentError , \"group element must be exactly #{NaCl::SCALARBYTES} bytes\" end @point = value", "commit_type": "use"}
{"commit_tokens": ["updated", "README", ".", "made", "Configurable", ".", "parser", "add", "confgurations", "to", "ConfigParser", "in", "declaration", "order"], "add_tokens": "autoload ( :Shellwords , 'shellwords' ) # Parse is non-destructive to argv. If a string argv is provided, parse # splits it into an array using Shellwords. # argv = argv . kind_of? ( String ) ? Shellwords . shellwords ( argv ) : argv . dup # Same as parse, but removes parsed args from argv. comments = @options . collect do | option | next unless option . respond_to? ( :desc ) option . desc . kind_of? ( Lazydoc :: Comment ) ? option . desc : nil end . compact Lazydoc . resolve_comments ( comments )", "del_tokens": "argv = argv . dup", "commit_type": "update"}
{"commit_tokens": ["Add", "MatchSet", "and", "MatchSets", "::", "CSV"], "add_tokens": "klass . send ( :define_method , :add_score ) do | comparator_index , id_1 , id_2 , value | def new_match_set ( & block ) klass = Class . new ( Linkage :: MatchSet ) klass . send ( :define_method , :add_match ) do | id_1 , id_2 , value | end if block_given? klass . class_eval ( & block ) end klass end", "del_tokens": "klass . send ( :define_method , :add_score ) do | comparator , record_1 , record_2 , value |", "commit_type": "add"}
{"commit_tokens": ["use", "special", "route", "macro", "API", "to", "update", "route", "file"], "add_tokens": "insert_last_in_routes 'root :to => \"main#index\"'", "del_tokens": "routes_file . insert :before_last => 'end' do 'root :to => \"main#index\"' end", "commit_type": "use"}
{"commit_tokens": ["Move", "SaxHandler", "and", "XMLBuilder", "up", "out", "of", "the", "helpers", "sub", "-", "directory", "."], "add_tokens": "require 'ebay_trading/sax_handler' require 'ebay_trading/xml_builder'", "del_tokens": "require 'ebay_trading/helpers/sax_handler' require 'ebay_trading/helpers/xml_builder'", "commit_type": "move"}
{"commit_tokens": ["Remove", "some", "duplication", "in", "report", "header", "field", "definitions"], "add_tokens": "# Report headers HEADERS = { :method => \"Method\" , :min => \"Min Time\" , :max => \"Max Time\" , :average => \"Average Time\" , :total_time => \"Total Time\" , :total_calls => \"Total Calls\" , } FIELDS = HEADERS . keys :headers => HEADERS . dup , :fields => FIELDS . dup ,", "del_tokens": "FIELDS = [ :method , :min , :max , :average , :total_time , :total_calls ] :headers => { :method => \"Method\" , :min => \"Min Time\" , :max => \"Max Time\" , :average => \"Average Time\" , :total_time => \"Total Time\" , :total_calls => \"Total Calls\" , } , :fields => [ :method , :min , :max , :average , :total_time , :total_calls ] ,", "commit_type": "remove"}
{"commit_tokens": ["Added", "convenient", "methods", "for", "reading", "options", "as", "attributes", "on", "Map", "."], "add_tokens": "GoogleStaticMapsHelper :: Map . new ( @@require_options ) . options [ :key ] . should == @@require_options [ :key ] end @@require_options . each_key do | key | it \"should provide a short cut method to read the option #{key}\" do GoogleStaticMapsHelper :: Map . new ( @@require_options ) . send ( key ) . should == @@require_options [ key ] end", "del_tokens": "map = GoogleStaticMapsHelper :: Map . new ( @@require_options ) map . options [ :key ] . should == @@require_options [ :key ]", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "daemonize", "loop", "to", "next_background", "supplied", "by", "App#daemonize", "."], "add_tokens": "File . delete f if File . symlink? f App . daemonize ( :mulitple_pids => false ) { loop do run_once sleep 10 end }", "del_tokens": "File . delete f if File . symlink? f", "commit_type": "add"}
{"commit_tokens": ["adding", "run", "all", "option", "on", "start"], "add_tokens": "def initialize ( watchers = [ ] , options = { } ) @all_on_start = options . delete ( :all_on_start ) end run_all unless @all_on_start == false end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["Add", "output", "indicating", "build", "status"], "add_tokens": "if @report . values . collect ( & :values ) . flatten . all? Strainer . ui . say \"Strainer marked build OK\" exit ( true ) else Strainer . ui . say \"Strainer marked build as failure\" exit ( false ) end", "del_tokens": "abort unless @report . values . collect ( & :values ) . flatten . all?", "commit_type": "add"}
{"commit_tokens": ["Add", "hex", "and", "oct", "IP", "address", "encoding"], "add_tokens": "# - mode - String - encoding (int, ipv6, oct, hex) new_host = url . to_s . gsub! ( host , \"#{ip.to_u32}\" ) new_host = url . to_s . gsub! ( host , \"#{ip.to_ipv6}\" ) when 'oct' new_host = url . to_s . gsub! ( host , \"0#{ip.to_u32.to_s(8)}\" ) when 'hex' new_host = url . to_s . gsub! ( host , \"0x#{ip.to_u32.to_s(16)}\" )", "del_tokens": "# - mode - String - encoding (int, ipv6) new_host = url . to_s . gsub! ( host , ip . to_u32 . to_s ) . to_s new_host = url . to_s . gsub! ( host , ip . to_ipv6 . to_s ) . to_s", "commit_type": "add"}
{"commit_tokens": ["Create", "utility", "module", "for", "reusable", "functions", "."], "add_tokens": "require 'confoog/utility' include ConfoogUtils", "del_tokens": "def console_output ( message , severity ) return unless @options [ :quiet ] == false $stderr . puts \"#{@options[:prefix]} : #{severity} - #{message}\" end", "commit_type": "create"}
{"commit_tokens": ["Added", "test", "for", "options", "of", "TCPServer#new", "and", "RTUViaTCPServer#new"], "add_tokens": "ModBus :: Errors :: ModBusException , \"The function code received in the query is not an allowable action for the server\" ModBus :: Errors :: IllegalDataValue , ModBus :: Errors :: IllegalDataAddress , it \"should have options :host\" do host = '192.168.0.1' srv = ModBus :: TCPServer . new ( 1010 , 1 , :host => '192.168.0.1' ) srv . host . should eql ( host ) end it \"should have options :max_connection\" do max_conn = 5 srv = ModBus :: TCPServer . new ( 1010 , 1 , :max_connection => 5 ) srv . maxConnections . should eql ( max_conn ) end @cl . close while GServer . in_service? ( 8502 )", "del_tokens": "ModBus :: Errors :: ModBusException , \"The function code received in the query is not an allowable action for the server\" ModBus :: Errors :: IllegalDataValue , ModBus :: Errors :: IllegalDataAddress , @cl . close while GServer . in_service? ( 8502 )", "commit_type": "add"}
{"commit_tokens": ["allow", "alias", "definition", "to", "class", "Function"], "add_tokens": "def initialize ( parent , tmpl , ** opts ) @aliases = opts [ :aliases ] || [ ] a = [ \"rb_define#{s}_method(#{mod_var}, \\\"#{m}\\\", #{c_func}, #{n_arg});\" ] @aliases . map { | x | a << \"rb_define_alias(#{mod_var}, \\\"#{x}\\\", \\\"#{m}\\\");\" } a case x = i . definition when Array a . concat ( x ) when String a . push ( x ) else raise \"unknown definition: #{x}\" if x end", "del_tokens": "def initialize ( parent , tmpl , * opts ) @aliases = [ ] \"rb_define#{s}_method(#{mod_var}, \\\"#{m}\\\", #{c_func}, #{n_arg});\" x = i . definition a . push ( x ) if x", "commit_type": "allow"}
{"commit_tokens": ["Change", "unicode", "styling", "to", "match", "ascii", "fallback"], "add_tokens": "middle : Gem . win_platform? ? '|-- ' : \"\\u251c\\u2500\\u2500 \" , bottom : Gem . win_platform? ? '|__ ' : \"\\u2514\\u2500\\u2500 \"", "del_tokens": "middle : Gem . win_platform? ? '|-- ' : \"\\u251c\\u2500\\u2500\" , bottom : Gem . win_platform? ? '|__ ' : \"\\u2514\\u2500\\u2500\"", "commit_type": "change"}
{"commit_tokens": ["Make", "more", "rails3", "-", "like", "by", "changing", "raise", "to", "restrict", "and", "backporting", "code", "from", "rails", "3"], "add_tokens": "has_one :order_invoice , :dependent => :restrict def to_s \"Order #{id}\" end has_many :orders , :dependent => :restrict def to_s \"Category #{id}\" end 5 . times { Order . create! ( :category => category ) } lambda { category . reload . destroy } . should raise_error ( ActiveRecord :: DeleteRestrictionError , 'Cannot delete record because 5 dependent orders exist' ) begin category . destroy rescue ActiveRecord :: DeleteRestrictionError => e e . detailed_message . should == \"Cannot delete record because 5 dependent orders exist\\n\\n\\nThese include:\\n1: Order 1\\n2: Order 2\\n3: Order 3\\n4: Order 4\\n5: Order 5\" end 1 . times { Order . create! ( :category => category ) } begin category . destroy rescue ActiveRecord :: DeleteRestrictionError => e e . detailed_message . should == \"Cannot delete record because 6 dependent orders exist\\n\\n\\nThese include:\\n1: Order 1\\n2: Order 2\\n3: Order 3\\n4: Order 4\\n...and 2 more\" end Order . destroy_all lambda { order . reload . destroy } . should raise_error ( ActiveRecord :: DeleteRestrictionError , 'Cannot delete record because dependent order invoice exists' )", "del_tokens": "has_one :order_invoice , :dependent => :raise has_many :orders , :dependent => :raise order = Order . create! ( :category => category ) lambda { category . reload . destroy } . should raise_error ( ActiveRecord :: DependencyError ) order . destroy lambda { order . reload . destroy } . should raise_error ( ActiveRecord :: DependencyError )", "commit_type": "make"}
{"commit_tokens": ["Fix", "JS", "and", "CSS", "combination", "minification"], "add_tokens": "case File . extname ( dest_path ) when '.js' if dest_path =~ / .min.js$ / output_file ( dest_path , output ) else output_js ( dest_path , output ) end when '.css' if dest_path =~ / .min.css$ / output_file ( dest_path , output ) else output_css ( dest_path , output ) end else output_html ( dest_path , output ) end case File . extname ( dest_path ) when '.js' if dest_path =~ / .min.js$ / output_file ( dest_path , output ) else output_js ( dest_path , output ) end when '.css' if dest_path =~ / .min.css$ / output_file ( dest_path , output ) else output_css ( dest_path , output ) end else output_html ( dest_path , output ) end", "del_tokens": "output_html ( dest_path , output ) output_html ( dest_path , output )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "JID", "validation", "to", "allow", "components", "to", "talk", "over", "s2s", "streams", "."], "add_tokens": "raise ArgumentError , 'invalid jid' if @jid . empty?", "del_tokens": "raise ArgumentError , 'invalid jid' unless @jid . node && ! @jid . domain . empty?", "commit_type": "fix"}
{"commit_tokens": ["Add", "data", "from", "gares", "-", "sncf", ".", "com", "and", "open", "data", "referentiels"], "add_tokens": "# Represents a train from http://www.sncf.com/fr/horaires-info-trafic/train", "del_tokens": "# Represents something a train from http://www.sncf.com/fr/horaires-info-trafic/train", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "with", "the", "dependencies", "."], "add_tokens": "p . extra_deps = [ [ 'ruby-hmac' , '>= 0.3.1' ] ] # An array of rubygem dependencies [name, version], e.g. [ ['active_support', '>= 1.3.1'] ]", "del_tokens": "p . extra_deps = [ 'ruby-hmac' , '>= 0.3.1' ] # An array of rubygem dependencies [name, version], e.g. [ ['active_support', '>= 1.3.1'] ]", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "piping", "commands", "to", "launch", "an", "editor", "."], "add_tokens": "log_level = Jekyll . logger . log_level Jekyll . logger . log_level = Jekyll :: Stevenson :: WARN Jekyll . logger . log_level = log_level @config", "del_tokens": "end def self . layouts if Octopress . respond_to? :plugins Octopress . plugins end", "commit_type": "add"}
{"commit_tokens": ["updated", "/", "r", "/", "oneplus", "to", "new", "version"], "add_tokens": "next 'puts \"skip\"' unless DEVELOPER_CLASS == commenter_flair = comment [ \"data\" ] [ \"author_flair_css_class\" ]", "del_tokens": "next puts \"skip\" unless DEVELOPER_CLASS == commenter_flair = comment [ \"data\" ] [ \"author_flair_css_class\" ]", "commit_type": "update"}
{"commit_tokens": ["Allow", "Rjb", "to", "pass", "back", "Aether", "Dependency", "objects"], "add_tokens": "def add_notation_dependency ( notation , scope = 'compile' ) # Add a dependency def add_dependency ( dependency ) #@resolver.addDependency( dependency ) if Naether . platform == 'java' @resolver . addDependency ( dependency ) else @resolver . _invoke ( 'addDependency' , 'Lorg.sonatype.aether.graph.Dependency;' , dependency ) end end @resolver . clearDependencies ( ) add_notation_dependency ( key , dependent [ key ] ) elsif dependent . is_a? String add_notation_dependency ( dependent , 'compile' ) add_dependency ( dependent )", "del_tokens": "def add_dependency ( notation , scope = 'compile' ) @resolver . clearDependencies ( ) ; add_dependency ( key , dependent [ key ] ) add_dependency ( dependent )", "commit_type": "allow"}
{"commit_tokens": ["Used", "transpec", "to", "upgrade", "to", "RSpec", "3", ".", "x", "."], "add_tokens": "expect ( subject . const_get ( 'VERSION' ) ) . not_to be_empty expect ( subject [ var_name ] ) . to eq ( var_value ) expect ( subject [ 'FOO' ] ) . to eq ( 'bar' ) expect ( subject . const_get ( var_name ) ) . to eq ( var_value ) expect ( subject . send ( method_name ) ) . to eq ( var_value ) expect ( subject [ 'SHELL' ] ) . to eq ( '/bin/zsh' )", "del_tokens": "subject . const_get ( 'VERSION' ) . should_not be_empty subject [ var_name ] . should == var_value subject [ 'FOO' ] . should == 'bar' subject . const_get ( var_name ) . should == var_value subject . send ( method_name ) . should == var_value subject [ 'SHELL' ] . should == '/bin/zsh'", "commit_type": "use"}
{"commit_tokens": ["Added", "assertions", "for", "posting", "."], "add_tokens": "oauth = \"OAuth #{@token}\" 'Authorization' => oauth , key = \"rest-gem-post\" response = @rest . post ( \"http://rest-test.iron.io/code/200?store=#{key}\" , response = @rest . get ( \"http://rest-test.iron.io/stored/#{key}\" ) parsed = JSON . parse ( response . body ) p parsed assert_equal body , JSON . parse ( parsed [ 'body' ] ) assert_equal oauth , parsed [ 'headers' ] [ 'Authorization' . upcase ] response = @rest . post ( \"http://rest-test.iron.io/code/200?store=#{key}\" ,", "del_tokens": "'Authorization' => \" OAuth #{@token}\", response = @rest . post ( \"#{bin}\" , response = @rest . post ( \"#{bin}\" ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "regex", "check", "in", "filter_and_post"], "add_tokens": "fetch_new_posts", "del_tokens": "fetch_posts", "commit_type": "fix"}
{"commit_tokens": ["Add", "helpers", "to", "toggle", "cursor", "mouse", "example", "and", "TODO", "about", "pasting", "via", "mouse"], "add_tokens": "@@reterm_opts = opts disable_cursor! unless ! ! opts [ :cursor ] Ncurses :: mousemask ( MouseInput :: ALL_EVENTS , [ ] ) unless no_mouse # Return copy of options specified to init_reterm def reterm_opts @@_reterm_opts ||= Hash [ @@reterm_opts ] end ### # Cursor def cursor? ! ( @@cursor_disabled ||= false ) end def disable_cursor! # store cursor state o = cursor? # set cursor state @@cursor_disabled = true Ncurses :: curs_set ( 0 ) # invoke block if given return unless block_given? yield # restore cursor state after block enable_cursor! if o end def enable_cursor! # store cursor state o = cursor? # set cursor state @@cursor_disabled = false Ncurses :: curs_set ( 1 ) # invoke block if given return unless block_given? yield # restore cursor state after block disable_cursor! unless o end", "del_tokens": "Ncurses :: curs_set ( 0 ) # TODO toggleable Ncurses :: mousemask ( Ncurses :: ALL_MOUSE_EVENTS | Ncurses :: REPORT_MOUSE_POSITION , [ ] ) unless no_mouse", "commit_type": "add"}
{"commit_tokens": ["Added", "#time", "method", "that", "tracks", "timing", "for", "block", "."], "add_tokens": "describe \"#time\" do it \"should format the message according to the statsd spec\" do @statsd . time ( 'foobar' ) { sleep ( 0.001 ) ; 'test' } @statsd . socket . recv . must_equal [ 'foobar:1|ms' ] end it \"should return the result of the block\" do result = @statsd . time ( 'foobar' ) { sleep ( 0.001 ) ; 'test' } result . must_equal 'test' end describe \"with a sample rate\" do before { class << @statsd ; def rand ; 0 ; end ; end } # ensure delivery it \"should format the message according to the statsd spec\" do result = @statsd . time ( 'foobar' , 0.5 ) { sleep ( 0.001 ) ; 'test' } @statsd . socket . recv . must_equal [ 'foobar:1|ms|@0.5' ] end end end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Move", "client", "to", "class", "-", "level", "instance", "variable"], "add_tokens": "self . class . client ( url ) def self . client ( url ) @client ||= { } @client [ url ] ||= Savon . new ( url ) end", "del_tokens": "@@client = { } @@client [ url ] ||= Savon . new ( url )", "commit_type": "move"}
{"commit_tokens": ["Use", "Rails", ".", "logger", "when", "on", "Rails"], "add_tokens": "APN . logger = Rails . logger", "del_tokens": "logger = Logger . new ( File . join ( Rails . root , 'log' , 'apn_sender.log' ) ) APN . logger = logger", "commit_type": "use"}
{"commit_tokens": ["Fix", "color", "expectations", "when", "$stdout", ".", "tty?", "is", "false"], "add_tokens": "expected_log_output << \"\\e[0m\" if color_output? if color_output? \"\\\\e\\\\[#{code}m#{string}\\\\e\\\\[0m\" else string end # Whether or not SSHKit emits color depends on the test environment. SSHKit # versions up to 1.7.1 added colors to the log file, but only if # `$stdout.tty?` is true. Later versions never output color to the log file. def color_output? $stdout . tty? && ! ( sshkit_after? ( \"1.7.1\" ) || sshkit_master? )", "del_tokens": "expected_log_output << \"\\e[0m\" unless sshkit_master? color_if_legacy ( string , code ) def color_if_legacy ( text , color ) # SSHKit versions up to 1.7.1 added colors to the log file even though it did not have a tty. # Versions after this don't, so we must match output both with, and without colors # depending on the SSHKit version. if sshkit_after? ( \"1.7.1\" ) || sshkit_master? text else \"\\\\e\\\\[#{color}m#{text}\\\\e\\\\[0m\" end", "commit_type": "fix"}
{"commit_tokens": ["add", "realtime", "to", "lang", "switch"], "add_tokens": "respond_to do | format | format . js end # This function set a default language on cookie if no languages are set.", "del_tokens": "redirect_to lato_blog . root_path", "commit_type": "add"}
{"commit_tokens": ["Made", "small", "changes", "to", "get", "to", "some", "corner", "cases", "that", "had", "proved", "to", "be"], "add_tokens": "ind . offences . size . should == 2 source = [ 'y = case a' , ' when 0 then break' , ' z = case b' , ' when 1 then return' , 'case c' , 'when 2 then encoding' , 'end' ,", "del_tokens": "ind . offences . map ( & :message ) . should == [ \"Indent when as deep as case.\" , \"Indent when as deep as case.\" ] source = [ 'y = case x' , ' z = case w' , ' when 0 then return' , ' when 1 then break' , def check_offence ( offence , line_number , message ) offence . message . should == message offence . line_number . should == line_number end", "commit_type": "make"}
{"commit_tokens": ["Added", "methods", "to", "generate", "lesscss", "files", "before", "the", "public", "directory", "is", "moved", "around"], "add_tokens": "protected generate_css_from_less def generate_css_from_less Dir [ \"#{Smeg.root_dir}/public/**/*.less\" ] . each do | lessfile | css = File . open ( lessfile ) { | f | Less :: Engine . new ( f ) } . to_css path = \"#{File.dirname(lessfile)}/#{File.basename(lessfile, \".less\")}.css\" File . open ( path , \"w\" ) { | file | file . write ( css ) } end end", "del_tokens": "private", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "warnings", "around", "unintialized", "instance", "variables"], "add_tokens": "possible_file_name = if instance_variable_defined? :@tcfg_config_filename possible_file_name = if instance_variable_defined? :@tcfg_secret_config_filename", "del_tokens": "possible_file_name = if @tcfg_config_filename possible_file_name = if @tcfg_secret_config_filename", "commit_type": "fix"}
{"commit_tokens": ["Changed", "require", "order", "a", "bit"], "add_tokens": "require 'rubygems'", "del_tokens": "require 'rubygems'", "commit_type": "change"}
{"commit_tokens": ["Use", "Connection#socket_key", "instead", "of", "@connection", ".", "inspect", "."], "add_tokens": "Thread . current [ :_excon_sockets ] [ socket_key ] = new_socket if ! Thread . current [ :_excon_sockets ] [ socket_key ] || Thread . current [ :_excon_sockets ] [ socket_key ] . closed? Thread . current [ :_excon_sockets ] [ socket_key ] def socket_key \"#{@connection[:host]}:#{@connection[:port]}\" end", "del_tokens": "Thread . current [ :_excon_sockets ] [ @connection . inspect ] = new_socket if ! Thread . current [ :_excon_sockets ] [ @connection . inspect ] || Thread . current [ :_excon_sockets ] [ @connection . inspect ] . closed? Thread . current [ :_excon_sockets ] [ @connection . inspect ]", "commit_type": "use"}
{"commit_tokens": ["Changed", "the", "body", "method", "to", "accept", "blocks", "as", "well", "as", "strings", ".", "Also", "added", "example", "calendar", "app", "to", "be", "built", "more", "in", "the", "future", ".", "Finally", "added", "the", "respon_to", "block", ".", "View", "readme", "for", "example"], "add_tokens": "def body ( value = nil , & block ) @body = block . call if block", "del_tokens": "def body ( value = nil )", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "user", "specified", "output"], "add_tokens": "@io = output @result = Array . new @io = File . open ( \"./rspec.res\" , \"w\" ) if @io . class . to_s != \"File\"", "del_tokens": "@result = Array . new @io = File . open ( \"./rspec.res\" , \"w\" )", "commit_type": "add"}
{"commit_tokens": ["Move", "addon", "enabling", "logic", "to", "the", "shared", "actions", "module"], "add_tokens": "addons . each { | script | addon ( script ) }", "del_tokens": "def normalize_addon_paths addons . map! do | path | if URI ( path ) . is_a? ( URI :: HTTP ) path elsif File . exist? \"#{self.class.bundled_addons_path}/#{path}.rb\" \"#{self.class.bundled_addons_path}/#{path}.rb\" else File . expand_path ( path ) end end end addons . each { | addon | apply addon }", "commit_type": "move"}
{"commit_tokens": ["Fixing", "type", "of", "constant", "."], "add_tokens": "module Rack", "del_tokens": "class Rack", "commit_type": "fix"}
{"commit_tokens": ["fixing", "travis", "/", "version", "bump"], "add_tokens": "VERSION = '0.3.2'", "del_tokens": "VERSION = '0.3.1'", "commit_type": "fix"}
{"commit_tokens": ["fix", "issue", "with", "adding", "split", "-", "date", "to", "other", "selects"], "add_tokens": "year_html_options = html_options . dup year_html_options [ :class ] = year_html_options [ :class ] ? \"#{year_html_options[:class]} #{html_classes.join(' ')}\" : html_classes . join ( ' ' ) datepicker_select_html ( :year , year_options , options , year_html_options )", "del_tokens": "html_options [ :class ] = html_options [ :class ] ? \"#{html_options[:class]} #{html_classes.join(' ')}\" : html_classes . join ( ' ' ) datepicker_select_html ( :year , year_options , options , html_options )", "commit_type": "fix"}
{"commit_tokens": ["add", "assigning", "static", "IPs", "for", "both", "LXD", "and", "KVM"], "add_tokens": "method_option :provider , :aliases => '-p' , :type => :string , :default => ' lxd ', :desc => ' A provider such as lxd and libvirt ' method_option :chef , :aliases => '-c' , :type => :boolean , :default => false , :desc => 'Chef awareness' method_option :vlans , :aliases => '-v' , :type => :array , :desc => 'A list of VLAN IDs to connect to' method_option :ipaddresses , :aliases => '-i' , :type => :array , :desc => 'A list of static IPs to assign' def create ( name ) abort ( \"vlans and ipaddresses can not be used at the same time.\" ) if options [ 'vlans' ] and options [ 'ipaddresses' ] case options [ :provider ] Gogetit . lxd . create ( name , options . to_hash ) Gogetit . libvirt . create ( name , options . to_hash ) print \"ssh #{Gogetit.config[:default][:user]}@#{name}\"", "del_tokens": "method_option :chef , :type => :boolean , :desc => \"Enable chef awareness.\" def create ( type = 'lxd' , name ) case type Gogetit . lxd . create ( name ) Gogetit . libvirt . create ( name )", "commit_type": "add"}
{"commit_tokens": ["Add", "retries", "for", "tcp", "connection", "and", "read", "default", "of", "10", "retries", "still", "1", "second", "timeout", ".", "Fix", "typos", "-", "changed"], "add_tokens": "# Number of times to retry on connection and read timeouts CONNECTION_RETRIES = 10 READ_RETRIES = 10 def read_discrete_inputs ( addr , ncoils ) # Deprecated version of read_discrete_inputs def read_discret_inputs ( addr , ncoils ) warn \"[DEPRECATION] `read_discret_inputs` is deprecated. Please use `read_discrete_inputs` instead.\" read_discrete_inputs ( addr , ncoils ) end tried = 0 begin timeout ( 1 , ModBusTimeout ) do pdu = read_pdu end rescue ModBusTimeout => err tried += 1 retry unless tried >= READ_RETRIES raise ModBusTimeout . new , 'Timed out during read attempt' pdu = read_pdu + raise SlaveDeviceBus . new , \"The server is engaged in processing a long duration program command\" raise ModBusException . new , \"Unknown error\" def close end", "del_tokens": "def read_discret_inputs ( addr , ncoils ) timeout ( 1 ) do pdu = read_pdu raise SlaveDiviceBus . new , \"The server is engaged in processing a long duration program command\" raise ModBusException . new , \"Unknow error\"", "commit_type": "add"}
{"commit_tokens": ["fixed", "problem", "with", "boot", "loading"], "add_tokens": "Dir . chdir ( File . join ( File . dirname ( __FILE__ ) , '.' ) )", "del_tokens": "Dir . chdir ( File . join ( File . dirname ( __FILE__ ) , '..' ) )", "commit_type": "fix"}
{"commit_tokens": ["Change", "default", "time", "precision", "to", "seconds", "."], "add_tokens": "@time_precision = opts [ :time_precision ] || \"s\"", "del_tokens": "@time_precision = opts [ :time_precision ] || \"m\"", "commit_type": "change"}
{"commit_tokens": ["Adds", "support", "for", "slim", "templates"], "add_tokens": "if preprocessor? 'erb' insert_into_file \"app/views/layouts/application.html.erb\" , \"<%= html_import_tag \\\"application\\\", \\\"data-turbolinks-track\\\" => true %>\\n \" , before : \"<%= csrf_meta_tags %>\" elsif preprocessor? 'slim' insert_into_file \"app/views/layouts/application.slim\" , \"= html_import_tag \\\"application\\\", \\\"data-turbolinks-track\\\" => true\\n \" , before : \"= csrf_meta_tags\" end private def preprocessor? ( preprocessor_name ) layout_file_name = 'app/views/layouts/application' File . exists? ( \"#{layout_file_name}.html.#{preprocessor_name}\" ) || File . exists? ( \"#{layout_file_name}.#{preprocessor_name}\" ) end", "del_tokens": "insert_into_file \"app/views/layouts/application.html.erb\" , \"<%= html_import_tag \\\"application\\\", \\\"data-turbolinks-track\\\" => true %>\\n \" , before : \"<%= csrf_meta_tags %>\"", "commit_type": "add"}
{"commit_tokens": ["add", "option", "-", "k", "--", "ssl_no_verify", "for", "cli"], "add_tokens": "def initialize ( accesskey , secret , api = '2011-05-05' , endpoint = 'https://route53.amazonaws.com/' , verbose = false , ssl_no_verify = false ) @ssl_no_verify = ssl_no_verify http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE if RUBY_VERSION . start_with? ( \"1.8\" ) or @ssl_no_verify ( 0 ... name_arr . size ) . each do | i | http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE if RUBY_VERSION . start_with? ( \"1.8\" ) or @ssl_no_verify # \"unique string that identifies the request and that", "del_tokens": "def initialize ( accesskey , secret , api = '2011-05-05' , endpoint = 'https://route53.amazonaws.com/' , verbose = false ) http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE if RUBY_VERSION . start_with? ( \"1.8\" ) ( 0 ... name_arr . size ) . each do | i | http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE if RUBY_VERSION . start_with? ( \"1.8\" ) # \"unique string that identifies the request and that", "commit_type": "add"}
{"commit_tokens": ["added", "create", "task", "(", "open", "alias", "for", "Termfile", ")"], "add_tokens": "context \"with open\" do setup { mock . instance_of ( Terminitor :: Cli ) . open_in_editor ( \"/tmp/sample_project/Termfile\" ) { true } . once } setup { capture ( :stdout ) { Terminitor :: Cli . start ( [ 'open' , '-r=/tmp/sample_project' ] ) } } asserts_topic . matches %r{ create } asserts_topic . matches %r{ Termfile } end context \"with create\" do setup { mock . instance_of ( Terminitor :: Cli ) . invoke ( :open , [ ] , :root => '/tmp/sample_project' ) { true } . once } asserts ( 'calls open' ) { capture ( :stdout ) { Terminitor :: Cli . start ( [ 'create' , '-r=/tmp/sample_project' ] ) } } end", "del_tokens": "setup { mock . instance_of ( Terminitor :: Cli ) . open_in_editor ( \"/tmp/sample_project/Termfile\" ) { true } . once } setup { capture ( :stdout ) { Terminitor :: Cli . start ( [ 'open' , '-r=/tmp/sample_project' ] ) } } asserts_topic . matches %r{ create } asserts_topic . matches %r{ Termfile }", "commit_type": "add"}
{"commit_tokens": ["Make", "Authenticatable", "lookup", "case", "-", "insensitive"], "add_tokens": "\"lower(#{email_field}) = ?\" , params [ :passwordless ] [ email_field ] . downcase", "del_tokens": "\"lower(#{email_field}) = ?\" , params [ :passwordless ] [ email_field ]", "commit_type": "make"}
{"commit_tokens": ["Allow", "a", "base", "URL", "to", "be", "based", "in", "instead", "of", "specifying", "all", "of", "its", "parts", "piecewise", "."], "add_tokens": "DEFAULT_URL = \"http://api.sendwithus.com\" default_source = URI . parse ( options [ :url ] || DEFAULT_URL ) @api_proto = options [ :api_proto ] || default_source . scheme @api_host = options [ :api_host ] || default_source . host @api_version = options [ :api_version ] || 0 @api_port = options [ :api_port ] || default_source . port @debug = options [ :debug ] @base_url = URI . parse ( \"#{@api_proto}://#{@api_host}:#{@api_port}/api/v#{@api_version}\" )", "del_tokens": "@api_proto = options [ :api_proto ] || 'http' @api_host = options [ :api_host ] || 'api.sendwithus.com' @api_version = options [ :api_version ] || '0' @api_port = options [ :api_port ] || '80' @debug = options [ :debug ] || false", "commit_type": "allow"}
{"commit_tokens": ["Add", "threshold", "check", "to", "pagination", "scope"], "add_tokens": "EMPTY_PAGINATION_ERROR_THRESHOLD = 1_000 else count = search_scope . count if count > EMPTY_PAGINATION_ERROR_THRESHOLD raise 'Search returns too many results without pagination. %d results found. Threshold is %d' % [ count , EMPTY_PAGINATION_ERROR_THRESHOLD ] end private respond_to_and_has_and_present? ( pagination , :sort_direction ) && respond_to_and_has_and_present? ( proto . options . pagination , :page )", "del_tokens": "private respond_to_and_has_and_present? ( pagination , :sort_direction ) && respond_to_and_has_and_present? ( proto . options . pagination , :page )", "commit_type": "add"}
{"commit_tokens": ["remove", "sqlite", "dependency", "-", "use", "Sequel", ".", "mock", "instead"], "add_tokens": "Sequel :: Model . db = Sequel . mock Philtre :: Grinder . new ( Philtre :: Filter . new ) . transform ( Ods ) . sql . should =~ / SELECT \\* FROM ods /", "del_tokens": "Sequel :: Model . db = Sequel . sqlite Philtre :: Grinder . new ( Philtre :: Filter . new ) . transform ( Ods ) . sql . should =~ / SELECT \\* FROM .ods. /", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "where", "SET", "commands", "never", "finish"], "add_tokens": "if db . respond_to? ( :log_connection_execute ) db . send ( :log_connection_execute , c , stmt ) elsif c . respond_to? ( :log_connection_execute ) c . send ( :log_connection_execute , stmt ) elsif c . respond_to? ( :execute ) cursor = c . send ( :execute , stmt ) if cursor && cursor . respond_to? ( :close ) cursor . close end elsif db . respond_to? ( :execute ) db . send ( :execute , stmt ) else raise \"Failed to run SET queries\" end", "del_tokens": "execute_meth = c . respond_to? ( :log_connection_execute ) ? :log_connection_execute : :execute c . send ( execute_meth , stmt )", "commit_type": "fix"}
{"commit_tokens": ["Add", "transproc", "/", "all", "file", "that", "loads", "it", "all"], "add_tokens": "require 'transproc/all'", "del_tokens": "require 'transproc'", "commit_type": "add"}
{"commit_tokens": ["Move", "to", "new", "gem", "structure"], "add_tokens": "end", "del_tokens": "end", "commit_type": "move"}
{"commit_tokens": ["Adding", "on!", "and", "off!", "methods", "."], "add_tokens": "# determine if the light is on or off # turn on the light def on! set ( :on => true ) end # turn off the light def off! set ( :on => false ) end", "del_tokens": "#TODO: can this be set-able?", "commit_type": "add"}
{"commit_tokens": ["added", "new", "versioning", "style", "for", "gem"], "add_tokens": "module TheBigDB", "del_tokens": "class TheBigDB", "commit_type": "add"}
{"commit_tokens": ["Made", "PermitRule#matches?", "raise", "an", "error", "when", "target", "resource", "doesn", "t", "exist", "."], "add_tokens": "var_name = \"@#{@target_var.to_s}\" if eval ( %Q{instance_variables.include? \"#{var_name}\"} , context_binding ) eval var_name , context_binding else raise PermitEvaluationError , \"Target resource '#{var_name}' did not exist in the given context.\" end", "del_tokens": "eval \"@#{@target_var.to_s}\" , context_binding", "commit_type": "make"}
{"commit_tokens": ["Add", "HTML", "attribute", "spec", "for", "form_element", "."], "add_tokens": "@html_attributes = args . extract_options! classnames = @html_attributes . delete ( :class ) @classnames_list = [ ] @classnames_list . push ( classnames ) if classnames def render ( form , classnames = nil ) classnames_list = @classnames_list classnames_list = [ * classnames_list , classnames ] if classnames options = @html_attributes . dup options [ :class ] = classnames_list . join ( ' ' ) unless classnames_list . empty? form . public_send ( @type , @attribute_name , options )", "del_tokens": "attr_accessor @html_attrs = args . extract_options! class_attr = @html_attrs . delete ( :class ) @classnames = [ ] @classnames . push ( class_attr ) if class_attr def render ( form , html_attrs = { } ) class_attr = @html_attrs . delete ( :class ) classnames = class_attr ? @classnames . dup . push ( class_attr ) : @classnames options = ! classnames . empty? ? @html_attrs . merge ( class : classnames . join ( ' ' ) ) : @html_attrs form . public_send ( @type , @attribute_name , options . merge ( html_attrs ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "message", "for", "url", "upload", "empty", "file"], "add_tokens": "content = RestClient . get ( url ) rescue nil file . write ( content ) end if content", "del_tokens": "file . write RestClient . get ( url ) end", "commit_type": "add"}
{"commit_tokens": ["Update", "README", ".", "md", "with", "Decoder#words", "info"], "add_tokens": "until seg_iter . null? do ps_api . ps_seg_word ( seg_iter ) , start_frame . get_int16 ( 0 ) , end_frame . get_int16 ( 0 )", "del_tokens": "while ! seg_iter . null? do ps_api . ps_seg_word ( seg_iter ) , start_frame . get_int16 ( 0 ) , end_frame . get_int16 ( 0 )", "commit_type": "update"}
{"commit_tokens": ["move", "template", "generator", "into", "default", "install", "generator"], "add_tokens": "VERSION = \"0.1.0\"", "del_tokens": "VERSION = \"0.0.9\"", "commit_type": "move"}
{"commit_tokens": ["Make", "orders", "not", "throw", "invalid", "args", "errors", "about", "addresses", "order_items", "and", "shipping_rate", "."], "add_tokens": "panel_id coupon_rebate address shipping_rate order_items | def address Oshpark :: Address . from_json @address if @address end def shipping_rate Oshpark :: ShippingRate . from_json @shipping_rate if @shipping_rate end def order_items Array ( @order_items ) . map do | order_item | Oshpark :: OrderItem . from_json order_item end end", "del_tokens": "panel_id |", "commit_type": "make"}
{"commit_tokens": ["Add", "specific", "installation", "modes", "for", "gzip", "and", "bzip2", "compression", "."], "add_tokens": "def filename \"#{self.name}.tar\" end output = ` cd #{ Dir . tmpdir } ; tar xvf #{ filename } ` class Gzip < Tarball def filename @unpacked ? super : \"#{self.name}.tar.gz\" end def unpack system \"cd #{Dir.tmpdir}; gunzip #{self.filename}\" @unpacked = true super end end class Bzip2 < Tarball def filename @unpacked ? super : \"#{self.name}.tar.bz2\" end def unpack system \"cd #{Dir.tmpdir}; bunzip2 #{self.filename}\" @unpacked = true super end end", "del_tokens": "packed = filename =~ / gz / ? 'z' : '' output = ` cd #{ Dir . tmpdir } ; tar xvf #{ packed } #{ filename } `", "commit_type": "add"}
{"commit_tokens": ["Improved", ".", "simple_stats", "to", "only", "load", "commits", "once"], "add_tokens": "commits = repo . commits ( branch ) :commit_count => commits . size , } . merge Commit . activity ( commits )", "del_tokens": ":commit_count => repo . commits ( branch ) . size , } . merge Commit . activity ( repo . commits ( branch ) )", "commit_type": "improve"}
{"commit_tokens": ["Updating", "events", "for", "list", "webhooks", "."], "add_tokens": "# Valid events are \"Subscribe\", \"Deactivate\", and \"Update\". # Valid payload formats are \"json\", and \"xml\".", "del_tokens": "# Valid events are \"Subscribe\", \"Unsubscribe\", \"Bounce\", \"Spam\", and # \"SubscriberUpdate\". Valid payload formats are \"json\", and \"xml\".", "commit_type": "update"}
{"commit_tokens": ["Add", "find_by_id", "to", "active_record", "repository"], "add_tokens": "describe \"calling default record functions\" do let ( :task_one ) { DummyTaskRecord . new ( 1 ) } it 'find_by_id' do expect ( DummyTaskRecord ) . to receive ( :find ) . with ( 1 ) . and_return ( task_one ) task = registry . tasks . find_by_id ( 1 ) expect ( task ) . to eq task_one end it 'find_by_ids' do expect ( DummyTaskRecord ) . to receive ( :where ) . with ( id : 1 ) . and_return ( [ task_one ] ) tasks = registry . tasks . find_by_ids ( 1 ) expect ( tasks . count ) . to eq 1 expect ( tasks [ 0 ] ) . to eq task_one end it 'all' do expect ( DummyTaskRecord ) . to receive ( :all ) . and_return ( [ task_one ] ) tasks = registry . tasks . all expect ( tasks . count ) . to eq 1 expect ( tasks [ 0 ] ) . to eq task_one end end end", "del_tokens": "end", "commit_type": "add"}
{"commit_tokens": ["add", "multi", "-", "node", "support", "for", "listening", "on", "multiple", "protocols"], "add_tokens": "em_run do em_run do", "del_tokens": "EventMachine . run do EventMachine . run do", "commit_type": "add"}
{"commit_tokens": ["Added", "association", "convenience", "methods", "for", "collections", "and", "items"], "add_tokens": "def get_all_items ( query = { } ) response = self . get ( 'items' , nil , query ) . body return OmekaClient :: OmekaCollection . new ( self , JSON . parse ( response ) ) all_collections . push OmekaClient :: OmekaCollection . new ( self , item_hash )", "del_tokens": "def get_all_items ( ) response = self . get ( 'items' ) . body return OmekaClient :: OmekaCollection . new ( JSON . parse ( response ) ) all_collections . push OmekaClient :: OmekaCollection . new ( item_hash )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "-", "clusters", "method", "is", "not", "filtering", "by", "current", "data", "center", "."], "add_tokens": "cluster = OVIRT :: Cluster . new ( self , cl ) #the following line is needed as a work-around a bug in RHEV 3.0 rest-api cluster if cluster . datacenter . id == current_datacenter . id end . compact", "del_tokens": "OVIRT :: Cluster . new ( self , cl ) end", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "convenience", "method", "wrapping", "{", "enable", "disable", "}", "_rate_limit_forward"], "add_tokens": "before ( :each ) do Algolia . enable_rate_limit_forward ENV [ 'ALGOLIA_API_KEY' ] , \"1.2.3.4\" , \"ratelimitapikey\" it \"should use original headers\" do Algolia . disable_rate_limit_forward it \"should pass the right headers in the scope\" do WebMock . stub_request ( :get , %r{ https://.* \\. algolia \\. io/1/indexes/friends \\? query=.* } ) . with ( :headers => { 'Content-Type' => 'application/json; charset=utf-8' , 'User-Agent' => \"Algolia for Ruby #{Algolia::VERSION}\" , 'X-Algolia-Api-Key' => ENV [ 'ALGOLIA_API_KEY' ] , 'X-Algolia-Application-Id' => ENV [ 'ALGOLIA_APPLICATION_ID' ] , 'X-Forwarded-Api-Key' => 'ratelimitapikey' , 'X-Forwarded-For' => '1.2.3.4' } ) . to_return ( :status => 200 , :body => \"{ \\\"hits\\\": [], \\\"fakeAttribute\\\": 1 }\" , :headers => { } ) Algolia . with_rate_limits \"1.2.3.4\" , \"ratelimitapikey\" do index = Algolia :: Index . new ( \"friends\" ) index . search ( 'foo' ) [ 'fakeAttribute' ] . should == 1 index . search ( 'bar' ) [ 'fakeAttribute' ] . should == 1 end end after ( :each ) do", "del_tokens": "before ( :all ) do Algolia . enable_rate_limit_forward ENV [ 'ALGOLIA_API_KEY' ] , \"1.2.3.4\" , \"ratelimitapikey\" it \"should previous headers\" do Algolia . disable_rate_limit_forward after ( :all ) do", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "encoding", "comment", "."], "add_tokens": "VERSION = \"0.0.9.1\"", "del_tokens": "VERSION = \"0.0.9\"", "commit_type": "add"}
{"commit_tokens": ["make", "install", "-", "dir", "-", "specific", "build", "manifests"], "add_tokens": "\"#{config.build_dir}/#{camel_case_path(install_dir)}\" manifest_file_from_name ( @name ) def manifest_file_from_name ( software_name ) \"#{build_dir}/#{software_name}.manifest\" end def camel_case_path ( path ) # split the path and remove and empty strings parts = path . split ( \"/\" ) - [ \"\" ] parts . join ( \"_\" ) file manifest_file => manifest_file_from_name ( dep )", "del_tokens": "config . build_dir self . class . manifest_file_from_name ( @name ) def self . manifest_file_from_name ( software_name ) \"#{Omnibus.config.build_dir}/#{software_name}.manifest\" file manifest_file => self . class . manifest_file_from_name ( dep )", "commit_type": "make"}
{"commit_tokens": ["Allow", "VAT", "number", "search", "in", "multiple", "countries"], "add_tokens": "require \"creditsafe/constants\" @vat_number = search_criteria [ :vat_number ] unless vat_number . nil? search_criteria [ \"#{Creditsafe::Namespace::DAT}:VatNumber\" ] = vat_number end attr_reader :country_code , :registration_number , :city , :company_name , :postal_code , :vat_number # rubocop:disable Metrics/PerceivedComplexity # rubocop:disable Metrics/AbcSize unless only_one_required_criteria? ( search_criteria ) raise ArgumentError , \"only one of registration_number, company_name or \" \"vat number is required search criteria\" if search_criteria [ :vat_number ] && ! Constants :: Country :: VAT_NUMBER_SUPPORTED . include? ( search_criteria [ :country_code ] ) raise ArgumentError , \"VAT number is not supported in this country\" end # rubocop:enable Metrics/AbcSize # rubocop:enable Metrics/PerceivedComplexity def only_one_required_criteria? ( search_criteria ) by_registration_number = ! search_criteria [ :registration_number ] . nil? by_company_name = ! search_criteria [ :company_name ] . nil? by_vat_number = ! search_criteria [ :vat_number ] . nil? ( by_registration_number ^ by_company_name ^ by_vat_number ) && ! ( by_registration_number && by_company_name && by_vat_number )", "del_tokens": "attr_reader :country_code , :registration_number , :city , :company_name , :postal_code unless only_registration_number_or_company_name_provided? ( search_criteria ) raise ArgumentError , \"registration_number or company_name (not both) are \" \"required search criteria\" def only_registration_number_or_company_name_provided? ( search_criteria ) search_criteria [ :registration_number ] . nil? ^ search_criteria [ :company_name ] . nil?", "commit_type": "allow"}
{"commit_tokens": ["Make", "the", "Figaro", ".", "env", "proxy", "case", "-", "insensitive"], "add_tokens": "pair = ENV . detect { | k , _ | k . upcase == method . to_s . upcase } pair ? pair [ 1 ] : super def respond_to? ( method , * ) ENV . keys . any? { | k | k . upcase == method . to_s . upcase } || super", "del_tokens": "ENV . fetch ( method . to_s . upcase ) { super } def respond_to? ( method ) ENV . key? ( method . to_s . upcase )", "commit_type": "make"}
{"commit_tokens": ["fixed", "the", "handling", "of", "invalid", "page", "numbers", "in", "the", "paginate", "method"], "add_tokens": "# @param [Hash] options Options for the persistent database # @option options [Integer] :page (1) The page to access def paginate ( options = { } ) @current_page = options [ :page ] ? options [ :page ] . to_i : 1 raise ArgumentError . new ( \"page #{current_page} does not exist\" ) if @current_page < 1 || @current_page > @total_pages", "del_tokens": "# @param [Hash] opts Options for the persistent database # @option opts [Integer] :page (1) The page to access def paginate ( opts = { } ) options = { :page => 1 } . merge ( opts ) @current_page = options [ :page ] . to_i page . nil? ? page = 1 : page = page . to_i", "commit_type": "fix"}
{"commit_tokens": ["change", "MessagingClient", ".", "start", "()", "to", "accept", "a", "block", "to", "modify", "the", "default", "manifest", "."], "add_tokens": "def self . start ( amqp_uri , manifest = nil , & blk ) node = self . new ( manifest , & blk ) def sync_request ( endpoint , key , * args )", "del_tokens": "def self . start ( amqp_uri , manifest = nil ) node = self . new ( manifest ) def sync_request ( endpoint , key , args )", "commit_type": "change"}
{"commit_tokens": ["Add", "spec", "tests", "for", "module_path"], "add_tokens": "unless File . file? ( environment_conf ) return [ File . join ( compilation_dir , 'modules' ) ] end", "del_tokens": "return [ File . join ( compilation_dir , 'modules' ) ] unless File . file? ( environment_conf )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "link", "as", "lambdas"], "add_tokens": "label , url = attr [ :label ] , attr [ :url ] label = attr [ :label ] . call ( resource , attr ) if attr [ :label ] . respond_to? :call url = attr [ :url ] . call ( resource , attr ) if attr [ :url ] . respond_to? :call o . link_to label , url , attr [ :params ]", "del_tokens": "attr [ :label ] = attr [ :label ] . call ( resource , attr ) if attr [ :label ] . respond_to? :call attr [ :url ] = attr [ :url ] . call ( resource , attr ) if attr [ :url ] . respond_to? :call o . link_to attr [ :label ] , attr [ :url ] , attr [ :params ]", "commit_type": "fix"}
{"commit_tokens": ["fix", "naming", "of", "root?", "to", "is_root?", "etc", "."], "add_tokens": "if self . is_leaf?", "del_tokens": "if self . leaf?", "commit_type": "fix"}
{"commit_tokens": ["Add", "version", "to", "lib", "/", "active_copy", ".", "rb"], "add_tokens": "require 'active_copy/version'", "del_tokens": "require 'bundler' Bundler . require :active_copy", "commit_type": "add"}
{"commit_tokens": ["Make", "monitoring", "API", "consistent", "with", "pubsub"], "add_tokens": "if @monitoring emit ( :monitor , reply ) @monitoring = true", "del_tokens": "if @monitor_callback @monitor_callback . call ( reply ) @monitor_callback = blk", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "except", "option", "in", "authorize", "macro"], "add_tokens": "valid_arguments = parse_and_validate_arguments ( args ) self . instance_variable_set ( :@_verifiable_routes , valid_arguments [ :only ] ) unless valid_arguments [ :only ] . nil? self . instance_variable_set ( :@_verifiable_routes , self . action_methods - valid_arguments [ :except ] ) unless valid_arguments [ :except ] . nil? self . instance_variable_set ( :@_verifiable_routes , self . action_methods ) if valid_arguments [ :all ] end def parse_and_validate_arguments ( args = { } ) result = { } ( result [ :all ] = true ) and return if args . to_s == \"all\" [ :only , :except ] . each do | key | unless args [ key ] . nil? raise ActionsValueException unless args [ key ] . instance_of? ( Array ) result [ key ] = args [ key ] . map! { | v | v . to_s } . to_set end end", "del_tokens": "self . instance_variable_set ( :@_verifiable_routes , args [ :only ] ) unless args [ :only ] . nil? # TODO: understand and fix it self . instance_variable_set ( :@_verifiable_routes , self . action_methods - args [ :except ] ) unless args [ :except ] . nil?", "commit_type": "fix"}
{"commit_tokens": ["Add", "Snow", "::", "SNOW_MATH_VERSION", "constant", "."], "add_tokens": "module Snow # # snow-math bindings version string. # SNOW_MATH_VERSION = '1.3.0pre0' end", "del_tokens": "module Snow ; end", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "custom", "reports"], "add_tokens": "require 'linkshare/custom_reports' custom_reports : \"https://ran-reporting.rakutenmarketing.com/en/reports\" , attr_accessor :consumer_key , :consumer_secret , :sid , :username , :password , :security_token , :custom_report_token def self . customreports @customreports ||= Linkshare :: CustomReports . new end", "del_tokens": "attr_accessor :consumer_key , :consumer_secret , :sid , :username , :password , :security_token", "commit_type": "add"}
{"commit_tokens": ["added", "wrapper", "to", "nutcracker", "executable"], "add_tokens": "require 'socket' require 'json' def self . start options Nutcracker :: Process . new ( options ) . start end def self . executable File . expand_path ( \"../../ext/nutcracker/src/nutcracker\" , __FILE__ ) end Nutcracker :: VERSION class Process attr_reader :pid , :options def initialize options @options = options end def start raise RuntimeError , \"Nutcracker is already running (#{pid})...\" if running? @pid = :: Process . spawn ( \"#{Nutcracker.executable} -c #{options.fetch(:config_file).inspect}\" ) Kernel . at_exit { stop if running? } self end def running? ! ! ( pid and :: Process . getpgid pid rescue false ) end def stop signal :TERM end def kill signal :KILL end def join verify_running! and :: Process . waitpid2 pid end def stats JSON . parse TCPSocket . new ( 'localhost' , 22222 ) . read rescue { } end private def verify_running! running? or raise RuntimeError , \"Nutcracker isn't running...\" end def signal term verify_running! and :: Process . kill ( term , pid ) end end end", "del_tokens": "VERSION end", "commit_type": "add"}
{"commit_tokens": ["Use", "after_initialize", "instead", "of", "before_validation"], "add_tokens": "after_initialize :initialize_authentication!", "del_tokens": "before_validation :initialize_authentication!", "commit_type": "use"}
{"commit_tokens": ["Implemented", "rhom_db_adaptor", "as", "abstraction", "between", "rhom", "and", "the", "database", "."], "add_tokens": "Rhom :: RhomDbAdapter :: open ( Rho :: RhoFSConnector :: get_db_fullpathname ) # make sure we close the database file def self . finalize Rhom :: RhomDbAdapter :: close end Rhom :: RhomDbAdapter :: delete_all_from_table ( 'sources' ) uniq_sources = Rho :: RhoConfig :: sources . values . inject ( [ ] ) { | result , h | result << h unless result . include? ( h ) ; result } Rhom :: RhomDbAdapter :: insert_into_table ( 'sources' , { \"source_id\" => src_id , \"source_url\" => url } )", "del_tokens": "#SyncEngine::dosync Rhom :: Rhom :: execute_sql \"delete from sources\" uniq_sources = Rho :: RhoConfig :: sources . values . inject ( [ ] ) { | result , h | result << h unless result . include? ( h ) ; result } Rhom :: Rhom :: execute_sql \"insert into sources (source_id, source_url) values (#{src_id.to_s},'#{url}')\"", "commit_type": "implement"}
{"commit_tokens": ["Add", "comments", "for", "Parser", "::", "Parse", "class", "minor", "style", "fixes", "."], "add_tokens": "# Initializes instance of Parser::Parse # # @param [Java::opennlp.tools.parser.Parse] java_instance unless java_instance . is_a? ( self . class . java_class ) fail ArgumentError , \"java_instance must be an instance of #{self.class.java_class.name}\" end # Composes tree bank string, nested string representation of sentence parts, parts-of-speech and words, # for example: # '(TOP (S (NP (DT The) (JJ red) (NN fox)) (VP (VBZ sleeps) (ADVP (RB soundly))) (. .)))' # # @return [String] start = span . getStart # Composes array representation of sentence tree where # each hash has following fields: # # :type => <[String] node type>, # :parent_type => <[String] type of parent node>, # :token => <[String] current token>, # :children => <Array[Hash] array of child nodes hashes> # # @return [Array<Hash>] data = { :type => kid . getType , :parent_type => self . j_instance . getType , :token => kid . toString }", "del_tokens": "raise ArgumentError , \"java_instance must be an instance of #{self.class.java_class.name}\" unless java_instance . is_a? ( self . class . java_class ) start = span . getStart data = { :type => kid . getType , :parent_type => self . j_instance . getType , :token => kid . toString }", "commit_type": "add"}
{"commit_tokens": ["updated", "readme", "and", "version", "number"], "add_tokens": "VERSION = \"0.2.0\"", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "update"}
{"commit_tokens": ["updated", "html", "generator", "algorithm", ".", "added", "corresponded", "test", "."], "add_tokens": "case page when 1 ; setting [ :first_text ] when size ; setting [ :last_text ] else ; page end", "del_tokens": "page == 1 ? setting [ :first_text ] : page", "commit_type": "update"}
{"commit_tokens": ["Fix", "bug", "when", "using", "Bourgeois", "::", "Presenter", ".", "present"], "add_tokens": "def self . present ( object , klass = nil , & blk )", "del_tokens": "def self . present ( object , klass = self , & blk )", "commit_type": "fix"}
{"commit_tokens": ["added", "ready?", "method", "to", "the", "vm", "object", "to", "handle", "a", "change", "in", "ovirt", "api", "."], "add_tokens": "! ( @status =~ / down /i ) && ! ( @status =~ / wait_for_launch /i ) end # In oVirt 3.1 a vm can be marked down and not locked while its volumes are locked. # This method indicates if it is safe to launch the vm. def ready? return false unless @status =~ / down /i volumes . each do | volume | return false if volume . status =~ / locked /i end if @client . api_version? ( \"3\" , \"1\" ) true", "del_tokens": "! ( @status =~ / down /i )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "the", "zip", "DEFLATE", "algorithm", "."], "add_tokens": "require 'zlib' valid_aud : [ ] if header . has_key? ( 'zip' ) unless header [ 'zip' ] == 'DEF' raise ArgumentError , 'Invalid zip algorithm.' end payload = Zlib :: Deflate . deflate ( payload , Zlib :: BEST_COMPRESSION ) end # return the appropriate signature or decryption method to either validate the # signature or decrypt the token as applicable. When the tokens are nested, # this block will be called once per token. It can optionally have a second # options parameter which can be used to override the {DEFAULT_OPTIONS} on a # per-token basis; options are not persisted between yields. if header . has_key? ( 'zip' ) unless header [ 'zip' ] == 'DEF' raise Sandal :: TokenError , 'Invalid zip algorithm.' end payload = Zlib :: Inflate . inflate ( payload ) end private", "del_tokens": "valid_aud : [ ] , # return the appropriate signature method to validate the signature. It can # optionally have a second options parameter which can be used to override the # {DEFAULT_OPTIONS} on a per-token basis. private", "commit_type": "add"}
{"commit_tokens": ["adding", "method_missing", "to", "always", "get", "attrs"], "add_tokens": "def method_missing ( method_name , * args ) attr = \"@#{method_name}\" . to_sym super unless instance_variables . include? attr attr_value = instance_variable_get attr return attr_value unless attr_value . nil? complete_object! instance_variable_get attr end", "del_tokens": "attr_accessor :external_urls , :href , :id , :type , :uri", "commit_type": "add"}
{"commit_tokens": ["Fix", "possible", "Pathname", "exceptions", "when", "using", "the", "install", "task", "."], "add_tokens": "def copy_unless_exists ( file , from_dir = nil , to_dir = nil ) to_dir ||= Rails . root . to_s from_dir ||= Ajax . root . to_s def copy_and_overwrite ( file , from_dir = nil , to_dir = nil ) to_dir ||= Rails . root . to_s from_dir ||= Ajax . root . to_s end", "del_tokens": "def copy_unless_exists ( file , from_dir = Ajax . root , to_dir = Rails . root ) def copy_and_overwrite ( file , from_dir = Ajax . root , to_dir = Rails . root ) end", "commit_type": "fix"}
{"commit_tokens": ["Fix", "precrop", "error", "which", "fixes", "social_stream", "bug"], "add_tokens": "logo . errors [ 'precrop' ] = \"You have to make precrop\"", "del_tokens": "logo . errors [ 'precrop' ] = \"You have to make precrop\"", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "integer", "and", "integer", "ranges"], "add_tokens": "rule ( :integer ) { ( str ( '-' ) . maybe >> match ( '[0-9]' ) . repeat ( 1 ) ) } rule ( :p_integer ) { ( match ( '[0-9]' ) . repeat ( 1 ) ) } integer . as ( :integer_min ) >> str ( '..' ) >> integer . maybe . as ( :integer_max ) | ( str ( '..' ) >> integer . as ( :integer_max ) ) float . as ( :float_min ) >> str ( '..' ) >> float . maybe . as ( :float_max ) | str ( '..' ) >> float . as ( :float_max )", "del_tokens": "rule ( :integer ) { ( str ( '-' ) . maybe >> match ( '[0-9]' ) . repeat ) } rule ( :p_integer ) { ( match ( '[0-9]' ) . repeat ) } integer . maybe . as ( :integer_min ) >> str ( '..' ) >> integer . maybe . as ( :integer_max ) | ( str ( '..' ) >> integer . as ( :integer_max ) ) ( float . as ( :float_min ) >> str ( '..' ) >> float . as ( :float_max ) ) | ( str ( '..' ) >> float . as ( :float_max ) ) | float . as ( :float_min ) >> str ( '..' )", "commit_type": "fix"}
{"commit_tokens": ["Add", "JSONAPI", "::", "Utils", "::", "Request#relationship_params", "helper", "method"], "add_tokens": "build_params_for ( :resource ) end def relationship_params build_params_for ( :relationship ) end private def build_params_for ( param_type ) return { } if @request . operations . empty? keys = %i( attributes to_one to_many ) operation = @request . operations . find { | e | e . data . keys & keys == keys } if operation . nil? { } elsif param_type == :relationship operation . data . values_at ( :has_one , :to_many ) . compact . reduce ( & :merge ) else operation . data [ :attributes ]", "del_tokens": "unless @request . operations . empty? operation = @request . operations . find { | e | e . data [ :attributes ] . present? } operation . nil? ? { } : operation . data [ :attributes ]", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "and", "bump", "version"], "add_tokens": "VERSION = \"0.0.3\"", "del_tokens": "VERSION = \"0.0.2\"", "commit_type": "update"}
{"commit_tokens": ["add", "ability", "to", "pass", "connection", "params"], "add_tokens": "class Configuration < Struct . new ( :api_key , :connection_params ) ; end", "del_tokens": "class Configuration < Struct . new ( :api_key ) ; end", "commit_type": "add"}
{"commit_tokens": ["added", "a", "collector", "callback", "after", "update"], "add_tokens": "def self . register_after_update_callback ( callback ) Collector . instance . register_after_update_callback ( callback ) end @after_update_callback = lambda { } begin data = instance . fetch publish_data ( source , data ) ensure @after_update_callback . call end def register_after_update_callback ( callback ) @after_update_callback = callback end", "del_tokens": "data = instance . fetch publish_data ( source , data )", "commit_type": "add"}
{"commit_tokens": ["Using", "weighted_letter", "for", "selecting", "next", "/", "last", "letters"], "add_tokens": "weighted_letter :next , current_letter weighted_letter :last , penultimate_letter", "del_tokens": "if @letters [ :next ] . has_key? ( current_letter ) @selectors [ :next ] [ current_letter ] ||= WeightedSelect :: Selector . new @letters [ :next ] [ current_letter ] @selectors [ :next ] [ current_letter ] . select end if @letters [ :last ] . has_key? ( penultimate_letter ) @selectors [ :last ] [ penultimate_letter ] ||= WeightedSelect :: Selector . new @letters [ :last ] [ penultimate_letter ] @selectors [ :last ] [ penultimate_letter ] . select end", "commit_type": "use"}
{"commit_tokens": ["add", "ability", "to", "generate", "a", "blank", "set", "of", "factories", "for", "a", "controller", "spec", "using", "-", "f"], "add_tokens": "require 'factory_module' include FactoryModule option :f , :type => :boolean if controller sanitize ( controller , actions ) else puts \"Please provide a controller name.\" exit end # Factories if options [ :f ] controller != nil ? @working_file = \"#{@dir_factories}/#{controller.downcase}_spec.rb\" : @working_file = \"#{@dir_factories}/sample_spec.rb\" opener ( \"factory\" , FactoryModule . create ) end # Spec tests", "del_tokens": "sanitize ( controller , actions ) # Header stuff # p actions", "commit_type": "add"}
{"commit_tokens": ["allow", "to", "retrieve", "log", "entries", "created", "after", "given", "log", "id"], "add_tokens": "unless r [ 'from' ] . nil? scope = scope . where ( :id . gt => r [ 'from' ] ) end @logs = scope . order ( :$natural => - 1 ) . limit ( limit ) . to_a . reverse", "del_tokens": "@logs = grid_service . container_logs . order ( :$natural => - 1 ) . limit ( limit ) . to_a . reverse", "commit_type": "allow"}
{"commit_tokens": ["Add", "stacks", "to", "application", "helper"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "Hoe", "to", "centralized", "rakefile", "logic"], "add_tokens": "loop { channel . active? }", "del_tokens": "channel . on_close do | ch | ch [ :closed ] = true end loop { ! channel [ :closed ] }", "commit_type": "use"}
{"commit_tokens": ["Made", "some", "rectifications", "and", "updates", "to", "class", "code", "sample", ".", "Added", "black", "box", "testing", "to", "class", "specs", "."], "add_tokens": "context \"Case: #{test_case}\" do before do @path = path_str test_case end t = Rubex . ast ( @path + '.rubex' ) t , c , e = Rubex . compile ( @path + '.rubex' , test : true ) end end context \"Black Box testing\" do it \"compiles and checks for valid output\" do setup_and_teardown_compiled_files ( test_case ) do | dir | require_relative \"#{dir}/#{test_case}.so\" k = Kustom . new expect ( k . bye ) . to eq ( \"Bye world!\" ) k2 = Kustom2 . new expect ( k2 . hello ) . to eq ( \"This is a prelude.Hello world!\" ) end", "del_tokens": "path = \"spec/fixtures/#{test_case}/#{test_case}\" context \"File: #{path}.rubex\" do t = Rubex . ast ( path + '.rubex' ) pp t t , c , e = Rubex . compile ( ( path + '.rubex' ) , true )", "commit_type": "make"}
{"commit_tokens": ["allow", "via", ":", "value", "as", "string", ".", "minor", "version", "bump"], "add_tokens": "case via . to_sym when :sendmail then transport_via_sendmail build ( options ) , via_options when :smtp then transport_via_smtp build ( options ) , options [ :from ] , options [ :to ] , via_options", "del_tokens": "case via when :sendmail then transport_via_sendmail build ( options ) , via_options when :smtp then transport_via_smtp build ( options ) , options [ :from ] , options [ :to ] , via_options", "commit_type": "allow"}
{"commit_tokens": ["Updated", "README", "to", "remove", "sys", "-", "uname", "and", "removed", "sys", "-", "uname", "from", "manager", ".", "rb"], "add_tokens": "if Config :: CONFIG [ 'target_os' ] =~ / darwin / #Mac OS X", "del_tokens": "require 'sys/uname' os_name = Sys :: Uname . sysname parsed_os_name = os_name . downcase if parsed_os_name . include? \"darwin\" #Mac OS X", "commit_type": "update"}
{"commit_tokens": ["Fix", "reference", "to", "undefined", "local", "variable"], "add_tokens": "raise \"Invalid middleware, doesn't respond to `call`: #{klass.inspect}\"", "del_tokens": "raise \"Invalid middleware, doesn't respond to `call`: #{action.inspect}\"", "commit_type": "fix"}
{"commit_tokens": ["Add", "Clusterer", "module", "for", "common", "classify", "method"], "add_tokens": "require_relative 'clusterer' include Clusterer @bounds ||= clusters . map { | cluster | cluster . last } . insert ( 0 , 0 )", "del_tokens": "clusters . map { | cluster | cluster . last } . insert ( 0 , 0 )", "commit_type": "add"}
{"commit_tokens": ["Allows", "to", "set", "options", "on", "the", "postgres_pgp", "adapter"], "add_tokens": "attr_accessor :pgcrypto_options @pgcrypto_options = options . fetch ( :pgcrypto_options , '' ) escape_and_execute_sql ( [ \"SELECT pgp_sym_encrypt(?, ?, ?)\" , value . to_s , key , pgcrypto_options ] ) [ 'pgp_sym_encrypt' ]", "del_tokens": "escape_and_execute_sql ( [ \"SELECT pgp_sym_encrypt(?, ?)\" , value . to_s , key ] ) [ 'pgp_sym_encrypt' ]", "commit_type": "allow"}
{"commit_tokens": ["changed", "how", "the", "action", "class", "is", "to", "be", "used", "and", "called"], "add_tokens": "attr_reader :name , :description , :config , :block def initialize ( name , description , & block ) @name , @description , @config = name , description , { } @commands , @block = [ ] , block end def call ( configuration ) @config = configuration commands true", "del_tokens": "attr_reader :name , :description , :config def initialize ( name , description , config = { } , & block ) @name , @description , @config = name , description , config @commands = [ ] @loaded = false @loaded @loaded = true", "commit_type": "change"}
{"commit_tokens": ["Add", "new", "rules", "file", "from", "git", "submodule"], "add_tokens": "File . expand_path ( '../../../rules/rules.yml' , __FILE__ )", "del_tokens": "File . expand_path ( '../../../rules.yml' , __FILE__ )", "commit_type": "add"}
{"commit_tokens": ["Fix", "authenticity", "token", "errors", "when", "using", "cookie", "session", "store", "."], "add_tokens": "protect_from_forgery", "del_tokens": "protect_from_forgery :secret => \"sweet-harmonious-biscuits\"", "commit_type": "fix"}
{"commit_tokens": ["Create", "the", "shell", "user", "so", "it", "can", "be", "authorized", "."], "add_tokens": "user = User . create ( 1 , name : \"Shell User\" )", "del_tokens": "user = User . new ( 1 , name : \"Shell User\" )", "commit_type": "create"}
{"commit_tokens": ["add", "test", "to", "ensure", "unique", "auth", "codes", "across", "requests"], "add_tokens": "assert @response . redirected_to =~ / http \\: \\/ \\/ example \\. com \\/ cb \\? code \\= .* / def test_subsequent_requests_for_authorization_code_receive_unique_codes client = OauthClient . create! ( :name => 'my application' ) session [ :user_id ] = '13' post :authorize , :redirect_uri => 'http://example.com/cb' , :client_id => client . client_id , :authorize => '1' auth_response_1 = @response . redirected_to @request = ActionController :: TestRequest . new post :authorize , :redirect_uri => 'http://example.com/cb' , :client_id => client . client_id , :authorize => '1' auth_response_2 = @response . redirected_to assert auth_response_1 != auth_response_2 end", "del_tokens": "assert @response . redirected_to = ! / http \\: \\/ \\/ example \\. com \\/ cb \\? code \\= .* /", "commit_type": "add"}
{"commit_tokens": ["Add", "DataFrame#each", "#map", "#any?", "#all?", "and", "#collect"], "add_tokens": "alias_method :filter , :select def each ( & block ) return self . to_enum ( :each ) unless block_given? self . each_row do | row | row . instance_eval ( & block ) end self end def map ( & block ) return self . to_enum ( :map ) unless block_given? arr = [ ] self . each_row do | row | arr . push ( row . instance_eval ( & block ) ) end Mikon :: Series . new ( :new_series , arr , index : @index ) end alias_method :collect , :map def all? ( & block ) self . each_row { | row | return false unless row . instance_eval ( & block ) } true end def any? ( & block ) self . each_row { | row | return true if row . instance_eval ( & block ) } false end", "del_tokens": "include Enumerable def each ( & block ) raise \"NotImplementedError\" end alias_method :filter , :select", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "glob", "directory", "path", "."], "add_tokens": "source = escape_glob_path ( source_path ) dest_path = args . first || source pattern = opts [ :recursive ] ? :: File . join ( source , '**' ) : source", "del_tokens": "dest_path = args . first || source_path pattern = opts [ :recursive ] ? :: File . join ( source_path , '**' ) : source_path", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "bug", "with", "names", "in", "uppercase"], "add_tokens": "if ( matchdata = / ^git@([a-z0-9 \\. _-]+):([a-z0-9_-]+) \\/ ([a-z0-9_-]+)( \\. git)?$ /i . match ( url . strip ) ) end", "del_tokens": "if ( matchdata = / ^git@([a-z0-9 \\. _-]+):([a-z0-9_-]+) \\/ ([a-z0-9_-]+)( \\. git)?$ / . match ( url . strip ) ) end", "commit_type": "fix"}
{"commit_tokens": ["added", "ignore", "file", "for", "configuration", "files"], "add_tokens": "resources :people", "del_tokens": "# The priority is based upon order of creation: # first created -> highest priority. # Sample of regular route: # match 'products/:id' => 'catalog#view' # Keep in mind you can assign values other than :controller and :action # Sample of named route: # match 'products/:id/purchase' => 'catalog#purchase', :as => :purchase # This route can be invoked with purchase_url(:id => product.id) # Sample resource route (maps HTTP verbs to controller actions automatically): # resources :products # Sample resource route with options: # resources :products do # member do # get 'short' # post 'toggle' # end # # collection do # get 'sold' # end # end # Sample resource route with sub-resources: # resources :products do # resources :comments, :sales # resource :seller # end # Sample resource route with more complex sub-resources # resources :products do # resources :comments # resources :sales do # get 'recent', :on => :collection # end # end # Sample resource route within a namespace: # namespace :admin do # # Directs /admin/products/* to Admin::ProductsController # # (app/controllers/admin/products_controller.rb) # resources :products # end # You can have the root of your site routed with \"root\" # just remember to delete public/index.html. # root :to => \"welcome#index\" # See how all your routes lay out with \"rake routes\" # This is a legacy wild controller route that's not recommended for RESTful applications. # Note: This route will make all actions in every controller accessible via GET requests. # match ':controller(/:action(/:id(.:format)))'", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "DebtorContactProxy", "to", "Debtor"], "add_tokens": "subject . contacts . should be_instance_of ( Economic :: DebtorContactProxy ) subject . contacts . session . should == subject . session", "del_tokens": "subject . contcats . should be_instance_of ( Economic :: DebtorContactProxy ) subject . debtor . session . should == subject . session", "commit_type": "add"}
{"commit_tokens": ["Changing", "sub", "-", "second", "formatting", "to", "use", "a", "dash", "rather", "than", "a", "colon", "."], "add_tokens": "time = Time . now . to_f . to_s . gsub ( \".\" , \"-\" )", "del_tokens": "time = Time . now . to_f . to_s . gsub ( \".\" , \":\" )", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "specifying", "create", "and", "update", "payload", "formats"], "add_tokens": "# Extract the request payload in the specified format, defaults to XML def request_payload ( resource , headers ) if headers case headers [ :format ] when FHIR :: Formats :: ResourceFormat :: RESOURCE_XML resource . to_xml when FHIR :: Formats :: ResourceFormat :: RESOURCE_JSON resource . to_fhir_json else resource . to_xml end else resource . to_xml end end RestClient . post ( URI ( URI . escape ( \"#{base_path(path)}#{path}\" ) ) . to_s , request_payload ( resource , headers ) , headers ) { | response , request , result | RestClient . put ( URI ( URI . escape ( \"#{base_path(path)}#{path}\" ) ) . to_s , request_payload ( resource , headers ) , headers ) { | response , request , result |", "del_tokens": "RestClient . post ( URI ( URI . escape ( \"#{base_path(path)}#{path}\" ) ) . to_s , resource . to_xml , headers ) { | response , request , result | RestClient . put ( URI ( URI . escape ( \"#{base_path(path)}#{path}\" ) ) . to_s , resource . to_xml , headers ) { | response , request , result |", "commit_type": "add"}
{"commit_tokens": ["add", "type", "4", "(", "Token", "API", ")", "support"], "add_tokens": "# don't load image data for Token API raw64 = nil unless options [ :type ] == 4 raw64 = load_captcha ( options ) raise DeathByCaptcha :: InvalidCaptcha if raw64 . to_s . empty? end", "del_tokens": "raw64 = load_captcha ( options ) raise DeathByCaptcha :: InvalidCaptcha if raw64 . to_s . empty?", "commit_type": "add"}
{"commit_tokens": ["Fix", "write_inheritable_attribute", "usage", "for", "Rails", "3"], "add_tokens": "( self . is_a? ( Class ) ? self : self . class ) . write_inheritable_attribute ( :ajax_layout , template_name )", "del_tokens": "write_inheritable_attribute ( :ajax_layout , template_name )", "commit_type": "fix"}
{"commit_tokens": ["Add", "railtie", "to", "automatically", "include", "SendGrid", "in", "ActionMailer", ".", "Restructure", "."], "add_tokens": "require 'send_grid/railtie'", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "sort", "didn", "t", "work", "properly", "(", "patch", "by", "Geoff", ")"], "add_tokens": "if value . kind_of? Array if value . size > 9 raise Rfm :: Error :: ParameterError . new ( \":sort_order can have at most 9 fields, but you passed an array with #{value.size} elements.\" ) end value . each_index { | i | result [ \"-sortorder.#{i+1}\" ] = value [ i ] } else result [ \"-sortorder.1\" ] = value end", "del_tokens": "result [ '-sortorder' ] = value", "commit_type": "fix"}
{"commit_tokens": ["added", "default", "argnames", "suggesting", "correct", "YAML", "format", "to", "array", "/", "hash", "validations", ".", "changed", "Description#to_s", "to", "return", "a", "string", "even", "if", "no", "trailer", "is", "resolved", "."], "add_tokens": "trailer . to_s", "del_tokens": "trailer", "commit_type": "add"}
{"commit_tokens": ["implementing", "a", "way", "to", "access", "client", "username", "without", "the", "accessor"], "add_tokens": "if oauth_response . class == Net :: HTTPOK @username = JSON . parse ( oauth_response . body ) [ :username ] true else false end end def username @username ||= account_verify_credentials? . screen_name", "del_tokens": "return oauth_response . class == Net :: HTTPOK", "commit_type": "implement"}
{"commit_tokens": ["Fix", "lock", "/", "unlock", "to", "return", "nil", "rails", "NotImplementedError", "for", "stuff", "not", "done", "yet", "fix", "expiration_date", "and", "expired?", "add", "register_domain"], "add_tokens": "return nil return nil return nil date_string = @domain_payload [ 'interface_response' ] [ 'GetDomainInfo' ] [ 'status' ] [ 'expiration' ] Date . parse ( date_string . split ( ' ' ) . first ) registration_status == 'Expired' def renew! ( years = 1 ) # get('Command' => 'Renew', 'SLD' => sld, 'TLD' => tld) raise NotImplementedError", "del_tokens": "@domain_payload [ 'interface_response' ] [ 'GetDomainInfo' ] [ 'status' ] [ 'expiration' ] def renew", "commit_type": "fix"}
{"commit_tokens": ["fix", "DEPRECATION", "WARNING", ":", "render", ":", "text", "is", "deprecated", "because", "it", "does", "not", "actually", "render", "a", "text", "/", "plain", "response", "."], "add_tokens": "render :plain => robot_contents ,", "del_tokens": "render :text => robot_contents ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "linking", "scripts", "directory"], "add_tokens": "FileUtils . rm target_hook_path ( repo , hook ) def copy_scripts ( repo , options = { } ) FileUtils . rm_rf target_script_path ( repo ) if options [ :method ] == :copy FileUtils . cp_r SCRIPTS , target_script_path ( repo ) else FileUtils . ln_sf scripts_path , target_script_path ( repo ) end def scripts_path File . expand_path ( SCRIPTS ) end File . join ( repo_path ( repo ) , HOOKS_PATH , 'scripts' )", "del_tokens": "def copy_scripts ( repo ) FileUtils . cp_r SCRIPTS , target_script_path ( repo ) File . join ( repo_path ( repo ) , HOOKS_PATH )", "commit_type": "add"}
{"commit_tokens": ["Updating", "tests", "for", "gh", "-", "5"], "add_tokens": "PandocRuby . convert ( TestConversions . formatted_strings [ from ] , :from => from , :to => format ) . strip ,", "del_tokens": "PandocRuby . convert ( TestConversions . formatted_strings [ from ] , :from => from , :to => format ) ,", "commit_type": "update"}
{"commit_tokens": ["Fixing", "up", "associated_with", "rdoc", "."], "add_tokens": "# # # Assigns current_object.user= # # because #current_user returns a User # # # Assigns current_object.admin= # # #current_juror can return anything", "del_tokens": "# // Where current_object.user= # // and #current_user returns a User # // Where current_object.admin= # // and #current_juror returns anything", "commit_type": "fix"}
{"commit_tokens": ["change", "readme", "to", "less", "volatile"], "add_tokens": "class TestCache < Test :: Unit :: TestCase def test_new ( )", "del_tokens": "class ScrapahUnitTests < Test :: Unit :: TestCase def test_cache ( )", "commit_type": "change"}
{"commit_tokens": ["remove", "thin", "dependency", ".", "let", "the", "end", "user", "decide", "which", "server", "to", "use", "."], "add_tokens": "@server = Rack :: Server . new ( :Port => @port , :config => config_ru )", "del_tokens": "require 'thin' Thin :: Logging . debug = :log @server = Rack :: Server . new ( :Port => @port , :config => config_ru , :server => \"thin\" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "mkwhois", "tool", "fixture", "path"], "add_tokens": "# Usage: # # $ ./utils/mkwhois.rb google.com.br status_registered # # It will execute the query and dump the result into a file # called status_registered.txt into the appriate folder based # on the hostname that was queried, and the TLD. tld = r . server . allocation", "del_tokens": "tld = r . server . allocation [ 1 .. - 1 ]", "commit_type": "fix"}
{"commit_tokens": ["updated", "participant", "show", "page", "to", "disply", "an", "Assign", "Group", "button"], "add_tokens": "def current_coach_link ( participant ) def current_group_link ( participant ) if participant . active_membership && participant . active_membership . group text = \"Current Group: #{participant.active_membership.group.name}\" href = participant_group_path ( participant , participant . active_membership . group ) else text = \"Assign Group\" href = new_participant_group_path ( participant ) end link_to text , href , class : \"list-group-item\" end", "del_tokens": "def coach_link ( participant )", "commit_type": "update"}
{"commit_tokens": ["Add", "Wanikani", "::", "InvalidKey", "exception", "and", "handle", "invalid", "API", "keys", "better"], "add_tokens": "if ! res . success? || res . body . has_key? ( \"error\" ) self . raise_exception ( res ) raise Exception , \"There was an error: #{error.message}\" def self . raise_exception ( response ) raise Wanikani :: InvalidKey , \"The API key used for this request is invalid.\" and return if response . status == 401 message = if response . body . is_a? ( Hash ) and response . body . has_key? ( \"error\" ) response . body [ \"error\" ] [ \"message\" ] else \"Status code: #{response.status}\" end", "del_tokens": "if ! res . success? self . raise_exception ( \"Status code: #{res.status}\" ) elsif res . body . has_key? ( \"error\" ) self . raise_exception ( res . body [ \"error\" ] [ \"message\" ] ) self . raise_exception ( error . message ) def self . raise_exception ( message )", "commit_type": "add"}
{"commit_tokens": ["added", "whys", "speed", "patch", "to", "xchar"], "add_tokens": "0x9 , 0xA , 0xD , case n when * XChar :: VALID XChar :: PREDEFINED [ n ] or ( n < 128 ? n . chr : \"&##{n};\" ) else '*' end", "del_tokens": "[ 0x9 , 0xA , 0xD ] , n = 42 unless XChar :: VALID . find { | range | range . include? n } XChar :: PREDEFINED [ n ] or ( n < 128 ? n . chr : \"&##{n};\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "URI", "encoding", "&", "Added", "tests"], "add_tokens": "require 'open-uri' search = URI :: encode ( term )", "del_tokens": "search = term", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "Curation#hash", "and", "Curator#hash", "-", "don", "t", "think", "#eql?", "should", "be", "messed", "with", "though"], "add_tokens": "def_delegators :characteristics , :[] , :keys , :slice , :hash , :== , :each", "del_tokens": "def_delegators :characteristics , :[] , :keys , :slice , :== , :each", "commit_type": "fix"}
{"commit_tokens": ["Removed", "some", "unused", "code", "."], "add_tokens": "raise unless raw_yaml_content =~ / VCR::RecordedResponse / raise \"The VCR cassette #{name} uses an old format that is now deprecated. VCR provides a rake task to migrate your old cassettes to the new format. See http://github.com/myronmarston/vcr/blob/master/CHANGELOG.md for more info.\"", "del_tokens": "if raw_yaml_content =~ / VCR::RecordedResponse / raise \"The VCR cassette #{name} uses an old format that is now deprecated. VCR provides a rake task to migrate your old cassettes to the new format. See http://github.com/myronmarston/vcr/blob/master/CHANGELOG.md for more info.\" else raise end def unstub_requests VCR . http_stubbing_adapter . unstub_requests ( @original_recorded_interactions ) end", "commit_type": "remove"}
{"commit_tokens": ["Implement", "upload", "-", "defer", "-", "length", "extension"], "add_tokens": "@hash . reject { | key , value | value . nil? } @hash [ \"Upload-Concat\" ] . to_s . start_with? ( \"final\" ) end def defer_length? @hash [ \"Upload-Defer-Length\" ] == \"1\"", "del_tokens": "@hash @hash [ \"Upload-Concat\" ] . start_with? ( \"final\" )", "commit_type": "implement"}
{"commit_tokens": ["Added", "optimization", "that", "uses", "view", "data", "to", "build", "child", "resources", "rather", "than", "doing", "a", "GET"], "add_tokens": "## Can't do the following as the API doesn't support it due to a bug, but resource.links has the info.", "del_tokens": "## Can't do the following as the API doesn't support it due to a bug, but instance.links has the info.", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "alias", "changed", ".", "has_markup", "to", "be", "an", "alias"], "add_tokens": "def emits ( * args , & template_code ) if args . first . respond_to? ( :call ) or template_code _store :markup , _compile ( args . first || template_code ) # default fragment is named :markup alias_method :has_markup , :emits", "del_tokens": "def emits ( * args ) if args . first . respond_to? :call _store :markup , _compile ( args . first ) def has_markup ( & block ) emits ( markup : block ) end alias_method :renders , :emits", "commit_type": "remove"}
{"commit_tokens": ["Allow", "specifying", "rbenv", "versions", "on", "Ruby"], "add_tokens": "Job = Struct . new ( :name , :script , :prelude , :loop_count ) do self [ :loop_count ] || guessed_count Executable = Struct . new ( :name , :command ) do def self . parse ( name_path ) name , path = name_path . split ( '::' , 2 ) Benchmark :: Driver :: Configuration :: Executable . new ( name , path ? path . split ( ',' ) : [ name ] ) end def self . parse_rbenv ( spec ) version , * args = spec . split ( ',' ) path = ` RBENV_VERSION=' #{ version } ' rbenv which ruby ` . rstrip abort \"Failed to execute 'rbenv which ruby'\" unless $? . success? Benchmark :: Driver :: Configuration :: Executable . new ( version , [ path , * args ] ) end end RunnerOptions = Struct . new ( :type , :executables , :repeat_count ) do", "del_tokens": "class Job < Struct . new ( :name , :script , :prelude , :loop_count ) super || guessed_count Executable = Struct . new ( :name , :command ) class RunnerOptions < Struct . new ( :type , :executables , :repeat_count )", "commit_type": "allow"}
{"commit_tokens": ["added", "ability", "to", "save", "the", "config", "for", "each", "botpart"], "add_tokens": "@botpart_config_path = File . expand_path ( \"./etc/#{name}.yml\" ) @config = $bot [ :config ] . merge ( if File . exist? @botpart_config_path YAML . load_file @botpart_config_path $bot [ :botparts ] << self # Saves the botpart's configuration. This is automatically called when # Twittbot exits. def save_config botpart_config = Hash [ @config . to_a - $bot [ :config ] . to_a ] unless botpart_config . empty? File . open @botpart_config_path , 'w' do | f | f . write botpart_config . to_yaml end end end", "del_tokens": "botpart_config_path = File . expand_path ( \"./etc/#{name}.yml\" ) @config = $bot [ :config ] . merge ( if File . exist? botpart_config_path YAML . load_file botpart_config_path", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "to", "check", "controller", "will", "work", "properly", "with", "default", "model", "and", "customize", "model"], "add_tokens": "describe 'has certificate' do let! ( :certificate ) do context 'with default model' do it 'returns verification string when found verification path' do open ( :get , :show , verification_path : 'valid_path' ) expect ( response . status ) . to eq ( 200 ) expect ( response . body ) . to eq ( certificate . verification_string ) end end context 'with customize model' do LetsEncrypt . config . certificate_model = 'OtherModel' it 'set the certificate_model to customize model' do expect ( LetsEncrypt . certificate_model ) . to eq ( 'OtherModel' . constantize ) end it 'returns verification string when found verification path' do open ( :get , :show , verification_path : 'valid_path' ) expect ( response . status ) . to eq ( 200 ) expect ( response . body ) . to eq ( certificate . verification_string ) end", "del_tokens": "before ( :each ) do LetsEncrypt . config . certificate_model = 'OtherModel' end context 'has certificate' do let! ( :certificate ) do it 'returns verification string when found verification path' do open ( :get , :show , verification_path : 'valid_path' ) expect ( response . status ) . to eq ( 200 ) expect ( response . body ) . to eq ( certificate . verification_string )", "commit_type": "add"}
{"commit_tokens": ["fix", "net", "::", "telnet", "call", "to", "be", "more", "robust", "for", "retries"], "add_tokens": "# Sends commands over telnet to varnish servers listed in the config. response = nil connection . puts ( command ) connection . waitfor ( { \"Match\" => / ^200 / } ) { | r | response = r . strip } connection . close :response => response } ) response", "del_tokens": "# Sends commands over telnet to varnish servers listed in the config. response = [ ] connection . cmd ( command ) do | c | response . push c . strip c . strip end :response => response . join ( \"\\n\" ) } ) ensure connection . close rescue nil", "commit_type": "fix"}
{"commit_tokens": ["fix", "Savon", "s", "removed", "#to_hash", "method"], "add_tokens": "hresp = Nori . parse ( resp . to_xml ) [ :envelope ] [ :body ]", "del_tokens": "hresp = Savon :: SOAP :: XML . to_hash resp . to_xml", "commit_type": "fix"}
{"commit_tokens": ["Fix", "warning", "if", "squire", "is", "used", "without", "namespaces"], "add_tokens": "settings = defined? ( @namespace ) ? @settings . get_value ( @namespace ) : @settings", "del_tokens": "settings = @namespace ? @settings . get_value ( @namespace ) : @settings", "commit_type": "fix"}
{"commit_tokens": ["add", "example", "and", "parent", "helper", "methods"], "add_tokens": "cache_dir = File . expand_path ( File . join ( '.' , 'web_cache' ) , __dir__ )", "del_tokens": "cache_dir = File . expand_path ( File . join ( '.' , 'scrape_cache' ) , __dir__ )", "commit_type": "add"}
{"commit_tokens": ["add", "a", "new", "json", "format", "(", "to", "be", "continued", ")"], "add_tokens": "algos = %w[ build-dir print-dir json json2 yaml sqlite ] # TODO: capture CTRL^C to avoid show the stack trace # http://ruby-doc.org/core-1.9.3/Kernel.html#method-i-trap when 'json2' visitor = DirectoryToHash2Visitor . new ( dirname ) root = dtw . run ( visitor ) . root output . puts JSON . pretty_generate ( root )", "del_tokens": "algos = %w[ build-dir print-dir json yaml sqlite ] # TODO: capture CTRL^C to avoid show the stack trace # http://ruby-doc.org/core-1.9.3/Kernel.html#method-i-trap", "commit_type": "add"}
{"commit_tokens": ["Add", "dependencies", "and", "setup", "tests", "."], "add_tokens": "VERSION = \"0.1.0\"", "del_tokens": "VERSION = \"0.0.1\"", "commit_type": "add"}
{"commit_tokens": ["add", "helper", "for", "checker", "settings"], "add_tokens": "def self . available? engine? end private def self . engine? @engine ||= if settings . fetch ( 'Engine' , 'erb' ) . downcase == 'actionview' require 'action_view' else require 'erb' end end", "del_tokens": "begin require 'action_view' rescue LoadError require 'erb' end", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "last_updated", "returned", "wrong", "date"], "add_tokens": "Time . now . strftime ( '%d %b %Y %H:%M:%S' )", "del_tokens": "Time . now . strftime ( '%m %b %Y %H:%M:%S' )", "commit_type": "fix"}
{"commit_tokens": ["added", "lash", "to", "Hashie", "autoloads"], "add_tokens": "autoload :PrettyInspect , 'hashie/hash_extensions' autoload :Lash , 'hashie/lash'", "del_tokens": "autoload :PrettyInspect , 'hashie/hash_extensions'", "commit_type": "add"}
{"commit_tokens": ["Fix", "not", "to", "destory", "data", "hash"], "add_tokens": "def _call ( severity , time , progname , _data ) data = _data . dup", "del_tokens": "def _call ( severity , time , progname , data )", "commit_type": "fix"}
{"commit_tokens": ["Use", "require_relative", "rather", "than", "require", "so", "that", "consumers", "don", "t"], "add_tokens": "require_relative \"gnucash/account\" require_relative \"gnucash/account_transaction\" require_relative \"gnucash/book\" require_relative \"gnucash/transaction\" require_relative \"gnucash/value\" require_relative \"gnucash/version\"", "del_tokens": "require \"gnucash/account\" require \"gnucash/account_transaction\" require \"gnucash/book\" require \"gnucash/transaction\" require \"gnucash/value\" require \"gnucash/version\"", "commit_type": "use"}
{"commit_tokens": ["fix", "typos", "send", "first", "heartbeat", "immediately"], "add_tokens": "@heartbeat = EventHub :: Heartbeat . new ( self ) # send first heartbeat heartbeat EventMachine . add_timer ( watchdog_cycle_in_s ) { watchdog } EventMachine . add_periodic_timer ( heartbeat_cycle_in_s ) { heartbeat } end def heartbeat message = @heartbeat . build_message send_message ( message )", "del_tokens": "@hearbeat = EventHub :: Heartbeat . new ( self ) EventMachine . add_timer ( @watchdog_cycle_in_s ) { watchdog } EventMachine . add_periodic_timer ( @heartbeat_cycle_in_s ) do message = heartbeat . build_message send_message ( message ) end", "commit_type": "fix"}
{"commit_tokens": ["Use", "tree", "enumarator", "for", "Forest#key?", "and", "#prefix?"], "add_tokens": "trees . any? { | tree | tree . key? ( key ) } trees . any? { | tree_or_forest | tree_or_forest . prefix? ( key ) }", "del_tokens": "any? { | tree_or_forest | tree_or_forest . key? ( key ) } any? { | tree_or_forest | tree_or_forest . prefix? ( key ) }", "commit_type": "use"}
{"commit_tokens": ["added", "support", "for", "update_vm", "."], "add_tokens": "hostname = \"covirt.sat.lab.tlv.redhat.com\" @vm = @client . create_vm ( :name => name ) vm = @client . create_vm ( :name => name ) it \"test_should_update_vm\" do name = 'u-' + Time . now . to_i . to_s @client . update_vm ( :id => @vm . id , :name => name ) end vm = @client . create_vm ( :name => name )", "del_tokens": "hostname = \"ovirt.sat.lab.tlv.redhat.com\" params = { } params [ :name ] = name params [ :cluster_name ] = \"test\" @vm = @client . create_vm ( params ) params = { } params [ :name ] = name params [ :cluster_name ] = \"test\" vm = @client . create_vm ( params ) params = { } params [ :name ] = name params [ :cluster_name ] = \"test\" vm = @client . create_vm ( params )", "commit_type": "add"}
{"commit_tokens": ["make", "translation", "html", "safe", "for", "concatenation"], "add_tokens": "ta ( :none_available , association ( @object , attr ) ) . html_safe", "del_tokens": "ta ( :none_available , association ( @object , attr ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "limited", "support", "for", "live", "threads", "and", "new", "modmail", "."], "add_tokens": "# 403 => Redd::Forbidden, elsif response . code == 401 || response . code == 403 # FIXME: i think insufficient_scope comes with 403 and invalid_token with 401", "del_tokens": "403 => Redd :: Forbidden , elsif response . code == 401", "commit_type": "add"}
{"commit_tokens": ["Add", "include_blank", "option", "when", "inbound", "sync", "default", "to", "false"], "add_tokens": "define_singleton_method ( \"sync_with_#{rows_name}\" ) do | options = { } | synchronizer . sync_with_rows ( options ) def sync_with_rows ( options ) value = row . send ( attr ) if options [ :include_blank ] || value . present? record . send ( \"#{attr}=\" , value ) end", "del_tokens": "define_singleton_method ( \"sync_with_#{rows_name}\" ) do synchronizer . sync_with_rows def sync_with_rows record . send ( \"#{attr}=\" , row . send ( attr ) )", "commit_type": "add"}
{"commit_tokens": ["add", "comment", "to", "hack", "and", "make", "original_method", "pbulic"], "add_tokens": "attr_reader :base_object , :method_name , :calls , :original_method", "del_tokens": "attr_reader :base_object , :method_name , :calls # a hack to allow Spy to retrieve the spy from the object from this # specific method attr_reader :original_method", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "bit", "more", "extensibility", "to", "layout", "."], "add_tokens": "VERSION = '1.5.4.0'", "del_tokens": "VERSION = '1.5.3.0'", "commit_type": "add"}
{"commit_tokens": ["Use", "dependency", "injection", "for", "API", "to", "fix", "decoder_spec", "for", "JRuby"], "add_tokens": "attr_writer :ps_api @ps_decoder = ps_api . ps_init ( configuration . ps_config ) ps_api . ps_process_raw ( @ps_decoder , buffer , size , no_search ? 1 : 0 , full_utt ? 1 : 0 ) . tap do | result | ps_api . ps_start_utt ( @ps_decoder , name ) . tap do | result | ps_api . ps_end_utt ( @ps_decoder ) . tap do | result | ps_api . ps_get_in_speech ( @ps_decoder ) != 0 ps_api . ps_get_hyp ( @ps_decoder , nil , nil ) end def ps_api @ps_api || API :: Pocketsphinx", "del_tokens": "@ps_decoder = API :: Pocketsphinx . ps_init ( configuration . ps_config ) API :: Pocketsphinx . ps_process_raw ( @ps_decoder , buffer , size , no_search ? 1 : 0 , full_utt ? 1 : 0 ) . tap do | result | API :: Pocketsphinx . ps_start_utt ( @ps_decoder , name ) . tap do | result | API :: Pocketsphinx . ps_end_utt ( @ps_decoder ) . tap do | result | API :: Pocketsphinx . ps_get_in_speech ( @ps_decoder ) != 0 API :: Pocketsphinx . ps_get_hyp ( @ps_decoder , nil , nil )", "commit_type": "use"}
{"commit_tokens": ["Added", "docs", "to", "the", "twiddler", "for", "comment", "removal", "."], "add_tokens": "# This twiddler aims to remove comments and trailing whitespace # from the ruby source input, so that warnings that aren't concerned # with the implications of comments in their source can safely # discard them. This is a bit more complicated than simply # gsub(/#.*$/,''), because there are strings with # in them too. # # Like all twiddlers, is conservative. It might get tripped up by # a comment embedded code in a string.", "del_tokens": "\"hello \\\\#\"", "commit_type": "add"}
{"commit_tokens": ["Change", "default", "password", "strength", "message"], "add_tokens": "expect ( base_strength . errors [ :password ] ) . to eq ( [ \"is too weak\" ] ) expect ( alternative_usage . errors [ :password ] ) . to eq ( [ \"is too weak\" ] ) expect ( strong_entropy . errors [ :password ] ) . to eq ( [ \"is too weak\" ] )", "del_tokens": "expect ( base_strength . errors [ :password ] ) . to eq ( [ \"Password is too weak\" ] ) expect ( alternative_usage . errors [ :password ] ) . to eq ( [ \"Password is too weak\" ] ) expect ( strong_entropy . errors [ :password ] ) . to eq ( [ \"Password is too weak\" ] )", "commit_type": "change"}
{"commit_tokens": ["Added", "nested", "configurables", "for", "configuring", "in", "one", "big", "nested", "block", "."], "add_tokens": "def has_nested_configurable? ( method_name ) self . class . nested_configurables . include? ( method_name . to_sym ) end def nested_configurables @nested_configurables ||= [ ] end def nested_configurable ( method_name ) nested_configurables << method_name . to_sym end if owner . has_nested_configurable? ( method_name ) owner . send ( method_name ) . configure ( & block ) elsif owner . has_configuration_method? ( method_name )", "del_tokens": "class NothingToConfigure < StandardError ; end raise NothingToConfigure , \"You called configure but there are no configurable attributes\" if configuration_methods . empty? if owner . has_configuration_method? ( method_name )", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "not", "implemented", "error", "helpful"], "add_tokens": "def self . not_implemented ( method = \"\" ) raise NotImplementedError , method ? \"The call '#{method}' is not implemented\" : \"\"", "del_tokens": "def self . not_implemented raise NotImplementedError", "commit_type": "make"}
{"commit_tokens": ["Add", "very", "untested", "support", "for", "sysvinit", "scripts", "that", "read", "a", "pidfile", "generated", "by", "the", "command", "."], "add_tokens": "name : new_resource . service_name , new_resource : new_resource , options : options , platform_family : node [ 'platform_family' ] , user : new_resource . user ,", "del_tokens": "platform_family : node [ 'platform_family' ] , name : new_resource . service_name , user : new_resource . user ,", "commit_type": "add"}
{"commit_tokens": ["Implemented", "all", "HTTP", "verbs", "."], "add_tokens": "# Performs an HTTP POST request def post ( path , options = { } , raw = false ) request ( :post , path , options , raw ) end # Performs an HTTP PUT request def put ( path , options = { } , raw = false ) request ( :put , path , options , raw ) end # Performs an HTTP DELETE request def delete ( path , options = { } , raw = false ) request ( :delete , path , options , raw ) end raw ? response : Hashie :: Mash . new ( result ) . response", "del_tokens": "raw ? response : Hashie :: Mash . new ( result )", "commit_type": "implement"}
{"commit_tokens": ["update", "mercury", "with", "a", "blank", "project"], "add_tokens": "elsif @stack == BLANK # dont do anything else", "del_tokens": "else", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "Bluff", "JS", "graph", "on", "the", "overview", "page", "for", "some", "flair"], "add_tokens": "VERSION = \"0.1.8\"", "del_tokens": "VERSION = \"0.1.7\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "CHANGELOG", "and", "generated", "new", "gemspec", "."], "add_tokens": "TINY = 3", "del_tokens": "TINY = 2", "commit_type": "update"}
{"commit_tokens": ["Added", "ability", "set", "disconnect", "callback", "and", "updated", "closing", "of", "stdout"], "add_tokens": "EM . defer ( method ( :execute ) , method ( :create_pool ) , method ( :execution_failed ) ) def create_pool ( * ) if @connected == 0 logger . info ( \"Disconnected from Telegram CLI\" ) close_stdout @disconnect_callback . call if @disconnect_callback end end def on_disconnect = ( callback ) @disconnect_callback = callback def execution_failed ( e ) logger . error ( \"Failed execution of telegram-cli: #{e}\" ) close_stdout end def close_stdout Process . kill ( 'INT' , stdout . pid ) end", "del_tokens": "proc { } EM . defer ( execute , create_pool ) rescue = > e logger . error ( \"Failed establish connection with telegram-cli: #{e}\" ) Process . kill ( 'INT' , stdout . pid ) def create_pool proc { } logger . info ( \"Disconnected from Telegram CLI\" ) if @connected == 0", "commit_type": "add"}
{"commit_tokens": ["fixing", "more", "tests", ".", "yay"], "add_tokens": "short_name = target . tag . sub ( / ^! / , '' ) . split ( '/' , 2 ) . last", "del_tokens": "short_name = target . tag . split ( '/' , 2 ) . last", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "Smith", "-", "Waterman", "algorithm"], "add_tokens": "# Max of 2 def max2 ( a , b ) a >= b ? a : b end # [a,b,c].max. def max3 ( a , b , c ) ( a >= b ) ? ( ( a >= c ) ? a : c ) : ( ( b >= c ) ? b : c ) # Returns the max of 4 integers def max4 ( a , b , c , d ) x = a >= b ? a : b y = c >= d ? c : d ( x >= y ) ? x : y end", "del_tokens": "# [v1,v2,v3].max. def max3 ( v1 , v2 , v3 ) ( v1 >= v2 ) ? ( ( v1 >= v3 ) ? v1 : v3 ) : ( ( v2 >= v3 ) ? v2 : v3 )", "commit_type": "implement"}
{"commit_tokens": ["Use", "the", "existing", "#attribute_get", "and", "#attribute_set", "methods"], "add_tokens": "attribute_set ( name , value ) if respond_to? ( \"#{name}=\" ) attributes [ name ] = attribute_get ( name ) if respond_to? ( name )", "del_tokens": "writer_name = \"#{name}=\" __send__ ( writer_name , value ) if respond_to? ( writer_name ) attributes [ name ] = __send__ ( name ) if respond_to? ( name )", "commit_type": "use"}
{"commit_tokens": ["Remove", "gem", "push", "preventing", "code"], "add_tokens": "VERSION = '0.1.2'", "del_tokens": "VERSION = '0.1.1'", "commit_type": "remove"}
{"commit_tokens": ["Change", "to", "fix", "#from_stty", "when", "no", "output", "is", "provided", "on", "windows"], "add_tokens": "out = run_command ( 'stty' , 'size' ) return unless out size = out . split . map ( & :to_i )", "del_tokens": "size = run_command ( 'stty' , 'size' ) . split . map ( & :to_i )", "commit_type": "change"}
{"commit_tokens": ["Moving", "lambdas", "mock", "outside", "of", "SC", "::", "Database", "::", "fetch"], "add_tokens": "λ C: :D atabase. f etch( s elf, ethod_name, r equired_params)", "del_tokens": "λ C: :D atabase. f etch( s elf, ethod_name, equired_params)", "commit_type": "move"}
{"commit_tokens": ["fix", "spelling", "add", "ruletree", "walk", "operation"], "add_tokens": "def initialize ( data , options = { } ) @behaviors = [ ] @depth = options [ :depth ] || 0 @behaviors = data [ 'behaviors' ] . map do | bv | Rule . new ( child , { :depth => @depth + 1 } ) def to_pp bn = @behaviors . map { | b | b . name } cn = @criteria . map { | c | c . name } indent = \"\\t\" * @depth ppout = [ \"#{indent}#{name}: criteria[#{cn.join(',')}], behaviours[#{bn.join(',')}]\" ] if @children @children . each { | child | ppout << child . to_pp } end ppout . join ( \"\\n\" ) end def walk ( & block ) raise \"expected block\" unless block_given? yield self @children . each { | child | child . walk ( & block ) } if @children end attr_reader :children attr_reader :depth", "del_tokens": "def initialize ( data ) @behaviours = [ ] @behaviours = data [ 'behaviors' ] . map do | bv | Rule . new child", "commit_type": "fix"}
{"commit_tokens": ["Add", "sponsors", "and", "survey", "houses", "and", "bump", "version"], "add_tokens": "attr_reader :start_date , :end_date , :method , :pollster , :url , :source , :questions , :survey_houses , :sponsors data [ :survey_houses ] = data [ :survey_houses ] . map { | survey_house | hash_keys_to_sym ( survey_house ) } data [ :sponsors ] = data [ :sponsors ] . map { | sponsor | hash_keys_to_sym ( sponsor ) }", "del_tokens": "attr_reader :start_date , :end_date , :method , :pollster , :url , :source , :questions", "commit_type": "add"}
{"commit_tokens": ["Adds", "stop!", "method", "to", "service"], "add_tokens": "VERSION = '1.1.3'", "del_tokens": "VERSION = '1.1.2'", "commit_type": "add"}
{"commit_tokens": ["Removing", "model_instance", ".", "to_param", "for", "the", "moment"], "add_tokens": "# FIXME: url = instance.url_for(name) if name.respond_to?(\"to_param\") && url.nil?", "del_tokens": "url = instance . send ( :url_for , name ) if name . respond_to? ( \"to_param\" ) && url . nil?", "commit_type": "remove"}
{"commit_tokens": ["Add", "request", "to", "abstract", "controller"], "add_tokens": "respond body : \"it werks\" def post respond body : \"hello #{ request.params[\"name\"] }\" , code : 201 end", "del_tokens": "respond body : \"damn right\"", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "fail", "the", "build", "for", "certain", "warnings", "."], "add_tokens": "Then / the build status should be (successful|failed)$ / do | build_status | build_status == 'successful' ? assert_no_error_occurred : assert_error_occurred end expect_usage_option ( 'r' , '[no-]repl' , 'Drop into a REPL for interactive rule editing.' ) end Then 'the usage text should include an option for specifying tags that will fail the build' do expect_usage_option ( 'f' , 'epic-fail TAGS' , 'Fail the build if any of the specified tags are matched.' )", "del_tokens": "expect_output ( / -r, -- \\[ no- \\] repl[ ]+Drop into a REPL for interactive rule editing. / )", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "docs", "and", "changed", "publish", "to", "to_s", "."], "add_tokens": "# @param optional [Object] context The context to be passed to each step. # @param optional [Hash] options An option Hash to be passed to each step. def update ( context = nil , options = { } )", "del_tokens": "# @param [Object] context The context to be passed to each step. # @param [Hash] options An option Hash to be passed to each step. def update ( context , options = { } )", "commit_type": "add"}
{"commit_tokens": ["Add", "documentation", "to", "Wanikani", "::", "Client"], "add_tokens": "# Initialize a client which will be used to communicate with WaniKani. # # @param options [Hash] the API key (required) and API version (optional) # used to communicate with the WaniKani API. # @return [Wanikani::Client] an instance of Wanikani::Client. # Verifies if the client's API key is valid by checking WaniKani's API. # # @param api_key [String] the API key to validate in WaniKani. # @return [Boolean] whether the API key is valid. # Verifies if the specified API key is valid by checking WaniKani's API. # # @param api_key [String] the API key to validate in WaniKani. # @return [Boolean] whether the API key is valid. @client = Wanikani :: Client . new ( api_key : api_key ) return @client . valid_api_key? # Sets up the HTTP client for communicating with the WaniKani API. # # @return [Faraday::Connection] the HTTP client to communicate with the # WaniKani API. # Contacts the WaniKani API and returns the data specified. # # @param resource [String] the resource to access. # @param optional_arg [String] optional arguments for the specified resource. # @return [Hash] the parsed API response. # Handles exceptions according to the API response. # # @param response [Hash] the parsed API response from WaniKani's API.", "del_tokens": "client = Wanikani :: Client . new ( api_key : api_key ) return client . valid_api_key?", "commit_type": "add"}
{"commit_tokens": ["fix", "GridServices", "::", "Deploy", "spec"], "add_tokens": "# since validate method is called in constructor we need to stub deployer method globally before initialization allow_any_instance_of ( described_class ) . to receive ( :deployer ) . and_return ( deployer ) subject . run", "del_tokens": "expect ( subject ) . to receive ( :deployer ) . and_return ( deployer ) outcome = subject . run puts outcome . errors . message", "commit_type": "fix"}
{"commit_tokens": ["Improved", "variable", "binding", "evaluation", "for", "older", "ruby", "versions", "."], "add_tokens": "eval ( \"#{key} = nil; lambda {|v| #{key} = v}\" , scope ) . call ( value )", "del_tokens": "eval \"#{key} = #{value.inspect}\" , scope", "commit_type": "improve"}
{"commit_tokens": ["Added", "a", "get", "request", "to", "login", "method", "to", "check", "if", "SSL", "is", "required", "(", "whether", "it", "redirects", ")", ".", "Before", "this", "was", "failing", "silently", "with", "rooms", "method", "returning", "an", "empty", "array", "no", "error", "on", "login", ".", "Also", "modified", "tests", "to", "handle", "this", ".", "One", "test", "is", "still", "failing", "for", "other", "reasons", "."], "add_tokens": "# ensure that SSL is set if required on this account raise SSLRequiredError , \"Your account requires SSL\" unless verify_response ( get , :success ) else raise ( ArgumentError , \"Unknown response #{options}\" )", "del_tokens": "else raise ArgumentError . new ( \"Unknown response #{options}\" )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "circular", "dependency", "issue", "with", "newgem"], "add_tokens": "VERSION = '1.5.2'", "del_tokens": "VERSION = '1.5.1'", "commit_type": "fix"}
{"commit_tokens": ["Add", "puppet", "templates", "for", "manifests", "and", "hiera", "in", "project", "creation"], "add_tokens": "common_hiera_template = Tilt :: ERBTemplate . new ( \"#{Bebox::Puppet::templates_path}/puppet/#{self.step}/hiera/data/common_apply.yaml.erb\" ) manifest_template = Tilt :: ERBTemplate . new ( \"#{Bebox::Puppet::templates_path}/puppet/#{step}/manifests/site_apply.pp.erb\" , :trim => true )", "del_tokens": "common_hiera_template = Tilt :: ERBTemplate . new ( \"#{Bebox::Puppet::templates_path}/puppet/#{self.step}/hiera/data/common.yaml.erb\" ) manifest_template = Tilt :: ERBTemplate . new ( \"#{Bebox::Puppet::templates_path}/puppet/#{step}/manifests/site.pp.erb\" , :trim => true )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "use", "ips", "result", "for", "iterations", "measurement"], "add_tokens": "require_relative \"ips_result\" result = IPSResult . new next if time_s <= 0.0 # Iteration took no time result . add ( time_s , cycles_in_100ms ) result", "del_tokens": "iter = 0 measurements = [ ] next if time_s <= 0.0 # Iteration took no time iter += cycles_in_100ms measurements << time_s end elapsed_time_s = measurements . reduce ( :+ ) ips = measurements . map do | time_s | ( cycles_in_100ms . to_f / time_s . to_f ) [ Stats . average ( ips ) . round , Stats . std_dev ( ips ) . round , iter , elapsed_time_s ]", "commit_type": "change"}
{"commit_tokens": ["adding", "shared", "examples", "for", "connectors", "and", "specs", "in", "socket", "connector"], "add_tokens": "new_sub = Class . new ( subject . class ) { def send_request ; end } . new ( opts ) subject . success_cb . should eq ( cb ) subject . failure_cb . should eq ( cb )", "del_tokens": "new_sub = Class . new ( subject . class ) { def send_request ; end } new_sub = new_sub . new ( opts ) subject . success_cb . should eq cb subject . failure_cb . should eq cb", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "proxy", "in", "dev", "server", "at", "/", "-", "proxy", "/", "ENDPOINT_URL", "."], "add_tokens": "proxy_enabled : true , root : \".\" ,", "del_tokens": "root : \".\" ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "build", "plural", "transient", "associations"], "add_tokens": "builder_method = %W{ build_ #{ association } build_ #{ association . to_s . singularize } } . select { | m | f . object . respond_to? ( m ) } . first return f . object . send ( builder_method ) if builder_method", "del_tokens": "builder_method = \"build_#{association}\" return f . object . send ( builder_method ) if f . object . respond_to? ( builder_method )", "commit_type": "allow"}
{"commit_tokens": ["fix", "block_hash", "stub", "in", "tests"], "add_tokens": "h = n >= blk . number || n < blk . number - 256 ? Ethereum :: Constant :: BYTE_EMPTY : Ethereum :: Utils . big_endian_to_int ( h )", "del_tokens": "if n >= blk . number || n < blk . number - 256 Ethereum :: Constant :: BYTE_EMPTY else end", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "typo", "in", "the", "specs", "."], "add_tokens": "should_visit '/course/empty/start.html' , 'should visit the empty links start page' should_visit '/course/frames/start.html' , 'should visit the empty links start page' should_visit '/course/frames/iframe.html' , 'should visit the contents of iframes' should_visit '/course/frames/iframe_next.html' , 'should visit links within iframes' should_visit '/course/frames/frame.html' , 'should visit the contents of frames' should_visit '/course/frames/frame_next.html' , 'should visit links within frames'", "del_tokens": "should_visit '/course/empty/start.html ' , 'should visit the empty links start page' should_visit '/course/frames/start.html ' , 'should visit the empty links start page' should_visit '/course/frames/iframe.html ' , 'should visit the contents of iframes' should_visit '/course/frames/iframe_next.html ' , 'should visit links within iframes' should_visit '/course/frames/frame.html ' , 'should visit the contents of frames' should_visit '/course/frames/frame_next.html ' , 'should visit links within frames'", "commit_type": "fix"}
{"commit_tokens": ["Allow", "metric", "exit", "with", "string", "or", "exception", "for", "silent", "failure"], "add_tokens": "unless obj . nil? || obj . is_a? ( String ) || obj . is_a? ( Exception ) unless path . nil? || path . is_a? ( Exception ) || value . nil?", "del_tokens": "unless obj . nil? unless path . nil?", "commit_type": "allow"}
{"commit_tokens": ["added", "allow_blank", "to", "validates", "format", "of", "bumped", "version"], "add_tokens": "validates_format_of :email , allow_blank : true , with : / \\A ([^@ \\s ]+)@((?:[-a-z0-9]+ \\. )+[a-z]{2,}) \\Z /i , if : :validate_email_format?", "del_tokens": "validates_format_of :email , with : / \\A ([^@ \\s ]+)@((?:[-a-z0-9]+ \\. )+[a-z]{2,}) \\Z /i , if : :validate_email_format?", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "specs", "for", "GET", "et", ".", "al", ".", "ignoring", "message", "bodies", "more", "sane", "."], "add_tokens": "req = <<REQ #{method} / HTTP/1.1\\r Content - Length : 6 r r stuff REQ p . parse! ( req ) p . done? . should be_true p . headers [ \"CONTENT_LENGTH\" ] . should == \"6\" p . body . should be_nil req . should == \"\"", "del_tokens": "p . parse ( \"#{method} / HTTP/1.1\\r\\n\" ) p . parse ( \"Content-Length: 5\\r\\n\" ) p . parse ( \"\\r\\n\" ) p . parse ( \"stuff\" ) p . done? . should be_true p . headers [ \"CONTENT_LENGTH\" ] . should == \"5\" p . body . should_not be_nil p . body . read . should == \"\"", "commit_type": "make"}
{"commit_tokens": ["add", "option", "for", "output", "file", "update", "readme"], "add_tokens": "output_filename = \"#{@options[:output]}\"", "del_tokens": "output_filename = \"#{@options[:project]}_CHANGELOG.md\"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "for", "relocation", "of", "was_successful"], "add_tokens": "Then { Isbm . was_successful @response } Then { Isbm . was_successful @delete_channel_response }", "del_tokens": "Then { Isbm :: ChannelManagement . was_successful @response } Then { Isbm :: ChannelManagement . was_successful @delete_channel_response }", "commit_type": "fix"}
{"commit_tokens": ["Adding", "find", "on", "has", "many", "association"], "add_tokens": "@first_id = Mongo :: ObjectID . new @second_id = Mongo :: ObjectID . new { :_id => @first_id , :street => \"Street 1\" , :document_class => \"Address\" } , { :_id => @second_id , :street => \"Street 2\" , :document_class => \"Address\" } ] } describe \"#find\" do before do @association = Mongoid :: Associations :: HasManyAssociation . new ( :addresses , @document ) end context \"when finding all\" do it \"returns all the documents\" do @association . find ( :all ) . should == @association end end context \"when finding by id\" do it \"returns the document in the array with that id\" do address = @association . find ( @second_id ) address . id . should == @second_id end end end", "del_tokens": "{ :street => \"Street 1\" , :document_class => \"Address\" } , { :street => \"Street 2\" , :document_class => \"Address\" } ] }", "commit_type": "add"}
{"commit_tokens": ["Moved", "everything", "inside", "Zyps", "module", "."], "add_tokens": "module Zyps PI2 = Math :: PI * 2.0 #:nodoc: end #module Zyps", "del_tokens": "PI2 = Math :: PI * 2.0", "commit_type": "move"}
{"commit_tokens": ["Fix", "feats", "config", "file", "path"], "add_tokens": "FEATS_PATH = Gem :: Specification . find_by_name ( \"git-feats\" ) . gem_dir + '/feats.yml'", "del_tokens": "FEATS_PATH = 'feats.yml'", "commit_type": "fix"}
{"commit_tokens": ["removing", "filter", "...", "it", "is", "not", "a", "feature", "for", "a", "coloring", "tool"], "add_tokens": "# :any => color to use for any value without specified color def initialize ( mappings = nil ) def map ( params ) def call ( ctx ) config [ :patterns ] . each_key do | regex | def config ( params ) prefix = params [ :prefix ] suffix = params [ :suffix ] mode = ( params [ :mode ] or :all ) Regexp :: new ( \"#{prefix}#{pattern.to_s}#{suffix}\" , options ) , def call ( * args )", "del_tokens": "# :any => color to use for any value (overridable by the options above) def initialize mappings = nil def map params def call ctx level = - 1 config [ :patterns ] . each do | regex , color | level += 1 return if @level and level > @level and not @last_color def config params prefix = params [ :prefix ] suffix = params [ :suffix ] mode = ( params [ :mode ] or :all ) Regexp :: new ( \"#{prefix}#{pattern.to_s}#{suffix}\" , options ) , def call * args", "commit_type": "remove"}
{"commit_tokens": ["Add", "whitespace", "in", "headers", "and", "some", "specs", "."], "add_tokens": "Util . escape_zero_byte ( \"#{key}: #{value}\" )", "del_tokens": "Util . escape_zero_byte ( \"#{key}:#{value}\" )", "commit_type": "add"}
{"commit_tokens": ["Use", "native", "open", "(", "2", ")", "and", "close", "(", "2", ")", "calls", "for", "file", "descriptors", "for", "JRuby", "support", "."], "add_tokens": "@fd = Native . open ( path , 0 ) # 0 means \"read only\" if @fd < 0 raise SystemCallError . new ( \"Failed to open file #{path}\" + case FFI . errno when Errno :: EACCES :: Errno ; \": Permission denied.\" when Errno :: EAGAIN :: Errno ; \": Slave side of a locked pseudo-terminal device.\" when Errno :: EFAULT :: Errno ; \": Outside the process's allocated address space.\" when Errno :: EINTR :: Errno ; \": Interrupted.\" when Errno :: ELOOP :: Errno ; \": Too many symbolic links (possible loop).\" when Errno :: EMFILE :: Errno ; \": Too many open files.\" when Errno :: ENAMETOOLONG :: Errno ; \": Name too long.\" when Errno :: ENFILE :: Errno ; \": System file table is full.\" when Errno :: ENOENT :: Errno ; \": File doesn't exist.\" when Errno :: ENOTDIR :: Errno ; \": A component of the path prefix is not a directory.\" when Errno :: ENXIO :: Errno ; \": The device associated with this file doesn't exist.\" when Errno :: EOPNOTSUPP :: Errno ; \": File type not supported.\" when Errno :: EOVERFLOW :: Errno ; \": File too big.\" else ; \"\" end , FFI . errno ) end ObjectSpace . define_finalizer ( self , lambda do next unless Native . close ( @fd ) < 0 raise SystemCallError . new ( \"Failed to close file #{path}\" + case FFI . errno when Errno :: EBADF :: Errno ; \": Invalid file descriptor.\" when Errno :: EINTR :: Errno ; \": Closing interrupted.\" when Errno :: EIO :: Errno ; \": IO error.\" else ; \"\" end , FFI . errno ) end )", "del_tokens": "@file = File . open ( path ) # TODO: not JRuby-compatible", "commit_type": "use"}
{"commit_tokens": ["Fixed", "another", "connection", "-", "error", "thing"], "add_tokens": "notes = base . arel_table scope :visible , where ( notes [ :ntype ] . not_in ( [ 'web.form' , 'web.url' , 'web.vuln' ] ) )", "del_tokens": "scope :visible , where ( [ 'ntype NOT IN (?)' , [ 'web.form' , 'web.url' , 'web.vuln' ] ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "proper", "requires", "for", "mixins"], "add_tokens": "require 'tangle/mixin/relations' require 'set'", "del_tokens": "require 'tangle/mixin/connectedness'", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "allow_extra", "in", "MultiTupleType", "."], "add_tokens": "unless heading . allow_extra? or ( extra = extra_attrs ( value , true ) ) . empty? ( heading . allow_extra? || ! extra_attr? ( value , to_s ) ) && ! missing_attr? ( value )", "del_tokens": "unless ( extra = extra_attrs ( value , true ) ) . empty? ! extra_attr? ( value , to_s ) && ! missing_attr? ( value )", "commit_type": "add"}
{"commit_tokens": ["Changed", "PartialDateError", "to", "DayError", "."], "add_tokens": "raise DayError , \"A month must be set before a day\" if month == 0", "del_tokens": "raise PartialDateError , \"A month must be set before a day\" if month == 0", "commit_type": "change"}
{"commit_tokens": ["Use", "a", "better", "variable", "name", "than", "other", "in", "Body#new"], "add_tokens": "def new ( tuples ) self . class . new ( header , tuples )", "del_tokens": "def new ( other ) self . class . new ( header , other )", "commit_type": "use"}
{"commit_tokens": ["Fix", "case", "when", "negative", "offset", "is", "past", "beginning", "of", "partition"], "add_tokens": "unless partition_response . error == Errors :: NO_ERROR_CODE if @offset < 0 && Errors :: ERROR_CODES [ partition_response . error ] == Errors :: OffsetOutOfRange @offset = :earliest_offset return fetch ( options ) end", "del_tokens": "if partition_response . error != Errors :: NO_ERROR_CODE", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "name", "of", "the", "classe", "to", "use", "the", "error", ".", "class", "so", "we", "can", "keep", "any", "namespace"], "add_tokens": "# This method intends to raise the error inside the context of the use case # So we can have a more specific \"#{use_case}::#{error.class}\"", "del_tokens": "\"#{use_case}::#{demodulized_error_class}\"", "commit_type": "change"}
{"commit_tokens": ["Add", "more", "options", "to", "Subscription", "Manager", "registration"], "add_tokens": "raise ArgumentError , \"username and password are required\" unless options [ :username ] && options [ :password ] cmd << \" --username=#{LinuxAdmin::Common.sanitize(options[:username])} --password=#{LinuxAdmin::Common.sanitize(options[:password])}\" if options [ :username ] && options [ :password ] cmd << \" --org=#{LinuxAdmin::Common.sanitize(options[:org])}\" if options [ :org ] && options [ :server_url ] cmd << \" --proxy=#{LinuxAdmin::Common.sanitize(options[:proxy_address])}\" if options [ :proxy_address ] cmd << \" --proxyuser=#{LinuxAdmin::Common.sanitize(options[:proxy_username])}\" if options [ :proxy_username ] cmd << \" --proxypassword=#{LinuxAdmin::Common.sanitize(options[:proxy_password])}\" if options [ :proxy_password ] cmd << \" --serverurl=#{LinuxAdmin::Common.sanitize(options[:server_url])}\" if options [ :server_url ] Common . run ( LinuxAdmin :: Common . sanitize ( \"subscription-manager attach --pool #{pool_id}\" ) )", "del_tokens": "cmd << \" --username=#{options[:username]} --password=#{options[:password]}\" if options [ :username ] && options [ :password ] Common . run ( \"subscription-manager attach --pool #{pool_id}\" )", "commit_type": "add"}
{"commit_tokens": ["adding", "in", "some", "more", "magic", "via", "read_attributes_from_file"], "add_tokens": "csv_data = options [ :type ] == :io ? data : File . new ( data , 'r' ) :map => map_csv_with_data ( csv_data , & map_block ) } . merge! ( options ) def initialize ( context , csv_data = nil , & map_block ) @csv_data = csv_data # Allow us to read the first line of a csv file to automatically generate the attribute names. # Spaces are replaced with underscores and non-word characters are removed. # # Keep in mind that there is potential for overlap in using this (i.e. you have a field named # files+ and one named files- and they both get named 'files'). # # You can specify aliases to rename fields to prevent conflicts and/or improve readability and compatibility. # # i.e. read_attributes_from_file('files+' => 'files_plus', 'files-' => 'files_minus) def read_attributes_from_file aliases = { } attributes = FasterCSV . new ( @csv_data , @parser_options ) . readline @start_at_row = [ @start_at_row , 1 ] . max @csv_data . rewind attributes . each_with_index do | name , index | name . strip! use_name = aliases [ name ] || name . gsub ( / \\s + / , '_' ) . gsub ( / [ \\W ]+ / , '' ) . downcase add_attribute use_name , index end end protected # Create a new RowMap instance from the definition in the given block and pass the csv_data. def map_csv_with_data ( csv_data , & map_block ) # :nodoc: CsvMapper :: RowMap . new ( self , csv_data , & map_block ) end", "del_tokens": ":map => map_csv ( & map_block ) } . merge! ( options ) csv_data = config [ :type ] == :io ? data : File . new ( data , 'r' ) def initialize ( context , & map_block )", "commit_type": "add"}
{"commit_tokens": ["removed", "the", "name_prefix", "stuff", "from", "the", "route", "specifications"], "add_tokens": "users . resources :interests users . resources :posts , :controller => 'user_posts' users . resources :comments , :controller => 'user_comments' address . resources :tags forums . resources :interests forums . resources :tags forums . resources :posts , :controller => 'forum_posts' do | posts | posts . resources :tags posts . resources :comments do | comments | comments . resources :tags", "del_tokens": "users . resources :interests , :name_prefix => 'user_' users . resources :posts , :name_prefix => 'user_' , :controller => 'user_posts' users . resources :comments , :name_prefix => 'user_' , :controller => 'user_comments' address . resources :tags , :name_prefix => 'address_' forums . resources :interests , :name_prefix => 'forum_' forums . resources :tags , :name_prefix => 'forum_' forums . resources :posts , :name_prefix => 'forum_' , :controller => 'forum_posts' do | posts | posts . resources :tags , :name_prefix => 'forum_post_' posts . resources :comments , :name_prefix => 'forum_post_' do | comments | comments . resources :tags , :name_prefix => 'forum_post_comment_'", "commit_type": "remove"}
{"commit_tokens": ["Using", "CSS", "specifity", "and", "not", "!important"], "add_tokens": "def stamp_style { position : \"fixed\" , bottom : 0 , right : 0 , height : \"16px\" , background : \"rgb(0, 0, 0) transparent\" , \"background-color\" => \"rgba(0, 0, 0, 0.6)\" , padding : \"0 5 x\" } . collect { | k , v | \"%s: %s;\" % [ k , v ] } . join ( \" \" ) end < div id = \"sha-stamp\" style = \"#{stamp_style}\" > < span style = \"text-align: center;\" > < small style = \"color: white; font-weight: normal;font-size: 12px;\" > #{content}</small>", "del_tokens": "< div id = \"sha-stamp\" style = \"position: fixed; bottom: 0; right: 0; height: 16px; background-color: darkred; padding: 0 5px;\" > < span style = \"text-align: center; color: white; font-weight: normal;font-size: 12px !important;\" > < small > #{content}</small>", "commit_type": "use"}
{"commit_tokens": ["Use", "symbols", "rather", "than", "TAG_CONSTANTS", "for", ":", "as", ".", "Much", "easier", "on", "the", "eyes", "."], "add_tokens": "xml_text :description , :as => :cdata xml_text :text , :as => :text_content xml_text :description , :as => :cdata xml_object :contributions , :of => Contributor , :as => :array , :in => \"contributions\" xml_object :contributors , :of => Contributor , :as => :array xml_object :books , :of => BookWithContributions , :as => :array xml_text :name , :as => :text_content", "del_tokens": "xml_text :description , :as => ROXML :: TAG_CDATA xml_text :text , :as => ROXML :: TEXT_CONTENT xml_text :description , :as => ROXML :: TAG_CDATA xml_object :contributions , :of => Contributor , :as => ROXML :: TAG_ARRAY , :in => \"contributions\" xml_object :contributors , :of => Contributor , :as => ROXML :: TAG_ARRAY xml_object :books , :of => BookWithContributions , :as => ROXML :: TAG_ARRAY xml_text :name , :as => ROXML :: TEXT_CONTENT", "commit_type": "use"}
{"commit_tokens": ["allow", "single", "-", "key", "clearing"], "add_tokens": "Version = '0.0.8' # Empty out either the given key or the full store def clear! ( key = nil ) key . nil? @store . clear : @store . delete ( key )", "del_tokens": "Version = '0.0.7' # Empty out the store def clear @store . clear", "commit_type": "allow"}
{"commit_tokens": ["Created", "file", "browser", "&", "dialog", "(", "open", "/", "save", ")", "."], "add_tokens": "DEFAULT_BACKGROUND_COLOR = Gosu :: Color . rgb ( 50 , 50 , 50 )", "del_tokens": "DEFAULT_BACKGROUND_COLOR = Gosu :: Color . rgb ( 200 , 200 , 200 )", "commit_type": "create"}
{"commit_tokens": ["add", "g", ":", "CommandTMaxHeight", "option", "to", "limit", "window", "height"], "add_tokens": "@max_height = get_number ( 'g:CommandTMaxHeight' ) || 0 # vertical space and the g:CommandTMaxHeight option. limit = 1 if limit < 0 limit = [ limit , @max_height ] . min if @max_height > 0 limit", "del_tokens": "# vertical space. limit < 0 ? 1 : limit", "commit_type": "add"}
{"commit_tokens": ["Move", "Yardstick", "::", "Document", ".", "measure", "spec", "to", "correct", "place"], "add_tokens": "describe Yardstick :: Document , '.measure' do", "del_tokens": "# encoding: utf-8 describe \"Measure\" do", "commit_type": "move"}
{"commit_tokens": ["fix", "a", "typo", "and", "rescue", "StandardError", "instead", "of", "Exception"], "add_tokens": "rescue StandardError => e fail! ( \"Exception during OpenID discovery #{e.message}\" )", "del_tokens": "rescue Exception => e fail! ( \"Exception during OpenID discovery #{e.message}\"", "commit_type": "fix"}
{"commit_tokens": ["Update", "en", "locale", "and", "bump", "version"], "add_tokens": "VERSION = \"0.5.0.rc5\" . freeze", "del_tokens": "VERSION = \"0.5.0.rc4\" . freeze", "commit_type": "update"}
{"commit_tokens": ["Change", "wording", "in", "nil", "named", "spec", "."], "add_tokens": "it \"runs control when there is a nil named test\" do", "del_tokens": "it \"runs control when there is no named test\" do", "commit_type": "change"}
{"commit_tokens": ["Changed", "the", "gem", "from", "Ruby", "::", "Edit", "to", "RubyEdit"], "add_tokens": "require 'ruby_edit'", "del_tokens": "require 'ruby/edit'", "commit_type": "change"}
{"commit_tokens": ["Makes", "missing", "user_data", "on", "presence", "channel", "error", "explicit"], "add_tokens": "elsif user_data elsif is_presence_channel ( channel_name ) raise ArgumentError , \"user_data is required for presence channels\"", "del_tokens": "elsif ! user_data . nil?", "commit_type": "make"}
{"commit_tokens": ["Add", "RubyQml", "namespace", "to", "extension", "lib"], "add_tokens": "@name ||= CLib . qmetaobject_class_name ( self ) . to_s", "del_tokens": "@name ||= CLib . qmetaobject_class_name ( self ) . to_sym", "commit_type": "add"}
{"commit_tokens": ["Added", "specs", "for", "Host#scripts", "Port", "and", "Port#scripts", "."], "add_tokens": "@nse_xml = XML . new ( Helpers :: NSE_FILE ) @nse_host = @nse_xml . hosts . first it \"should list output of NSE scripts ran against the host\" do @nse_host . scripts . should_not be_empty @nse_host . scripts . keys . should_not include ( nil ) @nse_host . scripts . values . should_not include ( nil ) end", "del_tokens": "ports [ 0 ] . protocol . should == :tcp ports [ 0 ] . number . should == 21 ports [ 0 ] . state . should == :closed ports [ 0 ] . reason . should == 'reset' ports [ 0 ] . service . should == 'ftp' ports [ 1 ] . protocol . should == :tcp ports [ 1 ] . number . should == 23 ports [ 1 ] . state . should == :closed ports [ 1 ] . reason . should == 'reset' ports [ 1 ] . service . should == 'telnet' ports [ 2 ] . protocol . should == :tcp ports [ 2 ] . number . should == 443 ports [ 2 ] . state . should == :open ports [ 2 ] . reason . should == 'syn-ack' ports [ 2 ] . service . should == 'https'", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "order", "of", "callback", "and", "validation", "triggering"], "add_tokens": "include Kalimba :: Validations", "del_tokens": "include Kalimba :: Validations", "commit_type": "change"}
{"commit_tokens": ["Add", "only", "-", "trigger", "option", "to", "model", "generator"], "add_tokens": "class_option :only_trigger , type : :boolean , optional : true , desc : \"Create trigger-only migration\" def backfill? def only_trigger? options [ :only_trigger ] end", "del_tokens": "def backfill", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "easy", "to", "select", "a", "new", "subject", "without", "generating", "an", "element", "."], "add_tokens": "r . list_of ( :services ) do r . date end resulting_xml . should == %(<services/>) describe \"#representing\" do it \"selects a new subject without generating an element\" do r . representing :vehicle do r . element :make end resulting_xml . should == %(<make>Chevrolet</make>) end end", "del_tokens": "r . list_of ( :flags ) resulting_xml . should == %(<flags/>)", "commit_type": "make"}
{"commit_tokens": ["fixed", "solo", "/", "crossrunner", "test", "name", "output"], "add_tokens": "( fs - ex ) . uniq", "del_tokens": "fs - ex", "commit_type": "fix"}
{"commit_tokens": ["use", "pretty_theming", "url", "for", "home", "button"], "add_tokens": "Pageflow . config . theming_url_options ( theming ) . merge ( controller : 'entries' , action : 'index' )", "del_tokens": "\"//#{theming.cname}\"", "commit_type": "use"}
{"commit_tokens": ["Updated", "with", "suggestions", "from", "https", ":", "//", "github", ".", "com", "/", "cantino", "/", "reckon", "/", "pull", "/", "11"], "add_tokens": "self . options [ :currency ] ||= '$'", "del_tokens": "unless options [ :currency ] options [ :currency ] = '$' end unless options [ :suffixed ] options [ :suffixed ] = false end", "commit_type": "update"}
{"commit_tokens": ["change", "setting", "to", "marc_reader", ".", "xml_parser"], "add_tokens": "# [\"marc_reader.xml_parser\"] For XML type, which XML parser to tell Marc::Reader parser = settings [ \"marc_reader.xml_parser\" ] || @@best_xml_parser", "del_tokens": "# [\"marc_source.xml_parser\"] For XML type, which XML parser to tell Marc::Reader parser = settings [ \"marc_source.xml_parser\" ] || @@best_xml_parser", "commit_type": "change"}
{"commit_tokens": ["add", "more", "accented", "letters", "to", "regex", "matcher"], "add_tokens": "[ '-' , '(-| )' ] , ## e.g. Blau-Weiß Linz [ 'æ', (æ|ae)'], e.g. [ 'ä', (ä|ae)'], e.g. [ 'ç', (ç|c)'], e.g. Fenerbahçe [ 'ň', (ň|n)'], e.g. Plzeň [ 'Ö', (Ö|Oe)'], # e.g. Österreich [ 'ö', (ö|oe)'], e.g. Mönchengladbach [ 'ó', (ó|o)'], e.g. Colón [ 'ș', (ș|s)'], e.g. Bucarești [ 'ß', (ß|ss)'], e.g. Blau-Weiß Linz [ 'ü', (ü|ue)'], e.g.", "del_tokens": "[ '-' , '(-| )' ] , [ 'ß', (ß|ss)'], [ 'æ', (æ|ae)'], [ 'ä', (ä|ae)'], add a ? [ 'Ö', (Ö|Oe)'], # e.g. Österreich [ 'ö', (ö|oe)'], add o ? [ 'ó', (ó|o)'], e.g. Colón [ 'ü', (ü|ue)'], add u ?", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "set", "an", "array", "out", "outline", "colors", "in", "a", "theme", ".", "Really", "only", "used", "by", "the", "box", "plot", "."], "add_tokens": "theme = Scruffy :: Themes :: Base . new :background => \"#ffffff\" , :marker => \"#444444\" , :colors => [ \"#4f83bf\" , \"#be514e\" , \"#a1ba5e\" , \"#82649a\" ] graph . render :to => \"#{WEBSITE_DIR}/line_test_with_negatives.svg\" , :theme => theme graph . render :width => 400 , :to => \"#{WEBSITE_DIR}/line_test_with_negatives.png\" , :theme => theme , :as => 'png' if $make_png ] theme = Scruffy :: Themes :: Base . new :background => \"#ffffff\" , :marker => \"#aaaaaa\" , :colors => [ \"#4f83bf\" , \"#be514e\" , \"#a1ba5e\" , \"#82649a\" ] , :outlines => [ \"#be514e\" , \"#a1ba5e\" , \"#82649a\" , \"#4f83bf\" ] graph . render :to => \"#{WEBSITE_DIR}/box_plot_test.svg\" , :padding => :padded , :theme => theme graph . render :size => [ 600 , 540 ] , :theme => theme , :to => \"#{WEBSITE_DIR}/box_plot_test.png\" , :as => 'png' , :padding => :padded if $make_png", "del_tokens": "graph . render :to => \"#{WEBSITE_DIR}/line_test_with_negatives.svg\" graph . render :width => 400 , :to => \"#{WEBSITE_DIR}/line_test_with_negatives.png\" , :as => 'png' if $make_png ] , { } graph . render :to => \"#{WEBSITE_DIR}/box_plot_test.svg\" , :padding => :padded graph . render :size => [ 600 , 540 ] , :to => \"#{WEBSITE_DIR}/box_plot_test.png\" , :as => 'png' , :padding => :padded if $make_png", "commit_type": "add"}
{"commit_tokens": ["Fix", "redefinition", "of", "TimeOfDay", "warning"], "add_tokens": "module Tod", "del_tokens": "class TimeOfDay", "commit_type": "fix"}
{"commit_tokens": ["Add", "aliases", "for", "invocation", "convenience", "to", "repositories", "api", "."], "add_tokens": "_normalize_params_keys ( params ) alias :list_branches :branches alias :create_repository :create_repo alias :list_contributors :contributors alias :contribs :contributors alias :edit_repository :edit_repo alias :get_repository :get_repo alias :list_languages :languages def repos ( * args ) alias :list_repos :repos alias :list_repositories :repos alias :repo_tags :tags alias :repository_tags :tags alias :repo_teams :teams alias :repository_teams :teams", "del_tokens": "def list_repos ( * args )", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "more", "of", "the", "lies"], "add_tokens": "# The transfers included in the calculation can be limited by time range # and provided custom filters.", "del_tokens": "# The transfers included in the calculation can be limited by time range, # account scope and provided custom filters.", "commit_type": "remove"}
{"commit_tokens": ["use", "the", "better", "parser", "failure", "info"], "add_tokens": "@stderr . puts parser . parser_failure_info :verbose => true", "del_tokens": "@stderr . puts parser . parser_failure_info", "commit_type": "use"}
{"commit_tokens": ["Adds", "Pling", ".", "deliver", "and", "extends", "Pling", "to", "use", "both", "middle", "wares", "and", "adapters"], "add_tokens": "autoload :Device , 'pling/device' autoload :Message , 'pling/message' autoload :Gateway , 'pling/gateway' autoload :Middleware , 'pling/middleware' autoload :Adapter , 'pling/adapter' autoload :Configurable , 'pling/configurable' @middlewares = [ ] @adapter = Pling :: Adapter :: Base . new ## # Stores the list of avaiable middleware instances # # @return [Array] list of available middleware attr_accessor :middlewares ## # Stores the adapter # # @return [Pling::Adapter] attr_accessor :adapter ## # Delivers the given message to the given device using the given stack. # # @param message [#to_pling_message] # @param device [#to_pling_device] # @param stack [Array] The stack to use (Default: middlewares + [adapter]) def deliver ( message , device , stack = middlewares + [ adapter ] ) stack . shift . deliver ( message , device ) do | m , d | deliver ( m , d , stack ) end end", "del_tokens": "autoload :Device , 'pling/device' autoload :Message , 'pling/message' autoload :Gateway , 'pling/gateway'", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "alternative", "ruby", "implementations", "."], "add_tokens": "if scope . respond_to? :local_variable_set scope . local_variable_set key , value eval \"#{key} = #{value.inspect}\" , scope", "del_tokens": "if RUBY_VERSION . start_with? ( '1.9' , '2.0' ) eval \"#{key} = #{value.inspect}\" , scope scope . local_variable_set key , value", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "hidden", "option", "type", "for", "nested", "configurations"], "add_tokens": "unless delegate [ :type ] == :hidden add ( default . delegates , key ) end", "del_tokens": "add ( default . delegates , key )", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "that", "a", "new", "round", "doesn", "t", "start", "on", "the", "same", "gameday"], "add_tokens": "nbr_of_games = max_games_per_day = 0 day_game_ctr = 0 max_games_per_day += ( flight . include? ( :dummy ) ? ( flight . size - 2 ) / 2.0 : ( flight . size - 1 ) / 2.0 ) . ceil puts \"JOUE #{max_games_per_day}\" if day_game_ctr <= max_games_per_day - 1 flat_game = { :gamedate => cur_date , :gt => gt , :ps => ps } flat_schedule << flat_game nbr_of_games -= 1 day_game_ctr += 1 end last_date = cur_date day_game_ctr = 0 if cur_date != last_date", "del_tokens": "nbr_of_games = 0 flat_game = { :gamedate => cur_date , :gt => gt , :ps => ps } flat_schedule << flat_game nbr_of_games -= 1 #we have finished a round. We cannot start another round on the same gameday while flat_schedule [ i ] && flat_schedule [ i ] [ :gamedate ] == flat_schedule [ i - 1 ] [ :gamedate ] do i += 1 end", "commit_type": "make"}
{"commit_tokens": ["Changed", "GeneralNote", "id", "to", "general_debug_info"], "add_tokens": "'General (id=\"general_debug_info\")'", "del_tokens": "'General (id=\"tm_debug\")'", "commit_type": "change"}
{"commit_tokens": ["Add", "base", "setup", "and", "Ribose", "OSS", "style", "config"], "add_tokens": "VERSION = \"0.1.0\" . freeze", "del_tokens": "VERSION = \"0.1.0\"", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "remove", "ruby", "limit", "and", "udpate", "coverage", "api", "call"], "add_tokens": "# frozen_string_literal: true if ENV [ 'COVERAGE' ] || ENV [ 'TRAVIS' ] SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter . new ( [ ] )", "del_tokens": "if RUBY_VERSION > '1.9' and ( ENV [ 'COVERAGE' ] || ENV [ 'TRAVIS' ] ) SimpleCov . formatter = SimpleCov :: Formatter :: MultiFormatter [ ]", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "method", "to", "check", "if", "a", "date", "is", "convertible", "or", "not"], "add_tokens": "when ! era_convertible? def era_convertible? self . to_time >= :: Time . mktime ( 1868 , 9 , 8 ) end", "del_tokens": "when self . to_time < :: Time . mktime ( 1868 , 9 , 8 )", "commit_type": "add"}
{"commit_tokens": ["Adds", "tests", "for", "skipping", "existing", "labels"], "add_tokens": "VERSION = \"0.0.6\"", "del_tokens": "VERSION = \"0.0.5\"", "commit_type": "add"}
{"commit_tokens": ["Move", "requester", "creation", "to", "Requester", "module"], "add_tokens": "@requester = Requester . create ( config )", "del_tokens": "require 'oauth' @requester = create_requester ( config ) def create_requester ( config ) if config . auth_type == 'basic' Requester :: Basic . new ( config . user_id , config . api_key ) else consumer = OAuth :: Consumer . new ( config . consumer_key , config . consumer_secret ) Requester :: OAuth . new ( OAuth :: AccessToken . new ( consumer , config . access_token , config . access_token_secret ) ) end end", "commit_type": "move"}
{"commit_tokens": ["Updated", "remaining", "usages", "of", "MultiJson", "to", "work", "with", "new", "&", "old", "APIs"], "add_tokens": "MultiJson . respond_to? ( :adapter ) ? MultiJson . adapter : MultiJson . engine MultiJson . respond_to? ( :use ) ? MultiJson . use ( backend ) : MultiJson . engine = backend MultiJson . respond_to? ( :load ) ? MultiJson . load ( s ) : MultiJson . decode ( s ) MultiJson . respond_to? ( :dump ) ? MultiJson . dump ( schema ) : MultiJson . encode ( schema )", "del_tokens": "MultiJson . engine MultiJson . engine = backend MultiJson . decode ( s ) MultiJson . encode ( schema )", "commit_type": "update"}
{"commit_tokens": ["remove", "syntax", "sugar", "to", "calm", "trevis"], "add_tokens": "# collection_select :collection, [[\"a\", \"aa\"], [\"b\", \"bb\"]], :first, :last, bootstrap: {label: {text: \"Custom\"}}", "del_tokens": "# collection_select :collection, [[a, aa], [b, bb]], :first, :last, bootstrap: {label: {text: \"Custom\"}}", "commit_type": "remove"}
{"commit_tokens": ["use", "abort", "instead", "of", "raising", "errors"], "add_tokens": "abort ( \"JIRA ticket id or existing JIRA Git Branch is required to run this process\" ) unless tickets . any? end", "del_tokens": "raise \"JIRA ticket id or existing JIRA Git Branch is required to run this process\" unless tickets . any? end", "commit_type": "use"}
{"commit_tokens": ["Fix", "first", "round", "of", "tests"], "add_tokens": "fail \"Failed with #{response.status_type} error from server. Received error #{response.status_code}.\"", "del_tokens": "fail \"Failed with #{response.status_type} error from server\"", "commit_type": "fix"}
{"commit_tokens": ["Updated", "data", "store", "to", "accept", "an", "Imagetastic", "::", "Image"], "add_tokens": "def store ( image ) FileUtils . mkdir_p File . dirname ( storage_path ) unless File . exist? ( storage_path ) FileUtils . cp image . path , storage_path file = File . new ( absolute_storage_path ( relative_path ) , 'r' ) Imagetastic :: Image . new ( file )", "del_tokens": "def store ( data ) FileUtils . mkdir_p File . dirname ( storage_path ) File . open ( storage_path , 'w' ) do | file | file . write ( data ) end File . read ( absolute_storage_path ( relative_path ) )", "commit_type": "update"}
{"commit_tokens": ["fixed", "using", "the", "proper", "version", "of", "spec"], "add_tokens": "VERSION = '0.3.1'", "del_tokens": "VERSION = '0.3.0'", "commit_type": "fix"}
{"commit_tokens": ["make", "test", "helper", "load", "necessary", "stuff", "for", "bundler"], "add_tokens": "Bundler . setup ( :default , :test )", "del_tokens": "Bundler . setup ( :test )", "commit_type": "make"}
{"commit_tokens": ["Adds", "new", "layout", "with", "multiple", "ids", "action"], "add_tokens": "require 'active_list/rails'", "del_tokens": "autoload :ActionPack , 'active_list/action_pack' require 'active_list/rails/engine'", "commit_type": "add"}
{"commit_tokens": ["Removing", "references", "to", "roles", "and", "permissions", "from", "the", "base", "gem", "."], "add_tokens": "t . integer :role_id , :default => 0 # Not used by default, install challah-rolls to utilize this", "del_tokens": "t . integer :role_id", "commit_type": "remove"}
{"commit_tokens": ["Made", "sure", "totals", "are", "weighted", "correctly", ".", "Also", "added", "filtering", "and", "sorting", "to", "table"], "add_tokens": "require 'rubygems' require 'test/unit' require 'shoulda'", "del_tokens": "require 'rubygems' require 'test/unit' require 'shoulda'", "commit_type": "make"}
{"commit_tokens": ["Makes", "it", "work", "for", "multi", "joins!"], "add_tokens": "result = self . where ( user_id_field => _user_id ) # When there are multiple joins defined, just keep calling 'joins' # for each association. if hash_params [ :joins ] result = hash_params [ :joins ] . inject ( result ) do | query , assoc | result csv << query_fields . map do | f | f_splitted = f . to_s . split ( ' ' ) if ( f_splitted . size == 2 ) # field f is coming from an assoc, i.e. field has been defined # as \"<tablename> <field>\" in gdpr_collect then to get its value # do r.<tablename>.<field> f_splitted . inject ( r ) { | result , method | result . send ( method ) } else # No association involved, simply retrieve the field value. r . send ( f ) end end", "del_tokens": "assocs_to_join = hash_params [ :joins ] if assocs_to_join assocs_to_join . inject ( self . select ( query_fields ) . where ( user_id_field => _user_id ) ) do | query , assoc | else self . select ( query_fields ) . where ( user_id_field => _user_id ) csv << query_fields . map { | f | r . send ( f ) }", "commit_type": "make"}
{"commit_tokens": ["Make", "sure", "init", "only", "runs", "once"], "add_tokens": "init! ( klass ) || klass . new ( fetchable )", "del_tokens": "init ( klass ) || klass . new ( fetchable )", "commit_type": "make"}
{"commit_tokens": ["Remove", "unused", "options", "on", "Generator", "."], "add_tokens": "def self . gen ( & blk ) new . gen ( & blk )", "del_tokens": "def self . gen ( opts = { } , & blk ) new ( opts ) . gen ( & blk )", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "correct", "primary", "key"], "add_tokens": "Hash [ references . map { | model , ids | [ model , Hash [ model . classify . constantize . where ( model . classify . constantize . primary_key => ids . keys ) . map { | i | [ i . id . to_s , i ] } ] ] } ]", "del_tokens": "Hash [ references . map { | model , ids | [ model , Hash [ model . classify . constantize . where ( id : ids . keys ) . map { | i | [ i . id . to_s , i ] } ] ] } ]", "commit_type": "use"}
{"commit_tokens": ["Move", "the", "discovery", "of", "files", "to", "translate", "to", "a", "method", "so", "that", "it", "can", "be", "overriden", "by", "a", "user", "of", "the", "library", "."], "add_tokens": "files_to_translate ( ) , def files_to_translate Dir . glob ( \"{app,lib,config,locale}/**/*.{rb,erb,haml}\" ) end", "del_tokens": "Dir . glob ( \"{app,lib,config,locale}/**/*.{rb,erb,haml}\" ) ,", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "GitHub", "API", "auth", "via", "DANGER_API_TOKEN"], "add_tokens": "base_api_token = Base64 . strict_encode64 ( ENV [ \"DANGER_API_TOKEN\" ] ) response = REST . get api_url , { } , { 'Authorization' => \"Basic #{ base_api_token }\" 'User-Agent' => 'fastlane-danger' }", "del_tokens": "response = REST . get api_url", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "trace_id", "was", "always", "set", "to", "true", "."], "add_tokens": "if message && message . is_a? ( String ) && message . length > 1 && ! message . include? ( 'trace_id=' ) trace_id = get_trace_id message . gsub! ( \"\\n\" , \" trace_id=#{trace_id}\\n\" ) if trace_id && trace_id != TRACE_ID_DEFAULT", "del_tokens": "if message && message . is_a? ( String ) && message . length > 1 && ! message . include? ( 'trace_id=' ) && trace_id = get_trace_id && trace_id != TRACE_ID_DEFAULT message . gsub! ( \"\\n\" , \" trace_id=#{trace_id}\\n\" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "rdoc", "style", "inline", "code", "documentation", "the", "GFM", "style", "with", "backticks", "does", "not", "work", "."], "add_tokens": "# A +Hexp::Node+ represents a single element in a HTML syntax tree. It # Instances of +Hexp::Node+ are immutable. Because of this all methods that # The +Hexp::Node+ constructor takes a +Symbol+, a +Hash+ and an +Array+ for # that child node in an array. One can use +H[tag, attrs, children]+ as a # With a CSS selector string like +\"form.checkout\"+ you specify the nodes # can replace an +Array+ of nodes to fill the place of the old node. # @example Wrap each +<input>+ tag into a +<p>+ tag", "del_tokens": "# A `Hexp::Node` represents a single element in a HTML syntax tree. It # Instances of `Hexp::Node` are immutable. Because of this all methods that # The `Hexp::Node` constructor takes a `Symbol`, a `Hash` and an `Array` for # that child node in an array. One can use `H[tag, attrs, children]` as a # With a CSS selector string like `\"form.checkout\"` you specify the nodes # can replace an `Array` of nodes to fill the place of the old node. # @example Wrap each `<input>` tag into a `<p>` tag", "commit_type": "use"}
{"commit_tokens": ["Removing", "redundant", "Object", ".", "const_get", "=", "X"], "add_tokens": "serializer_const = options [ :serializer ] serializer_const = options [ :serializer ] || options [ :each_serializer ]", "del_tokens": "serializer_const = Panko :: SerializationDescriptor . resolve_serializer ( options [ :serializer ] ) serializer_name = options [ :serializer ] || options [ :each_serializer ] serializer_const = Panko :: SerializationDescriptor . resolve_serializer ( serializer_name )", "commit_type": "remove"}
{"commit_tokens": ["fix", "stack", "name", "for", "stack_exists?"], "add_tokens": "base_module :: CloudFormation :: Stack . new ( stack_name : stack . name ) . exists?", "del_tokens": "base_module :: CloudFormation :: Stack . new ( name : stack . name ) . exists?", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "Merb", "s", "magic", "exception", "handling", "in", "tests", ".", "This", "could", "be", "more", "robust", "."], "add_tokens": "begin @controller = self . send ( method , path , parameters , headers ) do | new_controller | new_controller . cookies = mycookies end rescue = > exception raise unless exception . kind_of? ( Merb :: ControllerExceptions :: Base ) #Now we want to go one level below 'post' to build the request ourselves, then send it to the controller exception_klass = exception . class klass = :: Exceptions rescue Merb :: Controller request = fake_request request . params [ :exception ] = exception request . params [ :action ] = exception_klass . name @controller = dispatch_request ( request , klass , exception_klass . name )", "del_tokens": "@controller = self . send ( method , path , parameters , headers ) do | new_controller | new_controller . cookies = mycookies", "commit_type": "implement"}
{"commit_tokens": ["added", "past", "present", "future", "date", "rules"], "add_tokens": "def self . search_conditions_for ( params , language = Tr8n :: Config . current_language ) conditions = [ \"language_id = ?\" , language . id ] conditions [ 0 ] << \" and \" unless conditions [ 0 ] . blank?", "del_tokens": "def self . search_conditions_for ( params ) conditions = [ \"\" ]", "commit_type": "add"}
{"commit_tokens": ["Fixing", "spacing", "and", "whitespace", "issues", ":"], "add_tokens": "def initialize ( options ) # manage title", "del_tokens": "def initialize ( options ) # manage title", "commit_type": "fix"}
{"commit_tokens": ["Adding", "new", "rules", "on", "the", "fly", ":", "preliminary", "ready", "."], "add_tokens": "get '/html/mapping' do delete '/html/mapping/:key' do | key | content_type :json session [ :typo ] . mapping . remove_spice ( key . to_sym ) . to_json end put '/html/mapping/:section/:key/:value/?:enclosure?' do | section , key , value , enclosure | content_type :json session [ :typo ] . mapping . add_spice ( section . to_sym , key . to_sym , value . to_sym , enclosure ? enclosure . to_sym : nil ) . to_json end get '/html/parse' do", "del_tokens": "get '/mapping/:type' do | type | raise Exception . new \"Type #{type} is not supported. Aborting.\" unless type == 'html' get '/bowler/:type' do | type | raise Exception . new \"Type #{type} is not supported. Aborting.\" unless type == 'html'", "commit_type": "add"}
{"commit_tokens": ["allow", "globs", "to", "be", "specified", "for", "tests", "and", "specs", "when", "running", "rake"], "add_tokens": "spec_glob = ENV [ \"SAUCE_SPEC_GLOB\" ] || \"spec/selenium/**/*_spec.rb\" t . spec_files = FileList [ spec_glob ] spec_glob = ENV [ \"SAUCE_SPEC_GLOB\" ] || \"spec/selenium/**/*_spec.rb\" t . pattern = spec_glob test_glob = ENV [ \"SAUCE_TEST_GLOB\" ] || \"test/selenium/**/*_test.rb\" t . pattern = test_glob", "del_tokens": "t . spec_files = FileList [ \"spec/selenium/**/*_spec.rb\" ] t . pattern = \"spec/selenium/**/*_spec.rb\" t . pattern = 'test/selenium/**/*_test.rb'", "commit_type": "allow"}
{"commit_tokens": ["fix", "lookup", "method", "add", "to_s", "to", "query", "results"], "add_tokens": "return false results . select { | r | r . final } . map { | r | r . to_s }", "del_tokens": "return [ '' ] results . select { | r | r . final } . map { | r | r }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ActionDispatch", "::", "Http", "::", "ParameterFilter", "is", "deprecated"], "add_tokens": "parameter_filter = ActiveSupport :: ParameterFilter . new ( env [ \"action_dispatch.parameter_filter\" ] || [ ] )", "del_tokens": "parameter_filter = ActionDispatch :: Http :: ParameterFilter . new ( env [ \"action_dispatch.parameter_filter\" ] || [ ] )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "Kernel#puts", "to", "do", "info", "instead", "of", "debug", "."], "add_tokens": "ErnieBrodeur :: Log . info s", "del_tokens": "ErnieBrodeur :: Log . debug s", "commit_type": "change"}
{"commit_tokens": ["Use", "deep", "merge", "in", "display_meta_tags"], "add_tokens": "meta_tags = normalize_open_graph ( default ) . deep_merge! ( self . meta_tags )", "del_tokens": "meta_tags = normalize_open_graph ( default ) . merge ( self . meta_tags )", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "association", "to", "create", "the", "parent", "callback"], "add_tokens": "association = belongs_to ( * args ) create_cached_belongs_to_parent_callbacks ( caches , klass , children_callback_name , association ) def create_cached_belongs_to_parent_callbacks ( caches , parent_class_name , children_callback_name , association ) has_many_association = self . name . demodulize . underscore . pluralize . to_sym # What is this? I don't even... parent_class = association . klass . name . constantize", "del_tokens": "belongs_to ( * args ) create_cached_belongs_to_parent_callbacks ( caches , klass , children_callback_name ) def create_cached_belongs_to_parent_callbacks ( caches , parent_class_name , children_callback_name ) has_many_association = self . name . underscore . pluralize . to_sym parent_class = parent_class_name . to_s . camelize . constantize", "commit_type": "use"}
{"commit_tokens": ["Make", "message", "deduplication", "operation", "atomic"], "add_tokens": "begin job_execution = Barbeque :: JobExecution . create ( message_id : @message . id , job_definition : job_definition , job_queue : @job_queue ) rescue ActiveRecord :: RecordNotUnique raise DuplicatedExecution end", "del_tokens": "job_execution = Barbeque :: JobExecution . find_or_initialize_by ( message_id : @message . id ) raise DuplicatedExecution if job_execution . persisted? job_execution . update! ( job_definition : job_definition , job_queue_id : @job_queue . id )", "commit_type": "make"}
{"commit_tokens": ["Fix", "struct", "type", "for", "arguments", "from", "Bytes", "to", "Table", "."], "add_tokens": ":arguments , Table :arguments , Table :arguments , Table :arguments , Table :arguments , Table :arguments , Table", "del_tokens": ":arguments , Bytes :arguments , Bytes :arguments , Bytes :arguments , Bytes :arguments , Bytes :arguments , Bytes", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "when", "looking", "up", "with", "--", "name"], "add_tokens": "if d . name == user_droplet_name", "del_tokens": "if droplet . name == user_droplet_name", "commit_type": "fix"}
{"commit_tokens": ["move", "response", "parsing", "to", "the", "parser", "class", ".", "add", "server", "validation", "test"], "add_tokens": "when 500 .. 599 raise Errors :: ServerError , env", "del_tokens": "when 500 .. 599 raise Errors :: ServerError , env", "commit_type": "move"}
{"commit_tokens": ["removed", "some", "obsolte", ".", "to_s", "calls", "within", "string", "interpolations"], "add_tokens": "options = { :column => \"#{enum_cd}_cd\" , :whiny => true } . merge ( options ) define_method ( \"#{enum_cd}=\" ) do | new_value | define_method ( \"values_for_#{enum_cd}\" ) do prefix = options [ :prefix ] && \"#{options[:prefix] == true ? enum_cd : options[:prefix]}_\" define_method ( \"#{prefix}#{k}?\" ) do define_method ( \"#{prefix}#{k}!\" ) do", "del_tokens": "options = { :column => \"#{enum_cd.to_s}_cd\" , :whiny => true } . merge ( options ) define_method ( \"#{enum_cd.to_s}=\" ) do | new_value | define_method ( \"values_for_#{enum_cd.to_s}\" ) do prefix = options [ :prefix ] && \"#{options[:prefix] == true ? enum_cd.to_s : options[:prefix]}_\" define_method ( \"#{prefix}#{k.to_s}?\" ) do define_method ( \"#{prefix}#{k.to_s}!\" ) do", "commit_type": "remove"}
{"commit_tokens": ["Add", "ability", "to", "reset", "field", "."], "add_tokens": "# Reset to original value # # @api public def reset! @content = @value . to_s end", "del_tokens": "def value_height @height end", "commit_type": "add"}
{"commit_tokens": ["use", "JRuby", "::", "Rack", "::", "Worker", "::", "ENV", "for", "config", "when", "workers", "start"], "add_tokens": "require 'jruby/rack/worker/env' env = JRuby :: Rack :: Worker :: ENV options = { :quiet => true } options [ :queues ] = ( env [ 'QUEUES' ] || env [ 'QUEUE' ] || '' ) . split ( ',' ) options [ :min_priority ] = env [ 'MIN_PRIORITY' ] options [ :max_priority ] = env [ 'MAX_PRIORITY' ] # beyond `rake delayed:work` compatibility : if read_ahead = env [ 'READ_AHEAD' ] # DEFAULT_READ_AHEAD = 5 options [ :read_ahead ] = read_ahead . to_i end if sleep_delay = env [ 'SLEEP_DELAY' ] # DEFAULT_SLEEP_DELAY = 5 options [ :sleep_delay ] = sleep_delay . to_f end worker = Delayed :: JRubyWorker . new ( options )", "del_tokens": "worker = Delayed :: JRubyWorker . new ( :min_priority => ENV [ 'MIN_PRIORITY' ] , :max_priority => ENV [ 'MAX_PRIORITY' ] , :queues => ( ENV [ 'QUEUES' ] || ENV [ 'QUEUE' ] || '' ) . split ( ',' ) , :quiet => true )", "commit_type": "use"}
{"commit_tokens": ["Fixing", "some", "Package", "Cloud", "and", "version", "number", "stuff", "."], "add_tokens": "VERSION = \"0.3.2.pre\"", "del_tokens": "VERSION = \"0.3.1\"", "commit_type": "fix"}
{"commit_tokens": ["Made", "getting", "related", "services", "work", "within", "the", "brave", "new", "world", "of", "the", "Client", "class"], "add_tokens": "@client . service_named ( service_name )", "del_tokens": "base_options = { :username => self . username , :api_key => self . api_key , :endpoint_url => self . endpoint_url } base_options [ :savon_client_options ] = @savon_options if @savon_options self . class . new service_name , base_options . merge ( options )", "commit_type": "make"}
{"commit_tokens": ["Add", "#sum", "method", "to", "retrieve", "sum", "of", "all", "observed", "values"], "add_tokens": "@observations , @sum = 0 , 0 @sum += value end # # Returns the sum of all observed values. # def sum @sum", "del_tokens": "@observations = 0", "commit_type": "add"}
{"commit_tokens": ["Fix", "proxifing", "of", "arrays", "which", "include", "remote", "object", "proxies"], "add_tokens": "def proxify ( result ) \"[\" + result . map { | x | proxify ( x ) } . join ( \", \" ) + \"]\" result . inspect", "del_tokens": "def proxify ( result , in_array = false ) result . map { | x | proxify ( x , true ) } . inspect in_array ? result : result . inspect", "commit_type": "fix"}
{"commit_tokens": ["add", "timeline", "list", "convenience", "method", "to", "client", ";"], "add_tokens": ":api_keys , :timeline_list def timeline_list ( opts = { as_hash : true } ) retval = @timeline_list . nil? ? self . list ( opts ) : @timeline_list opts [ :as_hash ] ? retval . map ( & :to_hash ) : retval end ### this method is pretty much extracted directly from ### the mirror API code samples in ruby ### ### https://developers.google.com/glass/v1/reference/timeline/list def list ( opts = { as_hash : true } ) page_token = nil parameters = { } self . timeline_list = [ ] begin parameters = { } parameters [ 'pageToken' ] = page_token if page_token . present? api_result = google_client . execute ( api_method : mirror_api . timeline . list , parameters : parameters ) if api_result . success? timeline_items = api_result . data page_token = nil if timeline_items . items . empty? if timeline_items . items . any? @timeline_list . concat ( timeline_items . items ) page_token = timeline_items . next_page_token end else puts \"An error occurred: #{result.data['error']['message']}\" page_token = nil end end while page_token . to_s != '' timeline_list ( opts ) end", "del_tokens": ":api_keys", "commit_type": "add"}
{"commit_tokens": ["implement", "commands", "for", "get_marks", "and", "get_bar_config"], "add_tokens": "MESSAGE_TYPE_GET_MARKS = 5 MESSAGE_TYPE_GET_BAR_CONFIG = 6 MESSAGE_REPLY_GET_MARKS = 5 MESSAGE_REPLY_GET_BAR_CONFIG = 6 # Gets a list of marks (identifiers for containers to easily jump # to them later). # The reply will be a JSON-encoded list of window marks. # (see the reply section of i3 docu) def get_marks write format ( MESSAGE_TYPE_GET_MARKS ) handle_response MESSAGE_TYPE_GET_MARKS end # Gets the configuration (as JSON map) of the workspace bar with # the given ID. # If no ID is provided, an array with all configured bar IDs is returned instead. def get_bar_config id = nil write format ( MESSAGE_TYPE_GET_BAR_CONFIG , id ) handle_response MESSAGE_TYPE_GET_BAR_CONFIG end # Reads the reply from the socket # and parses the returned json into a ruby object.", "del_tokens": "# reads the reply from the socket # and parse the returned json into a ruby object", "commit_type": "implement"}
{"commit_tokens": ["Allow", "passing", "options", "to", "launch!"], "add_tokens": "def launch_device ( device , scale = 1.0 , opts = { } ) args = { '-ConnectHardwareKeyboard' => 1 , '-CurrentDeviceUDID' => device . udid , \"-SimulatorWindowLastScale-#{device.devicetype.identifier}\" => scale , } . merge ( opts ) . zip . flatten . join ( ' ' ) command = \"open -Fgn #{XCODE_HOME}/Applications/Simulator.app --args #{args}\"", "del_tokens": "def launch_device ( device , scale = 1.0 ) command = \"open -Fgn #{XCODE_HOME}/Applications/Simulator.app --args -ConnectHardwareKeyboard 0 -CurrentDeviceUDID #{device.udid} -SimulatorWindowLastScale-#{device.devicetype.identifier} #{scale}\"", "commit_type": "allow"}
{"commit_tokens": ["Add", "signal", "option", "to", "run", "command"], "add_tokens": "# @option options [Symbol] :signal # Signal used on timeout, SIGKILL by default", "del_tokens": "# #", "commit_type": "add"}
{"commit_tokens": ["make", "test", "output", "a", "lot", "less", "verbose", "to", "make", "Travis", "pass"], "add_tokens": "config . log_level = :warn", "del_tokens": "# Log error messages when you accidentally call methods on nil config . whiny_nils = true", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "change", "from", "dsisnero"], "add_tokens": "cmd = %Q/java -jar \"#{GOOGLE_JS_COMPRESSOR}\" --charset utf8/ cmd = %Q/java -jar \"#{YUI_JS_COMPRESSOR}\" --type js --charset utf8/ IO . popen ( cmd , 'r+' ) { | f | f . print ( scripts ) ; f . close_write ; min_js = f . read }", "del_tokens": "IO . popen ( \"java -jar #{GOOGLE_JS_COMPRESSOR} --charset utf8\" , 'r+' ) { | f | f . print ( scripts ) ; f . close_write ; min_js = f . read } IO . popen ( \"java -jar #{YUI_JS_COMPRESSOR} --type js --charset utf8\" , 'r+' ) { | f | f . print ( scripts ) ; f . close_write ; min_js = f . read }", "commit_type": "add"}
{"commit_tokens": ["adding", "spec", "for", "wait_for_", "method"], "add_tokens": "it \"element method should generate method to return the element\" do it \"should be able to wait for an element\" do class PageWithElement < SitePrism :: Page element :some_slow_element , 'a.slow' end page = PageWithElement . new page . should respond_to :wait_for_some_slow_element end", "del_tokens": "it \"element method hould generate method to return the element\" do", "commit_type": "add"}
{"commit_tokens": ["Added", "methods", "to", "pre", "-", "bonus", "rating", "and", "performance"], "add_tokens": "# _new_rating_:: This is the player's new rating. For rated players it is their old rating # plus their _rating_change_ plus their _bonus_ (if any). For provisional players # it is their performance rating including their previous games. For unrated # players it is their tournament performance rating. New ratings are not # calculated for foreign players so this method just returns their start _rating_. # _rating_change_:: This is calculated from a rated player's old rating, their K-factor and the sum # of expected scores in each game. The same as the difference between the old and # new ratings (unless there is a bonus). Not available for other player types. # _performance_:: This returns the tournament rating performance for rated, unrated and # foreign players. For provisional players it returns a weighted average # of the player's tournament performance and their previous games. For # provisional and unrated players it is the same as _new_rating_. # _expected_score_:: This returns the sum of expected scores over all results for all player types. # For rated players, this number times the K-factor gives their rating change. # It is calculated for provisional, unrated and foreign players but not actually # used to estimate new ratings (for provisional and unrated players performance # estimates are used instead). # _bonus_:: The bonus received by a rated player (usually zero). Only available for rated # players. # _pb_rating_:: A rated player's pre-bonus rating (rounded). Only for rated players and # returns nil for players who are ineligible for a bonus. # _pb_performance_:: A rated player's pre-bonus performance (rounded). Only for rated players and # returns nil for players ineligible for a bonus. attr_reader :rating , :kfactor , :bonus , :pb_rating , :pb_performance @pb_rating = nil @pb_performance = nil @pb_rating = ( @rating + change ) . round @pb_performance = @performance . round", "del_tokens": "# _new_rating_:: This is the player's new rating. For rated players it is their old rating # plus their _rating_change_ plus their _bonus_ (if any). For provisional players # it is their performance rating including their previous games. For unrated # players it is their tournament performance rating. New ratings are not # calculated for foreign players so this method just returns their start _rating_. # _rating_change_:: This is calculated from a rated player's old rating, their K-factor and the sum # of expected scores in each game. The same as the difference between the old and # new ratings (unless there is a bonus). Not available for other player types. # _performance_:: This returns the tournament rating performance for rated, unrated and # foreign players. For provisional players it returns a weighted average # of the player's tournament performance and their previous games. For # provisional and unrated players it is the same as _new_rating_. # _expected_score_:: This returns the sum of expected scores over all results for all player types. # For rated players, this number times the K-factor gives their rating change. # It is calculated for provisional, unrated and foreign players but not actually # used to estimate new ratings (for provisional and unrated players performance # estimates are used instead). # _bonus_:: The bonus received by a rated player (usually zero). Not available for other player types. attr_reader :rating , :kfactor , :bonus", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "settlement", "and", "currency", "are", "removed", "from", "request"], "add_tokens": "[ \"TermUrl\" , \"MerchantName\" , \"Currency\" , \"SettlementDay\" ] . each { | e | ops . delete_element e }", "del_tokens": "[ \"TermUrl\" , \"MerchantName\" ] . each { | e | ops . delete_element e }", "commit_type": "make"}
{"commit_tokens": ["Remove", "forced", "stub", "+", "response", "check", "in", "producer", "tests"], "add_tokens": "it { is_expected . to include ( { } ) } context 'With generated token' do it { expect ( stub_response ) . to include ( \"token\" => \"ATabc123\" ) } it { is_expected . to include ( stub_response . merge ( \"token\" => / \\A AT \\w + \\z / ) ) } end", "del_tokens": "it { is_expected . to include ( { } ) }", "commit_type": "remove"}
{"commit_tokens": ["fixing", "my", "syntax", "highlighting", "in", "textmate"], "add_tokens": "it \"should enable configuration option 'username_attribute_name'\" do SimpleAuth :: Model :: Config . username_attribute_name . should equal ( :email ) it \"should enable configuration option 'crypted_password_attribute_name'\" do it \"should enable configuration option 'encryption_algorithm'\" do it \"should enable configuration option 'encryption_key'\" do it \"should enable configuration option 'custom_encryption_provider'\" do", "del_tokens": "it \"should enable configuration option 'username_attribute_name'\" do SimpleAuth :: Model :: Config . username_attribute_name . should equal ( :email ) it \"should enable configuration option 'crypted_password_attribute_name'\" do it \"should enable configuration option 'encryption_algorithm'\" do it \"should enable configuration option 'encryption_key'\" do it \"should enable configuration option 'custom_encryption_provider'\" do", "commit_type": "fix"}
{"commit_tokens": ["Adds", "caching", "of", "host", "DNS", "lookups"], "add_tokens": "@exchanger = EmailAddress :: Exchanger . cached ( self . dns_host_name )", "del_tokens": "@exchanger = EmailAddress :: Exchanger . new ( self . dns_host_name )", "commit_type": "add"}
{"commit_tokens": ["fixed", "default", "filter", "if", "empty"], "add_tokens": "# errors[:filter] = \"This filter cannot be submitted without any criteria because too many results may be returned. A default filter has been selected for you.\" @sql_conditions = nil @results = nil", "del_tokens": "errors [ :filter ] = \"This filter cannot be submitted without any criteria because too many results may be returned. A default filter has been selected for you.\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "single", "quotes", "where", "possible"], "add_tokens": "node_name = { 'affiliate_tags' => 'tags' } . fetch ( method , method )", "del_tokens": "node_name = { \"affiliate_tags\" => \"tags\" } . fetch ( method , method )", "commit_type": "use"}
{"commit_tokens": ["used", "rspec", "command", "to", "install", "missing", "files"], "add_tokens": "describe \"participant tool\" do let ( :user ) { users ( :user ) } before do visit \"/social_networking/profile_page\" end scenario \"User creates participant\" do expect ( 1 ) . to be 2 end", "del_tokens": "describe \"participant tool\" , type : :feature do let ( :user ) { participants ( :user ) } scenario \"User creates participant\"", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "models", "passed", "as", "constraints", "were", "using", "incorrect"], "add_tokens": "def sanitize_constraints ( model , constraints ) primary_key = association_primary_key ( model , k ) param = v . respond_to? ( primary_key ) ? v . send ( primary_key ) : v . to_param condition = { primary_key => param }", "del_tokens": "def sanitize_constraints ( constraints ) condition = { association_primary_key ( k ) => v . to_param }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "dead", "code", "in", "#platform_path"], "add_tokens": "class InvalidVersion < ArgumentError ; end", "del_tokens": "class InvalidVersion < ArgumentError ; end", "commit_type": "remove"}
{"commit_tokens": ["Add", "specs", "to", "rake", "task"], "add_tokens": "Coveralls . wear_merged!", "del_tokens": "Coveralls . wear!", "commit_type": "add"}
{"commit_tokens": ["Made", "it", "possible", "to", "use", "the", "Auth", "::", "Sentry", "class", "as", "a", "base", "class", "for", "your", "own", "custom", "sentry", "."], "add_tokens": "@user = User . new ( @request . params [ 'username' ] ) @user ? @user : nil", "del_tokens": "@user_id = @request . params [ 'username' ] @user_id ? User . new ( @user_id ) : nil", "commit_type": "make"}
{"commit_tokens": ["Add", "specs", "for", "custom", "date", "/", "time", "formatting", ".", "All", "specs", "passing", "."], "add_tokens": "params . require ( :schedule ) . permit ( :name , :lunchtime , :apocalypse , :birthday , :alarm_setting , :epoch , :christmas , :suppertime , :beer_oclock , :sleepytime , :party_time , :easter )", "del_tokens": "params . require ( :schedule ) . permit ( :name , :lunchtime , :apocalypse , :birthday , :alarm_setting )", "commit_type": "add"}
{"commit_tokens": ["remove", "rubocop", "from", "CI", "s", "builds"], "add_tokens": "def call ( * , ** , & block ) pid = fork_and_return_pid ( & block ) private def fork_and_return_pid fork do read . close result = yield Marshal . dump ( result , write ) exit! ( 0 ) end end", "del_tokens": "def call pid = fork do read . close result = yield Marshal . dump ( result , write ) exit! ( 0 ) end", "commit_type": "remove"}
{"commit_tokens": ["removed", "double", "render", "from", "Admin", "::", "ResourceController"], "add_tokens": "@model_class = model_class . to_s . singularize . camelize . constantize unless model_class . nil? def index default_display_responses end def show default_display_responses end def new default_display_responses end def edit default_display_responses end default_modify_responses default_modify_responses default_modify_responses format . xml do if action_name == 'index' render :xml => models else render :xml => model end", "del_tokens": "around_filter :default_display_responses , :only => [ :index , :show , :new , :edit ] around_filter :default_modify_responses :only => [ :create , :update , :destroy ] @model_class = model_class . to_s . camelize . constantize unless model_class . nil? yield case action_name when 'index' format . xml { render :xml => models } else format . xml { render :xml => model } yield", "commit_type": "remove"}
{"commit_tokens": ["add", "testing", "helper", "methods", "for", "Task", "ssh", "hosts", "and", "callbacks"], "add_tokens": "def dk_dsl_ssh_hosts @dk_dsl_ssh_hosts ||= self . instance_eval ( & self . class . ssh_hosts ) end ssh_hosts [ self . dk_dsl_ssh_hosts ] || self . dk_dsl_ssh_hosts def before_callback_task_classes ; self . before_callbacks . map ( & :task_class ) end def after_callback_task_classes ; self . after_callbacks . map ( & :task_class ) end", "del_tokens": "ssh_hosts [ dk_dsl_ssh_hosts ] || dk_dsl_ssh_hosts end def dk_dsl_ssh_hosts @dk_dsl_ssh_hosts ||= self . instance_eval ( & self . class . ssh_hosts )", "commit_type": "add"}
{"commit_tokens": ["Added", "non", "-", "polymorphic", "_type", "=", ">", "nil", ".", "Added", "parent", "Object", "retrieval", "with", "pbt_parent", "."], "add_tokens": "val ? \"#{val}_id\" . to_sym : nil poly? ? \"#{pbt}_type\" . to_sym : nil poly? ? eval ( \"self.#{pbt}_type\" ) : nil end def pbt_parent if pbt if poly? eval \"#{pbt_type}.find(#{pbt_id})\" else eval \"#{val.capitalize.to_s}.find(#{pbt_id})\" end else nil end", "del_tokens": "val ? \"#{pbt}_id\" . to_sym : nil val = pbt val ? \"#{pbt}_type\" . to_sym : nil val ? eval ( \"self.#{val}_type\" ) : nil", "commit_type": "add"}
{"commit_tokens": ["added", "better", "exception", "handling", "and", "fixed", "some", "audio", "processor", "errors"], "add_tokens": "require 'attached/processor/error' begin raise \"command 'lame' not found: ensure LAME is installed\" end unless $? . exitstatus == 0 raise Attached :: Processor :: Error , \"attachment file must be an audio file\"", "del_tokens": "begin raise \"Command 'lame' failed. Ensure file is an audio and attachment options are valid.\" unless $? . exitstatus == 0 raise \"Command 'lame' not found. Ensure 'LAME' is installed.\"", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "bump", "gem", "version", "up"], "add_tokens": "VERSION = \"0.9.0\"", "del_tokens": "VERSION = \"0.8.0\"", "commit_type": "change"}
{"commit_tokens": ["update", "tests", "to", "use", "tilde"], "add_tokens": "context \"validating meads\" do end mead = Mead :: Identifier . new ( 'ua023_031-002-cb0126-031-001' , @loc_ua023_031 ) mead = Mead :: Identifier . new ( 'mc00240-002-bx0061-fr77~23_1-001' , @loc_mc00240 ) . extract", "del_tokens": "context \"validating meads\" do end mead = Mead :: Identifier . new ( 'ua023_031-002-cb0126-031-001' , @loc_ua023_031 ) mead = Mead :: Identifier . new ( 'mc00240-002-bx0061-fr77,23_1-001' , @loc_mc00240 ) . extract", "commit_type": "update"}
{"commit_tokens": ["Added", "AccessDenied", "spec", "for", "destroy", "post", "."], "add_tokens": "it \"raises Cornerstone::AccessDenied if the user did not create the post\" do user = Factory ( :user ) sign_in user user2 = Factory ( :user ) post = Factory ( :post_w_user , :user => user2 ) lambda { delete :destroy , :discussion_id => \"2\" , :id => post . id , :use_route => :cornerstone } . should raise_error ( Cornerstone :: AccessDenied ) end", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "example", "for", "SecondLevelCaching", "."], "add_tokens": "def initialize ( second_level_cache = nil ) @second_level_cache = second_level_cache @cache = if second_level_cache . nil? Hash . new { | h , k | h [ k ] = Hash . new } else Hash . new { | h , k | h [ k ] = Hash . new { | h2 , k2 | h2 [ k2 ] = @second_level_cache . get ( k , k2 ) } } end", "del_tokens": "def initialize # WeakHash is much more expensive, and not necessary if the IdentityMap is tied to Session instead of Repository. # @cache = Hash.new { |h,k| h[k] = Support::WeakHash.new } @cache = Hash . new { | h , k | h [ k ] = Hash . new }", "commit_type": "update"}
{"commit_tokens": ["Changed", "parameters", "for", "find", "in", "collection"], "add_tokens": "def find ( selector = { } , options = { } ) options = { :fields => nil , :offset => 0 , :limit => 0 , :sort => nil } . update ( options ) @db . query ( @name , Query . new ( selector , options [ :fields ] , options [ :offset ] , options [ :limit ] , options [ :sort ] ) )", "del_tokens": "def find ( selector = { } , fields = nil , options = { } ) fields = nil if fields && fields . empty? @db . query ( @name , Query . new ( selector , fields , options [ :offset ] || 0 , options [ :limit ] || 0 , options [ :sort ] ) )", "commit_type": "change"}
{"commit_tokens": ["added", "more", "tests", "to", "be", "written", "in", "base"], "add_tokens": "context \"Tests for the JumpStart::Base#create_template instance method. \\n\" do should \"run create_template method\" do end end context \"Tests for the JumpStart::#check_for_strings_to_replace instance method.\\n\" do should \"\" do end end context \"Tests for the JumpStart::#check_replace_string_pairs_for_project_name_sub instance method.\\n\" do should \"\" do end end", "del_tokens": "# TODO Add tests that involve extended FileUtils methods after writing tests for FileUtils module.", "commit_type": "add"}
{"commit_tokens": ["Updated", "unit", "tests", "for", "screenshots", "to", "test", "screenshot", "feature", "in", "different", "languages"], "add_tokens": "describe IosDeployKit :: AppScreenshot do describe \"#is_valid?\" do", "del_tokens": "describe IosDeployKit :: AppScreenshot , now : true do describe \"is_valid?\" do", "commit_type": "update"}
{"commit_tokens": ["Added", "rest", "of", "functionality", "from", "old", "gem", "."], "add_tokens": "include OQGraph :: Edge", "del_tokens": "extend :: OQGraph :: EdgeClassMethods includes :: OQGraph :: EdgeInstanceMethods after_create :add_to_graph after_destroy :remove_from_graph after_update :update_graph belongs_to :from , :class_name => '<%= @node_class %>' belongs_to :to , :class_name => '<%= @node_class %>' validates :from_id , :presence => true validates :to_id , :presence => true self . table_name = '<%= @edge_class.underscore.pluralize %>'", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "conveniences", "to", "test_helper", "wrote", "and", "greened", "some", "tests", "of", "group", "data", "record", "locking"], "add_tokens": "common_test ( name . to_s + \" in online app\" , & block ) unless RAILS_ENV . start_with? ( \"offline\" ) common_test ( name . to_s + \" in offline app\" , & block ) if RAILS_ENV . start_with? ( \"offline\" ) define_method ( \"test_\" + name . to_s . gsub ( \" \" , \"_\" ) ) . to_sym , & block", "del_tokens": "common_test ( name , & block ) unless RAILS_ENV . start_with? ( \"offline\" ) common_test ( name , & block ) if RAILS_ENV . start_with? ( \"offline\" ) define_method ( \"test_\" + name . to_s ) . to_sym , & block", "commit_type": "add"}
{"commit_tokens": ["Move", "elements", "around", "-", "no", "functional", "changes"], "add_tokens": "def emit_boolean ( b , as_map_key , cache ) as_map_key ? emit_string ( ESC , \"?\" , b , true , cache ) : @oj . push_value ( b ) end def emit_quoted ( o , as_map_key , cache ) emit_map_start emit_string ( TAG , \"'\" , nil , true , cache ) marshal ( o , false , cache ) emit_map_end end", "del_tokens": "def emit_quoted ( o , as_map_key , cache ) emit_map_start emit_string ( TAG , \"'\" , nil , true , cache ) marshal ( o , false , cache ) emit_map_end end def emit_boolean ( b , as_map_key , cache ) as_map_key ? emit_string ( ESC , \"?\" , b , true , cache ) : @oj . push_value ( b ) end", "commit_type": "move"}
{"commit_tokens": ["Fixed", "our", "Net", "::", "HTTP", "monkey", "patch", "so", "that", "it", "only", "stores", "a", "the", "recorded", "response", "once", "per", "request", ".", "Internally", "Net", "::", "HTTP#request", "recursively", "calls", "itself", "(", "passing", "slightly", "different", "arguments", ")", "in", "certain", "circumstances", "."], "add_tokens": "@__request_with_vcr_call_count = ( @__request_with_vcr_call_count || 0 ) + 1 __store_response_with_vcr__ ( response , request ) if @__request_with_vcr_call_count == 1 ensure @__request_with_vcr_call_count -= 1", "del_tokens": "__store_response_with_vcr__ ( response , request )", "commit_type": "fix"}
{"commit_tokens": ["fix", "TypeError", "spec", "for", "ree"], "add_tokens": "expect { described_class . new ( Object . new ) } . to raise_error ( TypeError )", "del_tokens": "expect { described_class . new ( 1 ) } . to raise_error ( TypeError )", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "index", ".", "html", "-", "permalinked", "indexes"], "add_tokens": "INDEX_REGEX = %r! ^/($|index \\. html?$) !i ( site . pages + site . static_files ) . any? { | file | file . url =~ INDEX_REGEX }", "del_tokens": "INDEX_REGEX = %r! ^/index.html?$ !i site . pages . any? { | page | page . url == \"/\" } || site . static_files . any? { | file | file . url =~ INDEX_REGEX }", "commit_type": "add"}
{"commit_tokens": ["Add", "gzip", "decompression", "middleware", "."], "add_tokens": "# :compress - Set to true to have Salesforce compress the # response (default: false). # [ :username , :password , :security_token , :client_id , :client_secret , :host , :compress , builder . use Restforce :: Middleware :: Gzip , self , @options", "del_tokens": "[ :username , :password , :security_token , :client_id , :client_secret , :host ,", "commit_type": "add"}
{"commit_tokens": ["move", "page", "definitions", "into", "helper"], "add_tokens": "content_tag :script , \"var ample_assets = {}; ample_assets.load = true; #{ample_assets_pages}\" , :type => \"text/javascript\" end def ample_assets_pages \" \\n ample_assets . pages = [ { id : 'recent-assets' , title : 'Recently Viewed' , url : '#{root_path}' } , { id : 'image-assets' , title : 'Images' } , { id : 'document-assets' , title : 'Documents' } ] ; \"", "del_tokens": "content_tag :script , \"var ample_assets = {}; ample_assets.load = true;\" , :type => \"text/javascript\"", "commit_type": "move"}
{"commit_tokens": ["Fix", "looking", "up", "in", "the", "wrong", "array", "for", "lazy", "loading"], "add_tokens": "self . class . lazer_metadata [ :properties ] . include? ( name ) &&", "del_tokens": "self . class . lazer_metadata [ :required ] . include? ( name ) &&", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "and", "clean", "up", "test_helper", ".", "rb"], "add_tokens": "it 'should create query string if none existed before' do", "del_tokens": "it 'should create query string if non existed before' do", "commit_type": "fix"}
{"commit_tokens": ["using", "recursive", "hash", "for", "cache", "misses"], "add_tokens": "method = \"visit_#{(klass.name || '').split('::').join('_')}\" method = respond_to? ( method ) ? method : h [ klass . superclass ]", "del_tokens": "method = klass . ancestors . map { | ancestor | \"visit_#{(ancestor.name || '').split('::').join('_')}\" } . find { | sig | respond_to? sig }", "commit_type": "use"}
{"commit_tokens": ["Make", "Dirmon", "Entry", "file", "name", "pattern", "matching", "case", "-", "insensitive"], "add_tokens": "# Case insensitive filename matching Pathname . glob ( pattern , File :: FNM_CASEFOLD ) . each do | pathname |", "del_tokens": "Pathname . glob ( pattern ) . each do | pathname |", "commit_type": "make"}
{"commit_tokens": ["add", "--", "dry", "-", "run", "to", "upload", "and", "download"], "add_tokens": "option :dry_run , :long => '--dry-run' , :short => '-n' , :boolean => true , :default => false , :description => \"Don't take action, only print what would happen\" ChefFS :: FileSystem . copy_to ( pattern , chef_fs , local_fs , config [ :recurse ] ? nil : 1 , config )", "del_tokens": "ChefFS :: FileSystem . copy_to ( pattern , chef_fs , local_fs , config [ :recurse ] ? nil : 1 , config [ :purge ] , config [ :force ] )", "commit_type": "add"}
{"commit_tokens": ["make", "attribute_names", "properly", "inherited", "by", "subclasses"], "add_tokens": "attribute_names << attr . to_s . camelcase @attributes ||= ( self == Model ) ? [ ] : superclass . attribute_names . dup", "del_tokens": "@attributes ||= [ ] @attributes << attr . to_s . camelcase @attributes || [ ]", "commit_type": "make"}
{"commit_tokens": ["Allow", "to", "pass", "matcher", "to", "AugeasTree#delete"], "add_tokens": "# @param [String, Matcher] def delete ( matcher ) if matcher . is_a? ( CFA :: Matcher ) @data . reject! ( & matcher ) else @data . reject! { | entry | entry [ :key ] == matcher } end", "del_tokens": "# @param key [String] def delete ( key ) @data . reject! { | entry | entry [ :key ] == key } end # @yieldparam block [Object] condition to satisfy def delete_if ( & _block ) @data . reject! { | entry | yield ( entry ) }", "commit_type": "allow"}
{"commit_tokens": ["Created", "RSpec", "tests", "some", "fixes"], "add_tokens": "type_class = get_type_class ( ( @config [ column . to_sym ] . try ( :[] , :type ) || :any ) ) new_value = eval \"#{type_class}.new(:column => column, :value => value, :extend_at_column_id => new_column.id)\" last_model . value = value last_model . save value = model . try ( :value ) if value . nil? value = @config [ column . to_sym ] . try ( :[] , :default ) assign column , value end value array << yield ( value ) array << yield ( key , value ) :any", "del_tokens": "type_class = get_type_class @config [ column . to_sym ] . try ( :[] , :type ) eval \" new_value = #{type_class}.new(:column => column, :value => value, :extend_at_column_id => new_column.id) \" eval \" last_model . value = value last_model . save \" model . try ( :value ) array << yield value array << yield key , value nil", "commit_type": "create"}
{"commit_tokens": ["Use", "new", "Metric", "class", "to", "generate", "metric", "names"], "add_tokens": "queue_namespace = metrics . for ( queue : queue ) Librato . measure \"#{queue_namespace}.size\" , sidekiq_queue . size Librato . measure \"#{queue_namespace}.latency\" , sidekiq_queue . latency Librato . increment \"#{queue_namespace}.processed\" Librato . increment \"#{queue_namespace}failed\" def metrics @_metrics ||= Metric . new ( namespace ) end", "del_tokens": "Librato . measure \"#{namespace}.#{queue}.size\" , sidekiq_queue . size Librato . measure \"#{namespace}.#{queue}.latency\" , sidekiq_queue . latency Librato . increment \"#{namespace}.#{queue}.processed\" Librato . increment \"#{namespace}.#{queue}failed\"", "commit_type": "use"}
{"commit_tokens": ["Implemented", "read", "/", "write", "/", "destroy", "methods"], "add_tokens": "def write ( content , _opts = { } ) blob = storage . create_block_blob ( blob = storage . get_blob ( container . name , full_path ( uid ) ) [ blob [ 1 ] , blob [ 0 ] . properties ] rescue Azure :: Core :: Http :: HTTPError nil storage . delete_blob ( container . name , full_path ( uid ) ) true rescue Azure :: Core :: Http :: HTTPError false \"#{time.strftime '%Y/%m/%d/'}#{rand(1e15).to_s(36)}_#{filename.gsub(/[^\\w.]+/, '_')}\"", "del_tokens": "def write ( content , opts = { } ) blob = azure_blob_service . create_block_blob ( # storage.put_object(bucket_name, full_path(uid), f, full_storage_headers(headers, content.meta)) # content = File.open(\"test.png\", \"rb\") { |file| file.read } # def generate_uid(name) # \"#{Time.now.strftime '%Y/%m/%d/%H/%M/%S'}/#{SecureRandom.uuid}/#{name}\" # end \"#{time.strftime '%Y/%m/%d/'}#{rand(1e15).to_s(36)}_#{filename.gsub(/[^\\w.]+/,'_')}\"", "commit_type": "implement"}
{"commit_tokens": ["Changed", "the", "default", "Thin", "socket", "option", "to", "/", "var", "/", "run", "/", "thin", ".", "sock", "."], "add_tokens": ":socket => '/var/run/thin.sock' ,", "del_tokens": ":socket => '/tmp/thin.sock' ,", "commit_type": "change"}
{"commit_tokens": ["Fixed", "the", "typon", "in", "code", "where", "topcis", "was", "written", "instead", "of", "topics", ".", "This", "was", "causing", "call", "to", "unsubscribe", "crash"], "add_tokens": "end unless topics . empty? if @publisher . do_pubrec ( id ) == MQTT_ERR_SUCCESS", "del_tokens": "end unless topcis . empty? if @publisher . do_pubrec ( id ) == MQTT_ERR_SUCCESS", "commit_type": "fix"}
{"commit_tokens": ["changed", "name", "of", "hid", "interface", "var"], "add_tokens": "HID_INTERFACE = 3", "del_tokens": "C108_HID_INTERFACE = 3", "commit_type": "change"}
{"commit_tokens": ["added", "state", "to", "helper", "methods"], "add_tokens": ":authorize_url => '/connect' ,", "del_tokens": ":authorize_url => '/oauth/authorize' ,", "commit_type": "add"}
{"commit_tokens": ["Updating", "readme", "and", "changelog", "bumping", "version", "."], "add_tokens": "VERSION = \"3.0.17\"", "del_tokens": "VERSION = \"3.0.16\"", "commit_type": "update"}
{"commit_tokens": ["fixed", "bug", "where", "last_episode", "and", "last_season", "compared", "strings", "instead", "of", "ints", "."], "add_tokens": "episodes . min_by { | e | e . index . to_i } episodes . max_by { | e | e . index . to_i }", "del_tokens": "episodes . inject { | a , b | a . index < b . index ? a : b } episodes . inject { | a , b | a . index > b . index ? a : b }", "commit_type": "fix"}
{"commit_tokens": ["add", "parser", "and", "add", "flexible", "interface"], "add_tokens": "@@basic_sell_parser = lambda do | message | if lines . length > 3 { \"price\" => price . gsub ( \",\" , \"\" ) . to_i , \"title\" => lines [ 0 ] , \"message\" => lines [ 3 .. - 1 ] . join ( \"\\n\" ) } \"1730742887066429\" => @@basic_sell_parser , \"144498012423141\" => @@basic_sell_parser , \"107793636088378\" => @@basic_sell_parser , \"191505604299442\" => @@basic_sell_parser , \"815837461828111\" => @@basic_sell_parser , \"952367224814302\" => @@basic_sell_parser , \"373766972786317\" => @@basic_sell_parser , \"1049467665068019\" => @@basic_sell_parser ,", "del_tokens": "@@parse_1730742887066429 = lambda do | message | if lines . length >= 3 { \"price\" => price . gsub ( \",\" , \"\" ) . to_i , \"title\" => lines [ 0 ] , \"message\" => lines [ 2 .. - 1 ] . join ( \"\\n\" ) } \"1730742887066429\" => @@parse_1730742887066429 , \"144498012423141\" => @@parse_1730742887066429 , \"107793636088378\" => @@parse_1730742887066429 , \"191505604299442\" => @@parse_1730742887066429", "commit_type": "add"}
{"commit_tokens": ["Fixing", "post", "requests", "for", "balance_mauth"], "add_tokens": "response = post ( authentication_url , { \"authentication_ticket\" => data } ) headers = options [ :headers ] . nil? ? { } : options [ :headers ] json_post_data = post_data . to_json headers = { } headers [ \"Content-Length\" ] = json_post_data . length . to_s headers [ \"Content-Type\" ] = 'application/json' request = Net :: HTTP :: Post . new ( to_url . path , headers ) request . body = json_post_data", "del_tokens": "response = post ( authentication_url , 'data' => data . to_json ) headers = { \"Content-Type\" => \"application/json\" } headers = options [ :headers ] . nil? ? headers : headers . merge ( options [ :headers ] ) request = Net :: HTTP :: Post . new ( to_url . path ) request . set_form_data ( post_data )", "commit_type": "fix"}
{"commit_tokens": ["making", "some", "docs", "github", "friendly"], "add_tokens": "description Utils . section_of ( \"README.rdoc\" , \"description\" ) history \"HISTORY.rdoc\" readme \"README.rdoc\"", "del_tokens": "description Utils . section_of ( \"README\" , \"description\" ) history \"HISTORY\" readme \"README\"", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "VTUrl", "test", "that", "checked", "results", "size", "to", "check", "the", "proper", "size"], "add_tokens": "assert_equal 63 , result . results . size", "del_tokens": "assert_equal 65 , result . results . size", "commit_type": "fix"}
{"commit_tokens": ["remove", "carriage", "returns", "from", "b64", "encoded", "signature"], "add_tokens": "Base64 . encode64 ( sig ) . gsub ( \"\\n\" , \"\" )", "del_tokens": "Base64 . encode64 ( sig )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "the", "path", "to", "the", "rails", "initialiser"], "add_tokens": "require File . dirname ( __FILE__ ) + \"/lib/princely/rails\"", "del_tokens": "require \"./lib/princely/rails\"", "commit_type": "fix"}
{"commit_tokens": ["changed", "Net", "::", "HTTP", "call", "when", "proxies", "are", "used", "...", "old", "code", "didn", "t", "work", "with", "some", "proxies"], "add_tokens": "GeoKit :: Geocoders :: proxy_pass ) . start ( uri . host , uri . port ) { | http | http . get ( uri . path + \"?\" + uri . query ) }", "del_tokens": "GeoKit :: Geocoders :: proxy_pass ) . start ( uri . host , uri . port ) { | http | http . request ( req ) }", "commit_type": "change"}
{"commit_tokens": ["Added", "condition", "to", "block", "."], "add_tokens": "} if defined? Rails", "del_tokens": "require 'rails' }", "commit_type": "add"}
{"commit_tokens": ["Allow", "indentation", "in", "reported", "text"], "add_tokens": "file . write get ( groups . size > 1 ? 'group_report' : 'report' ) . result ( binding )", "del_tokens": "file . write get ( groups . size > 1 ? 'group_report' : 'report' ) . result ( binding ) . gsub ( ' ' , '' ) . gsub ( \"\\n\\n\" , '' )", "commit_type": "allow"}
{"commit_tokens": ["Use", "upsert", "to", "allow", "duplicate", "keys", "to", "be", "updated"], "add_tokens": "@cache . update ( { '_id' => key } , { '_id' => key , 'data' => serialized_value } , { :upsert => true } )", "del_tokens": "@cache . insert ( { '_id' => key , 'data' => serialized_value } )", "commit_type": "use"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = '0.7.3'", "del_tokens": "VERSION = '0.7.2'", "commit_type": "change"}
{"commit_tokens": ["Adding", "clear_aliased_actions", "to", "Ability", "which", "removes", "previously", "defined", "actions", "including", "defaults"], "add_tokens": "# Returns a hash of aliased actions. The key is the target and the value is an array of actions aliasing the key. # Removes previously aliased actions including the defaults. def clear_aliased_actions @aliased_actions = { } end private", "del_tokens": "private", "commit_type": "add"}
{"commit_tokens": ["Added", "rule", "helper", "to", "DSL"], "add_tokens": "# rule \"*.o\", \"*.c\" # rule \"**/*.o\", \"**/.c\" def rule ( glob , dependency , & block ) Dir . glob ( glob ) . each do | path | FileTask . new ( path ) do | task | task . description = \"Generate #{path}\" task . define ( & block ) end end end task . define { mkdir_p path }", "del_tokens": "task . define do mkdir_p path end", "commit_type": "add"}
{"commit_tokens": ["added", "localized", "verifications", "in", "viewables_controller", "specs"], "add_tokens": "FactoryGirl . create_list ( :unique_key_fr , 3 ) FactoryGirl . create_list ( :unique_key_en , 3 ) expect ( subject ) . to eql ( [ 3 , 1 , 2 , 3 , 1 , 2 ] ) expect ( subject ) . to eql ( [ 2 , 3 , 1 , 2 , 3 , 1 ] ) expect ( subject ) . to eql ( [ 1 , 2 , 3 , 1 , 2 , 3 ] )", "del_tokens": "FactoryGirl . create_list ( :unique_key , 3 ) expect ( subject ) . to eql ( [ 3 , 1 , 2 ] ) expect ( subject ) . to eql ( [ 2 , 3 , 1 ] ) expect ( subject ) . to eql ( [ 1 , 2 , 3 ] )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "indention", "of", "the", "code", "."], "add_tokens": "BELL = \"\\x07\" LINE_FEED = \"\\x0A\" CARRIAGE_RETURN = \"\\x0D\"", "del_tokens": "BELL = \"\\x07\" LINE_FEED = \"\\x0A\" CARRIAGE_RETURN = \"\\x0D\"", "commit_type": "fix"}
{"commit_tokens": ["Use", "string", "-", "based", "test", "names"], "add_tokens": "if arg =~ / \\/ (.*) \\/ / Regexp . new ( $1 ) else # Turn 'sample error1' into 'test_sample_error1' arg [ 0 .. 4 ] == \"test_\" ? arg . gsub ( \" \" , \"_\" ) : \"test_\" + arg . gsub ( \" \" , \"_\" ) end @@out . print \" #{test.gsub(\"test_\", \"\").gsub(/_/, \" \")}\"", "del_tokens": "arg =~ / \\/ (.*) \\/ / ? Regexp . new ( $1 ) : arg @@out . print \" #{test}\"", "commit_type": "use"}
{"commit_tokens": ["fixing", "scalar", "scanner", "for", "dates", "with", "timezone", "like", "-", "08", ":", "00", ".", "thanks", "Peter", "McLain!"], "add_tokens": "tz = md [ 3 ] ? Integer ( md [ 3 ] . split ( ':' ) . first . sub ( / ([-+])0 / , '\\1' ) ) : 0", "del_tokens": "tz = md [ 3 ] ? Integer ( md [ 3 ] . split ( ':' ) . first ) : 0", "commit_type": "fix"}
{"commit_tokens": ["updates", "to", "cache", "behavior", "so", "we", "can", "do", "a", "bit", "less", "configuration"], "add_tokens": "# if we have an overridden cache, return it return @overridden_cache if defined? ( @overridden_cache ) # use Rails.cache if it is defined return Rails . cache if defined? ( Rails ) && Rails . cache # last resort, just use our own cache choice @overridden_cache = cache", "del_tokens": "@cache = cache", "commit_type": "update"}
{"commit_tokens": ["Add", "escaping", "for", "$", "to", "class", "and", "define", "examples"], "add_tokens": "param_str = params . keys . map { | r | param_val = escape_special_chars ( params [ r ] . inspect ) \"#{r.to_s} => #{param_val}\" } . join ( ',' ) code = import_str + 'class' + \" { \\\"\" + klass_name + \"\\\": \" + param_str + \" }\"", "del_tokens": "code = import_str + 'class' + \" { \\\"\" + klass_name + \"\\\": \" + params . keys . map { | r | \"#{r.to_s} => #{params[r].inspect}\" } . join ( ',' ) + \" }\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "delete", "catalog", "item", "code", "which", "only", "deletes", "the", "catalog", "item", "reference", "."], "add_tokens": "catalog_item . delete", "del_tokens": "connection . delete ( catalog_item . remove_link )", "commit_type": "fix"}
{"commit_tokens": ["fix", "error", "in", "signature", "validation", "and", "bump", "version"], "add_tokens": "options , parsed_params = parse_params ( params . merge ( post_params ) )", "del_tokens": "options , parsed_params = parse_params ( params )", "commit_type": "fix"}
{"commit_tokens": ["Moves", "https", "setup", "into", "a", "private", "method"], "add_tokens": "setup_https @https . start do | connection | @response = @https . request ( https_request ) def setup_https @https = Net :: HTTP . new ( API_BASE , Net :: HTTP . https_default_port ) @https . use_ssl = true @https . verify_mode = OpenSSL :: SSL :: VERIFY_PEER @https . ca_file = File . join ( File . dirname ( __FILE__ ) , \"data/paymill.crt\" ) end", "del_tokens": "https = Net :: HTTP . new ( API_BASE , Net :: HTTP . https_default_port ) https . use_ssl = true https . verify_mode = OpenSSL :: SSL :: VERIFY_PEER https . ca_file = File . join ( File . dirname ( __FILE__ ) , \"@data/paymill.crt\" ) https . start do | connection | @response = https . request ( https_request )", "commit_type": "move"}
{"commit_tokens": ["use", "the", "tag", "helper", "to", "generate", "the", "html", "tag"], "add_tokens": "if options [ :xmlns ] && options [ :xmlns ] . kind_of? ( Array ) options . delete ( :xmlns ) . each do | xmlns | if xmlns . kind_of? ( Hash ) options [ \"xmlns:#{xmlns[:prefix]}\" ] = xmlns [ :url ] else options [ 'xmlns' ] = xmlns tag ( :html , options , true )", "del_tokens": "output = '<html' if options [ :version ] output << \" version=\\\"#{options[:version]}\\\"\" end if options [ :xmlns ] if options [ :xmlns ] . kind_of? ( String ) output << \" xmlns=\\\"#{options[:xmlns]}\\\"\" elsif options [ :xmlns ] . kind_of? ( Array ) output = options [ :xmlns ] . inject ( output ) do | html , xmlns | if xmlns . kind_of? ( Hash ) html << \" xmlns:#{xmlns[:prefix]}=\\\"#{xmlns[:url]}\\\"\" else html << \" xmlns=\\\"#{xmlns}\\\"\" end output << '>'", "commit_type": "use"}
{"commit_tokens": ["Removed", "the", "SSL", "option", "from", "the", "mock", "API", "client", "."], "add_tokens": "def call ( username , api_key , endpoint , params = { } , user_agent = 'DataSiftPHP/0.0' )", "del_tokens": "def call ( username , api_key , endpoint , params = { } , user_agent = 'DataSiftPHP/0.0' , use_ssl = true )", "commit_type": "remove"}
{"commit_tokens": ["Change", "to", "update", "path", "helpers"], "add_tokens": "def gem_root File . expand_path ( File . join ( File . dirname ( __FILE__ ) , \"..\" ) ) end def dir_path ( * args ) path = File . join ( gem_root , * args ) FileUtils . mkdir_p ( path ) unless :: File . exist? ( path ) File . realpath ( path ) end File . join ( dir_path ( 'spec/fixtures' ) , filename . to_s ) File . join ( gem_root , 'tmp' , filename . to_s )", "del_tokens": "File . join ( File . dirname ( __FILE__ ) , 'fixtures' , filename . to_s ) root_path = :: File . expand_path ( File . dirname ( __FILE__ ) , '..' ) File . join ( root_path , 'tmp' , filename . to_s )", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "typo", "for", "(", "record", ".", "id", "-", ">", "target", ".", "id", ")", "to", "prevent", "the", "error", "when", "destroying", "a", "record", "with", "has_one", "association", "."], "add_tokens": "target . class . record_cache . invalidate ( target . id ) if target . class . record_cache? unless target . new_record?", "del_tokens": "target . class . record_cache . invalidate ( record . id ) if target . class . record_cache? unless target . new_record?", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "relative", "path", "issue"], "add_tokens": "csproj = fix_path_relative project . project_path # get path relative to project root def self . fix_path_relative ( path ) root = File . dirname Souyuz . config [ :project_path ] # failsafe to __FILE__ and __DIR__ path = \"#{root}/#{path}\" path end", "del_tokens": "csproj = project . project_path", "commit_type": "fix"}
{"commit_tokens": ["remove", "authorization", "if", "we", "redirect", "to", "a", "different", "host"], "add_tokens": "location = :: URI . parse response [ 'location' ] if location . host != env [ :url ] . host env [ :request_headers ] . delete ( 'Authorization' ) end env [ :url ] = location", "del_tokens": "env [ :url ] = :: URI . parse response [ 'location' ]", "commit_type": "remove"}
{"commit_tokens": ["updated", "the", "way", "dsl", "objects", "store", "their", "state"], "add_tokens": "@@defaults = nil class << self @@defaults = hash . merge ( { def style ( value ) ; self . style_value = value ; end protected def method_missing ( meth , * args , & block ) # handle data access reads and writes # => only methods ending in '_value' or '_set' # => '=' operator: write to data value # => '<<' operator: write to data set if meth . to_s =~ / (.+)(_value|_set)(=|<{2}|) / data_access ( $1 . to_sym , $3 , args . first ) else super # continue method_missing handling end end self . send ( \"#{d}_value=\" , v ) end end def data_access ( key , operator , data ) @data ||= { } if operator == '=' # write data value @data [ key ] = data elsif operator == '<<' @data [ key ] ||= [ ] @data [ key ] << data else # read @data [ key ]", "del_tokens": "class << self protected @defaults = hash . merge ( { @style = nil def style ( style ) ; @style = style ; end instance_variable_set ( \"@d\" , v )", "commit_type": "update"}
{"commit_tokens": ["Fix", "bug", "in", "case", "whne", "workspace", "is", "not", "created"], "add_tokens": "workspace = Rails . root . join ( \"tmp/workspace\" ) workspace . rmtree if workspace . exist?", "del_tokens": "Rails . root . join ( \"tmp/workspace\" ) . rmtree", "commit_type": "fix"}
{"commit_tokens": ["Change", "to", "bump", "version", "up"], "add_tokens": "VERSION = \"0.4.2\"", "del_tokens": "VERSION = \"0.4.1\"", "commit_type": "change"}
{"commit_tokens": ["added", "some", "role", "and", "return", "url", "message", "handling"], "add_tokens": "\"launch_presentation_return_url\" => \"http://example.com/lti_return\" , \"ext_lti_message_type\" => \"extension-lti-launch\" , \"roles\" => \"learner,instructor,observer\"", "del_tokens": "\"ext_lti_message_type\" => \"extension-lti-launch\"", "commit_type": "add"}
{"commit_tokens": ["add", "--", "contains", "-", "header", "option", "to", "allow", "the", "header", "to", "be", "skipped"], "add_tokens": "require 'pp' if last && entry_as_num != 0 && last != 0 @csv_data = ( RUBY_VERSION =~ / ^1 \\. 9 / ? CSV : FasterCSV ) . parse ( data . strip , :col_sep => options [ :csv_separator ] || ',' ) csv_data . shift if options [ :contains_header ] csv_data opts . on ( \"\" , \"--contains-header\" , \"The first row of the CSV is a header and should be skipped\" ) do | contains_header | options [ :contains_header ] = contains_header end", "del_tokens": "if last && entry_as_num != 0 && last != 0 require 'pp' self . csv_data = ( RUBY_VERSION =~ / ^1 \\. 9 / ? CSV : FasterCSV ) . parse ( data . strip , :col_sep => options [ :csv_separator ] || ',' )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "date_submitted", "/", "datesubmitted", "property"], "add_tokens": "attribute :datesubmitted , DateTime", "del_tokens": "attribute :date_submitted , DateTime", "commit_type": "fix"}
{"commit_tokens": ["improving", "inline", "documentation", "for", "Query"], "add_tokens": "# Returns conditions intended to be used inside a database query. Normally you will not call this # method directly, but instead go through ActiveRecordAdditions#accessible_by. # # If there is only one \"can\" definition, a hash of conditions will be returned matching the one defined. # # can :manage, User, :id => 1 # query(:manage, User).conditions # => { :id => 1 } # # If there are multiple \"can\" definitions, a SQL string will be returned to handle complex cases. # Returns the associations used in conditions for the :joins option of a search. # Takes two hashes and does a deep merge. # Removes empty hashes and moves everything into arrays.", "del_tokens": "# Returns a string of SQL conditions which match the ability query. # Normally you will not call this method directly, but instead go through ActiveRecordAdditions#accessible_by. # # If there is just one :can ability, it conditions returned untouched. # Returns the associations used in conditions for the :joins option of a search", "commit_type": "improve"}
{"commit_tokens": ["move", "clean", "tasks", "to", "module", "that", "is", "loaded", "after", "configuration"], "add_tokens": "require 'omnibus/clean_tasks'", "del_tokens": "require 'rake/clean' CLEAN . include ( '/tmp/omnibus/**/*' ) CLOBBER . include ( '/opt/opscode/**/*' )", "commit_type": "move"}
{"commit_tokens": ["fixed", "readme", "and", "bug", "that", "prevented", "Host", "objects", "from", "being", "created"], "add_tokens": "report [ :hosts ] = string . scan ( Host_Entry_Regex ) . map { | entry | Host . new ( * entry ) }", "del_tokens": "report [ :hosts ] = string . scan ( Host_Entry_Regex ) hosts = report [ :hosts ] . map { | entry | Host . new ( * entry ) }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "translation", "key", "search", "options", "and", "added", "month", "selector", "helper", "method"], "add_tokens": "conditions [ 0 ] << \"verified_at is not null\"", "del_tokens": "conditions [ 0 ] << [ \"verified_at is not null\" ]", "commit_type": "fix"}
{"commit_tokens": ["Made", "Resync", "::", "XML", ".", "element", "()", "accept", "IO", "and", "IO", "-", "like", "things"], "add_tokens": "# @param xml [String, IO, REXML::Document, REXML::Element] A string or IO-like # object containing an XML document (with or without XML declaration), or an # XML document, or an XML element. # @return [REXML::Element] the root element of the document, or the element fail ArgumentError , \"Unexpected argument type; expected XML document, String, or IO source, was #{xml.class}\" unless can_parse ( xml ) REXML :: Document . new ( xml ) . root # ------------------------------------------------------------ # Private class methods # Whether the argument can be parsed as an +REXML::Document+ # # @return [Boolean] true if +REXML::Document.new()+ should be able to parse # the argument, false otherwise def self . can_parse ( arg ) arg . is_a? ( String ) || ( arg . respond_to? ( :read ) && arg . respond_to? ( :readline ) && arg . respond_to? ( :nil? ) && arg . respond_to? ( :eof? ) ) private_class_method :can_parse", "del_tokens": "# @param xml [String, REXML::Document, REXML::Element] A string containing # an XML document (with or without XML declaration), or an XML document, # or an XML element. # @return [REXML::Element] The root element of the document, or the element when String REXML :: Document . new ( xml ) . root if io_like? ( xml ) REXML :: Document . new ( xml ) . root else fail ArgumentError , \"Unexpected argument type; expected XML document, was #{xml.class}\" end def self . io_like? ( arg ) arg . respond_to? :read and arg . respond_to? :readline and arg . respond_to? :nil? and arg . respond_to? :eof? private_class_method :io_like?", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "if", "there", "wasn", "t", "a", "search", "the", "clear", "filter", "button", "was", "causing", "a", "nil", "error"], "add_tokens": "<<-HTML . strip_heredoc if options [ :search ]", "del_tokens": "<<-HTML . strip_heredoc", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "tzdata", "version", "2006o", "(", "http", ":", "//", "article", ".", "gmane", ".", "org", "/", "gmane", ".", "comp", ".", "time", ".", "tz", "/", "1329", ")", "."], "add_tokens": "tz . transition 1967 , 4 , :o2 , 19516661 , 8 tz . transition 1987 , 4 , :o5 , 545194800 tz . transition 1988 , 10 , :o6 , 591768000 tz . transition 1990 , 3 , :o5 , 637729200 tz . transition 1990 , 9 , :o6 , 653457600 tz . transition 1997 , 3 , :o5 , 859690800", "del_tokens": "tz . transition 1967 , 4 , :o2 , 19516653 , 8 tz . transition 1974 , 10 , :o4 , 150260400 tz . transition 1975 , 4 , :o3 , 165981600 tz . transition 1975 , 10 , :o4 , 181710000 tz . transition 1976 , 4 , :o3 , 197431200 tz . transition 1976 , 10 , :o4 , 213159600 tz . transition 1977 , 4 , :o3 , 228880800 tz . transition 1987 , 3 , :o5 , 542775600 tz . transition 1988 , 10 , :o6 , 592372800 tz . transition 1990 , 3 , :o5 , 637124400 tz . transition 1990 , 10 , :o6 , 655876800 tz . transition 1997 , 3 , :o5 , 857876400", "commit_type": "update"}
{"commit_tokens": ["Add", "gem", "signing", "and", "bumped", "version"], "add_tokens": "VERSION = \"1.2.1\"", "del_tokens": "VERSION = \"1.2.0\"", "commit_type": "add"}
{"commit_tokens": ["use", "hashes", "instead", "of", "arrays", "for", "pluralization", "data"], "add_tokens": "return entry unless entry . is_a? ( Hash ) and count # raise InvalidPluralizationData.new(entry, count) unless entry.is_a?(Hash) key = :zero if count == 0 && entry . has_key? ( :zero ) key ||= count == 1 ? :one : :many raise InvalidPluralizationData . new ( entry , count ) unless entry . has_key? ( key ) entry [ key ]", "del_tokens": "return entry unless entry . is_a? ( Array ) and count raise InvalidPluralizationData . new ( entry , count ) unless entry . size == 2 entry [ count == 1 ? 0 : 1 ]", "commit_type": "use"}
{"commit_tokens": ["Move", "window", "functions", "into", "Window"], "add_tokens": "extend FFI :: Library enum :GtkWindowType , [ :GTK_WINDOW_TOPLEVEL , :GTK_WINDOW_POPUP ] attach_function :gtk_window_new , [ :GtkWindowType ] , :pointer attach_function :gtk_widget_show , [ :pointer ] , :pointer @gobj = gtk_window_new ( type ) gtk_widget_show ( @gobj )", "del_tokens": "enum :GtkWindowType , [ :GTK_WINDOW_TOPLEVEL , :GTK_WINDOW_POPUP ] attach_function :gtk_window_new , [ :GtkWindowType ] , :pointer attach_function :gtk_widget_show , [ :pointer ] , :pointer @gobj = Gtk . gtk_window_new ( type ) Gtk . gtk_widget_show ( @gobj )", "commit_type": "move"}
{"commit_tokens": ["Fix", "bug", "where", "component", "-", "css", "was", "not", "applied", "to", "all", "components", "due", "to", "modified", "application", "order"], "add_tokens": "nkey = key [ 0 , 2 ] if ( style = css [ key ] || css [ nkey ] ) if ( cstyle = ccss [ key ] || ccss [ nkey ] )", "del_tokens": "if ( style = css [ key ] ) if ( cstyle = ccss [ key ] )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "case", "of", "Google", "attributes"], "add_tokens": "value = item [ 'inputValue' ] numericvalue = item [ 'numericValue' ]", "del_tokens": "value = item [ 'inputvalue' ] numericvalue = item [ 'numericvalue' ]", "commit_type": "fix"}
{"commit_tokens": ["Adding", "some", "unit", "tests", "for", "the", "main", "class", "."], "add_tokens": "cattr_accessor :tracker_id private # This is strictly for testability. I'd be happy to have an alternative. def class_reset # :nodoc: @@tracker_id = nil @@domain_name = nil @@legacy_mode = false @@analytics_url = 'http://www.google-analytics.com/urchin.js' @@analytics_ssl_url = 'https://ssl.google-analytics.com/urchin.js' @@environments = [ 'production' ] @@formats = [ :html ] @@defer_load = true @@local_javascript = false end", "del_tokens": "cattr_accessor :tracker_id #", "commit_type": "add"}
{"commit_tokens": ["Add", "benchmarking", "on", "conversion", "and", "downloads"], "add_tokens": "include ActiveSupport :: Benchmarkable delegate :logger , to : :Rails out = nil benchmark ( \"Riiif executed #{command}\" ) do stdin , stdout , stderr , wait_thr = popen3 ( command ) stdin . close stdout . binmode out = stdout . read stdout . close err = stderr . read stderr . close raise \"Unable to execute command \\\"#{command}\\\"\\n#{err}\" unless wait_thr . value . success? end", "del_tokens": "Rails . logger . debug \"RIIIF executed: #{command}\" stdin , stdout , stderr , wait_thr = popen3 ( command ) stdin . close stdout . binmode out = stdout . read stdout . close err = stderr . read stderr . close raise \"Unable to execute command \\\"#{command}\\\"\\n#{err}\" unless wait_thr . value . success?", "commit_type": "add"}
{"commit_tokens": ["Removed", "incorrect", "name", "from", "logs", "."], "add_tokens": "logger . error \"No matching interaction found for #{interaction_mismatch.actual_request.method_and_path}\"", "del_tokens": "logger . error \"No matching interaction found on #{name} for #{interaction_mismatch.actual_request.method_and_path}\"", "commit_type": "remove"}
{"commit_tokens": ["add", "VERSION", "to", ".", "yardopts"], "add_tokens": "# Example format: 0.0.1 # # @return [String] the contents of the version file in #.#.# format", "del_tokens": "# VERSION example format: 0.0.1 # @return [String] version the contents of the version file in #.#.# format", "commit_type": "add"}
{"commit_tokens": ["Remove", "a", "time", "-", "based", "test", "."], "add_tokens": "Subprocess . check_call ( [ 'bash' , '-c' , 'read var' ] , stdin : Subprocess :: PIPE ) do | p | Process . waitpid ( p . pid , Process :: WUNTRACED ) . must_equal ( p . pid ) p . stdin . write ( \"foo\\n\" )", "del_tokens": "start = Time . now Subprocess . check_call ( [ 'sleep' , '1' ] ) do | p | sleep 1 ( Time . now - start ) . must_be_close_to ( 2.0 , 0.2 )", "commit_type": "remove"}
{"commit_tokens": ["Added", "files", "to", "main", "gem", "file"], "add_tokens": "require \"fried/typings/boolean\" require \"fried/typings/is_strictly\" require \"fried/typings/meta_type\" require \"fried/typings/strictly_one_of\" require \"fried/typings/tuple_of\" require \"fried/typings/type\"", "del_tokens": "require \"fried/typings/type\" require \"fried/typings/meta_type\" require \"fried/typings/boolean\"", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "forgot", "assignment", "doesnt", "copy", "but", "becomes", "object"], "add_tokens": "@batch_config = BATCH_CONFIG . fetch ( cluster , { } ) . fetch ( batch , { } ) . clone", "del_tokens": "@batch_config = batch && cluster ? BATCH_CONFIG [ cluster ] [ batch ] : { }", "commit_type": "fix"}
{"commit_tokens": ["add", "HotTub", ".", "new", "Session", "should", "be", "Sessions", "and", "clean", "up"], "add_tokens": "require \"hot_tub/sessions\" def self . new ( opts = { } , & client_block ) if opts [ :sessions ] == false Pool . new ( opts , & client_block ) else opts [ :with_pool ] = true unless opts [ :pool ] == false Session . new ( opts , & client_block ) end end", "del_tokens": "require \"hot_tub/session\"", "commit_type": "add"}
{"commit_tokens": ["changed", "PONDER_ROOT", "to", "Ponder", ".", "root"], "add_tokens": "@traffic_logger = TwoFlogger . new ( Ponder . root . join ( 'logs' ) . expand_path , 'traffic.log' ) @error_logger = TwoFlogger . new ( Ponder . root . join ( 'logs' ) . expand_path , 'error.log' )", "del_tokens": "@traffic_logger = TwoFlogger . new ( PONDER_ROOT . join ( 'logs' ) . expand_path , 'traffic.log' ) @error_logger = TwoFlogger . new ( PONDER_ROOT . join ( 'logs' ) . expand_path , 'error.log' )", "commit_type": "change"}
{"commit_tokens": ["Allow", "Generator#includes", "to", "accept", "a", "separator", "string", "."], "add_tokens": "def includes ( name , separator = $/ ) return output_buffer . join ( separator )", "del_tokens": "def includes ( name ) return output_buffer . join ( $/ )", "commit_type": "allow"}
{"commit_tokens": ["fixing", "one", "more", "old", "reference"], "add_tokens": "files = %w( .rspec spec test foodcritic )", "del_tokens": "files = %w( .rspec spec test )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "CLI", "to", "receive", "extra", "args"], "add_tokens": "arguments = argv . dup task_name = arguments . shift klazz = Task . from_name ( task_name ) options = klazz . parse_options arguments klazz . new options", "del_tokens": "task_name = argv . first Task . from_name ( task_name ) . new", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "line", "items", "."], "add_tokens": "BASE_PATH = \"/line_items\" . freeze # The set of attributes defined by the API documentation ATTRIBUTES_NAMES = [ :line_item_id , :rg_order_id , :price , :quantity , :product_id , :variant_id , :sku , :name ] . freeze ATTRIBUTES_NAMES . each do | attrib | attr_accessor attrib end def initialize ( attribs = { } ) super # relations def order = ( order ) @rg_order_id = order . order_id @order = order end # API Stuff here # Find a product with given id # @param [Fixnum] product_id the prodct id to be found # @return [LineItem] if found any def self . find ( line_item_id ) begin result = Api . get ( \"#{BASE_PATH}/#{line_item_id}\" ) new ( result . parsed_response [ \"rg_line_item\" ] ) rescue NotFound nil end end # Create or update a line item with given id # @return [LineItem] if successfully created or updated # @raise [Httparty::Error] for all sorts of HTTP statuses. def save! result = Api . post ( \"#{BASE_PATH}/#{line_item_id}\" , body : attributes . to_json ) new ( result . parsed_response [ \"rg_line_item\" ] ) end # Delete this line item at retention grid # @return [Boolean] successfully deleted? def destroy Api . delete ( \"#{BASE_PATH}/#{line_item_id}\" ) true end", "del_tokens": "def initialize raise NotImplemented . new", "commit_type": "add"}
{"commit_tokens": ["Add", "GitHub", "Actions", "CI", "setup", "to", "replace", "Travis"], "add_tokens": "if ENV [ \"COVERAGE\" ] == \"true\"", "del_tokens": "if ENV [ \"COVERAGE\" ] || ENV [ \"TRAVIS\" ]", "commit_type": "add"}
{"commit_tokens": ["Adds", "to_f", "to", "prices", "to", "get", "correct", "range", "."], "add_tokens": "prices = variants . collect ( & :price ) . collect ( & :to_f )", "del_tokens": "prices = variants . collect ( & :price )", "commit_type": "add"}
{"commit_tokens": ["make", "em_client", "close", "more", "similar", "to", "the", "others"], "add_tokens": "if running? @_running = false # wake_event_loop! unless closed? @em_connection . detach if @em_connection @em_connection = nil logger . debug { \"closing handle\" } close_handle selectable_io . close unless selectable_io . closed? end else logger . debug { \"we are not running, so returning on_close deferred\" } end if running? and not closed? begin @em_connection = EM . watch ( selectable_io , ZKConnection , self ) { | cnx | cnx . notify_readable = true } rescue Exception => e $stderr . puts \"caught exception from EM.watch(): #{e.inspect}\" end on_attached . succeed", "del_tokens": "unless running? logger . debug { \"we are not running, so returning on_close deferred\" } return on_close end @_running = false wake_event_loop! unless closed? @em_connection . detach if @em_connection selectable_io . close unless selectable_io . closed? logger . debug { \"closing handle\" } close_handle # def really_close # unless closed? # logger.debug { \"#{self.class.name}: calling close_handle in native driver\" } # close_handle # selectable_io.close unless selectable_io.closed? # logger.debug { \"#{self.class.name}: calling on_close.succeed\" } # on_close.succeed # end # end begin @em_connection = EM . watch ( selectable_io , ZKConnection , self ) { | cnx | cnx . notify_readable = true } rescue Exception => e $stderr . puts \"caught exception from EM.watch(): #{e.inspect}\" on_attached . succeed # @on_detach = EM::DefaultDeferrable.new # @on_detach.callback { logger.debug { \"#{self.class.name}: on_detach callback fired\" } } # called back when we've successfully detached from the EM reactor # def on_detach(&blk) # @on_detach.callback(&blk) if blk # @on_detach # end", "commit_type": "make"}
{"commit_tokens": ["Change", "to", "extract", "answer", "rendering", "for", "easy", "customization", "."], "add_tokens": "answer = render_answer answer end # Find value for the choice selected # # @return [nil, Object] # # @api private def render_answer @choices [ @active - 1 ] . value", "del_tokens": "result = @choices [ @active - 1 ] . value result", "commit_type": "change"}
{"commit_tokens": ["Fix", "requirement", "of", "missing", "file"], "add_tokens": "", "del_tokens": "require 'lxc/errors'", "commit_type": "fix"}
{"commit_tokens": ["remove", "duplication", "with", "autoinclude", "method"], "add_tokens": "require \"active_support/core_ext/string\" def autoinclude ( klass ) autoload klass , \"aws_ec2/template/helper/#{klass.to_s.underscore}\" include const_get ( klass ) end extend self autoinclude :AmiHelper autoinclude :CoreHelper autoinclude :PartialHelper", "del_tokens": "# TODO: add method to remove duplication autoload :AmiHelper , \"aws_ec2/template/helper/ami_helper\" autoload :CoreHelper , \"aws_ec2/template/helper/core_helper\" autoload :PartialHelper , \"aws_ec2/template/helper/partial_helper\" include AmiHelper include CoreHelper include PartialHelper", "commit_type": "remove"}
{"commit_tokens": ["added", "test", "of", "session", "ID", "handling"], "add_tokens": "sessid = response . cookies [ SESSION_COOKIE_NAME ] if session_id != sessid @session_id = sessid Orientdb4r :: logger . debug \"new session id: #{session_id}\" end", "del_tokens": "@session_id = response . cookies [ SESSION_COOKIE_NAME ]", "commit_type": "add"}
{"commit_tokens": ["allow", "method", "action", "to", "refer", "to", "a", "previously", "defined", "method", "action"], "add_tokens": "if options [ :action ] . is_a? ( String ) options [ :action ] = method_action ( * options [ :action ] . split ( / [.#] / , 2 ) ) [ 1 ] end raise Bond :: InvalidMissionActionError unless options [ :action ] . respond_to? ( :call ) def method_action ( obj , meth ) ( @method_actions [ meth ] || { } ) . find { | k , v | get_class ( k ) && obj . is_a? ( get_class ( k ) ) } ( match = self . class . method_action ( @evaled_object , @meth ) ) @action = match [ 1 ]", "del_tokens": "def has_method_action? ( obj , meth ) @found = ( @method_actions [ meth ] || { } ) . find { | k , v | get_class ( k ) && obj . is_a? ( get_class ( k ) ) } def get_method_action ( obj , meth ) @found [ 1 ] end options . delete ( :object_method ) ( match = self . class . has_method_action? ( @evaled_object , @meth ) ) @action = self . class . get_method_action ( @evaled_object , @matched [ 2 ] )", "commit_type": "allow"}
{"commit_tokens": ["Added", "Rye", "::", "Box", ".", "upload", "and", "Rye", "::", "Box", ".", "download"], "add_tokens": "def upload ( * files ) ; net_scp_transfer! ( :upload , * files ) ; end def download ( * files ) ; net_scp_transfer! ( :download , * files ) ; end", "del_tokens": "# def copy_to(*boxes) # p boxes # # @scp = Net::SCP.start(@host, @opts[:user], @opts || {}) # #@ssh.is_a?(Net::SSH::Connection::Session) && !@ssh.closed? # p @scp # end #def copy_to(*args) # args = [args].flatten.compact || [] # other = args.pop # p other #end def exists? cmd ( \"uptime\" ) ; end", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "Linter", "::", "UnnecessaryStringOutput", "when", "tag", "is", "empty"], "add_tokens": "return false unless string return false unless inline_content = inline_node_content ( tag_node )", "del_tokens": "inline_content = inline_node_content ( tag_node )", "commit_type": "fix"}
{"commit_tokens": ["Use", "HSB", "class", "in", "color", "object"], "add_tokens": "@hsb ||= HSB . new * rgb2hsb ( rgb . to_a )", "del_tokens": "@hsb ||= rgb2hsb ( rgb . to_a )", "commit_type": "use"}
{"commit_tokens": ["updated", "the", "examplar", "config", "file", "and", "added", "a", "validation", "that", "ensures", "that", "BLAST", "root", "db", "path", "exists"], "add_tokens": "VERSION = '1.0.1'", "del_tokens": "VERSION = '1.0.0'", "commit_type": "update"}
{"commit_tokens": ["Change", "to", "allow", "for", "new", "initial", "event", "definition", "."], "add_tokens": "# A generic DSL for describing the state machine # Initialize top level DSL # # @api public state , name , @defer = parse ( value ) private # Parse initial options # # @params [String, Hash] value # # @return [Array[Symbol,String]] # # @api private def parse ( value ) if value . is_a? ( String ) || value . is_a? ( Symbol ) [ value , FiniteMachine :: DEFAULT_EVENT_NAME , false ] else [ value [ :state ] , value . fetch ( :event , FiniteMachine :: DEFAULT_EVENT_NAME ) , ! ! value [ :defer ] ] end end", "del_tokens": "if value . is_a? ( String ) || value . is_a? ( Symbol ) state , name = value , FiniteMachine :: DEFAULT_EVENT_NAME @defer = false else state = value [ :state ] name = value . has_key? ( :event ) ? value [ :event ] : FiniteMachine :: DEFAULT_EVENT_NAME @defer = value [ :defer ] || true end", "commit_type": "change"}
{"commit_tokens": ["Fix", "spelling", "and", "use", "logical", "operators"], "add_tokens": "# @return [\"ltr\"] if it's a left-to-right string if has_ltr_mark? && has_rtl_mark? elsif ! has_rtl_characters?", "del_tokens": "# @return [\"lft\"] if it's a left-to-right string if has_ltr_mark? and has_rtl_mark? elsif not has_rtl_characters?", "commit_type": "fix"}
{"commit_tokens": ["Change", "hard", "-", "linked", "test", "file"], "add_tokens": "test_file = ActionController :: TestUploadedFile . new ( File . join ( File . dirname ( __FILE__ ) , 'test-file.txt' ) )", "del_tokens": "test_file = ActionController :: TestUploadedFile . new ( '/home/andrew/tmp/tmp.txt' )", "commit_type": "change"}
{"commit_tokens": ["add", "support", "to", "read", "logger", "file", "from", "env"], "add_tokens": "output = ENV [ 'RJR_LOG' ] || STDOUT @@logger = :: Logger . new ( output )", "del_tokens": "@@logger = :: Logger . new ( STDOUT )", "commit_type": "add"}
{"commit_tokens": ["Use", "struct", "instead", "of", "hash", "for", "import", "API"], "add_tokens": "require 'ostruct' raw_values = { } parsed_values = { } raw_values [ name ] = row [ header ] parsed_values [ name ] = instance_exec ( row [ header ] , & parser ) parsed_values [ :values ] = OpenStruct . new ( raw_values ) return OpenStruct . new ( parsed_values )", "del_tokens": "parsed_row = { } parsed_row [ name ] = instance_exec ( row [ header ] , & parser ) parsed_row", "commit_type": "use"}
{"commit_tokens": ["Add", "more", "helper", "-", "method", "for", "Flame", "::", "Dispatcher"], "add_tokens": "path = route . assign_arguments ( args ) path . empty? ? '/' : path end def redirect ( * params ) throw :halt , response . redirect ( params [ 0 ] . is_a? ( String ) ? params [ 0 ] : path_to ( * params ) ) end def session request . session end def cookies @cookies ||= Cookies . new ( request . cookies , response ) ## Helper class for cookies class Cookies def initialize ( request_cookies , response ) @request_cookies = request_cookies @response = response end def [] ( key ) @request_cookies [ key ] || @request_cookies [ key . to_s ] end def []= ( key , new_value ) return @response . delete_cookie ( key ) if new_value . nil? @response . set_cookie ( key , new_value ) end end", "del_tokens": "route . assign_arguments ( args )", "commit_type": "add"}
{"commit_tokens": ["remove", "unnecessary", "local", "var", "."], "add_tokens": "EventCalendar . new ( $conf [ 'calendar_files' ] )", "del_tokens": "cal = EventCalendar . new ( $conf [ 'calendar_files' ] )", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "Custom", "Jar", "jobs", "."], "add_tokens": "VERSION = \"1.4\"", "del_tokens": "VERSION = \"1.3.1\"", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "pass", "api", "client", "to", "be", "used", "for", "sync"], "add_tokens": "# @param api [BookingSync::API::Client] - API client to be used for fetching # remote objects include : nil , api : api ) include : include , api : api", "del_tokens": "include : nil ) include : include", "commit_type": "add"}
{"commit_tokens": ["Add", "hard_example", ".", "toml", "and", "a", "test", "for", "it", "from", "the", "specs", "examples", "."], "add_tokens": "TOML :: Keyvalue . new ( key . value , v . value )", "del_tokens": "TOML :: Keyvalue . new ( word . value , v . value )", "commit_type": "add"}
{"commit_tokens": ["Making", "the", "entities", "explicit", "in", "Entities", "not", "Tracker"], "add_tokens": "# +struct_event+:: the custom structured event Contract StructEvent , OptionSubject , OptionContext => nil # TODO: fix return def track_struct_event ( struct_event , # +unstruct_event+:: the custom unstructured event Contract UnstructEvent , OptionSubject , OptionContext => nil # TODO: fix return def track_unstruct_event ( usntruct_event , # Track a sales order - referred to as an # ecommerce transaction in other Snowplow # trackers. # +sales_order+:: the sales order to track, # including order line items Contract SalesOrder , OptionSubject , OptionContext => nil # TODO: fix return def track_sales_order ( sales_order , subject = @pinned_subject , context = @pinned_context )", "del_tokens": "# +category+:: the name you supply for the group of # objects you want to track # +action+:: a string that is uniquely paired with each # category, and commonly used to define the # type of user interaction for the object # +label+:: an optional string to provide additional # dimensions to the event data # +property+:: an optional string describing the object # or the action performed on it. This might # be the quantity of an item added to basket # +value+:: an optional value that you can use to provide # numerical data about the user event Contract String , String , OptionString , OptionString , OptionNum , OptionSubject , OptionContext => nil # TODO: fix return def track_struct_event ( category , action , label = nil , property = nil , value = nil , # +name+:: the name of the event # +properties+:: the properties of the event Contract String , Hash , OptionSubject , OptionContext => nil # TODO: fix return def track_unstruct_event ( name , properties , # Track an ecommerce transaction. # +transaction+:: the ecommerce transaction to track, # including transaction items Contract EcommerceTransaction , OptionSubject , OptionContext => nil # TODO: fix return def track_ecommerce_transaction ( transaction , subject = @pinned_subject , context = @pinned_context )", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "root", "taxon", "for", "taxonomies"], "add_tokens": "@taxon . move_to_child_with_index ( Taxon . find ( parent_from_params ) , params [ :position ] . to_i ) @collection = @taxonomy . root . children params [ :node ] [ :parent ] == '#' ? @taxonomy . root . id : params [ :node ] [ :parent ]", "del_tokens": "if parent_from_params @taxon . move_to_child_with_index ( Taxon . find ( parent_from_params ) , params [ :position ] . to_i ) else @taxon . move_to_root # TODO : Create a root taxon to allow first level taxons to be ordered end @collection = Taxon . includes ( :children ) . by_taxonomy ( @taxonomy ) . where ( depth : 0 ) params [ :node ] [ :parent ] == '#' ? nil : params [ :node ] [ :parent ]", "commit_type": "use"}
{"commit_tokens": ["Remove", "usage", "of", "deprecated", "OpenSSL", "::", "Digest", "::", "Digest"], "add_tokens": "sha256 = OpenSSL :: Digest . new ( \"sha256\" )", "del_tokens": "sha256 = OpenSSL :: Digest :: Digest . new ( \"sha256\" )", "commit_type": "remove"}
{"commit_tokens": ["Make", "the", "_content", "strings", "real", "string", "when", "there", "is", "no", "attributes", ".", "This", "allow", "Flickr", "objects", "to", "be", "marshalled"], "add_tokens": "elsif obj . keys == [ '_content' ] obj [ '_content' ] . to_s def to_s ; @_content || super end", "del_tokens": "elsif obj [ '_content' ] content = obj [ '_content' ] . to_s content . extend SimpleOStruct content . instance_eval { obj . each { | kv , vv | __attr_define kv , vv } } content", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "network", "errors"], "add_tokens": "begin results = get_api_results url rescue Timeout :: Error , Errno :: EINVAL , Errno :: ECONNRESET , EOFError , Net :: HTTPBadResponse , Net :: HTTPHeaderSyntaxError , Net :: ProtocolError => e delegate . inspector_could_not_create_report ( e , query , inspector ) return end # TODO: progress callback", "del_tokens": "results = get_api_results url # TODO: error handling # progress callback puts query", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "specify", "directory", "names", "which", "is", "necessary", "when", "there", "is", "a", "build", "order", "dependency", "."], "add_tokens": "# Allow either a string (usually \"*\") or an array of strings with directories redir = @pattern . kind_of? ( String ) ? Dir [ @pattern ] : Dir [ * @pattern ] redir . select { | path | File . directory? path } . each do | dir |", "del_tokens": "Dir [ @pattern ] . select { | path | File . directory? path } . each do | dir |", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "modified", "kafka", "run", "class", "script", "to", "allow", "us", "to", "shutdown", "java", "processes", "correctly"], "add_tokens": ":start_command => \"#{@start_cmd} #{config_path} &>> #{log_path} & echo $! > #{pid_path}\" , \"#{POSEIDON_PATH}/spec/bin/kafka-run-class.sh kafka.Kafka\" , @jr = JavaRunner . new ( \"zookeeper\" , \"#{POSEIDON_PATH}/spec/bin/kafka-run-class.sh org.apache.zookeeper.server.quorum.QuorumPeerMain\" ,", "del_tokens": ":start_command => \"#{self.class.kafka_path}/#{@start_cmd} #{config_path} &>> #{log_path} & echo $! > #{pid_path}\" , 'bin/kafka-run-class.sh kafka.Kafka' , @jr = JavaRunner . new ( \"zookeeper\" , 'bin/zookeeper-server-start.sh' ,", "commit_type": "use"}
{"commit_tokens": ["Added", "logger", "output", "to", "Downloader", "class"], "add_tokens": "require_relative 'Validator' require_relative 'MyLogger' include Logging Logger . info ( \"Downloading file => #{filename}\" )", "del_tokens": "require_relative 'Validator.rb' puts \"Downloading file => #{filename}\"", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "inverse", "tranformations", "."], "add_tokens": "def test_gk_to_wgs84_forward def test_gk_to_wgs84_inverse transform = Proj :: Transformation . new ( @crs_gk , @crs_wgs84 ) from = Proj :: Coordinate . new ( lam : 48.9906726079 , phi : 8.4302123334 ) to = transform . inverse ( from ) assert_in_delta ( 5428306.389495558 , to . x , PRECISION ) assert_in_delta ( 3458375.3367194114 , to . y , PRECISION ) assert_in_delta ( 0 , to . z , PRECISION ) assert_in_delta ( 0 , to . t , PRECISION ) end def test_wgs84_to_gk_forward def test_wgs84_to_gk_forward_inverse transform = Proj :: Transformation . new ( @crs_wgs84 , @crs_gk ) from = Proj :: Coordinate . new ( x : 5428192.0 , y : 3458305.0 , z : - 5.1790915237 ) to = transform . inverse ( from ) assert_in_delta ( 48.98963932450735 , to . x , PRECISION ) assert_in_delta ( 8.429263044355544 , to . y , PRECISION ) assert_in_delta ( - 5.1790915237 , to . z , PRECISION ) assert_in_delta ( 0 , to . t , PRECISION ) end end", "del_tokens": "def test_gk_to_wgs84 def test_wgs84_to_gk end", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "sequences", "work", "with", "tsorting", "too"], "add_tokens": "[ email_attr , id_attr , name_attr ] let ( :id_attr ) do attribute ( :Sequence , :id ) { | n | n } end expect ( registry . tsort ) . to eql ( [ name_attr , email_attr , id_attr ] )", "del_tokens": "[ email_attr , name_attr ] expect ( registry . tsort ) . to eql ( [ name_attr , email_attr ] )", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "railtie", "for", "zero", "-", "config", "inclusion", "in", "a", "rails", "app"], "add_tokens": "require 'slimmer/railtie' if defined? ( Rails ) require 'nokogiri' def initialize ( app , * args , & block ) options = args . first || { }", "del_tokens": "require 'nokogiri' require 'open-uri' def initialize ( app , options = { } )", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "README", "and", "added", "a", "few", "comments"], "add_tokens": "require 'memoize' include Memoize # Registers the given event handler so that it will be # invoked when the event is raised. # Pass the specific arguments / block to all of the # event handlers. Return true if there was at least # 1 event handler; return false otherwise.", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Add", "helper", "method", "for", "response", "time", "in", "read_response", "block"], "add_tokens": "attr_reader :name , :start def initialize ( start ) @start = start def msec_delta ( Time . now - @start ) * 1000 end worker_response = WorkerResponse . new ( @start )", "del_tokens": "attr_reader :name def initialize worker_response = WorkerResponse . new", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "couple", "of", "misbehaviours", "in", "the", "parser", "."], "add_tokens": "if ( ! [ \"OPTIONS\" , \"GET\" , \"HEAD\" , \"POST\" , \"PUT\" , \"DELETE\" , \"TRACE\" , \"CONNECT\" ] . include? ( @method ) ) raise Http :: ParserError :: NotImplemented end addition = str [ scanner . pos , remain ] scanner . pos += addition . length", "del_tokens": "addition = scanner . scan ( %r| .{0, #{ remain } } | )", "commit_type": "fix"}
