{"commit_tokens": ["use", "new", "function", "signature", "in", "tests"], "add_tokens": "\" \" createBot = func ( token string , httpClient * http . Client ) ( adapter . BotAdapter , error ) {", "del_tokens": "createBot = func ( token string ) ( adapter . BotAdapter , error ) {", "commit_type": "use"}
{"commit_tokens": ["updated", "matchandget", "improves", "performance", "for", "URIs", "without", "any", "variables"], "add_tokens": "if r . Pattern == requestURI { return true , nil } if ! r . uriPattern . Match ( [ ] byte ( requestURI ) ) {", "del_tokens": "if ( r . Pattern != requestURI ) && ! r . uriPattern . Match ( [ ] byte ( requestURI ) ) {", "commit_type": "update"}
{"commit_tokens": ["fix", "json", "export", "and", "unittest"], "add_tokens": "Exclude_keys [ ] string `json:\"exclude_keys,omitempty\"`", "del_tokens": "exclude_keys [ ] string `json:\"exclude_keys,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["added", "test", "for", "basic", "auth", "+", "cleaned", "up", "incorrect", "test"], "add_tokens": "t . Error ( \" \" ) t . Log ( \" \" , err ) func TestBasicAuth ( t * testing . T ) { ts := httptest . NewServer ( http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { if r . Header . Get ( \" \" ) != \" \" { t . Fatalf ( \" \" , r . Header . Get ( r . Header . Get ( \" \" ) ) ) } } ) ) defer ts . Close ( ) client , err := New ( ts . URL , \" \" ) if err != nil { t . Fatalf ( \" \" , err . Error ( ) ) } client . UseBasicAuth = true client . BasicAuthUser = \" \" client . BasicAuthPass = \" \" t . Log ( client ) _ , err = client . API ( ) if err != nil { t . Fatalf ( \" \" , err . Error ( ) ) } }", "del_tokens": "t . Error ( \" \" , err ) t . Log ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["uses", "path", ".", "Clean", "instead", "of", "filepath", ".", "Clean", "to", "correct", "an", "issue", "on", "Windows", ".", "go", "test", "now", "passes", "on", "windows", "."], "add_tokens": "\" \" ruri := r . URL . RequestURI ( ) ruri = ruri [ : len ( ruri ) - len ( r . URL . RawQuery ) - 1 ] slash := strings . HasSuffix ( ruri , \" \" ) ruri = path . Clean ( ruri ) if ruri != \" \" && slash { ruri += \" \" w . Write ( [ ] byte ( ruri ) )", "del_tokens": "\" \" path := r . URL . RequestURI ( ) path = path [ : len ( path ) - len ( r . URL . RawQuery ) - 1 ] slash := strings . HasSuffix ( path , \" \" ) path = filepath . Clean ( path ) if path != \" \" && slash { path += \" \" w . Write ( [ ] byte ( path ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "PrintToPDF", "and", "SavePDF", "(", "and", "--", "pdf", "option", "to", "test", "app", ")"], "add_tokens": "pdf := flag . Bool ( \" \" , false , \" \" ) wait := flag . Bool ( \" \" , false , \" \" ) should_wait := true should_wait = false should_wait = false if * screenshot { remote . CallbackEvent ( \" \" , func ( params godet . Params ) { log . Println ( \" \" ) remote . SaveScreenshot ( \" \" , 0644 , 0 , false ) remote . Close ( ) } ) } if * pdf { remote . CallbackEvent ( \" \" , func ( params godet . Params ) { log . Println ( \" \" ) remote . SavePDF ( \" \" , 0644 ) remote . Close ( ) } ) } should_wait = false should_wait = false should_wait = false should_wait = false } if * wait || should_wait { log . Println ( \" \" ) <- done", "del_tokens": "if * screenshot { remote . CallbackEvent ( \" \" , func ( params godet . Params ) { log . Println ( \" \" ) remote . SaveScreenshot ( \" \" , 0644 , 0 , false ) } ) } <- done", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "router", "path", "matching"], "add_tokens": "var i int for i < len ( r . Path ) { i ++ i ++ if k , i = consumeIdent ( i , r . Path ) ; len ( k ) == 0 { if v , j = consumeIdent ( j , path ) ; len ( v ) == 0 { v , j = consumeCount ( j , path , len ( k ) ) return path [ pos : i ] , i return path [ pos : i ] , i return path [ pos : i ] , i", "del_tokens": "for i := 0 ; i < len ( r . Path ) ; i ++ { if k , i = consumeIdent ( i , r . Path ) ; i == 0 { if v , j = consumeIdent ( j , path ) ; j == 0 { v , j = consumeCount ( j , path , i + 1 ) return path [ pos : i ] , i - 1 return path [ pos : i ] , i - 1 return path [ pos : i ] , i - 1", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "few", "more", "data", "structures", "and", "moved", "things", "around"], "add_tokens": "func ( f Function ) c ( ) C . CUfunction { return C . CUfunction ( unsafe . Pointer ( uintptr ( fn ) ) ) } f := fn . c ( ) f := fn . c ( ) f := fn . c ( ) f := fn . c ( )", "del_tokens": "f := C . CUfunction ( unsafe . Pointer ( uintptr ( fn ) ) ) f := C . CUfunction ( unsafe . Pointer ( uintptr ( fn ) ) ) f := C . CUfunction ( unsafe . Pointer ( uintptr ( fn ) ) ) f := C . CUfunction ( unsafe . Pointer ( uintptr ( fn ) ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "gizak", "/", "termui", "/", "issues", "/", "75"], "add_tokens": "// Sparkline is like: ▅▆▂▂▅▇▂▂▃▆▆▆▅▃. The data points should be non-negative integers. max := 0 if max != 0 { sl . Lines [ i ] . scale = float32 ( 8 * sl . Lines [ i ] . Height ) / float32 ( max ) } else { // when all negative sl . Lines [ i ] . scale = 0 } // display height of the data point, zero when data is negative if v < 0 { h = 0 }", "del_tokens": "import \" \" // Sparkline is like: ▅▆▂▂▅▇▂▂▃▆▆▆▅▃ max := math . MinInt32 sl . Lines [ i ] . scale = float32 ( 8 * sl . Lines [ i ] . Height ) / float32 ( max )", "commit_type": "fix"}
{"commit_tokens": ["use", "JSON", "as", "default", "responder"], "add_tokens": "// client. It uses render.JSON by default which will respond using JSON encoding. // You can set it to render.JSON, render.XML, render.Data, etc. See // github.com/go-chi/render for more info var Responder = render . JSON", "del_tokens": "// client. It uses render.DefaultResponder by default which will respond using // the appropriate data type based on the Accept header. You can set it to // render.JSON, render.XML, render.Data, etc. See github.com/go-chi/render // for more info var Responder = render . DefaultResponder", "commit_type": "use"}
{"commit_tokens": ["add", "default", "port", "where", "none", "is", "specified"], "add_tokens": "\" \" \" \" addr , port , err := net . SplitHostPort ( addrs [ 0 ] ) if ae , ok := err . ( * net . AddrError ) ; ok && ae . Err == \" \" { port = \" \" config . Address = fmt . Sprintf ( \" \" , addr , port ) } else if err == nil { config . Address = fmt . Sprintf ( \" \" , addr , port ) }", "del_tokens": "config . Address = addrs [ 0 ]", "commit_type": "add"}
{"commit_tokens": ["Removed", "panicing", "spew", "https", ":", "//", "github", ".", "com", "/", "EmileVauge", "/", "traefik", "/", "issues", "/", "56"], "add_tokens": "log . Debugf ( \" \" , globalConfiguration )", "del_tokens": "\" \" log . Debugf ( \" \" , spew . Sdump ( globalConfiguration ) ) log . Debugf ( \" \" , spew . Sdump ( configMsg . configuration ) ) log . Debugf ( \" \" , spew . Sdump ( srv ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "IsTmpFriendDir", "(", "string", ")", "bool"], "add_tokens": "var dirRe = regexp . MustCompile ( `^tmpfriend-([0-9]+)-.*$` ) // if !IsTmpFriendDir(\"\") { // f, err := tmpfriend.RootTempDir(\"\") // if err != nil { // return err // } // defer f() // IsTmpFriendDir returns true if we are in a tmpfriend dir. func IsTmpFriendDir ( rootDir string ) bool { if rootDir == \" \" { rootDir = os . TempDir ( ) } return dirRe . MatchString ( filepath . Base ( rootDir ) ) } m := dirRe . FindStringSubmatch ( d . Name ( ) )", "del_tokens": "// f, err := tmpfriend.RootTempDir(\"\") // if err != nil { // return err // defer f() var p = regexp . MustCompile ( `^tmpfriend-([0-9]+)-.*$` ) m := p . FindStringSubmatch ( d . Name ( ) )", "commit_type": "add"}
{"commit_tokens": ["Implement", "the", "escape", "sequence", "to", "bold", "off"], "add_tokens": "ansi_reset = \" \" ansi_intensity_on = \" \" ansi_intensity_off = \" \" case ansi_intensity_on : case ansi_intensity_off : winIntensity = false", "del_tokens": "ansi_reset = \" \" ansi_intensity = \" \" case ansi_intensity :", "commit_type": "implement"}
{"commit_tokens": ["Allow", "wait", "-", "free", "reservations"], "add_tokens": "It ( \" \" , func ( ) { It ( \" \" , func ( ) { It ( \" \" , func ( ) { subject . opts . WaitTimeout = 0 future := time . Now ( ) . Add ( 50 * time . Millisecond ) . UnixNano ( ) err := redisClient . Set ( testRedisKey , strconv . FormatInt ( future , 10 ) ) . Err ( ) Expect ( err ) . NotTo ( HaveOccurred ( ) ) ok , err := subject . Lock ( ) Expect ( err ) . NotTo ( HaveOccurred ( ) ) Expect ( ok ) . To ( BeFalse ( ) ) Expect ( future ) . To ( BeNumerically ( \" \" , time . Now ( ) . UnixNano ( ) ) ) } )", "del_tokens": "It ( \" \" , func ( ) { It ( \" \" , func ( ) {", "commit_type": "allow"}
{"commit_tokens": ["removed", "all", "remains", "of", "token", "/", "tag", "auth", "(", "for", "now", ")"], "add_tokens": "// verify access before doing action // verify access before doing action // verify access before doing action // verify access before doing action // verify access before doing action", "del_tokens": "// Authorized bool // Authorized: false, // // if !p.Authorized { // return ErrUnauthorized // } // // if !p.Authorized { // return ErrUnauthorized // } // // if !p.Authorized { // return ErrUnauthorized // } // // if !p.Authorized { // return ErrUnauthorized // } // // if !p.Authorized { // return ErrUnauthorized // }", "commit_type": "remove"}
{"commit_tokens": ["Updating", "documentation", "on", "Oracle", "and", "SQL", "Server", "instance", "/", "service", "IDs"], "add_tokens": "// dbname* - the database, instance, or service name/id to connect to // * for Microsoft SQL Server, the syntax to supply an instance and database // name is /instance/dbname, where /instance is optional. For Oracle databases, // /dbname is the unique database ID (SID). Please see below for examples. //", "del_tokens": "// dbname - the database or service name to connect to", "commit_type": "update"}
{"commit_tokens": ["add", "shirou", ".", "gopsutil", "/", "mem", "to", "meminfo", "benchmarks"], "add_tokens": "line , err = out . ReadBytes ( '\\n' ) if v == 0x20 || v == '\\r' { line , err = buf . ReadSlice ( '\\n' ) if v == 0x20 || v == '\\r' { line , err = buf . ReadSlice ( '\\n' ) if v == 0x20 || v == '\\r' {", "del_tokens": "joe \" \" line , err = out . ReadBytes ( joe . LF ) if v == 0x20 || v == joe . CR { line , err = buf . ReadSlice ( joe . LF ) if v == 0x20 || v == joe . CR { line , err = buf . ReadSlice ( joe . LF ) if v == 0x20 || v == joe . CR {", "commit_type": "add"}
{"commit_tokens": ["added", "linear", "and", "jitter", "backoffs"], "add_tokens": "client . Backoff = pester . ExponentialJitterBackoff", "del_tokens": "client . Backoff = pester . ExponentialBackoff", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "-", "p", "flag", "to", "generate", "cpu", "profiles"], "add_tokens": "\" \" var opt_e , opt_l , opt_p string flag . StringVar ( & opt_p , \" \" , \" \" , \" \" ) fmt . Println ( `Usage: glua [options] [script [args]]. - p file write cpu profiles to the file if len ( opt_p ) != 0 { f , err := os . Create ( opt_p ) if err != nil { fmt . Println ( err . Error ( ) ) os . Exit ( 1 ) } pprof . StartCPUProfile ( f ) defer pprof . StopCPUProfile ( ) }", "del_tokens": "var opt_e , opt_l string fmt . Println ( `usage: glua.exe [options] [script [args]].", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "ignored", ":", "true", "tag", "which", "causes", "envconfig", "to", "ignore", "the", "tagged", "field", "."], "add_tokens": "if ! f . CanSet ( ) || typeOfSpec . Field ( i ) . Tag . Get ( \" \" ) == \" \" {", "del_tokens": "if ! f . CanSet ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "default", "context", "from", "context", ".", "TODO", "()", "to", "context", ".", "Background", "()", "for", "ServeHTTP", "method"], "add_tokens": "r . ServeHTTPC ( context . Background ( ) , w , req )", "del_tokens": "r . ServeHTTPC ( context . TODO ( ) , w , req )", "commit_type": "fix"}
{"commit_tokens": ["Update", "README", "with", "desired", "behavior"], "add_tokens": "// Execute executes a slice of queries, each of which doesn't // return rows. It tx is true, then all queries will be executed // successfully or none will be. Execute ( queries [ ] string , tx bool ) ( [ ] sql . Result , error ) // Query executes a slice of queries, each of which returns rows. // If tx is true, then the query will take place while a read // transaction is held on the database. Query ( queries [ ] string , tx bool ) ( [ ] * sql . Rows , error )", "del_tokens": "Exec ( queries [ ] string , tx bool ) ( sql . Result , error ) Query ( queries [ ] string , tx bool ) ( * sql . Rows , error )", "commit_type": "update"}
{"commit_tokens": ["Adding", "support", "for", "cross", "-", "dc", "forwarding"], "add_tokens": "\" \" // Bail if we can't find any servers s . remoteLock . RLock ( ) servers := s . remoteConsuls [ dc ] if len ( servers ) == 0 { s . remoteLock . RUnlock ( ) return rpc . ErrNoDCPath } // Select a random addr offset := rand . Int31 ( ) % int32 ( len ( servers ) ) server := servers [ offset ] s . remoteLock . RUnlock ( ) // Forward to remote Consul return s . connPool . RPC ( server , method , args , reply )", "del_tokens": "// TODO: Fix return fmt . Errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["added", "claim", "partition", "retries", "+", "backoff"], "add_tokens": "var err error for i := 0 ; i <= zc . config . MaxClaimPartitionRetries ; i ++ { ok , err := zc . tryClaimPartitionOwnership ( group , topic , partition , consumerThreadId ) if ok { return ok , err } Tracef ( zc , \" \" , topic , partition , i ) time . Sleep ( zc . config . ClaimPartitionBackoff ) } return false , err } func ( zc * ZookeeperCoordinator ) tryClaimPartitionOwnership ( group string , topic string , partition int32 , consumerThreadId ConsumerThreadId ) ( bool , error ) { /* Zookeeper read timeout */ /* Max retries to claim one partition */ MaxClaimPartitionRetries int /* Backoff to retry to claim partition */ ClaimPartitionBackoff time . Duration config . MaxClaimPartitionRetries = 3 config . ClaimPartitionBackoff = 150 * time . Millisecond", "del_tokens": "/** Zookeeper read timeout */", "commit_type": "add"}
{"commit_tokens": ["Move", "responsibility", "of", "response", "writing", "to", "the", "Handler", "protector", "."], "add_tokens": "authErr := vg . AuthenticateRequest ( r ) if authErr != nil { authErr . WriteResponse ( w , vg . debug ) authErr := vg . AuthenticateRequest ( r ) if authErr != nil { authErr . WriteResponse ( w , vg . debug ) return next ( w , r )", "del_tokens": "\" \" err := vg . AuthenticateRequest ( w , r ) if err != nil { if vg . debug { w . Header ( ) . Add ( \" \" , \" \" ) fmt . Fprintf ( w , \" \" , err ) } err := vg . AuthenticateRequest ( w , r ) if err == nil && next != nil { next ( w , r )", "commit_type": "move"}
{"commit_tokens": ["Make", "decorators", "consistent", "by", "always", "having", "handler", "last", "."], "add_tokens": "func CommonLogHandler ( logger * log . Logger , templ string , h http . Handler ) http . Handler {", "del_tokens": "func CommonLogHandler ( logger * log . Logger , h http . Handler , templ string ) http . Handler {", "commit_type": "make"}
{"commit_tokens": ["implement", "DecodeUint64", "for", "reducing", "numbers", "formatting"], "add_tokens": "return nil , fmt . Errorf ( \" \" , c , src ) // DecodeUint64 decodes the base58 encoded bytes to an unsigned integer. func ( enc * Encoding ) DecodeUint64 ( src [ ] byte ) ( uint64 , error ) { var n uint64 var i int64 for _ , c := range src { if i = enc . decodeMap [ c ] ; i < 0 { return 0 , fmt . Errorf ( \" \" , c , src ) } n = n * radixInt + uint64 ( i ) } return n , nil }", "del_tokens": "return nil , fmt . Errorf ( \" \\\" \\\" \" , c , src )", "commit_type": "implement"}
{"commit_tokens": ["fixed", "test", "to", "acommodate", "new", "change", "in", "LargeMap", "not", "-", "found", "behaviour"], "add_tokens": "// This test only passes in Aerospike 3.4.1 and above Expect ( err ) . NotTo ( HaveOccurred ( ) ) Expect ( elem ) . To ( Equal ( map [ interface { } ] interface { } { } ) )", "del_tokens": "Expect ( err ) . To ( HaveOccurred ( ) ) Expect ( elem ) . To ( BeNil ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "tar", "type", "(", "GNU", "POSIX", "etc", ".", ")", "identification"], "add_tokens": "return true", "del_tokens": "// checksum OK magic := buf [ 257 : 265 ] if bytes . Equal ( magic , [ ] byte ( \" \\x00 \" ) ) { return true // GNU tar } else if bytes . Equal ( magic [ : 6 ] , [ ] byte ( \" \\x00 \" ) ) { return true // POSIX tar } return true // Old style tar", "commit_type": "remove"}
{"commit_tokens": ["Add", "wide", "CJK", "runes", "support", "for", "terminal", "-", "based", "implementations", "."], "add_tokens": "func print_wide ( x , y int , s string ) { for _ , r := range s { termbox . SetCell ( x , y , r , termbox . ColorDefault , termbox . ColorDefault ) x += 2 } } const hello_world = \" print_wide ( 2 + len ( chars ) , 11 , hello_world ) case termbox . EventResize : draw_all ( ) }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["added", "http", "https", "and", "ipfs", "protocols"], "add_tokens": "\" \" , \" \" , t . Errorf ( \" \" , a , err ) \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , t . Errorf ( \" \" , a , err )", "del_tokens": "t . Errorf ( \" \" , a ) t . Errorf ( \" \" , a )", "commit_type": "add"}
{"commit_tokens": ["improved", "type", "checking", "of", "arguments"], "add_tokens": "First int32", "del_tokens": "First int", "commit_type": "improve"}
{"commit_tokens": ["Changed", "the", "type", "uri", "for", "membershiprole"], "add_tokens": "membershipRoleURI = \" \"", "del_tokens": "membershipRoleURI = \" \"", "commit_type": "change"}
{"commit_tokens": ["Use", "slices", "for", "AND", "and", "OR", "expressions"], "add_tokens": "\" \" } , \" \" } , \" \" } , { users . Select ( \" \" ) . Where ( foo . Eq ( \" \" ) . And ( bar . Eq ( \" \" ) ) . And ( qux . IsNull ( ) . Or ( qux . Gt ( 5 ) ) ) ) , \" \" } ,", "del_tokens": "\" \" } , \" \" } , \" \" } ,", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "query", "logging", "Exec", "takes", "builders"], "add_tokens": "func ( r * recordingExecutor ) Exec ( stmt interface { } , args ... interface { } ) ( sql . Result , error ) { var querystr string var err error switch t := stmt . ( type ) { case string : querystr = t return r . Exec ( t , args ... ) case Serializer : querystr , err = Serialize ( t ) if err != nil { return nil , err } default : return nil , fmt . Errorf ( \" \" ) } r . exec = append ( r . exec , querystr )", "del_tokens": "func ( r * recordingExecutor ) Exec ( stmt string , args ... interface { } ) ( sql . Result , error ) { r . exec = append ( r . exec , stmt )", "commit_type": "add"}
{"commit_tokens": ["moving", "the", "locks", "outside", "of", "if", "loop"], "add_tokens": "result . mu . Lock ( ) result . mu . Unlock ( ) result . mu . Lock ( ) result . mu . Unlock ( )", "del_tokens": "result . mu . Lock ( ) result . mu . Unlock ( ) result . mu . Lock ( ) result . mu . Unlock ( )", "commit_type": "move"}
{"commit_tokens": ["Add", "simple", "timeout", "and", "throttling", "support", "start", "collecting", "results", "immediately", "refactor", "."], "add_tokens": "type Report struct { latencies [ ] float64 avgTotal float64 statusCodeDist map [ int ] int } N int // Number of requests C int // Number of Concurrent workers S int // Timeout Q int // Rate limit (QPS) start time . Time end time . Time results chan * result bar * pb . ProgressBar timeout <- chan time . Time timedOut bool report Report", "del_tokens": "N int C int start time . Time end time . Time results chan * result bar * pb . ProgressBar", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "on", "New", "()", "s", "test", "."], "add_tokens": "t . Error ( \" \" )", "del_tokens": "t . Error ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "tags", "to", "structures", "for", "JSON", "serialization"], "add_tokens": "Instance string `json:\"name\"` // Instance name (e.g. \"My web page\") Service string `json:\"type\"` // Service name (e.g. _http._tcp.) Domain string `json:\"domain\"` // If blank, assumes \"local\" serviceName string `json:\"-\"` serviceInstanceName string `json:\"-\"` HostName string `json:\"hostname\"` // Host machine DNS name Port int `json:\"port\"` // Service Port Text [ ] string `json:\"text\"` // Service info served as a TXT record TTL uint32 `json:\"ttl\"` // TTL of the service record AddrIPv4 net . IP `json:\"-\"` // Host machine IPv4 address AddrIPv6 net . IP `json:\"-\"` // Host machine IPv6 address", "del_tokens": "Instance string // Instance name (e.g. \"My web page\") Service string // Service name (e.g. _http._tcp.) Domain string // If blank, assumes \"local\" serviceName string serviceInstanceName string HostName string // Host machine DNS name Port int // Service Port Text [ ] string // Service info served as a TXT record TTL uint32 // TTL of the service record AddrIPv4 net . IP // Host machine IPv4 address AddrIPv6 net . IP // Host machine IPv6 address", "commit_type": "add"}
{"commit_tokens": ["Add", "gcdapi", "WithParams", "methods", "and", "a", "new", "simple", "unit", "test"], "add_tokens": "\" \" _ \" \" \" \" flag . StringVar ( & chromePath , \" \" , \" \" , \" \" ) go func ( ) { log . Println ( http . ListenAndServe ( \" \" , nil ) ) } ( ) if _ , _ , err := tab . Navigate ( \" \" ) ; err != nil { time . Sleep ( 1 * time . Hour )", "del_tokens": "\" \" flag . StringVar ( & chromePath , \" \" , \" \" , \" \" ) if _ , err := tab . Navigate ( \" \" ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Implement", "http", ".", "Client", "reuse", "so", "we", "are", "not", "creating", "a", "new", "client", "for", "every", "request", "."], "add_tokens": "var r * http . Request", "del_tokens": "var r * http . Request ;", "commit_type": "implement"}
{"commit_tokens": ["added", "jquery", "to", "the", "new", "app", "Generator"], "add_tokens": "var skipJQuery bool \" \" : skipJQuery , newCmd . Flags ( ) . BoolVar ( & skipPop , \" \" , false , \" \" ) newCmd . Flags ( ) . BoolVar ( & skipJQuery , \" \" , false , \" \" )", "del_tokens": "newCmd . Flags ( ) . BoolVar ( & skipPop , \" \" , false , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Update", "for", "larger", "Chat", "IDs", "."], "add_tokens": "ChatID int64 // required v . Add ( \" \" , strconv . FormatInt ( chat . ChatID , 10 ) ) params [ \" \" ] = strconv . FormatInt ( file . ChatID , 10 ) FromChatID int64 // required v . Add ( \" \" , strconv . FormatInt ( config . FromChatID , 10 ) )", "del_tokens": "ChatID int // required v . Add ( \" \" , strconv . Itoa ( chat . ChatID ) ) params [ \" \" ] = strconv . Itoa ( file . ChatID ) FromChatID int // required v . Add ( \" \" , strconv . Itoa ( config . FromChatID ) )", "commit_type": "update"}
{"commit_tokens": ["Adding", "ability", "to", "read", "from", "io", ".", "Reader"], "add_tokens": "\" \" var SIMPLE_PAGE_YAML = `--- contenttype : \" \" - - - Sample Text ` p , err := ReadFrom ( strings . NewReader ( SIMPLE_PAGE_YAML ) , filepath . Join ( \" \" ) ) if err != nil { t . Fatalf ( \" \" ) } func TestNewPageWithFilePath ( t * testing . T ) { p , err := ReadFrom ( strings . NewReader ( SIMPLE_PAGE_YAML ) , el [ \" \" ] ) if err != nil { t . Fatalf ( \" \" , err ) }", "del_tokens": "p := NewPage ( filepath . Join ( \" \" ) ) func TestCreateNewPage ( t * testing . T ) { p := NewPage ( el [ \" \" ] )", "commit_type": "add"}
{"commit_tokens": ["Fix", "logic", "for", "getting", "absolute", "path", "of", "output", "directory"], "add_tokens": "wd , err := os . Getwd ( ) if err != nil { return errors . Wrapf ( err , \" \" ) outputDir = path . Join ( wd , outputDir )", "del_tokens": "var err error if outputDir , err = filepath . Abs ( outputDir ) ; err != nil { return errors . Wrapf ( err , \" \" , outputDir )", "commit_type": "fix"}
{"commit_tokens": ["use", "flags", ".", "NewParser", "to", "remove", "flags", ".", "PrintErrors", "option"], "add_tokens": "args , err := flags . NewParser ( & opts , flags . HelpFlag | flags . PassDoubleDash , ) . ParseArgs ( args ) fmt . Fprintln ( cli . errStream , err . Error ( ) )", "del_tokens": "args , err := flags . ParseArgs ( & opts , args )", "commit_type": "use"}
{"commit_tokens": ["Add", "CreatedAt", "field", "to", "silence"], "add_tokens": "CreatedAt time . Time `json:\"createdAt,omitempty\"` CreatedBy string `json:\"createdBy\"` Comment string `json:\"comment,omitempty\"`", "del_tokens": "CreatedBy string `json:\"createdBy\"` Comment string `json:\"comment,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Remove", "support", "for", "TChannel", "as", "transport", ";", "split", "ZipkinSpan", "interface"], "add_tokens": "// ExtractableZipkinSpan is a type of Carrier used for integration with Zipkin-aware // RPC frameworks (like TChannel). It does not support baggage, only trace IDs. type ExtractableZipkinSpan interface { } // InjectableZipkinSpan is a type of Carrier used for integration with Zipkin-aware // RPC frameworks (like TChannel). It does not support baggage, only trace IDs. type InjectableZipkinSpan interface { carrier , ok := abstractCarrier . ( InjectableZipkinSpan ) carrier , ok := abstractCarrier . ( ExtractableZipkinSpan )", "del_tokens": "// ZipkinSpan is a type of Carrier used for integration with Zipkin-aware RPC frameworks // (like TChannel). It does not support baggage, only trace IDs. type ZipkinSpan interface { carrier , ok := abstractCarrier . ( ZipkinSpan ) carrier , ok := abstractCarrier . ( ZipkinSpan )", "commit_type": "remove"}
{"commit_tokens": ["add", "support", "for", "embedding", "struct", "configuration", "with", "special", "_", "tag"], "add_tokens": "populateNodeStruct ( t , t . Name ( ) , v , t , m ) // if using the \"_\" notation to embed structs, it's possible that names are no longer unique. props := make ( map [ string ] struct { } ) for _ , item := range m . Items ( ) { if _ , ok := props [ item . Name ] ; ok { panic ( \" \" + item . Name + \" \" + t . String ( ) ) } props [ item . Name ] = struct { } { } } return } // populateNodeStruct is the mutually recursive helper of makeNodeStruct to create the node struct with potentially // embedded types. It will populate m with the struct fields from v. The original type and path of the current field // are passed in order to create decent panic strings if an invalid configuration is detected. func populateNodeStruct ( originalT reflect . Type , path string , v reflect . Value , t reflect . Type , m Map ) { case \" \" : path = path + \" \" + ft . Name if ft . Type . Kind ( ) != reflect . Struct && ! ft . Anonymous { panic ( \" \\\" \\\" \" + path + \" \" + originalT . Name ( ) ) } populateNodeStruct ( originalT , path , fv , ft . Type , m ) continue", "del_tokens": "return", "commit_type": "add"}
{"commit_tokens": ["Updating", "package", "path", "for", "clickhouse", "database"], "add_tokens": "// ClickHouse (clickhouse) | github.com/ClickHouse/clickhouse-go", "del_tokens": "// ClickHouse (clickhouse) | github.com/kshvakov/clickhouse", "commit_type": "update"}
{"commit_tokens": ["Implement", "test", "utility", "function", ":", "comparePart"], "add_tokens": "for i := range part . Errors {", "del_tokens": "for i , _ := range part . Errors {", "commit_type": "implement"}
{"commit_tokens": ["Remove", "extra", "comma", "from", "annotations", "in", "reference", ".", "go", "and", "add", "Query", "handlers", "back", "to", "routing", ".", "go"], "add_tokens": "Reference string `bson:\"reference,omitempty\" json:\"reference,omitempty\"` Display string `bson:\"display,omitempty\" json:\"display,omitempty\"` Type string `bson:\"type,omitempty\" json:\"type,omitempty\"` ReferencedID string `bson:\"referenceid,omitempty\" json:\"referenceid,omitempty\"` External * bool `bson:\"external,omitempty\" json:\"external,omitempty\"`", "del_tokens": "Reference string `bson:\"reference,omitempty\", json:\"reference,omitempty\"` Display string `bson:\"display,omitempty\", json:\"display,omitempty\"` Type string `bson:\"type,omitempty\", json:\"type,omitempty\"` ReferencedID string `bson:\"referenceid,omitempty\", json:\"referenceid,omitempty\"` External * bool `bson:\"external,omitempty\", json:\"external,omitempty\"`", "commit_type": "remove"}
{"commit_tokens": ["changed", "flag", "f", ".", "conn", "to", "err"], "add_tokens": "if err == nil {", "del_tokens": "if err != nil {", "commit_type": "change"}
{"commit_tokens": ["add", "samples", "and", "some", "new", "operators"], "add_tokens": "a := interpreter . PopFloat ( ) * math . Pi / 180 interpreter . Push ( float ( math . Cos ( float64 ( a ) ) ) ) a := interpreter . PopFloat ( ) * math . Pi / 180 interpreter . Push ( float ( math . Sin ( float64 ( a ) ) ) ) interpreter . Push ( float ( rand . Int ( ) ) )", "del_tokens": "a := interpreter . PopFloat ( ) interpreter . Push ( float ( math . Cos ( float64 ( a ) ) ) * ( 180.0 / math . Pi ) ) a := interpreter . PopFloat ( ) interpreter . Push ( float ( math . Sin ( float64 ( a ) ) ) * ( 180.0 / math . Pi ) ) interpreter . Push ( rand . Int ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "nil", "response", "when", "getting", "a", "session", "cookie"], "add_tokens": "if resp != nil { session . Cookies = resp . Cookies ( ) }", "del_tokens": "session . Cookies = resp . Cookies ( )", "commit_type": "fix"}
{"commit_tokens": ["implement", "DefaultSimilarity", ".", "decodeNormValue", "()"], "add_tokens": "\" \" /** Cache of decoded bytes. */ var NORM_TABLE [ ] float32 = buildNormTable ( ) func buildNormTable ( ) [ ] float32 { table := make ( [ ] float32 , 256 ) for i , _ := range table { table [ i ] = util . Byte315ToFloat ( byte ( i ) ) } return table } return NORM_TABLE [ int ( norm & 0xff ) ] // & 0xFF maps negative bytes to positive above 127", "del_tokens": "panic ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["Adding", "more", "test", "cases", "for", "the", "command", "-", "line", "client"], "add_tokens": "\" \" nsErr = fmt . Errorf ( \" \\n \" , value ) var nsErr error if nsErr != nil { fmt . Fprintf ( stderr , nsErr . Error ( ) ) retCode = 1 return } fi , err := os . Stat ( path ) data , _ := ioutil . ReadFile ( path ) ret , err := runXPath ( x , bytes . NewBuffer ( data ) , ns , value ) list , _ := ioutil . ReadDir ( path )", "del_tokens": "return fmt . Errorf ( \" \" + value ) f , err := os . Open ( path ) if err != nil { fmt . Fprintf ( stderr , \" \\n \" , path ) retCode = 1 return } fi , err := f . Stat ( ) ret , err := runXPath ( x , f , ns , value ) list , err := ioutil . ReadDir ( path ) if err != nil { fmt . Fprintf ( stderr , \" \\n \" , path ) retCode = 1 return }", "commit_type": "add"}
{"commit_tokens": ["Fix", "fallout", "from", "https", ":", "//", "github", ".", "com", "/", "opentracing", "/", "basictracer", "-", "go", "/", "pull", "/", "36"], "add_tokens": "SpanGuid : thrift . StringPtr ( strconv . FormatUint ( raw . Context . SpanID , 16 ) ) , TraceGuid : thrift . StringPtr ( strconv . FormatUint ( raw . Context . TraceID , 16 ) ) ,", "del_tokens": "SpanGuid : thrift . StringPtr ( strconv . FormatUint ( raw . SpanID , 16 ) ) , TraceGuid : thrift . StringPtr ( strconv . FormatUint ( raw . TraceID , 16 ) ) ,", "commit_type": "fix"}
{"commit_tokens": ["makes", "args", "flags", "case", "insensitive"], "add_tokens": "// prevents case sensitivity issue args = argsToLower ( args ) func argToLower ( inArg string ) string { var outArg string dashIndex := strings . Index ( inArg , \" \" ) if dashIndex == - 1 { if dashIndex = strings . Index ( inArg , \" \" ) ; dashIndex == - 1 { return inArg } //-fValue outArg = strings . ToLower ( inArg [ dashIndex : dashIndex + 2 ] ) + inArg [ dashIndex + 2 : ] return outArg } //--flag if equalIndex := strings . Index ( inArg , \" \" ) ; equalIndex != - 1 { //--flag=value outArg = strings . ToLower ( inArg [ dashIndex : equalIndex ] ) + inArg [ equalIndex : ] } else { //--boolflag outArg = strings . ToLower ( inArg [ dashIndex : ] ) } return outArg } func argsToLower ( inArgs [ ] string ) [ ] string { outArgs := make ( [ ] string , len ( inArgs ) , len ( inArgs ) ) for i , inArg := range inArgs { outArgs [ i ] = argToLower ( inArg ) } return outArgs }", "del_tokens": "// Call custom helper", "commit_type": "make"}
{"commit_tokens": ["added", "multiline", "test", "and", "trie", "structure"], "add_tokens": "func TestHighlightCaseInsensitive ( t * testing . T ) { func TestHighlightMultiLine ( t * testing . T ) { cases := [ ] highlightCase { { \" \\n \" , \" \\n \" , } , } testCases ( t , \" \" , cases ) }", "del_tokens": "func TestCaseInsensitive ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "better", "YML", "parsing", "for", "metadata"], "add_tokens": "return NestedMapsToMapInterface ( config . Metadata )", "del_tokens": "return config . Metadata", "commit_type": "add"}
{"commit_tokens": ["Use", "generic", "implementation", "for", "s390x"], "add_tokens": "// +build !amd64", "del_tokens": "// +build !amd64,!s390x", "commit_type": "use"}
{"commit_tokens": ["change", "the", "flag", "of", "the", "spickspan", "config", "file"], "add_tokens": "flag . StringVar ( & ssconfig , \" \" , \" \" , \" \" )", "del_tokens": "flag . StringVar ( & ssconfig , \" \" , \" \" , \" \" )", "commit_type": "change"}
{"commit_tokens": ["removed", "Makefile", "updated", "copyright", "now", "in", "correct", "format", "for", "1", ".", "x", "compilation"], "add_tokens": "// Copyright 2013 The Go Authors. All rights reserved.", "del_tokens": "// Copyright 2011 The Go Authors. All rights reserved.", "commit_type": "remove"}
{"commit_tokens": ["Update", "common", "/", "packet", "/", "connack", ".", "go"], "add_tokens": "// Length of the Fixed header of the CONNACK Packet. const lenCONNACKFixedHeader = 2 // First byte of the Fixed header of the CONNACK Packet. const firstByteCONNACKFixedHeader = 0x20 var ( ErrInvalidCONNACKFixedHeaderLen = errors . New ( \" \" ) ErrInvalidCONNACKVariableHeaderLen = errors . New ( \" \" ) ErrInvalidfirstByteCONNACKFixedHeader = errors . New ( \" \" ) ) // Check the length of the Fixed header of the CONNACK Packet. if len ( fixedHeader ) != lenCONNACKFixedHeader { return nil , ErrInvalidCONNACKFixedHeaderLen } // Check the first byte of the Fixed header of the CONNACK Packet. if fixedHeader [ 0 ] != firstByteCONNACKFixedHeader { return nil , ErrInvalidCONNACKVariableHeaderLen }", "del_tokens": "var ErrInvalidCONNACKVariableHeaderLen = errors . New ( \" \" )", "commit_type": "update"}
{"commit_tokens": ["Use", "net", "/", "rpc", "instead", "of", "valyala", "/", "gorpc"], "add_tokens": "\" \" const DefaultPath = \" \" var rpcPath string func closeClients ( clients [ ] * rpc . Client ) { for _ , clnt := range clients { clnt . Close ( ) } } // Set nodes that are participating in distributed locking/unlocking calls. return SetNodesWithPath ( nodes , DefaultPath ) } // Same as SetNodes, but takes a path argument different from the package-level default. func SetNodesWithPath ( nodeList [ ] string , path string ) ( err error ) { // Validate if number of nodes is within allowable range. rpcPath = path", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["remove", "allowing", "empty", "string", "as", "wildcare", "to", "migrate", "/", "rollback", "completely", "and", "add", "test"], "add_tokens": "if len ( g . migrations ) == 0 { return ErrNoMigrationDefined } return g . migrate ( g . migrations [ len ( g . migrations ) - 1 ] . ID )", "del_tokens": "return g . migrate ( \" \" ) if migrationID == \" \" { return nil }", "commit_type": "remove"}
{"commit_tokens": ["add", "test", "for", "json", "marshaling", "failure", "and", "handle", "it", "more", "gracefully"], "add_tokens": "// We'll log the error (which for our purposes, can't fail), which // gives us an indication we have something to investigate b , _ = json . Marshal ( map [ string ] interface { } { \" \" : time . Now ( ) , \" \" : \" \" , \" \" : Namespace , \" \" : context , \" \" : map [ string ] interface { } { \" \" : err . Error ( ) } , } )", "del_tokens": "// FIXME: not sure what we should do here", "commit_type": "add"}
{"commit_tokens": ["added", "dms", "support", "to", "auth", "sub", "req"], "add_tokens": "// DMSCancelOnDisconnect cancels session orders on disconnect. const DMSCancelOnDisconnect int = 4 s . DMS = DMSCancelOnDisconnect", "del_tokens": "s . DMS = true", "commit_type": "add"}
{"commit_tokens": ["added", "type", "parsing", "and", "pointer", "error", "handling"], "add_tokens": "httpDocumentNode , err := jsonPointer . Get ( dsp . Document ) if err != nil { return err } // type if existsMapKey ( m , \" \" ) && ! isKind ( m [ \" \" ] , reflect . String ) { return errors . New ( fmt . Sprintf ( ERROR_MESSAGE_MUST_BE_OF_TYPE , \" \" , \" \" ) ) } if k , ok := m [ \" \" ] . ( string ) ; ok { currentSchema . etype = & k }", "del_tokens": "httpDocumentNode := jsonPointer . Get ( dsp . Document )", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "to", "Sorcix", ".", "v2", "actually", "fixes", "ISSUE", "-", "43"], "add_tokens": "\" \" bot . Debug ( \" \" , \" \" , scan . Text ( ) , \" \" , msg . To , \" \" , msg . From , \" \" , msg . Params , \" \" , msg . Trailing ( ) ) m . Content = m . Trailing ( ) m . To = m . Trailing ( )", "del_tokens": "\" \" bot . Debug ( \" \" , \" \" , scan . Text ( ) , \" \" , msg . To , \" \" , msg . From , \" \" , msg . Params , \" \" , msg . Trailing ) m . Content = m . Trailing m . To = m . Trailing", "commit_type": "upgrade"}
{"commit_tokens": ["Move", "and", "rename", "delimiter", "and", "comment", "consts", "to", "the", "top"], "add_tokens": "const ( defaultLeftDelim = \" \" defaultRightDelim = \" \" leftComment = \" \" rightComment = \" \" ) leftDelim string rightDelim string name : name , input : input , items : make ( chan item ) , leftDelim : defaultLeftDelim , rightDelim : defaultRightDelim ,", "del_tokens": "name : name , input : input , items : make ( chan item ) , const ( leftDelim = \" \" rightDelim = \" \" leftComment = \" \" rightComment = \" \" )", "commit_type": "move"}
{"commit_tokens": ["Add", "scripts", "to", "test", "all", "dialects"], "add_tokens": "return \" \"", "del_tokens": "return \" \"", "commit_type": "add"}
{"commit_tokens": ["add", "Queue", ".", "Cancel", "support", "untested"], "add_tokens": "ch chan Command // signal channels closed , cancelled , done chan struct { } wg sync . WaitGroup // Cancel closes the Queue and drains the pending commands without processing // them, allowing for a fast \"stop immediately\"-ish operation. func ( q * Queue ) Cancel ( ) error { select { case <- q . cancelled : // already cancelled, no-op return nil default : // mark the queue as cancelled close ( q . cancelled ) // Close the Queue, that will wait for pending commands to drain // will unblock any callers waiting on q.Block return q . Close ( ) } } select { case <- f . q . cancelled : // queue got cancelled, drain continue default : // go on }", "del_tokens": "ch chan Command closed , done chan struct { } wg sync . WaitGroup", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "few", "regular", "expression", "tests"], "add_tokens": "all of which are not supported by Go 's RE2 - like engine : https : //code.google.com/p/re2/wiki/Syntax More information about RE2 : https : //code.google.com/p/re2/", "del_tokens": "all of which are not supported by Go 's re2 - like engine : https : //code.google.com/p/re2/wiki/Syntax", "commit_type": "add"}
{"commit_tokens": ["Fix", "prototype", "property", "being", "read", "-", "only"], "add_tokens": "self . define ( _propertyMode ( propertyModeWrite ) , \" \" , toValue ( prototype ) )", "del_tokens": "self . define ( _propertyMode ( 0 ) , \" \" , toValue ( prototype ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "NEON", "to", "defer", "function"], "add_tokens": "defer func ( sse4 , avx2 , neon bool ) { useSSE4 , useAVX2 , useNEON = sse4 , avx2 , neon } ( useSSE4 , useAVX2 , useNEON )", "del_tokens": "defer func ( sse4 , avx2 bool ) { useSSE4 , useAVX2 = sse4 , avx2 } ( useSSE4 , useAVX2 )", "commit_type": "add"}
{"commit_tokens": ["adds", "newlines", "to", "the", "invalid", "character", "regex", "for", "pages"], "add_tokens": "var invalidCharacterRegex = regexp . MustCompile ( `[\\t\\n\\\"]` )", "del_tokens": "var invalidCharacterRegex = regexp . MustCompile ( \" \\t \\\" \\\\ \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "multiple", "writes", "to", "a", "BodyPart", "overwriting", "previous"], "add_tokens": "* w = append ( * w , p ... )", "del_tokens": "* w = p", "commit_type": "fix"}
{"commit_tokens": ["Allow", "insecure", "/", "http", "registry"], "add_tokens": "func NewImage ( qname , user , password string , insecureTLS , insecureRegistry bool ) ( * Image , error ) { if insecureRegistry { registry = fmt . Sprintf ( \" \" , registry ) } else { registry = fmt . Sprintf ( \" \" , registry ) }", "del_tokens": "func NewImage ( qname , user , password string , insecureTLS bool ) ( * Image , error ) { registry = fmt . Sprintf ( \" \" , registry )", "commit_type": "allow"}
{"commit_tokens": ["Add", "a", "RegisterImage", "()", "function", "that", "adds", "the", "image", "to", "the", "PDF", "but", "not", "the", "page", "."], "add_tokens": "type ImageInfoType struct { // The width of the image in the units of the Fpdf object. func ( info * ImageInfoType ) Width ( f * Fpdf ) float64 { return info . w / f . k } // The height of the image in the units of the Fpdf object. func ( info * ImageInfoType ) Height ( f * Fpdf ) float64 { return info . h / f . k } images map [ string ] * ImageInfoType // array of used images", "del_tokens": "type imageInfoType struct { images map [ string ] imageInfoType // array of used images", "commit_type": "add"}
{"commit_tokens": ["add", "a", "dead", "stupid", "implementation", "of", "WriteFile"], "add_tokens": "// TODO replace with something else when we do MPU for flushing Buf [ ] byte return & FileHandle { Name : in . Name , FullName : in . FullName , Buf : make ( [ ] byte , 0 , 4096 ) } ;", "del_tokens": "return & FileHandle { Name : in . Name , FullName : in . FullName } ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "code", "generator", "initialisation"], "add_tokens": "cl = example . NewExampleClient ( \" \" , nil )", "del_tokens": "cl = example . NewExampleClient ( nil )", "commit_type": "update"}
{"commit_tokens": ["Use", "raw", "literal", "for", "string", "formatting"], "add_tokens": "want : \" \\\" \\\" \" ,", "del_tokens": "want : \" \\\" \\\" \" ,", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "latest", "version", "of", "gosrc", "."], "add_tokens": "if req . URL . Host == \" \" && gitHubCredentials != \" \" { if req . URL . RawQuery == \" \" { req . URL . RawQuery = gitHubCredentials } else { req . URL . RawQuery += \" \" + gitHubCredentials } } if userAgent != \" \" { req . Header . Set ( \" \" , userAgent ) } return t . t . RoundTrip ( req )", "del_tokens": "resp , err := t . t . RoundTrip ( req ) return resp , err", "commit_type": "update"}
{"commit_tokens": ["Removed", "deprecated", "library", "hosted", "in", "google", "code", "in", "favor", "of", "its", "new", "home"], "add_tokens": "\" \" \" \" \" \"", "del_tokens": "\" \" \" \" \" \"", "commit_type": "remove"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", "definitions"], "add_tokens": "DomNodeIndex int64 `json:\"domNodeIndex\"` // The index of the related DOM node in the domNodes array returned by getSnapshot. BoundingBox * dom . Rect `json:\"boundingBox\"` // The absolute position bounding box. LayoutText string `json:\"layoutText,omitempty\"` // Contents of the LayoutText, if any. InlineTextNodes [ ] * InlineTextBox `json:\"inlineTextNodes,omitempty\"` // The post-layout inline text nodes, if any. StyleIndex int64 `json:\"styleIndex,omitempty\"` // Index into the computedStyles array returned by getSnapshot. PaintOrder int64 `json:\"paintOrder,omitempty\"` // Global paint order index, which is determined by the stacking order of the nodes. Nodes that are painted together will have the same index. Only provided if includePaintOrder in getSnapshot was true. IsStackingContext bool `json:\"isStackingContext,omitempty\"` // Set to true to indicate the element begins a new stacking context. NodeIndex [ ] int64 `json:\"nodeIndex\"` // The index of the related DOM node in the domNodes array returned by getSnapshot. Styles [ ] ArrayOfStrings `json:\"styles\"` // Index into the computedStyles array returned by captureSnapshot. Bounds [ ] Rectangle `json:\"bounds\"` // The absolute position bounding box. Text [ ] StringIndex `json:\"text\"` // Contents of the LayoutText, if any. StackingContexts * RareBooleanData `json:\"stackingContexts\"` // Stacking context information.", "del_tokens": "DomNodeIndex int64 `json:\"domNodeIndex\"` // The index of the related DOM node in the domNodes array returned by getSnapshot. BoundingBox * dom . Rect `json:\"boundingBox\"` // The absolute position bounding box. LayoutText string `json:\"layoutText,omitempty\"` // Contents of the LayoutText, if any. InlineTextNodes [ ] * InlineTextBox `json:\"inlineTextNodes,omitempty\"` // The post-layout inline text nodes, if any. StyleIndex int64 `json:\"styleIndex,omitempty\"` // Index into the computedStyles array returned by getSnapshot. PaintOrder int64 `json:\"paintOrder,omitempty\"` // Global paint order index, which is determined by the stacking order of the nodes. Nodes that are painted together will have the same index. Only provided if includePaintOrder in getSnapshot was true. NodeIndex [ ] int64 `json:\"nodeIndex\"` // The index of the related DOM node in the domNodes array returned by getSnapshot. Styles [ ] ArrayOfStrings `json:\"styles\"` // Index into the computedStyles array returned by captureSnapshot. Bounds [ ] Rectangle `json:\"bounds\"` // The absolute position bounding box. Text [ ] StringIndex `json:\"text\"` // Contents of the LayoutText, if any.", "commit_type": "update"}
{"commit_tokens": ["Use", "magic", "fd", "when", "recording", "rsc", "executions", "."], "add_tokens": "fd := os . Stderr f := os . NewFile ( 10 , \" \" ) _ , err := f . Stat ( ) if err == nil { // fd 10 is open, dump to it (used by recorder) fd = f } fmt . Fprintf ( fd , \" \\n \" , string ( b ) )", "del_tokens": "fmt . Fprintf ( os . Stderr , \" \\n \" , string ( b ) )", "commit_type": "use"}
{"commit_tokens": ["added", "IPSANs", "to", "make", "certificates", "work", "for", "us", "now"], "add_tokens": "IPSANs string issueCmd . Flags ( ) . StringVar ( & newIssueFlags . CommonName , \" \" , \" \" , \" \" ) issueCmd . Flags ( ) . StringVar ( & newIssueFlags . IPSANs , \" \" , \" \" , \" \" ) return maskAnyf ( invalidConfigError , \" \" ) } if newIssueFlags . IPSANs == \" \" { return maskAnyf ( invalidConfigError , \" \" ) IPSANs : newIssueFlags . IPSANs ,", "del_tokens": "issueCmd . Flags ( ) . StringVar ( & newIssueFlags . CommonName , \" \" , \" \" , \" \" ) return maskAnyf ( invalidConfigError , \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "apex", "backend"], "add_tokens": "t . Errorf ( \" \" , test . tags , test . json , s )", "del_tokens": "t . Errorf ( \" \" , test . json , s )", "commit_type": "add"}
{"commit_tokens": ["add", "batch", "support", "for", "server"], "add_tokens": "} , nil )", "del_tokens": "} )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "ServerPool", "name", "format", "."], "add_tokens": "Name : fmt . Sprintf ( \" \" , name ) , Name : fmt . Sprintf ( \" \" , name ) ,", "del_tokens": "Name : fmt . Sprintf ( \" \" , name ) , Name : fmt . Sprintf ( \" \" , name ) ,", "commit_type": "fix"}
{"commit_tokens": ["moved", "a", "bunch", "of", "stuff", "around"], "add_tokens": "done := server . Run ( ) err = server . Status ( ) if err != nil { log . Println ( \" \" ) log . Fatal ( err ) }", "del_tokens": "done := make ( chan error ) go func ( ) { done <- server . Run ( ) } ( ) // time.Sleep(3 * time.Second) // status, err := server.Status() // if err != nil { // log.Println(\"Could not get server status\") // log.Fatal(err) // } // if status == nil { // log.Fatalf(\"status was nil\") // }", "commit_type": "move"}
{"commit_tokens": ["Adding", "support", "for", "signing", "using", "IAM", "User", "temporary", "credentials", "."], "add_tokens": "AccessKey : os . Getenv ( \" \" ) , SecretKey : os . Getenv ( \" \" ) ,", "del_tokens": "os . Getenv ( \" \" ) , os . Getenv ( \" \" ) ,", "commit_type": "add"}
{"commit_tokens": ["Use", "map", "[", "string", "]", "interface", "{}", "to", "represent", "events", "coming", "from", "Asterisk"], "add_tokens": "func NewARInGO ( wsUrl , wsOrigin string , evChannel chan map [ string ] interface { } , errChannel chan error , connectAttempts , reconnects int ) ( ari * ARInGO , err error ) { evChannel chan map [ string ] interface { } // Events coming from Asterisk are posted here errChannel chan error // Errors are posted here wsListenerExit chan struct { } // Signal dispatcher to stop listening wsListenerMux * sync . Mutex // Use it to get access to wsListenerExit recreation var ev map [ string ] interface { } if err := websocket . JSON . Receive ( ari . ws , & ev ) ; err != nil { // ToDo: Add reconnects here ari . evChannel <- ev", "del_tokens": "\" \" func NewARInGO ( wsUrl , wsOrigin string , evChannel chan * json . RawMessage , errChannel chan error , connectAttempts , reconnects int ) ( ari * ARInGO , err error ) { evChannel chan * json . RawMessage // Events coming from Asterisk are posted here errChannel chan error // Errors are posted here wsListenerExit chan struct { } // Signal dispatcher to stop listening wsListenerMux * sync . Mutex // Use it to get access to wsListenerExit recreation var data json . RawMessage if err := websocket . JSON . Receive ( ari . ws , & data ) ; err != nil { // ToDo: Add reconnects here ari . evChannel <- & data", "commit_type": "use"}
{"commit_tokens": ["Fix", "slowness", "with", "repetitive", "stars"], "add_tokens": "if pattern == \" \" { return true } for len ( pattern ) > 1 && pattern [ 0 ] == '*' && pattern [ 1 ] == '*' { pattern = pattern [ 1 : ] } if pattern == \" \" { return true } for len ( pattern ) > 1 && pattern [ 0 ] == '*' && pattern [ 1 ] == '*' { pattern = pattern [ 1 : ] }", "del_tokens": "if pattern == \" \" { return true }", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "specify", "a", "custom", "seed", "to", "the", "generator"], "add_tokens": "return GenerateNameWithSeed ( adjectiveAmount , nounAmount , randomNumberPlaces , time . Now ( ) . UnixNano ( ) ) } // GenerateNameWithSeed generates a Random Name with adjectiveAmount Adjectives, nounAmount Nouns and a random Number with randomNumberPlaces places. // The Random Generator uses the specified number as a seed. func GenerateNameWithSeed ( adjectiveAmount int , nounAmount int , randomNumberPlaces int , seed int64 ) ( string , error ) { var nameBuffer bytes . Buffer random = rand . New ( rand . NewSource ( seed ) )", "del_tokens": "var nameBuffer bytes . Buffer", "commit_type": "add"}
{"commit_tokens": ["use", "plain", "bool", "instead", "of", "Control", "in", "ScanCookies"], "add_tokens": "func ScanCookies ( data [ ] byte , validate bool , it func ( key , value [ ] byte ) bool ) bool { if ! it ( key , value ) {", "del_tokens": "func ScanCookies ( data [ ] byte , validate bool , it func ( key , value [ ] byte ) Control ) bool { switch it ( key , value ) { case ControlBreak : case ControlSkip : state = stateKey lexer . Skip ( ';' ) case ControlContinue : // default : panic ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "correct", "data", "path"], "add_tokens": "pathString := * a . DataPath", "del_tokens": "pathString := \" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "post", "(", "project", "user", ")", "support", ".", "Improve", "project"], "add_tokens": "// New initializes a Project struct func ( prj * Project ) New ( id int64 ) error { func ( prj * Project ) GetProjectInfo ( ) * ProjectInfo { var mem [ ] ProjectMember db . Find ( & mem , ProjectMember { Group : prj . Counter } ) var fol [ ] ProjectFollower db . Find ( & fol , ProjectFollower { Group : prj . Counter } )", "del_tokens": "// New initializes a Group struct func ( prj * Group ) New ( id int64 ) error { func ( prj * Group ) GetProjectInfo ( ) * ProjectInfo { var mem [ ] GroupsMember db . Find ( & mem , GroupsMember { Group : prj . Counter } ) var fol [ ] GroupsFollower db . Find ( & fol , GroupsFollower { Group : prj . Counter } )", "commit_type": "add"}
{"commit_tokens": ["Add", "sorting", "options", "to", "tables", "."], "add_tokens": "Columns [ ] column `json:\"columns\"` Sort * struct { Col uint `json:\"col\"` Desc bool `json:\"desc\"` } `json:\"sort,omitempty\"`", "del_tokens": "Columns [ ] column `json:\"columns\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "raff", "/", "godet", "/", "issues", "/", "54", ":", "mispelled", "fulfillRequest"], "add_tokens": "// FulfillRequest provides a response to the request. func ( remote * RemoteDebugger ) FulfillRequest ( requestID string , responseCode int , responsePhrase string , headers map [ string ] string , body [ ] byte ) error { _ , err := remote . SendRequest ( \" \" , params )", "del_tokens": "// FullfillRequest provides a response to the request. func ( remote * RemoteDebugger ) FullfillRequest ( requestID string , responseCode int , responsePhrase string , headers map [ string ] string , body [ ] byte ) error { _ , err := remote . SendRequest ( \" \" , params )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "error", "message", "in", "case", "the", "directory", "to", "clone", "to", "already", "exists"], "add_tokens": "return fmt . Errorf ( \" \" , path )", "del_tokens": "return fmt . Errorf ( \" \" , path )", "commit_type": "improve"}
{"commit_tokens": ["Added", "untested", "Bulletin", "insertion", "logic", "speced", "out", "endorsements"], "add_tokens": "insertBlockHead * sql . Stmt insertBulletin * sql . Stmt insertTag * sql . Stmt insertEndorsement * sql . Stmt", "del_tokens": "insertBlockHead * sql . Stmt", "commit_type": "add"}
{"commit_tokens": ["Use", "setters", "to", "specify", "default", "durations", "instead", "of", "varibales"], "add_tokens": "var defaultEventuallyTimeout = time . Second var defaultEventuallyPollingInterval = 10 * time . Millisecond var defaultConsistentlyDuration = 100 * time . Millisecond var defaultConsistentlyPollingInterval = 10 * time . Millisecond timeoutInterval := defaultEventuallyTimeout pollingInterval := defaultEventuallyPollingInterval timeoutInterval := defaultConsistentlyDuration pollingInterval := defaultConsistentlyPollingInterval //Set the default timeout duration for Eventually. Eventually will repeatedly poll your condition until it succeeds, or until this timeout elapses. func SetDefaultEventuallyTimeout ( t time . Duration ) { defaultEventuallyTimeout = t } //Set the default polling interval for Eventually. func SetDefaultEventuallyPollingInterval ( t time . Duration ) { defaultEventuallyPollingInterval = t } //Set the default duration for Consistently. Consistently will verify that your condition is satsified for this long. func SetDefaultConsistentlyDuration ( t time . Duration ) { defaultConsistentlyDuration = t } //Set the default polling interval for Consistently. func SetDefaultConsistentlyPollingInterval ( t time . Duration ) { defaultConsistentlyPollingInterval = t }", "del_tokens": "//The default timeout duration for Eventually. Eventually will repeatedly poll your condition until it succeeds, or until this timeout elapses. var DefaultEventuallyTimeout = time . Second //The default polling interval for Eventually. var DefaultEventuallyPollingInterval = 10 * time . Millisecond //The default duration for Consistently. Consistently will verify that your condition is satsified for this long. var DefaultConsistentlyDuration = 100 * time . Millisecond //The default polling interval for Consistently. var DefaultConsistentlyPollingInterval = 10 * time . Millisecond timeoutInterval := DefaultEventuallyTimeout pollingInterval := DefaultEventuallyPollingInterval timeoutInterval := DefaultConsistentlyDuration pollingInterval := DefaultConsistentlyPollingInterval", "commit_type": "use"}
{"commit_tokens": ["Add", "shuffling", "of", "the", "array", "of", "host"], "add_tokens": "import \" \" import \" \" rand := rand . New ( rand . NewSource ( time . Now ( ) . Unix ( ) ) ) perm := rand . Perm ( 3 ) suffix := [ 3 ] string { \" \" , \" \" , \" \" } transport . hosts = [ 3 ] string { \" \" + appID + suffix [ perm [ 0 ] ] , \" \" + appID + suffix [ perm [ 1 ] ] , \" \" + appID + suffix [ perm [ 2 ] ] , }", "del_tokens": "transport . hosts = [ 3 ] string { \" \" + appID + \" \" , \" \" + appID + \" \" , \" \" + appID + \" \" , } //TODO Suffle", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "debug", "logs", "(", "requested", "in", "review", ")"], "add_tokens": "// Verify no other Traefik problems", "del_tokens": "// Verify no other Trarfik problems", "commit_type": "remove"}
{"commit_tokens": ["Add", "the", "DevEUI", "to", "the", "lock", "key", "."], "add_tokens": "key := fmt . Sprintf ( \" \" , txPayload . DevEUI , txPayload . Reference )", "del_tokens": "key := fmt . Sprintf ( \" \" , txPayload . Reference )", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "unhandled", "cases", "for", "recursive", "resolution"], "add_tokens": "data := [ ] struct { Ptr string Options [ ] jsref . Option } { { Ptr : \" \" , // \"bar\" } , { Ptr : \" \" , // \"baz\" } , { Ptr : \" \" , // \"quux\" (resolves via `mp`) } , { Ptr : \" \" , // [\"bar\",\"baz\",\"quux\"] // experimental option to resolve all resulting values Options : [ ] jsref . Option { jsref . WithRecursiveResolution ( true ) } , } , for _ , set := range data { result , err := res . Resolve ( v , set . Ptr , set . Options ... ) fmt . Printf ( \" \\n \" , set . Ptr , string ( b ) ) // #/foo -> [\"bar\",\"baz\",\"quux\"]", "del_tokens": "ptrs := [ ] string { \" \" , // \"bar\" \" \" , // \"baz\" \" \" , // \"quux\" (resolves via `mp`) \" \" , // contents of foo key for _ , ptr := range ptrs { result , err := res . Resolve ( v , ptr ) fmt . Printf ( \" \\n \" , ptr , string ( b ) ) // #/foo -> [\"bar\",{\"$ref\":\"#/sub\"},{\"$ref\":\"obj2#/sub\"}]", "commit_type": "fix"}
{"commit_tokens": ["added", "authentication", "support", "and", "default", "localisation", "(", "en", ")", "usage"], "add_tokens": "\" \" \" \" \" \" \" \" DatabaseHosts [ ] string DatabaseName string DatabaseUser string DatabasePassword string Locals map [ string ] string if _ , filename , _ , ok := runtime . Caller ( 0 ) ; ok { filepath := path . Join ( path . Dir ( filename ) , \" \" ) file , err := ioutil . ReadFile ( filepath ) if err != nil { return nil , err } var localMap map [ string ] map [ string ] string json . Unmarshal ( file , & localMap ) locals = localMap [ \" \" ] } else { panic ( \" \" ) } info := & mgo . DialInfo { Addrs : self . Config . DatabaseHosts , Timeout : 3 * time . Second , Database : self . Config . DatabaseName , Username : self . Config . DatabaseUser , Password : self . Config . DatabasePassword , } session , err := mgo . DialWithInfo ( info )", "del_tokens": "DatabaseHost string DatabaseName string Locals map [ string ] string panic ( \" \" ) session , err := mgo . Dial ( self . Config . DatabaseHost )", "commit_type": "add"}
{"commit_tokens": ["Fix", "golint", "suggestions", "and", "add", "gometalinter", "to", "CI"], "add_tokens": "// Snapshotter is the API for taking snapshots of values in your tests. SnapshotMulti ( snapshotID string , i ... interface { } ) error func SnapshotMulti ( snapshotID string , i ... interface { } ) error { snapshotName := fmt . Sprintf ( \" \" , getNameOfCaller ( ) , snapshotID ) func ( c * config ) SnapshotMulti ( snapshotID string , i ... interface { } ) error { snapshotName := fmt . Sprintf ( \" \" , getNameOfCaller ( ) , snapshotID ) return fmt . Errorf ( \" \\n \" , diff )", "del_tokens": "SnapshotMulti ( snapshotId string , i ... interface { } ) error func SnapshotMulti ( snapshotId string , i ... interface { } ) error { snapshotName := fmt . Sprintf ( \" \" , getNameOfCaller ( ) , snapshotId ) func ( c * config ) SnapshotMulti ( snapshotId string , i ... interface { } ) error { snapshotName := fmt . Sprintf ( \" \" , getNameOfCaller ( ) , snapshotId ) return fmt . Errorf ( \" \\n \\n \" , diff )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "sending", "files", "by", "url", "."], "add_tokens": "\" \" \" \" photo = tgbotapi . PhotoConfig { BaseFile : fileMessage ( m , photo . BaseFile ) } msg := tgbotapi . NewAudioUpload ( m . ChatID , m . Data ) msg = tgbotapi . AudioConfig { BaseFile : fileMessage ( m , msg . BaseFile ) } msg := tgbotapi . NewDocumentUpload ( m . ChatID , nil ) msg = tgbotapi . DocumentConfig { BaseFile : fileMessage ( m , msg . BaseFile ) } return msg func fileMessage ( m * model . Message , file tgbotapi . BaseFile ) tgbotapi . BaseFile { if strings . HasPrefix ( m . Data , \" \" ) { _ , err := url . Parse ( m . Data ) if err != nil { return file } file . FileID = m . Data file . UseExisting = true return file } return file }", "del_tokens": "return tgbotapi . NewAudioUpload ( m . ChatID , m . Data ) return tgbotapi . NewDocumentUpload ( m . ChatID , m . Data )", "commit_type": "add"}
{"commit_tokens": ["Use", "cmd", ".", "Wait", "in", "monitor"], "add_tokens": "if err := c . Wait ( ) ; err != nil { if exitErr , ok := err . ( * exec . ExitError ) ; ok { if status , ok := exitErr . Sys ( ) . ( syscall . WaitStatus ) ; ok { return status . ExitStatus ( ) , nil } } return 0 , nil", "del_tokens": "status , err := c . Process . Wait ( ) if err != nil { return status . Sys ( ) . ( syscall . WaitStatus ) . ExitStatus ( ) , nil", "commit_type": "use"}
{"commit_tokens": ["Removes", "unnecessary", "buffer", "spotted", "by", "@bradfitz"], "add_tokens": "data , err := ioutil . ReadAll ( r ) memReader := bytes . NewReader ( data ) zr , err := zip . NewReader ( memReader , int64 ( len ( data ) ) )", "del_tokens": "memoryBuffer := new ( bytes . Buffer ) _ , err := io . Copy ( memoryBuffer , r ) memReader := bytes . NewReader ( memoryBuffer . Bytes ( ) ) zr , err := zip . NewReader ( memReader , int64 ( memoryBuffer . Len ( ) ) )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "marking", "keys", "as", "used"], "add_tokens": "\" \" scriptAddress , _ := ts . extractScriptAddress ( txout . PkScript ) ts . keyManager . MarkKeyAsUsed ( scriptAddress ) func ( ts * TxStore ) extractScriptAddress ( script [ ] byte ) ( [ ] byte , error ) { _ , addrs , _ , err := txscript . ExtractPkScriptAddrs ( script , ts . params ) if err != nil { return nil , err } if len ( addrs ) == 0 { return nil , errors . New ( \" \" ) } return addrs [ 0 ] . ScriptAddress ( ) , nil }", "del_tokens": "ts . keyManager . MarkKeyAsUsed ( txout . PkScript )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "where", "the", "ValidMoves", "method", "didn", "t", "find", "castling"], "add_tokens": "m := & Move { s1 : s1 , s2 : s2 , state : gs }", "del_tokens": "m := & Move { s1 : s1 , s2 : s2 , state : & GameState { board : gs . board , turn : gs . turn } }", "commit_type": "fix"}
{"commit_tokens": ["use", "handlers", "instead", "of", "channels"], "add_tokens": "import \" \" var s string h := New ( ) h . Subscribe ( testKind , func ( e Event ) { s = string ( e . ( testEvent ) ) } ) h . Publish ( testEvent ( testValue ) ) if s != testValue { t . Errorf ( \" \" , s )", "del_tokens": "import ( \" \" \" \" ) h := New ( ) c := h . Subscribe ( testKind ) go func ( ) { h . Publish ( testEvent ( testValue ) ) } ( ) select { case received := <- c : if received . ( testEvent ) != testValue { t . Errorf ( \" \" , received ) } case <- time . After ( time . Second ) : t . Error ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "template", "icons", "on", "macOS"], "add_tokens": "systray . SetTemplateIcon ( icon . Data , icon . Data ) systray . SetTemplateIcon ( icon . Data , icon . Data ) // Sets the icon of a menu item. Only available on Mac. mEnabled . SetTemplateIcon ( icon . Data , icon . Data )", "del_tokens": "systray . SetIcon ( icon . Data ) systray . SetIcon ( icon . Data )", "commit_type": "add"}
{"commit_tokens": ["Add", "hyphen", "to", "allowed", "characters", "for", "dimension", "keys"], "add_tokens": "if unicode . IsDigit ( r ) || unicode . IsLetter ( r ) || r == '_' || r == '-' {", "del_tokens": "if unicode . IsDigit ( r ) || unicode . IsLetter ( r ) || r == '_' {", "commit_type": "add"}
{"commit_tokens": ["Fix", "fetching", "when", "metrics", "are", "disabled"], "add_tokens": "if pc . config . EnableMetrics { pc . metrics . FetchDuration ( func ( fetchDuration metrics . Timer ) { fetchDuration . Time ( func ( ) { response , err = pc . client . Fetch ( pc . topic , pc . partition , atomic . LoadInt64 ( & pc . offset ) ) } ) } else { response , err = pc . client . Fetch ( pc . topic , pc . partition , atomic . LoadInt64 ( & pc . offset ) ) }", "del_tokens": "pc . metrics . FetchDuration ( func ( fetchDuration metrics . Timer ) { fetchDuration . Time ( func ( ) { response , err = pc . client . Fetch ( pc . topic , pc . partition , atomic . LoadInt64 ( & pc . offset ) ) } )", "commit_type": "fix"}
{"commit_tokens": ["Make", "it", "clear", "that", "binary", "-", "prefixed", "and", "SI", "prefixed", "units", "are", "treated", "the", "same"], "add_tokens": "var invalidByteQuantityError = errors . New ( \" \" ) // ToBytes parses a string formatted by ByteSize as bytes. Note binary-prefixed and SI prefixed units both mean a base-2 units // KB = K = KiB = 1024 // MB = M = MiB = 1024 * K // GB = G = GiB = 1024 * M // TB = T = TiB = 1024 * G", "del_tokens": "var invalidByteQuantityError = errors . New ( \" \" ) // ToBytes parses a string formatted by ByteSize as bytes.", "commit_type": "make"}
{"commit_tokens": ["remove", "error", "on", "fullname", "creation", "since", "this", "cannot", "happen"], "add_tokens": "nn := NewACFullName ( s ) func NewACFullName ( s string ) * ACFullname { return & n return NewACFullName ( n . Name ( ) + \" \" + version ) , nil", "del_tokens": "nn , err := NewACFullName ( s ) if err != nil { return errors . Annotate ( err , \" \" + s ) } func NewACFullName ( s string ) ( * ACFullname , error ) { return & n , nil return NewACFullName ( n . Name ( ) + \" \" + version )", "commit_type": "remove"}
{"commit_tokens": ["fix", "some", "golint", "warning", "."], "add_tokens": "// HTTPResponse is basic HTTP response type type HTTPResponse * httptest . ResponseRecorder // HTTPRequest is basic HTTP request type type HTTPRequest * http . Request // EchoHTTPResponse is HTTP response type for echo framework type EchoHTTPResponse * test . ResponseRecorder // EchoHTTPRequest is HTTP request type for echo framework type EchoHTTPRequest engine . Request // ResponseFunc response handling func type type ResponseFunc func ( HTTPResponse , HTTPRequest ) // EchoResponseFunc response handling func type for echo framework type EchoResponseFunc func ( EchoHTTPResponse , EchoHTTPRequest ) // H is HTTP Header Type // D is HTTP Data Type // RequestConfig provide user input request structure // TestRequest is testing url string if server is running", "del_tokens": "// Gin http request and response type HttpResponse * httptest . ResponseRecorder type HttpRequest * http . Request // Echo http request and response type EchoHttpResponse * test . ResponseRecorder type EchoHttpRequest engine . Request // response handling func type type ResponseFunc func ( HttpResponse , HttpRequest ) // echo response handling func type type EchoResponseFunc func ( EchoHttpResponse , EchoHttpRequest ) // Request Header type", "commit_type": "fix"}
{"commit_tokens": ["Use", "go", "-", "kit", "logger", "interface"], "add_tokens": "Log ( keyvals ... interface { } ) error h . l . Log ( \" \" , \" \" , \" \" , err , )", "del_tokens": "Error ( args ... interface { } ) h . l . Error ( err )", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "new", "iris", "API"], "add_tokens": "\" \" : c . FormValueString ( \" \" ) , \" \" : c . FormValueString ( \" \" ) ,", "del_tokens": "\" \" : c . PostFormValue ( \" \" ) , \" \" : c . PostFormValue ( \" \" ) ,", "commit_type": "update"}
{"commit_tokens": ["added", "support", "for", "csv", "file", "output", "on", "soql"], "add_tokens": "format := \" \" formatArg := args [ len ( args ) - 1 ] if strings . Contains ( formatArg , \" \" ) { args = args [ : len ( args ) - 1 ] format = strings . SplitN ( formatArg , \" \" , 2 ) [ 1 ] } if format == \" \" { DisplayForceRecords ( records ) } else { DisplayForceRecordsf ( records , format ) }", "del_tokens": "DisplayForceRecords ( records )", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "clear", "screen", "."], "add_tokens": "return func ( args ... string ) ( string , error ) { return func ( args ... string ) ( string , error ) { func clearFunc ( s * Shell ) CmdFunc { return func ( args ... string ) ( string , error ) { err := s . ClearScreen ( ) return \" \" , err } } s . Register ( \" \" , clearFunc ( s ) )", "del_tokens": "return func ( args ... string ) ( output string , err error ) { return func ( args ... string ) ( output string , err error ) {", "commit_type": "add"}
{"commit_tokens": ["Moved", "100%", "of", "arg", "parsing", "to", "dockerd", ".", "Even", "help", "messages", "are", "generated", "on", "the", "server"], "add_tokens": "if len ( os . Args ) >= 2 { cmd = os . Args [ 1 ] if len ( os . Args ) >= 3 { args = os . Args [ 2 : ]", "del_tokens": "\" \" flag . Parse ( ) if len ( flag . Args ( ) ) >= 1 { cmd = flag . Args ( ) [ 0 ] if len ( flag . Args ( ) ) >= 2 { args = flag . Args ( ) [ 1 : ]", "commit_type": "move"}
{"commit_tokens": ["use", "float32", "for", "Midicps", "argument"], "add_tokens": "func Midicps ( note float32 ) float32 {", "del_tokens": "func Midicps ( note int ) float32 {", "commit_type": "use"}
{"commit_tokens": ["Uses", "the", "system", "version", "of", "liblinear"], "add_tokens": "# cgo CFLAGS : c_y := make ( [ ] C . int , len ( y ) ) c_y [ i ] = C . int ( y [ i ] )", "del_tokens": "# cgo CFLAGS : - I . . / ext / liblinear_src L2R_L2LOSS_SVR = C . L2R_L2LOSS_SVR L2R_L2LOSS_SVR_DUAL = C . L2R_L2LOSS_SVR_DUAL L2R_L1LOSS_SVR_DUAL = C . L2R_L1LOSS_SVR_DUAL param . c_param . p = C . double ( 0.1 ) c_y := make ( [ ] C . double , len ( y ) ) c_y [ i ] = C . double ( y [ i ] )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ContentLanguage : \" \" , ExpectEq ( \" \" , o . ContentLanguage )", "del_tokens": "ContentLanguage : \" \" , ExpectEq ( \" \" , o . ContentLanguage )", "commit_type": "fix"}
{"commit_tokens": ["added", "the", "ability", "not", "to", "search", "the", "certificate", "in", "the", "configuration", "file"], "add_tokens": "out , err := testEMT . ParseConfig ( samplesPath + conf . EptTest . ConfValidCaValid , true )", "del_tokens": "out , err := testEMT . ParseConfig ( samplesPath + conf . EptTest . ConfValidCaValid )", "commit_type": "add"}
{"commit_tokens": ["changed", "the", "syntax", "for", "read", "/", "write", "on", "columns"], "add_tokens": "if xs [ 1 ] == \" \" { if xs [ 1 ] == \" \" { func ColumnsForStruct ( s interface { } ) ( columns Columns ) { columns = NewColumns ( ) defer func ( ) { if r := recover ( ) ; r != nil { columns = NewColumns ( ) columns . Add ( \" \" ) } } ( ) rw := field . Tag . Get ( \" \" ) if rw != \" \" { tag = tag + \" \" + rw }", "del_tokens": "\" \" if xs [ 1 ] == \" \" { if xs [ 1 ] == \" \" { func ColumnsForStruct ( s interface { } ) Columns { columns := NewColumns ( ) log . Printf ( \" \\n \" , tag )", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "testing", "for", "TokenStore"], "add_tokens": "if err := ts . SetValueDuration ( \" \" , time . Second ) ; err == nil { t . Error ( \" \" ) } ts . NewValue ( time . Now ( ) . Format ( time . RFC3339Nano ) , time . Now ( ) )", "del_tokens": "ts . NewValue ( time . Now ( ) . Format ( time . ANSIC ) , time . Now ( ) )", "commit_type": "add"}
{"commit_tokens": ["remove", "connMutex", "for", "another", "approach"], "add_tokens": "// Disconn registers a function to handle client disconnection. func ( s * Server ) Disconn ( handler func ( conn * Conn ) ) { }", "del_tokens": "connMutex sync . Mutex s . connMutex . Lock ( ) s . connMutex . Unlock ( ) s . connMutex . Lock ( ) s . connMutex . Unlock ( ) s . connMutex . Lock ( ) s . connMutex . Unlock ( )", "commit_type": "remove"}
{"commit_tokens": ["Add", "file", "-", "fetch", "file", "write", "and", "rate", "limiter", "logging", "."], "add_tokens": "rateLimiter , err := c . acquireLimiter ( logger , cacheKey , cancelChan ) rateLimiter , err := c . acquireLimiter ( logger , cacheKey , cancelChan ) func ( c * cachedDownloader ) acquireLimiter ( logger lager . Logger , cacheKey string , cancelChan <- chan struct { } ) ( chan struct { } , error ) { logger = logger . Session ( \" \" ) logger . Info ( \" \" ) defer logger . Info ( \" \" , lager . Data { \" \" : time . Now ( ) . Sub ( startTime ) } )", "del_tokens": "rateLimiter , err := c . acquireLimiter ( cacheKey , cancelChan ) rateLimiter , err := c . acquireLimiter ( cacheKey , cancelChan ) func ( c * cachedDownloader ) acquireLimiter ( cacheKey string , cancelChan <- chan struct { } ) ( chan struct { } , error ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "Content", "-", "Type", "/", "Accept", "headers"], "add_tokens": "if mediatype != \" \" {", "del_tokens": "if mediatype != \" \" {", "commit_type": "fix"}
{"commit_tokens": ["Make", "default", "time", "format", "compliant", "with", "ISO", "8601"], "add_tokens": "TIMEFORMAT = \" \"", "del_tokens": "TIMEFORMAT = \" \"", "commit_type": "make"}
{"commit_tokens": ["Add", "more", "driver", "tests", "and", "godep", "change"], "add_tokens": "\" \" for i := 0 ; i < 3 ; i ++ { log . Errorf ( \" \" , servAddr , portNo ) return nil , nil // Check if connectin failed if self . client == nil { log . Errorf ( \" \" , serviceMethod ) return errors . New ( \" \" ) } // Perform RPC call.", "del_tokens": "for i := 0 ; i < 10 ; i ++ { log . Fatalf ( \" \" , servAddr , portNo ) // FIXME: handle disconnects", "commit_type": "add"}
{"commit_tokens": ["Add", "MAC", "for", "stored", "files", ".", "Backwards", "incompatible", "needs", "wipe", "of", ".", "storage", "and", "reregistering"], "add_tokens": "\" \" e , err := aesEncrypt ( s . aesKey , plaintext ) if err != nil { return nil , err } return appendMAC ( s . macKey , e ) , nil macPos := len ( ciphertext ) - 32 if ! verifyMAC ( s . macKey , ciphertext [ : macPos ] , ciphertext [ macPos : ] ) { return nil , errors . New ( \" \" ) } return aesDecrypt ( s . aesKey , ciphertext [ : macPos ] )", "del_tokens": "return aesEncrypt ( s . aesKey , plaintext ) return aesDecrypt ( s . aesKey , ciphertext )", "commit_type": "add"}
{"commit_tokens": ["Use", "contextualized", "and", "traced", "errors", "in", "reader"], "add_tokens": "go func ( ) { if err := s . persist ( ) ; err != nil { s . logger . Log ( \" \" , \" \" , \" \" , err ) } } ( )", "del_tokens": "go s . persist ( )", "commit_type": "use"}
{"commit_tokens": ["fixed", "the", "example", "compile", "error"], "add_tokens": "f5 := bigip . NewSession ( \" \" , \" \" , \" \" , nil )", "del_tokens": "f5 := bigip . NewSession ( \" \" , \" \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["add", "explicit", "log", "level", "calls"], "add_tokens": "// Debug log formatted // Log at info level func Info ( v ... interface { } ) { if LogLevel >= 4 { DoLog ( 3 , INFO , fmt . Sprint ( v ... ) ) } } // info log formatted func Infof ( format string , v ... interface { } ) { if LogLevel >= 4 { DoLog ( 3 , INFO , fmt . Sprintf ( format , v ... ) ) } } // Log at warn level func Warn ( v ... interface { } ) { if LogLevel >= 4 { DoLog ( 3 , WARN , fmt . Sprint ( v ... ) ) } } // Debug log formatted func Warnf ( format string , v ... interface { } ) { if LogLevel >= 4 { DoLog ( 3 , WARN , fmt . Sprintf ( format , v ... ) ) } } // Log at error level func Error ( v ... interface { } ) { if LogLevel >= 4 { DoLog ( 3 , ERROR , fmt . Sprint ( v ... ) ) } } // Error log formatted func Errorf ( format string , v ... interface { } ) { if LogLevel >= 4 { DoLog ( 3 , ERROR , fmt . Sprintf ( format , v ... ) ) } }", "del_tokens": "//", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "to", "request", "to", "apply", "signature"], "add_tokens": "func TestRequestSend ( t * testing . T ) {", "del_tokens": "func TestRequest_Send ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "typos", "in", "documentation", "."], "add_tokens": "// ListenAndServeTLS works like net/http.Server.ListenAndServeTLS except // Serve works like net/http.Server.Serve except that it gracefully", "del_tokens": "// ListenAndServe works like net/http.Server.ListenAndServeTLS except // Server works like net/http.Server.Serve except that it gracefully", "commit_type": "fix"}
{"commit_tokens": ["Changed", "signatures", "of", "Find", "and", "List"], "add_tokens": "func ( c * Client ) Find ( typ , what string , args ... string ) ( [ ] Attrs , error ) { id , err := c . cmd ( \" \" + quote ( typ ) + \" \" + quote ( what ) + \" \" + quoteArgs ( args ) ) func ( c * Client ) List ( typ ... string ) ( [ ] string , error ) { id , err := c . cmd ( \" \" + quoteArgs ( typ ) )", "del_tokens": "func ( c * Client ) Find ( uri [ ] string ) ( [ ] Attrs , error ) { id , err := c . cmd ( \" \" + quoteArgs ( uri ) ) func ( c * Client ) List ( uri [ ] string ) ( [ ] string , error ) { id , err := c . cmd ( \" \" + quoteArgs ( uri ) )", "commit_type": "change"}
{"commit_tokens": ["fix", "a", "bug", "when", "dec", "reach", "to", "the", "end", "with", "an", "open", "\\"], "add_tokens": "for ; j < dec . length || dec . read ( ) ; j ++ {", "del_tokens": "for ; j < dec . length ; j ++ {", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "Timestamp", "type", "name", "in", "cookie", "example"], "add_tokens": "expr := cdptypes . TimeSinceEpoch ( time . Now ( ) . Add ( 180 * 24 * time . Hour ) )", "del_tokens": "expr := cdptypes . Timestamp ( time . Now ( ) . Add ( 180 * 24 * time . Hour ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "custom", "http", ".", "Client", "as", "default", "client", "not", "http", ".", "DefaultClient"], "add_tokens": "\" \" ) const ( baseURL = \" \" clientTimeout = time . Second * 30 return & Twilio { accountSid , authToken , baseURL , HTTPClient } return twilio . do ( req ) return twilio . do ( req ) return twilio . do ( req ) } func ( twilio * Twilio ) do ( req * http . Request ) ( * http . Response , error ) { client = defaultClient ( ) func defaultClient ( ) * http . Client { client := http . Client { Timeout : clientTimeout , } return & client }", "del_tokens": "twilioUrl := \" \" // Should this be moved into a constant? if HTTPClient == nil { HTTPClient = http . DefaultClient } return & Twilio { accountSid , authToken , twilioUrl , HTTPClient } client := twilio . HTTPClient if client == nil { client = http . DefaultClient } return client . Do ( req ) client := twilio . HTTPClient if client == nil { client = http . DefaultClient } return client . Do ( req ) client = http . DefaultClient", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "DVD", "ISO", "data", "type", "and", "tests"], "add_tokens": "OsFamily string `json:\"os_family,omitempty\"` Os string `json:\"os,omitempty\"` OsVersion string `json:\"os_version,omitempty\"` Type string `json:\"type,omitempty\"` AvailableDatacenters [ ] string `json:\"available_datacenters,omitempty\"` Architecture interface { } `json:\"os_architecture,omitempty\"`", "del_tokens": "OsFamily string `json:\"os_family,omitempty\"` Os string `json:\"os,omitempty\"` OsVersion string `json:\"os_version,omitempty\"` Type string `json:\"type,omitempty\"` AvailableSites [ ] string `json:\"available_sites,omitempty\"` Architecture interface { } `json:\"architecture\"`", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "error", "to", "log", "message", "for", "no", "body"], "add_tokens": "log \" \" log . Infof ( \" \" , c . UUID ) return nil", "del_tokens": "return requestError { fmt . Sprintf ( \" \" , c . UUID ) } type requestError struct { details string } func ( re requestError ) Error ( ) string { return \" \" } func ( re requestError ) NoContentReturnedDetails ( ) string { return re . details }", "commit_type": "change"}
{"commit_tokens": ["Add", "stream", "behind", "request", "/", "response", "types", "of", "streaming", "RPCs", "in", "templates"], "add_tokens": "\" \" : \" \" , \" \" : \" \" , \" \" : \" \" ,", "del_tokens": "\" \" : \" \" , \" \" : \" \" , \" \" : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "hook", "for", "extending", "PongHandler"], "add_tokens": "func ( s * Session ) SetPongHandler ( f func ( ) error ) { s . conn . SetPongHandler ( func ( string ) error { s . conn . SetReadDeadline ( time . Now ( ) . Add ( s . melody . Config . PongWait ) ) return f ( ) } ) } s . SetPongHandler ( func ( ) error {", "del_tokens": "s . conn . SetPongHandler ( func ( string ) error { s . conn . SetReadDeadline ( time . Now ( ) . Add ( s . melody . Config . PongWait ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "notifications", "on", "debt", "added", "/", "removed", "."], "add_tokens": "eventqueue . Publish ( utils . CKPTEvent { Type : utils . PLAYER_EVENT , RestrictedTo : [ ] uuid . UUID { p . UUID } , Subject : \" \" , Message : \" } ) func ( p * Player ) SettleDebt ( debtuuid uuid . UUID ) error { if debt . UUID == debtuuid { eventqueue . Publish ( utils . CKPTEvent { Type : utils . PLAYER_EVENT , RestrictedTo : [ ] uuid . UUID { p . UUID } , Subject : \" \" , Message : \" )", "del_tokens": "func ( p * Player ) SettleDebt ( uuid uuid . UUID ) error { if debt . UUID == uuid {", "commit_type": "add"}
{"commit_tokens": ["Use", "go", "-", "utils", "backoff", "package"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["make", "golint", "happy", "with", "godoc", "comments"], "add_tokens": "// Command is the core struct for hystrix execution. It represents both the // happy path and fallback when accessing remote systems, as well as result delivery. Run func ( chan Result ) Fallback func ( error , chan Result ) // BUG(keith): all commands share the same executor pool, instead of being grouped by name // NewCommand maps the given run and fallback functions with result channels and an executor pool func NewCommand ( run func ( chan Result ) , fallback func ( error , chan Result ) ) * Command { // Execute runs the command synchronously, blocking until the result (or fallback) is returned // Queue runs the command asynchronously, immediately returning a channel which the result (or fallback) will be sent to.", "del_tokens": "Run RunFunc Fallback FallbackFunc Observer ObserverFunc func NewCommand ( run RunFunc , fallback FallbackFunc ) * Command {", "commit_type": "make"}
{"commit_tokens": ["Add", "--", "wait", "to", "argo", "submit", "."], "add_tokens": "submitCmd . Flags ( ) . BoolVarP ( & submitArgs . wait , \" \" , \" \" , false , \" \" ) wait bool // --wait var workflowNames [ ] string wfName , err := submitWorkflow ( & wf ) workflowNames = append ( workflowNames , wfName ) if submitArgs . wait { wsp := NewWorkflowStatusPoller ( wfClient , false , submitArgs . output == \" \" ) wsp . WaitWorkflows ( workflowNames ) } func submitWorkflow ( wf * wfv1 . Workflow ) ( string , error ) { return \" \" , err return \" \" , err return created . Name , nil", "del_tokens": "err = submitWorkflow ( & wf ) func submitWorkflow ( wf * wfv1 . Workflow ) error { return err return err return nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "handling", "of", "IntRange", "representation", "in", "dot", "files"], "add_tokens": "c := fmt . Sprintf ( \" \\\" \\\\ \\\\ \\\" \" , id , n . Elem , n . Range . Start , n . Range . End , n . Elem . ID ( ) )", "del_tokens": "c := fmt . Sprintf ( \" \\\" \\\\ \\\\ \\\" \" , id , n . Elem , n . Range , n . Elem . ID ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "various", "ranking", "code", "to", "ensure", "correct", "and", "consistant", "results", "with", "sensible", "tie", "breaks", "."], "add_tokens": "w . Write ( [ ] byte ( \" \" + err . Error ( ) ) )", "del_tokens": "w . Write ( [ ] byte ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["fix", "Error", "to", "rm", "container", ":", "Conflict", "cannot", "remove", "the", "default", "name", "of", "the", "container"], "add_tokens": "RemoveLink : false ,", "del_tokens": "RemoveLink : true ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "better", "example", "of", "aliasing", "with", "identifier", "."], "add_tokens": "sql , _ , _ = db . From ( \" \" ) . Select ( goqu . I ( \" \" ) . As ( goqu . I ( \" \" ) ) ) . ToSql ( ) // SELECT \"a\" AS \"as_a\" FROM \"test\"", "del_tokens": "sql , _ , _ = db . From ( \" \" ) . Select ( goqu . I ( \" \" ) . As ( goqu . I ( \" \" ) ) ) . ToSql ( ) // SELECT \"test\".\"a\" AS \"test\".\"b\" FROM \"test\"", "commit_type": "use"}
{"commit_tokens": ["make", "cbioFree", "not", "a", "go", "callback"], "add_tokens": "static int cbioFree ( BIO * b ) { return 1 ; }", "del_tokens": "extern int cbioFree ( BIO * b ) ; //export cbioFree func cbioFree ( b * C . BIO ) C . int { return 1 }", "commit_type": "make"}
{"commit_tokens": ["add", "Insightly", "Api", "Time", "formats"], "add_tokens": "InsightlyApiQuery = \" \" InsightlyApiObject = \" \" ISO8601CompactZ = \" \" ISO8601CompactLocal = \" \"", "del_tokens": "ISO8601ZCompact = \" \" ISO8601CompactLocal = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "PUB", "/", "SUB", ".", "Verified", "working", "now", ".", "Also", "added", "a", "self", "test", "for", "it", "."], "add_tokens": "\" \" if bytes . HasPrefix ( m . Body , e . Value . ( [ ] byte ) ) { var vb [ ] byte case [ ] byte : vb = value . ( [ ] byte ) if bytes . Equal ( e . Value . ( [ ] byte ) , vb ) { p . subs . PushBack ( vb ) if bytes . Equal ( e . Value . ( [ ] byte ) , vb ) {", "del_tokens": "\" \" if strings . HasPrefix ( string ( m . Body ) , e . Value . ( string ) ) { var vstr string case string : vstr = value . ( string ) if e . Value . ( string ) == vstr { p . subs . PushBack ( vstr ) if e . Value . ( string ) == vstr {", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "more", "documentation", "."], "add_tokens": "// // Each method that may block accepts a context object that is used for // deadlines and cancellation. Users need not package authorization information // into the context object (using cloud.WithContext or similar). // List the objects in the bucket that meet the criteria defined by the // query, returning a result object that contains the results and potentially // a cursor for retrieving the next portion of the larger set of results.", "del_tokens": "// ListObjects lists objects in the bucket that meet certain criteria.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "equals", "methods", "added", "tests"], "add_tokens": "if ! checkType ( t , e ) { return & Vector { t , el } , nil", "del_tokens": "v . typ = t if ! checkType ( v . typ , e ) { v . dat = el return v , nil", "commit_type": "fix"}
{"commit_tokens": ["Use", "net", ".", "SplitHostPort", "to", "get", "request", "IP"], "add_tokens": "ip , _ , err := net . SplitHostPort ( r . RemoteAddr ) if err != nil { ip = r . RemoteAddr } if i := net . ParseIP ( ip ) ; i != nil { ips = [ ] net . IP { i }", "del_tokens": "idx := strings . LastIndex ( r . RemoteAddr , \" \" ) if idx == - 1 { if i := net . ParseIP ( r . RemoteAddr ) ; i != nil { ips = [ ] net . IP { i } } } else { if i := net . ParseIP ( r . RemoteAddr [ : idx ] ) ; i != nil { ips = [ ] net . IP { i } }", "commit_type": "use"}
{"commit_tokens": ["Fixing", "minor", "issue", "with", "Firebird", "DSNs"], "add_tokens": "return strings . TrimPrefix ( z . String ( ) , \" \" ) , nil", "del_tokens": "return z . String ( ) , nil", "commit_type": "fix"}
{"commit_tokens": ["Make", "it", "possible", "to", "specify", "what", "timezone", "to", "parse", "timestamps", "in"], "add_tokens": "// Timezone that the server is in Location * time . Location Location : time . UTC , entry , err := parser ( scanner . Text ( ) , now , c . Location )", "del_tokens": "entry , err := parser ( scanner . Text ( ) , now )", "commit_type": "make"}
{"commit_tokens": ["Remove", "robots", ".", "txt", "we", "don", "t", "need", "it", "atm"], "add_tokens": "w . Header ( ) . Add ( cacheControl , fmt . Sprintf ( \" \" , maxAgeSeconds ) )", "del_tokens": "serveAsset ( \" \" , \" \" , nocache ) nocache = - 1 if maxAgeSeconds != nocache { w . Header ( ) . Add ( cacheControl , fmt . Sprintf ( \" \" , maxAgeSeconds ) ) }", "commit_type": "remove"}
{"commit_tokens": ["change", "to", "a", "streaming", "interface"], "add_tokens": "lexer := NewLexerFromStream ( bufio . NewReader ( os . Stdin ) ) expressions , err := ParseTokens ( lexer )", "del_tokens": "tokens , err := LexStream ( bufio . NewReader ( os . Stdin ) ) expressions , err := ParseTokens ( tokens ) if err != nil { fmt . Println ( err ) os . Exit ( - 1 ) } fmt . Println ( tokens )", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "_count", "and", "_offset", "parameters"], "add_tokens": "// corresponding mgo.Query. The returned mgo.Query will obey any options // passed in through the query string (such as _count and _offset) and will // also use default options when none are passed in (e.g., count = 100). // The caller is responsible for executing the returned query (allowing // additional flexibility in how results are returned). return m . createQuery ( query , true ) } // CreateQueryWithoutOptions takes a FHIR-based Query and returns a pointer to // the corresponding mgo.Query. Any options passed in through the query (such // as _count and _offset) are ignored and no default options are applied (e.g., // there is no set count / limit) The caller is responsible for executing // the returned query (allowing flexibility in how results are returned). func ( m * MongoSearcher ) CreateQueryWithoutOptions ( query Query ) * mgo . Query { return m . createQuery ( query , false ) } func ( m * MongoSearcher ) createQuery ( query Query , withOptions bool ) * mgo . Query { q := m . createQueryObject ( query ) mgoQuery := c . Find ( q ) if withOptions { o := query . Options ( ) if o . Offset > 0 { mgoQuery = mgoQuery . Skip ( o . Offset ) } mgoQuery = mgoQuery . Limit ( o . Count ) } return mgoQuery q := m . CreateQueryWithoutOptions ( ref . ChainedQuery )", "del_tokens": "// corresponding mgo.Query. The caller is responsible for executing // the returned query (allowing flexibility in how results are returned). o := m . createQueryObject ( query ) return c . Find ( o ) q := m . CreateQuery ( ref . ChainedQuery )", "commit_type": "add"}
{"commit_tokens": ["Allow", "paing", "via", "left", "/", "right", "arrows"], "add_tokens": "pagingCh chan PagingRequest make ( chan struct { } ) , // loopCh make ( chan string ) , // queryCh make ( chan [ ] Match ) , // drawCh make ( chan PagingRequest ) , // pagingCh func ( c * Ctx ) PagingCh ( ) chan PagingRequest { return c . pagingCh }", "del_tokens": "make ( chan struct { } ) , // loopCh make ( chan string ) , // queryCh make ( chan [ ] Match ) , // drawCh", "commit_type": "allow"}
{"commit_tokens": ["fixed", "a", "bug", "with", "gomap"], "add_tokens": "p := unsafe . Pointer ( & b [ 0 ] )", "del_tokens": "p := unsafe . Pointer ( & b )", "commit_type": "fix"}
{"commit_tokens": ["added", "File", ".", "Stat", "/", "fstat", "coverage"], "add_tokens": "fi . name = path . Base ( f . path )", "del_tokens": "fi . name = f . path", "commit_type": "add"}
{"commit_tokens": ["Fix", "an", "issue", "where", "a", "disco", "service", "wants", "to", "delete", "and", "readvertise"], "add_tokens": "watchedMutex sync . RWMutex d . watchedMutex . RLock ( ) services := make ( [ ] string , 0 , len ( d . myAdvertisedServices ) ) for s := range d . myAdvertisedServices { services = append ( services , s ) } d . watchedMutex . RUnlock ( ) for _ , serviceName := range services { d . watchedMutex . Lock ( ) defer d . watchedMutex . Unlock ( ) delete ( d . myAdvertisedServices , serviceName )", "del_tokens": "watchedMutex sync . Mutex for serviceName := range d . myAdvertisedServices {", "commit_type": "fix"}
{"commit_tokens": ["Use", "dep", "and", "implement", "testing", "."], "add_tokens": "return GetApiBaseURL ( ) + fmt . Sprintf ( template , args ... )", "del_tokens": "} else { return GetApiBaseURL ( ) + fmt . Sprintf ( template , args ... )", "commit_type": "use"}
{"commit_tokens": ["Fix", "identifier", "scanner", ".", "Was", "[", "A", "-", "Za", "-", "z0", "-", "9", "]", "should", "be", ":", "[", "A", "-", "Za", "-", "z0", "-", "9_", "]"], "add_tokens": "return unicode . IsDigit ( rune ) || unicode . IsLetter ( rune ) || rune == '_'", "del_tokens": "return unicode . IsDigit ( rune ) || unicode . IsLetter ( rune )", "commit_type": "fix"}
{"commit_tokens": ["Improves", "filepath", "sanitization", "thanks", "to", "@rui314", "once", "again"], "add_tokens": "for strings . HasPrefix ( name , \" \" ) { name = name [ 3 : ] } return name", "del_tokens": "return strings . TrimLeft ( name , \" \" )", "commit_type": "improve"}
{"commit_tokens": ["change", "the", "package", "name", "to", "graval"], "add_tokens": "package graval", "del_tokens": "package raval", "commit_type": "change"}
{"commit_tokens": ["use", "queryable", "interface", "in", "some", "helper", "methods"], "add_tokens": "func ( * SQLite ) databaseName ( q queryable ) ( dbName string ) { q . QueryRow ( \" \" ) . Scan ( & seq , & main , & dbName ) func ( * SQLite ) tableNames ( q queryable ) ( [ ] string , error ) { rows , err := q . Query ( query )", "del_tokens": "func ( * SQLite ) databaseName ( db * sql . DB ) ( dbName string ) { db . QueryRow ( \" \" ) . Scan ( & seq , & main , & dbName ) func ( * SQLite ) tableNames ( db * sql . DB ) ( [ ] string , error ) { rows , err := db . Query ( query )", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "time", "to", "be", "passed", "in", "on", "new"], "add_tokens": "\" \" \" \" return NewWithTime ( time . Now ( ) ) } // NewWithTime generates a globally unique ID with the passed in time func NewWithTime ( t time . Time ) ID { binary . BigEndian . PutUint32 ( id [ : ] , uint32 ( t . Unix ( ) ) )", "del_tokens": "\" \" \" \" binary . BigEndian . PutUint32 ( id [ : ] , uint32 ( time . Now ( ) . Unix ( ) ) )", "commit_type": "allow"}
{"commit_tokens": ["Use", "shard", "broker", "to", "monitor", "and", "process", "new", "shards"], "add_tokens": "// A myLogger provides a minimalistic logger satisfying the Logger interface. type myLogger struct { logger * log . Logger } // Log logs the parameters to the stdlib logger. See log.Println. func ( l * myLogger ) Log ( args ... interface { } ) { l . logger . Println ( args ... ) } // logger logger := & myLogger { logger : log . New ( os . Stdout , \" \" , log . LstdFlags ) , } * stream , consumer . WithCheckpoint ( ck ) , consumer . WithLogger ( logger ) , fmt . Println ( \" \" )", "del_tokens": "* stream , consumer . WithCheckpoint ( ck ) ,", "commit_type": "use"}
{"commit_tokens": ["add", "xml", "config", "in", "readme"], "add_tokens": "func BenchmarkBlog4go ( b * testing . B ) {", "del_tokens": "func BenchmarkBlog4goFormat ( b * testing . B ) {", "commit_type": "add"}
{"commit_tokens": ["added", "form", "handling", "and", "client", "side", "validation"], "add_tokens": "return NewHtmlId ( tag , id )", "del_tokens": "return & htmlIdImpl { tag , id }", "commit_type": "add"}
{"commit_tokens": ["update", "the", "name", "and", "version"], "add_tokens": "NAME = \" \" VERSION = \" \"", "del_tokens": "NAME = \" \" VERSION = \" \"", "commit_type": "update"}
{"commit_tokens": ["implemented", "freeing", "memory", "in", "secretservice", "and", "made", "minor", "edits", "to", "osxkeychain"], "add_tokens": "\" \" func ( h Osxkeychain ) List ( ) ( [ ] string , [ ] string , error ) { var pathsC * * C . char var acctsC * * C . char if errMsg != nil { var listLen int for i := 0 ; i < listLen ; i ++ { if C . GoString ( pathTmp [ i ] ) == \" \" { C . freeListData ( & acctsC , listLenC )", "del_tokens": "\" \" func ( h Osxkeychain ) List ( ) ( [ ] string , [ ] string , error ) { var pathsC * * C . char var acctsC * * C . char if errMsg != nil { var listLen int ; for i := 0 ; i < listLen ; i ++ { if C . GoString ( pathTmp [ i ] ) == \" \" { //still need to free all the memory we allocated in the c file //do it here >>", "commit_type": "implement"}
{"commit_tokens": ["Removed", "+", "linux", "build", "tag", ".", "Added", "-", "windows", "build", "tag", "."], "add_tokens": "// -windows", "del_tokens": "// +linux", "commit_type": "remove"}
{"commit_tokens": ["Add", "ErrorWithStackSkip", "function", "for", "adding", "extra", "stack", "trace", "frame", "skips", "."], "add_tokens": "// -- Error reporting ErrorWithStackSkip ( level , err , 1 ) } func ErrorWithStackSkip ( level string , err error , skip int ) { data [ \" \" ] = errorBody ( err , skip ) // -- Message reporting // Build an error inner-body for the given error. If skip is provided, that // number of stack trace frames will be skipped. func errorBody ( err error , skip int ) map [ string ] interface { } { \" \" : stacktraceFrames ( 3 + skip ) ,", "del_tokens": "data [ \" \" ] = errorBody ( err ) func errorBody ( err error ) map [ string ] interface { } { \" \" : stacktraceFrames ( 3 ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "locks", "in", "disseminator", ".", "HasChanges", "method"], "add_tokens": "d . Lock ( ) r := len ( d . changes ) > 0 d . Unlock ( ) return r", "del_tokens": "return len ( d . changes ) > 0", "commit_type": "add"}
{"commit_tokens": ["Add", "skipping", "at", "levels", ">", "=", "4", "."], "add_tokens": "ii uint16 // position of last match, intended to overflow to reset. // Reset, if we got a match this run. if d . length >= minMatchLength { d . ii = 0 } d . ii ++ d . index ++ // If we have a long run of no matches, skip additional bytes // Resets when d.ii overflows after 64KB. if d . ii > 31 { n := int ( d . ii >> 5 ) for j := 0 ; j < n ; j ++ { i := d . index - 1 if d . index >= d . windowEnd - 1 { break } d . tokens . tokens [ d . tokens . n ] = literalToken ( uint32 ( d . window [ i ] ) ) d . tokens . n ++ if d . tokens . n == maxFlateBlockTokens { if d . err = d . writeBlock ( d . tokens , i + 1 , false ) ; d . err != nil { return } d . tokens . n = 0 } d . index ++ } } } else { d . index ++", "del_tokens": "ii uint16 // position of last match d . index ++", "commit_type": "add"}
{"commit_tokens": ["Uses", "TLS", "to", "communicate", "with", "the", "SMTP", "server", "if", "configured"], "add_tokens": "\" \" Host string Port string user string pass string client * smtp . Client Insecure bool client , err := smtp . Dial ( net . JoinHostPort ( c . Host , c . Port ) ) if ok , _ := c . client . Extension ( \" \" ) ; ok { err = c . client . StartTLS ( & tls . Config { ServerName : c . Host , InsecureSkipVerify : c . Insecure , } ) if err != nil { fmt . Println ( \" \" ) return err } }", "del_tokens": "Host string Port string user string pass string client * smtp . Client client , err := smtp . Dial ( fmt . Sprintf ( \" \" , c . Host , c . Port ) )", "commit_type": "use"}
{"commit_tokens": ["added", "missing", "context", "arg", "to", "server", ".", "ReceivePacket", "()"], "add_tokens": "\" \" packet , err := server . ReceivePacket ( context . Background ( ) , conn )", "del_tokens": "packet , err := server . ReceivePacket ( conn )", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "return", "nil", "and", "error", "on", "LoadEvent", "if", "aggregate", "type", "for"], "add_tokens": "// ErrMismatchedEventType occurs when loaded events from ID does not match aggregate type. var ErrMismatchedEventType = errors . New ( \" \" ) if event . AggregateType ( ) != aggregateType { return nil , ErrMismatchedEventType aggregate . ApplyEvent ( event ) aggregate . IncrementVersion ( )", "del_tokens": "// Events must be of same aggregate type as the command if event . AggregateType ( ) == aggregateType { aggregate . ApplyEvent ( event ) aggregate . IncrementVersion ( )", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "symlink", "to", "absolute", "directory"], "add_tokens": "var osp string if referent [ 0 ] != filepath . Separator { osp = filepath . Join ( filepath . Dir ( osPathname ) , referent ) } else { osp = referent } var osp string if referent [ 0 ] != filepath . Separator { osp = filepath . Join ( osPathname , referent ) } else { osp = referent }", "del_tokens": "osp := filepath . Join ( filepath . Dir ( osPathname ) , referent ) osp := filepath . Join ( osPathname , referent )", "commit_type": "fix"}
{"commit_tokens": ["Made", "readme", "more", "culture", "neutral", "."], "add_tokens": "mail . From ( \" \" ) mail . From ( \" \" )", "del_tokens": "mail . From ( \" \" ) mail . From ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["move", "test", "sources", "and", "run", "join", "in", "a", "gouroutine"], "add_tokens": "go c . send ( fmt . Sprintf ( \" \" , channel ) )", "del_tokens": "c . send ( fmt . Sprintf ( \" \" , channel ) )", "commit_type": "move"}
{"commit_tokens": ["Improve", "unpacking", "and", "unit", "tests"], "add_tokens": "struct { C struct { B bool } } { struct { B bool } { true } } , struct { C interface { } } { struct { B bool } { true } } , struct { C interface { } } { struct { B interface { } } { true } } , struct { C struct { B interface { } } } { struct { B interface { } } { true } } ,", "del_tokens": "", "commit_type": "improve"}
{"commit_tokens": ["Use", "SelectionTemplate", "for", "sortable", "select", "many"], "add_tokens": "if selectManyConfig , ok := sortableMeta . Config . ( * admin . SelectManyConfig ) ; ok { selectManyConfig . SelectionTemplate = selectManyTemplate }", "del_tokens": "sortableMeta . Type = \" \" + sortableMeta . Type", "commit_type": "use"}
{"commit_tokens": ["Remove", "dependency", "on", "docker", "in", "auth"], "add_tokens": "authConfig := dockerauth . GetAuthconfig ( image ) Repository : image ,", "del_tokens": "\" \" dockerparsers \" \" dockerregistry \" \" // The following lines of code are taken, in whole or part, from the docker // source code. Please see the NOTICE file in the root of the project for // attribution // https://github.com/docker/docker/blob/246ec5dd067fc17be5196ae29956e3368b167ccf/api/client/commands.go#L1180 taglessRemote , tag := dockerparsers . ParseRepositoryTag ( image ) if tag == \" \" { tag = \" \" } hostname , _ , err := dockerregistry . ResolveRepositoryName ( taglessRemote ) if err != nil { return err } // End of docker-attributed code authConfig := dockerauth . GetAuthconfig ( hostname ) Repository : taglessRemote , Registry : hostname , Tag : tag , // DescribeDockerImages takes no arguments, and returns a JSON-encoded string of all of the images located on the host func ( dg * DockerGoClient ) DescribeDockerImages ( ) ( string , error ) { client , err := dg . client ( ) if err != nil { return \" \" , err } imgs , err := client . ListImages ( true ) if err != nil { return \" \" , err } response := DockerImageResponse { Images : imgs } output , err := json . Marshal ( response ) if err != nil { return \" \" , err } return string ( output ) , nil }", "commit_type": "remove"}
{"commit_tokens": ["Make", "writing", "the", "global", "header", "explicit"], "add_tokens": "const HEADER_BYTE_SIZE = 60 // archive.WriteGlobalHeader() func ( aw * Writer ) WriteGlobalHeader ( ) error { _ , err := aw . w . Write ( [ ] byte ( \" \\n \" ) ) return err }", "del_tokens": "const HEADER_BYTE_SIZE = 68 globalHeader bool // has the global file header been written yet? if ! aw . globalHeader { aw . string ( s . next ( 8 ) , \" \\n \" ) aw . globalHeader = true }", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "longer", "timeout", "during", "unit", "tests", "."], "add_tokens": "var ( timeout = 5 * time . Second ) con . SetDeadline ( time . Now ( ) . Add ( timeout ) )", "del_tokens": "con . SetDeadline ( time . Now ( ) . Add ( 5 * time . Second ) )", "commit_type": "use"}
{"commit_tokens": ["Adds", "usage", "details", "for", "required", "flags"], "add_tokens": "var kindParts [ ] string if _ , ok := field . Tag . Lookup ( \" \" ) ; ok { kindParts = append ( kindParts , \" \" ) } kind = field . Type . Elem ( ) . Kind ( ) . String ( ) kindParts = append ( kindParts , \" \" ) } if len ( kindParts ) > 0 { kind = fmt . Sprintf ( \" \" , kind , strings . Join ( kindParts , \" \" ) )", "del_tokens": "kind = fmt . Sprintf ( \" \" , field . Type . Elem ( ) . Kind ( ) . String ( ) )", "commit_type": "add"}
{"commit_tokens": ["Adding", "keyspace", "support", "for", "cassandra", "URLs"], "add_tokens": "var dsn string host , port , dbname := \" \" , \" \" , strings . TrimPrefix ( u . Path , \" \" ) // add dbname if dbname != \" \" { q . Set ( \" \" , dbname ) }", "del_tokens": "// create dsn dsn := \" \" host , port := \" \" , \" \"", "commit_type": "add"}
{"commit_tokens": ["Move", "ReleaseDateTime", "method", "to", "SimpleAlbum", "struct"], "add_tokens": "// Acousticness is a confidence measure from 0.0 to 1.0 of whether", "del_tokens": "//Acousticness is a confidence measure from 0.0 to 1.0 of whether", "commit_type": "move"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// MatchIPProto creates an Openflow basic extensible match of IP protocol", "del_tokens": "// MatchIPPort creates an Openflow basic extensible match of IP protocol", "commit_type": "fix"}
{"commit_tokens": ["add", "basic", "reporting", "support", "and", "a", "basic", "reporter"], "add_tokens": "g . reporter . begin ( ) g . reporter . end ( ) g . reporter . beginDescribe ( d . name ) g . reporter . endDescribe ( ) //fmt.Println(it.name) if it . failed { g . reporter . itFailed ( it . name ) } else { g . reporter . itPassed ( it . name ) } g . reporter = Reporter ( & DetailedReporter { } ) reporter Reporter func ( g * G ) SetReporter ( r Reporter ) { g . reporter = r }", "del_tokens": "\" \" fmt . Println ( it . name )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "session", "demo", "application", ".", "Renamed", "CookieMngrOptions", ".", "Secure", "to"], "add_tokens": "// Name of the cookie used for storing the session id; default value is \"sessid\" SessIdCookieName string // Tells if session ID cookies are allowed to be sent over unsecure HTTP too (else only HTTPS); // default value is false (only HTTPS) AllowHTTP bool // Max age for session ID cookies; default value is 30 days CookieMaxAge time . Duration // Cookie path to use; default value is the root: \"/\" CookiePath string cookieSecure : ! o . AllowHTTP ,", "del_tokens": "SessIdCookieName string // Name of the cookie used for storing the session id; default value is \"sessid\" CookieSecure * bool // Tells if session ID cookies are to be sent only over HTTPS (and not over HTTP); default value is true CookieMaxAge time . Duration // Max age for session ID cookies; default value is 30 days CookiePath string // Cookie path to use; default value is the root: \"/\" cookieSecure : true , if o . CookieSecure != nil && ! * o . CookieSecure { m . cookieSecure = false }", "commit_type": "add"}
{"commit_tokens": ["remove", "access", "token", "in", "test"], "add_tokens": "FB_TEST_VALID_ACCESS_TOKEN = \" \"", "del_tokens": "FB_TEST_VALID_ACCESS_TOKEN = \" \"", "commit_type": "remove"}
{"commit_tokens": ["Updated", "the", "package", "documentation", "as", "recommended", "by", "Summerfield", "in", "Programming", "in", "Go"], "add_tokens": "// Package recaptcha handles reCaptcha (http://www.google.com/recaptcha) form submissions // // This package is designed to be called from within an HTTP server or web framework // which offers reCaptcha form inputs and requires them to be evaluated for correctness // // Edit the recaptcha_private_key constant before building and using", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Make", "string", "formatting", "explicit", "."], "add_tokens": "output , err := h . RunSSHCommand ( getStartCommand ( config . LocalkubeURL ) )", "del_tokens": "output , err := h . RunSSHCommand ( fmt . Sprintf ( startCommand , config . LocalkubeURL ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "String", "type"], "add_tokens": "Copyright 2015 - 2017 Red Hat , Inc . and / or its affiliates case String : addToURL ( u , \" \" )", "del_tokens": "Copyright 2015 - 2016 Red Hat , Inc . and / or its affiliates", "commit_type": "add"}
{"commit_tokens": ["Add", "plane", "copy", "without", "any", "resize"], "add_tokens": "if hrez == nil && wrez == nil { copyPlane ( dst . Data , src . Data , src . Width , src . Height , dst . Pitch , src . Pitch ) }", "del_tokens": "count := 0 count ++ count ++ if count == 0 { return nil , fmt . Errorf ( \" \" ) }", "commit_type": "add"}
{"commit_tokens": ["updated", "err", "handling", "in", "softlayer_vm", ".", "go"], "add_tokens": "if err != nil { return bosherr . WrapErrorf ( err , \" \" , virtualGuest . Id ) } if err != nil { return bosherr . WrapErrorf ( err , \" \" , virtualGuest . Id ) } new_agentEnv := old_agentEnv . AttachPersistentDisk ( strconv . Itoa ( disk . ID ( ) ) , \" \" ) // Naming convention for iscsi driver in Softlayer.", "del_tokens": "new_agentEnv := old_agentEnv . AttachPersistentDisk ( strconv . Itoa ( disk . ID ( ) ) , \" \" )", "commit_type": "update"}
{"commit_tokens": ["add", "rtpKeepaliveEnterCnt", "to", "fix", "keepalive", "reenter", "problem"], "add_tokens": "rtpKeepaliveEnterCnt int if self . RtpKeepAliveTimeout > 0 && self . rtpKeepaliveEnterCnt == 0 { self . rtpKeepaliveEnterCnt ++ defer func ( ) { self . rtpKeepaliveEnterCnt -- } ( )", "del_tokens": "if self . RtpKeepAliveTimeout > 0 {", "commit_type": "add"}
{"commit_tokens": ["fix", "varint", ".", "ReadFrom", "return", "value"], "add_tokens": "return 0 , 1 , ErrOutOfRange", "del_tokens": "return 0 , 0 , ErrOutOfRange", "commit_type": "fix"}
{"commit_tokens": ["Add", "newline", "after", "version", "output"], "add_tokens": "fmt . Printf ( \" \\n \" , gollumMajorVer , gollumMinorVer , gollumPatchVer )", "del_tokens": "fmt . Printf ( \" \" , gollumMajorVer , gollumMinorVer , gollumPatchVer )", "commit_type": "add"}
{"commit_tokens": ["change", "the", "test", "to", "be", "less", "flaky", "by", "allowing", "up", "to", "1", "min", "of", "difference"], "add_tokens": "Expect ( time . Time ( message . Timestamp ) ) . To ( BeTemporally ( \" \" , expected , time . Minute ) )", "del_tokens": "Expect ( time . Time ( message . Timestamp ) ) . To ( BeTemporally ( \" \" , expected ) )", "commit_type": "change"}
{"commit_tokens": ["Added", "some", "janky", "POSIX", "-", ">", "os", ".", "FileMode", "conversion"], "add_tokens": "\" \" \" \" name string a . mode = toFileMode ( mode ) // toFileMode converts sftp filemode bits to the os.FileMode specification func toFileMode ( mode uint32 ) os . FileMode { fmt . Println ( \" \" , mode ) var fm = os . FileMode ( mode & 0777 ) switch mode & syscall . S_IFMT { case syscall . S_IFBLK : fm |= os . ModeDevice case syscall . S_IFCHR : fm |= os . ModeDevice | os . ModeCharDevice case syscall . S_IFDIR : fm |= os . ModeDir case syscall . S_IFIFO : fm |= os . ModeNamedPipe case syscall . S_IFLNK : fm |= os . ModeSymlink case syscall . S_IFREG : // nothing to do case syscall . S_IFSOCK : fm |= os . ModeSocket } if mode & syscall . S_ISGID != 0 { fm |= os . ModeSetgid } if mode & syscall . S_ISUID != 0 { fm |= os . ModeSetuid } if mode & syscall . S_ISVTX != 0 { fm |= os . ModeSticky } return fm }", "del_tokens": "a . mode = os . FileMode ( mode )", "commit_type": "add"}
{"commit_tokens": ["Fix", "integer", "overflow", "on", "white", "colors"], "add_tokens": "c := 0.3 * float64 ( src . Pix [ srcPos + 0 ] ) + 0.6 * float64 ( src . Pix [ srcPos + 1 ] ) + 0.1 * float64 ( src . Pix [ srcPos + 2 ] ) dst . Pix [ dstPos ] = uint8 ( c + 0.5 )", "del_tokens": "var c uint8 c += uint8 ( 0.3 * float64 ( src . Pix [ srcPos + 0 ] ) + 0.5 ) c += uint8 ( 0.6 * float64 ( src . Pix [ srcPos + 1 ] ) + 0.5 ) c += uint8 ( 0.1 * float64 ( src . Pix [ srcPos + 2 ] ) + 0.5 ) dst . Pix [ dstPos ] = c", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "IPv6", "in", "NewIPNet"], "add_tokens": "// NewIPNet generates an IPNet from an ip address using a netmask of 32 or 128. if ip . To4 ( ) != nil { return & net . IPNet { IP : ip , Mask : net . CIDRMask ( 32 , 32 ) } } return & net . IPNet { IP : ip , Mask : net . CIDRMask ( 128 , 128 ) }", "del_tokens": "// NewIPNet generates an IPNet from an ip address using a netmask of 32. return & net . IPNet { IP : ip , Mask : net . CIDRMask ( 32 , 32 ) }", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "golangci", "-", "lint", "revive", "linter", "warnings"], "add_tokens": "ws \" \" conn * ws . Conn func NewObjectStream ( conn * ws . Conn ) ObjectStream { if e , ok := err . ( * ws . CloseError ) ; ok { if e . Code == ws . CloseAbnormalClosure && e . Text == io . ErrUnexpectedEOF . Error ( ) {", "del_tokens": "\" \" conn * websocket . Conn func NewObjectStream ( conn * websocket . Conn ) ObjectStream { if e , ok := err . ( * websocket . CloseError ) ; ok { if e . Code == websocket . CloseAbnormalClosure && e . Text == io . ErrUnexpectedEOF . Error ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "specific", "port", "names", "not", "overriding", "port", "suffix"], "add_tokens": "if isgroup && metadata [ \" \" ] == \" \" {", "del_tokens": "if isgroup {", "commit_type": "fix"}
{"commit_tokens": ["Add", "admin_buildpacks", "to", "staging", "request"], "add_tokens": "[ ] byte ( `{\"app_id\": \"some-app-guid\", \"task_id\": \"some-task-id\", \"stack\": \"default\", \"admin_buildpacks\" : [{\"key\": \"ruby\", \"url\": \"ruby-url\"}]}` ) )", "del_tokens": "[ ] byte ( `{\"app_id\": \"some-app-guid\", \"task_id\": \"some-task-id\", \"stack\": \"default\"}` ) )", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "commitCh", "to", "notify", "FSM", "of", "available", "logs"], "add_tokens": "// Commit chan is used to provide the newest commit index // so that changes can be applied to the FSM. This is used // so the main goroutine can use commitIndex without locking, // and the FSM manager goroutine can read from this and manipulate // lastApplied without a lock. commitCh chan uint64 commitCh : make ( chan uint64 , 128 ) , // Trigger applying logs locally r . commitCh <- r . commitIndex", "del_tokens": "// TODO: Trigger applying logs locally!", "commit_type": "add"}
{"commit_tokens": ["fix", "multiple", ".", "flushAfter", "()", "calls"], "add_tokens": "debug bool running bool key string url string flushCount int flushInterval time . Duration buffer [ ] * interface { } c . flushCount = n c . flushInterval = interval if c . running { return } c . running = true time . Sleep ( c . flushInterval ) c . log ( \" \" , c . flushInterval ) // when the buffer exceeds .flushCount. c . log ( \" \" , len ( c . buffer ) , c . flushCount , msg ) if len ( c . buffer ) >= c . flushCount {", "del_tokens": "debug bool key string url string flushAt int flushAfter time . Duration buffer [ ] * interface { } c . flushAt = n c . flushAfter = interval time . Sleep ( interval ) c . log ( \" \" , interval ) // when the buffer exceeds .flushAt. c . log ( \" \" , len ( c . buffer ) , c . flushAt , msg ) if len ( c . buffer ) >= c . flushAt {", "commit_type": "fix"}
{"commit_tokens": ["add", "eq", "baked", "in", "function", "+", "tests"], "add_tokens": "if tag == \" \" && ( ( valueField . Kind ( ) != reflect . Struct && valueField . Kind ( ) != reflect . Interface ) || valueField . Type ( ) == reflect . TypeOf ( time . Time { } ) ) {", "del_tokens": "if tag == \" \" && valueField . Kind ( ) != reflect . Struct && valueField . Kind ( ) != reflect . Interface {", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "signing", "string", "tests"], "add_tokens": "expected : \" \" , expected : \" \" ,", "del_tokens": "expected : \" \" , expected : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "logging", "condition", "back", "to", "avoid", "ruining", "it", "for", "everybody"], "add_tokens": "if ! prof . Quiet { log . Printf ( \" \" , fn ) } if ! prof . Quiet { log . Printf ( \" \" , fn ) } if ! prof . Quiet { log . Printf ( \" \" , fn ) }", "del_tokens": "if prof . Quiet { log . SetOutput ( ioutil . Discard ) } log . Printf ( \" \" , fn ) log . Printf ( \" \" , fn ) log . Printf ( \" \" , fn )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "Linux", "Int", "Driver", "s", "Mount", "/", "Preempt"], "add_tokens": "lsAtt := types . VolAttReqWithDevMapOnlyVolsAttachedToInstanceOrUnattachedVols if opts . Preempt { lsAtt = types . VolAttReq } ctx , volumeID , volumeName , lsAtt , opts . Opts )", "del_tokens": "ctx , volumeID , volumeName , types . VolAttReqWithDevMapOnlyVolsAttachedToInstanceOrUnattachedVols , opts . Opts ) var err error", "commit_type": "fix"}
{"commit_tokens": ["Updated", "database", "interface", "and", "eth", "test", "code"], "add_tokens": "//db.trie = NewTrie(db)", "del_tokens": "db . trie = NewTrie ( db )", "commit_type": "update"}
{"commit_tokens": ["Use", "cadvisor", "docker", "API", "and", "not", "container", "API"], "add_tokens": "if id != \" \" { cInfo , err := getContainerStats ( c , count , id ) log . WithFields ( log . Fields { \" \" : err , \" \" : id } ) . Error ( \" \" ) log . WithFields ( log . Fields { \" \" : err } ) . Error ( \" \" )", "del_tokens": "container , err := resolveContainer ( id ) if container != \" \" { cInfo , err := c . ContainerInfo ( container , & info . ContainerInfoRequest { NumStats : count , } )", "commit_type": "use"}
{"commit_tokens": ["Make", "TypeMappingLexer", "a", "bit", "less", "prone", "to", "error", "."], "add_tokens": ") , TypeMapping { { NameVariable , NameFunction , emacsBuiltinFunction } , { NameVariable , NameBuiltin , emacsSpecialForms } , { NameVariable , NameException , emacsErrorKeywords } , { NameVariable , NameBuiltin , append ( emacsBuiltinFunctionHighlighted , emacsMacros ... ) } , { NameVariable , KeywordPseudo , emacsLambdaListKeywords } ,", "del_tokens": ") , TypeRemappingMap { { NameVariable , NameFunction } : emacsBuiltinFunction , { NameVariable , NameKeyword } : emacsSpecialForms , { NameVariable , NameException } : emacsErrorKeywords , { NameVariable , NameBuiltin } : append ( emacsBuiltinFunctionHighlighted , emacsMacros ... ) , { NameVariable , KeywordPseudo } : emacsLambdaListKeywords ,", "commit_type": "make"}
{"commit_tokens": ["fix", "out", "of", "bounds", "panic"], "add_tokens": "return nil , fmt . Errorf ( \" \" , pid , err )", "del_tokens": "return nil , fmt . Errorf ( \" \" , pid , err )", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "martini", ".", "ResponseWriter", "interface", "to", "make", "wrapping", "easier"], "add_tokens": "c := & context { inject . New ( ) , append ( m . handlers , m . action ) , NewResponseWriter ( res ) , 0 } rw ResponseWriter return c . rw . Written ( ) if c . rw . Written ( ) {", "del_tokens": "c := & context { inject . New ( ) , append ( m . handlers , m . action ) , & responseWriter { res , false } , 0 } rw * responseWriter return c . rw . written if c . rw . written { type responseWriter struct { w http . ResponseWriter written bool } func ( r * responseWriter ) Header ( ) http . Header { return r . w . Header ( ) } func ( r * responseWriter ) Write ( b [ ] byte ) ( int , error ) { r . written = true return r . w . Write ( b ) } func ( r * responseWriter ) WriteHeader ( s int ) { r . written = true r . w . WriteHeader ( s ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "Collaborators", "to", "Component", "type"], "add_tokens": "Type string `json:\"type\"` ID string `json:\"id\"` Created time . Time `json:\"created,omitempty\"` Collaborators [ ] Collaborator `json:\"collaborators,omitempty\"`", "del_tokens": "Type string `json:\"type\"` ID string `json:\"id\"` Created time . Time `json:\"created,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "reporters", "+", "two", "types", "of", "reporters"], "add_tokens": "\" \" } , spec . Report ( report . Terminal { } ) )", "del_tokens": "} )", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "result", "from", "Remove", "()", "to", "decide", "wether", "to", "panic", "()"], "add_tokens": "removed := t . summary . Remove ( c ) if removed == nil { updated := removed . ( Centroid ) updated . Update ( mean , weight ) t . addCentroid ( updated )", "del_tokens": "if t . summary . Find ( c ) == nil { t . summary . Remove ( c ) c . Update ( mean , weight ) t . addCentroid ( c )", "commit_type": "use"}
{"commit_tokens": ["Updated", "due", "to", "changes", "in", "store"], "add_tokens": "s . vs , restartChan = store . NewGroupStore ( & s . GroupStoreConfig ) if err := s . vs . Startup ( ) ; err != nil { panic ( err ) } s . vs . Shutdown ( )", "del_tokens": "var err error s . vs , restartChan , err = store . NewGroupStore ( & s . GroupStoreConfig ) if err != nil { panic ( err ) } s . vs . EnableAll ( ) s . vs . DisableAll ( ) s . vs . Flush ( )", "commit_type": "update"}
{"commit_tokens": ["Allow", "lowercase", "charset", "utf", "-", "8"], "add_tokens": "\" \" ! ( mediatype == \" \" && strings . ToUpper ( charset ) == \" \" ) {", "del_tokens": "! ( mediatype == \" \" && charset == \" \" ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "wrong", "key", "size", "of", "ECDH", "-", "ES", "+", "AES", "key", "wrap"], "add_tokens": "keysize = contentcrypt . KeySize ( ) / 2", "del_tokens": "keysize = contentcrypt . KeySize ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "option", "for", "test", "failure", "type", "on", "snapshot", "mismatch"], "add_tokens": "// FatalOnMismatch controls whether failed tests should fail using t.Fatal which should // immediately stop any remaining tests. Will use t.Error on false. // Default: false func FatalOnMismatch ( fatalOnMismatch bool ) Configurator { return func ( c * Config ) { c . fatalOnMismatch = fatalOnMismatch } } shouldUpdate func ( ) bool subDirName string failOnUpdate bool fatalOnMismatch bool FatalOnMismatch ( false ) , shouldUpdate : c . shouldUpdate , subDirName : c . subDirName , failOnUpdate : c . failOnUpdate , fatalOnMismatch : c . fatalOnMismatch ,", "del_tokens": "shouldUpdate func ( ) bool subDirName string failOnUpdate bool shouldUpdate : c . shouldUpdate , subDirName : c . subDirName , failOnUpdate : c . failOnUpdate ,", "commit_type": "add"}
{"commit_tokens": ["updated", "package", "name", "from", "spotify", "to", "spotify_test", "to", "stay", "consistent", "with", "other", "provider", "packages", "."], "add_tokens": "package spotify_test \" \" func provider ( ) * spotify . Provider { return spotify . New ( os . Getenv ( \" \" ) , os . Getenv ( \" \" ) , \" \" , \" \" ) s := session . ( * spotify . Session ) s := session . ( * spotify . Session )", "del_tokens": "package spotify func provider ( ) * Provider { return New ( os . Getenv ( \" \" ) , os . Getenv ( \" \" ) , \" \" , \" \" ) s := session . ( * Session ) s := session . ( * Session )", "commit_type": "update"}
{"commit_tokens": ["Fixed", "RedisBroker", "interface", "and", "corrected", "some", "comments"], "add_tokens": "// NewAMQPBroker creates new AMQPBroker instance", "del_tokens": "// NewAMQPBroker creates new AMQPConnection instance", "commit_type": "fix"}
{"commit_tokens": ["Update", "gateway", "type", "to", "support", "AntennaLocation"], "add_tokens": "// AntennaLocation is the location of the gateway antenna AntennaLocation * AntennaLocation `json:\"antenna_location,omitempty\"` // AntennaLocation is the location of the gateway antenna AntennaLocation * AntennaLocation `json:\"location,omitempty\"` ID : gatewayID , FrequencyPlan : frequencyPlan , AntennaLocation : opts . AntennaLocation , Attributes : opts . Attributes , Router : opts . Router , AntennaLocation * AntennaLocation `json:\"antenna_location,omitempty\"` // ChangeLocation changes the location of the gateway, set to nil, nil if you // want to remove the location AntennaLocation : & AntennaLocation { AntennaLocation : & AntennaLocation { Altitude : altitude , } ,", "del_tokens": "// Altitude is the altitude of the new gateway Altitude * float64 `json:\"altitude,omitempty\"` // Location is the location of the new gateway Location * Location `json:\"location,omitempty\"` // Location is the location of the new gateway Location * Location `json:\"location,omitempty\"` // Altitude is the altitude of the new gateway Altitude * float64 `json:\"altitude,omitempty\"` ID : gatewayID , FrequencyPlan : frequencyPlan , Location : opts . Location , Altitude : opts . Altitude , Attributes : opts . Attributes , Router : opts . Router , Location * Location `json:\"location,omitempty\"` Altitude * float64 `json:\"altitude,omitempty\"` // ChangeLocation changes the location of the gateway Location : & Location { Altitude : & altitude ,", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "-", "ignore"], "add_tokens": "err = findFiles ( input . Path , c . Prefix , input . Recursive , & toc , c . Ignore ) func findFiles ( dir , prefix string , recursive bool , toc * [ ] Asset , ignore [ ] * regexp . Regexp ) error { ignoring := false for _ , re := range ignore { if re . MatchString ( asset . Path ) { ignoring = true break } } if ignoring { continue } findFiles ( asset . Path , prefix , recursive , toc , ignore )", "del_tokens": "err = findFiles ( input . Path , c . Prefix , input . Recursive , & toc ) func findFiles ( dir , prefix string , recursive bool , toc * [ ] Asset ) error { findFiles ( asset . Path , prefix , recursive , toc )", "commit_type": "add"}
{"commit_tokens": ["moved", "all", "virtual", "file", "stuff", "to", "packd"], "add_tokens": "return packd . NewFile ( name , bytes . NewReader ( bb ) ) return packd . NewFile ( cleanName , bytes . NewReader ( bb ) ) return packd . NewDir ( cleanName ) return packd . NewDir ( p ) return packd . NewFile ( name , bytes . NewReader ( bb ) )", "del_tokens": "return newVirtualFile ( name , bb ) , nil return newVirtualFile ( cleanName , bb ) , nil return newVirtualDir ( cleanName ) , nil return newVirtualDir ( p ) , nil return newVirtualFile ( name , bb ) , nil", "commit_type": "move"}
{"commit_tokens": ["add", "-", "f", "on", "job", "create", "and", "job", "update"], "add_tokens": "var spec * api . JobSpec if flags . Changed ( \" \" ) { service , err := readServiceConfig ( flags ) spec = service . JobSpec ( ) } else { // TODO(vieux): support or error on both file. spec = & api . JobSpec { } if flags . Changed ( \" \" ) { instances , err := flags . GetInt64 ( \" \" ) if err != nil { return err } spec . Orchestration = & api . JobSpec_Service { Service : & api . JobSpec_ServiceJob { Instances : instances , } , } updateCmd . Flags ( ) . StringP ( \" \" , \" \" , \" \" , \" \" )", "del_tokens": "spec := & api . JobSpec { } if flags . Changed ( \" \" ) { instances , err := flags . GetInt64 ( \" \" ) spec . Orchestration = & api . JobSpec_Service { Service : & api . JobSpec_ServiceJob { Instances : instances , } ,", "commit_type": "add"}
{"commit_tokens": ["add", "detail", "to", "internal", "error", "messages"], "add_tokens": "w . InternalError = errors . New ( \" \" ) w . InternalError = errors . New ( \" \" )", "del_tokens": "w . InternalError = errors . New ( \" \" ) w . InternalError = errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "use", "of", "Host", "header"], "add_tokens": "if host := req . Header . Get ( \" \" ) ; host != \" \" { req . Host = host }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Fix", "bug", "where", "jobs", "with", "zero", "arguments", "were", "not", "being", "executed", "correctly", "."], "add_tokens": "// Use reflection to instantiate arguments for the handler args := [ ] reflect . Value { } if job . typ . dataType != nil { // Instantiate a new variable to hold this argument dataVal := reflect . New ( job . typ . dataType ) if err := decode ( job . data , dataVal . Interface ( ) ) ; err != nil { // TODO: set the job status to StatusError instead of panicking panic ( err ) } args = append ( args , dataVal . Elem ( ) ) // Call the handler using the arguments we just instantiated handlerVal . Call ( args )", "del_tokens": "// Instantiate a new variable to hold the data for this job dataVal := reflect . New ( job . typ . dataType ) if err := decode ( job . data , dataVal . Interface ( ) ) ; err != nil { // TODO: set the job status to StatusError instead of panicking panic ( err ) // Call the handler using the data we just instantiated and scanned handlerVal . Call ( [ ] reflect . Value { dataVal . Elem ( ) } )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "temporary", "swap", "variable", "instead", "of", "copying", "slices"], "add_tokens": "var swp [ ] complex128 swp = t t = r r = swp", "del_tokens": "copy ( r , t )", "commit_type": "use"}
{"commit_tokens": ["Adds", "DataField", "()", "function", "to", "HelperArg"], "add_tokens": "// Returns input data func ( h * HelperArg ) Data ( ) interface { } { return h . eval . curCtx ( ) } func ( h * HelperArg ) DataField ( name string ) interface { } { return Str ( h . DataField ( name ) )", "del_tokens": "func ( h * HelperArg ) Data ( name string ) interface { } { return Str ( h . Data ( name ) )", "commit_type": "add"}
{"commit_tokens": ["Move", "gomega", "tests", "to", "a", "different", "package", "so", "goblin", "tests", "do", "not", "depend", "on", "a", "third", "party", "library"], "add_tokens": "package gomega . \" \"", "del_tokens": "package goblin", "commit_type": "move"}
{"commit_tokens": ["fix", "getting", "job", "exit", "status"], "add_tokens": "exitStatus = uint32 ( link . ProcessState . Sys ( ) . ( syscall . WaitStatus ) . ExitStatus ( ) )", "del_tokens": "// TODO: why do I need to modulo this? exitStatus = uint32 ( link . ProcessState . Sys ( ) . ( syscall . WaitStatus ) % 255 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "virtual", "docs"], "add_tokens": "for i , v := range path { case * opalog . Rule : return nil , notFoundError ( \" \" , path , i - 1 ) return nil , notFoundError ( \" \" , path , i )", "del_tokens": "for _ , v := range path { return nil , & StorageError { Code : StorageInternalErr , Message : fmt . Sprintf ( \" \" , path ) }", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "set", "lastRun", "before", "running", "the", "function"], "add_tokens": "result = f . Call ( in )", "del_tokens": "result = f . Call ( in )", "commit_type": "fix"}
{"commit_tokens": ["Add", "mutex", "around", "sending", "bytes", "with", "publisher"], "add_tokens": "\" \" mux sync . Mutex zep . mux . Lock ( ) defer zep . mux . Unlock ( )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "function", "for", "duplicating", "a", "slice", "of", "runes"], "add_tokens": "seps := duplicateRuneSlice ( sepsOriginal ) alphabet := duplicateRuneSlice ( h . alphabet ) result := duplicateRuneSlice ( alphabet ) func duplicateRuneSlice ( data [ ] rune ) [ ] rune { result := make ( [ ] rune , len ( data ) ) copy ( result , data ) return result }", "del_tokens": "seps := make ( [ ] rune , len ( sepsOriginal ) ) copy ( seps , sepsOriginal ) alphabet := make ( [ ] rune , len ( h . alphabet ) ) copy ( alphabet , h . alphabet ) result := make ( [ ] rune , len ( alphabet ) ) copy ( result , alphabet )", "commit_type": "add"}
{"commit_tokens": ["Allow", "readline", "to", "set", "defaults"], "add_tokens": "c := & readline . Config { Stdin : s . Stdin , Stdout : s . Stdout , } c . Stdin = readline . NewCancelableStdin ( c . Stdin )", "del_tokens": "stdin := readline . NewCancelableStdin ( s . Stdin ) c := & readline . Config { } c . Stdin = stdin c . Stdout = s . Stdout", "commit_type": "allow"}
{"commit_tokens": ["use", "exclude", "annotation", "tag", "in", "nested", "ToStruct", "call"], "add_tokens": "err = d . ToStruct ( obj . Interface ( ) , excludeAnnotationTag )", "del_tokens": "err = d . ToStruct ( obj . Interface ( ) , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Use", "strings", "for", "URLs", "not", "url", ".", "URL"], "add_tokens": "func Href ( value string ) * SimpleElement { return newSEString ( \" \" , value ) } func TargetHref ( value string ) * SimpleElement { return newSEString ( \" \" , value ) }", "del_tokens": "\" \" func Href ( value * url . URL ) * SimpleElement { return newSEString ( \" \" , value . String ( ) ) } func TargetHref ( value * url . URL ) * SimpleElement { return newSEString ( \" \" , value . String ( ) ) } func HrefMustParse ( value string ) * SimpleElement { url , err := url . Parse ( value ) if err != nil { panic ( err ) } return Href ( url ) }", "commit_type": "use"}
{"commit_tokens": ["Use", "gopkg", ".", "in", "in", "examples"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Adding", "Expiration", "TTL", "for", "contextValues"], "add_tokens": "// Map of Context values to limit. contextValues map [ string ] * gocache . Cache tokenBucketExpirationTTL time . Duration basicAuthExpirationTTL time . Duration headerEntryExpirationTTL time . Duration contextEntryExpirationTTL time . Duration // SetHeaderEntryExpirationTTL is thread-safe way of setting custom basic auth expiration TTL. func ( l * Limiter ) SetContextEntryEntryExpirationTTL ( ttl time . Duration ) * Limiter { l . Lock ( ) l . contextEntryExpirationTTL = ttl l . Unlock ( ) return l } // GetHeaderEntryExpirationTTL is thread-safe way of getting custom basic auth expiration TTL. func ( l * Limiter ) GetContextEntryExpirationTTL ( ) time . Duration { l . RLock ( ) defer l . RUnlock ( ) return l . contextEntryExpirationTTL }", "del_tokens": "tokenBucketExpirationTTL time . Duration basicAuthExpirationTTL time . Duration headerEntryExpirationTTL time . Duration", "commit_type": "add"}
{"commit_tokens": ["moving", "SetVar", "/", "GetVar", "(", "and", "specialized", "sets", ")", "in", "cmd", "so", "they", "can", "be", "used", "by", "end", "-", "user", "applications", "."], "add_tokens": "cf . cmd . SetVar ( \" \" , res , true ) if cf . cmd . GetBoolVar ( \" \" ) {", "del_tokens": "cf . ctx . SetVar ( \" \" , res , true ) if cf . ctx . GetBoolVar ( \" \" ) {", "commit_type": "move"}
{"commit_tokens": ["remove", "obsolete", "sleep", "from", "get", "usage", ";", "update", "global", "get", "comment"], "add_tokens": "// Get returns the current disk usage using the package's global Profiler. // The profiler is lazily instantiated. This means that probability of // the first utilization snapshot returning inaccurate information is high // due to the lack of time elapsing between the initial and current // snapshot for utilization calculation.", "del_tokens": "time . Sleep ( time . Second ) // Get returns the current disk usage using the package's global Profiler..", "commit_type": "remove"}
{"commit_tokens": ["Fix", "panic", "when", "a", "map", "contains", "pointers"], "add_tokens": "elementsAreValues := base . Type ( ) . Elem ( ) . Kind ( ) != reflect . Ptr if elementsAreValues && newVal . Kind ( ) == reflect . Ptr {", "del_tokens": "if newVal . Kind ( ) == reflect . Ptr {", "commit_type": "fix"}
{"commit_tokens": ["fix", "data", "race", "of", "baseFileWriter", "&&", "BLog"], "add_tokens": "writer . file . Close ( )", "del_tokens": "writer . lock . Lock ( ) writer . lock . Unlock ( ) writer . file . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "invalid", "datum", "reader", "/", "writer", "behavior", "on", "empty", "arrays", "/", "maps"], "add_tokens": "if arrayLength == 0 { break } if mapLength == 0 { break } if arrayLength == 0 { break } if mapLength == 0 { break }", "del_tokens": "} else if arrayLength == 0 { break } else if mapLength == 0 { break } else if arrayLength == 0 { break } else if mapLength == 0 { break", "commit_type": "fix"}
{"commit_tokens": ["Fix", "panic", "from", "not", "checking", "for", "nil"], "add_tokens": "\" \" s := c . Get ( key ) if s == nil { return nil , fmt . Errorf ( \" \" , name ) } store := s . ( sessions . Store )", "del_tokens": "store := c . Get ( key ) . ( sessions . Store )", "commit_type": "fix"}
{"commit_tokens": ["Add", "REST", "API", "expression", "browser", "and", "text", "/", "JSON", "output", "formats", "."], "add_tokens": "\" \" \" \" gorest . RegisterService ( new ( api . MetricsService ) ) http . Handle ( \" \" , gorest . Handle ( ) ) http . Handle ( \" \" , http . StripPrefix ( \" \" , http . FileServer ( http . Dir ( \" \" ) ) ) ) //fmt.Printf(\"scrapeResult -> %s\\n\", scrapeResult) //fmt.Printf(\"ruleResult -> %s\\n\", ruleResult)", "del_tokens": "fmt . Printf ( \" \\n \" , scrapeResult ) fmt . Printf ( \" \\n \" , ruleResult )", "commit_type": "add"}
{"commit_tokens": ["Add", "aliases", "to", "the", "line", "after", "the", "associated", "argument"], "add_tokens": "- - fifth bool * * DEPRECATED * * the fifth flag - - first , - 1 bool ( required ) the first flag ( aliases : -- one , -- uno ) - - fourth string * * EXPERIMENTAL * * the fourth flag - - second , - 2 string ( required , variadic ) the second flag ( default : true ) - - third , THIRD , THREE string the third flag", "del_tokens": "- - fifth bool * * DEPRECATED * * the fifth flag - - first , - 1 , - - one , - - uno bool ( required ) the first flag - - fourth string * * EXPERIMENTAL * * the fourth flag - - second , - 2 string ( required , variadic ) the second flag ( default : true ) - - third , THIRD , THREE string the third flag", "commit_type": "add"}
{"commit_tokens": ["Added", "data", "directory", "path", "to", "options"], "add_tokens": "// Init data directory path if err = p . initDataDirectory ( o . DataDirectoryPath , o . AppName ) ; err != nil { err = errors . Wrap ( err , \" \" ) return } func ( p * Paths ) initDataDirectory ( dataDirectoryPath , appName string ) ( err error ) { // Path is specified in the options if len ( dataDirectoryPath ) > 0 { // We need the absolute path if p . dataDirectory , err = filepath . Abs ( dataDirectoryPath ) ; err != nil { err = errors . Wrapf ( err , \" \" , dataDirectoryPath ) return } return } // If the APPDATA env exists, we use it // Default to base directory path return", "del_tokens": "p . initDataDirectory ( o . AppName ) func ( p * Paths ) initDataDirectory ( appName string ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "unnecessary", "202", "ACCEPTED", "check"], "add_tokens": "if res . StatusCode != http . StatusOK && res . StatusCode != http . StatusCreated {", "del_tokens": "if res . StatusCode != http . StatusOK && res . StatusCode != http . StatusAccepted && res . StatusCode != http . StatusCreated {", "commit_type": "remove"}
{"commit_tokens": ["use", "AddListener", "/", "RemoveListener", "for", "public", "API"], "add_tokens": "AddListener ( listener NodeCacheListener ) RemoveListener ( listener NodeCacheListener ) func ( c * NodeCacheListenerContainer ) AddListener ( listener NodeCacheListener ) { c . Add ( listener ) func ( c * NodeCacheListenerContainer ) RemoveListener ( listener NodeCacheListener ) { c . Remove ( listener ) c . client . ConnectionStateListenable ( ) . AddListener ( c . connectionStateListener ) c . client . ConnectionStateListenable ( ) . RemoveListener ( c . connectionStateListener )", "del_tokens": "Add ( listener NodeCacheListener ) Remove ( listener NodeCacheListener ) func ( c * NodeCacheListenerContainer ) Add ( listener NodeCacheListener ) { c . AddListener ( listener ) func ( c * NodeCacheListenerContainer ) Remove ( listener NodeCacheListener ) { c . RemoveListener ( listener ) c . client . ConnectionStateListenable ( ) . Add ( c . connectionStateListener ) c . client . ConnectionStateListenable ( ) . Remove ( c . connectionStateListener )", "commit_type": "use"}
{"commit_tokens": ["Implement", "function", "to", "collect", "received", "packets", "."], "add_tokens": "NodeSessionTTL = time . Hour * 24 * 5", "del_tokens": "\" \" NodeSessionTTL = time . Hour * 24 * 5 }", "commit_type": "implement"}
{"commit_tokens": ["Fix", "tests", "and", "add", "benchmarks", "for", "more", "record", "types"], "add_tokens": "for _ , f := range fixtures { err := record . Serialize ( buf ) if err != nil { b . Fatal ( err ) } someRecord . Set ( \" \" , int32 ( 1 ) ) someRecord . Set ( \" \" , int64 ( 2 ) ) someRecord . Set ( \" \" , float32 ( 3.4 ) ) someRecord . Set ( \" \" , float64 ( 5.6 ) ) err := codec . Encode ( buf , someRecord ) if err != nil { b . Fatal ( err ) }", "del_tokens": "\" \" for i , f := range fixtures { fmt . Printf ( \" \\n \" , i ) fmt . Printf ( \" \\n \" , buf . Bytes ( ) ) record . Serialize ( buf ) someRecord . Set ( \" \" , 1 ) someRecord . Set ( \" \" , 2 ) someRecord . Set ( \" \" , 3.4 ) someRecord . Set ( \" \" , 5.6 ) codec . Encode ( buf , someRecord )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "custom", "pager", "to", "be", "specified"], "add_tokens": "if s . pager == \" \" { if runtime . GOOS == \" \" { s . pager = \" \" } else { s . pager = \" \" } cmd = exec . Command ( s . pager , s . pagerArgs ... )", "del_tokens": "if runtime . GOOS == \" \" { cmd = exec . Command ( \" \" ) } else { cmd = exec . Command ( \" \" )", "commit_type": "allow"}
{"commit_tokens": ["Use", "OSS", "as", "i18n", "file", "upload", "backend"], "add_tokens": "\" \" TranslationsFile oss . OSS", "del_tokens": "\" \" TranslationsFile media_library . FileSystem", "commit_type": "use"}
{"commit_tokens": ["Adds", "a", "job", "route", ".", "And", "patches", "job", "creation", "through", "."], "add_tokens": "mux . HandleFunc ( \" \" , BranchHandler ) mux . HandleFunc ( \" \" , JobHandler )", "del_tokens": "mux . HandleFunc ( \" \" , BranchHandler )", "commit_type": "add"}
{"commit_tokens": ["add", "filter", "flag", "and", "support", "for", "file", "reading"], "add_tokens": "Filter string var h * pcap . Handle var err error if m . Filename != \" \" { h , err = pcap . OpenOffline ( m . Filename ) } else { h , err = pcap . OpenLive ( m . Iface , m . Snaplen , m . Promisc , m . Timeout ) } err = h . SetBPFFilter ( m . Filter )", "del_tokens": "h , err := pcap . OpenLive ( m . Iface , m . Snaplen , m . Promisc , m . Timeout ) err = h . SetBPFFilter ( \" \" ) log . Printf ( \" \" ) fmt . Println ( ) log . Printf ( \" \" ) fmt . Println ( )", "commit_type": "add"}
{"commit_tokens": ["fix", "non", "-", "standard", "NameChars", "comment"], "add_tokens": "// NameChars are the allowed name characters in the beanstalkd protocol.", "del_tokens": "// Characters allowed in a name in the beanstalkd protocol.", "commit_type": "fix"}
{"commit_tokens": ["Implement", "OOB", "in", "Send", "()", "and", "add", "SendOOB", "()", "function", "for", "messages", "without", "body"], "add_tokens": "Ooburl string Oobdesc string var subtext , thdtext , oobtext string if chat . Ooburl != `` { oobtext = `<x xmlns=\"jabber:x:oob\"><url>` + xmlEscape ( chat . Ooburl ) + `</url>` if chat . Oobdesc != `` { oobtext += `<desc>` + xmlEscape ( chat . Oobdesc ) + `</desc>` } oobtext += `</x>` } stanza := \" \" + subtext + \" \" + oobtext + thdtext + \" \" // SendOOB sends OOB data wrapped inside an XMPP message stanza, without actual body. func ( c * Client ) SendOOB ( chat Chat ) ( n int , err error ) { var thdtext , oobtext string if chat . Thread != `` { thdtext = `<thread>` + xmlEscape ( chat . Thread ) + `</thread>` } if chat . Ooburl != `` { oobtext = `<x xmlns=\"jabber:x:oob\"><url>` + xmlEscape ( chat . Ooburl ) + `</url>` if chat . Oobdesc != `` { oobtext += `<desc>` + xmlEscape ( chat . Oobdesc ) + `</desc>` } oobtext += `</x>` } return fmt . Fprintf ( c . conn , \" \" + oobtext + thdtext + \" \" , xmlEscape ( chat . Remote ) , xmlEscape ( chat . Type ) , cnonce ( ) ) }", "del_tokens": "var subtext = `` var thdtext = `` stanza := \" \" + subtext + \" \" + thdtext + \" \"", "commit_type": "implement"}
{"commit_tokens": ["add", "a", "RPC", "version", "checker"], "add_tokens": "// RPCVersion returns true if the lib RPC version is greater or equals to the remote server rpc minimum version. func ( c * Client ) RPCVersion ( ) ( ok bool , serverVersion int64 , serverMinimumVersion int64 , err error ) { payload , err := c . SessionArgumentsGet ( ) if err != nil { err = fmt . Errorf ( \" \" , err ) return } if payload . RPCVersion == nil { err = fmt . Errorf ( \" \" ) return } if payload . RPCVersionMinimum == nil { err = fmt . Errorf ( \" \" ) return } serverVersion = * payload . RPCVersion serverMinimumVersion = * payload . RPCVersionMinimum ok = RPCVersion >= serverMinimumVersion return } var currentValue reflect . Value var currentStructField reflect . StructField", "del_tokens": "var currentValue , nestedStruct , currentNestedValue reflect . Value var currentStructField , currentNestedStructField reflect . StructField var j int", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectEq ( \" \" , body )", "del_tokens": "ExpectEq ( \" \" , body )", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "hostname", "validation", "on", "newer", "openssl"], "add_tokens": "unsigned int flags , char * * peername ) ; C . uint ( flags ) , nil )", "del_tokens": "unsigned int flags ) ; C . uint ( flags ) )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "(", "capital", ")", "AS", "in", "FROM", "statement"], "add_tokens": "if ! strings . EqualFold ( n . Value , \" \" ) || n . Next == nil || len ( n . Next . Value ) == 0 {", "del_tokens": "if n . Value != \" \" || n . Next == nil || len ( n . Next . Value ) == 0 {", "commit_type": "allow"}
{"commit_tokens": ["fixing", "up", "jump", "points", "to", "use", "next"], "add_tokens": "positiveLabels : make ( map [ label ] [ ] uint ) , negativeLabels : make ( map [ label ] [ ] uint ) , positiveLabels map [ label ] [ ] uint negativeLabels map [ label ] [ ] uint cv := & compilerVisitor { c : c , topLevel : true , jf : negative , jt : positive } tree . LT : kexInstruction { k : JEGE_K , x : JEGE_X } , tree . LTE : kexInstruction { k : JEG_K , x : JEG_X } , // TODO how to handle setPosFlags bool c . jumpOnKComp ( sys , tree . EQL , noLabel , negative )", "del_tokens": "positiveLabels : make ( map [ label ] [ ] labelInfo ) , negativeLabels : make ( map [ label ] [ ] labelInfo ) , positiveLabels map [ label ] [ ] labelInfo negativeLabels map [ label ] [ ] labelInfo cv := & compilerVisitor { c : c , terminal : true , exclusive : false , negated : false , inverted : false , topLevel : true } tree . LT : kexInstruction { k : JEG_K , x : JEG_X } , tree . LTE : kexInstruction { k : JEGE_K , x : JEGE_X } , c . jumpOnSyscallComparison ( sys , tree . EQL , true , setPosFlags )", "commit_type": "fix"}
{"commit_tokens": ["Make", "GetArray", "and", "AsArray", "return", "primitive"], "add_tokens": "func ( v * Value ) GetArray ( keys ... string ) ( [ ] * Value , error ) { return child . AsArray ( ) func ( j * Value ) AsArray ( ) ( [ ] * Value , error ) { return a . slice , err", "del_tokens": "func ( v * Value ) GetArray ( keys ... string ) ( * Array , error ) { obj , err := child . AsArray ( ) if err != nil { return nil , err } else { return obj , nil } // Check IsArray() before using if you want to know. func ( j * Value ) AsArray ( ) ( * Array , error ) { return a , err", "commit_type": "make"}
{"commit_tokens": ["fixed", "/", "n", "to", "\\", "n"], "add_tokens": "fmt . Printf ( \" \\n \" )", "del_tokens": "fmt . Printf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "data", "race", "between", "Reset", "and", "Add"], "add_tokens": "t . next = t . mock . now . Add ( d )", "del_tokens": "t . next = t . mock . now . Add ( d )", "commit_type": "fix"}
{"commit_tokens": ["Use", "leaky", "buffer", "to", "when", "piping", "data", "."], "add_tokens": "\" \" const bufSize = 4096 const nBuf = 2048 var pipeBuf = leakybuf . NewLeakyBuf ( nBuf , bufSize ) buf := pipeBuf . Get ( ) defer pipeBuf . Put ( buf )", "del_tokens": "buf := make ( [ ] byte , 4096 )", "commit_type": "use"}
{"commit_tokens": ["add", "readme", "and", "example", "of", "kie"], "add_tokens": "ConfigCenterSource = \" \"", "del_tokens": "ConfigCenterSource = \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "slow", "close", "and", "timeout", "toxics"], "add_tokens": "t \" \" stubs [ ] * t . ToxicStub stubs : make ( [ ] * t . ToxicStub , t . MaxToxics ) , for i := 0 ; i < t . MaxToxics ; i ++ { link . stubs [ i ] = t . NewToxicStub ( last , next ) func ( link * ToxicLink ) pipe ( toxic t . Toxic , stub * t . ToxicStub ) { stub . Unblock ( link . closed ) func ( link * ToxicLink ) SetToxic ( toxic t . Toxic , index int ) {", "del_tokens": "stubs [ ] * ToxicStub stubs : make ( [ ] * ToxicStub , MaxToxics ) , for i := 0 ; i < MaxToxics ; i ++ { link . stubs [ i ] = NewToxicStub ( proxy , last , next ) func ( link * ToxicLink ) pipe ( toxic Toxic , stub * ToxicStub ) { for { select { case <- stub . interrupt : case <- link . closed : return } } func ( link * ToxicLink ) SetToxic ( toxic Toxic , index int ) {", "commit_type": "add"}
{"commit_tokens": ["add", "getservices", "and", "localservices", "methods"], "add_tokens": "\" \" \" \" fmt . Println ( \" \" ) fmt . Println ( \" \" ) \" \" + os . Getenv ( \" \" ) , \" \" + os . Getenv ( \" \" ) ,", "del_tokens": "\" \" \" \" fmt . Println ( \" \" ) fmt . Println ( \" \" ) \" \" , \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Use", "random", "local", "ports", "for", "NetRecorder"], "add_tokens": "return newNetRecorder ( \" \" , randomAddress ( ) , false ) return newNetRecorder ( \" \" , randomAddress ( ) , true ) func randomAddress ( ) string { l , err := net . Listen ( \" \" , \" \" ) defer l . Close ( ) if err != nil { panic ( err ) } return l . Addr ( ) . String ( ) }", "del_tokens": "const ( testAddress = \" \" ) return newNetRecorder ( \" \" , testAddress , false ) return newNetRecorder ( \" \" , testAddress , true )", "commit_type": "use"}
{"commit_tokens": ["Add", "locals", ".", "lua", "testcase"], "add_tokens": "\" \" , \" \" , //\"sort\", //\"vararg\",", "del_tokens": "\" \" , // \"vararg\",", "commit_type": "add"}
{"commit_tokens": ["move", "html", "templates", "inside", "the", "GO", "code"], "add_tokens": "const standAloneServicesFileName = \" \" f , err := os . OpenFile ( Config . ConfigDir + string ( os . PathSeparator ) + standAloneServicesFileName , os . O_RDONLY , 0666 ) if err != nil { return err } var b [ ] byte _ , err = f . Read ( b ) return ioutil . WriteFile ( Config . ConfigDir + string ( os . PathSeparator ) + standAloneServicesFileName , jsonData , 0655 )", "del_tokens": "b , err := ioutil . ReadFile ( Config . ConfigDir + string ( os . PathSeparator ) + \" \" ) return ioutil . WriteFile ( Config . ConfigDir + string ( os . PathSeparator ) + \" \" , jsonData , 0655 )", "commit_type": "move"}
{"commit_tokens": ["Change", "the", "inheritance", "for", "MembershipRole"], "add_tokens": "\" \" : \" \" , \" \" : \" \" ,", "del_tokens": "\" \" : \" \" , \" \" : \" \" ,", "commit_type": "change"}
{"commit_tokens": ["Add", "initial", "index", "reader", "implementation"], "add_tokens": "b := [ 5 ] byte { flagStd , 0 , 0 , 0 , 0 } binary . BigEndian . PutUint32 ( b [ 1 : ] , l ) buf := [ binary . MaxVarintLen32 ] byte { } n := binary . PutUvarint ( buf [ : ] , uint64 ( len ( e . name ) ) ) b = append ( b , buf [ : n ] ... ) n = binary . PutUvarint ( buf [ : ] , uint64 ( e . offset ) ) b = append ( b , buf [ : n ] ... )", "del_tokens": "b := [ 5 ] byte { } binary . BigEndian . PutUint32 ( b [ : 4 ] , l ) b [ 4 ] = flagStd buf := make ( [ ] byte , 4 ) binary . PutUvarint ( buf , uint64 ( len ( e . name ) ) ) b = append ( b , buf ... ) binary . BigEndian . PutUint32 ( buf , e . offset ) b = append ( b , buf ... )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "actualError := \" \" if err != nil { actualError = err . Error ( ) } if actualError != c . expectedError {", "del_tokens": "if err . Error ( ) != c . expectedError {", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "index", "options", "mechanism"], "add_tokens": "func ( s * Schema ) Index ( name string , options ... * IndexOptions ) ( * Index , error ) { var indexOptions * IndexOptions if len ( options ) == 1 { indexOptions = options [ 0 ] } else if len ( options ) > 1 { return nil , ErrInvalidIndexOption } index , err := NewIndex ( name , indexOptions )", "del_tokens": "func ( s * Schema ) Index ( name string , options * IndexOptions ) ( * Index , error ) { index , err := NewIndex ( name , options )", "commit_type": "add"}
{"commit_tokens": ["Add", "log", "output", "options", "and", "sortable", "output"], "add_tokens": "\" \" \" \" logJSON bool flag . StringVar ( & proxyCommandLineConfiguration . logDir , \" \" , os . TempDir ( ) , \" \" ) flag . BoolVar ( & proxyCommandLineConfiguration . logJSON , \" \" , false , \" \" ) func ( proxyCommandLineConfiguration * proxyCommandLineConfigurationT ) getLogrusOutput ( ) io . Writer { if proxyCommandLineConfiguration . logDir == \" \" { fmt . Printf ( \" \" ) return os . Stdout } return lumberjackLogger } func ( proxyCommandLineConfiguration * proxyCommandLineConfigurationT ) getLogrusFormatter ( ) logrus . Formatter { if proxyCommandLineConfiguration . logJSON { return & log . JSONFormatter { } } return & log . TextFormatter { DisableColors : true } } func ( proxyCommandLineConfiguration * proxyCommandLineConfigurationT ) setupLogrus ( ) { out := proxyCommandLineConfiguration . getLogrusOutput ( ) formatter := proxyCommandLineConfiguration . getLogrusFormatter ( ) log . SetOutput ( out ) log . SetFormatter ( formatter )", "del_tokens": "flag . StringVar ( & proxyCommandLineConfiguration . logDir , \" \" , os . TempDir ( ) , \" \" ) func ( proxyCommandLineConfiguration * proxyCommandLineConfigurationT ) setupLogrus ( ) { log . SetOutput ( lumberjackLogger ) log . SetFormatter ( & log . TextFormatter { DisableColors : true } )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "container", ".", "Vector", "as", "section", "value"], "add_tokens": "//if the context is an interface, get the actual value if iface , ok := context . ( * reflect . InterfaceValue ) ; ok && ! iface . IsNil ( ) { context = iface . Elem ( ) } //the context may be a pointer, so do an indirect contextInd := reflect . Indirect ( context ) var ret reflect . Value = nil switch val := contextInd . ( type ) { ret = val . Elem ( reflect . NewValue ( name ) ) ret = val . FieldByName ( name ) //if the lookup value is an interface, return the actual value if iface , ok := ret . ( * reflect . InterfaceValue ) ; ok && ! iface . IsNil ( ) { ret = iface . Elem ( ) } return ret", "del_tokens": "switch val := context . ( type ) { return val . Elem ( reflect . NewValue ( name ) ) return val . FieldByName ( name ) return nil", "commit_type": "add"}
{"commit_tokens": ["Add", "migration", "and", "new", "schema", "version", "for", "resource_string"], "add_tokens": "Create : CreateString , Read : ReadString , Delete : schema . RemoveFromState , MigrateState : resourceRandomStringMigrateState , SchemaVersion : 1 ,", "del_tokens": "Create : CreateString , Read : ReadString , Delete : schema . RemoveFromState ,", "commit_type": "add"}
{"commit_tokens": ["change", "panic", "to", "just", "Println"], "add_tokens": "fmt . Println ( \" \" )", "del_tokens": "panic ( \" \" )", "commit_type": "change"}
{"commit_tokens": ["Allow", "Playlist", "description", "to", "be", "added", "/", "modified", "on", "playlist", "creation", "/", "modification"], "add_tokens": "\" \" : \" \" , p , err := client . CreatePlaylistForUser ( \" \" , \" \" , \" \" , false ) if p . Description != \" \" { t . Errorf ( \" \\n \" , p . Description ) } func TestChangePlaylistDescription ( t * testing . T ) { client , server := testClientString ( http . StatusOK , \" \" ) defer server . Close ( ) if err := client . ChangePlaylistDescription ( ID ( \" \" ) , \" \" ) ; err != nil { t . Error ( err ) } } func TestChangePlaylistNamdAccessAndDescription ( t * testing . T ) { client , server := testClientString ( http . StatusOK , \" \" ) defer server . Close ( ) if err := client . ChangePlaylistNameAccessAndDescription ( ID ( \" \" ) , \" \" , \" \" , true ) ; err != nil { t . Error ( err ) } }", "del_tokens": "\" \" : null , p , err := client . CreatePlaylistForUser ( \" \" , \" \" , false )", "commit_type": "allow"}
{"commit_tokens": ["make", "example", "easier", "to", "understand", "(", "used", "from", "outside", "the", "goquery", "package", ")"], "add_tokens": "doc , err := NewDocument ( \" \" ) if err != nil { log . Fatal ( err )", "del_tokens": "var doc * Document var e error if doc , e = NewDocument ( \" \" ) ; e != nil { log . Fatal ( e )", "commit_type": "make"}
{"commit_tokens": ["allow", "nil", "for", "dialer", "laddr"], "add_tokens": "if laddr == nil { zaddr , err := ma . NewMultiaddr ( \" \" ) if err != nil { return nil , err } laddr = zaddr }", "del_tokens": "if raddr == nil { zaddr , err := ma . NewMultiaddr ( \" \" ) if err != nil { return nil , err } raddr = zaddr }", "commit_type": "allow"}
{"commit_tokens": ["moved", "resource", "cleanup", "back", "to", "tests", "since", "experiencing", "failures", "with", "ssh", "/", "vg", "cleanups"], "add_tokens": "\" \" testhelpers \" \" func cleanUpTestResources ( ) { virtualGuestIds , err := testhelpers . FindAndDeleteTestVirtualGuests ( ) Expect ( err ) . ToNot ( HaveOccurred ( ) ) for _ , vgId := range virtualGuestIds { waitForVirtualGuestToHaveNoActiveTransactions ( vgId ) } err = testhelpers . FindAndDeleteTestSshKeys ( ) Expect ( err ) . ToNot ( HaveOccurred ( ) ) }", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Fix", "initialization", "to", "use", "apid", "events", "instead", "of", "a", "new", "plugin", "callback"], "add_tokens": "func postInitPlugins ( ) { events . Listen ( apid . PluginsInitializedEvent , postInitPlugins )", "del_tokens": "apid . RegisterPostPlugin ( postinitPlugin ) func postinitPlugin ( services apid . Services ) error { return nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "syntax", "error", "and", "duplicate", "import"], "add_tokens": "\" \" } }", "del_tokens": "\" \" \" \" )", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "information", "in", "user", "agent", "and", "allow", "changing", "it", "with", "config"], "add_tokens": "\" \" goVersion = runtime . Version ( ) presets = map [ string ] Settings { UserAgent : \" \" + goVersion + \" \" , UserAgent : \" \" + goVersion + \" \" , UserAgent : \" \" + goVersion + \" \" , if vers , found := data [ \" \" ] ; found { s . ApiVersion = vers . ( string ) }", "del_tokens": "presets = map [ string ] Settings { UserAgent : \" \" , UserAgent : \" \" , UserAgent : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Added", "/", "libStorage", "/", "config"], "add_tokens": "serviceName := config . GetString ( \" \" ) if serviceName == \" \" { return nil , goof . New ( \" \" ) log . WithField ( \" \" , serviceName ) . Debug ( \" \" ) c . url = fmt . Sprintf ( \" \" , laddr , serviceName )", "del_tokens": "serverName := config . GetString ( \" \" ) if serverName == \" \" { return nil , goof . New ( \" \" ) log . WithField ( \" \" , serverName ) . Debug ( \" \" ) c . url = fmt . Sprintf ( \" \" , laddr , serverName )", "commit_type": "add"}
{"commit_tokens": ["Updating", "examples", "for", "json", "pem", "auth", "approach"], "add_tokens": "bqClient := client . New ( JSON_PEM_PATH )", "del_tokens": "const SERVICE_ACCOUNT_EMAIL = \" \" const SERVICE_ACCOUNT_CLIENT_ID = \" \" const SECRET = \" \" bqClient := client . New ( PEM_PATH , SERVICE_ACCOUNT_EMAIL , SERVICE_ACCOUNT_CLIENT_ID , SECRET )", "commit_type": "update"}
{"commit_tokens": ["Make", "_example", "/", "main", ".", "go", "a", "Godoc", "example"], "add_tokens": "package toml_test \" \" \" \" type Config struct { Servers map [ string ] ServerInfo type ServerInfo struct { IP net . IP func Example ( ) { f , err := os . Open ( \" \" ) var config Config if err := toml . NewDecoder ( f ) . Decode ( & config ) ; err != nil { fmt . Println ( \" \" , config . Servers [ \" \" ] . IP ) // Output: IP of server 'alpha': 10.0.0.1", "del_tokens": "package main \" \" type tomlConfig struct { Servers struct { Alpha Server Beta Server } type Server struct { IP string func main ( ) { f , err := os . Open ( \" \" ) buf , err := ioutil . ReadAll ( f ) if err != nil { var config tomlConfig if err := toml . Unmarshal ( buf , & config ) ; err != nil { panic ( err ) } // then to use the unmarshaled config...", "commit_type": "make"}
{"commit_tokens": ["fixed", "heartbeat", "reconnect", "intermittent", "failure"], "add_tokens": "case keep := <- r . keepAliveChan : if keep != nil { log . Debugf ( \" \" , keep ) status = alive }", "del_tokens": "case <- r . keepAliveChan : status = alive", "commit_type": "fix"}
{"commit_tokens": ["add", "size", "checking", "before", "write"], "add_tokens": "case <- logger . flush : // do nothing if len ( b . Bytes ( ) ) > 0 { logger . out . Write ( b . Bytes ( ) ) b . Reset ( ) }", "del_tokens": "logger . out . Write ( b . Bytes ( ) ) b . Reset ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "DMACode", "and", "MetroCode", "fields", "to", "GeoIPRecord", "and", "only", "get", "AreaCode", "if", "db", "version", ">", "0"], "add_tokens": "CountryCode string CountryCode3 string CountryName string Region string City string PostalCode string Latitude float32 Longitude float32 MetroCode int if gi . db . databaseType != C . GEOIP_CITY_EDITION_REV0 { / * DIRTY HACK BELOW : The GeoIPRecord struct in GeoIPCity . h contains an int32 union of metro_code and dma_code . The union is unnamed , so cgo names it anon0 and assumes it 's a 4 - byte array . * / union_int := ( * int32 ) ( unsafe . Pointer ( & record . anon0 ) ) rec . MetroCode = int ( * union_int ) rec . AreaCode = int ( record . area_code ) }", "del_tokens": "CountryCode string CountryCode3 string CountryName string Region string City string PostalCode string Latitude float32 Longitude float32 // DMACode int rec . AreaCode = int ( record . area_code )", "commit_type": "add"}
{"commit_tokens": ["Adding", "explicit", "curves", "and", "corresponding", "SSL", "context", "function"], "add_tokens": "static long SSL_CTX_set_tmp_ecdh_not_a_macro ( SSL_CTX * ctx , EC_KEY * key ) { return SSL_CTX_set_tmp_ecdh ( ctx , key ) ; // EllipticCurve repesents the ASN.1 OID of an elliptic curve. // see https://www.openssl.org/docs/apps/ecparam.html for a list of implemented curves. type EllipticCurve int const ( // P-256: X9.62/SECG curve over a 256 bit prime field Prime256v1 EllipticCurve = C . NID_X9_62_prime256v1 // P-384: NIST/SECG curve over a 384 bit prime field Secp384r1 EllipticCurve = C . NID_secp384r1 ) // SetEllipticCurve sets the elliptic curve used by the SSL context to // enable an ECDH cipher suite to be selected during the handshake. func ( c * Ctx ) SetEllipticCurve ( curve EllipticCurve ) error { k := C . EC_KEY_new_by_curve_name ( C . int ( curve ) ) if k == nil { return errors . New ( \" \" ) } defer C . EC_KEY_free ( k ) if int ( C . SSL_CTX_set_tmp_ecdh_not_a_macro ( c . ctx , k ) ) != 1 {", "del_tokens": "static long SSL_CTX_auto_enable_ecdh_not_a_macro ( SSL_CTX * ctx ) { # if defined ( SSL_CTX_set_ecdh_auto ) return SSL_CTX_set_ecdh_auto ( ctx , 1 ) ; # else EC_KEY * k = NULL ; k = EC_KEY_new_by_curve_name ( NID_X9_62_prime256v1 ) ; long result = SSL_CTX_set_tmp_ecdh ( ctx , k ) ; EC_KEY_free ( k ) ; return result ; # endif // EnableECDH sets the elliptic curve on the context to enable an // ECDH cipher suite to be selected. func ( c * Ctx ) EnableECDH ( ) error { if int ( C . SSL_CTX_auto_enable_ecdh_not_a_macro ( c . ctx ) ) != 1 {", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "sub", "-", "interfaces", "."], "add_tokens": "- Sub - interface func addInterfaceDumpTests ( ) { // Sub-interface. v2 := interface { } ( uint16 ( 65535 ) ) pv2 := & v2 v2Addr := fmt . Sprintf ( \" \" , pv2 ) pv2Addr := fmt . Sprintf ( \" \" , & pv2 ) v2t := \" \" v2s := \" \" addDumpTest ( v2 , \" \" + v2t + \" \" + v2s + \" \\n \" ) addDumpTest ( pv2 , \" \" + v2t + \" \" + v2Addr + \" \" + v2s + \" \\n \" ) addDumpTest ( & pv2 , \" \" + v2t + \" \" + pv2Addr + \" \" + v2Addr + \" \" + v2s + \" \\n \" ) addInterfaceDumpTests ( )", "del_tokens": "func addNilInterfaceDumpTests ( ) { addNilInterfaceDumpTests ( )", "commit_type": "add"}
{"commit_tokens": ["fix", "unintuitive", "numeric", "-", "nonnumeric", "comparisons", "of", "prerelease", "information"], "add_tokens": "selfNumeric := true _ , err := strconv . ParseInt ( preSelf , 10 , 64 ) if err != nil { selfNumeric = false } otherNumeric := true _ , err = strconv . ParseInt ( preOther , 10 , 64 ) if err != nil { otherNumeric = false } if otherNumeric { if selfNumeric { if selfNumeric && ! otherNumeric { return - 1 } else if ! selfNumeric && otherNumeric { return 1 } else if preSelf > preOther {", "del_tokens": "_ , notIsNumeric := strconv . ParseInt ( preOther , 10 , 64 ) if notIsNumeric == nil { _ , notIsNumeric := strconv . ParseInt ( preSelf , 10 , 64 ) if notIsNumeric == nil { if preSelf > preOther {", "commit_type": "fix"}
{"commit_tokens": ["Adds", "option", "to", "switch", "between", "skin", "and", "face", "detection", "."], "add_tokens": "useFaceDetection = true // if true, opencv face detection is used instead of skin detection. if useFaceDetection { faceDetect ( img , & o ) fmt . Println ( \" \" , time . Since ( now ) ) if debug { writeImageToPng ( & o , \" \" ) } } else { skinDetect ( img , & o ) fmt . Println ( \" \" , time . Since ( now ) ) if debug { writeImageToPng ( & o , \" \" ) }", "del_tokens": "//now = time.Now() //skinDetect(img, &o) //fmt.Println(\"Time elapsed skin:\", time.Since(now)) //if debug { // writeImageToPng(&o, \"./smartcrop_skin.png\") //} faceDetect ( img , & o ) fmt . Println ( \" \" , time . Since ( now ) ) if debug { writeImageToPng ( & o , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Removing", "old", "YARDdoc", "style", "documentation", "such", "that", "more", "human", "-", "readable", "documentation", "can", "be", "generated", "by", "godoc"], "add_tokens": "// as a URL-encoded entity. Returns an array of byes as a result, or an error if one occurs during the process. // Extracts the first lat and lng values from a Google Geocoder Response body. // Returns an Address from a Google Geocoder Response body.", "del_tokens": "// as URL-encoded entities. Returns an array of byes as a result, or any error incurred along the way // private // TODO Refactor out of MapQuestGeocoder // @param [[]byte] data. The response struct from the earlier mapquest request as an array of bytes. // @return [float64] lat. The first point's latitude in the response. // @return [float64] lng. The first point's longitude in the response.", "commit_type": "remove"}
{"commit_tokens": ["Use", "env", "var", "OS_POOL_NAME", "as", "default", "for", "pool", "attribute"], "add_tokens": "Type : schema . TypeString , Required : true , ForceNew : true , DefaultFunc : envDefaultFunc ( \" \" ) ,", "del_tokens": "Type : schema . TypeString , Required : true , ForceNew : true ,", "commit_type": "use"}
{"commit_tokens": ["Adds", "Multipart", "flag", "to", "operations", "+", "update", "ops", "to", "use", "hash", "style", "."], "add_tokens": "Endpoint Endpoint `query:\"-\"` Method string `query:\"-\"` Path string `query:\"-\"` Values url . Values `query:\"-\"` Multipart bool `query:\"-\"`", "del_tokens": "Endpoint Endpoint `query:\"-\"` Method string `query:\"-\"` Path string `query:\"-\"` Values url . Values `query:\"-\"`", "commit_type": "add"}
{"commit_tokens": ["Remove", "UserUID", "and", "use", "UID", "from", "TypeMeta"], "add_tokens": "existing . User . UID = uid existing . User . UID = uid", "del_tokens": "existing . User . UserUID = uid existing . User . UserUID = uid", "commit_type": "remove"}
{"commit_tokens": ["Changed", "*", "Event", "to", "Event", "for", "PushEvent", "()"], "add_tokens": "func PushEvent ( event Event ) int { _event := ( * C . SDL_Event ) ( unsafe . Pointer ( cEvent ( & event ) ) )", "del_tokens": "func PushEvent ( event * Event ) int { _event := ( * C . SDL_Event ) ( unsafe . Pointer ( cEvent ( event ) ) )", "commit_type": "change"}
{"commit_tokens": ["added", "code", "that", "checks", "vendor", "folders"], "add_tokens": "conf := types . Config { Importer : newImporter ( m . src ) }", "del_tokens": "conf := types . Config { Importer : newImporter ( ) }", "commit_type": "add"}
{"commit_tokens": ["removing", "intentional", "panics", "and", "handles", "errors", "gracefully"], "add_tokens": "return nil , ErrParamsNotAdapted return 0 , 0 , 0 , ErrTimeFormat return 0 , 0 , 0 , err return 0 , 0 , 0 , err return 0 , 0 , 0 , err return 0 , 0 , 0 , ErrTimeFormat", "del_tokens": "\" \" return nil , errors . New ( \" \" ) var er = errors . New ( \" \" ) err = er return return return return err = er return", "commit_type": "remove"}
{"commit_tokens": ["Add", "comment", "and", "usage", "example"], "add_tokens": "// BytesEqual checker. // ByteEquals checker compares two bytes sequence using bytes.Equal. // // For example: // // c.Assert(b, BytesEquals, []byte(\"bar\")) //", "del_tokens": "// BytesEqual checker compares two bytes sequence using bytes.Equal", "commit_type": "add"}
{"commit_tokens": ["fixing", "tests", "to", "use", "proper", "types", "and", "structure"], "add_tokens": "Networks : [ ] InstanceGroupNetwork { InstanceGroupNetwork { * NewInstanceJob ( fakeString , fakeString , struct { } { } ) , Networks : [ ] InstanceGroupNetwork { InstanceGroupNetwork { * NewInstanceJob ( fakeString , fakeString , struct { } { } ) ,", "del_tokens": "Networks : [ ] map [ string ] interface { } { map [ string ] interface { } { InstanceJob { Name : fakeString , Release : fakeString } , Networks : [ ] map [ string ] interface { } { map [ string ] interface { } { InstanceJob { Name : fakeString , Release : fakeString } ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \"", "del_tokens": "expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "retrieving", "context", "from", "database"], "add_tokens": "import ( \" \" log \" \" \" \" ) log . Debug ( \" \" ) err := db . Get ( & tmp , q , si . FlexId , si . FlexIdType ) if err != nil && err != sql . ErrNoRows {", "del_tokens": "import \" \" if err := db . Get ( & tmp , q , si . FlexId , si . FlexIdType ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "duplicate", "and", "in", "GoDoc"], "add_tokens": "// the specified tls configuration. If TLSConfig is set, will encapsulate the", "del_tokens": "// and the specified tls configuration. If TLSConfig is set, will encapsulate the", "commit_type": "remove"}
{"commit_tokens": ["fix", "terrible", "int64", "overflow", "in", "benchmark", "report"], "add_tokens": "sum := float64 ( 0 ) sumOfSquares := float64 ( 0 ) sum += sample . Seconds ( ) sumOfSquares += sample . Seconds ( ) * sample . Seconds ( ) mean := time . Duration ( ( sum / n ) * float64 ( time . Second ) ) stdDev := time . Duration ( math . Sqrt ( sumOfSquares / n - float64 ( sum * sum / n / n ) ) * float64 ( time . Second ) )", "del_tokens": "sum := time . Duration ( 0 ) sumOfSquares := time . Duration ( 0 ) sum += sample sumOfSquares += sample * sample mean := time . Duration ( float64 ( sum ) / n ) stdDev := time . Duration ( math . Sqrt ( float64 ( sumOfSquares ) / n - float64 ( mean * mean ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "bool", "from", "key", "hashing", "types"], "add_tokens": "// getKeyHash returns a hash for the key. Only string and number types are supported.", "del_tokens": "// getKeyHash returns a hash for the key case bool : if x { return 1 } return 0", "commit_type": "remove"}
{"commit_tokens": ["remove", "net", "when", "targeting", "JS"], "add_tokens": "nodeMu sync . Mutex ifname string // name of interface being used nodeID [ 6 ] byte // hardware for version 1 UUIDs zeroID [ 6 ] byte // nodeID with only 0's iname , addr := getHardwareInterface ( name ) // null implementation for js if iname != \" \" && addr != nil { ifname = iname copy ( nodeID [ : ] , addr ) return true", "del_tokens": "\" \" nodeMu sync . Mutex interfaces [ ] net . Interface // cached list of interfaces ifname string // name of interface being used nodeID [ 6 ] byte // hardware for version 1 UUIDs zeroID [ 6 ] byte // nodeID with only 0's if interfaces == nil { var err error interfaces , err = net . Interfaces ( ) if err != nil && name != \" \" { return false } } for _ , ifs := range interfaces { if len ( ifs . HardwareAddr ) >= 6 && ( name == \" \" || name == ifs . Name ) { copy ( nodeID [ : ] , ifs . HardwareAddr ) ifname = ifs . Name return true }", "commit_type": "remove"}
{"commit_tokens": ["Update", "to", "match", "github", ".", "com", "/", "gholt", "/", "ring"], "add_tokens": "tr := ring . NewTCPMsgRing ( nil ) tr . SetRing ( r ) return tr , nil t := ring . NewTCPMsgRing ( nil ) t . SetRing ( s . r ) go func ( ) { t . Listen ( ) log . Println ( \" \" ) } ( )", "del_tokens": "return ring . NewTCPMsgRing ( r ) , nil t := ring . NewTCPMsgRing ( s . r ) go func ( ) { chanerr := t . Start ( ) err := <- chanerr if err != nil { log . Fatal ( err ) } else { log . Println ( \" \" ) } } ( )", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "handle", "change", "in", "net", "/", "url"], "add_tokens": "buf . WriteString ( `<a href=\"` ) buf . WriteString ( formatPathFrag ( pdoc . ImportPath [ : j ] , \" \" ) ) func formatPathFrag ( path , fragment string ) string { u := url . URL { Path : path , Fragment : fragment } buf . WriteString ( formatPathFrag ( c . Paths [ a . PathIndex ] , \" \" ) ) p = \" \" p = c . Paths [ a . PathIndex ] buf . WriteString ( formatPathFrag ( p , string ( n ) ) )", "del_tokens": "buf . WriteString ( `<a href=\"/` ) buf . WriteString ( escapePath ( pdoc . ImportPath [ : j ] ) ) func escapePath ( s string ) string { u := url . URL { Path : s } p := \" \" + c . Paths [ a . PathIndex ] buf . WriteString ( escapePath ( p ) ) p = \" \" p = \" \" + c . Paths [ a . PathIndex ] buf . WriteString ( escapePath ( p ) ) buf . WriteByte ( '#' ) buf . WriteString ( escapePath ( string ( n ) ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "multiple", "entry", "points", "support", "add", "entry", "point", "redirection"], "add_tokens": "\" \" EntryPoints : make ( EntryPoints ) , traefikCmd . PersistentFlags ( ) . Var ( & arguments . EntryPoints , \" \" , \" \" ) traefikCmd . PersistentFlags ( ) . Var ( & arguments . DefaultEntryPoints , \" \" , \" \" ) //viper.BindPFlag(\"defaultEntryPoints\", traefikCmd.PersistentFlags().Lookup(\"defaultEntryPoints\")) viper . SetDefault ( \" \" , \" \" ) jsonConf , _ := json . Marshal ( globalConfiguration ) log . Debugf ( \" \" , string ( jsonConf ) )", "del_tokens": "traefikCmd . PersistentFlags ( ) . Var ( & arguments . Certificates , \" \" , \" \" ) // viper.BindPFlag(\"certificates\", TraefikCmd.PersistentFlags().Lookup(\"certificates\")) viper . SetDefault ( \" \" , & Certificates { } ) log . Debugf ( \" \" , globalConfiguration )", "commit_type": "add"}
{"commit_tokens": ["Implementing", "osin", ".", "Storage", "interface", ".", "Creating", "tests", ".", "Created", "message", "type", "for", "the", "dbms", "messages", "view", ".", "Changed", "some", "query", "in", "Home", "fetching", "..", "WIP"], "add_tokens": "// ProjectPostsNoNotifyTO represents the TO of ProjectPostsNoNotify Type uint8 `json:\"type\"` post . PostInfo . Type = 1 News bool `json:\"news\"` post . PostInfo . Type = 0", "del_tokens": "// ProjectPostsNoNotifyTo represents the TO of ProjectPostsNoNotify News bool `json:\"news\"`", "commit_type": "implement"}
{"commit_tokens": ["Fixing", "wrong", "error", "checking", "in", "List", "and", "ListAll", "functions"], "add_tokens": "if err := scanner . Err ( ) ; err != nil { if err := scanner . Err ( ) ; err != nil {", "del_tokens": "if scanner . Err ( ) != nil { if scanner . Err ( ) != nil {", "commit_type": "fix"}
{"commit_tokens": ["add", "head", "support", "for", "local", "repos"], "add_tokens": "return r . remoteHead ( remote ) } func ( r * Repository ) remoteHead ( remote string ) ( core . Hash , error ) { storage , ok := r . Storage . ( * seekable . ObjectStorage ) if ! ok { return core . ZeroHash , fmt . Errorf ( \" \" ) } return storage . Head ( )", "del_tokens": "return core . ZeroHash , nil", "commit_type": "add"}
{"commit_tokens": ["fixed", "ldflags", "tag", "vs", "version", "confusion"], "add_tokens": "Tag string Tag : ctx . Git . CurrentTag , Version : ctx . Version ,", "del_tokens": "Version : ctx . Git . CurrentTag ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "filtering", "to", "the", "table", "for", "clausees", "fully", "binded", "."], "add_tokens": "nrws : 1 , nrws : 4 , } , { q : `select ?s from ?test where {/u<joe> \"parent_of\"@[] ?o. ?o \"parent_of\"@[] /u<john>};` , nbs : 1 ,", "del_tokens": "nrws : 4 ,", "commit_type": "add"}
{"commit_tokens": ["change", "log", "level", "of", "ssh", "key", "config", "from", "debug", "to", "info"], "add_tokens": "log . Infof ( \" \" ) log . Infof ( \" \" )", "del_tokens": "log . Debugf ( \" \" , keyName ) log . Debugf ( \" \" , d . SSHKeyPair )", "commit_type": "change"}
{"commit_tokens": ["Fix", "a", "couple", "of", "comment", "typos", "."], "add_tokens": "so that it integrates cleanly with standard fmt package printing functions . The", "del_tokens": "so that integrates cleanly with standard fmt package printing functions . The", "commit_type": "fix"}
{"commit_tokens": ["changing", "some", "function", "names", "and", "documenting", "others"], "add_tokens": "//Handle a connection from a client //Requests and notifies readed the Hello s . addMessageLine ( text ) //readSender reads the Sender from the connection s . addMessageLine ( text ) //readRecipients reads recipients from the connection s . addMessageLine ( text ) s . addMessageLine ( text ) //readData reads the message data. s . addMessageLine ( text ) //addMessageLine ads a line to the last message func ( s * Server ) addMessageLine ( text string ) { //LastMessage returns the last message on the server //Messages returns the list of messages on the server //Clear the server messages //NewServer returns a pointer to a new Server instance listening on the given port.", "del_tokens": "s . AddMessageLine ( text ) s . AddMessageLine ( text ) s . AddMessageLine ( text ) s . AddMessageLine ( text ) s . AddMessageLine ( text ) func ( s * Server ) AddMessageLine ( text string ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "error", "messages", "showing", "top", "-", "level", "key", "names", "."], "add_tokens": "if len ( p . currentKey ) == 0 { return p . context . String ( ) if len ( p . context ) == 0 { return p . currentKey } return fmt . Sprintf ( \" \" , p . context , p . currentKey )", "del_tokens": "if len ( p . currentKey ) > 0 { return fmt . Sprintf ( \" \" , p . context , p . currentKey ) return p . context . String ( )", "commit_type": "fix"}
{"commit_tokens": ["add", "a", "few", "more", "methods"], "add_tokens": "if ! assert . NoError ( t , err , \" \" ) { func TestChannelsInfoUnit ( t * testing . T ) { ctx , cancel := context . WithCancel ( context . Background ( ) ) defer cancel ( ) s := httptest . NewServer ( newDummyServer ( ) ) defer s . Close ( ) c := newSlackWithDummy ( s ) _ , err := c . Channels ( ) . Info ( \" \" ) . Do ( ctx ) if ! assert . NoError ( t , err , \" \" ) { return } } func TestChannelsInviteUnit ( t * testing . T ) { ctx , cancel := context . WithCancel ( context . Background ( ) ) defer cancel ( ) s := httptest . NewServer ( newDummyServer ( ) ) defer s . Close ( ) c := newSlackWithDummy ( s ) _ , err := c . Channels ( ) . Invite ( \" \" , \" \" ) . Do ( ctx ) if ! assert . NoError ( t , err , \" \" ) { return } }", "del_tokens": "if ! assert . NoError ( t , err , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "prefix", "option", "to", "random_id", "provider"], "add_tokens": "\" \" : { Type : schema . TypeString , Optional : true , ForceNew : true , } , prefix := d . Get ( \" \" ) . ( string ) d . Set ( \" \" , prefix + base64Str ) d . Set ( \" \" , prefix + base64Str ) d . Set ( \" \" , prefix + b64StdStr ) d . Set ( \" \" , prefix + hexStr ) d . Set ( \" \" , prefix + decStr )", "del_tokens": "d . Set ( \" \" , base64Str ) d . Set ( \" \" , base64Str ) d . Set ( \" \" , b64StdStr ) d . Set ( \" \" , hexStr ) d . Set ( \" \" , decStr )", "commit_type": "add"}
{"commit_tokens": ["update", "version", "of", "go", "-", "multiaddr"], "add_tokens": "manet \" \" ma \" \"", "del_tokens": "ma \" \" manet \" \"", "commit_type": "update"}
{"commit_tokens": ["Allow", "no", "config", "file", "and", "specify", "all", "options", "on", "cmd", "line", "."], "add_tokens": "\" \" log . Printf ( \" \\n \" , port , server ) func enoughOptions ( config * ss . Config ) bool { return config . Server != \" \" && config . ServerPort != 0 && config . LocalPort != 0 && config . Password != \" \" } enough := enoughOptions ( & cmdConfig ) if ! ( enough && os . IsNotExist ( err ) ) { log . Printf ( \" \\n \" , configFile , err ) } if ! enough { return } log . Println ( \" \" ) config = & cmdConfig } else { ss . UpdateConfig ( config , & cmdConfig )", "del_tokens": "log . Printf ( \" \\n \" , port , server ) return ss . UpdateConfig ( config , & cmdConfig )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "redirect", "when", "POST", "method"], "add_tokens": "// second parameter is the http status should send, default is 302 (StatusFound), you can set it to 301 (Permant redirect), if that's nessecery httpStatus := StatusFound // temporary redirect ctx . Redirect ( s , StatusFound )", "del_tokens": "// second parameter is the http status should send, default is 307 (Temporary redirect), you can set it to 301 (Permant redirect), if that's nessecery httpStatus := StatusTemporaryRedirect // temporary redirect ctx . Redirect ( s , StatusTemporaryRedirect )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "25", "-", "connect", "using", "address", "type", "received", "in", "advertisement"], "add_tokens": "LEScanInterval : 0x0004 , // N x 0.625ms LEScanWindow : 0x0004 , // N x 0.625ms InitiatorFilterPolicy : 0x00 , // white list not used PeerAddressType : pd . AddressType , // public or random PeerAddress : pd . Address , // OwnAddressType : 0x00 , // public ConnIntervalMin : 0x0006 , // N x 0.125ms ConnIntervalMax : 0x0006 , // N x 0.125ms ConnLatency : 0x0000 , // SupervisionTimeout : 0x000A , // N x 10ms MinimumCELength : 0x0000 , // N x 0.625ms MaximumCELength : 0x0000 , // N x 0.625ms", "del_tokens": "LEScanInterval : 0x0004 , // N x 0.625ms LEScanWindow : 0x0004 , // N x 0.625ms InitiatorFilterPolicy : 0x00 , // white list not used PeerAddressType : 0x00 , // public PeerAddress : pd . Address , // OwnAddressType : 0x00 , // public ConnIntervalMin : 0x0006 , // N x 0.125ms ConnIntervalMax : 0x0006 , // N x 0.125ms ConnLatency : 0x0000 , // SupervisionTimeout : 0x000A , // N x 10ms MinimumCELength : 0x0000 , // N x 0.625ms MaximumCELength : 0x0000 , // N x 0.625ms", "commit_type": "fix"}
{"commit_tokens": ["Fix", "possible", "memory", "confusion", "in", "unsafe", "slice", "cast"], "add_tokens": "func unsafeString2Bytes ( s string ) ( b [ ] byte ) { bh := ( * reflect . SliceHeader ) ( unsafe . Pointer ( & b ) ) bh . Data = sh . Data bh . Cap = sh . Len bh . Len = sh . Len return b", "del_tokens": "func unsafeString2Bytes ( s string ) [ ] byte { bh := reflect . SliceHeader { Data : sh . Data , Len : sh . Len , Cap : sh . Len , } return * ( * [ ] byte ) ( unsafe . Pointer ( & bh ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "Datasource", "Features", "allowing", "different", "sources", "to", "implement", "different", "features"], "add_tokens": "u . Debugf ( \" \" , len ( tasks ) )", "del_tokens": "//u.Debugf(\"in RunJob exec %v\", len(tasks))", "commit_type": "add"}
{"commit_tokens": ["remove", "trailing", "slash", "from", "host"], "add_tokens": "suffix = strings . Join ( hostSplits [ 1 : ] , \" \" )", "del_tokens": "suffix = strings . Join ( hostSplits [ 1 : ] , \" \" ) + \" \"", "commit_type": "remove"}
{"commit_tokens": ["Add", "error", "struct", "and", "example", "code"], "add_tokens": "e := Error { HTTPCode : code } json . Unmarshal ( resp , & e ) // If unparseable, just use the response body as the Error message if err != nil { e . APIError = string ( resp ) } return e type Error struct { HTTPCode int APICode string `json:\"code\"` APIError string `json:\"error\"` } func ( r Error ) Error ( ) string { var msg string if r . APICode != \" \" { msg = r . APICode + \" \" } if r . APIError != \" \" { msg = msg + r . APIError + \" \" } if r . HTTPCode != 0 { msg = fmt . Sprintf ( \" \" , msg , r . HTTPCode ) } return msg }", "del_tokens": "return fmt . Errorf ( \" \" , code , string ( resp ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "pwd", "package", "naming", "."], "add_tokens": "abspath , _ := filepath . Abs ( path ) p := & ego . Package { Templates : templates , Name : filepath . Base ( abspath ) }", "del_tokens": "p := & ego . Package { Templates : templates , Name : filepath . Base ( path ) }", "commit_type": "fix"}
{"commit_tokens": ["Use", "LoginAuth", "()", "to", "exchange", "a", "username", "/", "password", "for", "auth", "token"], "add_tokens": "\" \" ctx context . Context // LoginAuth creates the required HTTP client with a new token. func ( o * OAuthSession ) LoginAuth ( username , password string ) error { // Fetch OAuth token. t , err := o . OAuthConfig . PasswordCredentialsToken ( o . ctx , username , password ) return err o . Client = o . OAuthConfig . Client ( o . ctx , t ) return nil } if o . Client == nil { return errors . New ( \" \" ) } if o . Client == nil { return errors . New ( \" \" ) }", "del_tokens": "// TODO offer auth code version as well as personal scripts t , err := s . OAuthConfig . PasswordCredentialsToken ( ctx , s . Username , s . Password ) return nil , err", "commit_type": "use"}
{"commit_tokens": ["Fix", "panic", "if", "Permissioner", "is", "nil"], "add_tokens": "var newPS [ ] Permissioner for _ , p := range ps { if p != nil { newPS = append ( newPS , p ) } } return permissioners ( newPS ) if p != nil && ! p . HasPermission ( mode , roles ) {", "del_tokens": "return permissioners ( ps ) if ! p . HasPermission ( mode , roles ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "debug", "logging", "to", "api", "fix", "templates", "end", "points", "add", "template", "tests"], "add_tokens": "const debug bool = false if debug { log . Printf ( \" \" , requestUrl ) } if debug { log . Printf ( \" \" , string ( body ) ) } if debug { log . Printf ( \" \" , string ( b ) ) } if debug { log . Printf ( \" \" , requestUrl ) } if debug { log . Printf ( \" \" , string ( body ) ) }", "del_tokens": "log . Printf ( \" \" , requestUrl ) log . Printf ( \" \" , string ( body ) ) log . Printf ( \" \" , string ( b ) ) log . Printf ( \" \" , requestUrl ) log . Printf ( \" \" , string ( body ) )", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "float32", "conversion", "for", "24bit", "audio", "files"], "add_tokens": "max := 0 // hack to handle different bit depths without having the information bitDepth := 2.0 for _ , s := range buf . Data { if s > max { max = s } } // greater than int16, expecting int32 if max > 32767 { bitDepth = 4.0 } newB . Data [ i ] = float32 ( float64 ( int16 ( buf . Data [ i ] ) ) / math . Pow ( bitDepth , 8 * 2 - 1 ) )", "del_tokens": "newB . Data [ i ] = float32 ( float64 ( int16 ( buf . Data [ i ] ) ) / math . Pow ( 2 , 8 * 2 - 1 ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "strict", "option", "to", "JsonDecode", "(", "disallow", "unknown", "fields", ")", "."], "add_tokens": "func ( resp * HttpResponse ) JsonDecode ( out interface { } , strict bool ) error { if strict { dec . DisallowUnknownFields ( ) } // set the request URL (passed as string) func URLString ( ustring string ) RequestOption { return func ( req * http . Request ) ( * http . Request , error ) { u , err := url . Parse ( ustring ) if err != nil { return nil , err } req . URL = u return req , nil } }", "del_tokens": "func ( resp * HttpResponse ) JsonDecode ( out interface { } ) error {", "commit_type": "add"}
{"commit_tokens": ["Fix", "delete", "virtual", "nested", "collection"], "add_tokens": "\" \" if destroy := metaValue . MetaValues . Get ( \" \" ) ; destroy == nil || fmt . Sprint ( destroy . Value ) == \" \" { setMeta ( fieldValue . Interface ( ) , metaResource . GetMetas ( [ ] string { } ) , metaValue . MetaValues . Values ) if ! reflect . DeepEqual ( reflect . Zero ( nestedFieldValue . Type ( ) . Elem ( ) ) . Interface ( ) , fieldValue . Elem ( ) . Interface ( ) ) { nestedFieldValue . Set ( reflect . Append ( nestedFieldValue , fieldValue . Elem ( ) ) ) }", "del_tokens": "setMeta ( fieldValue . Interface ( ) , metaResource . GetMetas ( [ ] string { } ) , metaValue . MetaValues . Values ) if ! reflect . DeepEqual ( reflect . Zero ( nestedFieldValue . Type ( ) . Elem ( ) ) . Interface ( ) , fieldValue . Elem ( ) . Interface ( ) ) { nestedFieldValue . Set ( reflect . Append ( nestedFieldValue , fieldValue . Elem ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "better", "error", "handling", "for", "PullImage"], "add_tokens": "\" \" req , err := http . NewRequest ( \" \" , client . URL . String ( ) + uri , nil ) req . Header . Add ( \" \" , auth . encode ( ) ) resp , err := client . HTTPClient . Do ( req ) if err != nil { return err } defer resp . Body . Close ( ) var finalBytes [ ] byte scanner := bufio . NewScanner ( resp . Body ) for scanner . Scan ( ) { finalBytes = scanner . Bytes ( ) } var finalObj map [ string ] interface { } if err = json . Unmarshal ( finalBytes , & finalObj ) ; err != nil { return err } if err , ok := finalObj [ \" \" ] ; ok { return fmt . Errorf ( \" \" , err ) } return nil", "del_tokens": "headers := make ( map [ string ] string ) headers [ \" \" ] = auth . encode ( ) _ , err := client . doRequest ( \" \" , uri , nil , headers ) return err", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", ":", "writen", "-", ">", "written"], "add_tokens": "log . Println ( \" \" , cfg . Dest + cfg . Output , \" \" )", "del_tokens": "log . Println ( \" \" , cfg . Dest + cfg . Output , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "devs", "to", "change", "the", "width", "of", "the", "logging", "level", "column", "in", "consolewriter"], "add_tokens": "// LevelWidth defines the desired character width of the log level column. // Default 0 does not trim or pad (variable width based level text, e.g. \"INFO\" or \"ERROR\") var LevelWidth = 0 level = strings . ToUpper ( l ) if LevelWidth > 0 { if padding := LevelWidth - len ( level ) ; padding > 0 { level += strings . Repeat ( \" \" , padding ) } else { level = level [ 0 : LevelWidth ] } }", "del_tokens": "level = strings . ToUpper ( l ) [ 0 : 4 ]", "commit_type": "allow"}
{"commit_tokens": ["Fix", "comment", ":", "unit", "character", "-", ">", "unit", "name"], "add_tokens": "// an optional unit name as defined in its mapping.", "del_tokens": "// an optional unit character as defined in its mapping.", "commit_type": "fix"}
{"commit_tokens": ["fix", "endian", "of", "decoded", "values"], "add_tokens": "dst [ n - 4 ] = byte ( remainder >> 24 ) dst [ n - 3 ] = byte ( remainder >> 16 ) dst [ n - 2 ] = byte ( remainder >> 8 ) dst [ n - 1 ] = byte ( remainder )", "del_tokens": "dst [ n - 1 ] = byte ( remainder >> 24 ) dst [ n - 2 ] = byte ( remainder >> 16 ) dst [ n - 3 ] = byte ( remainder >> 8 ) dst [ n - 4 ] = byte ( remainder )", "commit_type": "fix"}
{"commit_tokens": ["update", "travisci", "not", "include", "ovs", "related", "test", "to", "get", "it", "passed"], "add_tokens": "Addr : \" \" ,", "del_tokens": "Addr : \" \" ,", "commit_type": "update"}
{"commit_tokens": ["Adds", "indicies", "to", "selector", "strings", "+", "more", "testing"], "add_tokens": "import \" \" text := s . Value if s . Indexed { text = text + fmt . Sprintf ( \" \" , s . Index ) } return \" \" + text return \" \" + text", "del_tokens": "return \" \" + s . Value return \" \" + s . Value", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "options", "and", "option", "to", "force", "output"], "add_tokens": "w := wow . New ( os . Stdout , spin . Get ( v ) , \" \" + v . String ( ) , wow . ForceOutput )", "del_tokens": "w := wow . New ( os . Stdout , spin . Get ( v ) , \" \" + v . String ( ) )", "commit_type": "add"}
{"commit_tokens": ["add", "checksum", "optimization", "for", "PostgreSQL"], "add_tokens": "modified , err := c . helper . isTableModified ( tx , file . fileNameWithoutExtension ( ) )", "del_tokens": "modified , err := c . helper . isTableModified ( c . db , file . fileNameWithoutExtension ( ) )", "commit_type": "add"}
{"commit_tokens": ["Allow", "hostname", "labels", "starting", "with", "digits"], "add_tokens": "// for an Internet host name, as defined by RFC 1034 section 3.1 and // RFC 1123 section 2.1. // labels must not start with a hyphen // RFC 1123 section 2.1: restriction on the first character // is relaxed to allow either a letter or a digit if first := s [ 0 ] ; first == '-' {", "del_tokens": "// for an Internet host name, as defined by RFC 1034, section 3.1. // labels could not start with a digit or with a hyphen if first := s [ 0 ] ; ( first >= '0' && first <= '9' ) || ( first == '-' ) {", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "basic", "test", "in", "order", "to", "accomodate", "new", "HCL", "error", "checking"], "add_tokens": "another { another {", "del_tokens": "another = \" \" { another = \" \" {", "commit_type": "fix"}
{"commit_tokens": ["Made", "better", "testing", "executable", ";", "fixed", "0", "length", "bug"], "add_tokens": "vm . vfID = vf . id vm . vfOffset = atomic . LoadUint32 ( & vf . atOffset )", "del_tokens": "vm . vfID = vf . id vm . vfOffset = atomic . LoadUint32 ( & vf . atOffset )", "commit_type": "make"}
{"commit_tokens": ["use", "GoClose", "in", "conns", "accessor"], "add_tokens": "c . GoClose ( )", "del_tokens": "c . Close ( )", "commit_type": "use"}
{"commit_tokens": ["Added", "affinity", "group", "to", "resources"], "add_tokens": "func NewAffinityGroupsService ( apiClient api . ApiClient , serviceCode string , environmentName string ) AffinityGroupService {", "del_tokens": "func NewAffinityGroupService ( apiClient api . ApiClient , serviceCode string , environmentName string ) AffinityGroupService {", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "-", "fmt", "json", "produces", "valid", "output"], "add_tokens": "\" \" : { \" \" : { { . Stats . NumFiles } } , \" \" : { { . Stats . NumLines } } , \" \" : { { . Stats . NumNosec } } , \" \" : { { . Stats . NumFound } } } ,", "del_tokens": "\" \" : [ Files : { { . Stats . NumFiles } } , Lines : { { . Stats . NumLines } } , Nosec : { { . Stats . NumNosec } } , Issues : { { . Stats . NumFound } } ] ,", "commit_type": "make"}
{"commit_tokens": ["Fix", "null", "pointer", "error", "in", "controller"], "add_tokens": "liveResource := controlledLiveObj [ i ] if liveResource != nil { childResources , err := getChildren ( liveResource , objByFullName ) if err != nil { return nil , err } resource . ChildLiveResources = childResources resources [ i ] = resource", "del_tokens": "childResources , err := getChildren ( controlledLiveObj [ i ] , objByFullName ) if err != nil { return nil , err resource . ChildLiveResources = childResources resources [ i ] = resource", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "unit", "test", "for", "dashboard", "unmarshalling", "."], "add_tokens": "// \"y_formats\": null, // \"xaxis\": { // \"show\": false // }, // \"yaxes\": null // \"y_formats\": null, // \"xaxis\": { // \"show\": false // }, // \"yaxes\": null // \"schemaVersion\": 0,", "del_tokens": "// \"y_formats\": null // \"y_formats\": null // \"schemiaVersion\": 0,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "logs", "from", "consul", "client"], "add_tokens": "consulapi \" \" )", "del_tokens": "consulapi \" \" \" \" \" \" ) // Logger for the consul client package var logger = log . New ( os . Stdout , \" \" , log . Ldate | log . Ltime | log . Lshortfile ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) ) logger . Println ( err . Error ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "comments", "(", "to", "pass", "golint", ")"], "add_tokens": "// A GraphicsContext is the interface that means a context of rendering. // Filters", "del_tokens": "// A Context is the interface that means a context of rendering.", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "behaviour", "of", "Back", "()", "and", "Front", "()", ":", "now", "returns", "a", "nil", "item", "and", "a", "nil", "error", "when", "called", "on", "an", "empty", "list", ".", "Updated", "documentation", "."], "add_tokens": "// as its underlying data structure but with a doubly linked list-like behaviour // Returns a nil item if the list is empty. // // // bbolt.View() error // // proto.Unmarshal() error i , err = nil , nil return err // Returns a nil item if the list is empty. // // // bbolt.View() error // // proto.Unmarshal() error i , err = nil , nil return err", "del_tokens": "// as its underlying data structure but with a simply linked list-like behaviour // * Empty linked list - a list with no elements // * bbolt.View() error // * proto.Unmarshal() error return fmt . Errorf ( \" \" ) // * Empty linked list - a list with no elements // * bbolt.View() error // * proto.Unmarshal() error return fmt . Errorf ( \" \" )", "commit_type": "change"}
{"commit_tokens": ["add", "source", "for", "Channel", "or", "Slice"], "add_tokens": "Type : \" \" ,", "del_tokens": "Type : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Fixing", "ordering", "of", "test", "actual", "/", "expected", "values", "+", "byte", "type", "-", "casting", "."], "add_tokens": "g . Expect ( tableUnderTest . FieldNames ( ) ) . To ( Equal ( expectedFieldNames ) ) g . Expect ( actualRecordNumber ) . To ( BeNumerically ( \" \" , expectedRecordNumber ) )", "del_tokens": "g . Expect ( expectedFieldNames ) . To ( Equal ( tableUnderTest . FieldNames ( ) ) ) g . Expect ( expectedRecordNumber ) . To ( BeNumerically ( \" \" , actualRecordNumber ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "protocol", "func", ":", "//", "to", "use", "in", "-", "memory", "function", "as", "data", "source", "for", "template"], "add_tokens": "ErrMissingTemplateFunc = errors . New ( \" \" ) ErrBadTemplateFunc = errors . New ( \" \" ) var config_template_text string var err error switch { case strings . Index ( url , \" \" ) == 0 && len ( funcs ) == 1 : if f , has := funcs [ 0 ] [ url [ len ( \" \" ) : ] ] ; has { if ff , ok := f . ( func ( ) string ) ; ok { config_template_text = ff ( ) } else { glog . Warningln ( \" \" , url ) return nil , ErrBadTemplateFunc } } else { glog . Warningln ( \" \" , url ) return nil , ErrMissingTemplateFunc } default : config_template_text , _ , err = FetchUrl ( url , headers , zc ) if err != nil { glog . Warningln ( \" \" , err ) return nil , err }", "del_tokens": "config_template_text , _ , err := FetchUrl ( url , headers , zc ) if err != nil { glog . Warningln ( \" \" , err ) return nil , err", "commit_type": "add"}
{"commit_tokens": ["Make", "lack", "of", "support", "for", "AllowUnexported", "more", "obvious"], "add_tokens": "const supportAllowUnexported = false panic ( \" \" )", "del_tokens": "panic ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Use", "gopkg", ".", "in", "for", "gin"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["improve", "test", "coverage", "of", "empty", "space"], "add_tokens": "p . FillRect ( 0 , 0 , sz . X , sz . Y )", "del_tokens": "p . FillRect ( 0 , 0 , sz . X - 1 , sz . Y - 1 )", "commit_type": "improve"}
{"commit_tokens": ["Remove", "direct", "access", "to", "manifests", "to", "prepare", "for", "persistence", ".."], "add_tokens": "latest , err := m . repository . GetLatestManifest ( name ) if err != nil { return nil , err }", "del_tokens": "latest := getLatestManifest ( d . Manifests ) if latest != nil { d . Current = latest . ExpandedConfig } latest := getLatestManifest ( d . Manifests ) // Given a map of manifests, finds the largest time stamp, hence probably the latest manifest. // This is a hack until we get a real story for storage. func getLatestManifest ( l map [ string ] * Manifest ) * Manifest { var latest = 0 var ret * Manifest for k , v := range l { var i = 0 fmt . Sscanf ( k , \" \" , & i ) if i > latest { latest = i ret = v } } return ret }", "commit_type": "remove"}
{"commit_tokens": ["Use", "zero", "MAC", "address", "when", "none", "is", "provided"], "add_tokens": "macAddress = \" \"", "del_tokens": "\" \" \" \" \" \" func generateMAC ( ) string { var n [ ] string = make ( [ ] string , 6 ) rand . Seed ( time . Now ( ) . UnixNano ( ) ) for i := 0 ; i < 6 ; i ++ { n [ i ] = fmt . Sprintf ( \" \" , rand . Intn ( 64 ) ) } return strings . Join ( n , \" \" ) } macAddress = generateMAC ( )", "commit_type": "use"}
{"commit_tokens": ["Move", "NopDecoder", "to", "separate", "package"], "add_tokens": "\" \" nopdecoder . NopDecoder", "del_tokens": "rdb . NopDecoder", "commit_type": "move"}
{"commit_tokens": ["Fix", "errors", "from", "previous", "commit"], "add_tokens": "dataFile , err := os . Create ( filePath + \" \" ) defer dataFile . Close ( ) data , err := json . Marshal ( ApiCallValueInstance ) if err != nil { _ , err = dataFile . Write ( data )", "del_tokens": "\" \" data , err := json . Marshal ( ApiCallValueInstance ) if ioutil . WriteFile ( filePath + \" \" , data , os . O_CREATE ) != nil { _ , err := dataFile . Write ( data )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "a", "globstar", "as", "the", "only", "component", "(", "and", "handle", "it", "properly", ")"], "add_tokens": "if isLast && len ( glob . parserState . processedTokens ) > 0 {", "del_tokens": "if isLast {", "commit_type": "allow"}
{"commit_tokens": ["Allow", "connections", "to", "successfully", "close", "even", "if", "wrapped", "connection", "doesn", "t", "respect", "read", "deadlines"], "add_tokens": "rdic := & readDeadlineIgnoringConn { conn } c := Conn ( rdic , clientTimeout , func ( ) { } ) go func ( ) { b := make ( [ ] byte , 10 ) n , err := c . Read ( b ) t . Logf ( \" \" , n , err ) } ( ) time . Sleep ( 100 * time . Millisecond ) type readDeadlineIgnoringConn struct { net . Conn } func ( conn * readDeadlineIgnoringConn ) SetReadDeadline ( deadline time . Time ) error { return nil }", "del_tokens": "c := Conn ( conn , clientTimeout , func ( ) { } )", "commit_type": "allow"}
{"commit_tokens": ["Change", "acceptor", "signature", "when", "receiving", "Docker", "event"], "add_tokens": "return c . WatchContainerMatching ( func ( Action , * Container ) bool { return true } , notify ) func ( c * Docker ) WatchContainerMatching ( accept func ( Action , * Container ) bool , notify func ( Action , * Container ) ) ( chan <- bool , error ) { if watch != nil && accept ( action , container ) {", "del_tokens": "return c . WatchContainerMatching ( func ( c * Container ) bool { return true } , notify ) func ( c * Docker ) WatchContainerMatching ( accept func ( * Container ) bool , notify func ( Action , * Container ) ) ( chan <- bool , error ) { if watch != nil && accept ( container ) {", "commit_type": "change"}
{"commit_tokens": ["Updated", "to", "work", "with", "arbitrary", "byte", "escape", "sequences", "."], "add_tokens": "case 'x' : return lexStringBinary \" \\\\ \\\\ \\\\ \\\\ \\\\ \\\" \\\\ \\\\ \" , r ) } // lexStringBinary consumes two hexadecimal digits following '\\x'. It assumes // that the '\\x' has already been consumed. func lexStringBinary ( lx * lexer ) stateFn { r := lx . next ( ) if ! isHexadecimal ( r ) { return lx . errorf ( \" \\\\ \" + \" \" , r ) } r = lx . next ( ) if ! isHexadecimal ( r ) { return lx . errorf ( \" \\\\ \" + \" \" , r ) } return lexString func isHexadecimal ( r rune ) bool { return ( r >= '0' && r <= '9' ) || ( r >= 'a' && r <= 'f' ) || ( r >= 'A' && r <= 'F' ) }", "del_tokens": "case '0' : fallthrough \" \\\\ \\\\ \\\\ \\\\ \\\\ \\\" \\\\ \\\\ \" , r )", "commit_type": "update"}
{"commit_tokens": ["add", "DirectMap1G", "ignore", "unknown", "fields", "silently"], "add_tokens": "DirectMap1G uint64 case \" \" : meminfo . DirectMap1G = val", "del_tokens": "\" \" log . Printf ( \" \" , name )", "commit_type": "add"}
{"commit_tokens": ["make", "compilation", "work", "on", "linux", "too"], "add_tokens": "# cgo linux LDFLAGS : - lstdc ++ # cgo darwin CXXFLAGS : - stdlib = libc + + # cgo CXXFLAGS : - std = c + + 11", "del_tokens": "# cgo CXXFLAGS : - std = c + + 11 - stdlib = libc + +", "commit_type": "make"}
{"commit_tokens": ["Fix", "concurrent", "map", "read", "and", "map", "write", "errors"], "add_tokens": "\" \" \" \" sync . RWMutex return & Tracer { metrics : make ( map [ string ] * TraceTransaction ) , component : component } t . RLock ( ) if m , ok := t . metrics [ tracerName ] ; ok { return & Trace { m , time . Now ( ) } t . RUnlock ( ) trans := TraceTransaction { name : tracerName , timer : metrics . NewTimer ( ) } t . Lock ( ) t . metrics [ tracerName ] = & trans t . Unlock ( ) trans . addMetricsToComponent ( t . component ) return & Trace { transaction : & trans , startTime : time . Now ( ) }", "del_tokens": "\" \" return & Tracer { make ( map [ string ] * TraceTransaction ) , component } m := t . metrics [ tracerName ] if m == nil { t . metrics [ tracerName ] = & TraceTransaction { tracerName , metrics . NewTimer ( ) } m = t . metrics [ tracerName ] m . addMetricsToComponent ( t . component ) return & Trace { m , time . Now ( ) }", "commit_type": "fix"}
{"commit_tokens": ["make", "initializeTrap", "in", "start", "not", "a", "go", "func", "and", "return", "error", "on", "failure", "to", "initialize"], "add_tokens": "func ( m * CirconusMetrics ) Start ( ) error { if m . Debug { m . Log = log . New ( os . Stderr , \" \" , log . LstdFlags ) } if ! m . ready { if err := m . initializeTrap ( ) ; err != nil { return err } return nil m . Log . Printf ( \" \\n \" , err ) return", "del_tokens": "func ( m * CirconusMetrics ) Start ( ) { go func ( ) { if m . Debug { m . Log = log . New ( os . Stderr , \" \" , log . LstdFlags ) } //m.loadCACert() if ! m . ready { m . initializeTrap ( ) } ( ) m . Log . Println ( \" \" ) return", "commit_type": "make"}
{"commit_tokens": ["adding", "limit", "on", "extending", "array", "size"], "add_tokens": "var ArraySizeAdditionLimit int = 0 if diff := idx + 1 - sz ; ArraySizeAdditionLimit > 0 && diff > ArraySizeAdditionLimit { return fmt . Errorf ( \" \" , diff , ArraySizeAdditionLimit ) } if ArraySizeLimit > 0 && sz > ArraySizeLimit { if ArraySizeLimit > 0 && sz > ArraySizeLimit {", "del_tokens": "if sz > ArraySizeLimit && ArraySizeLimit != 0 { if sz > ArraySizeLimit && ArraySizeLimit != 0 {", "commit_type": "add"}
{"commit_tokens": ["updating", "primitive", "definitions", "to", "support", "compilation", "in", "cloud", "config"], "add_tokens": "Name string `yaml:\"name,omitempty\"` Name string `yaml:\"name,omitempty\"` func ( s * CloudConfigManifest ) SetCompilation ( cpl * Compilation ) ( err error ) { s . Compilation = cpl return }", "del_tokens": "Name string `yaml:\"name:omitempty\"` Name string `yaml:\"name:omitempty\"`", "commit_type": "update"}
{"commit_tokens": ["use", "Go", "facilities", "to", "get", "a", "socket"], "add_tokens": "fd , err := syscall . Socket ( syscall . AF_INET , syscall . SOCK_DGRAM , syscall . IPPROTO_IP ) if err != nil { return nil , err", "del_tokens": "fd , _ , err := syscall . RawSyscall ( syscall . SYS_SOCKET , syscall . AF_INET , syscall . SOCK_DGRAM , syscall . IPPROTO_IP ) if err != 0 { return nil , syscall . Errno ( err )", "commit_type": "use"}
{"commit_tokens": ["Remove", "unused", "struct", "member", "in", "LazyFile"], "add_tokens": "// FileName is path to the file to which genny will write.", "del_tokens": "written [ ] byte", "commit_type": "remove"}
{"commit_tokens": ["Added", "an", "injected", "clock", "."], "add_tokens": "\" \" return openBucket ( name , httpConn , signer , time . RealClock ( ) ) signer auth . Signer , clock time . Clock ) ( Bucket , error ) {", "del_tokens": "return openBucket ( name , httpConn , signer ) signer auth . Signer ) ( Bucket , error ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "NEON", "support", "for", "ARM64"], "add_tokens": "// This is what the assembler routines do in blocks of 16 bytes:", "del_tokens": "// This is what the assembler rountes does in blocks of 16 bytes:", "commit_type": "add"}
{"commit_tokens": ["Fix", "generation", "of", "secured", "API", "Key", "with", "query", "parameter"], "add_tokens": "} else if strings . Contains ( public . ( string ) , \" \" ) { // Url encoded query parameters if ( len ( userTokenStr ) != 0 ) { message = public . ( string ) + \" \" + c . transport . EncodeParams ( \" \" + c . transport . urlEncode ( userTokenStr ) ) } else { message = public . ( string ) }", "del_tokens": "} else if strings . Contains ( public . ( string ) , \" \" ) && len ( userTokenStr ) != 0 { // Url encoded query parameters message = public . ( string ) + \" \" + c . transport . urlEncode ( userTokenStr )", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "to", "confd", ".", "go", "and", "rename", "SetConfig", "function"], "add_tokens": "// All flags are defined in the confd/config package which allow us to // override configuration settings from the cli. Parse the flags now to // make them active. if err := config . InitConfig ( ) ; err != nil { // If the -onetime flag is passed on the command line we immediately exit // after processing the template config files.", "del_tokens": "if err := config . SetConfig ( ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["make", "min", "/", "max", "test", "more", "readable"], "add_tokens": "min := func ( values [ ] int64 ) bool { } if err := quick . Check ( min , nil ) ; err != nil { max := func ( values [ ] int64 ) bool { } if err := quick . Check ( max , nil ) ; err != nil {", "del_tokens": "err := quick . Check ( func ( values [ ] int64 ) bool { } , nil ) if err != nil { err := quick . Check ( func ( values [ ] int64 ) bool { } , nil ) if err != nil {", "commit_type": "make"}
{"commit_tokens": ["allow", "to", "extend", "user", "info"], "add_tokens": "ldapclient \" \" config Config config : config , return us . makeUser ( client , username , attrs ) return us . makeUser ( client , userID , attrs ) func ( us * UserStore ) makeUser ( client * ldapclient . LDAPClient , id string , attrs map [ string ] string ) ( * UserInfo , error ) { var err error if us . config . GetMoreUserInfo != nil { var extra map [ string ] string extra , err = us . config . GetMoreUserInfo ( client , attrs ) if extra != nil { for k , v := range extra { attrs [ k ] = v } } } } , err", "del_tokens": "return us . makeUser ( username , attrs ) , nil return us . makeUser ( userID , attrs ) , nil func ( us * UserStore ) makeUser ( id string , attrs map [ string ] string ) * UserInfo { }", "commit_type": "allow"}
{"commit_tokens": ["Use", "the", "util", "RoundTripper", "for", "oauth", "requests"], "add_tokens": "err := util . GET ( log . Get ( ) , o . Server , strategy , fmt . Sprintf ( \" \" , gatewayID ) , o . Client . ExtraHeaders , token )", "del_tokens": "err := util . GET ( log . Get ( ) , o . Server , strategy , fmt . Sprintf ( \" \" , gatewayID ) , token )", "commit_type": "use"}
{"commit_tokens": ["Fix", "handling", "of", "non", "-", "pointer", "custom", "types"], "add_tokens": "if fv . Kind ( ) == reflect . Struct && unsettableType ( fv . Type ( ) ) != nil {", "del_tokens": "if fv . Kind ( ) == reflect . Struct {", "commit_type": "fix"}
{"commit_tokens": ["remove", "err", "argument", "in", "panic"], "add_tokens": "func ( c * C ) Panic ( ) {", "del_tokens": "func ( c * C ) Panic ( err error ) {", "commit_type": "remove"}
{"commit_tokens": ["implemented", "header", "and", "signature", "parsing"], "add_tokens": "import \" \" Comment [ ] byte // FieldID: 1 CipherID [ ] byte // FieldID: 2 CompressionFlags uint32 // FieldID: 3 MasterSeed [ ] byte // FieldID: 4 TransformSeed [ ] byte // FieldID: 5 TransformRounds uint32 // FieldID: 6 EncryptionIV [ ] byte // FieldID: 7 ProtectedStreamKey [ ] byte // FieldID: 8 StreamStartBytes [ ] byte // FieldID: 9 InnerRandomStreamID [ ] byte // FieldID: 10 func ( h Headers ) String ( ) string { return fmt . Sprintf ( \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" + \" \\n \" , h . Comment , h . CipherID , h . CompressionFlags , h . MasterSeed , h . TransformSeed , h . TransformRounds , h . EncryptionIV , h . ProtectedStreamKey , h . StreamStartBytes , h . InnerRandomStreamID , ) }", "del_tokens": "Comment uint32 // FieldID: 1 CipherID uint32 // FieldID: 2 CompressionFlags [ ] byte // FieldID: 3 MasterSeed uint32 // FieldID: 4 TransaformSeed uint32 // FieldID: 5 TransformRounds [ ] byte // FieldID: 6 EncryptionIV uint32 // FieldID: 7 ProtectedStreamKey uint32 // FieldID: 8 StreamStartBytes uint32 // FieldID: 9 InnerRandomStreamID uint32 // FieldID: 10", "commit_type": "implement"}
{"commit_tokens": ["Implement", "DNS", "interface", "besides", "netcat"], "add_tokens": "func NewCountryFromCode ( code string ) ( country * Country , err error ) { country = & Country { } country . Name , err = langreg . RegionName ( code ) return country , err", "del_tokens": "func NewCountryFromCode ( code string ) * Country { country := & Country { } country . Name , _ = langreg . RegionName ( code ) return country", "commit_type": "implement"}
{"commit_tokens": ["Add", "changelog", "and", "version", "flag"], "add_tokens": "\" \" \" \" : false , if flags . Has ( \" \" ) { fmt . Println ( goprotowrap . Version ) os . Exit ( 0 ) } os . Exit ( 2 )", "del_tokens": "os . Exit ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "custom", "boolean", "flags", "through", "IsBoolFlag", "()"], "add_tokens": "if bv , ok := flag . Value . ( boolFlag ) ; ! ok || ! bv . IsBoolFlag ( ) { if bv , ok := flag . Value . ( boolFlag ) ; ok && bv . IsBoolFlag ( ) {", "del_tokens": "if _ , ok := flag . Value . ( * boolValue ) ; ! ok { if _ , ok := flag . Value . ( * boolValue ) ; ok {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "for", "assigning", "local", "respError"], "add_tokens": "Response * Response `json:\"-\"` Type ResponseErrorType `json:\"-\"` Message string `json:\"message,omitempty\"` Err string `json:\"error,omitempty\"` Errors [ ] ErrorObject `json:\"errors,omitempty\"` DocumentationURL string `json:\"documentation_url,omitempty\"` respErr = resp . ApiError . ( * ResponseError )", "del_tokens": "Response * Response Type ResponseErrorType Message string `json:\"message,omitempty\"` Err string `json:\"error,omitempty\"` Errors [ ] ErrorObject `json:\"errors,omitempty\"` DocumentationURL string `json:\"documentation_url,omitempty\"` respErr := resp . ApiError . ( * ResponseError )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "build", "error", "."], "add_tokens": "\" \" return gcsfake . NewFakeBucket ( \" \" )", "del_tokens": "return gcstest . NewFakeBucket ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", ".", "json"], "add_tokens": "ComputedStyleWhitelist [ ] string `json:\"computedStyleWhitelist\"` // Whitelist of computed styles to return. IncludeEventListeners bool `json:\"includeEventListeners,omitempty\"` // Whether or not to retrieve details of DOM listeners (default false). // WithIncludeEventListeners whether or not to retrieve details of DOM // listeners (default false). func ( p GetSnapshotParams ) WithIncludeEventListeners ( includeEventListeners bool ) * GetSnapshotParams { p . IncludeEventListeners = includeEventListeners return & p }", "del_tokens": "ComputedStyleWhitelist [ ] string `json:\"computedStyleWhitelist\"` // Whitelist of computed styles to return.", "commit_type": "update"}
{"commit_tokens": ["Implement", "the", "new", "hcsshim", "API", "using", "the", "new", "HCS", "RPC", "API"], "add_tokens": "var uniqDllFuncName = make ( map [ string ] bool ) // IsNotDuplicate is true if f is not a duplicated function func ( f * Fn ) IsNotDuplicate ( ) bool { funcName := f . DLLFuncName ( ) if uniqDllFuncName [ funcName ] == false { uniqDllFuncName [ funcName ] = true return true } return false } import \" \" { { define \" \" } } { { range . Funcs } } { { if . IsNotDuplicate } } proc { { . DLLFuncName } } = mod { { . DLLName } } . NewProc ( \" \" ) { { end } }", "del_tokens": "{ { define \" \" } } { { range . Funcs } } proc { { . DLLFuncName } } = mod { { . DLLName } } . NewProc ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["Use", "shorter", "version", "to", "initialize", "variables"], "add_tokens": "var dry , version bool", "del_tokens": "dry := false version := false", "commit_type": "use"}
{"commit_tokens": ["Fix", "json", "format", "for", "TotalResponseTime"], "add_tokens": "TotalResponseTime string `json:\"total_response_time`", "del_tokens": "TotalResponseTime string `json\"\"total_response_time`", "commit_type": "fix"}
{"commit_tokens": ["Use", "io", ".", "Pipe", "instead", "of", "StreamBuffer", "..."], "add_tokens": "import ( \" \" \" \" ) upBuffers [ ] * Pipe downBuffers [ ] * Pipe } type Pipe struct { io . Reader io . WriteCloser } func NewPipe ( ) * Pipe { r , w := io . Pipe ( ) return & Pipe { r , w } upBuffers : make ( [ ] * Pipe , MaxToxics - 1 ) , downBuffers : make ( [ ] * Pipe , MaxToxics - 1 ) , link . upBuffers [ i ] = NewPipe ( ) link . downBuffers [ i ] = NewPipe ( )", "del_tokens": "import \" \" upBuffers [ ] * StreamBuffer downBuffers [ ] * StreamBuffer upBuffers : make ( [ ] * StreamBuffer , MaxToxics - 1 ) , downBuffers : make ( [ ] * StreamBuffer , MaxToxics - 1 ) , link . upBuffers [ i ] = NewStreamBuffer ( ) link . downBuffers [ i ] = NewStreamBuffer ( )", "commit_type": "use"}
{"commit_tokens": ["Added", "notes", "on", "TrueString", "and", "FalseString"], "add_tokens": "// be your choice. Although I suppose you could use TrueString(s), // FalseString(s), and !TrueString(s) && !FalseString(s). // such as \"false\", \"False\", \"FALSE\", \"no\", \"off\", etc. Yes, there is already // strconv.ParseBool, but this function is often easier to work with since it // just returns true or false instead of (bool, error) like ParseBool does. If // you need to differentiate between true, false, and unknown, ParseBool should // be your choice. Although I suppose you could use TrueString(s), // FalseString(s), and !TrueString(s) && !FalseString(s).", "del_tokens": "// be your choice. // such as \"false\", \"False\", \"FALSE\", \"no\", \"off\", etc.", "commit_type": "add"}
{"commit_tokens": ["Fix", "doc", "comment", "on", "attribute"], "add_tokens": "// AllowOriginRequestFunc is a custom function to validate the origin. It takes the HTTP Request object and the origin as", "del_tokens": "// AllowOriginFunc is a custom function to validate the origin. It takes the HTTP Request object and the origin as", "commit_type": "fix"}
{"commit_tokens": ["Adds", "ability", "to", "not", "wrap", "error"], "add_tokens": "logger logrus . FieldLogger Reporter func ( args ... interface { } ) reporter WrapError bool logger : logger , WrapError : true , var e interface { } = richError if h . WrapError { e = & jsonError { Error : richError } } if err := json . NewEncoder ( w ) . Encode ( e ) ; err != nil {", "del_tokens": "logger logrus . FieldLogger Reporter func ( args ... interface { } ) reporter logger : logger , if err := json . NewEncoder ( w ) . Encode ( & jsonError { Error : richError } ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["move", "delta", "to", "after", "the", "fields"], "add_tokens": "fmt . Fprintf ( h . Writer , \" \\033 \\033 \" , color , level , e . Message ) fmt . Fprintf ( h . Writer , \" \\n \" , int ( time . Since ( start ) / time . Millisecond ) )", "del_tokens": "ts := time . Since ( start ) / time . Second fmt . Fprintf ( h . Writer , \" \\033 \\033 \" , color , level , ts , e . Message ) fmt . Fprintln ( h . Writer )", "commit_type": "move"}
{"commit_tokens": ["add", ".", "n", "to", "all", "frames", "to", "ensure", "topN", "indexing"], "add_tokens": "netSrcFrame = \" \" netDstFrame = \" \" transSrcFrame = \" \" transDstFrame = \" \" netProtoFrame = \" \" transProtoFrame = \" \" appProtoFrame = \" \" hostnameFrame = \" \" methodFrame = \" \" contentTypeFrame = \" \" userAgentFrame = \" \" packetSizeFrame = \" \" TCPFlagsFrame = \" \"", "del_tokens": "netSrcFrame = \" \" netDstFrame = \" \" transSrcFrame = \" \" transDstFrame = \" \" netProtoFrame = \" \" transProtoFrame = \" \" appProtoFrame = \" \" hostnameFrame = \" \" methodFrame = \" \" contentTypeFrame = \" \" userAgentFrame = \" \" packetSizeFrame = \" \" TCPFlagsFrame = \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "test", "cases", "."], "add_tokens": "\" \" type hwAddrFunc func ( ) ( net . HardwareAddr , error ) hwAddrFunc hwAddrFunc epochFunc : time . Now , hwAddrFunc : defaultHWAddrFunc , rand : rand . Reader , u , err := g . NewV1 ( ) if hwAddr , err := g . hwAddrFunc ( ) ; err == nil { copy ( g . hardwareAddr [ : ] , hwAddr ) return // Returns hardware address. func defaultHWAddrFunc ( ) ( net . HardwareAddr , error ) { ifaces , err := net . Interfaces ( ) if err != nil { return [ ] byte { } , err } for _ , iface := range ifaces { if len ( iface . HardwareAddr ) >= 6 { return iface . HardwareAddr , nil } } return [ ] byte { } , fmt . Errorf ( \" \" ) }", "del_tokens": "epochFunc : time . Now , rand : rand . Reader , u , err := NewV1 ( ) interfaces , err := net . Interfaces ( ) if err == nil { for _ , iface := range interfaces { if len ( iface . HardwareAddr ) >= 6 { copy ( g . hardwareAddr [ : ] , iface . HardwareAddr ) return } }", "commit_type": "add"}
{"commit_tokens": ["implement", "random_password", "resource", "as", "a", "mirror", "of", "random_string"], "add_tokens": "\" \" : resourceId ( ) , \" \" : resourceShuffle ( ) , \" \" : resourcePet ( ) , \" \" : resourceString ( ) , \" \" : resourcePassword ( ) , \" \" : resourceInteger ( ) , \" \" : resourceUuid ( ) ,", "del_tokens": "\" \" : resourceId ( ) , \" \" : resourceShuffle ( ) , \" \" : resourcePet ( ) , \" \" : resourceString ( ) , \" \" : resourceInteger ( ) , \" \" : resourceUuid ( ) ,", "commit_type": "implement"}
{"commit_tokens": ["added", "Iterate", "method", ";", "added", "Omit", "method"], "add_tokens": "if len ( src ) == 1 { return strings . ToLower ( string ( src [ 0 ] ) ) } else { return strings . ToLower ( string ( src [ 0 ] ) ) + src [ 1 : ] }", "del_tokens": "return strings . ToLower ( string ( src [ 0 ] ) ) + src [ 1 : ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "with", "new", "roles", "API"], "add_tokens": "var roles = [ ] interface { } { } for _ , role := range context . Roles { roles = append ( roles , role ) } return job . Permission . HasPermission ( mode , roles ... )", "del_tokens": "return job . Permission . HasPermission ( mode , context . Roles ... )", "commit_type": "fix"}
{"commit_tokens": ["remove", "systematic", "detach", "add", "SetAutoDetach", "method"], "add_tokens": "// SetAutoDetach Enable/disable libusb's automatic kernel driver detachment. // When this is enabled libusb will automatically detach the kernel driver // on an interface when claiming the interface, and attach it when releasing the interface. // Automatic kernel driver detachment is disabled on newly opened device handles by default. func ( d * Device ) SetAutoDetach ( autodetach int ) error { errno := C . libusb_set_auto_detach_kernel_driver ( d . handle , C . int ( autodetach ) , ) // TODO LIBUSB_ERROR_NOT_SUPPORTED (-12) handling // if any errors occur if errno < 0 { return fmt . Errorf ( \" \" , usbError ( errno ) ) } return nil }", "del_tokens": "// Detach the interface if errno := C . libusb_detach_kernel_driver ( d . handle , C . int ( iface ) ) ; errno < 0 { fmt . Errorf ( \" \" , usbError ( errno ) ) }", "commit_type": "remove"}
{"commit_tokens": ["Add", "newId", "function", "to", "generate", "a", "call", "ID", "."], "add_tokens": "\" \" func ( c * Client ) Call ( procURI string , args ... interface { } ) error { msg , err := CreateCall ( newId ( 16 ) , procURI , args ... ) // newId generates a random string of fixed size. func newId ( size int ) string { const alpha = \" \" buf := make ( [ ] byte , size ) for i := 0 ; i < size ; i ++ { buf [ i ] = alpha [ rand . Intn ( len ( alpha ) ) ] } return string ( buf ) }", "del_tokens": "func ( c * Client ) Call ( callID , procURI string , args ... interface { } ) error { msg , err := CreateCall ( callID , procURI , args ... )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Return", ".", "CheckType", "."], "add_tokens": "\" \" // Check the length of the return value. numOut := signature . NumOut ( ) numVals := len ( a . returnVals ) if numOut != numVals { return errors . New ( fmt . Sprintf ( \" \" , numVals , numOut ) ) } // Check the type of each. for i , val := range a . returnVals { expectedType := signature . Out ( i ) actualType := reflect . TypeOf ( val ) if expectedType != actualType { return errors . New ( fmt . Sprintf ( \" \" , actualType , i , expectedType ) ) } } return nil", "del_tokens": "return errors . New ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["Updated", "string", "output", "for", "CollisionType"], "add_tokens": "return \" \" case CT_SAME_ORIG_PERP : return \" \" return \" \"", "del_tokens": "return \" \" return \" \"", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "Retryable", "interface", "and", "implemented", "a", "NoOpConfiguration", "that", "just", "calls", "the", "function", "."], "add_tokens": "Retryable Retryable db . Retryable = retryable Retryable : & NoOpConfiguration { } , return db . Retryable . Retry ( func ( ) error { return selectObjects ( db . Context ( ) , db , db , dest , q , args ) } ) return db . Retryable . Retry ( func ( ) error {", "del_tokens": "retryable Retryable db . retryable = retryable retryable : & NoOpConfiguration { } , return db . retryable . Retry ( func ( ) error { return selectObjects ( db . Context ( ) , db , db , dest , q , args ) } ) return db . retryable . Retry ( func ( ) error {", "commit_type": "add"}
{"commit_tokens": ["add", "ping", "in", "timeouts", "(", "client", "must", "recieve", "ping", "from", "server", "within", "period", "or", "else", "reconnect", ")"], "add_tokens": "Ping bool `json:\"ping,omitempty\"` Version int64 `json:\"version,omitempty\"` //53 usable bits Body json . RawMessage `json:\"body,omitempty\"`", "del_tokens": "Version int64 `json:\"version\"` //53 usable bits Body json . RawMessage `json:\"body\"`", "commit_type": "add"}
{"commit_tokens": ["remove", "redundant", "return", "statements", "and", "unused", "variables"], "add_tokens": "var srcImageMedian = genTestImageMedian ( 100 , 100 )", "del_tokens": "\" \" var ( srcImageMedian = genTestImageMedian ( 100 , 100 ) dstImageMedian draw . Image )", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "test", "for", "RetrFrom", "method", "."], "add_tokens": "r , err = c . RetrFrom ( \" \" , 5 ) buf , err := ioutil . ReadAll ( r ) if err != nil { t . Error ( err ) } expected := testData [ 5 : ] if string ( buf ) != expected { t . Errorf ( \" \" , buf , expected ) }", "del_tokens": "r , err = c . Retr ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplicate", "quorum", "check", "in", "recvViewChange", "()"], "add_tokens": "instance . vcResendTimer . Stop ( ) instance . startTimer ( instance . lastNewViewTimeout , \" \" ) instance . lastNewViewTimeout = 2 * instance . lastNewViewTimeout return viewChangeQuorumEvent { }", "del_tokens": "if quorum >= instance . allCorrectReplicasQuorum ( ) { instance . vcResendTimer . Stop ( ) instance . startTimer ( instance . lastNewViewTimeout , \" \" ) instance . lastNewViewTimeout = 2 * instance . lastNewViewTimeout return viewChangeQuorumEvent { } }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "potential", "data", "race", "in", "handlers", "code"], "add_tokens": "if input == nil { input = & HandlerInput { ErrStatus : http . StatusBadRequest , } // Default to http.StatusBadRequest on error if input . ErrStatus == 0 { input . ErrStatus = http . StatusBadRequest } return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { // Nil-check on input to make it optional", "del_tokens": "return http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { // Nil-check on input to make it optional if input == nil { input = & HandlerInput { ErrStatus : http . StatusBadRequest , } // Default to http.StatusBadRequest on error if input . ErrStatus == 0 { input . ErrStatus = http . StatusBadRequest }", "commit_type": "fix"}
{"commit_tokens": ["Change", "long", "alignment", "in", "Usage"], "add_tokens": "formatLong := fmt . Sprintf ( \" \\n \" , maxShort + 1 , maxLong + 2 )", "del_tokens": "formatLong := fmt . Sprintf ( \" \\n \" , maxShort + 1 , maxLong + 2 )", "commit_type": "change"}
{"commit_tokens": ["move", "stuff", "to", "appease", "godoc", ".", "org"], "add_tokens": "package jsval", "del_tokens": "package jsval", "commit_type": "move"}
{"commit_tokens": ["removing", "pointless", "loop", "wasnt", "a", "good", "testing", "approach"], "add_tokens": "It ( fmt . Sprintf ( \" \" , KillGroupSize ) , func ( ) { maestroFunc ( ) min := 1 max := int ( float64 ( len ( f . FakeQueryResponse ) ) * float64 ( KillGroupSize ) ) Ω( * a ppKiller. K illCounter) . S hould( B eNumerically( \" > , in) ) Ω( * a ppKiller. K illCounter) . S hould( B eNumerically( \" < , ax) ) } )", "del_tokens": "var itAssertions = func ( ) { It ( fmt . Sprintf ( \" \" , KillGroupSize ) , func ( ) { maestroFunc ( ) min := 1 max := int ( float64 ( len ( f . FakeQueryResponse ) ) * float64 ( KillGroupSize ) ) Ω( * a ppKiller. K illCounter) . S hould( B eNumerically( \" > , in) ) Ω( * a ppKiller. K illCounter) . S hould( B eNumerically( \" < , ax) ) } ) } for i := 1 ; i < 200 ; i ++ { itAssertions ( ) } itAssertions ( )", "commit_type": "remove"}
{"commit_tokens": ["Use", "latest", "goagen", "+", "websocket", "example"], "add_tokens": "goaclient \" \" \" \" // Client is the cellar service client. type Client struct { * goaclient . Client } func New ( c * http . Client ) * Client { return & Client { Client : goaclient . New ( c ) }", "del_tokens": "\" \" \" \" type ( // Client is the cellar service client. Client struct { * goa . Client } // ActionCommand represents a single action command as defined on the command line. // Each command is associated with a generated client method and contains the logic to // call the method passing in arguments computed from the command line. ActionCommand interface { // Run makes the HTTP request and returns the response. Run ( c * Client ) error // RegisterFlags defines the command flags. RegisterFlags ( * cobra . Command ) } ) func New ( ) * Client { return & Client { Client : goa . NewClient ( ) }", "commit_type": "use"}
{"commit_tokens": ["Add", "interface", "for", "message", "allowing", "mock", "messages", "to", "be", "injected", "."], "add_tokens": "type Message interface { GetData ( ) [ ] byte Commit ( ) } type SaramaMessage struct { func ( M SaramaMessage ) GetData ( ) [ ] byte { func ( M SaramaMessage ) Commit ( ) { cg . Incoming ( ) <- SaramaMessage { msg , cg . Consumer ( ) }", "del_tokens": "type Message struct { func ( M Message ) GetData ( ) [ ] byte { func ( M Message ) Commit ( ) { cg . Incoming ( ) <- Message { msg , cg . Consumer ( ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "to", "ui", "/", "cocoa", "/", "texture_factory", ".", "go"], "add_tokens": "MainLoop ( ) Window", "del_tokens": "Events ( ) <- chan interface { }", "commit_type": "add"}
{"commit_tokens": ["Add", "HTTP", "multiplexor", "wrapper", "for", "automatic", "telemetry", "."], "add_tokens": "http . ListenAndServe ( * listeningAddress , nil ) var ( listeningAddress = flag . String ( \" \" , \" \" , \" \" ) )", "del_tokens": "var ( listeningAddress string ) func init ( ) { flag . StringVar ( & listeningAddress , \" \" , \" \" , \" \" ) } http . ListenAndServe ( listeningAddress , nil )", "commit_type": "add"}
{"commit_tokens": ["remove", "unused", "error", "return", "from", "sumMURMUR3"], "add_tokens": "d = sumMURMUR3 ( data ) func sumMURMUR3 ( data [ ] byte ) [ ] byte { return bytes", "del_tokens": "d , err = sumMURMUR3 ( data ) func sumMURMUR3 ( data [ ] byte ) ( [ ] byte , error ) { return bytes , nil", "commit_type": "remove"}
{"commit_tokens": ["Use", "any", "ReadSeeker", "instead", "of", "os", ".", "File"], "add_tokens": "image * ImageReader", "del_tokens": "image * os . File", "commit_type": "use"}
{"commit_tokens": ["allow", "for", "limit", "to", "be", "passed", "to", "pager"], "add_tokens": "\" \" func ( l * Client ) GetSegmentEntities ( segment , next string , limit int ) ( interface { } , string , [ ] Entity , error ) { params [ \" \" ] = strconv . Itoa ( limit ) _ , l . Scan . Next , entities , err = l . GetSegmentEntities ( l . Scan . SegmentID , l . Scan . Next , 100 )", "del_tokens": "func ( l * Client ) GetSegmentEntities ( segment , next string ) ( interface { } , string , [ ] Entity , error ) { _ , l . Scan . Next , entities , err = l . GetSegmentEntities ( l . Scan . SegmentID , l . Scan . Next )", "commit_type": "allow"}
{"commit_tokens": ["Allow", "lowercase", "letters", "in", "pkgname"], "add_tokens": "return isAlphaNumeric ( c ) || c == '@' || c == '.' || c == '_' || c == '+' || c == '-'", "del_tokens": "return isLowerAlpha ( c ) || isDigit ( c ) || c == '@' || c == '.' || c == '_' || c == '+' || c == '-'", "commit_type": "allow"}
{"commit_tokens": ["Use", "time", ".", "Sleep", "for", "rate", "-", "limiting", "."], "add_tokens": "time . Sleep ( 10 * time . Millisecond )", "del_tokens": "throttle := time . NewTicker ( time . Millisecond * 10 ) defer throttle . Stop ( ) <- throttle . C", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "uploading", "zip", "files", "using", "--", "path", "option"], "add_tokens": "func TestZipWithDirectory ( t * testing . T ) { func TestZipWithZipFile ( t * testing . T ) { dir , err := os . Getwd ( ) assert . NoError ( t , err ) zipper := ApplicationZipper { } zipFile , err := zipper . Zip ( filepath . Clean ( dir + \" \" ) ) assert . NoError ( t , err ) assert . Equal ( t , string ( zipFile . Bytes ( ) ) , \" \\n \" ) }", "del_tokens": "func TestZip ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Removed", "duplicated", "code", "when", "killing", "a", "process", "after", "graceful", "killing", "fails"], "add_tokens": "killProcessHard ( process )", "del_tokens": "if err := process . Kill ( ) ; err != nil { log . Fatal ( failColor ( \" \" ) ) }", "commit_type": "remove"}
{"commit_tokens": ["remove", "scalar", "mercator", "projects", "and", "fix", "tile", "package"], "add_tokens": "x , y := mercator . ToPlanar ( p . Lon ( ) , p . Lat ( ) , level )", "del_tokens": "x , y := mercator . ScalarProject ( p . Lon ( ) , p . Lat ( ) , level )", "commit_type": "remove"}
{"commit_tokens": ["fix", "array", "idx", "issue", "with", "custom", "functions"], "add_tokens": "val , err := cf ( arr [ idx : ] )", "del_tokens": "val , err := cf ( arr )", "commit_type": "fix"}
{"commit_tokens": ["change", "302", "back", "to", "307", "."], "add_tokens": "http . Redirect ( * w , req , url , http . StatusTemporaryRedirect )", "del_tokens": "http . Redirect ( * w , req , url , http . StatusFound )", "commit_type": "change"}
{"commit_tokens": ["Adding", "changes", "to", "switch", "to", "linux"], "add_tokens": "Actual * Vpc Expected * Vpc CIDR string Tags map [ string ] string AssociatedAsgs [ ] * Asg for _ , serverPool := range r . KnownCluster . ServerPools { asg := & Asg { AssociatedServerPool : serverPool , } asg . Init ( r . KnownCluster , r . AwsSdk ) err := asg . Parse ( ) if err != nil { return fmt . Errorf ( \" \" , serverPool . Name , err ) } r . Expected . AssociatedAsgs = append ( r . Expected . AssociatedAsgs , asg ) } for _ , expectedAsg := range r . Expected . AssociatedAsgs { err := expectedAsg . Apply ( ) if err != nil { return err } } for _ , expectedAsg := range r . Expected . AssociatedAsgs { err := expectedAsg . Render ( ) if err != nil { return err } } for _ , expectedAsg := range r . Expected . AssociatedAsgs { err := expectedAsg . Delete ( ) if err != nil { return err } }", "del_tokens": "Actual * Vpc Expected * Vpc CIDR string Tags map [ string ] string", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "Local", "Devices", "sans", "VolID"], "add_tokens": "ld , err := unmarshalLocalDevices ( ctx , out ) if err != nil { ld , err := unmarshalLocalDevices ( ctx , out ) if err != nil { func unmarshalLocalDevices ( ctx types . Context , out [ ] byte ) ( * types . LocalDevices , error ) { ld := & types . LocalDevices { } if err := ld . UnmarshalText ( out ) ; err != nil { return nil , err } // remove any local devices that has no mapped volume information for k , v := range ld . DeviceMap { if len ( v ) == 0 { ctx . WithField ( \" \" , k ) . Warn ( \" \" ) delete ( ld . DeviceMap , k ) } } return ld , nil }", "del_tokens": "ld := & types . LocalDevices { } if err := ld . UnmarshalText ( out ) ; err != nil { ld := & types . LocalDevices { } if err := ld . UnmarshalText ( out ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "Entry", "Credit", "balance", "command"], "add_tokens": "func ECBalance ( key string ) ( int64 , error ) { str := fmt . Sprintf ( \" \" , serverFct , key ) resp , err := http . Get ( str ) return 0 , err return 0 , err type Balance struct { Balance int64 } b := new ( Balance ) return 0 , err return b . Balance , nil func FctBalance ( key string ) ( int64 , error ) { return 0 , err return 0 , err type Balance struct { Balance int64 } return 0 , err return b . Balance , nil", "del_tokens": "type Balance struct { Balance int64 } func ECBalance ( key string ) ( * Balance , error ) { resp , err := http . Get ( fmt . Sprintf ( \" \" , server , key ) ) return nil , err return nil , err b := new ( Balance ) return nil , err return b , nil func FctBalance ( key string ) ( * Balance , error ) { return nil , err return nil , err return nil , err return b , nil", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "stale", "append", "."], "add_tokens": "// Ensure that entries with stale terms are rejected. func TestServerAppendEntriesWithStaleTermsAreRejected ( t * testing . T ) { server := newTestServer ( \" \" ) server . Start ( ) server . currentTerm = 2 // Append single entry. entries := [ ] * LogEntry { NewLogEntry ( nil , 1 , 1 , & TestCommand1 { \" \" , 10 } ) } resp , err := server . AppendEntries ( NewAppendEntriesRequest ( 1 , \" \" , 0 , 0 , entries , 0 ) ) if ! ( resp . Term == 2 && ! resp . Success && err != nil && err . Error ( ) == \" \" ) { t . Fatalf ( \" \" , resp . Term , resp . Success , err ) } if index , term := server . log . CommitInfo ( ) ; ! ( index == 0 && term == 0 ) { t . Fatalf ( \" \" , index , term ) } }", "del_tokens": "// TODO: Reject entries from old terms.", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "keep", "flag", "for", "mage", "intermediate", "file"], "add_tokens": "force , verbose , list , help , mageInit , keep bool tags string flag . BoolVar ( & keep , \" \" , false , \" \" ) if ! keep { defer os . Remove ( mainfile ) }", "del_tokens": "force , verbose , list , help , mageInit bool tags string defer os . Remove ( mainfile )", "commit_type": "add"}
{"commit_tokens": ["Add", "timeout", "safe", "check", "for", "fsck"], "add_tokens": "const _VERSION = \" \" // Make sure timeout makes sense. if timeout <= 0 { timeout == - 1 }", "del_tokens": "const _VERSION = \" \"", "commit_type": "add"}
{"commit_tokens": ["use", "Response", "wrapper", "added", "docs"], "add_tokens": "//type RouteFunction func(*Request, http.ResponseWriter) type RouteFunction func ( * Request , * Response ) // TODO match Accept header self . Function ( & Request { httpRequest , params } , & Response { httpWriter } )", "del_tokens": "type RouteFunction func ( * Request , http . ResponseWriter ) // TODO match accept //writerWrapper := responseWriter{httpWriter} restRequest := Request { httpRequest , params } restResponse := Response { httpWriter } self . Function ( & restRequest , restResponse )", "commit_type": "use"}
{"commit_tokens": ["Makes", "btrfs", "make", "more", "sense", "."], "add_tokens": "writeFile ( fs , \" \" , \" \" , t ) checkFile ( fs , path . Join ( \" \" , commit , \" \" ) , \" \" , t ) check ( fs . Branch ( \" \" , commit , \" \" ) , t ) checkFile ( fs , \" \" , \" \" , t ) writeFile ( fs , \" \" , \" \" , t ) checkFile ( fs , path . Join ( \" \" , commit , \" \" ) , \" \" , t )", "del_tokens": "writeFile ( fs , \" \" , \" \" , t ) checkFile ( fs , path . Join ( \" \" , \" \" , commit , \" \" ) , \" \" , t ) check ( fs . Branch ( \" \" , \" \" , commit , \" \" ) , t ) checkFile ( fs , \" \" , \" \" , t ) writeFile ( fs , \" \" , \" \" , t ) checkFile ( fs , path . Join ( \" \" , \" \" , commit , \" \" ) , \" \" , t )", "commit_type": "make"}
{"commit_tokens": ["change", "symbol", "to", "blank", "and", "filled", "hexagon"], "add_tokens": "mark := \" mark = \"", "del_tokens": "mark := \" \" mark = \"", "commit_type": "change"}
{"commit_tokens": ["Moved", "regions", "into", "seperate", "file", "and", "noticed", "package", "name", "was", "wrong", "."], "add_tokens": "package aws", "del_tokens": "package main // http://docs.amazonwebservices.com/general/latest/gr/rande.html var ( USEast = & Region { \" \" , \" \" , \" \" } )", "commit_type": "move"}
{"commit_tokens": ["Update", "dataset", "api", "client", "to", "match", "updated", "spec"], "add_tokens": "// Model represents a response dataset model from the dataset api CollectionID string `json:\"collection_id\"` Contact Contact `json:\"contact\"` Description string `json:\"description\"` Links Links `json:\"links\"` NextRelease string `json:\"next_release\"` Periodicity string `json:\"yearly\"` Publisher Publisher `json:\"publisher\"` State string `json:\"state\"` Theme string `json:\"theme\"` Title string `json:\"title\"` } // Version represents a version within a dataset type Version struct { CollectionID string `json:\"collection_id\"` Edition string `json:\"edition\"` ID string `json:\"id\"` InstanceID string `json:\"instance_id\"` License string `json:\"license\"` Links Links `json:\"links\"` ReleaseDate string `json:\"release_date\"` State string `json:\"date\"` } // Edition represents an edition within a dataset type Edition struct { Edition string `json:\"edition\"` ID string `json:\"id\"` Links Links `json:\"links\"` State string `json:\"state\"` } // Publisher represents the publisher within the dataset type Publisher struct { URL string `json:\"href\"` Name string `json:\"name\"` Type string `json:\"type\"` } // Links represent the Links within a dataset model type Links struct { Dataset Link `json:\"dataset\"` Dimensions Link `json:\"dimensions\"` Edition Link `json:\"edition\"` Editions Link `json:\"editions\"` LatestVersion Link `json:\"latest_version\"` Versions Link `json:\"versions\"` Self Link `json:\"self\"` } // Link represents a single link within a dataset model type Link struct { URL string `json:\"href\"` ID string `json:\"id,omitempty\"`", "del_tokens": "// Model represents a response model from the dataset api ID string `json:\"id\"` Title string `json:\"title\"` URL string `json:\"url\"` ReleaseDate string `json:\"release_date\"` NextRelease string `json:\"next_release\"` Edition string `json:\"edition\"` Version string `json:\"version\"` Contact Contact `json:\"contact\"` // Metadata represents metadata from dataset type Metadata struct { Name string `json:\"name\"` Description string `json:\"description\"` }", "commit_type": "update"}
{"commit_tokens": ["Make", "resourcespec", "properly", "have", "nil", "fields"], "add_tokens": "// If we blindly do this copy, we get nils with type info (i.e. != nil) if res . Object != nil { rs . Object = res . Object }", "del_tokens": "rs . Object = res . Object", "commit_type": "make"}
{"commit_tokens": ["Add", "Seamless", "Telegram", "Login", "support", "."], "add_tokens": "Text string `json:\"text\"` URL string `json:\"url,omitempty\"` LoginURL * LoginURL `json:\"login_url,omitempty\"` CallbackData string `json:\"callback_data,omitempty\"` SwitchInlineQuery * string `json:\"switch_inline_query,omitempty\"` SwitchInlineQueryCurrentChat * string `json:\"switch_inline_query_current_chat,omitempty\"` } // LoginURL is a property of InlineKeyboardButton for Seamless Login feature type LoginURL struct { URL string `json:\"url\"` ForwardText * string `json:\"forward_text,omitempty\"` BotUsername * string `json:\"bot_username,omitempty\"` RequestWriteAccess * string `json:\"request_write_access,omitempty\"`", "del_tokens": "Text string `json:\"text\"` URL string `json:\"url,omitempty\"` CallbackData string `json:\"callback_data,omitempty\"` SwitchInlineQuery * string `json:\"switch_inline_query,omitempty\"` SwitchInlineQueryCurrentChat * string `json:\"switch_inline_query_current_chat,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Allow", "ignoring", "recource", "deletion", "related", "errors", "while", "deleting", "application"], "add_tokens": "if err != nil && ! apierr . IsNotFound ( err ) && ! q . Force { if err != nil && ! q . Force { if err != nil && ! q . Force {", "del_tokens": "if err != nil && ! apierr . IsNotFound ( err ) { if err != nil { if err != nil {", "commit_type": "allow"}
{"commit_tokens": ["removed", "debug", "print", "fixed", "typo"], "add_tokens": "func newMockConn ( address , scheme , username , password string , config * Config ) mcConn {", "del_tokens": "func newMockConn ( address , schema , username , password string , config * Config ) mcConn {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "bug", "where", "keys", "and", "key", "groups", "could", "be", "on", "the", "same", "line", "as", "other"], "add_tokens": "func ( lx * lexer ) current ( ) string { return lx . input [ lx . start : lx . pos ] } lx . items <- item { typ , lx . current ( ) , lx . line } lx . push ( lexTopEnd ) // lexTopEnd is entered whenever a top-level item has been consumed. (A value // or a keygroup.) It must see only whitespace, and will turn back to lexTop // upon a new line. If it sees EOF, it will quit the lexer successfully. func lexTopEnd ( lx * lexer ) stateFn { return lexTopEnd return lx . errorf ( \" \" + case keyGroupStart : return lx . errorf ( \" \" , keyGroupStart , keyGroupEnd ) return lexTopEnd return lexSkip ( lx , lexValue )", "del_tokens": "lx . items <- item { typ , lx . input [ lx . start : lx . pos ] , lx . line } lx . push ( lexTopValueEnd ) // lexTopValueEnd is entered whenever a top-level value has been consumed. // It must see only whitespace, and will turn back to lexTop upon a new line. // If it sees EOF, it will quit the lexer successfully. func lexTopValueEnd ( lx * lexer ) stateFn { return lexTopValueEnd return lx . errorf ( \" \" + return lexTop return lexValue", "commit_type": "fix"}
{"commit_tokens": ["Use", "context", "span", "as", "parent"], "add_tokens": "c , sp0 := trace . Start ( c , \" \" ) c , sp1 := trace . Start ( c , \" \" ) c , sp1 := trace . Start ( c , \" \" )", "del_tokens": "_ , sp0 := trace . Start ( c , \" \" ) _ , sp1 := trace . Start ( c , \" \" ) _ , sp1 := trace . Start ( c , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Use", "seconds", "in", "haproxy_check_duration_seconds", "as", "unit"], "add_tokens": "pxnameField = 0 svnameField = 1 statusField = 17 typeField = 32 checkDurationField = 38 qtimeMsField = 58 ctimeMsField = 59 rtimeMsField = 60 ttimeMsField = 61 38 : newServerMetric ( \" \" , \" \" , prometheus . GaugeValue , nil ) , case checkDurationField , qtimeMsField , ctimeMsField , rtimeMsField , ttimeMsField :", "del_tokens": "pxnameField = 0 svnameField = 1 typeField = 32 statusField = 17 qtimeMsField = 58 ctimeMsField = 59 rtimeMsField = 60 ttimeMsField = 61 38 : newServerMetric ( \" \" , \" \" , prometheus . GaugeValue , nil ) , case qtimeMsField , ctimeMsField , rtimeMsField , ttimeMsField :", "commit_type": "use"}
{"commit_tokens": ["adding", "schema", "examples", "slight", "mods", "to", "lexer"], "add_tokens": "// TokenType enum message = \" \" \" \" , \" \" , \" \" , // Handler is simpley a function which takes a single Token argument return l . errorf ( \" \" )", "del_tokens": "// Token Type enum message = \" \" \" \" , \" \" , \" \" , // Token handler function } else { return l . errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["use", "scratch", "buffer", "for", "all", "tests"], "add_tokens": "var testScratchBuffer [ ] byte func init ( ) { testScratchBuffer = make ( [ ] byte , testScratchBufferSize ) } ScratchBuffer : testScratchBuffer , ScratchBuffer : testScratchBuffer , ScratchBuffer : testScratchBuffer , ScratchBuffer : testScratchBuffer , FollowSymbolicLinks : true , ScratchBuffer : testScratchBuffer , FollowSymbolicLinks : true , ScratchBuffer : testScratchBuffer ,", "del_tokens": "ScratchBuffer : make ( [ ] byte , testScratchBufferSize ) , ScratchBuffer : make ( [ ] byte , testScratchBufferSize ) , FollowSymbolicLinks : true , FollowSymbolicLinks : true , ScratchBuffer : make ( [ ] byte , testScratchBufferSize ) ,", "commit_type": "use"}
{"commit_tokens": ["Add", "documentation", "to", "Message", "and", "Delivery"], "add_tokens": "// Message represents a Facebook messenge message. // Sender is who the message was sent from. Sender Sender `json:\"-\"` // Recipient is who the message was sent to. Recipient Recipient `json:\"-\"` // Time is when the message was sent. Time time . Time `json:\"-\"` // Mid is the ID of the message. Mid string `json:\"mid\"` // Seq is order the message was sent in relation to other messages. Seq int `json:\"seq\"` // Text is the textual contents of the message. Text string `json:\"text\"` // Attachments is the information about the attachments which were sent // with the message. // Delivery represents a the event fired when a recipient reads one of Messengers sent // messages. // Mids are the IDs of the messages which were read. Mids [ ] string `json:\"mids\"` // RawWatermark is the timestamp contained in the message of when the read was. RawWatermark int64 `json:\"watermark\"` // Seq is the sequence the message was sent in. Seq int `json:\"seq\"` // Watermark is the RawWatermark timestamp rendered as a time.Time.", "del_tokens": "Sender Sender `json:\"-\"` Recipient Recipient `json:\"-\"` Time time . Time `json:\"-\"` Mid string `json:\"mid\"` Text string `json:\"text\"` Seq int `json:\"seq\"` Mids [ ] string `json:\"mids\"` RawWatermark int64 `json:\"watermark\"` Seq int `json:\"seq\"`", "commit_type": "add"}
{"commit_tokens": ["Use", "console", "=", "ttyS0", "in", "kernel", "options"], "add_tokens": "if mgr . consoleTTY { extraFlags += \" \" mgr . logger . Log ( \" \" , \" \" , \" \" , \" \" ) } extraFlags += \" \"", "del_tokens": "extraFlags += \" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "Context", "and", "Subject", "types"], "add_tokens": "// Remove any Here, Cause, Trace, Context or Subject wrappers from err for { switch specific := err . ( type ) { case * HereError : err = specific . error case * CauseError : err = specific . error case * TraceError : err = specific . error case * ContextError : err = specific . error case * SubjectError : err = specific . error default : return err }", "del_tokens": "// If err is a Here, Cause, or Trace wrapper, return the inner error switch specific := err . ( type ) { case * HereError : return specific . error case * CauseError : return specific . error case * TraceError : return specific . error default : return err", "commit_type": "add"}
{"commit_tokens": ["Improve", "the", "DB", "adapter", "test", "."], "add_tokens": "func TestDBSavePolicy ( t * testing . T ) { e . Init ( \" \" , \" \" ) a . savePolicy ( e . model ) func TestDBSaveAndLoadPolicy ( t * testing . T ) { e . Init ( \" \" , \" \" ) clearPolicy ( e . model ) testGetPolicy ( t , e , [ ] [ ] string { } ) a . loadPolicy ( e . model ) testGetPolicy ( t , e , [ ] [ ] string { { \" \" , \" \" , \" \" } , { \" \" , \" \" , \" \" } , { \" \" , \" \" , \" \" } , { \" \" , \" \" , \" \" } } )", "del_tokens": "func TestDBLoadPolicy ( t * testing . T ) { e . Init ( \" \" , \" \" ) a . loadPolicy ( e . model ) printPolicy ( e . model ) func TestDBSavePolicy ( t * testing . T ) { e . Init ( \" \" , \" \" )", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "GET", "route", "for", "IDs", "containing", "slashes"], "add_tokens": "route := ws . GET ( \" \" ) . To ( r . GetByIDs ) .", "del_tokens": "route := ws . GET ( \" \" ) . To ( r . GetByIDs ) .", "commit_type": "fix"}
{"commit_tokens": ["Fix", "an", "issue", "that", "error", "occurs", "when", "a", "same", "name", "tables", "exist", "in", "each", "array", "of", "tables"], "add_tokens": "names := splitTableKey ( name ) if lt := p . tableMap [ names [ len ( names ) - 1 ] ] ; t . tableType == tableTypeArray || lt != nil && lt . tableType == tableTypeNormal { p . Error ( fmt . Errorf ( \" \" , name , t . tableType , t . line ) ) } t , err := p . lookupTable ( t , names )", "del_tokens": "p . Error ( fmt . Errorf ( \" \" , name , t . tableType , t . line ) ) t , err := p . lookupTable ( t , splitTableKey ( name ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "generator", "unit", "tests", "."], "add_tokens": "var r0 * string if ret . Get ( 0 ) != nil { r0 = ret . Get ( 0 ) . ( * string ) } var r1 * test . Err if ret . Get ( 1 ) != nil { r1 = ret . Get ( 1 ) . ( * test . Err ) }", "del_tokens": "r0 := ret . Get ( 0 ) . ( * string ) r1 := ret . Get ( 1 ) . ( * test . Err )", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "mutex", "around", "adding", "helpers"], "add_tokens": "\" \" var Helpers = HelperMap { moot : & sync . Mutex { } , }", "del_tokens": "var Helpers = HelperMap { }", "commit_type": "add"}
{"commit_tokens": ["fixed", "parse", "free", ".", "tk", "domain"], "add_tokens": "if ! assert . IsContains ( [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , extension ) { if ! assert . IsContains ( [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , extension ) { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , extension ) {", "del_tokens": "if ! assert . IsContains ( [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , extension ) { if ! assert . IsContains ( [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , extension ) { \" \" , \" \" , \" \" , \" \" , \" \" } , extension ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "plugin", "-", "based", "implementations", "of", "risk", "services", ".", "Also", "update", "vendored", "fhir", "dependency", "and", "add", "dependency", "on", "fhir", "/", "search", ".", "WARNING", ":", "Not", "yet", "hooked", "up", "to", "actual", "calculation", "runner", "(", "todo", ")", "."], "add_tokens": "\" \" func ( p * Pie ) Clone ( ) * Pie { cloned := * p cloned . Slices = make ( [ ] Slice , len ( p . Slices ) ) copy ( cloned . Slices , p . Slices ) return & cloned } func ( p * Pie ) UpdateSliceValue ( name string , value int ) { for i := range p . Slices { if p . Slices [ i ] . Name == name { p . Slices [ i ] . Value = value return } } } func ( p * Pie ) TotalValues ( ) int { total := 0 for i := range p . Slices { total += p . Slices [ i ] . Value } return total }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "buffered", "writer", "for", "stdout"], "add_tokens": "\" \" Version = fileseq . Version w = bufio . NewWriter ( os . Stdout )", "del_tokens": "Version = \" \" w = os . Stdout os . Exit ( 0 )", "commit_type": "use"}
{"commit_tokens": ["Add", "no", "-", "write", "option", "to", "jlp", "."], "add_tokens": "func prettify ( file string , validateOnly bool ) error { if validateOnly { return nil } func compact ( file string , validateOnly bool ) error { if validateOnly { return nil } - n Don 't prettify ; only perform validation . var shouldCompact , validateOnly bool flag . BoolVar ( & validateOnly , \" \" , false , \" \" ) err := action ( fileName , validateOnly )", "del_tokens": "func prettify ( file string ) error { func compact ( file string ) error { var shouldCompact bool err := action ( fileName )", "commit_type": "add"}
{"commit_tokens": ["fixed", "problems", "with", "DB", "table"], "add_tokens": "// init full DB err = InitDBFullColumns ( db )", "del_tokens": "err = InitDB ( db )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "output", "check", "for", "ExampleTxn_Mutate_list", "."], "add_tokens": "// List items aren't guaranteed to be in the same order. // {\"me\":[{\"address\":[\"Riley Street\",\"Redfern\"],\"phone_number\":[9876,123]}]}", "del_tokens": "// Output: {\"me\":[{\"address\":[\"Riley Street\",\"Redfern\"],\"phone_number\":[9876,123]}]}", "commit_type": "remove"}
{"commit_tokens": ["added", "a", "new", "ESError", "type", "to", "get", "back", "http", "status", "code", "to", "support", "implementation", "of", "index", "exists", "HEAD", "call", ".", "Fixed", "handling", "of", "multiple", "indices", "in", "flush"], "add_tokens": "\" \" return body , ESError { time . Now ( ) , fmt . Sprintf ( \" \" , error , status ) , httpStatusCode } // ESError is an error implementation that includes a time, message, and code. type ESError struct { When time . Time What string Code int } func ( e ESError ) Error ( ) string { return fmt . Sprintf ( \" \" , e . When , e . What , e . Code ) }", "del_tokens": "\" \" return body , errors . New ( fmt . Sprintf ( \" \" , error , status ) )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "custom", "error", "type", "for", "invalid", "lengths", "replacing", "fmt", ".", "Errorf"], "add_tokens": "type invalidLengthError struct { len int } func ( err * invalidLengthError ) Error ( ) string { return fmt . Sprintf ( \" \" , err . len ) } return uuid , & invalidLengthError { len ( s ) } return uuid , & invalidLengthError { len ( b ) }", "del_tokens": "return uuid , fmt . Errorf ( \" \" , len ( s ) ) return uuid , fmt . Errorf ( \" \" , len ( b ) )", "commit_type": "use"}
{"commit_tokens": ["Use", "our", "own", "Value", "for", "String"], "add_tokens": "// String is an atomic type-safe wrapper around Value for strings. type String struct { v Value } // Note: Converting the string to an interface{} to store in the Value", "del_tokens": "import \" \" // String is an atomic type-safe wrapper around atomic.Value for strings. type String struct { v atomic . Value } // Note: Converting the string to an interface{} to store in the atomic.Value", "commit_type": "use"}
{"commit_tokens": ["Move", "_yr_rules_scan_fd", "definition", "to", "rules_yara34", ".", "go"], "add_tokens": "// Helper function that is merely used to cast fd from int to HANDLE. // CGO treats HANDLE (void*) to an unsafe.Pointer. This confuses the // go1.4 garbage collector, leading to runtime errors such as: // // runtime: garbage collector found invalid heap pointer *(0x5b80ff14+0x4)=0xa0 s=nil int timeout ) { return yr_rules_scan_fd ( rules , ( YR_FILE_DESCRIPTOR ) fd , flags , callback , user_data , timeout ) ; }", "del_tokens": "int timeout ) ;", "commit_type": "move"}
{"commit_tokens": ["Change", "config", "file", "flag", "name"], "add_tokens": "func NewConfigFromPath ( configFile string , fs boshsys . FileSystem ) ( Config , error ) { if configFile == \" \" { return config , bosherr . Errorf ( \" \" ) } bytes , err := fs . ReadFile ( configFile ) return config , bosherr . WrapErrorf ( err , \" \" , configFile ) return config , bosherr . WrapError ( err , \" \" )", "del_tokens": "func NewConfigFromPath ( path string , fs boshsys . FileSystem ) ( Config , error ) { bytes , err := fs . ReadFile ( path ) return config , bosherr . WrapErrorf ( err , \" \" , path ) return config , bosherr . WrapError ( err , \" \" )", "commit_type": "change"}
{"commit_tokens": ["Fixing", "an", "issue", "with", "reading", "full", "blocks", "as", "an", "optimization", "."], "add_tokens": "\" \" ReportErr ( fmt . Errorf ( \" \" , err ) , ) //ReadLoop: if err == nil { generator . WeakRollingHash . SetBlock ( block ) blockMemory . WriteEvicted ( block ) i += int64 ( generator . BlockSize ) } else if err == io . EOF || err == io . ErrUnexpectedEOF { err = io . EOF break }", "del_tokens": "ReportErr ( err ) generator . WeakRollingHash . SetBlock ( block ) blockMemory . WriteEvicted ( block ) i += int64 ( generator . BlockSize )", "commit_type": "fix"}
{"commit_tokens": ["use", "data", ".", "InsertItems", "and", "data", ".", "CleanDB", "in", "pay", "tests"], "add_tokens": "tx , _ := db . Begin ( ) tx . Insert ( item ) tx . Commit ( )", "del_tokens": "db . Insert ( item )", "commit_type": "use"}
{"commit_tokens": ["Fix", "handler", "comparison", "test", "and", "remove", "unnecessary", "pname", "look", "up", "when", "pos", ">", "0"], "add_tokens": "\" \" mailAtHandler := fakeHandler ( ) { Pattern : \" \" , Handler : mailAtHandler } , { Input : \" \" , ExpectedHandler : mailAtHandler , ExpectedParams : M { \" \" : \" \" } } , // TODO: Find a better way to compare handlers that using a random token type fakeHandlerType struct { t string } return & fakeHandlerType { t : randToken ( ) } } func randToken ( ) string { b := make ( [ ] byte , 16 ) rand . Read ( b ) return fmt . Sprintf ( \" \" , b )", "del_tokens": "type fakeHandlerType struct { } return new ( fakeHandlerType )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "sending", "emails", "that", "have", "html", "content"], "add_tokens": "\" \" From string To [ ] string Subject string Body string BodyContentType string Attachments map [ string ] [ ] byte m := & Message { Subject : subject , Body : body , BodyContentType : \" \" } m . Attachments = make ( map [ string ] [ ] byte ) return m } func NewHTMLMessage ( subject string , body string ) * Message { m := & Message { Subject : subject , Body : body , BodyContentType : \" \" } buf . WriteString ( fmt . Sprintf ( \" \\n \" , m . BodyContentType ) )", "del_tokens": "From string To [ ] string Subject string Body string Attachments map [ string ] [ ] byte m := & Message { Subject : subject , Body : body } buf . WriteString ( \" \\n \" )", "commit_type": "allow"}
{"commit_tokens": ["Updated", "version", "updated", "readme", "to", "reflect", "breaking", "changes"], "add_tokens": "const Version = \" \"", "del_tokens": "const Version = \" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "client", "connection", "number", "in", "server", "debug", "msg", "."], "add_tokens": "var connCnt int32 var host string debug . Printf ( \" \\n \" , conn . RemoteAddr ( ) . String ( ) , conn . LocalAddr ( ) ) atomic . AddInt32 ( & connCnt , 1 ) defer func ( ) { atomic . AddInt32 ( & connCnt , - 1 ) debug . Printf ( \" \\n \" , conn . RemoteAddr ( ) , host ) conn . Close ( ) debug . Printf ( \" \\n \" , connCnt ) } ( ) } else { defer conn . Close ( ) // debug.Println(\"getRequest read extra data, writing to remote, len\", len(extra)) if debug { debug . Printf ( \" \" , conn . RemoteAddr ( ) , host ) }", "del_tokens": "debug . Printf ( \" \\n \" , conn . RemoteAddr ( ) . String ( ) ) defer conn . Close ( ) debug . Println ( \" \" , len ( extra ) ) debug . Println ( \" \" , host ) debug . Println ( \" \" , host )", "commit_type": "add"}
{"commit_tokens": ["add", "proto", "validation", "at", "parse"], "add_tokens": "\" \" func validateProto ( proto string ) bool { for _ , availableProto := range [ ] string { \" \" , \" \" } { if availableProto == proto { return true } } return false } if ! validateProto ( proto ) { return nil , nil , fmt . Errorf ( \" \" , proto ) }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "config", ".", "http", ".", "addr", "and", "config", ".", "http", ".", "ssl", "for", "create", "baseURL", "test", "server"], "add_tokens": "var httpAddr = revel . HttpAddr if httpAddr == \" \" { httpAddr = \" \" } var httpProto = \" \" if revel . HttpSsl { httpProto = \" \" } var baseURL = fmt . Sprintf ( \" \" , httpProto , httpAddr , revel . HTTPPort )", "del_tokens": "var baseURL = fmt . Sprintf ( \" \" , revel . HTTPPort )", "commit_type": "use"}
{"commit_tokens": ["Added", "default", "validation", "for", "headers"], "add_tokens": "path := \" \"", "del_tokens": "path := \" \"", "commit_type": "add"}
{"commit_tokens": ["add", "image_ref", "and", "flavor_ref", "checks"], "add_tokens": "var ( OS_REGION_NAME = \" \" ) v := os . Getenv ( \" \" ) if v == \" \" { v = os . Getenv ( \" \" ) if v == \" \" { t . Fatal ( \" \" ) OS_REGION_NAME = v v = os . Getenv ( \" \" ) if v == \" \" { t . Fatal ( \" \" ) v = os . Getenv ( \" \" ) if v == \" \" { t . Fatal ( \" \" )", "del_tokens": "if v := os . Getenv ( \" \" ) ; v == \" \" { t . Fatal ( \" \" ) } if v := os . Getenv ( \" \" ) ; v == \" \" { if v := os . Getenv ( \" \" ) ; v == \" \" { t . Fatal ( \" \" ) if v := os . Getenv ( \" \" ) ; v != \" \" { t . Fatal ( \" \" ) if v := os . Getenv ( \" \" ) ; v != \" \" { t . Fatal ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "texture", ".", "Texture", ".", "Native"], "add_tokens": "defer C . glBindFramebuffer ( C . GL_FRAMEBUFFER , C . GLuint ( origFramebuffer ) ) func New ( width , height int , filter texture . Filter ) ( * rendertarget . RenderTarget , error ) { tex , err := texture . New ( width , height , filter ) framebuffer := C . GLuint ( 0 ) tex . CreateFramebuffer ( func ( native interface { } ) { framebuffer = createFramebuffer ( C . GLuint ( native . ( texture . Native ) ) ) } ) func NewWithFramebuffer ( width , height int , framebuffer Framebuffer , filter texture . Filter ) ( * rendertarget . RenderTarget , error ) { tex , err := texture . New ( width , height , filter )", "del_tokens": "C . glBindFramebuffer ( C . GL_FRAMEBUFFER , C . GLuint ( origFramebuffer ) ) func NewRenderTarget ( width , height int ) ( * rendertarget . RenderTarget , error ) { tex , err := texture . New ( width , height ) framebuffer := createFramebuffer ( C . GLuint ( tex . Native ( ) . ( texture . Native ) ) ) func NewRenderTargetWithFramebuffer ( width , height int , framebuffer Framebuffer ) ( * rendertarget . RenderTarget , error ) { tex , err := texture . New ( width , height )", "commit_type": "remove"}
{"commit_tokens": ["changed", "go", "-", "manifold", "s", "codeRegex", "to", "allow", "the", "6", "digit", "verification"], "add_tokens": "codeRegex = regexp . MustCompile ( \" \" )", "del_tokens": "codeRegex = regexp . MustCompile ( \" \" )", "commit_type": "change"}
{"commit_tokens": ["Use", "Error", "and", "NoError", "add", "test", "for", "SteamIDsEqual"], "add_tokens": "assert . Error ( t , err ) assert . NoError ( t , err ) assert . Error ( t , err ) assert . NoError ( t , err ) assert . NoError ( t , err ) assert . Equal ( t , res , \" \" ) res , err = SteamIdToCommId ( \" \" ) assert . NoError ( t , err ) assert . Error ( t , err ) assert . NoError ( t , err ) assert . Error ( t , err ) assert . Error ( t , err ) } func TestSteamIDsEqual ( t * testing . T ) { eq := SteamIDsEqual ( \" \" , \" \" ) assert . True ( t , eq )", "del_tokens": "assert . NotNil ( t , err ) assert . Nil ( t , err ) assert . NotNil ( t , err ) assert . Nil ( t , err ) assert . Nil ( t , err ) assert . NotNil ( t , err ) assert . Nil ( t , err ) assert . NotNil ( t , err ) assert . NotNil ( t , err )", "commit_type": "use"}
{"commit_tokens": ["allow", "overriding", "of", "dists", "path"], "add_tokens": "\" \" cli . StringFlag { Name : \" \" , Usage : \" \" , } , if distp := c . String ( \" \" ) ; distp != \" \" { util . IpfsVersionPath = distp } if ! strings . HasPrefix ( vers , \" \" ) && looksLikeSemver ( vers ) { if ! strings . HasPrefix ( vers , \" \" ) && looksLikeSemver ( vers ) { func looksLikeSemver ( v string ) bool { parts := strings . Split ( v , \" \" ) if len ( parts ) < 3 { return false } if _ , err := strconv . Atoi ( parts [ 0 ] ) ; err == nil { return true } return false }", "del_tokens": "if ! strings . HasPrefix ( vers , \" \" ) { if ! strings . HasPrefix ( vers , \" \" ) {", "commit_type": "allow"}
{"commit_tokens": ["Allow", "retrieval", "of", "ordered", "keys", "from", "meta", "data", "."], "add_tokens": "p , err := parse ( data ) return MetaData { p . mapping , p . types , p . ordered } , unify ( p . mapping , rvalue ( v ) ) keys [ ] Key // The list will have the same order as the keys appeared in the TOML data. // return md . keys", "del_tokens": "mapping , types , err := parse ( data ) return MetaData { mapping , types } , unify ( mapping , rvalue ( v ) ) return allKeys ( md . mapping , nil )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "import", "/", "export", "proc", "calls"], "add_tokens": "dll , proc , err := loadAndFind ( procExportLayer )", "del_tokens": "dll , proc , err := loadAndFind ( procPrepareLayer )", "commit_type": "fix"}
{"commit_tokens": ["create", "new", "channel", "before", "start", "heartbeat", "to", "avoid", "recv", "stop", "signal", "from", "old", "heartbeat", "func"], "add_tokens": "p . stopChan = make ( chan bool , 1 ) stopChan := p . stopChan case <- stopChan :", "del_tokens": "stopChan : make ( chan bool , 1 ) , case <- p . stopChan :", "commit_type": "create"}
{"commit_tokens": ["changing", "how", "Draw", ".", "LineSeries", "handles", "the", "0", "line"], "add_tokens": "yv0 := yrange . Translate ( 0 ) style . GetFillOptions ( ) . WriteToRenderer ( r ) r . LineTo ( x , Math . MinInt ( cb , cb - yv0 ) ) r . LineTo ( x0 , Math . MinInt ( cb , cb - yv0 ) ) r . LineTo ( x0 , y0 )", "del_tokens": "r . SetFillColor ( fill ) r . LineTo ( x , cb ) r . LineTo ( x0 , cb ) r . Close ( )", "commit_type": "change"}
{"commit_tokens": ["added", "integration", "test", "for", "client", ".", "StatVFS"], "add_tokens": "return nil , errors . New ( fxp ( ssh_FXP_STATUS ) . String ( ) )", "del_tokens": "return nil , errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["fix", "target", "-", "path", "for", "pod"], "add_tokens": "cnt . target = cnt . path + \" \" if args . Path != \" \" { currentAbsDir , err := filepath . Abs ( args . Path ) if err != nil { log . Get ( ) . Panic ( \" \" ) } cnt . target = currentAbsDir }", "del_tokens": "\" \" cnt . target = path . Join ( args . TargetPath , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["move", "handshake", "handling", "and", "server", "config", "into", "handshake", "package"], "add_tokens": "\" \" serverConfig := handshake . NewServerConfig ( crypto . NewCurve25519KEX ( ) , keyData )", "del_tokens": "serverConfig := quic . NewServerConfig ( crypto . NewCurve25519KEX ( ) , keyData )", "commit_type": "move"}
{"commit_tokens": ["Use", "http", ".", "MethodOptions", "instead", "of", "literal"], "add_tokens": "if r . Method == http . MethodOptions && r . Header . Get ( \" \" ) != \" \" { if r . Method == http . MethodOptions && r . Header . Get ( \" \" ) != \" \" { if r . Method == http . MethodOptions && r . Header . Get ( \" \" ) != \" \" { if r . Method != http . MethodOptions { if r . Method == http . MethodOptions { if method == http . MethodOptions {", "del_tokens": "if r . Method == \" \" && r . Header . Get ( \" \" ) != \" \" { if r . Method == \" \" && r . Header . Get ( \" \" ) != \" \" { if r . Method == \" \" && r . Header . Get ( \" \" ) != \" \" { if r . Method != \" \" { if r . Method == \" \" { if method == \" \" {", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "missing", "constant", "in", "sdl_cpuinfo", ".", "go"], "add_tokens": "// #include <SDL2/SDL_cpuinfo.h> const CACHELINE_SIZE = 128", "del_tokens": "// #include <SDL2/SDL.h>", "commit_type": "add"}
{"commit_tokens": ["Add", "function", "calls", "to", "SQL", "example", "grammar", "."], "add_tokens": "sqlLexer = lexer . Unquote ( lexer . Upper ( lexer . Must ( lexer . Regexp ( `(\\s+)` + `|(?P<String>'[^']*'|\"[^\"]*\")` + ) ) , \" \" ) , \" \" ) Select * Select `( \"(\" @@ \")\"` SymbolRef * SymbolRef ` | @@` Value * Value ` | @@ )` } type SymbolRef struct { Symbol string `@Ident @{ \".\" Ident }` Parameters [ ] * Expression `[ \"(\" @@ { \",\" @@ } \")\" ]` } type Value struct { Negated bool `[ @\"-\" | \"+\" ]` Wildcard bool `( @\"*\"` Number * float64 ` | @Number` String * string ` | @String` Boolean * Boolean ` | @(\"TRUE\" | \"FALSE\")` Null bool ` | @\"NULL\"` Array * Array ` | @@ )`", "del_tokens": "sqlLexer = lexer . Upper ( lexer . Must ( lexer . Regexp ( `(\\s+)` + `|(?P<String>'[^']*')` + ) ) , \" \" ) Negated bool `[ @\"-\" | \"+\" ]` ColumnRef * string `( @Ident @{ \".\" Ident }` Number * float64 ` | @Number` String * string ` | @String` Boolean * Boolean ` | @(\"TRUE\" | \"FALSE\")` Null bool ` | @\"NULL\"` Array * Array ` | @@ )`", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "t . clock . SetTime ( time . Now ( ) )", "del_tokens": "t . clock . AdvanceTime ( time . Now ( ) . Sub ( t . clock . Now ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "IsBinary", ":", "returning", "full", "reader"], "add_tokens": "func TestDetectBinaryFormatReturningFullReader ( t * testing . T ) { ok , _ := IsBinaryFormat ( & buff ) if got , want := ok , false ; got != want { orig := buff . String ( ) ok , r := IsBinaryFormat ( & buff ) if got , want := ok , true ; got != want { b , _ := ioutil . ReadAll ( r ) if got , want := string ( b ) , orig ; got != want { t . Fatalf ( \" \" , got , want ) } orig = buff . String ( ) ok , r = IsBinaryFormat ( & buff ) if got , want := ok , false ; got != want { b , _ = ioutil . ReadAll ( r ) if got , want := string ( b ) , orig ; got != want { t . Fatalf ( \" \" , got , want ) }", "del_tokens": "func TestDetectBinaryFormat ( t * testing . T ) { if got , want := IsBinaryFormat ( & buff ) , false ; got != want { if got , want := IsBinaryFormat ( & buff ) , true ; got != want { if got , want := IsBinaryFormat ( & buff ) , false ; got != want {", "commit_type": "fix"}
{"commit_tokens": ["Improve", "the", "debug", "messages", "sent", "via", "trace", ".", "T", "()", "."], "add_tokens": "trace . T ( \" \" , trace . PrioVerbose , \" \" )", "del_tokens": "trace . T ( \" \" , trace . PrioDebug , \" \" )", "commit_type": "improve"}
{"commit_tokens": ["Updated", "to", "use", "latest", "middleware", "."], "add_tokens": "app . ConfigureAdminPassSecurity ( service , basicauth . New ( \" \" , \" \" ) )", "del_tokens": "app . AdminPassSecurity . Use ( basicauth . New ( \" \" , \" \" ) )", "commit_type": "update"}
{"commit_tokens": ["Use", "cookiejar", "to", "store", "cookies"], "add_tokens": "\" \" \" \" url * url . URL cookies http . CookieJar httpRequest , err := NewRequest ( codec . url . String ( ) , request . ServiceMethod , args ) for _ , cookie := range codec . cookies . Cookies ( codec . url ) { if codec . cookies != nil { codec . cookies . SetCookies ( codec . url , httpResponse . Cookies ( ) ) func NewClient ( requrl string , transport http . RoundTripper ) ( * Client , error ) { jar , err := cookiejar . New ( nil ) if err != nil { return nil , err } u , err := url . Parse ( requrl ) if err != nil { return nil , err } url : u , cookies : jar ,", "del_tokens": "url string cookies [ ] * http . Cookie httpRequest , err := NewRequest ( codec . url , request . ServiceMethod , args ) for _ , cookie := range codec . cookies { if codec . cookies == nil { codec . cookies = httpResponse . Cookies ( ) func NewClient ( url string , transport http . RoundTripper ) ( * Client , error ) { url : url ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "Current", "not", "implemented", "on", "freebsd", "/", "amd64", "error"], "add_tokens": "homeDir := \" \" homeDir = os . Getenv ( \" \" ) if homeDir == \" \" { panic ( fmt . Sprintf ( \" \\n \" , err . Error ( ) ) ) } } else { homeDir = u . HomeDir out = [ ] string { homeDir + \" \" }", "del_tokens": "panic ( err ) out = [ ] string { u . HomeDir + \" \" }", "commit_type": "fix"}
{"commit_tokens": ["implement", "functional", "options", "pattern", "."], "add_tokens": "ui := NewUI ( Reader ( r ) , Writer ( outBuf ) ) ui := NewUI ( Writer ( outBuf ) ) ui := NewUI ( Writer ( outBuf ) ) ui := NewUI ( ErrorWriter ( outBuf ) ) ui := NewUI ( ErrorWriter ( outBuf ) )", "del_tokens": "ui := NewUI ( r , outBuf , nil ) ui := NewUI ( nil , outBuf , nil ) ui := NewUI ( nil , outBuf , nil ) ui := NewUI ( nil , nil , outBuf ) ui := NewUI ( nil , nil , outBuf )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "save", "images", "for", "virtual", "attributes"], "add_tokens": "\" \" b . FileHeader , b . FileName = file , file . Filename var doCrop struct { Crop bool } if err = json . Unmarshal ( values , & doCrop ) ; err == nil && doCrop . Crop { b . Crop = true } return json . Marshal ( b )", "del_tokens": "\" \" Valid bool `json:\"-\"` b . Valid = true b . FileHeader , b . FileName , b . Valid = file , file . Filename , true b . Valid = true } var doCrop struct { Crop bool } if err = json . Unmarshal ( values , & doCrop ) ; err == nil && doCrop . Crop { b . Crop = true if b . Valid { result , err := json . Marshal ( b ) return string ( result ) , err } return nil , nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "wrong", "build", "tag", "."], "add_tokens": "// +build linux", "del_tokens": "// -build linux", "commit_type": "fix"}
{"commit_tokens": ["Moving", "tests", "back", "to", "normal"], "add_tokens": "j := SampleJob { Name : fmt . Sprintf ( \" \" , i + 1 ) , Duration : randomFloatDuration ( 2 , 6 ) }", "del_tokens": "// var worker Worker j := SampleJob { Name : fmt . Sprintf ( \" \" , i + 1 ) , Duration : randomFloatDuration ( 3 , 3 ) }", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "problem", "when", "removing", "KeyValue", "collections"], "add_tokens": "// Find all keys that starts with rkv.id+\":\" results , err := redis . Values ( conn . Do ( \" \" , rkv . id + \" \" ) ) if err != nil { return err } // For each key id for i := 0 ; i < len ( results ) ; i ++ { // Delete this key if _ , err = conn . Do ( \" \" , getString ( results , i ) ) ; err != nil { return err } } return nil", "del_tokens": "_ , err := conn . Do ( \" \" , rkv . id ) return err", "commit_type": "fix"}
{"commit_tokens": ["Add", "key", "and", "bucket", "name", "handling", "for", "s3", "properly"], "add_tokens": "bucket := a . bucketFromHost ( req , host ) func ( a * Auth ) bucketFromHost ( req * http . Request , host string ) string {", "del_tokens": "bucket := a . bucketFromEndpoint ( req , host ) func ( a * Auth ) bucketFromEndpoint ( req * http . Request , host string ) string {", "commit_type": "add"}
{"commit_tokens": ["Added", "status", "to", "logtime", "middleware"], "add_tokens": "type statusLoggingResponseWriter struct { status int http . ResponseWriter } func ( w * statusLoggingResponseWriter ) WriteHeader ( code int ) { w . status = code w . ResponseWriter . WriteHeader ( code ) } wrapW := statusLoggingResponseWriter { - 1 , w } next . ServeHTTP ( & wrapW , r ) Info . Printf ( \" \\n \" , ips , r . Method , wrapW . status , r . URL . Path , duration )", "del_tokens": "next . ServeHTTP ( w , r ) Info . Printf ( \" \\n \" , ips , r . Method , r . URL . Path , duration )", "commit_type": "add"}
{"commit_tokens": ["change", "VenuePage", "to", "a", "more", "generic", "ID", "struct"], "add_tokens": "VenuePage ID `json:\"venuePage\"`", "del_tokens": "VenuePage VenuePage `json:\"venuePage\"` type VenuePage struct { ID string `json:\"id\"` }", "commit_type": "change"}
{"commit_tokens": ["Add", "possibility", "to", "not", "check", "some", "claims", "."], "add_tokens": "if config . Issuer != \" \" { expectedClaims . SetIssuer ( config . Issuer ) } if config . Audience != \" \" { expectedClaims . SetAudience ( config . Audience ) }", "del_tokens": "expectedClaims . SetIssuer ( config . Issuer ) expectedClaims . SetAudience ( config . Audience )", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tolerance", "for", "tests"], "add_tokens": "if ! tolerance ( s , m , m / 500 ) {", "del_tokens": "if ! tolerance ( s , m , m / 1000 ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "publically", "imported", "descriptors", "enums", "and", "extensions"], "add_tokens": "//go:generate protoc --descriptor_set_out=fileset.pb --include_imports --include_source_info -I. ./booking.proto ./todo.proto", "del_tokens": "//go:generate protoc --descriptor_set_out=fileset.pb --include_imports --include_source_info ./booking.proto ./todo.proto", "commit_type": "add"}
{"commit_tokens": ["use", "interface", "instead", "of", "*", "http", ".", "Client", "in", "Session", "."], "add_tokens": "// An interface to send http request. // This interface is designed to be compatible with type `*http.Client`. type HttpClient interface { Post ( url string , bodyType string , body io . Reader ) ( resp * http . Response , err error ) } HttpClient HttpClient", "del_tokens": "HttpClient * http . Client", "commit_type": "use"}
{"commit_tokens": ["makes", "yaml", "for", "httpkit", "runtime", "opt", "-", "in"], "add_tokens": "package yamlpc \" \" func YAMLConsumer ( ) httpkit . Consumer { return httpkit . ConsumerFunc ( func ( r io . Reader , v interface { } ) error { func YAMLProducer ( ) httpkit . Producer { return httpkit . ProducerFunc ( func ( w io . Writer , v interface { } ) error {", "del_tokens": "package httpkit func YAMLConsumer ( ) Consumer { return ConsumerFunc ( func ( r io . Reader , v interface { } ) error { func YAMLProducer ( ) Producer { return ProducerFunc ( func ( w io . Writer , v interface { } ) error {", "commit_type": "make"}
{"commit_tokens": ["Added", "some", "optimizations", "to", "the", "graph", "code", "."], "add_tokens": "var dependentNodes Nodes // if there are no items in the graph then no node added // has a dependent in the graph if g . numItems > 0 { dependentNodes = dp . GetDependents ( nodes ) } // Len returns the number of items in the graph. func ( g * Graph ) Len ( ) uint64 { return g . numItems }", "del_tokens": "dependentNodes := dp . GetDependents ( nodes )", "commit_type": "add"}
{"commit_tokens": ["Fix", "spelling", "compatability", "-", ">", "compatibility"], "add_tokens": "backwards compatibility the - procnames / - namemapping options exist as an", "del_tokens": "backwards compatability the - procnames / - namemapping options exist as an", "commit_type": "fix"}
{"commit_tokens": ["Add", "getting", "sin", "from", "pem"], "add_tokens": "func GenerateSinFromPem ( pm string ) string { key := ExtractKeyFromPem ( pm ) sin := generateSinFromKey ( key ) return sin } func generateSinFromKey ( key * btcec . PrivateKey ) string { hexb := hex . EncodeToString ( comp ) stx := generateSinFromPublicKey ( hexb ) func generateSinFromPublicKey ( key string ) string {", "del_tokens": "\" \" func GenerateSinFromKey ( key * btcec . PrivateKey ) string { stx := fmt . Sprintf ( \" \" , comp ) func GenerateSinFromPublicKey ( key string ) string {", "commit_type": "add"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "nlopes", "/", "slack", "/", "issues", "/", "50"], "add_tokens": "\" \" : { api . config . token } , \" \" : { group } ,", "del_tokens": "\" \" : { api . config . token } , \" \" : { group } ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "with", "query", "params", "showing", "up", "as", "path", "params", ".", "Add", "Body", "params", "."], "add_tokens": "const ( path = \" \" query = \" \" body = \" \" ) switch p . In { case path : operation . PathParams = append ( operation . PathParams , definitions . parameterToField ( p ) ) case query : operation . QueryParams = append ( operation . QueryParams , definitions . parameterToField ( p ) ) case body : operation . BodyParams = append ( operation . BodyParams , definitions . parameterToField ( p ) ) default : panic ( \" \" ) } switch p . In { case path : operation . PathParams = append ( operation . PathParams , definitions . parameterToField ( p ) ) case query : operation . QueryParams = append ( operation . QueryParams , definitions . parameterToField ( p ) ) case body : operation . BodyParams = append ( operation . BodyParams , definitions . parameterToField ( p ) ) default : panic ( \" \" ) }", "del_tokens": "operation . PathParams = append ( operation . PathParams , definitions . parameterToField ( p ) ) operation . QueryParams = append ( operation . QueryParams , definitions . parameterToField ( p ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unreachable", "code", "and", "complete", "format", "strings"], "add_tokens": "return Answer { } , fmt . Errorf ( \" \" , err ) return nil , fmt . Errorf ( \" \" , err )", "del_tokens": "return Answer { } , fmt . Errorf ( \" \" ) return nil , fmt . Errorf ( \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Use", "AuthError", "type", "for", "static", "errors"], "add_tokens": "ErrNoAuth = AuthError ( \" \" ) ErrReplay = AuthError ( \" \" ) ErrInvalidMAC = AuthError ( \" \" ) ErrBewitExpired = AuthError ( \" \" ) ErrTimestampSkew = AuthError ( \" \" ) ErrMissingServerAuth = AuthError ( \" \" ) ErrInvalidBewitMethod = AuthError ( \" \" ) type AuthError string func ( e AuthError ) Error ( ) string { return \" \" + string ( e ) }", "del_tokens": "\" \" ErrNoAuth = errors . New ( \" \" ) ErrReplay = errors . New ( \" \" ) ErrInvalidMAC = errors . New ( \" \" ) ErrBewitExpired = errors . New ( \" \" ) ErrTimestampSkew = errors . New ( \" \" ) ErrMissingServerAuth = errors . New ( \" \" ) ErrInvalidBewitMethod = errors . New ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Adds", "template_cloudinit_config", "resource", "to", "template"], "add_tokens": "\" \" : resourceFile ( ) , \" \" : resourceCloudinitConfig ( ) ,", "del_tokens": "\" \" : resource ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "German", "stemmer", "written", "by", "Holger", "Knauer", "."], "add_tokens": "// Package porter2 implements English (Porter2) stemmer, as described in // Stem returns a stemmed string word.", "del_tokens": "// Package porter2 implements English (Porter2) stemmer, as described by // Stem returns a stemmed string word", "commit_type": "add"}
{"commit_tokens": ["Add", "lower", "-", "case", "*", ".", "r", "glob", "for", "R", "."], "add_tokens": "Filenames : [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } ,", "del_tokens": "Filenames : [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "e", "notation", "handling", "for", "floats", ".", "Corrected", "behavior", "of"], "add_tokens": "if l == 0 && s [ n ] == '.' { if n + 1 < len ( s ) && unicode . IsDigit ( rune ( s [ n + 1 ] ) ) { return \" \" , nil } break } else if s [ n ] == 'e' && l > 0 && n + 1 < len ( s ) && s [ n + 1 ] == '+' { l ++ } else if s [ n ] == '+' && l > 0 && s [ n - 1 ] == 'e' { if n + 1 < len ( s ) && unicode . IsDigit ( rune ( s [ n + 1 ] ) ) { l ++ continue } l -- break", "del_tokens": "if l == 0 && s [ n ] == '.' && unicode . IsDigit ( rune ( s [ n + 1 ] ) ) { return \" \" , nil", "commit_type": "add"}
{"commit_tokens": ["added", "application", "as", "a", "built", "-", "in", "model"], "add_tokens": "authenticator . SetModels ( & User { } , & Application { } , & AccessToken { } )", "del_tokens": "type Application struct { Base `bson:\",inline\" fire:\"application:applications\"` Name string `json:\"name\" valid:\"required\"` Key string `json:\"key\" valid:\"required\" fire:\"identifiable\"` Secret [ ] byte `json:\"secret\" valid:\"required\" fire:\"verifiable\"` Scopes [ ] string `json:\"scopes\" valid:\"required\" fire:\"grantable\"` Callbacks [ ] string `json:\"callbacks\" valid:\"required\" fire:\"callable\"` } authenticator . SetModels ( & Application { } , & User { } , & AccessToken { } )", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "xml", "tag", "unmarshalling", "for", "client", "messages"], "add_tokens": "//c.p = xml.NewDecoder(tee{c.tls, os.Stdout}) From string `xml:\"from,attr\"` Id string `xml:\"id,attr\"` To string `xml:\"to,attr\"` Type string `xml:\"type,attr\"` // chat, error, groupchat, headline, or normal Subject string `xml:\"subject\"` Body string `xml:\"body\"` Thread string `xml:\"thread\"`", "del_tokens": "//c.p = xml.NewDecoder(tee{c.tls, os.Stdout}); From string `xml:\",attr\"` Id string `xml:\",attr\"` To string `xml:\",attr\"` Type string `xml:\",attr\"` // chat, error, groupchat, headline, or normal Subject string Body string Thread string", "commit_type": "fix"}
{"commit_tokens": ["Add", "--", "race", "flag", "to", "test", "command"], "add_tokens": "race : cmd . Race ( ctx ) , stdout : ctx . App . Stdout , verbose : cmd . Verbose ( ctx ) , race bool if params . race { cmder = amalgomated . CmderWithPrependedArgs ( cmder , \" \" ) } failedPkgs , currPkgCoverageFilePath , err := coverSinglePkg ( cmder , params . stdout , w , wd , params . verbose , params . race , currPkg , tmpDir , longestPkgNameLen ) func coverSinglePkg ( cmder amalgomated . Cmder , stdout io . Writer , rawWriter io . Writer , cmdWd string , verbose , race bool , currPkg , tmpDir string , longestPkgNameLen int ) ( rFailedPkgs [ ] string , rTmpFile string , rErr error ) { if race { prependedArgs = append ( prependedArgs , \" \" ) }", "del_tokens": "stdout : ctx . App . Stdout , verbose : cmd . Verbose ( ctx ) , failedPkgs , currPkgCoverageFilePath , err := coverSinglePkg ( cmder , params . stdout , w , wd , params . verbose , currPkg , tmpDir , longestPkgNameLen ) func coverSinglePkg ( cmder amalgomated . Cmder , stdout io . Writer , rawWriter io . Writer , cmdWd string , verbose bool , currPkg , tmpDir string , longestPkgNameLen int ) ( rFailedPkgs [ ] string , rTmpFile string , rErr error ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "list", "for", "InFile", "and", "InStream", "results"], "add_tokens": "if root == \" \" { root = \" \" }", "del_tokens": "if root == \" \" { root = \" \" }", "commit_type": "use"}
{"commit_tokens": ["Improved", "to", "return", "the", "io", ".", "Writer"], "add_tokens": "func NewAnsiColorWriter ( w io . Writer ) io . Writer {", "del_tokens": "func NewAnsiColorWriter ( w io . Writer ) * ansiColorWriter {", "commit_type": "improve"}
{"commit_tokens": ["Fix", "bug", "in", "set", "value"], "add_tokens": "return false return false", "del_tokens": "return return", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "terminal", "line", "-", "break", "that", "is", "missing", "in", "some", "CLI", "error", "messages"], "add_tokens": "\" \\n \" ) \" \\n \" ) PrintRedf ( cli . errStream , \" \\n \" , err ) PrintRedf ( cli . errStream , \" \\n \" , err ) PrintRedf ( cli . errStream , \" \\n \" , err ) fmt . Fprintf ( cli . errStream , \" \\n \" , * release . UploadURL , err ) PrintRedf ( cli . errStream , \" \\n \" , err )", "del_tokens": "\" \" ) \" \" ) PrintRedf ( cli . errStream , \" \" , err ) PrintRedf ( cli . errStream , \" \" , err ) PrintRedf ( cli . errStream , \" \" , err ) fmt . Fprintf ( cli . errStream , \" \" , * release . UploadURL , err ) PrintRedf ( cli . errStream , \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["add", "note", "to", "test", "failure"], "add_tokens": "t . Fatalf ( \" \" , expect )", "del_tokens": "t . Fatalf ( \" \" , expect )", "commit_type": "add"}
{"commit_tokens": ["Use", "SplitN", "instead", "of", "split"], "add_tokens": "splitString := strings . SplitN ( line , \" \" , 2 )", "del_tokens": "splitString := strings . Split ( line , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Add", "example", "test", "and", "update", "documentation"], "add_tokens": "func ExampleFile_HeaderAndPackageComments ( ) { f . HeaderComment ( \" \" ) f . PackageComment ( \" \" ) // // Code generated by... // // // Package c implements...", "del_tokens": "func ExampleFile_PackageComment ( ) { f . PackageComment ( \" \" ) f . PackageComment ( \" \" ) // // a // // b", "commit_type": "add"}
{"commit_tokens": ["Added", "enable", "/", "disable", "API", "to", "global", "object"], "add_tokens": "return fmt . Sprintf ( \" \" , msg ) // Disable disables the colors and styles. // Enable enables the colors and styles. func Disable ( ) { global . disabled = true } func Enable ( ) { global . disabled = false }", "del_tokens": "return fmt . Sprintf ( \" \" , msg ) // Disable disables the package. // Enable enables the package.", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "custom", "hosts", "location", "via", "environment", "variables"], "add_tokens": "osHostsFilePath := \" \" if os . Getenv ( \" \" ) == \" \" { osHostsFilePath = os . ExpandEnv ( filepath . FromSlash ( hostsFilePath ) ) } else { osHostsFilePath = os . Getenv ( \" \" ) }", "del_tokens": "osHostsFilePath := os . ExpandEnv ( filepath . FromSlash ( hostsFilePath ) )", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "doc", "references", "a", "bit", "."], "add_tokens": "// Package chacha20poly1305 implements the AEAD_CHACHA20_POLY1305 algorithm // specified in draft-agl-tls-chacha20poly1305-03: // first counter word after each block and overflowing into the second. // http://tools.ietf.org/html/draft-agl-tls-chacha20poly1305-03", "del_tokens": "// Package chacha20poly1305 implements the ChaCha20Poly1305 AEAD construction as // specified in draft-agl-tls-chacha20poly1305-02: // first counter word for each block and overflowing into the second. // http://tools.ietf.org/html/draft-agl-tls-chacha20poly1305-02", "commit_type": "update"}
{"commit_tokens": ["Add", "kernel", "-", "param", "check"], "add_tokens": "//go:generate genny -in=$GOFILE -out=resource_list.go gen \"ResourceType=Addr,Command,DNS,File,Gossfile,Group,Package,Port,Process,Service,User,KernelParam\"", "del_tokens": "//go:generate genny -in=$GOFILE -out=resource_list.go gen \"ResourceType=Addr,Command,DNS,File,Gossfile,Group,Package,Port,Process,Service,User\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "document", "style", "to", "match", "go", "design", "doc", ".", "Changed", "color", "display"], "add_tokens": "// getCerts takes in a filename and format type and returns an // array of all the certificates found in that file. If no format // is specified for the file, getCerts guesses what format was used // based on the file extension used in the file name. If it can't // guess based on this it returns and error.", "del_tokens": "/ * * Variables used to setup command line interface . * / / * * Arguments : file name and format * Returns : Array of certificates contained in file * * Retrieves all certificates file given a format . * If no foramt is specified , getCerts ( ) guesses the format * based on the file extension . * If this doesn 't work , it returns an error . * /", "commit_type": "update"}
{"commit_tokens": ["Fix", "typo", "in", "godoc", "for", "Float64"], "add_tokens": "// Looks up the value of a local float64 flag, returns 0 if no float64 flag exists", "del_tokens": "// Looks up the value of a local float64 flag, returns 0 if no int flag exists", "commit_type": "fix"}
{"commit_tokens": ["Added", "correct", "cache", "lock", "usage", "to", "the", "Next", "method", "."], "add_tokens": "// Update the struct to have correct key info if ! t . g . inTransaction { t . g . cacheLock . Lock ( ) t . g . cache [ memkey ( k ) ] = dst t . g . cacheLock . Unlock ( ) }", "del_tokens": "if ! t . g . inTransaction && dst != nil { t . g . cache [ memkey ( k ) ] = dst } // Before returning, update the struct to have correct key info", "commit_type": "add"}
{"commit_tokens": ["Implement", "gocb", "interface", "for", "various", "internal", "methods", "."], "add_tokens": "internal * bucketInternal bucket := & Bucket { } bucket . internal = & bucketInternal { b : bucket , } return bucket , nil // Internal methods, not safe to be consumed by third parties. func ( b * Bucket ) Internal ( ) * bucketInternal { return b . internal }", "del_tokens": "return & Bucket { } , nil", "commit_type": "implement"}
{"commit_tokens": ["Add", "translationProvider", "for", "Google", "s", "API"], "add_tokens": "func apiKey ( t * testing . T ) string { t . Skip ( \" \" ) return apiKey } func TestTranslateAcceptance ( t * testing . T ) { authenticator := newAuthenticator ( apiKey ( t ) ) provider := newTranslationProvider ( authenticator , newRouter ( ) ) translation , err := provider . Translate ( \" \" , \" \" , \" \" ) if err != nil { t . Errorf ( \" \" , err . Error ( ) ) } expectedTranslation := \" \" if translation != expectedTranslation { t . Errorf ( \" \" , translation , expectedTranslation , ) } } func TestLanguagesAcceptance ( t * testing . T ) { authenticator := newAuthenticator ( apiKey ( t ) )", "del_tokens": "func TestLanguagesAcceptance ( t * testing . T ) { t . Skip ( \" \" ) authenticator := newAuthenticator ( apiKey )", "commit_type": "add"}
{"commit_tokens": ["add", "new", "line", "character", "before", "the", "first", "boundary"], "add_tokens": "buf . WriteString ( \" \\r \\n \" + boundary + \" \\r \\n \" )", "del_tokens": "buf . WriteString ( \" \" + boundary + \" \\r \\n \" )", "commit_type": "add"}
{"commit_tokens": ["added", "sendBeginXact", "function", "and", "others"], "add_tokens": "func ( tx * MssqlTx ) Commit ( ) error { panic ( \" \" ) return nil } func ( tx * MssqlTx ) Rollback ( ) error { panic ( \" \" ) return nil } headers := [ ] headerStruct { { hdrtype : dataStmHdrTransDescr , data : transDescrHdr { 0 , 1 } . pack ( ) } , } if err := sendBeginXact ( c . sess . buf , 0 , \" \" , headers ) ; err != nil { return nil , err } tokchan := make ( chan tokenStruct , 5 ) go processResponse ( c . sess , tokchan ) for tok := range tokchan { switch token := tok . ( type ) { case doneStruct : if token . Status & doneError != 0 { return nil , c . sess . messages [ 0 ] } break case error : return nil , token } } return & MssqlTx { c } , nil", "del_tokens": "//func (tx *MssqlTx) Commit() error { // return nil //} // //func (tx *MssqlTx) Rollback() error { // return nil //} // // _, err := oleutil.CallMethod(c.db, \"BeginTrans\") // if err != nil { // return nil, err // } // return &AdodbTx{c}, nil return nil , nil", "commit_type": "add"}
{"commit_tokens": ["Made", "*", "default", "matched", "origin"], "add_tokens": "corsOriginMatchAll string = \" \" allowedOrigins : [ ] string { corsOriginMatchAll } , if v == corsOriginMatchAll { ch . allowedOrigins = [ ] string { corsOriginMatchAll } if allowedOrigin == origin || allowedOrigin == corsOriginMatchAll {", "del_tokens": "corsMatchAll string = \" \" if v == corsMatchAll { ch . allowedOrigins = [ ] string { corsMatchAll } if allowedOrigin == origin || allowedOrigin == corsMatchAll {", "commit_type": "make"}
{"commit_tokens": ["fix", "int", "-", "to", "-", "string", "conversions"], "add_tokens": "var v = deepCopyValue ( cfg )", "del_tokens": "var v = reflect . New ( cfg . Type ( ) ) . Elem ( ) // discard values from the arguments", "commit_type": "fix"}
{"commit_tokens": ["Fix", "load", "templates", "in", "Windows"], "add_tokens": "if p := filepath . Join ( gopath , \" \" , pth ) ; isExistingDir ( p ) { if p := filepath . Join ( gopath , \" \" , pth ) ; isExistingDir ( p ) {", "del_tokens": "\" \" if p := path . Join ( gopath , \" \" , pth ) ; isExistingDir ( p ) { if p := path . Join ( gopath , \" \" , pth ) ; isExistingDir ( p ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "helper", "Bytes", "type", "that", "takes", "human", "readable", "sizes"], "add_tokens": "if am , ok := v . Addr ( ) . Interface ( ) . ( ArgsMarshaler ) ; ok {", "del_tokens": "if am , ok := v . Interface ( ) . ( ArgsMarshaler ) ; ok {", "commit_type": "add"}
{"commit_tokens": ["Use", "rogpeppe", "s", "sortimports", "to", "fix", "this", "goimports", "ordering", "madness"], "add_tokens": "\" \" \" \"", "del_tokens": "\" \" \" \"", "commit_type": "use"}
{"commit_tokens": ["make", "scope", ".", "Get", "restrict", "(", "return", "error", "when", "key", "is", "undefined"], "add_tokens": "\" \" func ( ds * DataScope ) Get ( key string ) ( value interface { } , err error ) { var ok bool if value , ok = ds . Data [ key ] ; ! ok { return nil , fmt . Errorf ( \" \" , key ) } return value , nil", "del_tokens": "func ( ds * DataScope ) Get ( key string ) ( interface { } , error ) { return ds . Data [ key ] , nil", "commit_type": "make"}
{"commit_tokens": ["Updated", "for", "weekly", ".", "2012", "-", "02", "-", "07", "+", "52ba9506bd99"], "add_tokens": "\" \" t := time . Unix ( int64 ( p . Time . Sec ) , 0 ) return fmt . Sprintf ( \" \" , t . Hour ( ) , t . Minute ( ) , t . Second ( ) , p . Time . Usec )", "del_tokens": "\" \" t := time . SecondsToLocalTime ( int64 ( p . Time . Sec ) ) return fmt . Sprintf ( \" \" , t . Hour , t . Minute , t . Second , p . Time . Usec )", "commit_type": "update"}
{"commit_tokens": ["Make", "sure", "the", "@", "symbol", "directly", "precedes", "the", "bot", "name"], "add_tokens": "regexString := strings . Replace ( * a . Pattern , \" \" , bot . BotName , - 1 ) r , _ := regexp . Compile ( \" \" + regexString )", "del_tokens": "r , _ := regexp . Compile ( \" \" + * a . Pattern )", "commit_type": "make"}
{"commit_tokens": ["Move", "Windows", "path", "logic", "into", "fs_windows", "fix", "tests"], "add_tokens": "\" \" defer os . RemoveAll ( path ) if _ , err := Stat ( path ) ; err != nil { t . Fatalf ( \" \" , err ) } // Make sure the handling of long paths is case-insensitive if _ , err := Stat ( strings . ToLower ( path ) ) ; err != nil { t . Fatalf ( \" \" , err ) } if err := os . RemoveAll ( path ) ; err != nil { t . Fatalf ( \" \" , err ) }", "del_tokens": "defer func ( ) { if err := os . RemoveAll ( path ) ; err != nil { t . Fatalf ( \" \" , err ) } } ( )", "commit_type": "move"}
{"commit_tokens": ["Fix", "non", "uTP", "read", "buffer"], "add_tokens": "\" \" pc : pc , ctx : ctx , backlog : make ( chan * Conn , 5 ) , conns : make ( map [ * C . utp_socket ] * Conn ) , nonUtpReads : make ( chan packet , 10 ) , log . Printf ( \" \" )", "del_tokens": "pc : pc , ctx : ctx , backlog : make ( chan * Conn , 5 ) , conns : make ( map [ * C . utp_socket ] * Conn ) ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "gateway", "attributes", "optional", "in", "edit"], "add_tokens": "Owner string `json:\"owner,omitempty\"` PublicRights [ ] types . Right `json:\"public_rights,omitempty\"` FrequencyPlan string `json:\"frequency_plan,omitempty\"` AutoUpdate * bool `json:\"auto_update,omitempty\"` Location * Location `json:\"location,omitempty\"` Altitude float64 `json:\"altitude,omitempty\"` Attributes * GatewayAttributes `json:\"attributes,omitempty\"` Router string `json:\"router,omitempty\"`", "del_tokens": "Owner string `json:\"owner,omitempty\"` PublicRights [ ] types . Right `json:\"public_rights,omitempty\"` FrequencyPlan string `json:\"frequency_plan,omitempty\"` AutoUpdate * bool `json:\"auto_update,omitempty\"` Location * Location `json:\"location,omitempty\"` Altitude float64 `json:\"altitude,omitempty\"` Attributes GatewayAttributes `json:\"attributes,omitempty\"` Router string `json:\"router,omitempty\"`", "commit_type": "make"}
{"commit_tokens": ["Changing", "character", "set", "no", "longer", "can", "cause", "panic"], "add_tokens": "for i := 0 ; i < len ( s . Chars ) ; i ++ { select { case <- StopChan : return default : fmt . Printf ( \" \\r \" , s . Prefix , s . Chars [ i ] , s . Suffix ) time . Sleep ( s . Delay ) for i := len ( s . Chars ) - 1 ; i >= 0 ; i -- {", "del_tokens": "Offset int Offset : len ( c ) - 1 , count := 0 select { case <- StopChan : return default : fmt . Printf ( \" \\r \" , s . Prefix , s . Chars [ count ] , s . Suffix ) time . Sleep ( s . Delay ) if count != s . Offset { count ++ } else { count = 0 for i := s . Offset ; i >= 0 ; i -- {", "commit_type": "change"}
{"commit_tokens": ["update", "README", "and", "godoc", "documentation", ".", "Basic", "but", "should", "cover", "the", "major", "points", "."], "add_tokens": "This is \" \" , a golang implementation of the nodejs raintank - worker program . It reads metric and event data from rabbitmq and writes that information to elasticsearch and influxdb . Installation Installing raintank - metric is easy . Just run $ go get - u github . com / raintank / raintank - metric from the command line , assuming you have your golang environment properly set up , and it will pull down and install all the dependencies and compile the program . Usage The raintank - metric worker can be configured from the command line , or it can use a configuration file . The available options are : - v , - - version Show version information . A sample configuration file can be found in the `etc` directory of this repository .", "del_tokens": "This is \" \" , a golang implementation of the nodejs raintank - worker program . The documentation is a work in progress , but in the meantime here are the command - line flags while the documention gets written : Usage : raintank - metric [ OPTIONS ] Application Options : Help Options : - h , - - help Show this help message", "commit_type": "update"}
{"commit_tokens": ["Allow", "token", "as", "query", "param"], "add_tokens": "\" \" var token string queryParam := r . FormValue ( \" \" ) if queryParam == \" \" { return & jwtError { status : http . StatusUnauthorized , err : ErrMissingToken } } var err error token , err = url . QueryUnescape ( queryParam ) if err != nil { return & jwtError { status : http . StatusUnauthorized , err : ErrMalformedToken } } } else { token = strings . Split ( authHeader , \" \" ) [ 1 ]", "del_tokens": "return & jwtError { status : http . StatusUnauthorized , err : ErrMissingToken } token := strings . Split ( authHeader , \" \" ) [ 1 ]", "commit_type": "allow"}
{"commit_tokens": ["add", "Logger", "interface", "remove", "logrus", "dependency"], "add_tokens": "Logger Logger func New ( prefix string , logger Logger ) * API {", "del_tokens": "\" \" Logger logrus . StdLogger func New ( prefix string , logger logrus . StdLogger ) * API {", "commit_type": "add"}
{"commit_tokens": ["Uses", "aliases", "/", "default", "rather", "then", "collection", "/", "Default", "to", "find", "the", "default", "keyring", "."], "add_tokens": "ssCollectionPath = \" \"", "del_tokens": "ssCollectionPath = \" \"", "commit_type": "use"}
{"commit_tokens": ["Updated", "the", "test", "and", "example", "code"], "add_tokens": "err = list . Remove ( ) t . Errorf ( \" \" , err )", "del_tokens": "err = list . DelAll ( ) t . Errorf ( \" \" , err )", "commit_type": "update"}
{"commit_tokens": ["Add", "of", "like", "the", "rest", "of", "the", "function", "docstrings"], "add_tokens": "// It accepts a sequence of schemes to be matched, e.g.: \"http\", \"https\".", "del_tokens": "// It accepts a sequence schemes to be matched, e.g.: \"http\", \"https\".", "commit_type": "add"}
{"commit_tokens": ["Add", "nice", "formatter", "(", "simple", "textual", "output", "for", "testing", ")", "."], "add_tokens": "func ( self * AutoCompleteContext ) processPackage ( filename , uniquename , pkgname string ) {", "del_tokens": "func ( self * AutoCompleteContext ) processPackage ( filename string , uniquename string , pkgname string ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "spurious", "errors", "when", "deleting", "a", "cluster"], "add_tokens": "if len ( resources ) == 0 { fmt . Printf ( \" \\n \" ) return nil }", "del_tokens": "glog . Infof ( \" \" ) if len ( resources ) == 0 { fmt . Printf ( \" \\n \" ) return nil }", "commit_type": "remove"}
{"commit_tokens": ["add", "some", "CLI", "stuff", "to", "run", "a", "broker"], "add_tokens": "// SetupLogging configures logging based on mcollective config directives // currently only file and console behaviours are supported func ( c * Choria ) SetupLogging ( debug bool ) ( err error ) { log . SetOutput ( os . Stdout ) if c . Config . LogFile != \" \" { log . SetFormatter ( & log . JSONFormatter { } ) file , err := os . OpenFile ( c . Config . LogFile , os . O_CREATE | os . O_WRONLY , 0666 ) if err != nil { return fmt . Errorf ( \" \" , err . Error ( ) ) } log . SetOutput ( file ) } switch c . Config . LogLevel { case \" \" : log . SetLevel ( log . DebugLevel ) case \" \" : log . SetLevel ( log . InfoLevel ) case \" \" : log . SetLevel ( log . WarnLevel ) case \" \" : log . SetLevel ( log . ErrorLevel ) case \" \" : log . SetLevel ( log . FatalLevel ) default : log . SetLevel ( log . WarnLevel ) } if debug { log . SetLevel ( log . DebugLevel ) } return }", "del_tokens": "fmt . Printf ( \" \\n \" , parsed ) fmt . Printf ( \" \\n \" , s . Host , s . Port )", "commit_type": "add"}
{"commit_tokens": ["Move", "getOldestEntry", "to", "test", "file"], "add_tokens": "getOldestEntry := func ( s * cacheShard ) ( [ ] byte , error ) { s . lock . RLock ( ) defer s . lock . RUnlock ( ) return s . entries . Peek ( ) } if oldestEntry , err := getOldestEntry ( cache . shards [ i ] ) ; err == nil {", "del_tokens": "if oldestEntry , err := cache . shards [ i ] . getOldestEntry ( ) ; err == nil {", "commit_type": "move"}
{"commit_tokens": ["Make", "some", "errors", "with", "stackes"], "add_tokens": "\" \" return nil , errorsp . WithStacks ( err )", "del_tokens": "return nil , err", "commit_type": "make"}
{"commit_tokens": ["added", "webocket", "client", "also", "change", "localClient", "to", "match", "Client", "interface"], "add_tokens": "func NewLocalClient ( mist * Mist , buffer int ) Client { func ( client * localSubscriber ) Subscribe ( tags [ ] string ) error { return nil func ( client * localSubscriber ) Unsubscribe ( tags [ ] string ) error { return nil", "del_tokens": "func NewLocalClient ( mist * Mist , buffer int ) * localSubscriber { func ( client * localSubscriber ) Subscribe ( tags [ ] string ) { func ( client * localSubscriber ) Unsubscribe ( tags [ ] string ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "bad", "JwtConf", "json", "tag", "names"], "add_tokens": "PrivateKeyBase64 string `json:\"private_keybase64,omitempty\"` Keytype string `json:\"keytype,omitempty\"`", "del_tokens": "PrivateKeyBase64 string `json:\"private_key,omitempty\"` Keytype string `json:\"type,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "read", "pages"], "add_tokens": "//Counter string Revisions [ ] revision } type revision struct { Body string `json:\"*\"` User string Timestamp string comment string func ( m * MWApi ) Read ( pageName string ) ( * revision , error ) { query := Values { \" \" : \" \" , \" \" : \" \" , \" \" : pageName , \" \" : \" \" , \" \" : \" \" , } body , _ , err := m . API ( query ) var response Query err = json . Unmarshal ( body , & response ) if err != nil { return nil , err } for _ , page := range response . Query . Pages { return & page . Revisions [ 0 ] , nil } return nil , errors . New ( \" \" )", "del_tokens": "Counter string func ( m * MWApi ) Read ( pageName string ) { return", "commit_type": "add"}
{"commit_tokens": ["Add", "storing", "of", "wildcard", "param", "in", "context", "params", "+", "tests"], "add_tokens": "if lowercase { for i := 0 ; i < l ; i ++ { locale := strings . SplitN ( options [ i ] , \" \" , 2 ) } else { for i := 0 ; i < l ; i ++ { locale := strings . SplitN ( options [ i ] , \" \" , 2 ) language [ i ] = strings . Trim ( locale [ 0 ] , \" \" ) }", "del_tokens": "for i := 0 ; i < l ; i ++ { locale := strings . SplitN ( options [ i ] , \" \" , 2 ) if lowercase { continue language [ i ] = strings . Trim ( locale [ 0 ] , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "selecting", "databases"], "add_tokens": "list . SelectDatabase ( 1 )", "del_tokens": "pool . SelectDatabase ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "JS", "version", "referenced", "by", "API", "docs"], "add_tokens": "fmt . Fprintf ( html , \" \\\" \\\" \\n \" )", "del_tokens": "fmt . Fprintf ( html , \" \\\" \\\" \\n \" )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "all", "t", ".", "Errorf", "&", "return", "statements", "into", "t", ".", "Fatalf"], "add_tokens": "t . Fatalf ( \" \" ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" ) t . Fatalf ( \" \" ) t . Fatalf ( \" \" ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" )", "del_tokens": "t . Errorf ( \" \" ) return t . Errorf ( \" \" , err ) return t . Errorf ( \" \" ) return t . Errorf ( \" \" ) return t . Errorf ( \" \" ) return t . Errorf ( \" \" , err ) return t . Errorf ( \" \" , err ) return t . Errorf ( \" \" ) return t . Errorf ( \" \" , err ) return t . Errorf ( \" \" , err ) return t . Errorf ( \" \" ) return", "commit_type": "change"}
{"commit_tokens": ["change", "PTS", "to", "timeScale", "unit", "in", "SimpleH264Writer"], "add_tokens": "PTS int64 PCR int64 // 1s self . PTS = int64 ( self . TimeScale ) // 1s self . PCR = int64 ( self . TimeScale ) PTS : uint64 ( self . PTS ) * PTS_HZ / uint64 ( self . TimeScale ) , self . tswH264 . PCR = uint64 ( self . PCR ) * PCR_HZ / uint64 ( self . TimeScale ) self . PTS += int64 ( duration ) self . PCR += int64 ( duration )", "del_tokens": "PTS uint64 PCR uint64 self . PTS = PTS_HZ self . PCR = PCR_HZ PTS : self . PTS , self . tswH264 . PCR = self . PCR self . PTS += uint64 ( duration ) * PTS_HZ / uint64 ( self . TimeScale ) self . PCR += uint64 ( duration ) * PCR_HZ / uint64 ( self . TimeScale )", "commit_type": "change"}
{"commit_tokens": ["Change", "behavior", "of", "test", "tags"], "add_tokens": "if err := cfg . Validate ( ) ; err != nil { return err } // tagsMatcher is a matcher that matches the specified tags (or nil if no tags were specified) tagsMatcher , err := cmd . TagsMatcher ( testParams . tags , cfg ) if err != nil { return err } excludeMatchers := [ ] matcher . Matcher { cfg . Exclude } if tagsMatcher != nil { // if tagsMatcher is non-nil, should exclude all files that do not match the tags excludeMatchers = append ( excludeMatchers , matcher . Not ( tagsMatcher ) ) pkgs , err := cmd . PkgPaths ( pkgsParam , wd , matcher . Any ( excludeMatchers ... ) )", "del_tokens": "// tagsMatcher is the matcher that represents the files that must be excluded to match the tag. var tagsMatcher matcher . Matcher if len ( testParams . tags ) == 0 { // if no tags were provided, exclude all files matched by any tags (run only non-tagged tests) tagsMatcher = cmd . AllTagsMatcher ( cfg ) } else { // otherwise, exclude files not matched by the specified tags tagsMatcher , err = cmd . TagsMatcher ( testParams . tags , cfg ) if err != nil { return err } tagsMatcher = matcher . Not ( tagsMatcher ) m := matcher . Any ( tagsMatcher , cfg . Exclude ) pkgs , err := cmd . PkgPaths ( pkgsParam , wd , m )", "commit_type": "change"}
{"commit_tokens": ["Added", "prefix", "to", "the", "catfacts", "fact"], "add_tokens": "msgPrefix = \" \" return fmt . Sprintf ( msgPrefix , data . Facts [ 0 ] ) , nil", "del_tokens": "return data . Facts [ 0 ] , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "IPAMData", "struct", "and", "removing", "debugging"], "add_tokens": "IPv4Data [ ] * IPAMData IPv6Data [ ] * IPAMData Pool string Gateway string AuxAddresses map [ string ] interface { }", "del_tokens": "\" \" log \" \" IPv4Data [ ] IPAMData IPv6Data [ ] IPAMData Pool * net . IPNet Gateway * net . IPNet AuxAddresses map [ string ] * net . IPNet defer r . Body . Close ( ) body , _ := ioutil . ReadAll ( r . Body ) log . Debugf ( \" \" , string ( body ) )", "commit_type": "fix"}
{"commit_tokens": ["moved", "aeshash", "to", "it", "s", "own", "project"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Update", "the", "rest", "of", "the", "deps"], "add_tokens": "// Non-specific tag (Issue #75) { \" \" , map [ string ] interface { } { \" \" : \" \" } , } , for i , item := range unmarshalTests { c . Logf ( \" \" , i , item . data ) { \" \\n \\n \" , \" \" } ,", "del_tokens": "for _ , item := range unmarshalTests {", "commit_type": "update"}
{"commit_tokens": ["Create", "error", "via", "errors", ".", "New"], "add_tokens": "\" \" return nil , errors . New ( result . Error )", "del_tokens": "\" \" return nil , fmt . Errorf ( result . Error )", "commit_type": "create"}
{"commit_tokens": ["Fix", "host", "for", "oauth", "."], "add_tokens": "url = fmt . Sprintf ( \" \" , c . Host )", "del_tokens": "url = fmt . Sprintf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "OSS", "as", "i18n", "file", "upload", "backend"], "add_tokens": "\" \" TranslationsFile oss . OSS", "del_tokens": "\" \" TranslationsFile media_library . FileSystem", "commit_type": "use"}
{"commit_tokens": ["Fix", "user", "search", "and", "status", "show", "/", "lookup", "to", "allow", "nil", "parameters"], "add_tokens": "func TestUserService_Search ( t * testing . T ) { users , _ , err := client . Users . Search ( \" \" , & UserSearchParams { Query : \" \" , Count : 11 } ) func TestUserService_SearchHandlesNilParams ( t * testing . T ) { httpClient , mux , server := testServer ( ) defer server . Close ( ) mux . HandleFunc ( \" \" , func ( w http . ResponseWriter , r * http . Request ) { assertParams ( t , map [ string ] string { \" \" : \" \" } , r ) } ) client := NewClient ( httpClient ) client . Users . Search ( \" \" , nil ) }", "del_tokens": "func TestSearch ( t * testing . T ) { users , _ , err := client . Users . Search ( \" \" , & UserSearchParams { Count : 11 } )", "commit_type": "fix"}
{"commit_tokens": ["add", "test", "for", "removing", "handlers"], "add_tokens": "case <- time . After ( timeout ) :", "del_tokens": "case <- time . After ( time . Second * timeout ) :", "commit_type": "add"}
{"commit_tokens": ["Move", "expectedBlockSize", "to", "blockReader", "section"], "add_tokens": "func expectedBlockSize ( h gzip . Header ) int { i := bytes . Index ( h . Extra , bgzfExtraPrefix ) if i < 0 || i + 5 >= len ( h . Extra ) { return - 1 } return ( int ( h . Extra [ i + 4 ] ) | int ( h . Extra [ i + 5 ] ) << 8 ) + 1 }", "del_tokens": "func expectedBlockSize ( h gzip . Header ) int { i := bytes . Index ( h . Extra , bgzfExtraPrefix ) if i < 0 || i + 5 >= len ( h . Extra ) { return - 1 } return ( int ( h . Extra [ i + 4 ] ) | int ( h . Extra [ i + 5 ] ) << 8 ) + 1 }", "commit_type": "move"}
{"commit_tokens": ["Fixing", "crossed", "wires", "in", "DedupSQSFilter"], "add_tokens": "// an old item if necessary. Returns true if item as added to cache. return false return true", "del_tokens": "// an old item if necessary. Returns if already exists in cache. return true return false", "commit_type": "fix"}
{"commit_tokens": ["use", "github", ".", "com", "/", "pboraman", "/", "uuid", "package"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "UUID", "type", "and", "handle", "Blob", "and", "Timestamp", "types"], "add_tokens": "\" \" \" \" var ( uuidType = reflect . TypeOf ( UUID ( \" \" ) ) blobType = reflect . TypeOf ( [ ] byte { } ) timestampType = reflect . TypeOf ( time . Time { } ) int32Type = reflect . TypeOf ( int32 ( 0 ) ) int64Type = reflect . TypeOf ( int64 ( 0 ) ) doubleType = reflect . TypeOf ( float64 ( 0.0 ) ) stringType = reflect . TypeOf ( \" \" ) boolType = reflect . TypeOf ( true ) ) switch f { case uuidType : return TUUID , nil case blobType : return Blob , nil case timestampType : return Timestamp , nil case int32Type : case int64Type : case doubleType : case stringType : case boolType : return Bool , nil return Invalid , fmt . Errorf ( \" \" , f )", "del_tokens": "\" \" switch f . Kind ( ) { case reflect . Bool : return Bool , nil case reflect . Int32 : case reflect . Int64 : case reflect . Float64 : case reflect . String : // TODO: need UUID default : return 0 , fmt . Errorf ( \" \" , f )", "commit_type": "add"}
{"commit_tokens": ["add", "README", ".", "md", "and", "fix", "strings", ".", "ToLower", "(", "configType", ")"], "add_tokens": "switch strings . ToLower ( configType ) {", "del_tokens": "switch configType {", "commit_type": "add"}
{"commit_tokens": ["use", "correct", "implementation", "in", "doc", ".", "go"], "add_tokens": "// alert, err := client.Monitor.Alerts.Get(context.TODO(), \"NO123\")", "del_tokens": "// alert, err := client.Monitor.Alerts.Get(\"NO123\")", "commit_type": "use"}
{"commit_tokens": ["Fix", "up", "setup", ".", "sh", "args"], "add_tokens": "out , err := exec . Command ( \" \" , gateway , ipnet . String ( ) , fmt . Sprint ( subnetMaskLength ) , containerNetwork , servicesNetwork , fmt . Sprint ( mtu ) ) . CombinedOutput ( )", "del_tokens": "out , err := exec . Command ( \" \" , gateway , ipnet . String ( ) , containerNetwork , fmt . Sprint ( subnetMaskLength ) , gateway , fmt . Sprint ( mtu ) ) . CombinedOutput ( )", "commit_type": "fix"}
{"commit_tokens": ["Change", "MarshalJSON", "into", "MarshalText", "."], "add_tokens": "// MarshalText implements encoding.TextMarshaler. func ( n NetID ) MarshalText ( ) ( [ ] byte , error ) { return [ ] byte ( n . String ( ) ) , nil // UnmarshalText implements encoding.TextUnmarshaler. func ( n * NetID ) UnmarshalText ( text [ ] byte ) error { b , err := hex . DecodeString ( string ( text ) )", "del_tokens": "\" \" // MarshalJSON implements json.Marshaler. func ( n NetID ) MarshalJSON ( ) ( [ ] byte , error ) { return [ ] byte ( `\"` + n . String ( ) + `\"` ) , nil // UnmarshalJSON implements json.Unmarshaler. func ( n * NetID ) UnmarshalJSON ( data [ ] byte ) error { hexStr := strings . Trim ( string ( data ) , `\"` ) b , err := hex . DecodeString ( hexStr )", "commit_type": "change"}
{"commit_tokens": ["Fix", "lint", "warnings", "in", "global", "client", "."], "add_tokens": "// VERSION defines the version of the honeybadger package. // client is a pre-defined \"global\" client. client = New ( Configuration { } ) // Config is a pointer to the global client's Config. Config = client . Config // Feature references a resource provided by the API service. Its Endpoint maps // to the collection endpoint of the /v1 API. // CGIData stores variables from the server/request environment indexed by key. // Header keys should be converted to upercase, all non-alphanumeric characters // replaced with underscores, and prefixed with HTTP_. For example, the header // \"Content-Type\" would become \"HTTP_CONTENT_TYPE\". // Params stores the form or url values from an HTTP request. // Configure updates configuration of the global client. // SetContext merges c Context into the Context of the global client. // Handler returns an http.Handler function which automatically reports panics // to Honeybadger and then re-panics.", "del_tokens": "// The global client. client * Client = New ( Configuration { } ) // The global configuration (available through the client). Config * Configuration = client . Config // A feature is provided by the API service. Its Endpoint maps to the // collection endpoint of the /v1 API. // CGI variables such as HTTP_METHOD. // Request parameters. // Configures the global client. // Set/merge the global context. // Returns an http.Handler function which automatically reports panics to // Honeybadger including request data.", "commit_type": "fix"}
{"commit_tokens": ["Updating", "jshapi", "to", "use", "updated", "goji2logger"], "add_tokens": "gojilogger . SetLogger ( logger ) api . UseC ( gojilogger . Middleware )", "del_tokens": "api . UseC ( gojilogger . With ( logger ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "copying", "directories", "to", "gocp"], "add_tokens": "fi , err := os . Stat ( os . Args [ 1 ] ) if err != nil { log . Fatalf ( \" \" , err ) } if fi . IsDir ( ) { if err := fileutils . CopyDirectory ( os . Args [ 1 ] , os . Args [ 2 ] ) ; err != nil { log . Fatalf ( \" \" , os . Args [ 1 ] , os . Args [ 2 ] , err ) } } else { if err := fileutils . CopyFile ( os . Args [ 1 ] , os . Args [ 2 ] ) ; err != nil { log . Fatalf ( \" \" , os . Args [ 1 ] , os . Args [ 2 ] , err ) }", "del_tokens": "if err := fileutils . CopyFile ( os . Args [ 1 ] , os . Args [ 2 ] ) ; err != nil { log . Fatalf ( \" \" , os . Args [ 1 ] , os . Args [ 2 ] , err )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "tabletserver", "unit", "test", "to", "pass", "."], "add_tokens": "\" \" panic ( fmt . Sprintf ( \" \" , n , cap ( cw . bufs [ 0 ] ) ) )", "del_tokens": "panic ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["make", "small", "readability", "improvement", "to", "formatArgs", "()"], "add_tokens": "if names [ i ] == noName { continue name := colorize ( names [ i ] , bold ) formatted [ i ] = fmt . Sprintf ( \" \" , name , val )", "del_tokens": "if names [ i ] == \" \" { } else { name := colorize ( names [ i ] , bold ) formatted [ i ] = fmt . Sprintf ( \" \" , name , val )", "commit_type": "make"}
{"commit_tokens": ["Add", "zero", ".", "Time", "and", "tests"], "add_tokens": "return fmt . Errorf ( \" \\\" \\\" \\\" \\\" \" , x [ \" \" ] , x [ \" \" ] )", "del_tokens": "return fmt . Errorf ( \" \\\" \\\" \\\" \\\" \" , x [ \" \" ] , x [ \" \" ] )", "commit_type": "add"}
{"commit_tokens": ["fix", "bad", "now", "()", "function", "returning", "false"], "add_tokens": "return value . NewTimeValue ( time . Now ( ) . In ( time . UTC ) ) , true", "del_tokens": "return value . NewTimeValue ( time . Now ( ) . In ( time . UTC ) ) , false", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "option", "to", "trim", "expensive", "operations", "for", "all", "spans", "."], "add_tokens": "return s . tracer . options . TrimSpans || ( ! s . raw . Sampled && s . tracer . options . TrimUnsampledSpans )", "del_tokens": "return ! s . raw . Sampled && s . tracer . options . TrimUnsampledSpans", "commit_type": "add"}
{"commit_tokens": ["Remove", "checks", "for", "predetermined", "archs"], "add_tokens": "variable = witharch [ 0 ]", "del_tokens": "if _ , ok := archs [ witharch [ 1 ] ] ; ok { variable = witharch [ 0 ] }", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "flag", "for", "controlling", "the", "localkube", "binary", "location", "."], "add_tokens": "var ( localkubeURL string ) config := cluster . KubernetesConfig { LocalkubeURL : localkubeURL , } if err := cluster . StartCluster ( host , config ) ; err != nil { startCmd . Flags ( ) . StringVarP ( & localkubeURL , \" \" , \" \" , \" \" , \" \" ) startCmd . Flags ( ) . MarkHidden ( \" \" )", "del_tokens": "if err := cluster . StartCluster ( host ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Made", "a", "start", "on", "gradient", "descent"], "add_tokens": "import ( \" \" \" \" \" \" ) // Serialises an estimator to a provided filepath, in gob format. // See http://golang.org/pkg/encoding/gob for further details. func SaveEstimatorToGob ( path string , e * Estimator ) { b := new ( bytes . Buffer ) enc := gob . NewEncoder ( b ) err := enc . Encode ( e ) if err != nil { panic ( err ) } err = ioutil . WriteFile ( path , b . Bytes ( ) , 0644 ) if err != nil { panic ( err ) } }", "del_tokens": "// @todo: Implement BaseEstimator setters and getters. Estimator", "commit_type": "make"}
{"commit_tokens": ["add", "ringcentral", ".", "RcToken", ".", "RefreshTokenExpiry"], "add_tokens": "RefreshTokenExpiry time . Time `json:\"refresh_token_expiry,omitempty\"` now := time . Now ( ) if ( rcTok . ExpiresIn ) > 0 { expiresIn , err := time . ParseDuration ( fmt . Sprintf ( \" \" , rcTok . ExpiresIn ) ) if err != nil { return err } rcTok . Expiry = now . Add ( expiresIn ) if ( rcTok . RefreshTokenExpiresIn ) > 0 { expiresIn , err := time . ParseDuration ( fmt . Sprintf ( \" \" , rcTok . RefreshTokenExpiresIn ) ) if err != nil { return err } rcTok . RefreshTokenExpiry = now . Add ( expiresIn ) }", "del_tokens": "expiresIn , err := time . ParseDuration ( fmt . Sprintf ( \" \" , rcTok . ExpiresIn ) ) if err != nil { return err rcTok . Expiry = time . Now ( ) . Add ( expiresIn )", "commit_type": "add"}
{"commit_tokens": ["Use", "Id", "()", "instead", "of", "getId", "()"], "add_tokens": "id string func ( container * Container ) Id ( ) ( id string , err error ) { if len ( container . id ) > 0 { id = container . id container . id = output id , err := container . Id ( ) id , err := container . Id ( )", "del_tokens": "Id string func ( container * Container ) getId ( ) ( id string , err error ) { if len ( container . Id ) > 0 { id = container . Id container . Id = output id , err := container . getId ( ) id , err := container . getId ( )", "commit_type": "use"}
{"commit_tokens": ["Use", "sub", "-", "types", "instead", "of", "embedded", "type"], "add_tokens": "HREF : href , HREF : href , Meta : meta , // Create a sub-type here so when we call Marshal below, we don't recursively // call this function over and over type MarshalLink Link return json . Marshal ( MarshalLink ( * l ) ) // Create a sub-type here so when we call Unmarshal below, we don't recursively // call this function over and over type UnmarshalLink Link link := UnmarshalLink { } * l = Link ( link )", "del_tokens": "link } type link struct { link : link { HREF : href , } , link : link { HREF : href , Meta : meta , } , return json . Marshal ( l . link ) link := link { } l . link = link", "commit_type": "use"}
{"commit_tokens": ["removed", "ErrorStop", "modified", "IterKeyFun", "IterItemFun"], "add_tokens": "func Test_ForEachItem ( t * testing . T ) { m . ForEachItem ( func ( item * Item ) bool { return false m . Set ( i . Key , \" \" ) m . ForEachKey ( func ( key string ) bool { return false", "del_tokens": "func Test_ForEachItem ( t * testing . T ) { m . ForEachItem ( func ( item * Item ) error { return ErrorStop m . Set ( i . Key , \" \" ) m . ForEachKey ( func ( key string ) error { return ErrorStop", "commit_type": "remove"}
{"commit_tokens": ["Fix", "resolution", "setting", "needs", "division", "instead", "of", "multiplication"], "add_tokens": "samples := make ( audio . F64Samples , ( config . SampleRate * config . Channels ) / options . Resolution )", "del_tokens": "samples := make ( audio . F64Samples , config . SampleRate * config . Channels * options . Resolution )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "running", "complex", "commands", "in", "runner"], "add_tokens": "boshsys \" \" CommandResults map [ string ] [ ] [ ] string RunComplexCommands [ ] boshsys . Command func ( runner * FakeCmdRunner ) RunComplexCommand ( cmd boshsys . Command ) ( stdout , stderr string , err error ) { runner . RunComplexCommands = append ( runner . RunComplexCommands , cmd ) runCmd := append ( [ ] string { cmd . Name } , cmd . Args ... ) stdout , stderr , err = runner . getOutputsForCmd ( runCmd ) return }", "del_tokens": "CommandResults map [ string ] [ ] [ ] string", "commit_type": "add"}
{"commit_tokens": ["Improve", "documentation", "and", "tests", "for", "redis", ".", "Scan", "()"], "add_tokens": "// The values pointed at by dest must be an integer, float, boolean, string, // []byte, interface{} or slices of these types. Scan uses the standard strconv // package to convert bulk values to numeric and boolean types.", "del_tokens": "// The values pointed at by dest must be an integer, float, boolean, string, or // []byte. Scan uses the standard strconv package to convert bulk values to // numeric and boolean types.", "commit_type": "improve"}
{"commit_tokens": ["fix", "zadd", "pairs", "type", "member", "should", "be", "map", "key"], "add_tokens": "func ( r * Redis ) ZAdd ( key string , pairs map [ string ] float32 ) ( int64 , error ) { args := packArgs ( \" \" , key ) for member , score := range pairs { args = append ( args , score , member ) }", "del_tokens": "func ( r * Redis ) ZAdd ( key string , pairs map [ float32 ] string ) ( int64 , error ) { args := packArgs ( \" \" , key , pairs )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "setting", "IPv6", "source", "address"], "add_tokens": "source6 string source6 : \" \" , // Source sets ipv4/ipv6 source IP for sending ICMP packets and returns the previous // setting. Empty value indicates to use system default one (for both ipv4 and ipv6). // using ipv4 previous value for new empty one p . source = \" \" p . source6 = \" \" return origSource , errors . New ( source + \" \" ) if isIPv4 ( addr ) { p . mu . Lock ( ) p . source = source p . mu . Unlock ( ) } else if isIPv6 ( addr ) { origSource = p . source6 p . mu . Lock ( ) p . source6 = source p . mu . Unlock ( ) } else { return origSource , errors . New ( source + \" \" ) } if conn6 = p . listen ( ipv6Proto [ p . network ] , p . source6 ) ; conn6 == nil {", "del_tokens": "// Source sets source IP for sending ICMP packets and returns the previous // setting. Empty value indicates to use system default one. p . source = source return origSource , errors . New ( source + \" \" ) p . mu . Lock ( ) p . source = source p . mu . Unlock ( ) if conn6 = p . listen ( ipv6Proto [ p . network ] , p . source ) ; conn6 == nil {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "small", "inconsistency", "in", "example", "."], "add_tokens": "// conn, err := websocket.Upgrade(w, r, nil, 1024, 1024)", "del_tokens": "// ws, err := websocket.Upgrade(w, r, nil, 1024, 1024)", "commit_type": "fix"}
{"commit_tokens": ["Make", "TraceErr", "compatible", "with", "errors", ".", "Is", "/", "As", "/", "Unwrap"], "add_tokens": "// Unwrap returns the error this TraceErr wraps. The returned error may also // wrap another one, Unwrap doesn't recursively get the inner-most error like // OrigError does. func ( e * TraceErr ) Unwrap ( ) error { return e . Err } next := newerr . OrigError ( ) if next == nil || next == err { break err = next // // Error handlers can use Unwrap() to retrieve error from the wrapper, or // errors.Is()/As() to compare it to another value.", "del_tokens": "if newerr . OrigError ( ) != err { err = newerr . OrigError ( ) // So error handlers can use OrigError() to retrieve error from the wrapper // OrigError returns the original error. // Implements WrappingError func ( r proxyError ) OrigError ( ) error { return r . TraceErr . OrigError ( ) } // Error returns the error message of the underlying error func ( r proxyError ) Error ( ) string { return r . TraceErr . Error ( ) }", "commit_type": "make"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \"", "del_tokens": "expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "EstablishedChannel", "()", "for", "NullOverlay"], "add_tokens": "func ( NullOverlay ) EstablishedChannel ( ) <- chan struct { } { c := make ( chan struct { } ) close ( c ) return c }", "del_tokens": "func ( NullOverlay ) EstablishedChannel ( ) <- chan struct { } { return nil }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "temporary", "files", "created", "by", "the", "integration", "test", "from", "remote", "kubernetes", "nodes", "."], "add_tokens": "err = fmt . Errorf ( \" \" , imageName , remoteFile , hostname , err , out ) out , rmErr := exec . Command ( \" \" , \" \" , hostname , \" \" , \" \" , \" \" , remoteFile ) . CombinedOutput ( ) if rmErr != nil { if err != nil { rmErr = fmt . Errorf ( \" \\n \" , err , hostname , err , out ) } return rmErr } return err func cleanupRemoteHost ( hostname string ) { _ = exec . Command ( \" \" , \" \" , hostname , \" \" , \" \" , \" \" , \" \" ) . Run ( ) _ = exec . Command ( \" \" , \" \" , hostname , \" \" , \" \" , \" \" , \" \" ) . Run ( ) }", "del_tokens": "return fmt . Errorf ( \" \" , hostname , err , out ) return nil", "commit_type": "remove"}
{"commit_tokens": ["remove", "file", "from", "request", "log"], "add_tokens": "var request = log . New ( os . Stderr , \" \" , log . Ldate | log . Ltime )", "del_tokens": "var request = log . New ( os . Stderr , \" \" , log . Ldate | log . Ltime | log . Lshortfile )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "raff", "/", "godet", "/", "issues", "/", "38", ":", "close", "remote", ".", "requests", "channel", "in", "remote", ".", "Close", "()", "so", "that", "sender", "gorouting", "can", "terminate", "."], "add_tokens": "// ErrorClose is returned if a method is called after the connection has been close ErrorClose = errors . New ( \" \" ) return \" \" + string ( err ) close ( remote . requests ) if remote . ws == nil { remote . Unlock ( ) return nil , ErrorClose } responseChan := make ( chan json . RawMessage , 1 ) remote . responses [ reqID ] = responseChan reply := <- responseChan if errorText , ok := res [ \" \" ] ; ok { return \" \" , NavigationError ( errorText . ( string ) ) }", "del_tokens": "return \" \" + string ( err ) responseChann := make ( chan json . RawMessage , 1 ) remote . responses [ reqID ] = responseChann reply := <- responseChann if errorText , ok := res [ \" \" ] ; ok { return \" \" , NavigationError ( errorText . ( string ) ) }", "commit_type": "fix"}
{"commit_tokens": ["use", "init", "()", "for", "defaultSignal"], "add_tokens": "var defaultSignal os . Signal func init ( ) { switch runtime . GOOS { case \" \" : defaultSignal = os . Interrupt default : defaultSignal = syscall . SIGTERM }", "del_tokens": "var defaultSignal = func ( ) os . Signal { if runtime . GOOS == \" \" { return os . Interrupt return syscall . SIGTERM } ( )", "commit_type": "use"}
{"commit_tokens": ["remove", "unnecessary", "[]", "string", "in", "declaration"], "add_tokens": "var consonants = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "del_tokens": "var consonants [ ] string = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "commit_type": "remove"}
{"commit_tokens": ["adds", "SearchPlace", "method", "+", "test"], "add_tokens": "// SearchPlace queries MusicBrainz´ Search Server for Places. // With no fields specified searchTerm searches the place, alias, address and // area fields. For a list of all valid fields visit // https://musicbrainz.org/doc/Development/XML_Web_Service/Version_2/Search#Place result := placeListResult { } err := c . searchRequest ( \" \" , & result , searchTerm , limit , offset ) rsp := PlaceSearchResponse { } rsp . WS2ListResponse = result . PlaceList . WS2ListResponse rsp . Scores = make ( ScoreMap ) for i , v := range result . PlaceList . Places { rsp . Places = append ( rsp . Places , v . Place ) rsp . Scores [ rsp . Places [ i ] ] = v . Score } return & rsp , err", "del_tokens": "//TODO implement return nil , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "default", "port", "for", "svc"], "add_tokens": "return fmt . Sprintf ( \" \" , name , \" \" )", "del_tokens": "return fmt . Sprintf ( \" \" , name , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "double", "bookkeeping", "and", "data", "storage", "from", "the", "client"], "add_tokens": "import ( \" \" ) // GetLocations returns a slice of all locations known to the protocol, or // ErrNotFound if no locations are currently known. GetLocations ( ) ( locations [ ] Location , err error ) // GetLocation looks up a location by its `id` GetLocation ( id string ) ( Location , error ) // GetGroups returns a slice of all groups known to the protocol, or // ErrNotFound if no locations are currently known. GetGroups ( ) ( locations [ ] Group , err error ) // GetGroup looks up a group by its `id` GetGroup ( id string ) ( Group , error ) // GetDevices returns a slice of all devices known to the protocol, or // ErrNotFound if no devices are currently known. GetDevices ( ) ( devices [ ] Device , err error ) // GetDevice looks up a device by its `id` GetDevice ( id uint64 ) ( Device , error ) // SetTimeout attaches the client timeout to the protocol SetTimeout ( timeout * time . Duration ) // SetRetryInterval attaches the client retry interval to the protocol SetRetryInterval ( retryInterval * time . Duration )", "del_tokens": "import \" \" // SetClient sets the client on the protocol for bi-directional // communication SetClient ( client Client )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "empty", "IN", "/", "NOT", "IN", "conditions"], "add_tokens": "_ , err := fmt . Fprint ( w , \" \" ) return err", "del_tokens": "if _ , err := fmt . Fprintf ( w , \" \" , condIn . col ) ; err != nil { return err } return nil", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "example", "of", "setting", "the", "variables", "via", "the", "command", "line", "+", "fix", "some", "typos"], "add_tokens": "Package envconfig implements a configuration reader which reads each value from an environment variable . Then it 's just a matter of setting the environment variables when calling your binary : ADDR = localhost PORT = 6379 AUTH_KEY = foobar . / mybinary Now envconfig will read the environment variable named \" \" . Sometimes you don 't absolutely need a value . Here 's how we tell envconfig a value is optional :", "del_tokens": "Package envconfig implements a configuration reader which reads each values from a environment variable And then you 'r e done , your conf object is populated . Let 's see the details Now envconfig will read the environment variable named \" \" Sometimes you don 't absolutely need a value . Here 's how we tell envconfig a value is optional", "commit_type": "add"}
{"commit_tokens": ["Added", "Request", "as", "part", "of", "logger", "struct"], "add_tokens": "\" \" var buff bytes . Buffer l . ALogger = log . New ( & buff , \" \" , 0 ) func Test_LoggerCustomFormat ( t * testing . T ) { var buff bytes . Buffer recorder := httptest . NewRecorder ( ) l := NewLogger ( ) l . ALogger = log . New ( & buff , \" \" , 0 ) l . SetFormat ( \" \\\" \\\" \" ) n := New ( ) n . Use ( l ) n . UseHandler ( http . HandlerFunc ( func ( rw http . ResponseWriter , r * http . Request ) { rw . Write ( [ ] byte ( \" \" ) ) } ) ) userAgent := \" \" req , err := http . NewRequest ( \" \" , \" \" , nil ) if err != nil { t . Error ( err ) } req . Header . Set ( \" \" , userAgent ) n . ServeHTTP ( recorder , req ) expect ( t , strings . TrimSpace ( buff . String ( ) ) , \" \" + userAgent + \" \" ) }", "del_tokens": "buff := bytes . NewBufferString ( \" \" ) l . ALogger = log . New ( buff , \" \" , 0 )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "UserIds", "and", "TeamIds"], "add_tokens": "UserIds : [ ] int { 123 , 456 } , TeamIds : [ ] int { 789 } , \" \" : \" \" , \" \" : \" \" , UserIds : [ ] int { 123 , 456 } , TeamIds : [ ] int { 789 } , \" \" : \" \" , \" \" : \" \" , check := PingCheck { Name : \" \" , Hostname : \" \" , IntegrationIds : [ ] int { 33333333 , 44444444 } , UserIds : [ ] int { 123 , 456 } , TeamIds : [ ] int { 789 } , } \" \" : \" \" , \" \" : \" \" ,", "del_tokens": "check := PingCheck { Name : \" \" , Hostname : \" \" , IntegrationIds : [ ] int { 33333333 , 44444444 } }", "commit_type": "add"}
{"commit_tokens": ["Add", "audit", "to", "default", "middleware"], "add_tokens": "opentracing . Middleware { } , audit . Middleware { } , opentracing . Middleware { } , audit . Middleware { } ,", "del_tokens": "opentracing . Middleware { } , audit . Middleware { } , opentracing . Middleware { } ,", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "that", "when", "configurationData", "is", "not", "nil", "it", "doesn", "t", "populate", "new", "parameter", "."], "add_tokens": "// Package gonfig implements simple configuration reading \" \" configValue := reflect . ValueOf ( configuration ) if typ := configValue . Type ( ) ; typ . Kind ( ) != reflect . Ptr || typ . Elem ( ) . Kind ( ) != reflect . Struct { return fmt . Errorf ( \" \" ) } //configuration = configurationData dataValue := reflect . ValueOf ( configurationData ) configValue . Elem ( ) . Set ( dataValue . Elem ( ) )", "del_tokens": "// Package gonfig implements simple configuration reading configuration = configurationData", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "test", "for", "QWriter", ".", "U"], "add_tokens": "wn . U ( \" we . U ( \" expectedS := `<a></a>123'\"foo\"ds1.23%D0%B0%D0%B1%D0%B2{}&lt;a&gt;&lt;/a&gt;321&#39;&quot;foo&quot;ds1.23%D0%B0%D0%B1%D0%B2{}`", "del_tokens": "expectedS := `<a></a>123'\"foo\"ds1.23{}&lt;a&gt;&lt;/a&gt;321&#39;&quot;foo&quot;ds1.23{}`", "commit_type": "add"}
{"commit_tokens": ["improve", "documentation", "and", "use", "golint", "notes"], "add_tokens": "// Function signature of retryable function // Function signature of OnRetry function // n = count of tries type OnRetry func ( n uint , err error ) var n uint return fmt . Errorf ( \" \" , opts . tries )", "del_tokens": "\" \" type OnRetry func ( n uint , err error ) var defaultTries uint = 10 var defaultDelay time . Duration = 1e5 var n uint = 0 return errors . New ( fmt . Sprintf ( \" \" , opts . tries ) )", "commit_type": "improve"}
{"commit_tokens": ["Add", "unix", "timestamp", "of", "the", "last", "service", "state", "change", "to", "runit", "collector"], "add_tokens": "state , stateDesired , stateNormal , stateTimestamp * prometheus . GaugeVec Help : \" \" , Help : \" \" , Help : \" \" , ConstLabels : constLabels , } , labelNames , ) , stateTimestamp : prometheus . NewGaugeVec ( prometheus . GaugeOpts { Namespace : Namespace , Subsystem : subsystem , Name : \" \" , Help : \" \" , c . stateTimestamp . WithLabelValues ( service . Name ) . Set ( float64 ( status . Timestamp . Unix ( ) ) ) c . stateTimestamp . Collect ( ch )", "del_tokens": "state , stateDesired , stateNormal * prometheus . GaugeVec Help : \" \" , Help : \" \" , Help : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "trailing", "/", "to", "endpoint"], "add_tokens": "ResourceManagerEndpoint : \" \" , ServiceManagementEndpoint : \" \" , ResourceManagerEndpoint : \" \" ,", "del_tokens": "ResourceManagerEndpoint : \" \" , ServiceManagementEndpoint : \" \" , ResourceManagerEndpoint : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "warnings", "for", "validating", "services", "more", "obvious"], "add_tokens": "\" \" func init ( ) { flag . Parse ( ) if * debug { logrus . SetLevel ( logrus . DebugLevel ) } } logrus . Debugf ( f , v ... ) var log = logrus . Logger { Level : logrus . InfoLevel , Formatter : & logrus . TextFormatter { } , Out : os . Stdout , } func main ( ) { log . Warnf ( \" \\n \" , err , string ( output ) )", "del_tokens": "\" \" log . Printf ( f , v ... ) func main ( ) { flag . Parse ( ) log . Printf ( \" \\n \" , err , string ( output ) )", "commit_type": "make"}
{"commit_tokens": ["Allow", "setting", "of", "channel", "depth", "for", "queued", "outgoing", "messages", "while", "reconnecting", "."], "add_tokens": "if ! c . options . AutoReconnect { c . options . MessageChannelDepth = 0 } c . obound = make ( chan * PacketAndToken , c . options . MessageChannelDepth ) c . oboundP = make ( chan * PacketAndToken , c . options . MessageChannelDepth ) c . incomingPubChan = make ( chan * packets . PublishPacket , c . options . MessageChannelDepth )", "del_tokens": "c . obound = make ( chan * PacketAndToken , 100 ) c . oboundP = make ( chan * PacketAndToken , 100 ) c . incomingPubChan = make ( chan * packets . PublishPacket , 100 )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "verifying", "App", "Store", "receipts"], "add_tokens": "hash , err := getHashForOID ( signer . DigestAlgorithm . Algorithm ) if err != nil { return err } if algo == x509 . UnknownSignatureAlgorithm { // I'm not sure what the spec here is, and the openssl sources were not // helpful. But, this is what App Store receipts appear to do. // The DigestEncryptionAlgorithm is just \"rsaEncryption (PKCS #1)\" // But we're expecting a digest + encryption algorithm. So... we're going // to determine an algorithm based on the DigestAlgorithm and this // encryption algorithm. if signer . DigestEncryptionAlgorithm . Algorithm . Equal ( oidEncryptionAlgorithmRSA ) { algo = getRSASignatureAlgorithmForDigestAlgorithm ( hash ) } } func getRSASignatureAlgorithmForDigestAlgorithm ( hash crypto . Hash ) x509 . SignatureAlgorithm { for _ , details := range signatureAlgorithmDetails { if details . pubKeyAlgo == x509 . RSA && details . hash == hash { return details . algo } } return x509 . UnknownSignatureAlgorithm }", "del_tokens": "hash , err := getHashForOID ( signer . DigestAlgorithm . Algorithm ) if err != nil { return err }", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "to", "public", "members", "of", "custom", "-", "fields", "(", "golint", ")"], "add_tokens": "// CustomFieldItem represents the custom field items of Trello a trello card. // CustomField represents Trello's custom fields: \"extra bits of structured data // attached to cards when our users need a bit more than what Trello provides.\" // https://developers.trello.com/reference/#custom-fields // CustomFieldOption are nested resources of CustomFields // GetCustomField takes a field id string and Arguments and returns the matching custom Field. // GetCustomFields returns a slice of all receiver board's custom fields.", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "default", "zone", "for", "amazonec2"], "add_tokens": "Value : \" \" ,", "del_tokens": "Value : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "inline", "comments"], "add_tokens": "lexer . state = LexerNormal", "del_tokens": "lexer . state = LexerComment", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "cachable", "POSTs"], "add_tokens": "if ! hasFreshness ( obj . ReqDirectives , obj . RespDirectives , obj . RespHeaders , obj . RespExpiresHeader , obj . CacheIsPrivate ) { func hasFreshness ( reqDir * RequestCacheDirectives , respDir * ResponseCacheDirectives , respHeaders http . Header , respExpires time . Time , privateCache bool ) bool { if ! respExpires . IsZero ( ) || respHeaders . Get ( \" \" ) != \" \" {", "del_tokens": "if ! hasFreshness ( obj . ReqDirectives , obj . RespDirectives , obj . RespHeaders , obj . CacheIsPrivate ) { func hasFreshness ( reqDir * RequestCacheDirectives , respDir * ResponseCacheDirectives , respHeaders http . Header , privateCache bool ) bool { if respHeaders . Get ( \" \" ) != \" \" {", "commit_type": "add"}
{"commit_tokens": ["Allow", "the", "format", "on", "ksuid", "generated", "on", "the", "fly"], "add_tokens": "flag . StringVar ( & format , \" \" , \" \" , \" \" ) case \" \" : print = printString args = append ( args , ksuid . New ( ) . String ( ) ) func printString ( id ksuid . KSUID ) { fmt . Println ( id . String ( ) ) }", "del_tokens": "flag . StringVar ( & format , \" \" , \" \" , \" \" ) fmt . Println ( ksuid . New ( ) ) os . Exit ( 0 )", "commit_type": "allow"}
{"commit_tokens": ["make", "the", "linters", "happy", ":", ")"], "add_tokens": "\" \" : { \" \" : \" \" , \" \" : [ 102.0 , 0.5 ] } , \" \" : { \" \" : true , \" \" : false , \" \" : 1 , \" \" : 1.2 , \" \" : \" \" } if ! f . Properties . MustBool ( \" \" , true ) { if f . Properties . MustBool ( \" \" , true ) { if f . Properties . MustBool ( \" \" ) {", "del_tokens": "\" \" : { \" \" : \" \" , \" \" : [ 102.0 , 0.5 ] } , \" \" : { \" \" : true , \" \" : false , \" \" : 1 , \" \" : 1.2 , \" \" : \" \" } b := f . Properties . MustBool ( \" \" , true ) if b != true { b = f . Properties . MustBool ( \" \" , true ) if b != false { b = f . Properties . MustBool ( \" \" ) if b != false {", "commit_type": "make"}
{"commit_tokens": ["Fix", "removal", "of", "keys", "with", "the", "pass", "backend", "and", "add", "corresponding", "test"], "add_tokens": "cmd , err := k . pass ( \" \" , \" \" , name ) if err != nil { return err } err = cmd . Run ( )", "del_tokens": "_ , err := k . pass ( \" \" , name )", "commit_type": "fix"}
{"commit_tokens": ["remove", "debug", "print", "from", "sso"], "add_tokens": "package crowd // import \"go.jona.me/crowd\"", "del_tokens": "package crowd fmt . Printf ( \" \\n \" , resp . StatusCode )", "commit_type": "remove"}
{"commit_tokens": ["Added", "max", "-", "split", "check"], "add_tokens": "newhm := n . highMask >> 1 if newhm == 0 { // Can't split anymore since there are no more mask bits to use; means // this area will just be overfull. Everything should work fine, it // just won't be as fast. Really should only reach this issue with // grouplocmap or when keys barely differ in their high 64 bits. return } var newsl uint32 if newhm != 1 { newsl = uint32 ( float64 ( vlm . splitLevel ) + ( rand . Float64 ( ) - .5 ) / 5 * float64 ( vlm . splitLevel ) ) } highMask : newhm , splitLevel : newsl , if newhm != 1 { newsl = uint32 ( float64 ( vlm . splitLevel ) + ( rand . Float64 ( ) - .5 ) / 5 * float64 ( vlm . splitLevel ) ) } highMask : newhm , splitLevel : newsl , if n . splitLevel != 0 && u >= n . splitLevel {", "del_tokens": "highMask : hm >> 1 , splitLevel : uint32 ( float64 ( vlm . splitLevel ) + ( rand . Float64 ( ) - .5 ) / 5 * float64 ( vlm . splitLevel ) ) , highMask : hm >> 1 , splitLevel : uint32 ( float64 ( vlm . splitLevel ) + ( rand . Float64 ( ) - .5 ) / 5 * float64 ( vlm . splitLevel ) ) , if u >= n . splitLevel {", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "capitalization", "of", "Shutdown", "consistent"], "add_tokens": "ShutdownChannel chan os . Signal signal . Notify ( ShutdownChannel ) <- ShutdownChannel", "del_tokens": "ShutDownChannel chan os . Signal signal . Notify ( ShutDownChannel ) <- ShutDownChannel", "commit_type": "make"}
{"commit_tokens": ["Made", "stubs", "for", "missing", "tests", ".", "Fixed", "issue", "in", "struct", "decoding"], "add_tokens": "case marker == Struct8Marker : case marker == Struct16Marker :", "del_tokens": "case marker == Map8Marker : case marker == Map16Marker :", "commit_type": "make"}
{"commit_tokens": ["Fix", "PNet", "hadnshake", "being", "after", "the", "muxer", "on", "listener", "side"], "add_tokens": "if l . protec != nil { pc , err := l . protec . Protect ( maconn ) if err != nil { maconn . Close ( ) log . Warning ( \" \" , err ) } maconn = pc } log . Warning ( \" \" , err )", "del_tokens": "if l . protec != nil { pc , err := l . protec . Protect ( con . conn ) if err != nil { con . conn . Close ( ) return nil , err } con . conn = pc } log . Info ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Added", "X", "-", "Forward", "-", "Proto", "support", "in", "rewrite", "reles"], "add_tokens": "if request . TLS != nil || isXForwardedHttps ( request ) { func isXForwardedHttps ( request * http . Request ) bool { xForwardedProto := request . Header . Get ( \" \" ) return len ( xForwardedProto ) > 0 && xForwardedProto == \" \" }", "del_tokens": "if request . TLS != nil {", "commit_type": "add"}
{"commit_tokens": ["Added", "access", "to", "http", "response", "from", "api", "calls"], "add_tokens": "StructName string IsInputSchema bool IsOutputSchema bool if withComments && jsonSubSchema . IsOutputSchema { content += \" \\t \\n \" content += \" \\t \\n \" }", "del_tokens": "StructName string", "commit_type": "add"}
{"commit_tokens": ["update", "Network", ".", "Enable", "calls", "to", "take", "buffer", "sizes"], "add_tokens": "func overridenRuntimeEvaluate ( target * gcd . ChromeTarget , expression string , objectGroup string , includeCommandLineAPI bool , doNotPauseOnExceptionsAndMuteConsole bool , contextId int , returnByValue bool , generatePreview bool ) ( * gcdapi . RuntimeRemoteObject , bool , * gcdapi . RuntimeExceptionDetails , error ) { ExceptionDetails * gcdapi . RuntimeExceptionDetails", "del_tokens": "func overridenRuntimeEvaluate ( target * gcd . ChromeTarget , expression string , objectGroup string , includeCommandLineAPI bool , doNotPauseOnExceptionsAndMuteConsole bool , contextId int , returnByValue bool , generatePreview bool ) ( * gcdapi . RuntimeRemoteObject , bool , * gcdapi . DebuggerExceptionDetails , error ) { ExceptionDetails * gcdapi . DebuggerExceptionDetails", "commit_type": "update"}
{"commit_tokens": ["Improve", "LlongFile", "and", "LshortFile", "testing"], "add_tokens": "LlongFile LshortFile // Disable ansi in file output LnoFileAnsi LstdFlags = Ldate | Lansi | LnoFileAnsi if l . Flags & ( LshortFile | LlongFile ) != 0 { if l . Flags & LshortFile != 0 {", "del_tokens": "Llongfile Lshortfile LstdFlags = Ldate | Lansi if l . Flags & ( Lshortfile | Llongfile ) != 0 { if l . Flags & Lshortfile != 0 {", "commit_type": "improve"}
{"commit_tokens": ["Add", "utility", "for", "flag", "bytes"], "add_tokens": "header . unsynchronization = isBitSet ( header . flags , 7 ) header . compression = isBitSet ( header . flags , 6 ) header . unsynchronization = isBitSet ( header . flags , 7 ) header . extendedHeader = isBitSet ( header . flags , 6 ) header . experimental = isBitSet ( header . flags , 5 )", "del_tokens": "header . unsynchronization = ( header . flags & 1 << 7 ) == 1 header . compression = ( header . flags & 1 << 6 ) == 1 header . unsynchronization = ( header . flags & 1 << 7 ) == 1 header . extendedHeader = ( header . flags & 1 << 6 ) == 1 header . experimental = ( header . flags & 1 << 5 ) == 1", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "wrap", "invalid", "2d", "geometry", "around", "a", "bound"], "add_tokens": "// bitCode returns the point position relative to the bbox: // pointFor returns a representative point for the side of the given bitCode. func ( b Bound ) pointFor ( code int ) ( x , y float64 ) { switch code { case 1 : return b . Left , ( b . Top + b . Bottom ) / 2 case 2 : return b . Right , ( b . Top + b . Bottom ) / 2 case 4 : return ( b . Right + b . Left ) / 2 , b . Bottom case 5 : return b . Left , b . Bottom case 6 : return b . Right , b . Bottom case 8 : return ( b . Right + b . Left ) / 2 , b . Top case 9 : return b . Left , b . Top case 10 : return b . Right , b . Top } panic ( \" \" ) }", "del_tokens": "// bit code reflects the point position relative to the bbox:", "commit_type": "add"}
{"commit_tokens": ["fixing", "issue", "with", "some", "urls", "missing", "/"], "add_tokens": "content = strings . Replace ( content , \" \\\" \" , \" \\\" \" + s . c . BaseUrl + \" \" , - 1 ) content = strings . Replace ( content , \" \" , \" \" + s . c . BaseUrl + \" \" , - 1 ) content = strings . Replace ( content , \" \" , \" \" + s . c . BaseUrl + \" \" , - 1 ) content = strings . Replace ( content , \" \\\" \" , \" \\\" \" + s . c . BaseUrl + \" \" , - 1 )", "del_tokens": "content = strings . Replace ( content , \" \\\" \" , \" \\\" \" + s . c . BaseUrl , - 1 ) content = strings . Replace ( content , \" \" , \" \" + s . c . BaseUrl , - 1 ) content = strings . Replace ( content , \" \" , \" \" + s . c . BaseUrl , - 1 ) content = strings . Replace ( content , \" \\\" \" , \" \\\" \" + s . c . BaseUrl , - 1 )", "commit_type": "fix"}
{"commit_tokens": ["Added", "wildcard", "support", "to", "the", "=", "and", "!", "=", "functions"], "add_tokens": "\" \" : constraintTildeOrEqual , if c . dirty { if c . con . Major ( ) != v . Major ( ) { return true } if c . con . Minor ( ) != v . Minor ( ) && ! c . minorDirty { return true } else if c . minorDirty { return false } return false } return v . Equal ( c . con )", "del_tokens": "\" \" : constraintEqual , func constraintEqual ( v * Version , c * constraint ) bool { return v . Equal ( c . con ) } return constraintEqual ( v , c )", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "after", "heroku", "fork"], "add_tokens": "clean := filterParams ( FilterFields , values )", "del_tokens": "clean := filterParams ( values )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "Googlebot", "News"], "add_tokens": "\" \" : u ( \" \" ) , \" \" : u ( \" \" ) , \" \" : u ( \" \" ) , \" \" : u ( \" \" ) , \" \" : u ( \" \" ) , \" \" : u ( \" \" ) , ua . Type = Crawler // Alternate Googlebots if l . match ( \" \" ) { if l . match ( \" \" ) { ua . Name = \" \" } else if parseNameVersion ( l , ua ) { switch ua . Name { case \" \" ua . Name = \" \" case \" \" : ua . Name = \" \" default : ua . Name = \" \" + ua . Name [ 1 : ] } } else { return nil } return ua } else if l . match ( \" \" ) { ua . Name = \" \" return ua } else if l . match ( \" \" ) { ua . Name = \" \" return ua }", "del_tokens": "\" \" : u ( \" \" ) , \" \" : u ( \" \" ) , // TODO: finish // https://support.google.com/webmasters/answer/1061943 ua . Type = Crawler", "commit_type": "add"}
{"commit_tokens": ["Makes", "sure", "host", "handle", "is", "nil", "or", "invalid", "before", "attempting", "to", "disconnect"], "add_tokens": "if & h . handle != nil && h . handle != C . VIX_INVALID_HANDLE {", "del_tokens": "if h . handle != C . VIX_INVALID_HANDLE {", "commit_type": "make"}
{"commit_tokens": ["Remove", "use", "of", "mutex", "around", "done", "chan"], "add_tokens": "m . closeDoneChan ( ) select { case <- m . donec : // cmux was closed with cmux.Close() return nil default : // do nothing } case <- m . donec : m . closeDoneChan ( ) func ( m * cMux ) closeDoneChan ( ) { case <- m . donec : close ( m . donec )", "del_tokens": "mu sync . Mutex m . closeDoneChanLocked ( ) select { case <- m . getDoneChan ( ) : // cmux was closed with cmux.Close() return nil } case <- m . getDoneChan ( ) : m . mu . Lock ( ) defer m . mu . Unlock ( ) m . closeDoneChanLocked ( ) } func ( m * cMux ) getDoneChan ( ) chan struct { } { m . mu . Lock ( ) defer m . mu . Unlock ( ) return m . getDoneChanLocked ( ) } func ( m * cMux ) getDoneChanLocked ( ) chan struct { } { if m . donec == nil { m . donec = make ( chan struct { } ) } return m . donec func ( m * cMux ) closeDoneChanLocked ( ) { ch := m . getDoneChanLocked ( ) case <- ch : close ( ch )", "commit_type": "remove"}
{"commit_tokens": ["Removed", "autogen", "id", "for", "state", "as", "it", "was", "failing", "for", "heroku", "gitlab", "etc"], "add_tokens": "return \" \"", "del_tokens": "\" \" b := make ( [ ] byte , 16 ) n , _ := rand . Read ( b ) return string ( b [ : n ] )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "data", "race", "in", "use", "of", "cmd", "output", "buffers", "."], "add_tokens": "import ( \" \" \" \" \" \" ) func TestParallelCmds ( t * testing . T ) { rc := & Runc { // we don't need a real runc, we just want to test running a caller of cmdOutput in parallel Command : \" \" , } var wg sync . WaitGroup ctx , cancel := context . WithCancel ( context . Background ( ) ) defer cancel ( ) for i := 0 ; i < 256 ; i ++ { wg . Add ( 1 ) go func ( ) { defer wg . Done ( ) // We just want to fail if there is a race condition detected by // \"-race\", so we ignore the (expected) error here. _ , _ = rc . Version ( ctx ) } ( ) } wg . Wait ( ) }", "del_tokens": "import \" \"", "commit_type": "fix"}
{"commit_tokens": ["allowed", "all", "update", "messages", "to", "pass", "to", "recorder"], "add_tokens": "filterMessages bool filterMessages : config . Pin . Type != \" \" , } else if g . status && ( msg . Location == g . Location || ! g . filterMessages ) {", "del_tokens": "} else if g . status && msg . Location == g . Location {", "commit_type": "allow"}
{"commit_tokens": ["Updated", "dependency", "to", "golang", ".", "org", "/", "x", "/", "net", "/", "websocket", "(", "code", ".", "google", ".", "com", "will", "be", "closed", ")"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["fixing", "bug", "where", "re", "-", "using", "the", "same", "CORS", "factory", "with", "multiple", "handlers", "would", "cross", "the", "wires", "the", "handlers"], "add_tokens": "ch := parseCORSOptions ( opts ... )", "del_tokens": "ch := parseCORSOptions ( opts ... )", "commit_type": "fix"}
{"commit_tokens": ["fixed", ":", "use", "the", "syncHandler"], "add_tokens": "l collector . EventCollector , syncAtStart bool , syncAtStart : syncAtStart , syncHandler : s ,", "del_tokens": "l collector . EventCollector , syncAtStart bool , syncAtStart : syncAtStart ,", "commit_type": "fix"}
{"commit_tokens": ["Updated", "migrate", "-", "cmd", "to", "automatically", "use", "the", "POSTGRES_DSN", "if", "set", ".", "Password", "is", "now", "an", "optional", "parameter", "."], "add_tokens": "\" \" const ( postgresDsn = \" \" ) pgdsn := os . Getenv ( postgresDsn ) dsn := flag . String ( \" \" , \" \" , \" \" ) if * dsn != \" \" { // use the dsn parameter value as an override if supplied pgdsn = * dsn } if pgdsn == \" \" { // if both the env and dsn parameter are not present, return an error. db , err := dbx . InitializeDB ( pgdsn , * schema , * password , * migrationsDir )", "del_tokens": "dsn := flag . String ( \" \" , \" \" , \" \" ) if * dsn == \" \" { if * password == \" \" { log . Fatalln ( \" \" ) } db , err := dbx . InitializeDB ( * dsn , * schema , * password , * migrationsDir )", "commit_type": "update"}
{"commit_tokens": ["add", "Int", "()", "helper", "for", "event", "level"], "add_tokens": "type Level int func ( l Level ) Int ( ) int { return int ( l ) }", "del_tokens": "type Level int32", "commit_type": "add"}
{"commit_tokens": ["Add", "changes", "to", "handle", "cwd", "being", "required", "in", "the", "spec"], "add_tokens": "cli . StringFlag { Name : \" \" , Value : \" \" , Usage : \" \" } , Cwd : \" \" ,", "del_tokens": "cli . StringFlag { Name : \" \" , Usage : \" \" } ,", "commit_type": "add"}
{"commit_tokens": ["add", "map", "[", "string", "]", "RawTypeOption", "mappings", "so", "we", "can", "add", "routines", "required", "for", "kingpin", "interfaces"], "add_tokens": "Str1 StringOption `yaml:\"str1,omitempty\"` Int1 IntOption `yaml:\"int1,omitempty\"` Map1 MapStringOption `yaml:\"map1,omitempty\"` app . Flag ( \" \" , \" \" ) . SetValue ( & opts . Map1 ) _ , err = app . Parse ( [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } ) Map1 : map [ string ] StringOption { \" \" : StringOption { \" \" , true , \" \" } , \" \" : StringOption { \" \" , true , \" \" } , \" \" : StringOption { \" \" , true , \" \" } , \" \" : StringOption { \" \" , true , \" \" } , \" \" : StringOption { \" \" , true , \" \" } , \" \" : StringOption { \" \" , true , \" \" } , } ,", "del_tokens": "Str1 StringOption `yaml:\"str1,omitempty\"` Int1 IntOption `yaml:\"int1,omitempty\"` _ , err = app . Parse ( [ ] string { \" \" , \" \" } )", "commit_type": "add"}
{"commit_tokens": ["change", "v2", "to", "v3", "in", "stack", "trace", "test"], "add_tokens": "( . + ) ? logrus - graylog - hook ( % 2 ev3 ) ? . TestStackTracer ( / | [ A - Z ] : / ) . + / logrus - graylog - hook ( . v3 ) ? / graylog_hook_test . go : \\d +", "del_tokens": "( . + ) ? logrus - graylog - hook ( % 2 ev2 ) ? . TestStackTracer ( / | [ A - Z ] : / ) . + / logrus - graylog - hook ( . v2 ) ? / graylog_hook_test . go : \\d +", "commit_type": "change"}
{"commit_tokens": ["Remove", "duplication", "around", "removing", "cache", "entries"], "add_tokens": "c . removeCacheEntryFor ( cacheKey ) c . unsafelyRemoveCacheEntryFor ( oldestCacheKey ) f . access = time . Now ( ) c . unsafelyRemoveCacheEntryFor ( cacheKey ) func ( c * cachedDownloader ) unsafelyRemoveCacheEntryFor ( cacheKey string ) { delete ( c . cachedFiles , cacheKey )", "del_tokens": "c . removeCacheFileFor ( cacheKey ) fp := c . pathForCacheKey ( oldestCacheKey ) if fp != \" \" { delete ( c . cacheFilePaths , fp ) os . RemoveAll ( fp ) } delete ( c . cachedFiles , oldestCacheKey ) fp := c . pathForCacheKey ( cacheKey ) if fp != \" \" { delete ( c . cacheFilePaths , fp ) os . RemoveAll ( fp ) } delete ( c . cachedFiles , cacheKey ) func ( c * cachedDownloader ) removeCacheFileFor ( cacheKey string ) { c . lock . Lock ( ) defer c . lock . Unlock ( ) cf := c . cachedFiles [ cacheKey ] cf . filePath = \" \" c . cachedFiles [ cacheKey ] = cf", "commit_type": "remove"}
{"commit_tokens": ["Add", "integration", "test", "flag", "for", "sftp", "binary", "path"], "add_tokens": "var testSftp = flag . String ( \" \" , \" \" , \" \" ) cmd := exec . Command ( * testSftp , \" \" , \" \" , \" \" , debuglevel ) // log to stderr, read only cmd = exec . Command ( * testSftp , \" \" , \" \" , debuglevel ) // log to stderr", "del_tokens": "cmd := exec . Command ( \" \" , \" \" , \" \" , \" \" , debuglevel ) // log to stderr, read only cmd = exec . Command ( \" \" , \" \" , \" \" , debuglevel ) // log to stderr", "commit_type": "add"}
{"commit_tokens": ["Add", "full", "test", "for", "decoding", "response", "/", "validating", "assertion"], "add_tokens": "if err != nil && ! sp . SkipSignatureValidation || response == nil {", "del_tokens": "if err != nil && ! sp . SkipSignatureValidation {", "commit_type": "add"}
{"commit_tokens": ["add", "test", "case", "for", "SyncBuilder"], "add_tokens": "return b . client . unfixForNamespace ( syncPath ) , err", "del_tokens": "return syncPath , err", "commit_type": "add"}
{"commit_tokens": ["Added", "git", ".", "Clone", "as", "default", "Downloader"], "add_tokens": "\" \" s . source = & git . Clone { s . git , s . fs } s := & STI { s . source = & git . Clone { s . git , s . fs } return s bh . source . Download ( bh . request )", "del_tokens": "return & STI { bh . Download ( bh . request )", "commit_type": "add"}
{"commit_tokens": ["Use", "HTTP", "Client", "SetTimeout", "instead", "of", "custom", "timeout"], "add_tokens": "assertEqual ( t , true , strings . Contains ( strings . ToLower ( err . Error ( ) ) , \" \" ) ) } func TestClientTimeoutWithinThreshold ( t * testing . T ) { ts := createGetServer ( t ) defer ts . Close ( ) c := dc ( ) c . SetHTTPMode ( ) . SetTimeout ( time . Duration ( time . Second * 3 ) ) resp , err := c . R ( ) . Get ( ts . URL + \" \" ) assertError ( t , err ) seq1 , _ := strconv . ParseInt ( resp . String ( ) , 10 , 64 ) resp , err = c . R ( ) . Get ( ts . URL + \" \" ) assertError ( t , err ) seq2 , _ := strconv . ParseInt ( resp . String ( ) , 10 , 64 ) assertEqual ( t , seq1 + 1 , seq2 )", "del_tokens": "assertEqual ( t , true , strings . Contains ( err . Error ( ) , \" \" ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "additional", "console", "mode", "constants"], "add_tokens": "ENABLE_PROCESSED_INPUT = 0x0001 ENABLE_LINE_INPUT = 0x0002 ENABLE_ECHO_INPUT = 0x0004 ENABLE_WINDOW_INPUT = 0x0008 ENABLE_MOUSE_INPUT = 0x0010 ENABLE_INSERT_MODE = 0x0020 ENABLE_QUICK_EDIT_MODE = 0x0040 ENABLE_EXTENDED_FLAGS = 0x0080 ENABLE_AUTO_POSITION = 0x0100 ENABLE_VIRTUAL_TERMINAL_INPUT = 0x0200 ENABLE_PROCESSED_OUTPUT = 0x0001 ENABLE_WRAP_AT_EOL_OUTPUT = 0x0002 ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004 DISABLE_NEWLINE_AUTO_RETURN = 0x0008 ENABLE_LVB_GRID_WORLDWIDE = 0x0010", "del_tokens": "ENABLE_PROCESSED_INPUT = 0x0001 ENABLE_LINE_INPUT = 0x0002 ENABLE_ECHO_INPUT = 0x0004 ENABLE_WINDOW_INPUT = 0x0008 ENABLE_MOUSE_INPUT = 0x0010 ENABLE_INSERT_MODE = 0x0020 ENABLE_QUICK_EDIT_MODE = 0x0040 ENABLE_EXTENDED_FLAGS = 0x0080 ENABLE_PROCESSED_OUTPUT = 0x0001 ENABLE_WRAP_AT_EOL_OUTPUT = 0x0002", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Chromium", "Edge", "on", "macOS", "/", "iOS", "/", "Android"], "add_tokens": "{ \" \" , \" \" , \" \" , \" \" , \" \" } , { \" \" , ua . Edge , \" \" , \" \" , \" \" } , { \" \" , ua . Edge , \" \" , \" \" , \" \" } , //{\"Aweme 8.2.0 rv:82017 (iPhone6,2; iOS 12.4; zh_CN) Cronet\", \"Aweme\", \"\", \"\", \"\"}, //Mozilla/5.0 (Macintosh; Intel Mac OS Xt 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.6.0 Chrome/45.0.2454.101 Safari/537.36", "del_tokens": "//Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.6.0 Chrome/45.0.2454.101 Safari/537.36", "commit_type": "add"}
{"commit_tokens": ["Updating", "jsh", "with", "new", "parsing", "features"], "add_tokens": "if ! d . HasData ( ) && d . Included != nil {", "del_tokens": "if d . HasData ( ) && d . Included != nil {", "commit_type": "update"}
{"commit_tokens": ["Improving", "the", "documentation", "for", "function", "arguments", "."], "add_tokens": "// The first argument is a slice of strings containing the dictionary of words. // The second argument is the words we are looking for. Finally, the dist // argument is the distance. // The first argument is a slice of strings containing the dictionary of words. // The second argument is the words we are looking for.", "del_tokens": "// dict - A slice of strings containing the dictionary of words. // // word - The word that we are looking for. // // dist - The given distance. // dict - A slice of strings containing the dictionary of words. // // word - The word that we are looking for.", "commit_type": "improve"}
{"commit_tokens": ["Add", "callback", "when", "import", "products"], "add_tokens": "\" \" ProductExchange . Import ( csv . New ( path . Join ( \" \" , argument . File . URL ( ) ) ) , context , func ( progress exchange . Progress ) error { qorJob . SetProgress ( uint ( float32 ( progress . Current ) / float32 ( progress . Total ) * 100 ) ) qorJob . AddLog ( fmt . Sprintf ( \" \" , progress . Current ) ) return nil } , )", "del_tokens": "ProductExchange . Import ( csv . New ( path . Join ( \" \" , argument . File . URL ( ) ) ) , context )", "commit_type": "add"}
{"commit_tokens": ["fix", "access", "to", "nil", "memory", "address"], "add_tokens": "fds := ( * C . int ) ( nil ) num := C . int ( 0 ) fdlist := listFd ( ) if len ( fdlist ) != 0 { fds = ( * C . int ) ( unsafe . Pointer ( & fdlist [ 0 ] ) ) num = C . int ( len ( fdlist ) ) } ret , err := C . daemonize ( C . CString ( cmd ) , ( * * C . char ) ( unsafe . Pointer ( & cargs [ 0 ] ) ) , C . int ( pipe ) , fds , num )", "del_tokens": "fds := listFd ( ) ret , err := C . daemonize ( C . CString ( cmd ) , ( * * C . char ) ( unsafe . Pointer ( & cargs [ 0 ] ) ) , C . int ( pipe ) , ( * C . int ) ( unsafe . Pointer ( & fds [ 0 ] ) ) , C . int ( len ( fds ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "feedback", "token", "was", "being", "returned", "as", "invalid", "string"], "add_tokens": "\" \" var ts uint32 var tokLen uint16 tok := make ( [ ] byte , tokLen ) return FeedbackTuple { Timestamp : time . Unix ( int64 ( ts ) , 0 ) , TokenLength : tokLen , DeviceToken : hex . EncodeToString ( tok ) , }", "del_tokens": "var ts uint32 var tokLen uint16 tok := make ( [ ] byte , 32 ) return FeedbackTuple { Timestamp : time . Unix ( int64 ( ts ) , 0 ) , TokenLength : tokLen , DeviceToken : string ( tok ) }", "commit_type": "fix"}
{"commit_tokens": ["Update", "rss", "date", "format", "to", "RFC822", "per", "the", "spec", "."], "add_tokens": "< pubDate > 16 Jan 13 21 : 52 EST < / pubDate > < pubDate > 16 Jan 13 21 : 52 EST < / pubDate > < pubDate > 16 Jan 13 21 : 52 EST < / pubDate > < pubDate > 16 Jan 13 21 : 52 EST < / pubDate >", "del_tokens": "< pubDate > 2013 - 01 - 16 T21 : 52 : 35 - 05 : 00 < / pubDate > < pubDate > 2013 - 01 - 16 T21 : 52 : 35 - 05 : 00 < / pubDate > < pubDate > 2013 - 01 - 16 T21 : 52 : 35 - 05 : 00 < / pubDate > < pubDate > 2013 - 01 - 16 T21 : 52 : 35 - 05 : 00 < / pubDate >", "commit_type": "update"}
{"commit_tokens": ["Remove", "golang", ".", "org", "/", "x", "/", "net", "/", "internal", "/", "iana", "dependency"], "add_tokens": "const ( TimeSliceLength = 8 ProtocolICMP = 1 ProtocolIPv6ICMP = 58 ) proto = ProtocolICMP proto = ProtocolIPv6ICMP", "del_tokens": "\" \" const TimeSliceLength = 8 proto = iana . ProtocolICMP proto = iana . ProtocolIPv6ICMP", "commit_type": "remove"}
{"commit_tokens": ["Remove", "stray", "mutex", "lock", "and", "correct", "link", "in", "example"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "remove"}
{"commit_tokens": ["Updated", "the", "intrinsic", "function", "handler", "signature", "to", "include", "the", "full", "template", "interface", "{}", ".", "This", "will", "allow", "us", "to", "do", "lookups", "on", "other", "resources", "should", "we", "want", "to", "implement", "!Ref", "at", "a", "later", "date", "."], "add_tokens": "type IntrinsicHandler func ( string , interface { } , interface { } ) interface { } func nonResolvingHandler ( name string , input interface { } , template interface { } ) interface { } { processed := search ( unmarshalled , unmarshalled , options ) func search ( input interface { } , template interface { } , options * ProcessorOptions ) interface { } { return h ( key , template , search ( val , template , options ) ) processed [ key ] = search ( val , template , options ) processed = append ( processed , search ( val , template , options ) )", "del_tokens": "type IntrinsicHandler func ( string , interface { } ) interface { } func nonResolvingHandler ( name string , input interface { } ) interface { } { processed := search ( unmarshalled , options ) func search ( input interface { } , options * ProcessorOptions ) interface { } { return h ( key , search ( val , options ) ) processed [ key ] = search ( val , options ) processed = append ( processed , search ( val , options ) )", "commit_type": "update"}
{"commit_tokens": ["Updated", "due", "to", "dependencies", "being", "updated"], "add_tokens": "content += \" \" + exchangeEntry + \" \\n \"", "del_tokens": "content += \" \" + exchangeEntry + \" \\n \"", "commit_type": "update"}
{"commit_tokens": ["use", "explanatory", "names", "in", "test", "conn", "/", "svr", "methods"], "add_tokens": "s := getServer ( t ) c := getClientConnWithClientCert ( t ) s := getServer ( t ) c := getClientConnWithClientCert ( t ) func getClientConnWithClientCert ( t * testing . T ) * Conn { return _getClientConn ( t , true ) } func _getClientConn ( t * testing . T , useClientCert bool ) * Conn { func getServer ( t * testing . T ) * Server { return _getServer ( t , false ) } func _getServer ( t * testing . T , createNewCertPair bool ) * Server {", "del_tokens": "s := getServer ( t , false ) c := getClientConn ( t , true ) s := getServer ( t , false ) c := getClientConn ( t , true ) func getClientConn ( t * testing . T , useClientCert bool ) * Conn { func getServer ( t * testing . T , createNewCertPair bool ) * Server {", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "non", "-", "SSL", "access"], "add_tokens": "\" \" var reProtocol = regexp . MustCompile ( \" \" ) url := strings . TrimSuffix ( auth . ServerAddress , \" \" ) if ! reProtocol . MatchString ( url ) { url = \" \" + url } Domain : reProtocol . ReplaceAllString ( url , \" \" ) ,", "del_tokens": "url := \" \" + strings . TrimPrefix ( strings . TrimSuffix ( auth . ServerAddress , \" \" ) , \" \" ) Domain : strings . TrimPrefix ( url , \" \" ) ,", "commit_type": "allow"}
{"commit_tokens": ["Adding", "support", "for", "XML", "-", "tagged", "structs", "."], "add_tokens": "//ResValue prints the node's string value", "del_tokens": "//String prints the node's string value", "commit_type": "add"}
{"commit_tokens": ["Make", "custom", "endpoints", "return", "list", "of", "containers"], "add_tokens": "region , ok := config . Config ( ConfigRegion ) if ok { } else { awsConfig . WithRegion ( \" \" )", "del_tokens": "if region , ok := config . Config ( ConfigRegion ) ; ok {", "commit_type": "make"}
{"commit_tokens": ["implement", "local", "-", "name", "()", "function"], "add_tokens": "case \" \" , \" \" : return nil , fmt . Errorf ( \" \" , root . FuncName ) f := & functionQuery { Input : inp } switch root . FuncName { case \" \" : f . Func = nameFunc case \" \" : f . Func = localNameFunc } qyOutput = f", "del_tokens": "case \" \" : return nil , errors . New ( \" \" ) qyOutput = & functionQuery { Input : inp , Func : nameFunc }", "commit_type": "implement"}
{"commit_tokens": ["add", "missing", "go", "for", "es", "flushes"], "add_tokens": "go h . flush ( h . batch )", "del_tokens": "h . flush ( h . batch )", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "in", "documentation", "for", "(", "g", "Gauge", ")", "Remove", "()"], "add_tokens": "// Remove removes the given gauge.", "del_tokens": "// Remove removes the given counter.", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "better", "integration", "with", "errors"], "add_tokens": "if s , ok := err . ( TraceSetter ) ; ok { s . SetTrace ( t . Trace ) return s } nil , Trace { File : \" \" , Path : \" \" , Func : \" \" , Line : 0 , } , \" \" , nil , Trace { File : filepath . Base ( filePath ) , Path : filePath , Func : runtime . FuncForPC ( pc ) . Name ( ) , Line : line , } , \" \" , type Trace struct { File string Path string Func string Line int } Trace type TraceSetter interface { Error SetTrace ( Trace ) }", "del_tokens": "File : \" \" , Path : \" \" , Func : \" \" , Line : 0 , File : filepath . Base ( filePath ) , Path : filePath , Func : runtime . FuncForPC ( pc ) . Name ( ) , Line : line , File string Path string Func string Line int", "commit_type": "add"}
{"commit_tokens": ["Use", "plural", "form", "of", "nouns", "in", "REST", "API"], "add_tokens": "BasePath ( \" \" ) Response ( Created , \" \" , func ( ) { BasePath ( \" \" )", "del_tokens": "BasePath ( \" \" ) Response ( Created , \" \" , func ( ) { BasePath ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Add", "result", ".", "Errors", ".", "List", "count", "to", "output", "."], "add_tokens": "fmt . Printf ( \" \\n \" , len ( result . Errors . List ( ) ) )", "del_tokens": "fmt . Println ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "title", "title", "-", "loc", "-", "key", "and", "title", "-", "loc", "-", "args", "to", "alert", "dictionary", "."], "add_tokens": "import \" \" dict . Title = \" \" dict . TitleLocKey = \" \" dict . TitleLocArgs = args if len ( bytes ) != 340 { t . Error ( \" \" , len ( bytes ) ) if len ( json ) != 279 { t . Error ( \" \" , len ( json ) )", "del_tokens": "import ( \" \" ) if len ( bytes ) != 255 { t . Error ( \" \" , len ( bytes ) ) if len ( json ) != 194 { t . Error ( \" \" , len ( bytes ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "windows", "build", "for", "io", "options"], "add_tokens": "func NewPipeIO ( opts ... IOOpt ) ( i IO , err error ) {", "del_tokens": "func NewPipeIO ( ) ( i IO , err error ) { err error", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "temporary", "ForceResource", "field", "so", "that", "it", "is", "not", "persisted", "to", "the", "JSON", "(", "json", ":", "-", ")", "."], "add_tokens": "ForceResource string `json:\"-\"`", "del_tokens": "ForceResource string", "commit_type": "fix"}
{"commit_tokens": ["Implement", "fuzzing", "of", "complex", "types"], "add_tokens": "v . SetComplex ( complex128 ( complex ( r . Float32 ( ) , r . Float32 ( ) ) ) ) v . SetComplex ( complex ( r . Float64 ( ) , r . Float64 ( ) ) )", "del_tokens": "panic ( \" \" ) panic ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["move", "util", ".", "Key", "into", "its", "own", "package", "under", "blocks"], "add_tokens": "key \" \" func ConvertKey ( id key . Key ) ID { func Closer ( a , b peer . ID , key key . Key ) bool {", "del_tokens": "func ConvertKey ( id u . Key ) ID { func Closer ( a , b peer . ID , key u . Key ) bool {", "commit_type": "move"}
{"commit_tokens": ["Use", "qor", "resource", "s", "multiple", "primary", "keys"], "add_tokens": "* resource . Resource res := Resource { Resource : resource . New ( value ) } scope := gorm . Scope { Value : res . Value } if field , ok := scope . FieldByName ( res . Config . PrimaryField ) ; ok { res . SetPrimaryFields ( [ ] * gorm . StructField { field . StructField } )", "del_tokens": "\" \" \" \" resource . Resource res := Resource { Resource : * resource . New ( value ) } res . FindOneHandler = func ( result interface { } , metaValues * resource . MetaValues , context * qor . Context ) error { scope := context . GetDB ( ) . NewScope ( res . Value ) if field , ok := scope . FieldByName ( res . Config . PrimaryField ) ; ok { if metaValue := metaValues . Get ( res . Config . PrimaryField ) ; metaValue != nil { field . Set ( metaValue . Value ) } return context . GetDB ( ) . First ( result , fmt . Sprintf ( \" \" , scope . Quote ( field . DBName ) ) , field . Field . Interface ( ) ) . Error } return errors . New ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Update", "chi", "Router", "interface", ";", "rename", "v1", "Route", "()", "to", "Group", "()", "in", "v2", "and", "v1", "Group", "()", "to", "Stack", "()", "in", "v2"], "add_tokens": "Stack ( fn func ( r Router ) ) Router Group ( pattern string , fn func ( r Router ) ) Router", "del_tokens": "Group ( fn func ( r Router ) ) Router // TODO: rename to XXX? Route ( pattern string , fn func ( r Router ) ) Router // TODO: rename to Group()..?", "commit_type": "update"}
{"commit_tokens": ["Make", "unknown", "worker", "error", "better"], "add_tokens": "err := UnknownWorkerError { job . Type } type UnknownWorkerError struct { Type string } func ( e UnknownWorkerError ) Error ( ) string { return \" \" + e . Type }", "del_tokens": "err := fmt . Errorf ( \" \" , job . Type )", "commit_type": "make"}
{"commit_tokens": ["making", "obvious", "the", "race", "condition", "without", "-", "race", "flag"], "add_tokens": "const max = 1024", "del_tokens": "const max = 128", "commit_type": "make"}
{"commit_tokens": ["Add", "break", "capability", "to", "switch"], "add_tokens": "_labelSet := node . _labelSet return self . breakEvaluate ( _labelSet , func ( ) Value { target := node . Default for index , clause := range node . CaseList { test := clause . Test if test != nil { testResult := self . evaluate ( test ) if self . calculateComparison ( \" \" , discriminantResult , testResult ) { target = index break } if target != - 1 { for _ , clause := range node . CaseList [ target : ] { self . evaluateBody ( clause . Body ) } return emptyValue ( ) } )", "del_tokens": "target := node . Default for index , clause := range node . CaseList { test := clause . Test if test != nil { testResult := self . evaluate ( test ) if self . calculateComparison ( \" \" , discriminantResult , testResult ) { target = index break } if target != - 1 { for _ , clause := range node . CaseList [ target : ] { self . evaluateBody ( clause . Body ) } return emptyValue ( )", "commit_type": "add"}
{"commit_tokens": ["use", "interfaces", "instead", "of", "strings"], "add_tokens": "\" \" : func ( a [ ] interface { } ) interface { } { \" \" : func ( a [ ] interface { } ) interface { } {", "del_tokens": "\" \" : func ( a [ ] string ) string { \" \" : func ( a [ ] string ) string {", "commit_type": "use"}
{"commit_tokens": ["Updated", "to", "work", "with", "keybind", "package", "refactoring", "."], "add_tokens": "modMap := keybind . ModMapGet ( X ) symsPerKc := int ( keybind . KeyMapGet ( X ) . KeysymsPerKeycode )", "del_tokens": "modMap := X . ModMapGet ( ) symsPerKc := int ( X . KeyMapGet ( ) . KeysymsPerKeycode )", "commit_type": "update"}
{"commit_tokens": ["Use", "int64", "for", "millisecond", "epochs"], "add_tokens": "Timestamp int64 `json:\"timestamp\"` AfterEpochMs int64 BeforeEpochMs int64", "del_tokens": "Timestamp int `json:\"timestamp\"` AfterEpochMs int BeforeEpochMs int", "commit_type": "use"}
{"commit_tokens": ["Adding", "support", "for", "recent", "content", "."], "add_tokens": "s . Info = SiteInfo { BaseUrl : template . URL ( s . Config . BaseUrl ) , Title : s . Config . Title , Recent : & s . Pages , Config : & s . Config , } n . Url = Urlize ( section + \" \" ) n . Url = Urlize ( section + \" \" + \" \" )", "del_tokens": "s . Info = SiteInfo { BaseUrl : template . URL ( s . Config . BaseUrl ) , Title : s . Config . Title , Config : & s . Config } n . Url = Urlize ( section + \" \" ) n . Url = Urlize ( section + \" \" + \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "testdata", "/", "stubcmd", "and", "use", "it", "in", "testing"], "add_tokens": "cmd : exec . Command ( stubCmd , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ) ,", "del_tokens": "cmd : exec . Command ( \" \" , \" \" ) ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "ExpectEq ( 1 , msb ( buf ) , \" \" , i , buf ) ExpectEq ( 0 , msb ( buf ) , \" \" , i , buf )", "del_tokens": "ExpectEq ( 1 , buf , \" \" , i , buf ) ExpectEq ( 0 , buf , \" \" , i , buf )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "improper", "usage", "of", "external", "tag"], "add_tokens": "import opentracing \" \" SamplingPriority = uint16Tag ( \" \" )", "del_tokens": "import ( \" \" ) SamplingPriority = uint32Tag ( \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Make", ".", "the", "default", "directory"], "add_tokens": "flag_directory = flag . String ( \" \" , \" \" , \" \" )", "del_tokens": "flag_directory = flag . String ( \" \" , \" \" , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Make", "the", "IP", "loopback", "check", "faster"], "add_tokens": "var localPrefixes = [ ] [ ] byte { { ma . P_IP4 , 127 } , // 127.* IP6LinkLocalLoopback . Bytes ( ) , IP6Loopback . Bytes ( ) , } // This means either /ip4/127.*.*.*, /ip6/::1, or /ip6/fe80::1 for _ , prefix := range localPrefixes { if bytes . HasPrefix ( b , prefix ) { return true }", "del_tokens": "// This means either /ip4/127.0.0.1 or /ip6/::1 // TODO: differentiate IsIPLoopback and OverIPLoopback // /ip4/127 prefix (_entire_ /8 is loopback...) if bytes . HasPrefix ( b , [ ] byte { ma . P_IP4 , 127 } ) { return true // /ip6/::1 if ! m . Decapsulate ( IP6Loopback ) . Equal ( m ) || ! m . Decapsulate ( IP6LinkLocalLoopback ) . Equal ( m ) { return true }", "commit_type": "make"}
{"commit_tokens": ["fix", "json", "marshaling", "to", "add", "option", "for", "protocol", "(", "as", "same", "with", "msgpack", "protocol", ")"], "add_tokens": "return [ ] byte ( fmt . Sprintf ( \" \\\" \\\" \" , chunk . message . Tag ,", "del_tokens": "return [ ] byte ( fmt . Sprintf ( \" \\\" \\\" \" , chunk . message . Tag ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "an", "annoying", "crash", "."], "add_tokens": "if err != nil || ! f . IsDir ( ) { // TODO: Is there some other thing we should be doing to handle errors? When watching large // directories that have lots of programs modifying them (esp. if they're making tempfiles along the // way), we often get errors.", "del_tokens": "if ! f . IsDir ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "start", "of", "the", "sandbox", "item", "testing"], "add_tokens": "// A SandboxItem is embedded into the response from the chef-server and the actual sandbox is the Url and state for a specific Item. // Sandbox Is the structure of an actual sandbox that has been created and returned by the final PUT to the sandbox ID // Put is used to commit a sandbox ID to the chef server. To signal that the sandbox you have Posted is now uploaded.", "del_tokens": "// A SandbooxItem is embeddedinto the response from the chef-server and the actual sandbox It is the Url and state for a specific Item. // Sandbox Is the structure of an actul sandbox that has been created and returned by the final PUT to the sandbox ID // Put is used to commit a sandbox ID to the chef server. To singal that the sandox you have Posted is now uploaded.", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "failing", "test", "unit", ":", "error", "when", "Id", "isn", "t", "a", "string", "or", "a", "byte"], "add_tokens": "\" \" \" \" \" \" \" \" u1 := SimpleUser { Id : 1 , Name : \" \" } func TestSave ( t * testing . T ) { dir , _ := ioutil . TempDir ( os . TempDir ( ) , \" \" ) defer os . RemoveAll ( dir ) db , _ := storm . Open ( filepath . Join ( dir , \" \" ) , storm . Codec ( Codec ) ) u := SimpleUser { Id : 1 , Name : \" \" } err := db . Save ( & u ) assert . NoError ( t , err ) }", "del_tokens": "u1 := SimpleUser { Id : uint64 ( 1 ) , Name : \" \" , }", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "potiental", "goroutine", "leak", "by", "using", "buffer", "channel", "."], "add_tokens": "done := make ( chan bool , 1 )", "del_tokens": "done := make ( chan bool )", "commit_type": "fix"}
{"commit_tokens": ["Add", "generatorURL", "to", "Alert", "struct"], "add_tokens": "StartsAt time . Time `json:\"startsAt,omitempty\"` EndsAt time . Time `json:\"endsAt,omitempty\"` GeneratorURL string `json:\"generatorURL\"`", "del_tokens": "StartsAt time . Time `json:\"startsAt,omitempty\"` EndsAt time . Time `json:\"endsAt,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "own", "type", "for", "the", "direction", "argument"], "add_tokens": "type directionConst bool DirectionEncrypt = directionConst ( true ) DirectionDecrypt = directionConst ( false ) func aesTransform ( dst [ ] byte , src [ ] byte , direction directionConst , bc cipher . Block ) { // (defined in the constants DirectionEncrypt and DirectionDecrypt). func Transform ( bc cipher . Block , T [ ] byte , P [ ] byte , direction directionConst ) ( C [ ] byte ) {", "del_tokens": "DirectionEncrypt = true DirectionDecrypt = false func aesTransform ( dst [ ] byte , src [ ] byte , direction bool , bc cipher . Block ) { } else { log . Panicf ( \" \" , direction ) // (defined in the constants directionEncrypt and directionDecrypt). func Transform ( bc cipher . Block , T [ ] byte , P [ ] byte , direction bool ) ( C [ ] byte ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "request", "address", "state", "bug"], "add_tokens": "return true , nil", "del_tokens": "yes := language . ExtractYesNo ( t . ctx . Msg . Input . Sentence ) if ! yes . Bool && yes . Valid { return true , nil }", "commit_type": "fix"}
{"commit_tokens": ["Removed", "parameterization", "from", "date", "part", "functions"], "add_tokens": "clauses : [ ] Clause { StringClause { part } , c . inner } ,", "del_tokens": "clauses : [ ] Clause { & Parameter { part } , c . inner } ,", "commit_type": "remove"}
{"commit_tokens": ["use", "correct", "port", "for", "wss"], "add_tokens": "// if host does not specify a port, use the default http port if ! strings . Contains ( host , \" \" ) { if outreq . URL . Scheme == \" \" { host = host + \" \" } else { host = host + \" \" } }", "del_tokens": "// if host does not specify a port, default to port 80 if ! strings . Contains ( host , \" \" ) { host = host + \" \" }", "commit_type": "use"}
{"commit_tokens": ["change", "NamedQuery", "and", "NamedExec", "from", "using", "maps", "to", "structs", "and", "retain", "old", "map", "based", "interface", "on", "NamedQueryMap", "and", "NamedExecMap", ".", "It", "would", "be", "trivial", "to", "write", "one", "function", "to", "do", "both", "but", "it", "would", "be", "equally", "trivial", "for", "other", "people", "to", "do", "this", "if", "they", "require", "it", ".", "I", "d", "rather", "not", "build", "an", "interface", "that", "layers", "reflection", "upon", "reflection", "for", "small", "conveniences"], "add_tokens": "\" \" // Bind a named parameter query with fields from a struct argument // Use of reflect here makes this func BindStruct ( bindType int , query string , arg interface { } ) ( string , [ ] interface { } , error ) { arglist := make ( [ ] interface { } , 0 , 5 ) t , err := BaseStructType ( reflect . TypeOf ( arg ) ) if err != nil { return \" \" , arglist , err } // resolve this type into a map of fields to field positions fm , err := getFieldmap ( t ) if err != nil { return \" \" , arglist , err } argmap := map [ string ] interface { } { } v := reflect . ValueOf ( arg ) for v = reflect . ValueOf ( arg ) ; v . Kind ( ) == reflect . Ptr ; { v = v . Elem ( ) } for key , val := range fm { argmap [ key ] = v . Field ( val ) . Interface ( ) } return BindMap ( bindType , query , argmap ) } } else if inName && ( unicode . IsLetter ( rune ( b ) ) || b == '_' ) && i != last {", "del_tokens": "} else if inName && unicode . IsLetter ( rune ( b ) ) && i != last {", "commit_type": "change"}
{"commit_tokens": ["Remove", "old", "variadic", "optional", "message", "from", "MatchEmail"], "add_tokens": "func ( v * Validator ) MatchEmail ( field string ) * ValidationResult {", "del_tokens": "func ( v * Validator ) MatchEmail ( field string , msg ... string ) * ValidationResult {", "commit_type": "remove"}
{"commit_tokens": ["Added", "public", "Listen", "to", "tcp_msg_ring", ".", "go"], "add_tokens": "func ( m * TCPMsgRing ) Listen ( ) error { node := m . ring . LocalNode ( ) tcpAddr , err := net . ResolveTCPAddr ( \" \" , node . Address ( m . AddressIndex ) )", "del_tokens": "// TODO: This should result in a public method for activating this TCPMsgRing; // which would involve listening on the address identified by the local node's // address according to AddressIndex, etc. func ( m * TCPMsgRing ) listen ( addr string ) error { tcpAddr , err := net . ResolveTCPAddr ( \" \" , addr )", "commit_type": "add"}
{"commit_tokens": ["fixed", "method", "for", "route", "update"], "add_tokens": "apps . PUT ( \" \" , handleRouteUpdate )", "del_tokens": "apps . POST ( \" \" , handleRouteUpdate )", "commit_type": "fix"}
{"commit_tokens": ["Add", "table", "-", "name", "option", "for", "custom", "table", "names"], "add_tokens": "Id int `json:\"id\" sql:\"auto-increment primary-key required table-name=renamed-post\"` assert . True ( t , DB . CheckIfTableExists ( \" \" ) )", "del_tokens": "Id int `json:\"id\" sql:\"auto-increment primary-key required\"` assert . True ( t , DB . CheckIfTableExists ( \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "when", "matching", "a", "proc", "with", "empty", "/", "proc", "/", "<pid", ">", "/", "cmdline", ".", "Fix", "concurrent", "map", "read", "/", "write", "when", "multiple", "scrapes", "overlap", "(", "fix", "is", "to", "serialize", "them", ")", "."], "add_tokens": "scrapeRequest struct { results chan <- prometheus . Metric done chan struct { } } scrapeChan chan scrapeRequest scrapeChan : make ( chan scrapeRequest ) , Grouper : proc . NewGrouper ( children , n ) , fs : fs , go p . start ( ) req := scrapeRequest { results : ch , done : make ( chan struct { } ) } p . scrapeChan <- req <- req . done } func ( p * NamedProcessCollector ) start ( ) { for req := range p . scrapeChan { ch := req . results p . scrape ( ch ) req . done <- struct { } { } } } func ( p * NamedProcessCollector ) scrape ( ch chan <- prometheus . Metric ) {", "del_tokens": "Grouper : proc . NewGrouper ( children , n ) , fs : fs ,", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "potential", "race", "condition", "setting", "context", "values"], "add_tokens": "import ( \" \" \" \" ) moot * sync . Mutex c . moot . Lock ( ) defer c . moot . Unlock ( ) moot : & sync . Mutex { } ,", "del_tokens": "import \" \"", "commit_type": "fix"}
{"commit_tokens": ["Make", "public", "for", "easier", "testing", "within", "glmenu", "."], "add_tokens": "text . Font = f text . Font = & Font { } text . Font . WindowWidth = 100 text . Font = & Font { }", "del_tokens": "text . font = f text . font = & Font { } text . font . WindowWidth = 100 text . font = & Font { }", "commit_type": "make"}
{"commit_tokens": ["Use", "strings", ".", "TrimFunc", "instead", "of", "strings", ".", "Trim", "."], "add_tokens": "func cutsetFunc ( r rune ) bool { // Characters to trim from prefixes/messages. return r == '\\r' || r == '\\n' || r == '\\x20' || r == '\\x00' } if raw = strings . TrimFunc ( raw , cutsetFunc ) ; len ( raw ) < 2 {", "del_tokens": "cutset string = \" \\r \\n \\x20 \\x00 \" // Characters to trim from prefixes/messages. if raw = strings . Trim ( raw , cutset ) ; len ( raw ) < 2 {", "commit_type": "use"}
{"commit_tokens": ["Remove", "charset", "for", "internal", "script"], "add_tokens": "assertHTML ( t , m , `<script language=\"x\" charset=\"x\" src=\"y\"></script>` , `<script src=y></script>` ) assertHTML ( t , m , `<a href=\"https://x\">y</a>` , `<a href=//x>y</a>` ) assertHTML ( t , m , `<a href=\"https://x\" rel=\"external\">y</a>` , `<a href=https://x rel=external>y</a>` )", "del_tokens": "assertHTML ( t , m , `<script language=\"x\" charset=\"x\" src=\"y\"></script>` , `<script src=\"y\"></script>` ) assertHTML ( t , m , `<a href=\"https://x\">y</a>` , `<a href=\"//x\">y</a>` ) assertHTML ( t , m , `<a href=\"https://x\" rel=\"external\">y</a>` , `<a href=\"https://x\" rel=\"external\">y</a>` )", "commit_type": "remove"}
{"commit_tokens": ["make", "default", "ClientAddressFinder", "more", "basic"], "add_tokens": "return r . RemoteAddr , nil", "del_tokens": "\" \" host , _ , err := net . SplitHostPort ( r . RemoteAddr ) if err != nil { return \" \" , err } return host , nil", "commit_type": "make"}
{"commit_tokens": ["allow", "for", "setting", "global", "normalization", "function"], "add_tokens": "// NormalizeTimeForMarshal NormalizeTimeForMarshal = func ( t time . Time ) time . Time { return t } return NormalizeTimeForMarshal ( time . Time ( t ) ) . Format ( MarshalFormat ) return json . Marshal ( NormalizeTimeForMarshal ( time . Time ( t ) ) . Format ( MarshalFormat ) ) i64 := NormalizeTimeForMarshal ( time . Time ( t ) ) . Unix ( ) * 1000 return NormalizeTimeForMarshal ( time . Time ( t ) ) . MarshalBinary ( )", "del_tokens": "return time . Time ( t ) . Format ( MarshalFormat ) return json . Marshal ( time . Time ( t ) . Format ( MarshalFormat ) ) i64 := time . Time ( t ) . Unix ( ) * 1000 return time . Time ( t ) . MarshalBinary ( )", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "a", "bug", "in", "Heapster", ".", "Updated", "sample", "cloud", "config", "for", "cadvisor", "."], "add_tokens": "Containers : make ( [ ] * Container , 0 ) , localContainer := newContainer ( ) localContainer . Name = container . Name localContainer . ID = pod . CurrentState . Info [ container . Name ] . ID", "del_tokens": "Containers : make ( [ ] Container , 0 ) , localContainer := Container { Name : container . Name , ID : pod . CurrentState . Info [ container . Name ] . ID , }", "commit_type": "fix"}
{"commit_tokens": ["Added", "useful", "tests", "on", "Task", "running", "+", "pipe", "hookups"], "add_tokens": "//FIXME: either give this proper environment vaariables, or remove env variables altogether fmt . Sprintf ( \" \" , os . Getenv ( \" \" ) ) , //FIXME: either give this proper environment vaariables, or remove env variables altogether fmt . Sprintf ( \" \" , os . Getenv ( \" \" ) ) , // FIXME - implement this properly fmt . Sprintf ( \" \" ) , // pipe := bytes.NewBufferString(\"\") // targetCmd.Stdout = pipe storeCmd . Stdin , _ = targetCmd . StdoutPipe ( ) targetCmd . Stdin , _ = storeCmd . StdoutPipe ( ) err := targetCmd . Start ( )", "del_tokens": "// FIXME: SHIELD_RESTORE_KEY ? input , output , err := os . Pipe ( ) if err != nil { return err } targetCmd . Stdout = input storeCmd . Stdin = output storeCmd . Stdout = input targetCmd . Stdin = output err = targetCmd . Start ( )", "commit_type": "add"}
{"commit_tokens": ["adding", "stroke", "to", "annotation", "measure", "."], "add_tokens": "r . SetStrokeWidth ( s . GetStrokeWidth ( ) )", "del_tokens": "r . SetStrokeWidth ( strokeWidth )", "commit_type": "add"}
{"commit_tokens": ["Add", "first", "games", "and", "bots"], "add_tokens": "import \" \" type Game interface { Run ( ) error Name ( ) string CheckArgs ( [ ] string ) error RegisterBot ( bots . Bot ) var RegisteredGames [ ] Game func RegisterGame ( game Game ) {", "del_tokens": "type Game struct { Name string var RegisteredGames [ ] * Game func RegisterGame ( game * Game ) { func NewGame ( name string ) * Game { return & Game { Name : name , } }", "commit_type": "add"}
{"commit_tokens": ["Make", "a", "couple", "minor", "changes", "to", "Backoff"], "add_tokens": "type Backoff func ( min , max time . Duration , attemptNum int , resp * http . Response ) time . Duration // Backoff specifies the policy for how long to wait between retries Backoff : DefaultBackoff , // DefaultBackoff provides a default callback for Client.Backoff which func DefaultBackoff ( min , max time . Duration , attemptNum int , resp * http . Response ) time . Duration { wait := c . Backoff ( c . RetryWaitMin , c . RetryWaitMax , i , resp )", "del_tokens": "type Backoff func ( min , max time . Duration , attemptNum int ) time . Duration // BackoffRetry specifies the policy for how long to wait between retries Backoff : DefaultBackoffPolicy , // DefaultBackoffPolicy provides a default callback for Client.Backoff which func DefaultBackoffPolicy ( min , max time . Duration , attemptNum int ) time . Duration { wait := c . Backoff ( c . RetryWaitMin , c . RetryWaitMax , i )", "commit_type": "make"}
{"commit_tokens": ["fix", "rare", "nil", "ptr", "panic"], "add_tokens": "if mp . slaveCmd != nil && mp . slaveCmd . Process != nil { if err := mp . slaveCmd . Process . Signal ( s ) ; err != nil { mp . debugf ( \" \" , err ) os . Exit ( 1 ) }", "del_tokens": "if err := mp . slaveCmd . Process . Signal ( s ) ; err != nil { mp . debugf ( \" \" , err ) os . Exit ( 1 )", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "default", "pilosaHost"], "add_tokens": "netCommand . Flags ( ) . StringVarP ( & net . PilosaHost , \" \" , \" \" , \" \" , \" \" )", "del_tokens": "netCommand . Flags ( ) . StringVarP ( & net . PilosaHost , \" \" , \" \" , \" \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["added", "linebreak", "before", ".", "TE", "(", "table", "end", ")"], "add_tokens": "tableEnd = \" \\n \\n \"", "del_tokens": "tableEnd = \" \\n \"", "commit_type": "add"}
{"commit_tokens": ["added", "api", "function", "BatchUnsubscribe", "to", "unsubscribe", "subscribers", "in", "bulk"], "add_tokens": "lists_subscribe_endpoint string = \" \" lists_unsubscribe_endpoint string = \" \" lists_list_endpoint string = \" \" lists_update_member_endpoint string = \" \" lists_members_endpoint string = \" \" lists_member_info_endpoint string = \" \" lists_batch_unsubscribe_endpoint string = \" \" func ( a * ChimpAPI ) BatchUnsubscribe ( req BatchUnsubscribe ) ( BatchResponse , error ) { var response BatchResponse req . ApiKey = a . Key err := parseChimpJson ( a , lists_batch_unsubscribe_endpoint , req , & response ) return response , err } type BatchUnsubscribe struct { ApiKey string `json:\"apikey\"` ListId string `json:\"id\"` Batch [ ] Email `json:\"batch\"` DeleteMember bool `json:\"delete_member\"` SendGoodbye bool `json:\"send_goodbye\"` SendNotify bool `json:\"send_notify\"` } type BatchResponse struct { Success int `json:\"success_count\"` ErrorCount int `json:\"error_count\"` BatchErrors [ ] BatchError `json:\"errors\"` } type BatchError struct { Emails Email `json:\"email\"` Code int `json:\"code\"` Error string `json:\"error\"` }", "del_tokens": "lists_subscribe_endpoint string = \" \" lists_unsubscribe_endpoint string = \" \" lists_list_endpoint string = \" \" lists_update_member_endpoint string = \" \" lists_members_endpoint string = \" \" lists_member_info_endpoint string = \" \"", "commit_type": "add"}
{"commit_tokens": ["fixes", "https", ":", "//", "github", ".", "com", "/", "gernest", "/", "mention", "/", "issues", "/", "5"], "add_tokens": "{ \" \" , [ ] string { \" \" } } , terminators := [ ] rune { ',' , '/' , '@' }", "del_tokens": "terminators := [ ] rune { ',' , '/' }", "commit_type": "fix"}
{"commit_tokens": ["implement", "rsh", "compatibilty", "flag", "(", "--", "rsh", ")"], "add_tokens": "var rsh = flag . Bool ( \" \" , false , \" \" , ) var rshLogin = flag . String ( \" \" , \" \" , \" \" , ) var rshTimeout = flag . String ( \" \" , \" \" , \" \" , ) var rsh4 = flag . Bool ( \" \" , false , \" \" , ) var rsh6 = flag . Bool ( \" \" , false , \" \" , ) var rshD = flag . Bool ( \" \" , false , \" \" , ) var rshN = flag . Bool ( \" \" , false , \" \" , ) args := flag . Args ( ) if * rsh { if * rshLogin != \" \" { user = rshLogin } args = args [ 1 : ] } Argv : args ,", "del_tokens": "Argv : flag . Args ( ) ,", "commit_type": "implement"}
{"commit_tokens": ["Added", "proper", "offset", "assignment", "for", "record", "metadata"], "add_tokens": "currentOffset := status . Offset Offset : currentOffset , currentOffset ++", "del_tokens": "Offset : status . Offset ,", "commit_type": "add"}
{"commit_tokens": ["make", "zero", "value", "hub", "usable"], "add_tokens": "if h . subscribers == nil { h . subscribers = make ( map [ int ] [ ] handler ) } var DefaultHub Hub", "del_tokens": "// New returns pointer to a new Hub. func New ( ) * Hub { return & Hub { subscribers : make ( map [ int ] [ ] handler ) } } var DefaultHub = New ( )", "commit_type": "make"}
{"commit_tokens": ["add", "DefaultDeploymentTimeout", "to", "client", "config"], "add_tokens": "timeout = client . config . DefaultDeploymentTimeout", "del_tokens": "timeout = time . Duration ( 300 ) * time . Second", "commit_type": "add"}
{"commit_tokens": ["add", "a", "time", ".", "Time", "field", "to", "test"], "add_tokens": "\" \" email text , added_at timestamp default now ( ) AddedAt time . Time `db:\"added_at\"` reflect . TypeOf ( new ( Person ) ) : { \" \" : 0 , \" \" : 1 , \" \" : 2 , \" \" : 3 } , \" \" : 0 , \" \" : 1 , \" \" : 2 , \" \" : 3 , \" \" : 4 , \" \" : 5 , \" \" : 6 } ,", "del_tokens": "email text reflect . TypeOf ( new ( Person ) ) : { \" \" : 0 , \" \" : 1 , \" \" : 2 } , \" \" : 0 , \" \" : 1 , \" \" : 2 , \" \" : 3 , \" \" : 4 , \" \" : 5 } ,", "commit_type": "add"}
{"commit_tokens": ["remove", "deprecated", "log", ".", "Warning", "(", "f", ")"], "add_tokens": "log . Warnf ( \" \" , err . Error ( ) ) log . Warnf ( \" \" , len ( b ) ) log . Warnf ( \" \" ) log . Warnf ( \" \" , err . Error ( ) )", "del_tokens": "log . Warningf ( \" \" , err . Error ( ) ) log . Warningf ( \" \" , len ( b ) ) log . Warningf ( \" \" ) log . Warningf ( \" \" , err . Error ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Added", "potentially", "buggy", "softmax", "regression", ".", "No", "tests", "yet"], "add_tokens": "// []float64 to come as either a 0 or a 1, and err = fmt . Errorf ( \" \" )", "del_tokens": "// []float64 to come as either a 0 or a 1, and err = fmt . Errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Update", "and", "fix", "go", ".", "mod"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["fixed", "the", "custom", "parser", "and", "added", "logging", "to", "aiffinfo"], "add_tokens": "\" \" // SSND chunk is the sound chunk // Chunk specs: // http://www.onicos.com/staff/iz/formats/aiff.html // AFAn seems to be an OS X specific chunk, meaning & format TBD Wg * sync . WaitGroup ch . Wg . Done ( )", "del_tokens": "ch . okChan <- true", "commit_type": "fix"}
{"commit_tokens": ["Add", "time", "bounds", "to", "the", "where", "clauses", "."], "add_tokens": "// ItemPredicate represents a BadWolf predicates in BQL. // ItemPredicateBound represents a BadWolf predicate bound in BQL. ItemPredicateBound case ItemPredicateBound : return \" \" var ( nr rune commas = 0 ) nr = l . next ( ) if nr == comma { commas ++ } if nr == rightSquarePar || nr == eof { if commas > 1 { l . emitError ( \" \" ) return nil } if commas == 0 { l . emit ( ItemPredicate ) } else { l . emit ( ItemPredicateBound ) }", "del_tokens": "// ItemPredicate represents a BadWolf presicates in BQL. var nr rune if nr = l . next ( ) ; nr == rightSquarePar || nr == eof { l . emit ( ItemPredicate )", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "in", "Stats", "when", "there", "are", "nil", "failed", "or", "processed", "jobs"], "add_tokens": "if results [ 0 ] != nil { stats . Processed , _ = strconv . Atoi ( string ( results [ 0 ] . ( [ ] byte ) ) ) } if results [ 1 ] != nil { stats . Failed , _ = strconv . Atoi ( string ( results [ 1 ] . ( [ ] byte ) ) ) }", "del_tokens": "stats . Processed , _ = strconv . Atoi ( string ( results [ 0 ] . ( [ ] byte ) ) ) stats . Failed , _ = strconv . Atoi ( string ( results [ 1 ] . ( [ ] byte ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Change", "print", "function", "in", "tests"], "add_tokens": "// Usefull for debugging on Linux: pidstat -tu -C '<pid-name>' 1 // TODO case timeout, returns error. // TODO has a non blocking version a sense (API semplification, performance etc.)? Es: // When using RunBlocking one must wait that all tasks are done // and put separate results togherther in the end. RunNonBlocking avoids that. // func RunNonBlocking(jobs <-chan Tasker) (results chan<- Resulter) { //code //code // Comunicate to callers that we are done. // close(results) //}", "del_tokens": "// TODO has a non blocking version a sense (API semplification, performance etc.)? Es: // RunNonBlocking(jobs <-chan Tasker, results chan<- Tasker) {} // TODO case timeout, returns error.", "commit_type": "change"}
{"commit_tokens": ["fix", "output", "method", "for", "kubicorn", "create"], "add_tokens": "logger . Always ( \" \" , options . StateStorePath , name , name )", "del_tokens": "fmt . Printf ( options . StateStorePath + \" \" + name + \" \" + \" \\n \\n \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "real", "error", "in", "call", "result"], "add_tokens": "Error error func ( c * Client ) Call ( procURI string , args ... interface { } ) chan CallResult { // Channel size must be 1 to avoid blocking if no one is receiving the channel later. resultCh := make ( chan CallResult , 1 ) r := CallResult { Result : nil , Error : fmt . Errorf ( \" \" , err ) , } resultCh <- r return resultCh c . messages <- string ( msg ) return resultCh Error : nil ,", "del_tokens": "Error RPCError func ( c * Client ) Call ( procURI string , args ... interface { } ) ( chan CallResult , error ) { return nil , fmt . Errorf ( \" \" , err ) c . messages <- string ( msg ) // Channel size must be 1 to avoid blocking if no one is receiving the channel later. resultCh := make ( chan CallResult , 1 ) return resultCh , nil", "commit_type": "use"}
{"commit_tokens": ["update", "the", "Learn", "()", "message", "for", "logistic", "regression"], "add_tokens": "fmt . Printf ( \" \\n \\t \\n \\t \\n \\t \\n \\t \\n \\t n\\ tR .. \\n \", e amples, l n(l . t r ainingSet[0 ] ) , l a l pha, l r e gularization)", "del_tokens": "fmt . Printf ( \" \\n \\t \\n \\t \\n \\t \\n \\t \\n \\t n\\ tR .. \\n \", e amples, l n(l . t r ainingSet[0 ] ) , l a l pha, l r e gularization)", "commit_type": "update"}
{"commit_tokens": ["Remove", "the", "wrapper", "for", "registry", "errors"], "add_tokens": "return nil , err return nil , err", "del_tokens": "// Error wraps a registry error. type Error struct { * dockerregistry . RegistryError } func mkError ( registryError error ) error { return Error { registryError . ( * dockerregistry . RegistryError ) } } return nil , mkError ( err ) return nil , mkError ( err )", "commit_type": "remove"}
{"commit_tokens": ["Update", "workfakedata", "for", "enqueue", "maps"], "add_tokens": "\" \" \" \" \" \" type Context struct { } go func ( ) { conn . Do ( \" \" , * redisNamespace + \" \" , \" \" ) en . Enqueue ( \" \" , work . Q { \" \" : i } ) time . Sleep ( 1 * time . Second ) wp := work . NewWorkerPool ( Context { } , 5 , * redisNamespace , pool ) select { } }", "del_tokens": "\" \" \" \" \" \" go func ( ) { conn . Do ( \" \" , * redisNamespace + \" \" , \" \" ) en . Enqueue ( \" \" , i ) time . Sleep ( 1 * time . Second ) wp := work . NewWorkerPool ( \" \" , 5 , * redisNamespace , pool ) select { } }", "commit_type": "update"}
{"commit_tokens": ["using", "Time", "for", "WorklogRecord", ".", "Started"], "add_tokens": "Started Time `json:\"started\"`", "del_tokens": "Started string `json:\"started\"`", "commit_type": "use"}
{"commit_tokens": ["remove", "return", "value", "names", "from", "TextMessage", ".", "writeTo"], "add_tokens": "func ( pm * TextMessage ) WriteTo ( w io . Writer ) ( int64 , error ) {", "del_tokens": "func ( pm * TextMessage ) WriteTo ( w io . Writer ) ( n int64 , err error ) {", "commit_type": "remove"}
{"commit_tokens": ["adds", "option", "to", "print", "output", "of", "notify", "command"], "add_tokens": "notifyOutput bool NotifyOutput bool } if config . NotifyOutput { for _ , line := range strings . Split ( string ( out ) , \" \\n \" ) { if line != \" \" { log . Printf ( \" \" , config . NotifyCmd , line ) } } flag . BoolVar ( & notifyOutput , \" \" , false , \" \" ) NotifyOutput : notifyOutput ,", "del_tokens": "log . Print ( string ( out ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "initial", "support", "for", "reading", "pw", "protected", "files", "."], "add_tokens": "zip64ExtraId = 0x0001 // zip64 Extended Information Extra Field winzipAesExtraId = 0x9901 // winzip AES Extra Field // AES key lengths aes128 = 16 aes192 = 24 aes256 = 32", "del_tokens": "zip64ExtraId = 0x0001 // zip64 Extended Information Extra Field", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "lookup", "of", "VNID", "for", "TearDownPod"], "add_tokens": "// The script's teardown functionality doesn't need the VNID out , err := utilexec . New ( ) . Command ( plugin . getExecutable ( ) , tearDownCmd , namespace , name , string ( id ) , \" \" ) . CombinedOutput ( )", "del_tokens": "vnid , found := plugin . OvsController . VNIDMap [ namespace ] if ! found { return fmt . Errorf ( \" \" , namespace ) } out , err := utilexec . New ( ) . Command ( plugin . getExecutable ( ) , tearDownCmd , namespace , name , string ( id ) , strconv . FormatUint ( uint64 ( vnid ) , 10 ) ) . CombinedOutput ( )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "a", "few", "small", "issues"], "add_tokens": "headerName := \" \" + kind + \" \" header := r . Header . Get ( headerName ) if header == \" \" { header = kind } l . Publish ( header , logLevel , string ( body ) )", "del_tokens": "l . Publish ( kind , logLevel , string ( body ) )", "commit_type": "fix"}
{"commit_tokens": ["Move", "Version", "into", "AgObject", "interface"], "add_tokens": "s , err := engine . Sign ( * sigKP , append ( [ ] byte ( strconv . Itoa ( body . Version ( ) ) ) , b ... ) ) id , err := NewID ( body , & sig )", "del_tokens": "s , err := engine . Sign ( * sigKP , append ( [ ] byte ( strconv . Itoa ( 1 ) ) , b ... ) ) id , err := NewID ( 1 , body , & sig )", "commit_type": "move"}
{"commit_tokens": ["Change", "select", "case", "order", "in", "leaderLoop", "to", "prioritize", "messages"], "add_tokens": "case rpc := <- r . rpcCh : switch cmd := rpc . Command . ( type ) { case * AppendEntriesRequest : transition = r . appendEntries ( rpc , cmd ) case * RequestVoteRequest : transition = r . requestVote ( rpc , cmd ) default : log . Printf ( \" \" , rpc . Command ) rpc . Respond ( nil , fmt . Errorf ( \" \" ) ) } case commitLog := <- commitCh : // Increment the commit index idx := commitLog . log . Index r . setCommitIndex ( idx ) // Trigger applying logs locally r . commitCh <- commitTuple { idx , commitLog }", "del_tokens": "case commitLog := <- commitCh : // Increment the commit index idx := commitLog . log . Index r . setCommitIndex ( idx ) // Trigger applying logs locally r . commitCh <- commitTuple { idx , commitLog } case rpc := <- r . rpcCh : switch cmd := rpc . Command . ( type ) { case * AppendEntriesRequest : transition = r . appendEntries ( rpc , cmd ) case * RequestVoteRequest : transition = r . requestVote ( rpc , cmd ) default : log . Printf ( \" \" , rpc . Command ) rpc . Respond ( nil , fmt . Errorf ( \" \" ) ) }", "commit_type": "change"}
{"commit_tokens": ["Updated", "JIRA", "API", "doc", "links"], "add_tokens": "// JIRA API docs: https://docs.atlassian.com/jira/REST/latest/#auth/1/session // See https://docs.atlassian.com/jira/REST/latest/#auth/1/session // See https://docs.atlassian.com/jira/REST/latest/#auth/1/session", "del_tokens": "// JIRA API docs: https://docs.atlassian.com/jira/REST/latest/#d2e459 // See https://docs.atlassian.com/jira/REST/latest/#d2e456 // https://docs.atlassian.com/jira/REST/latest/#d2e456", "commit_type": "update"}
{"commit_tokens": ["add", "Contents", "()", "and", "Children", "()", "with", "tests", "."], "add_tokens": "// TODO : Test End() on all filtering/expanding/array/traversal functions, make // sure it returns the same object as the previous selection. // x Contents() // x Html()", "del_tokens": "// - Contents() (similar to Children(), but includes text and comment nodes, so Children() should filter them out) - Misc. Traversing // - Html() ? - Attributes // - Val() ? - Attributes", "commit_type": "add"}
{"commit_tokens": ["Use", "NewURL", "()", "instead", "of", "raw", "url", ".", "Parse", "()", "."], "add_tokens": "url , err := NewURL ( argURL )", "del_tokens": "url , err := url . Parse ( argURL )", "commit_type": "use"}
{"commit_tokens": ["Removed", "dagger", "broadcasting", "to", "the", "net"], "add_tokens": "log . Println ( \" \" , res ) //server.Broadcast(\"blockmine\", ethutil.Encode(res.String()))", "del_tokens": "server . Broadcast ( \" \" , ethutil . Encode ( res . String ( ) ) )", "commit_type": "remove"}
{"commit_tokens": ["Allow", "for", "GC", "of", "cache", "when", "CleanWindow", "is", "set"], "add_tokens": "close chan struct { } close : make ( chan struct { } ) , ticker := time . NewTicker ( config . CleanWindow ) defer ticker . Stop ( ) for { select { case t := <- ticker . C : cache . cleanUp ( uint64 ( t . Unix ( ) ) ) case <- cache . close : return } // Close is used to signal a shutdown of the cache when you are done with it. // This allows the cleaning goroutines to exit and ensures references are not // kept to the cache preventing GC of the entire cache. func ( c * BigCache ) Close ( ) error { close ( c . close ) return nil }", "del_tokens": "for t := range time . Tick ( config . CleanWindow ) { cache . cleanUp ( uint64 ( t . Unix ( ) ) )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "panic", "on", "leave", "of", "host", "driver", "endpont", "leave"], "add_tokens": "type sandboxTable map [ string ] * sandboxData sData = & sandboxData { sandbox : sb , refCnt : 1 }", "del_tokens": "type sandboxTable map [ string ] sandboxData sData = sandboxData { sandbox : sb , refCnt : 1 }", "commit_type": "fix"}
{"commit_tokens": ["add", "string", "-", "like", "encoding", "for", "[]", "byte"], "add_tokens": "// handle byte slices like strings if byteSlice , ok := val . Interface ( ) . ( [ ] byte ) ; ok { _ , err := fmt . Fprintf ( w , \" \" , len ( byteSlice ) ) if err == nil { _ , err = w . Write ( byteSlice ) } return err } specified in the struct field 's tag value . The \" \" key in struct field 's tag value is the key name , followed by an optional comma and options .", "del_tokens": "specified in the struct field 's tag value . The \" \" key in struct field 's tag value is the key name , followed by an optional comma and options .", "commit_type": "add"}
{"commit_tokens": ["Fix", "deadlock", "in", "ErrorPercent", "method", "where", "mutex", "is", "RLocked", "twice", "and", "in", "between", "another", "goroutine", "Locks", "on", "same", "mutex", "."], "add_tokens": "reqs := m . DefaultCollector ( ) . NumRequests . Sum ( now )", "del_tokens": "reqs := m . Requests ( ) . Sum ( now )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Signature", ".", "Values", "for", "arrays", "of", "complex", "types"], "add_tokens": "t = reflect . SliceOf ( value ( s [ 1 : ] ) )", "del_tokens": "} else if s [ 1 ] == '(' { t = interfacesType t = reflect . SliceOf ( sigToType [ s [ 1 ] ] )", "commit_type": "fix"}
{"commit_tokens": ["Uses", "fixed", "timezone", "in", "tests", "fixes", "failing", "build"], "add_tokens": "date := time . Date ( 2009 , time . November , 10 , 23 , 0 , 0 , 0 , time . UTC ) if cmd != \" \\\\ \\\\ \\\" \\\" \" {", "del_tokens": "date := time . Unix ( 1462292515 , 0 ) if cmd != \" \\\\ \\\\ \\\" \\\" \" {", "commit_type": "use"}
{"commit_tokens": ["Remove", "New", "*", "Widget", "functions", "(", "initially", ")", "added", "support", "for", "Screenboards", "and", "Widgets", "plus", "tests", "are", "awesome", "as", "it", "is", ".", "Update", "tests", ".", "Test", "pass", ":"], "add_tokens": "Default string `json:\"default\"` Name string `json:\"name\"` Prefix string `json:\"prefix\"` TimeseriesWidget TimeseriesWidget `json:\"timeseries\"` QueryValueWidget QueryValueWidget `json:\"query_value\"` EventStreamWidget EventStreamWidget `json:\"event_stream\"` FreeTextWidget FreeTextWidget `json:\"free_text\"` ToplistWidget ToplistWidget `json:\"toplist\"` ImageWidget ImageWidget `json:\"image`", "del_tokens": "Default string `json:\"default\"` Name string `json:\"name\"` Prefix string `json:\"prefix\"` TimeseriesWidget string `json:\"timeseries\"` QueryValueWidget string `json:\"query_value\"` EventStreamWidget string `json:\"event_stream\"` FreeTextWidget string `json:\"free_text\"` ToplistWidget string `json:\"toplist\"` ImageWidget string `json:\"image`", "commit_type": "remove"}
{"commit_tokens": ["make", "new", "option", "for", "clearing", "on", "finish"], "add_tokens": "// clear bar once finished clearOnFinish bool // OptionClearOnFinish will clear the bar once its finished func OptionClearOnFinish ( ) Option { return func ( p * ProgressBar ) { p . config . clearOnFinish = true } } // check if the progress bar is finished if p . config . clearOnFinish { // if the progressbar is finished, return return nil }", "del_tokens": "// if the progressbar is finished, return return nil", "commit_type": "make"}
{"commit_tokens": ["fix", "heuristic", "based", "expiration", "times"], "add_tokens": "w . Header ( ) . Set ( \" \" , time . Now ( ) . UTC ( ) . Add ( time . Duration ( time . Hour * - 5 ) ) . Format ( http . TimeFormat ) ) require . WithinDuration ( t , time . Now ( ) . UTC ( ) . Add ( time . Duration ( float64 ( time . Hour ) * 0.5 ) ) , expires , 10 * time . Second )", "del_tokens": "require . Equal ( t , time . Time { } , expires )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "struct", "-", "based", "facility", "to", "add", "options", "and", "arguments"], "add_tokens": "optionsIdx : map [ string ] * opt { } ,", "del_tokens": "optionsIdx : map [ string ] * option { } ,", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "test", "and", "example", "code"], "add_tokens": "err = list . Remove ( ) t . Errorf ( \" \" , err )", "del_tokens": "err = list . DelAll ( ) t . Errorf ( \" \" , err )", "commit_type": "update"}
{"commit_tokens": ["Use", "constants", "and", "fixed", "array", "http", "methods"], "add_tokens": "const ( var allowedHttpMethods = [ ... ] string { GET , HEAD , POST , PUT , DELETE , TRACE , OPTIONS , CONNECT , PATCH }", "del_tokens": "var ( var allowedHttpMethods = [ ] string { GET , HEAD , POST , PUT , DELETE , TRACE , OPTIONS , CONNECT , PATCH }", "commit_type": "use"}
{"commit_tokens": ["Fix", "variable", "expansion", "in", "repeat", "one", "liner"], "add_tokens": "if cname != \" \" && cname != \" \" { // XXX: don't expand one-line body of \"function\" or \"repeat\"", "del_tokens": "if cname != \" \" { // XXX: don't expand one-line body of \"function\"", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "bug", "(", "oops", ")"], "add_tokens": "\" \" var out uint32 err = binary . Read ( buf , binary . BigEndian , & out ) fmt . Printf ( \" \" , out ) return int64 ( out + 0x200000 )", "del_tokens": "var out int64 err = binary . Read ( buf , binary . LittleEndian , & out ) return out + 0x200000", "commit_type": "fix"}
{"commit_tokens": ["Remove", "markdown", "from", "doc", ".", "go"], "add_tokens": "Colors provides a simple way to print colored messages to the console . appropriate colors on supported terminals .", "del_tokens": "# colors Simple go ANSI colors library # Usage appropriate colors on supported terminals .", "commit_type": "remove"}
{"commit_tokens": ["Add", "hk", "destroy", "and", "errors", "compatibility"], "add_tokens": "type Deleter interface { // Delete deletes one or more records Delete ( ... interface { } ) ( int64 , error ) } Deleter db . AddTableWithName ( App { } , \" \" ) . SetKeys ( false , \" \" )", "del_tokens": "db . AddTableWithName ( App { } , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Implement", "get", "build", "and", "project", "APIs"], "add_tokens": "Id int64 `orm:\"pk;auto\"` func GetAllBuilds ( ) [ ] * Build { o := orm . NewOrm ( ) var builds [ ] * Build // o.QueryTable(\"build\").Filter(\"name\", \"slene\").All(&builds) to filter with build status num , err := o . QueryTable ( \" \" ) . All ( & builds ) fmt . Printf ( \" \" , num , err ) return builds } func GetBuildWithId ( buildId int64 ) Build { o := orm . NewOrm ( ) build := Build { Id : buildId } err := o . Read ( & build ) fmt . Printf ( \" \\n \" , err ) return build } func GetProjectWithId ( projectId int64 ) Project { project := Project { Id : projectId } err := o . Read ( & project ) fmt . Printf ( \" \\n \" , err ) return project", "del_tokens": "Id int64 `orm:\"auto\"` func GetAllBuilds ( ) [ ] * Build { var builds [ ] * Build // o.QueryTable(\"build\").Filter(\"name\", \"slene\").All(&builds) to filter with build status num , err := o . QueryTable ( \" \" ) . All ( & builds ) fmt . Printf ( \" \" , num , err ) return builds", "commit_type": "implement"}
{"commit_tokens": ["fix", "bug", "in", "redis", "store"], "add_tokens": "t . LastUsed = time . Unix ( tsi , 0 ) . UTC ( )", "del_tokens": "time . Unix ( tsi , 0 ) . UTC ( )", "commit_type": "fix"}
{"commit_tokens": ["fix", "absent", "context", "for", "method", "without", "params"], "add_tokens": "if x , ok := x . ( WithContext ) ; ok { x . SetContext ( c . ctx ) }", "del_tokens": "if x , ok := x . ( WithContext ) ; ok { x . SetContext ( c . ctx ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "and", "update", "for", "create", "server", "tests"], "add_tokens": "func get_random_datacenterID ( ) string { rand . Seed ( time . Now ( ) . UnixNano ( ) ) dcs , _ := api . ListDatacenters ( ) if len ( dcs ) > 0 { i := rand . Intn ( len ( dcs ) ) return dcs [ i ] . Id } return \" \" } if saps [ i ] . MinHddSize <= max_disk_size && saps [ i ] . Type == \" \" || saps [ i ] . Type == \" \" { if fl . Name == \" \" { DatacenterId : get_random_datacenterID ( ) , Name : \" \" , ApplianceId : sap . Id ,", "del_tokens": "if saps [ i ] . IsAutomaticInstall && saps [ i ] . MinHddSize <= max_disk_size && saps [ i ] . Type == \" \" { if fl . Name == \" \" { Name : \" \" , ApplianceId : sap . Id ,", "commit_type": "fix"}
{"commit_tokens": ["Improve", "the", "way", "the", "new", "canvas", "size", "is", "calculated"], "add_tokens": "resizedImg := image . NewRGBA64 ( image . Rect ( 0 , 0 , int ( 0.7 + oldWidth / scaleX ) , int ( 0.7 + oldHeight / scaleY ) ) )", "del_tokens": "resizedImg := image . NewRGBA64 ( image . Rect ( 0 , 0 , int ( oldWidth / scaleX ) , int ( oldHeight / scaleY ) ) )", "commit_type": "improve"}
{"commit_tokens": ["Added", "Errs", "method", "with", "multiError", "handling"], "add_tokens": "// After exiting the loop where you are using Throttler, you can call the `Err` or `Errs` method to check // for errors. `Err` will return a single error representative of all the errors Throttler caught. The // `Errs` method will return all the errors as a slice of errors (`[]error`). // See a fully functional example on the playground at http://bit.ly/throttler-v3 import ( \" \" \" \" ) // Err returns an error representative of all errors caught by throttler func ( t * Throttler ) Err ( ) error { if len ( t . errs ) == 0 { return nil } return multiError ( t . errs ) } // Errs returns a slice of any errors that were received from calling Done() func ( t * Throttler ) Errs ( ) [ ] error { type multiError [ ] error func ( te multiError ) Error ( ) string { errString := te [ 0 ] . Error ( ) if len ( te ) > 1 { errString += fmt . Sprintf ( \" \" , len ( te ) - 1 ) } return errString }", "del_tokens": "// After exiting the loop where you are using Throttler, you can call the .Err method to get // an array of all the goroutine errors that occurred. // See a fully functional example on the playground at http://bit.ly/throttler-docs-v2 import \" \" // Err returns a slice of any errors that were received from calling Done() func ( t * Throttler ) Err ( ) [ ] error {", "commit_type": "add"}
{"commit_tokens": ["Added", "useful", "method", "to", "get", "information", "about", "layers", "in", "the", "subgraph", "and", "apply"], "add_tokens": "ParallelRecursivelyApply ( fn func ( node INode ) ) RecursivelyApply ( fn func ( node INode ) ) // Circulars returns the circulars that are part of this execution graph. Circulars ( ) Nodes // NumLayers returns the number of layers in this graph. NumLayers ( ) uint64 // Layer returns the layer at the specified index. If the index // is out of bounds, an error is returned. Layer ( index uint64 ) ( Nodes , error ) // ParallelApplyLayer will (in parallel) apply the provided function // to the nodes at the given index. Returns an error if nodes // do not exist at the given index. ParallelApplyLayer ( index uint64 , fn func ( INode ) ) error", "del_tokens": "ParallelRecursivelyApply ( fn func ( node INode ) bool ) RecursivelyApply ( fn func ( node INode ) bool )", "commit_type": "add"}
{"commit_tokens": ["update", "customer", "card", "passing", "logic", "as", "well"], "add_tokens": "if len ( params . Card . Token ) > 0 { body . Add ( \" \" , params . Card . Token ) } else { params . Card . appendTo ( body , true ) }", "del_tokens": "params . Card . appendTo ( body , true )", "commit_type": "update"}
{"commit_tokens": ["make", "Import", "()", "call", "Db", ".", "Exec", "()", "directly"], "add_tokens": "defer session . Close ( ) err = session . newDb ( ) if err != nil { return results , err } result , err := session . Db . Exec ( query )", "del_tokens": "session . IsAutoClose = false result , err := session . Exec ( query ) session . Close ( )", "commit_type": "make"}
{"commit_tokens": ["Add", "optional", "parametter", "for", "GetObject"], "add_tokens": "func ( i * Index ) GetObject ( objectID string , attribute ... string ) ( interface { } , error ) { v := url . Values { } if len ( attribute ) > 0 { v . Add ( \" \" , attribute [ 0 ] ) } return i . client . transport . request ( \" \" , \" \" + i . nameEncoded + \" \" + i . client . transport . urlEncode ( objectID ) + \" \" + v . Encode ( ) , nil )", "del_tokens": "func ( i * Index ) GetObject ( objectID string ) ( interface { } , error ) { return i . client . transport . request ( \" \" , \" \" + i . nameEncoded + \" \" + i . client . transport . urlEncode ( objectID ) , nil )", "commit_type": "add"}
{"commit_tokens": ["Add", "Comments", "to", "WorkItem", "API"], "add_tokens": "import ( \" \" \" \" ) func ( db * MockDB ) WorkItemComments ( ) comment . Repository { return nil }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["add", "models", "/", "doc", ".", "go"], "add_tokens": "// Package api implements the BOSH API client functions", "del_tokens": "/ * Package api implements the BOSH API client functions * /", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "ListChains", "method", "."], "add_tokens": "func contains ( list [ ] string , value string ) bool { for _ , val := range list { if val == value { return true } } return false } // Saving the list of chains before executing tests originaListChain , err := ipt . ListChains ( \" \" ) if err != nil { t . Fatalf ( \" \" , err ) } err = ipt . ClearChain ( \" \" , chain ) // chain should be in listChain listChain , err := ipt . ListChains ( \" \" ) if err != nil { t . Fatalf ( \" \" , err ) } if ! contains ( listChain , chain ) { t . Fatalf ( \" \" , chain ) } // check that chain is fully gone and that state similar to initial one listChain , err = ipt . ListChains ( \" \" ) if err != nil { t . Fatalf ( \" \" , err ) } if ! reflect . DeepEqual ( originaListChain , listChain ) { t . Fatalf ( \" \\n \\n \" , originaListChain , listChain ) }", "del_tokens": "err := ipt . ClearChain ( \" \" , chain )", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "calls", "to", "Dependency", ".", "String"], "add_tokens": "if reqs := p . Requires ( ) ; len ( reqs ) > 0 { printDeps ( t , p , \" \" , reqs ) } else { if provs := p . Provides ( ) ; len ( provs ) > 0 { printDeps ( t , p , \" \" , provs ) } else { printDeps ( t , p , \" \" , p . Conflicts ( ) ) printDeps ( t , p , \" \" , p . Obsoletes ( ) ) } } func printDeps ( t * testing . T , p * PackageFile , typ string , deps Dependencies ) { for _ , dep := range deps { t . Logf ( \" \" , p , typ , dep )", "del_tokens": "if reqs := p . Requires ( ) ; len ( reqs ) == 0 { if provs := p . Provides ( ) ; len ( provs ) == 0 { p . Conflicts ( ) p . Obsoletes ( )", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "references", "to", "register", "through", "login"], "add_tokens": "{ \" \" , \" \" } ,", "del_tokens": "{ \" \" , \" \" } ,", "commit_type": "remove"}
{"commit_tokens": ["Adds", "compile", "blacklist", "and", "enforce", "flag", "for", "compile"], "add_tokens": "// TODO: test when compiler is done settings := SeccompSettings { } settings . defaultPositiveAction = \" \" if enforce { settings . defaultNegativeAction = \" \" } else { settings . defaultNegativeAction = \" \" } return Prepare ( path , settings ) // TODO: test when compiler is done settings := SeccompSettings { } settings . defaultNegativeAction = \" \" if enforce { settings . defaultPositiveAction = \" \" } else { settings . defaultPositiveAction = \" \" } return Prepare ( path , settings )", "del_tokens": "// TODO: test once compiler is done, light testing needed, since main testing // will be of the Prepare method return nil , nil // TODO: test once compiler is done, light testing needed, since main testing // will be of the Prepare method return nil , nil", "commit_type": "add"}
{"commit_tokens": ["add", "a", "test", "example", "and", "debug"], "add_tokens": "\" \" if len ( req . URL . Path ) == len ( r . Path ) && req . URL . Path [ : len ( r . Path ) ] == r . Path { r . handler . ServeHTTP ( rw , req ) return } else if fileExt ( req . URL . Path ) { func fileExt ( s string ) bool { parts := strings . Split ( s , \" \" ) if strings . Contains ( parts [ len ( parts ) - 1 ] , \" \" ) { return true } return false }", "del_tokens": "if len ( req . URL . Path ) >= len ( r . Path ) && req . URL . Path [ : len ( r . Path ) ] == r . Path {", "commit_type": "add"}
{"commit_tokens": ["Add", "file", "name", "flag", "file", "and", "function", "name", "flag", "fnname", "."], "add_tokens": "var inputFile = flag . String ( \" \" , \" \" , \" \" ) var fnname = flag . String ( \" \" , \" \" , \" \" ) if * inputFile != \" \" { file = * inputFile if fn := pkg . Func ( * fnname ) ; fn == nil { log . Fatalf ( msg , fnname , filePkgName ) log . Fatalf ( msg , filePkgName , fnname ) log . Fatalf ( msg , fnname , filePkgName )", "del_tokens": "args := flag . Args ( ) funcName := \" \" if len ( args ) == 1 { funcName = args [ 0 ] } else if len ( args ) == 2 { file = args [ 0 ] funcName = args [ 1 ] if fn := pkg . Func ( funcName ) ; fn == nil { log . Fatalf ( msg , funcName , filePkgName ) log . Fatalf ( msg , filePkgName , funcName ) log . Fatalf ( msg , funcName , filePkgName )", "commit_type": "add"}
{"commit_tokens": ["Add", "list", "webhooks", "method", "."], "add_tokens": "It ( \" \" , func ( ) { By ( \" \" ) webhooks , err := client . WebhooksForListID ( newList . ID ) Expect ( err ) . NotTo ( HaveOccurred ( ) ) Expect ( len ( webhooks ) ) . To ( BeZero ( ) ) By ( \" \" ) Eventually ( func ( ) ( bool , error ) { webhooks , err := client . WebhooksForListID ( newList . ID ) return webhooksContain ( webhooks , newWebhook ) , err } ) . Should ( BeTrue ( ) ) By ( \" \" ) By ( \" \" ) Eventually ( func ( ) ( bool , error ) { webhooks , err := client . WebhooksForListID ( newList . ID ) return webhooksContain ( webhooks , newWebhook ) , err } ) . Should ( BeFalse ( ) ) func webhooksContain ( webhooks [ ] wundergo . Webhook , webhook wundergo . Webhook ) bool { for _ , w := range webhooks { if w . ID == webhook . ID { return true } } return false }", "del_tokens": "It ( \" \" , func ( ) { By ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "Docker", "Credentials", "label", "support", "for", "macOS"], "add_tokens": "label := C . CString ( creds . Label ) defer C . free ( unsafe . Pointer ( label ) ) errMsg := C . keychain_add ( s , label , username , secret ) func ( h Osxkeychain ) List ( credsLabel string ) ( map [ string ] string , error ) { credsLabelC := C . CString ( credsLabel ) defer C . free ( unsafe . Pointer ( credsLabelC ) ) errMsg := C . keychain_list ( credsLabelC , & pathsC , & acctsC , & listLenC )", "del_tokens": "errMsg := C . keychain_add ( s , username , secret ) func ( h Osxkeychain ) List ( ) ( map [ string ] string , error ) { errMsg := C . keychain_list ( & pathsC , & acctsC , & listLenC )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "shadowed", "err", "variable", "."], "add_tokens": "var lineBytes [ ] byte lineBytes , err = buf . ReadBytes ( '\\n' )", "del_tokens": "lineBytes , err := buf . ReadBytes ( '\\n' )", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "logs", "to", "the", "producer"], "add_tokens": "if err != nil { log . Printf ( \" \" , p . address , err ) } log . Printf ( \" \" , p . address ) log . Printf ( \" \" , p . address , err )", "del_tokens": "log . Printf ( \" \" , p . address , err )", "commit_type": "add"}
{"commit_tokens": ["Remove", "distinction", "between", "returnable", "stale", "responses", "and", "fresh", "ones"], "add_tokens": "if freshness == fresh { // but that seems like a hassle, and is it actually useful? If so, then there needs to be a different // return-value available here. return fresh return fresh", "del_tokens": "asFresh if freshness == fresh || freshness == asFresh { // asFresh indicates the response is stale but can be returned if lifetime > currentAge { return fresh } // but that seems like a hassle, and is it actually useful? return asFresh return asFresh", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "incompatibilities", "in", "testing_utils", ".", "go", "and", "fixed", "logging", "system", "from", "utils", ".", "go"], "add_tokens": "type logWriter struct { t * testing . T p string } func ( lw logWriter ) Write ( b [ ] byte ) ( int , error ) { lw . t . Logf ( \" \" , lw . p , string ( b ) ) return len ( b ) , nil } testCluster , err := zk . StartTestCluster ( 1 , nil , logWriter { t : t , p : \" \" } ) p := producer . NewKafkaProducer ( topic , [ ] string { brokerAddr } ) if err := p . SendStringSync ( message ) ; err != nil {", "del_tokens": "testCluster , err := zk . StartTestCluster ( 1 ) p := producer . NewKafkaProducer ( topic , [ ] string { brokerAddr } , nil ) if err := p . Send ( message ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "StateChangeLogs", "from", "index", "show", "attrs"], "add_tokens": "res . IndexAttrs ( res . IndexAttrs ( ) , \" \" ) res . ShowAttrs ( res . ShowAttrs ( ) , \" \" , false ) res . NewAttrs ( res . NewAttrs ( ) , \" \" ) res . EditAttrs ( res . EditAttrs ( ) , \" \" )", "del_tokens": "res . NewAttrs ( res . NewAttrs ( ) , \" \" , \" \" ) res . EditAttrs ( res . EditAttrs ( ) , \" \" , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Use", "correct", "type", "assertion", "for", "uint16", "parameters", "passed", "to", "(", "*", "ole", ".", "IDispatch", ")", ".", "Invoke", "."], "add_tokens": "vargs [ n ] = VARIANT { VT_UI2 , 0 , 0 , 0 , int64 ( v . ( uint16 ) ) , 0 }", "del_tokens": "vargs [ n ] = VARIANT { VT_UI2 , 0 , 0 , 0 , int64 ( v . ( int16 ) ) , 0 }", "commit_type": "use"}
{"commit_tokens": ["Move", "color", "averaging", "to", "package", "common"], "add_tokens": "func ( g * Group ) getColor ( cached bool ) ( color common . Color , err error ) { colors := make ( [ ] common . Color , len ( lights ) ) for i , light := range lights { colors [ i ] = c color = common . AverageColor ( colors ... )", "del_tokens": "func ( g * Group ) getColor ( cached bool ) ( common . Color , error ) { var ( hueSum , satSum , brightSum , kelvSum uint64 color common . Color ) for _ , light := range lights { hueSum += uint64 ( c . Hue ) satSum += uint64 ( c . Saturation ) brightSum += uint64 ( c . Brightness ) kelvSum += uint64 ( c . Kelvin ) color . Hue = uint16 ( hueSum / uint64 ( len ( lights ) ) ) color . Saturation = uint16 ( satSum / uint64 ( len ( lights ) ) ) color . Brightness = uint16 ( brightSum / uint64 ( len ( lights ) ) ) color . Kelvin = uint16 ( kelvSum / uint64 ( len ( lights ) ) )", "commit_type": "move"}
{"commit_tokens": ["make", "log", "printing", "of", "TestingT", "pluggable"], "add_tokens": "// LoggingPrintf is the function used by TestingT to produce logging on Logf,Error and Fatal. var LoggingPrintf = fmt . Printf LoggingPrintf ( \" \\t \" + tabify ( format ) + \" \\n \" , args ... ) LoggingPrintf ( \" \\t \" + tabify ( \" \" ) + \" \\n \" , args ) LoggingPrintf ( \" \\t \" + tabify ( \" \" ) + \" \\n \" , args ... )", "del_tokens": "fmt . Printf ( \" \\t \" + tabify ( format ) + \" \\n \" , args ... ) fmt . Printf ( \" \\t \" + tabify ( \" \" ) + \" \\n \" , args ) fmt . Printf ( \" \\t \" + tabify ( \" \" ) + \" \\n \" , args ... )", "commit_type": "make"}
{"commit_tokens": ["fix", "the", "relay", "reset", "test", "again"], "add_tokens": "<- ready hosts [ 2 ] . Network ( ) . ClosePeer ( hosts [ 1 ] . ID ( ) )", "del_tokens": "<- ready hosts [ 2 ] . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["add", "comment", "for", "multifile", "opts"], "add_tokens": "RootDir string `json:\"rootdir\"` // log directory(default: .) ErrorDir string `json:\"errordir\"` // error subdirectory(default: error) WarnDir string `json:\"warndir\"` // warn subdirectory(default: warn) InfoDir string `json:\"infodir\"` // info subdirectory(default: info) DebugDir string `json:\"debugdir\"` // debug subdirectory(default: debug) TraceDir string `json:\"tracedir\"` // trace subdirectory(default: trace) Filename string `json:\"filename\"` // log filename(default: <appName>.log) NoSymlink bool `json:\"nosymlink\"` // doesn't create symlink to latest log file(default: false) MaxSize int `json:\"maxsize\"` // max bytes number of every log file(default: 64M)", "del_tokens": "RootDir string `json:\"rootdir\"` ErrorDir string `json:\"errordir\"` WarnDir string `json:\"warndir\"` InfoDir string `json:\"infodir\"` DebugDir string `json:\"debugdir\"` TraceDir string `json:\"tracedir\"` Filename string `json:\"filename\"` NoSymlink bool `json:\"nosymlink\"` MaxSize int `json:\"maxsize\"`", "commit_type": "add"}
{"commit_tokens": ["Makes", "function", "name", "more", "explicit"], "add_tokens": "func readNetworkCfg ( path string ) ( map [ string ] string , error ) { func writeNetworkCfg ( path string , network map [ string ] string ) error {", "del_tokens": "func readNetwork ( path string ) ( map [ string ] string , error ) { func writeNetwork ( path string , network map [ string ] string ) error {", "commit_type": "make"}
{"commit_tokens": ["Add", "consumer", "example", "without", "checkpointing"], "add_tokens": "var client = kinesis . New ( session . Must ( session . NewSession ( aws . NewConfig ( ) . WithEndpoint ( * kinesisEndpoint ) . WithRegion ( * awsRegion ) . WithLogLevel ( 3 ) , ) ) )", "del_tokens": "const ( kinesisEndpoint = \" \" awsRegion = \" \" ) cfg := aws . NewConfig ( ) . WithEndpoint ( * kinesisEndpoint ) . WithRegion ( * awsRegion ) . WithLogLevel ( 3 ) var client = kinesis . New ( session . Must ( session . NewSession ( cfg ) ) )", "commit_type": "add"}
{"commit_tokens": ["add", "struct", "tag", "for", "xml"], "add_tokens": "gorm . Model `json:\"-\" xml:\"-\"` CveInfoID uint `json:\"-\" xml:\"-\"` gorm . Model `json:\"-\" xml:\"-\"` CveDetailID uint `json:\"-\" xml:\"-\"` gorm . Model `json:\"-\" xml:\"-\"` CveDetailID uint `json:\"-\" xml:\"-\"` gorm . Model `json:\"-\" xml:\"-\"` JvnID uint `json:\"-\" xml:\"-\"` NvdID uint `json:\"-\" xml:\"-\"` gorm . Model `json:\"-\" xml:\"-\"` JvnID uint `json:\"-\" xml:\"-\"` NvdID uint `json:\"-\" xml:\"-\"`", "del_tokens": "gorm . Model `json:\"-\"` CveInfoID uint `json:\"-\"` gorm . Model `json:\"-\"` CveDetailID uint `json:\"-\"` gorm . Model `json:\"-\"` CveDetailID uint `json:\"-\"` gorm . Model `json:\"-\"` JvnID uint `json:\"-\"` NvdID uint `json:\"-\"` gorm . Model `json:\"-\"` JvnID uint `json:\"-\"` NvdID uint `json:\"-\"`", "commit_type": "add"}
{"commit_tokens": ["move", "listers", "to", "resources", "pkg"], "add_tokens": "return n . Run ( )", "del_tokens": "n . Run ( ) return nil", "commit_type": "move"}
{"commit_tokens": ["improve", "coverage", "of", "forward", "/", "forward", ".", "go"], "add_tokens": "pre := f . inflight if pre != inflight { // emit a change f . emit ( InflightRequestsChangedEvent { inflight } ) }", "del_tokens": "f . emit ( InflightRequestsChangedEvent { inflight } )", "commit_type": "improve"}
{"commit_tokens": ["update", "elastigo", "method", "to", "v2"], "add_tokens": "elastigo \" \" func worker ( msgs <- chan amqp . Delivery , es * elastigo . Conn ) { _ , err = es . Index ( \" \" , \" \" , SHA1Hash ( certif . Raw ) , nil , jsonCert ) es := elastigo . NewConn ( ) es . Domain = \" \" go worker ( msgs , es )", "del_tokens": "\" \" \" \" func worker ( msgs <- chan amqp . Delivery ) { _ , err = core . Index ( \" \" , \" \" , SHA1Hash ( certif . Raw ) , nil , jsonCert ) api . Domain = \" \" go worker ( msgs )", "commit_type": "update"}
{"commit_tokens": ["Add", "prefix", "to", "profile", "dump", "file", "names"], "add_tokens": "return pprof ( addr , signal . HeapProfile , \" \" ) return pprof ( addr , signal . CPUProfile , \" \" ) func pprof ( addr net . TCPAddr , p byte , prefix string ) error { tmpDumpFile , err := ioutil . TempFile ( \" \" , prefix + \" \" )", "del_tokens": "return pprof ( addr , signal . HeapProfile ) return pprof ( addr , signal . CPUProfile ) func pprof ( addr net . TCPAddr , p byte ) error { tmpDumpFile , err := ioutil . TempFile ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "set", "values", "role", "in", "sitemap", "url", "and", "testing"], "add_tokens": "\" \" utils . SetElementValue ( sitemap , su . data , \" \" ) if ! utils . SetElementValue ( sitemap , su . data , \" \" ) { lastmod := sitemap . CreateElement ( \" \" ) lastmod . SetText ( time . Now ( ) . Format ( time . RFC3339 ) ) }", "del_tokens": "\" \" if v , ok := su . data [ \" \" ] ; ok { loc := sitemap . CreateElement ( \" \" ) loc . SetText ( fmt . Sprint ( v ) ) } lastmod := sitemap . CreateElement ( \" \" ) lastmod . SetText ( time . Now ( ) . Format ( time . RFC3339 ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "writer", "and", "more", "docs", "."], "add_tokens": "Package rateio provides an io interfaces for rate - limiting . This can be used to apply rate limiting to any type that implements an io - style interface . For example , we can use it to restrict the reading rate of a net . Conn : type limitedConn struct { net . Conn io . Reader // Our rate-limited io.Reader for net.Conn } func ( r * limitedConn ) Read ( p [ ] byte ) ( n int , err error ) { return r . Reader . Read ( p ) } // ReadLimitConn returns a net.Conn whose io.Reader interface is rate-limited by limiter. func ReadLimitConn ( conn net . Conn , limiter rateio . Limiter ) net . Conn { return & limitedConn { Conn : conn , Reader : rateio . NewReader ( conn , limiter ) , } } Then we can use ReadLimitConn to wrap our existing net . Conn and continue using the wrapped version in its place .", "del_tokens": "Package rateio provides an io . Reader and io . Writer interface for rate - limiting io .", "commit_type": "add"}
{"commit_tokens": ["Update", "btcscript", "import", "paths", "to", "new", "location", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "test", "for", "view", ".", "ScopeName"], "add_tokens": "if node . Name != \" \" { in += \" \" + node . Name } if node . Range . Contains ( search ) && node . Name != \" \" { return findScope ( parser . Range { point , point + 1 } , v . syntax . RootNode ( ) , v . syntax . Language . ScopeName )", "del_tokens": "in += \" \" + node . Name if node . Range . Contains ( search ) { return findScope ( parser . Range { point , point + 1 } , v . syntax . RootNode ( ) , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", "for", "byte", "and", "durationformatters"], "add_tokens": "// SecondFormatter represents a duration in seconds // Weeks returns the amount of whole weeks represented by the // SecondFormatter instance // Minimum value: 0 // Days returns the amount of days of a partial week represented // by the SecondFormatter instance // Minimum value: 0, Maximum Value: 6 // Hours returns the amount of hours of the last partial day // represented by the SecondFormatter instance // Minumum value: 0, Maximum value: 23 // Minutes returns the amount of minutes of the last partial hour // represented by the SecondFormatter instance // Minumum value: 0, Maximum value: 59 // Seconds returns the amount of seconds of the last partial minute // represented by the SecondFormatter instance // Minumum value: 0, Maximum value: 59 // String returns the string representation of the SecondFormatter // instance, specifying (if applicable): the amount of weeks, days, // hours, minutes and seconds it represents // FormatDuration returns the string representation of the specified // time.Duration, in the (if applicable) amount of weeks, days, hours, // minutes and seconds it represents // FormatSeconds returns a string representing the (if applicable) // amount of weeks, days, hours, minutes and seconds the amount of // seconds it is passed as a parameter.", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["fix", "typo", "for", "env", "and", "add", "the", "newline"], "add_tokens": "fmt . Printf ( \" \\n \" , value )", "del_tokens": "fmt . Printf ( \" \" , value )", "commit_type": "fix"}
{"commit_tokens": ["fix", "atomic", "race", "condition", "bug", "."], "add_tokens": "ret := atomic . LoadInt32 ( ( * int32 ) ( i ) ) ret := atomic . LoadInt32 ( ( * int32 ) ( i ) ) func ( i * AtomicInteger ) Get ( ) int32 { return atomic . LoadInt32 ( ( * int32 ) ( i ) )", "del_tokens": "ret := int32 ( * i ) ret := int32 ( * i ) func ( i AtomicInteger ) Get ( ) int32 { return int32 ( i )", "commit_type": "fix"}
{"commit_tokens": ["add", "setting", "luar", "tag", "to", "change", "Lua", "name", "of", "struct", "fields"], "add_tokens": "fields : var names [ ] string tag := field . Tag . Get ( \" \" ) if tag == \" \" { if tag != \" \" { names = [ ] string { tag , } } else { names = [ ] string { field . Name , getUnexportedName ( field . Name ) , } } for _ , key := range names { if tbl . RawGetString ( key ) != lua . LNil { continue fields } } for _ , key := range names { tbl . RawSetString ( key , ud ) }", "del_tokens": "if tbl . RawGetString ( field . Name ) != lua . LNil { tbl . RawSetString ( field . Name , ud ) tbl . RawSetString ( getUnexportedName ( field . Name ) , ud )", "commit_type": "add"}
{"commit_tokens": ["improved", "commments", "and", "usage", "examples"], "add_tokens": "// it holds the open TCP connection, access token, prefix and flags. // // all Logger operations are thread safe and blocking, // log operations can be invoked in a non-blocking way by calling them from // a goroutine. // Connect creates a new Logger instance and opens a TCP connection to // Fatal is same as Print() but calls to os.Exit(1) // Fatalf is same as Printf() but calls to os.Exit(1) // Fatalln is same as Println() but calls to os.Exit(1) // Flags returns the logger flags // Output does the actual writing to the TCP connection // Panic is same as Print() but calls to panic // Panicf is same as Printf() but calls to panic // Panicln is same as Println() but calls to panic // Prefix returns the logger prefix // Print logs a message // Printf logs a formatted message // Println logs a message with a linebreak // SetFlags sets the logger flags // SetPrefix sets the logger prefix", "del_tokens": "// it holds the open TCP connection, access token, prefix and flags // Connte creates a new Logger instance and opens a TCP connection to", "commit_type": "improve"}
{"commit_tokens": ["Update", "to", "new", "semver", "system", ";", "fix", "constraints"], "add_tokens": "\" \" , //\"shared 3.6.9\", // this will be correct once #3 is in and we //default to upgrading", "del_tokens": "\" \" ,", "commit_type": "update"}
{"commit_tokens": ["fix", "working", "directory", "+", "environment", "variables"], "add_tokens": "cd \" \" if [ - d . profile . d ] ; then for env_file in . profile . d / * ; do os . Setenv ( \" \" , os . Args [ 1 ] ) os . Setenv ( \" \" , os . Args [ 1 ] + \" \" ) syscall . Exec ( \" \" , append ( argv , os . Args ... ) , os . Environ ( ) )", "del_tokens": "if [ - d \" \" ] ; then for env_file in \" \" / . profile . d / * ; do env := [ ] string { \" \" + os . Args [ 1 ] , \" \" + os . Args [ 1 ] + \" \" , } syscall . Exec ( \" \" , append ( argv , os . Args ... ) , env )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "in", "NewLimits", "."], "add_tokens": "l . FileSize , err = parseInt ( fields [ 1 ] )", "del_tokens": "l . FileLocks , err = parseInt ( fields [ 1 ] )", "commit_type": "fix"}
{"commit_tokens": ["fix", "amqp", "check", "datasource", "template", "not", "used"], "add_tokens": "conn , err := amqp . Dial ( x . templatedDatasource )", "del_tokens": "conn , err := amqp . Dial ( x . Datasource )", "commit_type": "fix"}
{"commit_tokens": ["Move", "queueLength", "to", "the", "top", "of", "the", "struct", "to", "guarantee", "64bit", "alignment"], "add_tokens": "// must be first in the struct because `sync/atomic` expects 64-bit alignment. // Cf. https://github.com/uber/jaeger-client-go/issues/155, https://goo.gl/zW7dgq queueLength int64", "del_tokens": "queueLength int64 // signed because metric's gauge is signed", "commit_type": "move"}
{"commit_tokens": ["Use", "Store", "to", "Get", "resources"], "add_tokens": "\" \" configMapInf := informerFactory . Core ( ) . V1 ( ) . ConfigMaps ( ) . Informer ( ) secretInf := informerFactory . Core ( ) . V1 ( ) . Secrets ( ) . Informer ( ) store . AddInformer ( api . Unversioned . WithKind ( \" \" ) , serviceInf ) store . AddInformer ( api . Unversioned . WithKind ( \" \" ) , configMapInf ) store . AddInformer ( api . Unversioned . WithKind ( \" \" ) , secretInf ) configMapInf . AddEventHandler ( reh ) secretInf . AddEventHandler ( reh )", "del_tokens": "store . AddInformer ( schema . GroupVersionKind { Group : \" \" , Version : \" \" , Kind : \" \" } , serviceInf )", "commit_type": "use"}
{"commit_tokens": ["fix", "tests", "by", "removing", "unnecessary", "check", "on", "first", "stack", "entry"], "add_tokens": "// first entry is not compared since the actual and expected stacks cannot if i != 0 && pc != expected [ i ] {", "del_tokens": "// first entry is compared inexact since the actual and expected stacks cannot if i == 0 { firstEntryDiff := ( int ) ( expected [ i ] ) - ( int ) ( pc ) if firstEntryDiff < - 27 || firstEntryDiff > 27 { return stackCompareError ( fmt . Sprintf ( \" \" , firstEntryDiff ) , actual , expected ) } } else if pc != expected [ i ] {", "commit_type": "fix"}
{"commit_tokens": ["allow", "calling", "of", "custom", "pointer", "methods"], "add_tokens": "func ( s * SliceAlias ) Append ( v string ) { * s = append ( * s , v ) } local len1 = b : Len ( ) b : Append ( \" \" ) print ( len1 , b : Len ( ) ) L . SetGlobal ( \" \" , luar . New ( L , & b ) ) // 2 3", "del_tokens": "print ( b : Len ( ) ) L . SetGlobal ( \" \" , luar . New ( L , b ) ) // 2", "commit_type": "allow"}
{"commit_tokens": ["Make", "transport", "http", ".", "RoundTripper"], "add_tokens": "AcceptType string // specify this to get server response in non XML style if server supports it UserAgent string // user override useful when objectstorage-go is used with in your application Transport http . RoundTripper // custom transport usually for debugging, by default its nil", "del_tokens": "AcceptType string // specify this to get server response in non XML style if server supports it UserAgent string // user override useful when objectstorage-go is used with in your application Transport * http . Transport // custom transport usually for debugging, by default its nil", "commit_type": "make"}
{"commit_tokens": ["Make", "DevAddr", "a", "uint32", "."], "add_tokens": "import ( \" \" \" \" ) type DevAddr uint32 b := make ( [ ] byte , 4 ) binary . LittleEndian . PutUint32 ( b , uint32 ( a ) ) return b , nil * a = DevAddr ( binary . LittleEndian . Uint32 ( data ) )", "del_tokens": "import \" \" type DevAddr [ 4 ] byte return a [ 0 : 4 ] , nil for i , v := range data { a [ i ] = v }", "commit_type": "make"}
{"commit_tokens": ["Make", "request", "timeout", "configurable", "and", "allow", "multiple", "accepted", "codes"], "add_tokens": "\" \" \" \" actualCode int acceptedCodes [ ] int uri string return fmt . Sprintf ( \" \" , e . acceptedCodes , // NewZebedeeClient creates a new Zebedee Client, set ZEBEDEE_REQUEST_TIMEOUT_SECOND // environment variable to modify default 5 second timeout timeout , err := strconv . Atoi ( os . Getenv ( \" \" ) ) if timeout == 0 || err != nil { timeout = 5 } client : & http . Client { Timeout : time . Duration ( timeout ) * time . Second } , acceptedResponseCodes := [ ] int { http . StatusOK , http . StatusCreated , http . StatusAccepted } if ! isValidResponse ( resp . StatusCode , acceptedResponseCodes ) { return nil , ErrInvalidZebedeeResponse { resp . StatusCode , acceptedResponseCodes , req . URL . Path } func isValidResponse ( actual int , expected [ ] int ) bool { for _ , code := range expected { if code == actual { return true } } return false }", "del_tokens": "actualCode int expectedCode int uri string return fmt . Sprintf ( \" \" , e . expectedCode , // NewZebedeeClient creates a new Zebedee Client client : & http . Client { Timeout : 5 * time . Second } , if resp . StatusCode != http . StatusOK { return nil , ErrInvalidZebedeeResponse { resp . StatusCode , http . StatusOK , req . URL . Path }", "commit_type": "make"}
{"commit_tokens": ["Adding", "an", "external", "source", "driver", "which", "will", "look", "for", "hosts", "in", "a", "configurable", "filesystem", "path", "."], "add_tokens": "source , err := sources . NewSource ( ) cadvisorData , err := source . GetContainerStats ( ) pods , err := source . GetPods ( )", "del_tokens": "kubeMasterSource , err := sources . NewKubeMasterSource ( ) if err != nil { return err } cadvisorSource , err := sources . NewCadvisorSource ( ) minions , err := kubeMasterSource . ListMinions ( ) if err != nil { return err } cadvisorData , err := cadvisorSource . FetchData ( minions ) pods , err := kubeMasterSource . ListPods ( )", "commit_type": "add"}
{"commit_tokens": ["added", "quoted", "strings", "to", "parser"], "add_tokens": "case ' ' , '\"' :", "del_tokens": "case ' ' :", "commit_type": "add"}
{"commit_tokens": ["Added", "/", "clear", "to", "the", "gin", "example"], "add_tokens": "msg += fmt . Sprintln ( \" \\n \" ) g . GET ( \" \" , func ( c * gin . Context ) { userstate . ClearCookie ( c . Writer ) c . String ( http . StatusOK , \" \" ) } )", "del_tokens": "msg += fmt . Sprintln ( \" \\n \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "sslmode", "to", "Database", "config"], "add_tokens": "// Test the database config methods when values are missing", "del_tokens": "// Test the database config methods", "commit_type": "add"}
{"commit_tokens": ["Moved", "recovery", "to", "martini", "package"], "add_tokens": "package martini func Test_RecoveryHandler ( t * testing . T ) { m := New ( ) m . Use ( RecoveryHandler ( ) ) expect ( t , recorder . Code , 500 )", "del_tokens": "package recovery \" \" func Test_Recovery ( t * testing . T ) { m := martini . New ( ) m . Use ( New ( ) ) if recorder . Code != 500 { t . Error ( \" \" ) }", "commit_type": "move"}
{"commit_tokens": ["Add", "more", "test", "cases", "fix", "tld", "links", "without", "path"], "add_tokens": "`(([^\\s'\"<>\\(\\)]+:(//)?|(http|ftp|www)[^.]*\\.)[^\\s'\"<>\\(\\)]*[^.,;:\\s'\"<>\\(\\)]|[^\\s'\"<>\\(\\)]+\\.(com|org|net|edu|info)(/([^\\s'\"<>\\(\\)]*[^.,;:\\s'\"<>\\(\\)])?)?)` )", "del_tokens": "`(([^\\s'\"<>\\(\\)]+:(//)?|(http|ftp|www)[^.]*\\.)[^\\s'\"<>\\(\\)]*|[^\\s'\"<>\\(\\)]+\\.(com|org|net|edu|info)(/[^\\s'\"<>\\(\\)]*)?)[^.,;:\\s'\"<>\\(\\)]` )", "commit_type": "add"}
{"commit_tokens": ["Add", "(", "*", "Server", ")", ".", "Close"], "add_tokens": "\" \" closed * int32 closed : new ( int32 ) , if atomic . LoadInt32 ( c . closed ) == 1 { return } atomic . StoreInt32 ( c . closed , 1 ) if atomic . LoadInt32 ( s . closed ) == 1 { return } reply := s . getReply ( ) reply . ID = req . ID reply . Data , err = s . call ( c , f , req . Data ) if err != nil { reply . Data = s . codec . Error ( err ) } s . Requests . Done ( ) go func ( ) { bytes , _ := json . Marshal ( reply )", "del_tokens": "go func ( ) { var err error var bytes [ ] byte reply := s . getReply ( ) reply . ID = req . ID reply . Data , err = s . call ( c , f , req . Data ) if err != nil { reply . Data = s . codec . Error ( err ) } s . Requests . Done ( ) bytes , _ = json . Marshal ( reply )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "leak", "and", "compiler", "error"], "add_tokens": "Serial : big . NewInt ( int64 ( 1 ) ) ,", "del_tokens": "Serial : 1 ,", "commit_type": "fix"}
{"commit_tokens": ["make", "Clear", "thread", "-", "safe"], "add_tokens": "type clear struct { done chan struct { } } // Clears the cache done := make ( chan struct { } ) c . control <- clear { done : done } <- done case clear : for _ , bucket := range c . buckets { bucket . clear ( ) } c . size = 0 c . list = list . New ( ) msg . done <- struct { } { }", "del_tokens": "//this isn't thread safe. It's meant to be called from non-concurrent tests for _ , bucket := range c . buckets { bucket . clear ( ) } c . size = 0 c . list = list . New ( )", "commit_type": "make"}
{"commit_tokens": ["use", "HitRate", "API", "in", "test"], "add_tokens": "cache . HitRate ( ) , cache . EvacuateCount ( ) , cache . EntryCount ( ) , cache . AverageAccessTime ( ) )", "del_tokens": "hitCount := 0 hitCount ++ float64 ( hitCount ) / float64 ( n / 2 ) , cache . EvacuateCount ( ) , cache . EntryCount ( ) , cache . AverageAccessTime ( ) )", "commit_type": "use"}
{"commit_tokens": ["add", "testmain", "migration", "code", "and", "testdata", "code"], "add_tokens": "migrationsDir = \" \"", "del_tokens": "migrationsDir = \" \"", "commit_type": "add"}
{"commit_tokens": ["Implement", "/", "api", "/", "workitem", "/", ":", "ID", "/", "relationships", "/", "links"], "add_tokens": "List ( ctx context . Context , wiIDStr * string ) ( * app . WorkItemLinkArray , error ) // List returns all work item links if wiID is nil; otherwise the work item links are returned // that have wiID as source or target. func ( r * GormWorkItemLinkRepository ) List ( ctx context . Context , wiIDStr * string ) ( * app . WorkItemLinkArray , error ) { db := r . db if wiIDStr == nil { // When no work item ID is given, return all links db = db . Find ( & rows ) if db . Error != nil { return nil , db . Error } } else { // When work item ID is given, filter by it wi , err := workitem . CheckWorkItemExists ( r . db , * wiIDStr ) if err != nil { return nil , err } // Now fetch all links for that work item db = r . db . Model ( & WorkItemLink { } ) . Where ( \" \" , wi . ID ) . Find ( & rows ) if db . Error != nil { return nil , db . Error }", "del_tokens": "List ( ctx context . Context ) ( * app . WorkItemLinkArray , error ) //db := r.db.Model(&res).Where(\"id=?\", ID).First(&res) // List returns all work item links func ( r * GormWorkItemLinkRepository ) List ( ctx context . Context ) ( * app . WorkItemLinkArray , error ) { // We don't have any where clause or paging at the moment. db := r . db . Find ( & rows ) if db . Error != nil { return nil , db . Error", "commit_type": "implement"}
{"commit_tokens": ["Fix", "compilation", "on", "Windows", "amd64"], "add_tokens": "args := & C . CK_C_INITIALIZE_ARGS { CreateMutex : nil , DestroyMutex : nil , LockMutex : nil , UnlockMutex : nil , flags : C . CKF_OS_LOCKING_OK , pReserved : nil }", "del_tokens": "args := & C . CK_C_INITIALIZE_ARGS { nil , nil , nil , nil , C . CKF_OS_LOCKING_OK , nil }", "commit_type": "fix"}
{"commit_tokens": ["Add", "FirewallEnabled", "to", "the", "machine", "struct"], "add_tokens": "Id string // Unique identifier for the image Name string // Machine friendly name Type string // Machine type, one of 'smartmachine' or 'virtualmachine' State string // Current state of the machine Dataset string // The dataset URN the machine was provisioned with. For new images/datasets this value will be the dataset id, i.e, same value than the image attribute Memory int // The amount of memory the machine has (in Mb) Disk int // The amount of disk the machine has (in Gb) IPs [ ] string // The IP addresses the machine has Metadata map [ string ] string // Map of the machine metadata, e.g. authorized-keys Tags map [ string ] string // Map of the machine tags Created string // When the machine was created Updated string // When the machine was updated Package string // The name of the package used to create the machine Image string // The image id the machine was provisioned with PrimaryIP string // The primary (public) IP address for the machine Networks [ ] string // The network IDs for the machine FirewallEnabled bool // whether or not the firewall is enabled", "del_tokens": "Id string // Unique identifier for the image Name string // Machine friendly name Type string // Machine type, one of 'smartmachine' or 'virtualmachine' State string // Current state of the machine Dataset string // The dataset URN the machine was provisioned with. For new images/datasets this value will be the dataset id, i.e, same value than the image attribute Memory int // The amount of memory the machine has (in Mb) Disk int // The amount of disk the machine has (in Gb) IPs [ ] string // The IP addresses the machine has Metadata map [ string ] string // Map of the machine metadata, e.g. authorized-keys Tags map [ string ] string // Map of the machine tags Created string // When the machine was created Updated string // When the machine was updated Package string // The name of the package used to create the machine Image string // The image id the machine was provisioned with PrimaryIP string // The primary (public) IP address for the machine Networks [ ] string // The network IDs for the machine", "commit_type": "add"}
{"commit_tokens": ["add", "commands", "for", "listing", "errors", "and", "showing", "the", "latest"], "add_tokens": "return & Command { name , subname , flag . NewFlagSet ( os . Args [ 0 ] , flag . ExitOnError ) , args , args } Name string SubCommand string FlagSet * flag . FlagSet Args [ ] string SubCommands [ ] string c . SubCommands = c . FlagSet . Args ( )", "del_tokens": "return & Command { name , subname , flag . NewFlagSet ( os . Args [ 0 ] , flag . ExitOnError ) , args } Name string SubCommand string FlagSet * flag . FlagSet Args [ ] string", "commit_type": "add"}
{"commit_tokens": ["adds", "shell", ".", "Process", "to", "readme"], "add_tokens": "\" \" // when started with \"exit\" as first argument, assume non-interactive execution if len ( os . Args ) > 1 && os . Args [ 1 ] == \" \" { shell . Process ( os . Args [ 2 : ] ... ) } else { // start shell shell . Run ( ) // teardown shell . Close ( ) }", "del_tokens": "// start shell shell . Run ( ) // teardown shell . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "useful", "utility", "methods", "and", "default", "exit", "and", "help", "commands", ".."], "add_tokens": "shell . Register ( \" \" , func ( cmd string , args [ ] string ) ( string , error ) { doLogin ( shell ) return \" \" , nil shell . ShowPrompt ( false ) defer shell . ShowPrompt ( true ) shell . Print ( \" \" ) shell . Print ( \" \" )", "del_tokens": "shell . Register ( \" \" , func ( cmd string , args [ ] string ) ( string , error ) { shell . Println ( \" \" ) line , _ := shell . ReadLine ( ) if strings . ToLower ( line ) == \" \" { doLogin ( shell ) } shell . Stop ( ) return \" \" , nil shell . Println ( \" \" ) shell . Println ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["allow", "decision", "worker", "to", "complete", "decisionTasks", "with", "multiple", "decisions"], "add_tokens": "Debug bool if c . Debug { out , err := httputil . DumpRequestOut ( req , true ) if err != nil { return nil , err } Multiln ( string ( out ) ) if c . Debug { defer resp . Body . Close ( ) out , err := httputil . DumpResponse ( resp , true ) if err != nil { return nil , err } Multiln ( string ( out ) )", "del_tokens": "out , err := httputil . DumpRequestOut ( req , true ) if err != nil { return nil , err Multiln ( string ( out ) ) defer resp . Body . Close ( ) out , err = httputil . DumpResponse ( resp , true ) if err != nil { return nil , err Multiln ( string ( out ) )", "commit_type": "allow"}
{"commit_tokens": ["move", "GLFW", "init", "from", "Run", "to", "NewWindow"], "add_tokens": "func Run ( run func ( ) ) {", "del_tokens": "\" \" func Run ( run func ( ) ) error { err := glfw . Init ( ) if err != nil { return errors . Wrap ( err , \" \" ) } return nil", "commit_type": "move"}
{"commit_tokens": ["Allow", "setting", "of", "disk", "size", "on", "app", "push"], "add_tokens": "Disk string Disk : DefaultDisk , if a . Disk != \" \" { args = append ( args , \" \" , a . Disk )", "del_tokens": "if DefaultDisk != \" \" { args = append ( args , \" \" , DefaultDisk )", "commit_type": "allow"}
{"commit_tokens": ["Adding", "in", "a", "battery", "of", "tests"], "add_tokens": "if ! ( strings . Contains ( doc . String ( ) , \" \\\" \\\" \" ) ) { attribute , _ = node . Attribute ( \" \" ) if attribute . Name ( ) != \" \" { t . Error ( \" \" ) } attribute . SetName ( \" \" ) if ! ( strings . Contains ( doc . String ( ) , \" \\\" \\\" \" ) ) { t . Error ( \" \" ) } if strings . Contains ( doc . String ( ) , \" \" ) { t . Error ( \" \" ) }", "del_tokens": "if ! ( strings . Contains ( doc . String ( ) , \" \" ) ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "a", "last", "go", "with", "the", "normal", "client", "so", "we", "can", "get", "the", "payload", "for", "the", "error", "."], "add_tokens": "\" \" \" \" standard_client := & http . Client { } dataReader . Seek ( 0 , 0 ) standard_req , _ := http . NewRequest ( reqMethod , url , dataReader ) standard_req . Header . Add ( \" \" , \" \" ) standard_req . Header . Add ( \" \" , m . ApiToken ) standard_req . Header . Add ( \" \" , m . ApiApp ) resp , err := standard_client . Do ( standard_req ) if resp != nil && resp . Body != nil { defer resp . Body . Close ( ) body , _ := ioutil . ReadAll ( resp . Body ) if m . Debug { m . Log . Printf ( \" \\n \" , string ( body ) ) } return nil , fmt . Errorf ( \" \" , string ( body ) ) } return nil , fmt . Errorf ( \" \" , url , err )", "del_tokens": "\" \" return nil , fmt . Errorf ( \" \\n \" , url , err )", "commit_type": "make"}
{"commit_tokens": ["Improve", "and", "rename", "Signals", "/", "Eavesdropped"], "add_tokens": "c := make ( chan dbus . Message , 10 ) conn . Eavesdrop ( c ) for v := range c { fmt . Println ( v )", "del_tokens": "for { select { case v := <- conn . Signals ( ) : fmt . Println ( v ) case v := <- conn . Eavesdropped ( ) : fmt . Println ( v ) }", "commit_type": "improve"}
{"commit_tokens": ["changed", "etype", "to", "types", "(", "JsonSchemaType", ")"], "add_tokens": "types JsonSchemaType", "del_tokens": "etype string", "commit_type": "change"}
{"commit_tokens": ["Moved", "default", "time", "format", "to", "variable"], "add_tokens": "const rfc3339Milli = \" \" rfc3339Milli ,", "del_tokens": "\" \" ,", "commit_type": "move"}
{"commit_tokens": ["Remove", "internal", "map", "as", "it", "wasn", "t", "really", "used"], "add_tokens": "empty := make ( map [ string ] struct { } , 0 ) return c . GetNewTargets ( empty ) } // Gets a list of current tabs and creates new chrome targets returning a list // provided they weren't in the knownIds list. Note it is a fatal error to attempt // to create a new chrome target from one that already exists. func ( c * Gcd ) GetNewTargets ( knownIds map [ string ] struct { } ) ( [ ] * ChromeTarget , error ) { log . Fatalf ( \" \\n \" , err ) chromeTargets := make ( [ ] * ChromeTarget , 0 ) if _ , ok := knownIds [ v . Id ] ; ! ok { target := newChromeTarget ( c . addr , v ) chromeTargets = append ( chromeTargets , target ) } return chromeTargets , nil", "del_tokens": "\" \" sync . RWMutex // for locking pages (i.e. websocket clients) Targets [ ] * ChromeTarget c . Targets = make ( [ ] * ChromeTarget , 0 ) // close all websockets for _ , target := range c . Targets { target . shutdown ( ) } log . Fatalf ( \" \\n \" , err ) target := newChromeTarget ( c . addr , v ) c . Targets = append ( c . Targets , target ) return c . Targets , nil", "commit_type": "remove"}
{"commit_tokens": ["add", "more", "tests", "to", "the", "feed", "updater"], "add_tokens": "db = NewDB ( \" \" , \" \" )", "del_tokens": "db = NewDB ( \" \" , conn )", "commit_type": "add"}
{"commit_tokens": ["Change", "float", "marshal", "to", "normal", "receiver", "function"], "add_tokens": "func ( value Float64 ) MarshalJSON ( ) ( [ ] byte , error ) { val := float64 ( value ) return json . Marshal ( float64 ( value ) )", "del_tokens": "func ( value * Float64 ) MarshalJSON ( ) ( [ ] byte , error ) { val := float64 ( * value ) return json . Marshal ( float64 ( * value ) )", "commit_type": "change"}
{"commit_tokens": ["Move", "CHD", "into", "its", "own", "package", "."], "add_tokens": "\" \" mph := chd . Builder ( ) mph . Add ( [ ] byte ( last ) , [ ] byte ( v ) ) m , err := mph . Build ( ) w , err := os . Create ( \" \" ) defer w . Close ( ) wb := bufio . NewWriter ( w ) err = m . Marshal ( wb ) wb . Flush ( )", "del_tokens": "\" \" \" \" chd := mph . NewCHDBuilder ( ) chd . Add ( [ ] byte ( last ) , [ ] byte ( v ) ) m , err := chd . Build ( ) b , err := m . Serialize ( ) err = ioutil . WriteFile ( \" \" , b , 0666 )", "commit_type": "move"}
{"commit_tokens": ["add", "streaming", "test", "to", "cbor"], "add_tokens": "\" \" uint ( 0 ) , func TestStream ( t * testing . T ) { r , w := io . Pipe ( ) e := NewStreamEncoder ( w ) d := NewStreamDecoder ( r ) go func ( ) { defer e . Close ( ) for i := 0 ; i != 100 ; i ++ { if err := e . Encode ( i ) ; err != nil { t . Error ( err ) } } } ( ) var i int for d . Decode ( & i ) == nil { i = 0 } if err := d . Err ( ) ; err != nil { t . Error ( err ) } }", "del_tokens": "0 ,", "commit_type": "add"}
{"commit_tokens": ["Made", "CreateWindowAndRenderer", "()", "return", "the", "two", "variables", "instead", "of", "int"], "add_tokens": "func CreateWindowAndRenderer ( w , h int , flags uint32 ) ( * Window , * Renderer ) { var window * C . SDL_Window var renderer * C . SDL_Renderer C . SDL_CreateWindowAndRenderer ( C . int ( w ) , C . int ( h ) , C . Uint32 ( flags ) , & window , & renderer ) return ( * Window ) ( unsafe . Pointer ( window ) ) , ( * Renderer ) ( unsafe . Pointer ( renderer ) )", "del_tokens": "func CreateWindowAndRenderer ( width int , height int , windowFlags uint32 , window * * Window , renderer * * Renderer ) int { _width := ( C . int ) ( width ) _height := ( C . int ) ( height ) _windowFlags := ( C . Uint32 ) ( windowFlags ) _window := ( * * C . SDL_Window ) ( unsafe . Pointer ( window ) ) _renderer := ( * * C . SDL_Renderer ) ( unsafe . Pointer ( renderer ) ) return ( int ) ( C . SDL_CreateWindowAndRenderer ( _width , _height , _windowFlags , _window , _renderer ) )", "commit_type": "make"}
{"commit_tokens": ["add", "recursive", "expansion", "of", "subcommands"], "add_tokens": "func TestErrorOnNonStruct ( t * testing . T ) { err := parse ( \" \" , & args ) assert . Error ( t , err )", "del_tokens": "func TestPanicOnNonStruct ( t * testing . T ) { assert . Panics ( t , func ( ) { _ = parse ( \" \" , & args ) } )", "commit_type": "add"}
{"commit_tokens": ["fix", "precision", "timing", "metric", "+", "added", "test", "case"], "add_tokens": "fmt . Sprintf ( \" \" , e . Name , float64 ( int64 ( e . Value ) / e . Count ) / 1000000 ) , // make sure e.Count != 0 fmt . Sprintf ( \" \" , e . Name , e . durationToMs ( e . Min ) ) , fmt . Sprintf ( \" \" , e . Name , e . durationToMs ( e . Max ) ) , // durationToMs converts time.Duration into the corresponding value in milliseconds func ( e PrecisionTiming ) durationToMs ( x time . Duration ) float64 { return float64 ( x ) / float64 ( time . Millisecond ) }", "del_tokens": "fmt . Sprintf ( \" \" , e . Name , float64 ( int64 ( e . Value ) / e . Count ) ) , // make sure e.Count != 0 fmt . Sprintf ( \" \" , e . Name , e . Min ) , fmt . Sprintf ( \" \" , e . Name , e . Max ) ,", "commit_type": "fix"}
{"commit_tokens": ["use", "all", "lower", "cased", "sirupsen", "/", "logrus", "import"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "openbsd", "and", "netbsd"], "add_tokens": "// +build linux freebsd dragonfly openbsd netbsd", "del_tokens": "// +build linux freebsd dragonfly", "commit_type": "add"}
{"commit_tokens": ["Use", "DialContext", "to", "make", "dials", "cancellable"], "add_tokens": "DialContext : ( & net . Dialer { } ) . DialContext ,", "del_tokens": "Dial : ( & net . Dialer { } ) . Dial ,", "commit_type": "use"}
{"commit_tokens": ["adds", "the", "updated", "transfer", "and", "transaction_test", "files"], "add_tokens": "var trytes Trytes = \" \" if ! tx . HasValidNonce ( DefaultMinWeightMagnitude ) { doTransactionHashTest ( t , trytes1 , hash1_p81 ) doTransactionHashTest ( t , trytes2 , hash2_p81 ) t . Errorf ( \" \\n \" , trytes . Hash ( ) ) if tx . Hash ( ) != hash_p81 { t . Errorf ( \" \\n \" , tx . Hash ( ) )", "del_tokens": "var trytes Trytes = \" \" if ! tx . HasValidNonce ( 18 ) { doTransactionHashTest ( t , trytes1 , hash1_p81 ) doTransactionHashTest ( t , trytes2 , hash2_p81 ) t . Errorf ( \" \\n \" , trytes . Hash ( ) ) if ( tx . Hash ( ) != hash_p81 ) { t . Errorf ( \" \\n \" , tx . Hash ( ) )", "commit_type": "add"}
{"commit_tokens": ["changed", "default", "number", "of", "replicas", "in", "http", "pool", "hash", "ring", "to", "50", "and", "fixed", "hash", "ring", "benchmark"], "add_tokens": "hash := New ( 50 , nil )", "del_tokens": "hash := New ( shards , nil )", "commit_type": "change"}
{"commit_tokens": ["Added", "distance", "testing", ".", "Update", "documentation", "with", "KNN", "info"], "add_tokens": "sum += math . Abs ( u [ i ] - v [ i ] )", "del_tokens": "sum += u [ i ] - v [ i ]", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "for", "default", "Content", "-", "Type"], "add_tokens": "MaxLineLength = 76 // MaxLineLength is the maximum line length per RFC 2045 defaultContentType = \" \" // defaultContentType is the default Content-Type according to RFC 2045, section 5.2 // If no content type is given, set it to the default if _ , ok := hs [ \" \" ] ; ! ok { hs . Set ( \" \" , defaultContentType ) } // If it's a multipart email, recursively parse the parts } else { // If it is not a multipart email, parse the body content as a single \"part\" var buf bytes . Buffer if _ , err := io . Copy ( & buf , b ) ; err != nil { return ps , err } ps = append ( ps , & part { body : buf . Bytes ( ) , header : hs } )", "del_tokens": "// MaxLineLength is the maximum line length per RFC 2045 MaxLineLength = 76", "commit_type": "add"}
{"commit_tokens": ["add", "return", "code", "evaluation", "and", "fixed", "test"], "add_tokens": "\" \" \" \" resBodyAsString := string ( resBody [ : len ( resBody ) ] ) if strings . HasPrefix ( resBodyAsString , \" \" ) { return nil , errors . New ( resBodyAsString ) }", "del_tokens": "//fmt.Println(\"resBody:\", string(resBody[:len(resBody)]))", "commit_type": "add"}
{"commit_tokens": ["add", "example", "of", "handling", "kafka", "producer", "errors"], "add_tokens": "case consumerError := <- consumer . Errors ( ) : log . Error ( fmt . Errorf ( \" \" ) , log . Data { \" \" : consumerError } ) producer . Closer ( ) <- true consumer . Closer ( ) <- true exitChannel <- true return case producerError := <- producer . Errors ( ) : log . Error ( fmt . Errorf ( \" \" ) , log . Data { \" \" : producerError } )", "del_tokens": "case errorMessage := <- consumer . Errors ( ) : log . Error ( fmt . Errorf ( \" \" ) , log . Data { \" \" : errorMessage } )", "commit_type": "add"}
{"commit_tokens": ["added", "prefix", "to", "State", "constants"], "add_tokens": "StateDisconnected State = iota StateConnected StateSynced state : StateDisconnected , if c . state != StateDisconnected { c . state = StateConnected c . state = StateDisconnected if c . state == StateDisconnected {", "del_tokens": "Disconnected State = iota Connected Synced state : Disconnected , if c . state != Disconnected { c . state = Connected c . state = Disconnected if c . state == Disconnected {", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "env", "loadings", "&", "command", "running", "into", "main", "package", "."], "add_tokens": "\" \" var envFilenames [ ] string if rawEnvFilenames != \" \" { envFilenames = strings . Split ( rawEnvFilenames , \" \" ) err := godotenv . Exec ( envFilenames , cmd , cmdArgs ) if err != nil { log . Fatal ( err ) }", "del_tokens": "\" \" \" \" // TODO would be nicer for an empty rawEnvFilenames to give us an empty map // and then only call Load() once // other TODO error handling on Load() if rawEnvFilenames == \" \" { godotenv . Load ( ) } else { envFilenames := strings . Split ( rawEnvFilenames , \" \" ) godotenv . Load ( envFilenames ... ) command := exec . Command ( cmd , cmdArgs ... ) command . Stdin = os . Stdin command . Stdout = os . Stdout command . Stderr = os . Stderr command . Start ( )", "commit_type": "move"}
{"commit_tokens": ["Added", "retry", "policies", "for", "Query", "and", "Batch", "Statements", ".", "Policies", "can", "be", "defined", "at", "the", "cluster", "or", "per", "query", ".", "Added", "test", "cases", "for", "retries", "and", "added", "test", "case", "for", "batch", "statement", "limits", "."], "add_tokens": "Address string t * testing . T nreq uint64 listen net . Listener nKillReq uint64 // TestQueryRetry will test to make sure that gocql will execute // the exact amount of retry queries designated by the user. func TestQueryRetry ( t * testing . T ) { srv := NewTestServer ( t ) defer srv . Stop ( ) db , err := NewCluster ( srv . Address ) . CreateSession ( ) if err != nil { t . Errorf ( \" \" , err ) } go func ( ) { <- time . After ( 5 * time . Second ) t . Fatal ( \" \" ) } ( ) rt := RetryPolicy { NumRetries : 1 } if err := db . Query ( \" \" ) . RetryPolicy ( rt ) . Exec ( ) ; err == nil { t . Fatal ( \" \" ) } //Minus 1 from the nKillReq variable since there is the initial query attempt if srv . nKillReq - 1 != uint64 ( rt . NumRetries ) { t . Fatalf ( \" \" , rt . NumRetries , srv . nKillReq - 1 ) } } atomic . AddUint64 ( & srv . nKillReq , 1 )", "del_tokens": "Address string t * testing . T nreq uint64 listen net . Listener", "commit_type": "add"}
{"commit_tokens": ["Remove", "media", "/", "process", "module"], "add_tokens": "c * ipmi . Connection cmd * exec . Cmd m . cmd = exec . Command ( m . cli ( ) , args ... ) return m . cmd . Start ( ) } func ( m * dell ) UnMount ( ) error { return m . cmd . Process . Kill ( )", "del_tokens": "process c * ipmi . Connection m . Cmd = exec . Command ( m . cli ( ) , args ... ) return m . start ( )", "commit_type": "remove"}
{"commit_tokens": ["fix", "wrong", "CJK", "Character", "size", "."], "add_tokens": "tmp := ansi . ReplaceAllLiteralString ( str , \" \" ) tmp_rune := [ ] rune ( tmp ) count := 0 for _ , v := range tmp_rune { if v > 128 { count ++ } } return utf8 . RuneCountInString ( tmp ) + count", "del_tokens": "return utf8 . RuneCountInString ( ansi . ReplaceAllLiteralString ( str , \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "up", "the", "two", "screen", "terminfo", "sgr0", "sequences", "."], "add_tokens": "AttrOff : \" \\x1b \\x0f \" ,", "del_tokens": "AttrOff : \" \\x1b \\x00 \" ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "start", "-", "up", "time", "race", "."], "add_tokens": "if c . adminClient == nil && reg == c . adminRegionInfo && ! c . adminRegionInfo . IsUnavailable ( ) || c . metaClient == nil && reg == c . metaRegionInfo && ! c . metaRegionInfo . IsUnavailable ( ) { c . regionsLock . Lock ( ) if ! c . metaRegionInfo . IsUnavailable ( ) { reg . MarkUnavailable ( ) go c . reestablishRegion ( reg ) } c . regionsLock . Unlock ( )", "del_tokens": "if reg == c . adminRegionInfo && c . adminClient == nil && ! c . adminRegionInfo . IsUnavailable ( ) || reg == c . metaRegionInfo && c . metaClient == nil && ! c . metaRegionInfo . IsUnavailable ( ) { reg . MarkUnavailable ( ) go c . reestablishRegion ( reg )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "few", "errors", "found", "in", "testing", ".", "Now", "it", "s", "usable!"], "add_tokens": "\" \" if resp . StatusCode == http . StatusRequestedRangeNotSatisfiable { return 0 , io . EOF } n , err := fmt . Sscanf ( content_range , \" \" , & first , & last , & total ) if err != nil { return 0 , err } if n != 3 { return 0 , & HttpFileError { Err : fmt . Errorf ( \" \" , content_range , n ) } newpos = f . pos + offset newpos = f . len + offset", "del_tokens": "//\"io\" n , err := fmt . Sscanf ( content_range , \" \" , first , last , total ) if err != nil || n != 3 { return 0 , & HttpFileError { Err : fmt . Errorf ( \" \" , content_range ) } newpos = f . pos + int64 ( offset ) newpos = f . len + int64 ( offset )", "commit_type": "fix"}
{"commit_tokens": ["using", "user", ".", "New", "instead", "createUser"], "add_tokens": "u , err := user . New ( \" \" , [ ] string { } ) u , err := user . New ( \" \" , [ ] string { } ) user , err := user . New ( \" \" , [ ] string { } ) u , err := user . New ( \" \" , [ ] string { } ) u , err := user . New ( \" \" , [ ] string { } )", "del_tokens": "func createUser ( name string ) ( u user . User , err error ) { u = user . User { Name : name } err = db . Session . User ( ) . Insert ( & u ) return } u , err := createUser ( \" \" ) u , err := createUser ( \" \" ) user , err := createUser ( \" \" ) u , err := createUser ( \" \" ) u , err := createUser ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "few", "more", "tests", "and", "update", "the", "readme", "to", "use", "shields", ".", "io"], "add_tokens": "func ( queue * queue ) startQueueWorkers ( ) error { return errors . New ( \" \" ) return nil func ( queue * queue ) stopQueueWorkers ( ) error { return nil return errors . New ( \" \" )", "del_tokens": "func ( queue * queue ) startQueueWorkers ( ) { return func ( queue * queue ) stopQueueWorkers ( ) {", "commit_type": "add"}
{"commit_tokens": ["made", "file", "fieldnames", "explicit", "rather", "than", "magic", "#nomagic"], "add_tokens": "part , err := writer . CreateFormFile ( req . files [ i ] . Field , req . files [ i ] . Name ) func ( req * Request ) File ( fieldname , filename string , r io . Reader ) { Field : fieldname , Name : filename , R : r , Field string Name string R io . Reader", "del_tokens": "\" \" filename := fmt . Sprintf ( \" \" , i + 1 ) if i == 0 { // just use \"file\" for the first one filename = \" \" } part , err := writer . CreateFormFile ( filename , req . files [ i ] . Name ) func ( req * Request ) File ( filename string , r io . Reader ) { Name : filename , R : r , Name string R io . Reader", "commit_type": "make"}
{"commit_tokens": ["added", "math", "/", "rand", "to", "readme", "example"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Improve", "test", "logic", "for", "Norvig", "set"], "add_tokens": "const test2AccuracyThreshold = .60 model . SetThreshold ( 1 ) // This ensures a more complete dictionary at the expense of size/speed.", "del_tokens": "const test2AccuracyThreshold = .59", "commit_type": "improve"}
{"commit_tokens": ["Allow", "user", "use", "dsn", "without", "dbname"], "add_tokens": "// User Password scrambleBuff := scramblePassword ( mc . server . scrambleBuff , [ ] byte ( mc . cfg . passwd ) ) pktLen := 4 + 4 + 1 + 23 + len ( mc . cfg . user ) + 1 + 1 + len ( scrambleBuff ) pktLen += len ( mc . cfg . dbname ) + 1 e = errors . New ( \" \" )", "del_tokens": "// User Password scrambleBuff := scramblePassword ( mc . server . scrambleBuff , [ ] byte ( mc . cfg . passwd ) ) pktLen := 4 + 4 + 1 + 23 + len ( mc . cfg . user ) + 1 + 1 + len ( scrambleBuff ) + len ( mc . cfg . dbname ) + 1 e = errors . New ( \" \" )", "commit_type": "allow"}
{"commit_tokens": ["Improve", "error", "handling", "in", "examples"], "add_tokens": "\" \" if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) } if err != nil { log . Fatal ( err ) }", "del_tokens": "fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil> fmt . Println ( err ) // <nil>", "commit_type": "improve"}
{"commit_tokens": ["remove", "BibTeX", "and", "authors", "temporary"], "add_tokens": "// Authors []string // Bibtex string / * * / / * * / // fmt.Println(\"autho :\", a.Author) // fmt.Println(\"BibTeX: \", a.Bibtex)", "del_tokens": "\" \" Authors [ ] string Bibtex string fmt . Println ( \" \" , a . Bibtex )", "commit_type": "remove"}
{"commit_tokens": ["Make", "local", "adapter", "tests", "windows", "compatible"], "add_tokens": "\" \" is . True ( data [ \" \" ] == \" \" || data [ \" \" ] == \" \" || data [ \" \" ] == \" \" ) is . True ( data [ \" \" ] == \" \" || data [ \" \" ] == \" \" || data [ \" \" ] == \" \" ) is . True ( data [ \" \" ] == \" \" || data [ \" \" ] == \" \" || data [ \" \" ] == \" \" ) if runtime . GOOS != \" \" { is . OK ( data [ \" \" ] ) }", "del_tokens": "is . True ( data [ \" \" ] == \" \" || data [ \" \" ] == \" \" ) is . True ( data [ \" \" ] == \" \" || data [ \" \" ] == \" \" ) is . True ( data [ \" \" ] == \" \" || data [ \" \" ] == \" \" ) is . OK ( data [ \" \" ] )", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "disable", "messages", "buffering", "by", "passing", "negative", "values", "to", "FlushDelay", ".", "Thanks", "to", "funny", "-", "falcon", "to", "the", "idea", "-", "see", "https", ":", "//", "github", ".", "com", "/", "valyala", "/", "gorpc", "/", "pull", "/", "1", "for", "details"], "add_tokens": "// Negative values disable request buffering. // if c . FlushDelay == 0 { var ( flushChan <- chan time . Time closedFlushChan = make ( chan time . Time ) ) close ( closedFlushChan ) if c . FlushDelay > 0 { flushChan = time . After ( c . FlushDelay ) } else { flushChan = closedFlushChan }", "del_tokens": "if c . FlushDelay <= 0 { var flushChan <- chan time . Time flushChan = time . After ( c . FlushDelay )", "commit_type": "add"}
{"commit_tokens": ["Changed", "locker", "to", "anon", "struct"], "add_tokens": "sync . RWMutex s . Lock ( ) s . Unlock ( ) s . Lock ( ) s . Unlock ( ) s . Lock ( ) s . Unlock ( ) return & Strobe { listeners : make ( map [ chan string ] bool ) , views : make ( map [ <- chan string ] chan string ) }", "del_tokens": "lock sync . Locker s . lock . Lock ( ) s . lock . Unlock ( ) s . lock . Lock ( ) s . lock . Unlock ( ) s . lock . Lock ( ) s . lock . Unlock ( ) return & Strobe { listeners : make ( map [ chan string ] bool ) , views : make ( map [ <- chan string ] chan string ) , lock : & sync . Mutex { } }", "commit_type": "change"}
{"commit_tokens": ["Fix", "use", "of", "AnythingOfType", "with", "AssertCalled"], "add_tokens": "func ( m * Mock ) methodWasCalled ( methodName string , expected [ ] interface { } ) bool { _ , differences := Arguments ( expected ) . Diff ( call . Arguments )", "del_tokens": "func ( m * Mock ) methodWasCalled ( methodName string , arguments [ ] interface { } ) bool { _ , differences := call . Arguments . Diff ( arguments )", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "to", "reproduce", "issue", "29", "."], "add_tokens": "func TestUnexported ( t * testing . T ) { type unexported struct { unexported int } enc := NewEncoder ( new ( bytes . Buffer ) ) if err := enc . Encode ( & unexported { 0 } ) ; err != nil { t . Fatalf ( \" \" ) } } type Embedded struct { Int int `toml:\"_int\"` }", "del_tokens": "type Embedded struct { Int int `toml:\"_int\"` }", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "on", "unexpected", "conn", "close"], "add_tokens": "if s . cm != nil && s . cm . IfIndex != s . ifIndex { // Filter all other interfaces", "del_tokens": "if s . cm . IfIndex != s . ifIndex { // Filter all other interfaces", "commit_type": "fix"}
{"commit_tokens": ["Move", "libraries", "to", "sub", "-", "packages"], "add_tokens": "// This is a temporary helper API until the Lua compiler is complete func BinaryTest ( t * testing . T , fileName string , libs ... RegistryFunction ) State { file , err := os . Open ( fileName ) t . Fatal ( \" \" + fileName ) for _ , lib := range libs { Require ( l , lib . Name , lib . Function , true ) l . Pop ( 1 ) } return l", "del_tokens": "func TestMath ( t * testing . T ) { file , err := os . Open ( \" \" ) t . Fatal ( \" \" ) OpenBase ( l ) Require ( l , \" \" , OpenMath , true ) l . Pop ( 1 ) l . Call ( 0 , 0 )", "commit_type": "move"}
{"commit_tokens": ["Fix", "issue", "with", "circular", "sidekick", "dependency"], "add_tokens": "for _ , link := range s . service . DependentServices ( ) {", "del_tokens": "for _ , link := range append ( s . service . Config ( ) . Links . Slice ( ) , s . service . Config ( ) . VolumesFrom ... ) {", "commit_type": "fix"}
{"commit_tokens": ["improve", "docstrings", "of", "draw2dpdf", "/", "gc", ".", "go"], "add_tokens": "// Stroke strokes the paths with the color specified by SetStrokeColor // Fill fills the paths with the color specified by SetFillColor", "del_tokens": "// Stroke strokes the paths // Fill strokes the paths", "commit_type": "improve"}
{"commit_tokens": ["add", "Filter", "and", "Scope", "route", "options"], "add_tokens": "if string ( r . Name ( ) ) == \" \" {", "del_tokens": "if string ( r . Name ( ) ) == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Use", "slice", "for", "accepters", "."], "add_tokens": "accepters [ ] PipeAccepter sock . Unlock ( ) for _ , a := range sock . accepters { sock . accepters = append ( sock . accepters , a )", "del_tokens": "accepters List sock . accepters . Init ( ) for e := sock . accepters . HeadNode ( ) ; e != nil ; e = sock . accepters . HeadNode ( ) { a := e . Value . ( PipeAccepter ) sock . accepters . Remove ( e ) sock . Unlock ( ) sock . Lock ( ) sock . Unlock ( ) type accepter struct { a PipeAccepter n ListNode } sock . accepters . InsertTail ( & ListNode { Value : a } )", "commit_type": "use"}
{"commit_tokens": ["Added", "LRUCache", "doc", "improvements", "and", "some", "tests"], "add_tokens": "// They probably want no concurrency if size == 0 { size = 1 } go func ( ) { err := callBack ( data ) if err != nil { p . errChan <- err } <- p . size } ( )", "del_tokens": "err := callBack ( data ) if err != nil { p . errChan <- err } <- p . size", "commit_type": "add"}
{"commit_tokens": ["Fix", "Travis", "errors", "on", "recent", "Go"], "add_tokens": "log . Fatalf ( \" \" , err )", "del_tokens": "log . Fatalln ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "to", "add", "/", "remove", "IIP"], "add_tokens": "return fmt . Errorf ( \" \" , processName , portName )", "del_tokens": "return fmt . Errorf ( \" \" , processName , portName )", "commit_type": "add"}
{"commit_tokens": ["Add", "special", "case", "for", "TargetLogLatency", "==", "0"], "add_tokens": "if cfg . TargetLogLatency < 0 { return nil , errors . New ( \" \" + \" \" ) } } // If duration is zero, don't bother starting the ticker; a // special code path for a nil ticker will send immediately. if cfg . TargetLogLatency > 0 { m . ticker = time . NewTicker ( cfg . TargetLogLatency ) if m . ticker != nil { go func ( ) { for { // Wait for a while to do work, or to // exit select { case <- m . ticker . C : case _ , _ = <- m . finalize : return } // Avoid sending empty requests s := m . c . Statistics ( ) if s . NumberFramed > 0 { go m . syncWorker ( ) } } ( ) } if s . Buffered >= m . RequestSizeTrigger || m . ticker == nil {", "del_tokens": "ticker : time . NewTicker ( cfg . TargetLogLatency ) , go func ( ) { for { // Wait for a while to do work, or to exit select { case <- m . ticker . C : case _ , _ = <- m . finalize : return // Avoid sending empty requests s := m . c . Statistics ( ) if s . NumberFramed > 0 { go m . syncWorker ( ) } } } ( ) if s . Buffered >= m . RequestSizeTrigger {", "commit_type": "add"}
{"commit_tokens": ["Use", "Unix", "sockets", "to", "connect", "to", "temporary", "Redis", "instances"], "add_tokens": "import \" \" m , err := redsync . NewMutexWithGenericPool ( \" \" , pools )", "del_tokens": "import ( \" \" \" \" ) m , err := redsync . NewMutex ( \" \" , [ ] net . Addr { & net . TCPAddr { Port : 63790 } , & net . TCPAddr { Port : 63791 } , & net . TCPAddr { Port : 63792 } , & net . TCPAddr { Port : 63793 } , } )", "commit_type": "use"}
{"commit_tokens": ["Improve", "types", "of", "algorithm", "identifier", "constants"], "add_tokens": "type AlgorithmID string func ( id AlgorithmID ) String ( ) string { return string ( id ) } // Supported canonicalization algorithms CanonicalXML10ExclusiveAlgorithmId AlgorithmID = \" \" CanonicalXML11AlgorithmId AlgorithmID = \" \" EnvelopedSignatureAltorithmId AlgorithmID = \" \"", "del_tokens": "type SignatureAlgorithm string // NOTE(russell_h): I guess 1.0 is \"exclusive\" and 1.1 isn't CanonicalXML10AlgorithmId SignatureAlgorithm = \" \" CanonicalXML11AlgorithmId = \" \" ) const ( EnvelopedSignatureAltorithmId = \" \"", "commit_type": "improve"}
{"commit_tokens": ["Add", "go", "-", "vet", "task", "and", "fix", "temporary", "vet", "error", "."], "add_tokens": "// sdk, err := godoSdk.NewSdk() // if err != nil { // return err // } // resources.Sdk = sdk // model = ClusterModel(r.Known) // return nil", "del_tokens": "sdk , err := godoSdk . NewSdk ( ) if err != nil { return err } resources . Sdk = sdk model = ClusterModel ( r . Known ) return nil", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "generated", "code", "build", "errors", "."], "add_tokens": "import ( oglemock \" \" )", "del_tokens": "import ( )", "commit_type": "fix"}
{"commit_tokens": ["make", "GetPin", "case", "-", "insensitive"], "add_tokens": "pl := strings . ToLower ( pinName ) if strings . ToLower ( name ) == pl {", "del_tokens": "if name == pinName {", "commit_type": "make"}
{"commit_tokens": ["improved", "the", "way", "calls", "worked"], "add_tokens": "t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) t . Fatalf ( \" \" , err ) func TestTemplateFuncs ( t * testing . T ) { fn := templateFuncs [ \" \" ] . ( func ( string ) string ) if fn ( \" \" ) != \" \" { t . Errorf ( \" \" , fn ( \" \" ) ) } }", "del_tokens": "t . Errorf ( \" \" , err ) t . Errorf ( \" \" , err ) t . Errorf ( \" \" , err ) t . Errorf ( \" \" , err ) t . Errorf ( \" \" , err ) t . Errorf ( \" \" , err )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "some", "bugs", "in", "LGTM", "detection", "by", "searching", "more", "events"], "add_tokens": "github_util \" \" events , err := github_util . GetAllEventsForPR ( client , opts . Org , opts . Project , * pr . Number )", "del_tokens": "events , _ , err := client . Issues . ListIssueEvents ( opts . Org , opts . Project , * pr . Number , & github . ListOptions { } )", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "custom", "distance", "function", "for", "point", "estimates"], "add_tokens": "sqlite \" \" // createPubRec attaches the DB conn to the public record. That DB connection // must be initialiazed with custom SQL functions before anything else can // touch it. sql . Register ( \" \" , & sqlite . SQLiteDriver { ConnectHook : func ( conn * sqlite . SQLiteConn ) error { err := conn . RegisterFunc ( \" \" , pow , true ) if err != nil { return err } err = conn . RegisterFunc ( \" \" , distance , true ) if err != nil { return err } return nil } , } ) conn , err := sql . Open ( \" \" , path )", "del_tokens": "_ \" \" conn , err := sql . Open ( \" \" , path )", "commit_type": "add"}
{"commit_tokens": ["remove", "main", "function", "from", "this", "package"], "add_tokens": "package raval", "del_tokens": "package main func main ( ) { laddr , err := net . ResolveTCPAddr ( \" \" , \" \" ) if err != nil { log . Fatal ( err ) } listener , err := net . ListenTCP ( \" \" , laddr ) if err != nil { log . Fatal ( err ) } ftpServer := & FTPServer { \" \" , listener , new ( Array ) , } log . Fatal ( ftpServer . Listen ( ) ) }", "commit_type": "remove"}
{"commit_tokens": ["Add", "option", "to", "print", "out", "available", "collectors", "."], "add_tokens": "\" \" enabledCollectors = flag . String ( \" \" , \" \" , \" \" ) printCollectors = flag . Bool ( \" \" , false , \" \" ) if * printCollectors { fmt . Printf ( \" \\n \" ) for n , _ := range collector . Factories { fmt . Printf ( \" \\n \" , n ) } return }", "del_tokens": "enabledCollectors = flag . String ( \" \" , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Create", "mutateCh", "on", "root", "node"], "add_tokens": "t := & Tree { root : & Node { mutateCh : make ( chan struct { } ) , } , }", "del_tokens": "t := & Tree { root : & Node { } }", "commit_type": "create"}
{"commit_tokens": ["Allow", "changing", "base", "cookie", "name"], "add_tokens": "func ( h CSRFHandler ) getCookieName ( ) string { if h . baseCookie . Name != \" \" { return h . baseCookie . Name } return CookieName } tokenCookie , err := r . Cookie ( h . getCookieName ( ) ) cookie . Name = h . getCookieName ( )", "del_tokens": "tokenCookie , err := r . Cookie ( CookieName ) cookie . Name = CookieName", "commit_type": "allow"}
{"commit_tokens": ["Remove", "dependency", "on", "kardianos", "/", "osext"], "add_tokens": "path , err := os . Executable ( )", "del_tokens": "\" \" path , err := osext . Executable ( )", "commit_type": "remove"}
{"commit_tokens": ["Add", "environment", "name", "and", "hostname", "config", "."], "add_tokens": "import \" \" APIKey string EnvironmentName string Hostname string hostname , err := os . Hostname ( ) if err != nil { panic ( err ) } APIKey : \" \" , EnvironmentName : \" \" , Hostname : hostname ,", "del_tokens": "APIKey string APIKey : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "library", "user", "to", "specify", "custom", "min", "and", "max", "-", "sizes", "using", "NewWithBoundaries"], "add_tokens": "return NewWithBoundaries ( rd , pol , MinSize , MaxSize ) } // NewWithBoundaries returns a new Chunker based on polynomial p that reads from // rd and custom min and max size boundaries func NewWithBoundaries ( rd io . Reader , pol Pol , min , max uint ) * Chunker { MinSize : min , MaxSize : max ,", "del_tokens": "MinSize : MinSize , MaxSize : MaxSize ,", "commit_type": "allow"}
{"commit_tokens": ["Moving", "the", "allocation", "outside", "."], "add_tokens": "buffer := make ( [ ] uint , 256 )", "del_tokens": "buffer := make ( [ ] uint , 256 )", "commit_type": "move"}
{"commit_tokens": ["Added", "path", "to", "trending", "developers"], "add_tokens": "parseURL += developersPath", "del_tokens": "parseURL += \" \" + modeDevelopers", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "union", "with", "empty", "bm"], "add_tokens": "var o_last_Key = uint64 ( 0xdeadbeef )", "del_tokens": "var o_last_Key = uint64 ( 0 )", "commit_type": "fix"}
{"commit_tokens": ["Added", "NewTLSDial", "()", "and", "NewTLSListener", "()", "helpers", "for", "TLS", "transport"], "add_tokens": "// If you need encrypted transport, then feel free using NewTLSDial() // on the client and NewTLSListener() helpers on the server. //", "del_tokens": "\" \" var ( dialer = & net . Dialer { Timeout : 10 * time . Second , KeepAlive : 30 * time . Second , } defaultDial = func ( addr string ) ( conn io . ReadWriteCloser , err error ) { return dialer . Dial ( \" \" , addr ) } )", "commit_type": "add"}
{"commit_tokens": ["use", "no", "proxy", "for", "testing"], "add_tokens": "\" \" d . httpClient = getClient ( http . ProxyFromEnvironment ) return d } func NewNoProxy ( ) * downloader { d := new ( downloader ) d . httpClient = getClient ( nil ) func getClient ( proxy ProxyFunc ) * http . Client { Proxy : proxy , type ProxyFunc func ( req * http . Request ) ( * url . URL , error )", "del_tokens": "d . httpClient = getClient ( ) func getClient ( ) * http . Client { Proxy : http . ProxyFromEnvironment ,", "commit_type": "use"}
{"commit_tokens": ["fix", "race", "and", "reinit", "conn", ".", "Me", "on", "disconnect"], "add_tokens": "// if this is being called because we are reconnecting, conn.Me // will still have all the old channels referenced -- nuke them! if conn . Me != nil { conn . Me = conn . NewNick ( conn . Me . Nick , conn . Me . Ident , conn . Me . Name , \" \" ) } // reinit datastructures ready for next connection // do this here rather than after runLoop()'s for due to race conn . initialise ( )", "del_tokens": "// if we fall off the end here due to shutdown, // reinit everything once the runloop is done // so that Connect() can be called again. conn . initialise ( )", "commit_type": "fix"}
{"commit_tokens": ["Upgrade", "to", "weekly", ".", "2011", "-", "12", "-", "14"], "add_tokens": "job := <- client . JobQueue }", "del_tokens": "/ * job := <- client . JobQueue } * /", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "atoi32", "for", "large", "numbers", "on", "64", "bit", "OSes", "."], "add_tokens": "n , err := strconv . ParseInt ( s , 0 , 32 )", "del_tokens": "n , err := strconv . Atoi ( s )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "card", "list", "test", "."], "add_tokens": "defer client . Do ( nil , & DestroyCustomer { customer . ID } ) // see added cards (using pagination API to call twice) firstHalf := & omise . CardList { } list . Offset = 0 list . Limit = 1 if e := client . Do ( firstHalf , list ) ; ! a . NoError ( t , e ) { a . Len ( t , firstHalf . Data , 1 ) secondHalf := & omise . CardList { } list . Offset = 1 list . Limit = 1 if e := client . Do ( secondHalf , list ) ; ! a . NoError ( t , e ) { return } a . Len ( t , secondHalf . Data , 1 ) cards = & omise . CardList { List : omise . List { Offset : 0 , Limit : 0 } , Data : append ( firstHalf . Data , secondHalf . Data ... ) , }", "del_tokens": "// see added cards if e := client . Do ( cards , list ) ; ! a . NoError ( t , e ) {", "commit_type": "fix"}
{"commit_tokens": ["Implement", "RawSetInt", "and", "Hooker", "functions"], "add_tokens": "func SetHooker ( l * State , f Hook , mask byte , count int ) { func Hooker ( l * State ) Hook { return l . hooker } func HookerMask ( l * State ) byte { return l . hookMask } func HookerCount ( l * State ) int { return l . hookCount }", "del_tokens": "func SetHook ( l * State , f Hook , mask byte , count int ) {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "lint", "warnings", "in", "server", "."], "add_tokens": "// Errors returned by the backend when unable to successfully handle payload. ErrRateExceeded = errors . New ( \" \" ) ErrPaymentRequired = errors . New ( \" \" ) ErrUnauthorized = errors . New ( \" \" ) return ErrRateExceeded return ErrPaymentRequired return ErrUnauthorized", "del_tokens": "RateExceeded = errors . New ( \" \" ) PaymentRequired = errors . New ( \" \" ) Unauthorized = errors . New ( \" \" ) return RateExceeded return PaymentRequired return Unauthorized", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "the", "ChmodDir", "test", "is", "actually", "chmodding", "a", "dir"], "add_tokens": "mkdirp ( t , \" \" )", "del_tokens": "touch ( t , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Updated", "import", "path", "for", "bcrypt"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Update", "dfs", "(", "Depth", "First", "Search", ")", "with", "visualization"], "add_tokens": "var rs string rs += fmt . Sprintf ( \" u I D ) // rs += fmt.Sprintf(\"%v(timestamp: %v) → \", u.ID, u.StampD) return rs [ : len ( rs ) - 5 ]", "del_tokens": "s := \" \" s += fmt . Sprintf ( \" u I D ) // s += fmt.Sprintf(\"%v(timestamp: %v) → \", u.ID, u.StampD) return s [ : len ( s ) - 5 ]", "commit_type": "update"}
{"commit_tokens": ["added", "textareas", "and", "numbers", "to", "optional", "field", "spec"], "add_tokens": "// Validate the options for this field type xOptions , err := force . Metadata . ValidateFieldOptions ( parts [ 1 ] , optionMap ) if err != nil { ErrorAndExit ( err . Error ( ) ) } fmt . Println ( \" \" ) for key , val := range newOptions { fmt . Println ( \" \" + key + \" \" + val ) } newOptions = xOptions", "del_tokens": "//fmt.Println(\"options: \" + options[0] + \" - \" + options[1]) // Validate the options for this field type xOptions , err := force . Metadata . ValidateFieldOptions ( parts [ 1 ] , optionMap ) if err != nil { ErrorAndExit ( err . Error ( ) ) } fmt . Println ( \" \" ) for key , val := range newOptions { fmt . Println ( \" \" + key + \" \" + val ) } newOptions = xOptions", "commit_type": "add"}
{"commit_tokens": ["Remove", "un", "-", "needed", "variable"], "add_tokens": "TLSClientConfig : & tls . Config { InsecureSkipVerify : b . AllowInsecure , ServerName : b . Req . Host } ,", "del_tokens": "TLSClientConfig : & tls . Config { InsecureSkipVerify : b . AllowInsecure , ServerName : b . ServerName } ,", "commit_type": "remove"}
{"commit_tokens": ["use", "CommandRunner", "for", "cgroups", "management"], "add_tokens": "cgroupsManager := cgroups_manager . New ( \" \" , id , p . runner )", "del_tokens": "cgroupsManager := cgroups_manager . New ( \" \" , id )", "commit_type": "use"}
{"commit_tokens": ["use", "chan", "for", "async", "logging"], "add_tokens": "\" \" func ( logger * Logger ) watchLog ( ) { var buf bytes . Buffer for true { for i := 0 ; i < 1000 ; i ++ { select { case msg := <- logger . queue : fmt . Fprintln ( & buf , msg ) case <- logger . flush : logger . out . Write ( buf . Bytes ( ) ) buf . Reset ( ) } } logger . out . Write ( buf . Bytes ( ) ) buf . Reset ( ) } } logger . queue <- message logger . queue <- message", "del_tokens": "go logger . printLog ( message ) go logger . printLog ( message )", "commit_type": "use"}
{"commit_tokens": ["Added", "limit", "processing", "to", "backend"], "add_tokens": "\" \" MaxMessages uint64 MaxBytes uint64 keepSending chan struct { } currentMessages uint64 currentBytes uint64 keepSending : make ( chan struct { } ) , // Limit the messages/bytes per second go func ( ) { for { timer := time . NewTimer ( 1 * time . Second ) <- timer . C f . keepSending <- struct { } { } } } ( ) atomic . AddUint64 ( & f . counter , 1 ) atomic . AddUint64 ( & f . currentMessages , 1 ) atomic . AddUint64 ( & f . currentBytes , uint64 ( message . OutputBuffer . Len ( ) ) ) // Wait if the limit has ben reached if f . config . MaxMessages > 0 && f . currentMessages >= f . config . MaxMessages { <- f . keepSending atomic . StoreUint64 ( & f . currentMessages , 0 ) } else if f . config . MaxBytes > 0 && f . currentBytes >= f . config . MaxBytes { <- f . keepSending atomic . StoreUint64 ( & f . currentBytes , 0 ) }", "del_tokens": "f . counter ++", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "makefont", "utility", "has", "been", "built", "before", "running", "test"], "add_tokens": "var out [ ] byte var err error // Make sure makefont utility has been built before generating font definition file err = exec . Command ( \" \" , \" \" ) . Run ( ) if err != nil { t . Fatal ( err ) } out , err = exec . Command ( \" \" , \" \" , \" \" ,", "del_tokens": "out , err := exec . Command ( \" \" , \" \" , \" \" ,", "commit_type": "make"}
{"commit_tokens": ["Fix", "condition", "causing", "missing", "vertical", "GridLines", "."], "add_tokens": "if ticcnt >= 0 && ticcnt <= len ( rng . Tics ) - 1 && rng . TicSetting . Grid == GridLines {", "del_tokens": "if ticcnt > 0 && ticcnt < len ( rng . Tics ) - 1 && rng . TicSetting . Grid == GridLines {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "the", "organizations", "endpoint"], "add_tokens": "ACLs * ACLService Clients * ApiClientService Cookbooks * CookbookService DataBags * DataBagService Environments * EnvironmentService Groups * GroupService Nodes * NodeService Organizations * OrganizationService Principals * PrincipalService Roles * RoleService Sandboxes * SandboxService Search * SearchService c . Organizations = & OrganizationService { client : c }", "del_tokens": "ACLs * ACLService Clients * ApiClientService Cookbooks * CookbookService DataBags * DataBagService Environments * EnvironmentService Groups * GroupService Nodes * NodeService Principals * PrincipalService Roles * RoleService Sandboxes * SandboxService Search * SearchService", "commit_type": "add"}
{"commit_tokens": ["use", "elasticsearch", "BulkAPI", "for", "indexing", "metricDefs"], "add_tokens": "var Indexer * elastigo . BulkIndexer Indexer = es . NewBulkIndexer ( 20 ) //dont retry sends. Indexer . RetryForSeconds = 0 // index at most 10k docs per request. Indexer . BulkMaxDocs = 10000 //flush at least every 10seconds. Indexer . BufferDelayMax = time . Second * 10 Indexer . Refresh = true Indexer . Start ( ) err = Indexer . Index ( \" \" , \" \" , m . Id , \" \" , \" \" , nil , m ) log . Printf ( \" \" )", "del_tokens": "resp , err := es . Index ( \" \" , \" \" , m . Id , nil , m ) log . Printf ( \" \\n \" , resp )", "commit_type": "use"}
{"commit_tokens": ["made", "minor", "map", "allocation", "/", "assigning", "changes", ".", "Updated", "benchmark"], "add_tokens": "var uriValues map [ string ] string uriValues = make ( map [ string ] string , len ( values ) - 1 ) return true , uriValues var params map [ string ] string ok := false", "del_tokens": "var uriValues = make ( map [ string ] string , len ( values ) - 1 ) return true , map [ string ] string { } params := make ( map [ string ] string ) ok := false", "commit_type": "make"}
{"commit_tokens": ["fix", "bug", "in", "in", "-", "memory", "storage", "(", "delete", "on", "invalid", "ID", ")"], "add_tokens": "\" \" var index int var ok bool if index , ok = memory . MessageIDIndex [ id ] ; ! ok && true { return errors . New ( \" \" ) }", "del_tokens": "index := memory . MessageIDIndex [ id ]", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "tags", "within", "logrus", ".", "Fields"], "add_tokens": "// These fields are: error, logger, server_name, http_request, tags if tags , ok := getAndDeleteTags ( d , \" \" ) ; ok { packet . Tags = tags } func getAndDeleteTags ( d logrus . Fields , key string ) ( raven . Tags , bool ) { if value , ok := d [ key ] . ( raven . Tags ) ; ok { delete ( d , key ) return value , true } return nil , false }", "del_tokens": "// These fields are: error, logger, server_name and http_request", "commit_type": "add"}
{"commit_tokens": ["Remove", "marketplace", "dep", "copy", "&", "pasta"], "add_tokens": "s := string ( b . StructSource ) return & s", "del_tokens": "\" \" return ptr . String ( string ( b . StructSource ) )", "commit_type": "remove"}
{"commit_tokens": ["Adds", "AllowedOrigins", "option", "to", "allow", "CORS", "csrf", "token", "generation"], "add_tokens": "// Array of allowed origins. Will be checked during generation from a cross site request. // Must be the complete origin. Example: 'https://golang.org'. You will only need to set this // if you are supporting CORS. AllowedOrigins [ ] string isAllowed := false for _ , origin := range opts . AllowedOrigins { if originUrl . String ( ) == origin { isAllowed = true break } } if ! isAllowed { return }", "del_tokens": "return", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "xp", "&", "ntfs", ";", "gopm", "build", "self", "bug", "fixed"], "add_tokens": "var isExistP , isCurChild bool if name == pkgName { continue }", "del_tokens": "var isExistP bool var isCurChild bool", "commit_type": "add"}
{"commit_tokens": ["Add", "basic", "support", "for", "semicolons"], "add_tokens": "return r == '#' || r == '=' || r == '&' || r == '|' || r == ';' p . got ( ';' )", "del_tokens": "return r == '#' || r == '=' || r == '&' || r == '|'", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "edge", "cases"], "add_tokens": "// Package pq implements a priority queue data structure on top of container/heap. // As an addition to regular operations, it allows an update of an items priority, // allowing the queue to be used in graph search algorithms like Dijkstra's algorithm. // Computational complexities of operations are mainly determined by container/heap. // In addition, a map of items is maintained, allowing O(1) lookup needed for priority updates, // which themselves are O(log n). // PriorityQueue represents the queue // New initializes an empty priority queue.", "del_tokens": "// PriorityQueue implements a priority queue data structure on top of container/heap. // As an addition to regular operations, it allows an update of an items priority, // allowing the queue to be used in graph search algorithms like Dijkstra's algorithm. // Computational complexities of operations are mainly determined by container/heap. // In addition, a map of items is maintained, allowing O(1) lookup needed for priority updates, // which themselves are O(log n). // NewPQ initializes an empty priority queue.", "commit_type": "add"}
{"commit_tokens": ["Fix", "docker", "cp", "Behavior", "With", "Symlinks"], "add_tokens": "// \"name\" is basename of the resource. Name string `json:\"name\"` Size int64 `json:\"size\"` Mode os . FileMode `json:\"mode\"` Mtime time . Time `json:\"mtime\"` LinkTarget string `json:\"linkTarget\"`", "del_tokens": "// \"name\" is the file or directory name. // \"path\" is the absolute path to the resource in the container. Name string `json:\"name\"` Path string `json:\"path\"` Size int64 `json:\"size\"` Mode os . FileMode `json:\"mode\"` Mtime time . Time `json:\"mtime\"`", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Grant", "()", "function", "and", "added", "accompanying", "test", "."], "add_tokens": "// Grant the specified permissions for a file. The new access control entries // will replace existing ones unless the replace parameter is false. func Grant ( name string , replace bool , entries ... api . ExplicitAccess ) error {", "del_tokens": "// Grant permission for a file to the provided SIDs. The new access control // entries will replace existing ones unless the replace parameter is false. func Grant ( name string , accessPermissions uint32 , replace bool , sids ... * windows . SID ) error { var entries = make ( [ ] api . ExplicitAccess , len ( sids ) ) for i , sid := range sids { entries [ i ] = api . ExplicitAccess { AccessPermissions : windows . GENERIC_ALL , AccessMode : api . GRANT_ACCESS , Inheritance : api . SUB_CONTAINERS_AND_OBJECTS_INHERIT , Trustee : api . Trustee { TrusteeForm : api . TRUSTEE_IS_SID , Name : ( * uint16 ) ( unsafe . Pointer ( sid ) ) , } , } } return nil", "commit_type": "update"}
{"commit_tokens": ["use", "SQLT_STR", "for", "*", "string"], "add_tokens": "sbind . kind = C . SQLT_STR sbind . kind = C . SQLT_AFC // don't trim strings !!!", "del_tokens": "sbind . kind = C . SQLT_AFC // don't trim strings !!!", "commit_type": "use"}
{"commit_tokens": ["Fix", "fs", ".", "Copy", "()", "to", "handle", "copying", "STI", "scripts"], "add_tokens": "if _ , err := os . Stat ( sourcePath ) ; err != nil { info , err := os . Stat ( targetPath ) if err != nil || ( info != nil && ! info . IsDir ( ) ) {", "del_tokens": "info , err := os . Stat ( sourcePath ) if err != nil { if ! info . IsDir ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "package", "prefix", "to", "errors"], "add_tokens": "ErrAbsentSubject = errors . New ( \" \" ) ErrAbsentPredicate = errors . New ( \" \" ) ErrAbsentObject = errors . New ( \" \" ) ErrUnterminated = errors . New ( \" \" )", "del_tokens": "ErrAbsentSubject = errors . New ( \" \" ) ErrAbsentPredicate = errors . New ( \" \" ) ErrAbsentObject = errors . New ( \" \" ) ErrUnterminated = errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "constructor", "for", "ReqLatencyCounter", "."], "add_tokens": "type limitStubThing time . Duration func ( l * limitStubThing ) Get ( ) time . Duration { return time . Duration ( * l ) limitStub := limitStubThing ( fastRequestLimit ) counter := NewReqLatencyCounter ( & limitStub ) counter . timeKeeper = timeStub", "del_tokens": "type limitStub time . Duration func ( l limitStub ) Get ( ) time . Duration { return time . Duration ( l ) limitStub := limitStub ( fastRequestLimit ) counter := ReqLatencyCounter { fastRequestLimitDuration : limitStub , timeKeeper : timeStub , }", "commit_type": "add"}
{"commit_tokens": ["Add", "Custom", "Config", "for", "Plush"], "add_tokens": "func Init ( box packd . Walkable , config PlushConfig ) error { x , err := render ( file , config )", "del_tokens": "func Init ( box packd . Walkable ) error { x , err := render ( file )", "commit_type": "add"}
{"commit_tokens": ["Add", "specific", "error", "message", "in", "marshal", "error"], "add_tokens": "fmt . Sprintf ( \" \" , option . Value . Type ( ) , err . Error ( ) ) )", "del_tokens": "fmt . Sprintf ( \" \" , option . Value . Type ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["fixes", "bug", "with", "parsing", "of", "environment", "variables", "and", "headers", "into", "context"], "add_tokens": "vs := strings . SplitN ( e , \" \" , 2 ) vs := strings . SplitN ( e , \" \" , 2 )", "del_tokens": "vs := strings . SplitN ( e , \" \" , 1 ) vs := strings . SplitN ( e , \" \" , 1 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "volume", "and", "snapshot", "tracking", "in", "global", "configuration", "file"], "add_tokens": "if _ , exists := b . Volumes [ volumeId ] ; exists { return fmt . Errorf ( \" \" , volumeId , id ) } volumeDir := filepath . Join ( BLOCKSTORE_BASE , VOLUME_DIRECTORY , volumeId ) err = driver . MkDirAll ( volumeDir ) log . Debug ( \" \" , volumeDir ) if _ , exists := b . Volumes [ volumeId ] ; ! exists { return fmt . Errorf ( \" \" , volumeId , id ) } volumeDir := filepath . Join ( BLOCKSTORE_BASE , VOLUME_DIRECTORY , volumeId ) err = driver . RemoveAll ( volumeDir ) log . Debug ( \" \" , volumeDir )", "del_tokens": "volumeBase := filepath . Join ( BLOCKSTORE_BASE , VOLUME_DIRECTORY , volumeId ) err = driver . MkDirAll ( volumeBase ) log . Debug ( \" \" , volumeBase ) volumeBase := filepath . Join ( BLOCKSTORE_BASE , VOLUME_DIRECTORY , volumeId ) err = driver . RemoveAll ( volumeBase ) log . Debug ( \" \" , volumeBase )", "commit_type": "add"}
{"commit_tokens": ["remove", "static", "allocation", "for", "config", "buffer"], "add_tokens": "\" \" configBytes , err := ioutil . ReadFile ( getMcConfigFilename ( ) ) err = json . Unmarshal ( configBytes , config )", "del_tokens": "configFile , err := os . Open ( getMcConfigFilename ( ) ) defer configFile . Close ( ) var n int configBytes := make ( [ ] byte , 512 ) n , err = configFile . Read ( configBytes ) err = json . Unmarshal ( configBytes [ : n ] , & config )", "commit_type": "remove"}
{"commit_tokens": ["remove", "standalone", "encode", "function", "and", "clarify", "code", "comments"], "add_tokens": "// Encode marshals a Todo into a buffer. func ( todo * Todo ) Encode ( ) ( * bytes . Buffer , error ) { b , err := json . Marshal ( todo ) if err != nil { return & bytes . Buffer { } , err } return bytes . NewBuffer ( b ) , nil } body , err := todo . Encode ( ) return err /* -- UTILITY FUNCTIONS -- */", "del_tokens": "body , err := encode ( todo ) log . Print ( err ) /* -- CODEC -- */ // encode marshals a Todo into a buffer. func encode ( todo * Todo ) ( * bytes . Buffer , error ) { b , err := json . Marshal ( todo ) if err != nil { return & bytes . Buffer { } , err } return bytes . NewBuffer ( b ) , nil } /* -- UTILITY FUNCTIONS -- */", "commit_type": "remove"}
{"commit_tokens": ["Add", "additional", "info", "for", "secret", "drivers"], "add_tokens": "SecretLabels map [ string ] string `json:\",omitempty\"` // SecretLabels capture environment names and other metadata pertaining to the secret ServiceID string `json:\",omitempty\"` // ServiceID is the name of the service that requested the secret ServiceLabels map [ string ] string `json:\",omitempty\"` // ServiceLabels capture environment names and other metadata pertaining to the service TaskID string `json:\",omitempty\"` // TaskID is the ID of the task that the secret is assigned to TaskName string `json:\",omitempty\"` // TaskName is the name of the task that the secret is assigned to", "del_tokens": "ServiceLabels map [ string ] string `json:\",omitempty\"` // ServiceLabels capture environment names and other metadata", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "credit", "card", "requests", "and", "responses"], "add_tokens": "AvailBalAmt * Amount `xml:\"CCSTMTRS>AVAILBAL>BALAMT,omitempty\"`", "del_tokens": "AvailBalAmt Amount `xml:\"CCSTMTRS>AVAILBAL>BALAMT,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["add", "fluent", ".", "PostWithTime", "method"], "add_tokens": "// // send message with specified time // mapStringData := map[string]string{ // \"foo\": \"bar\", // } // tm := time.Now() // f.PostWithTime(\"tag_name\", tm, mapStringData) // timeNow := time . Now ( ) f . PostWithTime ( tag , timeNow , message ) } func ( f * Fluent ) PostWithTime ( tag string , tm time . Time , message interface { } ) { timeUnix := tm . Unix ( ) msg := [ ] interface { } { tag , timeUnix , message }", "del_tokens": "timeNow := time . Now ( ) . Unix ( ) msg := [ ] interface { } { tag , timeNow , message }", "commit_type": "add"}
{"commit_tokens": ["Update", "App", "to", "use", "new", "registry", "package", "."], "add_tokens": "Running bool interval time . Duration func NewHeartbeater ( registration * AppRegistration , strategy RegistrationStrategy , interval time . Duration ) * Heartbeater { return & Heartbeater { registration : registration , strategy : strategy , interval : interval } h . Running = true h . ticker = time . NewTicker ( h . interval ) h . Running = false } // Toggle starts or stops the Heartbeater based on whether it is already running. func ( h * Heartbeater ) Toggle ( ) { if h . Running { h . Stop ( ) } else { h . Start ( ) }", "del_tokens": "func NewHeartbeater ( registration * AppRegistration , strategy RegistrationStrategy ) * Heartbeater { return & Heartbeater { registration : registration , strategy : strategy } h . ticker = time . NewTicker ( 10 * time . Millisecond )", "commit_type": "update"}
{"commit_tokens": ["use", "a", "constructor", "to", "build", "new", "FTPConn", "s"], "add_tokens": "const ( welcomeMessage = \" \" USER = \" \" PASS = \" \" ) conn * net . TCPConn func NewFTPConn ( tcpConn * net . TCPConn ) * FTPConn { c := new ( FTPConn ) c . cwd = \" \" c . conn = tcpConn c . controlReader = bufio . NewReader ( tcpConn ) c . controlWriter = bufio . NewWriter ( tcpConn ) return c } ftpConn . conn . Close ( )", "del_tokens": "control * net . TCPConn ftpConn . control . Close ( )", "commit_type": "use"}
{"commit_tokens": ["make", "static", "configuration", "compatible", "with", "the", "new", "changes"], "add_tokens": "TrustedAuthorities : cfg . Auth . TrustedAuthorities . Authorities ( ) , acfg . UserCA = cfg . Auth . UserCA . CA ( ) acfg . HostCA = cfg . Auth . HostCA . CA ( )", "del_tokens": "TrustedAuthorities : convertRemoteCerts ( cfg . Auth . TrustedAuthorities ) , acfg . UserCA = cfg . Auth . UserCA . ToCA ( ) acfg . UserCA . ID = string ( acfg . UserCA . PublicKey ) acfg . HostCA = cfg . Auth . HostCA . ToCA ( ) acfg . HostCA . ID = string ( acfg . HostCA . PublicKey )", "commit_type": "make"}
{"commit_tokens": ["Use", "length", "in", "header", "when", "receiving", "response", "data"], "add_tokens": "length , err := strconv . Atoi ( string ( bytes . TrimSpace ( data [ 5 : 15 ] ) ) ) if err != nil { return nil , err } remainder := length data = make ( [ ] byte , remainder ) remainder -= n if remainder <= 0 {", "del_tokens": "data = make ( [ ] byte , bufferSize ) // New line signals the end of content. This check helps // if the connection is not forcibly closed if n != bufferSize && data [ n - 1 ] == byte ( '\\n' ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "Each", "()", "method", "for", "validating", "iterables", "."], "add_tokens": "m1 := Model1 { A : \" \" , B : \" \" , c : \" \" , G : \" \" , H : [ ] string { \" \" , \" \" } , I : map [ string ] string { \" \" : \" \" } } { \" \" , & m1 , [ ] * FieldRules { Field ( & m1 . H , Each ( & validateAbc { } ) ) , Field ( & m1 . I , Each ( & validateAbc { } ) ) } , \" \" } , { \" \" , & m1 , [ ] * FieldRules { Field ( & m1 . H , Each ( & validateXyz { } ) ) , Field ( & m1 . I , Each ( & validateXyz { } ) ) } , \" \" } ,", "del_tokens": "m1 := Model1 { A : \" \" , B : \" \" , c : \" \" , G : \" \" }", "commit_type": "add"}
{"commit_tokens": ["Added", "documentation", "on", "benchmarks", "."], "add_tokens": "func BenchmarkComplexCreation ( b * testing . B ) { func BenchmarkLargeRepeatCreateSerial ( b * testing . B ) { for i := 0 ; i < b . N ; i ++ { NewGenerator ( `a{999}` , & GeneratorArgs { RngSource : rand . NewSource ( 0 ) , } ) } } func BenchmarkComplexGeneration ( b * testing . B ) { func BenchmarkLargeRepeatGenerateSerial ( b * testing . B ) { generator , err := NewGenerator ( `a{999}` , & GeneratorArgs { RngSource : rand . NewSource ( 0 ) , } ) if err != nil { b . Fatal ( err ) } b . ResetTimer ( ) for i := 0 ; i < b . N ; i ++ { generator . Generate ( ) } }", "del_tokens": "func BenchmarkCreation ( b * testing . B ) { func BenchmarkGeneration ( b * testing . B ) {", "commit_type": "add"}
{"commit_tokens": ["add", "reused", "google", "option", "and", "fix", "name", "machine", "customization"], "add_tokens": "driver := digitalocean . NewDriver ( p . Name , clientPath ) driver . AccessToken = token", "del_tokens": "driver := digitalocean . NewDriver ( name , clientPath )", "commit_type": "add"}
{"commit_tokens": ["add", "goroutine", "safety", "note", "on", "Client", "struct", "doc"], "add_tokens": "// A Client is a handle for sending udp messages to dogstatsd. It is safe to // use one Client from multiple goroutines simultaneously.", "del_tokens": "// A Client is a handle for sending udp messages to dogstatsd.", "commit_type": "add"}
{"commit_tokens": ["make", "nicer", "json", "endpoint", "for", "the", "application"], "add_tokens": "ctx . JSON ( http . StatusOK , gin . H { \" \" : map [ string ] string { \" \" : \" \" , \" \" : \" \" } , \" \" : map [ string ] string { \" \" : \" \" , \" \" : \" \" } } )", "del_tokens": "ctx . JSON ( http . StatusOK , gin . H { \" \" : \" \" } )", "commit_type": "make"}
{"commit_tokens": ["Fixed", "some", "errors", "in", "the", "docs", "for", "PutVhost", "and", "UpdatePermissionsIn"], "add_tokens": "resp , err := rmqc . PutVhost ( \" \" , VhostSettings { Tracing : false } ) resp , err := rmqc . UpdatePermissionsIn ( \" \" , \" \" , Permissions { Configure : \" \" , Write : \" \" , Read : \" \" } )", "del_tokens": "resp , err := rmqc . PutVhost ( \" \" ) resp , err := rmqc . UpdatePermissionsIn ( \" \" , \" \" , Permission { Configure : \" \" , Write : \" \" , Read : \" \" } )", "commit_type": "fix"}
{"commit_tokens": ["fix", "property", "name", "in", "CreationPolicy"], "add_tokens": "// ResourceSignal configures the number of required success signals and the length of time that AWS CloudFormation waits for those signals. ResourceSignal * ResourceSignal `json:\"ResourceSignal,omitempty\"` // ResourceSignal configures the number of required success signals and the length of time that AWS CloudFormation waits for those signals. type ResourceSignal struct {", "del_tokens": "// ResourcesSignal configures the number of required success signals and the length of time that AWS CloudFormation waits for those signals. ResourcesSignal * ResourcesSignal `json:\"ResourcesSignal,omitempty\"` // ResourcesSignal configures the number of required success signals and the length of time that AWS CloudFormation waits for those signals. type ResourcesSignal struct {", "commit_type": "fix"}
{"commit_tokens": ["Add", "MD5", "public", "key", "fingerprints", "as", "computed", "attributes", "."], "add_tokens": "expectedPublicSSH = `ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDPLaq43D9C596ko9yQipWUf2FbRhFs18D3wBDBqXLIoP7W3rm5S292/JiNPa+mX76IYFF416zTBGG9J5w4d4VFrROn8IuMWqHgdXsCUf2szN7EnJcVBsBzTxxWqz4DjX315vbm/PFOLlKzC0Ngs4h1iDiCD9Hk2MajZuFnJiqj1Q==` expectedPublicFingerprintMD5 = `62:c2:c6:7a:d0:27:72:e7:0d:bc:4e:97:42:0e:9e:e6` resource . TestCheckResourceAttr ( \" \" , \" \" , strings . TrimSpace ( expectedPublicFingerprintMD5 ) ) ,", "del_tokens": "expectedPublicSSH = `ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDPLaq43D9C596ko9yQipWUf2FbRhFs18D3wBDBqXLIoP7W3rm5S292/JiNPa+mX76IYFF416zTBGG9J5w4d4VFrROn8IuMWqHgdXsCUf2szN7EnJcVBsBzTxxWqz4DjX315vbm/PFOLlKzC0Ngs4h1iDiCD9Hk2MajZuFnJiqj1Q==`", "commit_type": "add"}
{"commit_tokens": ["changed", "ciphersuites", "from", "object", "array", "to", "map", "using", "algorithm", "preference", "as", "key", ".", "This", "will", "enable", "result", "visualisation", "in", "kibana", "."], "add_tokens": "ConnectionTimestamp string `json:\"connectionTimestamp\"` ServerSide bool `json:\"serverside\"` CipherSuites map [ string ] ConnectionCiphersuite `json:\"ciphersuite\"` CurvesFallback bool `json:\"curvesFallback\"` c . CipherSuites = make ( map [ string ] ConnectionCiphersuite ) pos := 1 c . CipherSuites [ strconv . Itoa ( pos ) ] = newcipher pos ++", "del_tokens": "ConnectionTimestamp string `json:\"connectionTimestamp\"` ServerSide bool `json:\"serverside\"` CipherSuites [ ] ConnectionCiphersuite `json:\"ciphersuite\"` CurvesFallback bool `json:\"curvesFallback\"` c . CipherSuites = append ( c . CipherSuites , newcipher )", "commit_type": "change"}
{"commit_tokens": ["Add", "example", "of", "errors", "and", "some", "tests", "for", "errors"], "add_tokens": "\" \" // <div id=\"5\"><h1><span></span></h1></div> h1 := doc . Find ( \" \" , \" \" , \" \" ) . Find ( \" \" ) if h1 . Error != nil { assert . Equal ( t , ErrElementNotFound , h1 . Error . ( Error ) . Type ) } if h1 . FullText ( ) != \" \" { func TestNewErrorReturnsInspectableError ( t * testing . T ) { err := newError ( ErrElementNotFound , \" \" ) assert . NotNil ( t , err ) assert . Equal ( t , ErrElementNotFound , err . Type ) assert . Equal ( t , \" \" , err . Error ( ) ) } func TestFindReturnsInspectableError ( t * testing . T ) { r := doc . Find ( \" \" , \" \" ) assert . IsType ( t , Error { } , r . Error ) assert . Equal ( t , \" \" , r . Error . Error ( ) ) assert . Equal ( t , ErrElementNotFound , r . Error . ( Error ) . Type ) }", "del_tokens": "// <div id=\"5\"><h1><span></span></h1></div> h1 := doc . Find ( \" \" , \" \" , \" \" ) . Find ( \" \" ) if h1 . FullText ( ) != \" \" {", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "ensure", "sanitized", "extensions", "are", "properly", "returned", "when", "reading", "from", "the", "extensions", "file", "."], "add_tokens": "sanitizedExtensions = append ( sanitizedExtensions , extension )", "del_tokens": "extensions = append ( extensions , extension )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "comment", "in", "driver", ".", "go", "."], "add_tokens": "// AcceptValue accepts the specified control value sent via an MQTT value topic", "del_tokens": "// AcceptOnValue accepts the specified control value sent via an MQTT value topic", "commit_type": "fix"}
{"commit_tokens": ["add", "convert", "0", "to", "int64"], "add_tokens": "return err == nil && status != int64 ( 0 ) return err == nil && status != int64 ( 0 )", "del_tokens": "return err == nil && status != 0 return err == nil && status != 0", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "workpool", "to", "minimize", "goroutines"], "add_tokens": "\" \" emitter := initializeNatsEmitter ( natsClient , logger ) monitor := ifrit . Invoke ( sigmon . New ( group ) ) pool := workpool . New ( 10 , 10 , workpool . DefaultAround ) return nats_emitter . New ( natsClient , pool , logger ) workpool . NewWorkPool ( 10 ) ,", "del_tokens": "\" \" var emitter * nats_emitter . NATSEmitter emitter = initializeNatsEmitter ( natsClient , logger ) monitor := ifrit . Envoke ( sigmon . New ( group ) ) return nats_emitter . New ( natsClient , logger ) workerpool . NewWorkerPool ( 10 ) ,", "commit_type": "use"}
{"commit_tokens": ["Changed", "format", "string", "calculation", "with", "a", "loop", "counter", "so", "that", "we", "can", "just", "generate", "the", "string", "properly", "the", "first", "time", "rather", "than", "generating", "a", "string", "and", "then", "trimming", "it", "with", "the", "strings", "library", "."], "add_tokens": "for i := 0 ; i < len ( widths ) ; i ++ { if i == len ( widths ) - 1 { stringfmt += \" \\n \" } else { stringfmt += fmt . Sprintf ( \" \" , widths [ i ] + 2 ) } result += fmt . Sprintf ( stringfmt , elems ... )", "del_tokens": "for _ , w := range widths { stringfmt += fmt . Sprintf ( \" \" , w ) result += strings . TrimRight ( fmt . Sprintf ( stringfmt , elems ... ) , \" \" ) + \" \\n \"", "commit_type": "change"}
{"commit_tokens": ["Add", "escape", "to", "initial", "scanner", "mode"], "add_tokens": "t . scanner . mode = scanIdent | scanLbrack | scanEscape", "del_tokens": "t . scanner . mode = scanIdent | scanLbrack", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "panic", "for", "and", "invalid", "terrain", "map", "slicing", "operation"], "add_tokens": "Cell { - 100 , 100 } , Cell { 100 , - 100 } ,", "del_tokens": "Cell { - 10 , 10 } , Cell { 10 , - 10 } ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "embed", "for", "calls", "to", "MustFindBox", "(", "..", ")"], "add_tokens": "regexpBox , err := regexp . Compile ( `rice\\.(?:Must)?FindBox\\([\"` + \" \" + `]{1}([a-zA-Z0-9\\\\/\\.-]+)[\"` + \" \" + `]{1}\\)` )", "del_tokens": "regexpBox , err := regexp . Compile ( `rice\\.FindBox\\([\"` + \" \" + `]{1}([a-zA-Z0-9\\\\/\\.-]+)[\"` + \" \" + `]{1}\\)` )", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "latest", "chrome", "protocol", ".", "json"], "add_tokens": "InitiatorTypeParser InitiatorType = \" \" InitiatorTypeScript InitiatorType = \" \" InitiatorTypePreload InitiatorType = \" \" InitiatorTypeOther InitiatorType = \" \" case InitiatorTypePreload : * t = InitiatorTypePreload", "del_tokens": "InitiatorTypeParser InitiatorType = \" \" InitiatorTypeScript InitiatorType = \" \" InitiatorTypeOther InitiatorType = \" \"", "commit_type": "update"}
{"commit_tokens": ["fix", "example", "name", "again!", "organize", "under", "Env", ".", "SetMapSize", "with", "second", "example"], "add_tokens": "// This example demonstrates how an application typically uses Env.SetMapSize. // The call to Env.SetMapSize() is made before calling env.Open(). Any calls // after calling Env.Open() must take special care to synchronize with other // goroutines. func ExampleEnv_SetMapSize ( ) { env , err := NewEnv ( ) if err != nil { // ... } // set the memory map size (maximum database size) to 1GB. err = env . SetMapSize ( 1 << 30 ) if err != nil { // ... } err = env . Open ( \" \" , 0 , 0644 ) if err != nil { // ... } // ... } func ExampleEnv_SetMapSize_mapResized ( ) {", "del_tokens": "func Example_IsMapResized ( ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "BindInterval", "delay", "(", "if", "given", ")", "instead", "of", "exponent", "growth"], "add_tokens": "delayDuration := c . BindInterval if delayDuration == 0 { delay = math . Min ( delay * math . E , maxdelay ) delayDuration = time . Duration ( delay ) * time . Second } c . trysleep ( delayDuration )", "del_tokens": "delay = math . Min ( delay * math . E , maxdelay ) c . trysleep ( time . Duration ( delay ) * time . Second )", "commit_type": "use"}
{"commit_tokens": ["add", "multiple", "hasone", "and", "belongsto"], "add_tokens": "codegen . SimpleImport ( \" \" ) ,", "del_tokens": "codegen . SimpleImport ( \" \" ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "better", "subsequent", "Sync", "call", "test"], "add_tokens": "assert . NoError ( t , f . Sync ( ) )", "del_tokens": "assert . NoError ( t , f . Sync ( ) )", "commit_type": "add"}
{"commit_tokens": ["added", "stop", "kite", "and", "checks", "for", "start", "kite"], "add_tokens": "\" \" var err = errors . New ( \" \" )", "del_tokens": "var err error", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "unique", "encoding", "for", "keys"], "add_tokens": "return k . Encode ( )", "del_tokens": "return k . String ( )", "commit_type": "use"}
{"commit_tokens": ["Make", "unit", "-", "tests", "run", "in", "a", "vagrant", "sandbox", "to", "accomodate", "tests", "with"], "add_tokens": "} else {", "del_tokens": "} else if ! isCreateEp {", "commit_type": "make"}
{"commit_tokens": ["Allow", "tasks", "to", "request", "multiple", "tokens", "before", "their", "maximum", "allowable"], "add_tokens": "Policies [ ] string `json:\"policies\"` Meta map [ string ] string `json:\"meta,omitempty\"` Ttl int `json:\"ttl,omitempty\"` NumUses int `json:\"num_uses,omitempty\"` MultiFetch bool `json:\"multi_fetch,omitempty\"` MultiFetchLimit int `json:\"multi_fetch_limit,omitempty\"`", "del_tokens": "Policies [ ] string `json:\"policies\"` Meta map [ string ] string `json:\"meta,omitempty\"` Ttl int `json:\"ttl,omitempty\"` NumUses int `json:\"num_uses,omitempty\"`", "commit_type": "allow"}
{"commit_tokens": ["added", "GetOfficialVersions", "moving", "helpers", "to", "their", "own", "file"], "add_tokens": "latest := candidates [ len ( candidates ) - 1 ] fmt . Println ( latest ) //runt //for _, value := range candidates { // fmt.Println(value) //}", "del_tokens": "for _ , value := range candidates { fmt . Println ( value ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "log", "to", "an", "io", ".", "Writer", "when", "a", "panic", "occurs"], "add_tokens": "log . Println ( string ( debug . Stack ( ) ) )", "del_tokens": "log . Println ( lh ) log . Println ( string ( debug . Stack ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "download", "Bank", "Transactions"], "add_tokens": "Banking [ ] Message //<BANKMSGSETV1> if err := oq . marshalMessageSet ( encoder , oq . Banking , \" \" ) ; err != nil { return nil , err } func ( oq * Request ) Request ( ) ( * http . Response , error ) { return response , nil } func ( oq * Request ) RequestAndParse ( ) ( * Response , error ) { response , err := oq . Request ( ) if err != nil { return nil , err } defer response . Body . Close ( ) Banking [ ] Message //<BANKMSGSETV1> case \" \" : msgs , err := DecodeBankingMessageSet ( decoder , start ) if err != nil { return err } or . Banking = msgs", "del_tokens": "//<BANKMSGSETV1> func ( oq * Request ) Request ( ) ( * Response , error ) { defer response . Body . Close ( ) //<BANKMSGSETV1> //case \"BANKMSGSRSV1\":", "commit_type": "add"}
{"commit_tokens": ["add", "call", "to", "allow", "main", "functions", "to", "generate", "dart", "source", "to", "a", "file"], "add_tokens": "//used by the TypeHolder (probably a dispatcher) to map its rest resources. This can be used if you //want to make a _live_ URL to the generated code. This is usually unnecessary and is typically //handled by the FileContent method to generate a static dart file once per server invocation. func generatedDartContent ( mux * ServeMux , holder TypeHolder , urlPath string , restPrefix string ) { mux . HandleFunc ( fmt . Sprintf ( \" \" , urlPath ) , generateDartFunc ( holder , restPrefix ) ) }", "del_tokens": "//used by the TypeHolder (probably a dispatcher) to map its rest resources. //func GeneratedDartContent(mux *ServeMux, holder TypeHolder, urlPath string, restPrefix string) { // mux.HandleFunc(fmt.Sprintf(\"%sdart\", urlPath), generateDartFunc(holder, restPrefix)) //}", "commit_type": "add"}
{"commit_tokens": ["added", "pass", "through", "auth", "option"], "add_tokens": "return fmt . Sprintf ( \" \" , err . StatusCode , err . Method , err . URL , err . ErrorCode , err . Reason )", "del_tokens": "return fmt . Sprintf ( \" \" , err . Method , err . URL , err . StatusCode , err . ErrorCode , err . Reason )", "commit_type": "add"}
{"commit_tokens": ["Updated", "methods", "to", "return", "errors", "instead", "of", "printing", "them", "."], "add_tokens": "\" \" func ( r * Regression ) RunLinearRegression ( ) error { return errors . New ( \" \" ) return fmt . Errorf ( \" \" , numOfVars ) return err return nil func ( r * Regression ) Dump ( data bool ) error { return errors . New ( \" \" ) return nil", "del_tokens": "func ( r * Regression ) RunLinearRegression ( ) { fmt . Println ( \" \" ) return fmt . Println ( \" \" ) return fmt . Println ( err ) return func ( r * Regression ) Dump ( data bool ) { fmt . Println ( \" \" ) return", "commit_type": "update"}
{"commit_tokens": ["moved", "tests", "into", "jwt_test", "package", "for", "better", "clarity"], "add_tokens": "package jwt_test \" \" method := jwt . GetSigningMethod ( data . alg ) method := jwt . GetSigningMethod ( data . alg )", "del_tokens": "package jwt method := GetSigningMethod ( data . alg ) method := GetSigningMethod ( data . alg )", "commit_type": "move"}
{"commit_tokens": ["Make", "Centroid", ".", "count", "a", "uint"], "add_tokens": "var tot uint = 0", "del_tokens": "var tot float64 = 0", "commit_type": "make"}
{"commit_tokens": ["Remove", "-", "v", "as", "a", "synonym", "for", "--", "version", "."], "add_tokens": "addOpt ( opt { [ ] string { \" \" } , \" \" , \" \" , false , nil ,", "del_tokens": "addOpt ( opt { [ ] string { \" \" , \" \" } , \" \" , \" \" , false , nil ,", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "label", "for", "the", "int64", "negatives", "property", "test", "."], "add_tokens": "commonGeneratorTest ( t , \" \" , gen . Int64Range ( math . MinInt64 , - 1 ) , func ( value interface { } ) bool {", "del_tokens": "commonGeneratorTest ( t , \" \" , gen . Int64Range ( math . MinInt64 , - 1 ) , func ( value interface { } ) bool {", "commit_type": "fix"}
{"commit_tokens": ["Add", "submenu", "support", "for", "Linux"], "add_tokens": "subMenuTop := systray . AddMenuItem ( \" \" , \" \" ) subMenuMiddle := subMenuTop . AddSubMenuItem ( \" \" , \" \" ) subMenuBottom := subMenuMiddle . AddSubMenuItemCheckbox ( \" \" , \" \" , false ) subMenuBottom2 := subMenuMiddle . AddSubMenuItem ( \" \" , \" \" )", "del_tokens": "subMenuTop := systray . AddMenuItem ( \" \" , \" \" ) subMenuMiddle := subMenuTop . AddSubMenuItem ( \" \" , \" \" ) subMenuBottom := subMenuMiddle . AddSubMenuItemCheckbox ( \" \" , \" \" , false ) subMenuBottom2 := subMenuMiddle . AddSubMenuItem ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Make", "sublist", "its", "own", "package"], "add_tokens": "package sublist", "del_tokens": "package gnatsd", "commit_type": "make"}
{"commit_tokens": ["Move", "Business", "Logic", "into", "Logic", "package"], "add_tokens": "\" \" cryptoEngine := crypto . NewEngine ( s , db ) lEngine := logic . NewEngine ( c , s , db , cryptoEngine , client ) mux . PostFunc ( \" \" , keypairsGenerateRoute ( lEngine , o ) ) mux . GetFunc ( \" \" , credentialsGetRoute ( lEngine , o ) ) mux . PostFunc ( \" \" , credentialsPostRoute ( lEngine , o ) ) orgInvitesApproveRoute ( lEngine , o ) ) func encodeResponseErr ( w http . ResponseWriter , err interface { } ) {", "del_tokens": "engine := crypto . NewEngine ( s , db ) mux . PostFunc ( \" \" , keypairsGenerateRoute ( client , s , db , engine , o ) ) mux . GetFunc ( \" \" , credentialsGetRoute ( client , s , engine , o ) ) mux . PostFunc ( \" \" , credentialsPostRoute ( client , s , engine , o ) ) orgInvitesApproveRoute ( client , s , db , engine , o ) ) func encodeResponseErr ( w http . ResponseWriter , err error ) {", "commit_type": "move"}
{"commit_tokens": ["Change", "stack", ".", "Stats", "()", "to", "read", "each", "stat", "using", "atomic", "instructions", "instead", "of"], "add_tokens": "\" \" // // NOTE: The underlying stats are updated using atomic instructions as a result // the snapshot returned does not represent the value of all the stats at any // single given point of time. return tcpip . Stats { UnknownProtocolRcvdPackets : atomic . LoadUint64 ( & s . stats . UnknownProtocolRcvdPackets ) , UnknownNetworkEndpointRcvdPackets : atomic . LoadUint64 ( & s . stats . UnknownNetworkEndpointRcvdPackets ) , MalformedRcvdPackets : atomic . LoadUint64 ( & s . stats . MalformedRcvdPackets ) , DroppedPackets : atomic . LoadUint64 ( & s . stats . DroppedPackets ) , }", "del_tokens": "return s . stats", "commit_type": "change"}
{"commit_tokens": ["update", "version", "of", "go", "-", "multiaddr"], "add_tokens": "proto \" \"", "del_tokens": "proto \" \"", "commit_type": "update"}
{"commit_tokens": ["Change", "flag", ".", "Duration", "descriptions", "to", "be", "unit", "-", "free", "."], "add_tokens": "syncFrequency = flag . Duration ( \" \" , 10 * time . Second , \" \" ) fileCheckFrequency = flag . Duration ( \" \" , 20 * time . Second , \" \" ) httpCheckFrequency = flag . Duration ( \" \" , 20 * time . Second , \" \" )", "del_tokens": "syncFrequency = flag . Duration ( \" \" , 10 * time . Second , \" \" ) fileCheckFrequency = flag . Duration ( \" \" , 20 * time . Second , \" \" ) httpCheckFrequency = flag . Duration ( \" \" , 20 * time . Second , \" \" )", "commit_type": "change"}
{"commit_tokens": ["add", "stringers", "to", "display", "history", "neatly"], "add_tokens": "\" \" //QAPairs is a slice of QAPair type QAPairs [ ] QAPair func ( q QAPair ) String ( ) string { return fmt . Sprintf ( \" \" , q . Question , q . Answer ) } func ( q QAPairs ) String ( ) string { result := \" \" for i , pair := range q { if i + 1 == len ( q ) { result += fmt . Sprintf ( \" \" , i + 1 , pair ) } else { result += fmt . Sprintf ( \" \\n \" , i + 1 , pair ) } } return result } //History returns an array of QApair of upto 100 interactions that have happened in Session. func ( s * Session ) History ( ) QAPairs {", "del_tokens": "//History returns an array of QApairs of upto 100 interactions that have happened in Session. func ( s * Session ) History ( ) [ ] QAPair {", "commit_type": "add"}
{"commit_tokens": ["Fix", "potential", "integer", "overflow", "."], "add_tokens": "i := h % uint64 ( n )", "del_tokens": "i := int ( h ) % n", "commit_type": "fix"}
{"commit_tokens": ["Creating", "a", "constructor", "for", "the", "FHIRServer"], "add_tokens": "func NewServer ( databaseHost string ) * FHIRServer { server := & FHIRServer { DatabaseHost : databaseHost , MiddlewareConfig : make ( map [ string ] [ ] negroni . Handler ) } server . Router = mux . NewRouter ( ) server . Router . StrictSlash ( true ) server . Router . KeepContext = true return server }", "del_tokens": "f . Router = mux . NewRouter ( ) f . Router . StrictSlash ( true ) f . Router . KeepContext = true", "commit_type": "create"}
{"commit_tokens": ["improved", "failure", "situations", "for", "default", "values"], "add_tokens": "// Do that for error checking (not necessary if value preset otherwise). defaultValue , e := handleDefault ( field , tagMap ) if e != nil { return fmt . Errorf ( `wrong value for \"default\" tag: %s` , e . Error ( ) ) } opt . value = defaultValue", "del_tokens": "opt . value , e = handleDefault ( field , tagMap ) if e != nil { return fmt . Errorf ( `wrong value for \"default\" tag: %s` , e . Error ( ) ) }", "commit_type": "improve"}
{"commit_tokens": ["move", "decoding", "to", "go", "-", "sawyer", "/", "mediatype"], "add_tokens": "\" \" func init ( ) { mediatype . AddDecoder ( \" \" , func ( r io . Reader ) mediatype . Decoder { return json . NewDecoder ( r ) } ) } return & Client { client , endpoint }", "del_tokens": "Decoders map [ string ] DecoderFunc } type DecoderFunc func ( r io . Reader ) Decoder type Decoder interface { Decode ( v interface { } ) error decoders := map [ string ] DecoderFunc { \" \" : func ( r io . Reader ) Decoder { return json . NewDecoder ( r ) } , } return & Client { client , endpoint , decoders }", "commit_type": "move"}
{"commit_tokens": ["Fixed", "tests", "up", "to", "master", "branch"], "add_tokens": "v , err := c . Get ( \" \" ) if err != nil { t . Errorf ( \" \" ) } if v != \" \" { templ , _ := template . New ( \" \" ) . Parse ( `Hello {{.Name}}` ) r . SetHTMLTemplate ( templ )", "del_tokens": "if v := c . Get ( \" \" ) ; v != \" \" { r . HTMLTemplates = template . Must ( template . New ( \" \" ) . Parse ( `Hello {{.Name}}` ) )", "commit_type": "fix"}
{"commit_tokens": ["made", "mongodb", "backend", "return", "error", "on", "creation"], "add_tokens": "func NewMongodbBackend ( mongoUrl string , database string ) ( b MongodbAuthBackend , e error ) { return b , err } err = session . Ping ( ) if err != nil { return b , err return b , err", "del_tokens": "func NewMongodbBackend ( mongoUrl string , database string ) ( b MongodbAuthBackend ) { panic ( err ) panic ( err )", "commit_type": "make"}
{"commit_tokens": ["use", "multiple", "variable", "/", "for", "loop"], "add_tokens": "for p , _p := h . Next , h . Next . Next ; p != h ; p , _p = _p , _p . Next {", "del_tokens": "p := h . Next _p := p . Next for p != h { p = _p _p = _p . Next", "commit_type": "use"}
{"commit_tokens": ["Fix", "Locale", ".", "findPO", "to", "support", "language", "code", "simplification", "on", "LC_MESSAGES", "dir", "."], "add_tokens": "// Load domain '/path/to/i18n/dir/en_US/LC_MESSAGES/default.po' // Load different domain ('/path/to/i18n/dir/en_US/LC_MESSAGES/extras.po') if len ( l . lang ) > 2 { filename = path . Join ( l . path , l . lang [ : 2 ] , \" \" , dom + \" \" ) if _ , err := os . Stat ( filename ) ; err == nil { return filename } } if len ( l . lang ) > 2 {", "del_tokens": "// Load domain '/path/to/i18n/dir/en_US/default.po' // Load different domain ('/path/to/i18n/dir/en_US/extras.po') if len ( filename ) > 2 {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "in", "checkpointing", "errors"], "add_tokens": "// ApplyingError is an error indicating something that went wrong transitioning // from one state to another. For now it's very simple (and exists in part to // ensure that there's a symetric marshal/unmarshal for the error). type ApplyingError struct { Err string `json:\"error\"` } func ( ae * ApplyingError ) Error ( ) string { return ae . Err } func NewApplyingError ( err error ) * ApplyingError { return & ApplyingError { err . Error ( ) } } ApplyingError * ApplyingError", "del_tokens": "ApplyingError error", "commit_type": "fix"}
{"commit_tokens": ["fix", "time", "issue", "by", "sleep"], "add_tokens": "\" \" time . Sleep ( 100 * time . Millisecond )", "del_tokens": "runtime . Gosched ( )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "file", "path", "substitution", "for", "-", "command"], "add_tokens": "starting a new one each time you build . For advanced usage you can also supply the changed file to the command by doing … $ CompileDaemon - command = \" \" …bu t n te t at t is w ll n t b s t o t e f rst s art. func builder ( jobs <- chan string , buildStarted chan <- string , buildDone chan <- bool ) { eventPath := \" \" case eventPath = <- jobs : buildStarted <- eventPath func runner ( commandTemplate string , buildStarted <- chan string , buildSuccess <- chan bool ) { eventPath := <- buildStarted // append %0.s to use format specifier even if not supplied by user // to suppress warning in returned string. command := fmt . Sprintf ( \" \" + commandTemplate , eventPath ) func flusher ( buildStarted <- chan string , buildSuccess <- chan bool ) { buildStarted := make ( chan string )", "del_tokens": "starting a new one each time you build . func builder ( jobs <- chan string , buildStarted chan <- struct { } , buildDone chan <- bool ) { case <- jobs : buildStarted <- struct { } { } func runner ( command string , buildStarted <- chan struct { } , buildSuccess <- chan bool ) { <- buildStarted func flusher ( buildStarted <- chan struct { } , buildSuccess <- chan bool ) { buildStarted := make ( chan struct { } )", "commit_type": "implement"}
{"commit_tokens": ["removed", "space", "()", "and", "use", "existing", "hasSpace", "()"], "add_tokens": "if f . hasSpace ( ex ) == false {", "del_tokens": "if ex > f . space ( ) { func ( f * fixed ) space ( ) int { return f . capacity - f . length }", "commit_type": "remove"}
{"commit_tokens": ["fix", "golint", "warning", "and", "typo"], "add_tokens": "// Package httpstat traces HTTP latency infomation (DNSLookup, TCP Connection and so on) on any golang HTTP request. // The followings are timeline of request", "del_tokens": "// package httpstat traces HTTP latency infomation (DNSLookup, TCP Connection and so on) on any golang HTTP request. // The followings are timeline of reuqest", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typos", "and", "commenting", "in", "pqueue", ".", "go"], "add_tokens": "// order defines the priority ordering of the queue. ASC order = iota // Set priority level 0 as most important. DESC // Set priority level 255 as most important.", "del_tokens": "// pqorder defines the priority ordering of the queue. // // ASC will use priority level 0 as the most important. // DESC will use priority level 255 as the most important. ASC order = iota DESC", "commit_type": "fix"}
{"commit_tokens": ["Remove", "labels", "from", "object", "when", "API", "call", "made"], "add_tokens": "which := - 1 for i , l := range obj . Issue . Labels { if l . Name != nil && * l . Name == label { which = i break } } if which != - 1 { obj . Issue . Labels = append ( obj . Issue . Labels [ : which ] , obj . Issue . Labels [ which + 1 : ] ... ) } glog . Errorf ( \" \" , label , prNum , err )", "del_tokens": "glog . Errorf ( \" \" , label , prNum , err )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "an", "issue", "that", "Update", "and", "Insert", "don", "t", "use", "column", "tag"], "add_tokens": "col := db . columnFromTag ( rtype . FieldByIndex ( index ) ) cols [ i ] = db . dialect . Quote ( db . columnFromTag ( rtype . FieldByIndex ( index ) ) )", "del_tokens": "col := stringutil . ToSnakeCase ( rtype . FieldByIndex ( index ) . Name ) cols [ i ] = db . dialect . Quote ( stringutil . ToSnakeCase ( rtype . FieldByIndex ( index ) . Name ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "bufio", ".", "Scanner", "for", "load", "dict"], "add_tokens": "\" \" \" \" f , err := os . Open ( path ) defer f . Close ( ) var rwords [ ] [ ] rune scanner := bufio . NewScanner ( f ) for scanner . Scan ( ) { rwords = append ( rwords , [ ] rune ( scanner . Text ( ) ) )", "del_tokens": "\" \" \" \" b_slice , err := ioutil . ReadFile ( path ) data := string ( b_slice ) swords := strings . Split ( data , \" \\r \\n \" ) rwords := make ( [ ] [ ] rune , len ( swords ) ) for i , word := range swords { rwords [ i ] = [ ] rune ( word )", "commit_type": "use"}
{"commit_tokens": ["Remove", "panic", "from", "unmarshal", "for", "invalid", "datatypes", "."], "add_tokens": "return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" )", "del_tokens": "panic ( \" \" ) panic ( \" \" ) panic ( \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Make", "lexComment", "jump", "back", "to", "the", "previous", "state"], "add_tokens": "return l . lexComment ( l . lexVoid ) return l . lexComment ( l . lexRvalue ) func ( l * tomlLexer ) lexComment ( previousState tomlLexStateFn ) tomlLexStateFn { return func ( ) tomlLexStateFn { for next := l . peek ( ) ; next != '\\n' && next != eof ; next = l . peek ( ) { if next == '\\r' && l . follow ( \" \\r \\n \" ) { break } l . next ( ) l . ignore ( ) return previousState", "del_tokens": "return l . lexComment return l . lexComment func ( l * tomlLexer ) lexComment ( ) tomlLexStateFn { for next := l . peek ( ) ; next != '\\n' && next != eof ; next = l . peek ( ) { if next == '\\r' && l . follow ( \" \\r \\n \" ) { break l . next ( ) l . ignore ( ) return l . lexVoid", "commit_type": "make"}
{"commit_tokens": ["Add", "missing", "error", "check", "when", "seeking"], "add_tokens": "if _ , err := currentFile . Seek ( 0 , os . SEEK_SET ) ; err != nil { return nil , err }", "del_tokens": "currentFile . Seek ( 0 , os . SEEK_SET )", "commit_type": "add"}
{"commit_tokens": ["Make", "Dialer", "s", "domain", "configurable"], "add_tokens": "// LocalName is the hostname sent to the SMTP server with the HELO command. // By default, \"localhost\" is sent. LocalName string if d . LocalName != \" \" { if err := c . Hello ( d . LocalName ) ; err != nil { return nil , err } } c , err := newClient ( conn , d . Host ) if err != nil { return nil , err } if d . LocalName != \" \" { if err := c . Hello ( d . LocalName ) ; err != nil { return nil , err } } return c , nil Hello ( string ) error", "del_tokens": "return newClient ( conn , d . Host )", "commit_type": "make"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "nested", "quotes", "caused", "broke", "line", "comments"], "add_tokens": "lastQuote := [ ] rune { rune ( 0 ) } case c == lastQuote [ 0 ] : lastQuote = lastQuote [ 1 : ] lastQuote = append ( [ ] rune { c } , lastQuote ... ) case c == slash && lastQuote [ 0 ] == rune ( 0 ) :", "del_tokens": "lastQuote := rune ( 0 ) case c == lastQuote : lastQuote = rune ( 0 ) lastQuote = c case c == slash && lastQuote == rune ( 0 ) :", "commit_type": "fix"}
{"commit_tokens": ["Add", "ZKFlag", "and", "HttpProxy", "Checks", "with", "docs"], "add_tokens": "// param2,param3,param4,param5 are ignored // param4,param5 are ignored // param5 is ignored // if _type == zkflag // param5 is the list of hosts // param1 is the path to check // param2,param3,param3 are ignored // if _type == httpproxy // param1 is the username // param2 is the password // param3 is the host // param4 is the port // param5 is the urls to checks func CreateCheck ( _type string , IP string , Host string , Port int , ConnectTimeout int , ipv6 bool , param1 string , param2 string , param3 string , param4 string , param5 [ ] string ) ( CheckI , error ) { case CHECK_ZKFLAG_TYPE : zkflag_check := new ( zkflagCheck ) zkflag_check . Initialize ( ) zkflag_check . SetZKFlagConfiguration ( param5 , param2 ) check = zkflag_check", "del_tokens": "// param2,param3 are ignored // param4 is ignored func CreateCheck ( _type string , IP string , Host string , Port int , ConnectTimeout int , ipv6 bool , param1 string , param2 string , param3 string , param4 string ) ( CheckI , error ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "k", "/", "v", "cascade", ".", "Make", "interfaces", "so", "that", "other", "libraries", "can", "loosely", "depend", "on", "health", "without", "an", "explicit", "dependency", "."], "add_tokens": "\" \" // sink := health.LogfileWriterSink{os.Stdout} // sink.EmitEvent(\"api/v2/tickets/show\", \"started\", nil) // sink.EmitTiming(\"api/v2/tickets/show\", \"started\", 13248714, map[string]string{\"host\": \"web33\", \"request_id\": \"12345\", \"subdomain\": \"slimtimer\"}) stream := health . NewStream ( ) stream . KeyValue ( \" \" , \" \" ) stream . AddLogfileWriterSink ( os . Stdout ) job := stream . Job ( \" \" ) job . KeyValue ( \" \" , \" \" ) job . Event ( \" \" ) job . EventKv ( \" \" , health . Kvs { \" \" : \" \" , \" \" : \" \" } ) dbr . DoSomething ( job )", "del_tokens": "sink := health . LogfileWriterSink { os . Stdout } sink . EmitEvent ( \" \" , \" \" , nil ) sink . EmitTiming ( \" \" , \" \" , 13248714 , map [ string ] string { \" \" : \" \" , \" \" : \" \" , \" \" : \" \" } )", "commit_type": "fix"}
{"commit_tokens": ["Make", "UnmarshalText", "parse", "more", "strictly"], "add_tokens": "braced := false braced = true for i , byteGroup := range byteGroups { if i > 0 && t [ 0 ] == '-' { } else if i > 0 && t [ 0 ] != '-' { err = fmt . Errorf ( \" \" ) return } if i == 2 { if ! bytes . Contains ( [ ] byte ( \" \" ) , [ ] byte { t [ 0 ] } ) { err = fmt . Errorf ( \" \" , t [ 0 ] ) return } if i == 4 && len ( t ) > byteGroup && ( ( braced && t [ byteGroup ] != '}' ) || ! braced ) { err = fmt . Errorf ( \" \" , t ) return }", "del_tokens": "for _ , byteGroup := range byteGroups { if t [ 0 ] == '-' {", "commit_type": "make"}
{"commit_tokens": ["Allow", "sorting", "a", "slice", "of", "pointers"], "add_tokens": "vals [ i ] = reflect . Indirect ( reflect . Indirect ( s . Index ( i ) ) ) vals [ i ] = reflect . Indirect ( reflect . Indirect ( s . Index ( i ) ) . FieldByName ( name ) ) vals [ i ] = reflect . Indirect ( reflect . Indirect ( s . Index ( i ) ) . FieldByIndex ( index ) ) vals [ i ] = reflect . Indirect ( reflect . Indirect ( s . Index ( i ) ) . Index ( index ) )", "del_tokens": "vals [ i ] = reflect . Indirect ( s . Index ( i ) ) vals [ i ] = reflect . Indirect ( s . Index ( i ) . FieldByName ( name ) ) vals [ i ] = reflect . Indirect ( s . Index ( i ) . FieldByIndex ( index ) ) vals [ i ] = reflect . Indirect ( s . Index ( i ) . Index ( index ) )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "unused", "err", "return", "value", "from", "NewDeviceWatcher", "."], "add_tokens": "watcher := adb . NewDeviceWatcher ( adb . ClientConfig { } )", "del_tokens": "watcher , err := adb . NewDeviceWatcher ( adb . ClientConfig { } )", "commit_type": "remove"}
{"commit_tokens": ["Allow", "uuid", "s", "to", "be", "unmarsalled", "into", "strings", "and", "bytes"], "add_tokens": "func ( ) UUID { x , _ := UUIDFromBytes ( [ ] byte { 0x3d , 0xcd , 0x98 , 0x0 , 0xf3 , 0xd9 , 0x11 , 0xbf , 0x86 , 0xd4 , 0xb8 , 0xe8 , 0x56 , 0x2c , 0xc , 0xd0 } ) return x } ( ) ,", "del_tokens": "UUIDFromBytes ( [ ] byte { 0x3d , 0xcd , 0x98 , 0x0 , 0xf3 , 0xd9 , 0x11 , 0xbf , 0x86 , 0xd4 , 0xb8 , 0xe8 , 0x56 , 0x2c , 0xc , 0xd0 } ) ,", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "the", "count", "()", "function", "."], "add_tokens": "return [ ] tree . Res { numlit . NumLit ( 0 ) } , nil", "del_tokens": "return nil , nil", "commit_type": "fix"}
{"commit_tokens": ["Updated", "funcs", ".", ":", "IsFile", "IsDir"], "add_tokens": "fmt . Println ( \" \" )", "del_tokens": "fmt . Println ( \" \" )", "commit_type": "update"}
{"commit_tokens": ["Fix", "bug", "when", "specified", "max", "completions"], "add_tokens": "p . maxCompletions = x maxCompletions : 6 , selected : - 1 ,", "del_tokens": "p . renderer . maxCompletions = x maxCompletions : 10 , chosen : - 1 ,", "commit_type": "fix"}
{"commit_tokens": ["added", "_Service", "suffix", "which", "was", "missing", "to", "test"], "add_tokens": "accountService , err := client . GetService ( \" \" )", "del_tokens": "accountService , err := client . GetService ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "SHA512", "."], "add_tokens": "\" \" //Well-known public-key encryption methods MethodRSAOAEP = \" \" MethodRSAOAEP2 = \" \" ) //Well-known private key encryption methods const ( MethodAES128GCM = \" \" MethodAES128CBC = \" \" MethodSHA512 = \" \" return nil , fmt . Errorf ( \" \" , string ( cert . Certificate [ 0 ] ) , string ( encCert ) ) case MethodSHA512 : h = sha512 . New ( ) case MethodRSAOAEP , MethodRSAOAEP2 :", "del_tokens": "//Well-known encryption methods MethodRSAOAEP = \" \" return nil , fmt . Errorf ( \" \" ) case MethodRSAOAEP :", "commit_type": "add"}
{"commit_tokens": ["Adding", "methods", "to", "Get", "/", "Set", "ContextValue"], "add_tokens": "// SetContextValueEntryExpirationTTL is thread-safe way of setting custom Context value expiration TTL. func ( l * Limiter ) SetContextValueEntryExpirationTTL ( ttl time . Duration ) * Limiter { // GetContextValueEntryExpirationTTL is thread-safe way of getting custom Cpntext value expiration TTL. func ( l * Limiter ) GetContextValueEntryExpirationTTL ( ) time . Duration { // GetContextValue is thread-safe way of getting 1 Context value entry. func ( l * Limiter ) GetContextValue ( contextValue string ) [ ] string { l . RLock ( ) entriesAsGoCache := l . contextValues [ contextValue ] l . RUnlock ( ) entriesAsMap := entriesAsGoCache . Items ( ) entries := make ( [ ] string , 0 ) for entry , _ := range entriesAsMap { entries = append ( entries , entry ) } return entries } // RemoveContextValue is thread-safe way of removing entries of 1 Context value. func ( l * Limiter ) RemoveContextValue ( contextValue string ) * Limiter { ttl := l . GetContextValueEntryExpirationTTL ( ) if ttl <= 0 { ttl = l . generalExpirableOptions . DefaultExpirationTTL } l . Lock ( ) l . contextValues [ contextValue ] = gocache . New ( ttl , l . generalExpirableOptions . ExpireJobInterval ) l . Unlock ( ) return l }", "del_tokens": "// SetHeaderEntryExpirationTTL is thread-safe way of setting custom basic auth expiration TTL. func ( l * Limiter ) SetContextEntryExpirationTTL ( ttl time . Duration ) * Limiter { // GetHeaderEntryExpirationTTL is thread-safe way of getting custom basic auth expiration TTL. func ( l * Limiter ) GetContextEntryExpirationTTL ( ) time . Duration {", "commit_type": "add"}
{"commit_tokens": ["Updated", "godoc", "url", ".", "Added", "build", "status"], "add_tokens": "//Returns true if successful and false if timeout occurs.", "del_tokens": "//Returns true if successful and false if timeout occurs.", "commit_type": "update"}
{"commit_tokens": ["Add", "media", "library", "index", "template"], "add_tokens": "Sizes map [ string ] Size `json:\",omitempty\"` Video string SelectedType string meta . Type = \" \" // MediaBoxConfig configure MediaBox metas", "del_tokens": "Sizes map [ string ] Size `json:\",omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "PSK", "logic", "to", "the", "handshake"], "add_tokens": "assertEquals ( t , client . context . state , server . context . state )", "del_tokens": "assertEquals ( t , client . context . initialized , server . context . initialized )", "commit_type": "add"}
{"commit_tokens": ["Add", "GetCellMargin", "()", "SetCellMargin", "()", "and", "one", "clarifying", "comment", "."], "add_tokens": "// Return the cell margin. This is the amount of space before and after the text // within a cell that's left blank, and is in units passed to New(). It defaults // to 1mm. func ( f * Fpdf ) GetCellMargin ( ) float64 { return f . cMargin } // Set the cell margin. This is the amount of space before and after the text // within a cell that's left blank, and is in units passed to New(). It defaults // to 1mm. func ( f * Fpdf ) SetCellMargin ( margin float64 ) { f . cMargin = margin } // w and h specify the width and height of the cell. If w is 0, it will be set // to the remaining horizontal space on the page (until the right margin).", "del_tokens": "// w and h specify the width and height of the cell.", "commit_type": "add"}
{"commit_tokens": ["Implement", "client", "-", "side", "Remove", "()"], "add_tokens": "// Remove removes a row by primary key. The passed-in entity should contain Remove ( context . Context , DomainObject ) error // MultiRemove removes multiple rows by primary key. The passed-in entity should MultiRemove ( context . Context , ... DomainObject ) ( MultiResult , error ) // MultiRead, MultiUpsert and MultiRemove. If the operation succeeded for // Remove deletes an entity by primary key, The entity provided must contain func ( c * client ) Remove ( ctx context . Context , entity DomainObject ) error { if ! c . initialized { return ErrNotInitialized } // lookup registered entity, registry will return error if registration // is not found re , err := c . registrar . Find ( entity ) if err != nil { return err } // translate entity field values to a map of primary key name/values pairs keyFieldValues := re . KeyFieldValues ( entity ) err = c . connector . Remove ( ctx , re . EntityInfo ( ) , keyFieldValues ) return err // MultiRemove deletes several entities by primary key, The entities provided func ( c * client ) MultiRemove ( context . Context , ... DomainObject ) ( MultiResult , error ) {", "del_tokens": "// Delete removes a row by primary key. The passed-in entity should contain Delete ( context . Context , DomainObject ) error // MultiDelete removes multiple rows by primary key. The passed-in entity should MultiDelete ( context . Context , ... DomainObject ) ( MultiResult , error ) // MultiRead, MultiUpsert and MultiDelete. If the operation succeeded for // Delete deletes an entity by primary key, The entity provided must contain func ( c * client ) Delete ( context . Context , DomainObject ) error { panic ( \" \" ) // MultiDelete deletes several entities by primary key, The entities provided func ( c * client ) MultiDelete ( context . Context , ... DomainObject ) ( MultiResult , error ) {", "commit_type": "implement"}
{"commit_tokens": ["Make", "summary", ".", "Add", "()", "handle", "duplicates", "by", "updating", "the", "centroid"], "add_tokens": "if s . meanAtIndexIs ( idx , key ) { s . updateAt ( idx , key , value ) return nil", "del_tokens": "if idx < len ( s . keys ) && s . keys [ idx ] == key { return fmt . Errorf ( \" \" , key )", "commit_type": "make"}
{"commit_tokens": ["Add", "option", "to", "skip", "setting", "cloud", "attributes"], "add_tokens": "// If OmitCloudAttrs is true no extra attributes for cloud are set OmitCloudAttrs bool if ! objMgr . OmitCloudAttrs { ea [ \" \" ] = cloudAPIOwned ea [ \" \" ] = objMgr . cmpType ea [ \" \" ] = objMgr . tenantID }", "del_tokens": "ea [ \" \" ] = cloudAPIOwned ea [ \" \" ] = objMgr . cmpType ea [ \" \" ] = objMgr . tenantID", "commit_type": "add"}
{"commit_tokens": ["use", "sync", ".", "Once", "instead", "of", "atomic"], "add_tokens": "\" \" var routerStarter sync . Once routerStarter . Do ( func ( ) { go notificationRouter ( ) } ) routerStarter . Do ( func ( ) { go notificationRouter ( ) } ) routerStarter . Do ( func ( ) { go notificationRouter ( ) } )", "del_tokens": "\" \" var routerStarted = int32 ( 0 ) startRouter ( ) startRouter ( ) startRouter ( ) // internal helper function to start the message routing goroutine func startRouter ( ) { if atomic . CompareAndSwapInt32 ( & routerStarted , 0 , 1 ) { go notificationRouter ( ) } }", "commit_type": "use"}
{"commit_tokens": ["added", "read", "lock", "to", "robotsMap", "access", "refactored", "tests", "to", "use", "existing", "init", "function"], "add_tokens": "lock * sync . RWMutex c . lock = & sync . RWMutex { } // var robot *robotstxt.RobotsData // var ok bool c . lock . RLock ( ) robot , ok := c . robotsMap [ u . Host ] c . lock . RUnlock ( ) if ! ok {", "del_tokens": "lock * sync . Mutex c . lock = & sync . Mutex { } var robot * robotstxt . RobotsData var ok bool if robot , ok = c . robotsMap [ u . Host ] ; ! ok {", "commit_type": "add"}
{"commit_tokens": ["Implement", "Graceful", "for", "graceful", "restart", "."], "add_tokens": "ignoreLogFilename bool func init ( ) { // This is for child processes of graceful restarting server. // See graceful.go ignoreLogFilename = ! isMaster ( ) } if len ( filename ) > 0 && ! ignoreLogFilename {", "del_tokens": "if len ( filename ) > 0 {", "commit_type": "implement"}
{"commit_tokens": ["allow", "to", "change", "rate", "unit"], "add_tokens": "// Scale returns a conversion factor from one unit to another. func Scale ( o , d time . Duration ) float64 { return float64 ( o ) / float64 ( d ) } scale float64 return NewRateScale ( rateScale ) } // NewRateScale creates a new rate instruments with the given conversion factor. func NewRateScale ( s float64 ) * Rate { time : time . Now ( ) . UnixNano ( ) , scale : s , s := float64 ( c ) / r . scale / float64 ( now - t ) // NewDeriveScale creates a new derive instruments with the given conversion factor. func NewDeriveScale ( v int64 , s float64 ) * Derive { return & Derive { value : v , rate : NewRateScale ( s ) , } }", "del_tokens": "time : time . Now ( ) . UnixNano ( ) , s := float64 ( c ) / rateScale / float64 ( now - t )", "commit_type": "allow"}
{"commit_tokens": ["add", "defaultUrl", "as", "deprecated", "by", "DefaultURL", "in", "order", "to", "keep", "compatibility", "with", "the", "previous", "version", "100%"], "add_tokens": "const DefaultURL = \" \"", "del_tokens": "var DefaultURL = \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "client", "auth", "via", "TLS", "certificates"], "add_tokens": "EnvVar : \" \" , EnvVar : \" \" , } , ccli . StringFlag { Name : \" \" , Usage : \" \" , EnvVar : \" \" ,", "del_tokens": "EnvVar : \" \" , EnvVar : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "extra", "union", "in", "the", "autocomplete", "query"], "add_tokens": "rows , err := db . Query ( autocompleteQuery , q , q , q , q , q , limit , offset ) UNION SELECT newtag from aliases where newtag like ?", "del_tokens": "rows , err := db . Query ( autocompleteQuery , q , q , q , q , limit , offset )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Errors", "&", "Add", "tests"], "add_tokens": "modeRegex = regexp . MustCompile ( \" \\n \" ) fmt . Println ( \" \" , projectFlag ) func processDIR ( wg * sync . WaitGroup , fullPath , relPath string , out chan <- [ ] byte ) { fmt . Println ( \" \" + coverFlag + \" \" + fullPath + \" \" + relPath ) cmd := exec . Command ( \" \" , \" \" , \" \" + coverFlag , \" \" , \" \" + fullPath + \" \" , relPath ) go processDIR ( wg , path , rel , out ) final = modeRegex . ReplaceAllString ( final , \" \" )", "del_tokens": "modeRegex = regexp . MustCompile ( \" \\n \" ) func processDIR ( wg * sync . WaitGroup , relPath string , out chan <- [ ] byte ) { fmt . Println ( \" \" + coverFlag + \" \" + relPath ) cmd := exec . Command ( \" \" , \" \" , \" \" + coverFlag , \" \" , relPath ) go processDIR ( wg , rel , out ) if modeRegex . Match ( buff . Bytes ( ) ) { final = modeRegex . ReplaceAllString ( final , \" \" ) }", "commit_type": "fix"}
{"commit_tokens": ["Adds", "join", "and", "part", "commands"], "add_tokens": "Join ( target string ) Part ( target string )", "del_tokens": "irccon . Privmsg ( e . Arguments [ 1 ] , \" \\n \" )", "commit_type": "add"}
{"commit_tokens": ["Make", "-", "R", "value", "abosolute"], "add_tokens": "\" \" args = fs . Args ( ) // reset args to the leftovers from fs.Parse cwd , err := filepath . Abs ( cwd ) // if cwd was passed in via -R, make sure it is absolute if err != nil { gb . Fatalf ( \" \" , err ) }", "del_tokens": "args = fs . Args ( ) // reset args to the leftovers from fs.Parse", "commit_type": "make"}
{"commit_tokens": ["Fix", "typo", "/", "indent", "error", "in", "comment"], "add_tokens": "// When true, the whole security policy applied by the middleware is disabled completely. // SSLProxyHeaders: map[string]string{\"X-Forwarded-Proto\": \"https\"},", "del_tokens": "// When true, the whole secury policy applied by the middleware is disable // completely. // SSLProxyHeaders: map[string]string{\"X-Forwarded-Proto\": \"https\"},", "commit_type": "fix"}
{"commit_tokens": ["Added", "unix", "sockets", "transport", "and", "refactored", "TLS", "transport"], "add_tokens": "// * NewTLSClient() and NewTLSServer() can be used for encrypted rpc. // * NewUnixClient() and NewUnixServer() can be used for fast local // inter-process rpc.", "del_tokens": "// If you need encrypted transport, then feel free using NewTLSDial() // on the client and NewTLSListener() helpers on the server.", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "unix", "sockets"], "add_tokens": "case \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" : // This block helps us avoid parsing addresses in transports (such as unix // sockets) that don't have local addresses when dialing out. if local == nil && nconn . LocalAddr ( ) . String ( ) != \" \" { var raddr ma . Multiaddr // This block protects us in transports (i.e. unix sockets) that don't have // remote addresses for inbound connections. if nconn . RemoteAddr ( ) . String ( ) != \" \" { raddr , err = FromNetAddr ( nconn . RemoteAddr ( ) ) if err != nil { return nil , fmt . Errorf ( \" \" , err ) }", "del_tokens": "case \" \" , \" \" , \" \" , \" \" , \" \" , \" \" : if local == nil { raddr , err := FromNetAddr ( nconn . RemoteAddr ( ) ) if err != nil { return nil , fmt . Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Use", "WriteByte", "()", "in", "Client", ".", "printfLine", "()", "."], "add_tokens": "c . text . W . WriteByte ( '\\n' )", "del_tokens": "var nl = [ ] byte { '\\n' } c . text . W . Write ( nl )", "commit_type": "use"}
{"commit_tokens": ["updated", "headers", "standard", "way", "for", "me"], "add_tokens": "// author sigu-399 // author-github https://github.com/sigu-399 // author-mail sigu.399@gmail.com // // repository-name gojsonreference // repository-desc An implementation of JSON Reference - Go language // // description Main and unique file. // // created 26-02-2013", "del_tokens": "// @author sigu-399 // @description An implementation of JSON Reference - Go language // @created 26-02-2013", "commit_type": "update"}
{"commit_tokens": ["Add", "basic", "coverage", "for", "OAuth", "API", "endpoints"], "add_tokens": "ID string `json:\"id\"` Name string `json:\"name\"` Created float32 `json:\"created_utc\"` Gold bool `json:\"is_gold\"` Mod bool `json:\"is_mod\"` Mail * bool `json:\"has_mail\"` ModMail * bool `json:\"has_mod_mail\"` Karma } type Preferences struct { Research bool `json:\"research\"` ShowStylesheets bool `json:\"show_stylesheets\"` ShowLinkFlair bool `json:\"show_link_flair\"` ShowTrending bool `json:\"show_trending\"` PrivateFeeds bool `json:\"private_feeds\"` IgnoreSuggestedSort bool `json:\"ignore_suggested_sort\"` Media string `json:\"media\"` ClickGadget bool `json:\"clickgadget\"` LabelNSFW bool `json:\"label_nsfw\"` Over18 bool `json:\"over_18\"` EmailMessages bool `json:\"email_messages\"` HighlightControversial bool `json:\"highlight_controversial\"` ForceHTTPS bool `json:\"force_https\"` Language string `json:\"lang\"` HideFromRobots bool `json:\"hide_from_robots\"` PublicVotes bool `json:\"public_votes\"` ShowFlair bool `json:\"show_flair\"` HideAds bool `json:\"hide_ads\"` Beta bool `json:\"beta\"` NewWindow bool `json:\"newwindow\"` LegacySearch bool `json:\"legacy_search\"` } type Friend struct { Date float32 `json:\"date\"` Name string `json:\"name\"` ID string `json:\"id\"` } type Karma struct { CommentKarma int `json:\"comment_karma\"` LinkKarma int `json:\"link_karma\"` } type Trophy struct { Name string `json:\"name\"` Description string `json:\"description\"` Icon string `json:\"icon_70\"`", "del_tokens": "ID string `json:\"id\"` Name string `json:\"name\"` LinkKarma int `json:\"link_karma\"` CommentKarma int `json:\"comment_karma\"` Created float64 `json:\"created_utc\"` Gold bool `json:\"is_gold\"` Mod bool `json:\"is_mod\"` Mail * bool `json:\"has_mail\"` ModMail * bool `json:\"has_mod_mail\"`", "commit_type": "add"}
{"commit_tokens": ["Adding", "GCM", "as", "an", "available", "Heapster", "sink", "."], "add_tokens": "var argSink = flag . String ( \" \" , \" \" , \" \" ) case \" \" : return NewGcmSink ( ) return nil , fmt . Errorf ( \" \" , * argSink )", "del_tokens": "var argSink = flag . String ( \" \" , \" \" , \" \" ) return nil , fmt . Errorf ( \" \" , * argSink )", "commit_type": "add"}
{"commit_tokens": ["use", "go", "-", "simplejson", "as", "json", "parser"], "add_tokens": "\" \" CreatedAt string `json:created_at,omitempty` // binRes, err := ioutil.ReadAll(res.Body) // res.Body.Close() // if err != nil { // log.Fatal(err) // } v , err := simplejson . NewFromReader ( res . Body ) // records, err := v.Array() // if err != nil { // log.Fatal(err) // } log . Printf ( \" \" , v . GetIndex ( 0 ) . Get ( \" \" ) )", "del_tokens": "\" \" \" \" CreateAt string `json:created_at,omitempty` binRes , err := ioutil . ReadAll ( res . Body ) res . Body . Close ( ) var records [ ] GitRecord json . Unmarshal ( binRes , records ) log . Printf ( \" \" , githubURL , binRes )", "commit_type": "use"}
{"commit_tokens": ["Make", "storage", "directory", "path", "a", "config", "option", "."], "add_tokens": "groupDir = filepath . Join ( config . StorageDir , \" \" )", "del_tokens": "groupDir = filepath . Join ( storageDir , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Add", "stack", "to", "staging", "request"], "add_tokens": "err := natsRunner . MessageBus . PublishWithReplyTo ( \" \" , \" \" , [ ] byte ( `{\"app_id\": \"some-app-guid\", \"task_id\": \"some-task-id\", \"stack\": \"default\"}` ) )", "del_tokens": "err := natsRunner . MessageBus . PublishWithReplyTo ( \" \" , \" \" , [ ] byte ( `{\"app_id\": \"some-app-guid\", \"task_id\": \"some-task-id\"}` ) )", "commit_type": "add"}
{"commit_tokens": ["change", "default", "adapter_type", "to", "lsiLogic"], "add_tokens": "Default : \" \" ,", "del_tokens": "Default : \" \" ,", "commit_type": "change"}
{"commit_tokens": ["add", "a", "pointer", "to", "bool", "and", "float64"], "add_tokens": "Int * int Int64 * int64 Bool * bool Float64 * float64 Bool : Bool ( true ) , Float64 : Float64 ( 4.0 ) , So ( * p . Bool , ShouldBeTrue ) So ( * p . Float64 , ShouldEqual , 4.0 )", "del_tokens": "Int * int Int64 * int64", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "validate", "token", "manually"], "add_tokens": "val , _ := json . Marshal ( Token { ExpiresAt : time . Now ( ) . Add ( 5 * time . Second ) , IssuedAt : time . Now ( ) } ) var tok Token", "del_tokens": "val , _ := json . Marshal ( token { ExpiresAt : time . Now ( ) . Add ( 5 * time . Second ) , IssuedAt : time . Now ( ) } ) var tok token", "commit_type": "allow"}
{"commit_tokens": ["Use", "a", "more", "appropriate", "identifier", "for", "micro"], "add_tokens": "var s , us int64 if _ , err := redis . Scan ( timeReply , & s , & us ) ; err != nil { now = time . Unix ( s , us * int64 ( time . Microsecond ) )", "del_tokens": "var s , ms int64 if _ , err := redis . Scan ( timeReply , & s , & ms ) ; err != nil { now = time . Unix ( s , ms * int64 ( time . Microsecond ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "proportions", "to", "Flex", "layout", "."], "add_tokens": "AddItem ( form , 0 , 1 ) . AddItem ( frame , 0 , 1 ) . AddItem ( textView , 0 , 1 ) , 0 , 1 ) . AddItem ( table , 0 , 1 ) . AddItem ( tview . NewBox ( ) . SetBorder ( true ) . SetTitle ( \" \" ) , 20 , 1 ) AddItem ( flex , 0 , 1 ) . AddItem ( inputField , 3 , 1 ) app . SetRoot ( pages , true ) . SetFocus ( list )", "del_tokens": "AddItem ( form , 0 ) . AddItem ( frame , 0 ) . AddItem ( textView , 0 ) , 0 ) . AddItem ( table , 0 ) . AddItem ( tview . NewBox ( ) . SetBorder ( true ) . SetTitle ( \" \" ) , 20 ) AddItem ( flex , 0 ) . AddItem ( inputField , 3 ) app . SetRoot ( pages ) . SetFocus ( list )", "commit_type": "add"}
{"commit_tokens": ["use", "mergeStructs", "instead", "of", "direct", "assignments", "to", "generated", "struct", "types", "to", "avoid", "2", "similar", "structs", "with", "fields", "in", "different", "order", "not", "being", "set", "able"], "add_tokens": "m := merger { } structFieldName := camelCase ( key . String ( ) ) m . mergeStructs ( dest . FieldByName ( structFieldName ) , reflect . ValueOf ( keyval . Interface ( ) ) ) m . mergeStructs ( dest . FieldByName ( structFieldName ) , reflect . ValueOf ( keyval . Interface ( ) ) ) } else { dest . FieldByName ( structFieldName ) . Set ( reflect . ValueOf ( keyval . Interface ( ) ) )", "del_tokens": "structFieldName := camelCase ( key . String ( ) ) dest . FieldByName ( structFieldName ) . Set ( reflect . ValueOf ( keyval . Interface ( ) ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "a", "test", "error", "message"], "add_tokens": "t . Errorf ( \" \" )", "del_tokens": "t . Errorf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "mockExpectations", "undefined", "error", "when", "argument", "is", "nothing"], "add_tokens": "{ { if not ( eq ( params $ method ) . String \" \" ) } } m . mockExpectations = nil { { end } }", "del_tokens": "m . mockExpectations = nil", "commit_type": "fix"}
{"commit_tokens": ["Implement", "InfiniteBuffer", "in", "terms", "of", "AdjustableBuffer"], "add_tokens": "in , out , adjust := NewAdjustableBuffer ( ) adjust <- - 1 // set it to infinite // Be very careful using this, as no buffer is truly infinite - if the internal // buffer grows too large your program will run out of memory and crash.", "del_tokens": "in := make ( chan interface { } ) out := make ( chan interface { } ) go func ( ) { var buffer [ ] interface { } for { if len ( buffer ) == 0 { elem , open := <- in if open { buffer = append ( buffer , elem ) } else { close ( out ) return } } else { select { case elem , open := <- in : if open { buffer = append ( buffer , elem ) } else { for elem := range buffer { out <- elem } close ( out ) return } case out <- buffer [ 0 ] : buffer = buffer [ 1 : ] } } } } ( )", "commit_type": "implement"}
{"commit_tokens": ["add", "a", "quick", "example", "for", "concurrent", "loggers"], "add_tokens": "space = \" \"", "del_tokens": "space = \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "creating", "missing", "directories"], "add_tokens": "// create download request with context", "del_tokens": "// create downlaod request with context", "commit_type": "add"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// String renders Box", "del_tokens": "// Render Box", "commit_type": "fix"}
{"commit_tokens": ["Add", "validation", "required", "fix", "and", "corresponding", "package", "tests"], "add_tokens": "if reflect . DeepEqual ( reflect . Zero ( val . Type ( ) ) . Interface ( ) , val . Interface ( ) ) {", "del_tokens": "if reflect . DeepEqual ( reflect . Zero ( val . Type ( ) ) , val ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bad", "reference", "to", "db", "in", "builder"], "add_tokens": "db2 := & DB { db2 . Builder = db2 . newBuilder ( db . sqlDB ) return db2", "del_tokens": "return & DB { Builder : db . Builder ,", "commit_type": "fix"}
{"commit_tokens": ["changed", "how", "urls", "work", "per", "request"], "add_tokens": "const ( baseUrl string = \" \" ) const ( baseUrl string = \" \" ) response , err := http . Get ( fmt . Sprintf ( fmt . Sprintf ( baseUrl , \" \" ) , location ) ) response , err := http . Get ( fmt . Sprintf ( fmt . Sprintf ( baseUrl , \" \" ) , location . Latitude , location . Longitude ) ) response , err := http . Get ( fmt . Sprintf ( fmt . Sprintf ( baseUrl , \" \" ) , id ) )", "del_tokens": "response , err := http . Get ( fmt . Sprintf ( cityUrl , location ) ) response , err := http . Get ( fmt . Sprintf ( coordUrl , location . Latitude , location . Longitude ) ) response , err := http . Get ( fmt . Sprintf ( idUrl , id ) )", "commit_type": "change"}
{"commit_tokens": ["Move", "ResetSequencesTo", "and", "SkipDatabaseNameCheck", "to", "functional", "options", "."], "add_tokens": "skipDatabaseNameCheck bool // SkipResetSequences prevents Loader from reseting sequences after loading // fixtures. // ResetSequencesTo sets the value the sequences will be reset to. // Defaults to 10000. // // Only valid for PostgreSQL. Returns an error otherwise. func ResetSequencesTo ( value int64 ) func ( * Loader ) error { return func ( l * Loader ) error { pgHelper , ok := l . helper . ( * PostgreSQL ) if ! ok { return fmt . Errorf ( \" \" ) } pgHelper . resetSequencesTo = value return nil } } // SkipDatabaseNameCheck will make Loader not check if the database // name contains \"test\". Use with caution! func SkipDatabaseNameCheck ( ) func ( * Loader ) error { return func ( l * Loader ) error { l . skipDatabaseNameCheck = true return nil } } if ! l . skipDatabaseNameCheck {", "del_tokens": "// SkipResetSequences prevents the reset of the databases // sequences after load fixtures time if ! skipDatabaseNameCheck {", "commit_type": "move"}
{"commit_tokens": ["Fix", "nil", "pointer", "in", "Recover"], "add_tokens": "if _ , ok := StackTrace ( err ) ; ! ok { err = & wrappedError { err : err , stack : callers ( ) [ 2 : ] , // TODO: improve callers? }", "del_tokens": "} if _ , ok := StackTrace ( err ) ; ! ok { err = & wrappedError { err : err , stack : callers ( ) [ 2 : ] , // TODO: improve callers?", "commit_type": "fix"}
{"commit_tokens": ["Add", "thirdparty", "proto", "to", "include", "path", "for", "examples"], "add_tokens": "//go:generate protoc --descriptor_set_out=fileset.pb --include_imports --include_source_info -I. -I../thirdparty Booking.proto Vehicle.proto", "del_tokens": "//go:generate protoc --descriptor_set_out=fileset.pb --include_imports --include_source_info -I. -I../vendor Booking.proto Vehicle.proto", "commit_type": "add"}
{"commit_tokens": ["fix", "wrong", "stat", "count", "for", "redis", "engine", "."], "add_tokens": "redis . resetRedis ( ) redis . addTotalCount ( 10 ) assert . Equal ( t , int64 ( 10 ) , val ) redis . addTotalCount ( 10 ) val = redis . getTotalCount ( ) assert . Equal ( t , int64 ( 20 ) , val ) redis . addIosSuccess ( 20 ) assert . Equal ( t , int64 ( 20 ) , val ) redis . addIosError ( 30 ) assert . Equal ( t , int64 ( 30 ) , val ) redis . addAndroidSuccess ( 40 ) assert . Equal ( t , int64 ( 40 ) , val ) redis . addAndroidError ( 50 ) assert . Equal ( t , int64 ( 50 ) , val )", "del_tokens": "redis . addTotalCount ( 1 ) assert . Equal ( t , int64 ( 1 ) , val ) redis . addIosSuccess ( 2 ) assert . Equal ( t , int64 ( 2 ) , val ) redis . addIosError ( 3 ) assert . Equal ( t , int64 ( 3 ) , val ) redis . addAndroidSuccess ( 4 ) assert . Equal ( t , int64 ( 4 ) , val ) redis . addAndroidError ( 5 ) assert . Equal ( t , int64 ( 5 ) , val )", "commit_type": "fix"}
{"commit_tokens": ["Use", "replace", "instead", "of", "a", "regexp"], "add_tokens": "frange = strings . Replace ( frange , \" \" , \" \" , - 1 )", "del_tokens": "stripSpace * regexp . Regexp stripSpace = regexp . MustCompile ( `(\\s+)` ) frange = stripSpace . ReplaceAllLiteralString ( frange , \" \" )", "commit_type": "use"}
{"commit_tokens": ["implement", "a", "simplist", "font", "management"], "add_tokens": "\" \" //\"draw2d.googlecode.com/svn/trunk/draw2d/src/pkg/draw2d\" draw2d . SetFontFolder ( \" \" ) gc . SetFontData ( draw2d . FontData { \" \" , draw2d . FontFamilyMono , draw2d . FontStyleBold | draw2d . FontStyleItalic } )", "del_tokens": "//\"draw2d\" \" \"", "commit_type": "implement"}
{"commit_tokens": ["Use", "a", "sorted", "doubly", "linked", "list", "to", "get", "rid", "of", "deleted", "flag"], "add_tokens": "if n != nil { t . Error ( \" \" )", "del_tokens": "if n != l . root { t . Error ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Change", "MarshalJSON", "to", "MarshalText", "."], "add_tokens": "// MarshalText implements encoding.TextMarshaler. func ( k AES128Key ) MarshalText ( ) ( [ ] byte , error ) { return [ ] byte ( k . String ( ) ) , nil // UnmarshalText implements encoding.TextUnmarshaler. func ( k * AES128Key ) UnmarshalText ( text [ ] byte ) error { b , err := hex . DecodeString ( string ( text ) )", "del_tokens": "\" \" // MarshalJSON implements json.Marshaler. func ( k AES128Key ) MarshalJSON ( ) ( [ ] byte , error ) { return [ ] byte ( `\"` + k . String ( ) + `\"` ) , nil // UnmarshalJSON implements json.Unmarshaler. func ( k * AES128Key ) UnmarshalJSON ( data [ ] byte ) error { hexStr := strings . Trim ( string ( data ) , `\"` ) b , err := hex . DecodeString ( hexStr )", "commit_type": "change"}
{"commit_tokens": ["Add", "two", "port", "config", "for", "yopa", "and", "or", "(", "fake", "-", "sns", "+", "fake", "-", "sqs", ")", "compatibility"], "add_tokens": "port := LoadYamlConfig ( \" \" , env ) if port [ 0 ] != \" \" { port := LoadYamlConfig ( \" \" , env ) if port [ 0 ] != \" \" {", "del_tokens": "port := LoadYamlConfig ( \" \" , env , \" \" ) if port != \" \" { port := LoadYamlConfig ( \" \" , env , \" \" ) if port != \" \" {", "commit_type": "add"}
{"commit_tokens": ["fix", "an", "infinite", "scanning", "bug"], "add_tokens": "if matchIndex != - 1 && ( slashIndex == - 1 || slashIndex > matchIndex ) {", "del_tokens": "if slashIndex > matchIndex && matchIndex != - 1 {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "off", "-", "by", "-", "one", "error", "during", "Hmset"], "add_tokens": "if v . Index ( 0 ) . OverflowUint ( 257 ) {", "del_tokens": "if v . Index ( 1 ) . OverflowUint ( 257 ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "sync", ".", "Pool", "to", "gzip", "middleware"], "add_tokens": "\" \" \" \" var writerPool = sync . Pool { New : func ( ) interface { } { return gzip . NewWriter ( ioutil . Discard ) } , } w := writerPool . Get ( ) . ( * gzip . Writer ) w . Reset ( c . Response ( ) . Writer ( ) ) defer func ( ) { w . Close ( ) writerPool . Put ( w ) } ( )", "del_tokens": "w := gzip . NewWriter ( c . Response ( ) . Writer ( ) ) defer w . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "Prev", "time", "record", "to", "the", "entry"], "add_tokens": "Prev time . Time entry := & Entry { Schedule : Parse ( spec ) , Job : cmd , } e . Prev = e . Next entries = append ( entries , & Entry { Schedule : e . Schedule , Next : e . Next , Prev : e . Prev , Job : e . Job , } )", "del_tokens": "entry := & Entry { Parse ( spec ) , time . Time { } , cmd } entries = append ( entries , & Entry { e . Schedule , e . Next , e . Job } )", "commit_type": "add"}
{"commit_tokens": ["Implement", "new", "interface", "with", "DVSNI"], "add_tokens": "func ( s * dvsniChallenge ) Solve ( challenge challenge , domain string ) error { return nil", "del_tokens": "func ( s * dvsniChallenge ) Solve ( challenge challenge , domain string ) {", "commit_type": "implement"}
{"commit_tokens": ["use", "context", "not", "docker", "timeout"], "add_tokens": "// 这里 block 的问题很严重，按照目前的配置是 5 分钟一级的 block // 一个简单的处理方法是相信 ctx 不相信 docker 自身的处理 // 另外我怀疑 docker 自己的 timeout 实现是完全的等 timeout 而非结束了就退出 ctx , cancel := context . WithTimeout ( context . Background ( ) , c . config . GlobalTimeout ) defer cancel ( ) if err = container . Engine . ContainerStop ( ctx , info . ID , nil ) ; err != nil { log . Debugf ( \" \" , info . ID ) log . Debugf ( \" \" , info . ID ) return c . store . RemoveContainer ( info . ID , container )", "del_tokens": "if err = container . Engine . ContainerStop ( context . Background ( ) , info . ID , & c . config . GlobalTimeout ) ; err != nil { if err = c . store . RemoveContainer ( info . ID , container ) ; err != nil { log . Errorf ( \" \" , err . Error ( ) ) return err } return nil", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "bridge", "driver", "where", "when", "the", "bridge", "already", "exists"], "add_tokens": "{ bridgeAlreadyExists , setupVerifyAndReconcile } ,", "del_tokens": "{ bridgeAlreadyExists , setupVerifyConfiguredAddresses } ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "typo", "in", "fileserver", "options"], "add_tokens": "DefaultInternalServerErrorHandler = http . HandlerFunc ( func ( w http . ResponseWriter , _ * http . Request ) {", "del_tokens": "DefaultInternalServerErrorhandler = http . HandlerFunc ( func ( w http . ResponseWriter , _ * http . Request ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "mis", "-", "used", "pointer", "in", "embedded", "interface", "that", "mimic", "Java", "s", "abstract", "class"], "add_tokens": "Query func NewAbstractQuery ( self Query ) * AbstractQuery { return & AbstractQuery { self , 1.0 } return q . Query", "del_tokens": "func NewAbstractQuery ( ) * AbstractQuery { return & AbstractQuery { 1.0 } return q", "commit_type": "fix"}
{"commit_tokens": ["Fix", "govet", "/", "golint", "warnings", "."], "add_tokens": "source proc . Source source : fs , colErrs , _ , err := p . Update ( p . source . AllProcs ( ) ) permErrs , groups , err := p . Update ( p . source . AllProcs ( ) ) prometheus . CounterValue , gcounts . CPUUserTime , gname ) prometheus . CounterValue , gcounts . CPUSystemTime , gname )", "del_tokens": "fs * proc . FS fs : fs , colErrs , _ , err := p . Update ( p . fs . AllProcs ( ) ) permErrs , groups , err := p . Update ( p . fs . AllProcs ( ) ) prometheus . CounterValue , gcounts . CpuUserTime , gname ) prometheus . CounterValue , gcounts . CpuSystemTime , gname )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "parser", ".", "go", "."], "add_tokens": "case html . DoctypeToken , html . SelfClosingTagToken , html . CommentToken :", "del_tokens": "case html . SelfClosingTagToken :", "commit_type": "update"}
{"commit_tokens": ["added", "a", "mutex", "around", "map", "in", "json", "handler", ".", "discovered", "a", "concurrent", "map", "read", "/", "write", "panic", "in", "logs", "that", "led", "to", "this", "block"], "add_tokens": "\" \" type mutexMap struct { sync . Mutex data map [ string ] interface { } } fullBody := mutexMap { } fullBody . Lock ( ) fullBody . data = map [ string ] interface { } { fullBody . data [ k ] = v data , err := json . Marshal ( fullBody . data ) fullBody . Unlock ( )", "del_tokens": "fullBody := map [ string ] interface { } { fullBody [ k ] = v data , err := json . Marshal ( fullBody )", "commit_type": "add"}
{"commit_tokens": ["changed", "to", "use", "HaveOccurred", "matcher", "for", "err", "tests"], "add_tokens": "Expect ( err ) . ToNot ( HaveOccured ( ) ) Expect ( err ) . ToNot ( HaveOccured ( ) ) Expect ( err ) . ToNot ( HaveOccured ( ) )", "del_tokens": "Expect ( err ) . To ( BeNil ( ) ) Expect ( err ) . ToNot ( BeNil ( ) ) Expect ( err ) . To ( BeNil ( ) )", "commit_type": "change"}
{"commit_tokens": ["Added", "interface", "to", "allow", "different", "printing", "styles", "."], "add_tokens": "g . reporter = Reporter ( & DetailedReporter { fancy : & TerminalFancier { } } )", "del_tokens": "g . reporter = Reporter ( & DetailedReporter { } )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "way", "to", "link", "harnessed", "catbox", "servers"], "add_tokens": "catbox , err := harnessCatbox ( \" \" )", "del_tokens": "catbox , err := harnessCatbox ( )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "which", "would", "render", "the", "background", "color", "of", "the", "label", "in", "the", "gauge", "widget", "incorrectly", "."], "add_tokens": "if w + g . innerX > pos + i {", "del_tokens": "if w > pos + i {", "commit_type": "fix"}
{"commit_tokens": ["Add", "conf", "field", "to", "builder", "/", "ring", "and", "ring", "cmd"], "add_tokens": "b . AddNode ( true , capacity , [ ] string { fmt . Sprintf ( \" \" , server ) , fmt . Sprintf ( \" \" , zone ) } , nil , \" \" , [ ] byte ( \" \" ) )", "del_tokens": "b . AddNode ( true , capacity , [ ] string { fmt . Sprintf ( \" \" , server ) , fmt . Sprintf ( \" \" , zone ) } , nil , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "latest", "gosrc", "lint", "."], "add_tokens": "\" \" Link string Link : p . Link ,", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "limiter", "functions", "for", "decoders", "."], "add_tokens": "// UnmarshalLimited is identical to Unmarshal but it sets maxReadSize in order // to cap reads. func UnmarshalLimited ( r io . Reader , v interface { } , maxSize uint ) ( int , error ) { d := Decoder { r : r , maxReadSize : maxSize } return d . Decode ( v ) } // maxReadSize is the default maximum bytes an element can contain. 0 // is unlimited and provides backwards compatability. Setting it to a // non-zero value caps reads. maxReadSize uint if uint ( dataLen ) > uint ( math . MaxInt32 ) || ( d . maxReadSize != 0 && uint ( dataLen ) > d . maxReadSize ) { if uint ( dataLen ) > uint ( math . MaxInt32 ) || ( d . maxReadSize != 0 && uint ( dataLen ) > d . maxReadSize ) { if uint ( dataLen ) > uint ( math . MaxInt32 ) || ( d . maxReadSize != 0 && uint ( dataLen ) > d . maxReadSize ) { // NewDecoderLimited is identical to NewDecoder but it sets maxReadSize in // order to cap reads. func NewDecoderLimited ( r io . Reader , maxSize uint ) * Decoder { return & Decoder { r : r , maxReadSize : maxSize } }", "del_tokens": "if uint ( dataLen ) > uint ( math . MaxInt32 ) { if uint ( dataLen ) > uint ( math . MaxInt32 ) { if uint ( dataLen ) > uint ( math . MaxInt32 ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "new", "certs", "to", "vetinari"], "add_tokens": "TLSCertFile : \" \" , TLSKeyFile : \" \" , TLSCertFile : \" \" , TLSKeyFile : \" \" ,", "del_tokens": "TLSCertFile : \" \" , TLSKeyFile : \" \" , TLSCertFile : \" \" , TLSKeyFile : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Use", "httpcontrol", "library", "to", "manage", "timeouts"], "add_tokens": "\" \" Transport : & httpcontrol . Transport { RequestTimeout : readWriteTimeout , DialTimeout : connectTimeout , MaxTries : 3 ,", "del_tokens": "\" \" func TimeoutDialer ( cTimeout time . Duration , rwTimeout time . Duration ) func ( net , addr string ) ( c net . Conn , err error ) { return func ( netw , addr string ) ( net . Conn , error ) { conn , err := net . DialTimeout ( netw , addr , cTimeout ) if err != nil { return nil , err } conn . SetDeadline ( time . Now ( ) . Add ( rwTimeout ) ) return conn , nil } } Transport : & http . Transport { Dial : TimeoutDialer ( connectTimeout , readWriteTimeout ) ,", "commit_type": "use"}
{"commit_tokens": ["Updated", "to", "use", "garybirds", "websocket", "implementation", "."], "add_tokens": "broadcast chan [ ] byte default : broadcast : make ( chan [ ] byte ) ,", "del_tokens": "broadcast chan string default : // default only triggered when sending failed, so get rid of problematic connection // go conn.CloseSocket() Shouldn't be necessary! broadcast : make ( chan string ) ,", "commit_type": "update"}
{"commit_tokens": ["Removed", "commented", "snippets", "in", "test"], "add_tokens": "numMessages := 1000 testProduce ( t , topicName , numMessages , connector ) testConsume ( t , topicName , numMessages , connector ) closeWithin ( t , time . Second , connector ) anotherConnector := testConnector ( t ) testConsume ( t , topicName , numMessages , anotherConnector ) closeWithin ( t , time . Second , anotherConnector )", "del_tokens": "//numMessages := 1000 //testProduce(t, topicName, numMessages, connector) //testConsume(t, topicName, numMessages, connector) //closeWithin(t, time.Second, connector) //anotherConnector := testConnector(t) //testConsume(t, topicName, numMessages, anotherConnector) //closeWithin(t, time.Second, anotherConnector)", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "few", "examples", "as", "code", "examples"], "add_tokens": "Prefix : \" \" , // Output: // CyanogenMod/android_device_htc_pyramid - State: ACTIVE", "del_tokens": "// CyanogenMod/android_external_drm - State: ACTIVE // CyanogenMod/android_external_jhead - State: ACTIVE // CyanogenMod/android_external_libppp - State: ACTIVE // ...", "commit_type": "add"}
{"commit_tokens": ["Use", "template", "repo", "to", "install", "job", "templates"], "add_tokens": "bmtemcomp \" \" fs boshsys . FileSystem packageInstaller PackageInstaller templateExtractor BlobExtractor templateRepo bmtemcomp . TemplatesRepo return bosherr . WrapError ( err , \" \" , pkg . Name ) template , found , err := i . templateRepo . Find ( job ) if err != nil { return bosherr . WrapError ( err , \" \" , job . Name ) } if ! found { return bosherr . New ( \" \" , job . Name ) } err = i . templateExtractor . Extract ( template . BlobID , template . BlobSha1 , jobDir ) if err != nil { return bosherr . WrapError ( err , \" \" , template . BlobID ) } blobExtractor BlobExtractor , templateRepo bmtemcomp . TemplatesRepo , fs : fs , packageInstaller : packageInstaller , templateExtractor : blobExtractor , templateRepo : templateRepo ,", "del_tokens": "fs boshsys . FileSystem packageInstaller PackageInstaller return bosherr . WrapError ( err , \" \" , pkg . Name ) // if any err, cleans things up fs : fs , packageInstaller : packageInstaller ,", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "parsing", "otherwise", "empty", "/", "ipfs", "addrs", "improve", "tests"], "add_tokens": "// TODO(lgierth): we shouldn't assume /ipfs is the last part ipfspart := parts [ len ( parts ) - 1 ] // make sure the /ipfs value parses as a peer.ID // we might have received just an /ipfs part, which means there's no addr. var addrs [ ] ma . Multiaddr if len ( parts ) > 1 { addrs = append ( addrs , ma . Join ( parts [ : len ( parts ) - 1 ] ... ) ) } Addrs : addrs ,", "del_tokens": "ipfspart := parts [ len ( parts ) - 1 ] // last part // make sure 'ipfs id' parses as a peer.ID Addrs : [ ] ma . Multiaddr { ma . Join ( parts [ : len ( parts ) - 1 ] ... ) } ,", "commit_type": "allow"}
{"commit_tokens": ["use", "up", "and", "down", "arrows", "to", "paginate"], "add_tokens": "help := ui . NewPar ( `:c, :h for profiles; :f to filter; ↓ and ↑ to paginate`)", "del_tokens": "case \" < left > \" case \" < right > \" help := ui . NewPar ( `:c, :h for profiles; :f to filter; < and > to paginate` )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "ExpectThat ( err , Error ( HasSubstr ( \" \" ) ) ) ExpectThat ( err , Error ( HasSubstr ( \" \" ) ) )", "del_tokens": "ExpectThat ( err , Error ( HasSubstr ( \" \" ) ) ) ExpectThat ( err , Error ( HasSubstr ( \" \" ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "inherit", "parameter", "to", "Apply", "()", "."], "add_tokens": "// parameter is true, existing entries will be overwritten. If the inherit // parameter is true, the file will inherit ACEs from its parent. func Apply ( name string , replace , inherit bool , entries ... api . ExplicitAccess ) error { var secInfo uint32 if ! inherit { secInfo = api . PROTECTED_DACL_SECURITY_INFORMATION } else { secInfo = api . UNPROTECTED_DACL_SECURITY_INFORMATION } api . DACL_SECURITY_INFORMATION | secInfo ,", "del_tokens": "// parameter is true, existing entries will be overwritten. func Apply ( name string , replace bool , entries ... api . ExplicitAccess ) error { api . DACL_SECURITY_INFORMATION ,", "commit_type": "add"}
{"commit_tokens": ["added", "test", "to", "make", "sure", "event", "file", "is", "being", "returned"], "add_tokens": "case event := <- w . Event : // TODO: Make event's accurate where if a modified event is a file, // don't return the file's folder first as a modified folder. // // Will be modified event because the folder will be checked first. if event . EventType != EventFileModified { t . Errorf ( \" \" , event . EventType ) } // For the same reason as above, the modified file won't be newfile.txt, // but rather test_folder. if event . Name ( ) != \" \" { t . Errorf ( \" \" , event . Name ( ) ) }", "del_tokens": "case <- w . Event :", "commit_type": "add"}
{"commit_tokens": ["Fix", "NewDataBytes", "with", "an", "empty", "input"], "add_tokens": "var cb * C . char if len ( b ) != 0 { cb = ( * C . char ) ( unsafe . Pointer ( & b [ 0 ] ) ) } return d , handleError ( C . gpgme_data_new_from_mem ( & d . dh , cb , C . size_t ( len ( b ) ) , 1 ) )", "del_tokens": "return d , handleError ( C . gpgme_data_new_from_mem ( & d . dh , ( * C . char ) ( unsafe . Pointer ( & b [ 0 ] ) ) , C . size_t ( len ( b ) ) , 1 ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "double", "iter", "close", "use", "exists"], "add_tokens": "\" \" \" \" \" \" \" \" err := d . Put ( ds . NewKey ( \" \" ) , nil ) err = b . Put ( ds . NewKey ( \" \" ) , nil )", "del_tokens": "\" \" \" \" \" \" \" \" err := d . Put ( ds . NewKey ( \" \" ) , nil ) err = b . Put ( ds . NewKey ( \" \" ) , nil )", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "HTTPS", "server"], "add_tokens": "//CertFile is the TLS/SSL certificate file path, required for HTTPS CertFile string `json:\"certFile,omitempty\"` //KeyFile is the filepath of private key of the certificate KeyFile string `json:\"keyFile,omitempty\"` //HTTPSPort is the port number where the server has to listen for the HTTP requests HTTPSPort string `json:\"httpsPort,omitempty\"` //HTTPSOnly if true will enable HTTPS server alone HTTPSOnly bool `json:\"httpsOnly,omitempty\"`", "del_tokens": "// Multiplexer params Params map [ string ] string g . Params = make ( map [ string ] string )", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "condition", "in", "election", "timer", "."], "add_tokens": "// Retrieve the current internal timer. // If the timer exists then grab the value from the channel and pass it // through to the election timer's external channel. v , ok := <- internalTimer . C t . mutex . Lock ( ) if ok && t . Running ( ) { t . mutex . Unlock ( )", "del_tokens": "if v , ok := <- t . internalTimer . C ; ok {", "commit_type": "fix"}
{"commit_tokens": ["Added", "expose", "header", "to", "allow", "api", "client", "to", "access", "header", "data"], "add_tokens": "expose_headers string = \" \" // If you want to expose some other headers add it here headers string = \" \" // Set allow origin to match origin of our request or fall back to * // Set other headers w . Header ( ) . Set ( allow_credentials , credentials ) w . Header ( ) . Set ( expose_headers , headers ) // If this was preflight options request let's write empty ok response and return", "del_tokens": "headers string = \" \" w . Header ( ) . Set ( allow_credentials , credentials )", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "on", "blank", "line", "."], "add_tokens": "if len ( cmd . fields ) > 0 { cmd . action = strings . ToUpper ( cmd . fields [ 0 ] ) if len ( cmd . fields ) > 1 { cmd . params = strings . Split ( cmd . fields [ 1 ] , \" \" ) }", "del_tokens": "cmd . action = strings . ToUpper ( cmd . fields [ 0 ] ) if len ( cmd . fields ) > 1 { cmd . params = strings . Split ( cmd . fields [ 1 ] , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "hk", "release", "-", "info", "support"], "add_tokens": "r . Handle ( \" \" , \" \" , & GetReleases { e } ) // hk releases r . Handle ( \" \" , \" \" , & GetRelease { e } ) // hk release-info r . Handle ( \" \" , \" \" , & PostReleases { e } ) // hk rollback", "del_tokens": "r . Handle ( \" \" , \" \" , & GetReleases { e } ) // hk releases r . Handle ( \" \" , \" \" , & PostReleases { e } ) // hk rollback", "commit_type": "add"}
{"commit_tokens": ["Fix", "schedule", "strategy", "make", "scheduling", "more", "uniform"], "add_tokens": "time . Sleep ( time . Duration ( RefreshInterval / 2 * 1000 + interval ) * time . Millisecond )", "del_tokens": "time . Sleep ( time . Duration ( interval ) * time . Millisecond )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "nats", "proto", "file", "to", "use", "nested", "message"], "add_tokens": "ctx . Trail = append ( ctx . Trail , & NatsContext_Trail { & ( n . Opts . Name ) , & requestType , & timeNow , nil } )", "del_tokens": "ctx . Trail = append ( ctx . Trail , & Trail { & ( n . Opts . Name ) , & requestType , & timeNow , nil } )", "commit_type": "update"}
{"commit_tokens": ["Make", "a", "copy", "of", "Options", "for", "each", "new", "session"], "add_tokens": "opts := * db . Options session . Options = & ( opts )", "del_tokens": "session . Options = & ( * db . Options )", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "Maybe", "interface", "so", "that", "jsval", "consumers", "can", "leverage"], "add_tokens": "g := pdebug . Marker ( \" \" , v ) . BindError ( & err ) defer g . End ( )", "del_tokens": "g := pdebug . IPrintf ( \" \" ) defer func ( ) { if err == nil { g . IRelease ( \" \" ) } else { g . IRelease ( \" \" , err ) } } ( )", "commit_type": "add"}
{"commit_tokens": ["updating", "examples", "to", "show", "how", "to", "use", "non", "-", "blocking", "channels"], "add_tokens": "client . RequestUsers ( ) select { case users := <- client . Users ( ) : for _ , user := range users { if user . Id == client . Id { fmt . Printf ( \" \\n \" , user . Name ) fmt . Printf ( \" \\n \" , user . MentionName ) }", "del_tokens": "var fullName string var mentionName string for _ , user := range client . Users ( ) { if user . Id == client . Id { fullName = user . Name mentionName = user . MentionName break fmt . Printf ( \" \\n \" , fullName ) fmt . Printf ( \" \\n \" , mentionName )", "commit_type": "update"}
{"commit_tokens": ["add", "tests", "for", "decode", "null", "methods"], "add_tokens": "return dec . AddFloatNull ( & t . testFloat64Null )", "del_tokens": "return dec . AddFloat64Null ( & t . testFloat64Null )", "commit_type": "add"}
{"commit_tokens": ["add", "comment", "//", "before", "note", "so", "that", "package", "routing", "compiles"], "add_tokens": "// TODO SEE https://github.com/jbenet/node-ipfs/blob/master/submodules/ipfs-routing/index.js", "del_tokens": "TODO SEE https : //github.com/jbenet/node-ipfs/blob/master/submodules/ipfs-routing/index.js", "commit_type": "add"}
{"commit_tokens": ["use", "a", "sync", "/", "atomic", "instead", "of", "a", "mutex", "for", "speeeed"], "add_tokens": "\" \" value * int64 var v int64 value : & v , atomic . AddInt64 ( c . value , val ) return atomic . LoadInt64 ( c . value )", "del_tokens": "\" \" value int64 mutex * sync . Mutex value : 0 , mutex : & sync . Mutex { } , c . mutex . Lock ( ) defer c . mutex . Unlock ( ) c . value += val c . mutex . Lock ( ) defer c . mutex . Unlock ( ) return c . value", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "read", "and", "print", "bin", "log"], "add_tokens": "var ( ErrSkipEvent = errors . New ( \" \" ) ) func ReadEventFromReader ( rb io . Reader , f func ( createTime uint32 , event [ ] byte ) error ) error { err = f ( createTime , dataBuf . Bytes ( ) ) if err != nil && err != ErrSkipEvent { return err func ( l * Ledis ) ReplicateFromReader ( rb io . Reader ) error { f := func ( createTime uint32 , event [ ] byte ) error { err := l . ReplicateEvent ( event ) if err != nil { log . Fatal ( \" \" , err . Error ( ) ) return ErrSkipEvent } return nil } return ReadEventFromReader ( rb , f ) }", "del_tokens": "func ( l * Ledis ) ReplicateFromReader ( rb io . Reader ) error { err = l . ReplicateEvent ( dataBuf . Bytes ( ) ) if err != nil { log . Fatal ( \" \" , err . Error ( ) )", "commit_type": "add"}
{"commit_tokens": ["Updated", "CircleCI", "config", "to", "v2", ".", "Fixed", "compilation", "issue", "to", "support", "latest", "GoLang", "version", ".", "Fixed", "test", "cases", "in", "blob_test", ".", "go"], "add_tokens": "table , err = driver . NewTable ( \" \" , 3 , 0 ) table , err = driver . NewTable ( \" \" , 3 , 0 )", "del_tokens": "table , err = driver . NewTable ( \" \" , 1 , 1 ) table , err = driver . NewTable ( \" \" , 1 , 1 )", "commit_type": "update"}
{"commit_tokens": ["Add", "BackendKeyData", "Reading", "whack", "around", "error", "handling"], "add_tokens": "err = ErrTooBig { fmt . Errorf ( err = ErrWrongSize {", "del_tokens": "type ErrStartupSmall struct { error } type ErrStartupBig struct { error } err = ErrStartupBig { fmt . Errorf ( err = ErrStartupSmall {", "commit_type": "add"}
{"commit_tokens": ["Add", "comments", "the", "ParseError", "type"], "add_tokens": "// A ParseError occurs when an environment variable cannot be converted to // the type required by a struct field during assignment. func ( e * InvalidSpecificationError ) Error ( ) string { func ( e * ParseError ) Error ( ) string {", "del_tokens": "func ( e InvalidSpecificationError ) Error ( ) string { func ( e ParseError ) Error ( ) string {", "commit_type": "add"}
{"commit_tokens": ["Changed", "values", "used", "for", "testing", "."], "add_tokens": "const DOMAIN = \" \" const API_KEY = \" \"", "del_tokens": "const DOMAIN = \" \" const API_KEY = \" \"", "commit_type": "change"}
{"commit_tokens": ["Adding", "truecolor", "support", "back", "in"], "add_tokens": "lol \" \" cmd . SetOutput ( & lol . Writer { Output : os . Stdout , ColorMode : lol . ColorModeTrueColor } )", "del_tokens": "cmd . SetOutput ( logger . FabulousWriter )", "commit_type": "add"}
{"commit_tokens": ["Fix", "using", "a", "registry", "anonymously", "if", "we", "have", "auth", "for", "another", "registry"], "add_tokens": "return types . AuthConfig { ServerAddress : c . GlobalString ( \" \" ) , } , nil", "del_tokens": "return types . AuthConfig { } , fmt . Errorf ( \" \" , c . GlobalString ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "simple", "30", "-", "second", "interval", "for", "polling"], "add_tokens": "//retry, _ := strconv.Atoi(res.Header.Get(\"Retry-After\")) //retry *= int(time.Second) return time . Duration ( 30 * time . Second ) , nil", "del_tokens": "\" \" retry , _ := strconv . Atoi ( res . Header . Get ( \" \" ) ) retry *= int ( time . Second ) return time . Duration ( retry ) , nil", "commit_type": "use"}
{"commit_tokens": ["Use", "pointers", "to", "be", "more", "efficient"], "add_tokens": "func Remotes ( ) ( [ ] * GitRemote , error ) { remotes := make ( [ ] * GitRemote , 0 ) remotes = append ( remotes , & GitRemote { Name : match [ 1 ] , URL : match [ 2 ] } ) return r , nil", "del_tokens": "func Remotes ( ) ( [ ] GitRemote , error ) { remotes := make ( [ ] GitRemote , 0 ) remotes = append ( remotes , GitRemote { Name : match [ 1 ] , URL : match [ 2 ] } ) return & r , nil", "commit_type": "use"}
{"commit_tokens": ["Remove", "useless", "fmt", "in", "routes", "/", "parsing", ".", "go"], "add_tokens": "// SelectFields changes the json part of struct tags of in interface{} (that must by a struct or a slice of structs with the right json tags)", "del_tokens": "\" \" // SelectFields changes the json part of struct tags of in interface{} (that must be of type struct) fmt . Println ( fieldName )", "commit_type": "remove"}
{"commit_tokens": ["Added", "memcache", "failure", "Get", "test", "."], "add_tokens": "errs [ index ] = datastoreGetMulti ( c , items , err := memcacheGetMulti ( c , memcacheKeys ) if err := memcacheAddMulti ( c , lockItems ) ; err != nil { items , err := memcacheGetMulti ( c , lockMemcacheKeys ) if err := datastoreGetMulti ( c , keys , vals . Interface ( ) ) ; err == nil { if err := memcacheCompareAndSwapMulti ( c , saveItems ) ; err != nil {", "del_tokens": "errs [ index ] = datastore . GetMulti ( c , items , err := memcache . GetMulti ( c , memcacheKeys ) if err := memcache . AddMulti ( c , lockItems ) ; err != nil { items , err := memcache . GetMulti ( c , lockMemcacheKeys ) if err := datastore . GetMulti ( c , keys , vals . Interface ( ) ) ; err == nil { if err := memcache . CompareAndSwapMulti ( c , saveItems ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "the", "VFS", "Test", "Issue"], "add_tokens": "snapCountEqual := false for x := 0 ; x < 10 ; x ++ { time . Sleep ( time . Duration ( 1 ) * time . Second ) snapshots , err := client . API ( ) . SnapshotsByService ( nil , vfs . Name ) if ! assert . NoError ( t , err ) { t . FailNow ( ) } if len ( snapshots ) != 10 { continue } snapCountEqual = assert . EqualValues ( t , 10 , len ( snapshots ) ) break assert . True ( t , snapCountEqual )", "del_tokens": "snapshots , err := client . API ( ) . SnapshotsByService ( nil , vfs . Name ) assert . NoError ( t , err ) if err != nil { t . FailNow ( ) assert . EqualValues ( t , 10 , len ( snapshots ) )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "block", "and", "unblock", "functions", "(", "internally", ")", "and", "updated", "Friendship", "structure"], "add_tokens": "// This function updates current User.Friendship structure. resp := friendResp { } err = json . Unmarshal ( body , & resp ) user . Friendship = resp . Friendship resp := friendResp { } err = json . Unmarshal ( body , & resp ) user . Friendship = resp . Friendship", "del_tokens": "// This function updates current User structure. usr := User { } err = json . Unmarshal ( body , & usr ) if err == nil { * user = usr user . inst = insta } usr := User { } err = json . Unmarshal ( body , & usr ) if err == nil { * user = usr user . inst = insta }", "commit_type": "change"}
{"commit_tokens": ["Fix", "r1", "and", "r2", "handling", "upon", "suffix", "replacement", "."], "add_tokens": "{ \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 5 , \" \" , \" \" , \" \" } , { \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 6 , \" \" , \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } ,", "del_tokens": "{ \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 5 , \" \" , \" \" , \" \" } , { \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 7 , \" \" , \" \" , \" \" } , { \" \" , 3 , 6 , \" \" , \" \" , \" \" } ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "Light", "colors", "and", "Bright", "modifier"], "add_tokens": "BrightFm // bright return c & ( BrightFm | BoldFm | InverseFm | maskFg | maskBg ) != 0 || c == 0 if c & BrightFm != 0 { bs = append ( bs , '9' , '0' + byte ( ( c >> 8 ) & 0xff ) - 1 ) } else { bs = append ( bs , '3' , '0' + byte ( ( c >> 8 ) & 0xff ) - 1 ) } if c & BrightFm != 0 { bs = append ( bs , '1' , '0' , '0' + byte ( ( c >> 16 ) & 0xff ) - 1 ) } else { bs = append ( bs , '4' , '0' + byte ( ( c >> 16 ) & 0xff ) - 1 ) }", "del_tokens": "return c & ( BoldFm | InverseFm | maskFg | maskBg ) != 0 || c == 0 bs = append ( bs , '3' , '0' + byte ( ( c >> 8 ) & 0xff ) - 1 ) bs = append ( bs , '4' , '0' + byte ( ( c >> 16 ) & 0xff ) - 1 )", "commit_type": "add"}
{"commit_tokens": ["Use", "array", "instead", "of", "map", "for", "formats"], "add_tokens": "if itag < len ( FORMATS ) { if f := FORMATS [ itag ] ; f . Itag > 0 { return f , true } var FORMATS = [ ] Format {", "del_tokens": "if f , ok := FORMATS [ itag ] ; ok { f . meta = make ( map [ string ] interface { } ) return f , true var FORMATS = map [ int ] Format {", "commit_type": "use"}
{"commit_tokens": ["Use", "single", "=", "for", "versioned", "deps"], "add_tokens": "case \" = \"", "del_tokens": "case \" == \"", "commit_type": "use"}
{"commit_tokens": ["Use", "net", ".", "SplitHostPort", "instead", "of", "custom", "function"], "add_tokens": "_ , port , _ := net . SplitHostPort ( ln . Addr ( ) . String ( ) )", "del_tokens": "port := ExtractPort ( ln . Addr ( ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "bug", "in", "BytesReader", "and", "add", "test", "cases"], "add_tokens": "return strings . NewReader ( s . String ( ) ) return strings . NewReader ( s . Error ( ) )", "del_tokens": "strings . NewReader ( s . String ( ) ) strings . NewReader ( s . Error ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "argument", "names", "of", "pretty", ".", "Compare", "to", "a", "and", "b"], "add_tokens": "// values in a and b, using the CompareConfig. // Each line in the output is prefixed with '+', '-', or ' ' to indicate which // side it's from. Lines from the a side are marked with a '-', lines from the // b side are marked with a '+' and lines that are the same on both sides are // marked with a ' '. func Compare ( a , b interface { } ) string { return CompareConfig . Compare ( a , b ) func ( cfg * Config ) Compare ( a , b interface { } ) string { return diff . Diff ( cfg . Sprint ( a ) , cfg . Sprint ( b ) )", "del_tokens": "// values in got and want, using the CompareConfig. // Each line in the output is prefixed with '+', '-', or ' ' to indicate if it // should be added to, removed from, or is correct for the \"got\" value with // respect to the \"want\" value. func Compare ( got , want interface { } ) string { return CompareConfig . Compare ( got , want ) func ( cfg * Config ) Compare ( got , want interface { } ) string { return diff . Diff ( cfg . Sprint ( got ) , cfg . Sprint ( want ) )", "commit_type": "change"}
{"commit_tokens": ["Fix", "regression", "in", "value", "of", "unspecified", "string"], "add_tokens": "const Unspecified = \" \"", "del_tokens": "const Unspecified = \" \"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "panic", "if", "input", "string", "contains", "null", "string", "\\", "x00"], "add_tokens": "\" / / \" \" \" \" \" / / \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"", "del_tokens": "\" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"", "commit_type": "fix"}
{"commit_tokens": ["adding", "support", "for", "[]", "string", "input", "to", "NewBoundingBox"], "add_tokens": "case [ ] string : for _ , coord := range inputType { if coordValue , err = strconv . ParseFloat ( coord , 64 ) ; err == nil { result = append ( result , coordValue ) } else { return result , errors . New ( \" \" + err . Error ( ) ) } } return NewBoundingBox ( strings . Split ( inputType , \" \" ) )", "del_tokens": "coords := strings . Split ( inputType , \" \" ) for _ , coord := range coords { if coordValue , err = strconv . ParseFloat ( coord , 64 ) ; err == nil { result = append ( result , coordValue ) } else { return result , errors . New ( \" \" + err . Error ( ) ) } }", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "no", "robots"], "add_tokens": "func TestNoRobot ( t * testing . T ) { spy := newSpy ( new ( DefaultExtender ) , true ) spy . setExtensionMethod ( eMKFilter , func ( u * url . URL , from * url . URL , isVisited bool , o EnqueueOrigin ) ( enqueue bool , priority int , hrm HeadRequestMode ) { return ! isVisited && from == nil , 0 , HrmDefault } ) opts := NewOptions ( spy ) opts . CrawlDelay = DefaultTestCrawlDelay opts . LogFlags = LogAll c := NewCrawlerWithOptions ( opts ) c . Run ( \" \" ) // TODO : Check if it really has no robots.txt! assertCallCount ( spy , eMKFetch , 2 , t ) // robots + root assertCallCount ( spy , eMKVisit , 1 , t ) // root }", "del_tokens": "// TODO : Add test with web fetcher for a site with no robots.txt (404)", "commit_type": "add"}
{"commit_tokens": ["implement", "most", "of", "the", "LIST", "command"], "add_tokens": "case \" \" : ftpConn . cmdList ( param ) // cmdList responds to the LIST FTP command. It allows the client to retreive // a detailed listing of the contents of a directory. func ( ftpConn * FTPConn ) cmdList ( param string ) { ftpConn . writeMessage ( 150 , \" \" ) path := ftpConn . buildPath ( param ) files := ftpConn . driver . DirContents ( path ) formatter := NewListFormatter ( files ) ftpConn . sendOutofbandData ( formatter . Detailed ( ) ) } // cmdNlst responds to the NLST FTP command. It allows the client to retreive", "del_tokens": "// cmdList responds to the NLST FTP command. It allows the client to retreive", "commit_type": "implement"}
{"commit_tokens": ["Use", "correct", "variable", "in", "logger", ".", "SetFormat", "call"], "add_tokens": "logger . SetFormat ( LoggerDefaultFormat )", "del_tokens": "logger . SetFormat ( LoggerDefaultDateFormat )", "commit_type": "use"}
{"commit_tokens": ["updated", "watcher", "to", "take", "a", "polling", "interval", "on", "start"], "add_tokens": "// Start the watcher to check for changes every 100ms. if err := w . Start ( 100 ) ; err != nil {", "del_tokens": "// Start the watcher if err := w . Start ( ) ; err != nil {", "commit_type": "update"}
{"commit_tokens": ["Move", "AuthConfig", "to", "api", "/", "types"], "add_tokens": "func ( cli * Client ) RegistryLogin ( auth types . AuthConfig ) ( types . AuthResponse , error ) {", "del_tokens": "\" \" func ( cli * Client ) RegistryLogin ( auth cliconfig . AuthConfig ) ( types . AuthResponse , error ) {", "commit_type": "move"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "foreign", "key", "constraints", "in", "Load", "()", "function"], "add_tokens": "err = loadFn ( tx ) _ , err2 := tx . Exec ( \" \" ) if err != nil { if err2 != nil { return err2 }", "del_tokens": "// re-enable after load defer func ( ) { if _ , err2 := db . Exec ( \" \" ) ; err2 != nil && err == nil { err = err2 } } ( ) if err = loadFn ( tx ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Use", "$HOME", "/", "go", "when", "$GOPATH", "not", "available", "."], "add_tokens": "\" \" if s := gopath ( ) ; s != \" \" { func gopath ( ) string { path := os . Getenv ( \" \" ) if path != \" \" { return path } path , ok := os . LookupEnv ( \" \" ) if ok { return filepath . Join ( path , \" \" ) } return \" \" }", "del_tokens": "if s := os . Getenv ( \" \" ) ; s != \" \" {", "commit_type": "use"}
{"commit_tokens": ["changed", "interface", ".", "order", "function", "passed", "separately", "."], "add_tokens": "return t . getHeight ( t . root , key ) func ( t * Tree ) getHeight ( h * node , item Item ) ( Item , int ) { if t . less ( item , h . item ) { result , depth := t . getHeight ( h . left , item ) if t . less ( h . item , item ) { result , depth := t . getHeight ( h . right , item )", "del_tokens": "return getHeight ( t . root , key ) func getHeight ( h * node , item Item ) ( Item , int ) { if item . LessThan ( h . item ) { result , depth := getHeight ( h . left , item ) if h . item . LessThan ( item ) { result , depth := getHeight ( h . right , item )", "commit_type": "change"}
{"commit_tokens": ["add", "completed_frameworks", "field", "to", "state", "json"], "add_tokens": "ID string `json:\"id\"` Slaves [ ] Slave `json:\"slaves\"` Frameworks [ ] Framework `json:\"frameworks\"` CompletedFrameworks [ ] Framework `json:\"completed_frameworks\"`", "del_tokens": "ID string `json:\"id\"` Slaves [ ] Slave `json:\"slaves\"` Frameworks [ ] Framework `json:\"frameworks\"`", "commit_type": "add"}
{"commit_tokens": ["Removing", "old", "session", ".", "DB", "hardcoded", "references"], "add_tokens": "type session struct { var Session = session { } func ( ssn * session ) Repository ( ) * mgo . Collection { func ( ssn * session ) User ( ) * mgo . Collection {", "del_tokens": "type s struct { var Session = s { } var session * mgo . Session session , err = mgo . Dial ( \" \" ) if err != nil { panic ( err ) } func ( ssn * s ) Repository ( ) * mgo . Collection { func ( ssn * s ) User ( ) * mgo . Collection {", "commit_type": "remove"}
{"commit_tokens": ["Allow", "fethching", "queues", "with", "query", "GET", "arguments"], "add_tokens": "// RateDetailSample single touple type RateDetailSample struct { Sample int64 `json:\"sample\"` Timestamp int64 `json:\"timestamp\"` } Rate float32 `json:\"rate\"` Samples [ ] RateDetailSample `json:\"samples\"`", "del_tokens": "Rate float32 `json:\"rate\"`", "commit_type": "allow"}
{"commit_tokens": ["use", "one", "address", "variable", "in", "test", "case"], "add_tokens": "\" \" _ , err := DialTimeout ( network , address + \" \" , 0 , \" \" , 5 * time . Second , 5 ) rawurl := fmt . Sprintf ( \" \" , address ) rawurl := fmt . Sprintf ( \" \" , address )", "del_tokens": "_ , err := DialTimeout ( network , \" \" , 0 , \" \" , 5 * time . Second , 5 ) rawurl := \" \" rawurl := \" \"", "commit_type": "use"}
{"commit_tokens": ["Allow", "setting", "the", "cache", "size"], "add_tokens": "if CacheEnabled ( ) {", "del_tokens": "if cacheEnabled ( ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "adaptive", "sampler", "update", "bug"], "add_tokens": "if s . defaultSamplingProbability != strategies . DefaultSamplingProbability { defaultSampler , err := NewProbabilisticSampler ( strategies . DefaultSamplingProbability ) if err != nil { return err } s . defaultSamplingProbability = strategies . DefaultSamplingProbability s . defaultSampler = defaultSampler }", "del_tokens": "s . defaultSamplingProbability = strategies . DefaultSamplingProbability", "commit_type": "fix"}
{"commit_tokens": ["Moving", "error", "handlers", "to", "the", "cache", "implementations", "."], "add_tokens": "Read ( ) ( token * Token ) Write ( token * Token ) filename string ErrorHandlerFunc func ( error ) func ( f * FileCache ) Read ( ) ( token * Token ) { if err == nil { err = json . Unmarshal ( data , token ) if f . ErrorHandlerFunc != nil { f . ErrorHandlerFunc ( err ) } return func ( f * FileCache ) Write ( token * Token ) { if err == nil { err = ioutil . WriteFile ( f . filename , data , 0644 ) } if f . ErrorHandlerFunc != nil { f . ErrorHandlerFunc ( err )", "del_tokens": "Read ( ) ( token * Token , err error ) Write ( token * Token ) ( err error ) filename string func ( f * FileCache ) Read ( ) ( token * Token , err error ) { if err != nil { return nil , err token = & Token { } err = json . Unmarshal ( data , & token ) return token , err func ( f * FileCache ) Write ( token * Token ) error { if err != nil { return err return ioutil . WriteFile ( f . filename , data , 0644 )", "commit_type": "move"}
{"commit_tokens": ["Use", "constant", "to", "replace", "strings"], "add_tokens": "_ , err := NewCommand ( \" \" , \" \" , BRANCH_PREFIX + name ) . RunInDir ( repo . Path ) branches [ i ] = strings . TrimPrefix ( fields [ 1 ] , BRANCH_PREFIX )", "del_tokens": "_ , err := NewCommand ( \" \" , \" \" , \" \" + name ) . RunInDir ( repo . Path ) branches [ i ] = strings . TrimPrefix ( fields [ 1 ] , \" \" )", "commit_type": "use"}
{"commit_tokens": ["add", "some", "more", "planar", "area", "tests", "and", "comments"], "add_tokens": "centroid , area := CentroidArea ( ring ) if ! centroid . Equal ( expected ) { t . Errorf ( \" \" , centroid , expected ) } if area != - 2.5 { t . Errorf ( \" \" , area ) t . Run ( \" \" , func ( t * testing . T ) {", "del_tokens": "if c , _ := CentroidArea ( ring ) ; ! c . Equal ( expected ) { t . Errorf ( \" \" , c , expected ) t . Run ( \" \" , func ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "go", "-", "ws", "-", "transport", "package", "name"], "add_tokens": "ws \" \"", "del_tokens": "ws \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "running", "reaper", "out", "of", "process", "aka", "run", "as", "init", "and", "add"], "add_tokens": "func start_reaper ( ) { } /* End of function start_reaper. */ func launch_test ( ) { sig := make ( chan os . Signal , 1 ) signal . Notify ( sig , syscall . SIGUSR1 ) } /* End of function launch_test. */ func main ( ) { start_reaper ( ) launch_test ( )", "del_tokens": "func main ( ) { sig := make ( chan os . Signal , 1 ) signal . Notify ( sig , syscall . SIGUSR1 )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "AES", "-", "256", "-", "CBC"], "add_tokens": "\" \" var ErrUnsupportedAlgorithm = errors . New ( \" \" ) var oidEncryptionAlgorithmAES256CBC = asn1 . ObjectIdentifier { 2 , 16 , 840 , 1 , 101 , 3 , 4 , 1 , 42 } if ! alg . Equal ( oidEncryptionAlgorithmDESCBC ) && ! alg . Equal ( oidEncryptionAlgorithmDESEDE3CBC ) && ! alg . Equal ( oidEncryptionAlgorithmAES256CBC ) { case alg . Equal ( oidEncryptionAlgorithmAES256CBC ) : block , err = aes . NewCipher ( key )", "del_tokens": "var ErrUnsupportedAlgorithm = errors . New ( \" \" ) if ! alg . Equal ( oidEncryptionAlgorithmDESCBC ) && ! alg . Equal ( oidEncryptionAlgorithmDESEDE3CBC ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "embed", "-", "go"], "add_tokens": "fullPath := filepath . Join ( dir , f . Name ) if err := os . MkdirAll ( filepath . Dir ( fullPath ) , 0770 ) ; err != nil { return nil , cleanup , err } if err := ioutil . WriteFile ( fullPath , f . Contents , 0660 ) ; err != nil {", "del_tokens": "if err := ioutil . WriteFile ( filepath . Join ( dir , f . Name ) , f . Contents , 0660 ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["implement", "login", "user", "for", "the", "sqlite", "backend"], "add_tokens": "loginUserStmt * sql . Stmt backend . loginUserStmt , err = backend . db . Prepare ( `SELECT uid FROM Users WHERE email = ? AND password = ?`) if err != nil { return err } result , err := backend . createUserStmt . Exec ( email , password ) if email == \" \" || password == \" \" { return 0 , & Error { \" \" , \" \" } } rows , err := backend . loginUserStmt . Query ( email , password ) defer rows . Close ( ) if err != nil { return 0 , & Error { \" \" , err . Error ( ) } } if ! rows . Next ( ) { return 0 , & Error { \" \" , \" \" } } var uid int64 serr := rows . Scan ( & uid ) if serr != nil { return 0 , & Error { \" \" , err . Error ( ) } } return uid , nil", "del_tokens": "result , err := backend . createUserStmt . Exec ( email , password ) return 0 , nil", "commit_type": "implement"}
{"commit_tokens": ["Remove", "unnecessary", "recreation", "of", "map", "."], "add_tokens": "if contextMap [ req ] != nil {", "del_tokens": "contextMap = make ( map [ * http . Request ] * csrfContext ) if len ( contextMap ) != 0 || contextMap [ req ] != nil {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "import", "path", "parsing", "when", "there", "was", "no", "path", "arg"], "add_tokens": "args = [ ] string { \" \" }", "del_tokens": "args = [ ] string { srcdir }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "adding", "to", "chanotify", "on", "blocking", "select"], "add_tokens": "ctrl chan struct { } ctrl : make ( chan struct { } ) , s . ctrl <- struct { } { } close ( s . ctrl ) if ok { continue } // ctrl was closed, we can safely close output // put ctrl channel as 0 element of select Chan : reflect . ValueOf ( s . ctrl ) ,", "del_tokens": "exit chan struct { } exit : make ( chan struct { } ) , close ( s . exit ) // exit was closed, we can safely close output // put exit channel as 0 element of select Chan : reflect . ValueOf ( s . exit ) ,", "commit_type": "fix"}
{"commit_tokens": ["Allow", "CORS", "Final", "-", "Length", "header"], "add_tokens": "w . Header ( ) . Add ( \" \" , \" \" )", "del_tokens": "w . Header ( ) . Add ( \" \" , \" \" )", "commit_type": "allow"}
{"commit_tokens": ["Fixing", "expected", "path", "for", "pgx", "in", "documentation"], "add_tokens": "// PostgreSQL (pgx) | github.com/jackc/pgx/stdlib", "del_tokens": "// PostgreSQL (pgx) | github.com/jackc/pgx", "commit_type": "fix"}
{"commit_tokens": ["Use", "different", "duration", "for", "ttl", "&", "heartbeat"], "add_tokens": "interval : interval , ttl : interval + 5 * time . Second , ttl time . Duration err = r . store . Put ( key , b , & store . WriteOptions { TTL : r . ttl } )", "del_tokens": "interval : interval + 5 * time . Second , err = r . store . Put ( key , b , & store . WriteOptions { TTL : r . interval } )", "commit_type": "use"}
{"commit_tokens": ["added", "regex", "matching", "for", "strings"], "add_tokens": "EQ = \" \" NOT_EQ = \" \" AND = \" \" OR = \" \" MATCHES = \" \"", "del_tokens": "EQ = \" \" NOT_EQ = \" \" AND = \" \" OR = \" \"", "commit_type": "add"}
{"commit_tokens": ["added", "some", "time", "series", "queries", "and", "commands", ".", "Added", "extra", "post", "-", "process", "table", "and", "index", "to", "inventory", "cmd"], "add_tokens": "\" \" , \" \" , \" \" , query . Index ( \" \" , \" \" ) , panic ( err ) panic ( err ) panic ( err )", "del_tokens": "\" \" , panic ( err . Error ( ) ) panic ( err . Error ( ) ) panic ( err . Error ( ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "a", "not", "very", "useful", "variable"], "add_tokens": "remote net . Addr func ( s * UDPSession ) LocalAddr ( ) net . Addr { return s . conn . LocalAddr ( ) }", "del_tokens": "local , remote net . Addr sess . local = conn . LocalAddr ( ) func ( s * UDPSession ) LocalAddr ( ) net . Addr { return s . local }", "commit_type": "remove"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", "definitions"], "add_tokens": "out . Type = string ( in . String ( ) ) out . String ( string ( in . Type ) )", "del_tokens": "( out . Type ) . UnmarshalEasyJSON ( in ) ( in . Type ) . MarshalEasyJSON ( out )", "commit_type": "update"}
{"commit_tokens": ["Fix", "exception", "propagation", "when", "N", ">", "1", "calls", "are", "calling", "in", "/", "out", "of", "go", "-", "mruby", "and", "one", "of", "then", "throws", "."], "add_tokens": "func goMRBFuncCall ( s * C . mrb_state , v C . mrb_value ) C . mrb_value { result , exc := f ( mrb , newValue ( s , v ) ) if exc != nil { s . exc = C . _go_mrb_getobj ( exc . MrbValue ( mrb ) . value ) }", "del_tokens": "func goMRBFuncCall ( s * C . mrb_state , v * C . mrb_value , callExc * C . mrb_value ) C . mrb_value { result , exc := f ( mrb , newValue ( s , * v ) ) if exc != nil { * callExc = exc . MrbValue ( mrb ) . value return mrb . NilValue ( ) . value } // If the result was a Go nil, convert it to a Ruby nil", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "bug", "where", "invalid", "chunk", "tokens", "would", "cause", "a", "misalignment", "in", "the", "protocol"], "add_tokens": "errState := false errState = true //fmt.Println(id, \"Get miss because of invalid chunk token. Cmd:\", cmd) errState = true if errState || chunk < int ( metaData . NumChunks - 1 ) {", "del_tokens": "errorOut <- err return //fmt.Println(\"Get miss because of invalid chunk token. Cmd:\", getCmd) dataOut <- errResponse continue outer if chunk < int ( metaData . NumChunks - 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "lower", "case", "log", "messages", "for", "consistency", "in", "xwatch"], "add_tokens": "initCh : make ( chan struct { } ) , s . logger . Errorf ( \" \" ) s . logger . Errorf ( \" \" , err )", "del_tokens": "initCh : make ( chan struct { } ) , s . logger . Errorf ( \" \" ) s . logger . Errorf ( \" \" , err )", "commit_type": "use"}
{"commit_tokens": ["Implemented", "specs", "so", "they", "are", "passing"], "add_tokens": "pathA . TimeSpan = NewTimeSpan ( 5 , 20 ) pathB . TimeSpan = NewTimeSpan ( 6 , 21 ) pathA . TimeSpan = NewTimeSpan ( 6 , 21 ) pathB . TimeSpan = NewTimeSpan ( 5 , 20 )", "del_tokens": "pathA . TimeSpan = NewTimeSpan ( 0 , 20 ) pathB . TimeSpan = NewTimeSpan ( 1 , 21 ) pathA . TimeSpan = NewTimeSpan ( 1 , 21 ) pathB . TimeSpan = NewTimeSpan ( 0 , 20 )", "commit_type": "implement"}
{"commit_tokens": ["Allow", "publishing", "to", "and", "unsubscribing", "from", "multiple", "topics", "in", "a", "single", "call"], "add_tokens": "// the specified topics. func ( ps * PubSub ) Pub ( msg interface { } , topics ... string ) { for _ , topic := range topics { ps . pub <- cmd { topic , msg } } // topics. func ( ps * PubSub ) Unsub ( ch chan interface { } , topics ... string ) { for _ , topic := range topics { ps . unsub <- cmd { topic , ch } }", "del_tokens": "// the specified topic. func ( ps * PubSub ) Pub ( topic string , msg interface { } ) { ps . pub <- cmd { topic , msg } // topic. func ( ps * PubSub ) Unsub ( topic string , ch chan interface { } ) { ps . unsub <- cmd { topic , ch }", "commit_type": "allow"}
{"commit_tokens": ["allow", "client", "secret", "or", "access", "token"], "add_tokens": "func NewClient ( mode , clientID , clientSecret , accessToken string ) * Client { return newClient ( httpClient , mode , clientID , clientSecret , accessToken ) func newClient ( httpClient * http . Client , mode , clientID , clientSecret , accessToken string ) * Client { ClientSecret string `url:\"client_secret,omitempty\"` AccessToken string `url:\"access_token,omitempty\"` AccessToken : accessToken ,", "del_tokens": "func NewClient ( mode , clientID , clientSecret string ) * Client { return newClient ( httpClient , mode , clientID , clientSecret ) func newClient ( httpClient * http . Client , mode , clientID , clientSecret string ) * Client { ClientSecret string `url:\"client_secret\"`", "commit_type": "allow"}
{"commit_tokens": ["Make", "log", "message", "prefixes", "constants"], "add_tokens": "const ( msgPrefix = \" \" redPrefix = \" \\033 \" bluePrefix = \" \\033 \" colorSuffix = \" \\033 \" msgError = msgPrefix + redPrefix + \" \" + colorSuffix msgWarning = msgPrefix + redPrefix + \" \" + colorSuffix msgProtip = msgPrefix + bluePrefix + \" \" + colorSuffix )", "del_tokens": "var msgPrefix , msgError , msgWarning , msgProtip string func init ( ) { msgPrefix = \" \" msgError = msgPrefix + red ( \" \" ) msgWarning = msgPrefix + red ( \" \" ) msgProtip = msgPrefix + blue ( \" \" ) } func red ( uncolored string ) string { return fmt . Sprintf ( \" \\033 \\033 \" , uncolored ) } func yellow ( uncolored string ) string { return fmt . Sprintf ( \" \\033 \\033 \" , uncolored ) } func blue ( uncolored string ) string { return fmt . Sprintf ( \" \\033 \\033 \" , uncolored ) }", "commit_type": "make"}
{"commit_tokens": ["Move", "debug", "printout", "to", "before", "the", "data", "is", "used", "."], "add_tokens": "flog . irc . Debugf ( \" \" , event )", "del_tokens": "flog . irc . Debugf ( \" \" , event )", "commit_type": "move"}
{"commit_tokens": ["moves", "invalid", "character", "checking", "away", "from", "regexes", ".", "no", "more", "regexes", "used", "in", "parsing!"], "add_tokens": "\" \" title = string ( removeAllBytes ( [ ] byte ( title ) , [ ] byte ( `[\\t\\n\\\"]` ) ) ) func removeAllBytes ( source [ ] byte , targets [ ] byte ) [ ] byte { clean := make ( [ ] byte , len ( source ) ) cleanBytes := 0 for _ , b := range source { if bytes . IndexByte ( targets , b ) == - 1 { clean [ cleanBytes ] = b } } return clean [ : cleanBytes + 1 ] }", "del_tokens": "\" \" var invalidCharacterRegex = regexp . MustCompile ( `[\\t\\n\\\"]` ) title = invalidCharacterRegex . ReplaceAllString ( title , \" \" )", "commit_type": "move"}
{"commit_tokens": ["Add", "file", "-", "server", "AltDir", "option"], "add_tokens": "f , err := s . open ( p ) ff , err := s . open ( index ) f , err := s . open ( p ) func ( s Server ) open ( p string ) ( f http . File , err error ) { if s . AltDir == \" \" { return open ( s . dir , p ) } f , err = open ( s . AltDir , p ) if os . IsNotExist ( err ) { f , err = open ( s . dir , p ) } return }", "del_tokens": "f , err := open ( s . dir , p ) ff , err := open ( s . dir , index ) f , err := open ( s . dir , p )", "commit_type": "add"}
{"commit_tokens": ["use", "time", ".", "Duration", "instead", "of", "int", "to", "specify", "session", "timeout"], "add_tokens": "\" \" // Set session cache timeout. Returns previously set value. func ( c * Ctx ) SetTimeout ( t time . Duration ) time . Duration { prev := C . SSL_CTX_set_timeout_not_a_macro ( c . ctx , C . long ( t / time . Second ) ) return time . Duration ( prev ) * time . Second // Get session cache timeout. func ( c * Ctx ) GetTimeout ( ) time . Duration { return time . Duration ( C . SSL_CTX_get_timeout_not_a_macro ( c . ctx ) ) * time . Second", "del_tokens": "// Set session cache timeout in seconds. Returns previously set value. func ( c * Ctx ) SetTimeout ( t int ) int { return int ( C . SSL_CTX_set_timeout_not_a_macro ( c . ctx , C . long ( t ) ) ) // Get session cache timeout in seconds. func ( c * Ctx ) GetTimeout ( ) int { return int ( C . SSL_CTX_get_timeout_not_a_macro ( c . ctx ) )", "commit_type": "use"}
{"commit_tokens": ["Allow", "debug", "queries", "to", "etcd", "middleware"], "add_tokens": "// this name will always have a closing dot and will be lower cased. After a call Name // the value will be cached. To clear this caching call Clear. // TODO(miek): make this less awkward.", "del_tokens": "// this name will always have a closing dot and will be lower cased.", "commit_type": "allow"}
{"commit_tokens": ["Allow", "Range", "and", "If", "-", "None", "-", "Match", "headers", "to", "be", "set", "on", "Download"], "add_tokens": "for k , v := range arg . ExtraHeaders { headers [ k ] = v } if resp . StatusCode == http . StatusOK || resp . StatusCode == http . StatusPartialContent {", "del_tokens": "if resp . StatusCode == http . StatusOK {", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "typo", "in", "DomainCreateResult", "of", "WhoisguardEnable"], "add_tokens": "WhoisguardEnable bool `xml:\"WhoisguardEnable,attr\"`", "del_tokens": "WhoisGuardEnable bool `xml:\"WhoisGuardEnable,attr\"`", "commit_type": "fix"}
{"commit_tokens": ["Fix", "linting", "errors", "and", "adjusted", "API", "add", "documentation", "for", "usage", "hints", "."], "add_tokens": "URL : \" \" , os . Exit ( service . ExitRegistration ) os . Exit ( service . ExitSuccess )", "del_tokens": "Url : \" \" , os . Exit ( service . EXIT_REGISTRATION ) os . Exit ( service . EXIT_SUCCESS )", "commit_type": "fix"}
{"commit_tokens": ["Use", "private", "esc", "function", "names"], "add_tokens": "//go:generate go run ./vendor/github.com/mweagle/esc/main.go -o ./CONSTANTS.go -private -pkg sparta ./resources nodeJSSource := escFSMustString ( false , \" \" ) resourceContent := escFSMustString ( false , resourceName ) nodeModuleBytes , err := escFSByte ( false , \" \" ) \" \" : ctx . s3Bucket , \" \" : keyName , \" \" : ctx . s3Bucket , \" \" : s3keyName ,", "del_tokens": "//go:generate go run ./vendor/github.com/mjibson/esc/main.go -o ./CONSTANTS.go -pkg sparta ./resources nodeJSSource := FSMustString ( false , \" \" ) resourceContent := FSMustString ( false , resourceName ) nodeModuleBytes , err := FSByte ( false , \" \" ) \" \" : uploadInput , \" \" : uploadInput ,", "commit_type": "use"}
{"commit_tokens": ["Fixed", "the", "build", "after", "a", "change", "in", "package", "gcs", "."], "add_tokens": "return gcs . NewConn ( projectId , httpClient )", "del_tokens": "return gcs . OpenConn ( projectId , httpClient )", "commit_type": "fix"}
{"commit_tokens": ["Make", "use", "of", "Index", "function", "."], "add_tokens": "import ( \" \" ) index := utils . Index ( header )", "del_tokens": "index := make ( map [ string ] int ) for i , h := range header { index [ h ] = i }", "commit_type": "make"}
{"commit_tokens": ["Changed", "HTTP", "Client", "in", "examples", "to", "a", "higher", "timeout"], "add_tokens": "\" \" \" \" client := & http . Client { Timeout : 30 * time . Second , } trend := trending . NewTrendingWithClient ( client ) client := & http . Client { Timeout : 30 * time . Second , } trend := trending . NewTrendingWithClient ( client ) client := & http . Client { Timeout : 30 * time . Second , } trend := trending . NewTrendingWithClient ( client ) client := & http . Client { Timeout : 30 * time . Second , } trend := trending . NewTrendingWithClient ( client )", "del_tokens": "trend := trending . NewTrending ( ) trend := trending . NewTrending ( ) trend := trending . NewTrending ( ) trend := trending . NewTrending ( )", "commit_type": "change"}
{"commit_tokens": ["add", "logging", "for", "error", "from", "close"], "add_tokens": "err := c . Close ( ) if nil != err { d . log . Error ( err ) }", "del_tokens": "c . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "TriggerIncidentKeyWithDetails", "s", "missing", "incident", "key", "."], "add_tokens": "func TriggerIncidentKeyWithDetails ( description , key string , details map [ string ] interface { } ) ( incidentKey string , err error ) { return trigger ( description , key , details )", "del_tokens": "func TriggerIncidentKeyWithDetails ( description string , details map [ string ] interface { } ) ( incidentKey string , err error ) { return trigger ( description , \" \" , details )", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "and", "documentation", "for", "headers"], "add_tokens": "headers . set ( req . Header ) // set headers for an HTTP request func ( h * Headers ) set ( reqHeader http . Header ) { reqHeader . Set ( \" \" , h . ID ) reqHeader . Set ( \" \" , strconv . FormatInt ( h . Expiration . Unix ( ) , 10 ) ) reqHeader . Set ( \" \" , \" \" ) reqHeader . Set ( \" \" , h . Topic )", "del_tokens": "headers . set ( req ) // set headers on an HTTP request func ( h * Headers ) set ( req * http . Request ) { req . Header . Set ( \" \" , h . ID ) req . Header . Set ( \" \" , strconv . FormatInt ( h . Expiration . Unix ( ) , 10 ) ) req . Header . Set ( \" \" , \" \" ) req . Header . Set ( \" \" , h . Topic )", "commit_type": "add"}
{"commit_tokens": ["Make", "quit", "()", "exit", "even", "while", "waiting", "for", "next", "tick"], "add_tokens": "for { select { case <- ticker . C : runIteration ( ) case <- l . quitChan : stopFunc ( nil ) return", "del_tokens": "for range ticker . C { if stop { break runIteration ( )", "commit_type": "make"}
{"commit_tokens": ["Use", "cookiejar", "in", "soap", "client"], "add_tokens": "\" \" c . Jar , _ = cookiejar . New ( nil ) return err", "del_tokens": "c * http . Cookie if c . c != nil { httpreq . AddCookie ( c . c ) } panic ( err ) } cookies := httpres . Cookies ( ) for _ , cookie := range cookies { if cookie . Name != \" \" { continue } c . c = cookie c . c . Secure = false // Don't care", "commit_type": "use"}
{"commit_tokens": ["Fix", "EventStream", ".", "match", "randomness", "behaviour"], "add_tokens": "termui . UseTheme ( \" \" ) b := termui . NewBlock ( ) b . Width = 20 b . Height = 30 b . BorderLabel = \" \" termui . SendBufferToRender ( b ) debug . Logf ( \" \\n \" , e ) termui . Handle ( \" \" , func ( e termui . Event ) { //debug.Logf(\"<-%v\\n\", e) t := e . Data . ( termui . EvtTimer ) if t . Count % 2 == 0 { b . BorderLabel = \" \" } else { b . BorderLabel = \" \" } termui . SendBufferToRender ( b )", "del_tokens": "debug . Logf ( \" \\n \" , e ) termui . Handle ( \" \" , func ( e termui . Event ) { //debug.Logf(\"-->%v\\n\", e)", "commit_type": "fix"}
{"commit_tokens": ["updated", "Value", "to", "use", "simpler", "algorithm", "and", "change", "interface", "."], "add_tokens": "// Float64ToString returns a Lens which transforms from float64 // to string. The given formats are used to effect the conversion; // fmt.Sscanf(s, scanf, &x) is used to scan the string s into the float64 func Float64ToString ( printf , scanf string ) * Lens { func round ( f float64 ) int { if f < 0 { return int ( f - 0.5 ) } return int ( f + 0.5 ) } // Float64ToInt returns a Lens that transforms a float64 // value to the nearest int. func Float64ToInt ( ) * Lens { return round ( f ) , nil // UnitFloat64ToRangedFloat64 returns a Lens that peforms a linear // transformation from a float64 // value in [0, 1] to a float64 value in [lo, hi]. func UnitFloat64ToRangedFloat64 ( lo , hi float64 ) * Lens { // Float64Multiply returns a Lens that multiplies by x. func Float64Multiply ( x float64 ) * Lens {", "del_tokens": "// Float2String returns a Lens which maps between float64 // and string. The given formats are used to effect the conversion; // fmt.Sscanf(s, scanf, &x) is used to convert the string s to the float64 func Float2String ( printf , scanf string ) * Lens { func Float2Int ( ) * Lens { return int ( f + 0.5 ) , nil // UnitFloat2RangedFloat peforms a linear conversion between a float64 // value in [0, 1] and a float64 value in [lo, hi]. func UnitFloat2RangedFloat ( lo , hi float64 ) * Lens { // FloatMultiply multiplies by x. func FloatMultiply ( x float64 ) * Lens {", "commit_type": "update"}
{"commit_tokens": ["Fixed", "a", "bug", "which", "occurrs", "when", "RemoteAddr", "is", "used"], "add_tokens": "buf . WriteString ( strings . ToLower ( r . RemoteAddr [ : strings . Index ( r . RemoteAddr , \" \" ) ] ) + sep )", "del_tokens": "buf . WriteString ( strings . ToLower ( r . RemoteAddr ) + sep )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "custom", "metrics"], "add_tokens": "\" \" type WaveMetrica struct { sawtoothMax int sawtoothCounter int } func ( metrica * WaveMetrica ) GetName ( ) string { return \" \" } func ( metrica * WaveMetrica ) GetUnits ( ) string { return \" \" } func ( metrica * WaveMetrica ) GetValue ( ) ( float64 , error ) { metrica . sawtoothCounter ++ if metrica . sawtoothCounter > metrica . sawtoothMax { metrica . sawtoothCounter = 0 } return float64 ( metrica . sawtoothCounter ) , nil } agent . AddCustomMetric ( & WaveMetrica { sawtoothMax : 10 , sawtoothCounter : 5 , } )", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "to", "cover", "the", "Pretty", "=", "False", "codepath", "in", "the", "ServeHTTP", "function", "."], "add_tokens": "func TestHandler_BasicQuery_Pretty ( t * testing . T ) { func TestHandler_BasicQuery_Ugly ( t * testing . T ) { expected := & graphql . Result { Data : map [ string ] interface { } { \" \" : map [ string ] interface { } { \" \" : \" \" , \" \" : \" \" , } , } , } queryString := `query=query RebelsShipsQuery { rebels { id, name } }` req , _ := http . NewRequest ( \" \" , fmt . Sprintf ( \" \" , queryString ) , nil ) h := handler . New ( & handler . Config { Schema : & starwars . Schema , Pretty : false , } ) result , resp := executeTest ( t , h , req ) if resp . Code != http . StatusOK { t . Fatalf ( \" \" , resp . Code ) } if ! reflect . DeepEqual ( result , expected ) { t . Fatalf ( \" \" , testutil . Diff ( expected , result ) ) } }", "del_tokens": "func TestHandler_BasicQuery ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Update", "some", "mistakes", "in", "doc", "."], "add_tokens": "// NewChaincodeExecute is used to invoke chaincode.", "del_tokens": "// NewChaincodeExecute is used to deploy chaincode.", "commit_type": "update"}
{"commit_tokens": ["Fix", "tag", "parse", "with", "no", "padding"], "add_tokens": "if int ( t . padding ) > t . frameHeaderSize { // Psuedo-unread bytes for last attempted frame nAdvance := int ( t . padding ) - t . frameHeaderSize if n , err := io . ReadFull ( reader , make ( [ ] byte , nAdvance ) ) ; n != nAdvance || err != nil { return nil }", "del_tokens": "nAdvance := int ( t . padding ) - t . frameHeaderSize if n , err := io . ReadFull ( reader , make ( [ ] byte , nAdvance ) ) ; n != nAdvance || err != nil { return nil", "commit_type": "fix"}
{"commit_tokens": ["make", "CertificateInfo", "Serial", "type", "to", "*", "big", ".", "Int"], "add_tokens": "\" \" Serial * big . Int func ( c * Certificate ) SetSerial ( serial * big . Int ) error { sno := C . ASN1_INTEGER_new ( ) defer C . ASN1_INTEGER_free ( sno ) bn := C . BN_new ( ) defer C . BN_free ( bn ) serialBytes := serial . Bytes ( ) if bn = C . BN_bin2bn ( ( * C . uchar ) ( unsafe . Pointer ( & serialBytes [ 0 ] ) ) , C . int ( len ( serialBytes ) ) , bn ) ; bn == nil { return errors . New ( \" \" ) } if sno = C . BN_to_ASN1_INTEGER ( bn , sno ) ; sno == nil { return errors . New ( \" \" ) } if C . X509_set_serialNumber ( c . x , sno ) != 1 {", "del_tokens": "Serial int func ( c * Certificate ) SetSerial ( serial int ) error { if C . ASN1_INTEGER_set ( C . X509_get_serialNumber ( c . x ) , C . long ( serial ) ) != 1 {", "commit_type": "make"}
{"commit_tokens": ["Fix", "tiny", "typo", "in", "docs", "."], "add_tokens": "// for the purposes of this example, the private extended key for the // for the purposes of this example, the private extended key for the", "del_tokens": "// for the purposes of this example, the private exteded key for the // for the purposes of this example, the private exteded key for the", "commit_type": "fix"}
{"commit_tokens": ["Create", "new", "hook", "on", "parallel", "test"], "add_tokens": "h := NewHook ( \" \" , \" \" , WithIgnoreFunc ( func ( err error , m map [ string ] string ) bool { if err == io . EOF { return true } if m [ \" \" ] == \" \" { return true } return false } ) )", "del_tokens": "h := NewHook ( \" \" , \" \" , WithIgnoreFunc ( func ( err error , m map [ string ] string ) bool { if err == io . EOF { return true } if m [ \" \" ] == \" \" { return true } return false } ) )", "commit_type": "create"}
{"commit_tokens": ["Add", "bigger", "covers", "for", "testing"], "add_tokens": "backCoverName = \" \" framesSize = 222479 MimeType : \" \" ,", "del_tokens": "backCoverName = \" \" framesSize = 63009 MimeType : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["implement", "user", "adding", "from", "the", "web", "interface"], "add_tokens": "webfw . NewBaseController ( \" \" , webfw . MethodGet | webfw . MethodPost , \" \" ) ,", "del_tokens": "webfw . NewBaseController ( \" \" , webfw . MethodGet | webfw . MethodPost , \" \" ) ,", "commit_type": "implement"}
{"commit_tokens": ["make", "the", "kafka", "lib", "more", "interface", "-", "friendly", "and", "hence", "test", "-", "friendly"], "add_tokens": "case consumedMessage := <- consumer . Incoming ( ) : producer . Output ( ) <- consumedMessage . GetData ( ) case errorMessage := <- consumer . Errors ( ) : producer . Closer ( ) <- true consumer . Closer ( ) <- true", "del_tokens": "case consumedMessage := <- consumer . Incoming : producer . Output <- consumedMessage . GetData ( ) case errorMessage := <- consumer . Errors : producer . Closer <- true consumer . Closer <- true", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "ability", "to", "scan", "directories", "recursively", "."], "add_tokens": "\" \" \" \" \" \" if isDir ( filename ) { lintDir ( filename ) } else { lintFile ( filename ) } func isDir ( filename string ) bool { fi , err := os . Stat ( filename ) return err == nil && fi . IsDir ( ) } func lintDir ( dirname string ) { filepath . Walk ( dirname , func ( path string , info os . FileInfo , err error ) error { if err == nil && ! info . IsDir ( ) && strings . HasSuffix ( path , \" \" ) { lintFile ( path ) } return err } ) }", "del_tokens": "lintFile ( filename )", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "and", "instructions", "for", "testing", "in", "the", "README"], "add_tokens": "if item == js . Undefined || item == nil { if key == js . Undefined || key == nil { length := localStorage . Get ( \" \" ) if length == js . Undefined || length == nil {", "del_tokens": "if item == js . Undefined { if key == js . Undefined { length := localStorage . Call ( \" \" ) if length == js . Undefined {", "commit_type": "add"}
{"commit_tokens": ["add", "AddString", "()", "and", "AddBytes", "()", "helpers"], "add_tokens": "id , err := q . Queue . AddString ( \" \" )", "del_tokens": "\" \" id , err := q . Queue . Add ( bytes . NewBufferString ( \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["make", "background", "instance", "as", "array"], "add_tokens": "background [ 2 ] Background scene . background [ 0 ] . W = config . ScreenWidth scene . background [ 0 ] . H = config . ScreenHeight scene . background [ 0 ] . X = config . ScreenWidth / 2 scene . background [ 0 ] . Y = config . ScreenHeight / 2 & scene . background [ 0 ] . Sprite ) // set size of background scene . background [ 1 ] . W = config . ScreenWidth scene . background [ 1 ] . H = config . ScreenHeight // put out of screen scene . background [ 1 ] . X = config . ScreenWidth / 2 + config . ScreenWidth scene . background [ 1 ] . Y = config . ScreenHeight / 2 simra . GetInstance ( ) . AddSprite ( \" \" , image . Rect ( 0 , 0 , config . ScreenWidth , config . ScreenHeight ) , & scene . background [ 1 ] . Sprite )", "del_tokens": "background Background scene . background . W = config . ScreenWidth scene . background . H = config . ScreenHeight scene . background . X = config . ScreenWidth / 2 scene . background . Y = config . ScreenHeight / 2 & scene . background . Sprite )", "commit_type": "make"}
{"commit_tokens": ["fix", "progress", "bar", "on", "ipfs", "get"], "add_tokens": "Path string Progress func ( int64 ) int64 err = copyWithProgress ( file , r , te . Progress ) func copyWithProgress ( to io . Writer , from io . Reader , cb func ( int64 ) int64 ) error { buf := make ( [ ] byte , 4096 ) for { n , err := from . Read ( buf ) if err != nil { if err == io . EOF { return nil } return err } cb ( int64 ( n ) ) _ , err = to . Write ( buf [ : n ] ) if err != nil { return err } } }", "del_tokens": "Path string _ , err = io . Copy ( file , r )", "commit_type": "fix"}
{"commit_tokens": ["added", "methods", "to", "delete", "start", "stop", "pause", "and", "resume", "a", "scan"], "add_tokens": "//log.Println(nessus.StartScan(5)) //log.Println(nessus.StopScan(5)) //log.Println(nessus.DeleteScan(5)) //log.Println(nessus.PauseScan(5)) //log.Println(nessus.ResumeScan(5))", "del_tokens": "log . Println ( nessus . StartScan ( 5 ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "omitempty", "as", "null", "values", "create", "errors", "."], "add_tokens": "Type string `json:\"type\"` // required ID string `json:\"id\"` // required Title string `json:\"title\"` // required InputMessageContent interface { } `json:\"input_message_content,omitempty\"` // required InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"` InputMessageContent interface { } `json:\"input_message_content,omitempty\"`", "del_tokens": "Type string `json:\"type\"` // required ID string `json:\"id\"` // required Title string `json:\"title\"` // required InputMessageContent interface { } `json:\"input_message_content\"` // required InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"` InputMessageContent interface { } `json:\"input_message_content\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "fork", "URL", "which", "always", "has", "owner", "and", "repo"], "add_tokens": "ForksURL = Hyperlink ( \" \" )", "del_tokens": "ForksURL = Hyperlink ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["updated", "digestAuthHeader", "to", "return", "ErrWWWAuthenticateHeader", "*", "instead", "of", "calling", "fmt", ".", "Errorf"], "add_tokens": "\" \" var ( // Returned by digestAuthHeader when the WWW-Authenticate header is missing ErrWWWAuthenticateHeaderMissing = errors . New ( \" \" ) // Returned by digestAuthHeader when the WWW-Authenticate invalid ErrWWWAuthenticateHeaderInvalid = errors . New ( \" \" ) // Returned by digestAuthHeader when the WWW-Authenticate header is not 'Digest' ErrWWWAuthenticateHeaderNotDigest = errors . New ( \" \" ) ) return \" \" , ErrWWWAuthenticateHeaderMissing return \" \" , ErrWWWAuthenticateHeaderInvalid return \" \" , ErrWWWAuthenticateHeaderNotDigest", "del_tokens": "return \" \" , fmt . Errorf ( \" \" ) return \" \" , fmt . Errorf ( \" \" ) return \" \" , fmt . Errorf ( \" \" )", "commit_type": "update"}
{"commit_tokens": ["Update", "token", "generator", "to", "return", "expiration", "date", "and", "error"], "add_tokens": "// TokenGenerator method that clients can use to get a jwt token. func ( mw * GinJWTMiddleware ) TokenGenerator ( userID string ) ( string , time . Time , error ) { expire := mw . TimeFunc ( ) . UTC ( ) . Add ( mw . Timeout ) claims [ \" \" ] = expire . Unix ( ) tokenString , err := token . SignedString ( mw . Key ) if err != nil { return \" \" , time . Time { } , err } return tokenString , expire , nil", "del_tokens": "// TokenGenerator handler that clients can use to get a jwt token. func ( mw * GinJWTMiddleware ) TokenGenerator ( userID string ) string { claims [ \" \" ] = mw . TimeFunc ( ) . Add ( mw . Timeout ) . Unix ( ) tokenString , _ := token . SignedString ( mw . Key ) return tokenString", "commit_type": "update"}
{"commit_tokens": ["Fix", "typo", "on", "error", "name"], "add_tokens": "Unauthorized = NewErrorf ( http . StatusUnauthorized , http . StatusText ( http . StatusUnauthorized ) )", "del_tokens": "Unauthtorized = NewErrorf ( http . StatusUnauthorized , http . StatusText ( http . StatusUnauthorized ) )", "commit_type": "fix"}
{"commit_tokens": ["created", "an", "internal", "goon", ".", "timeout", "()", "function", "since", "appengine", ".", "Timeout", "(", "context", "duration", ")", "didn", "t", "work", "in", "the", "development", "environment"], "add_tokens": "err := memcache . SetMulti ( g . timeout ( MemcachePutTimeout ) , items )", "del_tokens": "err := memcache . SetMulti ( appengine . Timeout ( g . context , MemcachePutTimeout ) , items )", "commit_type": "create"}
{"commit_tokens": ["Add", "support", "for", "dereferencing", "pointers", ".", "Nil", "prints", "as", "empty", "string"], "add_tokens": "\" \" // limit the number of pointers to follow dereferenceLimit := 2 for resolved . Kind ( ) == reflect . Ptr && dereferenceLimit >= 0 { dereferenceLimit -- if resolved . IsNil ( ) { return reflect . ValueOf ( \" \" ) } resolved = reflect . Indirect ( resolved ) }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "(", "default", "true", ")", "option", "to", "format", "output"], "add_tokens": "\" \" \" \" runFmt := flag . Bool ( \" \" , true , \" \" ) var buf bytes . Buffer // Write template to buffer. if err := p . Write ( & buf ) ; err != nil { log . Fatal ( \" \" , err ) } result := buf . Bytes ( ) if * runFmt { var err error if result , err = format . Source ( result ) ; err != nil { log . Fatal ( \" \" , err ) } } if _ , err = f . Write ( result ) ; err != nil {", "del_tokens": "// Write template to file. if err := p . Write ( f ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Add", "good", "logging", "support", "to", "both", "sides"], "add_tokens": "\" \" func Init ( container * libcontainer . Container , uncleanRootfs , console string , pipe io . ReadCloser , args [ ] string ) error { rootfs , err := resolveRootfs ( uncleanRootfs ) log . Printf ( \" \" , rootfs ) if tempVethName != \" \" { log . Printf ( \" \" , tempVethName ) } log . Printf ( \" \" , console ) log . Printf ( \" \" ) log . Printf ( \" \" ) log . Printf ( \" \" , args [ 0 ] ) func resolveRootfs ( uncleanRootfs string ) ( string , error ) { rootfs , err := filepath . Abs ( uncleanRootfs )", "del_tokens": "func Init ( container * libcontainer . Container , console string , pipe io . ReadCloser , args [ ] string ) error { rootfs , err := resolveRootfs ( ) func resolveRootfs ( ) ( string , error ) { cwd , err := os . Getwd ( ) if err != nil { return \" \" , err } rootfs , err := filepath . Abs ( cwd )", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "default", "http", "client", "to", "a", "variable"], "add_tokens": "// The default http.Client that is used if none is specified var defaultClient = & http . Client { Timeout : time . Second * 30 , } HTTPClient = defaultClient client = defaultClient client = defaultClient client = defaultClient", "del_tokens": "HTTPClient = defaultClient ( ) client = defaultClient ( ) client = defaultClient ( ) client = defaultClient ( ) func defaultClient ( ) * http . Client { client := http . Client { Timeout : clientTimeout , } return & client }", "commit_type": "move"}
{"commit_tokens": ["Fix", "potential", "panic", "in", "variable", "-", "length", "encoding"], "add_tokens": "binary . LittleEndian . PutUint32 ( byteSample , uint32 ( sample ) )", "del_tokens": "binary . PutVarint ( byteSample , int64 ( sample ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "subtask", "integration", "test", "."], "add_tokens": "newSubtaskTitle1 := uuid1 . String ( ) newSubtaskTitle2 := uuid2 . String ( ) newSubtaskTitle1 , newSubtaskTitle2 , var firstListTasks [ ] wundergo . Task Eventually ( func ( ) error { flt , err := client . TasksForListID ( firstList . ID ) firstListTasks = * flt return err } ) . Should ( Succeed ( ) ) var index int for i , task := range firstListTasks { if task . ID == newTask . ID { index = i } } subtaskPosition = & tp [ index ]", "del_tokens": "newTaskTitle1 := uuid1 . String ( ) newTaskTitle2 := uuid2 . String ( ) newTaskTitle1 , newTaskTitle2 , // Assume tasks are in first TaskPosition subtaskPosition = & tp [ 0 ]", "commit_type": "fix"}
{"commit_tokens": ["Remove", "duplicate", "mdb_cursor_get", "()", "."], "add_tokens": "if set_key != nil && ( op == SET || op == SET_KEY || op == SET_RANGE ) { ckey . mv_size = C . size_t ( len ( set_key ) ) ckey . mv_data = unsafe . Pointer ( & set_key [ 0 ] )", "del_tokens": "if set_key != nil && op == SET { var cset_key * C . MDB_val cset_key = & C . MDB_val { mv_size : C . size_t ( len ( set_key ) ) , mv_data : unsafe . Pointer ( & set_key [ 0 ] ) } ret := C . mdb_cursor_get ( cursor . _cursor , cset_key , & cval , C . MDB_cursor_op ( op ) ) if ret != SUCCESS { err = Errno ( ret ) key = nil val = nil return } key = set_key val = C . GoBytes ( cval . mv_data , C . int ( cval . mv_size ) )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "faulty", "rate", "limiting", "test"], "add_tokens": "handler . ServeHTTP ( rr , req ) //Should not be limited if status := rr . Code ; status != http . StatusOK { t . Errorf ( \" \" , status , http . StatusOK ) } // Should be limited if status := rr . Code ; status != http . StatusTooManyRequests { t . Errorf ( \" \" , status , http . StatusTooManyRequests )", "del_tokens": "// Should not be limited if status := rr . Code ; status != http . StatusOK { t . Errorf ( \" \" , status , http . StatusOK ) handler . ServeHTTP ( rr , req ) //Should be limited if status := rr . Code ; status != http . StatusTooManyRequests { t . Errorf ( \" \" , status , http . StatusTooManyRequests ) }", "commit_type": "fix"}
{"commit_tokens": ["fixing", "my", "broken", "exists", "check"], "add_tokens": "if m . Exists ( name ) {", "del_tokens": "if ! m . Exists ( name ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "url", "encoding", "for", "HTTP_HEADERS", "codec"], "add_tokens": "sp1 . SetBaggageItem ( \" \" , \" \" ) // colon : should be escaped as %3A assert . Equal ( t , \" \" , sp1 . BaggageItem ( \" \" ) , \" \" , sp1 . ( * span ) . context . baggage ) // check that colon : was encoded as %3A assert . Equal ( t , \" \" , h . Get ( TraceBaggageHeaderPrefix + \" \" ) ) assert . Equal ( t , map [ string ] string { \" \" : \" \" } , sp2 . ( SpanContext ) . baggage )", "del_tokens": "sp1 . SetBaggageItem ( \" \" , \" \" ) assert . Equal ( t , \" \" , sp1 . BaggageItem ( \" \" ) , \" \" , sp1 . ( * span ) . context . baggage ) assert . Equal ( t , map [ string ] string { \" \" : \" \" } , sp2 . ( SpanContext ) . baggage )", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "from", "Echo", ".", "WebSocket", "()"], "add_tokens": "func NewHTTPError ( code int , msg ... string ) * HTTPError { for _ , m := range msg { e . Get ( path , func ( c * Context ) ( err error ) { err = h ( c ) return err", "del_tokens": "func NewHTTPError ( code int , msgs ... string ) * HTTPError { for _ , m := range msgs { e . Get ( path , func ( c * Context ) * HTTPError { h ( c ) return nil", "commit_type": "add"}
{"commit_tokens": ["changed", "debug", "level", "for", "message"], "add_tokens": "Log . Debugln ( \" \" , reason )", "del_tokens": "Log . Println ( \" \" , reason )", "commit_type": "change"}
{"commit_tokens": ["Remove", "unused", "variable", "from", "FinalHandler", "and", "FinalHandlerFunc"], "add_tokens": "func FinalHandler ( h http . Handler ) func ( http . Handler ) http . Handler { func FinalHandlerFunc ( h func ( w http . ResponseWriter , r * http . Request ) ) func ( http . Handler ) http . Handler {", "del_tokens": "func FinalHandler ( h http . Handler ) func ( h http . Handler ) http . Handler { func FinalHandlerFunc ( h func ( w http . ResponseWriter , r * http . Request ) ) func ( h http . Handler ) http . Handler {", "commit_type": "remove"}
{"commit_tokens": ["Implement", "basic", ".", "recover", "(", "NOT", "IMPLEMENTED", "on", "RabbitMQ", ")"], "add_tokens": "/ * Asks the server to redeliver all unacknowledged deliveries on this channel . When requeue is false , messages will be redelivered to the original consumer . When requeue is true , messages will be redelivered to any available consumer , potentially including the original . If the deliveries cannot be recovered , an error will be returned and the channel will be closed . Note : this method is not implemented on RabbitMQ * / func ( me * Channel ) Recover ( requeue bool ) error { return me . call ( & basicRecover { Requeue : requeue } , & basicRecoverOk { } , ) }", "del_tokens": "//TODO func (me *Channel) Recover(requeue bool) error { return nil }", "commit_type": "implement"}
{"commit_tokens": ["Fix", "consumergroup", "tests", "to", "use", "sarama", ".", "Client", "interface"], "add_tokens": "func saramaClient ( ) sarama . Client {", "del_tokens": "func saramaClient ( ) * sarama . Client {", "commit_type": "fix"}
{"commit_tokens": ["Add", "one", "more", "error", "in", "pf", ".", "Bytes", "()"], "add_tokens": "if _ , err := b . ReadFrom ( pf . picture ) ; err != nil { return nil , err }", "del_tokens": "b . ReadFrom ( pf . picture )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "separate", "stream", "HTTP", "client", "that", "specifies", "infinite", "timeout", "for"], "add_tokens": "// streamClient is used as the HTTP client for streaming Event Source protocol // messages from Firebase var streamClient = newTimeoutClient ( connectTimeout , streamTimeout ) streamTimeout = time . Duration ( 0 ) // never time out reading from a stream func doFirebaseRequest ( client * http . Client , method , path , auth , accept string , body interface { } , params map [ string ] string ) ( * http . Response , error ) { return client . Do ( req ) response , err := doFirebaseRequest ( httpClient , method , path , auth , \" \" , body , params ) response , err := doFirebaseRequest ( streamClient , \" \" , path , auth , \" \" , body , params )", "del_tokens": "func doFirebaseRequest ( method , path , auth , accept string , body interface { } , params map [ string ] string ) ( * http . Response , error ) { return httpClient . Do ( req ) response , err := doFirebaseRequest ( method , path , auth , \" \" , body , params ) response , err := doFirebaseRequest ( \" \" , path , auth , \" \" , body , params )", "commit_type": "use"}
{"commit_tokens": ["Updating", "Header", "to", "comply", "to", "DxfElement", "interface", "and", "updated", "table", "utils", "to", "use", "Equals", "API", "whenever", "possible", "+", "unit", "tests", "."], "add_tokens": "if tags [ tagIndex ] . Equals ( stopTag ) { if tags [ tagIndex ] . Equals ( chunkDelimiter ) { if tags [ tagIndex ] . Equals ( stopTag ) {", "del_tokens": "if tags [ tagIndex ] . Equals ( * stopTag ) { if tags [ tagIndex ] . Equals ( * chunkDelimiter ) { if tags [ tagIndex ] . Equals ( * stopTag ) {", "commit_type": "update"}
{"commit_tokens": ["fix", "bug", "for", "database", ".", "ExtendSQLType", "add", "SimpleEmail", "validator", "add"], "add_tokens": "return typ - 1", "del_tokens": "return typ", "commit_type": "fix"}
{"commit_tokens": ["add", "some", "printf", "for", "debugging"], "add_tokens": "return newService , err", "del_tokens": "return newService , nil", "commit_type": "add"}
{"commit_tokens": ["Using", "pointer", "instead", "of", "index", "."], "add_tokens": "var remainder * treeHashNode for added > 1 || remainder != nil { // have a child that couldn't be paired up if remainder == nil { // hold on to child as remainder for later remainder = & th . nodes [ childIndex ] th . nodes [ outIndex ] . Right = remainder th . part . Write ( remainder . Hash [ : ] ) remainder = nil var remainder * treeHashNode for added > 1 || remainder != nil { if remainder == nil { remainder = & hashes [ childIndex ] hashes [ outIndex ] . Right = remainder partHash . Write ( remainder . Hash [ : ] ) remainder = nil", "del_tokens": "remainderIndex := - 1 for added > 1 || remainderIndex != - 1 { // have a remainder that couldn't be paired up if remainderIndex == - 1 { // hold on to remainder for later remainderIndex = childIndex th . nodes [ outIndex ] . Right = & th . nodes [ remainderIndex ] th . part . Write ( th . nodes [ remainderIndex ] . Hash [ : ] ) remainderIndex = - 1 remainderIndex := - 1 for added > 1 || remainderIndex != - 1 { if remainderIndex == - 1 { remainderIndex = childIndex hashes [ outIndex ] . Right = & hashes [ remainderIndex ] partHash . Write ( hashes [ remainderIndex ] . Hash [ : ] ) remainderIndex = - 1", "commit_type": "use"}
{"commit_tokens": ["Update", "config", "with", "defaults", "from", "config", "policy"], "add_tokens": "false , plugin . SetDefaultString ( \" \" ) )", "del_tokens": "false )", "commit_type": "update"}
{"commit_tokens": ["added", "a", "value", "interface", "pointer", "to", "a", "node"], "add_tokens": "// Value can be used to store information on the caller side. // Its use is optional. See the Topological Sort example for // a reason on why to use this pointer. // The reason it is a pointer is so that graph function calls // can test for equality on Nodes. The pointer wont change, // the value it points to will. If the pointer is explicitly changed, // graph functions that use Nodes will cease to work. Value * interface { } // If kind is anything else, this function will return an undirected graph by default. func New ( kind GraphType ) * Graph { return & Graph { nodes : [ ] * node { } , edges : make ( map [ * node ] [ ] Edge ) , kind : Directed } return & Graph { nodes : [ ] * node { } , edges : make ( map [ * node ] [ ] Edge ) } return & Graph { nodes : [ ] * node { } , edges : make ( map [ * node ] [ ] Edge ) } newNode . container = Node { node : newNode , Value : new ( interface { } ) }", "del_tokens": "\" \" // Otherwise, this will return nil and an error. func New ( kind GraphType ) ( * Graph , error ) { return & Graph { nodes : [ ] * node { } , edges : make ( map [ * node ] [ ] Edge ) , kind : Directed } , nil return & Graph { nodes : [ ] * node { } , edges : make ( map [ * node ] [ ] Edge ) } , nil return nil , errors . New ( \" \" ) newNode . container = Node { node : newNode }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "lowercases", "DN", "elements"], "add_tokens": "if strings . ToUpper ( rdnAttr . Type ) == \" \" {", "del_tokens": "if rdnAttr . Type == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Remove", "a", "branch", "from", "Set", "Add", "and", "CompareAndSwap"], "add_tokens": "return c . populateOne ( cmdSet , item , 0 ) return c . populateOne ( cmdAdd , item , 0 ) return c . populateOne ( cmdSet , item , item . casid ) func ( c * Client ) populateOne ( cmd command , item * Item , casid uint64 ) error {", "del_tokens": "return c . populateOne ( cmdSet , item , false ) return c . populateOne ( cmdAdd , item , false ) return c . populateOne ( cmdSet , item , true ) func ( c * Client ) populateOne ( cmd command , item * Item , cas bool ) error { casid := item . casid if ! cas { casid = 0 }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "another", "line", "which", "godoc", ".", "org", "mistook", "for", "a", "heading", "."], "add_tokens": "// Returns the number of rows updated. // Returns the number of rows deleted.", "del_tokens": "// Returns number of rows updated // Returns number of rows deleted.", "commit_type": "fix"}
{"commit_tokens": ["add", "error", "return", "to", "unsubscribe"], "add_tokens": "func ( bus * EventBus ) Unsubscribe ( channel string ) error { bus . lock . Unlock ( ) return nil // Adding for safety until PR with defer is merged return fmt . Errorf ( \" \" , channel )", "del_tokens": "func ( bus * EventBus ) Unsubscribe ( channel string ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "bad", "Cmp", "that", "spun", "from", "a", "bad", "test", "case"], "add_tokens": "if zl < xl { return - zs } if zl > xl { return zs", "del_tokens": "// zl and xl could be any combination of negative and positive. If the // signs differ compare zl and xl directly. If they don't, compare |zl| // and |xl|. if ( zl <= 0 ) == ( xl <= 0 ) { if abs := arith . AbsCmp ( zl , xl ) ; abs != 0 { return abs } } else { if zl > xl { return + 1 } if zl < xl { return - 1 }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "Go", "weekly", ".", "2012", "-", "01", "-", "15", "."], "add_tokens": "\" \" \" \" testLoginError = errors . New ( \" \" ) func getPwdVal ( login string ) ( [ ] byte , error ) { token := NewToken ( testLogin , 100 * time . Second , pwdVal , testSecret ) token = NewToken ( login , 100 * time . Second , testPwdVal , testSecret )", "del_tokens": "\" \" testLoginError = os . NewError ( \" \" ) func getPwdVal ( login string ) ( [ ] byte , os . Error ) { token := NewToken ( testLogin , 100 , pwdVal , testSecret ) token = NewToken ( login , 100 , testPwdVal , testSecret )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "nil", "check", "to", "empty", "check"], "add_tokens": "if frames := t . Frames ( id ) ; len ( frames ) != 0 {", "del_tokens": "if frames := t . Frames ( id ) ; frames != nil {", "commit_type": "fix"}
{"commit_tokens": ["add", "larger", "bar", "for", "example"], "add_tokens": "b . Width = 40", "del_tokens": "b . Width = 25", "commit_type": "add"}
{"commit_tokens": ["Updating", "goauth2client", "example", "to", "use", "newer", "golang", ".", "net", "/", "x", "/", "oauth2", "package"], "add_tokens": "// Use golang.org/x/oauth2 client to test \" \" \" \" client := & oauth2 . Config { ClientID : \" \" , Endpoint : oauth2 . Endpoint { AuthURL : \" \" , TokenURL : \" \" , } , RedirectURL : \" \" , var jr * oauth2 . Token jr , err = client . Exchange ( oauth2 . NoContext , code )", "del_tokens": "// Use code.google.com/p/goauth2/oauth client to test \" \" \" \" client := & oauth . Config { ClientId : \" \" , RedirectURL : \" \" , AuthURL : \" \" , TokenURL : \" \" , ctransport := & oauth . Transport { Config : client } var jr * oauth . Token jr , err = ctransport . Exchange ( code )", "commit_type": "update"}
{"commit_tokens": ["fix", "vtaction", "logging", "-", "looks", "like", "a", "merge", "casualty"], "add_tokens": "\" \" , logfile ,", "del_tokens": "\" \" , flag . Lookup ( \" \" ) . Value . String ( ) ,", "commit_type": "fix"}
{"commit_tokens": ["fix", "bugs", ":", "reset", "buffer", "after", "trigger", "io", ".", "EOF", "/", "ErrInterrupt"], "add_tokens": "o . buf . WriteString ( o . cfg . EOFPrompt + \" \\n \" ) o . buf . Reset ( ) o . buf . WriteString ( o . cfg . InterruptPrompt + \" \\n \" ) o . buf . Reset ( )", "del_tokens": "o . buf . WriteString ( \" \\n \" ) o . buf . WriteString ( \" \\n \" )", "commit_type": "fix"}
{"commit_tokens": ["use", "math", "/", "rand", "and", "increase", "tolerance", "on", "tests", "because", "poisson", "is", "a", "jerk"], "add_tokens": "\" \" \" \" r := rand . New ( rand . NewSource ( time . Now ( ) . UnixNano ( ) ) )", "del_tokens": "//\"gx/ipfs/QmRWDav6mzWseLWeYfVd5fvUKiVe9xNH29YfMF438fG364/go-datastore/query\" rand \" \" r := rand . New ( )", "commit_type": "use"}
{"commit_tokens": ["Update", "import", "for", "new", "net", "package", "home"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Fix", "lint", "/", "vet", "warnings"], "add_tokens": "// Glob is a single glob pattern; implements GlobMatcher. A Glob is immutable. // Options modify the behaviour of Glob parsing // DefaultOptions are a default set of Options that uses a forward slash as a separator, and require a full match var DefaultOptions = & Options { return nil , fmt . Errorf ( \" \" , string ( options . Separator ) )", "del_tokens": "// A single glob pattern; implements GlobMatcher. A Glob is immutable. var DefaultOptions * Options = & Options { return nil , fmt . Errorf ( \" \" , options . Separator )", "commit_type": "fix"}
{"commit_tokens": ["add", "TTL", ".", "minor", "adjustments", "to", "db", "patterns"], "add_tokens": "// Storage.Create guarantees the DB Bucket with a configured TTL. For long running executions it // is possible old buckets will get deleted, so we use `findOrCreate` rather than `bucket` dbBucket , err := b . db . findOrCreateBucket ( b . name , b . rate ) dbBucket , err = b . db . resetBucket ( * dbBucket , b . rate ) dbBucket , err := s . db . findOrCreateBucket ( name , rate ) func New ( tableName string , s * session . Session , itemTTL time . Duration ) ( * Storage , error ) { ttl : itemTTL ,", "del_tokens": "dbBucket , err := b . db . bucket ( b . name ) dbBucket , err = b . db . resetBucket ( * dbBucket , time . Now ( ) . Add ( b . rate ) ) dbBucket , err := s . db . createOrFindBucket ( newDDBBucket ( name , bucket . reset ) ) func New ( tableName string , s * session . Session ) ( * Storage , error ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "command", "timing", "to", "done", "marker", "for", "prep", "commands"], "add_tokens": "log . Notice ( \" \" , c . ProcessState . UserTime ( ) )", "del_tokens": "log . Notice ( \" \" ) // FIXME: rusage stats here log . NoticeAs ( \" \" , \" \" , c . ProcessState . UserTime ( ) )", "commit_type": "add"}
{"commit_tokens": ["allow", "a", "tls", "config", "to", "be", "specified"], "add_tokens": "\" \" func NewDockerClient ( daemonUrl string , tlsConfig * tls . Config ) ( * DockerClient , error ) { httpClient := newHTTPClient ( u , tlsConfig )", "del_tokens": "func NewDockerClient ( daemonUrl string ) ( * DockerClient , error ) { httpClient := newHTTPClient ( u )", "commit_type": "allow"}
{"commit_tokens": ["Adding", "an", "Unmarshall", "method", "that", "is", "not", "channel", "based"], "add_tokens": "UnmarshallMessage ( [ ] byte ) ( * events . Envelope , error ) envelope , err := u . UnmarshallMessage ( message ) func ( u * dropsondeUnmarshaller ) UnmarshallMessage ( message [ ] byte ) ( * events . Envelope , error ) { envelope := & events . Envelope { } err := proto . Unmarshal ( message , envelope ) if err != nil { u . logger . Debugf ( \" \" , err , message ) incrementCount ( & u . unmarshalErrorCount ) return nil , err } u . logger . Debugf ( \" \" , spew . Sprintf ( \" \" , envelope ) ) u . incrementReceiveCount ( envelope . GetEventType ( ) ) return envelope , nil }", "del_tokens": "envelope := & events . Envelope { } err := proto . Unmarshal ( message , envelope ) u . logger . Debugf ( \" \" , err , message ) incrementCount ( & u . unmarshalErrorCount ) u . logger . Debugf ( \" \" , spew . Sprintf ( \" \" , envelope ) ) u . incrementReceiveCount ( envelope . GetEventType ( ) )", "commit_type": "add"}
{"commit_tokens": ["add", "license", "update", "README", "and", "change", "init", "call", "to", "New", "()"], "add_tokens": "// Copyright 2013 Mark Canning // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // // // Author: Mark Canning // Developed at: Tamber, Inc. (http://www.tamber.com/). // // Tamber also has this really cool recommendation engine for music // (also development by me) which prioritizes up-and-coming artists, so // it doesn't succomb to the popularity biases that plague modern // recommendation engines, and still produces excellent personalized // recommendations! Make sure to check us out at http://www.tamber.com // or https://itunes.apple.com/us/app/tamber-concerts/id658240483", "del_tokens": "// Not ready yet / * * /", "commit_type": "add"}
{"commit_tokens": ["Make", "domain", "creation", "send", "a", "list", "instead", "of", "a", "single", "object"], "add_tokens": "newDomL := [ ] NewDomain { newDom } err := json . NewEncoder ( & b ) . Encode ( newDomL )", "del_tokens": "err := json . NewEncoder ( & b ) . Encode ( newDom )", "commit_type": "make"}
{"commit_tokens": ["Allow", "string", "method", "to", "be", "called", "on", "nil", "ID"], "add_tokens": "func ( id * ID ) String ( ) string { if id == nil { return \" \" }", "del_tokens": "func ( id ID ) String ( ) string {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "query", "&", "ensure", "company", "gets", "inserted", "for", "snapshots", "."], "add_tokens": "INNER JOIN DEVELOPER AS ad ON ad . id = a . developer_id INNER JOIN COMPANY AS ad ON ad . id = a . company_id", "del_tokens": "INNER JOIN ALL_DEVELOPERS AS ad ON ( ad . id = a . company_id OR ad . id = a . developer_id ) INNER JOIN ALL_DEVELOPERS AS ad ON ( ad . id = a . company_id OR ad . id = a . developer_id )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "panics", "in", "(", "*", "Connection", ")", ".", "handleCall"], "add_tokens": "reply . Body [ i ] = ret [ i ] . Interface ( ) reply . Headers [ FieldSignature ] = MakeVariant ( GetSignature ( reply . Body ... ) )", "del_tokens": "msg . Body [ i ] = ret [ i ] . Interface ( ) reply . Headers [ FieldSignature ] = MakeVariant ( GetSignature ( msg . Body ) )", "commit_type": "fix"}
{"commit_tokens": ["Move", "valuelocmap", "to", "its", "own", "package"], "add_tokens": "timestamp , id , offset , length := vm . vs . vlm . Get ( keyA , keyB )", "del_tokens": "timestamp , id , offset , length := vm . vs . vlm . get ( keyA , keyB )", "commit_type": "move"}
{"commit_tokens": ["fixed", "get", "jp", "domain", "created", "date"], "add_tokens": "var replacer = regexp . MustCompile ( `\\n\\[(.+?)\\][\\ ]+(.+?)` )", "del_tokens": "var replacer = regexp . MustCompile ( `\\n\\[(.+?)\\]\\s+(.+?)` )", "commit_type": "fix"}
{"commit_tokens": ["add", "basic", "http2", "header", "reading"], "add_tokens": "\" \" \" \" h2r := bytes . NewReader ( frame . Data ) h2framer := http2 . NewFramer ( nil , h2r ) h2framer . ReadMetaHeaders = hpack . NewDecoder ( 1024 , nil ) h2frame , err := h2framer . ReadFrame ( ) if err != nil { return err } h2headersFrame := h2frame . ( * http2 . MetaHeadersFrame ) fmt . Printf ( \" \\n \" , h2headersFrame )", "del_tokens": "fmt . Printf ( \" \\n \" , frame )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "the", "new", "logit", "api"], "add_tokens": "lgr . Print ( \" \" )", "del_tokens": "lgr . Log ( \" \" )", "commit_type": "update"}
{"commit_tokens": ["add", "detail", "explaination", "of", "the", "consistent", "hash", "algorithm", "cuz", "it", "s", "awesome!"], "add_tokens": "// A space efficient permutation-based consistent hashing function. This // implementation supports up to a maximum of (1 << 16 - 1), 65535, number // of shards. // // Implementation details: // // Unlike the standard ring-based algorithm (e.g., as described in dynamo db), // this algorithm relays on shard permutations to determine the mapping. The // idea is as follow: // 1. Assume there exist a set of shard ids, S, which contains every possible // shard ids in the universe (in this case 0 .. 65535). // 2. Now suppose, A (a subset of S), is the set of available shard ids, and we // want to find the shard mapping for key, K // 3. Use K as the pseudorandom generator's seed, and generate a random // permutation of S using variable-base permutation encoding (see // http://stackoverflow.com/questions/1506078/fast-permutation-number-permutation-mapping-algorithms // for additional details) // 4. Ignore all shard ids in the permutation that are not in set A // 5. use the first valid shard as the result. // // NOTE: Because each key generates a different permutation, the data // distibution is generally more uniform than the standard algorithm (The // standard algorithm works around this issue by adding more points to the // ring, which unfortunately uses even more memory). // // Complexity: this algorithm is O(1) in theory (because the max shard id is // known), but O(n) in practice. // // Example: // 1. Assume S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, and A = {0, 1, 2, 3, 4}. // 2. Now suppose K = 31415 and perm(S, K) = (3, 1, 9, 4, 7, 5, 8, 2, 0, 6). // 3. After ignoring S - A, the remaining permutation ids are (3, 1, 4, 2, 0) // 4. Therefore, the key belongs to shard 3. // Each hash can generate 2 permutation positions. Implementation // note: we can replace murmur hash with any other pesudorandom // generator, as long as it's sufficiently \"random\".", "del_tokens": "// This implements a variant of consistent hashing. This implementation // supports up to a maximum of (1 << 16 - 1) 65535 number of shards. // Each hash can generate 2 permutation positions", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "verpkg", "flag", "to", "be", "able", "to", "override", "the", "version", "package", "path", "."], "add_tokens": "// versionPackage is the path to this version package. // It is used to access version information attributes during link time. // This flag is useful when the version package is custom-vendored and has a different package path. var versionPackage = flag . String ( \" \" , \" \" , \" \" ) return fmt . Sprintf ( \" \" , * versionPackage , key , value ) return fmt . Sprintf ( \" \" , * versionPackage , key , value )", "del_tokens": "const versionPackage = \" \" return fmt . Sprintf ( \" \" , versionPackage , key , value ) return fmt . Sprintf ( \" \" , versionPackage , key , value )", "commit_type": "add"}
{"commit_tokens": ["Move", "google", "internal", "CI", "to", "seperate", "api"], "add_tokens": "PRStatus map [ string ] submitStatus http . HandleFunc ( \" \" , func ( w http . ResponseWriter , r * http . Request ) { sq . serveGoogleInternalStatus ( w , r ) } ) func ( sq * SubmitQueue ) getGoogleInternalStatus ( ) [ ] byte { sq . Lock ( ) defer sq . Unlock ( ) return sq . marshal ( sq . e2e . GetBuildStatus ( ) ) } func ( sq * SubmitQueue ) serveGoogleInternalStatus ( res http . ResponseWriter , req * http . Request ) { data := sq . getGoogleInternalStatus ( ) sq . serve ( data , res , req ) }", "del_tokens": "PRStatus map [ string ] submitStatus BuildStatus map [ string ] string status . BuildStatus = sq . e2e . GetBuildStatus ( )", "commit_type": "move"}
{"commit_tokens": ["Make", "Pool", "an", "exported", "type", "."], "add_tokens": "import ( ) Db databaseConfig", "del_tokens": "import ( \" \" \" \" ) Pool poolConfig Db databaseConfig // poolConfig holds config variables specific to the worker pool type poolConfig struct { // NumWorkers is the number of workers to run // Each worker will run inside its own goroutine // and execute jobs asynchronously. Default is // runtime.GOMAXPROCS. NumWorkers int // BatchSize is the number of jobs to send through // the jobs channel at once. Increasing BatchSize means // the worker pool will query the database less frequently, // so you would get higher performance. However this comes // at the cost that jobs with lower priority may sometimes be // executed before jobs with higher priority, because the jobs // with higher priority were not ready yet the last time the pool // queried the database. Decreasing BatchSize means more // frequent queries to the database and lower performance, but // greater likelihood of executing jobs in perfect order with regards // to priority. Setting BatchSize to 1 gaurantees that higher priority // jobs are always executed first as soon as they are ready. Default is // runtime.GOMAXPROCS. BatchSize int // MinWait is the minimum amount of time the pool will wait before checking // the database for queued jobs. The pool may take longer to query the database // if the jobs channel is blocking (i.e. if no workers are ready to execute new // jobs). Default is 200ms. MinWait time . Duration // StaleTimeout is the amount of time to wait for a pool to reply to a ping request // before considering it stale. Stale pools will be purged and if they have any // corresponding jobs in the executing set, those jobs will be requeued. Default // is 30 seconds. StaleTimeout time . Duration } Pool : poolConfig { NumWorkers : runtime . GOMAXPROCS ( 0 ) , BatchSize : runtime . GOMAXPROCS ( 0 ) , MinWait : 200 * time . Millisecond , StaleTimeout : 30 * time . Second , } ,", "commit_type": "make"}
{"commit_tokens": ["Add", "godoc", "example", "for", "fuzzy", "machers"], "add_tokens": "// To test it, you can chain redis responses. Let's write a test case // In the first iteration of the loop redigomock would return \"www.some.url.com\", then \"www.another.url.com\" and finally redis.ErrNil // // // Sometimes providing expected arguments to redigomock at compile time could be too constraining. Let's imagine you use redis hash sets to store some data, along with the // timestap of the last data update. Let's expand our Person struct : // type Person struct { // Name string `redis:\"name\"` // Age int `redis:\"age\"` // UpdatedAt uint64 `redis:updatedat` // Phone string `redis:phone` // } // // And add a function updating personal data (phone number for example. Please notice that the update timestamp can't be determined at compile time) // func UpdatePersonalData(conn redis.Conn, id string, person Person) error{ // _, err := conn.Do(\"HMSET\", fmt.Sprint(\"person:\", id), \"name\", person.Name, \"age\", person.Age, \"updatedat\" , time.Now.Unix(), \"phone\" , person.Phone) // return err // } // // func TestUpdatePersonalData(t *testing.T){ // redigomock.Clear() // // person := Person{ // Name :\"A name\", // Age : 18 // Phone : \"123456\" // } // // redigomock.Commmand(\"HMSET\", \"person:1\", \"name\", person.Name, \"age\", person.Age, \"updatedat\", redigomock.NewAnyInt(), \"phone\", person.Phone).Expect(\"OK!\") // err := UpdatePersonalData(redigomock.NewConn(), \"1\", person) // if err != nil { // t.Error(\"This shouldn't return any errors\") // } // As you can see at the position of current timestamp redigomock is told to match AnyInt struct created by NewAnyInt() method. AnyInt struct will match any integer // passed to redigomock from the tested method. Please see fuzzyMatch.go file for more details.", "del_tokens": "//To test it, you can chain redis responses. Let's write a test case //In the first iteration of the loop redigomock would return \"www.some.url.com\", then \"www.another.url.com\" and finally redis.ErrNil", "commit_type": "add"}
{"commit_tokens": ["Add", "Linkedin", "to", "the", "providers", "not", "supporting", "Auth", "headers", "."], "add_tokens": "strings . HasPrefix ( tokenURL , \" \" ) || strings . HasPrefix ( tokenURL , \" \" ) {", "del_tokens": "strings . HasPrefix ( tokenURL , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "race", "condition", "in", "wg"], "add_tokens": "defer l . wg . Wait ( ) l . wg . Add ( 1 ) wg . Add ( 1 ) wg . Add ( 1 )", "del_tokens": "wg . Add ( 1 ) wg . Add ( 1 ) wg . Add ( 1 ) l . wg . Wait ( )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "error", "message", "when", "we", "can", "t", "fetch", "assets"], "add_tokens": "if resp . StatusCode != http . StatusOK { return nil , errors . New ( \" \" + url ) } return s . parseAssets ( resp . Body )", "del_tokens": "manifest , err := s . parseAssets ( resp . Body ) return manifest , err", "commit_type": "improve"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "kataras", "/", "iris", "/", "issues", "/", "244", "and", "some", "more", "things"], "add_tokens": "ctx . RequestCtx . Request . Header . DelCookie ( name ) ctx . RequestCtx . Response . Header . DelClientCookie ( name )", "del_tokens": "cookie := fasthttp . AcquireCookie ( ) cookie . SetKey ( name ) cookie . SetValue ( \" \" ) cookie . SetPath ( \" \" ) cookie . SetHTTPOnly ( true ) exp := time . Now ( ) . Add ( - time . Duration ( 1 ) * time . Minute ) //RFC says 1 second, but make sure 1 minute because we are using fasthttp cookie . SetExpire ( exp ) ctx . Response . Header . SetCookie ( cookie ) fasthttp . ReleaseCookie ( cookie )", "commit_type": "fix"}
{"commit_tokens": ["adding", "EventsLogOptions", ".", "IgnoreUnmarshalErrors", "(", "see", "comment", "in", "code", ")"], "add_tokens": "// IgnoreUnmarshalErrors will cause GetEvents to ignore any errors // that come up when calling json.Unmarshal. This can be useful in // cases where the events-log plugin was not kept up to date with // the Gerrit version for some reason. In these cases the events-log // plugin will return data structs that don't match the EventInfo // struct which in turn causes issues for json.Unmarshal. IgnoreUnmarshalErrors bool if err != nil && ! options . IgnoreUnmarshalErrors {", "del_tokens": "if err != nil {", "commit_type": "add"}
{"commit_tokens": ["fix", "race", "in", "dockerclient", "test", "fix", "logs"], "add_tokens": "errorChan := make ( chan error , 1 )", "del_tokens": "errorChan := make ( chan error )", "commit_type": "fix"}
{"commit_tokens": ["fix", "comment", "wording", "to", "be", "clearer"], "add_tokens": "// if part of a utf8 continuation (>=0x80), then write out and continue", "del_tokens": "// if part of a unicode surrogate pair, write out and continue", "commit_type": "fix"}
{"commit_tokens": ["Fix", "erasing", "when", "multiple", "lines"], "add_tokens": "r . out . CursorBackward ( int ( r . col ) + len ( buffer . Text ( ) ) + len ( r . prefix ) )", "del_tokens": "r . out . CursorBackward ( int ( r . col ) )", "commit_type": "fix"}
{"commit_tokens": ["added", "cookie", "extractor", "to", "multi", "extractor", "test"], "add_tokens": "cookieTokenRequest , _ := http . NewRequest ( \" \" , \" \" , nil ) cookieTokenRequest . AddCookie ( & http . Cookie { Name : \" \" , Value : referenceToken } ) token , err := FromCookie ( cookieTokenRequest ) extractor := FromMultiple ( RequestTokenExtractorFunc ( FromHeader ) , RequestTokenExtractorFunc ( FromParams ) , RequestTokenExtractorFunc ( FromCookie ) ) cookieTokenRequest , _ := http . NewRequest ( \" \" , \" \" , nil ) cookieTokenRequest . AddCookie ( & http . Cookie { Name : \" \" , Value : referenceToken } ) for _ , r := range [ ] * http . Request { headerTokenRequest , paramTokenRequest , brokenParamTokenRequest , cookieTokenRequest } {", "del_tokens": "r , _ := http . NewRequest ( \" \" , \" \" , nil ) r . AddCookie ( & http . Cookie { Name : \" \" , Value : referenceToken } ) token , err := FromCookie ( r ) extractor := FromMultiple ( RequestTokenExtractorFunc ( FromHeader ) , RequestTokenExtractorFunc ( FromParams ) ) for _ , r := range [ ] * http . Request { headerTokenRequest , paramTokenRequest , brokenParamTokenRequest } {", "commit_type": "add"}
{"commit_tokens": ["fix", "kd", "tool", "upload", "script"], "add_tokens": "const VERSION = \" \"", "del_tokens": "const VERSION = \" \"", "commit_type": "fix"}
{"commit_tokens": ["Removed", "js", "struct", "field", "tag", ".", "Use", "native", "JS", "functions", "and", "wrappers", "instead", "."], "add_tokens": "func ( c * PkgContext ) translateArgs ( call * ast . CallExpr ) [ ] string {", "del_tokens": "func ( c * PkgContext ) translateArgs ( call * ast . CallExpr , isJavaScriptFunction bool ) [ ] string { if isJavaScriptFunction { if _ , isSlice := argType . Underlying ( ) . ( * types . Slice ) ; isSlice { args [ i ] = fmt . Sprintf ( \" \" , args [ i ] ) } }", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "some", "build", "errors", "."], "add_tokens": "ciph , err := aes . NewCipher ( key ) h := & cmacHash { ciph : ciph } h . k1 , h . k2 = generateSubkeys ( ciph )", "del_tokens": "c , err := aes . NewCipher ( key ) h := & cmacHash { ciph : c } h . k1 , h . k2 = generateSubkey ( key )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "panics", "due", "to", "out", "-", "of", "-", "bounds", "slice", "index", "access", "."], "add_tokens": "h := \" \" if i < len ( t . headers ) { h = t . headers [ i ] }", "del_tokens": "h := t . headers [ i ]", "commit_type": "fix"}
{"commit_tokens": ["add", "stat", "name", "validation", "as", "an", "example"], "add_tokens": "StatType string `long:\"type\" default:\"count\" description:\"stat type to send. Can be one of: timing, count, guage\"` Nil bool `long:\"nil\" description:\"Use nil client\"` Buffered bool `long:\"buffered\" description:\"Use a buffered client\"` Duration time . Duration `short:\"d\" long:\"duration\" default:\"10s\" description:\"How long to spread the volume across. For each second of duration, volume/seconds events will be sent.\"` fmt . Printf ( \" \" ) os . Exit ( 1 ) } if opts . Name == \" \" || statsd . CheckName ( opts . Name ) != nil { fmt . Printf ( \" \" ) os . Exit ( 1 ) } if statsd . CheckName ( opts . Prefix ) != nil { fmt . Printf ( \" \" ) count ++", "del_tokens": "StatType string `long:\"type\" default:\"count\" description:\"stat type to send. Can be timing, count, guage\"` Nil bool `long:\"nil\" default:\"false\" description:\"Use nil client\"` Buffered bool `long:\"buffered\" default:\"false\" description:\"Use a buffered client\"` Duration time . Duration `short:\"d\" long:\"duration\" default:\"10s\" description:\"How long to spread the volume across. Each second of duration volume/seconds events will be sent.\"` fmt . Printf ( \" \" ) count += 1", "commit_type": "add"}
{"commit_tokens": ["add", "a", "failing", "test", "for", "[]"], "add_tokens": "// \"[]\" fails because json.Marshal(empty list) returns null rather than [] examples := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , `{\"a\":\"IPFS\"}` , `{\"a\":\"IPFS\",\"b\":null,\"c\":[1]}` }", "del_tokens": "examples := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , `{\"a\":\"IPFS\"}` , `{\"a\":\"IPFS\",\"b\":null,\"c\":[1]}` }", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "of", "IPv6", "RemoteAddr"], "add_tokens": "\" \" var ( hostPortRegex = regexp . MustCompile ( `\\[?(.+?)\\]?:\\d+$` ) ) hp := hostPortRegex . FindStringSubmatch ( ra ) if hp != nil { ra = string ( hp [ 1 ] )", "del_tokens": "colonIndex := strings . LastIndex ( ra , \" \" ) if colonIndex > 0 && ra [ colonIndex - 1 ] >= 0x30 && ra [ colonIndex - 1 ] <= 0x39 { ra = ra [ : colonIndex ] } if ra [ 0 ] == '[' && ra [ len ( ra ) - 1 ] == ']' { // IPv6 ra = ra [ 1 : len ( ra ) - 1 ]", "commit_type": "fix"}
{"commit_tokens": ["Updating", "fast", "aggregation", "functions", "to", "answer", "https", ":", "//", "github", ".", "com", "/", "RoaringBitmap", "/", "roaring", "/", "issues", "/", "51"], "add_tokens": "return a . lazyOR ( ac ) } panic ( \" \" ) } func ( ac * arrayContainer ) lazyOR ( a container ) container { switch a . ( type ) { case * arrayContainer : return ac . orArray ( a . ( * arrayContainer ) ) case * bitmapContainer : return a . lazyOR ( ac )", "del_tokens": "return a . lazyIOR ( ac )", "commit_type": "update"}
{"commit_tokens": ["Made", "setBg", "/", "setFg", "public", "functions"], "add_tokens": "// SetFg sets foreground color func ( i * IrcText ) SetFg ( c int ) * IrcText { // SetBg sets background color func ( i * IrcText ) SetBg ( c int ) * IrcText {", "del_tokens": "func ( i * IrcText ) setFg ( c int ) * IrcText { func ( i * IrcText ) setBg ( c int ) * IrcText {", "commit_type": "make"}
{"commit_tokens": ["Add", "tests", "for", "company", "(", "via", "changes", ")"], "add_tokens": "\" \" : { \" \" : { /* COMPANY */ /* COMPANY_DEVELOPER */ \" \" : {", "del_tokens": "\" \" : { \" \" : { \" \" : {", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "calculation", "of", "file", "rotation"], "add_tokens": "if t . currentBytes + bytes <= t . MaxBytes || bytes > t . MaxBytes {", "del_tokens": "t . currentBytes += bytes if t . currentBytes <= t . MaxBytes || bytes > t . MaxBytes {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "errors", "in", "event", "store", "Append", "()"], "add_tokens": "if len ( resultEvents ) > 0 { // Store events err := d . eventStore . Append ( resultEvents ) if err != nil { return err } // Publish events for _ , event := range resultEvents { d . eventBus . PublishEvent ( event ) } if len ( resultEvents ) > 0 { // Store events err := d . eventStore . Append ( resultEvents ) if err != nil { return err } // Publish events for _ , event := range resultEvents { d . eventBus . PublishEvent ( event ) }", "del_tokens": "// Store events d . eventStore . Append ( resultEvents ) // Publish events for _ , event := range resultEvents { d . eventBus . PublishEvent ( event ) // Store events d . eventStore . Append ( resultEvents ) // Publish events for _ , event := range resultEvents { d . eventBus . PublishEvent ( event )", "commit_type": "add"}
{"commit_tokens": ["add", "special", "cases", "for", "Rat", "method"], "add_tokens": "return new ( big . Int ) if x . form != finite { return new ( big . Rat ) }", "del_tokens": "return big . NewInt ( 0 )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "object", "storage", "classes"], "add_tokens": "Bucket : & fs . bucket , Key : fh . inode . FullName , StorageClass : & fs . flags . StorageClass , Bucket : & fs . bucket , CopySource : & src , Key : toFullName , StorageClass : & fs . flags . StorageClass ,", "del_tokens": "Bucket : & fs . bucket , Key : fh . inode . FullName , Bucket : & fs . bucket , CopySource : & src , Key : toFullName ,", "commit_type": "add"}
{"commit_tokens": ["Add", "/", "_health", "to", "API"], "add_tokens": "\" \" func health ( w http . ResponseWriter , r * http . Request ) { w . WriteHeader ( http . OK ) } http . HandleFunc ( \" \" , health )", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["added", "example", "keepass", "file", ";", "fixed", "salsa", ";", "fixed", "content", "def", "to", "account", "for", "history"], "add_tokens": "XMLName xml . Name `xml:\"KeePassFile\"` Meta * MetaData `xml:\"Meta\"` Root * RootData `xml:\"Root\"` Histories [ ] History `xml:\"History` Password [ ] byte func ( e * Entry ) getProtectedPassword ( ) string { func ( e * Entry ) getTitle ( ) string { var val string for _ , v := range e . Values { if v . Key == \" \" { val = v . Value } } return val } type History struct { Entries [ ] Entry `xml:\"Entry\"` }", "del_tokens": "XMLName xml . Name `xml:\"KeePassFile\"` Meta MetaData `xml:\"Meta\"` Root RootData `xml:\"Root\"` func ( e * Entry ) getPassword ( ) string {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "true", "and", "false", "values"], "add_tokens": "var ok bool if value , ok = p . ReadBoolean ( ) ; ok == false { value , err = p . ReadDynamic ( negate ) } func ( p * Parser ) ReadBoolean ( ) ( Value , bool ) { if p . ConsumeIf ( [ ] byte ( \" \" ) ) { return trueValue , true } if p . ConsumeIf ( [ ] byte ( \" \" ) ) { return falseValue , true } return nil , false } func ( p * Parser ) ConsumeIf ( bytes [ ] byte ) bool { length := len ( bytes ) position := p . position left := p . len - position if left < length { return false } for index , b := range bytes { if p . data [ position + index ] != b { return false } } p . position += length return true }", "del_tokens": "value , err = p . ReadDynamic ( negate )", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "example", "for", "the", "Tweetin"], "add_tokens": "Code int // It's a user! // It's a Tweet! (Adorably referred to by the API as a \"status\"). type Tweet map [ string ] interface { } func ( t Tweet ) Id ( ) uint64 { id , _ := strconv . ParseUint ( t [ \" \" ] . ( string ) , 10 , 64 ) return id } func ( t Tweet ) IdStr ( ) string { return t [ \" \" ] . ( string ) } func ( t Tweet ) Text ( ) string { return t [ \" \" ] . ( string ) } func ( t Tweet ) User ( ) User { return User ( t [ \" \" ] . ( map [ string ] interface { } ) ) }", "del_tokens": "Code int", "commit_type": "add"}
{"commit_tokens": ["Fix", "websocket", "connection", "to", "newer", "server", "releases", "."], "add_tokens": "wsc , err := newWSConn ( config . Server + \" \" , config . Tel , registrationInfo . password , config . SkipTLSCheck )", "del_tokens": "wsc , err := newWSConn ( config . Server + \" \" , config . Tel , registrationInfo . password , config . SkipTLSCheck )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "provision", "build", "options", "on", "tests"], "add_tokens": "name , _ := FnImageBuild ( client , & BuildOptions { \" \" , \" \" , \" \" , \" \" , nil } ) name , _ := FnImageBuild ( client , & BuildOptions { \" \" , \" \" , \" \" , \" \" , nil } ) FnImageBuild ( client , & BuildOptions { \" \" , \" \" , \" \" , \" \" , nil } )", "del_tokens": "name , _ := FnImageBuild ( client , & BuildOptions { \" \" , \" \" , \" \" , \" \" } ) name , _ := FnImageBuild ( client , & BuildOptions { \" \" , \" \" , \" \" , \" \" } ) FnImageBuild ( client , & BuildOptions { \" \" , \" \" , \" \" , \" \" } )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "Restart", "and", "IsSupported", "global", "methods"], "add_tokens": "var currentProcess interface { triggerRestart ( ) run ( ) error } currentProcess = & slave { Config : c } currentProcess = & master { Config : c } return currentProcess . run ( ) } //Restart programmatically triggers a graceful restart. If NoRestart //is enabled, then this will essentially be a graceful shutdown. func Restart ( ) { if currentProcess != nil { currentProcess . triggerRestart ( ) } } //IsSupported returns whether overseer is supported on the current OS. func IsSupported ( ) bool { return supported", "del_tokens": "sp := slave { Config : c } return sp . run ( ) mp := master { Config : c } return mp . run ( )", "commit_type": "implement"}
{"commit_tokens": ["Add", "support", "for", "NEEDS_BOOTSTRAP", "and", "invalid", "state"], "add_tokens": "CLUSTERED = \" \" NEEDS_BOOTSTRAP = \" \" SINGLE_NODE = \" \" // If there is no state file, we must be a new deploy. if ! m . osHelper . FileExists ( m . stateFileLocation ) { // In this case node 0 will bootstrap if m . jobIndex == 0 { } else { // Other nodes join existing cluster err = m . joinCluster ( ) return } else { switch state { case SINGLE_NODE : // Upgrading from a single-node cluster means we have to re-bootstrap case CLUSTERED : err = m . joinCluster ( ) return case NEEDS_BOOTSTRAP : err = m . bootstrapCluster ( CLUSTERED ) return default : err = fmt . Errorf ( \" \" , state ) return", "del_tokens": "CLUSTERED = \" \" SINGLE_NODE = \" \" // If the state file reads 'NEEDS-BOOTSTRAP' then bootstrap, irrespective of // node index etc // // node 0 has special behavior if m . jobIndex == 0 { // Initial deploy, state file does not exist if ! m . osHelper . FileExists ( m . stateFileLocation ) { // state file exists, previous state was single-node if state == SINGLE_NODE { err = m . joinCluster ( ) return", "commit_type": "add"}
{"commit_tokens": ["added", "more", "tests", "for", "the", "twitter", "provider"], "add_tokens": "var ( RequestURL string = \" \" AuthURL string = \" \" TokenURL string = \" \" EndpointProfile string = \" \" EndpointProfile , RequestTokenUrl : RequestURL , AuthorizeTokenUrl : AuthURL , AccessTokenUrl : TokenURL ,", "del_tokens": "const ( requestURL string = \" \" authURL string = \" \" tokenURL string = \" \" endpointProfile string = \" \" endpointProfile , RequestTokenUrl : requestURL , AuthorizeTokenUrl : authURL , AccessTokenUrl : tokenURL ,", "commit_type": "add"}
{"commit_tokens": ["Move", "Config", "parsing", "into", "its", "own", "function"], "add_tokens": "// parseConfigFileOrDie reads and parses configuration from Supfile in CWD. func parseConfigFileOrDie ( file string ) * stackup . Config { var conf stackup . Config data , err := ioutil . ReadFile ( file ) return & conf } func main ( ) { // Parse configuration. // TODO: -f flag. conf := parseConfigFileOrDie ( \" \" ) network , commands := parseArgsOrDie ( conf ) var paddingLen int local := & stackup . LocalhostClient { if err := local . Connect ( host ) ; err != nil { c = local remote := & stackup . SSHClient { if err := remote . Connect ( host ) ; err != nil { defer remote . Close ( ) c = remote", "del_tokens": "func main ( ) { var ( conf stackup . Config paddingLen int ) // Read configuration file. data , err := ioutil . ReadFile ( \" \" ) network , commands := parseArgsOrDie ( & conf ) localhostClient := & stackup . LocalhostClient { if err := localhostClient . Connect ( host ) ; err != nil { c = localhostClient sshClient := & stackup . SSHClient { if err := sshClient . Connect ( host ) ; err != nil { defer sshClient . Close ( ) c = sshClient", "commit_type": "move"}
{"commit_tokens": ["Add", "delete", "command", "and", "tests", "."], "add_tokens": "Short : \" \" , Long : `Stops a local kubernetes cluster running in Virtualbox. This command stops the VM itself , leaving all files intact . The cluster can be started again with the \" \" command . `, fmt . Println ( \" \" , err )", "del_tokens": "Short : \" \" , Long : `A longer description that spans multiple lines and likely contains examples and usage of using your command . For example : Cobra is a CLI library for Go that empowers applications . This application is a tool to generate the needed files to quickly create a Cobra application . `, fmt . Println ( \" \" , err ) // Here you will define your flags and configuration settings. // Cobra supports Persistent Flags which will work for this command // and all subcommands, e.g.: // stopCmd.PersistentFlags().String(\"foo\", \"\", \"A help for foo\") // Cobra supports local flags which will only run when this command // is called directly, e.g.: // stopCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "stuff", "from", "scope", ".", "go", "."], "add_tokens": "file . filescope . parent = self . pkg", "del_tokens": "self . pkg . addChild ( file . filescope ) self . uni . children = nil", "commit_type": "remove"}
{"commit_tokens": ["Use", "flag", ".", "Duration", "for", "scrape", "duration", "."], "add_tokens": "haProxyScrapeInterval = flag . Duration ( \" \" , 15 , \" \" ) time . Sleep ( * haProxyScrapeInterval * time . Second )", "del_tokens": "haProxyScrapeInterval = flag . Int ( \" \" , 15 , \" \" ) time . Sleep ( time . Duration ( * haProxyScrapeInterval ) * time . Second )", "commit_type": "use"}
{"commit_tokens": ["Fix", "decay", "behaviour", "on", "overflow"], "add_tokens": "t := b . duration ( b . n ) if b . n < math . MaxUint64 { func ( b * Backoff ) duration ( n uint64 ) ( t time . Duration ) { lastDuration := b . duration ( b . n - 1 )", "del_tokens": "t , overflow := b . duration ( b . n ) if ! overflow { func ( b * Backoff ) duration ( n uint64 ) ( t time . Duration , overflow bool ) { overflow = true lastDuration , _ := b . duration ( b . n - 1 )", "commit_type": "fix"}
{"commit_tokens": ["Use", "gomemcached", "s", "constants", "."], "add_tokens": "\" \" case gomemcached . MCResponse : st := err . ( gomemcached . MCResponse ) . Status if st == gomemcached . NOT_MY_VBUCKET { if res . Status != gomemcached . SUCCESS { if res . Status != gomemcached . SUCCESS { if res . Status != gomemcached . SUCCESS {", "del_tokens": "case mcResponse : st := err . ( mcResponse ) . Status if st == mcNOT_MY_VBUCKET { if res . Status != mcSUCCESS { if res . Status != mcSUCCESS { if res . Status != mcSUCCESS {", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "official", "glfw3", "repo"], "add_tokens": "glfw \" \"", "del_tokens": "glfw \" \"", "commit_type": "use"}
{"commit_tokens": ["fix", "issue", "on", "32bit", "platform"], "add_tokens": "hash := int64 ( 0x811c9dc5 ) hash := int64 ( 0x811c9dc5 )", "del_tokens": "hash := 0x811c9dc5 hash := 0x811c9dc5", "commit_type": "fix"}
{"commit_tokens": ["remove", "log", ".", "Fatal", "and", "command", "input", "zk", "info"], "add_tokens": "c . Assert ( err , Equals , nil ) err = createNewTableAndDropOldTable ( cli , themisTestTableName , cfName ) c . Assert ( err , Equals , nil )", "del_tokens": "if err != nil { return } createNewTableAndDropOldTable ( cli , themisTestTableName , cfName )", "commit_type": "remove"}
{"commit_tokens": ["use", "bridge", "RPC", "for", "running", "mac", "driver"], "add_tokens": "macRPC bridge . RPC d . macRPC . Handler = macCall errC <- d . macRPC . Call ( \" \" , nil , nil ) case f := <- d . uichan : f ( ) case err := <- errC : return err", "del_tokens": "\" \" cancel func ( ) var ctx context . Context ctx , d . cancel = context . WithCancel ( context . Background ( ) ) defer d . cancel ( ) _ , err := d . macos . Request ( \" \" , nil ) errC <- err case function := <- d . uichan : function ( ) case <- ctx . Done ( ) : return <- errC d . cancel ( )", "commit_type": "use"}
{"commit_tokens": ["Remove", "spurious", "newline", "in", "HTML", "output", "."], "add_tokens": "fmt . Fprintf ( w , \" \" , f . styleAttr ( css , chroma . Background ) )", "del_tokens": "fmt . Fprintf ( w , \" \\n \" , f . styleAttr ( css , chroma . Background ) )", "commit_type": "remove"}
{"commit_tokens": ["Changing", "approach", "to", "truncation", "."], "add_tokens": "lf . Truncate ( filesize )", "del_tokens": "current , _ := out_file . Seek ( 1 , 0 ) out_file . Truncate ( current ) lf . Truncate ( current )", "commit_type": "change"}
{"commit_tokens": ["Add", "Scale", "to", "Metrics", "struct"], "add_tokens": "Name string `json:\"name\"` Label string `json:\"label\"` Diff bool `json:\"diff\"` Stacked bool `json:\"stacked\"` Scale float64 `json:\"scale\"` value *= metric . Scale", "del_tokens": "Name string `json:\"name\"` Label string `json:\"label\"` Diff bool `json:\"diff\"` Stacked bool `json:\"stacked\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "Do", "()", "call", "and", "error", "check"], "add_tokens": "_ , err := sh . errorService . Projects . Events . Report ( sh . projectID , & errorEvent ) . Do ( ) if err != nil { log . Println ( \" \" , err ) } _ , err := sh . service . Write ( & logging . WriteLogEntriesRequest { if err != nil { log . Println ( \" \" , err ) }", "del_tokens": "sh . errorService . Projects . Events . Report ( sh . projectID , & errorEvent ) _ , _ = sh . service . Write ( & logging . WriteLogEntriesRequest {", "commit_type": "add"}
{"commit_tokens": ["Updated", "function", "names", "for", "clarity"], "add_tokens": "func getVerbFlagForMethod ( method string ) verbFlag { switch method { panic ( \" \" + method ) type middlewareForVerb struct { middleware [ ] * middlewareForVerb middleware : make ( [ ] * middlewareForVerb , 0 ) , verb := getVerbFlagForMethod ( method ) r . middleware = append ( r . middleware , & middlewareForVerb { f = f | getVerbFlagForMethod ( verb ) r . middleware = append ( r . middleware , & middlewareForVerb { f = f | getVerbFlagForMethod ( verb ) r . middleware = append ( r . middleware , & middlewareForVerb {", "del_tokens": "func getVerbFlag ( verb string ) verbFlag { switch verb { panic ( \" \" + verb ) type middlewareVerb struct { middleware [ ] * middlewareVerb middleware : make ( [ ] * middlewareVerb , 0 ) , verb := getVerbFlag ( method ) r . middleware = append ( r . middleware , & middlewareVerb { f = f | getVerbFlag ( verb ) r . middleware = append ( r . middleware , & middlewareVerb { f = f | getVerbFlag ( verb ) r . middleware = append ( r . middleware , & middlewareVerb {", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "latest", "protocol", "definitions"], "add_tokens": "Location cdptype . DebuggerLocation `json:\"location\"` // Location to continue to. TargetCallFrames * string `json:\"targetCallFrames,omitempty\"` // // SetTargetCallFrames sets the TargetCallFrames optional argument. func ( a * DebuggerContinueToLocationArgs ) SetTargetCallFrames ( targetCallFrames string ) * DebuggerContinueToLocationArgs { a . TargetCallFrames = & targetCallFrames return a } // InputSetIgnoreInputEventsArgs represents the arguments for SetIgnoreInputEvents in the Input domain. type InputSetIgnoreInputEventsArgs struct { Ignore bool `json:\"ignore\"` // Ignores input events processing when set to true. } // NewInputSetIgnoreInputEventsArgs initializes InputSetIgnoreInputEventsArgs with the required arguments. func NewInputSetIgnoreInputEventsArgs ( ignore bool ) * InputSetIgnoreInputEventsArgs { args := new ( InputSetIgnoreInputEventsArgs ) args . Ignore = ignore return args } URL string `json:\"url\"` // URL to navigate the page to. Referrer * string `json:\"referrer,omitempty\"` // Referrer URL. TransitionType cdptype . PageTransitionType `json:\"transitionType,omitempty\"` // Intended transition type. // SetTransitionType sets the TransitionType optional argument. Intended transition type. func ( a * PageNavigateArgs ) SetTransitionType ( transitionType cdptype . PageTransitionType ) * PageNavigateArgs { a . TransitionType = transitionType return a } FromSurface * bool `json:\"fromSurface,omitempty\"` // Capture the screenshot from the surface, rather than the view. Defaults to true. // SetFromSurface sets the FromSurface optional argument. Capture the screenshot from the surface, rather than the view. Defaults to true. CommandLine string `json:\"commandLine\"` // The command line string used to launch the browser. Will be the empty string if not supported.", "del_tokens": "Location cdptype . DebuggerLocation `json:\"location\"` // Location to continue to. URL string `json:\"url\"` // URL to navigate the page to. Referrer * string `json:\"referrer,omitempty\"` // Referrer URL. FromSurface * bool `json:\"fromSurface,omitempty\"` // Capture the screenshot from the surface, rather than the view. Defaults to false. // SetFromSurface sets the FromSurface optional argument. Capture the screenshot from the surface, rather than the view. Defaults to false.", "commit_type": "update"}
{"commit_tokens": ["Fix", "signature", "sorting", "of", "common", "prefix", "keys", "."], "add_tokens": "var keys [ ] string for k , _ := range r . Header { if strings . HasPrefix ( strings . ToLower ( k ) , \" \" ) { keys = append ( keys , k ) sort . Strings ( keys ) var a [ ] string for _ , k := range keys { v := r . Header [ k ] a = append ( a , strings . ToLower ( k ) + \" \" + strings . Join ( v , \" \" ) ) }", "del_tokens": "var a [ ] string for k , v := range r . Header { k = strings . ToLower ( k ) if strings . HasPrefix ( k , \" \" ) { a = append ( a , k + \" \" + strings . Join ( v , \" \" ) ) sort . Strings ( a )", "commit_type": "fix"}
{"commit_tokens": ["add", "convenience", "method", "to", "filter", "relations", "by", "type"], "add_tokens": "// Relation describes a relationship between different MusicBrainz entities. // See this link https://musicbrainz.org/relationships for a table of // relationships. TypeOf ( ) string func ( r * RelationAbstract ) TypeOf ( ) string { return r . Type } // RelationsOfType returns a slice of Relations for the given relType. For a // list of all possible relationships see https://musicbrainz.org/relationships func RelationsOfType ( rels [ ] Relation , relType string ) [ ] Relation { // NOTE i could think about mapping the relationship types with a double map // like map[string]map[string][]Relation. For that to work the Unmarshaler // inferface needs to be implemented for the slice of relations (as a seperate // type). var out [ ] Relation for _ , rel := range rels { if rel . TypeOf ( ) == relType { out = append ( out , rel ) } } return out } type URLRelation struct { RelationAbstract }", "del_tokens": "} type URLRelation struct { RelationAbstract", "commit_type": "add"}
{"commit_tokens": ["Move", "non", "-", "error", "output", "back", "to", "stdout"], "add_tokens": "fmt . Printf ( \" \\n \" , n , filePath ) fmt . Printf ( \" \\n \\n \\n \\n \" , pub , priv )", "del_tokens": "fmt . Fprint ( os . Stderr , \" \\n \" , n , filePath ) fmt . Fprintf ( os . Stderr , \" \\n \\n \\n \\n \" , pub , priv )", "commit_type": "move"}
{"commit_tokens": ["Add", "time", "types", "(", "represented", "as", "float64", ")"], "add_tokens": "ExpirationDate cdptype . NetworkTimestamp `json:\"expirationDate,omitempty\"` // If omitted, the cookie becomes a session cookie.", "del_tokens": "ExpirationDate * cdptype . NetworkTimestamp `json:\"expirationDate,omitempty\"` // If omitted, the cookie becomes a session cookie. // SetExpirationDate sets the ExpirationDate optional argument. If omitted, the cookie becomes a session cookie. func ( a * NetworkSetCookieArgs ) SetExpirationDate ( expirationDate cdptype . NetworkTimestamp ) * NetworkSetCookieArgs { a . ExpirationDate = & expirationDate return a }", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "--", "help"], "add_tokens": "helpFlagVal bool // If help is called, regardless of other flags, we print that if c . helpFlagVal { c . Help ( ) return nil } // If help is called, regardless of other flags, we print that if c . helpFlagVal { c . Help ( ) return nil } c . flags . BoolVar ( & c . helpFlagVal , \" \" , false , \" \" + c . Name ( ) )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "func", "to", "quit", "watcher"], "add_tokens": "logger . quitWatcher ( ) // clean up if logger . fd != nil { logger . fd . Close ( ) } } func ( logger * Logger ) quitWatcher ( ) { if sync == logger . sync { return logger . quitWatcher ( ) if logger . sync == false {", "del_tokens": "// clean up if logger . fd != nil { logger . fd . Close ( ) } if logger . sync == false { // quit watcher logger . quit <- true // wait for watcher quit <- logger . quit if sync == false {", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "no", "new", "variables", "on", "the", "left"], "add_tokens": "err = ioutil . WriteFile ( goldenFileName ( name ) , actualData , FilePerms )", "del_tokens": "err := ioutil . WriteFile ( goldenFileName ( name ) , actualData , FilePerms )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "DOM", "element", "JS", "execution"], "add_tokens": "param := make ( map [ string ] interface { } ) if v := self . BackendID ( ) ; v != 0 { param [ `backendNodeId` ] = self . BackendID ( ) } else if v := self . NodeID ( ) ; v != 0 { param [ `nodeId` ] = self . NodeID ( ) } else { return nil , fmt . Errorf ( \" \" ) } if rv , err := self . document . tab . RPC ( `DOM` , `resolveNode` , param ) ; err == nil {", "del_tokens": "if rv , err := self . document . tab . RPC ( `DOM` , `resolveNode` , map [ string ] interface { } { `backendNodeId` : self . BackendID ( ) , } ) ; err == nil {", "commit_type": "improve"}
{"commit_tokens": ["Added", "blockquote", "to", "list", "of", "standard", "accepted", "tags"], "add_tokens": "defaultTags = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "del_tokens": "defaultTags = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Remove", "triple", "newline", "in", "generated", "code"], "add_tokens": "code = funcRegexp . ReplaceAllString ( code , \" \\n \\n \" ) code = strings . Replace ( code , \" \\n \\n \\n \" , \" \\n \\n \" , - 1 ) return code", "del_tokens": "return funcRegexp . ReplaceAllString ( code , \" \\n \\n \" )", "commit_type": "remove"}
{"commit_tokens": ["Add", "flags", "to", "examples", "and", "package", "godoc"], "add_tokens": "\" \" \" \" \" \" \" \" flags := flag . NewFlagSet ( \" \" , flag . ExitOnError ) accessToken := flags . String ( \" \" , \" \" , \" \" ) flags . Parse ( os . Args [ 1 : ] ) flagutil . SetFlagsFromEnv ( flags , \" \" ) if * accessToken == \" \" { log . Fatal ( \" \" ) token := & oauth2 . Token { AccessToken : * accessToken } // Twitter client", "del_tokens": "\" \" // Main makes App Auth (OAuth2) requests as a consumer on behalf of itself. // read credentials from environment variables accessToken := os . Getenv ( \" \" ) if accessToken == \" \" { panic ( \" \" ) token := & oauth2 . Token { AccessToken : accessToken } // twitter client", "commit_type": "add"}
{"commit_tokens": ["fix", "Shader", ".", "SetUniform", "*", "methods"], "add_tokens": "Float : 4 , Vec2 : 2 * 4 , Vec3 : 3 * 4 , Vec4 : 4 * 4 , Mat2 : 2 * 2 * 4 , Mat23 : 2 * 3 * 4 , Mat24 : 2 * 4 * 4 , Mat3 : 3 * 3 * 4 , Mat32 : 3 * 2 * 4 , Mat34 : 3 * 4 * 4 , Mat4 : 4 * 4 * 4 , Mat42 : 4 * 2 * 4 , Mat43 : 4 * 3 * 4 ,", "del_tokens": "Float : 8 , Vec2 : 2 * 8 , Vec3 : 3 * 8 , Vec4 : 4 * 8 , Mat2 : 2 * 2 * 8 , Mat23 : 2 * 3 * 8 , Mat24 : 2 * 4 * 8 , Mat3 : 3 * 3 * 8 , Mat32 : 3 * 2 * 8 , Mat34 : 3 * 4 * 8 , Mat4 : 4 * 4 * 8 , Mat42 : 4 * 2 * 8 , Mat43 : 4 * 3 * 8 ,", "commit_type": "fix"}
{"commit_tokens": ["remove", "the", "package", "that", "has", "not", "been", "used"], "add_tokens": "", "del_tokens": "\" \" \" \"", "commit_type": "remove"}
{"commit_tokens": ["Add", "apps", "on", "release", "struct"], "add_tokens": "Apps [ ] App `yaml:\"apps\"` Apps : ir . Apps ,", "del_tokens": "const indexReleaseTimestampFormat = \" \"", "commit_type": "add"}
{"commit_tokens": ["added", "N", "to", "stats", "computation"], "add_tokens": "Ω( s tats. N ( ) ) . S hould( E qual( u int64( 1 000000) ) ) Ω( s tats. N ( ) ) . S hould( E qual( u int64( 1 000000) ) )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "stats", "package", "use", "log"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "make"}
{"commit_tokens": ["removed", "SliceErrors", "and", "updated", "readme"], "add_tokens": "\" \" // in terms of Errors. errs := Errors { } errs [ strconv . Itoa ( i ) ] = err", "del_tokens": "// in terms of SliceErrors (for slices and arrays) or Errors (for maps). errs := SliceErrors { } errs [ i ] = err", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "build", "in", "Makefile"], "add_tokens": "import \" \"", "del_tokens": "import \" \"", "commit_type": "fix"}
{"commit_tokens": ["Improves", "client", "test", "-", "ability", "."], "add_tokens": "// GenerateRandomString generates a random string of desired length (default: 25) func GenerateRandomString ( params ... int ) string { if len ( params ) == 1 { size = params [ 0 ] }", "del_tokens": "// GenerateRandomString generates a random string of len 25 func GenerateRandomString ( ) string {", "commit_type": "improve"}
{"commit_tokens": ["Allow", "dashes", "in", "migration", "names"], "add_tokens": "upMigrationFile = regexp . MustCompile ( `(\\d+)_([\\w-]+)_up\\.sql` ) downMigrationFile = regexp . MustCompile ( `(\\d+)_([\\w-]+)_down\\.sql` )", "del_tokens": "upMigrationFile = regexp . MustCompile ( `(\\d+)_(\\w+)_up\\.sql` ) downMigrationFile = regexp . MustCompile ( `(\\d+)_(\\w+)_down\\.sql` )", "commit_type": "allow"}
{"commit_tokens": ["Implemented", "all", "of", "the", "timeline", "endpoints"], "add_tokens": "tweets , err := client . GetPublicTimeline ( nil ) tweets , err = client . GetRetweetedByMe ( & twittergo . Parameters { Count : 1 } ) if err != nil { fmt . Println ( \" \" , err ) } PrintTweets ( tweets ) fmt . Println ( \" \\n \" ) fmt . Println ( \" \" ) tweets , err = client . GetRetweetedByUser ( & twittergo . Parameters { Id : \" \" , Count : 1 , } )", "del_tokens": "tweets , err := client . GetPublicTimeline ( ) tweets , err = client . GetRetweetedByMe ( )", "commit_type": "implement"}
{"commit_tokens": ["Add", "proportional", "resident", "&", "swap", "memory", "size"], "add_tokens": "smaps = flag . Bool ( \" \" , false , \" \" ) pc , err := NewProcessCollector ( * procfsPath , * children , * threads , * smaps , matchnamer , * recheck , * debug ) smaps bool smaps bool , fs . GatherSMaps = smaps smaps : smaps , if p . smaps { ch <- prometheus . MustNewConstMetric ( membytesDesc , prometheus . GaugeValue , float64 ( gcounts . Memory . ProportionalBytes ) , gname , \" \" ) ch <- prometheus . MustNewConstMetric ( membytesDesc , prometheus . GaugeValue , float64 ( gcounts . Memory . ProportionalSwapBytes ) , gname , \" \" ) }", "del_tokens": "pc , err := NewProcessCollector ( * procfsPath , * children , * threads , matchnamer , * recheck , * debug )", "commit_type": "add"}
{"commit_tokens": ["add", "doc", "and", "extra", "error", "checking"], "add_tokens": "// GetImage downloads a Media object and returns an image.Image. The // documentation isn't great on what happens - as of October 2016, we make a // request to the Twilio API, then to media.twiliocdn.com, then to a S3 URL. We // then download that image and decode it based on the provided content-type. if u . Scheme == \" \" { return nil , fmt . Errorf ( \" \" , u . String ( ) ) }", "del_tokens": "// GetImage downloads a Media object and returns an image.Image.", "commit_type": "add"}
{"commit_tokens": ["allow", "the", "use", "of", "a", "config", "file", "instead", "of", "manually", "pasting", "configs"], "add_tokens": "msgs \" \" var vt , acct , appsc = msgs . GetTokens ( ) verifyToken = flag . String ( \" \" , vt , \" \" ) pageToken = flag . String ( \" \" , acct , \" \" ) appSecret = flag . String ( \" \" , appsc , \" \" ) port = flag . Int ( \" \" , 5000 , \" \" )", "del_tokens": "verifyToken = flag . String ( \" \" , \" \" , \" \" ) pageToken = flag . String ( \" \" , \" \" , \" \" ) appSecret = flag . String ( \" \" , \" \" , \" \" ) port = flag . Int ( \" \" , 8080 , \" \" )", "commit_type": "allow"}
{"commit_tokens": ["implements", "text", "rotation", "for", "extra", "readibility"], "add_tokens": "X , Y , R int", "del_tokens": "X , Y int", "commit_type": "implement"}
{"commit_tokens": ["change", "bitcount", "position", "argument", "type", "to", "int"], "add_tokens": "func ( r * Redis ) BitCount ( key string , start , end int ) ( int64 , error ) {", "del_tokens": "func ( r * Redis ) BitCount ( key , start , end string ) ( int64 , error ) {", "commit_type": "change"}
{"commit_tokens": ["Use", "extracted", "go", "-", "libp2p", "-", "crypto", "-", "secio", "-", "peer", "packages"], "add_tokens": "peer \" \"", "del_tokens": "peer \" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "panic", "for", "index", "not", "number"], "add_tokens": "// Get the key into the map // Get the index into the array at the key index , err := strconv . Atoi ( arrayMatches [ 2 ] ) if err != nil { // This should never happen. If it does, something has gone // seriously wrong. Panic. panic ( \" \" ) } // representation of an unsigned integer using a type switch and // assertions", "del_tokens": "// Ignore the error here since the regex would only match on 0-9 index , _ := strconv . Atoi ( arrayMatches [ 2 ] ) // representation of an unsigned integer", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "transform", "()", "and", "fix", "found", "bugs"], "add_tokens": "v = reflect . Indirect ( reflect . ValueOf ( in . agentMetricsSnapshot ) ) v = reflect . Indirect ( reflect . ValueOf ( c . Statistics ) )", "del_tokens": "v = reflect . ValueOf ( in . agentMetricsSnapshot ) v = reflect . ValueOf ( c . Statistics )", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "issuying", "cert", "with", "alternative", "names", "and", "option", "to", "allow", "-", "bare", "-", "domains"], "add_tokens": "AllowBareDomains string setupCmd . Flags ( ) . StringVar ( & newSetupFlags . AllowBareDomains , \" \" , \" \" , \" \" ) AllowedDomains : newSetupFlags . AllowedDomains , ClusterID : newSetupFlags . ClusterID , CommonName : newSetupFlags . CommonName , TTL : newSetupFlags . CATTL , AllowBareDomains : newSetupFlags . AllowBareDomains ,", "del_tokens": "AllowedDomains : newSetupFlags . AllowedDomains , ClusterID : newSetupFlags . ClusterID , CommonName : newSetupFlags . CommonName , TTL : newSetupFlags . CATTL ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "two", "-", "character", "escapes", "like", "\\", "n", "not", "escaping", "right"], "add_tokens": "// backslashCharEscapeTable: when '\\X' is found for some byte X, it is to be replaced with backslashCharEscapeTable[X] var backslashCharEscapeTable = [ ... ] byte { '\"' : '\"' , '\\\\' : '\\\\' , '/' : '/' , 'b' : '\\b' , 'f' : '\\f' , 'n' : '\\n' , 'r' : '\\r' , 't' : '\\t' , } case '\"' , '\\\\' , '/' , 'b' , 'f' , 'n' , 'r' , 't' : // Valid basic 2-character escapes (use lookup table) out [ 0 ] = backslashCharEscapeTable [ e ]", "del_tokens": "case '\"' , '\\\\' , 'n' , 't' , 'r' , '/' , 'b' , 'f' : // Valid basic 2-character escapes out [ 0 ] = e", "commit_type": "fix"}
{"commit_tokens": ["Fix", "missed", "path", "-", ">", "filepath", "renaming"], "add_tokens": "ext := filepath . Ext ( cf )", "del_tokens": "ext := path . Ext ( cf )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "few", "more", "commands", "that", "might", "end", "up", "being", "useful"], "add_tokens": "// Kick() sends a KICK command to remove a nick from a channel func ( conn * Conn ) Kick ( channel , nick string , message ... ) { msg := getStringMsg ( message ) if msg != \" \" { msg = \" \" + msg } conn . out <- \" \" + channel + \" \" + nick + msg } // Mode() sends a MODE command to the server. This one can get complicated if // we try to be too clever, so it's deliberately simple: // Away() sends an AWAY command to the server // Away() resets away status // Away(message) sets away with the given message func ( conn * Conn ) Away ( message ... ) { msg := getStringMsg ( message ) if msg != \" \" { msg = \" \" + msg } conn . out <- \" \" + msg } // Invite() sends an INVITE command to the server func ( conn * Conn ) Invite ( nick , channel string ) { conn . out <- \" \" + nick + \" \" + channel } // Oper() sends an OPER command to the server func ( conn * Conn ) Oper ( user , pass string ) { conn . out <- \" \" + user + \" \" + pass }", "del_tokens": "// send a MODE command to the server. This one can get complicated if we try // to be too clever, so it's deliberately simple:", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Wercker", "CI"], "add_tokens": "UnknownErrorError = Code ( \" \" )", "del_tokens": "UnknownErrorError = Code ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "platform", "as", "a", "configuration", "option", "add", "helper", "for", "creating", "common", "configuration", "options"], "add_tokens": "configuration := createConfiguration ( token , environment , codeVersion , serverHost , serverRoot ) func ( c * AsyncClient ) SetPlatform ( platform string ) { c . configuration . platform = platform } func ( c * AsyncClient ) Platform ( ) string { return c . configuration . platform }", "del_tokens": "\" \" configuration := configuration { token : token , environment : environment , endpoint : \" \" , filterHeaders : regexp . MustCompile ( \" \" ) , filterFields : regexp . MustCompile ( \" \" ) , codeVersion : codeVersion , serverHost : serverHost , serverRoot : serverRoot , }", "commit_type": "add"}
{"commit_tokens": ["improved", "wrapping", "of", "qbs", "resources", "that", "are", "udids"], "add_tokens": "id := path [ i + 1 : ]", "del_tokens": "id = path [ i + 1 : ]", "commit_type": "improve"}
{"commit_tokens": ["changed", "the", "export", "return", "type", "in", "formatter", ".", "go"], "add_tokens": "Export ( ) interface { }", "del_tokens": "Export ( ) map [ string ] interface { }", "commit_type": "change"}
{"commit_tokens": ["Make", "sure", "timestamp", "is", "formatted", "as", "a", "float"], "add_tokens": "func encodeTimestamp ( t RecordTimestamp ) string {", "del_tokens": "func encodeTimestamp ( t float64 ) string {", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "common", "Shape", "interface", "to", "PostGIS"], "add_tokens": "\" \" aspect . Column ( \" \" , Geometry { Geom : Point { } } ) , aspect . Column ( \" \" , Geometry { Polygon { } , 4326 } ) , compiled , err := stmt . Compile ( & postgres . PostGres { } , params ) func TestLatLong ( t * testing . T ) { p := LatLong { 39.739167 , - 104.984722 } `ST_SetSRID(ST_Point(-104.984722 39.739167), 4326)::geometry` , Within ( shapes . C [ \" \" ] , Point { - 104.984722 , 39.739167 } ) , `ST_Within(ST_Point(-104.984722 39.739167), \"shapes\".\"area\")` , c := AsGeoJSON ( shapes . C [ \" \" ] ) expectedPostGres ( t , c , `ST_AsGeoJSON(\"shapes\".\"area\")` , 0 )", "del_tokens": "aspect . Column ( \" \" , GeometryPolygon { 4326 } ) , compiled , err := stmt . Compile ( & aspect . PostGres { } , params ) func TestPoint ( t * testing . T ) { p := Point { 39.739167 , - 104.984722 } `ST_GeometryFromText('POINT(-104.984722 39.739167)', 4326)` , Within ( shapes . C [ \" \" ] , Point { 39.739167 , - 104.984722 } ) , `ST_Within(ST_GeometryFromText('POINT(-104.984722 39.739167)', 4326), \"shapes\".\"geom\")` , c := GeoJSON ( shapes . C [ \" \" ] ) expectedPostGres ( t , c , `ST_AsGeoJSON(\"shapes\".\"geom\")` , 0 )", "commit_type": "add"}
{"commit_tokens": ["Added", "simple", "man", "page", "support"], "add_tokens": "\" \" // Compilation date Compiled time . Time // Author Author string // Author e-mail Email string } // Tries to find out when this binary was compiled. // Returns the current time if it fails to find it. func compileTime ( ) time . Time { info , err := os . Stat ( os . Args [ 0 ] ) if err != nil { return time . Now ( ) } return info . ModTime ( ) Name : os . Args [ 0 ] , Usage : \" \" , Version : \" \" , Action : helpCommand . Action , Compiled : compileTime ( ) , Author : \" \" , Email : \" \" ,", "del_tokens": "Name : os . Args [ 0 ] , Usage : \" \" , Version : \" \" , Action : helpCommand . Action ,", "commit_type": "add"}
{"commit_tokens": ["make", "FromImage", "work", "with", "gifs"], "add_tokens": "", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Fix", "race", "in", "xmpp", "client", "creation"], "add_tokens": "\" \" xmppClients = struct { sync . RWMutex m map [ string ] * xmppGcmClient } { m : make ( map [ string ] * xmppGcmClient ) } xmppClients . Lock ( ) if xmppClients . m [ senderId ] == nil { xmppClients . m [ senderId ] = & xmppGcmClient { * c , make ( map [ string ] * messageLogEntry ) } xmppClients . Unlock ( ) return xmppClients . m [ senderId ] , nil", "del_tokens": "xmppClients = make ( map [ string ] * xmppGcmClient ) if xmppClients [ senderId ] == nil { xmppClients [ senderId ] = & xmppGcmClient { * c , make ( map [ string ] * messageLogEntry ) } return xmppClients [ senderId ] , nil", "commit_type": "fix"}
{"commit_tokens": ["Added", "new", "Job", "abstraction", ";", "tests"], "add_tokens": "func ( this * Service ) Name ( ) ServiceKey { return this . name } func ( this * Service ) Targets ( ) [ ] [ ] * Container { // all the container instances for all the jobs list := [ ] [ ] * Container { } for _ , job := range this . jobs { clist := [ ] * Container { } for _ , c := range job . container_instances { clist = append ( clist , c ) } list = append ( list , clist ) } return list } for _ , group := range this . Targets ( ) {", "del_tokens": "for _ , group := range this . Targets {", "commit_type": "add"}
{"commit_tokens": ["Adding", "statik", "HTTP", "file", "server", "."], "add_tokens": "flagDest = flag . String ( \" \" , \" \" , \" \" ) fmt . Fprint ( & qb , \" \\n \" ) fmt . Fprint ( & qb , \" \\t \\\" \\\" \\n \\n \" ) fmt . Fprint ( & qb , \" \\t \\\" \\\" \\n \" ) fmt . Fprintf ( & qb , \" \\t \\n \" , modTime . Unix ( ) ) fmt . Fprint ( & qb , \" \\t \" ) fmt . Fprint ( & qb , \" \\n \\t \" )", "del_tokens": "flagDest = flag . String ( \" \" , \" \" , \" \" ) fmt . Fprint ( & qb , \" \\\" \\\" \\n \\n \" ) fmt . Fprint ( & qb , \" \\n \" ) fmt . Fprint ( & qb , \" \\t \\n \" ) fmt . Fprint ( & qb , \" \\t \\n \" ) fmt . Fprintf ( & qb , \" \\t \\n \" , modTime . Unix ( ) ) fmt . Fprint ( & qb , \" \\t \" )", "commit_type": "add"}
{"commit_tokens": ["update", "README", "+", "some", "docs"], "add_tokens": "// --------- // |----------> | console | // | --------- // i.e. ----------------- ----------------- Unmarshal ------------- -------- // | app log handler | -- json --> | central log app | -- to -> | log handler | --> | syslog | // ----------------- ----------------- Entry ------------- -------- // | --------- // |----------> | DataDog | // ---------", "del_tokens": "// --------- // |----------> | console | // Addding this check for when you are doing centralized logging | --------- // i.e. ----------------- ----------------- ------------- -------- // | app log handler | -- json --> | central log app | -- unmarshal json to Entry -> | log handler | --> | syslog | // ----------------- ----------------- ------------- -------- // | --------- // |----------> | DataDog | // ---------", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "draft", "02", "of", "the", "spec", "."], "add_tokens": "// specified in draft-agl-tls-chacha20poly1305-02: // http://tools.ietf.org/html/draft-agl-tls-chacha20poly1305-02 h . Write ( b ) h . Write ( b )", "del_tokens": "// specified in draft-agl-tls-chacha20poly1305-00: // http://tools.ietf.org/html/draft-agl-tls-chacha20poly1305-00 h . Write ( b ) h . Write ( b )", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "specific", "to", "engine", "funcmap", "setter", "side", "-", "by", "-", "side", "with", "the", "generic", "UseFuncMap"], "add_tokens": "if len ( funcMap ) == 0 { m . SetFuncMapToEngine ( funcMap , m . Entries [ i ] . Engine ) // SetFuncMapToEngine sets or overrides a specific func map to a specific template engine // SharedFuncs stays untouched here. // // Call UseFuncMap if you want to set SharedFuncs and be applied // to all registered and future template engines registrations. func SetFuncMapToEngine ( funcMap map [ string ] interface { } , e Engine ) * Mux { return DefaultMux . SetFuncMapToEngine ( funcMap , e ) } // SetFuncMapToEngine sets or overrides a specific func map to a specific template engine // SharedFuncs stays untouched here. // // Call UseFuncMap if you want to set SharedFuncs and be applied // to all registered and future template engines registrations. func ( m * Mux ) SetFuncMapToEngine ( funcMap map [ string ] interface { } , e Engine ) * Mux { if len ( funcMap ) == 0 { return m } if funcer , ok := e . ( EngineFuncs ) ; ok { if funcer . Funcs ( ) != nil { for k , v := range funcMap { return m // add the shared funcs m . SetFuncMapToEngine ( m . SharedFuncs , e )", "del_tokens": "if funcMap == nil { entry := m . Entries [ i ] m . setSharedFuncs ( entry ) func ( m * Mux ) setSharedFuncs ( e * Entry ) { if funcer , ok := e . Engine . ( EngineFuncs ) ; ok { if funcer . Funcs ( ) != nil && m . SharedFuncs != nil { for k , v := range m . SharedFuncs { // add the shared funcs m . setSharedFuncs ( entry )", "commit_type": "add"}
{"commit_tokens": ["Added", "documentation", "generation", "to", "GenProg"], "add_tokens": "s = `// Mul performs a scalar multiplcation of the matrix. This is equivalent to iterating", "del_tokens": "`// Mul performs a scalar multiplcation of the matrix. This is equivalent to iterating", "commit_type": "add"}
{"commit_tokens": ["update", "logging", "usage", "to", "reflect", "recent", "API", "changes"], "add_tokens": "err = fmt . Errorf ( \" \" + log . Errorf ( err . Error ( ) )", "del_tokens": "err = log . Errorf ( \" \" +", "commit_type": "update"}
{"commit_tokens": ["Fix", "typo", "in", "DependencyAnalysis", "name"], "add_tokens": "func NewDependencyAnalysis ( ) DependencyAnalysis {", "del_tokens": "func NewDependencyAnalylis ( ) DependencyAnalysis {", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "for", "SystemStats", "."], "add_tokens": "// Number of goroutines currently running. NumGoRoutines int // Seconds in userland. UserTime float64 // Seconds in system time. SystemTime float64 // Number of bytes currently allocated. BytesAlloc uint64 // Number of bytes obtained from system. BytesFromSystem uint64 // How long the last GC pause time took in milliseconds. GCPauseTimeLast float64 // Maximum recent GC pause time in milliseconds. GCPauseTimeMax float64 // Total GC pause time in milliseconds. // Seconds since last GC pause. GCPauseSince float64 // GetStackTraces returns a map of goroutines to string // Slice of their respective stack trace.", "del_tokens": "NumGoRoutines int UserTime float64 SystemTime float64 BytesAlloc uint64 BytesFromSystem uint64 GCPauseTimesNs float64 GCPauseTimeMax float64 GCPauseSince float64 // Return a map of goroutines to string Slice of their // respective stack trace.", "commit_type": "add"}
{"commit_tokens": ["Implement", "logic", "for", "include", ":", "mechanism", "."], "add_tokens": "case tInclude : matches , result = p . parseInclude ( token ) func ( p * Parser ) parseInclude ( t * Token ) ( bool , SPFResult ) { result , _ := matchingResult ( t . Qualifier ) domain := t . Value if isEmpty ( & domain ) { return true , Permerror } matchesInclude := false if includeResult , err := checkHost ( p . Ip , domain , p . Sender ) ; err != nil { return false , None } else { // it's all fine switch includeResult { case Pass : matchesInclude = true case Fail , Softfail , Neutral : matchesInclude = false case Temperror : matchesInclude = false result = Temperror case Permerror , None : matchesInclude = false result = Permerror } } if matchesInclude { return true , result } return false , None }", "del_tokens": "/ * case tPTR : result = p . parsePTR ( token ) case tInclude : matches , result = p . parseInclude ( token ) * /", "commit_type": "implement"}
{"commit_tokens": ["made", "errors", "panic", "by", "default"], "add_tokens": "panic ( \" \" + err . Error ( ) ) // OnErrLog prints a log out with the specified error. func ( o * Options ) OnErrLog ( err error ) { log . Println ( \" \" + err . Error ( ) )", "del_tokens": "log . Println ( \" \" , err . Error ( ) ) // OnErrPanic panics with the specified error. func ( o * Options ) OnErrPanic ( err error ) { panic ( \" \" + err . Error ( ) )", "commit_type": "make"}
{"commit_tokens": ["add", "server", "state", "mutex", "to", "avoid", "state", "race", "condition"], "add_tokens": "rand : rand . New ( rand . NewSource ( time . Now ( ) . UnixNano ( ) ) ) ,", "del_tokens": "rand : rand . New ( rand . NewSource ( time . Now ( ) . UnixNano ( ) ) ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "benchmarks", "for", "struct", "encoding", "+", "optimize", "struct", "encoding"], "add_tokens": "if e . EmitBulkStringsOnly || strings . IndexByte ( v , '\\r' ) >= 0 || strings . IndexByte ( v , '\\n' ) >= 0 {", "del_tokens": "if e . EmitBulkStringsOnly || len ( v ) > 100 || strings . IndexByte ( v , '\\r' ) >= 0 || strings . IndexByte ( v , '\\n' ) >= 0 {", "commit_type": "add"}
{"commit_tokens": ["Added", "hamming", "24", "/", "18"], "add_tokens": "func Hamming84Decode ( i uint8 ) ( o uint8 , ok bool ) { ok = true return } func Hamming2418Decode ( i uint32 ) ( o uint32 , ok bool ) { o = i ok = true", "del_tokens": "import \" \" func Hamming84Decode ( i uint8 ) ( o uint8 , err error ) { err = fmt . Errorf ( \" \" , i )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "page", "for", "pre", "-", "generated", "User", "tokens", "to", "access", "backend"], "add_tokens": "Origin ( \" \" , func ( ) {", "del_tokens": "Origin ( \" \" , func ( ) {", "commit_type": "add"}
{"commit_tokens": ["Made", "a", "fake", "implementation", "of", "checkAgainstInt", "."], "add_tokens": "func checkAgainstInt ( e int64 , v reflect . Value ) ( res MatchResult , err string ) { res = MATCH_FALSE switch v . Kind ( ) { default : res = MATCH_UNDEFINED err = \" \" case reflect . Int , reflect . Int16 , reflect . Int32 , reflect . Int64 : if ( e == v . Int ( ) ) { res = MATCH_TRUE } case reflect . Uint , reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 : if ( uint64 ( e ) == v . Uint ( ) ) { res = MATCH_TRUE } } return", "del_tokens": "func checkAgainstInt ( e int64 , v reflect . Value ) ( MatchResult , string ) { return MATCH_UNDEFINED , \" \"", "commit_type": "make"}
{"commit_tokens": ["Fix", "bucketing", "on", "goroutine", "hung", "for", "several", "minutes", "."], "add_tokens": "\" \" , \" \\x1b \\x1b \\x1b \" ,", "del_tokens": "\" \" , \" \\x1b \\x1b \\x1b \" ,", "commit_type": "fix"}
{"commit_tokens": ["Implement", "the", "Error", "and", "NotFound", "helpers", "."], "add_tokens": "rest . NotFound ( w , r ) rest . Error ( w , err . Error ( ) , http . StatusInternalServerError )", "del_tokens": "http . NotFound ( w , r . Request ) http . Error ( w , err . Error ( ) , 500 )", "commit_type": "implement"}
{"commit_tokens": ["Improve", "support", "for", "image", "maps", "within", "the", "user", "generated", "content", "policy"], "add_tokens": "p . AllowAttrs ( \" \" ) . Matching ( regexp . MustCompile ( `^([\\p{L}\\p{N}_-]+)$` ) , ) . OnElements ( \" \" ) regexp . MustCompile ( `^([0-9]+,)+[0-9]+$` ) , p . AllowAttrs ( \" \" ) . Matching ( regexp . MustCompile ( `(?i)^#[\\p{L}\\p{N}_-]+$` ) , ) . OnElements ( \" \" )", "del_tokens": "regexp . MustCompile ( `^([0-9]+,){2}(,[0-9]+)*$` ) ,", "commit_type": "improve"}
{"commit_tokens": ["update", "youtube", "-", "info", "for", "new", "API"], "add_tokens": "config gumble . Config p . client = gumble . NewClient ( & p . config ) p . config . Username = * username p . config . Password = * password p . config . Address = * server p . config . TlsConfig . InsecureSkipVerify = true if err := p . client . Connect ( ) ; err != nil {", "del_tokens": "p . client = gumble . NewClient ( ) p . client . TlsConfig ( ) . InsecureSkipVerify = true if err := p . client . Dial ( * username , * password , * server ) ; err != nil {", "commit_type": "update"}
{"commit_tokens": ["Remove", "attributes", "from", "json", "response"], "add_tokens": "Attributes SObjectAttributes `json:\"-\" force:\"attributes,omitempty\"`", "del_tokens": "Attributes SObjectAttributes `force:\"attributes,omitempty\"`", "commit_type": "remove"}
{"commit_tokens": ["remove", "hash", "property", "of", "sketch"], "add_tokens": "sparse bool p uint8 b uint8 m uint32 alpha float64 tmpSet set hash = hashFunc x := hash ( e )", "del_tokens": "sparse bool p uint8 b uint8 m uint32 alpha float64 tmpSet set hash func ( e [ ] byte ) uint64 hash : hash , x := sk . hash ( e )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "global", "flags", "in", "Subcommands"], "add_tokens": "context := NewContext ( a , set , ctx . globalSet )", "del_tokens": "context := NewContext ( a , set , set )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "missing", "separator", "for", "sample", "rate"], "add_tokens": "c . appendString ( \" \" )", "del_tokens": "c . appendByte ( '@' )", "commit_type": "fix"}
{"commit_tokens": ["Update", "common", "/", "mqtt_control_packet_type", ".", "go"], "add_tokens": "MQTTControlPacketTypeCONNECT = 1 MQTTControlPacketTypeCONNACK = 2 MQTTControlPacketTypePUBLISH = 3 MQTTControlPacketTypePUBACK = 4 MQTTControlPacketTypePUBREC = 5 MQTTControlPacketTypePUBREL = 6 MQTTControlPacketTypePUBCOMP = 7 MQTTControlPacketTypeSUBSCRIBE = 8 MQTTControlPacketTypeSUBACK = 9 MQTTControlPacketTypeUNSUBSCRIBE = 10 MQTTControlPacketTypeUNSUBACK = 11 MQTTControlPacketTypePINGREQ = 12 MQTTControlPacketTypePINGRESP = 13 MQTTControlPacketTypeDISCONNECT = 14", "del_tokens": "MQTTControlPacketTypeCONNECT MQTTControlPacketType = 1 MQTTControlPacketTypeCONNACK MQTTControlPacketType = 2 MQTTControlPacketTypePUBLISH MQTTControlPacketType = 3 MQTTControlPacketTypePUBACK MQTTControlPacketType = 4 MQTTControlPacketTypePUBREC MQTTControlPacketType = 5 MQTTControlPacketTypePUBREL MQTTControlPacketType = 6 MQTTControlPacketTypePUBCOMP MQTTControlPacketType = 7 MQTTControlPacketTypeSUBSCRIBE MQTTControlPacketType = 8 MQTTControlPacketTypeSUBACK MQTTControlPacketType = 9 MQTTControlPacketTypeUNSUBSCRIBE MQTTControlPacketType = 10 MQTTControlPacketTypeUNSUBACK MQTTControlPacketType = 11 MQTTControlPacketTypePINGREQ MQTTControlPacketType = 12 MQTTControlPacketTypePINGRESP MQTTControlPacketType = 13 MQTTControlPacketTypeDISCONNECT MQTTControlPacketType = 14 // MQTTControlPacketType represents an MQTT Control Packet type type MQTTControlPacketType byte", "commit_type": "update"}
{"commit_tokens": ["Add", "missing", "Content", "-", "Type", "header", "for", "form", "data"], "add_tokens": "} else { req . Header . Set ( runtime . HeaderContentType , mediaType ) // write the form values as the body buf . WriteString ( r . formFields . Encode ( ) ) return req , nil", "del_tokens": "// write the form values as the body buf . WriteString ( r . formFields . Encode ( ) ) return req , nil", "commit_type": "add"}
{"commit_tokens": ["remove", "dep", "of", "go", "chassis"], "add_tokens": "LogRotateDate = 1 LogRotateSize = 10 LogBackupCount = 7 RollingPolicySize = \" \" if c . RollingPolicy == RollingPolicySize { c . RollingPolicy = RollingPolicySize } else if c . RollingPolicy != \" \" && c . RollingPolicy != RollingPolicySize { c . RollingPolicy = RollingPolicySize", "del_tokens": "\" \" LogRotateDate = 1 LogRotateSize = 10 LogBackupCount = 7 if c . RollingPolicy == common . Size { c . RollingPolicy = common . RollingPolicySize } else if c . RollingPolicy != \" \" && c . RollingPolicy != common . RollingPolicySize { c . RollingPolicy = common . RollingPolicySize", "commit_type": "remove"}
{"commit_tokens": ["add", "support", "for", "get", "terminal", "size", "for", "windows"], "add_tokens": "// +build !windows return 0 , 0 return 0 , 0", "del_tokens": "os . Exit ( 1 ) os . Exit ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Add", "firmware", "hardware", "and", "software", "revision", "which", "are", "optional", "characteristics", "for", "accessory", "info"], "add_tokens": "// Optional Firmware * characteristic . Revision Hardware * characteristic . Revision Software * characteristic . Revision return NewAccessoryInfo ( info . Name , info . SerialNumber , info . Manufacturer , info . Model , info . Firmware , info . Hardware , info . Software ) func NewAccessoryInfo ( accessoryName , serialNumber , manufacturerName , modelName , firmwareRevision , hardwareRevision , softwareRevision string ) * AccessoryInfo { var firmware * characteristic . Revision if firmwareRevision != \" \" { firmware = characteristic . NewFirmwareRevision ( firmwareRevision ) service . AddCharacteristic ( firmware . Characteristic ) } var hardware * characteristic . Revision if hardwareRevision != \" \" { hardware = characteristic . NewHardwareRevision ( hardwareRevision ) service . AddCharacteristic ( hardware . Characteristic ) } var software * characteristic . Revision if softwareRevision != \" \" { software = characteristic . NewSoftwareRevision ( softwareRevision ) service . AddCharacteristic ( software . Characteristic ) } return & AccessoryInfo { service , identify , serial , model , manufacturer , name , firmware , hardware , software }", "del_tokens": "return NewAccessoryInfo ( info . Name , info . SerialNumber , info . Manufacturer , info . Model ) func NewAccessoryInfo ( accessoryName , serialNumber , manufacturerName , modelName string ) * AccessoryInfo { return & AccessoryInfo { service , identify , serial , model , manufacturer , name }", "commit_type": "add"}
{"commit_tokens": ["Updating", "documentation", "with", "presto", "alias", "variants"], "add_tokens": "// -----------------------------|------------------------------------------- // -----------------------------|------------------------------------------- // -----------------------------|------------------------------------------- // -----------------------------|------------------------------------------- // -----------------------------|------------------------------------------- // Presto (presto) | pr, prestodb, prestos, prs, prestodbs", "del_tokens": "// -----------------------------|----------------------------------------- // -----------------------------|----------------------------------------- // -----------------------------|----------------------------------------- // -----------------------------|----------------------------------------- // -----------------------------|----------------------------------------- // Presto (presto) | pr, prestodb", "commit_type": "update"}
{"commit_tokens": ["Add", "answer", "suppression", "with", "Hidden"], "add_tokens": "\" \" if question . Hidden { return getpass . GetPassword ( \" \" ) } else { answer , err := bufio . NewReader ( os . Stdin ) . ReadString ( '\\n' ) if err != nil { return \" \" , err } // Strip off trailing newline return answer [ 0 : len ( answer ) - 1 ] , nil", "del_tokens": "answer , err := bufio . NewReader ( os . Stdin ) . ReadString ( '\\n' ) if err != nil { return answer , err // Strip off trailing newline return answer [ 0 : len ( answer ) - 1 ] , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "that", "lowered", "positional", "arguments"], "add_tokens": "arg := ap . Args [ ap . Idx ] arg = strings . ToLower ( arg ) func Parse ( params interface { } ) ( [ ] string , error ) { return ParseArguments ( os . Args [ 1 : ] , params , true )", "del_tokens": "arg := strings . ToLower ( ap . Args [ ap . Idx ] ) func Parse ( v interface { } ) ( [ ] string , error ) { return ParseArguments ( os . Args [ 1 : ] , v , true )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "CSRF", "protection", "."], "add_tokens": "func ( r * Requester ) SetCrumb ( ) error { crumbData := map [ string ] string { } response , err := r . GetJSON ( \" \" , & crumbData , nil ) if err != nil { return err } if response . StatusCode == 200 && crumbData [ \" \" ] != \" \" { r . SetHeader ( crumbData [ \" \" ] , crumbData [ \" \" ] ) } return nil } r . SetCrumb ( ) r . SetCrumb ( ) r . SetCrumb ( ) r . SetCrumb ( ) func ( r * Requester ) redirectPolicyFunc ( req * http . Request , via [ ] * http . Request ) error {", "del_tokens": "func ( r * Requester ) redirectPolicyFunc ( req * http . Request , via [ ] * http . Request ) error {", "commit_type": "add"}
{"commit_tokens": ["move", "stuff", "from", "example", "server", "to", "new", "Session", "and", "SessionConfig", "classes"], "add_tokens": "type Frame interface { Write ( b * bytes . Buffer ) error } func ( f * StreamFrame ) Write ( b * bytes . Buffer ) error { return nil func ( f * AckFrame ) Write ( b * bytes . Buffer ) error { return nil", "del_tokens": "func WriteStreamFrame ( b * bytes . Buffer , f * StreamFrame ) { func WriteAckFrame ( b * bytes . Buffer , f * AckFrame ) {", "commit_type": "move"}
{"commit_tokens": ["fix", "ExtractPublicKey", "semantics", "to", "return", "an", "error", "when", "it", "can", "t", "extract", "the", "public", "key"], "add_tokens": "// ErrNoPublickKey is an error for peer IDs that don't embed public keys ErrNoPublicKey = errors . New ( \" \" ) // This method returns ErrNoPublicKey if the peer ID looks valid but it can't extract return nil , ErrNoPublicKey", "del_tokens": "// This method returns nil, nil if the peer ID looks valid but it can't extract return nil , nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bing", "to", "the", "new", "interface"], "add_tokens": "\" \" \" \" \" \" assert . Equal ( t , geo . Location { Lat : - 37.81375 , Lng : 144.97176 } , * location ) assert . True ( t , strings . Index ( address . FormattedAddress , \" \" ) > 0 ) addr , err := geocoder . ReverseGeocode ( - 37.81375 , 164.97176 ) assert . NoError ( t , err ) assert . Nil ( t , addr )", "del_tokens": "\" \" \" \" \" \" \" \" fmt . Println ( location ) assert . Equal ( t , geo . Location { Lat : - 37.81375 , Lng : 144.97176 } , location ) fmt . Println ( address ) assert . True ( t , strings . Index ( address , \" \" ) > 0 ) _ , err := geocoder . ReverseGeocode ( - 37.81375 , 164.97176 ) assert . Equal ( t , err , geo . ErrNoResult )", "commit_type": "fix"}
{"commit_tokens": ["Add", "build", "options", "to", "update", "-", "repos"], "add_tokens": "args := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" } build_file_generation = \" \" , build_file_generation = \" \" ,", "del_tokens": "args := [ ] string { \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Add", "PodStatus", "to", "Pod", "definition"], "add_tokens": "type PodStatus struct { Phase string `json:\"phase\"` } Metadata * Metadata `json:\"metadata\"` Spec * PodSpec `json:\"spec\"` Status * PodStatus `json:\"status\"`", "del_tokens": "Metadata * Metadata `json:\"metadata\"` Spec * PodSpec `json:\"spec\"`", "commit_type": "add"}
{"commit_tokens": ["fix", "error", "on", "broken", "links"], "add_tokens": "\" \" // Extract contents of archivePath into the extractPath return fmt . Errorf ( \" \" , destinationPath ) ignoreBrokenSimlink := true if files . IsSymlink ( _path ) && ignoreBrokenSimlink { return nil } zipPath string // CreateFlat build a zip containing inputPath. // If inputPath is a directory the zip will contain the directory contents ctx := context { zipPath : zipPath , // Create build a zip containing inputPath. // If inputPath is a directory the zip will contain the directory ctx := context { zipPath : zipPath ,", "del_tokens": "\" \" return fmt . Errorf ( \" \" , destinationPath ) zipPath string ctx := context { zipPath : zipPath , // if inputPath is a directory the zip will contain the directory ctx := context { zipPath : zipPath ,", "commit_type": "fix"}
{"commit_tokens": ["add", "obfuscation", "support", "for", "SNI"], "add_tokens": "case \" \" : case \" \" : connector = gost . SNIConnector ( node . Values . Get ( \" \" ) )", "del_tokens": "case \" \" , \" \" : // sni is an alias of forward", "commit_type": "add"}
{"commit_tokens": ["Make", "FVTAddr", "configurable", "by", "using", "env", "variable", "."], "add_tokens": "import \" \" var ( FVTAddr string FVTTCP string FVTSSL string func init ( ) { FVTAddr := os . Getenv ( \" \" ) if FVTAddr == \" \" { FVTAddr = \" \" } FVTTCP = \" \" + FVTAddr + \" \" FVTSSL = \" \" + FVTAddr + \" \" }", "del_tokens": "// Set these values to the URI of your MQTT Broker before running go-test const ( FVTAddr = \" \" FVTTCP = \" \" + FVTAddr + \" \" FVTSSL = \" \" + FVTAddr + \" \"", "commit_type": "make"}
{"commit_tokens": ["Fixing", "transaction", "logic", "to", "use", "OCI8", "API"], "add_tokens": "rv := C . OCITransCommit ( ( * C . OCIServer ) ( tx . c . svc ) , ( * C . OCIError ) ( tx . c . err ) , 0 ) if rv == C . OCI_ERROR { return ociGetError ( tx . c . err ) rv := C . OCITransRollback ( ( * C . OCIServer ) ( tx . c . svc ) , ( * C . OCIError ) ( tx . c . err ) , 0 ) if rv == C . OCI_ERROR { return ociGetError ( tx . c . err ) rv := C . OCITransStart ( ( * C . OCIServer ) ( c . svc ) , ( * C . OCIError ) ( c . err ) , 60 , C . OCI_TRANS_NEW ) if rv == C . OCI_ERROR { return nil , ociGetError ( c . err )", "del_tokens": "if err := tx . c . exec ( \" \" ) ; err != nil { return err if err := tx . c . exec ( \" \" ) ; err != nil { return err if err := c . exec ( \" \" ) ; err != nil { return nil , err", "commit_type": "fix"}
{"commit_tokens": ["update", "comments", "in", "level", ".", "go"], "add_tokens": "// the type of level // String function casts level value to string // GetLevelName lets users be able to get level name from level value. // GetLevelValue lets users be able to get level value from level name. // AddLevel adds a new level to the level list. // SetLevel updates existing levels.", "del_tokens": "// cast level value to string // get level name from level value // get level value from level name // add a new level // update existing level", "commit_type": "update"}
{"commit_tokens": ["add", "comments", "to", "fields", ".", "go"], "add_tokens": "// the struct for each log record // this variable maps fields in format to relavent function signatures var fields = map [ string ] func ( * logging , * record ) interface { } { // if it fails to get some fields with string type, these fields are set to // errString value // here we uses -1 rather than 0, because the default value in // golang is 0 and we should know the value is uninitialized // or failed to get // logger name // next sequence number // log level number // log level name // file name of calling logger, with whole path // file name of calling logger // TODO: module name // line number // function name // timestamp of starting time // RFC3339Nano time // nanosecond of starting time // nanosecond timestamp // nanoseconds since logger created // thread id // thread name // the log message", "del_tokens": "type field func ( * logging , * record ) interface { } var fields = map [ string ] field {", "commit_type": "add"}
{"commit_tokens": ["add", "lock", "in", "decode", "stream", "when", "accessing", "err"], "add_tokens": "\" \" mux sync . RWMutex dec . mux . Lock ( ) err := dec . raiseInvalidJSONErr ( dec . cursor ) dec . mux . Unlock ( ) return err dec . mux . RLock ( ) defer dec . mux . RUnlock ( )", "del_tokens": "return dec . raiseInvalidJSONErr ( dec . cursor )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "json", "reporter", "to", "preserve", "formating", "across", "remote", "sessions"], "add_tokens": "\" \" JSON bool `long:\"json\" description:\"Output the run details in chunked json\"` abs , err := filepath . Abs ( args [ 0 ] ) if err != nil { panic ( err ) } Arg0 = abs args , err = parser . ParseArgs ( args ) if opts . JSON { env . ReportJSON ( ) }", "del_tokens": "Arg0 = args [ 0 ] args , err := parser . ParseArgs ( args )", "commit_type": "add"}
{"commit_tokens": ["Using", "master", "branch", "of", "syslogd"], "add_tokens": "\" \" \" \" // Address: \"0.0.0.0:5880\" // Format: \"RFC3164\" // Protocol: \"udp\"", "del_tokens": "\" \" \" \" // Address: 0.0.0.0:5880 // Format: RFC3164 // Protocol: udp", "commit_type": "use"}
{"commit_tokens": ["Use", "custom", "Position", "with", "Stringer", "."], "add_tokens": "// It parses namespaces, exceptions, services, structs, consts, typedefs and enums, but is easily // extensible to more. Requirement string `@[ \"optional\" | \"required\" ]` Default * Literal `[ \"=\" @@ ]` Str * string ` @String` Float * float64 `| @Float` Int * int64 `| @Int` Bool * string `| @( \"true\" | \"false\" )` Reference * string `| @Ident { @\".\" @Ident }` type Typedef struct { Type * Type `\"typedef\" @@` Name string `@Ident` } type Const struct { Type * Type `\"const\" @@` Name string `@Ident` Value * Literal `\"=\" @@` } Enums [ ] * Enum ` | @@` Typedefs [ ] * Typedef ` | @@` Consts [ ] * Const ` | @@ }`", "del_tokens": "// It parses namespaces, exceptions, services, structs, and enums, but is easily extensible to more. Requirement string `@( \"optional\" | \"required\" )` Str * string ` @String` Float * float64 `| @Float` Int * int64 `| @Int` Bool * string `| @( \"true\" | \"false\" )` Enums [ ] * Enum ` | @@ }`", "commit_type": "use"}
{"commit_tokens": ["Changed", "logrus", "import", "to", "lower", "case"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "change"}
{"commit_tokens": ["Remove", "turnpike", "use", "nexus", "instead"], "add_tokens": "\" \" \" \" \" \" Serialization : client . JSON , Version : \" \" , Realm : \" \" , var options = wamp . Dict { } func echo ( _ context . Context , args wamp . List , _ , _ wamp . Dict ) * client . InvokeResult { return & client . InvokeResult { }", "del_tokens": "\" \" Serialization : turnpike . JSON , Version : \" \" , Realm : \" \" , var options = make ( map [ string ] interface { } ) func echo ( args [ ] interface { } , kwargs map [ string ] interface { } , details map [ string ] interface { } , ) * turnpike . CallResult { return nil", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "dynamic", "log_packets", "via", "sentryctl", "and", "control", "API", "."], "add_tokens": "\" \" // LogPackets is a flag used to enable or disable packet valid values // are 0 or 1. var LogPackets uint32 = 1 if atomic . LoadUint32 ( & LogPackets ) == 1 { LogPacket ( \" \" , protocol , vv . First ( ) , nil ) } if atomic . LoadUint32 ( & LogPackets ) == 1 { LogPacket ( \" \" , protocol , hdr . UsedBytes ( ) , payload ) }", "del_tokens": "LogPacket ( \" \" , protocol , vv . First ( ) , nil ) LogPacket ( \" \" , protocol , hdr . UsedBytes ( ) , payload )", "commit_type": "add"}
{"commit_tokens": ["Fix", "base", "option", "on", "Windows"], "add_tokens": "fpath = utils . FixPath ( fpath ) c . Base = strings . TrimPrefix ( c . Base , \" \" )", "del_tokens": "if strings . HasPrefix ( c . Base , \" \" ) { c . Base = c . Base [ 2 : ] }", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "priority", "header"], "add_tokens": "if n . Priority > 0 { r . Header . Set ( \" \" , fmt . Sprintf ( \" \" , n . Priority ) )", "del_tokens": "if n . Priority > 5 { r . Header . Set ( \" \" , PriorityHigh ) } else { r . Header . Set ( \" \" , PriorityLow )", "commit_type": "fix"}
{"commit_tokens": ["add", "-", "debug", "flag", "to", "commands"], "add_tokens": "\" \" gitmedia . SetupDebugging ( nil ) flag . Parse ( )", "del_tokens": "gitmedia . SetupDebugging ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "MustNewPrometheusHook", "for", "less", "verbose", "hook", "creation", "(", "+", "tests", ")", "."], "add_tokens": "hook := promrus . MustNewPrometheusHook ( )", "del_tokens": "hook , err := promrus . NewPrometheusHook ( ) assert . Nil ( t , err )", "commit_type": "add"}
{"commit_tokens": ["Add", "better", "error", "output", "."], "add_tokens": "return fmt . Errorf ( \" \" , code , * resp . Message ) return fmt . Errorf ( \" \" , code , * resp . Message )", "del_tokens": "\" \" return errors . New ( * resp . Message ) return errors . New ( * resp . Message )", "commit_type": "add"}
{"commit_tokens": ["added", "an", "example", "json", "-", "crud", "app"], "add_tokens": "// DefaultContext is, as its name implies, a default // implementation of the Context interface. // Response returns the original Response for the request. // Request returns the original Request. // Params returns all of the parameters for the request, // including both named params and query string parameters. // These parameters are automatically available in templates // as \"{{.params}}\". // Logger returns the Logger for this context. // Param returns a param, either named or query string, // based on the key. // ParamInt tries to convert the requested parameter to // an int. It will return an error if there is a problem. return i , errors . WithMessage ( err , fmt . Sprintf ( \" \" , k ) ) // Set a value onto the Context. Any value set onto the Context // will be automatically available in templates. // Get a value that was previous set onto the Context. // Session for the associated Request. // Render a status code and render.Renderer to the associated Response. // The request parameters will be made available to the render.Renderer // \"{{.params}}\". Any values set onto the Context will also automatically // be made available to the render.Renderer. // Bind the interface to the request.Body. The type of binding // is dependent on the \"Content-Type\" for the request. If the type // is \"application/json\" it will use \"json.NewDecoder\". If the type // is \"application/xml\" it will use \"xml.NewDecoder\". The default // binder is \"http://www.gorillatoolkit.org/pkg/schema\". // NoContent will be rendered, but a status code will be set. // LogField adds the key/value pair onto the Logger to be printed out // as part of the request logging. This allows you to easily add things // like metrics (think DB times) to your request.", "del_tokens": "return i , errors . Wrapf ( err , \" \" , k )", "commit_type": "add"}
{"commit_tokens": ["remove", "timers", "in", "favor", "of", "After"], "add_tokens": "var GCDVERSION = \" \"", "del_tokens": "var GCDVERSION = \" \"", "commit_type": "remove"}
{"commit_tokens": ["Make", "interceptors", "fire", "when", "their", "target", "is", "embedded", "in", "another", "controller", "."], "add_tokens": "for _ , intc := range getInterceptors ( when , appControllerPtr ) {", "del_tokens": "for _ , intc := range getInterceptors ( when , appControllerPtr . Type ( ) ) {", "commit_type": "make"}
{"commit_tokens": ["added", "RawQuery", "to", "request", "builder"], "add_tokens": "func ( _ RequestTests ) SetsProtocol ( ) { func ( _ RequestTests ) SetsURL ( ) { func ( _ RequestTests ) SetsPath ( ) { func ( _ RequestTests ) SetsRawQuery ( ) { req := Request ( ) . RawQuery ( \" \" ) . Request Expect ( req . URL . Query ( ) [ \" \" ] [ 0 ] ) . To . Equal ( \" \" ) Expect ( req . URL . Query ( ) [ \" \" ] [ 0 ] ) . To . Equal ( \" \" ) Expect ( req . URL . RawQuery ) . To . Equal ( \" \" ) } func ( _ RequestTests ) SetsHost ( ) {", "del_tokens": "func ( _ * RequestTests ) SetsProtocol ( ) { func ( _ * RequestTests ) SetsURL ( ) { func ( _ * RequestTests ) SetsPath ( ) { func ( _ * RequestTests ) SetsHost ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "Set", "()", "and", "Unset", "()"], "add_tokens": "// Testing colors is kinda different. First we test for given colors and their // escaped formatted results. Next we create some visual tests to be tested. // Each visual test includes the color name to be compared. // First Visual Test // Third visual test Set ( FgBlue ) fmt . Println ( \" \" ) Unset ( ) Set ( FgMagenta ) fmt . Println ( \" \" ) Unset ( )", "del_tokens": "// Visual Test", "commit_type": "add"}
{"commit_tokens": ["make", "taxi", "download", "whole", "file", "before", "importing"], "add_tokens": "\" \" \" \" for i := 0 ; i < 2 ; i ++ { failedUrls := make ( map [ string ] int ) // we're using ReadAll here to ensure that we can read the entire // file/url before we start putting it into Pilosa. Not great for memory // usage or smooth performance, but we want to ensure repeatable results // in the simplest way possible. contentBytes , err := ioutil . ReadAll ( content ) if err != nil { failedUrls [ url ] ++ if failedUrls [ url ] > 10 { log . Fatalf ( \" \" , url , err ) } return } buf := bytes . NewBuffer ( contentBytes ) scan := bufio . NewScanner ( buf ) err = scan . Err ( )", "del_tokens": "for i := 0 ; i < m . Concurrency ; i ++ { scan := bufio . NewScanner ( content ) err := scan . Err ( )", "commit_type": "make"}
{"commit_tokens": ["fix", "the", "rule", "of", "regex"], "add_tokens": "decimal = regexp . MustCompile ( `^-?(?:\\d{1,3}(?:,\\d{3})*|\\d+)(?:\\.\\d+)?$` ) percent = regexp . MustCompile ( `^-?\\d+\\.?\\d*$%$` )", "del_tokens": "decimal = regexp . MustCompile ( `^(?:\\d{1,3}(?:,\\d{3})*|\\d+)(?:\\.\\d+)?$` ) percent = regexp . MustCompile ( `^-*\\d*\\.?\\d*$%$` )", "commit_type": "fix"}
{"commit_tokens": ["Use", "receptor", ".", "RoutingInfo", "on", "desired", "LRPs"], "add_tokens": "\" \" func RoutesByProcessGuidFromDesireds ( desireds [ ] receptor . DesiredLRPResponse ) RoutesByProcessGuid { URIs : desired . Routes . CFRoutes [ 0 ] . Hostnames , func ContainersByProcessGuidFromActuals ( actuals [ ] receptor . ActualLRPResponse ) ContainersByProcessGuid { func ContainerFromActual ( actual receptor . ActualLRPResponse ) ( Container , error ) {", "del_tokens": "\" \" func RoutesByProcessGuidFromDesireds ( desireds [ ] models . DesiredLRP ) RoutesByProcessGuid { URIs : desired . Routes , func ContainersByProcessGuidFromActuals ( actuals [ ] models . ActualLRP ) ContainersByProcessGuid { func ContainerFromActual ( actual models . ActualLRP ) ( Container , error ) {", "commit_type": "use"}
{"commit_tokens": ["moved", "if", "statements", "in", "better", "place"], "add_tokens": "if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } // Update w.Files and then sleep for a little bit.", "del_tokens": "if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } // Update w.Files. // Sleep for a little bit.", "commit_type": "move"}
{"commit_tokens": ["move", "dir", "hyperdaemon", "to", "daemon"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Added", "domain", "to", "Mailgun", "type", "."], "add_tokens": "const ( MAILGUN_API_ADDRESS = \" \" ) Domain ( ) string domain string func NewMailgun ( domain , apiKey string ) Mailgun { m := mailgunImpl { domain : domain , apiKey : apiKey } func ( m * mailgunImpl ) Domain ( ) string { return m . domain }", "del_tokens": "func NewMailgun ( apiKey string ) Mailgun { m := mailgunImpl { apiKey : apiKey }", "commit_type": "add"}
{"commit_tokens": ["fixed", "\\", "r", "test", "error", "when", "not", "on", "windows"], "add_tokens": "\" \" // insert \\r on windows var isWindows string if runtime . GOOS == \" \" { isWindows = \" \\r \" } e := \" \" + isWindows + \" \\n \\\" \\\" \\\" \\\" \" + isWindows + \" \\n \\\" \\\" \\\" \\\" \" + isWindows + \" \\n \" e := \" \" + isWindows + \" \\n \\\" \\\" \\\" \\\" \" + isWindows + \" \\n \"", "del_tokens": "e := \" \\r \\n \\\" \\\" \\\" \\\" \\r \\n \\\" \\\" \\\" \\\" \\r \\n \" e := \" \\r \\n \\\" \\\" \\\" \\\" \\r \\n \"", "commit_type": "fix"}
{"commit_tokens": ["removing", "useless", "call", "to", "ColorModel", "()", ".", "Convert", "()"], "add_tokens": "\" \" draw . Draw ( result , cr , img , cr . Min , draw . Src )", "del_tokens": "for y , dy := cr . Min . Y , cr . Max . Y ; y < dy ; y ++ { for x , dx := cr . Min . X , cr . Max . X ; x < dx ; x ++ { result . Set ( x , y , img . At ( x , y ) ) } }", "commit_type": "remove"}
{"commit_tokens": ["update", "multi", "-", "line", "indent", "to", "support", "max", "indent"], "add_tokens": "indent := 0 findIndent : for idx , r := range lines [ 0 ] { switch r { case '\\t' , ' ' : // keep consuming default : // first non-whitespace we are going to break // and use this as indent size. This makes a variety of assumptions // - subsequent indents use same mixture of spaces/tabs indent = idx break findIndent } } lines [ i ] = line [ indent : ]", "del_tokens": "findIndent : for idx , r := range line { switch r { case '\\t' , ' ' : // keep consuming default : // first non-whitespace we are going to break // and use this as indent size if idx > 0 { //u.Debugf(\"chooping line: %q\", line[0:idx-1]) lines [ i ] = line [ idx : ] } break findIndent } }", "commit_type": "update"}
{"commit_tokens": ["Use", "the", "result", "from", "Delete", "()", "to", "validate", "updateCentroid", "calls"], "add_tokens": "deleted := t . summary . Delete ( c ) if deleted == nil { deleted . Update ( mean , weight ) t . addCentroid ( deleted )", "del_tokens": "if t . summary . Find ( c ) == nil { t . summary . Delete ( c ) c . Update ( mean , weight ) t . addCentroid ( c )", "commit_type": "use"}
{"commit_tokens": ["Add", "Subject", "and", "Thread", "for", "Chat"], "add_tokens": "Subject string Thread string Subject : v . Subject , Thread : v . Thread , if bytes . Equal ( bytes . TrimSpace ( v . Query ) , [ ] byte ( `<ping xmlns='urn:xmpp:ping'/>` ) ) || bytes . Equal ( bytes . TrimSpace ( v . Query ) , [ ] byte ( `<ping xmlns=\"urn:xmpp:ping\"/>` ) ) { var subtext = `` var thdtext = `` if chat . Subject != `` { subtext = `<subject>` + xmlEscape ( chat . Subject ) + `</subject>` } if chat . Thread != `` { thdtext = `<thread>` + xmlEscape ( chat . Thread ) + `</thread>` } return fmt . Fprintf ( c . conn , \" \" + subtext + \" \" + thdtext + \" \" ,", "del_tokens": "if bytes . Equal ( v . Query , [ ] byte ( `<ping xmlns='urn:xmpp:ping'/>` ) ) || bytes . Equal ( v . Query , [ ] byte ( `<ping xmlns=\"urn:xmpp:ping\"/>` ) ) { return fmt . Fprintf ( c . conn , \" \" + \" \" ,", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "port", "ranges", "on", "--", "expose"], "add_tokens": "t . Fatal ( \" \" , proto , port ) t . Fatal ( \" \" , proto , port )", "del_tokens": "t . Fatal ( \" \" ) t . Fatal ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "EqualsAny", "method", "to", "router", "parameters", "to", "perform", "parameter", "value", "matching"], "add_tokens": "\" \" assert := assert . New ( t ) params := Params { { Key : \" \" , Value : \" \" } } assert . Equal ( \" \" , params . ByName ( \" \" ) , \" \" ) assert . Equal ( \" \" , params . ByName ( \" \" ) , \" \" ) assert . True ( params . EqualsAny ( \" \" , \" \" , \" \" , \" \" ) , \" \" , ) assert . False ( params . EqualsAny ( \" \" , \" \" , \" \" , \" \" ) , \" \" , ) assert . False ( params . EqualsAny ( \" \" , \" \" , \" \" , \" \" ) , \" \" , )", "del_tokens": "// Create a param id := Param { Key : \" \" , Value : \" \" } params := Params { id } // Get the id back out if exists := params . ByName ( \" \" ) ; exists != \" \" { t . Fatalf ( \" \" , exists ) } // Get a parameter that doesn't exist if doesnt := params . ByName ( \" \" ) ; doesnt != \" \" { t . Fatalf ( \" \" , doesnt ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "emit", "at", "most", "76", "chars", "per", "line"], "add_tokens": "// As required by RFC 2045, 6.7. (page 21) for quoted-printable, and // RFC 2045, 6.8. (page 25) for base64. const maxLineLen = 76 // base64LineWriter limits text encoded in base64 to 76 characters per line // qpLineWriter limits text encoded in quoted-printable to 76 characters per", "del_tokens": "// As defined in RFC 5322, 2.1.1. const maxLineLen = 78 // base64LineWriter limits text encoded in base64 to 78 characters per line // qpLineWriter limits text encoded in quoted-printable to 78 characters per", "commit_type": "fix"}
{"commit_tokens": ["update", "syslog", "coverage", "to", "100%"], "add_tokens": "displayColor bool miniTimestamp bool", "del_tokens": "miniTimestamp bool displayColor bool", "commit_type": "update"}
{"commit_tokens": ["fix", "the", "run", "image", "without", "colon", "panic"], "add_tokens": "if len ( fields ) < 2 {", "del_tokens": "if fields == nil {", "commit_type": "fix"}
{"commit_tokens": ["Move", "GetNodeIP", "()", "to", "netutils"], "add_tokens": "selfIP , err = netutils . GetNodeIP ( hostname )", "del_tokens": "selfIP , err = GetNodeIP ( hostname ) func GetNodeIP ( nodeName string ) ( string , error ) { ip := net . ParseIP ( nodeName ) if ip == nil { addrs , err := net . LookupIP ( nodeName ) if err != nil { log . Errorf ( \" \" , nodeName , err ) return \" \" , err } for _ , addr := range addrs { if addr . String ( ) != \" \" { ip = addr break } } } if ip == nil || len ( ip . String ( ) ) == 0 { return \" \" , fmt . Errorf ( \" \" , nodeName ) } return ip . String ( ) , nil }", "commit_type": "move"}
{"commit_tokens": ["fix", "bug", "in", "conn", ".", "SetWriteDeadline"], "add_tokens": "return c . stream . SetWriteDeadline ( t )", "del_tokens": "return c . stream . SetReadDeadline ( t )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tarball", "compressor", "for", "Windows"], "add_tokens": "return c . CompressSpecificFilesInDir ( dir , [ ] string { \" \" } )", "del_tokens": "return c . CompressSpecificFilesInDir ( dir , [ ] string { \" \" } )", "commit_type": "fix"}
{"commit_tokens": ["Add", "-", "save", "test", "flag"], "add_tokens": "\" \" var save bool func init ( ) { flag . BoolVar ( & save , \" \" , false , \" \" ) flag . Parse ( ) } if save { return SavePNG ( name + \" \" , dc . Image ( ) ) } return nil", "del_tokens": "return SavePNG ( name + \" \" , dc . Image ( ) )", "commit_type": "add"}
{"commit_tokens": ["add", "bypass", "support", "for", "proxy", "chain"], "add_tokens": "route , err := h . options . Chain . selectRouteFor ( req . Host ) if err != nil { log . Logf ( \" \" , conn . RemoteAddr ( ) , req . Host , err ) return } lastNode := route . LastNode ( ) h . forwardRequest ( conn , req , route ) cc , err := route . Dial ( host ) func ( h * httpHandler ) forwardRequest ( conn net . Conn , req * http . Request , route * Chain ) { if route . IsEmpty ( ) { lastNode := route . LastNode ( ) cc , err := route . Conn ( )", "del_tokens": "lastNode := h . options . Chain . LastNode ( ) h . forwardRequest ( conn , req ) cc , err := h . options . Chain . Dial ( host ) func ( h * httpHandler ) forwardRequest ( conn net . Conn , req * http . Request ) { if h . options . Chain . IsEmpty ( ) { lastNode := h . options . Chain . LastNode ( ) cc , err := h . options . Chain . Conn ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "register", "commands"], "add_tokens": "import ( \" \" \" \" ) func TestCommandRegister ( t * testing . T ) { cmds := Commands { make ( map [ string ] cmdfunc ) } cmds . Register ( \" \" , func ( ) error { return fmt . Errorf ( \" \" ) } ) cmd := cmds . Find ( \" \" ) err := cmd ( ) if err == nil { t . Fatal ( \" \" ) } if err . Error ( ) != \" \" { t . Fatal ( \" \" ) } }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "large", "logs", "breaking", "Travis", "CI", "buld", "."], "add_tokens": "//t.Log(\"(\", png.Pix[i], \",\", pnm.Pix[i], \")\")", "del_tokens": "t . Log ( \" \" , png . Pix [ i ] , \" \" , pnm . Pix [ i ] , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "defer", "+", "builtin", "."], "add_tokens": "case \" \" , \" \" , \" \" , \" \" , \" \" , \" \" :", "del_tokens": "case \" \" , \" \" : return fmt . Sprintf ( \" \" , o . Name ( ) , strings . Join ( c . translateExprSlice ( e . Args ) , \" \" ) ) case \" \" , \" \" , \" \" , \" \" :", "commit_type": "fix"}
{"commit_tokens": ["Add", "codegen", "memory", "transfer", "ops", "e", ".", "g", ".", "reg", "=", ">", "mem", "reg", "=", ">", "mem", "indirect", "ect"], "add_tokens": "asm += f . Indent + fmt . Sprintf ( \" \" , i , i . Name ( ) ) + \" \\n \" asm = asmMovRegReg ( f . Indent , nameInfo . reg , & tmpReg ) asm += asmMovRegReg ( f . Indent , & tmpReg , assignment . reg )", "del_tokens": "asm = asmMoveRegToReg ( f . Indent , nameInfo . reg , & tmpReg ) asm += asmMoveRegToReg ( f . Indent , & tmpReg , assignment . reg )", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "issue", "by", "using", "text", "/", "template", "instead", "of", "html", "/", "template"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Allow", "bundleURI", "to", "be", "configured"], "add_tokens": "\" \" bundleURI := * flag . String ( \" \" , \" \" , \" \" ) reliable := * flag . Bool ( \" \" , true , \" \" ) numDevs := * flag . Int ( \" \" , 2 , \" \" ) addDevEach := * flag . Duration ( \" \" , 0 * time . Second , \" \" ) upDevEach := * flag . Duration ( \" \" , 0 * time . Second , \" \" ) numDeps := * flag . Int ( \" \" , 2 , \" \" ) upDepEach := * flag . Duration ( \" \" , 0 * time . Second , \" \" ) BundleURI : bundleURI ,", "del_tokens": "reliable := * flag . Bool ( \" \" , true , \" \" ) numDevs := * flag . Int ( \" \" , 2 , \" \" ) addDevEach := * flag . Duration ( \" \" , 0 , \" \" ) upDevEach := * flag . Duration ( \" \" , 0 , \" \" ) numDeps := * flag . Int ( \" \" , 2 , \" \" ) upDepEach := * flag . Duration ( \" \" , 0 , \" \" )", "commit_type": "allow"}
{"commit_tokens": ["fix", "possible", "nil", "pointer", "deref"], "add_tokens": "if s . value != nil { return strings . Join ( * s . value , \" \" ) } return \" \"", "del_tokens": "return strings . Join ( * s . value , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "response", "for", "get", "misses", "since", "the", "binary", "protocol", "responds", "and", "the", "text", "does", "not"], "add_tokens": "defer close ( errorOut ) defer close ( dataOut ) if err == common . MISS || err == common . ERROR_KEY_NOT_FOUND { dataOut <- common . GetResponse { Miss : true , Key : key , //opaque } if err == common . MISS || err == common . ERROR_KEY_NOT_FOUND { dataOut <- common . GetResponse { Miss : true , Key : key , //opaque } dataOut <- common . GetResponse { Miss : true , Key : key , //opaque } Miss : false , // opaque", "del_tokens": "if err == common . MISS { close ( errorOut ) close ( dataOut ) if err == common . MISS { close ( errorOut ) close ( dataOut ) close ( dataOut ) close ( errorOut )", "commit_type": "add"}
{"commit_tokens": ["Add", "initial", "framework", "for", "stats"], "add_tokens": "ErrContainerExited = errors . New ( \" \" ) // Runtime handles containers, containers handle their own actions // Create creates a new container initialized but without it starting it // StartProcess adds a new process to the container", "del_tokens": "// runtime handles containers, containers handle their own actions.", "commit_type": "add"}
{"commit_tokens": ["Fixing", "issue", "when", "node", "is", "offscreen", "and", "more", "."], "add_tokens": "err = ScrollIntoNode ( n ) . Do ( ctxt , h ) }", "del_tokens": "/ * err = dom . Focus ( n . NodeID ) . Do ( ctxt , h ) } * / / * var pos [ ] int64 err = EvaluateAsDevTools ( fmt . Sprintf ( scrollJS , x , y ) , & pos ) . Do ( ctxt , h ) * /", "commit_type": "fix"}
{"commit_tokens": ["adding", "cleanup", "of", "empty", "SubscriptionManager", ".", "ClientSubChannels", "map", "entries"], "add_tokens": "// Remove the client sub map entry for this category if there are // zero clients. This keeps the ClientSubChannels map lean in // the event that there are many categories over time and we // would otherwise keep a bunch of empty sub maps if len ( subCategoryClients ) == 0 { delete ( sm . ClientSubChannels , disconnect . SubscriptionCategory ) } log . Printf ( \" \" , // Remove all client subscriptions since we just sent all the // clients an event. In longpolling, subscriptions only last // until there is data (which just got sent) or a timeout // (which is handled by the disconnect case). // Doing this also keeps the subscription map lean in the event // of many different subscription categories, we don't keep the // trivial/empty map entries. if sm . LoggingEnabled { log . Printf ( \" \" , len ( clients ) , event . Category ) } delete ( sm . ClientSubChannels , event . Category ) } // else no client subscriptions sm . checkExpiredEvents ( buf ) // TODO: make sure this call is trivial when TTL option == FOREVER sm . deleteBufferIfEmpty ( buf , event . Category ) // TODO: Make sure trivial if buffer nonempty (I believe this is the case)", "del_tokens": "log . Printf ( \" \" , // boot this client subscription since we found events // In longpolling, subscriptions only last until there is // data (happening here) or a timeout (handled by the //disconnect case above) // NOTE: it IS safe to delete map entries as you iterate // SEE: http://stackoverflow.com/questions/23229975/is-it-safe-to-remove-selected-keys-from-golang-map-within-a-range-loop if sm . LoggingEnabled { log . Printf ( \" \" , clientUUID . String ( ) ) } delete ( clients , clientUUID ) // TODO: remove entry from sm.ClientSubChannels if the sm.ClientSubChannels entry for that category is empty? // TODO: otherwise won't this container always be as big as the set of category ids ever called? // TODO: can this be made even simpler by deleting the sm.ClientSubChannels entry alltogether instead of one // client at a time and then checking if empty. because wouldn't it always be empty if we remove them??? // TODO: if so, move this to outside this loop (after loop) and delete entire category entry for client subscriptions } sm . checkExpiredEvents ( buf ) sm . deleteBufferIfEmpty ( buf , event . Category )", "commit_type": "add"}
{"commit_tokens": ["Add", "data", "-", "driven", "test", "framework", "for", "lexers", "."], "add_tokens": "Type TokenType `json:\"type\"` Value string `json:\"value\"`", "del_tokens": "Type TokenType Value string", "commit_type": "add"}
{"commit_tokens": ["added", "user", "specified", "headers", "and", "corrected", "bug", "with", "request", "error"], "add_tokens": "Headers map [ string ] string // Add user specified headers for k , v := range c . Headers { req . Header . Set ( k , v ) } return c . Connection . Do ( req )", "del_tokens": "resp , err := c . Connection . Do ( req ) return resp , nil", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "the", "C", "bits", "to", "compile"], "add_tokens": "for key , value := c . first ( ) ; key != nil && index < len ( items ) ; key , value = c . next ( ) { assert . Equal ( t , value , items [ index ] . Value )", "del_tokens": "var k , v C . bolt_val C . bolt_cursor_first ( c , & k , & v ) key := C . GoBytes ( k . data , k . size ) for key != nil && index < len ( items ) { assert . Equal ( t , C . GoBytes ( v . data , v . size ) , items [ index ] . Value ) C . bolt_cursor_next ( c , & k , & v ) key := C . GoBytes ( k . data , k . size )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "ErrNoticeRecoverWAL", "variable", "name", "."], "add_tokens": "ErrNoticeRecoverWAL = ErrNotice . Extend ( 1 )", "del_tokens": "ErrNoticeRecoverWal = ErrNotice . Extend ( 1 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "(", "*", "Section", ")", ".", "NewBooleanKey", "method"], "add_tokens": "_VERSION = \" \"", "del_tokens": "_VERSION = \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "PreQueue", "hook", "and", "do", "a", "little", "code", "reorg"], "add_tokens": "// HookPreQueue is an interface a Logger can implement to be able to inspect // and modify a Message before it is added to the queue type HookPreQueue interface { PreQueue ( msg * Message ) error", "del_tokens": "type PreQueueHook interface {", "commit_type": "add"}
{"commit_tokens": ["Add", "unit", "tests", "to", "gitter", "module"], "add_tokens": "url : streamBaseURL + \" \" + roomID + \" \" ,", "del_tokens": "url : gitterStreamAPI + \" \" + roomID + \" \" ,", "commit_type": "add"}
{"commit_tokens": ["updated", "README", "to", "reflect", "correct", "JSON"], "add_tokens": "\" \" \" \" \" \" \" \" var repo = plugin . Repo { } var build = plugin . Build { } var vargs = struct { Urls [ ] string `json:\"urls\"` } { } plugin . Param ( \" \" , & build ) plugin . Param ( \" \" , & vargs ) // data structure data := struct { Repo plugin . Repo `json:\"repo\"` Build plugin . Build `json:\"build\"` } { repo , build } // json payload that will be posted payload , err := json . Marshal ( & data ) if err != nil { os . Exit ( 1 ) } // post payload to each url for _ , url := range vargs . Urls { resp , err := http . Post ( url , \" \" , bytes . NewBuffer ( payload ) ) if err != nil { os . Exit ( 1 ) } resp . Body . Close ( ) }", "del_tokens": "\" \" repo := plugin . Repo { } commit := plugin . Commit { } plugin . Param ( \" \" , & commit ) fmt . Printf ( \" \\n \" , repo . Owner , repo . Name , commit . Sequence )", "commit_type": "update"}
{"commit_tokens": ["Update", "configure", "test", "removing", "UpstreamId", "from", "LocationUpstreamUpdated"], "add_tokens": "& LocationUpstreamUpdated { Host : host , Location : location } )", "del_tokens": "& LocationUpstreamUpdated { Host : host , Location : location , UpstreamId : \" \" } )", "commit_type": "update"}
{"commit_tokens": ["Use", "side", "to", "set", "sign", "of", "size", "."], "add_tokens": "side string t . side = data . Exec . Side t . output . RawData = & data . Exec size := int ( data . Exec . Shares ) if data . Exec . Side == \" \" { size *= - 1 } Size : size , Time : data . Exec . Time , if v . side == \" \" { v . output . Size *= - 1 }", "del_tokens": "RawData : data . Contract , Side : data . Exec . Side , Size : int ( data . Exec . Shares ) , e . Exchange = con . Exchange e . Side = data . Exec . Side e . Size = int ( data . Exec . Shares ) e . Price = data . Exec . Price e . Time = data . Exec . Time", "commit_type": "use"}
{"commit_tokens": ["Add", "testcases", "for", "ChangeMasterTo", "(", "without", "GTID", ")", "and", "fix", "a", "bug", "of", "it"], "add_tokens": "var host , portStr string var port int if host , portStr , err = net . SplitHostPort ( masterEndpoint ) ; err != nil { return err } if port , err = strconv . Atoi ( portStr ) ; err != nil { _ , err = slaveInst . connection . Exec ( \" \" ,", "del_tokens": "var host , port string if host , port , err = net . SplitHostPort ( masterEndpoint ) ; err != nil { _ , err = slaveInst . connection . Exec ( \" \" ,", "commit_type": "add"}
{"commit_tokens": ["fix", "accidental", "find", "and", "replace", "fail"], "add_tokens": "if strings . HasPrefix ( pid , \" \" ) {", "del_tokens": "if strings . HasPrefix ( pid , \" \" ) {", "commit_type": "fix"}
{"commit_tokens": ["Improve", "the", "comments", "in", "IPAddr", "."], "add_tokens": "// Constants for the sizes of the various IP addresses. // IPPort is the type for an IP port number for the TCP and UDP IP transports. // NewIPAddr creates a new IPAddr from a string. Returns nil if the string is // not an IPv4 or an IPv6 address.", "del_tokens": "// NewIPAddr creates a new IPAddr from a string.", "commit_type": "improve"}
{"commit_tokens": ["added", "method", "to", "get", "details", "of", "a", "scan"], "add_tokens": "//log.Println(nessus.Scans()) log . Println ( nessus . ScanDetails ( 13 ) )", "del_tokens": "log . Println ( nessus . Scans ( ) ) //log.Println(nessus.StartScan(5)) //log.Println(nessus.StopScan(5)) //log.Println(nessus.DeleteScan(5)) //log.Println(nessus.PauseScan(5)) //log.Println(nessus.ResumeScan(5))", "commit_type": "add"}
{"commit_tokens": ["Make", "encoder", "and", "related", "options", "configurable"], "add_tokens": "\" \" format string encoder Encoder value image . Image format : \" \" , encoder : PNGEncoder ( ) , format : \" \" , encoder : JPEGEncoder ( 95 ) , format : \" \" , encoder : BMPEncoder ( ) , c . encoder ( & buf , c . value ) if ! strings . Contains ( c . format , outFormat ) { t . Errorf ( \" \" , \" \" , c . format , outFormat )", "del_tokens": "var encodeFormats = map [ string ] Format { \" \" : PNG , \" \" : JPEG , \" \" : JPEG , \" \" : BMP , } format Format value image . Image format : PNG , format : JPEG , format : BMP , Encode ( & buf , c . value , c . format ) if encodeFormats [ outFormat ] != c . format { t . Errorf ( \" \" , \" \" , c . format , outFormat )", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "help", "command"], "add_tokens": "// Meant to be run on the highest node. Only searches down. if len ( args ) > 0 && c . HasSubCommands ( ) { func ( c * Command ) Root ( ) * Command { return findRoot ( c ) } func ( c * Command ) Commander ( ) * Commander { cmdr := c . Root ( ) // report flag parsing error c . Println ( strings . Split ( err . Error ( ) , \" \\n \" ) [ 0 ] ) erx := cmd . Usage ( ) if erx != nil { return erx }", "del_tokens": "if len ( args ) > 1 && c . HasSubCommands ( ) { func ( c * Command ) Commander ( ) * Commander { cmdr := findRoot ( c ) cmd . Usage ( ) if err != nil { fmt . Println ( err ) }", "commit_type": "add"}
{"commit_tokens": ["Implement", "multipart", "support", "for", "CreateObject", "()"], "add_tokens": "Part [ ] * Part type CompletePart struct { PartNumber int ETag string } Part [ ] * CompletePart", "del_tokens": "Part * [ ] Part Part * [ ] Part", "commit_type": "implement"}
{"commit_tokens": ["Use", "my", "types", "for", "json", "unmarshalling"], "add_tokens": "func ( tr * TumblrRequest ) Get ( requestUrl string , params map [ string ] string ) CompleteResponse { func ( tr * TumblrRequest ) Post ( requestUrl string , params map [ string ] string , files [ ] string ) CompleteResponse { //return tr.PostMultipart(requestUrl, params, files) func ( tr * TumblrRequest ) JSONParse ( content [ ] byte ) CompleteResponse { var data CompleteResponse", "del_tokens": "func ( tr * TumblrRequest ) Get ( requestUrl string , params map [ string ] string ) map [ string ] interface { } { func ( tr * TumblrRequest ) Post ( requestUrl string , params map [ string ] string , files [ ] string ) map [ string ] interface { } { return tr . PostMultipart ( requestUrl , params , files ) func ( tr * TumblrRequest ) JSONParse ( content [ ] byte ) map [ string ] interface { } { data := map [ string ] interface { } { }", "commit_type": "use"}
{"commit_tokens": ["add", "test", "cases", "from", "NIST", "."], "add_tokens": "\" \" \" \" group = & DHGroup { group = & DHGroup { group = & DHGroup {", "del_tokens": "\" \" \" \" group = & DHGroup { group = & DHGroup { group = & DHGroup {", "commit_type": "add"}
{"commit_tokens": ["Move", "bisectRight", "implementation", "to", "internal", "/", "bisect"], "add_tokens": "\" \" pos = bisect . Right ( indexes , index ) - 1", "del_tokens": "\" \" pos = bisectRight ( indexes , index ) - 1 // bisectRight to Locate the insertion point for v in a to maintain sorted order. func bisectRight ( a [ ] int , v int ) int { return bisectRightRange ( a , v , 0 , len ( a ) ) } func bisectRightRange ( a [ ] int , v int , lo , hi int ) int { s := a [ lo : hi ] return sort . Search ( len ( s ) , func ( i int ) bool { return s [ i ] > v } ) }", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "conn , err := http . NewConn ( \" \" , \" \" )", "del_tokens": "conn , err := http . NewConn ( \" \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "for", "server", "continuation", "requests"], "add_tokens": "func ( c * Client ) handleContinuationReqs ( continues chan bool ) { hdlr := make ( imap . RespHandler ) c . addHandler ( hdlr ) defer c . removeHandler ( hdlr ) defer close ( continues ) for h := range hdlr { if _ , ok := h . Resp . ( * imap . ContinuationResp ) ; ok { h . Accept ( ) continues <- true } else { h . Reject ( ) } } } continues := make ( chan bool ) c . writer = imap . NewClientWriter ( c . conn , continues ) go c . handleContinuationReqs ( continues )", "del_tokens": "writer : imap . NewWriter ( conn ) ,", "commit_type": "add"}
{"commit_tokens": ["remove", "trailing", "newline", "to", "avoid", "esty", "statsd", "log", "messages"], "add_tokens": "\" \" expected = strings . TrimSuffix ( expected , \" \\n \" ) expected := \" \"", "del_tokens": "expected := \" \\n \"", "commit_type": "remove"}
{"commit_tokens": ["add", "support", "for", "primary", "keys", "on", "metadata"], "add_tokens": "o . SetMetadata ( \" \" , commit . Id ( ) . String ( ) , MetadataAttributes { } ) o . SetMetadata ( \" \" , tentry . Id . String ( ) , MetadataAttributes { PrimaryKey : true , } ) // TODO: Type of staged. o . SetMetadata ( \" \" , \" \" , MetadataAttributes { } ) repo , err := git . OpenRepositoryExtended ( source , git . RepositoryOpenCrossFs , \" \" )", "del_tokens": "Metadata : map [ string ] string { \" \" : commit . Id ( ) . String ( ) , \" \" : tentry . Id . String ( ) , } , Metadata : map [ string ] string { \" \" : \" \" , } , var repo * git . Repository var err error repo , err = git . OpenRepositoryExtended ( source , git . RepositoryOpenCrossFs , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "client", "to", "handle", "event", "errors", "(", "ignore", "or", "close", "ConsumerGroup", ")", ";", "currently", "breaking", "out", "of", "loop", "on", "error", "only", "stops", "this", "partition", "consumer", "while", "other", "partition", "consumers", "are", "left", "running", "and", "the", "client", "is", "left", "unaware"], "add_tokens": "if event . Err == nil { lastOffset = event . Offset }", "del_tokens": "if event . Err != nil { err = event . Err break partitionConsumerLoop } lastOffset = event . Offset", "commit_type": "allow"}
{"commit_tokens": ["fixed", "handling", "of", "quoted", "strings", "starting", "with", "-"], "add_tokens": "case strings . Contains ( value , \" \" ) : // Must be an arg! if argIdx , e = a . handleArgs ( value , argIdx ) ; e != nil { return e } if argIdx , e = a . handleArgs ( value , argIdx ) ; e != nil { return e func ( a * action ) handleArgs ( value string , index int ) ( int , error ) { if arg := a . argumentForPosition ( index ) ; arg != nil { arg . setValue ( value ) return index + 1 , nil } return - 1 , fmt . Errorf ( \" \" ) }", "del_tokens": "arg := a . argumentForPosition ( argIdx ) if arg != nil { arg . setValue ( value ) } else { return fmt . Errorf ( \" \" ) argIdx += 1", "commit_type": "fix"}
{"commit_tokens": ["Use", "dedicated", "http", "client", "for", "datadog", "POST"], "add_tokens": "client * http . Client client : & http . Client { } , if err := json . NewEncoder ( body ) . Encode ( & series ) ; err != nil { return err } req , err := http . NewRequest ( \" \" , c . URL + \" \" + c . apiKey , body ) req . Header . Set ( \" \" , \" \" ) resp , err := c . client . Do ( req )", "del_tokens": "err := json . NewEncoder ( body ) . Encode ( & series ) url := c . URL + \" \" + c . apiKey resp , err := http . Post ( url , \" \" , body )", "commit_type": "use"}
{"commit_tokens": ["Added", "option", "to", "stop", "parsing", "after", "first", "non", "option"], "add_tokens": "// Pass all arguments after the first non option. This is equivalent // to strict POSIX processing PassAfterNonOption if ( p . Options & PassAfterNonOption ) != None { ret = append ( ret , args [ ( i - 1 ) : ] ... ) break } else { ret = append ( ret , arg ) }", "del_tokens": "ret = append ( ret , arg )", "commit_type": "add"}
{"commit_tokens": ["Fix", "null", "pointer", "dereference", "for", "go", "-", "hyphenated", "packages"], "add_tokens": "spec , found := importedSpecs [ prefixIdent . Name ] if ! found { return }", "del_tokens": "spec := importedSpecs [ prefixIdent . Name ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "IPv6", "format", "for", "ipvs"], "add_tokens": "{ LocalAddress : net . ParseIP ( \" \" ) , LocalPort : 80 , RemoteAddress : net . ParseIP ( \" \" ) , RemotePort : 80 , Proto : \" \" , Weight : 1 , ActiveConn : 0 , InactConn : 0 , } , { LocalAddress : net . ParseIP ( \" \" ) , LocalPort : 80 , RemoteAddress : net . ParseIP ( \" \" ) , RemotePort : 80 , Proto : \" \" , Weight : 1 , ActiveConn : 0 , InactConn : 0 , } , { LocalAddress : net . ParseIP ( \" \" ) , LocalPort : 80 , RemoteAddress : net . ParseIP ( \" \" ) , RemotePort : 80 , Proto : \" \" , Weight : 1 , ActiveConn : 1 , InactConn : 1 , } , gotIP , gotPort , err := parseIPPort ( \" \" )", "del_tokens": "gotIP , gotPort , err := parseIPPort ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "CHANGELOG", ".", "md", "and", "Update", "version"], "add_tokens": "version string = \" \"", "del_tokens": "version string = \" \"", "commit_type": "add"}
{"commit_tokens": ["Adding", "Support", "for", "Environment", "variable", "prefixes"], "add_tokens": "envPrefix string // Define a prefix that ENVIRONMENT variables will use. func SetEnvPrefix ( in string ) { v . SetEnvPrefix ( in ) } func ( v * viper ) SetEnvPrefix ( in string ) { if in != \" \" { v . envPrefix = in } } func ( v * viper ) mergeWithEnvPrefix ( in string ) string { if v . envPrefix != \" \" { return v . envPrefix + \" \" + in } return in } // EnvPrefix will be used when set when env name is not provided. envkey = strings . ToUpper ( v . mergeWithEnvPrefix ( key ) )", "del_tokens": "envkey = strings . ToUpper ( key )", "commit_type": "add"}
{"commit_tokens": ["Use", "testify", "to", "make", "real", "assertions", "."], "add_tokens": "return calCamMat , rvec , tvec } // Same as cv::Rodrigues func GcvRodrigues ( src * mat64 . Dense ) ( dst * mat64 . Dense ) { gcvSrc := Mat64ToGcvMat ( src ) gcvDst := NewGcvMat ( ) GcvRodrigues_ ( gcvSrc , gcvDst ) dst = GcvMatToMat64 ( gcvDst ) return dst", "del_tokens": "return camMat , rvec , tvec", "commit_type": "use"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", ".", "json"], "add_tokens": "Location * Location `json:\"location\"` // Location to continue to. TargetCallFrames ContinueToLocationTargetCallFrames `json:\"targetCallFrames,omitempty\"` // WithTargetCallFrames [no description]. func ( p ContinueToLocationParams ) WithTargetCallFrames ( targetCallFrames ContinueToLocationTargetCallFrames ) * ContinueToLocationParams { p . TargetCallFrames = targetCallFrames return & p }", "del_tokens": "Location * Location `json:\"location\"` // Location to continue to.", "commit_type": "update"}
{"commit_tokens": ["Allow", "BeNumerically", "to", "support", "thresholds", "for", "integers", "and", "unsigned", "integers"], "add_tokens": "Context ( \" \" , func ( ) { It ( \" \" , func ( ) { Ω( 5 ) . S hould( B eNumerically( \" ~ , ) ) Ω( 5 ) . S houldNot( B eNumerically( \" ~ , ) ) Ω( u int( 5 ) ) . S houldNot( B eNumerically( \" ~ , ) ) } ) } ) Context ( \" \" , func ( ) { It ( \" \" , func ( ) { Ω( 5 ) . S hould( B eNumerically( \" ~ , , ) ) Ω( 5 ) . S houldNot( B eNumerically( \" ~ , , ) ) Ω( u int( 5 ) ) . S hould( B eNumerically( \" ~ , , ) ) } )", "del_tokens": "It ( \" \" , func ( ) { Ω( 5 ) . S hould( B eNumerically( \" ~ , , 0) ) Ω( 5 ) . S houldNot( B eNumerically( \" ~ , , 0) ) Ω( 5 .0) . S hould( B eNumerically( \" ~ , .0, 0) )", "commit_type": "allow"}
{"commit_tokens": ["Make", "TxLoc", "comment", "consistent", "with", "others", "."], "add_tokens": "// TxLoc returns the offsets and lengths of each transaction in a raw block.", "del_tokens": "// TxLoc() returns the offsets and lengths of each transaction in a raw block.", "commit_type": "make"}
{"commit_tokens": ["Added", "box", "around", "code", "error", "message", "and", "comain"], "add_tokens": "finalString := fmt . Sprintf ( \" \" , this . Code ) finalString = finalString + fmt . Sprintf ( \" \" , this . error ) finalString = finalString + fmt . Sprintf ( \" \" , this . message ) finalString = finalString + fmt . Sprintf ( \" \" , this . Domain )", "del_tokens": "finalString := fmt . Sprintf ( \" \" , this . Code ) finalString = finalString + fmt . Sprintf ( \" \" , this . error ) finalString = finalString + fmt . Sprintf ( \" \" , this . message ) finalString = finalString + fmt . Sprintf ( \" \" , this . Domain )", "commit_type": "add"}
{"commit_tokens": ["Add", "travis", "build", "CI", "."], "add_tokens": "func blockAVX ( p [ ] uint8 , in , iv , t , f , shffle , out [ ] uint64 ) func compressAVX ( d * digest , p [ ] uint8 ) { blockAVX ( p , in , iv [ : ] , d . t [ : ] , d . f [ : ] , shffle , out ) // Verifies if AVX is available, use optimized code path. compressAVX ( d , p ) } // else { fallback to generic approach.", "del_tokens": "func blockSSE ( p [ ] uint8 , in , iv , t , f , shffle , out [ ] uint64 ) func compressSSE ( d * digest , p [ ] uint8 ) { blockSSE ( p , in , iv [ : ] , d . t [ : ] , d . f [ : ] , shffle , out ) compressSSE ( d , p ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "docstring", "of", "StreamClientInterceptor", "(", "golint", ")"], "add_tokens": "// StreamClientInterceptor is a gRPC client-side interceptor that provides Prometheus monitoring for Streaming RPCs.", "del_tokens": "// StreamServerInterceptor is a gRPC client-side interceptor that provides Prometheus monitoring for Streaming RPCs.", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "of", "TLS", "connections"], "add_tokens": "config amqp . Config // set default Heartbeat to 10 seconds like in original amqp.Dial if c . config . Heartbeat == 0 { c . config . Heartbeat = 10 * time . Second } conn , err = amqp . DialConfig ( c . addr , c . config ) // Config is a functional option, used to setup extended amqp configuration func Config ( config amqp . Config ) ClientOpt { return func ( c * Client ) { c . config = config } }", "del_tokens": "conn , err = amqp . Dial ( c . addr )", "commit_type": "add"}
{"commit_tokens": ["Fix", "writing", "of", "block", "size"], "add_tokens": "bLen := uint32 ( len ( zb . zdata ) ) bLen |= 1 << 31", "del_tokens": "bLen := int32 ( len ( zb . zdata ) ) bLen = - bLen", "commit_type": "fix"}
{"commit_tokens": ["Adds", "build", "flags", "to", "bundler", "."], "add_tokens": "// Build flags to pass into go build BuildFlags map [ string ] string `json:\"build_flags\"` buildFlags map [ string ] string if len ( c . BuildFlags ) > 0 { b . buildFlags = c . BuildFlags } args := [ ] string { \" \" , \" \" , std . String ( ) } var flag string for k , v := range b . buildFlags { if hasDash := strings . HasPrefix ( k , \" \" ) ; hasDash { flag = k } else { flag = \" \" + k } args = append ( args , flag , v ) } var binaryPath = filepath . Join ( environmentPath , \" \" ) args = append ( args , \" \" , binaryPath , b . pathBuild ) var cmd = exec . Command ( b . pathGoBinary , args ... )", "del_tokens": "var binaryPath = filepath . Join ( environmentPath , \" \" ) var cmd = exec . Command ( b . pathGoBinary , \" \" , \" \" , std . String ( ) , \" \" , binaryPath , b . pathBuild )", "commit_type": "add"}
{"commit_tokens": ["Use", "utf8", ".", "RuneCountInString", "()", "rather", "than", "len", "()", ":", "("], "add_tokens": "\" \" state . Pos += utf8 . RuneCountInString ( groups [ 0 ] )", "del_tokens": "state . Pos += len ( groups [ 0 ] )", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "from", "previous", "commit"], "add_tokens": "case strings . TrimSpace ( c . Region ) != \" \" :", "del_tokens": "case strings . TrimSpace ( c . Endpoint ) != \" \" && strings . TrimSpace ( c . Region ) != \" \" :", "commit_type": "fix"}
{"commit_tokens": ["Change", "findTest", "to", "return", "the", "most", "recently", "added", "test"], "add_tokens": "for i := len ( tests ) - 1 ; i >= 0 ; i -- {", "del_tokens": "for i := 0 ; i < len ( tests ) ; i ++ {", "commit_type": "change"}
{"commit_tokens": ["Changed", "node", "uptime", "in", "nodeinfo", "struct", "to", "uint64"], "add_tokens": "RunQueueLength uint32 `json:\"run_queue\"` Processors uint32 `json:\"processors\"` Uptime uint64 `json:\"uptime\"`", "del_tokens": "RunQueueLength uint32 `json:\"run_queue\"` Processors uint32 `json:\"processors\"` Uptime uint32 `json:\"uptime\"`", "commit_type": "change"}
{"commit_tokens": ["Use", "proper", "fd", "when", "retrieving", "console", "size", "on", "windows"], "add_tokens": "info , err := winterm . GetConsoleScreenBufferInfo ( m . out )", "del_tokens": "info , err := winterm . GetConsoleScreenBufferInfo ( m . in )", "commit_type": "use"}
{"commit_tokens": ["Fix", "missing", "delay", "before", "second", "attempt"], "add_tokens": "return config . delay * ( 1 << n )", "del_tokens": "return config . delay * ( 1 << ( n - 1 ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "handler", "for", "SlaveLost", "message", "."], "add_tokens": "SlaveLost func ( SchedulerDriver , * mesos . SlaveID )", "del_tokens": "SlaveLost func ( * SchedulerDriver , * mesos . SlaveID )", "commit_type": "add"}
{"commit_tokens": ["Updated", "credits", "to", "add", "Steven", "Gutzwiller"], "add_tokens": "mostRecentlyStartedToken = strings . ToLower ( token . Data ) if mostRecentlyStartedToken == strings . ToLower ( token . Data ) { switch mostRecentlyStartedToken {", "del_tokens": "mostRecentlyStartedToken = token . Data if mostRecentlyStartedToken == token . Data { switch strings . ToLower ( mostRecentlyStartedToken ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "binding", "of", "handlers", "to", "the", "router"], "add_tokens": "UrlLength ( ) int func ( this * shortyImpl ) UrlLength ( ) int { return this . settings . UrlLength }", "del_tokens": "Redirect404 string", "commit_type": "add"}
{"commit_tokens": ["Make", "user", "component", "a", "standalone", "micro", "service"], "add_tokens": "\" \" \" \" \" \" \" \" dbconn . DB . DropTable ( & service . Entity { } ) if ! r . Create ( service . Entity { t . Error ( \" \" ) if r . Create ( service . Entity { var entityToDelete service . Entity", "del_tokens": "\" \" \" \" \" \" \" \" dbconn . DB . DropTable ( & dbmodel . Entity { } ) if ! r . Create ( dbmodel . Entity { t . Error ( \" \" ) if r . Create ( dbmodel . Entity { var entityToDelete dbmodel . Entity", "commit_type": "make"}
{"commit_tokens": ["fix", "name", "of", "identity", "multihash"], "add_tokens": "\" \" : ID , ID : \" \" ,", "del_tokens": "\" \" : ID , ID : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "new", "context", "for", "publish", "to", "async", "operations", "work", "outside", "of", "rpc", "s"], "add_tokens": "ok , err := t . Exists ( context . Background ( ) ) t , err = g . client . CreateTopic ( context . Background ( ) , name )", "del_tokens": "ok , err := t . Exists ( ctx ) t , err = g . client . CreateTopic ( ctx , name )", "commit_type": "use"}
{"commit_tokens": ["Make", "separate", "nsinit", "pkg", "for", "a", "dockerinit", "like", "init"], "add_tokens": "if err := Setns ( fd , uintptr ( flag ) ) ; err != nil {", "del_tokens": "\" \" \" \" \" \" \" \" \" \" // CreateNewNamespace creates a new namespace and binds it's fd to the specified path func CreateNewNamespace ( namespace libcontainer . Namespace , bindTo string ) error { var ( flag = namespaceMap [ namespace ] name = namespaceFileMap [ namespace ] nspath = filepath . Join ( \" \" , name ) ) // TODO: perform validation on name and flag pid , err := fork ( ) if err != nil { return err } if pid == 0 { if err := unshare ( flag ) ; err != nil { writeError ( \" \" , err ) } if err := mount ( nspath , bindTo , \" \" , syscall . MS_BIND , \" \" ) ; err != nil { writeError ( \" \" , err ) } os . Exit ( 0 ) } exit , err := utils . WaitOnPid ( pid ) if err != nil { return err } if exit != 0 { return fmt . Errorf ( \" \" , exit ) } return err } if err := setns ( fd , uintptr ( flag ) ) ; err != nil {", "commit_type": "make"}
{"commit_tokens": ["Make", "it", "obvious", "what", "we", "do", "with", "that", "defer"], "add_tokens": "// until a new Get() is called. During a Get(), If there is no new connection // available in the pool, a new connection will be created via the Factory() // method. // wrap our connection with out custom net.Conn implementation that puts // the connection back to the pool if it's closed. conn = c . wrapConn ( conn ) case conn = <- conns :", "del_tokens": "// until a new Get() is called. conn = c . newConn ( conn ) case conn := <- conns :", "commit_type": "make"}
{"commit_tokens": ["Added", "assertion", "about", "contexts", "getting", "cleaned", "up"], "add_tokens": "defer Enter ( ) . Put ( \" \" , 6 ) . Exit ( ) defer Enter ( ) . Put ( \" \" , 7 ) . Exit ( ) allmx . RLock ( ) assert . Empty ( t , contexts , \" \" ) allmx . RUnlock ( )", "del_tokens": "Enter ( ) . Put ( \" \" , 6 ) Enter ( ) . Put ( \" \" , 7 )", "commit_type": "add"}
{"commit_tokens": ["add", "Asc", "and", "Desc", "methods"], "add_tokens": "\" \" engine . ShowSQL = true engine . Pool . SetMaxConns ( 5 ) runtime . GOMAXPROCS ( 2 )", "del_tokens": "engine . Pool . SetMaxConns ( 50 ) //conns := atomic.LoadInt32(&xorm.ConnectionNum) //fmt.Println(\"connection number:\", conns)", "commit_type": "add"}
{"commit_tokens": ["Adds", "Delete", "Adds", "Get", "to", "GTMWideIPs"], "add_tokens": "// GetGTMWideIPs returns a list of all WideIps for a provided type func ( b * BigIP ) GetGTMWideIPs ( recordType GTMType ) ( * GTMWideIPs , error ) { // DeleteGTMWideIP removes a WideIp by config to the BIG-IP system. func ( b * BigIP ) DeleteGTMWideIP ( fullPath string , recordType GTMType ) error { return b . delete ( uriGtm , uriWideIp , string ( recordType ) , fullPath ) }", "del_tokens": "// GTMWideIPs returns a list of all WideIps for a provided type func ( b * BigIP ) GTMWideIPs ( recordType GTMType ) ( * GTMWideIPs , error ) {", "commit_type": "add"}
{"commit_tokens": ["implemented", "wrapped", "API", "for", "using", "with", "context"], "add_tokens": "router := New ( ) . UsingContext ( ) router . TreeMux ( ) . HeadCanUseGet = headCanUseGet cg := router . NewContextGroup ( \" \" ) . NewContextGroup ( \" \" ) cg . GET ( \" \" , makeHandler ( \" \" ) ) cg . POST ( \" \" , makeHandler ( \" \" ) ) cg . PATCH ( \" \" , makeHandler ( \" \" ) ) cg . PUT ( \" \" , makeHandler ( \" \" ) ) cg . DELETE ( \" \" , makeHandler ( \" \" ) ) router . Handle ( \" \" , \" \" , makeHandler ( \" \" ) )", "del_tokens": "router := New ( ) router . HeadCanUseGet = headCanUseGet g := router . NewGroup ( \" \" ) . NewGroup ( \" \" ) g . HandleWithContext ( \" \" , \" \" , makeHandler ( \" \" ) ) g . HandleWithContext ( \" \" , \" \" , makeHandler ( \" \" ) ) g . HandleWithContext ( \" \" , \" \" , makeHandler ( \" \" ) ) g . HandleWithContext ( \" \" , \" \" , makeHandler ( \" \" ) ) g . HandleWithContext ( \" \" , \" \" , makeHandler ( \" \" ) ) router . HandleWithContext ( \" \" , \" \" , makeHandler ( \" \" ) )", "commit_type": "implement"}
{"commit_tokens": ["Remove", "line", "consumption", "and", "make", "execute", "triggers", "in", "goroutines"], "add_tokens": "go t . Action ( bot , msg ) bot . Incoming <- msg", "del_tokens": "consumed := false consumed = t . Action ( bot , msg ) if consumed { break } } if ! consumed { bot . Incoming <- msg", "commit_type": "remove"}
{"commit_tokens": ["use", "Default", "to", "forgo", "prompt"], "add_tokens": "Default : \" \" , Default : \" \" , Default : \" \" , Default : \" \" , Default : \" \" , Default : \" \" ,", "del_tokens": "DefaultFunc : envDefaultFunc ( \" \" ) , DefaultFunc : envDefaultFunc ( \" \" ) , DefaultFunc : envDefaultFunc ( \" \" ) , DefaultFunc : envDefaultFunc ( \" \" ) , DefaultFunc : envDefaultFunc ( \" \" ) , DefaultFunc : envDefaultFunc ( \" \" ) ,", "commit_type": "use"}
{"commit_tokens": ["Adding", "support", "to", "publish", "on", "custom", "host", "port", "ranges"], "add_tokens": "\" \" func toInt ( s string ) uint64 { i , _ , err := parsers . ParsePortRange ( s )", "del_tokens": "\" \" func toInt ( s string ) int64 { i , err := strconv . ParseInt ( s , 10 , 64 )", "commit_type": "add"}
{"commit_tokens": ["Make", "deadline", "exceeded", "message", "more", "usefu", "."], "add_tokens": "warning ( \" \" , state . name )", "del_tokens": "warning ( \" \" , state . name )", "commit_type": "make"}
{"commit_tokens": ["fixed", "a", "empty", "string", "check", "condition", "which", "was", "backwards"], "add_tokens": "log . Printf ( \" \\n \" , cluster ) log . Printf ( \" \\n \" , byName ) log . Printf ( \" \\n \" , jq . AsString ( \" \" ) , name , ip , byName [ name ] ) log . Printf ( \" \\n \" , err ) if ip != \" \" {", "del_tokens": "log . Printf ( \" \\n \" , jq . AsString ( \" \" ) , name , ip ) log . Println ( \" \" ) if ip == \" \" {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "caller", "to", "provide", "bytehash", "to", "buzhash"], "add_tokens": "window [ ] byte oldest int bytearray [ 256 ] uint32 return & digest { sum : 0 , window : nil , oldest : 0 , bytearray : bytehash } } // NewFromByteArray returns a buzhash based on the provided table uint32 values. func NewFromByteArray ( b [ 256 ] uint32 ) rollinghash . Hash32 { return & digest { sum : 0 , window : nil , oldest : 0 , bytearray : b }", "del_tokens": "window [ ] byte oldest int return & digest { sum : 0 , window : nil , oldest : 0 }", "commit_type": "allow"}
{"commit_tokens": ["add", "tests", "for", "string", "encoding"], "add_tokens": "enc . AddStringKeyOmitEmpty ( \" \" , \" \" )", "del_tokens": "enc . AddStringKey ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Move", "things", "around", "lay", "out", "framework", "for", "transport", "/", "dispatch", "logic"], "add_tokens": "\" \" Transport interfaces . Transporter Dispatch interfaces . Dispatcher go service . ProcessMapper . Run ( )", "del_tokens": "\" \" \" \" type Stats struct { MessageInCount int MessageOutCount int MessageProcessedCount int Uptime int MemoryUsed int } type Connection struct { Conn net . Conn Encoder * gob . Encoder Decoder * gob . Decoder } Port string PortHttp string Transport * Transporter Dispatcher * Dispatcher ////////////////////////////////////////////////", "commit_type": "move"}
{"commit_tokens": ["Added", "gzip", "and", "logrus", "and", "changed", "the", "API", "slightly", "."], "add_tokens": "func Buffer ( next http . Handler ) http . Handler { next . ServeHTTP ( bw , r )", "del_tokens": "func Buffer ( h http . Handler ) http . Handler { h . ServeHTTP ( bw , r )", "commit_type": "add"}
{"commit_tokens": ["Add", "heimdall", "as", "http", "client"], "add_tokens": "\" \" Client heimdall . Client initalTimeout := 2 * time . Millisecond maxTimeout := 1000 * time . Millisecond exponentFactor := 2.0 maximumJitterInterval := 2 * time . Millisecond backoff := heimdall . NewExponentialBackoff ( initalTimeout , maxTimeout , exponentFactor , maximumJitterInterval ) client := heimdall . NewHTTPClient ( 1 * time . Second ) client . SetRetrier ( heimdall . NewRetrier ( backoff ) ) client . SetRetryCount ( 4 ) client . SetCustomHTTPClient ( & http . Client { Transport : DefaultTransport , } ) Client : client ,", "del_tokens": "Client * http . Client Client : & http . Client { Transport : DefaultTransport , } ,", "commit_type": "add"}
{"commit_tokens": ["Adding", "Unmarshalling", "pre", "-", "req", "support", "in", "RowUpdate", "and", "Notation"], "add_tokens": "if _ , ok := newRow . Fields [ \" \" ] ; ok { name := newRow . Fields [ \" \" ] . ( string )", "del_tokens": "if newRow != nil { name := newRow [ \" \" ] . ( string )", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "s3", "key", "is", "properly", "URL", "encoded", "for", "keys", "with", "special", "characters"], "add_tokens": "\" \" \" \" o := s3 . Object ( fmt . Sprintf ( \" \" , time . Now ( ) . UnixNano ( ) ) )", "del_tokens": "o := s3 . Object ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "assembler", "disassembler"], "add_tokens": "// BPF_MOD is BPF_MOD - it is supported in Linux from v3.7+, but not in go's syscall... // BPF_XOR is BPF_XOR - it is supported in Linux from v3.7+, but not in go's syscall...", "del_tokens": "// These exist from Linux kernel v3.7+ // Not sure if we should emulate them in the compiler or trying to detect linux version or something", "commit_type": "add"}
{"commit_tokens": ["Implement", "escapable", "characters", "in", "strings"], "add_tokens": "func TestStringEscapables ( t * testing . T ) { tree , err := Load ( \" \\\" \\\\ \\\" \" ) assertTree ( t , tree , err , map [ string ] interface { } { \" \" : \" \\n \" , } ) tree , err = Load ( \" \\\" \\\\ \\\" \" ) assertTree ( t , tree , err , map [ string ] interface { } { \" \" : \" \\t \" , } ) tree , err = Load ( \" \\\" \\\\ \\\" \" ) assertTree ( t , tree , err , map [ string ] interface { } { \" \" : \" \\r \" , } ) tree , err = Load ( \" \\\" \\\\ \\\\ \\\" \" ) assertTree ( t , tree , err , map [ string ] interface { } { \" \" : \" \\\\ \" , } ) } \" \" : \" \\n \" ,", "del_tokens": "fmt . Println ( \" \" ) fmt . Println ( \" \" ) \" \" : \" \\n \" ,", "commit_type": "implement"}
{"commit_tokens": ["fix", "native", "size", "/", "off", "types", "and", "write", "PtrSize", "test"], "add_tokens": "if defTypeOk { fd . Type = fd . defType } else { err = errors . New ( \" \" ) }", "del_tokens": "if defTypeOk { fd . Type = fd . defType return } err = errors . New ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "pausing", "streams"], "add_tokens": "\" \" select { default : runtime . Gosched ( ) case msg := <- shared . GetFeedbackQueue ( ) : cons . route ( msg ) }", "del_tokens": "msg := <- shared . GetFeedbackQueue ( ) cons . route ( msg )", "commit_type": "add"}
{"commit_tokens": ["adding", "create", "table", "insert", "and", "select"], "add_tokens": "\" \" _ \" \" log . Printf ( \" \" ) if _ , crErr := models . CreatePersonTable ( db ) ; crErr != nil { log . Fatalf ( \" \" , crErr ) } log . Printf ( \" \" ) person := models . Person { FirstName : \" \" , LastName : \" \" , Age : 29 } log . Printf ( \" \" , person ) if _ , insErr := models . InsertPerson ( db , person ) ; insErr != nil { log . Fatalf ( \" \" , insErr ) } log . Printf ( \" \" ) log . Printf ( \" \" ) retPerson := models . Person { } if err := models . SelectPerson ( db , person . FirstName , person . LastName , person . Age , & retPerson ) ; err != nil { log . Fatalf ( \" \" , err ) } log . Printf ( \" \" , retPerson )", "del_tokens": "_ \" \"", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "hide", "all", "standard", "deps", "in", "import", "graph"], "add_tokens": "// DepLevel specifies the level of depdenencies to show in an import graph. type DepLevel int const ( ShowAllDeps DepLevel = iota // show all dependencies HideStandardDeps // don't show dependencies of standard libraries HideStandardAll // don't show standard libraries at all ) func ( db * Database ) ImportGraph ( pdoc * doc . Package , level DepLevel ) ( [ ] Package , [ ] [ 2 ] int , error ) { if level >= HideStandardAll && isStandardPackage ( path ) { continue } if level >= HideStandardDeps && isStandardPackage ( path ) { continue }", "del_tokens": "func ( db * Database ) ImportGraph ( pdoc * doc . Package , hideStdDeps bool ) ( [ ] Package , [ ] [ 2 ] int , error ) { if hideStdDeps && isStandardPackage ( nodes [ i ] . Path ) { continue }", "commit_type": "add"}
{"commit_tokens": ["Changed", "gocheck", "repo", "to", "use", "a", "github", "clone", "so", "we", "don", "t", "need", "bzr"], "add_tokens": ". \" \"", "del_tokens": ". \" \"", "commit_type": "change"}
{"commit_tokens": ["add", "goutil", ".", "WriteImportpath", "fixed", "stupid", "termcolor", "mistake"], "add_tokens": "BLACK = \" \" BLUE = \" \" BLACK : 3 , BLUE : 2 , Black = Bg ( BLACK ) Blue = Bg ( ( BLUE ) )", "del_tokens": "BLUE = \" \" BLACK = \" \" BLUE : 2 , BLACK : 3 , Blue = Bg ( ( BLUE ) ) Black = Bg ( BLACK )", "commit_type": "add"}
{"commit_tokens": ["Change", "bsd", "backend", "to", "watch", "files", "after", "triggering", "create", "events", "."], "add_tokens": "\" \" if fi . Mode ( ) & os . ModeSymlink == os . ModeSymlink { path , err := filepath . EvalSymlinks ( path ) if err != nil { filePath := filepath . Join ( dirPath , fileInfo . Name ( ) ) filePath := filepath . Join ( dirPath , fileInfo . Name ( ) ) w . watchDirectoryFiles ( dirPath )", "del_tokens": "\" \" for fi . Mode ( ) & os . ModeSymlink == os . ModeSymlink { path , errstat = os . Readlink ( path ) if errstat != nil { filePath := path . Join ( dirPath , fileInfo . Name ( ) ) w . watchDirectoryFiles ( dirPath ) filePath := path . Join ( dirPath , fileInfo . Name ( ) )", "commit_type": "change"}
{"commit_tokens": ["Added", "individual", "Header", "type", "for", "more", "readable", "header", "managment"], "add_tokens": "db . Headers = new ( FileHeaders ) err = db . Headers . ReadFrom ( d . r ) }", "del_tokens": "h , err := ReadHeaders ( d . r ) db . Headers = h }", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "take", "1", "-", "255", "as", "valid", "VRID", "."], "add_tokens": "if id < 1 || id > 255 { log . Exitf ( \" \" , id )", "del_tokens": "if id < 0 || id > 255 { log . Exitf ( \" \" , id )", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "we", "signal", "even", "during", "an", "error", "..."], "add_tokens": "} else { value , err := b . decodeValue ( bytes , flags , valuePtr ) if err != nil { errOut = err } else { valOut = value casOut = cas } } else { casOut = cas } else { valOut = value casOut = cas", "del_tokens": "return } value , err := b . decodeValue ( bytes , flags , valuePtr ) if err != nil { errOut = err return valOut = value casOut = cas return casOut = cas return valOut = value casOut = cas", "commit_type": "make"}
{"commit_tokens": ["Fix", "unmarshalling", "struct", "with", "custom", "json", "tag", "claim"], "add_tokens": "StrInt StrInt `json:\"custom_field\"`", "del_tokens": "StrInt StrInt", "commit_type": "fix"}
{"commit_tokens": ["Using", "filepath", "instead", "of", "path"], "add_tokens": "\" \" dir , file := filepath . Split ( file ) file = filepath . Join ( file , indexFile )", "del_tokens": "spath \" \" dir , file := spath . Split ( file ) file = spath . Join ( file , indexFile )", "commit_type": "use"}
{"commit_tokens": ["Fix", "typo", "in", "EthEstimateGas", "."], "add_tokens": "return 0 , err", "del_tokens": "return 0 , nil", "commit_type": "fix"}
{"commit_tokens": ["Remove", "yet", "another", "useless", "String", "()", "method"], "add_tokens": "t . Errorf ( \" \" , t1 , t2 , serialized )", "del_tokens": "t . Errorf ( \" \" , t1 , t2 , serialized )", "commit_type": "remove"}
{"commit_tokens": ["add", "DriverName", "to", "the", "dialect", "interface", "(", "required", "for", "interfacing", "with", "newer", "sqlx", ")", "and", "change", "NewDbMap", "to", "work", "with", "newer", "sqlx"], "add_tokens": "return & DbMap { Db : db , Dialect : dialect , Dbx : sqlx . NewDb ( db , dialect . DriverName ( ) ) }", "del_tokens": "return & DbMap { Db : db , Dialect : dialect , Dbx : & sqlx . DB { * db } }", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "atom", "elements", "to", "the", "feed", "object"], "add_tokens": "time . RFC822 , // RSS time . RFC822Z , // RSS time . RFC3339 , // Atom", "del_tokens": "time . RFC822 , time . RFC822Z , time . RFC3339 ,", "commit_type": "add"}
{"commit_tokens": ["Add", "blockheight", "argument", "to", "Proof"], "add_tokens": "// Proof fulfills the TMSP app interface. key is the one for which we // request a proof. blockHeight is the height for which we want the proof. // If blockHeight is 0, return the last commit. func ( app * MerkleEyesApp ) Proof ( key [ ] byte , blockHeight int ) tmsp . Result { // TODO: support older commits - right now we don't save the info if blockHeight != 0 { return tmsp . ErrInternalError . SetLog ( \" \" ) } proof , exists := app . state . Committed ( ) . Proof ( key ) if ! exists { return tmsp . NewResultOK ( nil , \" \" ) }", "del_tokens": "func ( app * MerkleEyesApp ) Proof ( key [ ] byte ) tmsp . Result { // TODO: we really need to return some sort of error if not there... but what? proof , _ := app . state . Committed ( ) . Proof ( key )", "commit_type": "add"}
{"commit_tokens": ["Make", "(", "z", "val", ")", "and", "(", "n", "val", ")", "accept", "0", "arguments", ".", "This", "allows", "tests", "like", "(", "z", "$var", ")", "where", "$var", "is", "unset", "."], "add_tokens": "switch nargs { case 0 : res = true case 1 : default : err = fmt . Errorf ( \" \" , nargs ) switch nargs { case 0 : res = false case 1 : default : err = fmt . Errorf ( \" \" , nargs )", "del_tokens": "if nargs != 1 { err = fmt . Errorf ( \" \" , nargs ) } else { if nargs != 1 { err = fmt . Errorf ( \" \" , nargs ) } else {", "commit_type": "make"}
{"commit_tokens": ["Implement", "and", "test", "a", "Refresh", "method", "for", "jobs"], "add_tokens": "t1 . scanJobById ( job . id , job )", "del_tokens": "args = redis . Args { job . key ( ) } t1 . command ( \" \" , args , newScanJobHandler ( job ) )", "commit_type": "implement"}
{"commit_tokens": ["making", "nfs", "driver", "use", "the", "builtin", "enumerator"], "add_tokens": "* volume . DefaultBlockDriver * volume . DefaultEnumerator // Status diagnostic information func ( d * nfsDriver ) Status ( ) [ ] [ 2 ] string { return [ ] [ 2 ] string { } }", "del_tokens": "volume . DefaultBlockDriver // Status diagnostic information func ( d * nfsDriver ) Status ( ) [ ] [ 2 ] string { return [ ] [ 2 ] string { } } func ( d * nfsDriver ) Enumerate ( locator api . VolumeLocator , labels api . Labels ) ( [ ] api . Volume , error ) { vs , err := d . enumerate ( ) if err != nil { log . Println ( err ) return nil , err } volumes := make ( [ ] api . Volume , 0 ) for _ , v := range vs { if locator . Name != \" \" { if v . Locator . Name != locator . Name { continue } } vol := api . Volume { ID : v . Id , Spec : & v . Spec } volumes = append ( volumes , vol ) } return volumes , nil }", "commit_type": "make"}
{"commit_tokens": ["add", "simplify", "cgo", "pointer", "comment"], "add_tokens": "// // TODO(chai2010): simplify cgo pointer: // // CBuffer/cgoSafePtr/cgoFreePtr removed! // // Go1.3: Changes to the garbage collector // http://golang.org/doc/go1.3#garbage_collector // // Go1.6: // https://github.com/golang/proposal/blob/master/design/12416-cgo-pointers.md //", "del_tokens": "// +build cgo", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "ExpectThat ( f , Panics ( HasSubstr ( \" \" ) ) ) ExpectThat ( f , Panics ( HasSubstr ( \" \" ) ) ) ExpectThat ( f , Panics ( HasSubstr ( \" \" ) ) )", "del_tokens": "ExpectThat ( f , Panics ( HasSubstr ( \" \" ) ) ) ExpectThat ( f , Panics ( HasSubstr ( \" \" ) ) ) ExpectThat ( f , Panics ( HasSubstr ( \" \" ) ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "missing", "Release", "call", "for", "IEnumVARIANT", "to", "fix", "memory", "leak", ".", "Also", "go", "fmt", "."], "add_tokens": "lock sync . Mutex defer enum . Release ( )", "del_tokens": "lock sync . Mutex", "commit_type": "add"}
{"commit_tokens": ["Fix", "compile", "error", "in", "rpc_test", ".", "go", "."], "add_tokens": "itemsToVerify := make ( [ ] interface { } , 0 , len ( items ) ) itemsToVerify = append ( itemsToVerify , fmt . Sprintf ( formatStr , args ... ) ) s . Verify ( itemsToVerify ... )", "del_tokens": "strs := make ( [ ] string , 0 , len ( items ) ) strs = append ( strs , fmt . Sprintf ( formatStr , args ... ) ) s . Verify ( strs ... )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "tcontainer", ".", "MarshalMap", "path", "resolve", "when", "having", "map", "[", "interface", "{}", "]", "interface", "{}"], "add_tokens": "return 0 , fmt . Errorf ( `\"%s\" is expected to be an integer` , key ) // TODO: Use reflection to get rid of duplicate code case map [ interface { } ] interface { } : mapValue := value . ( map [ interface { } ] interface { } ) if storedValue , exists := mapValue [ key ] ; exists { return storedValue , true } keyEnd , nextKeyStart := mmap . resolvePathKey ( key ) if storedValue , exists := mapValue [ key [ : keyEnd ] ] ; exists { remain := key [ nextKeyStart : ] return mmap . resolvePath ( remain , storedValue ) // ### return, nested map ### }", "del_tokens": "return 0 , fmt . Errorf ( `\"%s\" is expected to be an unsigned integer` , key )", "commit_type": "fix"}
{"commit_tokens": ["Add", "SetTo", "method", "to", "set", "a", "bit", "to", "a", "value", "."], "add_tokens": "\" \" func TestSetTo ( t * testing . T ) { v := New ( 1000 ) v . SetTo ( 100 , true ) if v . Test ( 100 ) != true { t . Errorf ( \" \" , 100 ) } v . SetTo ( 100 , false ) if v . Test ( 100 ) != false { t . Errorf ( \" \" , 100 ) } }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "TIP", "version", "error", ":", "Sprintf", "format", "%s", "has", "arg", "of", "wrong", "type", "byte"], "add_tokens": "return fmt . Sprintf ( \" \" , strconv . FormatInt ( int64 ( a . StatusCode ) , 10 ) [ 0 ] )", "del_tokens": "return fmt . Sprintf ( \" \" , strconv . FormatInt ( int64 ( a . StatusCode ) , 10 ) [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "pagination", "to", "ListAssets", "call"], "add_tokens": "result := [ ] * github . ReleaseAsset { } page := 1 for { assets , res , err := c . Repositories . ListReleaseAssets ( c . Owner , c . Repo , releaseID , & github . ListOptions { Page : page } ) if err != nil { return nil , errors . Wrap ( err , \" \" ) } if res . StatusCode != http . StatusOK { return nil , errors . Errorf ( \" \" , res . Status ) } result = append ( result , assets ... ) if res . NextPage <= page { break } page = res . NextPage return result , nil", "del_tokens": "assets , res , err := c . Repositories . ListReleaseAssets ( c . Owner , c . Repo , releaseID , nil ) if err != nil { return nil , errors . Wrap ( err , \" \" ) } if res . StatusCode != http . StatusOK { return nil , errors . Errorf ( \" \" , res . Status ) return assets , nil", "commit_type": "add"}
{"commit_tokens": ["move", "mock", "to", "it", "s", "own", "pkg"], "add_tokens": "package mockclient \" \" mock . On ( \" \" ) . Return ( & dockerclient . Version { Version : \" \" } , nil ) . Once ( ) iface := reflect . TypeOf ( ( * dockerclient . Client ) ( nil ) ) . Elem ( )", "del_tokens": "package dockerclient mock . On ( \" \" ) . Return ( & Version { Version : \" \" } , nil ) . Once ( ) iface := reflect . TypeOf ( ( * Client ) ( nil ) ) . Elem ( )", "commit_type": "move"}
{"commit_tokens": ["Use", "zookeeper", "event", "channels", "directly", "instead", "of", "wrapping", "them", "."], "add_tokens": "func ( cg * Consumergroup ) WatchInstances ( ) ( ConsumergroupInstanceList , <- chan zk . Event , error ) { return result , c , nil func ( cg * Consumergroup ) WatchPartitionOwner ( topic string , partition int32 ) ( * ConsumergroupInstance , <- chan zk . Event , error ) { return & ConsumergroupInstance { cg : cg , ID : string ( instanceID ) } , changed , nil", "del_tokens": "func ( cg * Consumergroup ) WatchInstances ( ) ( ConsumergroupInstanceList , <- chan struct { } , error ) { channel := make ( chan struct { } ) go func ( ) { <- c close ( channel ) } ( ) return result , channel , nil func ( cg * Consumergroup ) WatchPartitionOwner ( topic string , partition int32 ) ( * ConsumergroupInstance , <- chan struct { } , error ) { channel := make ( chan struct { } ) go func ( ) { <- changed close ( channel ) } ( ) return & ConsumergroupInstance { cg : cg , ID : string ( instanceID ) } , channel , nil", "commit_type": "use"}
{"commit_tokens": ["Make", "WebhookHandler", "return", "error", "vs", "bool"], "add_tokens": "type WebhookHandler func ( eventname string , payload * GitHubPayload , req * http . Request ) error if err := fn ( event , & payload , req ) ; err == nil { _fail ( err )", "del_tokens": "type WebhookHandler func ( eventname string , payload * GitHubPayload , req * http . Request ) bool success := fn ( event , & payload , req ) if success { _fail ( nil )", "commit_type": "make"}
{"commit_tokens": ["Add", "--", "dry_run", "config", "to", "healthceck", "CLI"], "add_tokens": "dryrun bool var result * Result if hc . dryrun { result = complete ( start , \" \" , true , nil ) } else { result = hc . execute ( ) } // Dryrun enables or disables dryrun mode for a healthcheck. func ( hc * Check ) Dryrun ( dryrun bool ) { hc . dryrun = dryrun } DryRun bool hc . Dryrun ( s . config . DryRun )", "del_tokens": "result := hc . execute ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "util", ".", "Download", "()"], "add_tokens": "\" \" return util . Download ( i . Src , out )", "del_tokens": "return download ( i . Src , out )", "commit_type": "add"}
{"commit_tokens": ["Add", "all", "Statuses", "and", "a", "Friendly", "()", "func"], "add_tokens": "\" \" // The status of the message (accepted, queued, etc). // For more information , see https://www.twilio.com/docs/api/rest/message func ( s Status ) Friendly ( ) string { return strings . ToUpper ( string ( s ) ) } const StatusAccepted = Status ( \" \" ) const StatusFailed = Status ( \" \" ) const StatusQueued = Status ( \" \" ) const StatusReceiving = Status ( \" \" ) const StatusReceived = Status ( \" \" ) const StatusSending = Status ( \" \" ) const StatusSent = Status ( \" \" ) const StatusUndelivered = Status ( \" \" )", "del_tokens": "const StatusSent = Status ( \" \" ) const StatusReceived = Status ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["use", "etcd", "origin", "v3", "mutex"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["fix", "windows", "test", "cases", "to", "use", "NewTab"], "add_tokens": "go http . Serve ( testListener , http . FileServer ( http . Dir ( \" \" ) ) )", "del_tokens": "go http . Serve ( testListener , http . FileServer ( http . Dir ( \" \" ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "prefix", "handling", "as", "only", "lowercase", "v", "is", "supported"], "add_tokens": "// Note, only lowercase v is supported as a prefix by the parser. if v . original != \" \" && v . original [ : 1 ] == \" \" {", "del_tokens": "if v . original != \" \" && strings . ToLower ( v . original [ : 1 ] ) == \" \" {", "commit_type": "update"}
{"commit_tokens": ["fixed", "any", "match", "node", "issue"], "add_tokens": "start += 1 + len ( pathArray [ i ] )", "del_tokens": "start = 1 + len ( pathArray [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "boundary", "error", "in", "TTF", "handling"], "add_tokens": "if value >= gTb . StartCharCode && value <= gTb . EndCharCode {", "del_tokens": "if value >= gTb . StartCharCode && value < gTb . EndCharCode {", "commit_type": "fix"}
{"commit_tokens": ["Use", "correct", "filemode", "when", "creating", "local", "directories"], "add_tokens": "if err := os . MkdirAll ( filepath . Dir ( path ) , 0700 ) ; err != nil {", "del_tokens": "if err := os . MkdirAll ( filepath . Dir ( path ) , os . ModeDir ) ; err != nil {", "commit_type": "use"}
{"commit_tokens": ["Move", "directory", "creation", "into", "the", "root", "cmd", ".", "Fix", "bug", "starting", "container", "."], "add_tokens": "// Start container. err = ctlr . StartCtr ( ctrID , \" \" ) if err != nil { return \" \" , err }", "del_tokens": "\" \" setupDirs ( ) return kubeHost , nil } // Start container. err = ctlr . StartCtr ( ctrID , \" \" ) if err != nil { return \" \" , err func setupDirs ( ) error { dirs := [ ... ] string { constants . Minipath , constants . MakeMiniPath ( \" \" ) , constants . MakeMiniPath ( \" \" ) } for _ , path := range dirs { if err := os . MkdirAll ( path , 0777 ) ; err != nil { return fmt . Errorf ( \" \" , err ) } } return nil } func certPath ( fileName string ) string { return filepath . Join ( constants . Minipath , \" \" , fileName ) }", "commit_type": "move"}
{"commit_tokens": ["Allow", "trees", "to", "trim", "to", "the", "top", "Nodes", "by", "NodeInfo"], "add_tokens": "continue", "del_tokens": "nextSample : continue nextSample", "commit_type": "allow"}
{"commit_tokens": ["Change", "display", "of", "verbose", "messages"], "add_tokens": "\" \" fmt . Printf ( \" \\n \" , strings . Join ( args , \" \" ) )", "del_tokens": "fmt . Printf ( \" \\n \" , args )", "commit_type": "change"}
{"commit_tokens": ["Add", "alias", "type", "for", "properties"], "add_tokens": "type Properties map [ string ] interface { } func ( m * Mixpanel ) makeRequestWithData ( method string , endpoint string , data Properties ) ( [ ] byte , error ) { func ( m * Mixpanel ) Track ( distinctId string , event string , props Properties ) error { props [ \" \" ] = distinctId props [ \" \" ] = m . Token props [ \" \" ] = \" \" data := map [ string ] interface { } { \" \" : event , \" \" : props }", "del_tokens": "func ( m * Mixpanel ) makeRequestWithData ( method string , endpoint string , data map [ string ] interface { } ) ( [ ] byte , error ) { func ( m * Mixpanel ) Track ( distinctId string , event string , params map [ string ] interface { } ) error { params [ \" \" ] = distinctId params [ \" \" ] = m . Token params [ \" \" ] = \" \" data := map [ string ] interface { } { \" \" : event , \" \" : params }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "of", "several", "GOPATH"], "add_tokens": "if envy . InGoPath ( ) { // pwd is inside a GOPATH // is outside of gopath, dont loop to parent", "del_tokens": "if strings . HasPrefix ( currentPath , os . Getenv ( \" \" ) ) { //is outside of gopath, dont loop to parent", "commit_type": "add"}
{"commit_tokens": ["improve", "some", "TG", "errors", "handling"], "add_tokens": "if strings . Contains ( e . Description , \" \" ) { if strings . Contains ( e . Description , \" \" ) { return - 1 if strings . Contains ( e . Description , \" \" ) {", "del_tokens": "if e . Description == \" \" || e . Description == \" \" { if e . Description == \" \" { return 10 if strings . Contains ( e . Description , \" \" ) {", "commit_type": "improve"}
{"commit_tokens": ["Add", "self", "to", "copyright", "notice", "."], "add_tokens": "// Copyright 2016 Dean Karn. // Copyright 2013 Julien Schmidt. // All rights reserved.", "del_tokens": "// Copyright 2013 Julien Schmidt. All rights reserved.", "commit_type": "add"}
{"commit_tokens": ["moved", "every", "major", "part", "to", "Cobra", "-", "own", "fork"], "add_tokens": "log . Warning ( \" \" + colorstring . Green ( \" \" ) )", "del_tokens": "log . Warning ( \" \" + colorstring . Green ( \" \" ) )", "commit_type": "move"}
{"commit_tokens": ["Make", "state", "of", "pod", "clearer"], "add_tokens": "pc . pod . State = RunStateError pc . pod . State = RunStateError pc . pod . State = RunStateError pc . pod . State = RunStateError pc . pod . State = RunStateError pc . pod . State = RunStateError", "del_tokens": "pc . pod . State = RunStateFail pc . pod . State = RunStateFail pc . pod . State = RunStateFail pc . pod . State = RunStateFail pc . pod . State = RunStateFail pc . pod . State = RunStateFail", "commit_type": "make"}
{"commit_tokens": ["Added", "some", "commands", "in", "the", "readme"], "add_tokens": "fmt . Println ( hostfile . Format ( ) )", "del_tokens": "fmt . Println ( hostfile )", "commit_type": "add"}
{"commit_tokens": ["use", "multiple", "loopback", "devices", "in", "parallel", "tests"], "add_tokens": "loopbackDevice := fmt . Sprintf ( \" \" , GinkgoParallelNode ( ) + 63 )", "del_tokens": "loopbackDevice := \" \"", "commit_type": "use"}
{"commit_tokens": ["removed", "unused", "field", "on", "fxpMkdir"], "add_tokens": "4 // uint32", "del_tokens": "Size uint64 // ignored 4 + 8 // uint32 + uint64 b = marshalUint64 ( b , p . Size )", "commit_type": "remove"}
{"commit_tokens": ["Add", "attachment", "field", "to", "DirectMessageEvent", "message", "data"], "add_tokens": "Text string `json:\"text\"` Entities * Entities `json:\"entitites\"` Attachment struct { Type string `json:\"type\"` Media MediaEntity `json:\"media\"` } `json:\"attachment\"`", "del_tokens": "Text string `json:\"text\"` Entities * Entities `json:\"entitites\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "pool", ".", "SetHelloHostname", "()", "to", "override", "SMTP", "HELLO", "hostname", "(", "FQDN", ")"], "add_tokens": "addr string auth smtp . Auth max int created int clients chan * client rebuild chan struct { } mut * sync . Mutex lastBuildErr * timestampedErr closing chan struct { } tlsConfig * tls . Config helloHostname string // SetHelloHostname optionally sets the hostname that the Go smtp.Client will // use when doing a HELLO with the upstream SMTP server. By default, Go uses // \"localhost\" which may not be accepted by certain SMTP servers that demand // an FQDN. func ( p * Pool ) SetHelloHostname ( h string ) { p . helloHostname = h } // Is there a custom hostname for doing a HELLO with the SMTP server? if p . helloHostname != \" \" { cl . Hello ( p . helloHostname ) }", "del_tokens": "addr string auth smtp . Auth max int created int clients chan * client rebuild chan struct { } mut * sync . Mutex lastBuildErr * timestampedErr closing chan struct { } tlsConfig * tls . Config", "commit_type": "add"}
{"commit_tokens": ["Add", "simple", "test", "case", "for", "input", "image", "with", "non", "-", "trivial", "bounds", "."], "add_tokens": "\" \" \" \" //\"runtime\" //runtime.GOMAXPROCS(runtime.NumCPU()) func Test_Bounds ( t * testing . T ) { img := image . NewRGBA ( image . Rect ( 20 , 10 , 200 , 99 ) ) out := Resize ( 80 , 80 , img , Lanczos2 ) out . At ( 0 , 0 ) } func Benchmark_LargeN ( b * testing . B ) { file , _ := os . Open ( \" \" ) defer file . Close ( ) img , _ := png . Decode ( file ) var output image . Image b . ResetTimer ( ) for i := 0 ; i < b . N ; i ++ { output = Resize ( 900 , 0 , img , Bicubic ) } b . StopTimer ( ) output . At ( 0 , 0 ) outPng , _ := os . Create ( \" \" ) defer outPng . Close ( ) png . Encode ( outPng , output ) }", "del_tokens": "\" \" runtime . GOMAXPROCS ( runtime . NumCPU ( ) )", "commit_type": "add"}
{"commit_tokens": ["add", "test", "case", "for", "FixedEnsembleProvider"], "add_tokens": "// Abstraction that provides the ZooKeeper connection string // Standard ensemble provider that wraps a fixed connection string type FixedEnsembleProvider struct { connectString string // The connection string to use func NewFixedEnsembleProvider ( connectString string ) * FixedEnsembleProvider { return & FixedEnsembleProvider { connectString } } func ( p * FixedEnsembleProvider ) Start ( ) error { return nil } func ( p * FixedEnsembleProvider ) Close ( ) error { return nil } func ( p * FixedEnsembleProvider ) ConnectionString ( ) string { return p . connectString }", "del_tokens": "type fixedEnsembleProvider struct { connectString string func ( p * fixedEnsembleProvider ) Start ( ) error { return nil } func ( p * fixedEnsembleProvider ) Close ( ) error { return nil } func ( p * fixedEnsembleProvider ) ConnectionString ( ) string { return p . connectString }", "commit_type": "add"}
{"commit_tokens": ["use", "prepared", "statements", "for", "big", "perf", "boost"], "add_tokens": "Prepared Statements que - go relies on prepared statements for performance . As of now these have to be initialized manually on your connection pool like so : pgxpool , err := pgx . NewConnPool ( pgx . ConnPoolConfig { ConnConfig : pgxcfg , AfterConnect : que . PrepareStatements , } ) If you have suggestions on how to cleanly do this automatically , please open an issue ! pgxpool , err := pgx . NewConnPool ( pgx . ConnPoolConfig { ConnConfig : pgxcfg , AfterConnect : que . PrepareStatements , } ) defer pgxpool . Close ( )", "del_tokens": "pgxpool , err := pgx . NewConnPool ( pgx . ConnPoolConfig { ConnConfig : pgxcfg } )", "commit_type": "use"}
{"commit_tokens": ["Adding", "raw", "quotes", "(", "but", "they", "just", "work", "as", "regular", "single", "or", "double", "quotes", ")"], "add_tokens": "QUOTE_CHARS = \" \\\" \" var ( BRACKETS = map [ rune ] rune { '{' : '}' , '[' : ']' , '(' : ')' , } )", "del_tokens": "QUOTE_CHARS = `'\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "returning", "multiple", "annotations", "in", "the", "READ"], "add_tokens": "results := [ ] annotation { } WITH c , cc , m , { id : cc . uuid , prefLabel : cc . prefLabel , types : labels ( cc ) } as thing , atTime : m . annotatedDate } ) as provenances RETURN thing , provenances ORDER BY thing . id for idx := range results { mapToResponseFormat ( & results [ idx ] ) return results , true , nil", "del_tokens": "results := [ ] struct { annotations } { } WITH c , cc , m , { id : cc . uuid , prefLabel : cc . prefLabel , types : labels ( cc ) } as t , atTime : m . annotatedDate } ) as p RETURN [ { thing : t , provenances : p } ] as annotations foundAnnotations := results [ 0 ] . annotations for idx := range foundAnnotations { mapToResponseFormat ( & foundAnnotations [ idx ] ) log . Debugf ( \" \" , foundAnnotations ) return foundAnnotations , true , nil", "commit_type": "fix"}
{"commit_tokens": ["Make", "dynamic", "reallocation", "much", "faster"], "add_tokens": "} else if cap ( b . set ) >= nsize { b . set = b . set [ : nsize ] // fast resize newset := make ( [ ] uint64 , nsize , 2 * nsize ) // increase capacity 2x", "del_tokens": "newset := make ( [ ] uint64 , nsize )", "commit_type": "make"}
{"commit_tokens": ["Allow", "opening", "other", "dirs", "."], "add_tokens": "// Allow opening any directory. resp = & fuse . OpenDirResponse { }", "del_tokens": "// We always allow opening the root directory. if req . Inode == rootInode { resp = & fuse . OpenDirResponse { } return } // TODO(jacobsa): Handle others. err = fuse . ENOSYS", "commit_type": "allow"}
{"commit_tokens": ["Fix", "indentation", "and", "package", "mismatch"], "add_tokens": "package backoff", "del_tokens": "package core", "commit_type": "fix"}
{"commit_tokens": ["Make", "HttpClient", "use", "a", "copy", "of", "DefaultTransport"], "add_tokens": "config . HttpClient . Transport = shallowDefaultTransport ( ) func shallowDefaultTransport ( ) * http . Transport { defaultTransport := http . DefaultTransport . ( * http . Transport ) return & http . Transport { Proxy : defaultTransport . Proxy , TLSHandshakeTimeout : defaultTransport . TLSHandshakeTimeout , ExpectContinueTimeout : defaultTransport . ExpectContinueTimeout , } }", "del_tokens": "config . HttpClient . Transport = http . DefaultTransport", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "constant", "-", "time", "compare", "for", "the", "signature", "."], "add_tokens": "\" \" return subtle . ConstantTimeCompare ( sig [ : 32 ] , checkR [ : ] ) == 1", "del_tokens": "\" \" return bytes . Equal ( sig [ : 32 ] , checkR [ : ] )", "commit_type": "use"}
{"commit_tokens": ["Update", "examples", "in", "help", "output"], "add_tokens": "# writes \" \" to . / packagefakes / fake_std_interface . go # writes \" \" to . / mySpecialFakesDir / specialFake . go counterfeiter - o . / mySpecialFakesDir / specialFake . go . / mypackage MyInterface # writes \" \" to . / mypackagefakes / cool_thing . go counterfeiter -- fake - name CoolThing . / mypackage MyInterface", "del_tokens": "# writes \" \" to . / fakes / fake_std_interface . go # writes \" \" to . / fakes / fake_my_interface . go counterfeiter - o . / fakes MyInterface . / mypackage # writes \" \" to . / fakes / cool_thing . go counterfeiter -- fake - name CoolThing MyInterface . / mypackage", "commit_type": "update"}
{"commit_tokens": ["added", "syntax", "&", "color", "scheme", "for", "sublime", "packages"], "add_tokens": "packages . Unregister ( pluginRecord ) packages . Unregister ( packageRecord )", "del_tokens": "// in case error ocured on running onInit function if module == nil { return }", "commit_type": "add"}
{"commit_tokens": ["Added", "timeout", "to", "writing", "to", "opussend", "channel"], "add_tokens": "\" \" var ( ErrVoiceConnClosed = errors . New ( \" \" ) ) panic ( \" \" ) // Timeout after 100ms (Maybe this needs to be changed?) timeOut := time . After ( time . Second ) // This will attempt to send on the channel before the timeout, which is 1s select { case <- timeOut : return ErrVoiceConnClosed case s . vc . OpusSend <- opus : } func ( s * StreamingSession ) SetPaused ( paused bool ) { if ! paused && s . running { if paused && ! s . running { if ! s . running && s . paused && ! paused { s . paused = paused", "del_tokens": "s . vc . OpusSend <- opus func ( s * StreamingSession ) SetRunning ( running bool ) { if running && s . running { if ! running && ! s . running { if ! s . running && s . paused && running { s . paused = ! running", "commit_type": "add"}
{"commit_tokens": ["Use", "Close", "()", "instead", "of", "Disconnect", "()"], "add_tokens": "natsClient . Close ( )", "del_tokens": "natsClient . Disconnect ( )", "commit_type": "use"}
{"commit_tokens": ["Remove", "state", "argument", "in", "callback", ".", "Remove", "EPOLLOUT"], "add_tokens": "type IRQEvent func ( )", "del_tokens": "type IRQEvent func ( state bool )", "commit_type": "remove"}
{"commit_tokens": ["adds", "cpu", "and", "memory", "profiling", "options", ".", "looks", "like", "most", "of", "the", "cpu", "usage", "comes", "from", "parsing", "pages", "with", "regexes", "and", "the", "largest", "memory", "consumers", "are", "xml", "encoding", "and", "id", "tracking"], "add_tokens": "\" \" \" \" var cpuprofile = true var memprofile = true if cpuprofile { f , err := os . Create ( \" \" ) if err != nil { log . Fatal ( err ) } pprof . StartCPUProfile ( f ) defer pprof . StopCPUProfile ( ) } if len ( os . Args ) < 5 { log . Fatal ( \" \" ) err := generateByPath ( os . Args [ 2 ] , os . Args [ 3 ] , os . Args [ 4 ] , 10000 ) default : fmt . Println ( \" \" ) } if memprofile { f , err := os . Create ( \" \" ) if err != nil { log . Fatal ( err ) } pprof . WriteHeapProfile ( f ) f . Close ( )", "del_tokens": "if len ( os . Args ) != 5 { fmt . Println ( \" \" ) err := generateByPath ( os . Args [ 2 ] , os . Args [ 3 ] , os . Args [ 4 ] , - 1 )", "commit_type": "add"}
{"commit_tokens": ["Improve", "swagger", "code", "coverage", "."], "add_tokens": "swag Swagger if swag != nil { panic ( \" \" + name ) swag = swagger if swag != nil { return swag . ReadDoc ( ) , nil return \" \" , errors . New ( \" \" )", "del_tokens": "swaggers = make ( map [ string ] Swagger ) if _ , dup := swaggers [ name ] ; dup { panic ( \" \" + name ) swaggers [ name ] = swagger if val , ok := swaggers [ Name ] ; ok { return val . ReadDoc ( ) , nil return \" \" , errors . New ( \" \" )", "commit_type": "improve"}
{"commit_tokens": ["Making", "sure", "Client", "can", "parse", "relative", "path", "or", "full", "url"], "add_tokens": "\" \" url , err := c . buildURL ( path ) if err != nil { return nil , err } request , err := http . NewRequest ( method , url . String ( ) , content ) func ( c * Client ) buildURL ( pathOrURL string ) ( * url . URL , error ) { u , e := url . ParseRequestURI ( pathOrURL ) if e != nil { u , e = url . Parse ( c . BaseURL ) if e != nil { return nil , e } return u . Parse ( pathOrURL ) } return u , nil }", "del_tokens": "url := fmt . Sprintf ( \" \" , c . BaseURL , path ) request , err := http . NewRequest ( method , url , content )", "commit_type": "make"}
{"commit_tokens": ["Add", "language", "provider", "for", "Google", "Translate"], "add_tokens": "// The Router provides necessary URLs to communicate with", "del_tokens": "// The Router provides the necessary URLs to communicate with", "commit_type": "add"}
{"commit_tokens": ["Remove", "ugly", "hack", "to", "grab", "pathMatcher", "from", "hostMatcher"], "add_tokens": "hs := & hostStore { } hs = hm . matcher . Set ( reversedHost , hs , nil ) . ( * hostStore ) return hs . rm", "del_tokens": "type registererRMGrabber struct { rm registerMatcher } rg := & registererRMGrabber { } hm . matcher . Set ( reversedHost , rg , nil ) return rg . rm // Little hack to grab the pointer of the underlying RegisterMatcher if rg , ok := value . ( * registererRMGrabber ) ; ok { rg . rm = hs . rm }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "test", "on", "Windows", "."], "add_tokens": "\" \" err := future . Error ( ) ut . AssertEqual ( t , true , strings . HasPrefix ( err . Error ( ) , \" \" ) ) ut . AssertEqual ( t , true , strings . HasPrefix ( closeErr . Error ( ) , \" \" ) )", "del_tokens": "expectedErr := \" \" ut . AssertEqual ( t , expectedErr , future . Error ( ) . Error ( ) ) ut . AssertEqual ( t , expectedErr , closeErr . Error ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "minor", "issues", "from", "las", "pull", "request"], "add_tokens": "type NullBool struct { Bool bool Valid bool } // \"true\" and \"t\" will be considered \"true\", \"false\" and \"f\" will // be treated as \"false\". All other values will //be set to null by Valid = false if t == \" \" || t == \" \" { ns . Valid = true ns . Bool = false return nil }", "del_tokens": "type NullBool sql . NullBool // \"true\" and \"t\" will be considered \"true\", all other // values will be considered \"false\". Null values will //be set by setting Valid = false", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "safeJoin"], "add_tokens": "if ! strings . HasSuffix ( parent , string ( os . PathSeparator ) ) {", "del_tokens": "if ! strings . HasPrefix ( parent , string ( os . PathSeparator ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "incorrect", "usage", "of", "manners"], "add_tokens": "return manners . ListenAndServe ( addr , app . router )", "del_tokens": "http . Handle ( \" \" , app . router ) return manners . ListenAndServe ( addr , nil )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "to", "parse", "other", "multipart", "Content", "-", "Type"], "add_tokens": "default : if strings . HasPrefix ( mediatype , \" \" ) { // according to rfc2046#section-5.1.7 all other multipart should // be treated as multipart/mixed return true }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["use", "time", ".", "Duration", "instead", "of", "int", "to", "specify", "session", "timeout"], "add_tokens": "\" \" // Set session cache timeout. Returns previously set value. func ( c * Ctx ) SetTimeout ( t time . Duration ) time . Duration { prev := C . SSL_CTX_set_timeout_not_a_macro ( c . ctx , C . long ( t / time . Second ) ) return time . Duration ( prev ) * time . Second // Get session cache timeout. func ( c * Ctx ) GetTimeout ( ) time . Duration { return time . Duration ( C . SSL_CTX_get_timeout_not_a_macro ( c . ctx ) ) * time . Second", "del_tokens": "// Set session cache timeout in seconds. Returns previously set value. func ( c * Ctx ) SetTimeout ( t int ) int { return int ( C . SSL_CTX_set_timeout_not_a_macro ( c . ctx , C . long ( t ) ) ) // Get session cache timeout in seconds. func ( c * Ctx ) GetTimeout ( ) int { return int ( C . SSL_CTX_get_timeout_not_a_macro ( c . ctx ) )", "commit_type": "use"}
{"commit_tokens": ["allow", "access", "to", "the", "inner", "http", "server", "so", "its", "settings", "can", "be", "tweaked"], "add_tokens": "InnerServer http . Server s . InnerServer . Handler = handler s . InnerServer . ConnState = func ( conn net . Conn , newState http . ConnState ) { err := s . InnerServer . Serve ( listener )", "del_tokens": "server := http . Server { Handler : handler } server . ConnState = func ( conn net . Conn , newState http . ConnState ) { err := server . Serve ( listener )", "commit_type": "allow"}
{"commit_tokens": ["Add", "types", "for", "prototype", "params", "and", "templates"], "add_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "del_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "test", "class", "and", "fix", "reference", "to", "old", "test", "class", "."], "add_tokens": "// IID_ICOMEchoTestObject is for ICOMEchoTestObject interfaces. IID_ICOMEchoTestObject = & GUID { 0x6485b1ef , 0xd780 , 0x4834 , [ 8 ] byte { 0xa4 , 0xfe , 0x1e , 0xbb , 0x51 , 0x74 , 0x6c , 0xa3 } } // CLSID_COMEchoTestObject is for COMEchoTestObject class. // // {3C24506A-AE9E-4D50-9157-EF317281F1B0} CLSID_COMEchoTestObject = & GUID { 0x3c24506a , 0xae9e , 0x4d50 , [ 8 ] byte { 0x91 , 0x57 , 0xef , 0x31 , 0x72 , 0x81 , 0xf1 , 0xb00 } } ;", "del_tokens": "// IID_ICOMTestObject is for ICOMTestObject interfaces. IID_ICOMTestObject = & GUID { 0x6485b1ef , 0xd780 , 0x4834 , [ 8 ] byte { 0xa4 , 0xfe , 0x1e , 0xbb , 0x51 , 0x74 , 0x6c , 0xa3 } }", "commit_type": "add"}
{"commit_tokens": ["added", "a", "readTimeout", "param", "to", "MySQL"], "add_tokens": "s := \" \"", "del_tokens": "s := \" \"", "commit_type": "add"}
{"commit_tokens": ["add", "deepcopy", "and", "update", "path"], "add_tokens": "\" \" // DirWalk walks the passed path, making a list of all the files that are if err != nil { // AppendSlash appends a slash, `/`, to the end of the passed string, if it // doesn't already end with one. For OS independend filepaths, `/` are always // used internally with OS-specific conversion occuring before interacting // with the filesystem via filepath.FromSlash() and filepath.ToSlash() func AppendSlash ( s string ) string { if strings . HasSuffix ( s , \" \" ) { return s } return s + \" \" }", "del_tokens": "// DirWalk walks the passed path, making a list of all the files that are if err != nil {", "commit_type": "add"}
{"commit_tokens": ["Add", "*", "mat64", ".", "Dense", "to", "cv", "::", "Mat", "converter", "."], "add_tokens": "// Convert Mat, which defined by SWIG, to *mat64.Dense. // Convert *mat64.Dense to Mat func ToMat ( mat * mat64 . Dense ) Mat { row , col := mat . Dims ( ) rawData := NewGcvFloat64Vector ( int64 ( row * col ) ) for i := 0 ; i < row ; i ++ { for j := 0 ; j < col ; j ++ { rawData . Set ( i * col + j , mat . At ( i , j ) ) } } return ToMat_ ( row , col , rawData ) }", "del_tokens": "// Convert Mat, which defined by SWIG, to mat64.Dense.", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "handler", "for", "message", "successfully", "sent"], "add_tokens": "\" \" messageSentHandler handleMessageFunc messageSentHandler : func ( * Session , [ ] byte ) { } , // HandleSentMessage fires fn when a message is successfully sent. func ( m * Melody ) HandleSentMessage ( fn func ( * Session , [ ] byte ) ) { m . messageSentHandler = fn }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Make", "mustCopyDir", "follow", "symlinks", "."], "add_tokens": "var realSrcDir string // handle symlinked source-direcories f , err := os . Lstat ( srcDir ) if err == nil && f . Mode ( ) & os . ModeSymlink == os . ModeSymlink { realSrcDir , _ = os . Readlink ( srcDir ) } else { realSrcDir = srcDir } return filepath . Walk ( realSrcDir , func ( srcPath string , info os . FileInfo , err error ) error { relSrcPath := strings . TrimLeft ( srcPath [ len ( realSrcDir ) : ] , string ( os . PathSeparator ) )", "del_tokens": "return filepath . Walk ( srcDir , func ( srcPath string , info os . FileInfo , err error ) error { relSrcPath := strings . TrimLeft ( srcPath [ len ( srcDir ) : ] , string ( os . PathSeparator ) )", "commit_type": "make"}
{"commit_tokens": ["add", "assert", "methods", "for", "testing"], "add_tokens": "func assertEqual ( t * testing . T , expected interface { } , actual interface { } ) { if expected != actual { t . Fatalf ( \" \" , expected , actual ) } } func TestSpanRecorder ( t * testing . T ) { assertEqual ( t , rs . Operation , ls . Operation ) assertEqual ( t , rs . Duration , ls . Duration ) assertEqual ( t , rs . Start . Nanosecond ( ) , ls . Start . Nanosecond ( ) ) assertEqual ( t , rs . Tags [ \" \" ] , ls . Tags [ \" \" ] )", "del_tokens": "\" \" func TestSpanRecorder ( t * testing . T ) { assert := assert . New ( t ) assert . Equal ( rs . Operation , ls . Operation ) assert . Equal ( rs . Duration , ls . Duration ) assert . Equal ( rs . Start . Nanosecond ( ) , ls . Start . Nanosecond ( ) ) assert . Equal ( rs . Tags , ls . Tags )", "commit_type": "add"}
{"commit_tokens": ["remove", "extention", "from", "test", "data", "(", "too", "much", "html", "codes", "in", "GitHub", "code", "analysis", ")"], "add_tokens": "test_case1 := \" \" test_case2 := \" \" doc1 . Find ( whole_article_selector ) . First ( )", "del_tokens": "test_case1 := \" \" test_case2 := \" \"", "commit_type": "remove"}
{"commit_tokens": ["Use", "Pty", "for", "test", "device"], "add_tokens": "import ( \" \" \" \" ) _ , pts , err := termios . Pty ( ) term , err := Open ( pts . Name ( ) ) if err != nil { t . Fatal ( err ) } pts . Close ( ) return term", "del_tokens": "import \" \" import \" \" var dev = flag . String ( \" \" , \" \" , \" \" ) tt , err := Open ( * dev ) return tt", "commit_type": "use"}
{"commit_tokens": ["add", "WriteOctetSlice", "for", "compat", "with", "old", "WriteByteSlice"], "add_tokens": "var Legacy * TMEncoderLegacy = & TMEncoderLegacy { } // convenience func ( e * TMEncoderLegacy ) WriteOctetSlice ( bz [ ] byte , w io . Writer , n * int , err * error ) { e . WriteVarint ( len ( bz ) , w , n , err ) if len ( bz ) > 0 { e . WriteTo ( bz , w , n , err ) } }", "del_tokens": "var Legacy * TMEncoderLegacy = & TMEncoderLegacy { } // convenience", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "handling", "deadlock", "."], "add_tokens": "// Note: There are many cryptic caveats to proper error handling here. // See: https://github.com/go-gl/glfw3/pull/86 err := & GLFWError { ErrorCode ( code ) , C . GoString ( desc ) } select { case lastError <- err : default : fmt . Printf ( \" \\n \" , err . Code , err . Desc ) } // flushErrors is called by Terminate before it actually calls C.glfwTerminate, // this ensures that any uncaught errors buffered in lastError are printed // before the program exits. func flushErrors ( ) { select { case err := <- lastError : fmt . Printf ( \" \\n \" , err . Code , err . Desc ) default : } }", "del_tokens": "lastError <- & GLFWError { ErrorCode ( code ) , C . GoString ( desc ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "GET", "/", "apps", "/", "{", "app", "}", "/", "releases"], "add_tokens": "FindByAppName ( AppName ) ( [ ] * Release , error ) func ( r * releasesRepository ) FindByAppName ( id AppName ) ( [ ] * Release , error ) { // Find existing releases for an app FindByAppName ( AppName ) ( [ ] * Release , error ) func ( s * releasesService ) FindByAppName ( appName AppName ) ( [ ] * Release , error ) { return s . Repository . FindByAppName ( appName ) }", "del_tokens": "FindByAppID ( AppName ) ( [ ] * Release , error ) func ( r * releasesRepository ) FindByAppID ( id AppName ) ( [ ] * Release , error ) {", "commit_type": "add"}
{"commit_tokens": ["changed", "Total", "to", "return", "uint8", "to", "be", "compatible", "with", "new", "autograder"], "add_tokens": "func Total ( scores [ ] * Score ) uint8 { return uint8 ( total * 100 )", "del_tokens": "func Total ( scores [ ] * Score ) int { return int ( total * 100 )", "commit_type": "change"}
{"commit_tokens": ["make", "the", "connection", "pool", "per", "-", "client"], "add_tokens": "//the channel for pub/sub commands Messages chan [ ] byte //the connection pool pool chan * net . TCPConn if client . pool == nil { client . pool = make ( chan * net . TCPConn , MaxPoolSize ) for i := 0 ; i < MaxPoolSize ; i ++ { //add dummy values to the pool client . pool <- nil } } c := <- client . pool client . pool <- c if v . Elem ( 1 ) . ( * reflect . UintValue ) . Overflow ( 257 ) {", "del_tokens": "var pool chan * net . TCPConn func init ( ) { pool = make ( chan * net . TCPConn , MaxPoolSize ) for i := 0 ; i < MaxPoolSize ; i ++ { //add dummy values to the pool pool <- nil } } c := <- pool pool <- c if v . Elem ( 1 ) . ( * reflect . UintValue ) . Overflow ( 257 ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "withValue", "option", "to", "Store", ".", "VisitAscend", "()"], "add_tokens": "func ( t * PTreap ) VisitAscend ( target [ ] byte , withValue bool , visitor PItemVisitor ) error { _ , err := t . store . visitAscendNode ( t , & t . root , target , withValue , visitor ) withValue bool , visitor PItemVisitor ) ( bool , error ) { keepGoing , err := o . visitAscendNode ( t , & nNode . node . left , target , withValue , visitor ) if withValue { nItem , err = o . loadItemLoc ( nItem ) if err != nil { return false , err } } return o . visitAscendNode ( t , & nNode . node . right , target , withValue , visitor )", "del_tokens": "func ( t * PTreap ) VisitAscend ( target [ ] byte , visitor PItemVisitor ) error { _ , err := t . store . visitAscendNode ( t , & t . root , target , visitor ) visitor PItemVisitor ) ( bool , error ) { keepGoing , err := o . visitAscendNode ( t , & nNode . node . left , target , visitor ) return o . visitAscendNode ( t , & nNode . node . right , target , visitor )", "commit_type": "add"}
{"commit_tokens": ["added", "Close", "method", "to", "speaker"], "add_tokens": "if done != nil { done <- struct { } { } done = nil }", "del_tokens": "done <- struct { } { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "type", "and", "format", "of", "definitions", ";", "especially", "int64", "/", "string"], "add_tokens": "schema . Type , schema . Format = reflectTypeAndFormatToSwaggerTypeString ( refT ) func reflectTypeAndFormatToSwaggerTypeString ( refT reflect . Type ) ( t , f string ) { t = \" \" t = \" \" t = \" \" t = \" \" f = \" \" t = \" \" f = \" \" case reflect . Float32 : t = \" \" f = \" \" case reflect . Float64 : t = \" \" f = \" \" t = \" \" t = \" \" return t , _ := reflectTypeAndFormatToSwaggerTypeString ( pw . StructField . Type ) return t", "del_tokens": "schema . Type = reflectTypeToSwaggerTypeString ( refT ) func reflectTypeToSwaggerTypeString ( refT reflect . Type ) string { return \" \" return \" \" return \" \" return \" \" return \" \" case reflect . Float32 , reflect . Float64 : return \" \" return \" \" return \" \" return reflectTypeToSwaggerTypeString ( pw . StructField . Type )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "documentation", "of", "Context", ".", "Args"], "add_tokens": "// daemon-process. If it is nil, the result of os.Args will be used.", "del_tokens": "// daemon-process. If it is nil, the result of os.Args will be used // (without program name).", "commit_type": "fix"}
{"commit_tokens": ["Allow", "whitelisting", "and", "blacklisting", "of", "http", "/", "http2"], "add_tokens": "\" \" \" \" \" \" if ! s . Base . Node . Can ( \" \" , req . Host ) { glog . Errorf ( \" \" , req . Host ) return } if ! s . Base . Node . Can ( \" \" , target ) { glog . Errorf ( \" \" , target ) return }", "del_tokens": "\" \" \" \" \" \"", "commit_type": "allow"}
{"commit_tokens": ["Make", "a", "test", "a", "little", "more", "robust"], "add_tokens": "ctx := context . Background ( ) ctx = errors . WithInfo ( ctx , \" \" , \" \" ) panic ( errors . New ( ctx , gerrors . New ( \" \" ) , 0 ) ) if got , want := fmt . Sprintf ( \" \" , e . StackTrace ( ) [ 0 ] ) , \" \" ; got != want { t . Errorf ( \" \" , got , want ) } if got , want := e . ContextData ( ) [ \" \" ] , \" \" ; got != want {", "del_tokens": "panic ( errors . New ( context . Background ( ) , gerrors . New ( \" \" ) , 0 ) ) if got , want := fmt . Sprintf ( \" \" , e . StackTrace ( ) [ 0 ] ) , \" \" ; got != want {", "commit_type": "make"}
{"commit_tokens": ["Fix", "string", "split", "in", "command", ".", "Run", "()", "use", "strings", ".", "Fields", "()", "instead", "of", "strings", ".", "Split", "()"], "add_tokens": "output [ i ] = strings . Fields ( l )", "del_tokens": "output [ i ] = strings . Split ( l , \" \\t \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "factory", "wrapper", "and", "extensions", "for", "ContainerMetric"], "add_tokens": "func Wrap ( event events . Event , origin string ) ( * events . Envelope , error ) { switch event := event . ( type ) { envelope . Heartbeat = event envelope . HttpStart = event envelope . HttpStop = event envelope . ValueMetric = event envelope . CounterEvent = event envelope . LogMessage = event case * events . ContainerMetric : envelope . EventType = events . Envelope_ContainerMetric . Enum ( ) envelope . ContainerMetric = event", "del_tokens": "func Wrap ( e events . Event , origin string ) ( * events . Envelope , error ) { switch e := e . ( type ) { envelope . Heartbeat = e envelope . HttpStart = e envelope . HttpStop = e envelope . ValueMetric = e envelope . CounterEvent = e envelope . LogMessage = e", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "in", "cloudfoundry", "provider", "due", "to", "nil", "http", ".", "Client"], "add_tokens": "\" \" \" \" \" \" Client : new ( http . Client ) ,", "del_tokens": "\" \" \" \" \" \"", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "RendererFactory", "in", "Par", "."], "add_tokens": "par2 := termui . NewPar ( \" \\n \\\\ \" ) par2 . RendererFactory = termui . MarkdownTextRendererFactory { }", "del_tokens": "par2 := termui . NewPar ( \" \\n \\\\ \" )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "bug", "on", "windows", "generation"], "add_tokens": "importPath = strings . Replace ( appPath , `\\` , \" \" , - 1 )", "del_tokens": "importPath = appPath", "commit_type": "fix"}
{"commit_tokens": ["use", "future", "also", "for", "publish"], "add_tokens": "func ( c * Client ) Publish ( topic string , payload [ ] byte , qos byte , retain bool ) ( * PublishFuture , error ) { err := c . send ( publish ) if err != nil { return nil , err } future := & PublishFuture { } future . initialize ( ) if qos == packet . QOSAtMostOnce { future . complete ( ) } // TODO: handle qos1 and qos2 return future , nil", "del_tokens": "func ( c * Client ) Publish ( topic string , payload [ ] byte , qos byte , retain bool ) error { return c . send ( publish )", "commit_type": "use"}
{"commit_tokens": ["fix", "wrong", "number", "of", "args", "for", "format", "in", "Errorf", "call"], "add_tokens": "t . Errorf ( \" \" , err )", "del_tokens": "t . Errorf ( \" \" , err , someErr )", "commit_type": "fix"}
{"commit_tokens": ["make", "keybindings", "work", "on", "multiwindow", "demo"], "add_tokens": "keybindings ( w )", "del_tokens": "\" \" if in := w . Input ( ) ; in != nil { k := in . Keyboard for _ , e := range k . Keys { scaling := mw . Style ( ) . Scaling switch { case ( e . Modifiers == key . ModControl || e . Modifiers == key . ModControl | key . ModShift ) && ( e . Code == key . CodeEqualSign ) : mw . Style ( ) . Scale ( scaling + 0.1 ) case ( e . Modifiers == key . ModControl || e . Modifiers == key . ModControl | key . ModShift ) && ( e . Code == key . CodeHyphenMinus ) : mw . Style ( ) . Scale ( scaling - 0.1 ) case ( e . Modifiers == key . ModControl ) && ( e . Code == key . CodeF ) : mw . SetPerf ( ! mw . GetPerf ( ) ) } } }", "commit_type": "make"}
{"commit_tokens": ["move", "KeepAlive", "to", "client", "and", "add", "an", "option", "to", "turn", "on", "reconnect"], "add_tokens": "// AutoReconnect makes the connection reset if we don't receive a ping in the KeepAliveInterval // KeepAliveInternal should almost never be overwritten. If we don't receive // a ping from twitch in that interval the connection will reset // IrcAddress can be overwritten to connect to a custom IrcServer AutoReconnect bool KeepAliveInterval time . Duration ircUser : username , ircToken : oauth , IrcAddress : ircTwitch , AutoReconnect : false , KeepAliveInterval : 360 * time . Second , if c . AutoReconnect { go c . keepConnectionAlive ( ) } } ticker := time . NewTicker ( c . KeepAliveInterval )", "del_tokens": "ircUser : username , ircToken : oauth , IrcAddress : ircTwitch , go c . keepConnectionAlive ( ) } // keepAliveInterval is for decreasing the duration tests var keepAliveInterval = 500 * time . Second ticker := time . NewTicker ( keepAliveInterval )", "commit_type": "move"}
{"commit_tokens": ["add", "support", "for", "closing", "stream", "when", "context", "is", "done"], "add_tokens": "\" \" cn : cn , codec : cc . dopts . codec , p : & parser { r : cn } , desc : desc , ctx : ctx , closing : make ( chan struct { } ) , go func ( ) { select { case <- ctx . Done ( ) : cs . CloseSend ( ) case <- cs . closing : } } ( ) ctx context . Context closing chan struct { } select { case <- c . closing : default : close ( c . closing ) } return c . ctx select { case <- c . closing : return errors . New ( \" \" ) default : } select { case <- c . closing : return errors . New ( \" \" ) default : }", "del_tokens": "cn : cn , codec : cc . dopts . codec , p : & parser { r : cn } , desc : desc , panic ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Removed", "unnecessary", "JSON", "parsing", "."], "add_tokens": "var count = 1 origSpec : d . origSpec ,", "del_tokens": "origswspec := new ( spec . Swagger ) if err := json . Unmarshal ( d . raw , origswspec ) ; err != nil { return nil , err } origSpec : origswspec ,", "commit_type": "remove"}
{"commit_tokens": ["fixed", "oneOf", "implemented", "anyOf", "and", "allOf"], "add_tokens": "if len ( currentSchema . anyOf ) > 0 { validatedAnyOf := false for _ , anyOfSchema := range currentSchema . anyOf { if ! validatedAnyOf { validationResult := anyOfSchema . Validate ( currentNode ) validatedAnyOf = validationResult . IsValid ( ) } } if ! validatedAnyOf { result . AddErrorMessage ( fmt . Sprintf ( \" \" , currentSchema . property ) ) } } nbValidated := 0 validationResult := oneOfSchema . Validate ( currentNode ) if validationResult . IsValid ( ) { nbValidated ++ if nbValidated != 1 { if len ( currentSchema . allOf ) > 0 { nbValidated := 0 for _ , allOfSchema := range currentSchema . allOf { validationResult := allOfSchema . Validate ( currentNode ) if validationResult . IsValid ( ) { nbValidated ++ } } if nbValidated != len ( currentSchema . allOf ) { result . AddErrorMessage ( fmt . Sprintf ( \" \" , currentSchema . property ) ) } }", "del_tokens": "validatedOneOf := false if ! validatedOneOf { validationResult := oneOfSchema . Validate ( currentNode ) validatedOneOf = validationResult . IsValid ( ) if ! validatedOneOf {", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "output", "deterministic", ".", "Improve", "test", "."], "add_tokens": "\" \" var goroot = runtime . GOROOT ( ) \" \" , \" \" , \" \" , \" \" , \" \" + goroot + \" \" , \" \" , \" \" , \" \" , \" \\x1b \\x1b \\x1b \" , \" \\x1b \\x1b \" , \" \\x1b \\x1b \\x1b \\x1b \" , \" \\x1b \\x1b \\x1b \\x1b \" , \" \\x1b \\x1b \\x1b \\x1b \" , actual := strings . Split ( out . String ( ) , \" \\n \" ) for i := 0 ; i < len ( actual ) && i < len ( expected ) ; i ++ { ut . AssertEqualIndex ( t , i , expected [ i ] , actual [ i ] ) } ut . AssertEqual ( t , expected , actual )", "del_tokens": "\" \\x1b \\x1b \\x1b \" , ut . AssertEqual ( t , strings . Join ( expected , \" \\n \" ) , out . String ( ) )", "commit_type": "make"}
{"commit_tokens": ["add", "more", "tests", "to", "json", "codec"], "add_tokens": "\" \"", "del_tokens": "/ * * /", "commit_type": "add"}
{"commit_tokens": ["Fix", "data", "race", "on", "Unsubscribe", "()", "when", "connection", "is", "closed", "in", "parallel", "."], "add_tokens": "// Snapshot connection to avoid data race, since the connection may be // closing while we try to send the request nc := sc . nc reply , err := nc . Request ( reqSubject , b , 2 * time . Second )", "del_tokens": "reply , err := sc . nc . Request ( reqSubject , b , 2 * time . Second )", "commit_type": "fix"}
{"commit_tokens": ["Add", "VIPs", "to", "interface", "in", "IPVS", "director"], "add_tokens": "Disco string Endpoints [ ] net . IP Flush bool ListenPort uint16 VipInterface string", "del_tokens": "Disco string Endpoints [ ] net . IP Flush bool ListenPort uint16", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "OAuth2", "client", "credentials", "flow"], "add_tokens": "\" \" \" \" options := registry . Options { Context : context . Background ( ) , } if c , ok := options . Context . Value ( contextHttpClient { } ) . ( * http . Client ) ; ok { fargo . HttpClient = c }", "del_tokens": "var options registry . Options", "commit_type": "allow"}
{"commit_tokens": ["Add", "an", "ability", "to", "mark", "error", "as", "unrecoverable"], "add_tokens": "retryIf : IsRecoverable , errorLog [ n ] = unpackUnrecoverable ( err ) type unrecoverableError struct { inner error } func ( err unrecoverableError ) Error ( ) string { return err . inner . Error ( ) } // Unrecoverable wraps an error in `unrecoverableError` struct func Unrecoverable ( err error ) unrecoverableError { return unrecoverableError { err } } // IsRecoverable checks if error is an instance of `unrecoverableError` func IsRecoverable ( err error ) bool { _ , isUnrecoverable := err . ( unrecoverableError ) return ! isUnrecoverable } func unpackUnrecoverable ( err error ) error { if unrecoverable , isUnrecoverable := err . ( unrecoverableError ) ; isUnrecoverable { return unrecoverable . inner } return err }", "del_tokens": "retryIf : func ( err error ) bool { return true } , errorLog [ n ] = err", "commit_type": "add"}
{"commit_tokens": ["Changed", "fmt", ".", "Sprintf", "for", "strconv", ".", "FormatInt"], "add_tokens": "\" \" args = append ( args , strconv . FormatInt ( int64 ( v ) , 10 ) )", "del_tokens": "\" \" args = append ( args , fmt . Sprintf ( \" \" , v ) )", "commit_type": "change"}
{"commit_tokens": ["Add", "missing", "yaml", "attributes", "to", "structs"], "add_tokens": "Metadata api . ObjectMeta `json:\"metadata\" yaml:\"metadata\"`", "del_tokens": "Metadata api . ObjectMeta `json:\"metadata\"`", "commit_type": "add"}
{"commit_tokens": ["Allow", "var", "def", "to", "infer", "type", "from", "right", "-", "hand", "side", "."], "add_tokens": "var Block100000 = btcwire . MsgBlock {", "del_tokens": "var Block100000 btcwire . MsgBlock = btcwire . MsgBlock {", "commit_type": "allow"}
{"commit_tokens": ["adding", "destination", "creation", "and", "deletion", "via", "api"], "add_tokens": "as . router . POST ( \" \" , as . destinationCreate )", "del_tokens": "as . router . POST ( \" \" , as . destinationUpsert )", "commit_type": "add"}
{"commit_tokens": ["Use", "current", "groupName", "not", "what", "was", "originally", "passed"], "add_tokens": "gr . groupName ,", "del_tokens": "groupName ,", "commit_type": "use"}
{"commit_tokens": ["Use", "new", "goavro", "types", "for", "Fixed", "and", "Enum", "in", "unit", "tests"], "add_tokens": "if recordVal . ( goavro . Enum ) . Value != f . EnumField . String ( ) {", "del_tokens": "if recordVal . ( string ) != f . EnumField . String ( ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "passing", "build", "args", "via", "--", "build", "-", "arg", "flag"], "add_tokens": "arguments := stringMapFlag { } flag . Var ( & arguments , \" \" , \" \" ) type stringMapFlag map [ string ] string func ( f * stringMapFlag ) String ( ) string { args := [ ] string { } for k , v := range * f { args = append ( args , strings . Join ( [ ] string { k , v } , \" \" ) ) } return strings . Join ( args , \" \" ) } func ( f * stringMapFlag ) Set ( value string ) error { kv := strings . Split ( value , \" \" ) ( * f ) [ kv [ 0 ] ] = kv [ 1 ] return nil }", "del_tokens": "// Accept ARGS on the command line arguments := make ( map [ string ] string )", "commit_type": "add"}
{"commit_tokens": ["add", "timed", "rotating", "file", "handler", "and", "test"], "add_tokens": "if _ , err := os . Stat ( filename ) ; err != nil { if e == nil { // Emit a record.", "del_tokens": "_ , err := os . Stat ( filename ) if err != nil { if err == nil {", "commit_type": "add"}
{"commit_tokens": ["fix", "validation", "of", "spec", "with", "local", "file", "references"], "add_tokens": "func ( s * SpecValidator ) resolveRef ( ref * spec . Ref ) ( * spec . Schema , error ) { if s . spec . SpecFilePath ( ) != \" \" { return spec . ResolveRefWithBase ( s . spec . Spec ( ) , ref , & spec . ExpandOptions { RelativeBase : s . spec . SpecFilePath ( ) } ) } return spec . ResolveRef ( s . spec . Spec ( ) , ref ) } reso , err := s . resolveRef ( & schc . Ref ) reso , err := s . resolveRef ( & schc . Ref ) if ! r . IsValidURI ( s . spec . SpecFilePath ( ) ) {", "del_tokens": "reso , err := spec . ResolveRef ( s . spec . Spec ( ) , & schc . Ref ) reso , err := spec . ResolveRef ( s . spec . Spec ( ) , & schc . Ref ) if ! r . IsValidURI ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "linting", "fail", "if", "warnings", "are", "present"], "add_tokens": "// Option configures a Limiter.", "del_tokens": "// option configures a Limiter.", "commit_type": "make"}
{"commit_tokens": ["Added", "base", "tests", "for", "gocd", "client"], "add_tokens": "Name * string `json:\"name\"` Stages [ ] Stage `json:\"stages\"` Collection [ ] PipelineGroup }", "del_tokens": "Name * string `json:\"name\"` Groups [ ] PipelineGroup }", "commit_type": "add"}
{"commit_tokens": ["Added", "metric", "server", "and", "first", "metrics"], "add_tokens": "const ( metricMsgSec = \" \" metricCons = \" \" metricProds = \" \" metricStreams = \" \" ) Log . Metric . New ( metricMsgSec ) Log . Metric . New ( metricCons ) Log . Metric . New ( metricProds ) Log . Metric . New ( metricStreams ) Log . Metric . SetI ( metricCons , len ( plex . consumers ) ) Log . Metric . SetI ( metricProds , len ( plex . producers ) ) Log . Metric . SetI ( metricStreams , len ( plex . managedStream ) ) duration := time . Since ( measure ) if messageCount >= 100000 || duration . Seconds ( ) > 5 { value := float64 ( messageCount ) / duration . Seconds ( ) if plex . profile { Log . Note . Printf ( \" \" , value ) Log . Metric . SetF ( metricMsgSec , value ) measure = time . Now ( ) messageCount = 0", "del_tokens": "if plex . profile { duration := time . Since ( measure ) if messageCount >= 100000 || duration . Seconds ( ) > 5 { Log . Note . Printf ( \" \" , float64 ( messageCount ) / duration . Seconds ( ) ) measure = time . Now ( ) messageCount = 0", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "gauges", "with", "callback"], "add_tokens": "\" \" mutex * sync . Mutex gauges [ ] gaugeWithCallback } type gaugeWithCallback struct { gauge metrics . Gauge callback func ( ) int64 mutex : & sync . Mutex { } , gauges : [ ] gaugeWithCallback { } , go metrics . collectMetrics ( ) // AddGauge installs a callback for a gauge with the given name. The callback // will be called every metrics collection interval, and should provide an // updated value for the gauge. func ( mb * SquareMetrics ) AddGauge ( name string , callback func ( ) int64 ) { mb . mutex . Lock ( ) defer mb . mutex . Unlock ( ) mb . gauges = append ( mb . gauges , gaugeWithCallback { metrics . GetOrRegisterGauge ( name , mb . Registry ) , callback } ) } func ( mb * SquareMetrics ) collectMetrics ( ) { // Update gauges mb . mutex . Lock ( ) for _ , gauge := range mb . gauges { gauge . gauge . Update ( gauge . callback ( ) ) } mb . mutex . Unlock ( )", "del_tokens": "go metrics . collectSystemMetrics ( ) func ( mb * SquareMetrics ) collectSystemMetrics ( ) {", "commit_type": "add"}
{"commit_tokens": ["Allow", "using", "limitListener", "with", "TCP", "Keep", "-", "Alive"], "add_tokens": "listener = keepAliveListener { listener , srv . TCPKeepAlive } type keepAliveConn interface { SetKeepAlive ( bool ) error SetKeepAlivePeriod ( d time . Duration ) error } // keepAliveListener sets TCP keep-alive timeouts on accepted type keepAliveListener struct { net . Listener func ( ln keepAliveListener ) Accept ( ) ( net . Conn , error ) { c , err := ln . Listener . Accept ( ) return nil , err kac := c . ( keepAliveConn ) kac . SetKeepAlive ( true ) kac . SetKeepAlivePeriod ( ln . keepAlivePeriod ) return c , nil", "del_tokens": "listener = tcpKeepAliveListener { listener . ( * net . TCPListener ) , srv . TCPKeepAlive } // tcpKeepAliveListener sets TCP keep-alive timeouts on accepted type tcpKeepAliveListener struct { * net . TCPListener func ( ln tcpKeepAliveListener ) Accept ( ) ( c net . Conn , err error ) { tc , err := ln . AcceptTCP ( ) return tc . SetKeepAlive ( true ) tc . SetKeepAlivePeriod ( ln . keepAlivePeriod ) return tc , nil", "commit_type": "allow"}
{"commit_tokens": ["Add", "newline", "to", "parse", "errors"], "add_tokens": "fmt . Printf ( \" \\n \" , oldRevID , err . Error ( ) ) fmt . Printf ( \" \\n \" , newRevID , err . Error ( ) )", "del_tokens": "fmt . Printf ( \" \" , oldRevID , err . Error ( ) ) fmt . Printf ( \" \" , newRevID , err . Error ( ) )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "user", "error", "if", "the", "http", "method", "is", "not", "supported"], "add_tokens": "server . sendError ( writer , imageserver . NewError ( \" \" ) )", "del_tokens": "server . sendError ( writer , fmt . Errorf ( \" \" ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "custom", "iops", "+", "size", "to", "volume", "and", "disk", "offering", "(", "+", "removed", "storage", "tier", ")"], "add_tokens": "Id string `json:\"id,omitempty\"` Name string `json:\"name,omitempty\"` GbSize int `json:\"gbSize,omitempty\"` MinIops int `json:\"minIops,omitempty\"` MaxIops int `json:\"maxIops,omitempty\"` CustomSize bool `json:\"customSize,omitempty\"` CustomIops bool `json:\"customIops,omitempty\"`", "del_tokens": "Id string `json:\"id,omitempty\"` Name string `json:\"name,omitempty\"` GbSize int `json:\"gbSize,omitempty\"` StorageTier string `json:\"storageTier,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "we", "free", "our", "data", "made", "by", "C", ".", "CString", ".", "Also", "updated", "cgo", "comments", "to", "multiline", "-", "seems", "to", "be", "preferred", "style"], "add_tokens": "/ * # include < iconv . h > # include < stdlib . h > * / // create C strings toEncodingC := C . CString ( toEncoding ) fromEncodingC := C . CString ( fromEncoding ) // open an iconv descriptor converter . context , err = C . iconv_open ( toEncodingC , fromEncodingC ) // free the C Strings C . free ( unsafe . Pointer ( toEncodingC ) ) C . free ( unsafe . Pointer ( fromEncodingC ) )", "del_tokens": "// #include <iconv.h> converter . context , err = C . iconv_open ( C . CString ( toEncoding ) , C . CString ( fromEncoding ) )", "commit_type": "make"}
{"commit_tokens": ["Changed", "default", "New", "to", "use", "NewWithClaims", "internally", "."], "add_tokens": "return NewWithClaims ( method , MapClaim { } )", "del_tokens": "return & Token { Header : map [ string ] interface { } { \" \" : \" \" , \" \" : method . Alg ( ) , } , Claims : MapClaim { } , Method : method , }", "commit_type": "change"}
{"commit_tokens": ["Added", "comment", "about", "randexp", "to", "package", "doc", "."], "add_tokens": "The generated strings will match the expressions they were generated from . Similar to Ruby 's randexp library .", "del_tokens": "The generated strings will match the expressions they were generated from .", "commit_type": "add"}
{"commit_tokens": ["Add", "deadline", "and", "hour", "rules", "for", "ru", "locale"], "add_tokens": "// Weekday(rules.OverWrite), CasualDate ( rules . OverWrite ) , CasualTime ( rules . OverWrite ) , Deadline ( rules . OverWrite ) , Hour ( rules . OverWrite ) , // HourMinute(rules.OverWrite), \" \" var INTEGER_WORDS_PATTERN = `(?:час|один|одну|одного|два|две|три|четыре|пять|шесть|семь|восемь|девять|десять|одиннадцать|двенадцать)`", "del_tokens": "// Weekday(rules.OverWrite), // CasualDate(rules.OverWrite), // CasualTime(rules.OverWrite), // Deadline(rules.OverWrite), // Hour(rules.OverWrite), // HourMinute(rules.OverWrite), var INTEGER_WORDS_PATTERN = `(?:один|одну|два|две|три|четыре|пять|шесть|семь|восемь|девять|десять|одиннадцать|двенадцать)`", "commit_type": "add"}
{"commit_tokens": ["Fix", "links", "and", "add", "godoc", "badge"], "add_tokens": "// go which compiles to javascript via gopherjs (https://github.com/gopherjs/gopherjs). // packages in the Humble Framework (https://github.com/go-humble/humble).", "del_tokens": "// go which compiles to javascript via [gopherjs](github.com/gopherjs/gopherjs). // packages in the Humble Framework (See github.com/go-humble/humble).", "commit_type": "fix"}
{"commit_tokens": ["Removes", "error", "in", "the", "return", "statement", "of", "isPerfData"], "add_tokens": "} else if isPerfFile ( source ) { // isPerfFile checks if a file is in perf.data format. It also returns false // if it encounters an error during the check. func isPerfFile ( path string ) bool { return false return false return bytes . Equal ( actualHeader , perfHeader )", "del_tokens": "} else if isPerf , isPerfErr := isPerfFile ( source ) ; isPerf { // Since the if statement is a new scope, if isPerfErr is named // err, it shadows the err in the return, and does not compile. if isPerfErr != nil { return nil , \" \" , isPerfErr } // isPerfFile checks if a file is in perf.data format. func isPerfFile ( path string ) ( bool , error ) { return false , openErr return false , readErr return bytes . Equal ( actualHeader , perfHeader ) , nil", "commit_type": "remove"}
{"commit_tokens": ["add", "tests", "for", "command", "timeouts", "and", "environments"], "add_tokens": "Script string `json:\"script\"` Env [ ] [ ] string `json:\"env\"` Timeout time . Duration `json:\"timeout\"`", "del_tokens": "Script string Env [ ] [ ] string Timeout time . Duration type runActionSerialized struct { Script string `json:\"script\"` TimeoutInSeconds uint64 `json:\"timeout_in_seconds\"` Env [ ] [ ] string `json:\"env\"` } func ( a RunAction ) MarshalJSON ( ) ( [ ] byte , error ) { return json . Marshal ( runActionSerialized { Script : a . Script , TimeoutInSeconds : uint64 ( a . Timeout / time . Second ) , Env : a . Env , } ) } func ( a * RunAction ) UnmarshalJSON ( payload [ ] byte ) error { var intermediate runActionSerialized err := json . Unmarshal ( payload , & intermediate ) if err != nil { return err } a . Script = intermediate . Script a . Timeout = time . Duration ( intermediate . TimeoutInSeconds ) * time . Second a . Env = intermediate . Env return nil }", "commit_type": "add"}
{"commit_tokens": ["Updated", "OS", "validation", "and", "added", "Paths"], "add_tokens": "validOSes = map [ string ] bool { \" \" : true , \" \" : true , \" \" : true , } if ! IsValidOS ( runtime . GOOS ) { err = errors . Wrapf ( err , \" \" ) // Init // IsValidOS validates the OS func IsValidOS ( os string ) ( ok bool ) { _ , ok = validOSes [ os ] return // Paths returns the paths func ( a * Astilectron ) Paths ( ) Paths { return * a . paths }", "del_tokens": "\" \" \" \" validOSes = [ ] string { \" \" , \" \" , \" \" } if err = validateOS ( runtime . GOOS ) ; err != nil { err = errors . Wrap ( err , \" \" ) // validateOS validates the OS func validateOS ( os string ) error { if ! astislice . InStringSlice ( os , validOSes ) { return fmt . Errorf ( \" \" , os ) } return nil } // ValidOSes returns a slice containing the names of all currently supported operating systems func ValidOSes ( ) [ ] string { return append ( make ( [ ] string , 0 , len ( validOSes ) ) , validOSes ... )", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "latest", "md", "-", "to", "-", "godoc"], "add_tokens": "// Copyright (c) 2016 Uber Technologies, Inc. // // Permission is hereby granted, free of charge, to any person obtaining a copy // of this software and associated documentation files (the \"Software\"), to deal // in the Software without restriction, including without limitation the rights // to use, copy, modify, merge, publish, distribute, sublicense, and/or sell // copies of the Software, and to permit persons to whom the Software is // furnished to do so, subject to the following conditions: // // The above copyright notice and this permission notice shall be included in // all copies or substantial portions of the Software. // // THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR // IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, // FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN // THE SOFTWARE. // Package core is the Framework Core. // // The core package contains the nuts and bolts useful to have in a fully-fledged // service, but are not specific to an instance of a service or even the idea of a // service. // // // If, for example, you just want use the configuration logic from UberFx, you // could import // go.uber.org/core/config and use it in a stand-alone CLI app. // // It is separate from theservice package, which contains logic specifically to // a running service. // // //", "del_tokens": "/ * Package core is the Framework Core . The core package contains the nuts and bolts useful to have in a fully - fledged service , but are not specific to an instance of a service or even the idea of a service . If , for example , you just want use the configuration logic from UberFx , you could import go . uber . org / core / config and use it in a stand - alone CLI app . It is separate from the service package , which contains logic specifically to a running service . * /", "commit_type": "update"}
{"commit_tokens": ["Fixing", "some", "minor", "problems", "in", "the", "test", "code", "found", "by", "gometalinter"], "add_tokens": "t . Errorf ( \" \" , i , err ) for key := range s {", "del_tokens": "t . Errorf ( \" \" , err ) for key , _ := range s {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "CodeToVarint", "[]", "byte", "size"], "add_tokens": "\" \" buf := make ( [ ] byte , bits . Len ( uint ( num ) ) / 7 + 1 )", "del_tokens": "buf := make ( [ ] byte , ( num / 7 ) + 1 ) // varint package is uint64", "commit_type": "fix"}
{"commit_tokens": ["Add", "CPUInfo", ".", "AmxFeatures", "detect", "AMXBF16", "AMXTILE", "and", "AMXINT8"], "add_tokens": "c . Features , c . AmxFeatures = support ( )", "del_tokens": "c . Features = support ( )", "commit_type": "add"}
{"commit_tokens": ["Move", "UniqueID", "generation", "from", "a", "global", "to", "an", "argument", "."], "add_tokens": "// UniqueIDProvider generates a sequence of unique identifiers useful for, // among other things, lock ordering. type UniqueIDProvider interface { // UniqueID returns a new unique identifier. UniqueID ( ) uint64 // idGenerator is used to generate new unique endpoint identifiers. idGenerator UniqueIDProvider func NewConnectioned ( stype SockType , uid UniqueIDProvider ) Endpoint { id : uid . UniqueID ( ) , idGenerator : uid , func NewPair ( stype SockType , uid UniqueIDProvider ) ( Endpoint , Endpoint ) { id : uid . UniqueID ( ) , idGenerator : uid , id : uid . UniqueID ( ) , idGenerator : uid , id : e . idGenerator . UniqueID ( ) , idGenerator : e . idGenerator , stype : e . stype ,", "del_tokens": "\" \" // lastID is the last endpoint id issued by UniqueID. It must be accessed // atomically. var lastID uint64 // UniqueID is used to generate endpoint ids. func UniqueID ( ) uint64 { return atomic . AddUint64 ( & lastID , 1 ) func NewConnectioned ( stype SockType ) Endpoint { id : UniqueID ( ) , func NewPair ( stype SockType ) ( Endpoint , Endpoint ) { id : UniqueID ( ) , id : UniqueID ( ) , id : UniqueID ( ) , stype : e . stype ,", "commit_type": "move"}
{"commit_tokens": ["Fix", "a", "spelling", "mistake", "in", "the", "message", "."], "add_tokens": "errMsg += \" \\n \"", "del_tokens": "errMsg += \" \\n \"", "commit_type": "fix"}
{"commit_tokens": ["use", "buffer", "as", "logger", "everywhere", "prepare", "robots", ".", "txt", "tests"], "add_tokens": "\" \" opts . Logger = log . New ( b , \" \" , 0 )", "del_tokens": "//\"log\" //opts.Logger = log.New(b, \"\", 0)", "commit_type": "use"}
{"commit_tokens": ["Add", "function", "to", "set", "a", "users", "avatar"], "add_tokens": "// res, err := cli.MakeRequest(\"GET\", urlPath, nil, &s) _ , err = cli . MakeRequest ( \" \" , urlPath , nil , & s ) // if err = json.Unmarshal(res, &s); err != nil { // return \"\", err // } return s . AvatarURL , nil } // SetAvatarURL sets the user's avatar URL. See http://matrix.org/docs/spec/client_server/r0.2.0.html#put-matrix-client-r0-profile-userid-avatar-url func ( cli * Client ) SetAvatarURL ( url string ) ( err error ) { urlPath := cli . BuildURL ( \" \" , cli . UserID , \" \" ) s := struct { AvatarURL string `json:\"avatar_url\"` } { url } res , err := cli . MakeRequest ( \" \" , urlPath , & s , nil ) if err != nil { return err } return err return nil", "del_tokens": "res , err := cli . MakeRequest ( \" \" , urlPath , & s , nil ) return \" \" , err return s . AvatarURL , nil", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "that", "the", "easy", "supervisor", "is", "persistent"], "add_tokens": "MaxRestarts : supervisor . AlwaysRestart , Log : func ( interface { } ) { } ,", "del_tokens": "Log : func ( interface { } ) { } ,", "commit_type": "make"}
{"commit_tokens": ["Make", "package", "summary", "a", "little", "more", "accurate", "(", "for", "now", ")"], "add_tokens": "Package dot implements an API to produce Graphviz dot language output .", "del_tokens": "Package dot implements Graphviz 's dot language in Go .", "commit_type": "make"}
{"commit_tokens": ["add", "unit", "test", "for", "CallWithRetry"], "add_tokens": "result , err := zkClient . newRetryLoop ( ) . CallWithRetry ( func ( ) ( interface { } , error ) { result , err := zkClient . newRetryLoop ( ) . CallWithRetry ( func ( ) ( interface { } , error ) {", "del_tokens": "result , err := zkClient . newRetryLoop ( ) . callWithRetry ( func ( ) ( interface { } , error ) { result , err := zkClient . newRetryLoop ( ) . callWithRetry ( func ( ) ( interface { } , error ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "fail", "and", "assert", "functions"], "add_tokens": "func TestAWSFuncs ( t * testing . T ) {", "del_tokens": "func TestFuncs ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["add", "RemoveFileLogged", "()", ";", "rename", "UserHomeDir", "()", "=", ">", "UserHomeDirMust", "()"], "add_tokens": "func UserHomeDirMust ( ) string { return UserHomeDirMust ( ) + s [ 1 : ]", "del_tokens": "func UserHomeDir ( ) string { return UserHomeDir ( ) + s [ 1 : ]", "commit_type": "add"}
{"commit_tokens": ["Make", "build", "request", "method", "private"], "add_tokens": "insertRequest := buildBigQueryInsertRequest ( [ ] map [ string ] interface { } { rowData } ) insertRequest := buildBigQueryInsertRequest ( rows ) func buildBigQueryInsertRequest ( rows [ ] map [ string ] interface { } ) * bigquery . TableDataInsertAllRequest {", "del_tokens": "insertRequest := BuildBigQueryInsertRequest ( [ ] map [ string ] interface { } { rowData } ) insertRequest := BuildBigQueryInsertRequest ( rows ) func BuildBigQueryInsertRequest ( rows [ ] map [ string ] interface { } ) * bigquery . TableDataInsertAllRequest {", "commit_type": "make"}
{"commit_tokens": ["Change", "some", "Error", "=", ">", "Errorf", "in", "tests", "in", "seq"], "add_tokens": "t . Errorf ( \" \" , 3 , s3 . Count ( ) ) t . Errorf ( \" \" , i ) t . Errorf ( \" \" , i )", "del_tokens": "t . Errorf ( \" \" , s3 . Count ( ) ) t . Error ( \" \" , i ) t . Error ( \" \" , i )", "commit_type": "change"}
{"commit_tokens": ["Use", "powerOf", "in", "extension", "test"], "add_tokens": "if err := c . AddResource ( \" \" , strings . NewReader ( `{\"powerOf\": \"hello\"}` ) ) ; err != nil { if err := c . AddResource ( \" \" , strings . NewReader ( `{\"powerOf\": 10}` ) ) ; err != nil { if ! strings . Contains ( err . Error ( ) , \" \" ) { t . Fatal ( \" \" ) }", "del_tokens": "if err := c . AddResource ( \" \" , strings . NewReader ( `{\"multipleOf\": \"hello\"}` ) ) ; err != nil { if err := c . AddResource ( \" \" , strings . NewReader ( `{\"multipleOf\": 10}` ) ) ; err != nil {", "commit_type": "use"}
{"commit_tokens": ["Fix", "panic", "in", "Run", "()", "&", "Restore", "()"], "add_tokens": "if opts != nil && opts . IO != nil { if opts != nil && opts . IO != nil {", "del_tokens": "if opts != nil { if opts != nil {", "commit_type": "fix"}
{"commit_tokens": ["use", "correct", "zero", "for", "custom", "alphabets"], "add_tokens": "zero := alphabet . encode [ 0 ] b58 [ i ] = zero zero := alphabet . encode [ 0 ] buf [ idx ] = zero zero = rune ( alphabet . encode [ 0 ] ) for i := 0 ; i < b58sz && b58u [ i ] == zero ; i ++ { zero := alphabet . encode [ 0 ] for i := 0 ; i < len ( str ) && str [ i ] == zero ; i ++ {", "del_tokens": "b58 [ i ] = '1' buf [ idx ] = alphabet . encode [ 0 ] for i := 0 ; i < b58sz && b58u [ i ] == '1' ; i ++ { for i := 0 ; i < len ( str ) && str [ i ] == '1' ; i ++ {", "commit_type": "use"}
{"commit_tokens": ["change", "auto", "color", "system", "to", "HCL", "color", "space"], "add_tokens": "\" \" , sat_offset := utils . Map ( utils . Hex_val ( p . Hash , 17 , 1 ) , 0 , 15 , - 1 , 1 ) h , c , l := color . Hcl ( ) if sat_offset >= 0 { c += float64 ( sat_offset ) c -= float64 ( sat_offset ) rgb = colorful . Color { h , c , l } r , g , b := int ( rgb . R / 2 ) , int ( rgb . G * 105 ) , int ( rgb . B * 150 ) fmt . Println ( p . Generator )", "del_tokens": "\" \" , sat_offset := int ( utils . Hex_val ( p . Hash , 17 , 1 ) ) h , s , v := color . Hsv ( ) if sat_offset % 2 == 0 { s += float64 ( sat_offset ) s -= float64 ( sat_offset ) rgb = colorful . Color { h , s , v } r , g , b := int ( rgb . R * 255 ) , int ( rgb . G * 255 ) , int ( rgb . B * 255 ) fmt . Println ( ( ring_size + stroke_width ) * 6 )", "commit_type": "change"}
{"commit_tokens": ["Implement", "option", "for", "manual", "update", "of", "progressbar"], "add_tokens": "ManualUpdate : false , currentValue : - 1 , ManualUpdate bool isFinish bool startTime time . Time currentValue int64 if ! pb . ManualUpdate { go pb . writer ( ) } // Write the current state of the progressbar func ( pb * ProgressBar ) Update ( ) { c := atomic . LoadInt64 ( & pb . current ) if c != pb . currentValue { pb . write ( c ) pb . currentValue = c } } // Internal loop for writing progressbar pb . Update ( )", "del_tokens": "isFinish bool startTime time . Time go pb . writer ( ) var c , oc int64 oc = - 1 c = atomic . LoadInt64 ( & pb . current ) if c != oc { pb . write ( c ) oc = c }", "commit_type": "implement"}
{"commit_tokens": ["fixed", "a", "small", "bug", "now", "just", "run", "-", "I", "if", "no", "args"], "add_tokens": "* I , * J = true , false", "del_tokens": "fmt . Printf ( \" \\n \" ) * I , * J = true , true", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "stronger", "return", "value", "binding", "from", "template", "context", "functions"], "add_tokens": "func ( t * Template ) dependencyAcc ( d * [ ] Dependency , dt DependencyType ) func ( string ) ( interface { } , error ) { func ( c * TemplateContext ) Evaluator ( dt DependencyType ) func ( string ) ( interface { } , error ) {", "del_tokens": "func ( t * Template ) dependencyAcc ( d * [ ] Dependency , dt DependencyType ) interface { } { func ( c * TemplateContext ) Evaluator ( dt DependencyType ) interface { } {", "commit_type": "use"}
{"commit_tokens": ["use", "the", "versioned", "sarama", "client"], "add_tokens": "sarama \" \" exit : make ( chan bool ) , t := thrift . NewTMemoryBuffer ( ) Key : nil , c , err := sarama . NewClient ( z . opts . Collectors , sarama . NewConfig ( ) ) if err != nil { return } p , err := sarama . NewSyncProducerFromClient ( c ) if err != nil { return }", "del_tokens": "\" \" t := thrift . NewTMemoryBufferLen ( 1024 ) p , _ := sarama . NewSyncProducer ( z . opts . Collectors , sarama . NewConfig ( ) )", "commit_type": "use"}
{"commit_tokens": ["Adds", "Pdbgf", "in", "the", "list", "of", "breaks"], "add_tokens": "newpdbg . breaks = append ( newpdbg . breaks , \" \" ) // fmt.Printf(\"'%s' (%s) => '%+v'\\n\", line, rxDbgLine.String(), m)", "del_tokens": "//fmt.Printf(\"'%s' (%s) => '%+v'\\n\", line, rxDbgLine.String(), m)", "commit_type": "add"}
{"commit_tokens": ["Move", "cache", "to", "top", "level", "to", "make", "clear", "it", "can", "be", "used", "elsewhere"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Creating", "a", "function", "to", "lookup", "medications", "."], "add_tokens": "import ( \" \" \" \" \" \" \" \" ) type MedicationLookup func ( id string ) ( Medication , error ) func MedicationFinder ( database mgo . Database , idString string ) ( Medication , error ) { var id bson . ObjectId if bson . IsObjectIdHex ( idString ) { id = bson . ObjectIdHex ( idString ) } else { return Medication { } , errors . New ( \" \" ) } c := database . C ( \" \" ) result := Medication { } err := c . Find ( bson . M { \" \" : id . Hex ( ) } ) . One ( & result ) if err != nil { return Medication { } , err } return result , nil } func BindMedicationLookup ( database mgo . Database ) MedicationLookup { return func ( id string ) ( Medication , error ) { return MedicationFinder ( database , id ) } }", "del_tokens": "import \" \"", "commit_type": "create"}
{"commit_tokens": ["add", "support", "for", "git", "+", "prefix"], "add_tokens": "return strings . HasPrefix ( url , \" \" ) || strings . HasPrefix ( url , \" \" ) || strings . HasSuffix ( url , \" \" ) if strings . HasPrefix ( url , \" \" ) { url = url [ len ( \" \" ) : ] }", "del_tokens": "return strings . HasPrefix ( url , \" \" ) || strings . HasSuffix ( url , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "separate", "screen", "buffer", "for", "termbox", "business", "on", "Windows", "OS", "."], "add_tokens": "w , h := get_win_size ( out ) orig_screen = out out , err = create_console_screen_buffer ( ) if err != nil { return err } err = set_console_screen_buffer_size ( out , coord { short ( w ) , short ( h ) } ) if err != nil { return err } err = set_console_active_screen_buffer ( out ) if err != nil { return err } show_cursor ( false ) // we ignore errors here, because we can't really do anything about them set_console_active_screen_buffer ( orig_screen )", "del_tokens": "show_cursor ( false )", "commit_type": "use"}
{"commit_tokens": ["add", "pagination", "support", "to", "Activity", ".", "ListWatchers"], "add_tokens": "func ( s * ActivityService ) ListWatchers ( owner , repo string , opt * ListOptions ) ( [ ] User , * Response , error ) { u , err := addOptions ( u , opt ) if err != nil { return nil , nil , err }", "del_tokens": "func ( s * ActivityService ) ListWatchers ( owner , repo string ) ( [ ] User , * Response , error ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "s", "to", "a", "verb", "write"], "add_tokens": "// Write writes data on console", "del_tokens": "// Write data on console", "commit_type": "add"}
{"commit_tokens": ["Fix", "nil", "pointer", "deref", "in", "panic", "recovery"], "add_tokens": "if err := recover ( ) ; err != nil && r . ErrorHandler != nil {", "del_tokens": "if err := recover ( ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["update", "config", "doc", "and", "add", "test", "case", "for", "large", "streams"], "add_tokens": "// Config contains the format configuration. The only field // which must always be set manually is the secret key. // The minimal supported version of the format. If // The highest supported version of the format. If", "del_tokens": "// Config contains the protocol configuration. The only field // which must always be set manually is the secret key // The minimal supported version of the protocol. If // The highest supported version of the protocol. If", "commit_type": "update"}
{"commit_tokens": ["Implement", "an", "improved", "namespaced", "element", "search"], "add_tokens": "\" \" sig , err := etreeutils . FindElement ( el , Namespace , SignatureTag ) if err != nil { return nil , err }", "del_tokens": "sig := el . FindElement ( SignatureTag ) if ! inNamespace ( sig , Namespace ) { return nil , errors . New ( \" \" ) }", "commit_type": "implement"}
{"commit_tokens": ["Fix", "cancelling", "request", "when", "websocket", "request", "is", "cancelled", "."], "add_tokens": "request , err := http . NewRequestWithContext ( r . Context ( ) , r . Method , r . URL . String ( ) , requestBodyR )", "del_tokens": "request , err := http . NewRequest ( r . Method , r . URL . String ( ) , requestBodyR )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "regex", "of", "unix", "path"], "add_tokens": "UnixPath string = `^((?:\\.{0,2})?(?:\\/[a-zA-Z0-9\\.\\:]*(?:_[a-zA-Z0-9\\:\\.]+)*(?:\\-[\\:a-zA-Z0-9\\.]+)*)*\\/?)$`", "del_tokens": "UnixPath string = `^((?:\\.{0,2}\\/[a-zA-Z0-9\\.\\:]+(?:_[a-zA-Z0-9\\:\\.]+)*(?:\\-[\\:a-zA-Z0-9\\.]+)*)+\\/?)$`", "commit_type": "fix"}
{"commit_tokens": ["Fix", "up", "a", "couple", "of", "other", "imports", "to", "use", "the", "new", "package", "name", "."], "add_tokens": "\" \" var opts [ ] grpc . DialOption opts = append ( opts , grpc . WithClientTLS ( creds ) ) conn , err := grpc . Dial ( serverAddr , opts ... )", "del_tokens": "\" \" var opts [ ] rpc . DialOption opts = append ( opts , rpc . WithClientTLS ( creds ) ) conn , err := rpc . Dial ( serverAddr , opts ... )", "commit_type": "fix"}
{"commit_tokens": ["fix", "doc", "comment", "for", "DeviceID"], "add_tokens": "// DeviceID is a MIDI device ID.", "del_tokens": "// DeviceId is a MIDI device ID.", "commit_type": "fix"}
{"commit_tokens": ["improve", "tests", "for", "decoder", "errors"], "add_tokens": "if validate { if validProp , validVal := validProperty ( k . name , v ) ; ! validProp { d . warn ( properties . pos ( k ) , \" \" , k . name , v ) } else if ! validVal { d . warn ( properties . pos ( k ) , \" \" , k . name , v ) } d . error ( d . pos ( tok ) , \" \" , tok )", "del_tokens": "func ( a position ) Less ( b position ) bool { if a . filenum != b . filenum { return a . filenum < b . filenum } return a . line < b . line } if validate && ! validProperty ( k . name , v ) { d . warn ( properties . pos ( k ) , \" \" , k . name , v ) d . error ( d . pos ( tok ) , \" \" , tok )", "commit_type": "improve"}
{"commit_tokens": ["Use", "an", "options", "struct", "for", "StandardLogger"], "add_tokens": "func ( z * intLogger ) StandardLogger ( opts * StandardLoggerOptions ) * log . Logger { if opts == nil { opts = & StandardLoggerOptions { } } return log . New ( & stdlogAdapter { z , opts . InferLevels } , \" \" , 0 )", "del_tokens": "func ( z * intLogger ) StandardLogger ( inferLevels bool ) * log . Logger { return log . New ( & stdlogAdapter { z , inferLevels } , \" \" , 0 )", "commit_type": "use"}
{"commit_tokens": ["Add", "complete", "event", "struct", "for", "timeboards"], "add_tokens": "Title string `json:\"title\"` Events [ ] struct { Query string `json:\"q\"` } `json:\"events\"`", "del_tokens": "Title string `json:\"title\"` Events [ ] struct { } `json:\"events\"`", "commit_type": "add"}
{"commit_tokens": ["Allow", "os", "or", "arch", "command", "line", "flag", "to", "be", "empty", "string"], "add_tokens": "if v != \" \" { s . appendIfMissing ( strings . ToLower ( v ) ) }", "del_tokens": "s . appendIfMissing ( strings . ToLower ( v ) )", "commit_type": "allow"}
{"commit_tokens": ["Use", "nodeShift", "instead", "of", "12", "."], "add_tokens": "return int64 ( f ) & 0x00000000003FF000 >> nodeShift", "del_tokens": "return int64 ( f ) & 0x00000000003FF000 >> 12", "commit_type": "use"}
{"commit_tokens": ["Add", "SDKData", "type", "and", "set", "name", "per", "sdk", "span"], "add_tokens": "Status : status } , SDK : & SDKData { Name : tp } } Call : rawSpan . Operation } , SDK : & SDKData { Name : tp } } data . Custom = & CustomData { Tags : rawSpan . Tags , Logs : collectLogs ( rawSpan ) } Name : \" \" ,", "del_tokens": "Status : status } } Call : rawSpan . Operation } } data . Custom = & CustomData { Tags : rawSpan . Tags , Logs : collectLogs ( rawSpan ) } Name : tp ,", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "to", "copy", "cache", "keys"], "add_tokens": "// FIXME, right now just remove all matching cache // entries. Should be smarter and walk small result // lists and delete // Make sure we copy the subject key here scopy := make ( [ ] byte , len ( subject ) ) copy ( scopy , subject ) s . cache . Set ( scopy , results )", "del_tokens": "r := s . cache . Get ( k ) if r == nil { continue } s . cache . Set ( subject , results )", "commit_type": "make"}
{"commit_tokens": ["Change", "bsd", "backend", "to", "watch", "files", "after", "triggering", "create", "events", "."], "add_tokens": "\" \" if fi . Mode ( ) & os . ModeSymlink == os . ModeSymlink { path , err := filepath . EvalSymlinks ( path ) if err != nil { filePath := filepath . Join ( dirPath , fileInfo . Name ( ) ) filePath := filepath . Join ( dirPath , fileInfo . Name ( ) ) w . watchDirectoryFiles ( dirPath )", "del_tokens": "\" \" for fi . Mode ( ) & os . ModeSymlink == os . ModeSymlink { path , errstat = os . Readlink ( path ) if errstat != nil { filePath := path . Join ( dirPath , fileInfo . Name ( ) ) w . watchDirectoryFiles ( dirPath ) filePath := path . Join ( dirPath , fileInfo . Name ( ) )", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "mismatched", "paren", "."], "add_tokens": "// by the mutex should hold (e.g. just after acquiring the lock). The function", "del_tokens": "// by the mutex should hold (e.g. just after acquiring the lock. The function", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "attributes", "for", "job"], "add_tokens": "EnvironmentVariables [ ] * EnvironmentVariable `json:\"environment_variables,omitempty\"` Properties [ ] * JobProperty `json:\"properties,omitempty\"` Tabs [ ] string `json:\"tabs,omitempty\"` Artifacts [ ] string `json:\"artifacts,omitempty\"` } type JobProperty struct { Name string `json:\"name\"` Source string `json:\"source\"` XPath string `json:\"xpath\"` } type EnvironmentVariable struct { Name string `json:\"name\"` Value string `json:\"value,omitempty\"` EncryptedValue string `json:\"encrypted_value,omitempty\"` Secure bool `json:\"secure\"`", "del_tokens": "EnvironmentVariables [ ] string `json:\"environment_variables,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["add", "a", "Print", "for", "stderr", "messages"], "add_tokens": "gitmedia . Print ( \" \" , path )", "del_tokens": "\" \" fmt . Fprintf ( os . Stderr , \" \\n \" , path )", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "test", "name", "."], "add_tokens": "{ \" \" , simpleStruct { 1 , \" \" } , simpleStruct { 0 , \" \" } , false } ,", "del_tokens": "{ \" \" , simpleStruct { 1 , \" \" } , simpleStruct { 0 , \" \" } , false } ,", "commit_type": "fix"}
{"commit_tokens": ["Implement", "outgoing", "Caller", "ID", "s"], "add_tokens": "Applications * ApplicationService Calls * CallService Conferences * ConferenceService IncomingNumbers * IncomingNumberService Keys * KeyService Media * MediaService Messages * MessageService OutgoingCallerIDs * OutgoingCallerIDService Queues * QueueService Recordings * RecordingService Transcriptions * TranscriptionService c . OutgoingCallerIDs = & OutgoingCallerIDService { client : c }", "del_tokens": "Applications * ApplicationService Calls * CallService Conferences * ConferenceService IncomingNumbers * IncomingNumberService Keys * KeyService Media * MediaService Messages * MessageService Queues * QueueService Recordings * RecordingService Transcriptions * TranscriptionService", "commit_type": "implement"}
{"commit_tokens": ["Added", "tests", "for", "git", "projects"], "add_tokens": "// use an empty GitIgnore for cached lookups var empty = & ignore { } // attempts on subsequent requests for the same file. Subsequent calls to // NewGitIgnoreCached for a file that could not be loaded due to an error will // return nil. if _ignore == nil { _ignore = empty if _ignore == empty { return nil , _err } else { return _ignore , _err }", "del_tokens": "// attempts on subsequent requests for the same file. if _ignore != nil { _ignore = & ignore { } return _ignore , _err", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "subsample", "ratio", "4", ":", "1", ":", "0", "and", "missing", "4", ":", "1", ":", "1"], "add_tokens": "// Ratio410 is 4:1:0 Ratio410 ChromaRatio = iota Ratio411 case Ratio410 , Ratio411 : case Ratio410 , Ratio420 , Ratio440 : case image . YCbCrSubsampleRatio410 : return Ratio410 case image . YCbCrSubsampleRatio411 : return Ratio411", "del_tokens": "Ratio411 ChromaRatio = iota case Ratio411 : case Ratio420 , Ratio440 :", "commit_type": "add"}
{"commit_tokens": ["add", "method", "for", "getting", "list", "of", "queues", "of", "specified", "project"], "add_tokens": "func ListProjectQueues ( projectId string , token string , page int , perPage int ) ( queues [ ] Queue , err error ) { q . Settings . ProjectId = projectId q . Settings . Token = token func ListQueues ( page , perPage int ) ( queues [ ] Queue , err error ) { settings := config . Config ( \" \" ) return ListProjectQueues ( settings . ProjectId , settings . Token , page , perPage ) }", "del_tokens": "func ListQueues ( page , perPage int ) ( queues [ ] Queue , err error ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "handling", "around", "WriteToUDP", "calls"], "add_tokens": "_ , err = c . ipv4UnicastConn . WriteToUDP ( buf , ipv4Addr ) if err != nil { return err } _ , err = c . ipv6UnicastConn . WriteToUDP ( buf , ipv6Addr ) if err != nil { return err }", "del_tokens": "c . ipv4UnicastConn . WriteToUDP ( buf , ipv4Addr ) c . ipv6UnicastConn . WriteToUDP ( buf , ipv6Addr )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "handling", "nil", "interface", "values"], "add_tokens": "_ , err := data . ToJSON ( wrap )", "del_tokens": "\" \" d , err := data . ToJSON ( wrap ) fmt . Println ( string ( d ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "isTerminal", "function", "as", "the", "logrus", "API", "changed", "https", ":", "//", "github", ".", "com", "/", "sirupsen", "/", "logrus", "/", "pull", "/", "604"], "add_tokens": "\" \" \" \" if ! isTerminal ( os . Stdout ) { func isTerminal ( w io . Writer ) bool { switch v := w . ( type ) { case * os . File : return terminal . IsTerminal ( int ( v . Fd ( ) ) ) default : return false } }", "del_tokens": "if ! logrus . IsTerminal ( os . Stdout ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "more", "tests", "to", "signingkeyprovider"], "add_tokens": "func ( c * jwksGetterMock ) getJwkSet ( url string ) ( jose . JsonWebKeySet , error ) {", "del_tokens": "func ( c * jwksGetterMock ) getJwks ( url string ) ( jose . JsonWebKeySet , error ) {", "commit_type": "add"}
{"commit_tokens": ["allow", "passing", "nil", "as", "parameter", "to", "the", "load", "function", "to", "indicate", "no", "options", "are", "supported", "by", "the", "loader"], "add_tokens": "var v1 reflect . Value if cfg == nil { v1 = reflect . ValueOf ( & struct { } { } ) } else { v1 = reflect . ValueOf ( cfg ) }", "del_tokens": "v1 := reflect . ValueOf ( cfg )", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "small", "progress", "indicator", "to", "example"], "add_tokens": "\" \" \" \" defer player . Unload ( ) // Output some progress information spinner := spin . New ( ) pattern := spin . Box2 spinner . Set ( pattern ) c1 := time . Tick ( time . Millisecond ) c2 := time . Tick ( time . Second / time . Duration ( len ( [ ] rune ( pattern ) ) ) ) formatDuration := func ( d time . Duration ) string { cen := d / time . Millisecond / 10 % 100 sec := d / time . Second % 60 min := d / time . Minute % 60 return fmt . Sprintf ( \" \" , min , sec , cen ) } now := time . Now ( ) start := now indicator := spinner . Next ( ) for { select { case now = <- c1 : case <- c2 : indicator = spinner . Next ( ) continue } elapsed := now . Sub ( start ) fmt . Printf ( \" \\r \" , indicator , formatDuration ( elapsed ) , formatDuration ( track . Duration ( ) ) ) if elapsed >= track . Duration ( ) { break } } print ( \" \\r \" )", "del_tokens": "player . Unload ( )", "commit_type": "add"}
{"commit_tokens": ["Allow", "less", "ratelimiting", "when", "tests", "take", "a", "long", "time"], "add_tokens": "\" \" var max_rate = flag . Int ( \" \" , 1 , \" \" ) start := time . Now ( ) allowanceForTimeTaken := int ( time . Since ( start ) . Seconds ( ) ) * ( * max_rate ) if ( * min_successes ) > statusCodeHist [ * success_status ] { if ( * ( min_limited_responses ) - allowanceForTimeTaken ) > statusCodeHist [ * ratelimited_status ] { fmt . Printf ( \" \\n \" , * min_limited_responses , statusCodeHist [ * ratelimited_status ] , allowanceForTimeTaken )", "del_tokens": "if * min_successes > statusCodeHist [ * success_status ] { if * min_limited_responses > statusCodeHist [ * ratelimited_status ] { fmt . Printf ( \" \\n \" , * min_limited_responses , statusCodeHist [ * ratelimited_status ] )", "commit_type": "allow"}
{"commit_tokens": ["Add", "built", "-", "in", "sprockets", "functions", "to", "goodies"], "add_tokens": "v := Views { nil , viewHelper } v . Init ( ) return v } func ( v * Views ) Init ( ) { if v . Template == nil { v . Template = template . New ( \" \" ) } v . Template . Funcs ( template . FuncMap { \" \" : UrlFor , \" \" : v . ViewHelper . StylesheetLinkTag , \" \" : v . ViewHelper . JavascriptTag , } )", "del_tokens": "tmpl := template . New ( \" \" ) return Views { tmpl , viewHelper }", "commit_type": "add"}
{"commit_tokens": ["added", "step", "wise", "log", ".", "Debug", "to", "debug", "[", "pipeline", "]", "and", "actions"], "add_tokens": "log . Debugf ( \" \" , len ( p . actions ) ) log . Debugf ( \" \" , i , a . Name ) log . Debugf ( \" \" , i , a . Name , err ) log . Debugf ( \" \" , len ( p . actions ) ) log . Debugf ( \" \" , i , p . actions [ i ] . Name )", "del_tokens": "log . Debugf ( \" \" , a . Name ) log . Debugf ( \" \" , a . Name , err ) log . Debugf ( \" \" , p . actions [ i ] . Name )", "commit_type": "add"}
{"commit_tokens": ["Make", "slice", "with", "correct", "capacity", "since", "it", "is", "known"], "add_tokens": "final := make ( [ ] string , 0 , len ( styles ) )", "del_tokens": "final := make ( [ ] string , 0 )", "commit_type": "make"}
{"commit_tokens": ["Added", "early", "out", "iteration", "based", "on", "Euclidean", "distance", "."], "add_tokens": "// String prints out a string representation of every vertex in this list. // Useful for debugging :). // euclideanDistance determines the euclidean distance between two points. func ( nm * nmVertex ) euclideanDistance ( other * nmVertex ) float64 { sum := float64 ( 0 ) // first we want to sum all the distances between the points for i , otherPoint := range other . vars { // distance between points is defined by (qi-ri)^2 sum += math . Pow ( otherPoint - nm . vars [ i ] , 2 ) } return math . Sqrt ( sum ) } // this will never be true for += inf best := nm . vertices [ 0 ] // here we are checking distance convergence. If all vertices // are near convergence, that is they are all within some delta // from the expected value, we can go ahead and quit early. This // can only be performed on convergence checks, not for finding // min/max. } // next we want to check to see if the changes in our polytopes // dip below some threshold. That is, we want to look at the // euclidean distances between the best guess and all the other // guesses to see if they are converged upon some point. If // all of the vertices have converged close enough, it may be // worth it to cease iteration. for _ , v := range nm . vertices [ 1 : ] { if best . euclideanDistance ( v ) >= delta { return true }", "del_tokens": "best := nm . vertices [ 0 ] } else { return true", "commit_type": "add"}
{"commit_tokens": ["add", "counter", "for", "bad", "passenger", "data"], "add_tokens": "badPassCounts * Counter badPassCounts : & Counter { } , log . Printf ( \" \" , m . skippedRecs . Get ( ) , m . badLocs . Get ( ) , m . nullLocs . Get ( ) , m . badSpeeds . Get ( ) , m . badTotalAmnts . Get ( ) , m . badDurations . Get ( ) , m . badUnknowns . Get ( ) , m . badPassCounts . Get ( ) ) if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { m . badPassCounts . Add ( 1 ) m . skippedRecs . Add ( 1 ) continue Records }", "del_tokens": "log . Printf ( \" \" , m . skippedRecs . Get ( ) , m . badLocs . Get ( ) , m . nullLocs . Get ( ) , m . badSpeeds . Get ( ) , m . badTotalAmnts . Get ( ) , m . badDurations . Get ( ) , m . badUnknowns . Get ( ) )", "commit_type": "add"}
{"commit_tokens": ["Allow", "http", "client", "overrides", "."], "add_tokens": "res , err := HttpClient . Get ( u . String ( ) )", "del_tokens": "\" \" res , err := http . Get ( u . String ( ) )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "defaults", "that", "are", "multiline"], "add_tokens": "indentedDefault := text . Indent ( value + \" \\n \" , \" \" ) metadata += \" \" + indentedDefault [ 15 : ]", "del_tokens": "metadata += \" \" + value + \" \\n \"", "commit_type": "fix"}
{"commit_tokens": ["Update", "a", "test", "expectation", "to", "fix", "a", "test", "failure"], "add_tokens": "expectedError := \" \"", "del_tokens": "expectedError := \" \"", "commit_type": "update"}
{"commit_tokens": ["remove", "prefix", "v", "from", "Version"], "add_tokens": "want := fmt . Sprintf ( \" \" , Version )", "del_tokens": "want := fmt . Sprintf ( \" \" , Version )", "commit_type": "remove"}
{"commit_tokens": ["Add", "new", "()", "built", "in", "function", ".", "identxpr", ".", "go", ":", "builtin", "types", "are", "indentifiers", "too!"], "add_tokens": "func TestBuiltinCap ( t * testing . T ) { env := makeEnv ( ) slice := [ ] int { 1 , 2 } env . Vars [ \" \" ] = reflect . ValueOf ( & slice ) expectResult ( t , \" \" , env , cap ( slice ) ) // FIXME: this is wrong. The type should be int, not int64 and // reflects something wrong in the eval's type system. expectError ( t , \" \" , env , \" \" ) } func TestBuiltinNew ( t * testing . T ) { expr := \" \" results := getResults ( t , expr , env ) returnKind := ( * results ) [ 0 ] . Kind ( ) . String ( ) if returnKind != \" \" { t . Fatalf ( \" \" , expr , returnKind ) } expectError ( t , \" \" , env , \" \" )", "del_tokens": "func TestBuiltinCap ( t * testing . T ) { slice := [ ] int { 1 , 2 } env . Vars [ \" \" ] = reflect . ValueOf ( & slice ) expectResult ( t , \" \" , env , cap ( slice ) ) // FIXME: this is wrong. The type should be int, not int64 and // reflects something wrong in the eval's type system. expectError ( t , \" \" , env , \" \" )", "commit_type": "add"}
{"commit_tokens": ["move", "handleForwardResponseOptions", "before", "json", ".", "Marshal", "in", "ForwardResponseMessage"], "add_tokens": "w . Header ( ) . Set ( \" \" , \" \" ) if err := handleForwardResponseOptions ( ctx , w , resp , opts ) ; err != nil { buf , err := json . Marshal ( resp ) if err != nil { glog . Errorf ( \" \" , err )", "del_tokens": "buf , err := json . Marshal ( resp ) if err != nil { glog . Errorf ( \" \" , err ) w . Header ( ) . Set ( \" \" , \" \" ) if err := handleForwardResponseOptions ( ctx , w , resp , opts ) ; err != nil {", "commit_type": "move"}
{"commit_tokens": ["Fix", "the", "issue", "where", "arrays", "weren", "t", "grown", "when", "unmarshalling", "data", "from", "server"], "add_tokens": "if f . Kind ( ) == reflect . Slice { if f . IsNil ( ) { f . Set ( reflect . MakeSlice ( reflect . SliceOf ( f . Type ( ) . Elem ( ) ) , theArray . Len ( ) , theArray . Len ( ) ) ) } else if f . Len ( ) < theArray . Len ( ) { count := theArray . Len ( ) - f . Len ( ) f = reflect . AppendSlice ( f , reflect . MakeSlice ( reflect . SliceOf ( f . Type ( ) . Elem ( ) ) , count , count ) ) }", "del_tokens": "if f . Kind ( ) == reflect . Slice && f . IsNil ( ) { f . Set ( reflect . MakeSlice ( reflect . SliceOf ( f . Type ( ) . Elem ( ) ) , theArray . Len ( ) , theArray . Len ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "marking", "-", "as", "-", "read", "code", "in", "operator", "."], "add_tokens": "messageIds := make ( [ ] string , len ( messages ) ) for i , message := range messages { messageIds [ i ] = message . GetName ( ) \" \" : messageIds , // Reply replies to a post, message, or comment. func ( o * Operator ) Reply ( parent , content string ) error { req , err := request . New ( \" \" , \" \" , & url . Values { \" \" : [ ] string { parent } , \" \" : [ ] string { content } , } , ) if err != nil { return err } _ , err = o . cli . Do ( req ) if err != nil { return err } return nil }", "del_tokens": "\" \" var buf bytes . Buffer for _ , message := range messages { buf . WriteString ( \" \" + message . GetId ( ) ) buf . WriteString ( \" \" ) \" \" : [ ] string { buf . String ( ) [ : len ( buf . String ( ) ) - 1 ] } ,", "commit_type": "improve"}
{"commit_tokens": ["Fix", "unmarshal", "error", "for", "recipient"], "add_tokens": "Recipient int64", "del_tokens": "Recipient int", "commit_type": "fix"}
{"commit_tokens": ["Allow", "the", "ability", "to", "optionally", "set", "keypath", "with", "SEC51_KEYPATH", "env", "var"], "add_tokens": "\" \" keyPath string keysFolderPrefixFormat string testKeysFolderPrefixFormat string if os . Getenv ( \" \" ) != \" \" { keyPath = os . Getenv ( \" \" ) } else { keyPath = \" \" } keysFolderPrefixFormat = filepath . Join ( keyPath , \" \" ) testKeysFolderPrefixFormat = filepath . Join ( testKeyPath , \" \" )", "del_tokens": "\" \" keyPath = \" \" osSeparator , _ = strconv . Unquote ( strconv . QuoteRuneToASCII ( os . PathSeparator ) ) keysFolderPrefixFormat = fmt . Sprintf ( \" \" , keyPath , osSeparator ) + \" \" testKeysFolderPrefixFormat = fmt . Sprintf ( \" \" , testKeyPath , osSeparator ) + \" \"", "commit_type": "allow"}
{"commit_tokens": ["Allow", "empty", "argument", "lists", "&", "tests"], "add_tokens": "key := filename [ 0 : len ( filename ) - len ( fileext ) ]", "del_tokens": "key := filename [ 0 : len ( filename ) - len ( fileext ) ]", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "GC", "export", "data", "for", "anonymous", "struct", "fields", "."], "add_tokens": "name := \" \" if ! field . Anonymous ( ) { name = e . makeName ( field ) } fields [ i ] = name + \" \" + e . makeType ( field . Type ( ) )", "del_tokens": "fields [ i ] = e . makeName ( field ) + \" \" + e . makeType ( field . Type ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "Error", "Handler", "callback", "prototype", "to", "have", "access", "to", "the", "request", "and", "full", "ehttp", ".", "ResponseWriter", "if", "needed"], "add_tokens": "HandleError ( w , nil , nil ) HandleError ( w , nil , fmt . Errorf ( \" \" ) ) HandleError ( w , nil , NewErrorf ( http . StatusTeapot , \" \" ) ) HandleError ( w , nil , NewErrorf ( http . StatusTeapot , \" \" ) )", "del_tokens": "HandleError ( w , nil ) HandleError ( w , fmt . Errorf ( \" \" ) ) HandleError ( w , NewErrorf ( http . StatusTeapot , \" \" ) ) HandleError ( w , NewErrorf ( http . StatusTeapot , \" \" ) )", "commit_type": "change"}
{"commit_tokens": ["Use", "fields", "ID", "and", "Request"], "add_tokens": "if client . Request == nil { rooms := server . RoomsJoined ( client . ID ) server . RemoveClient ( client . ID , room )", "del_tokens": "if client . Request ( ) == nil { rooms := server . RoomsJoined ( client . Id ( ) ) server . RemoveClient ( client . Id ( ) , room )", "commit_type": "use"}
{"commit_tokens": ["Fix", "command", "usage", "for", "apps", "."], "add_tokens": "return svc } // NewApp creates a new app with Module m as the entry point. Unlike // New, `start` is not automatically registered. func NewApp ( m Module ) * Service { svc := loadEnv ( m , GetEnvironment ( ) ) fmt . Printf ( \" \\n \" , os . Args [ 0 ] , cmd . Keyword ) if s . commands [ \" \" ] != nil { fmt . Printf ( \" \\n \" , \" \" , s . commands [ \" \" ] . ShortUsage ) } if s . commands [ \" \" ] != nil { fmt . Printf ( \" \\n \" , \" \" , s . commands [ \" \" ] . ShortUsage ) }", "del_tokens": "fmt . Printf ( \" \\n \" , os . Args [ 0 ] , cmd . Keyword ) // NewApp creates a new app with Module m as the entry point. Unlike // New, `start` is not automatically registered. func NewApp ( m Module ) * Service { return loadEnv ( m , GetEnvironment ( ) ) } fmt . Printf ( \" \\n \" , \" \" , s . commands [ \" \" ] . ShortUsage ) fmt . Printf ( \" \\n \" , \" \" , s . commands [ \" \" ] . ShortUsage )", "commit_type": "fix"}
{"commit_tokens": ["moving", "host", "port", "vars", "to", "global"], "add_tokens": "var host , port string host , port = server . HostPort ( )", "del_tokens": "host , port := server . HostPort ( ) host , port := server . HostPort ( ) host , port := server . HostPort ( ) host , port := server . HostPort ( ) host , port := server . HostPort ( ) host , port := server . HostPort ( ) host , port := server . HostPort ( ) host , port := server . HostPort ( )", "commit_type": "move"}
{"commit_tokens": ["fix", "xlsx", "to", "csv", "diff", "row", "size"], "add_tokens": "var firstRowSize int if len ( row . Cells ) == 0 { continue } if firstRowSize == 0 { firstRowSize = len ( row . Cells ) } var record = make ( [ ] string , firstRowSize )", "del_tokens": "var record = make ( [ ] string , len ( row . Cells ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "the", "r", "==", "n", "case"], "add_tokens": "if this . r == n { this . total = 1 } else if this . r > 1 {", "del_tokens": "if this . r > 1 {", "commit_type": "fix"}
{"commit_tokens": ["Add", "logging", "to", "BuildConfig", "functions"], "add_tokens": "\" \" log . Printf ( \" \" , user , name ) log . Printf ( \" \" , user , name ) endpoint := \" \" log . Printf ( \" \" , v . Slug ( ) , size )", "del_tokens": "endpoint := \" \"", "commit_type": "add"}
{"commit_tokens": ["add", "the", "options", "to", "runv", "start"], "add_tokens": "# cd / mycontainer # runv start [ - c spec - config - file ] [ - r runtime - config - file ] If not specified , the default value for the 's pec - config - file ' is 'c onfig . json ', and the default value for the 'r untime - config - file ' is 'r untime . json '.`", "del_tokens": "cd / mycontainer runv start [ spec - file ] If not specified , the default value for the 's pec - file ' is 'c onfig . json '. `", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "functions", "more", "consistent", "/", "readable", "debugging"], "add_tokens": "return fmt . Sprintf ( \" \" , e . StatusCode , e . Type , e . Detail )", "del_tokens": "return fmt . Sprintf ( \" \" , e . StatusCode , e . Type , e . Detail )", "commit_type": "remove"}
{"commit_tokens": ["Make", "AppWrapper", "a", "private", "struct"], "add_tokens": "type appWrapper struct { var aw appWrapper body , err := json . Marshal ( & appWrapper { & App { var aw appWrapper", "del_tokens": "type AppWrapper struct { var aw AppWrapper body , err := json . Marshal ( & AppWrapper { & App { var aw AppWrapper", "commit_type": "make"}
{"commit_tokens": ["Use", "github", ".", "user", "if", "set", "in", "gitconfig", "as", "repo", "owner"], "add_tokens": "githubOpts . OwnerName , err = gitconfig . GithubUser ( ) githubOpts . OwnerName , err = gitconfig . Username ( ) if err != nil { return err }", "del_tokens": "githubOpts . OwnerName , err = gitconfig . Username ( ) return err", "commit_type": "use"}
{"commit_tokens": ["Remove", "unnecessary", "rs", "variable", "from", "Chunk"], "add_tokens": "for _ , loc := range Locate ( tagged , TreebankNamedEntities ) {", "del_tokens": "rs := Locate ( tagged , TreebankNamedEntities ) for _ , loc := range rs {", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "packetdecoder", "from", "the", "ogg", "package"], "add_tokens": "r * bufio . Reader", "del_tokens": "r * bufio . Reader", "commit_type": "use"}
{"commit_tokens": ["move", "ball", "by", "pressing", "ctrl", "buttons"], "add_tokens": "ctrl := self . parent ctrl . buttonState = CTRL_UP ctrl := self . parent ctrl . buttonState = CTRL_NOP ctrl := self . parent ctrl . buttonState = CTRL_DOWN ctrl := self . parent ctrl . buttonState = CTRL_NOP switch self . buttonState { case CTRL_UP : self . ball . Y += 1 case CTRL_DOWN : self . ball . Y -= 1 }", "del_tokens": "// TODO: update buttonState //ctrl := self.parent // TODO: update buttonState //ctrl := self.parent // TODO: update buttonState //ctrl := self.parent // TODO: update buttonState //ctrl := self.parent // TODO: move ball according to buttonState", "commit_type": "move"}
{"commit_tokens": ["fix", "evaluation", "of", "list", "of", "functions"], "add_tokens": "v , parsed , err := evaluate ( codes [ i + 1 : ] )", "del_tokens": "v , parsed , err := evaluate ( codes [ top + 1 : ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "few", "more", "comments"], "add_tokens": "// Status represents the status of a Response (both top-level Request objects, // and *Response objects) // Valid returns whether the Status is valid according to the OFX spec // CodeMeaning returns the meaning of the current status Code // CodeConditions returns the conditions under which an OFX server is expected // to return the current status Code // BankAcct represents the identifying information for one bank account // CCAcct represents the identifying information for one checking account // InvAcct represents the identifying information for one investment account // Currency represents one ISO-4217 currency", "del_tokens": "// Return the meaning of the current status Code // Return the conditions under which an OFX server is expected to return the // current status Code", "commit_type": "add"}
{"commit_tokens": ["add", "local", "tests", "with", "same", "host", "and", "not", "same", "host", "policy"], "add_tokens": "func newFileFetcher ( basePath string ) * fileFetcher {", "del_tokens": "func NewFileFetcher ( basePath string ) * fileFetcher {", "commit_type": "add"}
{"commit_tokens": ["Use", "pkg", "-", "config", "to", "retrieve", "LDFLAGS", "and", "CFLAGS", "for", "geoip", "."], "add_tokens": "# cgo pkg - config : geoip", "del_tokens": "# cgo CFLAGS : - I / opt / local / include - I / usr / local / include - I / usr / include # cgo LDFLAGS : - lGeoIP - L / opt / local / lib - L / usr / local / lib - L / usr / lib", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "filter_by_prefix", "parameter"], "add_tokens": "FilterBy [ ] string `json:\"filter_by,omitempty\" url:\"filter_by,omitempty\"` FilterByPrefix [ ] string `json:\"filter_by_prefix,omitempty\" url:\"filter_by_prefix,omitempty\"` GroupBy [ ] string `json:\"group_by,omitempty\" url:\"group_by,omitempty\"` Collect [ ] string `json:\"collect,omitempty\" url:\"collect,omitempty\"` SortBy string `json:\"sort_by,omitempty\" url:\"sort_by,omitempty\"` Duration int `json:\"duration,omitempty\" url:\"duration,omitempty\"` Period string `json:\"period,omitempty\" url:\"period,omitempty\"` Limit int `json:\"limit,omitempty\" url:\"limit,omitempty\"` StartAt time . Time `json:\"start_at,omitempty\" url:\"start_at,omitempty\"` EndAt time . Time `json:\"end_at,omitempty\" url:\"end_at,omitempty\"`", "del_tokens": "FilterBy [ ] string `json:\"filter_by,omitempty\" url:\"filter_by,omitempty\"` GroupBy [ ] string `json:\"group_by,omitempty\" url:\"group_by,omitempty\"` Collect [ ] string `json:\"collect,omitempty\" url:\"collect,omitempty\"` SortBy string `json:\"sort_by,omitempty\" url:\"sort_by,omitempty\"` Duration int `json:\"duration,omitempty\" url:\"duration,omitempty\"` Period string `json:\"period,omitempty\" url:\"period,omitempty\"` Limit int `json:\"limit,omitempty\" url:\"limit,omitempty\"` StartAt time . Time `json:\"start_at,omitempty\" url:\"start_at,omitempty\"` EndAt time . Time `json:\"end_at,omitempty\" url:\"end_at,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Make", "builtin", "functions", "in", "topdown", "registerable"], "add_tokens": "// BuiltinFunc defines the interface that the evaluation engine uses to // invoke built-in functions. Users can implement their own built-in functions // and register them with the evaluation engine. // // Callers are given the current evaluation Context ctx with the expression // expr to be evaluated. Callers can assume that the expression has been plugged // with bindings from the current context. If the built-in function determines // that the expression has evaluated successfully it should bind any output variables // and invoke the iterator with the context produced by binding the output variables. type BuiltinFunc func ( ctx * Context , expr * ast . Expr , iter Iterator ) ( err error ) // RegisterBuiltinFunc adds a new built-in function to the evaluation engine. func RegisterBuiltinFunc ( name ast . Var , fun BuiltinFunc ) { builtinFunctions [ name ] = fun } var builtinFunctions map [ ast . Var ] BuiltinFunc var defaultBuiltinFuncs = map [ ast . Var ] BuiltinFunc { func init ( ) { builtinFunctions = map [ ast . Var ] BuiltinFunc { } for name , fun := range defaultBuiltinFuncs { RegisterBuiltinFunc ( name , fun ) } }", "del_tokens": "type builtinFunction func ( * Context , * ast . Expr , Iterator ) error var builtinFunctions = map [ ast . Var ] builtinFunction {", "commit_type": "make"}
{"commit_tokens": ["Add", "another", "key", "match", "function", "keyMatch2", "()", "to", "model", "."], "add_tokens": "// For example, \"/foo/bar\" matches \"/foo/*\" // KeyMatch2 determines whether key1 matches the pattern of key2 (similar to RESTful path), key2 can contain a *. // For example, \"/foo/bar\" matches \"/foo/*\", \"/resource1\" matches \"/:resource\" func KeyMatch2 ( key1 string , key2 string ) bool { key2 = strings . Replace ( key2 , \" \" , \" \" , - 1 ) re := regexp . MustCompile ( `(.*):[^/]+(.*)` ) for { if ! strings . Contains ( key2 , \" \" ) { break } key2 = re . ReplaceAllString ( key2 , \" \" ) } return RegexMatch ( key1 , key2 ) } // KeyMatch2Func is the wrapper for KeyMatch2. func KeyMatch2Func ( args ... interface { } ) ( interface { } , error ) { name1 := args [ 0 ] . ( string ) name2 := args [ 1 ] . ( string ) return ( bool ) ( KeyMatch2 ( name1 , name2 ) ) , nil } // For example, \"192.168.2.123\" matches \"192.168.2.0/24\"", "del_tokens": "// For example, /foo/bar matches /foo/* // For example, 192.168.2.123 matches 192.168.2.0/24", "commit_type": "add"}
{"commit_tokens": ["Use", "defined", "media", "library", "resource", "if", "found"], "add_tokens": "Admin := meta . GetBaseResource ( ) . ( * admin . Resource ) . GetAdmin ( ) mediaLibraryResource := Admin . GetResource ( \" \" ) if mediaLibraryResource == nil { mediaLibraryResource = Admin . NewResource ( & MediaLibrary { } ) } config . RemoteDataResource = mediaLibraryResource", "del_tokens": "config . RemoteDataResource = meta . GetBaseResource ( ) . ( * admin . Resource ) . GetAdmin ( ) . NewResource ( & MediaLibrary { } )", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "New", "()", "method", "that", "takes", "a", "readline", "config", "structure", "."], "add_tokens": "return NewWithConfig ( & readline . Config { Prompt : defaultPrompt } ) } // NewWithConfig creates a new shell with custom readline config. func NewWithConfig ( conf * readline . Config ) * Shell { rl , err := readline . NewEx ( conf ) writer : conf . Stdout ,", "del_tokens": "rl , err := readline . New ( defaultPrompt ) writer : os . Stdout ,", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "missed", "defer", "keyword"], "add_tokens": "defer hooksLocker . Unlock ( )", "del_tokens": "hooksLocker . Unlock ( )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "support", "for", "JOIN", "/", "PART", "multiple", "channels"], "add_tokens": "return fmt . Sprintf ( \" \" , m . Prefix , m . Command , // TODO: We should not permit ':' either. However in practice it appears", "del_tokens": "return fmt . Sprintf ( \" \" , m . Prefix , m . Command , // XXX: We should not permit ':' either. However in practice it appears // ParseChannels takes a channel(s) parameter, e.g., from a JOIN command, // and breaks it into the separate channel names. // // We validate each. // // Channel names are comma separated. func ParseChannels ( param string ) ( [ ] string , error ) { rawNames := strings . Split ( param , \" \" ) channels := [ ] string { } for _ , name := range rawNames { name = CanonicalizeChannel ( name ) channels = append ( channels , name ) if ! IsValidChannel ( name ) { // I want to pass at least one channel name back. We want to include it // in the error message if necessary. return channels , fmt . Errorf ( \" \" , name ) } } return channels , nil }", "commit_type": "remove"}
{"commit_tokens": ["Add", "Config", "structure", "to", "SPF", "."], "add_tokens": "parser := NewParser ( sender , domain , ip4 , stub , config ) \" \" , net . IP { 192 , 0 , 2 , 3 } , stub , config ) parser := NewParser ( sender , domain , ip4 , stub , config )", "del_tokens": "parser := NewParser ( sender , domain , ip4 , stub ) \" \" , net . IP { 192 , 0 , 2 , 3 } , stub ) parser := NewParser ( sender , domain , ip4 , stub )", "commit_type": "add"}
{"commit_tokens": ["fix", "checking", "of", "new", "fs", "-", "repo", "-", "migrations", "binary"], "add_tokens": "migrateBin , err = verifyMigrationSupportsVersion ( migrateBin , newv ) func verifyMigrationSupportsVersion ( fsrbin , v string ) ( string , error ) { return fsrbin , fmt . Errorf ( \" \" , v ) return fsrbin , err return fsrbin , nil fsrbin , err = GetMigrations ( ) return fsrbin , err return fsrbin , err return fsrbin , nil return fsrbin , fmt . Errorf ( \" \" , v )", "del_tokens": "err = verifyMigrationSupportsVersion ( migrateBin , newv ) func verifyMigrationSupportsVersion ( fsrbin , v string ) error { return fmt . Errorf ( \" \" , v ) return err return nil _ , err = GetMigrations ( ) return err return err return nil return fmt . Errorf ( \" \" , v )", "commit_type": "fix"}
{"commit_tokens": ["add", "iterator", "check", "for", "mongo"], "add_tokens": "Id string \" \" Added [ ] int64 Deleted [ ] int64 if it . collection == \" \" && len ( result . Added ) <= len ( result . Deleted ) { return it . Next ( ) }", "del_tokens": "Id string \" \" //Sub string \"Sub\" //Pred string \"Pred\" //Obj string \"Obj\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "benchmark", "so", "the", "buffer", "is", "read", "each", "time", "."], "add_tokens": "p , _ := ReadFrom ( bytes . NewReader ( sample . Bytes ( ) ) , \" \" ) p = p", "del_tokens": "ReadFrom ( sample , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["add", "ability", "to", "deregister", "registered", "users"], "add_tokens": "Client : client , RegisteredUsers : make ( RegisteredUsers , 0 , len ( packet . Users ) ) ,", "del_tokens": "Client : client , RegisteredUsers : make ( RegisteredUsers , 0 , len ( packet . Users ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "setting", "nexthop", "flags", "for", "routes"], "add_tokens": "type NextHopFlag int const ( FLAG_ONLINK NextHopFlag = syscall . RTNH_F_ONLINK FLAG_PERVASIVE NextHopFlag = syscall . RTNH_F_PERVASIVE ) Flags int return fmt . Sprintf ( \" \" , r . LinkIndex , r . Dst , r . Src , r . Gw , r . ListFlags ( ) ) } func ( r * Route ) SetFlag ( flag NextHopFlag ) { r . Flags |= int ( flag ) } func ( r * Route ) ClearFlag ( flag NextHopFlag ) { r . Flags &^= int ( flag ) } type flagString struct { f NextHopFlag s string } var testFlags = [ ] flagString { flagString { f : FLAG_ONLINK , s : \" \" } , flagString { f : FLAG_PERVASIVE , s : \" \" } , } func ( r * Route ) ListFlags ( ) [ ] string { var flags [ ] string for _ , tf := range testFlags { if r . Flags & int ( tf . f ) != 0 { flags = append ( flags , tf . s ) } } return flags", "del_tokens": "return fmt . Sprintf ( \" \" , r . LinkIndex , r . Dst , r . Src , r . Gw )", "commit_type": "add"}
{"commit_tokens": ["Added", "CommitTimeWait", "step", "the", "state", "machine", "model", "changed", "a", "bit", "."], "add_tokens": "Height uint32 // Last known block height BlockHash [ ] byte // Last known block hash BlockTime time . Time // LastKnown block time BlockTime : genesisTime , s . BlockTime = ReadTime ( reader , & n , & err ) func ( s * State ) Save ( ) { WriteTime ( & buf , s . BlockTime , & n , & err ) BlockTime : s . BlockTime , s . BlockTime = b . Time // excluding Height, BlockHash.", "del_tokens": "Height uint32 // Last known block height BlockHash [ ] byte // Last known block hash CommitTime time . Time CommitTime : genesisTime , s . CommitTime = ReadTime ( reader , & n , & err ) // For convenience, the commitTime (required by ConsensusAgent) // is saved here. func ( s * State ) Save ( commitTime time . Time ) { s . CommitTime = commitTime WriteTime ( & buf , commitTime , & n , & err ) CommitTime : s . CommitTime , // excluding Height, BlockHash, and CommitTime.", "commit_type": "add"}
{"commit_tokens": ["Fix", "bad", "s", "//", "invocation"], "add_tokens": "STORE_S3 := `05c3d005-f968-452f-bd59-bee8e79ab982` TARGET_REDIS := `66be7c43-6c57-4391-8ea9-e770d6ab5e9e` TARGET_PG := `fab00c82-aac3-4e5f-8a2f-c534f81cdee3` SCHED_DAILY := `590eddbd-426f-408c-981b-9cf1faf2669e` SCHED_WEEKLY := `fce33a96-d352-480f-b04a-db7f2c14e98f` RETAIN_SHORT := `848ff67e-f857-47bd-9692-ae5f2be85674` RETAIN_LONG := `c5fca8e0-7d40-4cff-8dec-5f0df36ecee9`", "del_tokens": "STORE_S3 := `05c3d005-f968-452f-bd59-bee8e79ab982:= ` TARGET_REDIS := `66be7c43-6c57-4391-8ea9-e770d6ab5e9e:= ` TARGET_PG := `fab00c82-aac3-4e5f-8a2f-c534f81cdee3:= ` SCHED_DAILY := `590eddbd-426f-408c-981b-9cf1faf2669e:= ` SCHED_WEEKLY := `fce33a96-d352-480f-b04a-db7f2c14e98f:= ` RETAIN_SHORT := `848ff67e-f857-47bd-9692-ae5f2be85674:= ` RETAIN_LONG := `c5fca8e0-7d40-4cff-8dec-5f0df36ecee9:= `", "commit_type": "fix"}
{"commit_tokens": ["Use", "shadowsocks", ".", "Conn", "in", "server", "and", "client", "."], "add_tokens": "\" \" func Pipe ( src net . Conn , dst net . Conn , end chan int ) { _ , err := dst . Write ( buf [ 0 : num ] )", "del_tokens": "\" \" func Pipe ( src net . Conn , dst net . Conn , table [ ] byte , end chan int ) { _ , err := dst . Write ( Encrypt ( table , buf [ 0 : num ] ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "examples", "test", "for", "new", "RPC", "framework"], "add_tokens": "// For some reason the registration paths need to be different (even for different server objs) server . HandleHTTP ( fmt . Sprintf ( \" \" , dsync . RpcPath , port ) , fmt . Sprintf ( \" \" , dsync . DebugPath , port ) ) nodes := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } if err := dsync . SetNodesWithPath ( nodes , dsync . RpcPath ) ; err != nil {", "del_tokens": "const rpcPath = \" \" const debugPath = \" \" server . HandleHTTP ( rpcPath , debugPath ) time . Sleep ( 2 * time . Second ) nodes := [ ] string { \" \" , \" \" , \" \" , \" \" } //, \"127.0.0.1:12349\", \"127.0.0.1:12350\", \"127.0.0.1:12351\", \"127.0.0.1:12352\"} if err := dsync . SetNodesWithPath ( nodes , rpcPath ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "ack", "from", "TCP", "check", "to", "not", "be", "seen", "as", "a", "bad", "client"], "add_tokens": "\" \" c := tcp . NewChecker ( true ) if err := c . InitChecker ( ) ; err != nil { return errs . WithEF ( err , x . fields , \" \" ) } err := c . CheckAddr ( x . url , time . Duration ( x . TimeoutInMilli ) * time . Millisecond ) switch err { case tcp . ErrTimeout : return errs . WithEF ( err , x . fields , \" \" ) case nil : return nil default : if e , ok := err . ( * tcp . ErrConnect ) ; ok { return errs . WithEF ( e , x . fields , \" \" ) } else { return errs . WithEF ( err , x . fields , \" \" ) }", "del_tokens": "\" \" conn , err := net . DialTimeout ( \" \" , x . url , time . Duration ( x . TimeoutInMilli ) * time . Millisecond ) if err != nil { return errs . WithEF ( err , x . fields , \" \" ) conn . Close ( ) return nil", "commit_type": "remove"}
{"commit_tokens": ["improve", "ctx", ".", "Error", "and", "app", "onerror", "handler"], "add_tokens": "const Version = \" \"", "del_tokens": "const Version = \" \"", "commit_type": "improve"}
{"commit_tokens": ["Add", "channel", "support", "for", "bitbucket", "bot"], "add_tokens": "if strings . Contains ( e . Description , \" \" ) { ChannelPost * Message `json:\"channel_post\"` EditedChannelPost * Message `json:\"edited_channel_post\"`", "del_tokens": "if strings . Contains ( e . Description , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplication", "between", "cached", "and", "uncached", "downloads"], "add_tokens": "\" \" func ( c * fileCache ) Get ( cacheKey string ) ( io . ReadCloser , error ) { path := c . entries [ cacheKey ] . filePath f , err := os . Open ( path ) if err != nil { return nil , err } readCloser := NewFileCloser ( f , func ( filePath string ) { c . removeFileIfUntracked ( filePath ) } ) return readCloser , nil func ( c * fileCache ) removeFileIfUntracked ( cacheFilePath string ) {", "del_tokens": "func ( c * fileCache ) PathForKey ( cacheKey string ) string { return c . entries [ cacheKey ] . filePath func ( c * fileCache ) RemoveFileIfUntracked ( cacheFilePath string ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "RedirectSTDLogOutput", "(", "...", ")", "to", "console", "logger", "to", "allow", "capturing", "of", "all", "std", "log", "messages", "."], "add_tokens": "stdlog \" \" func TestConsoleSTDLogCapturing ( t * testing . T ) { buff := new ( bytes . Buffer ) cLog := New ( ) cLog . SetWriter ( buff ) cLog . DisplayColor ( false ) cLog . SetBuffersAndWorkers ( 3 , 3 ) cLog . SetTimestampFormat ( \" \" ) cLog . RedirectSTDLogOutput ( true ) log . RegisterHandler ( cLog , log . AllLevels ... ) stdlog . Println ( \" \" ) s := buff . String ( ) expected := \" \" if ! strings . Contains ( s , expected ) { t . Errorf ( \" \" , expected , s ) } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "flag", "args", "to", "greenhouse", "example"], "add_tokens": "\" \" var ( configFlag = flag . String ( \" \" , \" \" , \" \" ) ) flag . Parse ( ) b , err := ioutil . ReadFile ( * configFlag )", "del_tokens": "b , err := ioutil . ReadFile ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "logging", "to", "error", "message"], "add_tokens": "body , _ := ioutil . ReadAll ( response . Body ) return errors . New ( fmt . Sprintf ( \" \" , response . StatusCode , string ( body ) ) )", "del_tokens": "return errors . New ( fmt . Sprintf ( \" \" , response . StatusCode ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "ipam", "host", "-", "local", "IP", "json", "tag"], "add_tokens": "IP net . IP `json:\"ip,omitempty\"`", "del_tokens": "IP net . IP `json:\"ip\",omitempty`", "commit_type": "fix"}
{"commit_tokens": ["Fix", "import", "and", "export", "of", "layers", "containing", "long", "paths"], "add_tokens": "\" \" path string // Use the original path here because ImportLayer does not support long paths for the source in TP5. // But do use a long path for the destination to work around another bug with directories // with MAX_PATH - 12 < length < MAX_PATH. info := r . info fullPath , err := makeLongAbsPath ( filepath . Join ( info . HomeDir , r . layerId ) ) if err == nil { info . HomeDir = \" \" err = ImportLayer ( info , fullPath , r . path , r . parentLayerPaths ) } return & legacyLayerWriterWrapper { LegacyLayerWriter : NewLegacyLayerWriter ( path ) , info : info , layerId : layerId , path : path , parentLayerPaths : parentLayerPaths , } , nil", "del_tokens": "err = ImportLayer ( r . info , r . layerId , r . root , r . parentLayerPaths ) return & legacyLayerWriterWrapper { NewLegacyLayerWriter ( path ) , info , layerId , parentLayerPaths } , nil", "commit_type": "fix"}
{"commit_tokens": ["Changed", "columnsToAutoMergeCells", "type", "to", "map", "[", "int", "]", "bool", "to", "avoid", "looping", "on", "every", "column", "to", "be", "rendered", "."], "add_tokens": "columnsToAutoMergeCells map [ int ] bool // If cols is empty, it is the same as `SetAutoMergeCells(true)`. if len ( cols ) > 0 { m := make ( map [ int ] bool ) for _ , col := range cols { m [ col ] = true } t . columnsToAutoMergeCells = m } if t . columnsToAutoMergeCells [ y ] { mergeCell = true // columnsToAutoMergeCells was not set.", "del_tokens": "columnsToAutoMergeCells [ ] int t . columnsToAutoMergeCells = cols for _ , c := range t . columnsToAutoMergeCells { if y == c { // index found. mergeCell = true break } // columnsToAutoMergeCells was not set or was set to nil.", "commit_type": "change"}
{"commit_tokens": ["Add", "negative", "tests", "for", "WriteMessage", "."], "add_tokens": "\" \" // encode errors in messages. command string payload [ ] byte forceEncodeErr bool // BtcEncode writes the payload field of the fake message or forces an error // if the forceEncodeErr flag of the fake message is set. It also satisfies the // btcwire.Message interface. if msg . forceEncodeErr { err := & btcwire . MessageError { Func : \" \" , Description : \" \" , } return err } _ , err := w . Write ( msg . payload ) return err // MaxPayloadLength simply returns 0. It is only here to satisfy the return 0", "del_tokens": "// errors. command string maxPayload uint32 // BtcEncode doesn't do anything. It just satisfies the btcwire.Message // interface. return nil // Command returns the maxPayload field of the fake message and satisfies the return msg . maxPayload", "commit_type": "add"}
{"commit_tokens": ["Made", "igor", "thread", "safe", "cloning", "the", "*", "Database", "on", "every", "method", "that", "returns", "a", "*", "Database"], "add_tokens": "db = db . clone ( ) db = db . clone ( ) db = db . clone ( ) db = db . clone ( ) db = db . clone ( ) db = db . Where ( value ) clone := db . Where ( value ) return clone . commonCreateUpdate ( value , clone . buildUpdate ) return db . commonCreateUpdate ( value , db . buildCreate ) db = db . Select ( \" \" + handleIdentifier ( key ) + \" \" ) db = db . clone ( ) db = db . clone ( ) db = db . Model ( s . ( DBModel ) ) db = db . clone ( ) db = db . clone ( ) db = db . clone ( ) db = db . clone ( )", "del_tokens": "db . Where ( value ) err := db . Where ( value ) . commonCreateUpdate ( value , db . buildUpdate ) return err err := db . commonCreateUpdate ( value , db . buildCreate ) return err db . Select ( \" \" + handleIdentifier ( key ) + \" \" ) db . Model ( s . ( DBModel ) )", "commit_type": "make"}
{"commit_tokens": ["fix", "dependency", "on", "gogoprotobuf", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["make", "thrift", "-", "gen", "on", "travis", "before", "starting", "the", "test", "."], "add_tokens": "func ( _m * Ringpop ) GetReachableMembers ( ) ( [ ] string , error ) { var r1 error if rf , ok := ret . Get ( 1 ) . ( func ( ) error ) ; ok { r1 = rf ( ) } else { r1 = ret . Error ( 1 ) } return r0 , r1 func ( _m * Ringpop ) CountReachableMembers ( ) ( int , error ) { var r1 error if rf , ok := ret . Get ( 1 ) . ( func ( ) error ) ; ok { r1 = rf ( ) } else { r1 = ret . Error ( 1 ) } return r0 , r1", "del_tokens": "func ( _m * Ringpop ) GetReachableMembers ( ) [ ] string { return r0 func ( _m * Ringpop ) CountReachableMembers ( ) int { return r0", "commit_type": "make"}
{"commit_tokens": ["Add", "GetInfo", "+", "API", "changes"], "add_tokens": "CK_RV GetInfo ( struct ctx * c , CK_INFO_PTR info ) { return c - > sym - > C_GetInfo ( info ) ; } /* GetInfo returns general information about Cryptoki. */ func ( c * Ctx ) GetInfo ( ) ( Info , error ) { var p C . CK_INFO e := C . GetInfo ( c . ctx , C . CK_INFO_PTR ( & p ) ) i := Info { CryptokiVersion : toVersion ( p . cryptokiVersion ) , ManufacturerID : string ( C . GoBytes ( unsafe . Pointer ( & p . manufacturerID [ 0 ] ) , 32 ) ) , Flags : uint ( p . flags ) , LibraryDescription : string ( C . GoBytes ( unsafe . Pointer ( & p . libraryDescription [ 0 ] ) , 32 ) ) , LibraryVersion : toVersion ( p . libraryVersion ) , } return i , toError ( e ) }", "del_tokens": "// GetInfo", "commit_type": "add"}
{"commit_tokens": ["Use", "RFC2047", "for", "header", "encoding"], "add_tokens": "// Create a new header encoder he := quotedprintable . Q . NewHeaderEncoder ( \" \" ) // Check if charset is set if ! strings . Contains ( email . ContentType , \" \" ) { email . ContentType += \" \" } Subject : he . Encode ( email . Name ) , Subject : he . Encode ( email . Name ) , Subject : he . Encode ( email . Name ) , Subject : he . Encode ( email . Name ) , Subject : he . Encode ( email . Name ) ,", "del_tokens": "Subject : quotedprintable . EncodeToString ( [ ] byte ( email . Name ) ) , Subject : quotedprintable . EncodeToString ( [ ] byte ( email . Name ) ) , Subject : email . Name , Subject : quotedprintable . EncodeToString ( [ ] byte ( email . Name ) ) , Subject : quotedprintable . EncodeToString ( [ ] byte ( email . Name ) ) ,", "commit_type": "use"}
{"commit_tokens": ["add", "methods", "Txn", ".", "PutReserve", "and", "Cursor", ".", "PutReserve"], "add_tokens": "// The MDB_MULTIPLE and MDB_RESERVE flags are special and do not fit the // calling pattern of other calls to Put. They are not exported because they // require special methods PutMultiple and PutReserve in which the flag is // implied and does not need to be passed. // PutReserve returns a []byte of length n that can be written to, potentially // avoiding a memcopy. The returned byte slice is only valid in txn's thread, // before it has terminated. func ( cursor * Cursor ) PutReserve ( key [ ] byte , n int , flags uint ) ( [ ] byte , error ) { ckey := wrapVal ( key ) cval := & mdbVal { mv_size : C . size_t ( n ) } ret := C . mdb_cursor_put ( cursor . _cursor , ( * C . MDB_val ) ( ckey ) , ( * C . MDB_val ) ( cval ) , C . uint ( flags | C . MDB_RESERVE ) ) err := errno ( ret ) if err != nil { return nil , err } return cval . Bytes ( ) , nil } return cursor . putVal ( ckey , cval . val ( ) , flags | C . MDB_MULTIPLE )", "del_tokens": "// Note: the MDB_RESERVE flag is somewhat special and does not fit the calling // pattern of most calls to Put. It requires a special method (TODO). Multiple = C . MDB_MULTIPLE // Danger Zone. Store multiple contiguous items (DupSort + DupFixed). // PutMulti implies Multiple and it does not need to be supplied in flags. // return cursor . putVal ( ckey , cval . val ( ) , flags | Multiple )", "commit_type": "add"}
{"commit_tokens": ["Fix", "timeout", "on", "uploading", "big", "files"], "add_tokens": "timer := time . NewTimer ( c . ConnectTimeout ) reader := p . Body if reader != nil { reader = newWatchdogReader ( reader , c . Timeout , timer ) } req , err = http . NewRequest ( p . Operation , url . String ( ) , reader )", "del_tokens": "req , err = http . NewRequest ( p . Operation , url . String ( ) , p . Body ) timer := time . NewTimer ( c . ConnectTimeout ) reader := p . Body if reader != nil { reader = newWatchdogReader ( reader , c . Timeout , timer ) }", "commit_type": "fix"}
{"commit_tokens": ["Adding", "support", "for", "glob", "matching", "of", "policies"], "add_tokens": "\" \" \" \" // Type and methods to sort a list of policy keys // by descending length of key. Implements sort.Interface type policyKeyList [ ] string func ( k policyKeyList ) Len ( ) int { return len ( k ) } func ( k policyKeyList ) Swap ( i , j int ) { k [ i ] , k [ j ] = k [ j ] , k [ i ] } func ( k policyKeyList ) Less ( i , j int ) bool { return len ( k [ i ] ) > len ( k [ j ] ) } // First look for an exact match } // Now we're going to check for globs // Order the keys in descending order of length // so that \"foobar*\" takes precedence over \"foo*\" // Now organize the keys by length policyKeys := make ( policyKeyList , 0 , ) for k := range p { policyKeys = append ( policyKeys , k ) } sort . Sort ( policyKeys ) // Iterate over the keys to find one that matches by glob for _ , pattern := range policyKeys { if glob . Glob ( pattern , key ) { return p [ pattern ] } } // Finally look for a catchall if pol , ok := p [ \" \" ] ; ok {", "del_tokens": "} else if pol , ok := p [ \" \" ] ; ok {", "commit_type": "add"}
{"commit_tokens": ["Change", "resource", ".", "StateChangeConf", "to", "use", "an", "array", "for", "target", "states"], "add_tokens": "Target : [ ] string { \" \" } ,", "del_tokens": "Target : \" \" ,", "commit_type": "change"}
{"commit_tokens": ["Add", "link", "to", "github", "issue", "for", "ResizableChannel"], "add_tokens": "// Resizing to a buffer capacity of None is, unfortunately, not supported and will panic // (see https://github.com/eapache/channels/issues/1).", "del_tokens": "// Resizing to a buffer capacity of None is, unfortunately, not supported and will panic.", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "rest", "of", "the", "code"], "add_tokens": "_ , err := broker . Subscribe ( topic , func ( p broker . Publication ) error { fmt . Println ( \" \" , string ( p . Message ( ) . Body ) , \" \" , p . Message ( ) . Header ) return nil", "del_tokens": "_ , err := broker . Subscribe ( topic , func ( msg * broker . Message ) { fmt . Println ( \" \" , string ( msg . Body ) , \" \" , msg . Header )", "commit_type": "fix"}
{"commit_tokens": ["allow", "install", "/", "uninstall", "of", "specific", "targets"], "add_tokens": "err = cmd . Install ( c , targets ) err = cmd . Uninstall ( c , targets )", "del_tokens": "err = cmd . Install ( c ) err = cmd . Uninstall ( c )", "commit_type": "allow"}
{"commit_tokens": ["move", "randString", "method", "into", "randstr", "package"], "add_tokens": "\" \" msg4 := randstr . Get ( 45000 ) //0.45 MB msg5 := randstr . Get ( 5000000 ) //5.0 MB", "del_tokens": "msg4 := randString ( 45000 ) //0.45 MB msg5 := randString ( 5000000 ) //5.0 MB", "commit_type": "move"}
{"commit_tokens": ["Fix", "typo", "in", "getBoolean", "add", "tests"], "add_tokens": "if v [ 0 ] == 't' {", "del_tokens": "if v [ '0' ] == 't' {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "rpc", "request", "ids", "to", "be", "null", "/", "strings", "/", "integers"], "add_tokens": "ID interface { } `json:\"id\" msgpack:\"id\"` ID interface { } `json:\"id\" msgpack:\"id\"`", "del_tokens": "ID string `json:\"id\" msgpack:\"id\"` ID string `json:\"id\" msgpack:\"id\"`", "commit_type": "allow"}
{"commit_tokens": ["Fix", "a", "blocking", "issue", "in", "buffer", "reader"], "add_tokens": "lastErr error if s . bufferSize > s . bufferRead { // If we have already read something from the buffer before, we return the // same data and the last error if any. We need to immediately return, // otherwise we may block for ever, if we try to be smart and call // source.Read() seeking a little bit of more data. bn := copy ( p , s . buffer . Bytes ( ) [ s . bufferRead : s . bufferSize ] ) s . bufferRead += bn return bn , s . lastErr } // If there is nothing more to return in the sniffed buffer, read from the // source. s . lastErr = sErr return wn , wErr return sn , sErr", "del_tokens": "// Functionality of bytes.Reader. bn := copy ( p , s . buffer . Bytes ( ) [ s . bufferRead : s . bufferSize ] ) s . bufferRead += bn p = p [ bn : ] // Funtionality of io.TeeReader. return bn + wn , wErr return bn + sn , sErr", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "build", "errors", "."], "add_tokens": "// Find the given inode and return it with its lock held. Panic if it doesn't // exist. // // SHARED_LOCKS_REQUIRED(fs.mu) // EXCLUSIVE_LOCK_FUNCTION(inode.mu) func ( fs * memFS ) getInodeForModifyingOrDie ( id fuse . InodeID ) ( inode * inode ) { inode = fs . inodes [ id ] if inode == nil { panic ( fmt . Sprintf ( \" \" , id ) ) } inode . mu . Lock ( ) return } // Find the given inode and return it with its lock held for reading. Panic if // it doesn't exist. // Allocate a new inode, assigning it an ID that is not in use. Return it with // its lock held. // // EXCLUSIVE_LOCKS_REQUIRED(fs.mu) // EXCLUSIVE_LOCK_FUNCTION(inode.mu) func ( fs * memFS ) allocateInode ( mode os . FileMode ) ( id fuse . InodeID , inode * inode ) parent := fs . getInodeForModifyingOrDie ( req . Parent ) parent . AddChild ( childID , req . Name , fuseutil . DT_Directory )", "del_tokens": "// Find the supplied inode and return it with its lock held for reading. Panic // if it doesn't exist. parent := fs . getInodeForModifying ( req . Parent ) parent . AddEntry ( childID , req . Name , fuseutil . DT_Directory )", "commit_type": "fix"}
{"commit_tokens": ["add", "OS", "X", "support", "for", "beyond", "compare"], "add_tokens": "import ( \" \" ) var programName string switch runtime . GOOS { case \" \" : programName = \" \" case \" \" : programName = \" \" }", "del_tokens": "programName := \" \"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "JsonReference", ".", "HasFullFilePath", "to", "be", "set", "correctly", "on", "Windows"], "add_tokens": "\" \" r . HasFullFilePath = filepath . IsAbs ( refUrl . Path )", "del_tokens": "\" \" r . HasFullFilePath = strings . HasPrefix ( refUrl . Path , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "test", "level", "failure", "to", "indicate", "build", "failure"], "add_tokens": "if setExitCode && report . Failures ( ) > 0 {", "del_tokens": "if setExitCode && report . Failed ( ) {", "commit_type": "use"}
{"commit_tokens": ["use", "internal", "/", "cpu", "for", "detect", "avx2"], "add_tokens": "import \" \" if cpufeat . X86 . HasAVX2 {", "del_tokens": "if hasAVX2 ( ) {", "commit_type": "use"}
{"commit_tokens": ["add", "special", "support", "for", "int64"], "add_tokens": "\" \" field : field , String : fieldInfo . IsInt64 ( ) ,", "del_tokens": "\" \" field : field ,", "commit_type": "add"}
{"commit_tokens": ["Add", "campaign", "create", "and", "send"], "add_tokens": "const debug bool = true return json . Unmarshal ( r . alterJson ( body ) , retval ) return json . Unmarshal ( body , retval )", "del_tokens": "const debug bool = false json . Unmarshal ( r . alterJson ( body ) , retval ) json . Unmarshal ( body , retval )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "server", "name", "randomizer"], "add_tokens": "var ( maxAdjectives = len ( possibleServerNames [ \" \" ] ) - 1 maxNouns = len ( possibleServerNames [ \" \" ] ) - 1 maxCountries = len ( possibleServerNames [ \" \" ] ) - 1", "del_tokens": "const ( maxAdjectives = 527 - 1 maxNouns = 364 - 1 maxCountries = 249 - 1", "commit_type": "fix"}
{"commit_tokens": ["Move", "html", "files", "into", "assets", "/"], "add_tokens": "http . ServeFile ( w , r , path . Join ( root , \" \" ) ) iconsHTML = template . Must ( template . ParseFiles ( path . Join ( root , \" \" ) ) )", "del_tokens": "http . ServeFile ( w , r , path . Join ( root , \" \" ) ) iconsHTML = template . Must ( template . ParseFiles ( path . Join ( root , \" \" ) ) )", "commit_type": "move"}
{"commit_tokens": ["Update", "RU864", "band", "config", "."], "add_tokens": "RX2Frequency : 869050000 , { Frequency : 864700000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } , { Frequency : 864900000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } , { Frequency : 864700000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } , { Frequency : 864900000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } ,", "del_tokens": "RX2Frequency : 869525000 , { Frequency : 864100000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } , { Frequency : 864300000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } , { Frequency : 864100000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } , { Frequency : 864300000 , DataRates : [ ] int { 0 , 1 , 2 , 3 , 4 , 5 } } ,", "commit_type": "update"}
{"commit_tokens": ["Fix", "up", "usb", "to", "pass", "reliably", "and", "to", "work", "cross", "-", "platform"], "add_tokens": "done chan struct { } done : make ( chan struct { } ) , tv := C . struct_timeval { tv_sec : 0 , tv_usec : 100000 , }", "del_tokens": "done chan bool done : make ( chan bool ) , tv := C . struct_timeval { 0 , 100000 } c . done <- true", "commit_type": "fix"}
{"commit_tokens": ["Fix", "param", "description", "and", "set", "default", "listen", "/", "addr", "value", "."], "add_tokens": "flag . StringVar ( & addr , \" \" , \" \" , \" \" )", "del_tokens": "flag . StringVar ( & addr , \" \" , \" \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["remove", "unused", "arg", "on", "router", "method"], "add_tokens": ") * cluster . Server { return server server := r . defaultRoute ( serversOfType ) return server , nil server := r . defaultRoute ( serversOfType ) return server , nil", "del_tokens": "svType string , ) ( * cluster . Server , error ) { return server , nil return r . defaultRoute ( svType , serversOfType ) return r . defaultRoute ( svType , serversOfType )", "commit_type": "remove"}
{"commit_tokens": ["Make", "all", "constants", "typed", "."], "add_tokens": "SELECTION_SECONDARY Atom = 2 SELECTION_CLIPBOARD Atom = 69 TARGET_BITMAP Atom = 5 TARGET_COLORMAP Atom = 7 TARGET_DRAWABLE Atom = 17 TARGET_PIXMAP Atom = 20 TARGET_STRING Atom = 31 SELECTION_TYPE_ATOM Atom = 4 SELECTION_TYPE_BITMAP Atom = 5 SELECTION_TYPE_COLORMAP Atom = 7 SELECTION_TYPE_DRAWABLE Atom = 17 SELECTION_TYPE_INTEGER Atom = 19 SELECTION_TYPE_PIXMAP Atom = 20 SELECTION_TYPE_WINDOW Atom = 33 SELECTION_TYPE_STRING Atom = 31", "del_tokens": "SELECTION_SECONDARY = 2 SELECTION_CLIPBOARD = 69 TARGET_BITMAP = 5 TARGET_COLORMAP = 7 TARGET_DRAWABLE = 17 TARGET_PIXMAP = 20 TARGET_STRING = 31 SELECTION_TYPE_ATOM = 4 SELECTION_TYPE_BITMAP = 5 SELECTION_TYPE_COLORMAP = 7 SELECTION_TYPE_DRAWABLE = 17 SELECTION_TYPE_INTEGER = 19 SELECTION_TYPE_PIXMAP = 20 SELECTION_TYPE_WINDOW = 33 SELECTION_TYPE_STRING = 31", "commit_type": "make"}
{"commit_tokens": ["fixes", "findTransactions", "sending", "null", "to", "IRI"], "add_tokens": "Addresses Hashes `json:\"addresses,omitempty\"` Approvees Hashes `json:\"approvees,omitempty\"` Bundles Hashes `json:\"bundles,omitempty\"` Tags [ ] Trytes `json:\"tags,omitempty\"`", "del_tokens": "Addresses Hashes `json:\"addresses\"` Approvees Hashes `json:\"approvees\"` Bundles Hashes `json:\"bundles\"` Tags [ ] Trytes `json:\"tags\"`", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectThat ( o . MediaLink , MatchesRegexp ( \" \" ) )", "del_tokens": "ExpectThat ( o . MediaLink , MatchesRegexp ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "support", "for", "strict", "mocks", "(", "calls", "in", "a", "particular", "order", ")", "."], "add_tokens": "// By default, expected calls are not enforced to run in any particular order. // Call order dependency can be enforced by use of InOrder and/or Call.After. // Call.After can create more varied call order dependencies, but InOrder is // often more convenient. // // The following examples create equivalent call order dependencies. // // Example of using Call.After to chain expected call order: // // firstCall := mockObj.EXPECT().SomeMethod(1, \"first\") // secondCall := mockObj.EXPECT().SomeMethod(2, \"second\").After(firstCall) // mockObj.EXPECT().SomeMethod(3, \"third\").After(secondCall) // // Example of using InOrder to declare expected call order: // // gomock.InOrder( // mockObj.EXPECT().SomeMethod(1, \"first\"), // mockObj.EXPECT().SomeMethod(2, \"second\"), // mockObj.EXPECT().SomeMethod(3, \"third\"), // ) // // Two things happen here: // * the matching call no longer needs to check prerequite calls, // * and the prerequite calls are no longer expected, so remove them. preReqCalls := expected . dropPrereqs ( ) for _ , preReqCall := range preReqCalls { ctrl . expectedCalls . Remove ( preReqCall ) }", "del_tokens": "// - Support strict mocks (calls in a particular order).", "commit_type": "implement"}
{"commit_tokens": ["Allow", "calls", "to", "{", "htop", "totp", "}", ".", "Generate", "()", "to", "specify", "the", "secret", "rather", "than", "using", "a", "randomly", "generated", "one", "."], "add_tokens": "// Secret to store. Defaults to a randomly generated secret of SecretSize. You should generally leave this empty. Secret [ ] byte if len ( opts . Secret ) != 0 { v . Set ( \" \" , b32NoPadding . EncodeToString ( opts . Secret ) ) } else { secret := make ( [ ] byte , opts . SecretSize ) _ , err := rand . Read ( secret ) if err != nil { return nil , err } v . Set ( \" \" , b32NoPadding . EncodeToString ( secret ) )", "del_tokens": "secret := make ( [ ] byte , opts . SecretSize ) _ , err := rand . Read ( secret ) if err != nil { return nil , err v . Set ( \" \" , b32NoPadding . EncodeToString ( secret ) )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "first", "miniredis_vs_redis", "discrepancy", "."], "add_tokens": "out . WriteErrorString ( \" \" )", "del_tokens": "out . WriteErrorString ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "a", "separate", "ServiceProviderIssuer", "parameter"], "add_tokens": "// NOTE(russell_h): In earlier versions we mistakenly sent the IdentityProviderIssuer // in the AuthnRequest. For backwards compatibility we will fall back to that // behavior when ServiceProviderIssuer isn't set. if sp . ServiceProviderIssuer != \" \" { authnRequest . CreateElement ( \" \" ) . SetText ( sp . ServiceProviderIssuer ) } else { authnRequest . CreateElement ( \" \" ) . SetText ( sp . IdentityProviderIssuer ) }", "del_tokens": "authnRequest . CreateElement ( \" \" ) . SetText ( sp . IdentityProviderIssuer )", "commit_type": "add"}
{"commit_tokens": ["Fix", "validation", "w", "/", "o", "value"], "add_tokens": "\" \" \" \" if scope . Value != nil { resource := scope . IndirectValue ( ) . Interface ( ) _ , validatorErrors := govalidator . ValidateStruct ( resource ) if validatorErrors != nil { if errors , ok := validatorErrors . ( govalidator . Errors ) ; ok { for _ , err := range flatValidatorErrors ( errors ) { scope . DB ( ) . AddError ( formattedError ( err , resource ) ) } } else { scope . DB ( ) . AddError ( validatorErrors )", "del_tokens": "\" \" \" \" resource := scope . IndirectValue ( ) . Interface ( ) _ , validatorErrors := govalidator . ValidateStruct ( resource ) if validatorErrors != nil { if errors , ok := validatorErrors . ( govalidator . Errors ) ; ok { for _ , err := range flatValidatorErrors ( errors ) { scope . DB ( ) . AddError ( formattedError ( err , resource ) ) } else { scope . DB ( ) . AddError ( validatorErrors )", "commit_type": "fix"}
{"commit_tokens": ["changed", "api", "path", "is", "now", "part", "of", "config"], "add_tokens": "r := chatter . GET ( t , rat . NewConfig ( \" \" ) ) chatter . PUT ( t , rat . NewConfig ( \" \" ) . Body ( \" \" ) ) chatter . DELETE ( t , rat . NewConfig ( \" \" ) )", "del_tokens": "r := chatter . GET ( t , \" \" ) chatter . PUT ( t , \" \" , rat . NewRequestConfig ( ) . Body ( \" \" ) ) chatter . DELETE ( t , \" \" )", "commit_type": "change"}
{"commit_tokens": ["fixed", "import", "referring", "to", "wrong", "lib"], "add_tokens": "\" \" \" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "DNS", "All", "Record", "-", "Related", "Function"], "add_tokens": "import ( \" \" )", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "complete", "event", "struct", "for", "timeboards"], "add_tokens": "Title string `json:\"title\"` Events [ ] struct { Query string `json:\"q\"` } `json:\"events\"`", "del_tokens": "Title string `json:\"title\"` Events [ ] struct { } `json:\"events\"`", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "arbitrary", "user", "profile", "data"], "add_tokens": "Login string FirstName string `db:\"first_name\"` LastName string `db:\"last_name\"` Email string HashType string `db:\"hash_type\"` ProfileJSON [ ] byte `db:\"profile_data\"` Salt [ ] byte Hash [ ] byte MD5API [ ] byte `db:\"md5_api\"` // \"md5(user:pass)\" ProfileData map [ string ] interface { }", "del_tokens": "Login string FirstName string `db:\"first_name\"` LastName string `db:\"last_name\"` Email string HashType string `db:\"hash_type\"` Salt [ ] byte Hash [ ] byte MD5API [ ] byte `db:\"md5_api\"` // \"md5(user:pass)\"", "commit_type": "add"}
{"commit_tokens": ["Added", "Hasher", "for", "computing", "hashes", "of", "streamed", "objects"], "add_tokens": "\" \" h := NewHasher ( t , int64 ( len ( content ) ) ) h . Write ( content ) return h . Sum ( ) type Hasher struct { hash . Hash } func NewHasher ( t ObjectType , size int64 ) Hasher { h := Hasher { sha1 . New ( ) } h . Write ( t . Bytes ( ) ) h . Write ( [ ] byte ( \" \" ) ) h . Write ( [ ] byte ( strconv . FormatInt ( size , 10 ) ) ) h . Write ( [ ] byte { 0 } ) return h } func ( h Hasher ) Sum ( ) ( hash Hash ) { copy ( hash [ : ] , h . Hash . Sum ( nil ) ) return }", "del_tokens": "h := t . Bytes ( ) h = append ( h , ' ' ) h = strconv . AppendInt ( h , int64 ( len ( content ) ) , 10 ) h = append ( h , 0 ) h = append ( h , content ... ) return Hash ( sha1 . Sum ( h ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "Shift", "method", "to", "List"], "add_tokens": "func TestListScanAndShift ( t * testing . T ) { l1 := NewList ( 100 , true , \" \" , NewList ( 42 , \" \" ) , 3.14 , Dictionary { } ) var ( i int b bool s string l2 List f float64 d Dictionary ) err := l1 . Scan ( & i , & b , & s , & l2 , & f , & d ) if err != nil { t . Fatal ( err ) } if i != 100 || ! b || s != \" \" { t . Error ( \" \" ) } var s2 string shifted := l1 . Shift ( 2 ) if shifted != 2 { t . Fatalf ( \" \" , 2 , shifted ) } err = l1 . Scan ( & s2 ) if err != nil { t . Fatal ( err ) } if s2 != \" \" { t . Fatal ( \" \" ) } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "where", "static", "fileserver", "only", "served", "from", "/"], "add_tokens": "h := http . StripPrefix ( prefix , http . FileServer ( http . Dir ( dir ) ) ) w . router . PathPrefix ( prefix ) . Handler ( h ) // Vars carries request URL parameters that are passed in route prefixes. // to the ResponseWriter", "del_tokens": "w . router . PathPrefix ( prefix ) . Handler ( http . FileServer ( http . Dir ( dir ) ) ) // Vars carries request url parameters passes in route prefixes // to the ResonseWriter", "commit_type": "fix"}
{"commit_tokens": ["add", "retry", "to", "api", "requests"], "add_tokens": "\" \" \" \" var MaxRequestRetries = 5 var bodyBytes [ ] byte if body == nil { bodyBytes = [ ] byte { } } else { bodyBytes , err = ioutil . ReadAll ( body ) if err != nil { return nil , err } } request , err := http . NewRequest ( method , u . URL . String ( ) , nil ) for tries := 0 ; tries <= MaxRequestRetries ; tries ++ { request . Body = ioutil . NopCloser ( bytes . NewBuffer ( bodyBytes ) ) response , err = client . Do ( request ) if err != nil { if err == io . EOF { continue } return } if response . StatusCode == http . StatusServiceUnavailable { delay := ( tries + 1 ) * 10 // smooth out delays from 0-2 time . Sleep ( time . Duration ( delay * delay ) * time . Millisecond ) } break", "del_tokens": "request , err := http . NewRequest ( method , u . URL . String ( ) , body ) // DumpRequest(request) if response , err = client . Do ( request ) ; err != nil { return", "commit_type": "add"}
{"commit_tokens": ["Add", "SetCurrentView", "()", ".", "Remove", "dupped", "field", "Gui", ".", "curview"], "add_tokens": "CurrentView * View func ( g * Gui ) SetCurrentView ( name string ) ( err error ) { for _ , v := range g . views { if v . Name == name { g . CurrentView = v return nil } } return errors . New ( \" \" ) } ( kb . ViewName == \" \" || ( g . CurrentView != nil && kb . ViewName == g . CurrentView . Name ) ) {", "del_tokens": "curview * View currentView * View ( kb . ViewName == \" \" || ( g . curview != nil && kb . ViewName == g . curview . Name ) ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "fisrt", "cut", "of", "WorkItem", "CRUD"], "add_tokens": "_ , res := test . AuthorizeLoginOK ( t , nil , nil , & controller ) if res . Token == \" \" { _ , res := test . ShowVersionOK ( t , nil , nil , & controller ) if res . Commit != \" \" {", "del_tokens": "resp := test . AuthorizeLoginOK ( t , & controller ) if resp . Token == \" \" { resp := test . ShowVersionOK ( t , & controller ) if resp . Commit != \" \" {", "commit_type": "add"}
{"commit_tokens": ["add", "pubdate", "to", "rss", "items"], "add_tokens": "Description : \" \" ,", "del_tokens": "Description : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "logger", "!", "=", "nil", "check", "for", "RequestLogHook", "and", "explicitly", "handle", "nil", "case"], "add_tokens": "if c . RequestLogHook != nil { case nil :", "del_tokens": "if c . RequestLogHook != nil && logger != nil { default :", "commit_type": "remove"}
{"commit_tokens": ["Make", "CredentialsProvider", "return", "a", "pointer", "."], "add_tokens": "Credentials ( ) ( * Credentials , error ) func ( p staticCredentialsProvider ) Credentials ( ) ( * Credentials , error ) { return & p . creds , nil", "del_tokens": "Credentials ( ) ( Credentials , error ) func ( p staticCredentialsProvider ) Credentials ( ) ( Credentials , error ) { return p . creds , nil", "commit_type": "make"}
{"commit_tokens": ["Add", "app", "to", "handle", "main", "server", "setup", "and", "running"], "add_tokens": "type OnChangeFunc func ( bool ) fn OnChangeFunc func ( s * Switch ) OnStateChanged ( fn OnChangeFunc ) {", "del_tokens": "type StateChangeFunc func ( bool ) fn StateChangeFunc func ( s * Switch ) OnStateChanged ( fn StateChangeFunc ) {", "commit_type": "add"}
{"commit_tokens": ["Made", "verify", "file", "default", "off", "with", "CLI", "usage"], "add_tokens": "const ApplicationVersion = `1.2.2`", "del_tokens": "const ApplicationVersion = `1.2.1`", "commit_type": "make"}
{"commit_tokens": ["Added", "FROM", "support", "to", "SQL", "parser", "."], "add_tokens": "err := sqlParser . ParseString ( `SELECT u.name, u.age, u.date_of_birth AS dob FROM user AS u` , sql )", "del_tokens": "err := sqlParser . ParseString ( `SELECT u.name, age, date_of_birth AS dob FROM user AS u` , sql )", "commit_type": "add"}
{"commit_tokens": ["add", "WriteHeader", "()", "to", "SimpleH264Writer", "for", "convenient", "segment", "big", "ts", "file", "into", "small", "ones"], "add_tokens": "func testInputGob ( pathGob string , pathOut string , testSeg bool ) { //w.WriteHeader() syncCount := 0 segCount := 0 for i , sample := range allSamples . Samples { if debugStream { fmt . Println ( \" \" , i ) } if sample . Sync { syncCount ++ if testSeg { if syncCount % 3 == 0 { outfile . Close ( ) segCount ++ outfile , _ = os . Create ( fmt . Sprintf ( \" \" , pathOut , segCount ) ) w . W = outfile w . WriteHeader ( ) fmt . Println ( \" \" , segCount , \" \" , syncCount ) } } } fmt . Println ( \" \" , pathOut ) testSegment := flag . Bool ( \" \" , false , \" \" ) testInputGob ( * inputGob , * output , * testSegment )", "del_tokens": "func testInputGob ( pathGob string , pathOut string ) { for _ , sample := range allSamples . Samples { fmt . Println ( \" \" , pathOut ) testInputGob ( * inputGob , * output )", "commit_type": "add"}
{"commit_tokens": ["Fix", "SetControlNavigation", "(", "missing", "s", "at", "the", "end", ")", ".", "Note", "that", "while", "this", "works", "(", "listen", "to", "navigationRequested", "events", "and", "response", "with", "a", "processNavigation", "message", ")", "it", "seems", "to", "only", "receive", "real", "navigation", "requests", "(", "load", "pages", ")", "and", "not", "generic", "load", "requests", "(", "for", "images", "css", "etc", ".", ")"], "add_tokens": "control := flag . String ( \" \" , \" \" , \" \" ) if * control != \" \" { remote . SetControlNavigations ( true ) navigationResponse := godet . NavigationProceed switch * control { case \" \" : navigationResponse = godet . NavigationProceed case \" \" : navigationResponse = godet . NavigationCancel case \" \" : navigationResponse = godet . NavigationCancelAndIgnore } log . Println ( \" \" , params . String ( \" \" ) , navigationResponse ) remote . ProcessNavigation ( params . Int ( \" \" ) , navigationResponse )", "del_tokens": "control := flag . Bool ( \" \" , false , \" \" ) if * control { remote . SetControlNavigation ( true ) log . Println ( \" \" , params [ \" \" ] )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "basic", "client", "UI", "issues", "for", "the", "network", "command"], "add_tokens": "return method ( chain + \" \" + args [ 0 ] , args [ 2 : ] ... ) return fmt . Errorf ( \" \\n \" , chain , args [ 0 ] , chain , chain ) flag . Usage ( ) return nil", "del_tokens": "\" \" \" \" var errStr string return method ( chain , args [ 2 : ] ... ) errStr = fmt . Sprintf ( \" \\n \" , chain , args [ 0 ] , chain , chain ) fmt . Fprintf ( cli . err , errStr ) return errors . New ( errStr ) errStr = fmt . Sprintf ( \" \\n \" , chain , chain ) fmt . Fprintf ( cli . err , errStr ) return errors . New ( errStr ) os . Exit ( 0 )", "commit_type": "fix"}
{"commit_tokens": ["made", "parsing", "token", "constants", "private"], "add_tokens": "const tSTRING = 57346 const tPHRASE = 57347 const tPLUS = 57348 const tMINUS = 57349 const tCOLON = 57350 const tBOOST = 57351 const tLPAREN = 57352 const tRPAREN = 57353 const tNUMBER = 57354 const tGREATER = 57355 const tLESS = 57356 const tEQUAL = 57357 \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "del_tokens": "const STRING = 57346 const PHRASE = 57347 const PLUS = 57348 const MINUS = 57349 const COLON = 57350 const BOOST = 57351 const LPAREN = 57352 const RPAREN = 57353 const NUMBER = 57354 const GREATER = 57355 const LESS = 57356 const EQUAL = 57357 \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "unparseable", "sections", "."], "add_tokens": "rawBody string return & Section { f , \" \" , name , make ( map [ string ] * Key ) , make ( [ ] string , 0 , 10 ) , make ( map [ string ] string ) , \" \" } // Body returns rawBody of Section if the section was marked as unparseable. // It still follows the other rules of the INI format surrounding leading/trailing whitespace. func ( s * Section ) Body ( ) string { return strings . TrimSpace ( s . rawBody ) }", "del_tokens": "return & Section { f , \" \" , name , make ( map [ string ] * Key ) , make ( [ ] string , 0 , 10 ) , make ( map [ string ] string ) }", "commit_type": "add"}
{"commit_tokens": ["Use", "uint", "to", "track", "window", "position"], "add_tokens": "wpos uint wpos = wpos % windowSize", "del_tokens": "wpos int if wpos >= windowSize { wpos = 0 }", "commit_type": "use"}
{"commit_tokens": ["Adds", "MatchText", "matcher", "for", "regex", "text", "matching"], "add_tokens": "return selectorMessage ( actual , \" \" , m . ExpectedText , m . actualText ) return selectorMessage ( actual , \" \" , m . ExpectedText , m . actualText )", "del_tokens": "return selectorMessage ( actual , \" \" , m . ExpectedText , m . actualText ) return selectorMessage ( actual , \" \" , m . ExpectedText , m . actualText )", "commit_type": "add"}
{"commit_tokens": ["Add", "l10n", "Locale", "for", "setting"], "add_tokens": "import ( \" \" \" \" ) l10n . Locale", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "when", "blanace", "is", "shortage"], "add_tokens": "bals , err = api . Balances ( adrs ) } // Return not enough balance error if total > bals . Total ( ) { return nil , nil , errors . New ( \" \" )", "del_tokens": "bals , err := api . Balances ( adrs ) // Return not enough balance error if total > bals . Total ( ) { return nil , nil , errors . New ( \" \" ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "variadic", "in", "Error", "/", "Errorf"], "add_tokens": "t . Error ( args ... ) t . Errorf ( format , args ... )", "del_tokens": "t . Error ( args ) t . Errorf ( format , args )", "commit_type": "fix"}
{"commit_tokens": ["add", "Resampler", "type", "(", "returned", "from", "Resample", "and", "ResampleRatio", ")", "with", "a", "SetRatio", "method"], "add_tokens": "func Resample ( quality int , old , new SampleRate , s Streamer ) * Resampler { func ResampleRatio ( quality int , ratio float64 , s Streamer ) * Resampler { return & Resampler { // Resampler is a Streamer created by Resample and ResampleRatio functions. It allows dynamic // changing of the resampling ratio, which can be useful for dynamically changing the speed of // streaming. type Resampler struct { // Stream streams the original audio resampled according to the current ratio. func ( r * Resampler ) Stream ( samples [ ] [ 2 ] float64 ) ( n int , ok bool ) { // Err propagates the original Streamer's errors. func ( r * Resampler ) Err ( ) error { // SetRatio sets the resampling ratio. This does not cause any glitches in the stream. func ( r * Resampler ) SetRatio ( ratio float64 ) { r . pos = int ( float64 ( r . pos ) * r . ratio / ratio ) r . ratio = ratio }", "del_tokens": "func Resample ( quality int , old , new SampleRate , s Streamer ) Streamer { func ResampleRatio ( quality int , ratio float64 , s Streamer ) Streamer { return & resample { type resample struct { func ( r * resample ) Stream ( samples [ ] [ 2 ] float64 ) ( n int , ok bool ) { func ( r * resample ) Err ( ) error {", "commit_type": "add"}
{"commit_tokens": ["Update", "examples", "with", "new", "code"], "add_tokens": "\" \" : \" \" ,", "del_tokens": "\" \" : \" \" ,", "commit_type": "update"}
{"commit_tokens": ["Fixed", "the", "generation", "of", "random", "peer", "ID", "s"], "add_tokens": "binary . BigEndian . PutUint64 ( inp [ 2 : ] , i ) printf ( \" \" )", "del_tokens": "binary . BigEndian . PutUint64 ( inp [ idLen - 8 : ] , i ) printf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "and", "example", "."], "add_tokens": "// Output: // <span class=\"com\">/* hello, world! */</span> // // <span class=\"com\">// b is a cool function</span> // <span class=\"kwd\">function</span> <span class=\"pln\">b</span><span class=\"pun\">(</span><span class=\"pun\">)</span> <span class=\"pun\">{</span>", "del_tokens": "// output: // span class=\"com\">/* hello, world! */</span> // <span class=\"com\">// b is a cool function // </span><span class=\"kwd\">function</span> <span class=\"pln\">b</span><span class=\"pun\">(</span><span class=\"pun\">)</span> <span class=\"pun\">{</span>", "commit_type": "fix"}
{"commit_tokens": ["Move", "parsing", "functions", "to", "pkg", "/", "parsers", "and", "the", "specific", "kernel", "handling"], "add_tokens": "\" \" parts , err := parsers . PartParser ( PortSpecTemplate , rawPort )", "del_tokens": "\" \" parts , err := utils . PartParser ( PortSpecTemplate , rawPort )", "commit_type": "move"}
{"commit_tokens": ["Add", "remote", "signing", "and", "consolidate", "remote", "cert", "generation"], "add_tokens": "h , err := NewSignHandler ( testCaFile , testCaKeyFile , \" \" ) _ , err := NewSignHandler ( testCaFile , testBrokenCSRFile , \" \" )", "del_tokens": "h , err := NewSignHandler ( testCaFile , testCaKeyFile ) _ , err := NewSignHandler ( testCaFile , testBrokenCSRFile )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "problem", "with", "column", "query"], "add_tokens": "cols , err := models . ColumnsByRelkindSchema ( db , \" \" , args . Schema )", "del_tokens": "cols , err := models . ColumnsByRelkindSchema ( db , \" \" , args . Schema )", "commit_type": "fix"}
{"commit_tokens": ["change", "way", "to", "get", "cpu", "ext", "instruction"], "add_tokens": "\" \" if cpuid . CPU . AVX2 ( ) { } else if cpuid . CPU . SSSE3 ( ) {", "del_tokens": "if hasAVX2 ( ) { } else if hasSSSE3 ( ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "tests", "to", "command", "and", "message"], "add_tokens": "ID : 0 , UserID : \" \" , Type : \" \" , Message : \" \" , } if msg . User ( ) != \" \" { t . Errorf ( \" \\\" \\\" \" ) } if msg . Text ( ) != \" \" { t . Errorf ( \" \\\" \\\" \" ) func TestStripMention ( t * testing . T ) {", "del_tokens": "ID : 0 , Type : \" \" , func StripMention ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "deluge", "daemon", "v2"], "add_tokens": "* go - libdeluge v0 . 3.0 - a native deluge RPC client library * Copyright ( C ) 2015 ~ 2019 gdm85 - https : //github.com/gdm85/go-libdeluge/ v2daemon bool free bool fs . BoolVar ( & v2daemon , \" \" , false , \" \" ) fs . BoolVar ( & free , \" \" , false , \" \" ) fs . BoolVar ( & free , \" \" , false , \" \" ) deluge := delugeclient . New ( delugeclient . Settings { Hostname : host , Port : port , Login : username , Password : password , Logger : logger , V2Daemon : v2daemon , DebugSaveInteractions : debugIncoming } ) if free { n , err := deluge . GetFreeSpace ( \" \" ) if err != nil { fmt . Fprintf ( os . Stderr , \" \\n \" , err ) os . Exit ( 6 ) } fmt . Printf ( \" \\n \" , n ) }", "del_tokens": "* go - libdeluge v0 . 2.0 - a native deluge RPC client library * Copyright ( C ) 2015 ~ 2017 gdm85 - https : //github.com/gdm85/go-libdeluge/ \" \" deluge := delugeclient . New ( delugeclient . Settings { host , port , username , password , logger , time . Duration ( 0 ) , debugIncoming } )", "commit_type": "add"}
{"commit_tokens": ["add", "OverrideTimeNow", "function", "to", "memstore", "driver"], "add_tokens": "lru \" \" keys * lru . Cache m map [ string ] * int64 timeNow func ( ) time . Time //usually time.Now, but can be overridden for unit tests keys : keys , timeNow : time . Now , m : make ( map [ string ] * int64 ) , timeNow : time . Now , // SetTimeNow makes this store use the given function instead of time.Now(). // This is useful for unit tests that use a simulated wallclock. func ( ms * MemStore ) SetTimeNow ( timeNow func ( ) time . Time ) { ms . timeNow = timeNow } now := ms . timeNow ( )", "del_tokens": "\" \" keys * lru . Cache m map [ string ] * int64 keys : keys , m : make ( map [ string ] * int64 ) , now := time . Now ( )", "commit_type": "add"}
{"commit_tokens": ["fixing", "tests", "for", "new", "version", "still", "a", "lot", "broken"], "add_tokens": "func ( m Magic ) GetID ( ) string { return m . ID . String ( ) } ID , Title , Text string } func ( s SimplePost ) GetID ( ) string { return s . ID func ( c Post ) GetReferences ( ) [ ] Reference { return [ ] Reference { { Type : \" \" , Name : \" \" , } , { Type : \" \" , Name : \" \" , } , } } result := [ ] MarshalIdentifier { } if c . Author != nil { result = append ( result , c . Author ) } result = append ( result , c . Comments [ key ] )", "del_tokens": "Title , Text string result := [ ] MarshalIdentifier { c . Author } result = append ( result , & c . Comments [ key ] )", "commit_type": "fix"}
{"commit_tokens": ["use", "channel", "to", "write", "responses", "to", "client"], "add_tokens": "b . Request . GetClient ( ) . chan_out <- b sr . Request . GetClient ( ) . chan_out <- sr s . Request . GetClient ( ) . chan_out <- entry", "del_tokens": "b . Request . GetClient ( ) . writeLdapResult ( b ) sr . Request . GetClient ( ) . writeLdapResult ( sr ) s . Request . GetClient ( ) . writeLdapResult ( entry )", "commit_type": "use"}
{"commit_tokens": ["added", "support", "to", "call", "tx", ".", "Rollback", "and", "Commit", "within", "DB", ".", "Transactional"], "add_tokens": "func ( db * DB ) Transactional ( f func ( * Tx ) error ) ( err error ) { defer func ( ) { if p := recover ( ) ; p != nil { tx . Rollback ( ) panic ( p ) } else if err != nil { if err2 := tx . Rollback ( ) ; err2 != nil { if err2 == sql . ErrTxDone { return } err = Errors { err , err2 } } } else { if err = tx . Commit ( ) ; err == sql . ErrTxDone { err = nil } } ( ) err = f ( tx ) return err", "del_tokens": "func ( db * DB ) Transactional ( f func ( * Tx ) error ) error { if err := f ( tx ) ; err != nil { if e := tx . Rollback ( ) ; e != nil { return Errors { err , e } return err } return tx . Commit ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "sort", "order", "for", "Jobs", "(", "Unix", "seconds", "vs", "Seconds", ")"], "add_tokens": "return s . jobs [ j ] . nextRun . Unix ( ) >= s . jobs [ i ] . nextRun . Unix ( )", "del_tokens": "return s . jobs [ j ] . nextRun . Second ( ) >= s . jobs [ i ] . nextRun . Second ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "basic", "unit", "tests", "around", "cached", "meta", "lookups", "."], "add_tokens": "c . addRegionToCache ( reg , client ) return client , reg , nil } // Adds a region to our meta cache. func ( c * Client ) addRegionToCache ( reg * region . Info , client * region . Client ) {", "del_tokens": "return client , reg , nil", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "benchmarks", "to", "the", "readme"], "add_tokens": "OneOfOne \" \" { \" \" , OneOfOne . Checksum64 } , { \" \" , 5 } , { \" \" , 100 } , { \" \" , 4e3 } , { \" \" , 10e6 } ,", "del_tokens": "\" \" { \" \" , xxhash . Checksum64 } , { \" \" , 5 } , { \" \" , 20 } , { \" \" , 100 } , { \" \" , 4e3 } , { \" \" , 10e6 } ,", "commit_type": "add"}
{"commit_tokens": ["fix", "goose", "error", "changing", "from", "g", ".", "ExtractFromUrl", "to", "g", ".", "ExtractFromURL"], "add_tokens": "\" \" article := g . ExtractFromURL ( buf . String ( ) )", "del_tokens": "\" \" article := g . ExtractFromUrl ( buf . String ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "test", "when", "local", "syslog", "unix", "socket", "is", "not", "available"], "add_tokens": "m := NewSyslogOutput ( \" \" , \" \" , \" \" )", "del_tokens": "m := NewSyslogOutput ( \" \" , \" \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Creating", "the", "correct", "base", "url"], "add_tokens": "server . RegisterRiskHandlers ( e , session . DB ( \" \" ) , \" \" )", "del_tokens": "server . RegisterRiskHandlers ( e , session . DB ( \" \" ) , \" \" )", "commit_type": "create"}
{"commit_tokens": ["Fix", "wrong", "description", "texts", "in", "the", "unmarshal", "test", "."], "add_tokens": "It ( \" \" , func ( ) { It ( \" \" , func ( ) {", "del_tokens": "It ( \" \" , func ( ) { It ( \" \" , func ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "Interrupt", "method", "to", "enable", "clients", "to", "catch", "a", "user", "interruption", "while", "processing", "a", "commend", "and", "for", "example", "simply", "terminate", "the", "command", "instead", "of", "terminating", "the", "application", "."], "add_tokens": "// this function is called when the user tries to interrupt a running // command. If it returns true, the application will be terminated. Interrupt func ( os . Signal ) bool // if true, a Ctrl-C should return an error // CtrlCAborts bool if cmd . Interrupt == nil { cmd . Interrupt = func ( sig os . Signal ) bool { return true } } // cmd.line.SetCtrlCAborts(cmd.CtrlCAborts) if cmd . Interrupt ( sig ) { // rethrow signal to kill app p , _ := os . FindProcess ( os . Getpid ( ) ) p . Signal ( sig ) } else { signal . Notify ( sigc , os . Interrupt , syscall . SIGTERM ) } m , _ := liner . TerminalMode ( ) if m != nil { m . ApplyMode ( ) }", "del_tokens": "// rethrow signal p , _ := os . FindProcess ( os . Getpid ( ) ) p . Signal ( sig )", "commit_type": "add"}
{"commit_tokens": ["add", "ptrace", "and", "cont", "syscall", "having", "bug"], "add_tokens": "c . Stdout = os . Stdout c . SysProcAttr = & syscall . SysProcAttr { Ptrace : true , Setpgid : true , // progress group ,killed when the leader process killed. } Ptrace : true , // continue the execution. err = syscall . PtraceCont ( c . Process . Pid , 0 ) if err != nil { t . Fatal ( err ) } t . Log ( err )", "del_tokens": "\" \" // sometime", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "decoding", "integers", "into", "float32"], "add_tokens": "var sv string sv , ok = k . ( string ) if ! ok { return nil , fmt . Errorf ( \" \" , k ) } } else { sv = string ( v )", "del_tokens": "return nil , errors . New ( \" \" ) sv := string ( v )", "commit_type": "add"}
{"commit_tokens": ["Add", "generate", "command", "to", "verify", "task"], "add_tokens": "skipGenerate = \" \" Usage : \" \" , flag . BoolFlag { Name : skipGenerate , Usage : \" \" } , if ! ctx . Bool ( skipGenerate ) { args := [ ] string { \" \" } if ! ctx . Bool ( apply ) { args = append ( args , \" \" ) } ctx . Println ( \" \" ) if err := runCmd ( cmder , args , wd , ctx ) ; err != nil { failedChecks = append ( failedChecks , strings . Join ( args , \" \" ) ) } }", "del_tokens": "Usage : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["added", "docs", "adaptive", "sse", "gzip"], "add_tokens": "\" \" if ! strings . Contains ( w . Header ( ) . Get ( \" \" ) , \" \" ) { es . s . Gzip = true }", "del_tokens": "es . s . Gzip = true", "commit_type": "add"}
{"commit_tokens": ["using", "Table", ".", "url", "instead"], "add_tokens": "return sql . Open ( \" \" , \" \" )", "del_tokens": "return sql . Open ( \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["adding", "better", "support", "for", "cloud", "config", "output"], "add_tokens": "EphemeralDisk EphemeralDisk `yaml:\"ephemeral_disk,omitempty,flow\"` //EBS backed ephemeral disk of custom size for when instance storage is not large enough or not available for selected instance type. DiskType string `yaml:\"type,omitempty\"` // [String, optional]: Type of the disk: standard, gp2. Defaults to standard.", "del_tokens": "EphemeralDisk EphemeralDisk `yaml:\"ephemeral_disk,omitempty\"` //EBS backed ephemeral disk of custom size for when instance storage is not large enough or not available for selected instance type. DiskType string `yaml\"type,omitempty\"` // [String, optional]: Type of the disk: standard, gp2. Defaults to standard.", "commit_type": "add"}
{"commit_tokens": ["Fix", "scale", "to", "zero", "instances", "."], "add_tokens": "changes := struct { ID string `json:\"id\"` Instances int `json:\"instances\"` } { ID : validateID ( name ) , Instances : instances , }", "del_tokens": "changes := new ( Application ) changes . ID = validateID ( name ) changes . Instances = instances", "commit_type": "fix"}
{"commit_tokens": ["Add", "documentation", "and", "minor", "formatting", "changes", "."], "add_tokens": "// TarReader type contains all the artifacts needed // to unpack a tar file. // NewTar creates a new TarReader. // NewTarGz create a new TarReader for a tar file that // has been gzipped. // Unpack will unpack a tar file contained in the TarReader. It // writes the new entires to the toPath. Unpack takes care of // closing the underlying artifacts (file, and gzip stream) for the // TarReader. You cannot call Unpack twice for the same TarReader.", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["moved", "json", "loading", "to", "jsonutils"], "add_tokens": "document , err := GetHttpJson ( documentReferenceString )", "del_tokens": "\" \" \" \" \" \" resp , err := http . Get ( documentReferenceString ) if err != nil { return nil , err } if resp . StatusCode != http . StatusOK { return nil , errors . New ( \" \" + resp . Status ) } bodyBuff , err := ioutil . ReadAll ( resp . Body ) if err != nil { return nil , err } var document interface { } err = json . Unmarshal ( bodyBuff , & document )", "commit_type": "move"}
{"commit_tokens": ["Add", "utility", "functions", "for", "outputting", "debug", "messages"], "add_tokens": "import ( \" \" \" \" ) // Println formats a message using the default formats for the operands and // outputs the message to the debugger console. It returns the number of // characters that were output and any error that occurred. func Println ( a ... interface { } ) ( n int , err error ) { return fmt . Fprint ( Console , a ... ) } // Printf formats a debug message using the format specifier and writes the // formatted message to the debugger console. It returns the number of // characters that were output and any error that occurred. func Printf ( format string , a ... interface { } ) ( n int , err error ) { return fmt . Fprintf ( Console , format , a ... ) }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "Time", ".", "RFC3339", "instead", "of", "custom", "format"], "add_tokens": "r . AddParameter ( \" \" , startDate . Format ( time . RFC3339 ) )", "del_tokens": "// TODO(sfalvo): // Use Time.RFC3339 for format? r . AddParameter ( \" \" , startDate . Format ( \" \" ) ) // TODO(sfalvo): // Test: can spaces in tag work? // Test: can unicode work?", "commit_type": "use"}
{"commit_tokens": ["Add", "find", "/", "findSubmatch", "(", "not", "-", "All", "versions", ")", "."], "add_tokens": "\" \" : reFind , \" \" : reFindSubmatch , return utils . DeepPush ( l , allSubmatch ) } } func reFind ( re * regexp . Regexp ) lua . Function { return func ( l * lua . State ) int { s := lua . CheckString ( l , 1 ) all := re . FindString ( s ) return utils . DeepPush ( l , all ) } } func reFindSubmatch ( re * regexp . Regexp ) lua . Function { return func ( l * lua . State ) int { s := lua . CheckString ( l , 1 ) allSubmatch := re . FindStringSubmatch ( s )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "snapshots", "and", "query", "Reuse", "connection"], "add_tokens": "\" \" \" \" if ref . database . app . jwtConfig == nil { return ref . database . app . databaseURL + \" \" + ref . path + \" \" , nil } return ref . database . app . databaseURL + \" \" + ref . path + \" \" + token , nil io . Copy ( ioutil . Discard , resp . Body ) io . Copy ( ioutil . Discard , resp . Body ) io . Copy ( ioutil . Discard , resp . Body )", "del_tokens": "return ref . database . app . databaseURL + ref . path + \" \" + token , nil", "commit_type": "add"}
{"commit_tokens": ["Change", "Global", "Constant", "String", "to", "Conform", "with", "the", "Go", "Standards"], "add_tokens": "const ExtendedPropertyDNS string = \" \" const ExtendedPropertyGateway string = \" \" const ExtendedPropertyNetMask string = \" \" const ExtendedPropertyMasterIP string = \" \" const ExtendedPropertyContainerNetwork string = \" \" const ExtendedPropertyZookeeperIP1 string = \" \" const ExtendedPropertyZookeeperIP2 string = \" \" const ExtendedPropertyZookeeperIP3 string = \" \" const ExtendedPropertyETCDIP1 string = \" \" const ExtendedPropertyETCDIP2 string = \" \" const ExtendedPropertyETCDIP3 string = \" \" const ExtendedPropertySSHKey string = \" \"", "del_tokens": "const EXTENDED_PROPERTY_DNS string = \" \" const EXTENDED_PROPERTY_GATEWAY string = \" \" const EXTENDED_PROPERTY_NETMASK string = \" \" const EXTENDED_PROPERTY_MASTER_IP string = \" \" const EXTENDED_PROPERTY_CONTAINER_NETWORK string = \" \" const EXTENDED_PROPERTY_ZOOKEEPER_IP1 string = \" \" const EXTENDED_PROPERTY_ZOOKEEPER_IP2 string = \" \" const EXTENDED_PROPERTY_ZOOKEEPER_IP3 string = \" \" const EXTENDED_PROPERTY_ETCD_IP1 string = \" \" const EXTENDED_PROPERTY_ETCD_IP2 string = \" \" const EXTENDED_PROPERTY_ETCD_IP3 string = \" \" const EXTENDED_PROPERTY_SSH_KEY string = \" \"", "commit_type": "change"}
{"commit_tokens": ["Move", "Set", "to", "set", "package"], "add_tokens": "package set", "del_tokens": "package data", "commit_type": "move"}
{"commit_tokens": ["Made", "LoadStruct", "and", "SaveStruct", "package", "private", "."], "add_tokens": "return loadStruct ( val . Interface ( ) , pl )", "del_tokens": "return LoadStruct ( val . Interface ( ) , pl )", "commit_type": "make"}
{"commit_tokens": ["Changing", "flag", "names", "and", "their", "defaults"], "add_tokens": "maxLogstashInputQueueLength = flag . Int ( \" \" , 50 * 10 ^ 6 , \" \" ) apiSocket = flag . String ( \" \" , \" \" , \" \" ) directorSocket = flag . String ( \" \" , \" \" , \" \" ) adminPort = flag . Int ( \" \" , 7070 , \" \" ) Addr : fmt . Sprintf ( \" \" , * adminPort ) ,", "del_tokens": "maxLogstashInputQueueLength = flag . Int ( \" \" , 1000 , \" \" ) apiSocket = flag . String ( \" \" , \" \" , \" \" ) directorSocket = flag . String ( \" \" , \" \" , \" \" ) managerPort = flag . Int ( \" \" , 7070 , \" \" ) Addr : fmt . Sprintf ( \" \" , * managerPort ) ,", "commit_type": "change"}
{"commit_tokens": ["add", "ctx", "to", "sub", ".", "Next", "for", "cancellation"], "add_tokens": "got , err := sub . Next ( ctx ) msg , err := sub1 . Next ( ctx ) msg , err = sub2 . Next ( ctx )", "del_tokens": "got , err := sub . Next ( ) msg , err := sub1 . Next ( ) msg , err = sub2 . Next ( )", "commit_type": "add"}
{"commit_tokens": ["add", "return", "variable", "names", "for", "documentation", "for", "Confirm"], "add_tokens": "func ( a Actor ) Confirm ( message string , def ConfirmDefault ) ( confirmed bool , err error ) {", "del_tokens": "func ( a Actor ) Confirm ( message string , def ConfirmDefault ) ( bool , error ) {", "commit_type": "add"}
{"commit_tokens": ["Implement", "webhooks", "API", "functionality", "."], "add_tokens": "webhooksEndpoint = \" \" GetWebhooks ( ) ( map [ string ] string , error ) CreateWebhook ( kind , url string ) error DeleteWebhook ( kind string ) error GetWebhookByType ( kind string ) ( string , error ) UpdateWebhook ( kind , url string ) error func generateDomainApiUrl ( m Mailgun , endpoint string ) string { return fmt . Sprintf ( \" \" , apiBase , m . Domain ( ) , endpoint ) } return generateDomainApiUrl ( m , fmt . Sprintf ( \" \" , tail ) ) // return fmt.Sprintf(\"%s/domains/%s/credentials%s\", apiBase, m.Domain(), tail) return generateDomainApiUrl ( m , fmt . Sprintf ( \" \" , endpoint , id ) ) // return fmt.Sprintf(\"%s/domains/%s/%s/%s\", apiBase, m.Domain(), endpoint, id)", "del_tokens": "// Generates a credential URL. return fmt . Sprintf ( \" \" , apiBase , m . Domain ( ) , tail ) return fmt . Sprintf ( \" \" , apiBase , m . Domain ( ) , endpoint , id )", "commit_type": "implement"}
{"commit_tokens": ["Change", "the", "way", "to", "write", "double", "quote"], "add_tokens": "return boldRed ( `\"` ) + red ( v . String ( ) ) + boldRed ( `\"` )", "del_tokens": "return boldRed ( \" \\\" \" ) + red ( v . String ( ) ) + boldRed ( \" \\\" \" )", "commit_type": "change"}
{"commit_tokens": ["Add", "config", "pointers", "to", "format", "and", "dump", "states", "."], "add_tokens": "func handleMethods ( cs * ConfigState , w io . Writer , v reflect . Value ) ( handled bool ) { if ! cs . DisablePointerMethods {", "del_tokens": "func handleMethods ( w io . Writer , v reflect . Value ) ( handled bool ) { if ! Config . DisablePointerMethods {", "commit_type": "add"}
{"commit_tokens": ["Add", "IO", "operations", "to", "pkg"], "add_tokens": "opts . Set ( cmd ) opts . Set ( cmd ) opts . Set ( cmd )", "del_tokens": "type IO struct { Stdin io . Reader Stdout io . Writer Stderr io . Writer } func ( i * IO ) Close ( ) error { var err error for _ , v := range [ ] interface { } { i . Stdin , i . Stderr , i . Stdout , } { if v != nil { if c , ok := v . ( io . Closer ) ; ok { if cerr := c . Close ( ) ; err == nil { err = cerr } } } } return err } func ( o IO ) setSTDIO ( cmd * exec . Cmd ) { cmd . Stdin = o . Stdin cmd . Stdout = o . Stdout cmd . Stderr = o . Stderr } opts . setSTDIO ( cmd ) opts . setSTDIO ( cmd ) opts . setSTDIO ( cmd )", "commit_type": "add"}
{"commit_tokens": ["add", "fallback", "for", "missing", "services", "in", "endpoint", "list"], "add_tokens": "// This means that the service does not exist in the endpoints list. if global { r . Error = ErrSkipRequest ( fmt . Sprintf ( \" \" , service ) ) }", "del_tokens": "// This means that the service does not exist and this shouldn't be handled here.", "commit_type": "add"}
{"commit_tokens": ["improved", "formatting", "of", "tests", "and", "updated", "them", "so", "that", "they", "would", "compile"], "add_tokens": "package token_test import ( \" \" \" \" \" \" ) ID token . Token func ExampleToken ( ) { model := Model { ID : token . New ( ) ,", "del_tokens": "package token ID token . Token func ExampleToken { model := Model { ID : token . New ( ) ,", "commit_type": "improve"}
{"commit_tokens": ["Create", "10", "clients", "instead", "of", "100"], "add_tokens": "wait . Add ( 10 ) for i := 0 ; i < 10 ; i ++ { for i := 0 ; i < 10 ; i ++ { wait . Add ( 10 )", "del_tokens": "wait . Add ( 100 ) for i := 0 ; i < 100 ; i ++ { for i := 0 ; i < 100 ; i ++ { wait . Add ( 100 )", "commit_type": "create"}
{"commit_tokens": ["Fix", "panic", "on", "encoding", "interface", "values", "that", "are", "pointers"], "add_tokens": "func ppint ( n int ) * * int { p := pint ( n ) ; return & p } func pppint ( n int ) * * * int { p := ppint ( n ) ; return & p }", "del_tokens": "func ppint ( n int ) * * int { p := & n ; return & p }", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "quick", "reply", "fix", "MarshalJSON", "for", "QuickReplyButton"], "add_tokens": "import ( \" \" ) ImageURL string Action QuickReplyAction } // MarshalJSON method of QuickReplyButton func ( b * QuickReplyButton ) MarshalJSON ( ) ( [ ] byte , error ) { return json . Marshal ( & struct { Type string `json:\"type\"` ImageURL string `json:\"imageUrl,omitempty\"` Action QuickReplyAction `json:\"action\"` } { Type : \" \" , ImageURL : b . ImageURL , Action : b . Action , } )", "del_tokens": "ImageURL string `json:\"imageUrl,omitempty\"` Action QuickReplyAction `json:\"action\"`", "commit_type": "add"}
{"commit_tokens": ["Implement", "minor", "suggestions", "by", "staticcheck"], "add_tokens": "// This database backend is interchangeable with xyproto/simpleredis and if err != nil { return err } if err != nil { return err }", "del_tokens": "// This database backend is interchangable with xyproto/simpleredis and kvCol = \" \"", "commit_type": "implement"}
{"commit_tokens": ["use", "errors", ".", "New", "where", "applicable"], "add_tokens": "\" \" return errors . New ( \" \" )", "del_tokens": "return fmt . Errorf ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Added", "binary", "encoding", "to", "int4", "and", "int8"], "add_tokens": "EncodeTo : encodeInt8 , EncodeFormat : 1 } EncodeTo : encodeInt4 , EncodeFormat : 1 } binary . Write ( buf , binary . BigEndian , int32 ( 8 ) ) binary . Write ( buf , binary . BigEndian , v ) binary . Write ( buf , binary . BigEndian , int32 ( 4 ) ) binary . Write ( buf , binary . BigEndian , v )", "del_tokens": "EncodeTo : encodeInt8 } EncodeTo : encodeInt4 } s := strconv . FormatInt ( int64 ( v ) , 10 ) binary . Write ( buf , binary . BigEndian , int32 ( len ( s ) ) ) buf . WriteString ( s ) s := strconv . FormatInt ( int64 ( v ) , 10 ) binary . Write ( buf , binary . BigEndian , int32 ( len ( s ) ) ) buf . WriteString ( s )", "commit_type": "add"}
{"commit_tokens": ["change", "SampleRate", "type", "to", "int"], "add_tokens": "numSamples : int ( math . Ceil ( d . Seconds ( ) * float64 ( SampleRate ) ) ) ,", "del_tokens": "numSamples : int ( math . Ceil ( d . Seconds ( ) * SampleRate ) ) ,", "commit_type": "change"}
{"commit_tokens": ["Fix", "IsNotExist", "for", "ip6tables", "in", "nft", "mode"], "add_tokens": "msgNoRuleExist := \" \\n \" msgNoChainExist := \" \\n \" return & Error { * e , cmd , stderr . String ( ) , nil }", "del_tokens": "proto Protocol cmdIptables := getIptablesCommand ( e . proto ) msgNoRuleExist := fmt . Sprintf ( \" \\n \" , cmdIptables ) msgNoChainExist := fmt . Sprintf ( \" \\n \" , cmdIptables ) return & Error { * e , cmd , stderr . String ( ) , ipt . proto , nil }", "commit_type": "fix"}
{"commit_tokens": ["Use", "time", ".", "NewTicker", "instead", "of", "time", ".", "Tick"], "add_tokens": "tick := time . NewTicker ( c . discoveryInterval ) defer func ( ) { tick . Stop ( ) } ( ) case <- tick . C :", "del_tokens": "tick := time . Tick ( c . discoveryInterval ) case <- tick :", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "classic", "registration", "toggle"], "add_tokens": "BindAddress string APIVersion string LogFormatterType string SessionDuration int ClassicRegistration bool", "del_tokens": "BindAddress string APIVersion string LogFormatterType string SessionDuration int", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "of", "record", "edit"], "add_tokens": "func modifyWithEditor ( record * skyrecord . Record ) ( * skyrecord . Record , error ) { return nil , err return nil , err return nil , err return nil , err return nil , err var data map [ string ] interface { } err = json . Unmarshal ( jsonBytes , & data ) return nil , err newRecord , err := skyrecord . MakeRecord ( data ) return newRecord , err record , err = modifyWithEditor ( record )", "del_tokens": "func modifyWithEditor ( record * skyrecord . Record ) error { return err return err return err return err return err err = json . Unmarshal ( jsonBytes , record ) return err return nil err = modifyWithEditor ( record )", "commit_type": "fix"}
{"commit_tokens": ["changed", "to", "take", "first", "provenance", "in", "list", "added", "log", "to", "file"], "add_tokens": "//todo temporary chnage to deal with multiple provenances / * if len ( ann . Provenances ) > 1 { } * / if len ( ann . Provenances ) >= 1 { params [ \" \" ] = \" \"", "del_tokens": "if len ( ann . Provenances ) > 1 { } if len ( ann . Provenances ) == 1 {", "commit_type": "change"}
{"commit_tokens": ["fix", "non", "exported", "fields", "in", "coolbook", ".", "go"], "add_tokens": "Attributes map [ string ] interface { } `json:\"attributes,omitempty\"` // this has a format as well that could be typed, but blargh https://github.com/lob/chef/blob/master/cookbooks/apache2/metadata.json Groupings map [ string ] interface { } `json:\"groupings,omitempty\"` // never actually seen this used.. looks like it should be map[string]map[string]string, but not sure http://docs.opscode.com/essentials_cookbook_metadata.html Recipes map [ string ] string `json:\"recipes,omitempty\"`", "del_tokens": "attributes map [ string ] interface { } `json:\"attributes,omitempty\"` // this has a format as well that could be typed, but blargh https://github.com/lob/chef/blob/master/cookbooks/apache2/metadata.json groupings map [ string ] interface { } `json:\"groupings,omitempty\"` // never actually seen this used.. looks like it should be map[string]map[string]string, but not sure http://docs.opscode.com/essentials_cookbook_metadata.html recipes map [ string ] string `json:\"recipes,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["changed", "api", "to", "access", "job", "as", "a", "function"], "add_tokens": "import \" \" job ( ) // Represents user request, function which should be executed in some worker. type Job func ( )", "del_tokens": "import ( \" \" \" \" ) // This defer function will try to catches a crash defer func ( ) { if r := recover ( ) ; r != nil { log . Println ( r ) // restart worker w . start ( ) if job . RecoverFn != nil { job . RecoverFn ( r ) } } } ( ) job . Fn ( job . Arg ) // Represents user request. // User has to provide function and optional arguments. // Job will be executed in first free goroutine // You can supply custom recover function for a panic. type Job struct { Fn func ( interface { } ) Arg interface { } RecoverFn func ( interface { } ) }", "commit_type": "change"}
{"commit_tokens": ["Add", "command", "line", "flags", "fix", "bug"], "add_tokens": "\" \" \" \" \" \" var version , genDir string fmt . Println ( \" \" ) fmt . Println ( \" \" ) outputDirFlag := flag . String ( \" \" , \" \" , \" \" ) platformFlag := flag . String ( \" \" , runtime . GOOS + \" \" + runtime . GOARCH , \" \" ) flag . Parse ( ) if flag . NArg ( ) < 2 { flag . Usage ( ) platform := * platformFlag appPath := flag . Arg ( 0 ) version = flag . Arg ( 1 ) genDir = * outputDirFlag createUpdate ( appPath , platform )", "del_tokens": "\" \" //\"runtime\" var plat , appPath , version , genDir string fmt . Println ( \" \\n \\n \" ) fmt . Println ( \" \\n \" ) func isArgsPresent ( ) bool { if len ( os . Args ) < 2 { return false } return true } if isArgsPresent ( ) == false { plat = os . Getenv ( \" \" ) + \" \" + os . Getenv ( \" \" ) appPath = os . Args [ 1 ] version = os . Args [ 2 ] genDir = \" \" createUpdate ( appPath , plat )", "commit_type": "add"}
{"commit_tokens": ["Adding", "binding", "on_error", ":", "ignore", "action", "handle", "zero", "-", "length", "response", "bodies"], "add_tokens": "ActionIgnore = `ignore` if res . ContentLength > 0 { switch self . Parser { case `json` , `` : var rv interface { } if err := json . Unmarshal ( data , & rv ) ; err == nil { return rv , nil } else { return nil , err } case `raw` : return template . HTML ( string ( data ) ) , nil default : return nil , fmt . Errorf ( \" \" , self . Parser ) } else { return nil , nil case ActionIgnore : return nil , nil", "del_tokens": "switch self . Parser { case `json` , `` : var rv interface { } if err := json . Unmarshal ( data , & rv ) ; err == nil { return rv , nil } else { return nil , err case `raw` : return template . HTML ( string ( data ) ) , nil default : return nil , fmt . Errorf ( \" \" , self . Parser )", "commit_type": "add"}
{"commit_tokens": ["add", "timer", ".", "fire", "function", "which", "can", "fire", "at", "the", "timer", "channel"], "add_tokens": "// Retrieves the current term of the server. func ( s * Server ) Term ( ) uint64 { s . mutex . Lock ( ) defer s . mutex . Unlock ( ) return s . currentTerm } func ( s * Server ) Initialize ( ) error { fmt . Println ( \" \" , s . currentTerm ) fmt . Println ( \" \" , s . currentTerm ) return nil } func ( s * Server ) StartFollower ( ) { s . electionTimer . Reset ( ) func ( s * Server ) StartLeader ( ) error { fmt . Println ( \" \" , s . currentTerm ) peer . heartbeatTimer . fire ( ) fmt . Println ( \" \" , s . currentTerm , \" \" , req . Term ) fmt . Println ( \" \" , req . LeaderName ) fmt . Println ( \" \" ) fmt . Println ( \" \" ) fmt . Println ( \" \" , name )", "del_tokens": "func ( s * Server ) Start ( ) error { return nil func ( s * Server ) Initialize ( ) error {", "commit_type": "add"}
{"commit_tokens": ["Fix", "implementation", "to", "pass", "tests"], "add_tokens": "case reflect . Map , reflect . Ptr , reflect . Func , reflect . Chan , reflect . Slice :", "del_tokens": "case reflect . Array , reflect . Map , reflect . Ptr , reflect . Func , reflect . Chan , reflect . Slice :", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "test", "names", "."], "add_tokens": "func ( t * readOnlyTest ) Inodes ( ) { AssertTrue ( false , \" \" ) } func ( t * readOnlyTest ) OpenNonExistentFile ( ) { AssertTrue ( false , \" \" ) } func ( t * readOnlyTest ) ReadNonExistentDir ( ) {", "del_tokens": "// TODO(jacobsa): Inodes // TODO(jacobsa): Error conditions func ( t * readOnlyTest ) DoesFoo ( ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "bootstrap", "flag", "to", "allow", "single", "server", "raft"], "add_tokens": "cmdFlags . BoolVar ( & cmdConfig . Server , \" \" , false , \" \" ) cmdFlags . BoolVar ( & cmdConfig . Bootstrap , \" \" , false , \" \" )", "del_tokens": "cmdFlags . BoolVar ( & cmdConfig . Server , \" \" , false , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "datastore", ".", "import", "command"], "add_tokens": "f . StringVar ( & flag . name , \" \" , os . Getenv ( \" \" ) , \" \" )", "del_tokens": "flag . name = os . Getenv ( \" \" ) f . StringVar ( & flag . name , \" \" , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "nil", "pointer", "issue", "when", "cacher", "disabled"], "add_tokens": "return data . Nil", "del_tokens": "return nil", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "typos", "in", "names"], "add_tokens": "func countMoves ( t * testing . T , originalPosition * Position , positions [ ] * Position , nodesPerDepth [ ] int , maxDepth int ) { depth := maxDepth - len ( nodesPerDepth ) + 1 expNodes := nodesPerDepth [ 0 ] gotNodes := len ( newPositions ) if expNodes != gotNodes { t . Errorf ( \" \" , depth , expNodes , gotNodes ) countMoves ( t , originalPosition , newPositions , nodesPerDepth [ 1 : ] , maxDepth )", "del_tokens": "func countMoves ( t * testing . T , originalPosition * Position , positions [ ] * Position , nodesPerDepth [ ] int , max_depth int ) { depth := max_depth - len ( nodesPerDepth ) + 1 exp_nodes := nodesPerDepth [ 0 ] got_nodes := len ( newPositions ) if exp_nodes != got_nodes { t . Errorf ( \" \" , depth , exp_nodes , got_nodes ) countMoves ( t , originalPosition , newPositions , nodesPerDepth [ 1 : ] , max_depth )", "commit_type": "fix"}
{"commit_tokens": ["Add", "integration", "tests", "for", "build", "/", "buildConfig", "client"], "add_tokens": "DesiredInput BuildInput `json:\"desiredInput,omitempty\" yaml:\"desiredInput,omitempty\"`", "del_tokens": "DesiredInput BuildInput", "commit_type": "add"}
{"commit_tokens": ["removing", "cycle", "issue", "with", "RadioButton"], "add_tokens": "return f . FormFor . RadioButtonTag ( field , opts ) return f . FormFor . TextAreaTag ( field , opts )", "del_tokens": "return f . FormFor . RadioButton ( field , opts ) return f . FormFor . TextArea ( field , opts )", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "multiple", "groupBy", "fields"], "add_tokens": "// TODO: Test multiple groupings", "del_tokens": "// test avg // test count //TODO: Test SubAggregate queries", "commit_type": "add"}
{"commit_tokens": ["Added", "RPL_LOCALUSERS", "and", "RPL_GLOBALUSERS", "."], "add_tokens": "RPL_TOPICWHOTIME = \" \" // From ircu, in use on Freenode RPL_LOCALUSERS = \" \" // From aircd, Hybrid, Hybrid, Bahamut, in use on Freenode RPL_GLOBALUSERS = \" \" // From aircd, Hybrid, Hybrid, Bahamut, in use on Freenode", "del_tokens": "RPL_TOPICWHOTIME = \" \" // From ircu, used on Freenode", "commit_type": "add"}
{"commit_tokens": ["remove", "dependencies", "to", "github", ".", "com", "/", "pkg", "/", "errors"], "add_tokens": "\" \" return fmt . Errorf ( \" \" , err ) return nil , fmt . Errorf ( \" \" , err ) return nil , fmt . Errorf ( \" \" , err ) return nil , fmt . Errorf ( \" \" , err )", "del_tokens": "\" \" return errors . New ( \" \" ) return nil , errors . Wrap ( err , \" \" ) return nil , errors . Wrap ( err , \" \" ) return nil , errors . Wrap ( err , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "example", "in", "README", "and", "attempt", "to", "use", "current", "username", "if", "username", "is", "empty", "."], "add_tokens": "\" \" // Connect with a password. If username is empty simplessh will attempt to get the current user. // Same as ConnectWithPassword but allows a custom timeout. If username is empty simplessh will attempt to get the current user. // to use $HOME/.ssh/id_rsa. If username is empty simplessh will attempt to get the current user. return ConnectWithKeyTimeout ( host , username , string ( privKey ) , timeout ) // Same as ConnectWithKeyFile but allows a custom timeout. If username is empty simplessh will attempt to get the current user. // Connect with a private key with a custom timeout. If username is empty simplessh will attempt to get the current user. // Connect with a private key. If username is empty simplessh will attempt to get the current user. func ConnectWithKey ( host , username , privKey string ) ( * Client , error ) { if username == \" \" { user , err := user . Current ( ) if err != nil { return nil , fmt . Errorf ( \" \" , err ) } username = user . Username } // Execute cmd on the remote host and return stderr and stdout", "del_tokens": "// Connect with a password. // Same as ConnectWithPassword but allows a custom timeout. // to use $HOME/.ssh/id_rsa. return ConnectWithKey ( host , username , string ( privKey ) , timeout ) // Same as ConnectWithKeyFile but allows a custom timeout. // Connect with a private key. // Same as ConnectWithKey but allows a custom timeout. func ConnectWithKey ( host , username , privKey string , timeout time . Duration ) ( * Client , error ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "IsTerminal", "function", "call", "on", "formatter", ".", "go", "line", "101"], "add_tokens": "if ! logrus . IsTerminal ( logrus . StandardLogger ( ) . Out ) || ( runtime . GOOS == \" \" && ! WindowsNativeANSI ( ) ) {", "del_tokens": "if ! logrus . IsTerminal ( ) || ( runtime . GOOS == \" \" && ! WindowsNativeANSI ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "example", "and", "README", "."], "add_tokens": "server , err := Start ( Config { \" \" : \" \" } ) server . WaitFor ( Ready )", "del_tokens": "server , err := Start ( Config { \" \" : \" \" , } , )", "commit_type": "update"}
{"commit_tokens": ["made", "capacity", "field", "public", "should", "have", "been"], "add_tokens": "Capacity int `json:\"capacity,omitempty\"`", "del_tokens": "capacity int `json:\"capacity,omitempty\"`", "commit_type": "make"}
{"commit_tokens": ["Update", "ber", "to", "accept", "longer", "encoded", "length", "values", "."], "add_tokens": "// Superfluous zeros in the length should be a accepted (different from DER). { [ ] byte { 0xa0 , 0x82 , 0x00 , 0xff } , true , tagAndLength { 2 , 0 , 0xff , true } } , // Long length form may be used for lengths that fit in short form (different from DER). { [ ] byte { 0xa0 , 0x81 , 0x7f } , true , tagAndLength { 2 , 0 , 0x7f , true } } ,", "del_tokens": "// Superfluous zeros in the length should be a accepted. { [ ] byte { 0xa0 , 0x82 , 0x00 , 0xff } , false , tagAndLength { } } , // Long length form may be used for lengths that fit in short form. { [ ] byte { 0xa0 , 0x81 , 0x7f } , false , tagAndLength { } } ,", "commit_type": "update"}
{"commit_tokens": ["Updated", "the", "import", "path", "for", "bcrypt"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["fixed", "broken", "selected", "state", "of", "select_tag"], "add_tokens": "s . Append ( x . String ( ) ) selected := opts [ \" \" ] delete ( opts , \" \" )", "del_tokens": "s . Append ( x ) selected := opts [ \" \" ] delete ( opts , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "eventloop", "package", "in", "containerd"], "add_tokens": "\" \" el : eventloop . NewChanLoop ( DefaultBufferSize ) , el eventloop . EventLoop return s . el . Start ( ) EventsCounter . Inc ( 1 ) s . el . Send ( & commonEvent { data : evt , sv : s } )", "del_tokens": "goruntime \" \" events : make ( chan * Event , DefaultBufferSize ) , go func ( ) { // allocate an entire thread to this goroutine for the main event loop // so that nothing else is scheduled over the top of it. goruntime . LockOSThread ( ) for e := range s . events { EventsCounter . Inc ( 1 ) h , ok := s . handlers [ e . Type ] if ! ok { e . Err <- ErrUnknownEvent continue } if err := h . Handle ( e ) ; err != nil { if err != errDeferedResponse { e . Err <- err close ( e . Err ) } continue } close ( e . Err ) } } ( ) return nil s . events <- evt", "commit_type": "use"}
{"commit_tokens": ["Remove", "all", "panics", "from", "repository"], "add_tokens": "It ( \" \" , func ( ) { It ( \" \" , func ( ) { It ( \" \" , func ( ) { It ( \" \" , func ( ) {", "del_tokens": "It ( \" \" , func ( ) { It ( \" \" , func ( ) { It ( \" \" , func ( ) { It ( \" \" , func ( ) {", "commit_type": "remove"}
{"commit_tokens": ["fix", "tests", "to", "use", "exported", "method", "Validate", "()"], "add_tokens": "err = cfg . Validate ( )", "del_tokens": "err = cfg . validate ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "initial", "support", "for", "snapshotting", "."], "add_tokens": "dbPath string dbPath := path . Join ( dataDir , dbfile ) dbPath : dbPath , db : db . New ( dbPath ) , stateMachine := NewDbStateMachine ( s . dbPath ) s . raftServer , err = raft . NewServer ( s . name , s . path , transporter , stateMachine , s . db , \" \" ) func ( s * Server ) execute ( tx bool , stmts [ ] string ) ( [ ] FailedSqlStmt , error ) { s . mutex . Lock ( ) defer s . mutex . Unlock ( ) failures , err := s . execute ( transaction , stmts ) diagnostics [ \" \" ] = s . dbPath", "del_tokens": "dbFile string dbFile : dbfile , db : db . New ( path . Join ( dataDir , dbfile ) ) , s . raftServer , err = raft . NewServer ( s . name , s . path , transporter , nil , s . db , \" \" ) func ( s * Server ) lockedExecute ( tx bool , stmts [ ] string ) ( [ ] FailedSqlStmt , error ) { s . mutex . Lock ( ) defer s . mutex . Unlock ( ) failures , err := s . lockedExecute ( transaction , stmts ) diagnostics [ \" \" ] = s . dbFile", "commit_type": "add"}
{"commit_tokens": ["Add", "NewDBIgnoringUnmappedCols", "to", "avoid", "DB", "migration", "errors"], "add_tokens": "func makeTestDBIgnoringUnmappedCols ( t testing . TB , ddls ... string ) * DB { return makeTestDBWithNewDB ( t , NewDBIgnoringUnmappedCols , ddls ) } return makeTestDBWithNewDB ( t , NewDB , ddls ) } func makeTestDBWithNewDB ( t testing . TB , newDBFunc func ( * sql . DB ) * DB , ddls [ ] string ) * DB { return newDBFunc ( db )", "del_tokens": "return NewDB ( db )", "commit_type": "add"}
{"commit_tokens": ["Remove", "route", "middleware", "register", "for", "all", "methods"], "add_tokens": "methods map [ string ] [ ] Handler matcher * regexp . Regexp params [ ] string for _ , method := range methodNames { r . addMethodHandlers ( method , handlers ... ) } r . All ( HandlerFunc ( fn ) ) for _ , handler := range r . methods [ req . Method ] {", "del_tokens": "middleware [ ] Handler methods map [ string ] [ ] Handler matcher * regexp . Regexp params [ ] string r . middleware = append ( r . middleware , handlers ... ) r . middleware = append ( r . middleware , HandlerFunc ( fn ) ) for _ , handler := range append ( r . middleware , r . methods [ req . Method ] ... ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "godoc", ".", "Add", "coveralls", "badge", "."], "add_tokens": "// KeyCase represenets the word case of the output keys // NotSet uses the original case for keys NotSet KeyCase = iota // CamelCase uses camelCase keys CamelCase = iota // PascalCase Uses PascalCase keys PascalCase = iota // SnakeCase uses snake_case keys SnakeCase = iota var defaultCase = NotSet // SetDefaultCase set the default key case (snake_case, camelCase or PascalCase) for // Predicate is an alias for func(interface{}) bool used to test for inclusion // KeyConverter is an alias for func(string) string used to transform keys // ValueConverter is an alias for func(interface{}) interface{} used to transform values // Serializer is the base interface containing all serialization methods // Base is a basic implementation of Serializer // New creates a new serializer // Transform transforms the entity into a map[string]interface{} ready to be serialized // TransformArray transforms the entities into a []map[string]interface{} array // ready to be serialized. Entities must be a slice or an array // MustTransformArray transforms the entities into a []map[string]interface{} // array ready to be serialized. Panics if entities is not a slice or an array return result // ConvertKeys converts all the keys using the given converter // UsePascalCase uses PascalCase keys for the serializer // UseCamelCase uses camelCase keys for the serializer // UseSnakeCase uses snake_case keys for the serializer // PickAll adds all the exported fields to the result // Pick adds the given fields to the result // PickIf adds the given fields to the result if the Predicate returns true // PickFunc adds the given fields to the result after applying the converter // PickFuncIf adds the given fields to the result after applying the converter if the predicate returns true // Omit omits the given fields from the result // OmitIf omits the given fields from the result if the Predicate returns true // Add adds a custom field to the result // AddIf adds a custom field to the result if the Predicate returns true // AddFunc adds a computed custom field to the result // AddFuncIf adds a computed custom field to the result if the Predicate returns true", "del_tokens": "NotSet KeyCase = iota CamelCase = iota PascalCase = iota SnakeCase = iota var defaultCase KeyCase = NotSet // Set the default key case (snake_case, camelCase or PascalCase) for // Transform the entity into a map[string]interface{} ready to be serialized // Transform the entities into a []map[string]interface{} array ready to be serialized // entities must be a slice or an array // Transform the entities into a []map[string]interface{} array ready to be serialized // Panics if entities is not a slice or an array // Convert all the keys using the given converter // Use snake_case keys // Use camelCase keys // Use PascalCase keys // Add all the exported fields to the result // Add the given fields to the result // Add the given fields to the result if the Predicate returns true // Add the given fields to the result after applying the converter // Add the given fields to the result after applying the converter if the predicate returns true // Omit the given fields from the result // Omit the given fields from the result if the Predicate returns true // Add a custom field to the result // Add a custom field to the result if the Predicate returns true // Add a computed custom field to the result // Add a computed custom field to the result if the Predicate returns true // A basic implementation of Serializer // Creates a new serializer } else { return result", "commit_type": "fix"}
{"commit_tokens": ["change", "import", "path", "from", "Sirupsen", "/", "logrus", "to", "sirupsen", "/", "logrus"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "change"}
{"commit_tokens": ["Use", "logger", "interface", "in", "recovery", "handler"], "add_tokens": "// RecoveryHandlerLogger is an interface used by the recovering handler to print logs. type RecoveryHandlerLogger interface { Println ( ... interface { } ) } logger RecoveryHandlerLogger func RecoveryLogger ( logger RecoveryHandlerLogger ) RecoveryOption { func ( h recoveryHandler ) log ( v ... interface { } ) { h . logger . Println ( v ... ) log . Println ( v ... )", "del_tokens": "logger * log . Logger func RecoveryLogger ( logger * log . Logger ) RecoveryOption { func ( h recoveryHandler ) log ( message interface { } ) { h . logger . Println ( message ) log . Println ( message )", "commit_type": "use"}
{"commit_tokens": ["Added", "test", "suite", "+", "stub", "tests", "for", "plugin", "framework"], "add_tokens": "} else if action == \" \" || action == \" \" || action == \" \" { } else { fmt . Fprintf ( os . Stderr , \" \" ) os . Exit ( UNSUPPORTED_ACTION )", "del_tokens": "} else if action == \" \" || action == \" \" {", "commit_type": "add"}
{"commit_tokens": ["add", "connWG", "only", "for", "debug"], "add_tokens": "connWG sync . WaitGroup l . connWG . Add ( 1 ) go handleClient ( l , c , handleMsg , handleDisconn ) func handleClient ( l * Listener , conn * Conn , handleMsg func ( conn * Conn , session * Session , msg [ ] byte ) , handleDisconn func ( conn * Conn , session * Session ) ) error { if l . debug { l . connWG . Done ( )", "del_tokens": "connwg * sync . WaitGroup go handleClient ( c , l . debug , handleMsg , handleDisconn ) func handleClient ( conn * Conn , debug bool , handleMsg func ( conn * Conn , session * Session , msg [ ] byte ) , handleDisconn func ( conn * Conn , session * Session ) ) error { if debug {", "commit_type": "add"}
{"commit_tokens": ["Improve", "goroutine", "usage", "in", "docs"], "add_tokens": "// up the stack. The rawData is used to send extra information along with any // panics that are handled this way. // Usage: // go func() { // defer bugsnag.AutoNotify() // // (possibly crashy code) // }() // See also: bugsnag.Recover()", "del_tokens": "// up the stack. See bugsnag.Recover(). The rawData is used to send extra // information along with any panics that are handled this way. // Usage: defer bugsnag.AutoNotify()", "commit_type": "improve"}
{"commit_tokens": ["Use", "new", "db", "version", "with", "triggers", "."], "add_tokens": "var e error if e = user . AddUserPost ( user , \" \" ) ; e != nil { if e = user . AddUserPost ( 1 , \" \" ) ; e != nil { if e = user . AddUserPost ( int8 ( 5 ) , \" \" ) ; e == nil { if e = user . AddUserPost ( 7 , \" \" ) ; e == nil { fmt . Printf ( \" \\n \" , e . Error ( ) ) // the e.Error() string should be handled in the same way we do in templates", "del_tokens": "if e := user . AddUserPost ( user , \" \" ) ; e != nil { if e := user . AddUserPost ( 1 , \" \" ) ; e != nil { if e := user . AddUserPost ( int8 ( 5 ) , \" \" ) ; e == nil { if e := user . AddUserPost ( 7 , \" \" ) ; e == nil {", "commit_type": "use"}
{"commit_tokens": ["Use", "a", "variable", "to", "decide", "whether", "or", "not", "maps", "types", "are", "printed", "."], "add_tokens": "// PrintMapTypes when set to true will have map types will always appended to maps. PrintMapTypes = true if PrintMapTypes { p . printf ( \" \" , p . typeString ( ) ) } else { p . println ( \" \" ) }", "del_tokens": "p . printf ( \" \" , p . typeString ( ) )", "commit_type": "use"}
{"commit_tokens": ["Updated", "to", "use", "github", ".", "com", "/", "golang", "/", "freetype", "."], "add_tokens": "\" \" \" \" \" \" func LoadTruetype ( r io . Reader , scale fixed . Int26_6 , low , high rune ) ( * Font , error ) { gc := fixed . Int26_6 ( len ( fc . Glyphs ) ) glyphsPerRow := fixed . Int26_6 ( 16 ) gw := ( gb . Max . X - gb . Min . X ) gh := ( gb . Max . Y - gb . Min . Y ) + 5 // why? var gx , gy fixed . Int26_6 pt := freetype . Pt ( int ( gx ) , int ( gy ) + int ( scale ) )", "del_tokens": "\" \" \" \" func LoadTruetype ( r io . Reader , scale int32 , low , high rune ) ( * Font , error ) { gc := int32 ( len ( fc . Glyphs ) ) glyphsPerRow := int32 ( 16 ) gw := ( gb . XMax - gb . XMin ) // why? gh := ( gb . YMax - gb . YMin ) + 5 var gx , gy int32 pt := freetype . Pt ( int ( gx ) , int ( gy ) + int ( c . PointToFix32 ( float64 ( scale ) ) >> 8 ) )", "commit_type": "update"}
{"commit_tokens": ["Fix", "MIC", "calculation", "typo", "."], "add_tokens": "if ! p . uplink {", "del_tokens": "if p . uplink {", "commit_type": "fix"}
{"commit_tokens": ["Add", "Common", "Name", "to", "certificate", "."], "add_tokens": "// Copyright (c) 2013-2015 The btcsuite developers \" \" extraHosts := [ ] string { \" \" , \" \" , \" \" } // Ensure that the Common Name is also the first SAN DNS name. cn := x509Cert . Subject . CommonName san0 := x509Cert . DNSNames [ 0 ] if cn != san0 { t . Errorf ( \" \" , cn , san0 ) } // Ensure there are no duplicate hosts or IPs. hostCounts := make ( map [ string ] int ) for _ , host := range x509Cert . DNSNames { hostCounts [ host ] ++ } ipCounts := make ( map [ string ] int ) for _ , ip := range x509Cert . IPAddresses { ipCounts [ string ( ip ) ] ++ } for host , count := range hostCounts { if count != 1 { t . Errorf ( \" \" , host , count ) } } for ipStr , count := range ipCounts { if count != 1 { t . Errorf ( \" \" , net . IP ( ipStr ) , count ) } }", "del_tokens": "// Copyright (c) 2013-2014 The btcsuite developers extraHosts := [ ] string { \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["added", "bishop", "and", "queen", "moves"], "add_tokens": "// bishop moves { m : & Move { s1 : E4 , s2 : H7 } , pos : unsafeFEN ( \" \" ) } , { m : & Move { s1 : E4 , s2 : D5 } , pos : unsafeFEN ( \" \" ) } , { m : & Move { s1 : E4 , s2 : B1 } , pos : unsafeFEN ( \" \" ) } , // bishop moves { m : & Move { s1 : E4 , s2 : C6 } , pos : unsafeFEN ( \" \" ) } , { m : & Move { s1 : E4 , s2 : E5 } , pos : unsafeFEN ( \" \" ) } , { m : & Move { s1 : E4 , s2 : E4 } , pos : unsafeFEN ( \" \" ) } , { m : & Move { s1 : E4 , s2 : F3 } , pos : unsafeFEN ( \" \" ) } ,", "del_tokens": "func TestBitboard ( t * testing . T ) { log . Println ( bbForDiagonal ( B1 ) . Draw ( ) ) log . Println ( bbForAntiDiagonal ( B1 ) . Draw ( ) ) // log.Println(bbDiagonal[B5].Draw()) // log.Println(bbAntiDiagonal[B5].Draw()) }", "commit_type": "add"}
{"commit_tokens": ["use", "interface", "instead", "of", "fun"], "add_tokens": "type BackgroundCallback interface { ProcessResult ( client CuratorFramework , event CuratorEvent ) error }", "del_tokens": "type BackgroundCallback func ( client CuratorFramework , event CuratorEvent ) error", "commit_type": "use"}
{"commit_tokens": ["add", "read", "writer", "lock", "for", "range"], "add_tokens": "func ( m * Map ) RLockRange ( f func ( interface { } , interface { } ) ) { func ( m * Map ) LockRange ( f func ( interface { } , interface { } , map [ interface { } ] interface { } ) ) { m . Lock ( ) defer m . Unlock ( ) m . init ( ) for k , v := range m . m { f ( k , v , m . m ) } }", "del_tokens": "func ( m * Map ) Range ( f func ( interface { } , interface { } ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "tiny", "grammatical", "error", "in", "docs"], "add_tokens": "// If using a slice of strings, promptui will use those strings directly into its base templates or the", "del_tokens": "// If using a slice a strings, promptui will use those strings directly into its base templates or the", "commit_type": "fix"}
{"commit_tokens": ["Use", "EndpointKey", "instead", "of", "InstanceGuid"], "add_tokens": "newEntry . Endpoints [ endpoint . key ( ) ] = endpoint delete ( newEntry . Endpoints , endpoint . key ( ) )", "del_tokens": "newEntry . Endpoints [ endpoint . InstanceGuid ] = endpoint delete ( newEntry . Endpoints , endpoint . InstanceGuid )", "commit_type": "use"}
{"commit_tokens": ["adding", "Timestamp", "and", "Retries", "to", "message", "object", "and", "basic", "tests", "for", "V2"], "add_tokens": "var ret interface { } buf := bytes . NewBuffer ( response [ : 4 ] ) ret , err = DecodeMessage ( response [ 4 : ] ) if err != nil { return - 1 , nil , err } ret = response [ 4 : ] return frameType , ret , nil", "del_tokens": "// TODO: i think it's easier if these are []byte var data interface { } buf := bytes . NewBuffer ( response [ : 3 ] ) data = NewMessage ( response [ 3 : ] ) data = response [ 3 : ] return frameType , data , nil", "commit_type": "add"}
{"commit_tokens": ["removing", "un", "-", "needed", "test", "complexity"], "add_tokens": "assert . True ( resp . Running ( ) ) if count <= 1 { fmt . Fprintf ( w , `{\"status\":\"running\"}` ) } else { fmt . Fprintf ( w , `{\"status\":\"succeeded\"}` ) } count ++ return", "del_tokens": "assert . True ( resp . Complete ( ) ) if r . RequestURI == \" \" { w . Header ( ) . Add ( \" \" , \" \" ) if count <= 1 { fmt . Fprintf ( w , `{\"status\":\"running\"}` ) } else { fmt . Fprintf ( w , `{\"status\":\"succeeded\"}` ) } count ++ return } fmt . Fprintf ( w , `{\"status\":\"succeeded\"}` )", "commit_type": "remove"}
{"commit_tokens": ["add", "default", "patterns", "into", "the", "code", "(", "will", "use", "a", "go", "generate", "in", "next", "commits", ")"], "add_tokens": "o . patterns = patterns // for k, v := range g.patterns { // fmt.Printf(\"`%s` : `%s`,\\n\", k, v) // }", "del_tokens": "o . patterns = map [ string ] string { }", "commit_type": "add"}
{"commit_tokens": ["Added", "timeout", "passthrough", "to", "It", "container"], "add_tokens": "func Scenario ( description string , body func ( ) , timeout ... float64 ) bool { return ginkgo . It ( description , body , timeout ... )", "del_tokens": "func Scenario ( description string , body func ( ) ) bool { return ginkgo . It ( description , body )", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "details", "to", "help", "text"], "add_tokens": "const helpMessage = ` This is a protoc plugin that is used to generate documentation from your protobuf files . Invocation is controlled by using the doc_opt and doc_out options for protoc . EXAMPLE : Generate HTML docs protoc -- doc_out = . -- doc_opt = html , index . html protos / * . proto EXAMPLE : Use a custom template protoc -- doc_out = . -- doc_opt = custom . tmpl , docs . txt protos / * . proto See https : //github.com/pseudomuto/protoc-gen-doc for more details. ` fmt . Fprintf ( f . writer , \" \\n \" , f . appName ) fmt . Fprintf ( f . writer , \" \\n \" , helpMessage )", "del_tokens": "fmt . Fprintf ( f . writer , \" \\n \\n \" , f . appName )", "commit_type": "add"}
{"commit_tokens": ["added", "comments", "set", "custom", "client"], "add_tokens": "SetHTTPClient ( * http . Client ) // RPCRequest is the structure that is used to build up an json-rpc request. // See: http://www.jsonrpc.org/specification#request_object // RPCResponse is the structure that is used to provide the result of an json-rpc request. // See: http://www.jsonrpc.org/specification#response_object // RPCError is the structure that is used to provide the result in case of an rpc call error. // See: http://www.jsonrpc.org/specification#error_object // NewRPCClient returns a new RPCClient interface with default configuration func ( client * rpcClient ) SetBasicAuth ( username string , password string ) { auth := username + \" \" + password client . basicAuth = \" \" + base64 . StdEncoding . EncodeToString ( [ ] byte ( auth ) ) } func ( client * rpcClient ) SetHTTPClient ( httpClient * http . Client ) { client . httpClient = httpClient }", "del_tokens": "func ( client * rpcClient ) SetBasicAuth ( username string , password string ) { auth := username + \" \" + password client . basicAuth = \" \" + base64 . StdEncoding . EncodeToString ( [ ] byte ( auth ) ) }", "commit_type": "add"}
{"commit_tokens": ["added", "some", "docs", "added", "a", "command", "line", "interface", "for", "sending", "commands", "to", "a", "system"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "example", "to", "match", "the", "recent", "changes", "(", "from", "@prep", "repo", ")"], "add_tokens": "fmt . Println ( \" \" ) fmt . Println ( \" \\n \" ) fmt . Println ( \" \\n \" )", "del_tokens": "fmt . Println ( \" \\n \" ) fmt . Println ( \" \\n \\n \\n \" ) fmt . Println ( \" \\n \\n \\n \" )", "commit_type": "fix"}
{"commit_tokens": ["improve", "cleaning", "up", "in", "dht", "tests", "."], "add_tokens": "defer dhtA . Halt ( ) defer dhtB . Halt ( ) defer dhtA . Halt ( ) defer dhtB . Halt ( ) defer func ( ) { for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } } ( ) defer func ( ) { for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } } ( ) go func ( ) { for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } } ( )", "del_tokens": "dhtA . Halt ( ) dhtB . Halt ( ) for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) }", "commit_type": "improve"}
{"commit_tokens": ["Use", "list", "flag", "to", "find", "datacenter"], "add_tokens": "\" \" * ClientFlag case \" \" : // Not supported; many edge case, little value return nil , errors . New ( \" \" )", "del_tokens": "* DatastoreFlag case \" \" : // Relative to datacenter, back to root // Remove every occurance of .. for len ( parts ) > 0 && parts [ 0 ] == \" \" { parts = parts [ 1 : ] }", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "RS384", "and", "RS512", "signing", "methods"], "add_tokens": "\" \" , { \" \" , \" \" , \" \" , map [ string ] interface { } { \" \" : \" \" } , true , } , { \" \" , \" \" , \" \" , map [ string ] interface { } { \" \" : \" \" } , true , } , method := GetSigningMethod ( \" \" ) . ( * SigningMethodRSA )", "del_tokens": "\" \" , method := GetSigningMethod ( \" \" ) . ( * SigningMethodRS256 )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "Sub", "method", "to", "atomics"], "add_tokens": "// Sub atomically subtracts from the wrapped int32 and returns the new value. func ( i * Int32 ) Sub ( n int32 ) int32 { return atomic . AddInt32 ( & i . int32 , - n ) } return i . Sub ( 1 ) // Sub atomically subtracts from the wrapped int64 and returns the new value. func ( i * Int64 ) Sub ( n int64 ) int64 { return atomic . AddInt64 ( & i . int64 , - n ) } return i . Sub ( 1 ) // Sub atomically subtracts from the wrapped uint32 and returns the new value. func ( i * Uint32 ) Sub ( n uint32 ) uint32 { return atomic . AddUint32 ( & i . uint32 , ^ ( n - 1 ) ) } return i . Sub ( 1 ) // Sub atomically subtracts from the wrapped uint64 and returns the new value. func ( i * Uint64 ) Sub ( n uint64 ) uint64 { return atomic . AddUint64 ( & i . uint64 , ^ ( n - 1 ) ) } return i . Sub ( 1 )", "del_tokens": "return i . Add ( - 1 ) return i . Add ( - 1 ) return i . Add ( ^ uint32 ( 0 ) ) return i . Add ( ^ uint64 ( 0 ) )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "fuse", ".", "Unmount", "."], "add_tokens": "func ( mfs * MountedFileSystem ) Unmount ( ) error { return fuse . Unmount ( mfs . dir ) }", "del_tokens": "func ( mfs * MountedFileSystem ) Unmount ( ) error", "commit_type": "implement"}
{"commit_tokens": ["add", "columntype", "method", "for", "table"], "add_tokens": "columns := make ( [ ] * Column , len ( table . PrimaryKeys ) ) for i , name := range table . PrimaryKeys { columns [ i ] = table . GetColumn ( name ) func ( table * Table ) ColumnType ( name string ) reflect . Type { t , _ := table . Type . FieldByName ( name ) return t . Type }", "del_tokens": "columns := make ( [ ] * Column , 0 ) for _ , name := range table . PrimaryKeys { columns = append ( columns , table . GetColumn ( name ) )", "commit_type": "add"}
{"commit_tokens": ["Allow", "use", "of", "pkg", "-", "config", "on", "Windows", "via", "tag"], "add_tokens": "//#cgo windows,pkgconfig pkg-config: opencv //#cgo windows,!pkgconfig LDFLAGS: -lopencv_core242.dll -lopencv_imgproc242.dll -lopencv_photo242.dll -lopencv_highgui242.dll -lstdc++", "del_tokens": "//#cgo windows LDFLAGS: -lopencv_core242.dll -lopencv_imgproc242.dll -lopencv_photo242.dll -lopencv_highgui242.dll -lstdc++", "commit_type": "allow"}
{"commit_tokens": ["updated", "test", "tools", "to", "compile"], "add_tokens": "d := aiff . NewDecoder ( f ) frames , err := d . Frames ( ) sampleRate = d . SampleRate sampleSize = int ( d . BitDepth )", "del_tokens": "info , frames , err := aiff . NewDecoder ( f , nil ) . Frames ( ) sampleRate = info . SampleRate sampleSize = info . BitDepth monoFrames = make ( misc . AudioFrames , len ( frames ) )", "commit_type": "update"}
{"commit_tokens": ["Added", "hide", "/", "show", "for", "Windows"], "add_tokens": "currentID = int32 ( - 1 )", "del_tokens": "currentID int32", "commit_type": "add"}
{"commit_tokens": ["add", "ios", "push", "test", "."], "add_tokens": "\" \" : [ ] string { \" \" } , \" \" : 1 , \" \" : \" \" , } ) . Run ( GetMainEngine ( ) , func ( r gofight . HttpResponse , rq gofight . HttpRequest ) { assert . Equal ( t , http . StatusOK , r . Code ) } ) } func TestIosPushHandler ( t * testing . T ) { initTest ( ) PushConf . Ios . Enabled = true PushConf . Ios . PemKeyPath = \" \" InitAPNSClient ( ) r := gofight . New ( ) r . POST ( \" \" ) . SetJSON ( gofight . D { \" \" : [ ] string { \" \" } ,", "del_tokens": "\" \" : [ ] string { \" \" } ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "Local", ".", "Delete", "to", "use", "RemoveAll", "."], "add_tokens": "// Delete implements FS. All files underneath path will be removed. return os . RemoveAll ( l . fullPath ( path ) )", "del_tokens": "// Delete implements FS. return os . Remove ( l . fullPath ( path ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "second", "return", "value", "to", "indicate", "kill", "signal", "on", "the", "prompt", "."], "add_tokens": "// KillSignalError is returned returned by Line() when a user quits from prompt. // This occurs when the user enters ctrl+C or ctrl+D. var KillSignalError = errors . New ( \" \" ) func Line ( prompt string ) ( string , error ) { // char *linenoise(const char *prompt); if resultCString == nil { return \" \" , KillSignalError } return result , nil", "del_tokens": "func Line ( prompt string ) string { // char *linenoise(const char *prompt); return result", "commit_type": "add"}
{"commit_tokens": ["Move", "dummyNCC", "to", "ncclient", "package"], "add_tokens": "ncclient \" \" lbIF := e . lbInterface . ( * ncclient . DummyLBInterface ) for v := range lbIF . Vips {", "del_tokens": "lbIF := e . lbInterface . ( * dummyLBInterface ) for v := range lbIF . vips {", "commit_type": "move"}
{"commit_tokens": ["removed", "a", "semicolon", "and", "the", "placeholder", "for", "the", "error", "which", "we", "used", "to", "locate", "it", ".", "Seems", "like", "SecItemCopyMatching", "is", "giving", "an", "error", "for", "some", "reason", "-", "no", "error", "on", "local", "machine"], "add_tokens": "helper . Add ( creds ) defer helper . Delete ( creds1 . ServerURL )", "del_tokens": "helper . Add ( creds ) ; helper . Delete ( creds1 . ServerURL )", "commit_type": "remove"}
{"commit_tokens": ["Add", "geocoder", "for", "HERE", "Geocoding", "and", "Search", "API"], "add_tokens": "// Package here is a geo-golang based HERE geocode/reverse geocode client for the legacy geocoder API", "del_tokens": "// Package here is a geo-golang based HERE geocode/reverse geocode client", "commit_type": "add"}
{"commit_tokens": ["Add", "convert", "string", "to", "integer", "value", "using", "base", "10", "correctly"], "add_tokens": "ID : strconv . FormatUint ( t . ID , 10 ) , ID : strconv . FormatUint ( res . ID , 10 ) , for i , tracker := range rows { t := app . Tracker { ID : strconv . FormatUint ( tracker . ID , 10 ) , URL : tracker . URL , Type : tracker . Type } result [ i ] = & t } ID : strconv . FormatUint ( id , 10 ) ,", "del_tokens": "ID : string ( t . ID ) , ID : string ( res . ID ) , ID : string ( id ) ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "type", "on", "type", "name"], "add_tokens": "device := vmx . Device { }", "del_tokens": "device := vmx . CommonDevice { }", "commit_type": "fix"}
{"commit_tokens": ["improve", "error", "message", "and", "keep", "temp", "file", "on", "failure"], "add_tokens": "\" \" \" \" keep = true return nil , errors . New ( fmt . Sprintf ( \" \\n \" , f . Name ( ) , err ) )", "del_tokens": "return nil , err", "commit_type": "improve"}
{"commit_tokens": ["Fix", "a", "minor", "but", "in", "utils", "parsing", "UDP", "/", "TCP", "ports"], "add_tokens": "case \" \" : return 6", "del_tokens": "return 6 case \" \" :", "commit_type": "fix"}
{"commit_tokens": ["changed", "checkerror", "to", "not", "be", "exported", "as", "it", "is", "always", "handled", "internally", "and", "translated", "to", "a", "regular", "error"], "add_tokens": "func checkError ( response [ ] byte ) error { if err = checkError ( body ) ; err != nil { if err = checkError ( body ) ; err != nil {", "del_tokens": "func CheckError ( response [ ] byte ) error { if err = CheckError ( body ) ; err != nil { if err = CheckError ( body ) ; err != nil {", "commit_type": "change"}
{"commit_tokens": ["fix", "bug", "with", "shell", "env", "reader"], "add_tokens": "args := strings . Split ( ln [ i + len ( sh . commentSigil ) : ] , \" \" )", "del_tokens": "args := strings . Split ( ln [ i + 1 : ] , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Made", "absolute", "filepaths", "use", "/", "instead", "of", "\\", "to", "prevent", "local", "loading", "errors", "on", "Windows"], "add_tokens": "if i , err = filepath . ToSlash ( filepath . Abs ( i ) ) ; err != nil {", "del_tokens": "if i , err = filepath . Abs ( i ) ; err != nil {", "commit_type": "make"}
{"commit_tokens": ["Add", "model", "package", "and", "moved", "model", "files", "to", "it"], "add_tokens": "package model Type ServiceType `json:\"type\"`", "del_tokens": "package hap Type UUID `json:\"type\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "vm", ".", "Exec", "command", "error"], "add_tokens": "execcmd , err := json . Marshal ( strings . Split ( command , \" \" ) )", "del_tokens": "execcmd , err := json . Marshal ( command )", "commit_type": "fix"}
{"commit_tokens": ["Move", "handling", "of", "org", ".", "freedesktop", ".", "DBus", ".", "Peer", "to", "handleCall"], "add_tokens": "go conn . handleCall ( msg )", "del_tokens": "if msg . Headers [ FieldInterface ] . value . ( string ) == \" \" { serial := msg . Serial sender := msg . Headers [ FieldSender ] . value . ( string ) switch msg . Headers [ FieldMember ] . value . ( string ) { case \" \" : rm := ReplyMessage ( nil ) conn . out <- rm . toMessage ( conn , sender , serial ) case \" \" : rm := ReplyMessage ( [ ] interface { } { conn . uuid } ) conn . out <- rm . toMessage ( conn , sender , serial ) } } else { go conn . handleCall ( msg ) }", "commit_type": "move"}
{"commit_tokens": ["Fix", "handling", "header", "values", "containing", "non", "ASCII", "characters"], "add_tokens": "\" \" \" \" if headerKey == \" \" { // header X-QS-Fetch-Source is a URL to fetch. // We should first parse this URL. requestURL , err := url . Parse ( headerValue ) if err != nil { return fmt . Errorf ( \" \" , headerValue ) } headerValue = requestURL . String ( ) } else { for _ , r := range headerValue { if r > unicode . MaxASCII { headerValue = utils . URLQueryEscape ( headerValue ) break }", "del_tokens": "for _ , r := range headerValue { if r > unicode . MaxASCII { headerValue = utils . URLQueryEscape ( headerValue ) break", "commit_type": "fix"}
{"commit_tokens": ["Improve", "test", "that", "verifies", "correct", "behavior", "of", "a", "destroyed", "node", "during", "bootstrap", "by", "making", "using", "of", "channels", "not", "sleeps"], "add_tokens": "// Destroy node first to ensure there are no races // in how the goroutine below is scheduled. s . node . Destroy ( ) errChan := make ( chan error ) errChan <- err // Block until the error is received from the bootstrap // goroutine above. chanErr := <- errChan s . EqualError ( chanErr , \" \" )", "del_tokens": "var lerr lError lerr . Set ( err ) time . Sleep ( 2 * time . Millisecond ) s . node . Destroy ( ) time . Sleep ( 2 * time . Millisecond ) s . EqualError ( lerr . Err ( ) , \" \" )", "commit_type": "improve"}
{"commit_tokens": ["updated", "for", "recommendations", "removed", "table", "DSL", "and", "using", "templates", "more", "directly"], "add_tokens": "// nil pointer to struct: create a zero instance", "del_tokens": "// nil point to struct: create a zero instnace", "commit_type": "update"}
{"commit_tokens": ["added", "indefinite", "retries", "on", "error", "instead", "of", "aborting", "process"], "add_tokens": "const ( PROJECT = \" \" BUCKET = \" \" OBJECT = \" \" ) m , err := New ( nil , PROJECT , BUCKET , OBJECT ) func TestLockTimeout ( t * testing . T ) { m , err := New ( nil , PROJECT , BUCKET , OBJECT ) if err != nil { t . Errorf ( \" \" ) return } TimedLock ( m , 3 * time . Second ) } func TestUnlockTimeout ( t * testing . T ) { m , err := New ( nil , PROJECT , BUCKET , OBJECT ) if err != nil { t . Errorf ( \" \" ) return } TimedUnlock ( m , 3 * time . Second ) }", "del_tokens": "m , err := newCloudMutex ( \" \" , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "build", "errors", "after", "recent", "fuse", "context", "and", "error", "changes", "."], "add_tokens": "func ( fs * fileSystem ) Root ( ) ( fs . Node , error ) {", "del_tokens": "\" \" func ( fs * fileSystem ) Root ( ) ( fs . Node , fuse . Error ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "logging", "for", "heartbeating", "logic"], "add_tokens": "\" \" hbVol . Heartbeat ( lagertest . NewTestLogger ( \" \" ) , 30 * time . Second , fakeClock ) hbVol . Heartbeat ( lagertest . NewTestLogger ( \" \" ) , 30 * time . Second , fakeClock ) hbVol . Heartbeat ( lagertest . NewTestLogger ( \" \" ) , 30 * time . Second , fakeClock )", "del_tokens": "hbVol . Heartbeat ( 30 * time . Second , fakeClock ) hbVol . Heartbeat ( 30 * time . Second , fakeClock ) hbVol . Heartbeat ( 30 * time . Second , fakeClock )", "commit_type": "add"}
{"commit_tokens": ["Allow", "cascade", "with", "no", "throughprop"], "add_tokens": "if len ( conf . ThroughProp ) > 0 { update [ \" \" ] [ conf . ThroughProp ] = nil } else { for _ , p := range conf . Properties { update [ \" \" ] [ p ] = nil } } // Set the id field automatically if there's a through prop if len ( conf . ThroughProp ) > 0 { data [ \" \" ] = id } if len ( conf . ThroughProp ) > 0 { update1 [ \" \" ] [ conf . ThroughProp ] = nil } else { for _ , p := range conf . Properties { update1 [ \" \" ] [ p ] = nil } } if len ( conf . ThroughProp ) > 0 { update [ \" \" ] [ conf . ThroughProp ] = data } else { for k , v := range data { update [ \" \" ] [ k ] = v } }", "del_tokens": "// \"log\" update [ \" \" ] [ conf . ThroughProp ] = nil // Set the id field automatically data [ \" \" ] = id update1 [ \" \" ] [ conf . ThroughProp ] = nil update [ \" \" ] [ conf . ThroughProp ] = data", "commit_type": "allow"}
{"commit_tokens": ["Add", "more", "debug", "statements", "and", "warn", "if", "confdir", "does", "not", "exist"], "add_tokens": "log . Debug ( \" \" + path ) log . Debug ( \" \" ) log . Debug ( \" \" + config . Prefix ( ) ) log . Debug ( \" \" + t . Src ) log . Debug ( \" \" + t . Src ) log . Debug ( \" \" + t . Dest ) log . Info ( \" \" + t . Dest ) log . Debug ( \" \" + t . Dest ) log . Info ( \" \" + t . Dest + \" \" ) log . Debug ( \" \" + config . ConfDir ( ) ) if ! isFileExist ( config . ConfDir ( ) ) { log . Warning ( fmt . Sprintf ( \" \" , config . ConfDir ( ) ) ) return runErrors } log . Debug ( \" \" + p ) log . Debug ( \" \" + p + \" \" )", "del_tokens": "log . Info ( \" \" + t . Dest ) log . Info ( t . Dest + \" \" )", "commit_type": "add"}
{"commit_tokens": ["Improve", "docstring", "for", "PtrOf", "generator"], "add_tokens": "// PtrOf generates either a pointer to a generated element or a nil pointer", "del_tokens": "// PtrOf generates a pointer to a generated element", "commit_type": "improve"}
{"commit_tokens": ["make", "metrics", "test", "a", "little", "less", "picky"], "add_tokens": "mu := ( rand . NormFloat64 ( ) * sig ) + mu", "del_tokens": "mu = ( rand . NormFloat64 ( ) * sig ) + mu", "commit_type": "make"}
{"commit_tokens": ["fix", "namespace", "-", "uri", "()", "function", "#xmlquery", "(", "https", ":", "//", "github", ".", "com", "/", "antchfx", "/", "xmlquery", "/", "issues", "/", "23", ")"], "add_tokens": "case \" \" : if len ( root . Args ) > 1 { return nil , fmt . Errorf ( \" \" , root . FuncName ) } var ( arg query err error ) if len ( root . Args ) == 1 { arg , err = b . processNode ( root . Args [ 0 ] ) if err != nil { return nil , err } } qyOutput = & functionQuery { Input : b . firstInput , Func : namespaceFunc ( arg ) } case \" \" , \" \" :", "del_tokens": "case \" \" , \" \" , \" \" : case \" \" : f . Func = namespaceFunc", "commit_type": "fix"}
{"commit_tokens": ["move", "to", "stripe", "-", "go"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Allow", "closing", "consumers", "even", "if", "rebalance", "fails"], "add_tokens": "// Check if close was requested select { case <- c . dying : return default : } hbStop , hbDone := make ( chan none ) , make ( chan none ) cmStop , cmDone := make ( chan none ) , make ( chan none ) func ( c * Consumer ) hbLoop ( stop <- chan none , done chan <- none ) { func ( c * Consumer ) cmLoop ( stop <- chan none , done chan <- none ) { select { case <- c . dying : case <- time . After ( c . client . config . Metadata . Retry . Backoff ) : }", "del_tokens": "hbStop , hbDone := make ( chan struct { } ) , make ( chan struct { } ) cmStop , cmDone := make ( chan struct { } ) , make ( chan struct { } ) func ( c * Consumer ) hbLoop ( stop <- chan struct { } , done chan <- struct { } ) { func ( c * Consumer ) cmLoop ( stop <- chan struct { } , done chan <- struct { } ) { time . Sleep ( c . client . config . Metadata . Retry . Backoff )", "commit_type": "allow"}
{"commit_tokens": ["changed", "engine", "setup", ":", "added", "tags", "to", "template", "config"], "add_tokens": "Dir string `yaml:\"dir\" json:\"dir\"` Delimiters [ ] string `yaml:\"delimiters\" json:\"delimiters\"` Extension string `yaml:\"ext\" json:\"ext\"` bo := BuildAssetTemplate ( name , t . config . Extension , dirs , fo , t . config . Delimiters ) bo := BuildAssetTemplate ( name , ext , dirs , fo , t . config . Delimiters )", "del_tokens": "Dir string Delimeters [ ] string Extension string bo := BuildAssetTemplate ( name , t . config . Extension , dirs , fo , t . config . Delimeters ) bo := BuildAssetTemplate ( name , ext , dirs , fo , t . config . Delimeters )", "commit_type": "change"}
{"commit_tokens": ["Adds", "global", "deploys", "to", "deploy", ".", "go", "."], "add_tokens": "for s := 1 ; s <= shards ; s ++ { config . Nshards = shards func printGlobalService ( name string ) { template , err := template . New ( \" \" ) . ParseFiles ( \" \" ) if err != nil { log . Fatal ( err ) } config := new ( service ) config . Name = name server , err := os . Create ( fmt . Sprintf ( \" \" , config . Name ) ) if err != nil { log . Fatal ( err ) } err = template . Execute ( server , config ) if err != nil { log . Fatal ( err ) } } printGlobalService ( \" \" )", "del_tokens": "nShards , err := strconv . Atoi ( os . Args [ 1 ] ) if err != nil { log . Fatal ( err ) } for s := 1 ; s <= nShards ; s ++ { config . Nshards = nShards", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "to", "add", "back", "snapshot", "total", "everywhere", "we", "register", "."], "add_tokens": "sw . register ( m ) func ( sw * sweeper ) register ( m * Meter ) { // Add back the snapshot total. If we unregistered this // one, we set it to zero. atomic . AddUint64 ( & m . accumulator , m . snapshot . Total ) sw . meters = append ( sw . meters , m ) } sw . register ( m )", "del_tokens": "sw . meters = append ( sw . meters , m ) // Add back the snapshot total. If we unregistered this // one, we set it to zero. // Technically, I don't need to take a lock here as this // is the only thread that writes to it. // However, I'm not sure if go is smart enough for that. atomic . AddUint64 ( & m . accumulator , m . Snapshot ( ) . Total ) sw . meters = append ( sw . meters , m )", "commit_type": "make"}
{"commit_tokens": ["Fix", "race", "condition", "in", "core", "::", "go"], "add_tokens": "const Version = `0.9.10`", "del_tokens": "const Version = `0.9.9`", "commit_type": "fix"}
{"commit_tokens": ["moved", "some", "of", "the", "test", "helpers", "into", "a", "shared", "location", "so", "they", "can", "be", "reused"], "add_tokens": "\" \" func init ( ) { jwtTestDefaultKey = test . LoadRSAPublicKeyFromDisk ( \" \" ) } privateKey := test . LoadRSAPrivateKeyFromDisk ( \" \" ) data . tokenString = test . MakeSampleToken ( data . claims , privateKey )", "del_tokens": "\" \" func init ( ) { if keyData , e := ioutil . ReadFile ( \" \" ) ; e == nil { if jwtTestDefaultKey , e = jwt . ParseRSAPublicKeyFromPEM ( keyData ) ; e != nil { panic ( e ) } } else { panic ( e ) } } func makeSample ( c jwt . MapClaims ) string { keyData , e := ioutil . ReadFile ( \" \" ) if e != nil { panic ( e . Error ( ) ) } key , e := jwt . ParseRSAPrivateKeyFromPEM ( keyData ) if e != nil { panic ( e . Error ( ) ) } token := jwt . NewWithClaims ( jwt . SigningMethodRS256 , c ) s , e := token . SignedString ( key ) if e != nil { panic ( e . Error ( ) ) } return s } data . tokenString = makeSample ( data . claims )", "commit_type": "move"}
{"commit_tokens": ["add", "test", "for", "image", "unmarshal", "error"], "add_tokens": "image2 , err := NewImageUnmarshal ( data ) func TestImageUnmarshalError ( t * testing . T ) { _ , err := NewImageUnmarshal ( nil ) if err == nil { t . Fatal ( \" \" ) } }", "del_tokens": "image2 := new ( Image ) err = image2 . Unmarshal ( data )", "commit_type": "add"}
{"commit_tokens": ["changed", "logger", "to", "use", "golang", "log", ".", "logger", "instead", "of", "syslog", ".", "Writer"], "add_tokens": "\" \" \" \" var buf bytes . Buffer l := log . New ( & buf , \" \" , log . Lshortfile )", "del_tokens": "\" \" l , err := syslog . New ( syslog . LOG_INFO , \" \" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "description", "of", "signal", "-", "on", "-", "hup", "."], "add_tokens": "OptSignalOnHUP string `long:\"signal-on-hup\" arg:\"Signal\" description:\"name of the signal to be sent to the server process when start_server\\nreceives a SIGHUP (default: TERM). If you use this option, be sure to\\nalso use '--signal-on-term' below.\"`", "del_tokens": "OptSignalOnHUP string `long:\"signal-on-hup\" arg:\"Signal\" description:\"name of the signal to be sent to the server process when start_server\\nreceives a SIGHUP (default: HUP). If you use this option, be sure to\\nalso use '--signal-on-term' below.\"`", "commit_type": "fix"}
{"commit_tokens": ["Implement", "deadline", "handling", "and", "propagation", "."], "add_tokens": "\" \" type fakeAPIHandler struct { die chan int // closed when the test server is going down } func ( f * fakeAPIHandler ) ServeHTTP ( w http . ResponseWriter , r * http . Request ) { case \" \" : // Avoid blocking test shutdown by aborting early when the test is over. select { case <- time . After ( 5 * time . Second ) : case <- f . die : return } resOut = & basepb . VoidProto { } f := & fakeAPIHandler { die : make ( chan int ) , } srv := httptest . NewServer ( f ) close ( f . die ) { \" \" , runtimepb . APIResponse_CANCELLED } , opts := & CallOptions { Timeout : 100 * time . Millisecond , } err := c . Call ( \" \" , tc . method , & basepb . VoidProto { } , & basepb . VoidProto { } , opts )", "del_tokens": "func fakeAPIHandler ( w http . ResponseWriter , r * http . Request ) { srv := httptest . NewServer ( http . HandlerFunc ( fakeAPIHandler ) ) err := c . Call ( \" \" , tc . method , & basepb . VoidProto { } , & basepb . VoidProto { } , nil )", "commit_type": "implement"}
{"commit_tokens": ["Used", "a", "map", "for", "something!", "Added", "notes", "..", "nothing", "big", "."], "add_tokens": "// TODO also since everything comes back as JSON let this // func unmarshal into a referenced object here // then it can reduce code more and handle errors better var temp map [ string ] interface { } token = temp [ \" \" ] . ( string ) func Messages ( session * Session , channelId int , limit int , beforeId int , afterId int ) ( messages [ ] Message , err error ) {", "del_tokens": "temp := & Session { } // TODO Must be a better way token = temp . Token func Messages ( session * Session , channelId int , limit int , afterId int , beforeId int ) ( messages [ ] Message , err error ) { fmt . Println ( urlStr )", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "new", "path", "for", "mgo", "library"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Fix", "var", "name", "in", "doc"], "add_tokens": "// listener, _ := gostream.Listen(host1, p2phttp.DefaultP2PProtocol)", "del_tokens": "// listener, _ := gostream.Listen(host1, p2phttp.P2PProtocol)", "commit_type": "fix"}
{"commit_tokens": ["Add", "variable", "collection", "clause", "hook", "."], "add_tokens": "var ( lastNopToken * lexer . Token f func ( st * Statement , ce ConsumedElement ) ( ElementHook , error ) ) f = func ( st * Statement , ce ConsumedElement ) ( ElementHook , error ) { if ce . IsSymbol ( ) { return f , nil } tkn := ce . Token ( ) p := st . WorkingProjection ( ) switch tkn . Type { case lexer . ItemBinding : if p . Binding == \" \" { p . Binding = tkn . Text } else { if lastNopToken != nil && lastNopToken . Type == lexer . ItemAs { p . Alias = tkn . Text lastNopToken = nil } else { return nil , fmt . Errorf ( \" \" , tkn . Type , p ) } } case lexer . ItemAs : lastNopToken = tkn case lexer . ItemSum , lexer . ItemCount : p . OP = tkn . Type case lexer . ItemDistinct : p . Modifier = tkn . Type default : lastNopToken = nil } return f , nil return f", "del_tokens": "return func ( st * Statement , ce ConsumedElement ) ( ElementHook , error ) { return nil , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "introduce", "in", "my", "last", "commit"], "add_tokens": "t . Errorf ( \" \" , testExpected , result , testName ) var resultString2 = `<h1>0: Mario Santos<small>mario@gmail.com</small></h1><h1>Joel Silva<small>joelsilva@gmail.com</small></h1><h1>2: Luis Santana<small>luis.santana@gmail.com</small></h1>` evalTestCase ( t , data , nil , \" \" , `{{range i, user:=users}}<h1>{{if i == 0 || i == 2}}{{i}}: {{end}}{{user.Name}}<small>{{user.Email}}</small></h1>{{end}}` , resultString2 )", "del_tokens": "t . Errorf ( \" \" , testExpected , result , testName ) var resultString2 = `<h1>1: Mario Santos<small>mario@gmail.com</small></h1><h1>Joel Silva<small>joelsilva@gmail.com</small></h1><h1>3: Luis Santana<small>luis.santana@gmail.com</small></h1>` evalTestCase ( t , data , nil , \" \" , `{{range i, user:=users}}<h1>{{if i == 1 || i == 3}}{{i}}: {{end}}{{user.Name}}<small>{{user.Email}}</small></h1>{{end}}` , resultString2 )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "build", "on", "windows", "/", "386"], "add_tokens": "sid = syscall . UTF16ToString ( ( * [ 0xffff ] uint16 ) ( unsafe . Pointer ( strBuffer ) ) [ : ] )", "del_tokens": "sid = syscall . UTF16ToString ( ( * [ 1 << 30 ] uint16 ) ( unsafe . Pointer ( strBuffer ) ) [ : ] )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "workers", "feature", "draft", "."], "add_tokens": "for i , worker := range wm . Workers { outputChannels [ i ] = worker . OutputChannel", "del_tokens": "for i := 0 ; i < wm . Config . NumWorkers ; i ++ { outputChannels [ i ] = make ( chan WorkerResult )", "commit_type": "implement"}
{"commit_tokens": ["Added", "2", "more", "assertions", "to", "Close", "()", "and", "Shutdown", "()", "tests"], "add_tokens": "err = srv . Close ( ) So ( err , ShouldEqual , nil ) err = srv . Shutdown ( context . Background ( ) ) So ( err , ShouldEqual , nil )", "del_tokens": "srv . Close ( ) srv . Shutdown ( context . Background ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "banner", "sometimes", "error", "because", "conc"], "add_tokens": "if len ( banner ) <= i { return c . Printf ( \" \" , banner [ i ] ) i ++", "del_tokens": "c . Printf ( \" \" , banner [ i ] ) i ++ if i == len ( banner ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "README", ".", "md", "."], "add_tokens": "// Template, http://tools.ietf.org/html/rfc6570).", "del_tokens": "// Template).", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "default", "provider", "path", "for", "Windows"], "add_tokens": "\" \" var DefaultPath = getDefaultPath ( ) func getDefaultPath ( ) string { if runtime . GOOS == \" \" { //No way to use SHGetKnownFolderPath(FOLDERID_ProgramFilesX64, ...) //Hardcoding should be fine for now since SUMMON_PROVIDER and -p are available return \" \\\\ \\\\ \\\\ \\\\ \" } else { return \" \" } }", "del_tokens": "var DefaultPath = \" \"", "commit_type": "add"}
{"commit_tokens": ["Make", "Token", ".", "String", "()", "outputs", "more", "readable", "."], "add_tokens": "return fmt . Sprintf ( \" \" , string ( c . Rune ( ) ) , c . Flag ( ) . String ( ) ) return fmt . Sprintf ( \" \" , d . Flag ( ) . String ( ) ) return fmt . Sprintf ( \" \" , strings . Join ( rs , \" \" ) , s . Flag ( ) . String ( ) )", "del_tokens": "return fmt . Sprintf ( \" \" , string ( c . Rune ( ) ) , c . Flag ( ) . String ( ) ) return fmt . Sprintf ( \" \" , d . Flag ( ) . String ( ) ) return fmt . Sprintf ( \" \" , strings . Join ( rs , \" \" ) , s . Flag ( ) . String ( ) )", "commit_type": "make"}
{"commit_tokens": ["Fix", "unclosed", "quotes", "in", "const_invalid_start", "message"], "add_tokens": "const_invalid_start = `JSON pointer must be empty or start with a \"` + const_pointer_separator + `\"`", "del_tokens": "const_invalid_start = `JSON pointer must be empty or start with a \"` + const_pointer_separator", "commit_type": "fix"}
{"commit_tokens": ["Add", "error", "check", "to", "leak", "regression", "test", "."], "add_tokens": "ch = make ( chan error ) errors = make ( chan int ) go func ( ) { defer close ( errors ) count := 0 for range ch { count ++ } errors <- count } ( ) testBase . SetErrorChan ( ch ) Expect ( len ( l1 . Messages ) ) . To ( Equal ( 2 * TestMaxQueueSize + 1 ) ) Eventually ( errors ) . Should ( Receive ( Equal ( 2 * TestMaxQueueSize - 1 ) ) )", "del_tokens": "Expect ( l1 . Messages ) . To ( HaveLen ( 2 * TestMaxQueueSize + 1 ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "allow", "trim", "all", "spaces"], "add_tokens": "// New initialize CSV backend, config is option, the last one will be used if there are more than one configs func New ( filename string , config ... Config ) * CSV { csv := & CSV { Filename : filename } for _ , cfg := range config { csv . config = cfg } return csv } type Config struct { TrimSpace bool config Config", "del_tokens": "func New ( filename string ) * CSV { return & CSV { Filename : filename }", "commit_type": "add"}
{"commit_tokens": ["Add", "TopN", "supporting", "in", "Interfaces", ".", "Fix", "un", "reference", "bug"], "add_tokens": "h . list [ len ( h . list ) - 1 ] = \" \" // remove the reference in h.list // NewStrings returns a *Strings with a customized less func and the initial capacity.", "del_tokens": "// NewStrings returns a *Strings with customized less func and initial capacity.", "commit_type": "add"}
{"commit_tokens": ["Add", "GetBool", "SectionGetBool", "and", "unit", "test", "code"], "add_tokens": "func ( ini * INI ) GetBool ( key string ) ( value bool , ok bool ) { return ini . SectionGetBool ( DefaultSection , key ) } return 0.0 , ok } func ( ini * INI ) SectionGetBool ( section , key string ) ( value bool , ok bool ) { v , ok := ini . SectionGet ( section , key ) if ok { v , err := strconv . ParseBool ( v ) if err == nil { return v , true } } return false , ok", "del_tokens": "return 0 , ok", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplicate", "NotFoundError", "and", "rename", "it", "to", "ErrNotFound", "(", "idiomatic", ")"], "add_tokens": "\" \" return nil , & common . ErrNotFound { c . url }", "del_tokens": "return nil , & NotFoundError { c . url } type NotFoundError struct { url string } func ( e NotFoundError ) Error ( ) string { return e . url }", "commit_type": "remove"}
{"commit_tokens": ["Add", "C", "-", "b", "and", "C", "-", "f", "by", "default"], "add_tokens": "if pos == len ( i . query ) - 1 { buf := make ( [ ] rune , len ( i . query ) - ( pos - i . caretPos ) ) buf := make ( [ ] rune , len ( i . query ) - ( i . caretPos - pos ) ) termbox . KeyCtrlF : handleForwardChar , termbox . KeyCtrlB : handleBackwardChar ,", "del_tokens": "if pos == len ( i . query ) - 1 { buf := make ( [ ] rune , len ( i . query ) - ( pos - i . caretPos ) ) buf := make ( [ ] rune , len ( i . query ) - ( i . caretPos - pos ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "encoding", "mechanisms", "to", "comment", "frame"], "add_tokens": "Encoding ( ) util . Encoding SetEncoding ( util . Encoding ) encoding util . Encoding b . WriteByte ( cf . encoding . Key ) b . Write ( cf . encoding . TerminationBytes ) func ( cf CommentFrame ) Encoding ( ) util . Encoding { return cf . encoding } func ( cf * CommentFrame ) SetEncoding ( e util . Encoding ) { cf . encoding = e }", "del_tokens": "b . WriteByte ( util . NativeEncoding ) b . WriteByte ( 0 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "regex", "to", "support", "abspath"], "add_tokens": "UnixPath string = `^((?:\\.{0,2}\\/[a-zA-Z0-9\\.\\:]+(?:_[a-zA-Z0-9\\:\\.]+)*(?:\\-[\\:a-zA-Z0-9\\.]+)*)+\\/?)$`", "del_tokens": "UnixPath string = `^((?:\\/[a-zA-Z0-9\\.\\:]+(?:_[a-zA-Z0-9\\:\\.]+)*(?:\\-[\\:a-zA-Z0-9\\.]+)*)+\\/?)$`", "commit_type": "fix"}
{"commit_tokens": ["Create", "a", "Huffman", "-", "only", "bitwriter", ".", "Speed", "~84MB", "/", "s", "."], "add_tokens": "// We only compress if we have >= 32KB (maxStoreBlockSize/2) if d . windowEnd < ( maxStoreBlockSize / 2 ) && ! d . sync { if d . windowEnd == 0 { d . w . writeBlockHuff ( false , d . window [ : d . windowEnd ] )", "del_tokens": "d . blockStart = 0 ntokens := d . windowEnd if d . windowEnd == 0 { for i , v := range d . window [ : d . windowEnd ] { d . tokens [ i ] = literalToken ( uint32 ( v ) ) } if d . err = d . writeBlock ( d . tokens [ : ntokens ] , d . windowEnd , false ) ; d . err != nil {", "commit_type": "create"}
{"commit_tokens": ["Fix", "crop", "media", "library", "s", "images"], "add_tokens": "if string ( values ) != \" \" { if err = json . Unmarshal ( values , b ) ; err == nil { var doCrop struct { Crop bool } if err = json . Unmarshal ( values , & doCrop ) ; err == nil && doCrop . Crop { b . Crop = true } return b . Scan ( [ ] byte ( values ) )", "del_tokens": "if err = json . Unmarshal ( values , b ) ; err == nil { var doCrop struct { Crop bool } if err = json . Unmarshal ( values , & doCrop ) ; err == nil && doCrop . Crop { b . Crop = true if values != \" \" { return b . Scan ( [ ] byte ( values ) ) }", "commit_type": "fix"}
{"commit_tokens": ["add", "method", "to", "initialize", "minwise", "struct", "from", "signatures", "."], "add_tokens": "// NewMinWise returns a new MinWise Hashing implementation // NewMinWise returns a new MinWise Hashing implementation // using a user-provided set of signatures func NewMinWiseFromSignatures ( h1 , h2 Hash64 , signatures [ ] uint64 ) * MinWise { minimums := make ( [ ] uint64 , len ( signatures ) ) copy ( minimums , signatures ) return & MinWise { h1 : h1 , h2 : h2 , minimums : signatures , } }", "del_tokens": "// NewMinWise returns a new MinWise Hashsing implementation", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "around", "bool", "specs"], "add_tokens": "if value == \" \" { continue } return & ParseError { FieldName : fieldName , TypeName : f . Kind ( ) . String ( ) , Value : value , }", "del_tokens": "return err", "commit_type": "add"}
{"commit_tokens": ["add", "another", "decode", "case", "for", "blank", "for", "when", "you", "want", "only", "Query", "()", "params"], "add_tokens": "ApplicationQueryParams = \" \"", "del_tokens": "// // CONNECT HTTP method // CONNECT = \"CONNECT\" // // DELETE HTTP method // DELETE = \"DELETE\" // // GET HTTP method // GET = \"GET\" // // HEAD HTTP method // HEAD = \"HEAD\" // // OPTIONS HTTP method // OPTIONS = \"OPTIONS\" // // PATCH HTTP method // PATCH = \"PATCH\" // // POST HTTP method // POST = \"POST\" // // PUT HTTP method // PUT = \"PUT\" // // TRACE HTTP method // TRACE = \"TRACE\"", "commit_type": "add"}
{"commit_tokens": ["Improve", "test", "coherence", "in", "kmeans", "and", "triangle_kmeans"], "add_tokens": "assert . Nil ( t , model . PersistToFile ( \" \" ) , \" \" ) assert . Nil ( t , model . RestoreFromFile ( \" \" ) , \" \" )", "del_tokens": "assert . Nil ( t , model . PersistToFile ( \" \" ) , \" \" ) assert . Nil ( t , model . RestoreFromFile ( \" \" ) , \" \" )", "commit_type": "improve"}
{"commit_tokens": ["Add", "a", "fixture", "method", "which", "takes", "a", "slice"], "add_tokens": "Expect ( model . Methods ) . To ( HaveLen ( 3 ) ) Expect ( model . Methods [ 2 ] . Names [ 0 ] . Name ) . To ( Equal ( \" \" ) )", "del_tokens": "Expect ( model . Methods ) . To ( HaveLen ( 2 ) )", "commit_type": "add"}
{"commit_tokens": ["added", "logging", "to", "trace", "NFS"], "add_tokens": "nfsMountPath = \" \" // Validate options. if spec . Format != \" \" && spec . Format != \" \" { return \" \" , errors . New ( \" \" + string ( spec . Format ) ) } if spec . BlockSize != 0 { log . Println ( \" \" ) } log . Println ( err ) log . Println ( err ) log . Println ( err ) log . Println ( err ) log . Println ( err ) log . Println ( err ) log . Println ( err ) log . Println ( err ) log . Println ( err )", "del_tokens": "nfsMountPath = \" \" log . Println ( err )", "commit_type": "add"}
{"commit_tokens": ["Add", "ParseReq", "method", "and", "tweak", "benchmarks", "."], "add_tokens": "return", "del_tokens": "break", "commit_type": "add"}
{"commit_tokens": ["Fix", "fingerprints", "flag", "handling", "in", "cli", "."], "add_tokens": "flag . StringVar ( & fingerprints , \" \" , \" \" , \" \" ) var err error var nessus nessie . Nessus if len ( fingerprints ) > 0 { nessus , err = nessie . NewFingerprintedNessus ( apiURL , strings . Split ( fingerprints , \" \" ) ) nessus , err = nessie . NewInsecureNessus ( apiURL )", "del_tokens": "flag . StringList ( & fingerprints , nil , \" \" ) if len ( * fingerprints ) > 0 { nessus , err := nessie . NewFingerprintedNessus ( apiURL , * fingerprints ) nessus , err := nessie . NewInsecureNessus ( apiURL )", "commit_type": "fix"}
{"commit_tokens": ["moved", "to", "gobuffalo", "/", "pop"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Fix", "string", "array", "inputs", "for", "query", "clients", "."], "add_tokens": "name := t . Field ( i ) . Name", "del_tokens": "name := t . Field ( i ) . Tag . Get ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["add", "a", "case", "in", "Decode", "for", "int", "and", "uint"], "add_tokens": "if val . Kind ( ) == reflect . Int && val . Type ( ) . Size ( ) < 8 { panic ( \" \" + \" \" ) } case reflect . Uint , reflect . Uint32 , reflect . Uint64 : if val . Kind ( ) == reflect . Uint && val . Type ( ) . Size ( ) < 8 { panic ( \" \" + \" \" ) } case reflect . Bool , reflect . Int32 , reflect . Int64 , reflect . Int , reflect . Uint32 , reflect . Uint64 , reflect . Uint : if ( eltype . Kind ( ) == reflect . Int || eltype . Kind ( ) == reflect . Uint ) && eltype . Size ( ) < 8 { panic ( \" \" + \" \" ) }", "del_tokens": "case reflect . Uint32 , reflect . Uint64 : case reflect . Bool , reflect . Int32 , reflect . Int64 , reflect . Uint32 , reflect . Uint64 :", "commit_type": "add"}
{"commit_tokens": ["removed", "the", "need", "for", "symbolic", "link", "to", "grafana", "/", "src"], "add_tokens": "Usage : \" \" , Description : \" \" , mapStatic ( m , \" \" , \" \" ) mapStatic ( m , \" \" , \" \" ) mapStatic ( m , \" \" , \" \" ) Directory : setting . TemplatesRootPath ,", "del_tokens": "Usage : \" \" , Description : `Start Grafana Pro server` , mapStatic ( m , \" \" , \" \" ) mapStatic ( m , \" \" , \" \" ) mapStatic ( m , \" \" , \" \" ) Directory : path . Join ( setting . StaticRootPath , \" \" ) ,", "commit_type": "remove"}
{"commit_tokens": ["Added", "method", "Reset", "()", "to", "Message"], "add_tokens": "want = & message { from : \" \" , to : [ ] string { \" \" } , content : \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \" , } msg . Reset ( ) msg . SetHeader ( \" \" , \" \" ) msg . SetHeader ( \" \" , \" \" ) msg . SetBody ( \" \" , \" \" ) testMessage ( t , msg , 0 , want ) buf := new ( bytes . Buffer ) msg . WriteTo ( buf ) buf . Reset ( ) msg := NewMessage ( ) b . ResetTimer ( ) msg . Reset ( )", "del_tokens": "msg := NewMessage ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "govet", "issues", "and", "make", "node", ".", "go", "thread", "safe", "."], "add_tokens": "import ( \" \" \" \" ) nodeMu sync . Mutex defer nodeMu . Unlock ( ) nodeMu . Lock ( ) defer nodeMu . Unlock ( ) nodeMu . Lock ( ) return setNodeInterface ( name ) } func setNodeInterface ( name string ) bool { defer nodeMu . Unlock ( ) nodeMu . Lock ( ) setNodeInterface ( \" \" ) defer nodeMu . Unlock ( ) nodeMu . Lock ( )", "del_tokens": "import \" \" SetNodeInterface ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "generational", "hash", "table", "to", "increase", "compression", "efficiency"], "add_tokens": "zbCompressBuf [ ] byte // buffer for compressing lz4 blocks writeSizeBuf [ ] byte // four-byte slice for writing checksums and sizes in writeblock hashTable [ ] hashEntry currentGeneration uint hashTable : make ( [ ] hashEntry , hashTableSize ) , n , err = compressGenerationalBlock ( zb . data , zbuf , zb . offset , z . currentGeneration , z . hashTable ) z . currentGeneration ++ if z . currentGeneration == 0 { // wrapped around, reset table z . hashTable = make ( [ ] hashEntry , hashTableSize ) }", "del_tokens": "zbCompressBuf [ ] byte // buffer for compressing lz4 blocks writeSizeBuf [ ] byte // four-byte slice for writing checksums and sizes in writeblock n , err = CompressBlock ( zb . data , zbuf , zb . offset )", "commit_type": "use"}
{"commit_tokens": ["move", "netdev", "flatbuffer", "stuff", "to", "net", "dir", "and", "flat", "subdir", ";", "refactor", "net", "code", "add", "some", "methods"], "add_tokens": "infS := inf . SerializeFlat ( ) infD := DeserializeFlat ( infS ) func TestInfo ( t * testing . T ) { b := inf . SerializeFlatBuilder ( bldr ) infD := DeserializeFlat ( b ) func TestInfoTicker ( t * testing . T ) { go InfoTickerFlat ( time . Second , results , done , errs ) inf := DeserializeFlat ( b )", "del_tokens": "infS := inf . Serialize ( ) infD := Deserialize ( infS ) func TestData ( t * testing . T ) { b := Serialize ( inf , bldr ) infD := Deserialize ( b ) func TestDataTicker ( t * testing . T ) { go DataTicker ( time . Second , results , done , errs ) inf := Deserialize ( b )", "commit_type": "move"}
{"commit_tokens": ["added", "basic", "blurs", "and", "convolution", "function"], "add_tokens": "img := cloneAsNRGBA ( src )", "del_tokens": "img := clone ( src )", "commit_type": "add"}
{"commit_tokens": ["Upgraded", "to", "fit", "changes", "to", "buffer", "channel", "and", "queue"], "add_tokens": "\" \" input := make ( chan interface { } ) output := make ( chan interface { } ) pending := buffer . NewBufferQueue ( buffer . NewUnboundedBuffer ( 32 * 1024 , 100 * 1024 * 1024 ) ) go channel . ChanQueue ( input , output , pending ) func inFeed ( r io . Reader , in chan <- interface { } ) { func outFeed ( w io . WriteCloser , out <- chan interface { } ) { data := output . ( [ ] byte ) for len ( data ) > 0 { n , _ := w . Write ( data ) data = data [ n : ]", "del_tokens": "input := make ( chan [ ] byte ) output := make ( chan [ ] byte ) go channel . Chan ( input , output ) func inFeed ( r io . Reader , in chan <- [ ] byte ) { func outFeed ( w io . WriteCloser , out <- chan [ ] byte ) { for len ( output ) > 0 { n , _ := w . Write ( output ) output = output [ n : ]", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "types", "in", "rsssh", "example", "."], "add_tokens": "func server ( client * cm15 . Api , name string ) * cm15 . Instance {", "del_tokens": "func server ( client * cm15 . Api , name string ) cm15 . Instance {", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "and", "fix", "a", "typo"], "add_tokens": "_ , err := Max ( [ ] float64 { } ) _ , err := Mode ( [ ] float64 { } ) if err == nil { t . Errorf ( \" \" ) } _ , err := LinReg ( [ ] Coordinate { } ) if err == nil { t . Errorf ( \" \" ) } _ , err := ExpReg ( [ ] Coordinate { } ) if err == nil { t . Errorf ( \" \" ) } _ , err := LogReg ( [ ] Coordinate { } ) if err == nil { t . Errorf ( \" \" ) }", "del_tokens": "_ , err := Min ( [ ] float64 { } )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "when", "using", "stdin"], "add_tokens": "if v , ok := f . optionMeta [ \" \" ] ; ok { mode = v . ( int ) if mode & os . O_RDONLY == os . O_RDONLY { } else if mode & os . O_WRONLY == os . O_WRONLY {", "del_tokens": "if v , ok := f . optionMeta [ \" \" ] . ( int ) ; ok { mode = v if mode & os . O_RDONLY > 0 { } else if mode & os . O_WRONLY > 0 {", "commit_type": "fix"}
{"commit_tokens": ["remove", "a", "useless", "test", "add", "test", "for", "IsSuperGroup"], "add_tokens": "func TestChatIsSuperGroup ( t * testing . T ) { chat := tgbotapi . Chat { ID : 10 , Type : \" \" } if ! chat . IsSuperGroup ( ) { t . Fail ( ) } }", "del_tokens": "func TestMessageIsGroup ( t * testing . T ) { from := tgbotapi . User { ID : 0 } chat := tgbotapi . Chat { ID : 10 } message := tgbotapi . Message { From : from , Chat : chat } if message . IsGroup ( ) != true { t . Fail ( ) } }", "commit_type": "remove"}
{"commit_tokens": ["add", "unit", "tests", "for", "transaction"], "add_tokens": "operations [ ] interface { } c . operations = append ( c . operations , ops ... ) err := args . Error ( 1 ) if c . log != nil { c . log ( \" \" , ops , res , err ) } return res , err", "del_tokens": "return res , args . Error ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "single", "frame", "instance", "instead", "of", "creating", "a", "new", "one", "each", "time"], "add_tokens": "return & Lepton3 { frame : newFrame ( ) , } frame * frame d . frame . reset ( ) complete , err := d . frame . nextPacket ( packetNum , packet ) d . frame . writeImage ( im ) d . frame . reset ( ) f := & frame { f . reset ( ) return f func ( f * frame ) reset ( ) { f . packetNum = - 1 f . segmentNum = 0 }", "del_tokens": "// XXX put code in the right place return new ( Lepton3 ) f := newFrame ( ) f = newFrame ( ) complete , err := f . nextPacket ( packetNum , packet ) f = newFrame ( ) f . writeImage ( im ) // XXX reuse a singe frame instead of recreating? return & frame { packetNum : - 1 , segmentNum : 0 ,", "commit_type": "use"}
{"commit_tokens": ["Changed", "code", "to", "use", "new", "rune", "type", "unicode", "code", "points", "."], "add_tokens": "if unicode . IsDigit ( rune ( ( * pkgname ) [ 0 ] ) ) { if unicode . IsDigit ( rune ( file [ 0 ] ) ) {", "del_tokens": "if unicode . IsDigit ( int ( ( * pkgname ) [ 0 ] ) ) { if unicode . IsDigit ( int ( file [ 0 ] ) ) {", "commit_type": "change"}
{"commit_tokens": ["Move", "handling", "of", "org", ".", "freedesktop", ".", "DBus", ".", "Peer", "to", "handleCall"], "add_tokens": "go conn . handleCall ( msg )", "del_tokens": "if msg . Headers [ FieldInterface ] . value . ( string ) == \" \" { serial := msg . Serial sender := msg . Headers [ FieldSender ] . value . ( string ) switch msg . Headers [ FieldMember ] . value . ( string ) { case \" \" : rm := ReplyMessage ( nil ) conn . out <- rm . toMessage ( conn , sender , serial ) case \" \" : rm := ReplyMessage ( [ ] interface { } { conn . uuid } ) conn . out <- rm . toMessage ( conn , sender , serial ) } } else { go conn . handleCall ( msg ) }", "commit_type": "move"}
{"commit_tokens": ["create", "indexes", "if", "not", "exist"], "add_tokens": "CREATE INDEX IF NOT EXISTS developer_id ON developer ( id ) ; CREATE INDEX IF NOT EXISTS api_product_id ON api_product ( id ) ; CREATE INDEX IF NOT EXISTS app_id ON app ( id ) ;", "del_tokens": "CREATE INDEX developer_id ON developer ( id ) ; CREATE INDEX api_product_id ON api_product ( id ) ; CREATE INDEX app_id ON app ( id ) ;", "commit_type": "create"}
{"commit_tokens": ["Add", "ParamInt64", "as", "requested", "on", "chat", "from", "the", "community"], "add_tokens": "// ParamInt64 returns the int64 representation of the key's path named parameter's value func ( ctx * Context ) ParamInt64 ( key string ) ( int64 , error ) { return strconv . ParseInt ( ctx . Param ( key ) , 10 , 64 ) } return strconv . ParseInt ( ctx . URLParam ( key ) , 10 , 64 )", "del_tokens": "return strconv . ParseInt ( ctx . Param ( key ) , 10 , 64 )", "commit_type": "add"}
{"commit_tokens": ["Made", "Coordinate", "a", "slice", "."], "add_tokens": "// Type to represent one coordinate (x,y). This coordinate can have any number of dimensions per the spec. // or // c := Coordinate{x, y, z} type Coordinate [ ] CoordType", "del_tokens": "// Type to represent one coordinate (x,y). type Coordinate [ 2 ] CoordType", "commit_type": "make"}
{"commit_tokens": ["add", "cat", "and", "tail", "/", "head"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "FTPS", "."], "add_tokens": "\" \" [ ] string { \" \" , \" \" , host + \" \" + port , \" \" , \" \" , \" \" , \" \" , } , for _ , addr := range ftpdAddrs { func TestExplicitFTPS ( t * testing . T ) { for _ , addr := range ftpdAddrs { config := Config { TLSConfig : & tls . Config { InsecureSkipVerify : true , } , TLSMode : TLSExplicit , } c , err := DialConfig ( config , addr ) if err != nil { t . Fatal ( err ) } buf := new ( bytes . Buffer ) err = c . Retrieve ( \" \" , buf ) if err != nil { t . Fatal ( err ) } if ! bytes . Equal ( [ ] byte { 1 , 2 , 3 , 4 } , buf . Bytes ( ) ) { t . Errorf ( \" \" , buf . Bytes ( ) ) } } }", "del_tokens": "[ ] string { \" \" , \" \" , host + \" \" + port , \" \" , \" \" } , for _ , addr := range ftpdAddrs [ 0 : 1 ] {", "commit_type": "add"}
{"commit_tokens": ["Add", "utility", "to", "normalize", "metric", "info"], "add_tokens": "func ( p * incrementalTestingProvider ) valueFor ( groupResource schema . GroupResource , metricName string , namespaced bool ) ( int64 , error ) { info , _ , err := info . Normalized ( api . Registry . RESTMapper ( ) ) if err != nil { return 0 , err } return value , nil value , err := p . valueFor ( groupResource , metricName , false ) if err != nil { return nil , err } totalValue , err := p . valueFor ( groupResource , metricName , false ) if err != nil { return nil , err } value , err := p . valueFor ( groupResource , metricName , true ) if err != nil { return nil , err } totalValue , err := p . valueFor ( groupResource , metricName , true ) if err != nil { return nil , err }", "del_tokens": "func ( p * incrementalTestingProvider ) valueFor ( groupResource schema . GroupResource , metricName string , namespaced bool ) int64 { return value value := p . valueFor ( groupResource , metricName , false ) totalValue := p . valueFor ( groupResource , metricName , false ) value := p . valueFor ( groupResource , metricName , true ) totalValue := p . valueFor ( groupResource , metricName , true )", "commit_type": "add"}
{"commit_tokens": ["Make", "retry_test", "more", "robust", "in", "the", "face", "of", "test", "system", "slowness", "."], "add_tokens": "MaxElapsedTime : 250 * time . Millisecond }", "del_tokens": "MaxElapsedTime : 250 * time . Microsecond }", "commit_type": "make"}
{"commit_tokens": ["make", "sure", "vm", "is", "exist", "before", "using", "it", "in", "StopPod"], "add_tokens": "vm , ok := daemon . VmList [ vmid ] if ! ok { return - 1 , \" \" , fmt . Errorf ( \" \" ) }", "del_tokens": "vm , _ := daemon . VmList [ vmid ]", "commit_type": "make"}
{"commit_tokens": ["Add", "buildpack_key", "to", "staging", "response"], "add_tokens": "Ω( s tring( p ayload) ) . S hould( M atchJSON( ` { \" \" : \" \" , \" \" : \" \" } `))", "del_tokens": "Ω( s tring( p ayload) ) . S hould( E qual( ` {\"detected_buildpack\":\"My Buildpack\"}`) )", "commit_type": "add"}
{"commit_tokens": ["Removing", "filepath", ".", "Separator", "using", "filepath", ".", "join", "()"], "add_tokens": "pluginDir , err := os . Stat ( filepath . Join ( prefix , file . Name ( ) ) ) latestVersion , err := GetLatestInstalledPluginVersion ( filepath . Join ( prefix , file . Name ( ) ) )", "del_tokens": "pluginDir , err := os . Stat ( prefix + fmt . Sprintf ( \" \" , filepath . Separator ) + file . Name ( ) ) latestVersion , err := GetLatestInstalledPluginVersion ( prefix + fmt . Sprintf ( \" \" , filepath . Separator ) + file . Name ( ) )", "commit_type": "remove"}
{"commit_tokens": ["fix", "non", "-", "pointer", "uintptr", "-", ">", "uint64", "export", "NextUID"], "add_tokens": "UID ( ) uint64", "del_tokens": "UID ( ) uintptr", "commit_type": "fix"}
{"commit_tokens": ["makes", "the", "parser", "skip", "invalid", "lines", "instead", "of", "crashing", "on", "them"], "add_tokens": "eof := false for ! eof { if scanner . Scan ( ) { chunks <- scanner . Bytes ( ) } else { if err := scanner . Err ( ) ; err != nil { log . Println ( err . Error ( ) + \" \" ) } else { eof = true } }", "del_tokens": "for scanner . Scan ( ) { chunks <- scanner . Bytes ( ) } if err := scanner . Err ( ) ; err != nil { log . Fatal ( err )", "commit_type": "make"}
{"commit_tokens": ["Made", "limit", "only", "apply", "if", ">", "0"], "add_tokens": "for hash , arrayOp := range query . ShardQueryByHash ( step ) { trips , err := s . ts . QueryArrayOp ( arrayOp , int ( q . Limit ) ) Steps : [ ] * protocol . ArrayOp { arrayOp } ,", "del_tokens": "for hash , q := range query . ShardQueryByHash ( step ) { trips , err := s . ts . QueryArrayOp ( q ) Steps : [ ] * protocol . ArrayOp { q } ,", "commit_type": "make"}
{"commit_tokens": ["Make", "the", "debug", "handler", "an", "actual", "thing", "that", "can", "be", "set", "by", "users"], "add_tokens": "registerDebugHandler ( s )", "del_tokens": "registerHealthChecker ( s )", "commit_type": "make"}
{"commit_tokens": ["Fixed", "two", "test", "bugs", "."], "add_tokens": "expectedDesc := \" \\\" \\x00 \\\" \" expectedDesc := \" \\\" \\x00 \\\" \"", "del_tokens": "expectedDesc := \" \\\" \\\\ \\\" \" expectedDesc := \" \\\" \\\\ \\\" \"", "commit_type": "fix"}
{"commit_tokens": ["fix", "incorrect", "print", "in", "error", "message"], "add_tokens": "gb . Fatalf ( \" \" , path , err )", "del_tokens": "gb . Fatalf ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "minor", "typo", "in", "message"], "add_tokens": "logger . Info ( \" \" )", "del_tokens": "logger . Info ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "BatchSubscribeResponse", ".", "Errors", "field", "name"], "add_tokens": "Error [ ] BatchSubscriberError `json:\"errors\"`", "del_tokens": "Error [ ] BatchSubscriberError `json:\"error\"`", "commit_type": "fix"}
{"commit_tokens": ["added", "domains", "and", "IPs", "where", "each", "certificate", "has", "been", "seen"], "add_tokens": "IP string `json:\"ip\"` certs , ip , err := tlsretriever . CheckHost ( string ( msg ) , \" \" , true ) chain . IP = ip jsonChain , er := json . MarshalIndent ( chain , \" \" , \" \" ) Body : [ ] byte ( jsonChain ) ,", "del_tokens": "certs , err := tlsretriever . CheckHost ( string ( msg ) , \" \" , true ) jsonCert , er := json . MarshalIndent ( chain , \" \" , \" \" ) Body : [ ] byte ( jsonCert ) ,", "commit_type": "add"}
{"commit_tokens": ["add", "ListOptions", "field", "to", "ListMembersOptions"], "add_tokens": "testFormValues ( t , r , values { \" \" : \" \" , \" \" : \" \" , } ) opt := & ListMembersOptions { PublicOnly : false , Filter : \" \" , ListOptions : ListOptions { Page : 2 } , }", "del_tokens": "testFormValues ( t , r , values { \" \" : \" \" } ) opt := & ListMembersOptions { PublicOnly : false , Filter : \" \" }", "commit_type": "add"}
{"commit_tokens": ["Allow", "digits", "in", "H", "record", "keys"], "add_tokens": "hRegexp = regexp . MustCompile ( `H([FP])([A-Z0-9]{3})(.*?:)?(.*?)\\s*\\z` )", "del_tokens": "hRegexp = regexp . MustCompile ( `H([FP])([A-Z]{3})(.*?:)?(.*?)\\s*\\z` )", "commit_type": "allow"}
{"commit_tokens": ["adding", "stronger", "connection", "validation", "on", "openPool", "()", "call", "&", "adding", "close", "test"], "add_tokens": "\" \" \" \" // OpenPool opens a returns a Bolt connection from the pool to the Neo4J database. if connectionNilOrClosed ( conn ) { return nil , errors . New ( \" \" ) } func connectionNilOrClosed ( conn * boltConn ) ( bool ) { if ( conn . conn == nil ) { //nil check before attempting read return true } conn . conn . SetReadDeadline ( time . Now ( ) ) zero := make ( [ ] byte , 0 ) _ , err := conn . conn . Read ( zero ) //read zero bytes to validate connection is still alive if err != nil { log . Error ( \" \" , err ) //the error caught here could be a io.EOF or a timeout, either way we want to log the error & return true return true } return false", "del_tokens": "// OpenNeo opens a new Bolt connection to the Neo4J database. if conn . conn == nil { } else { return nil , errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "logging", "of", "MTurk", "HIT", "IDs"], "add_tokens": "log . Println ( \" \" , hit . HITId )", "del_tokens": "log . Printf ( \" \" , hit . HITId )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "support", "for", "data", "function", "call", "with", "arguments"], "add_tokens": "// Instanciates a new HelperArg // Instanciates a new HelperArg for a function call func NewFuncHelperArg ( eval * EvalVisitor , ctx interface { } ) * HelperArg { eval : eval , params : [ ] interface { } { ctx } , hash : make ( map [ string ] interface { } ) ,", "del_tokens": "func NewEmptyHelperArg ( eval * EvalVisitor ) * HelperArg { eval : eval , hash : make ( map [ string ] interface { } ) ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "view", "status", "code", "default"], "add_tokens": "nextBuild = time . Now ( ) . Add ( time . Second * 2 )", "del_tokens": "nextBuild = time . Now ( ) . Add ( time . Second * 3 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "comments", "and", "some", "minor", "aesthetic", "cleanup", "(", "varnames", "etc", ")"], "add_tokens": "\" \" c , err := NewBufferedClient ( l . LocalAddr ( ) . String ( ) , tt . Prefix , 10 * time . Millisecond , 100 ) c , err := NewBufferedClient ( l . LocalAddr ( ) . String ( ) , \" \" , 10 * time . Millisecond , 1024 )", "del_tokens": "c , err := NewBufferedClient ( l . LocalAddr ( ) . String ( ) , tt . Prefix , 100 , 10 ) c , err := NewBufferedClient ( l . LocalAddr ( ) . String ( ) , \" \" , 1024 , 10 )", "commit_type": "add"}
{"commit_tokens": ["Adds", "/", "commit", "routeto", "router", "."], "add_tokens": "for s := 0 ; s < shards ; s ++ {", "del_tokens": "for s := 1 ; s <= shards ; s ++ {", "commit_type": "add"}
{"commit_tokens": ["Adding", "slice", "and", "jsonArray", "template", "functions"], "add_tokens": "\" \" : typeconv . Bool , func TestJSONArrayTemplates ( t * testing . T ) { ty := new ( TypeConv ) g := & Gomplate { funcMap : template . FuncMap { \" \" : ty . JSONArray , } , } assert . Equal ( t , \" \" , testTemplate ( g , `{{jsonArray \"[\\\"foo\\\",\\\"bar\\\"]\"}}` ) ) assert . Equal ( t , \" \" , testTemplate ( g , `{{ index (jsonArray \"[\\\"foo\\\",\\\"bar\\\"]\") 1 }}` ) ) } func TestSliceTemplates ( t * testing . T ) { typeconv := & TypeConv { } g := & Gomplate { funcMap : template . FuncMap { \" \" : typeconv . Slice , } , } assert . Equal ( t , \" \" , testTemplate ( g , `{{index (slice \"foo\") 0}}` ) ) assert . Equal ( t , `[foo bar 42]` , testTemplate ( g , `{{slice \"foo\" \"bar\" 42}}` ) ) assert . Equal ( t , `helloworld` , testTemplate ( g , `{{range slice \"hello\" \"world\"}}{{.}}{{end}}` ) ) }", "del_tokens": "env := & Env { } \" \" : env . Getenv , \" \" : typeconv . Bool ,", "commit_type": "add"}
{"commit_tokens": ["fix", "potential", "memory", "leak", "with", "time", ".", "After"], "add_tokens": "// so that we can stop the timer and not leak // see: https://groups.google.com/d/topic/golang-nuts/A597Btr_0P8/discussion timer := time . NewTimer ( 10 * time . Second ) case <- timer . C : timer . Stop ( )", "del_tokens": "case <- time . After ( 10 * time . Second ) :", "commit_type": "fix"}
{"commit_tokens": ["Added", "stats", "counters", "to", "both", "client", "and", "server"], "add_tokens": "\" \" // Connection statistics. // // The stats doesn't reset automatically. Feel free resetting it // any time you wish. Stats ConnStats dialChan := make ( chan struct { } ) close ( dialChan ) atomic . AddUint64 ( & c . Stats . DialCalls , 1 ) w = & writerCounter { W : w , BytesWritten : & c . Stats . BytesWritten , WriteCalls : & c . Stats . WriteCalls , } r = & readerCounter { R : r , BytesRead : & c . Stats . BytesRead , ReadCalls : & c . Stats . ReadCalls , }", "del_tokens": "dialChan := make ( chan struct { } , 1 ) dialChan <- struct { } { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "usage", "title", "when", "flagset", "name", "is", "empty"], "add_tokens": "if f . name == \" \" { fmt . Fprintf ( f . out ( ) , \" \\n \" ) } else { fmt . Fprintf ( f . out ( ) , \" \\n \" , f . name ) }", "del_tokens": "fmt . Fprintf ( f . out ( ) , \" \\n \" , f . name )", "commit_type": "fix"}
{"commit_tokens": ["Add", "coverage", "for", "bad", "hostnames", "and", "cancellation"], "add_tokens": "\" \" func Test_Influx_RejectsBadHostnames ( t * testing . T ) { t . Parallel ( ) _ , err := influx . NewClient ( \" \" ) if err == nil { t . Error ( \" \" ) } } func Test_Influx_MakesRequestsToQueryEndpoint ( t * testing . T ) { func Test_Influx_CancelsInFlightRequests ( t * testing . T ) { t . Parallel ( ) started := false finished := false ts := httptest . NewServer ( http . HandlerFunc ( func ( rw http . ResponseWriter , r * http . Request ) { started = true time . Sleep ( 2 * time . Second ) finished = true } ) ) defer func ( ) { ts . CloseClientConnections ( ) ts . Close ( ) } ( ) series , _ := influx . NewClient ( ts . URL ) ctx , cancel := context . WithCancel ( context . Background ( ) ) go func ( ) { _ , _ = series . Query ( ctx , \" \" ) } ( ) cancel ( ) if started != true && finished != false { t . Errorf ( \" \" , started , finished ) } }", "del_tokens": "func Test_MakesRequestsToQueryEndpoint ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "all", "old", "structs", "and", "simplify", "As", "-", "methods"], "add_tokens": "for key , value := range obj . Map {", "del_tokens": "for key , value := range obj . Map ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "fix", "to", "handle", "empty", "bodies"], "add_tokens": "if size != 0 { r . Body = & retryableRequestBody { body : body } r . GetBody = func ( ) ( io . ReadCloser , error ) { _ , err := body . Seek ( 0 , io . SeekStart ) if err != nil { return nil , err } return r . Body , nil } } else { // in case the body is an empty stream, we need to use http.NoBody to explicitly provide no content r . Body = http . NoBody r . GetBody = func ( ) ( io . ReadCloser , error ) { return http . NoBody , nil } // close the user-provided empty body if c , ok := body . ( io . Closer ) ; ok { c . Close ( ) if r . Body != nil && r . Body != http . NoBody { if r . Body != nil && r . Body != http . NoBody {", "del_tokens": "r . Body = & retryableRequestBody { body : body } r . GetBody = func ( ) ( io . ReadCloser , error ) { _ , err := body . Seek ( 0 , io . SeekStart ) if err != nil { return nil , err return r . Body , nil if r . Body != nil { if r . Body != nil {", "commit_type": "add"}
{"commit_tokens": ["Fix", "reflection", "of", "unexported", "fields"], "add_tokens": "if field . IsNil ( ) || ! field . CanInterface ( ) {", "del_tokens": "if field . IsNil ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "cache", "for", "Lookup", "too", "."], "add_tokens": "// Ensure that our cache of children has been initialized. if err := d . initChildren ( ctx ) ; err != nil { log . Println ( \" \" , err ) // Find the object within the map. if n , ok := d . children [ name ] ; ok { return n , nil", "del_tokens": "// Join the directory's prefix with this node's name to get the full name // that we expect to see in GCS (minus the slash that will be on it if it's a // prefix representing a directory). fullName := path . Join ( d . objectPrefix , name ) // We must determine whether this is a file or a directory. List objects // whose names start with fullName. // // HACK(jacobsa): As of 2015-02-05 the documentation here doesn't guarantee // that object listing results are ordered by object name: // // https://cloud.google.com/storage/docs/json_api/v1/objects/list // // Therefore in theory we are not guaranteed to see the object name on the // first page of results. It is reasonable to assume however that the results // are in order. Still, even if that is the case, we may have trouble with // directories since there are characters before '/' that could be in a path // name. Perhaps we should be sending a separate request for fullName plus // the slash, as much as it pains me to do so. query := & storage . Query { Delimiter : string ( dirSeparator ) , Prefix : fullName , } objects , err := d . bucket . ListObjects ( ctx , query ) if err != nil { log . Println ( \" \" , err ) // Is there a matching file name? for _ , o := range objects . Results { if o . Name == fullName { node := & file { bucket : d . bucket , objectName : o . Name , } return node , nil } } // Is there a matching directory name? for _ , p := range objects . Prefixes { if p == fullName + \" \" { node := & dir { bucket : d . bucket , objectPrefix : p , } return node , nil }", "commit_type": "use"}
{"commit_tokens": ["fix", "bug", "in", "TrimTrailingSpaces", ":", "should", "eveluate", "element", "0"], "add_tokens": "for i := len ( p ) - 1 ; i >= 0 ; i -- {", "del_tokens": "for i := len ( p ) - 1 ; i > 0 ; i -- {", "commit_type": "fix"}
{"commit_tokens": ["Make", "Request", ".", "SanitizedPath", "a", "function"], "add_tokens": "sanitizedPath string } func ( r * Request ) SanitizedPath ( ) string { return r . sanitizedPath", "del_tokens": "SanitizedPath string", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "bool", "in", "specs"], "add_tokens": "return \" \" case reflect . Bool : boolValue , err := strconv . ParseBool ( value ) if err != nil { return nil } f . SetBool ( boolValue )", "del_tokens": "return \" \"", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "ghosts", "and", "kill", "everything"], "add_tokens": "/ * if err := system . ParentDeathSignal ( ) ; err != nil { return fmt . Errorf ( \" \" , err ) }", "del_tokens": "/ * this is commented out so that we get the current Ghost functionality if err := system . ParentDeathSignal ( ) ; err != nil { return fmt . Errorf ( \" \" , err ) }", "commit_type": "remove"}
{"commit_tokens": ["Add", "basic", "rate", "limiting", "measures"], "add_tokens": "\" \" type emitJS struct { Id int `json:\"id\"` Data interface { } `json:\"data\"` } var emitPool = & sync . Pool { New : func ( ) interface { } { return emitJS { } } } //A thread-safe variant of EmitJSON func ( c * Client ) EmitJSON ( v interface { } ) error { c . connLock . Lock ( ) defer c . connLock . Unlock ( ) js := emitPool . Get ( ) . ( emitJS ) defer emitPool . Put ( js ) js . Id = - 1 js . Data = v return c . conn . WriteJSON ( js ) } throttle := time . NewTicker ( time . Millisecond * 10 ) defer throttle . Stop ( ) <- throttle . C if mtype != ws . TextMessage { c . conn . Close ( ) return } if err := json . Unmarshal ( data , & js ) ; err != nil {", "del_tokens": "err = json . Unmarshal ( data , & js ) if err != nil || mtype != ws . TextMessage { log . Println ( err )", "commit_type": "add"}
{"commit_tokens": ["fix", "S3", "with", "empty", "directories"], "add_tokens": "opts . Config . Region = aws . String ( region ) opts . Config . DisableRestProtocolURICleaning = aws . Bool ( true )", "del_tokens": "Config : aws . Config { Region : aws . String ( region ) , } , Region : aws . String ( region ) ,", "commit_type": "fix"}
{"commit_tokens": ["removed", "unnecessary", "filepath", ".", "Clean"], "add_tokens": "name , err = filepath . Abs ( name )", "del_tokens": "name , err = filepath . Abs ( filepath . Clean ( name ) )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "Close", "methods", "on", "several", "objects"], "add_tokens": "real net . PacketConn mu sync . Mutex unusedReads chan read closed bool s . raw . mu . Lock ( ) defer s . raw . mu . Unlock ( ) if s . raw . closed { return } return close ( s . closing ) s . raw . Close ( ) s . pc . Close ( ) s . event . Broadcast ( ) func ( me * packetConn ) Close ( ) ( err error ) { me . mu . Lock ( ) defer me . mu . Unlock ( ) if me . closed { return } close ( me . unusedReads ) me . closed = true", "del_tokens": "real net . PacketConn unusedReads chan read close ( s . closing ) err = s . pc . Close ( ) func ( s * packetConn ) Close ( ) ( err error ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "pflag", "support", "to", "LoadArgsEnv"], "add_tokens": "fs := & flagSet { flag . NewFlagSet ( \" \" , flag . ExitOnError ) } fs := & flagSet { flag . NewFlagSet ( \" \" , flag . ExitOnError ) }", "del_tokens": "fs := flag . NewFlagSet ( \" \" , flag . ExitOnError ) fs := flag . NewFlagSet ( \" \" , flag . ExitOnError )", "commit_type": "add"}
{"commit_tokens": ["Fix", "labels", "in", "Categorization", "()", "for", "lists", "+", "tests"], "add_tokens": "uri := catUri ( \" \" , labels )", "del_tokens": "uri := fmt . Sprintf ( urls [ \" \" ] , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Improves", "internal", "docs", "for", "myself", "to", "remember", "faster", "some", "made", "assumptions", "."], "add_tokens": "// by iterating the text file. This strategy makes it exponentially // easier to bind to slices or arrays. For the future myself looking at this code, // trust me, I tried first the other strategy and got stuck on that. For other // contributors, I'm happy to discuss more if you ask me. fmt . Printf ( \" \\n \" , destKey , value ) fmt . Printf ( \" \\n \" , key ) // The reason we have to keep track of seen indexes is because entries // with the same prefix are actually objects, they are decoded into Go // structs, meaning that they only need one pass to be decoded. // In a VMX entry, an index is the prefix, before the first dot, minus the // attribute involved as declared in the given Go tag by the user. // // Examples: // - In ethernet1.addressType the index is 1. // - In scsi0:0.filename the index is 0:0 // - In usb:1.deviceType the index is :1 func getVMXPropIndex ( vmxKey , goTag string ) string { // trimming the attribute's name returns 1.present in the case of ethernet1.present, // 0:0.filename for scsi0:0.filename, or :1.present for usb:1.present attr := strings . TrimPrefix ( vmxKey , goTag )", "del_tokens": "// by iterating the text file. This is strategy makes it exponentially // easier to bind to slices or arrays. Trust me, I tried first the other // strategy and got stuck on that. I'm happy to discuss more if you ask me //fmt.Printf(\"%s => %s\\n\", destKey, value) //fmt.Printf(\"Decode slice tagged as: %s\\n\", key) func getVMXPropIndex ( vmxKey , goKey string ) string { // range for scsci devices: scsi0:0 to scsi3:15 // // ethernet1.pciSlotNumber // scsi0:0.filename // scsi1:0.filename // scsi1:1.filename // usb:1.present = \"TRUE\" // usb:1.deviceType = \"hub\" // trimming the prefix returns 1.present in the case of ethernet1.present, // for instance. attr := strings . TrimPrefix ( vmxKey , goKey )", "commit_type": "improve"}
{"commit_tokens": ["use", "default", "resolver", "if", "confifured", "dns", "server", "is", "not", "reachable"], "add_tokens": "func getIPByDefaultResolver ( domain string ) ( string , error ) { addrs , err := net . DefaultResolver . LookupHost ( context . Background ( ) , domain ) if nil == err && len ( addrs ) > 0 { return addrs [ 0 ] , nil } return \" \" , err } if nil != LocalDNS { ips , err := LocalDNS . LookupA ( domain ) if len ( ips ) > 0 { return pickIP ( ips ) , err return getIPByDefaultResolver ( domain )", "del_tokens": "if nil == LocalDNS { addrs , err := net . DefaultResolver . LookupHost ( context . Background ( ) , domain ) if nil == err && len ( addrs ) > 0 { return addrs [ 0 ] , nil return \" \" , err } ips , err := LocalDNS . LookupA ( domain ) if len ( ips ) > 0 { return pickIP ( ips ) , err return \" \" , err", "commit_type": "use"}
{"commit_tokens": ["Adding", "support", "for", "struct", "tags"], "add_tokens": "var fieldName string alt := typeOfSpec . Field ( i ) . Tag . Get ( \" \" ) if alt != \" \" { fieldName = alt } else { fieldName = typeOfSpec . Field ( i ) . Name }", "del_tokens": "fieldName := typeOfSpec . Field ( i ) . Name", "commit_type": "add"}
{"commit_tokens": ["Add", "soap", ".", "Client", ".", "URL", "method"], "add_tokens": "err = login ( c . Client , u , sc )", "del_tokens": "u url . URL u : u , err = login ( c . Client , c . u , sc )", "commit_type": "add"}
{"commit_tokens": ["Removing", "creation", "of", "multiple", "temp", "directories", "on", "download"], "add_tokens": "return Download ( url , GetTempDir ( ) ) } func GetTempDir ( ) string { tempGaugeDir := filepath . Join ( os . TempDir ( ) , \" \" ) if ! exists ( tempGaugeDir ) { os . MkdirAll ( tempGaugeDir , NewDirectoryPermissions ) return tempGaugeDir } func exists ( path string ) bool { if _ , err := os . Stat ( path ) ; os . IsNotExist ( err ) { return false } return true if resp . StatusCode == 404 {", "del_tokens": "tempDir , err := CreateEmptyTempDir ( ) if err != nil { return \" \" , err return Download ( url , tempDir ) if resp . StatusCode != 200 {", "commit_type": "remove"}
{"commit_tokens": ["Add", "java", "default", "hash", "implementation", "of", "a", "ServerSelector", "for", "memcache"], "add_tokens": "type writeType string const ( toWrite writeType = \" \" ) next . ServeHTTPC ( context . WithValue ( ctx , toWrite , [ ] byte ( r . Header . Get ( \" \" ) ) ) , rw , r ) errors . PanicIfErrWrite ( rw . Write ( ctx . Value ( toWrite ) . ( [ ] byte ) ) )", "del_tokens": "next . ServeHTTPC ( context . WithValue ( ctx , \" \" , [ ] byte ( r . Header . Get ( \" \" ) ) ) , rw , r ) errors . PanicIfErrWrite ( rw . Write ( ctx . Value ( \" \" ) . ( [ ] byte ) ) )", "commit_type": "add"}
{"commit_tokens": ["use", "the", "tree", "for", "normal", "CLI", "get", "too"], "add_tokens": "raw , ok := c . commandTree . Get ( c . Subcommand ( ) ) command , err := raw . ( CommandFactory ) ( )", "del_tokens": "commandFunc , ok := c . Commands [ c . Subcommand ( ) ] command , err := commandFunc ( )", "commit_type": "use"}
{"commit_tokens": ["add", "io", ".", "EOF", "error", "to", "reader"], "add_tokens": "\" \" if err != io . EOF {", "del_tokens": "if err != nil {", "commit_type": "add"}
{"commit_tokens": ["Fix", "online", "expoentially", "weighted", "variance", "calculation"], "add_tokens": "v := ( x - e . m1 ) e . v = ( 1 - e . alpha ) * ( v * v ) + e . alpha * e . v", "del_tokens": "e . v = ( 1 - e . alpha ) * ( x - e . m1 ) + e . alpha * e . v", "commit_type": "fix"}
{"commit_tokens": ["added", "explicit", "casting", "the", "interface", "to", "int64", "+", "convert", "int64", "to", "int"], "add_tokens": "status , err := redis . Int64 ( deleteScript . Do ( conn , m . name , value ) ) return err == nil && status != 0 status , err := redis . Int64 ( touchScript . Do ( conn , m . name , value , expiry ) ) return err == nil && status != 0", "del_tokens": "status , err := deleteScript . Do ( conn , m . name , value ) return err == nil && status != int64 ( 0 ) status , err := touchScript . Do ( conn , m . name , value , expiry ) return err == nil && status != int64 ( 0 )", "commit_type": "add"}
{"commit_tokens": ["updates", "to", "be", "more", "consistant", "with", "naming", "conventions"], "add_tokens": "\" \" func Deserialize ( r io . Reader ) ( * Histogram , error ) { func ( h * Histogram ) Serialize ( w io . Writer ) error { h . Serialize ( buf ) // UnmarshalJSON - histogram will come in a base64 encoded serialized form func ( h * Histogram ) UnmarshalJSON ( b [ ] byte ) error { var s string if err := json . Unmarshal ( b , & s ) ; err != nil { return err } data , err := base64 . StdEncoding . DecodeString ( s ) if err != nil { return err } h , err = Deserialize ( bytes . NewBuffer ( data ) ) return err } func ( h * Histogram ) MarshalJSON ( ) ( [ ] byte , error ) { buf := bytes . NewBuffer ( [ ] byte { } ) err := h . SerializeB64 ( buf ) if err != nil { return buf . Bytes ( ) , err } return json . Marshal ( buf . String ( ) ) }", "del_tokens": "func DeserializeRaw ( r io . Reader ) ( * Histogram , error ) { func ( h * Histogram ) SerializeRaw ( w io . Writer ) error { h . SerializeRaw ( buf )", "commit_type": "update"}
{"commit_tokens": ["Fix", "the", "setup", "for", "no", "-", "TLS", "case", "."], "add_tokens": "var conn * rpc . ClientConn if useTLS { creds , err := credentials . NewClientTLSFromFile ( tlsDir + \" \" , \" \" ) if err != nil { log . Fatalf ( \" \" , err ) } conn , err = rpc . Dial ( addr , rpc . WithClientTLS ( creds ) ) } else { conn , err = rpc . Dial ( addr ) log . Fatalf ( \" \" , addr , err ) s , mc := setUp ( false , math . MaxUint32 )", "del_tokens": "creds , err := credentials . NewClientTLSFromFile ( tlsDir + \" \" , \" \" ) if err != nil { log . Fatalf ( \" \" , err ) conn , err := rpc . Dial ( addr , rpc . WithClientTLS ( creds ) ) log . Fatalf ( \" \" , conn , err ) s , mc := setUp ( true , math . MaxUint32 )", "commit_type": "fix"}
{"commit_tokens": ["Make", "all", "ints", "come", "out", "as", "int64", "and", "all", "floats", "as", "float64"], "add_tokens": "In most cases the driver will return the data from neo as the proper go - specific types . For integers they always come back as int64 and floats always come back as float64 . This is for the convenience of the user and acts similarly to go 's JSON interface . This prevents the user from having to use reflection to get these values . Internally , the types are always transmitted over the wire with as few bytes as possible .", "del_tokens": "In most cases the driver will return the data from neo as the proper go - specific types . These types are very specific and will be returned with the minimum amount of bytes necessary , as this is how they are encoded in the driver . For example , if you sent a number that 's an integer but it has a value of '1' , it will come back as an int8 , as that 's the lowest number of bytes that need to be sent over the line . The user is expected to cast them as necessary .", "commit_type": "make"}
{"commit_tokens": ["use", "disjunction", "for", "closed", "test", "in", "SetDeadline"], "add_tokens": "if s . closedRemote || s . isClosed ( ) {", "del_tokens": "if s . closedRemote && s . isClosed ( ) {", "commit_type": "use"}
{"commit_tokens": ["Adding", "a", "duration", "to", "a", "frozen", "Mock", "updates", "the", "Now", "()"], "add_tokens": "if c . frozen { c . setAt = c . setAt . Add ( d ) } else { c . setAt = time . Now ( ) }", "del_tokens": "c . setAt = time . Now ( )", "commit_type": "add"}
{"commit_tokens": ["Made", "consumer", ".", "Commit", "*", "()", "blocking"], "add_tokens": "_ , err = c . Commit ( ) if err != nil && err . ( KafkaError ) . Code ( ) != ERR__NO_OFFSET { t . Errorf ( \" \" , err )", "del_tokens": "err = c . Commit ( true ) if err != nil { t . Errorf ( \" \" , err ) } err = c . Commit ( false ) if err == nil { t . Errorf ( \" \" ) } else { t . Logf ( \" \" , err )", "commit_type": "make"}
{"commit_tokens": ["Add", "fallback", "detection", "of", "VCS", "by", "existence", "of", "dot", "-", "directory", "(", "e", ".", "g", ".", ".", "git", ")"], "add_tokens": "var repo , err = glockRepoRootForImportPath ( importPath )", "del_tokens": "var repo , err = repoRootForImportPath ( importPath )", "commit_type": "add"}
{"commit_tokens": ["change", "markupwriter", "print", "function", "to", "write"], "add_tokens": "// Write returns a stringed repesentation of the markup object func ( m * MarkupWriter ) Write ( ma Markup ) ( string , error ) {", "del_tokens": "// Print returns a stringed repesentation of the markup object func ( m * MarkupWriter ) Print ( ma Markup ) ( string , error ) {", "commit_type": "change"}
{"commit_tokens": ["Updated", "downloadCmd", "for", "git", "to", "also", "fetch", "tags", "."], "add_tokens": "downloadCmd : \" \" ,", "del_tokens": "downloadCmd : \" \" ,", "commit_type": "update"}
{"commit_tokens": ["use", "exact", "field", "names", "instead"], "add_tokens": "Secret : _client . Attribute ( s . clientSecretAttr . fieldName ) . ( [ ] byte ) , RedirectURIs : [ ] string { _client . Attribute ( s . clientCallableAttr . fieldName ) . ( string ) } , err := bcrypt . CompareHashAndPassword ( model . Attribute ( s . ownerSecretAttr . fieldName ) . ( [ ] byte ) , [ ] byte ( secret ) )", "del_tokens": "// TODO: We shouldn't use Attribute() as the field might be hidden. Secret : _client . Attribute ( s . clientSecretAttr . jsonName ) . ( [ ] byte ) , RedirectURIs : [ ] string { _client . Attribute ( s . clientCallableAttr . jsonName ) . ( string ) } , err := bcrypt . CompareHashAndPassword ( model . Attribute ( s . ownerSecretAttr . jsonName ) . ( [ ] byte ) , [ ] byte ( secret ) )", "commit_type": "use"}
{"commit_tokens": ["fix", "bare", "force", "record", "case"], "add_tokens": "if len ( args ) == 0 { cmd . printUsage ( ) } else { switch args [ 0 ] { case \" \" : runRecordGet ( args [ 1 : ] ) case \" \" : runRecordCreate ( args [ 1 : ] ) case \" \" : runRecordUpdate ( args [ 1 : ] ) case \" \" : runRecordDelete ( args [ 1 : ] ) default : ErrorAndExit ( \" \" , args [ 0 ] ) }", "del_tokens": "switch args [ 0 ] { case \" \" : runRecordGet ( args [ 1 : ] ) case \" \" : runRecordCreate ( args [ 1 : ] ) case \" \" : runRecordUpdate ( args [ 1 : ] ) case \" \" : runRecordDelete ( args [ 1 : ] ) default : ErrorAndExit ( \" \" , args [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "executors", "shape", "to", "NodeResponse"], "add_tokens": "Actions [ ] interface { } `json:\"actions\"` DisplayName string `json:\"displayName\"` Executors [ ] struct { CurrentExecutable struct { Number int `json:\"number\"` URL string `json:\"url\"` SubBuilds [ ] struct { Abort bool `json:\"abort\"` Build interface { } `json:\"build\"` BuildNumber int `json:\"buildNumber\"` Duration string `json:\"duration\"` Icon string `json:\"icon\"` JobName string `json:\"jobName\"` ParentBuildNumber int `json:\"parentBuildNumber\"` ParentJobName string `json:\"parentJobName\"` PhaseName string `json:\"phaseName\"` Result string `json:\"result\"` Retry bool `json:\"retry\"` URL string `json:\"url\"` } `json:\"subBuilds\"` } `json:\"currentExecutable\"` } `json:\"executors\"` Icon string `json:\"icon\"` IconClassName string `json:\"iconClassName\"` Idle bool `json:\"idle\"` JnlpAgent bool `json:\"jnlpAgent\"` LaunchSupported bool `json:\"launchSupported\"` LoadStatistics struct { } `json:\"loadStatistics\"` ManualLaunchAllowed bool `json:\"manualLaunchAllowed\"`", "del_tokens": "Actions [ ] interface { } `json:\"actions\"` DisplayName string `json:\"displayName\"` Executors [ ] struct { } `json:\"executors\"` Icon string `json:\"icon\"` IconClassName string `json:\"iconClassName\"` Idle bool `json:\"idle\"` JnlpAgent bool `json:\"jnlpAgent\"` LaunchSupported bool `json:\"launchSupported\"` LoadStatistics struct { } `json:\"loadStatistics\"` ManualLaunchAllowed bool `json:\"manualLaunchAllowed\"`", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "chains", "in", "ListenAndServeTLS"], "add_tokens": "certs := SplitPEM ( cert_bytes ) if len ( certs ) == 0 { return nil , fmt . Errorf ( \" \" , cert_file ) } first , certs := certs [ 0 ] , certs [ 1 : ] cert , err := LoadCertificateFromPEM ( first ) for _ , pem := range certs { cert , err := LoadCertificateFromPEM ( pem ) if err != nil { return nil , err } err = ctx . AddChainCertificate ( cert ) if err != nil { return nil , err } }", "del_tokens": "cert , err := LoadCertificateFromPEM ( cert_bytes )", "commit_type": "add"}
{"commit_tokens": ["Changed", "repositories", ".", "UpdateComment", "to", "use", "a", "struct", "."], "add_tokens": "Body * string `json:\"body\"` // User-initialized fields func ( s * RepositoriesService ) UpdateComment ( owner , repo string , id int , comment * RepositoryComment ) ( * RepositoryComment , * Response , error ) { req , err := s . client . NewRequest ( \" \" , u , comment )", "del_tokens": "Body * string `json:\"body\"` func ( s * RepositoriesService ) UpdateComment ( owner , repo string , id int , body string ) ( * RepositoryComment , * Response , error ) { comment := RepositoryComment { Body : String ( body ) } req , err := s . client . NewRequest ( \" \" , u , & comment )", "commit_type": "change"}
{"commit_tokens": ["removed", "self", "from", "the", "functions"], "add_tokens": "func ( h * ChannelHandler ) SetChannel ( channel LogPartsChannel ) { h . channel = channel func ( h * ChannelHandler ) Handle ( logParts syslogparser . LogParts , messageLength int64 , err error ) { h . channel <- logParts", "del_tokens": "func ( self * ChannelHandler ) SetChannel ( channel LogPartsChannel ) { self . channel = channel func ( self * ChannelHandler ) Handle ( logParts syslogparser . LogParts , messageLength int64 , err error ) { self . channel <- logParts", "commit_type": "remove"}
{"commit_tokens": ["added", "json", "config", "to", "greenhouse"], "add_tokens": "\" \" \" \" b , err := ioutil . ReadFile ( \" \" ) if err != nil { panic ( err ) } cfg := & gogadgets . Config { } err = json . Unmarshal ( b , cfg ) a := gogadgets . NewApp ( cfg ) stop := make ( chan bool ) a . Start ( stop )", "del_tokens": "var ( cfg := & gogadgets . Config { gogadgets . GadgetConfig { gogadgets . GadgetConfig { Location : \" \" , Name : \" \" , Pin : gogadgets . Pin { Type : \" \" , OneWireId : \" \" , Units : \" \" , } , } , } , gogadgets . GadgetConfig { gogadgets . GadgetConfig { Location : \" \" , Name : \" \" , Pin : gogadgets . Pin { Type : \" \" , OneWireId : \" \" , Units : \" \" , } , } , } , } ) a := gogadgets . App { } fmt . Println ( a )", "commit_type": "add"}
{"commit_tokens": ["fix", "bufio", ".", "Reader", ".", "Read", "not", "read", "full", "buffer"], "add_tokens": "if _ , err := io . ReadFull ( c . Reader , buf ) ; err != nil {", "del_tokens": "if _ , err := c . Reader . Read ( buf ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "ability", "to", "customize", "the", "connection", "timeout"], "add_tokens": "func connect ( host , user , passwd string , timeout time . Duration ) ( net . Conn , error ) { c , err := net . DialTimeout ( \" \" , addr , timeout ) // DialTimeout is the time limit for establishing a connection. A // DialTimeout of zero means no timeout. DialTimeout time . Duration c , err := connect ( host , o . User , o . Password , o . DialTimeout )", "del_tokens": "func connect ( host , user , passwd string ) ( net . Conn , error ) { c , err := net . Dial ( \" \" , addr ) c , err := connect ( host , o . User , o . Password )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "crash", "if", "a", "non", "-", "pointer", "is", "given", "to", "Decode"], "add_tokens": "\" \" val := reflect . ValueOf ( out ) if val . Kind ( ) != reflect . Ptr { return errors . New ( \" \" ) } return d . decode ( \" \" , n , val . Elem ( ) )", "del_tokens": "return d . decode ( \" \" , n , reflect . ValueOf ( out ) . Elem ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "VersionPrinter", "and", "tests", "."], "add_tokens": "\" \" func TestAppVersionPrinter ( t * testing . T ) { oldPrinter := cli . VersionPrinter defer func ( ) { cli . VersionPrinter = oldPrinter } ( ) var wasCalled = false cli . VersionPrinter = func ( c * cli . Context ) { wasCalled = true } app := cli . NewApp ( ) ctx := cli . NewContext ( app , nil , nil ) cli . ShowVersion ( ctx ) if wasCalled == false { t . Errorf ( \" \" ) } }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "a", "bit", "and", "fix", "examples"], "add_tokens": "articleID := chi . URLParam ( r , \" \" ) w . Write ( [ ] byte ( fmt . Sprintf ( \" \" , chi . URLParam ( r , \" \" ) ) ) )", "del_tokens": "articleID := chi . URLParam ( r . Context ( ) , \" \" ) w . Write ( [ ] byte ( fmt . Sprintf ( \" \" , chi . URLParam ( r . Context ( ) , \" \" ) ) ) )", "commit_type": "update"}
{"commit_tokens": ["add", "and", "use", "a", "deduplicating", "source"], "add_tokens": "endpointsSource := source . NewDedupSource ( source . NewMultiSource ( sources ) ) Source : endpointsSource ,", "del_tokens": "multiSource := source . NewMultiSource ( sources ) Source : multiSource ,", "commit_type": "add"}
{"commit_tokens": ["Add", "square", "brackets", "around", "error", "string", "for", "Errors"], "add_tokens": "assert . Equal ( t , \" \" + \" \" , errs . Error ( ) )", "del_tokens": "assert . Equal ( t , \" \" + \" \" , errs . Error ( ) )", "commit_type": "add"}
{"commit_tokens": ["Using", "constant", "values", "for", "Content", "-", "Type"], "add_tokens": "c . Writer . Header ( ) . Set ( \" \" , MIMEJSON ) c . Writer . Header ( ) . Set ( \" \" , MIMEXML ) c . Writer . Header ( ) . Set ( \" \" , MIMEHTML ) c . Writer . Header ( ) . Set ( \" \" , MIMEPlain )", "del_tokens": "c . Writer . Header ( ) . Set ( \" \" , \" \" ) c . Writer . Header ( ) . Set ( \" \" , \" \" ) c . Writer . Header ( ) . Set ( \" \" , \" \" ) c . Writer . Header ( ) . Set ( \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Move", "the", "build", "command", "into", "the", "actual", "build", "command"], "add_tokens": "import ( \" \" \" \" ) func ( Command ) Run ( env packer . Environment , args [ ] string ) int { if len ( args ) != 1 { // TODO: Error message return 1 } // Read the file into a byte array so that we can parse the template tplData , err := ioutil . ReadFile ( args [ 0 ] ) if err != nil { // TODO: Error message return 1 } // Parse the template into a machine-usable format _ , err = packer . ParseTemplate ( tplData ) if err != nil { // TODO: error message return 1 } // Go through each builder and compile the builds that we care about //builds := make([]Build, 0, len(tpl.Builders)) //for name, rawConfig := range tpl.Builders { //builder := env.Builder(name, rawConfig) //build := env.Build(name, builder) //builds = append(builds, build) //}", "del_tokens": "import \" \" func ( Command ) Run ( env packer . Environment , arg [ ] string ) int { env . Ui ( ) . Say ( \" \" )", "commit_type": "move"}
{"commit_tokens": ["Added", "tests", "for", "Gob", "Encode", "and", "Decode", "and", "fixed", "a", "related", "bug"], "add_tokens": "import ( \" \" \" \" \" \" \" \" ) // Ensures that Buckets can be serialized and deserialized without errors. func TestBucketsGob ( t * testing . T ) { b := NewBuckets ( 5 , 2 ) for i := 0 ; i < 5 ; i ++ { b . Increment ( uint ( i ) , 1 ) } var buf bytes . Buffer if err := gob . NewEncoder ( & buf ) . Encode ( b ) ; err != nil { t . Error ( err ) } b2 := NewBuckets ( 5 , 2 ) if err := gob . NewDecoder ( & buf ) . Decode ( b2 ) ; err != nil { t . Error ( err ) } if diff , equal := messagediff . PrettyDiff ( b , b2 ) ; ! equal { t . Errorf ( \" \\n \" , b2 , b , diff ) } }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "mon_command", "input", "buffer"], "add_tokens": "return c . monCommand ( args , nil ) } // MonCommand sends a command to one of the monitors, with an input buffer func ( c * Conn ) MonCommandWithInputBuffer ( args , inputBuffer [ ] byte ) ( buffer [ ] byte , info string , err error ) { return c . monCommand ( args , inputBuffer ) } func ( c * Conn ) monCommand ( args , inputBuffer [ ] byte ) ( buffer [ ] byte , info string , err error ) { inbuf := C . CString ( string ( inputBuffer ) ) inbufLen := len ( inputBuffer ) inbuf , // bulk input (e.g. crush map) C . size_t ( inbufLen ) , // length inbuf & outbuf , // buffer & outbuflen , // buffer length & outs , // status string", "del_tokens": "inbuf := C . CString ( \" \" ) inbuf , // bulk input (e.g. crush map) C . size_t ( 0 ) , // length inbuf & outbuf , // buffer & outbuflen , // buffer length & outs , // status string", "commit_type": "add"}
{"commit_tokens": ["Updating", "the", "basic", "push", "notification", "."], "add_tokens": "payload = NewPayload ( )", "del_tokens": "payload = new ( Payload )", "commit_type": "update"}
{"commit_tokens": ["Added", "some", "better", "comments", "removed", "old", "todos"], "add_tokens": "connStr : connStr , timeout : time . Second * time . Duration ( 60 ) ,", "del_tokens": "// TODO: TLS Support connStr : connStr , // TODO: Test best default // Default to 10 second timeout timeout : time . Second * time . Duration ( 60 ) , // TODO: Test best default. // TODO: Try RESET on failures?", "commit_type": "add"}
{"commit_tokens": ["Fix", "encoding", "of", "Win32", "file", "times"], "add_tokens": "return fmt . Sprintf ( \" \" , uint64 ( ft . LowDateTime ) + ( uint64 ( ft . HighDateTime ) << 32 ) ) , time . Unix ( 0 , ft . Nanoseconds ( ) )", "del_tokens": "return fmt . Sprintf ( \" \" , uint64 ( ft . LowDateTime ) + ( uint64 ( ft . HighDateTime ) << 32 ) ) , time . Unix ( 0 , ft . Nanoseconds ( ) )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", "in", "gpio", "heater"], "add_tokens": "if h . started { h . target = 0.0 h . status = false h . io <- & Value { Value : false } }", "del_tokens": "h . target = 0.0 h . status = false h . io <- & Value { Value : false }", "commit_type": "fix"}
{"commit_tokens": ["Added", "stage", "and", "screen", "to", "camera", "coord", "projection"], "add_tokens": "Zoom float32 Position * Vector Direction * Vector Up * Vector Projection * Matrix View * Matrix Combined * Matrix InvProjectionView * Matrix ViewportWidth float32 ViewportHeight float32 camera . InvProjectionView = NewMatrix ( ) c . InvProjectionView . Set ( c . Combined ) . Inv ( ) } func ( c * Camera ) Unproject ( vec * Vector ) { viewportWidth := float32 ( Width ( ) ) viewportHeight := float32 ( Height ( ) ) x := vec . X y := vec . Y y = viewportHeight - y - 1 vec . X = ( 2 * x ) / viewportWidth - 1 vec . Y = ( 2 * y ) / viewportHeight - 1 vec . Z = 2 * vec . Z - 1 vec . Prj ( c . InvProjectionView )", "del_tokens": "Zoom float32 Position * Vector Direction * Vector Up * Vector Projection * Matrix View * Matrix Combined * Matrix ViewportWidth float32 ViewportHeight float32 camera . Position . X = width / 2 camera . Position . Y = height / 2 camera . Update ( )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "deadlock", "in", "handlePacketizerFailure"], "add_tokens": "// NOTE: The logging implementation can be anything. In particular, it // might try to send logs over this transport, which would take the mutex // again. We *must not* call this while we hold the lock. (Yes, we figured // this out by deadlocking ourselves :p) t . log . TransportError ( err )", "del_tokens": "t . log . TransportError ( err )", "commit_type": "fix"}
{"commit_tokens": ["Make", "including", "VlAPIVersion", "in", "generated", "file", "as", "opt", "-", "in"], "add_tokens": "var ( inputFile = flag . String ( \" \" , \" \" , \" \" ) inputDir = flag . String ( \" \" , \" \" , \" \" ) outputDir = flag . String ( \" \" , \" \" , \" \" ) includeAPIVer = flag . Bool ( \" \" , false , \" \" ) ) vlAPIVersion := rootNode . Map ( \" \" ) . Get ( ) if * includeAPIVer { fmt . Fprintln ( w , \" \" ) fmt . Fprintln ( w , \" \" , vlAPIVersion ) fmt . Fprintln ( w )", "del_tokens": "inputFile := flag . String ( \" \" , \" \" , \" \" ) inputDir := flag . String ( \" \" , \" \" , \" \" ) outputDir := flag . String ( \" \" , \" \" , \" \" ) fmt . Fprintln ( w , \" \" ) vlAPIVersion := rootNode . Map ( \" \" ) if vlAPIVersion != nil { fmt . Fprintln ( w , \" \" , vlAPIVersion . Get ( ) ) fmt . Fprintln ( w )", "commit_type": "make"}
{"commit_tokens": ["add", "keys", "fix", "response", "without", "write", "header"], "add_tokens": "if ! nw . wroteHeader { nw . beforeWriteHeader ( ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "NewSubStatter", "method", "to", "Client", "(", "s", ")", "which", "returns", "a", "SubStatter"], "add_tokens": "type StatSender interface { } type Statter interface { StatSender NewSubStatter ( string ) SubStatter type SubStatter interface { StatSender NewSubStatter ( string ) SubStatter } // Returns a SubStatter with appended prefix func ( s * Client ) NewSubStatter ( prefix string ) SubStatter { var c * Client if s != nil { c = & Client { prefix : s . prefix + \" \" + prefix , sender : s . sender , } } return c }", "del_tokens": "type Statter interface {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "last", "-", "second", "negative", "logic", "change"], "add_tokens": "if RetryOnRateLimit {", "del_tokens": "if ! RetryOnRateLimit {", "commit_type": "fix"}
{"commit_tokens": ["move", "heavy", "ops", "out", "and", "fix", "once"], "add_tokens": "close ( s . die ) once = true } ) if once { return s . conn . Close ( )", "del_tokens": "var err error err = s . conn . Close ( ) close ( s . die ) } ) if once { return err", "commit_type": "move"}
{"commit_tokens": ["Remove", "previou", "commit", ".", "Replaced", "with", "better", "alternative", "."], "add_tokens": "var token string", "del_tokens": "var token string = \" \" / * * NOTE : FIXME XAPID - 629 * The following function is just a temporary hack for analytics plugin to * consume this function to get the bearer token . In the future there will * have to be a common plugin , that shall provide such info . * / type Export struct { } func ( c Export ) GetCurrentToken ( ) string { return token }", "commit_type": "remove"}
{"commit_tokens": ["Add", "timestamp", "for", "updates", "as", "well", "."], "add_tokens": "req . Header . Set ( \" \" , time . Now ( ) . Format ( time . RFC3339 ) ) req . Header . Set ( \" \" , time . Now ( ) . Format ( time . RFC3339 ) )", "del_tokens": "req . Header . Set ( \" \" , time . Now ( ) . Format ( time . RFC3339 ) )", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "AscendLessThan", "and", "fix", "function"], "add_tokens": "if ! iterator ( h . Item ) { return false }", "del_tokens": "if ! iterator ( h . Item ) { return false }", "commit_type": "add"}
{"commit_tokens": ["move", "flagutil", "to", "cliutil", "add", "cli", "/", "cmdutil"], "add_tokens": "\" \" ErrorFlagDefined1 = errutil . ErrorFactory ( \" \" ) if _ , ok := flags [ cliflag . Name ] ; ok { panic ( ErrorFlagDefined1 . New ( nil , cliflag . Name ) ) if _ , ok := flags [ cliflag . Name ] ; ok { panic ( ErrorFlagDefined1 . New ( nil , cliflag . Name ) ) if _ , ok := flags [ cliflag . Name ] ; ok { panic ( ErrorFlagDefined1 . New ( nil , cliflag . Name ) )", "del_tokens": "\" \" var ( ok bool ) if _ , ok = flags [ cliflag . Name ] ; ok { panic ( fmt . Errorf ( \" \" , cliflag . Name ) ) var ( ok bool ) if _ , ok = flags [ cliflag . Name ] ; ok { panic ( fmt . Errorf ( \" \" , cliflag . Name ) ) var ( ok bool ) if _ , ok = flags [ cliflag . Name ] ; ok { panic ( fmt . Errorf ( \" \" , cliflag . Name ) )", "commit_type": "move"}
{"commit_tokens": ["remove", "unnecessary", "rlocks", "from", "col", ".", "ForAll"], "add_tokens": "col . syncDocUpdate . RLock ( ) col . syncDocUpdate . RUnlock ( )", "del_tokens": "col . syncDocUpdate . RLock ( ) col . syncDocUpdate . RUnlock ( ) col . syncDocUpdate . RUnlock ( ) col . syncDocUpdate . RUnlock ( )", "commit_type": "remove"}
{"commit_tokens": ["Use", "lowercase", "field", "names", "in", "JSON", "codec"], "add_tokens": "\" \" JsonCodec r := NewRecord ( \" \" , LOG_INFO , \" \" , map [ string ] string { } ) m , err := s . EncodeRecord ( r ) c . Assert ( err , IsNil ) // The names of these fields are a direct copy of the fields used by the Ruby // version of steno to prevent breaking the prettifiers. Some of these fields // can be changed (e.g. `process_id` -> `pid`, `log_level` -> `level), but // only as long as the prettifiers are also updated. fields := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , } for _ , f := range fields { c . Check ( string ( m ) , Matches , fmt . Sprintf ( `{.*\"%s\":.*}` , f ) ) }", "del_tokens": "record := NewRecord ( \" \" , LOG_INFO , \" \" , map [ string ] string { } ) codec := NewJsonCodec ( ) msg , _ := codec . EncodeRecord ( record ) c . Assert ( string ( msg ) , Matches , `{.*\"Message\":\"Hello world\".*}` )", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "automatically", "sorting", "each", "CSV", "by", "the", "join", "columns", "prior", "to", "the", "join", "."], "add_tokens": "// A Join can be used to construct a process that will join two streams of CSV records by matching // records from each stream on the specified key columns.", "del_tokens": "// A process that can perform an outer join between the elements of two CSV streams.", "commit_type": "add"}
{"commit_tokens": ["Change", "nullable", "GithubUser", "strings", "to", "interface", "{}", "to", "avoid", "json", "exception"], "add_tokens": "UserEmail interface { } `json:\"email\"` UserName interface { } `json:\"name\"` UserAvatar interface { } `json:\"avatar_url\"` func ( u * GitHubUser ) Link ( ) string { return u . UserLink } if u . UserName == nil { return \" \" } return u . UserName . ( string ) if u . UserEmail == nil { return \" \" } return u . UserEmail . ( string ) if u . UserAvatar == nil { return \" \" } return u . UserAvatar . ( string )", "del_tokens": "// GitHubUser represents a GitHub user object returned by the OAuth2 service. UserEmail string `json:\"email\"` UserAvatar string `json:\"avatar_url\"` UserName string `json:\"name\"` return u . UserName return u . UserEmail return u . UserAvatar func ( u * GitHubUser ) Link ( ) string { return u . UserLink }", "commit_type": "change"}
{"commit_tokens": ["Fixed", "Copy", "input", "types", "updated", "Reader", "/", "Writer", "to", "use", "Copy"], "add_tokens": "r , w := io . Pipe ( ) Copy ( w , reader ) r , w := io . Pipe ( ) Copy ( w , reader ) r , w := io . Pipe ( ) go Copy ( writer , r ) r , w := io . Pipe ( ) Copy ( writer , r )", "del_tokens": "r , w := Pipe ( ) io . Copy ( w , reader ) r , w := Pipe ( ) io . Copy ( w , reader ) r , w := Pipe ( ) go io . Copy ( writer , r ) r , w := Pipe ( ) io . Copy ( writer , r )", "commit_type": "fix"}
{"commit_tokens": ["fix", "fwd", "/", "bck", "search"], "add_tokens": "if len ( item ) >= start { item = item [ : start ] if start < 0 { start = 0 } if len ( item ) - 1 >= start { item = item [ start : ]", "del_tokens": "if len ( item ) < start { continue item = item [ : start ] if len ( item ) - 1 < start { continue item = item [ start : ]", "commit_type": "fix"}
{"commit_tokens": ["Make", "file", "serving", "actually", "work", "."], "add_tokens": "\" \" if f , err := fs . Open ( file ) ; err != nil { http . Error ( w , err . Error ( ) , 500 ) log . Print ( err ) return } else { io . Copy ( w , f ) }", "del_tokens": "http . StripPrefix ( \" \" , http . FileServer ( http . Dir ( commitPath ) ) ) . ServeHTTP ( w , r )", "commit_type": "make"}
{"commit_tokens": ["use", "Self", "method", "to", "obtain", "link", "url"], "add_tokens": "Self : ctx . Request . Self ( ) , Self : ctx . Request . Self ( ) , Self : ctx . Request . Self ( ) + \" \" + ctx . Model . ID ( ) . Hex ( ) , Self : ctx . Request . Self ( ) ,", "del_tokens": "Self : r . endpoint . prefix + \" \" + r . Model . Meta ( ) . PluralName , Self : r . endpoint . prefix + \" \" + r . Model . Meta ( ) . PluralName + \" \" + ctx . Model . ID ( ) . Hex ( ) , Self : r . endpoint . prefix + \" \" + r . Model . Meta ( ) . PluralName + \" \" + ctx . Model . ID ( ) . Hex ( ) , Self : r . endpoint . prefix + \" \" + r . Model . Meta ( ) . PluralName + \" \" + ctx . Model . ID ( ) . Hex ( ) ,", "commit_type": "use"}
{"commit_tokens": ["Make", "Context", "even", "more", "lazy", "and", "add", "convenience", "functions"], "add_tokens": "store map [ string ] interface { } if c . store == nil { return nil } func ( c * Context ) Delete ( key string ) { if c . store == nil { return } delete ( c . store , key ) } func ( c * Context ) Exists ( key string ) bool { if c . store == nil { return false } _ , exists := c . store [ key ] return exists } c . store = make ( map [ string ] interface { } )", "del_tokens": "store storage c . assureStorage ( ) c . store = make ( storage ) type storage map [ string ] interface { }", "commit_type": "make"}
{"commit_tokens": ["Change", "SetTLSConfig", "to", "exported", "RegisterTLSConfig", "and", "add", "documentation"], "add_tokens": "var tlsConfigMap map [ string ] * tls . Config // Registers a custom tls.Config to be used with sql.Open. // Use the key as a value in the DSN where tls=value. // // rootCertPool := x509.NewCertPool() // { // pem, err := ioutil.ReadFile(\"/path/ca-cert.pem\") // if err != nil { // log.Fatal(err) // } // if ok := rootCAs.AppendCertsFromPEM(pem); !ok { // log.Fatal(\"Failed to append PEM.\") // } // } // clientCert := make([]tls.Certificate, 0, 1) // { // certs, err := tls.LoadX509KeyPair(\"/path/client-cert.pem\", \"/path/client-key.pem\") // if err != nil { // log.Fatal(err) // } // clientCert = append(clientCerts, certs) // } // mysql.RegisterTLSConfig(\"custom\", tls.Config{ // RootCAs: rootCertPool, // Certificates: clientCert, // }) // db, err := sql.Open(\"mysql\", \"user@tcp(localhost:3306)/test?tls=custom\") // func RegisterTLSConfig ( key string , config * tls . Config ) { if tlsConfigMap == nil { tlsConfigMap = make ( map [ string ] * tls . Config ) } tlsConfigMap [ key ] = config } // Removes tls.Config associated with key. func DeregisterTLSConfig ( key string ) { if tlsConfigMap == nil { return } delete ( tlsConfigMap , key ) } cfg . tls = tlsConfig", "del_tokens": "cfg . tls = & tls . Config { } * cfg . tls = * tlsConfig", "commit_type": "change"}
{"commit_tokens": ["Added", "full", "path", "matching", "to", "the", "router", "match", "component"], "add_tokens": "if leaf . matchesFullPath && leaf . match ( wildcardValues ) {", "del_tokens": "if leaf . matchesFullPath { _ = \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "GoEvtxMap", ".", "UserID", "+", "Test", "+", "doc"], "add_tokens": "//log.InitLogger(log.LDebug) / * func TestMonitorChunks ( t * testing . T ) { } * / func TestUserID ( t * testing . T ) { files , err := ioutil . ReadDir ( testfilesDir ) if err != nil { panic ( err ) } for _ , fi := range files { fullpath := filepath . Join ( testfilesDir , fi . Name ( ) ) ef , _ := evtx . New ( fullpath ) for e := range ef . FastEvents ( ) { if uid , ok := e . UserID ( ) ; ok { if uid == \" \" { t . Log ( string ( evtx . ToJSON ( e ) ) ) } t . Log ( uid ) } } } }", "del_tokens": "log . InitLogger ( log . LDebug ) func TestMonitorChunks ( t * testing . T ) { }", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "seed", "argument", "from", "Sample", "()"], "add_tokens": "seed int64 t . seed = time . Now ( ) . Unix ( ) t . randGenerator = rand . New ( rand . NewSource ( t . seed ) ) // Seed returns the seed used for the random number generator that controls timing func ( t Ticker ) Seed ( ) int64 { return t . seed } // point within each specified sampleInterval. All samples still take place at baseInterval // and offset specified during construction. Turn off sampling by specifying a zero // duration interval. func ( t * Ticker ) Sample ( sampleInterval time . Duration ) {", "del_tokens": "// point within each specified sampleInterval. (The seed controls the randomness.) // all samples still take place at baseInterval and offset specified during construction. // Turn off sampling by specifying a zero duration interval. func ( t * Ticker ) Sample ( sampleInterval time . Duration , seed int64 ) { t . randGenerator = rand . New ( rand . NewSource ( seed ) )", "commit_type": "remove"}
{"commit_tokens": ["Added", "Push", "OSSCallback", "rewrote", "DM", "SMS"], "add_tokens": "err := client . SendBatchMail ( & SendBatchMailArgs { SendEmailArgs : SendEmailArgs { AccountName : accountName , AddressType : \" \" } , TemplateName : templateName , ReceiverName : receiverName } ) err := client . SendSingleMail ( & SendSingleMailArgs { SendEmailArgs : SendEmailArgs { AccountName : accountName , AddressType : \" \" } , ReplyToAddress : replyToAddress , ToAddress : toAddress } )", "del_tokens": "err := client . SendBatchMail ( accountName , \" \" , templateName , receiverName , \" \" ) err := client . SendSingleMail ( accountName , replyToAddress , \" \" , toAddress , \" \" , \" \" , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Adding", "some", "advanced", "selectors", "and", "remove", "duplicate", "one"], "add_tokens": "\" \" , \" \" ,", "del_tokens": "\" \\\" \\\" \" ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "type", "for", "bundle", "id"], "add_tokens": "Id string `json:\"id,omitempty\"`", "del_tokens": "Id int `json:\"id,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["Adds", "compatibility", "with", "latest", "go", "-", "imap"], "add_tokens": "// Client is an IDLE client. c * client . Client // NewClient creates a new client. func NewClient ( c * client . Client ) * Client { return & Client { c } } // Idle indicates to the server that the client is ready to receive unsolicited Writer : c . c . Writer ( ) , if status , err := c . c . Execute ( cmd , res ) ; err != nil { } else { return status . Err ( ) // SupportIdle checks if the server supports the IDLE extension. func ( c * Client ) SupportIdle ( ) ( bool , error ) { return c . c . Support ( Capability )", "del_tokens": "client * client . Client // Indicate to the server that the client is ready to receive unsolicited Writer : c . client . Writer ( ) , status , err := c . client . Execute ( cmd , res ) if err != nil { return status . Err ( ) // SupportsIdle returns true if the server supports the IDLE extension. func ( c * Client ) SupportsIdle ( ) bool { return c . client . Caps [ Capability ] } // Create a new client. func NewClient ( c * client . Client ) * Client { return & Client { client : c }", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "argument", "from", "AddFontFromReader"], "add_tokens": "f . AddFontFromReader ( familyStr , styleStr , file ) // AddFontFromReader imports a TrueType, OpenType or Type1 font and makes it // available using a reader that satisifies the io.Reader interface. See // AddFont for details about familyStr and styleStr. func ( f * Fpdf ) AddFontFromReader ( familyStr , styleStr string , r io . Reader ) {", "del_tokens": "f . AddFontFromReader ( familyStr , styleStr , fileStr , file ) func ( f * Fpdf ) AddFontFromReader ( familyStr , styleStr , fileStr string , r io . Reader ) { if fileStr == \" \" { fileStr = strings . Replace ( familyStr , \" \" , \" \" , - 1 ) + strings . ToLower ( styleStr ) + \" \" } // dbg(\"fontkey [%s]\", fontkey) // dbg(\"fontkey found; returning\") // dbg(\"font [%s], I [%d]\", fileStr, info.I)", "commit_type": "remove"}
{"commit_tokens": ["moves", "loads", "and", "analysis", "into", "their", "own", "packages"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Add", "required", "instance", "details", "in", "serviceToInstance"], "add_tokens": "\" \" HostName : node . Address , return fmt . Sprintf ( \" \" , node . Address , node . Id ) // set instance ID instance . SetMetadataString ( \" \" , node . Id )", "del_tokens": "return node . Id", "commit_type": "add"}
{"commit_tokens": ["remove", "defer", "keyword", "to", "avoid", "overhead"], "add_tokens": "evicted = c . lru . Add ( key , value ) c . lock . Unlock ( ) return evicted value , ok = c . lru . Get ( key ) c . lock . Unlock ( ) return value , ok containKey := c . lru . Contains ( key ) c . lock . RUnlock ( ) return containKey value , ok = c . lru . Peek ( key ) c . lock . RUnlock ( ) return value , ok keys := c . lru . Keys ( ) c . lock . RUnlock ( ) return keys length := c . lru . Len ( ) c . lock . RUnlock ( ) return length", "del_tokens": "defer c . lock . Unlock ( ) return c . lru . Add ( key , value ) defer c . lock . Unlock ( ) return c . lru . Get ( key ) defer c . lock . RUnlock ( ) return c . lru . Contains ( key ) defer c . lock . RUnlock ( ) return c . lru . Peek ( key ) defer c . lock . RUnlock ( ) return c . lru . Keys ( ) defer c . lock . RUnlock ( ) return c . lru . Len ( )", "commit_type": "remove"}
{"commit_tokens": ["use", "Chat", ".", "type", "in", "<message", "/", ">", "s", "type", "attr", "in", "Send", "()"], "add_tokens": "fmt . Fprintf ( c . tls , \" \" + xmlEscape ( chat . Remote ) , xmlEscape ( chat . Type ) , xmlEscape ( chat . Text ) )", "del_tokens": "fmt . Fprintf ( c . tls , \" \" + xmlEscape ( chat . Remote ) , xmlEscape ( chat . Text ) )", "commit_type": "use"}
{"commit_tokens": ["using", "time", ".", "After", "instead", "of", "a", "separate", "goroutine"], "add_tokens": "case <- time . After ( client . TimeOut ) :", "del_tokens": "timeout := make ( chan bool ) defer close ( timeout ) go func ( ) { defer common . DisablePanic ( ) time . Sleep ( client . TimeOut ) timeout <- true } ( ) case <- timeout :", "commit_type": "use"}
{"commit_tokens": ["fix", "golint", "warning", "by", "just", "returning", "err", "returned", "by", "rows", ".", "Close"], "add_tokens": "// make sure we always close rows, even if there is a scan error return rows . Close ( )", "del_tokens": "// make sure we always close rows if err := rows . Close ( ) ; err != nil { return err } return nil", "commit_type": "fix"}
{"commit_tokens": ["Adding", "ability", "to", "attach", "node", "meta", "data"], "add_tokens": "Meta [ ] byte // Node meta data Meta : a . Meta , a := alive { Incarnation : inc , Node : state . Name , Addr : state . Addr , Meta : state . Meta } a := alive { Incarnation : inc , Node : state . Name , Addr : state . Addr , Meta : state . Meta } a := alive { Incarnation : r . Incarnation , Node : r . Name , Addr : r . Addr , Meta : r . Meta }", "del_tokens": "a := alive { Incarnation : inc , Node : state . Name , Addr : state . Addr } a := alive { Incarnation : inc , Node : state . Name , Addr : state . Addr } a := alive { Incarnation : r . Incarnation , Node : r . Name , Addr : r . Addr }", "commit_type": "add"}
{"commit_tokens": ["Use", "Configure", "to", "check", "for", "conflicts"], "add_tokens": "if rl . rotationCount > 0 && d > 0 { return errors . New ( \" \" ) } if rl . maxAge > 0 && n > 0 { return errors . New ( \" \" ) }", "del_tokens": "if rl . maxAge > 0 && rl . rotationCount > 0 { return errors . New ( \" \" ) }", "commit_type": "use"}
{"commit_tokens": ["fixed", "quick", "stop", "task", "."], "add_tokens": "var ( downUrl = req . GetUrl ( ) sp = self . Spider ) if sp . IsStopping ( ) { if sp . DoHistory ( req , false ) { var ctx = self . Downloader . Download ( sp , req ) // download page if sp . DoHistory ( req , false ) { sp . DoHistory ( req , true )", "del_tokens": "var downUrl = req . GetUrl ( ) if activeStop , _ := err . ( string ) ; activeStop == spider . ACTIVE_STOP { if self . Spider . DoHistory ( req , false ) { var ctx = self . Downloader . Download ( self . Spider , req ) // download page if self . Spider . DoHistory ( req , false ) { self . Spider . DoHistory ( req , true )", "commit_type": "fix"}
{"commit_tokens": ["add", "inclusive", "flag", "for", "scan"], "add_tokens": "//if inclusive is true, scan range [key, inf) else (key, inf) func ( db * DB ) Scan ( key [ ] byte , count int , inclusive bool ) ( [ ] KVPair , error ) { rangeType := leveldb . RangeROpen if ! inclusive { rangeType = leveldb . RangeOpen } it := db . db . Iterator ( minKey , maxKey , rangeType , 0 , count )", "del_tokens": "func ( db * DB ) Scan ( key [ ] byte , count int ) ( [ ] KVPair , error ) { it := db . db . Iterator ( minKey , maxKey , leveldb . RangeROpen , 0 , count )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "StringSlice", "issues", "for", "postgres"], "add_tokens": "v := make ( [ ] string , len ( ss ) ) v [ i ] = `\"` + strings . Replace ( strings . Replace ( s , `\\` , `\\\\\\` , - 1 ) , `\"` , `\\\"` , - 1 ) + `\"` return \" \" + strings . Join ( v , \" \" ) + \" \" , nil", "del_tokens": "ss [ i ] = `\"` + strings . Replace ( strings . Replace ( s , `\\` , `\\\\\\` , - 1 ) , `\"` , `\\\"` , - 1 ) + `\"` return \" \" + strings . Join ( ss , \" \" ) + \" \" , nil", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "track", "reads", "and", "writes", "while", "copying"], "add_tokens": "\" \" return BidiCopyWithTracking ( out , in , bufOut , bufIn , func ( int ) { } , func ( int ) { } ) } // BidiCopyWithTracking is like BidiCopy but tracks reads and writes via callbacks func BidiCopyWithTracking ( out net . Conn , in net . Conn , bufOut [ ] byte , bufIn [ ] byte , onOut func ( int ) , onIn func ( int ) ) ( outErr error , inErr error ) { go doCopy ( out , in , bufIn , outErrCh , & stop , onOut ) go doCopy ( in , out , bufOut , inErrCh , & stop , onIn ) func doCopy ( dst net . Conn , src net . Conn , buf [ ] byte , errCh chan error , stop * uint32 , cb func ( int ) ) { err = errors . New ( \" \\n \" , p , string ( debug . Stack ( ) ) ) cb ( nw )", "del_tokens": "go doCopy ( out , in , bufIn , outErrCh , & stop ) go doCopy ( in , out , bufOut , inErrCh , & stop ) func doCopy ( dst net . Conn , src net . Conn , buf [ ] byte , errCh chan error , stop * uint32 ) { err = errors . New ( \" \" , p )", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "of", "the", "format", "argument"], "add_tokens": "t . Errorf ( \" \" , tt . mtu , tt . head , tt . chunk , ok , tt . ok )", "del_tokens": "t . Errorf ( \" \" , tt . mtu , tt . head , tt . chunk , ok , tt . ok )", "commit_type": "fix"}
{"commit_tokens": ["improved", "the", "way", "chalk", "works"], "add_tokens": "type Chalk struct { * sync . WaitGroup Tasks chan Handler Errors chan error } func New ( size int ) * Chalk { c := Chalk { WaitGroup : & sync . WaitGroup { } , Tasks : make ( chan Handler ) , Errors : make ( chan error ) , } c . Add ( 1 ) for f := range c . Tasks { c . Errors <- err c . Done ( ) return & c", "del_tokens": "func New ( size int ) ( chan Handler , chan error ) { tasks := make ( chan Handler ) errors := make ( chan error ) wg := sync . WaitGroup { } wg . Add ( 1 ) for f := range tasks { errors <- err wg . Done ( ) return tasks , errors", "commit_type": "improve"}
{"commit_tokens": ["Added", "reference", "to", "parent", "structs"], "add_tokens": "func Validate ( obj interface { } , parents ... string ) error { err := Validate ( fieldValue , field . Name ) if len ( parents ) > 0 { return errors . New ( \" \" + field . Name + \" \" + parents [ 0 ] ) } else { return errors . New ( \" \" + field . Name ) }", "del_tokens": "func Validate ( obj interface { } ) error { err := Validate ( fieldValue ) return errors . New ( \" \" + field . Name )", "commit_type": "add"}
{"commit_tokens": ["Adds", "String", "method", "for", "Link"], "add_tokens": "func TestLinksMethods ( t * testing . T ) { func TestParseMultiple ( t * testing . T ) { func TestLinkToString ( t * testing . T ) { l := Link { URL : \" \" , Rel : \" \" , } have := l . String ( ) want := \" \\\" \\\" \" if have != want { t . Errorf ( \" \" , want , have ) } parsed := Parse ( have ) if len ( parsed ) != 1 { t . Errorf ( \" \" ) } if parsed [ 0 ] . URL != l . URL { t . Errorf ( \" \" , parsed [ 0 ] . URL ) } if parsed [ 0 ] . Rel != l . Rel { t . Errorf ( \" \" , parsed [ 0 ] . Rel ) } }", "del_tokens": "func testLinksMethods ( t * testing . T ) { func testParseMultiple ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "complication", "with", "msg", "in", "Keyvals", "()", "method", "."], "add_tokens": "keyvals = append ( keyvals , \" \" , e . msg )", "del_tokens": "if e . msg != \" \" { keyvals = append ( keyvals , \" \" , e . msg ) } else { keyvals = append ( keyvals , \" \" , \" \" ) }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "typo", "match", "fd0", "not", "fdd0"], "add_tokens": "ignoredDevices = flag . String ( \" \" , \" \\\\ \" , \" \" )", "del_tokens": "ignoredDevices = flag . String ( \" \" , \" \\\\ \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "algorithm", "of", "RotateHue"], "add_tokens": "geoMat := ebiten . ScaleGeometry ( float64 ( fieldWidth ) / float64 ( emptyWidth ) , float64 ( fieldHeight ) / float64 ( emptyHeight ) ) colorMat := ebiten . ScaleColor ( color . RGBA { 0 , 0 , 0 , 0x80 } )", "del_tokens": "geoMat := ebiten . GeometryMatrixI ( ) geoMat . Concat ( ebiten . ScaleGeometry ( float64 ( fieldWidth ) / float64 ( emptyWidth ) , float64 ( fieldHeight ) / float64 ( emptyHeight ) ) ) colorMat := ebiten . ColorMatrixI ( ) colorMat . Concat ( ebiten . ScaleColor ( color . RGBA { 0 , 0 , 0 , 0x80 } ) )", "commit_type": "change"}
{"commit_tokens": ["fix", "flag", ".", "Value", "support"], "add_tokens": "var flagValueType = reflect . TypeOf ( ( * flag . Value ) ( nil ) ) . Elem ( ) case reflect . Interface : if ! sf . Type . Implements ( flagValueType ) { o . errorf ( \" \" , sf . Name ) return o } o . addOptArg ( sf , val ) case * flag . Value : fvalue := * addr flagset . Var ( fvalue , opt . name , \" \" ) flagset . Var ( fvalue , opt . shortName , \" \" )", "del_tokens": "case flag . Value : flagset . Var ( addr , opt . name , \" \" ) flagset . Var ( addr , opt . shortName , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "original", "GetEvents", "()", "API", "."], "add_tokens": "func TestEventIterator ( t * testing . T ) { ei := mg . NewEventIterator ( ) err := ei . GetFirstPage ( mailgun . GetEventsOptions { } ) events := ei . Events ( ) // We're on the first page. We must at the beginning. ei . GetPrevious ( ) if len ( ei . Events ( ) ) != 0 { t . Fatal ( \" \" )", "del_tokens": "func TestGetEvents ( t * testing . T ) { events , links , err := mg . GetEvents ( mailgun . GetEventsOptions { } ) // Print out the types of links provided in case more pages of data exist. // For brevity, links are truncated. fmt . Fprintln ( tw , \" \\t \\t \" ) for k , v := range links { if len ( v ) > 48 { v = fmt . Sprintf ( \" \" , v [ 0 : 48 ] ) } fmt . Fprintf ( tw , \" \\t \\t \\n \" , k , v ) tw . Flush ( ) fmt . Printf ( \" \\n \\n \" , len ( links ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "to", "expose", "io", ".", "ReadWriteClose", "on", "requests"], "add_tokens": "type writerCloseTracker struct { io . ReadWriteCloser sp opentracing . Span } func ( c writerCloseTracker ) Close ( ) error { err := c . ReadWriteCloser . Close ( ) c . sp . LogFields ( log . String ( \" \" , \" \" ) ) c . sp . Finish ( ) return err } readWriteCloser , ok := resp . Body . ( io . ReadWriteCloser ) if ok { resp . Body = writerCloseTracker { readWriteCloser , tracer . sp } } else { resp . Body = closeTracker { resp . Body , tracer . sp } }", "del_tokens": "resp . Body = closeTracker { resp . Body , tracer . sp }", "commit_type": "add"}
{"commit_tokens": ["Added", "MaxReadAhead", "to", "options", "to", "allow", "larger", "reads"], "add_tokens": "//fuse.AllowOther(), fuse . MaxReadahead ( 64 * 1024 ) ,", "del_tokens": "fuse . AllowOther ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "bunch", "of", "error", "cases", "for", "the", "parser", "and", "some", "tests"], "add_tokens": "return EOF return EOF , nil", "del_tokens": "return ILLEGAL return ILLEGAL , nil", "commit_type": "add"}
{"commit_tokens": ["Add", "sse2", "vertical", "scaler", "for", "6", "8", "10", "and", "12", "-", "taps"], "add_tokens": "if taps > 12 {", "del_tokens": "if taps > 4 {", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "go", "-", "libp2p", "-", "gostream"], "add_tokens": "conn , err := gostream . Dial ( r . Context ( ) , rt . h , peer . ID ( pid ) , rt . opts . Protocol )", "del_tokens": "conn , err := gostream . Dial ( rt . h , peer . ID ( pid ) , rt . opts . Protocol )", "commit_type": "upgrade"}
{"commit_tokens": ["Changing", "string", "concatenation", "in", "scanner", "to", "buffer", "copy"], "add_tokens": "\" \" var tok bytes . Buffer tok . WriteRune ( s . ch ) tok . WriteRune ( s . ch ) return tok . String ( ) , nil", "del_tokens": "tok := string ( s . ch ) tok += string ( s . ch ) return tok , nil", "commit_type": "change"}
{"commit_tokens": ["Fix", "name", "of", "reverse", "unit", "test", "func", "."], "add_tokens": "func TestUnitRegularizeCI ( t * testing . T ) {", "del_tokens": "func TestRegularizeCI ( t * testing . T ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "wildcard", "search", "for", "ID"], "add_tokens": "res . id = append ( res . id , strings . Trim ( part , \" \" ) + \" \" )", "del_tokens": "res . id = append ( res . id , strings . Trim ( part , \" \" ) + \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "short", "hand", "methods", "Get", "/", "Post", "/", "Delete", "and", "update", "doc"], "add_tokens": "// res, _ := facebook.Get(\"/huandu\", nil) // res, _ := facebook.Get(\"/me/feed\", facebook.Params{ // res, _ := session.Get(\"/me/feed\", nil) // res, _ := session.Get(\"/me/feed\", nil) // Get is a short hand of Api(path, GET, params). func Get ( path string , params Params ) ( Result , error ) { return Api ( path , GET , params ) } // Post is a short hand of Api(path, GET, params). func Post ( path string , params Params ) ( Result , error ) { return Api ( path , POST , params ) } // Delete is a short hand of Api(path, GET, params). func Delete ( path string , params Params ) ( Result , error ) { return Api ( path , DELETE , params ) }", "del_tokens": "// You can just use the Api() for most work. // res, _ := facebook.Api(\"/huandu\", facebook.GET, nil) // res, _ := facebook.Api(\"/me/feed\", facebook.GET, facebook.Params{ // res, _ := session.Api(\"/me/feed\", facebook.GET, nil) // res, _ := session.Api(\"/me/feed\", facebook.GET, nil) // // This library doesn't include any HTTP integration. I will do it later.", "commit_type": "add"}
{"commit_tokens": ["make", "the", "internal", "backend", "public"], "add_tokens": "// InternalBackend is the internal implementation for making HTTP calls to Stripe. type InternalBackend struct { HttpClient * http . Client backend = & InternalBackend { GetHttpClient ( ) } func ( s * InternalBackend ) Call ( method , path , token string , body * url . Values , v interface { } ) error { res , err := s . HttpClient . Do ( req )", "del_tokens": "// s is the internal implementation for making HTTP calls to Stripe. type s struct { httpClient * http . Client backend = & s { GetHttpClient ( ) } func ( s * s ) Call ( method , path , token string , body * url . Values , v interface { } ) error { res , err := s . httpClient . Do ( req )", "commit_type": "make"}
{"commit_tokens": ["remove", "GetResult", "methods", "from", "Message", "and", "MessageAttributeValue"], "add_tokens": "message = append ( message , getMessageResult ( & msg ) ) func getMessageResult ( m * app . Message ) * app . ResultMessage { attrs := [ ] * app . ResultMessageAttribute { } for _ , attr := range m . MessageAttributes { attrs = append ( attrs , getMessageAttributeResult ( & attr ) ) } return & app . ResultMessage { MessageId : m . Uuid , Body : m . MessageBody , ReceiptHandle : m . ReceiptHandle , MD5OfBody : common . GetMD5Hash ( string ( m . MessageBody ) ) , MD5OfMessageAttributes : m . MD5OfMessageAttributes , MessageAttributes : attrs , } }", "del_tokens": "message = append ( message , msg . GetResult ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "command", "aliases"], "add_tokens": "init CmdInitializer name string aliases [ ] string desc string aliases := strings . Split ( name , \" \" ) name : aliases [ 0 ] , aliases : aliases , fmt . Fprintf ( w , \" \\t \\n \" , strings . Join ( c . aliases , \" \" ) , c . desc ) if sub . isAlias ( arg ) { if sub . isAlias ( arg ) { if sub . isAlias ( arg ) { func ( c * Cmd ) isAlias ( arg string ) bool { for _ , alias := range c . aliases { if arg == alias { return true } } return false }", "del_tokens": "init CmdInitializer name string desc string name : name , fmt . Fprintf ( w , \" \\t \\n \" , c . name , c . desc ) if arg == sub . name { if arg == sub . name { if arg == sub . name {", "commit_type": "add"}
{"commit_tokens": ["improve", "tests", "and", "direct", "packing", "behavior"], "add_tokens": "next := value . Elem ( ) . Kind ( ) if next == reflect . Struct || next == reflect . Ptr { value = value . Elem ( ) } else { break }", "del_tokens": "value = value . Elem ( )", "commit_type": "improve"}
{"commit_tokens": ["add", "convertible", "check", "to", "LUserData"], "add_tokens": "func Test_udconversion ( t * testing . T ) { L := lua . NewState ( ) defer L . Close ( ) ud := L . NewUserData ( ) ud . Value = \" \" L . SetGlobal ( \" \" , ud ) var out int L . SetGlobal ( \" \" , New ( L , & out ) ) testError ( t , L , `_ = out ^ ud` , \" \" ) } Var func ( L * lua . LState ) lua . LValue { Code : `var` , Var : func ( L * lua . LState ) lua . LValue { ud := L . NewUserData ( ) ud . Value = \" \" return ud } , Expected : string ( \" \" ) , } , if cur . Var != nil { L . SetGlobal ( \" \" , cur . Var ( L ) ) }", "del_tokens": "// TODO: *Userdata", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "latest", "gosrc", "."], "add_tokens": "\" \" \" \"", "del_tokens": "\" \" \" \"", "commit_type": "update"}
{"commit_tokens": ["removed", "some", "unnecessary", "fmt", ".", "Printlns", "and", "added", "some", "error", "passing"], "add_tokens": "func ( u * Updater ) BackgroundRun ( ) error { return err return err return nil if u . DiffURL != \" \" { log . Println ( \" \" , err ) }", "del_tokens": "fmt . Println ( path ) func ( u * Updater ) BackgroundRun ( ) { return log . Println ( err ) log . Println ( \" \" , err ) fmt . Println ( u . ApiURL ) fmt . Println ( plat )", "commit_type": "remove"}
{"commit_tokens": ["fixes", "replacement", "of", "/", "releases", "/", "name", "=", "os", "-", "conf?", "where", "last", "token", "was", "marked", "optional"], "add_tokens": "if isLast { prevUpdate ( append ( typedObj , op . Value ) ) } else { obj = map [ interface { } ] interface { } { typedToken . Key : typedToken . Value } prevUpdate ( append ( typedObj , obj ) ) // no need to change prevUpdate since matching item can only be a map }", "del_tokens": "obj = map [ interface { } ] interface { } { typedToken . Key : typedToken . Value } prevUpdate ( append ( typedObj , obj ) ) // no need to change prevUpdate since matching item can only be a map", "commit_type": "fix"}
{"commit_tokens": ["Use", "full", "path", "for", "/", "usr", "/", "bin", "/", "security"], "add_tokens": "c := exec . Command ( \" \" , args ... ) return \" \" , fmt . Errorf ( \" \" , err ) c := exec . Command ( \" \" , args ... )", "del_tokens": "c := exec . Command ( \" \" , args ... ) return \" \" , fmt . Errorf ( \" \" , err ) c := exec . Command ( \" \" , args ... )", "commit_type": "use"}
{"commit_tokens": ["add", "backoff", "/", "jitter", "to", "rcache"], "add_tokens": "\" \" \" \" r = rand . New ( rand . NewSource ( time . Now ( ) . UnixNano ( ) ) ) func backoff ( attempts int ) time . Duration { if attempts == 0 { return time . Duration ( 0 ) } return time . Duration ( math . Pow ( 10 , float64 ( attempts ) ) ) * time . Millisecond } var a , b int // jitter before starting j := r . Int63n ( 100 ) time . Sleep ( time . Duration ( j ) * time . Millisecond ) d := backoff ( a ) log . Log ( \" \" , err , \" \" , d ) time . Sleep ( d ) a += 1 // reset a a = 0 d := backoff ( b ) log . Log ( \" \" , err , \" \" , d ) time . Sleep ( d ) b += 1 // reset b b = 0", "del_tokens": "log . Log ( \" \" , err ) time . Sleep ( time . Second ) log . Log ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Update", "ToPublicName", "to", "be", "go", "-", "idiomatic"], "add_tokens": "\" \" // ToPublicName returns a go-idiomatic public name return snaker . SnakeToCamel ( name )", "del_tokens": "\" \" if name == \" \" { return \" \" } return strings . ToUpper ( name [ 0 : 1 ] ) + name [ 1 : ]", "commit_type": "update"}
{"commit_tokens": ["added", "apostrophe", "filter", "to", "improve", "turkish", "analyzer"], "add_tokens": "\" \" Config . Analysis . TokenFilters [ \" \" ] = apostrophe_filter . NewApostropheFilter ( ) // register stemmer filters turkishAnalyzer := Config . MustBuildNewAnalyzer ( [ ] string { } , \" \" , [ ] string { \" \" , \" \" , \" \" , \" \" } )", "del_tokens": "turkishAnalyzer := Config . MustBuildNewAnalyzer ( [ ] string { } , \" \" , [ ] string { \" \" , \" \" , \" \" } )", "commit_type": "add"}
{"commit_tokens": ["add", "optional", "now", "key", "to", "grohl", "lines"], "add_tokens": "func BuildLine ( data map [ string ] interface { } , addTime bool ) string { extraRows := 0 if addTime { extraRows = extraRows + 1 delete ( data , \" \" ) } pieces := make ( [ ] string , len ( data ) + extraRows ) pieces [ index + extraRows ] = fmt . Sprintf ( \" \" , key , formatValue ( value ) ) if addTime { pieces [ 0 ] = fmt . Sprintf ( \" \" , time . Now ( ) . UTC ( ) . Format ( timeLayout ) ) } return BuildLine ( dupeMaps ( context , data ) , false )", "del_tokens": "func BuildLine ( data map [ string ] interface { } ) string { pieces := make ( [ ] string , len ( data ) ) pieces [ index ] = fmt . Sprintf ( \" \" , key , formatValue ( value ) ) return BuildLine ( dupeMaps ( context , data ) )", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "writer", "contents"], "add_tokens": "_ , err := f . Write ( [ ] byte ( \" \" ) ) assert . NoError ( t , err ) _ , err = f . Write ( [ ] byte ( \" \" ) ) b , err := c . ReadAll ( \" \" ) assert . NoError ( t , err ) assert . Equal ( t , \" \" , string ( b ) )", "del_tokens": "{ _ , err := f . Write ( [ ] byte ( \" \" ) ) assert . NoError ( t , err ) } _ , err := f . Write ( [ ] byte ( \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["add", "methods", "to", "stream", "encoder", "and", "add", "tests", "update", "readme"], "add_tokens": "// AddArray adds an implementation of MarshalerArray to be encoded, must be used inside a slice or array encoding (does not encode a key)", "del_tokens": "// AddArray adds an array or slice to be encoded, must be used inside a slice or array encoding (does not encode a key)", "commit_type": "add"}
{"commit_tokens": ["use", "OpenFile", "to", "open", "with", "exclusive", "flag"], "add_tokens": "fileCreateFlag = os . O_RDWR | os . O_CREATE | os . O_EXCL responseFile , err := os . OpenFile ( filepath . Join ( path , responseFilename ) , fileCreateFlag , 0666 ) bodyFile , err := os . OpenFile ( filepath . Join ( path , bodyFilename ) , fileCreateFlag , 0666 )", "del_tokens": "responseFile , err := os . Create ( filepath . Join ( path , responseFilename ) ) bodyFile , err := os . Create ( filepath . Join ( path , bodyFilename ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "facebook", "specific", "error", "parsing", "for", "GetProfile"], "add_tokens": "\" \" read , err := ioutil . ReadAll ( resp . Body ) er := new ( Error ) json . Unmarshal ( read , er ) return nil , errors . New ( \" \" + er . Message ) return profile , json . Unmarshal ( read , profile )", "del_tokens": "return nil , errors . New ( \" \" ) decoder := json . NewDecoder ( resp . Body ) return profile , decoder . Decode ( profile )", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "with", "synopsis", "code"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["add", "support", "for", "oauth", "/", "X", "-", "HIPCHAT", "-", "OAUTH2"], "add_tokens": "defaultAuthType = \" \" // or \"oauth\" AuthType string func NewClient ( user , pass , resource , authType string ) ( * Client , error ) { return NewClientWithServerInfo ( user , pass , resource , authType , defaultHost , defaultConf ) func NewClientWithServerInfo ( user , pass , resource , authType , host , conf string ) ( * Client , error ) { AuthType : authType , var errStr string if m == \" \" && c . AuthType == \" \" { } else if m == \" \" && c . AuthType == \" \" { c . connection . Oauth ( c . Password , c . Resource ) // oauth: case \" \" + xmpp . NsSASL : errStr = \" \" case \" \" + xmpp . NsSASL : errStr += \" \" case \" \" + xmpp . NsSASL : errStr += \" \" return errors . New ( errStr ) case \" \" + xmpp . NsSASL : return nil", "del_tokens": "func NewClient ( user , pass , resource string ) ( * Client , error ) { return NewClientWithServerInfo ( user , pass , resource , defaultHost , defaultConf ) func NewClientWithServerInfo ( user , pass , resource , host , conf string ) ( * Client , error ) { if m == \" \" {", "commit_type": "add"}
{"commit_tokens": ["fixed", "default", "history", "limit", "count", "error"], "add_tokens": "if c . HistoryLimit <= 0 {", "del_tokens": "if c . HistoryLimit < 0 {", "commit_type": "fix"}
{"commit_tokens": ["Use", "red", "color", "for", "errors", "in", "tests"], "add_tokens": "return red ( \" \" , r . Title , r . Property , r . Err )", "del_tokens": "return fmt . Sprintf ( \" \" , r . Title , r . Property , r . Err )", "commit_type": "use"}
{"commit_tokens": ["fix", "issue", "with", "secret", "list", "endpoint"], "add_tokens": "uri := fmt . Sprintf ( pathSecrets , c . addr ) err := c . get ( uri , & out )", "del_tokens": "err := c . get ( pathSecrets , & out )", "commit_type": "fix"}
{"commit_tokens": ["Add", "Retries", "to", "Redshift", "Basic", "Emitter"], "add_tokens": "if consecutiveErrorAttempts > 50 { logger . Fatalf ( \" \" ) } if isRecoverableError ( err ) { handleAwsWaitTimeExp ( consecutiveErrorAttempts )", "del_tokens": "\" \" // determine whether the error is recoverable func ( p Pipeline ) isRecoverableError ( err error ) bool { cErr , ok := err . ( * kinesis . Error ) if ok && cErr . Code == \" \" { return true } return false } // handle the aws exponential backoff // http://docs.aws.amazon.com/general/latest/gr/api-retries.html func ( p Pipeline ) handleAwsWaitTimeExp ( attempts int ) { // wait up to 5 minutes based on the aws exponential backoff algorithm logger . Printf ( \" \" ) waitTime := time . Duration ( math . Min ( 100 * math . Pow ( 2 , float64 ( attempts ) ) , 300000 ) ) * time . Millisecond time . Sleep ( waitTime ) } if p . isRecoverableError ( err ) { p . handleAwsWaitTimeExp ( consecutiveErrorAttempts )", "commit_type": "add"}
{"commit_tokens": ["Add", "hooks", "so", "that", "multiple", "calls", "to", "a", "select", "can", "maintain", "scroll", "and", "cursor", "position"], "add_tokens": "// Run executes the select list. It displays the label and the list of items, asking the user to chose any return s . RunCursorAt ( 0 , 0 ) } // RunCursorAt executes the select list, initializing the cursor to the given // position. Invalid cursor positions will be clamped to valid values. It // displays the label and the list of items, asking the user to chose any value // within to list. Run will keep the prompt alive until it has been canceled // from the command prompt or it has received a valid value. It will return // the value and an error if any occurred during the select's execution. func ( s * Select ) RunCursorAt ( cursorPos , scroll int ) ( int , string , error ) { return s . innerRun ( cursorPos , scroll , ' ' ) func ( s * Select ) innerRun ( cursorPos , scroll int , top rune ) ( int , string , error ) { s . list . SetCursor ( cursorPos ) s . list . SetStart ( scroll ) // ScrollPosition returns the current scroll position. func ( s * Select ) ScrollPosition ( ) int { return s . list . Start ( ) } selected , value , err := s . innerRun ( 1 , 0 , '+' )", "del_tokens": "// Run executes the select list. Its displays the label and the list of items, asking the user to chose any return s . innerRun ( 0 , ' ' ) func ( s * Select ) innerRun ( starting int , top rune ) ( int , string , error ) { selected , value , err := s . innerRun ( 1 , '+' )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typo", "in", "usage", ".", "go"], "add_tokens": "// Usagef writes usage information to the specified io.Writer using the specified template specification", "del_tokens": "// Usagef writes usage information to the specified io.Writer using the specifed template specification", "commit_type": "fix"}
{"commit_tokens": ["add", "update", "zone", "record", "method"], "add_tokens": "Id int64 Name string Ttl int64 Type string Value string Zone int64 `goptions:\"-z, --zone, obligatory, description='Zone id'\"` Version int64 `goptions:\"-v, --version, obligatory, description='Zone version'\"` Name string `goptions:\"-n, --name, obligatory, description='Record name. Relative name, may contain leading wildcard. @ for empty name'\"` Type string `goptions:\"-t, --type, obligatory, description='Record type'\"` Value string `goptions:\"-V, --value, obligatory, description='Value for record. Semantics depends on the record type.'\"` Ttl int64 `goptions:\"-T, --ttl, description='Time to live, in seconds, between 5 minutes and 30 days'\"` type RecordUpdate struct { Zone int64 `goptions:\"-z, --zone, obligatory, description='Zone id'\"` Version int64 `goptions:\"-v, --version, obligatory, description='Zone version'\"` Name string `goptions:\"-n, --name, obligatory, description='Record name. Relative name, may contain leading wildcard. @ for empty name'\"` Type string `goptions:\"-t, --type, obligatory, description='Record type'\"` Value string `goptions:\"-V, --value, obligatory, description='Value for record. Semantics depends on the record type.'\"` Ttl int64 `goptions:\"-T, --ttl, description='Time to live, in seconds, between 5 minutes and 30 days'\"` Id int64 `goptions:\"-r, --record, obligatory, description='Record id'\"` }", "del_tokens": "Id int64 Name string Ttl int64 Type string Value string Zone int64 `goptions:\"-z, --zone, obligatory, description='Zone id'\"` Version int64 `goptions:\"-v, --version, obligatory, description='Zone version'\"` Name string `goptions:\"-n, --name, obligatory, description='Record name. Relative name, may contain leading wildcard. @ for empty name'\"` Type string `goptions:\"-t, --type, obligatory, description='Record type'\"` Value string `goptions:\"-V, --value, obligatory, description='Value for record. Semantics depends on the record type.'\"` Ttl int64 `goptions:\"-T, --ttl, description='Time to live, in seconds, between 5 minutes and 30 days'\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "example", "type", "+", "better", "README"], "add_tokens": "fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , false ) ) fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , false ) ) fmt . Println ( ExampleInvertedSuffix . ErrorCorrectingQuery ( \" \" , 5 , false , ExampleCorrection ) ) fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , true ) ) fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , false ) )", "del_tokens": "fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , false ) fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , false ) fmt . Println ( ExampleInvertedSuffix . ErrorCorrectingQuery ( \" \" , 5 , false , ExampleCorrection ) fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , true ) fmt . Println ( ExampleInvertedSuffix . Query ( \" \" , 5 , false )", "commit_type": "fix"}
{"commit_tokens": ["Move", "protobuf", "assembly", "to", "single", "function"], "add_tokens": "entries = append ( entries , toProto ( resource ) )", "del_tokens": "entry := & pb . Resource { Path : [ ] string { resource . Path ( ) } , Mode : uint32 ( resource . Mode ( ) ) , Uid : resource . UID ( ) , Gid : resource . GID ( ) , } if xattrer , ok := resource . ( XAttrer ) ; ok { entry . Xattr = xattrer . XAttrs ( ) } switch r := resource . ( type ) { case RegularFile : entry . Path = r . Paths ( ) entry . Size = uint64 ( r . Size ( ) ) for _ , dgst := range r . Digests ( ) { entry . Digest = append ( entry . Digest , dgst . String ( ) ) } case SymLink : entry . Target = r . Target ( ) } // enforce a few stability guarantees that may not be provided by the // resource implementation. sort . Strings ( entry . Path ) entries = append ( entries , entry )", "commit_type": "move"}
{"commit_tokens": ["Fix", "copy", "/", "paste", "error"], "add_tokens": "bf , err := os . Create ( fmt . Sprintf ( \" \" , i , failure ( ! ok ) ) ) bf , err := os . Create ( fmt . Sprintf ( \" \" , i , failure ( ! ok ) ) )", "del_tokens": "bf , err := os . Create ( fmt . Sprintf ( \" \" , i , failure ( ! ok ) ) ) bf , err := os . Create ( fmt . Sprintf ( \" \" , i , failure ( ! ok ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "Event", ".", "Copy", "()", "in", "the", "new", "muxes"], "add_tokens": "newEvent := e . Copy ( )", "del_tokens": "newEvent := & Event { } * newEvent = * e", "commit_type": "use"}
{"commit_tokens": ["Add", "in", "circle", ".", "yml", "got", "CI", "testing"], "add_tokens": "var brandAPIURLRegex = baseAPIURL + \" \" neoLabels := [ ] string { \" \" } func TestBrandAPIURLs ( t * testing . T ) { neoLabels := [ ] string { \" \" } for _ , neoLabel := range neoLabels { assert . New ( t ) . Regexp ( brandAPIURLRegex , APIURL ( \" \" , [ ] string { neoLabel } ) ) assert . New ( t ) . Regexp ( brandAPIURLRegex , APIURL ( \" \" , [ ] string { mixUpCase ( neoLabel ) } ) ) } }", "del_tokens": "neoLabels := [ ] string { \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Change", "name", "of", "AgreeToTos", "to", "AgreeToTOS", "."], "add_tokens": "// AgreeToTOS updates the Client registration and sends the agreement to func ( c * Client ) AgreeToTOS ( ) error {", "del_tokens": "// AgreeToTos updates the Client registration and sends the agreement to func ( c * Client ) AgreeToTos ( ) error {", "commit_type": "change"}
{"commit_tokens": ["Fixing", "initialism", "logic", "and", "adding", "ToIdentifier", "variants"], "add_tokens": "var lastWasUpper , lastWasLetter , lastWasIsm , isUpper , isLetter bool if ism := peekInitialism ( rs [ i : ] ) ; ism != \" \" && ( ! lastWasUpper || lastWasIsm ) { lastWasIsm = false if len ( next ) > 1 { lastWasIsm = true } lastWasUpper = isUpper // CamelToSnakeIdentifier converts s to its snake_case identifier. func CamelToSnakeIdentifier ( s string ) string { return toIdentifier ( CamelToSnake ( s ) ) } // SnakeToCamelIdentifier converts s to its CamelCase identifier (first // letter is capitalized). func SnakeToCamelIdentifier ( s string ) string { return SnakeToCamel ( toIdentifier ( s ) )", "del_tokens": "var lastWasLetter , lastWasIsm , isUpper , isLetter bool lastWasIsm = false if ism := peekInitialism ( rs [ i : ] ) ; ism != \" \" { lastWasIsm = true lastWasIsm = false // SnakeToGoIdentifier converts s into a Go safe identifier (first letter will // be capitalized). func SnakeToGoIdentifier ( s string ) string { // replace bad chars with _ s = replaceBadChars ( s ) // fix 2 or more __ s = underscoreRE . ReplaceAllString ( s , \" \" ) // remove leading/trailing underscores s = strings . TrimLeft ( s , \" \" ) s = strings . TrimRight ( s , \" \" ) // convert to camel s = SnakeToCamel ( s ) // remove leading numbers s = numberRE . ReplaceAllString ( s , \" \" ) if s == \" \" { s = \" \" } return s", "commit_type": "fix"}
{"commit_tokens": ["fixed", "imports", "and", "generalized", "test"], "add_tokens": "fd , err := os . Open ( \" \" ) var lineCount uint if cf . InsertUnique ( s ) { lineCount ++ } if count != lineCount { t . Errorf ( \" \" , lineCount , count )", "del_tokens": "fd , err := os . Open ( \" \" ) cf . InsertUnique ( s ) if count != 235081 { t . Errorf ( \" \" , count )", "commit_type": "fix"}
{"commit_tokens": ["Make", "copies", "of", "subject", "and", "reply"], "add_tokens": "// FIXME(dlc), put these in with msg? subj := string ( nc . ps . ma . subject ) reply := string ( nc . ps . ma . reply )", "del_tokens": "// br *bufio.Reader // FIXME(dlc), if the callback holds onto these could be not good. subj := * ( * string ) ( unsafe . Pointer ( & nc . ps . ma . subject ) ) reply := * ( * string ) ( unsafe . Pointer ( & nc . ps . ma . reply ) )", "commit_type": "make"}
{"commit_tokens": ["add", "new", "multi", "-", "node"], "add_tokens": "parseSqlTest ( t , `select name from movies where director IN (\"Quentin\",\"copola\",\"Bay\",\"another\")` )", "del_tokens": "parseSqlTest ( t , `select name from movies where director IN (\"Quentin\",\"copola\")` )", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "to", "parse", "signal", "names", "due", "to", "niceNameToSigs", "was", "not", "set", "."], "add_tokens": "niceNameToSigs = make ( map [ string ] syscall . Signal )", "del_tokens": "niceNameToSigs := make ( map [ string ] syscall . Signal )", "commit_type": "fix"}
{"commit_tokens": ["Move", "file", "serving", "into", "context"], "add_tokens": "\" \" // \"path/filepath\" // \"io\" func ( c * Context ) File ( path string ) ( err error ) { info , err := os . Stat ( path ) if err != nil { return NewHTTPError ( 404 ) } if info . IsDir ( ) == false { file , err := os . Open ( path ) if err != nil { return NewHTTPError ( 404 ) } http . ServeContent ( c . Response ( ) . ResponseWriter , c . Request ( ) . Request , info . Name ( ) , info . ModTime ( ) , file ) } if info . IsDir ( ) == true { file , err := os . Open ( path + index ) if err != nil { return NewHTTPError ( 404 ) } http . ServeContent ( c . Response ( ) . ResponseWriter , c . Request ( ) . Request , info . Name ( ) , info . ModTime ( ) , file ) } return nil", "del_tokens": "\" \" func ( c * Context ) File ( path , name string ) ( err error ) { d , f := filepath . Split ( path ) return c . fibre . Serve ( d , f , c )", "commit_type": "move"}
{"commit_tokens": ["Fix", "scope", "issues", "with", ":", "=", "assignment", "operator"], "add_tokens": "var err error orm , err = NewORM ( db ) Ω( o rm) . S houldNot( B eNil( ) )", "del_tokens": "orm , err := NewORM ( db )", "commit_type": "fix"}
{"commit_tokens": ["add", "a", "method", "for", "a", "task", "ContainerID", "()"], "add_tokens": "import \" \" // ErrContainerIDNotFound is returned by ContainerIDs() function if the container id is not set. var ErrContainerIDNotFound = errors . New ( \" \" ) Statuses [ ] Status `json:\"statuses\"` } // Status is a field in state.json type Status struct { ContainerStatus ContainerStatus `json:\"container_status\"` } // ContainerStatus is a field in state.json type ContainerStatus struct { ContainerID NestedValue `json:\"container_id\"` } // NestedValue represents a nested container ID. The value is the actual container ID // and Parent is a reference to another NestedValue structure. type NestedValue struct { Value string `json:\"value\"` Parent * NestedValue `json:\"parent\"` } // ContainerIDs returns a slice of container ids , starting with the current, // and then appending the parent container ids. func ( t Task ) ContainerIDs ( ) ( containerIDs [ ] string , err error ) { for _ , status := range t . Statuses { containerID := status . ContainerStatus . ContainerID . Value if containerID == \" \" { return nil , ErrContainerIDNotFound } containerIDs = append ( containerIDs , containerID ) parent := status . ContainerStatus . ContainerID . Parent for parent != nil { containerIDs = append ( containerIDs , parent . Value ) parent = parent . Parent } } if len ( containerIDs ) == 0 { return nil , ErrContainerIDNotFound } return containerIDs , nil", "del_tokens": "Statuses [ ] struct { } `json:\"statuses\"`", "commit_type": "add"}
{"commit_tokens": ["add", "more", "tests", "for", "delete"], "add_tokens": "return ErrNoTableName", "del_tokens": "\" \" return errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "code", "may", "call", "NamedStopwatch", "with", "a", "nil", "pointer", ".", "(", "null", "action", ")"], "add_tokens": "if ns == nil { return // if we're not using stopwatches we just do nothing } if ns == nil { return // if we're not using stopwatches we just do nothing } if ns == nil { return // if we're not using stopwatches we just do nothing } if ns == nil { return // if we're not using stopwatches we just do nothing } if ns == nil { return // if we're not using stopwatches we just do nothing } ns . RLock ( ) defer ns . RUnlock ( ) if ns == nil { return time . Duration ( 0 ) } if ns == nil { return float64 ( 0 ) } if ns == nil { return float64 ( 0 ) }", "del_tokens": "ns . RLock ( ) defer ns . RUnlock ( ) // AddElapsedSince adds the duration since the reference time to the given named stopwatch. func ( ns * NamedStopwatch ) AddElapsedSince ( name string , t time . Time ) { ns . Lock ( ) defer ns . Unlock ( ) if s , ok := ns . stopwatches [ name ] ; ok { s . AddElapsedSince ( t ) } }", "commit_type": "allow"}
{"commit_tokens": ["removed", "redundant", "tests", ".", "added", "parameter", "output", "to", "log", "on", "startup", ".", "fixed", "tests", "for", "hb", "adjust"], "add_tokens": "if e != nil { log . Printf ( \" \" , e . Error ( ) ) } if e != nil { log . Printf ( \" \" , e . Error ( ) ) } func ( c * Client ) dumpParams ( ) { log . Print ( \" \" ) log . Printf ( \" \" , c . parameters . AutoReconnect ) log . Printf ( \" \" , c . parameters . ReconnectInterval ) log . Printf ( \" \" , c . parameters . ReconnectAttempts ) log . Printf ( \" \" , c . parameters . ShutdownTimeout ) log . Printf ( \" \" , c . parameters . ResubscribeOnReconnect ) log . Printf ( \" \" , c . parameters . HeartbeatTimeout ) log . Printf ( \" \" , c . parameters . URL ) } c . dumpParams ( )", "del_tokens": "log . Printf ( \" \" , e . Error ( ) ) log . Printf ( \" \" , e . Error ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "stub", "implementation", "."], "add_tokens": "\" \" func ( b * bucket ) Name ( ) string { return b . name } query * storage . Query ) ( * storage . Objects , error ) { return nil , errors . New ( \" \" ) } objectName string ) ( io . ReadCloser , error ) { return nil , errors . New ( \" \" ) } attrs * storage . ObjectAttrs ) ( gcs . ObjectWriter , error ) { return nil , errors . New ( \" \" ) } name string ) error { return errors . New ( \" \" ) }", "del_tokens": "func ( b * bucket ) Name ( ) string query * storage . Query ) ( * storage . Objects , error ) objectName string ) ( io . ReadCloser , error ) attrs * storage . ObjectAttrs ) ( gcs . ObjectWriter , error ) name string ) error", "commit_type": "add"}
{"commit_tokens": ["add", "redacting", "writer", "sink", "for", "scrubbing", "secrets", "from", "logging", "data"], "add_tokens": "return newLogger ( component , minLogLevel , lager . NewWriterSink ( os . Stdout , lager . DEBUG ) ) } func NewFromSink ( component string , sink lager . Sink ) ( lager . Logger , * lager . ReconfigurableSink ) { return newLogger ( component , minLogLevel , sink ) return newLogger ( component , config . LogLevel , lager . NewWriterSink ( os . Stdout , lager . DEBUG ) ) func newLogger ( component , minLogLevel string , inSink lager . Sink ) ( lager . Logger , * lager . ReconfigurableSink ) { sink := lager . NewReconfigurableSink ( inSink , minLagerLogLevel )", "del_tokens": "return newLogger ( component , minLogLevel ) return newLogger ( component , config . LogLevel ) func newLogger ( component , minLogLevel string ) ( lager . Logger , * lager . ReconfigurableSink ) { sink := lager . NewReconfigurableSink ( lager . NewWriterSink ( os . Stdout , lager . DEBUG ) , minLagerLogLevel )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "data", "race", "error", "in", "test"], "add_tokens": "l , err := net . Listen ( \" \" , \" \" ) if err != nil { t . Fatalf ( \" \" , err ) } res , err := grab ( t , \" \" + l . Addr ( ) . String ( ) ) _ , err = grab ( t , \" \" + l . Addr ( ) . String ( ) ) t . Fatalf ( \" \" , err )", "del_tokens": "// listener address addr := new ( string ) l , err := net . Listen ( \" \" , \" \" ) if err != nil { return err } * addr = l . Addr ( ) . String ( ) <- time . After ( 1 * time . Second ) res , err := grab ( t , \" \" + * addr ) _ , err = grab ( t , \" \" + * addr ) t . Fatalf ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "state", "check", "in", "candidate", "inner", "loop", "."], "add_tokens": "if s . State ( ) != Candidate || timeout {", "del_tokens": "break if s . State ( ) == Follower || timeout {", "commit_type": "fix"}
{"commit_tokens": ["allow", "ColumnMaps", "to", "set", "an", "sqltype", "which", "is", "not", "used", "yet", "but", "will", "be", "used", "in", "sql", "creation"], "add_tokens": "sqltype string // Set the column's sql type. This is a string, such as 'varchar(32)' or // 'text', which will be used by CreateTable and nothing else. It is the // caller's responsibility to ensure this will map cleanly to the struct func ( c * ColumnMap ) SetSqlType ( t string ) * ColumnMap { c . sqltype = t return c } // Transaction represents a database transaction. // Insert/Update/Delete/Get/Exec operations will be run in the context // of that transaction. Transactions should be terminated with // a call to Commit() or Rollback() type Transaction struct { dbmap * DbMap tx * sqlx . Tx }", "del_tokens": "// This mapping should be known ahead of time, and this is the one case where // I think I want things to actually be done in the struct tags instead of // being changed at runtime where other systems then do not have access to them // Rename allows you to specify the column name in the table // // Example: table.ColMap(\"Updated\").Rename(\"date_updated\") // //func (c *ColumnMap) Rename(colname string) *ColumnMap { // c.ColumnName = colname // return c //} // Transaction represents a database transaction. // Insert/Update/Delete/Get/Exec operations will be run in the context // of that transaction. Transactions should be terminated with // a call to Commit() or Rollback() type Transaction struct { dbmap * DbMap tx * sqlx . Tx }", "commit_type": "allow"}
{"commit_tokens": ["fix", "mongo", "indexing", "name", "mismatch"], "add_tokens": "constraint := bson . M { d . String ( ) : name }", "del_tokens": "var constraint bson . M switch d { case quad . Subject : constraint = bson . M { \" \" : name } case quad . Predicate : constraint = bson . M { \" \" : name } case quad . Object : constraint = bson . M { \" \" : name } case quad . Label : constraint = bson . M { \" \" : name } }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "an", "issue", "with", "calling", "functions", "on", "values"], "add_tokens": "if rv . Kind ( ) == reflect . Ptr { rv = rv . Elem ( ) } args := [ ] reflect . Value { } rt := m . Type ( ) if rt . NumIn ( ) > 0 { last := rt . In ( rt . NumIn ( ) - 1 ) if last . Name ( ) == \" \" { hargs := HelperContext { Context : ev . context , Args : [ ] interface { } { } , evalVisitor : ev , } args = append ( args , reflect . ValueOf ( hargs ) ) } if len ( args ) > rt . NumIn ( ) { err := errors . Errorf ( \" \" , p , len ( args ) , rt . NumIn ( ) ) return errors . WithStack ( err ) } } vv := m . Call ( args )", "del_tokens": "vv := m . Call ( [ ] reflect . Value { } ) case reflect . Ptr : f := rv . Elem ( ) . FieldByName ( p ) v = f . Interface ( )", "commit_type": "fix"}
{"commit_tokens": ["Use", "an", "empty", "struct", "instead", "of", "bool", "as", "map", "value", "for", "set", "."], "add_tokens": "data : make ( map [ interface { } ] struct { } ) , data map [ interface { } ] struct { } s . data = make ( map [ interface { } ] struct { } ) s . data [ v ] = struct { } { }", "del_tokens": "data : make ( map [ interface { } ] bool ) , data map [ interface { } ] bool s . data = make ( map [ interface { } ] bool ) s . data [ v ] = true", "commit_type": "use"}
{"commit_tokens": ["Made", "the", "temp", "ring", "use", "address2"], "add_tokens": "b . AddNode ( true , 1 , nil , [ ] string { \" \" , \" \" , vaddr } , \" \" , nil ) b . AddNode ( true , 1 , nil , [ ] string { \" \" , \" \" , gaddr } , \" \" , nil ) AddressIndex : 2 , AddressIndex : 2 ,", "del_tokens": "b . AddNode ( true , 1 , nil , [ ] string { vaddr } , \" \" , nil ) b . AddNode ( true , 1 , nil , [ ] string { gaddr } , \" \" , nil )", "commit_type": "make"}
{"commit_tokens": ["update", "validate", "struct", "benchmark", "for", "lager", "struct", "with", "nested", "struct"], "add_tokens": "// type Inner struct { // } // type Test struct { // StringVal string `bson:\"required,lt=10\"` // Int64Val int64 `bson:\"gt=0,lt=10\"` // } tFail := & TestString { Required : \" \" , Len : \" \" , Min : \" \" , Max : \" \" , MinMax : \" \" , Lt : \" \" , Lte : \" \" , Gt : \" \" , Gte : \" \" , OmitEmpty : \" \" , Sub : & SubTest { Test : \" \" , } , Anonymous : struct { A string `validate:\"required\"` } { A : \" \" , } , Iface : & Impl { F : \" \" , } , // t := &Test{ // StringVal: \"test\", // Int64Val: 5, // } validate . Struct ( tFail )", "del_tokens": "type Test struct { StringVal string `bson:\"required,lt=10\"` Int64Val int64 `bson:\"gt=0,lt=10\"` } t := & Test { StringVal : \" \" , Int64Val : 5 , validate . Struct ( t )", "commit_type": "update"}
{"commit_tokens": ["Upgrade", "to", "new", "RegisterViewPath", "API"], "add_tokens": "res . GetAdmin ( ) . RegisterViewPath ( \" \" )", "del_tokens": "admin . RegisterViewPath ( \" \" )", "commit_type": "upgrade"}
{"commit_tokens": ["Improve", "interface", "of", "fuzz", ".", "Continue"], "add_tokens": "// Note c's embedded Rand allows for direct use. // We could also use c.RandBool() here. switch c . Intn ( 2 ) {", "del_tokens": "switch c . Rand ( ) . Intn ( 2 ) {", "commit_type": "improve"}
{"commit_tokens": ["Move", "error", "code", "out", "to", "error", ".", "go"], "add_tokens": "body , err := c . post ( \" \" , headers , bytes . NewBufferString ( content ) )", "del_tokens": "body , err := c . post ( \" \" , nil , bytes . NewBufferString ( content ) ) assert . Equal ( t , \" \" , err . Error ( ) ) body , err = c . post ( \" \" , headers , bytes . NewBufferString ( content ) )", "commit_type": "move"}
{"commit_tokens": ["add", "SetOperationName", "()", ";", "remove", "an", "unneeded", "method", ";"], "add_tokens": "// newly-returned Span into an existing trace. (I.e., the returned Span is // the \"root\" of its trace).", "del_tokens": "// newly-returned Span into an existing trace. // Like `StartTrace`, but the returned `Span` is made a child of `parent`. // // The `parent` parameter can either be a `context.Context` or an // `opentracing.Span`. In the former case, the implementation attempts to // extract an `opentracing.Span` using `SpanFromContext()`. JoinTrace ( operationName string , parent interface { } ) Span", "commit_type": "add"}
{"commit_tokens": ["add", "some", "comments", "drop", "reflect", "version"], "add_tokens": "inbuf , // bulk input (e.g. crush map) & outbuf , // buffer & outbuflen , // buffer length & outs , // status string buffer = C . GoBytes ( unsafe . Pointer ( outbuf ) , C . int ( outbuflen ) ) C . free ( unsafe . Pointer ( outbuf ) )", "del_tokens": "import \" \" inbuf , // inbuf & outbuf , // actual data & outbuflen , // len data & outs , // report largenumber //C.rados_buffer_free(outs) length := int ( outbuflen ) hdr := reflect . SliceHeader { Data : uintptr ( unsafe . Pointer ( outbuf ) ) , Len : length , Cap : length , } // now goSlice is a Go slice backed by the C array buffer = * ( * [ ] byte ) ( unsafe . Pointer ( & hdr ) ) // info might contain hints as to why the error happened", "commit_type": "add"}
{"commit_tokens": ["use", "infinite", "queue", "add", "example", "that", "crawls", "golang", ".", "org"], "add_tokens": "f := New ( nopHandler ) f := New ( sh ) f := New ( sh ) f := New ( sh ) f := New ( sh ) f := New ( sh ) f := New ( sh ) f := New ( sh ) f := New ( nil ) f := New ( sh )", "del_tokens": "f := New ( nopHandler , - 1 ) if f . buf != DefaultChanBufferSize { t . Errorf ( \" \" , DefaultChanBufferSize , f . buf ) } f := New ( sh , 0 ) f := New ( sh , 0 ) f := New ( sh , 0 ) f := New ( sh , - 1 ) f := New ( sh , - 1 ) f := New ( sh , - 1 ) f := New ( sh , - 1 ) f := New ( nil , - 1 ) f := New ( sh , 1 ) // Buffer of only one", "commit_type": "use"}
{"commit_tokens": ["Fix", "os", ".", "IsExist", "()", "condition", "in", "filelist", ".", "Contains", "()"], "add_tokens": "if os . IsExist ( e ) && st . IsDir ( ) && strings . HasPrefix ( abs , rel ) {", "del_tokens": "if ! os . IsNotExist ( e ) && st . IsDir ( ) && strings . HasPrefix ( abs , rel ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "os", ".", "O_TRUNC", "instead", "of", "os", ".", "Remove", "when", "writing", "output", "files"], "add_tokens": "outFile , err := os . OpenFile ( outFilePath , os . O_CREATE | os . O_WRONLY | os . O_TRUNC , 0600 ) outFile , err := os . OpenFile ( outFilePath , os . O_CREATE | os . O_RDWR | os . O_TRUNC , 0600 )", "del_tokens": "if err = os . Remove ( outFilePath ) ; err != nil && ! os . IsNotExist ( err ) { return err } outFile , err := os . OpenFile ( outFilePath , os . O_CREATE | os . O_RDWR , 0600 ) if err = os . Remove ( outFilePath ) ; err != nil && ! os . IsNotExist ( err ) { return err } outFile , err := os . OpenFile ( outFilePath , os . O_CREATE | os . O_RDWR , 0600 )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "typos", "and", "moved", "the", "graphical", "description", "to", "the", "package", "leve", "."], "add_tokens": "The actual call stack of our chain of handlers starts from the last added and ends with the first added . For example , if there are 3 middlewares added in order ( 0 , 1 , 2 ) , the calls look like so : //2 START //1 START //0 START //0 END //1 END //2 END Therefore , the last middleware generator to be added will not only be the first to be called , but will also have the opportunity to make the final call after the rest of the middleware is called // Add a piece of middleware which is simply any http.Handler // Satisfies the net/http Handler interface and calls the middleware stack //Call the middleware stack", "del_tokens": "// Add a pice of middleware which is simply any http.Handler / * The actual call stack of our chain of handlers starts from the last added and ends with the first added . For example , if there are 3 middlewares added in order ( 0 , 1 , 2 ) , the calls look like so : //2 START //1 START //0 START //0 END //1 END //2 END Therefore , the last middleware generator to be added will not only be the first to be called , but will also have the opportunity to make the final call after the rest of the middleware is called * /", "commit_type": "fix"}
{"commit_tokens": ["added", "Gin", "Context", "to", "authenticator", "/", "may", "be", "useful", "to", "be", "aware", "of", "the", "request", "context", "to", "authenticate", "or", "to", "be", "able", "to", "interact", "with", "it", "so", "that", "Authorizator", "can", "have", "access", "to", "set", "variables"], "add_tokens": "userId , ok := mw . Authenticator ( loginVals . Username , loginVals . Password , c )", "del_tokens": "userId , ok := mw . Authenticator ( loginVals . Username , loginVals . Password )", "commit_type": "add"}
{"commit_tokens": ["Use", "reflection", "to", "load", "network", "and", "volume", "config"], "add_tokens": "Ipam : types . IPAMConfig { Config : [ ] * types . IPAMPool { & types . IPAMPool {", "del_tokens": "IPAM : types . IPAMConfig { Config : [ ] types . IPAMPool { types . IPAMPool {", "commit_type": "use"}
{"commit_tokens": ["fixed", "bat", "interaction", "between", "jsonPointer", "and", "jsonReference", "resulting", "in"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Use", "filepath", ".", "Join", "for", "windows", "paths"], "add_tokens": "profilebin := filepath . Join ( profile , \" \" , \" \" )", "del_tokens": "profilebin := filepath . Join ( profile , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Use", "range", "in", "cas", "example"], "add_tokens": "for key := range keyChan {", "del_tokens": "for key , ok := <- keyChan ; ok ; key , ok = <- keyChan {", "commit_type": "use"}
{"commit_tokens": ["Use", "buffered", "channels", "for", "Timer", "s", "to", "avoid", "hang", "on", "mock", ".", "Add", "."], "add_tokens": "ch := make ( chan time . Time , 1 ) ch := make ( chan time . Time , 1 ) default :", "del_tokens": "ch := make ( chan time . Time ) ch := make ( chan time . Time ) case <- time . After ( 1 * time . Millisecond ) :", "commit_type": "use"}
{"commit_tokens": ["Change", "host", "by", "hostname", "in", "statsd", "tags", "."], "add_tokens": "fmt . Sprintf ( \" \" , s . hostname ) , fmt . Sprintf ( \" \" , s . hostname ) ,", "del_tokens": "fmt . Sprintf ( \" \" , s . hostname ) , fmt . Sprintf ( \" \" , s . hostname ) ,", "commit_type": "change"}
{"commit_tokens": ["Fixed", "bug", "where", "err", "from", "Exec", "was", "not", "returned"], "add_tokens": "return err", "del_tokens": "return nil", "commit_type": "fix"}
{"commit_tokens": ["added", "test", "and", "fixed", "implementation"], "add_tokens": "sorted , err := SortTypes ( types ) if err != nil { return \" \" , err return sorted [ len ( sorted ) - 1 ] , nil // SortTypes sorts the given types from least specific to most specific", "del_tokens": "result := types [ 0 ] for _ , t := range types [ 1 : ] { if isDescendent ( t , result ) { result = t } if ! isDescendent ( result , t ) { return \" \" , ErrNotHierarchy } return result , nil // SortTypes sorts the given types from most specific to least specific", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "At", "()", "in", "middle", "of", "Find", "*", "sequence"], "add_tokens": "Expect ( selection . At ( 2 ) . Click ( ) ) . To ( MatchError ( \" \" ) ) Context ( \" \" , func ( ) { Context ( \" \" , func ( ) { It ( \" \" , func ( ) { Expect ( selection . At ( 0 ) . Find ( \" \" ) . String ( ) ) . To ( Equal ( \" \" ) ) } ) } ) Expect ( err ) . To ( MatchError ( \" \" ) )", "del_tokens": "Expect ( selection . At ( 2 ) . Click ( ) ) . To ( MatchError ( \" \" ) ) Context ( \" \" , func ( ) { Expect ( err ) . To ( MatchError ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectThat ( o . Metadata , DeepEquals ( attrs . Metadata ) )", "del_tokens": "ExpectEq ( nil , o . Metadata )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "test", "for", "the", "Info", "function"], "add_tokens": "t . Errorf ( \" \" , c . request . host )", "del_tokens": "t . Errorf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "encoding", ".", "BinaryUnmarshaler"], "add_tokens": "if decoderFrom ( f ) == nil && setterFrom ( f ) == nil && textUnmarshaler ( f ) == nil && binaryUnmarshaler ( f ) == nil { if b := binaryUnmarshaler ( field ) ; b != nil { return b . UnmarshalBinary ( [ ] byte ( value ) ) } func binaryUnmarshaler ( field reflect . Value ) ( b encoding . BinaryUnmarshaler ) { interfaceFrom ( field , func ( v interface { } , ok * bool ) { b , * ok = v . ( encoding . BinaryUnmarshaler ) } ) return b }", "del_tokens": "if decoderFrom ( f ) == nil && setterFrom ( f ) == nil && textUnmarshaler ( f ) == nil {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "finding", "an", "element", "by", "label", "text", "(", "via", "XPath", ")"], "add_tokens": "It ( \" \" , func ( ) { Describe ( \" \" , func ( ) { It ( \" \" , func ( ) { Expect ( selection . FindByLabel ( \" \" ) . String ( ) ) . To ( Equal ( `CSS: #selector | XPath: //input[@id=(//label[text()=\"label name\"]/@for)] | //label[text()=\"label name\"]/input` ) ) } ) } )", "del_tokens": "It ( \" \" , func ( ) {", "commit_type": "add"}
{"commit_tokens": ["Implemented", "a", "solution", "for", "handling", "async", "element", "data", "coming", "in"], "add_tokens": "type ChangeEventType uint16 const ( DocumentUpdatedEvent ChangeEventType = 0x0 SetChildNodesEvent ChangeEventType = 0x1 AttributeModifiedEvent ChangeEventType = 0x2 AttributeRemovedEvent ChangeEventType = 0x3 InlineStyleInvalidatedEvent ChangeEventType = 0x4 CharacterDataModifiedEvent ChangeEventType = 0x5 ChildNodeCountUpdatedEvent ChangeEventType = 0x6 ChildNodeInsertedEvent ChangeEventType = 0x7 ChildNodeRemovedEvent ChangeEventType = 0x8 ) type NodeChangeEvent struct { EventType ChangeEventType // the type of node change event NodeId int // nodeid of change NodeIds [ ] int // nodeid of changes for inlinestyleinvalidated ChildNodeCount int // updated childnodecount event Nodes [ ] * gcdapi . DOMNode // Child nodes array. for setChildNodesEvent Node * gcdapi . DOMNode // node for child node inserted event Name string // attribute name Value string // attribute value CharacterData string // new text value for characterDataModified events ParentNodeId int // node id for setChildNodesEvent, childNodeInsertedEvent and childNodeRemovedEvent PreviousNodeId int // previous node id for childNodeInsertedEvent", "del_tokens": "type PageLoadEventFired struct { timestamp int } type ConsoleEventHeader struct { Method string `json:\"method\"` Params * ConsoleEventParams `json:\"params\"` } type ConsoleEventParams struct { Message * gcdapi . ConsoleConsoleMessage `json:\"message\"` } type DefaultEventHeader struct { Method string `json:\"method\"` Params interface { } `json:\"params\"`", "commit_type": "implement"}
{"commit_tokens": ["Add", "Merge", "and", "Without", "methods"], "add_tokens": "mergedMap := make ( flagMap ) if fm != nil { for k , v := range fm { mergedMap [ k ] = v } if fm2 != nil { for k , v := range fm2 { mergedMap [ k ] = v } } return mergedMap func ( fm flagMap ) Without ( fm2 flagMap ) flagMap { diffedMap := make ( flagMap ) if fm == nil { return diffedMap } if fm2 == nil { return fm } for k , v := range fm { if _ , exist := fm2 [ k ] ; ! exist { diffedMap [ k ] = v } } return diffedMap }", "del_tokens": "for k , v := range fm2 { fm [ k ] = v return fm", "commit_type": "add"}
{"commit_tokens": ["Implement", "auto", "-", "update", "for", "datetime", "/", "timestamp", "fields"], "add_tokens": "case ON : // for now, only applicable to ON UPDATE ... ctx . skipWhiteSpaces ( ) if t := ctx . next ( ) ; t . Type != UPDATE { return newParseError ( ctx , t , \" \" ) } ctx . skipWhiteSpaces ( ) v := ctx . next ( ) col . SetAutoUpdate ( v . Value ) return newParseError ( ctx , t , \" \" )", "del_tokens": "return newParseError ( ctx , t , \" \" )", "commit_type": "implement"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// GetPaymentsWithFilter retrieve payments resources from Paypal by the provided filter", "del_tokens": "// GetPayments retrieve payments resources from Paypal by the provided filter", "commit_type": "fix"}
{"commit_tokens": ["added", "keys", "to", "english", "ortho", "context"], "add_tokens": "& sentences . OrthoContext { Storage : training , PunctStrings : lang , TokenType : word , TokenFirst : word , } ,", "del_tokens": "& sentences . OrthoContext { training , lang , word , word } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "documentation", "removed", "unused", "methods", "."], "add_tokens": "//Package key_utils provides methods to generate keys and retrieve bitpay specific ids (the SIN) and correctly formatted signatures. //This type provides compatibility with the btcec package //All BitPay clients use a PEM file to store the private and public keys. //GenerateSinFromPem returns a base58 encoding of a public key. It expects a pem string as the argument. //ExtractCompressedPublicKey returns a hexadecimal encoding of the compressed public key. It expects a pem string as the argument. //Returns a hexadecimal encoding of the signed sha256 hash of message, using the key provide in the pem string pm. //Returns a btec.Private key object if provided a correct secp256k1 encoded pem. func ExtractKeyFromPem ( pm string ) * btcec . PrivateKey { byta := [ ] byte ( pm ) blck , _ := pem . Decode ( byta ) var ecp ecPrivateKey asn1 . Unmarshal ( blck . Bytes , & ecp ) priv , _ := btcec . PrivKeyFromBytes ( btcec . S256 ( ) , ecp . PrivateKey ) return priv }", "del_tokens": "func ExtractKeyFromPem ( pm string ) * btcec . PrivateKey { byta := [ ] byte ( pm ) blck , _ := pem . Decode ( byta ) var ecp ecPrivateKey asn1 . Unmarshal ( blck . Bytes , & ecp ) priv , _ := btcec . PrivKeyFromBytes ( btcec . S256 ( ) , ecp . PrivateKey ) return priv } func ExtractSerializedKeyFromPem ( pm string ) string { priv := ExtractKeyFromPem ( pm ) ser := priv . Serialize ( ) hexa := hex . EncodeToString ( ser ) return hexa } func GeneratePrivateKey ( ) * btcec . PrivateKey { priv , _ := btcec . NewPrivateKey ( btcec . S256 ( ) ) return priv }", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "periods", "to", "end", "of", "sentences", "."], "add_tokens": "// ErrUnauthorized can be returned on any call on response status code 401. // Errors always has at least 1 element when returned.", "del_tokens": "// ErrUnauthorized can be returned on any call on response status code 401 // Errors always has at least 1 element when returned", "commit_type": "add"}
{"commit_tokens": ["Change", "example", "to", "reflect", "production"], "add_tokens": "client := apns . NewClient ( cert ) . Production ( )", "del_tokens": "client := apns . NewClient ( cert ) . Development ( )", "commit_type": "change"}
{"commit_tokens": ["Fix", "typo", "in", "comment", "."], "add_tokens": "// The values pointed at by dest must be a numeric type, boolean, string,", "del_tokens": "// The values pointed at by test must be a numeric type, boolean, string,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "leaking", "http", "goroutines", "by", "closing", "the", "response", "body", "in", "every", "situation"], "add_tokens": "defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( )", "del_tokens": "defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["Added", "bool", "key", "double", "tests"], "add_tokens": "// KeyAt extracts a key from an Object at the specified index. // MustKeyAt extracts a key from an Object at the specified index. // Panics in case of an error. func ( s Slice ) MustKeyAt ( index ValueLength , translate ... bool ) Slice { if result , err := s . KeyAt ( index , translate ... ) ; err != nil { panic ( err ) } else { return result } } // ValueAt extracts a value from an Object at the specified index func ( s Slice ) ValueAt ( index ValueLength ) ( Slice , error ) { if ! s . IsObject ( ) { return nil , InvalidTypeError { \" \" } } key , err := s . getNthKey ( index , false ) if err != nil { return nil , WithStack ( err ) } byteSize , err := key . ByteSize ( ) if err != nil { return nil , WithStack ( err ) } return Slice ( key [ byteSize : ] ) , nil } // MustValueAt extracts a value from an Object at the specified index. // Panics in case of an error. func ( s Slice ) MustValueAt ( index ValueLength ) Slice { if result , err := s . ValueAt ( index ) ; err != nil { panic ( err ) } else { return result } }", "del_tokens": "// KeyAt extract a key from an Object at the specified index.", "commit_type": "add"}
{"commit_tokens": ["Create", "the", "default", "database", "if", "it", "doesn", "t", "exist", "already", "in", "influxdb", "."], "add_tokens": "if err := client . CreateDatabase ( * argDbName ) ; err != nil { glog . Infof ( \" \" , err ) } // Create the database if it does not already exist. Ignore errors.", "del_tokens": "", "commit_type": "create"}
{"commit_tokens": ["Use", "strings", ".", "NewReader", "instead", "of", "an", "empty", "buffer", "."], "add_tokens": "\" \" _ , err = io . Copy ( writer , strings . NewReader ( strings . Repeat ( \" \" , 1 << 19 ) ) )", "del_tokens": "_ , err = io . Copy ( writer , bytes . NewBuffer ( make ( [ ] byte , 1 << 20 ) ) )", "commit_type": "use"}
{"commit_tokens": ["Updated", "README", "and", "added", "IsDone", "to", "Event"], "add_tokens": "// True if our candidate is leader IsLeader bool // True if the election is shutdown and // no further events will follow. IsDone bool // Holds the current leader key LeaderKey string // Hold the current leaders data // If not nil, contains an error encountered // while participating in the election. Err error } else { event . IsDone = true", "del_tokens": "IsLeader bool LeaderKey string Err error", "commit_type": "update"}
{"commit_tokens": ["Added", "errors", "for", "unknown", "short", "options"], "add_tokens": "for j , s := range a [ 1 : ] { foundone := false for _ , o := range opts { foundone = true } // Process if we find a match } // Loop over the shortnames that this option supports } // Loop over the short arguments that we know if ! foundone { failnoting ( \" \" , os . NewError ( \" \" + a [ j : j + 1 ] ) ) Args . Push ( \" \" + a [ j : j + 1 ] ) } // Loop over the characters in this short argument", "del_tokens": "//fmt.Println(\"looking at short option\",a) for _ , o := range opts { //fmt.Println(\"checking in shortnames \", o.shortnames) for j , s := range a [ 1 : len ( a ) ] { //fmt.Println(\"comparing \",string(c),\" with \",string(s)) } } }", "commit_type": "add"}
{"commit_tokens": ["allowing", "to", "set", "passwords", "on", "empty", "files"], "add_tokens": "\" \" _ , err := os . Stat ( file ) passwords := HashedPasswords ( map [ string ] string { } ) if err == nil { passwords , err = ParseHtpasswdFile ( file ) if err != nil { return err }", "del_tokens": "passwords , err := ParseHtpasswdFile ( file ) if err != nil { return err", "commit_type": "allow"}
{"commit_tokens": ["Fix", "recursive", "call", "of", "String", "()", "of", "Clause", "constants"], "add_tokens": "panic ( fmt . Errorf ( \" \" , uint ( c ) ) )", "del_tokens": "panic ( fmt . Errorf ( \" \" , c ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "API", "to", "enable", "/", "disable", "the", "package", "."], "add_tokens": "global = New ( )", "del_tokens": "global = New ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "array", "traversal", "tests", ".", "Reorganize", "code", ".", "Remove", "dead", "code", "."], "add_tokens": "for i , step := range tst { t . Errorf ( \" \" , i , step . match , m )", "del_tokens": "for _ , step := range tst { t . Errorf ( \" \" , step . match , m )", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "test", "condition", "for", "self", "-", "documentation"], "add_tokens": "expect ( t , s . Dep3 , \" \" ) typ := reflect . TypeOf ( \" \" ) typSend := reflect . ChanOf ( reflect . SendDir , typ ) typRecv := reflect . ChanOf ( reflect . RecvDir , typ )", "del_tokens": "typ := reflect . TypeOf ( \" \" ) typSend := reflect . ChanOf ( reflect . SendDir , typ ) typRecv := reflect . ChanOf ( reflect . RecvDir , typ )", "commit_type": "add"}
{"commit_tokens": ["Fix", "comment", "on", "range", "of", "normalized", "angles", "."], "add_tokens": "// Normalized returns an equivalent angle in [0, 2π).", "del_tokens": "// Normalized returns an equivalent angle in (-π, π].", "commit_type": "fix"}
{"commit_tokens": ["Add", "per", "service", "MsgRing", "port"], "add_tokens": "_SYN_REGISTER_TIMEOUT = 4 _SYN_DIAL_TIMEOUT = 2 DefaultPort = 8443 DefaultCmdCtrlPort = 4443 DefaultMsgRingPort = 8001 DefaultRingDir = \" \" DefaultCertFile = \" \" DefaultCertKey = \" \" MsgRingPort int if s . cfg . MsgRingPort == 0 { log . Println ( \" \" , DefaultPort ) s . cfg . MsgRingPort = DefaultMsgRingPort } addrs = append ( addrs , fmt . Sprintf ( \" \" , i . String ( ) , s . cfg . MsgRingPort ) )", "del_tokens": "_SYN_REGISTER_TIMEOUT = 4 _SYN_DIAL_TIMEOUT = 2 _SYN_DEFAULT_NODE_PORT = 8001 DefaultPort = 8443 DefaultCmdCtrlPort = 4443 DefaultRingDir = \" \" DefaultCertFile = \" \" DefaultCertKey = \" \" addrs = append ( addrs , fmt . Sprintf ( \" \" , i . String ( ) , _SYN_DEFAULT_NODE_PORT ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "watcher", "bug", "(", "incorrect", "fdset", "when", "watching", "with", "select", ")"], "add_tokens": "fdset . Bits [ val / 64 ] |= 1 << ( uint ( val ) % 64 ) if ( fdset . Bits [ fd / 64 ] & ( 1 << ( uint ( fd ) % 64 ) ) ) != 0 { changed , err := doSelect ( int ( w . fds [ 0 ] ) + 1 , nil , nil , fdset , timeval )", "del_tokens": "fdset . Bits [ val / 64 ] |= 1 << uint ( val ) % 64 if ( fdset . Bits [ fd / 64 ] & ( 1 << uint ( fd ) % 64 ) ) != 0 { changed , err := doSelect ( int ( w . fds [ 0 ] + 1 ) , nil , nil , fdset , timeval )", "commit_type": "fix"}
{"commit_tokens": ["improve", "json", "unmarshalling", ";", "improve", "debug", "output", "on", "panic"], "add_tokens": "name := elem . Field ( i ) . Tag . Get ( \" \" ) if jsonBlob . Get ( name ) . IsUndefined ( ) || jsonBlob . Get ( name ) . IsNull ( ) { continue } case reflect . Bool : f . SetBool ( jsonBlob . Get ( name ) . Bool ( ) ) default : print ( \" \" , name , \" \" )", "del_tokens": "name := elem . Field ( i ) . Name", "commit_type": "improve"}
{"commit_tokens": ["Add", "right_net", "actions", "improve", "help", "format", "."], "add_tokens": "desc := p . Name desc += \" \" + strings . TrimSpace ( p . Description ) mandatory = append ( mandatory , desc ) desc := p . Name desc += \" \" + strings . TrimSpace ( p . Description ) if ! strings . HasSuffix ( description , \" \\n \" ) { description += \" \\n \" } description += \" \\n \\t \" + strings . Join ( mandatory , \" \\n \\t \" ) if ! strings . HasSuffix ( description , \" \\n \" ) { description += \" \\n \" } description += \" \\n \\t \" + strings . Join ( optional , \" \\n \\t \" )", "del_tokens": "var desc = fmt . Sprintf ( \" \" , p . VarName , p . Description ) mandatory = append ( mandatory , desc ) var desc = p . Name desc += \" \" + p . Description description += \" \\n \\t \" + strings . Join ( mandatory , \" \\n \\t \" ) description += \" \\n \\n \\t \" + strings . Join ( optional , \" \\n \\t \" )", "commit_type": "add"}
{"commit_tokens": ["add", "rpc", "client", "to", "wallet"], "add_tokens": "\" \" chainClient * chain . Client netDir := networkDir ( dataDir , ActiveNetParams ) // TODO(roasbeef): config... rpcc , err := chain . NewClient ( ActiveNetParams , \" \" , \" \" , \" \" , [ ] byte ( \" \" ) , true ) if err != nil { return err } // Start the goroutines in the underlying wallet. l . chainClient = rpcc l . wallet . Start ( rpcc )", "del_tokens": "netDir := networkDir ( defaultDataDir , ActiveNetParams )", "commit_type": "add"}
{"commit_tokens": ["Fix", "update", "statement", "by", "looking", "up", "by", "names"], "add_tokens": "// Sorting is too hard in go, just create a second map ... updateValues := make ( map [ string ] Expression ) for col , expr := range u . updateValues { if col == nil { return \" \" , errors . Newf ( \" \" , buf . String ( ) ) } updateValues [ col . Name ( ) ] = expr } val , inMap := updateValues [ col . Name ( ) ]", "del_tokens": "val , inMap := u . updateValues [ col ] if col == nil { return \" \" , errors . Newf ( \" \" , buf . String ( ) ) }", "commit_type": "fix"}
{"commit_tokens": ["add", "indices", "to", "vertex", "array"], "add_tokens": "[ ] int { 0 , 1 , 2 , 0 , 2 , 3 } , [ ] int { 0 , 1 , 2 , 1 , 2 , 3 } , var indices [ ] int for i := 2 ; i < len ( points ) ; i ++ { indices = append ( indices , 0 , i - 1 , i ) } indices , var indices [ ] int for i := 2 ; i < ( n + 1 ) * 2 ; i ++ { indices = append ( indices , i - 2 , i - 1 , i ) } indices , panic ( errors . Wrap ( err , \" \" ) )", "del_tokens": "pixelgl . TriangleFanDrawMode , pixelgl . TriangleStripDrawMode , pixelgl . TriangleFanDrawMode , pixelgl . TriangleStripDrawMode , panic ( errors . Wrap ( err , \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "data", ".", "Move", "setID", "to", "UnmarshalJSON"], "add_tokens": "for _ , t := range m { tests = append ( tests , t . ( resource . Resource ) ) for _ , g := range configJSON . Gossfiles { fpath := filepath . Join ( path , g . ID ( ) )", "del_tokens": "for id , t := range m { t2 := t . ( resource . Resource ) t2 . SetID ( id ) tests = append ( tests , t2 ) for id , _ := range configJSON . Gossfiles { fpath := filepath . Join ( path , id )", "commit_type": "fix"}
{"commit_tokens": ["Create", "data", ".", "Value", "to", "be", "the", "soy", "expression", "value", "instead", "of", "using", "reflect", ".", "Value"], "add_tokens": "\" \" globals data . Map return Tofu { make ( map [ string ] * parse . TemplateNode ) , make ( data . Map ) } tofu . globals [ name ] = exprValue", "del_tokens": "globals map [ string ] interface { } return Tofu { make ( map [ string ] * parse . TemplateNode ) , make ( map [ string ] interface { } ) } tofu . globals [ name ] = exprValue . Interface ( )", "commit_type": "create"}
{"commit_tokens": ["add", "open", "trace", "support", "."], "add_tokens": "color . Green ( \" core . RunCmd ( \" \" ) core . RunCmd ( \" \" ) core . RunCmd ( \" \" ) core . RunCmd ( \" \" ) core . RunCmd ( \" \" )", "del_tokens": "color . Magenta ( \"", "commit_type": "add"}
{"commit_tokens": ["Adds", "GroupsService", ".", "Delete", "method"], "add_tokens": "err := client . Groups . Delete ( group . ID , UAAToken ) Expect ( err ) . NotTo ( HaveOccurred ( ) ) //_, err := client.Groups.Get(group.ID, UAAToken)", "del_tokens": "//client.Groups.Delete(group.ID, UAAToken) //_, err := client.Group.Get(group.ID, UAAToken)", "commit_type": "add"}
{"commit_tokens": ["added", "more", "archive", "pipe", "test"], "add_tokens": "log . Println ( \" \" , file . Name ( ) )", "del_tokens": "log . Println ( \" \" , file . Name ( ) )", "commit_type": "add"}
{"commit_tokens": ["update", "Result", ".", "Bool", "to", "use", "golang", "bool", "parsing"], "add_tokens": "b , err := strconv . ParseBool ( t . Str ) return ! ( ! b || err != nil )", "del_tokens": "return t . Str != \" \" && t . Str != \" \" && t . Str != \" \"", "commit_type": "update"}
{"commit_tokens": ["change", "the", "vlan", "count", "larger"], "add_tokens": "const vlanCount = 1000000", "del_tokens": "const vlanCount = 4096", "commit_type": "change"}
{"commit_tokens": ["Fix", "dumb", "unescaping", "bug", "."], "add_tokens": "return strings . Replace ( strings . Replace ( s , \" \" , \" \" , - 1 ) , \" \" , \" \" , - 1 ) func escape ( s string , out [ ] rune ) [ ] rune { for _ , c := range s { switch c { case '/' : out = append ( out , '~' , '1' ) case '~' : out = append ( out , '~' , '0' ) default : out = append ( out , c ) } } return out } out = escape ( s , out )", "del_tokens": "return strings . Replace ( strings . Replace ( s , \" \" , \" \" , - 1 ) , \" \" , \" \" , - 1 ) for _ , c := range s { switch c { case '/' : out = append ( out , '~' , '1' ) case '~' : out = append ( out , '~' , '0' ) default : out = append ( out , c ) } }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "problems", "in", "the", "race", "condition", "handling", "logic", "in", "LockJob"], "add_tokens": "var testConnConfig = pgx . ConnConfig { Host : \" \" , Database : \" \" , } func openTestClientMaxConns ( t testing . TB , maxConnections int ) * Client { ConnConfig : testConnConfig , MaxConnections : maxConnections , func openTestClient ( t testing . TB ) * Client { return openTestClientMaxConns ( t , 5 ) }", "del_tokens": "func openTestClient ( t testing . TB ) * Client { ConnConfig : pgx . ConnConfig { Host : \" \" , Database : \" \" , } , MaxConnections : 5 ,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "the", "singleton", "pattern", "in", "favor", "of", "explicit", "creation", "of", "the", "client", "when", "needed", ".", "Feels", "more", "idiomatic", "."], "add_tokens": "// buildClient instanciates the *http.Client used by the browser func ( bow * Browser ) buildClient ( ) * http . Client { return & http . Client { // Head requests the given URL using the HEAD method. if bow . client == nil { bow . client = bow . buildClient ( ) } return bow . client . Jar . Cookies ( bow . Url ( ) ) if bow . client == nil { bow . client = bow . buildClient ( ) } bow . client . Jar = cj if bow . client == nil { bow . client = bow . buildClient ( ) } bow . client . Transport = rt if bow . client == nil { bow . client = bow . buildClient ( ) } resp , err := bow . client . Do ( req )", "del_tokens": "// httpClient returns the *http.Client used by the browser func ( bow * Browser ) httpClient ( ) * http . Client { if bow . client != nil { return bow . client } bow . client = & http . Client { return bow . client // Open requests the given URL using the HEAD method. return bow . httpClient ( ) . Jar . Cookies ( bow . Url ( ) ) bow . httpClient ( ) . Jar = cj bow . httpClient ( ) . Transport = rt resp , err := bow . httpClient ( ) . Do ( req )", "commit_type": "remove"}
{"commit_tokens": ["remove", "kubernetes", "-", "specific", "defaults"], "add_tokens": "goflag \" \" GoHeaderFilePath : filepath . Join ( DefaultSourceTree ( ) , \" \" ) , pflag . CommandLine . AddGoFlagSet ( goflag . CommandLine ) pflag . Parse ( )", "del_tokens": "utilflag \" \" \" \" GoHeaderFilePath : filepath . Join ( DefaultSourceTree ( ) , \" \" ) , utilflag . InitFlags ( ) logs . InitLogs ( )", "commit_type": "remove"}
{"commit_tokens": ["Added", "XFree86", "vendor", "specific", "keysym", "codes", "(", "i", ".", "e", ".", "XF86AudioMute", ")", "."], "add_tokens": "// connect is essentially 'Connect' for either KeyPress or KeyRelease events. func deduceKeyInfo ( state uint16 , detail byte ) ( uint16 , byte ) { mods , kc := state , detail for _ , m := range xgbutil . IgnoreMods { mods &= ^ m } return mods , kc } mods , kc := deduceKeyInfo ( ev . State , ev . Detail ) mods , kc := deduceKeyInfo ( ev . State , ev . Detail )", "del_tokens": "kc , mods := ev . Detail , ev . State for _ , m := range xgbutil . IgnoreMods { mods &= ^ m } kc , mods := ev . Detail , ev . State for _ , m := range xgbutil . IgnoreMods { mods &= ^ m }", "commit_type": "add"}
{"commit_tokens": ["Move", "Configure", "method", "to", "client", "."], "add_tokens": "func ( client * Client ) Configure ( config Config ) { * client . Config = client . Config . merge ( config ) } func ( c * Client ) Flush ( ) { func ( c * Client ) Notify ( err interface { } ) string {", "del_tokens": "func ( c Client ) Flush ( ) { func ( c Client ) Notify ( err interface { } ) string {", "commit_type": "move"}
{"commit_tokens": ["Added", "simple", "BuildQuery", "function", "."], "add_tokens": "err = Query ( BuildQuery ( desc . AllFields , desc . Name , nil ) , list )", "del_tokens": "err = Query ( fmt . Sprintf ( BaseQueryString , desc . AllFields , desc . Name ) , list )", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "Opera", "version", "that", "is", "using", "Webkit"], "add_tokens": "if sections [ len ( sections ) - 1 ] . name == \" \" { p . browser . name = \" \" p . browser . version = sections [ len ( sections ) - 1 ] . version } else if sections [ 2 ] . name == \" \" {", "del_tokens": "if sections [ 2 ] . name == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "internal", "representation", "of", "a", "part"], "add_tokens": "header header copier func ( io . Writer ) error header : m . getPartHeader ( contentType ) , header : m . getPartHeader ( contentType ) , header : m . getPartHeader ( contentType ) , copier : f , func ( m * Message ) getPartHeader ( contentType string ) header { return map [ string ] [ ] string { \" \" : { contentType + \" \" + m . charset } , \" \" : { string ( m . encoding ) } , } }", "del_tokens": "contentType string copier func ( io . Writer ) error contentType : contentType , contentType : contentType , contentType : contentType , copier : f ,", "commit_type": "change"}
{"commit_tokens": ["Update", "to", "lastest", "Go", "-", "Glut", "release"], "add_tokens": "gl . ColorPointer ( 4 , 0 , p . colors ) gl . VertexPointer ( 2 , 0 , p . vertices )", "del_tokens": "\" \" gl . ColorPointer ( 4 , gl . UNSIGNED_BYTE , 0 , unsafe . Pointer ( & ( p . colors [ 0 ] ) ) ) gl . VertexPointer ( 2 , gl . INT , 0 , unsafe . Pointer ( & ( p . vertices [ 0 ] ) ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "to", "Get", "()", "for", "[]", "byte", "keys"], "add_tokens": "\" \" if element . keyHash == h { switch key . ( type ) { case [ ] byte : if bytes . Compare ( element . key . ( [ ] byte ) , key . ( [ ] byte ) ) == 0 { return element . Value ( ) , true } default : if element . key == key { return element . Value ( ) , true } }", "del_tokens": "if element . keyHash == h && element . key == key { return element . Value ( ) , true", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "to", "run", "with", "delay", "=", "0"], "add_tokens": "\" \" : string ( data ) , if time . Since ( st ) > time . Second {", "del_tokens": "\" \" : data , if time . Since ( st ) > 6 * time . Second {", "commit_type": "fix"}
{"commit_tokens": ["adding", "pprof", "controller", "as", "defaults"], "add_tokens": "return & PProfController { NewController ( \" \" ) } func ( p * PProfController ) Profile ( c * Context , next NextHandler ) { func ( p * PProfController ) Index ( c * Context , next NextHandler ) { func ( p * PProfController ) Symbol ( c * Context , next NextHandler ) { func ( p * PProfController ) Trace ( c * Context , next NextHandler ) {", "del_tokens": "\" \" return PProfController { NewController ( \" \" ) } func ( p * PProfController ) Profile ( c * Context , next relay . NextHandler ) { func ( p * PProfController ) Index ( c * Context , next relay . NextHandler ) { func ( p * PProfController ) Symbol ( c * Context , next relay . NextHandler ) { func ( p * PProfController ) Trace ( c * Context , next relay . NextHandler ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "lint", "add", "godoc", "comments"], "add_tokens": "// Snapshot compares the given value to the it's previous value stored on the filesystem. // An error containing a diff is returned if the snapshots do not match. // Snapshot determines the snapshot file automatically from the name of the calling function. // SnapshotMulti is identical to Snapshot but can be called multiple times from the same function. // This is done by providing a unique snapshotId for each invocation. return fmt . Errorf ( \" \\n \\n \" , diff )", "del_tokens": "\" \" return errors . New ( fmt . Sprintf ( \" \\n \\n \" , diff ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "post", "order", "expectation", "in", "monitor", "test", "."], "add_tokens": "if b . tip [ 0 ] != \" \" { t . Errorf ( \" \" , b . tip [ 0 ] ) if b . tip [ 1 ] != \" \" { t . Errorf ( \" \" , b . tip [ 1 ] )", "del_tokens": "if b . tip [ 0 ] != \" \" { t . Errorf ( \" \" , b . tip [ 0 ] ) if b . tip [ 1 ] != \" \" { t . Errorf ( \" \" , b . tip [ 1 ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "better", "logging", "for", "registration", "."], "add_tokens": "for s := range heartbeatChan { log . Infof ( \" \" , s )", "del_tokens": "for range heartbeatChan {", "commit_type": "add"}
{"commit_tokens": ["added", "fix", "on", "relay", "fore", "request", "gen"], "add_tokens": "_ , err := io . CopyN ( buf , reader , int64 ( proxy . base . MaxSize ) ) proxy . Reply ( 250 , \" \" ) datawriter , err := c . Data ( ) if err != nil { return err n , err := datawriter . Write ( bu ) log . Debug ( \" \" , n ) err = datawriter . Close ( ) c . Close ( )", "del_tokens": "n , err := io . CopyN ( buf , reader , int64 ( proxy . base . MaxSize ) ) log . Debug ( \" \" , n , err ) proxy . Reply ( 250 , \" \" ) log . Debug ( \" \" ) datawriter , err := c . Data ( ) if proxy . envelope != nil { envl := proxy . envelope envl . Data = append ( [ ] byte { } , bu ... ) log . Debug ( \" \" , envl ) //jsonify envelope // envljson, err := json.Marshal(envl) // if err != nil { // log.Error(\"json.Mashall fail on envelop\", err) // } else { // proxy.recorder.Data(SMTPSensorTypeMail, envl.ID, envljson) // } _ , err = datawriter . Write ( bu ) err = datawriter . Close ( ) log . Error ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["update", "comments", "in", "logging", ".", "go"], "add_tokens": "// These variables are visible to users. startTime time . Time // start time of the logger // Internally used variables, which don't have get and set functions.", "del_tokens": "startTime time . Time // start time of the logger // Internal used variables, which don't have get and set functions.", "commit_type": "update"}
{"commit_tokens": ["Changed", "function", "position", "back", "in", "item", ".", "go"], "add_tokens": "// NewItem creates a new item for use with a stack or queue. func NewItem ( value [ ] byte ) * Item { return & Item { Value : value } } // NewItemString is a helper function for NewItem that accepts a // value as a string rather than a byte slice. func NewItemString ( value string ) * Item { return NewItem ( [ ] byte ( value ) ) }", "del_tokens": "// NewItem creates a new item for use with a stack or queue. func NewItem ( value [ ] byte ) * Item { return & Item { Value : value } } // NewItemString is a helper function for NewItem that accepts a // value as a string rather than a byte slice. func NewItemString ( value string ) * Item { return NewItem ( [ ] byte ( value ) ) }", "commit_type": "change"}
{"commit_tokens": ["Fixed", ":", "Get", "timer", "reference", "under", "lock", "to", "prevent", "data", "race"], "add_tokens": "var t * time . Timer if a != nil { t = a . t } if t != nil { t . Stop ( )", "del_tokens": "if a != nil && a . t != nil { a . t . Stop ( )", "commit_type": "fix"}
{"commit_tokens": ["use", "strings", ".", "ToValidUTF8", "to", "validate", "string"], "add_tokens": "\" \" t = strings . ToValidUTF8 ( t , \" \" ) s = strings . ToValidUTF8 ( s , \" \" )", "del_tokens": "t = string ( [ ] rune ( t ) ) s = string ( [ ] rune ( s ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "some", "windows", "archive", "issues"], "add_tokens": "\" \" if runtime . GOOS == \" \" { t . Skip ( \" \" ) } if runtime . GOOS == \" \" { t . Skip ( \" \" ) } oldName := filepath . ToSlash ( filepath . Join ( testDir , \" \" ) ) newName := filepath . ToSlash ( filepath . Join ( testDir , \" \" ) ) os . Remove ( newName ) oldName := filepath . ToSlash ( filepath . Join ( testDir , \" \" ) ) newName := filepath . ToSlash ( filepath . Join ( testDir , \" \" ) ) os . Remove ( newName ) t . Fatalf ( \" \\n \\n \\n \\n \" , expected , entries ) t . Fatalf ( \" \\n \\n \\n \\n \" , expected , entries )", "del_tokens": "oldName := filepath . Join ( testDir , \" \" ) newName := filepath . Join ( testDir , \" \" ) oldName := filepath . Join ( testDir , \" \" ) newName := filepath . Join ( testDir , \" \" ) t . Fatalf ( \" \" , entries ) t . Fatalf ( \" \" , entries )", "commit_type": "fix"}
{"commit_tokens": ["fix", "race", "condition", "and", "wait", "for", "writes", "to", "complete", "thanks", "@jbenet"], "add_tokens": "buf := make ( [ ] byte , len ( read ) ) copy ( buf , read ) s . extra = buf extra := make ( [ ] byte , len ( s . extra ) - n ) copy ( extra , s . extra [ n : ] ) s . extra = extra errs := make ( chan error , 1 ) case s . data_out <- msg { header : s . header , data : b , err : errs } : select { case err := <- errs : return len ( b ) , err case <- s . closed : return 0 , errors . New ( \" \" ) } err : make ( chan error , 1 ) , //throw away error, whatever msg . err <- err continue msg . err <- err continue msg . err <- err continue msg . err <- nil err : make ( chan error , 1 ) , //throw away error", "del_tokens": "s . extra = read s . extra = s . extra [ n : ] case s . data_out <- msg { header : s . header , data : b } : return len ( b ) , nil panic ( err ) panic ( err ) panic ( err )", "commit_type": "fix"}
{"commit_tokens": ["Add", "data", "URI", "minification", "to", "all", "URL", "attributes"], "add_tokens": "assertHTML ( t , m , \" \" , \" \" ) assertHTML ( t , m , \" \\\" \\\" \" , \" \" ) assertHTML ( t , m , `<script type=\"text/html\"><![CDATA[ <img id=\"x\"> ]]></script>` , `<script type=text/html><img id=x></script>` )", "del_tokens": "//assertHTML(t, \"<!--[if IE 6]>some spaces<![endif]-->\", \"<!--[if IE 6]>some spaces<![endif]-->\") // TODO: make this work by changing the tokenizer code, see other TODO //assertHTML(t, \"<ul><li></li><a></a></ul>\", \"<ul><li></li><a></a></ul>\") assertHTML ( t , m , `<script type=\"text/html\"><![CDATA[ <img id=\"x\"> ]]></script>` , `<script type=text/html><![CDATA[<img id=x>]]></script>` )", "commit_type": "add"}
{"commit_tokens": ["Use", "uuid", ".", "Must", "()", "as", "suggested", "upstream"], "add_tokens": "return DefaultEncoder . Encode ( uuid . Must ( uuid . NewV4 ( ) ) ) return enc . Encode ( uuid . Must ( uuid . NewV4 ( ) ) ) u = uuid . Must ( uuid . NewV4 ( ) ) return enc . Encode ( uuid . Must ( uuid . NewV4 ( ) ) )", "del_tokens": "\" \" str , err := uuid . NewV4 ( ) if err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) } return DefaultEncoder . Encode ( str ) str , err := uuid . NewV4 ( ) if err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) } return enc . Encode ( str ) var err error u , err = uuid . NewV4 ( ) if err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) } str , err := uuid . NewV4 ( ) if err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) } return enc . Encode ( str )", "commit_type": "use"}
{"commit_tokens": ["Use", "common", "prometheus", "log", "library"], "add_tokens": "\" \" log . Errorf ( \" \" , err ) log . Errorf ( \" \" , err ) log . Errorf ( \" \" , len ( csvRow ) , expectedCsvFieldCount ) log . Errorf ( \" \" , valueStr , err ) return 0 , fmt . Errorf ( \" \" , err ) return 0 , fmt . Errorf ( \" \" , err ) log . Infof ( \" \" , * listenAddress )", "del_tokens": "\" \" log . Printf ( \" \" , err ) log . Printf ( \" \" , err ) log . Printf ( \" \" , len ( csvRow ) , expectedCsvFieldCount ) log . Printf ( \" \" , valueStr , err ) return 0 , fmt . Errorf ( \" \" , err ) return 0 , fmt . Errorf ( \" \" , err ) log . Printf ( \" \" , * listenAddress )", "commit_type": "use"}
{"commit_tokens": ["Use", "felixge", "/", "httpsnoop", "approach", "to", "preserve", "additional", "interfaces"], "add_tokens": "sct := & statusCodeTracker { w , 200 } h ( sct . wrappedResponseWriter ( ) , r ) ext . HTTPStatusCode . Set ( sp , uint16 ( sct . status ) )", "del_tokens": "type statusCodeTracker struct { http . ResponseWriter status int } func ( w * statusCodeTracker ) WriteHeader ( status int ) { w . status = status w . ResponseWriter . WriteHeader ( status ) } w = & statusCodeTracker { w , 200 } h ( w , r ) ext . HTTPStatusCode . Set ( sp , uint16 ( w . ( * statusCodeTracker ) . status ) )", "commit_type": "use"}
{"commit_tokens": ["added", "ContentType", "to", "httpx", "package"], "add_tokens": "\" \" ct := defaults . String ( httpx . ContentType ( ctx . Request ( ) ) , \" \" )", "del_tokens": "ct := defaults . String ( strings . ToLower ( ctx . Request ( ) . Header . Get ( \" \" ) ) , \" \" )", "commit_type": "add"}
{"commit_tokens": ["use", "existing", "err", "instead", "of", "making", "up", "new", "one", "in", "argNames", "()"], "add_tokens": "return nil , err", "del_tokens": "\" \" return nil , errors . New ( \" \" + file )", "commit_type": "use"}
{"commit_tokens": ["Update", "README", ".", "md", "fix", "broken", "code", "in", "detector", "package", "fix", "other", "minor", "bugs", "update", "tests", "."], "add_tokens": "// go func() { // for { // receiver <- s.ch // log.V(2).Infoln(\"Master detected\") // } // }() return nil", "del_tokens": "go func ( ) { for { receiver <- s . ch log . V ( 2 ) . Infoln ( \" \" ) } } ( )", "commit_type": "update"}
{"commit_tokens": ["fix", "usage", "of", "astest", ".", "NewContext"], "add_tokens": "c , done , err := aetest . NewContext ( ) defer done ( )", "del_tokens": "c , err := aetest . NewContext ( nil ) defer c . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["add", "usage", "examples", "to", "readme"], "add_tokens": "cmd . Command ( \" \" , \" \" , serversList ) c . Command ( \" \" , \" \" , serversList ) cmd . Command ( \" \" , \" \" , printAPIKey ) c . Command ( \" \" , \" \" , printAPIKey ) cmd . Command ( \" \" , \" \" , printAPIKey ) c . Command ( \" \" , \" \" , printAPIKey )", "del_tokens": "cmd . Command ( \" \" , \" \" , serversList ) c . Command ( \" \" , \" \" , serversList ) cmd . Command ( \" \" , \" \" , printAPIKey ) c . Command ( \" \" , \" \" , printAPIKey ) cmd . Command ( \" \" , \" \" , printAPIKey ) c . Command ( \" \" , \" \" , printAPIKey )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "listing", "all", "raw", "files"], "add_tokens": "func printResources ( res [ ] * cloudinary . Resource , err error ) { if err != nil { fatal ( err . Error ( ) ) } fmt . Printf ( \" \\n \" , \" \" , \" \" , \" \" , \" \" ) fmt . Println ( strings . Repeat ( \" \" , 70 ) ) for _ , r := range res { fmt . Printf ( \" \\n \" , r . PublicId , r . Version , r . ResourceType , r . Size ) } } listRaws := flag . Bool ( \" \" , false , \" \" ) printResources ( service . Images ( ) ) } else if * listRaws { printResources ( service . RawFiles ( ) )", "del_tokens": "// listRaws := flag.Bool(\"listraws\", false, \"List all remote raw files\") images , err := service . Images ( ) if err != nil { fatal ( err . Error ( ) ) } fmt . Printf ( \" \\n \" , \" \" , \" \" , \" \" , \" \" , \" \" ) fmt . Println ( strings . Repeat ( \" \" , 70 ) ) for _ , img := range images { fmt . Printf ( \" \\n \" , img . PublicId , img . Format , img . Version , img . ResourceType , img . Size ) }", "commit_type": "add"}
{"commit_tokens": ["updated", "package", "name", "from", "spotify", "to", "spotify_test", "(", "stay", "consistent", "with", "other", "provider", "packages", ")"], "add_tokens": "package spotify_test \" \" s := & spotify . Session { } s := & spotify . Session { } s := & spotify . Session { }", "del_tokens": "package spotify s := Session { } s := & Session { } s := & Session { }", "commit_type": "update"}
{"commit_tokens": ["Add", "Close", "function", "to", "server", "handler", "interface"], "add_tokens": "require . False ( t , h . isClosed ( ) ) require . True ( t , h . isClosed ( ) ) n int closed bool received [ ] string func ( h * mockHandler ) Close ( ) { h . Lock ( ) h . closed = true h . Unlock ( ) } func ( h * mockHandler ) isClosed ( ) bool { h . Lock ( ) defer h . Unlock ( ) return h . closed }", "del_tokens": "n int received [ ] string handleConnectionFn func ( conn net . Conn )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "bufio", ".", "Writer", "to", "buffer", "Puts", "to", "the", "database"], "add_tokens": "startingSlot := ( hash >> 8 ) % table . length slot := startingSlot if ( slot == startingSlot ) { break }", "del_tokens": "slot := ( hash >> 8 ) % table . length", "commit_type": "use"}
{"commit_tokens": ["Fix", "test", "and", "restore", "overall"], "add_tokens": "func ( d * DockTile ) SetBadge ( v interface { } ) error { return nil", "del_tokens": "func ( d * DockTile ) SetBadge ( v interface { } ) {", "commit_type": "fix"}
{"commit_tokens": ["Move", "doc", "examples", "to", "tokenize_test"], "add_tokens": "// characters. // This tokenizer splits text into a sequence of word-like tokens.", "del_tokens": "// characters. For example, // // t := NewWordPunctTokenizer() // t.Tokenize(\"They'll save and invest more.\") // // [They 'll save and invest more .] // This tokenizer splits text into a sequence of word-like tokens. For example, // // t := NewWordBoundaryTokenizer() // t.Tokenize(\"They'll save and invest more.\") // // [They'll save and invest more]", "commit_type": "move"}
{"commit_tokens": ["Move", "fake", "time", "service", "extension", "back", "to", "bosh", "-", "agent"], "add_tokens": "NowTimes [ ] time . Time SleepDuration time . Duration if len ( f . NowTimes ) < 1 { return time . Now ( ) } time := f . NowTimes [ 0 ] if len ( f . NowTimes ) > 0 { f . NowTimes = f . NowTimes [ 1 : ] } return time } func ( f * FakeService ) Sleep ( duration time . Duration ) { f . SleepDuration = duration", "del_tokens": "NowTime time . Time return f . NowTime", "commit_type": "move"}
{"commit_tokens": ["Fix", "error", "message", "along", "with", "golint"], "add_tokens": "return nil , fmt . Errorf ( \" \" , err )", "del_tokens": "return nil , fmt . Errorf ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Added", "proper", "parsing", "for", "server", "PINGs"], "add_tokens": "Version = \" \"", "del_tokens": "Version = \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "adaptor", "for", "FUSE", "cancellation", "and", "a", "ReadDir", "stub", "."], "add_tokens": "\" \" \" \" authContext context . Context bucketName string objectPrefix string // A version of readDir that is context-aware. The context must contain auth // information. func ( d * dir ) readDirWithContext ( ctx context . Context ) ( [ ] fuse . Dirent , fuse . Error ) func ( d * dir ) ReadDir ( intr fs . Intr ) ( [ ] fuse . Dirent , fuse . Error ) { ctx , cancel := withIntr ( d . authContext , intr ) defer cancel ( ) return d . readDirWithContext ( ctx ) }", "del_tokens": "prefix string", "commit_type": "add"}
{"commit_tokens": ["Add", "URLs", "field", "to", "changelogs"], "add_tokens": "\" \" if reflect . DeepEqual ( clog , r . changelogs [ i ] ) {", "del_tokens": "if clog == r . changelogs [ i ] {", "commit_type": "add"}
{"commit_tokens": ["Add", "doc", "and", "test", "for", "List", "zero", "value"], "add_tokens": "// List represents a list of numbers with support for efficient // prefix sum computation. The zero value is an empty list.", "del_tokens": "// List represents a Fenwick tree.", "commit_type": "add"}
{"commit_tokens": ["Implement", "white", "/", "blacklisting", "for", "socks", "and", "ssh"], "add_tokens": "\" \" \" \" if ! s . Base . Node . Can ( \" \" , raddr ) { glog . Errorf ( \" \" , raddr ) return } if ! s . Base . Node . Can ( \" \" , addr ) { glog . Errorf ( \" \" , addr ) req . Reply ( false , nil ) return }", "del_tokens": "\" \" \" \"", "commit_type": "implement"}
{"commit_tokens": ["Fix", "missing", "mock", "when", "overridden", "by", "subpackage"], "add_tokens": "if * fAll { ret := checkDir ( p , path , name ) if ret { return true } } else { continue if * fAll { walkDir ( path ) }", "del_tokens": "ret := checkDir ( p , path , name ) if ret { return true walkDir ( path )", "commit_type": "fix"}
{"commit_tokens": ["fix", "path", "for", "a", "build"], "add_tokens": "// Create a new build for this job. // Params can be nil. if params == nil { return jenkins . post ( fmt . Sprintf ( \" \" , job . Name ) , params , nil ) } else { return jenkins . post ( fmt . Sprintf ( \" \" , job . Name ) , params , nil ) }", "del_tokens": "return jenkins . post ( fmt . Sprintf ( \" \" , job . Name ) , params , nil )", "commit_type": "fix"}
{"commit_tokens": ["Use", "EqualFold", "instead", "of", "ToLower"], "add_tokens": "if strings . EqualFold ( mp . name , metaname ) { var fpath string fname := strings . TrimSuffix ( f . Name ( ) , filepath . Ext ( f . Name ( ) ) ) if strings . EqualFold ( fname , objName ) {", "del_tokens": "if strings . ToLower ( mp . name ) == strings . ToLower ( metaname ) { fpath := \" \" fname := strings . ToLower ( f . Name ( ) ) fname = strings . TrimSuffix ( fname , filepath . Ext ( fname ) ) if strings . ToLower ( fname ) == strings . ToLower ( objName ) { fmt . Println ( \" \" + metaType ) fmt . Println ( \" \" + member )", "commit_type": "use"}
{"commit_tokens": ["Adding", "math", ".", "Seq", "function"], "add_tokens": "func mustSeq ( n ... interface { } ) [ ] int64 { m := MathNS ( ) s , err := m . Seq ( n ... ) if err != nil { panic ( err ) } return s } func TestSeq ( t * testing . T ) { m := MathNS ( ) assert . EqualValues ( t , [ ] int64 { 0 , 1 , 2 , 3 } , mustSeq ( 0 , 3 ) ) assert . EqualValues ( t , [ ] int64 { 1 , 0 } , mustSeq ( 0 ) ) assert . EqualValues ( t , [ ] int64 { 0 , 2 , 4 } , mustSeq ( 0 , 4 , 2 ) ) assert . EqualValues ( t , [ ] int64 { 0 , 2 , 4 } , mustSeq ( 0 , 5 , 2 ) ) assert . EqualValues ( t , [ ] int64 { 0 } , mustSeq ( 0 , 5 , 8 ) ) _ , err := m . Seq ( ) assert . Error ( t , err ) }", "del_tokens": "// assert.Equal(t, int64(1), m.Mod(true, \"42\"))", "commit_type": "add"}
{"commit_tokens": ["Add", "Term", "()", "and", "Kill", "()", "for", "stopping", "servers", "."], "add_tokens": "defer server . Term ( )", "del_tokens": "defer server . Stop ( )", "commit_type": "add"}
{"commit_tokens": ["Allow", "ID", "to", "have", "Empty", "values"], "add_tokens": "type ID [ ] byte return [ ] byte ( `\"` + id . String ( ) + `\"` ) , nil if id . IsEmpty ( ) { return nil } copy ( ( * id ) [ : ] , out ) // Equals compares two ids func ( id ID ) Equals ( other ID ) bool { if len ( id ) != len ( other ) { return false } for i := range id { if id [ i ] != other [ i ] { return false } } return true } if len ( id ) == 0 { return true } for _ , b := range id { if b != 0 { return false } } return true", "del_tokens": "// Comparator for empty IDs var emptyID [ byteLength ] byte type ID [ byteLength ] byte return [ ] byte ( \" \\\" \" + id . String ( ) + \" \\\" \" ) , nil copy ( id [ : ] , out ) return id == emptyID", "commit_type": "allow"}
{"commit_tokens": ["Use", "underlying", "rand", ".", "Reader", "if", "available", "in", "Monotnoic"], "add_tokens": "m := monotonic { Reader : bufio . NewReader ( entropy ) , inc : inc } if m . inc == 0 { m . inc = math . MaxUint32 if rng , ok := entropy . ( * rand . Rand ) ; ok { m . rng = rng } else { m . rng = rand . New ( rand . NewSource ( time . Now ( ) . UnixNano ( ) ) ) return & m", "del_tokens": "if inc == 0 { inc = math . MaxUint32 return & monotonic { Reader : bufio . NewReader ( entropy ) , rng : rand . New ( rand . NewSource ( time . Now ( ) . UnixNano ( ) ) ) , inc : inc ,", "commit_type": "use"}
{"commit_tokens": ["Use", "ValidationContext", ".", "IdAttribute", "property"], "add_tokens": "idAttr := el . SelectAttr ( ctx . IdAttribute ) idAttr := el . SelectAttr ( ctx . IdAttribute )", "del_tokens": "idAttr := el . SelectAttr ( DefaultIdAttr ) idAttr := el . SelectAttr ( DefaultIdAttr )", "commit_type": "use"}
{"commit_tokens": ["add", "initial", "prototype", "of", "squares", "pattern"], "add_tokens": "func ( s * SVG ) Rect ( x , y , w , h interface { } , args map [ string ] interface { } ) { rect_str := fmt . Sprintf ( \" \" , x , y , w , h , s . Write_args ( args ) ) case \" \" : str += fmt . Sprintf ( \" \" , k , v )", "del_tokens": "func ( s * SVG ) Rect ( x , y , w , h string , args map [ string ] interface { } ) { rect_str := fmt . Sprintf ( \" \" , x , y , w , h , s . Write_args ( args ) )", "commit_type": "add"}
{"commit_tokens": ["add", "block", "storage", "create", "&", "list"], "add_tokens": "Version = \" \"", "del_tokens": "Version = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "missing", "namespace", "for", "client", "example"], "add_tokens": "var caller telnet . Caller = telnet . StandardCaller var caller telnet . Caller = telnet . StandardCaller", "del_tokens": "var caller Caller = telnet . StandardCaller var caller Caller = telnet . StandardCaller", "commit_type": "fix"}
{"commit_tokens": ["Allow", "underscores", "in", "service", "names", "."], "add_tokens": "`((?P<name>[[:word:]\\-/_]+))` +", "del_tokens": "`((?P<name>[[:word:]\\-/]+))` +", "commit_type": "allow"}
{"commit_tokens": ["add", "correct", "headers", "to", "PATCH", "requests"], "add_tokens": "return & Request { client : c , method : \" \" , headers : map [ string ] string { \" \" : \" \" , } , }", "del_tokens": "return & Request { client : c , method : \" \" }", "commit_type": "add"}
{"commit_tokens": ["Made", "MemProfileRate", "an", "unexported", "const", "and", "moved", "path", "resolver", "back", "inline"], "add_tokens": "// memProfileRate sets the rate for the memory profile. const memProfileRate = 4096 path , err := func ( ) ( string , error ) { if p := prof . path ; p != \" \" { return p , os . MkdirAll ( p , 0777 ) } return ioutil . TempDir ( \" \" , \" \" ) } ( ) runtime . MemProfileRate = memProfileRate", "del_tokens": "// MemProfileRate sets the rate for the memory profile. var MemProfileRate = 4096 // profilePath returns the path where the output will be dumped. If it is not // set, a temporary directory will be used func ( p * profile ) profilePath ( ) ( resolvedPath string , err error ) { if p := p . path ; p != \" \" { return p , os . MkdirAll ( p , 0777 ) } return ioutil . TempDir ( \" \" , \" \" ) } path , err := prof . profilePath ( ) runtime . MemProfileRate = MemProfileRate", "commit_type": "make"}
{"commit_tokens": ["Fix", "issues", "with", "request", "body", "and", "Content", "-", "Length"], "add_tokens": "req . WithChunked ( bytes . NewBufferString ( \" \" ) ) req . WithChunked ( nil ) req1 . WithChunked ( nil ) req1 . WithChunked ( nil ) req2 . WithChunked ( nil ) req3 . WithChunked ( nil ) req4 . WithChunked ( nil ) req5 . WithChunked ( nil ) req6 . WithChunked ( nil ) req7 . WithChunked ( nil )", "del_tokens": "req . WithBody ( bytes . NewBufferString ( \" \" ) ) req . WithBody ( nil ) req1 . WithBody ( nil ) req1 . WithBody ( nil ) req2 . WithBody ( nil ) req3 . WithBody ( nil ) req4 . WithBody ( nil ) req5 . WithBody ( nil ) req6 . WithBody ( nil ) req7 . WithBody ( nil )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "unicode", "string", "width", "count"], "add_tokens": "\" \" var ansi = regexp . MustCompile ( \" \\033 \\\\ \" ) return runewidth . StringWidth ( ansi . ReplaceAllLiteralString ( str , \" \" ) )", "del_tokens": "\" \" ) var ( ansi = regexp . MustCompile ( \" \\033 \\\\ \" ) tmp := ansi . ReplaceAllLiteralString ( str , \" \" ) tmp_rune := [ ] rune ( tmp ) count := 0 for _ , v := range tmp_rune { if v > 128 { count ++ } } return utf8 . RuneCountInString ( tmp ) + count", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "incorrect", "error", "on", "missing", "key"], "add_tokens": "\" \" r , err := fs . d . ReadStream ( hashKey ( key ) , false ) if os . IsNotExist ( err ) { return nil , ErrNotExists } return r , err", "del_tokens": "return fs . d . ReadStream ( hashKey ( key ) , false )", "commit_type": "fix"}
{"commit_tokens": ["Added", "command", "to", "generate", "schema"], "add_tokens": "ID int64 `json:\"id,omitempty\"` return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" ) // JobRunHistoryResponse describes the api response from // Validate a job structure has non-nil values on correct attributes return errors . New ( \" \" )", "del_tokens": "Id int64 `json:\"id,omitempty\"` return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" ) return errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "available", "plugins", "to", "runner", "as", "a", "struct", "with", "synchronizatin"], "add_tokens": "func ( m * monitor ) Start ( availablePlugins * availablePlugins ) { availablePlugins . Lock ( ) for _ , ap := range availablePlugins . Table ( ) { availablePlugins . Unlock ( )", "del_tokens": "func ( m * monitor ) Start ( ) { for _ , ap := range availablePlugins {", "commit_type": "add"}
{"commit_tokens": ["Add", "IsIO", "to", "detect", "if", "an", "error", "is", "of", "the", "ErrIO", "type", "."], "add_tokens": "import \" \" // IsIO returns a boolean indicating whether the error is known to report that // the underlying reader or writer encountered an ErrIO. func IsIO ( err error ) bool { switch e := err . ( type ) { case * UnmarshalError : return e . ErrorCode == ErrIO case * MarshalError : return e . ErrorCode == ErrIO } return false }", "del_tokens": "import ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Change", "import", "path", "to", "be", "absolute", "."], "add_tokens": "geojson \" \"", "del_tokens": "geojson \" \"", "commit_type": "change"}
{"commit_tokens": ["fixed", "pdu", "out", "spec", "check", "for", "trx", "and", "tx", "binds", "."], "add_tokens": "default :", "del_tokens": "case SUBMIT_SM , DELIVER_SM_RESP , BIND_TRANSCEIVER :", "commit_type": "fix"}
{"commit_tokens": ["Moved", "special", "localhost", "logic", "into", "a", "reusable", "funciton"], "add_tokens": "// MoveToFront looks for string in a slice of strings and if it finds it, moves // it to the front of the slice. // Note: this could probably be made faster using pointers to switch the values // instead of copying a bunch of crap, but it works and speed is not a problem. func MoveToFront ( list [ ] string , search string ) [ ] string { for k , v := range list { if v == search { list = append ( list [ : k ] , list [ k + 1 : ] ... ) } } return append ( [ ] string { search } , list ... ) } // ListDomainsByIp will look through Hostfile to find domains that match the // specified Ip and return them in a sorted slice. names = MoveToFront ( names , \" \" )", "del_tokens": "for k , v := range names { if v == \" \" { names = append ( names [ : k ] , names [ k + 1 : ] ... ) } } names = append ( [ ] string { \" \" } , names ... )", "commit_type": "move"}
{"commit_tokens": ["Fix", "a", "bug", "when", "keys", "does", "not", "start", "with", "prefix", "and", "contains", "prefix"], "add_tokens": "if ! bytes . HasPrefix ( p . external . key , prefix ) {", "del_tokens": "if ! bytes . Contains ( p . external . key , prefix ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "Request", "struct", "in", "rewrite", "interface"], "add_tokens": "Rewrite ( request * Request ) * AddrSpec", "del_tokens": "Rewrite ( addr * AddrSpec ) * AddrSpec", "commit_type": "use"}
{"commit_tokens": ["Fixed", "blob", "close", "function", "to", "return", "an", "error"], "add_tokens": "func ( d * Driver ) Close ( ) error {", "del_tokens": "func ( d * Driver ) Close ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "passing", "helper", "functions", "for", "templates", "to", "Mail", "method"], "add_tokens": "func ( m * Mailer ) Mail ( to , subjectTemplate , templateURL , defaultTemplate string , templateData map [ string ] interface { } , funcMap map [ string ] interface { } ) error { if funcMap != nil { tmp = tmp . Funcs ( funcMap ) }", "del_tokens": "func ( m * Mailer ) Mail ( to , subjectTemplate , templateURL , defaultTemplate string , templateData map [ string ] interface { } ) error {", "commit_type": "allow"}
{"commit_tokens": ["Use", "correct", "name", "during", "decode", "with", "omit", "options"], "add_tokens": "IP string `toml:\"ip,omitempty\"`", "del_tokens": "IP string `toml:\"ip\"`", "commit_type": "use"}
{"commit_tokens": ["add", "offset", "param", "to", "kafka", ".", "NewConsumer", "()"], "add_tokens": "func NewConsumer ( brokers [ ] string , topic string , offset int64 ) Consumer { consumer , err := master . ConsumePartition ( topic , 0 , offset )", "del_tokens": "func NewConsumer ( brokers [ ] string , topic string ) Consumer { consumer , err := master . ConsumePartition ( topic , 0 , sarama . OffsetNewest )", "commit_type": "add"}
{"commit_tokens": ["Use", "/", "etc", "/", "confd", "as", "the", "default", "confdir"], "add_tokens": "ConfDir : \" \" ,", "del_tokens": "ConfDir : \" \" ,", "commit_type": "use"}
{"commit_tokens": ["Use", "TEST_TMPDIR", "(", "if", "it", "exists", ")", "for", "the", "sharedmem_test", "."], "add_tokens": "\" \" tmpDir := os . Getenv ( \" \" ) if tmpDir == \" \" { tmpDir = os . Getenv ( \" \" ) } f , err := ioutil . TempFile ( tmpDir , \" \" )", "del_tokens": "f , err := ioutil . TempFile ( \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Added", "better", "commenting", "for", "things", "fixed", "in", "commit", "bfa6a5a"], "add_tokens": "// initialize the neighbors as an empty // slice of Neighbors. insertSorted will // take care of capping the neighbors at // K.", "del_tokens": "// initialize neighbors with first k // training examples", "commit_type": "add"}
{"commit_tokens": ["Implemented", "basic", "support", "for", "user", "defined", "functions", "and", "the", "execution", "of", "those", "functions"], "add_tokens": "env := NewEnv ( & StringLoader { } ) err := execute ( test . tmpl , w , test . ctx , env )", "del_tokens": "err := execute ( test . tmpl , w , test . ctx , & StringLoader { } )", "commit_type": "implement"}
{"commit_tokens": ["fix", "random", "map", "order", "problem"], "add_tokens": "length := len ( s . posts ) for i := 0 ; i < length ; i ++ { postsSlice [ i ] = * s . posts [ strconv . Itoa ( i + 1 ) ] if i + 1 >= int ( l ) { length := len ( s . posts ) for i := 0 ; i < length ; i ++ { postsSlice [ i ] = * s . posts [ strconv . Itoa ( i + 1 ) ]", "del_tokens": "i int64 for _ , p := range s . posts { postsSlice [ i ] = * p i ++ if i >= l { for _ , p := range s . posts { postsSlice [ i ] = * p i ++", "commit_type": "fix"}
{"commit_tokens": ["Add", "Stat", "to", "Conn", "interface"], "add_tokens": "// Stat returns metadata pertaining to this stream. // Stat stores metadata pertaining to a given Stream/Conn. // Stat stores metadata pertaining to this conn. Stat ( ) Stat", "del_tokens": "// StreamInfo stores metadata pertaining to a given Stream.", "commit_type": "add"}
{"commit_tokens": ["Use", "*", "internal", "intstead", "of", "internal"], "add_tokens": "INTERNAL_RPC = \" \"", "del_tokens": "INTERNAL_RPC = \" \"", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "values", "of", "the", "2", "-", "Degree", "illuminants"], "add_tokens": "var D65 = [ 3 ] float64 { 0.95047 , 1.00000 , 1.08883 } var D50 = [ 3 ] float64 { 0.96422 , 1.00000 , 0.82521 }", "del_tokens": "var D65 = [ 3 ] float64 { 0.95043 , 1.00000 , 1.08890 } var D50 = [ 3 ] float64 { 0.96421 , 1.00000 , 0.82519 }", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "Thai", "word", "corpus", "and", "change", "directory"], "add_tokens": "return LoadDict ( path . Join ( path . Dir ( filename ) , \" \" ) )", "del_tokens": "return LoadDict ( path . Join ( path . Dir ( filename ) , \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["move", "drivers", "to", "a", "standalone", "file", "to", "make", "it", "easier", "for", "someone", "to", "add", "a", "driver"], "add_tokens": "log . Printf ( \" \" , socket )", "del_tokens": "log . Printf ( \" \" , socket )", "commit_type": "move"}
{"commit_tokens": ["Create", "NewResponseError", "to", "encapsulate", "the", "logic"], "add_tokens": "respErr := NewResponseError ( sawyerResp ) resp = & Response { Response : sawyerResp . Response , Error : respErr }", "del_tokens": "var respErr ResponseError if sawyerResp . IsApiError ( ) { respErr = sawyerResp . ApiError . ( ResponseError ) } resp = & Response { Response : sawyerResp . Response , Error : & respErr }", "commit_type": "create"}
{"commit_tokens": ["Remove", "%c", "as", "it", "was", "not", "supported", "by", "jehiah", "version"], "add_tokens": "const benchfmt = `%A %a %B %b %d %H %I %M %m %p %S %Y %y %Z`", "del_tokens": "const benchfmt = `%A %a %B %b %c %d %H %I %M %m %p %S %Y %y %Z`", "commit_type": "remove"}
{"commit_tokens": ["add", "separate", "testing", "of", "lock", "and", "unlock", "using", "a", "GCS", "stub"], "add_tokens": "\" \" \" \" storage \" \" const ( defaultStorageLockURL = \" \" defaultStorageUnlockURL = \" \" ) var ( storageLockURL = defaultStorageLockURL storageUnlockURL = defaultStorageUnlockURL ) url := fmt . Sprintf ( \" \" , storageLockURL , m . bucket , q . Encode ( ) ) url := fmt . Sprintf ( \" \" , storageUnlockURL , m . bucket , m . object )", "del_tokens": "\" \" \" \" storage \" \" url := fmt . Sprintf ( \" \" , m . bucket , q . Encode ( ) ) url := \" \" + m . bucket + \" \" + m . object", "commit_type": "add"}
{"commit_tokens": ["Move", "native", "pieces", "of", "the", "seccomp", "syscall", "into", "its", "own", "package"], "add_tokens": "\" \" \" \" prog := & data . SockFprog { return native . InstallSeccomp ( prog )", "del_tokens": "\" \" \" \" // #include <linux/seccomp.h> import \" \" type sockFprog struct { Len uint16 // Number of BPF machine instructions. Filter * unix . SockFilter // Pointer to the first instruction. } // seccomp is a wrapper for the 'seccomp' system call. // See <linux/seccomp.h> for valid op and flag values. // uargs is typically a pointer to struct sock_fprog. func seccomp ( op , flags uintptr , uargs unsafe . Pointer ) error { _ , _ , e := syscall . Syscall ( syscall . PR_GET_SECCOMP , op , flags , uintptr ( uargs ) ) if e != 0 { return e } return nil } prog := & sockFprog { return seccomp ( C . SECCOMP_SET_MODE_FILTER , C . SECCOMP_FILTER_FLAG_TSYNC , unsafe . Pointer ( prog ) )", "commit_type": "move"}
{"commit_tokens": ["Allow", "the", "use", "of", "Go", "templating", "engine", "in", "rewrite", "middleware", "."], "add_tokens": "\" \" \" \" \" \" oldURL := r . GetHttpRequest ( ) . URL . String ( ) // apply a rewrite regexp to the URL newURL := rewrite . regexp . ReplaceAllString ( oldURL , rewrite . replacement ) // then make a template out of the new URL to replace any variables // that may be in there t , err := template . New ( \" \" ) . Parse ( newURL ) if err != nil { return nil , err } // template data includes http.Request object making all its properties/methods // available inside replacement string context := struct { Request * http . Request } { r . GetHttpRequest ( ) } var b bytes . Buffer if err := t . Execute ( & b , context ) ; err != nil { return nil , err } // parse the rewritten URL and replace request URL with it parsedURL , err := url . Parse ( b . String ( ) ) if err != nil { return nil , err } r . GetHttpRequest ( ) . URL = parsedURL", "del_tokens": "newPath [ ] byte oldPath := r . GetHttpRequest ( ) . URL . Path rewrite . newPath = rewrite . regexp . ReplaceAll ( [ ] byte ( oldPath ) , [ ] byte ( rewrite . replacement ) ) r . GetHttpRequest ( ) . URL . Path = string ( rewrite . newPath )", "commit_type": "allow"}
{"commit_tokens": ["Add", "error", "return", "to", "resolveFamily"], "add_tokens": "if err = s . resolveFamily ( ) ; err != nil { panic ( err ) }", "del_tokens": "s . resolveFamily ( )", "commit_type": "add"}
{"commit_tokens": ["update", "version", "of", "go", "-", "multiaddr"], "add_tokens": "proto \" \"", "del_tokens": "proto \" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "transparent", "compression", "in", "memory", "VFS"], "add_tokens": "return NewRFile ( entry . ( * File ) ) return NewWFile ( f . ( * File ) , true , false ) return NewWFile ( f . ( * File ) , flag & os . O_RDWR != 0 , true )", "del_tokens": "return NewRFile ( entry . ( * File ) ) , nil return NewWFile ( f . ( * File ) , true , false ) , nil return NewWFile ( f . ( * File ) , flag & os . O_RDWR != 0 , true ) , nil", "commit_type": "add"}
{"commit_tokens": ["fix", "gofmt", "-", "s", "and", "ineffassign"], "add_tokens": "{", "del_tokens": "rc . MessageStoreCallerInfoRequest {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "panic", "if", ".", "Stop", "()", "is", "called", "on", "a", "non", "-", "running", "Supervisor", "."], "add_tokens": "Serve will panic if it is called on an already - running supervisor , because the guarantees about how services are managed can not be maintained if a supervisor is double - served . panic ( \" \" ) defer func ( ) { s . Lock ( ) s . state = notRunning s . Unlock ( ) } ( ) // they timeout after the timeout value given to the Supervisor at // creation. // // This will panic if the Supervisor has not had Serve() called on it at // the time it is executed. This is because the supervisor can not maintain // its guarantees with regard to how it will shut down services if it is // called at this point. s . Lock ( ) if s . state == notRunning { defer s . Unlock ( ) panic ( \" \" ) } s . Unlock ( )", "del_tokens": "defer func ( ) { s . Lock ( ) s . state = notRunning s . Unlock ( ) } ( ) panic ( \" \" ) // they timeout after the timeout value given to the Supervisor at creation.", "commit_type": "add"}
{"commit_tokens": ["move", "config", "to", "separate", "package"], "add_tokens": "\" \" cfg := config . NewConfig ( ) cfg . ParseFlags ( ) if err := cfg . Validate ( ) ; err != nil { if cfg . LogFormat == \" \" { if cfg . Debug { go registerHandlers ( cfg . HealthPort )", "del_tokens": "cfg := newConfig ( ) cfg . parseFlags ( ) if err := cfg . validate ( ) ; err != nil { if cfg . logFormat == \" \" { if cfg . debug { go registerHandlers ( cfg . healthPort )", "commit_type": "move"}
{"commit_tokens": ["Fix", "chatserver", "to", "use", "gopkg", ".", "in", "for", "turnpike"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "METHODS", "on", "route"], "add_tokens": "func MakeQuery ( fn * ast . FuncDecl , comments map [ string ] [ ] string , method [ ] string , path string ) [ ] string { if stringInSlice ( MethodGET , method ) { func MakeMethod ( fn * ast . FuncDecl , comments map [ string ] [ ] string ) [ ] string { method := [ ] string { } if len ( v ) > 1 { for i := 1 ; i < len ( v ) ; i ++ { method = append ( method , v [ i ] ) } if len ( method ) == 0 { method = append ( method , MethodGET ) }", "del_tokens": "func MakeQuery ( fn * ast . FuncDecl , comments map [ string ] [ ] string , method , path string ) [ ] string { if method == MethodGET { func MakeMethod ( fn * ast . FuncDecl , comments map [ string ] [ ] string ) string { method := MethodGET if len ( v ) == 2 { method = v [ 1 ]", "commit_type": "allow"}
{"commit_tokens": ["Implement", "api", "to", "get", "log", "with", "index"], "add_tokens": "beego . Router ( \" \" , & controllers . ApiController { } , \" \" ) beego . Router ( \" \" , & controllers . ApiController { } , \" \" )", "del_tokens": "beego . Router ( \" \" , & controllers . ApiController { } , \" \" ) beego . Router ( \" \" , & controllers . ApiController { } , \" \" )", "commit_type": "implement"}
{"commit_tokens": ["removed", "bundle", "tracking", "test", "from", "api"], "add_tokens": "type Timestamp struct { time . Time } ts := t . Unix ( ) * t = Timestamp { time . Unix ( ts / 1000 , 0 ) }", "del_tokens": "// DomainBilling represents a billing change event. These happen for example when // the bundle for a domain changes, or the domain get's disabled or activated. type DomainBilling struct { Time Timestamp `json:\"timestamp\"` // Time when the change happend. Action string `json:\"action\"` // Type of change, can be either `link` or `unlink`. Bundle string `json:\"bundle\"` // ID of bundle this change occured against. Note: The bundle may no longer exist. Amount int `json:\"amount\"` // The value of the bundle at the time the change occured. } type Timestamp time . Time ts := time . Time ( t ) . Unix ( ) * t = Timestamp ( time . Unix ( ts / 1000 , 0 ) ) // GetDomainBilling gets the billing change log for the given domain. The returned // list is sorted by time descending, where up to `limit` items will be returned. func ( a * API ) GetDomainBilling ( domain int , limit int ) ( [ ] DomainBilling , error ) { dst := make ( [ ] DomainBilling , 0 ) url := a . geturl ( \" \" , domain ) err := a . get ( url , params { \" \" : strconv . Itoa ( limit ) } , & dst ) return dst , err }", "commit_type": "remove"}
{"commit_tokens": ["Allow", "callbacks", "to", "return", "errors"], "add_tokens": "func ( info * Info ) call ( value * string ) error { var retval [ ] reflect . Value retval = info . value . Call ( nil ) retval = info . value . Call ( [ ] reflect . Value { val } ) if len ( retval ) == 1 && retval [ 0 ] . Type ( ) == reflect . TypeOf ( ( * error ) ( nil ) ) . Elem ( ) { return retval [ 0 ] . Interface ( ) . ( error ) } return nil return info . call ( value )", "del_tokens": "func ( info * Info ) call ( value * string ) { info . value . Call ( nil ) info . value . Call ( [ ] reflect . Value { val } ) info . call ( value )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "Windows", "second", "try", "."], "add_tokens": "// TODO(maruel): Using '/' for this function is inconsistent on Windows // w.r.t. other functions. ut . AssertEqual ( t , \" \" , c . Func . String ( ) )", "del_tokens": "ut . AssertEqual ( t , filepath . Join ( \" \" , \" \" ) , c . Func . String ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "README", "summary", "and", "usage", "docs"], "add_tokens": "// oauth_token and oauth_token_secret from the body. // See RFC 5849 2.2 Resource Owner Authorization. // See RFC 5849 2.3 Token Credentials.", "del_tokens": "// oauth_token and oauth_token_secret in the body. // See RFC 2.2 Resource Owner Authorization. // See RFC 2.3 Token Credentials.", "commit_type": "improve"}
{"commit_tokens": ["add", "clone", "()", "and", "normalizeNullExpression", "change", "to", "mutator"], "add_tokens": "col := t . clone ( ) col . normalizeNullExpression ( ) return col func ( t * tablecol ) normalizeNullExpression ( ) { if t . HasDefault ( ) { t . SetNullState ( NullStateNone ) t . SetDefault ( t . Default ( ) , false ) if t . NullState ( ) != NullStateNotNull { t . SetDefault ( \" \" , false ) t . SetNullState ( NullStateNone ) } func ( t * tablecol ) clone ( ) TableColumn { col := & tablecol { } * col = * t", "del_tokens": "col := & tablecol { } * col = * t return col . normalizeNullExpression ( ) func ( t * tablecol ) normalizeNullExpression ( ) TableColumn { col := & tablecol { } * col = * t if col . HasDefault ( ) { col . SetNullState ( NullStateNone ) col . SetDefault ( t . Default ( ) , false ) if col . NullState ( ) != NullStateNotNull { col . SetDefault ( \" \" , false ) col . SetNullState ( NullStateNone )", "commit_type": "add"}
{"commit_tokens": ["Fix", "deadlock", "on", "rewrite", "of", "opHistory", "when", "history", "limit", "is", "reached"], "add_tokens": "\" \" fdLock sync . Mutex o . rewriteLocked ( ) o . rewriteLocked ( ) } func ( o * opHistory ) rewriteLocked ( ) {", "del_tokens": "\" \" fdLock sync . Mutex o . Rewrite ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "running", "on", "32", "bit", "systems"], "add_tokens": "// This must be at the beginning of the struct due to // how 64 bit atomic values are handled on 32 bit systems // in Go. sequence uint64", "del_tokens": "sequence uint64", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "macros", "with", "Otto", "javascript", "to", "insert", "filters", "into", "macro"], "add_tokens": "\" \" \" \" type QueryList [ ] QueryListItem type QueryListItem struct { Id * uuid . UUID Label string PQL string } func TokensToString ( tokens [ ] Token ) string { var str [ ] string for i , _ := range tokens { spew . Dump ( tokens [ i ] . Text ) str = append ( str , tokens [ i ] . Text ) } // for now, we're just using this function to pull the filter out of the outer function \"outerfunc(filter)\" str = str [ 2 : len ( str ) - 1 ] return strings . Join ( str , \" \" ) }", "del_tokens": "/ * //spew.Dump(query) query_planner := QueryPlanner { Database : database } id := uuid . RandomUUID ( ) query_plan := query_planner . Plan ( query , & id , destination ) //spew.Dump(query_plan) return query_plan * / //spew.Dump(query) //spew.Dump(query_plan)", "commit_type": "add"}
{"commit_tokens": ["Add", "FmtDateTime", "helper", "functions", "."], "add_tokens": "", "del_tokens": "// for k, v := range trans.timezones { // fmt.Println(\"\\t-\", k) // fmt.Println(\"\\t\\t-\", v.standard) // fmt.Println(\"\\t\\t-\", v.daylight) // } // TODO: Chunk THIS up for lease amount of appends // b = append(b, format[i]) // results += \"b = append(b, '\" + fmt.Sprintf(\"%#v\", format[i]) + \"')\" // func stringToIndividualBytes(s string) (results string) { // for _, b := range s { // results += \"'\" + fmt.Sprintf(\"%#v\", b) + \"',\" // } // results = strings.TrimRight(results, \",\") // return // }", "commit_type": "add"}
{"commit_tokens": ["Fix", "flowing", "inner", "json", "progress", "events", "through"], "add_tokens": "chmod a + x $ BIN ln - s $ BIN tachyon return nil , fmt . Errorf ( \" \" , err , string ( out ) ) err = ssh . CopyToHost ( filepath . Join ( path , binary ) , \" \" + binary + \" \" ) ssh . Run ( fmt . Sprintf ( \" \" , binary ) ) if t . Debug { fmt . Fprintf ( os . Stderr , \" \\n \" , c . Args ) }", "del_tokens": "mv $ BIN tachyon chmod a + x tachyon return nil , fmt . Errorf ( \" \\n \" , err ) err = ssh . CopyToHost ( filepath . Join ( path , binary ) , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "Continue", ".", "Fuzz", "to", "accept", "a", "reflect", ".", "Value"], "add_tokens": "// Fuzz continues fuzzing obj. obj must be a pointer or a reflect.Value of a // pointer. v , ok := obj . ( reflect . Value ) if ! ok { v = reflect . ValueOf ( obj ) } v , ok := obj . ( reflect . Value ) if ! ok { v = reflect . ValueOf ( obj ) }", "del_tokens": "// Fuzz continues fuzzing obj. obj must be a pointer. v := reflect . ValueOf ( obj ) v := reflect . ValueOf ( obj )", "commit_type": "allow"}
{"commit_tokens": ["Changed", "flags", "to", "an", "more", "friendly", "syntax"], "add_tokens": "& cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } ,", "del_tokens": "& cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } , & cli . BoolFlag { Name : \" \" , Usage : \" \" } ,", "commit_type": "change"}
{"commit_tokens": ["Make", "Datastore", ".", "walk", "()", "error", "more", "specific"], "add_tokens": "log . Warningf ( \" \" , fn )", "del_tokens": "log . Warning ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Add", "flags", "to", "ignore", "case", "and", "ignore", "unknown", "keys"], "add_tokens": "func findField ( v reflect . Value , n string , ignoreCase bool ) ( reflect . Value , bool ) { var lowerN string caseInsensitiveMatch := - 1 if ignoreCase { lowerN = strings . ToLower ( n ) } } else if ignoreCase && lowerN == strings . ToLower ( k ) { caseInsensitiveMatch = i // If no exact match was found try case insensitive match. if caseInsensitiveMatch != - 1 { return v . Field ( caseInsensitiveMatch ) , true } if ev , ok := findField ( fv , n , ignoreCase ) ; ok {", "del_tokens": "func findField ( v reflect . Value , n string ) ( reflect . Value , bool ) { if ev , ok := findField ( fv , n ) ; ok {", "commit_type": "add"}
{"commit_tokens": ["update", "sdk", "and", "add", "missing", "returns"], "add_tokens": "sdk . EncodeResponse ( w , res , res . Err != \" \" )", "del_tokens": "sdk . EncodeResponse ( w , res , res . Err )", "commit_type": "update"}
{"commit_tokens": ["add", "ListAll", "and", "Create", "methods", "for", "repositories"], "add_tokens": "v := & ErrorResponse { Response : & http . Response { StatusCode : http . StatusNotFound } } v := & ErrorResponse { Response : & http . Response { StatusCode : http . StatusBadRequest } }", "del_tokens": "v := & ErrorResponse { Response : & http . Response { StatusCode : http . StatusNotFound } } v := & ErrorResponse { Response : & http . Response { StatusCode : http . StatusBadRequest } }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bad", "cli", "sdk", "integration"], "add_tokens": "p := & gocd . Pipeline { Version : version , } pc , r , err := cliAgent ( c ) . PipelineConfigs . Update ( context . Background ( ) , group , name , p )", "del_tokens": "p := & gocd . Pipeline { } pc , r , err := cliAgent ( c ) . PipelineConfigs . Update ( context . Background ( ) , group , name , version , p )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "an", "unused", "struct", "field", "."], "add_tokens": "ctx context . Context bucket gcs . Bucket", "del_tokens": "getBucket func ( ) gcs . Bucket ctx context . Context bucket gcs . Bucket", "commit_type": "remove"}
{"commit_tokens": ["add", "unit", "tests", "and", "add", "one", "to", "maximumJitterInterval"], "add_tokens": "if maximumJitterInterval < 0 { maximumJitterInterval = 0 } return ( time . Duration ( cb . backoffInterval ) * time . Millisecond ) + ( time . Duration ( rand . Int63n ( cb . maximumJitterInterval + 1 ) ) * time . Millisecond ) if maximumJitterInterval < 0 { maximumJitterInterval = 0 // protect against panic when generating random jitter } if retry < 0 { retry = 0 } return time . Duration ( math . Min ( eb . initialTimeout * math . Pow ( eb . exponentFactor , float64 ( retry ) ) , eb . maxTimeout ) + float64 ( rand . Int63n ( eb . maximumJitterInterval + 1 ) ) ) * time . Millisecond", "del_tokens": "// The maximum jitter interval must be more than 1*time.Millisecond return ( time . Duration ( cb . backoffInterval ) * time . Millisecond ) + ( time . Duration ( rand . Int63n ( cb . maximumJitterInterval ) ) * time . Millisecond ) // The maximum jitter interval must be more than 1*time.Millisecond return time . Duration ( math . Min ( eb . initialTimeout * math . Pow ( eb . exponentFactor , float64 ( retry ) ) , eb . maxTimeout ) + float64 ( rand . Int63n ( eb . maximumJitterInterval ) ) ) * time . Millisecond", "commit_type": "add"}
{"commit_tokens": ["Add", "check", ".", "Unknownf", "shorthand", "function"], "add_tokens": "// Criticalf is a shorthand function which exits the check with status // CRITICAL and the message provided. // Unknownf is a shorthand function which exits the check with status // UNKNOWN and the message provided. func ( c * Check ) Unknownf ( format string , v ... interface { } ) { c . Exitf ( UNKNOWN , format , v ... ) }", "del_tokens": "// Criticalf is a shorthand function which calls Exitf with", "commit_type": "add"}
{"commit_tokens": ["Allow", "optional", "flags", "by", "asking", "if", "its", "been", "set", "/", "present", "on", "the", "command", "line"], "add_tokens": "setFlags map [ string ] bool return & Context { app , set , globalSet , nil } // Determines if the flag was actually set exists func ( c * Context ) IsSet ( name string ) bool { if c . setFlags == nil { c . setFlags = make ( map [ string ] bool ) c . flagSet . Visit ( func ( f * flag . Flag ) { c . setFlags [ f . Name ] = true } ) } return c . setFlags [ name ] == true }", "del_tokens": "return & Context { app , set , globalSet }", "commit_type": "allow"}
{"commit_tokens": ["Adding", "naive", "ability", "to", "detect", "variable", "case", "."], "add_tokens": "type WordCase func ( string ) string SubsequentCase WordCase InitialCase WordCase", "del_tokens": "SubsequentCase func ( string ) string InitialCase func ( string ) string", "commit_type": "add"}
{"commit_tokens": ["Add", "NoEscapeHTML", "to", "jwriter", ".", "Writer"], "add_tokens": "Error error Buffer buffer . Buffer NoEscapeHTML bool func isNotEscapedSingleChar ( c byte , escapeHTML bool ) bool { if escapeHTML { return c != '<' && c != '>' && c != '&' && c != '\\\\' && c != '\"' && c >= 0x20 && c < utf8 . RuneSelf } else { return c != '\\\\' && c != '\"' && c >= 0x20 && c < utf8 . RuneSelf } if isNotEscapedSingleChar ( c , ! w . NoEscapeHTML ) {", "del_tokens": "Error error Buffer buffer . Buffer func isNotEscapedSingleChar ( c byte ) bool { return c != '<' && c != '\\\\' && c != '\"' && c != '>' && c >= 0x20 && c < utf8 . RuneSelf if isNotEscapedSingleChar ( c ) {", "commit_type": "add"}
{"commit_tokens": ["moved", "code", "into", "an", "importable", "package"], "add_tokens": "package gcm err = EncryptFile ( inputFileName , outputFileName , key , iv , aad ) err = DecryptFile ( outputFileName , inputFileName , key , iv , aad )", "del_tokens": "package main err = encryptFile ( inputFileName , outputFileName , key , iv , aad ) err = decryptFile ( outputFileName , inputFileName , key , iv , aad )", "commit_type": "move"}
{"commit_tokens": ["Changed", "the", "references", "of", "Brand", "to", "Thing", "to", "ensure", "it", "works", "when", "no", "Brands", "are", "present"], "add_tokens": "\" \" OPTIONAL MATCH ( n ) - [ : IS_CLASSIFIED_BY ] - > ( b : Thing ) WITH n , collect ( { id : b . uuid } ) as brands MATCH ( b : Thing ) <- [ rel : IS_CLASSIFIED_BY ] - ( t ) statement := `MATCH (b:Thing{uuid:{brandUuid}}) OPTIONAL MATCH ( p ) - [ rel : IS_CLASSIFIED_BY ] - > ( b : Thing )", "del_tokens": "\" \" OPTIONAL MATCH ( n ) - [ : IS_CLASSIFIED_BY ] - > ( b : Brand ) WITH n , collect ( { id : b . uuid } ) as brands OPTIONAL MATCH ( b : Brand ) <- [ rel : IS_CLASSIFIED_BY ] - ( t ) statement := `MATCH (b:Brand{uuid:{brandUuid}}) OPTIONAL MATCH ( p ) - [ rel : IS_CLASSIFIED_BY ] - > ( b : Brand )", "commit_type": "change"}
{"commit_tokens": ["Added", "tests", "for", "authorization", "endpoint"], "add_tokens": "mess . Authentication = func ( event Event , opts MessageOpts , optin * Optin ) { wg . Add ( 6 ) // authentication _ = r . Post ( \" \" , \" \" , `{\"object\":\"page\",\"entry\":[{\"id\":\"510249619162304\",\"time\":1468152897212,\"messaging\":[{\"sender\":{\"id\":\"1066835436691078\"},\"recipient\":{\"id\":\"510249619162304\"},\"timestamp\":1468152897212,\"optin\":{\"ref\":\"test\"}}]}]}` )", "del_tokens": "mess . Authentication = func ( Event , MessageOpts , * Optin ) { wg . Add ( 5 )", "commit_type": "add"}
{"commit_tokens": ["Change", "public", "API", "of", "kvlog", "package", "."], "add_tokens": "output := NewWriter ( & buf ) Effect : \" \" , Effect : \" \" , output := NewWriter ( ioutil . Discard ) output . Attach ( tt . logger ) e1 . Effect != e2 . Effect ||", "del_tokens": "output := NewOutput ( & buf ) Action : \" \" , Action : \" \" , output := NewOutput ( ioutil . Discard ) output . SetOutputFor ( tt . logger ) e1 . Action != e2 . Action ||", "commit_type": "change"}
{"commit_tokens": ["Fix", "typo", "in", "Upgrade", "example", "."], "add_tokens": "// ws, err := websocket.Upgrade(w, r, nil, 1024, 1024) // if _, ok := err.(websocket.HandshakeError); ok { // http.Error(w, \"Not a websocket handshake\", 400) // return // } else if err != nil { // log.Println(err) // return // }", "del_tokens": "// conn, err := websocket.Upgrade(w, r.Header, nil, 1024, 1024) // if _, ok := err.(websocket.HandshakeError); ok { // http.Error(w, \"Not a websocket handshake\", 400) // return // } else if err != nil { // log.Println(err) // return // }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "wording", "in", "Quat", "documentation"], "add_tokens": "// rotations will be transformed for the purposes of AnglesToQuat // Performs a rotation in the specified order. If the order is not", "del_tokens": "// rotations may be transformed for the purposes of AnglesToQuat // Performs a canonical rotation in the specified order. If the order is not", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bad", "print", "statement"], "add_tokens": "v . Message = fmt . Sprintf ( \" \" , v . Min , v . Max )", "del_tokens": "\" \" v . Message = fmt . Sprintf ( \" \" , v . Min , v . Max )", "commit_type": "fix"}
{"commit_tokens": ["added", "Server", ".", "NextSynthID", "and", "constants", "for", "DefaultGroupID", "and", "RootNodeID"], "add_tokens": "err = server . NewSynth ( \" \" , server . NextSynthID ( ) , AddToHead , DefaultGroupID )", "del_tokens": "err = server . NewSynth ( \" \" , 1000 , 0 , 1 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "resource", "leak", ";", "optimize"], "add_tokens": "m . maybeWork ( ) m . maybeWork ( ) func ( m * Client ) maybeWork ( ) { go m . syncWorker ( & b ) } func ( m * Client ) syncWorker ( b * Bundle ) { // When exiting, free up the token for use by another // worker. defer func ( ) { m . bucket <- struct { } { } } ( ) resp , err := m . c . Post ( b )", "del_tokens": "go m . syncWorker ( ) m . statLock . Lock ( ) defer m . statLock . Unlock ( ) go m . syncWorker ( ) func ( m * Client ) syncWorker ( ) { // When exiting, free up the token for use by another // worker. defer func ( ) { m . bucket <- struct { } { } } ( ) return resp , err := m . c . Post ( & b ) return", "commit_type": "fix"}
{"commit_tokens": ["Add", "0x", "to", "llvm", "-", "symbolizer", "input"], "add_tokens": "if err := d . rw . write ( fmt . Sprintf ( \" \" , d . filename , addr - d . base ) ) ; err != nil {", "del_tokens": "if err := d . rw . write ( fmt . Sprintf ( \" \" , d . filename , addr - d . base ) ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Added", "env", "command", "integration", "test"], "add_tokens": "func TestClusterStatus ( t * testing . T ) {", "del_tokens": "func TestCluster ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["added", "per", "-", "hook", "defined", "response", "message"], "add_tokens": "version = \" \" // send the hook defined response message fmt . Fprintf ( w , hook . ResponseMessage ) w . WriteHeader ( http . StatusNotFound )", "del_tokens": "version = \" \" // say thanks fmt . Fprintf ( w , \" \" )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "potential", "unexpected", "closing", "while", "bucket", "has", "exhausted"], "add_tokens": "// recvLoop main block on bucket == 0, in this case, // session should not be closed. if atomic . LoadInt32 ( & s . bucket ) > 0 { s . Close ( ) return }", "del_tokens": "s . Close ( ) return", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "few", "race", "conditions"], "add_tokens": "h interface { } name string parent * Describe failure * Failure failureMu sync . RWMutex reporter Reporter isAsync bool it . failureMu . RLock ( ) it . failureMu . RUnlock ( ) it . failureMu . Lock ( ) defer it . failureMu . Unlock ( )", "del_tokens": "h interface { } name string parent * Describe failure * Failure reporter Reporter isAsync bool", "commit_type": "fix"}
{"commit_tokens": ["make", "test", "dsn", "based", "on", "env", "variable", ":", "GORP_TEST_DSN"], "add_tokens": "type PersistentUser struct { Key int32 Id string PassedTraining bool } func TestPersistentUser ( t * testing . T ) { dbmap := & DbMap { Db : connect ( ) , Dialect : dialect } dbmap . Exec ( \" \" ) dbmap . TraceOn ( \" \" , log . New ( os . Stdout , \" \" , log . Lmicroseconds ) ) table := dbmap . AddTable ( PersistentUser { } ) . SetKeys ( false , \" \" ) table . ColMap ( \" \" ) . Rename ( \" \" ) err := dbmap . CreateTables ( ) if err != nil { panic ( err ) } defer dbmap . DropTables ( ) pu := & PersistentUser { 43 , \" \" , false } err = dbmap . Insert ( pu ) if err != nil { panic ( err ) } } dsn := os . Getenv ( \" \" ) if dsn == \" \" { panic ( \" \" ) } db , err := sql . Open ( \" \" , dsn )", "del_tokens": "db , err := sql . Open ( \" \" , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Made", "ISP", "thread", "-", "safe"], "add_tokens": "\" \" entries = & atomic . Value { } func init ( ) { entries . Store ( newTree ( ) ) } func newTree ( ) * yfast . YFastTrie { return yfast . New ( uint32 ( 0 ) ) // 32 bit universe size for 32 bit IPv4 } tree := newTree ( ) tree . Insert ( newEntries ... ) entries . Store ( tree ) tree := entries . Load ( ) . ( * yfast . YFastTrie ) _e := tree . Predecessor ( uint64 ( i ) )", "del_tokens": "entries = yfast . New ( uint32 ( 0 ) ) // 32 bit universe size for 32 bit IPv4 entries . Insert ( newEntries ... ) _e := entries . Predecessor ( uint64 ( i ) )", "commit_type": "make"}
{"commit_tokens": ["Update", "to", "yaml", ".", "v2", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["add", "default", "value", "for", "customize", "Seo"], "add_tokens": "Admin . RegisterFuncMap ( \" \" , func ( name string , value interface { } ) interface { } { globalInteface := seoCollection . SettingResource . NewStruct ( ) db . Where ( \" \" , name ) . Find ( globalInteface ) globalSetting := globalInteface . ( QorSeoSettingInterface ) setting := value . ( Setting ) if ! setting . EnabledCustomize && setting . Title == \" \" && setting . Description == \" \" && setting . Keywords == \" \" { setting . Title = globalSetting . GetTitle ( ) setting . Description = globalSetting . GetDescription ( ) setting . Keywords = globalSetting . GetKeywords ( ) } return setting } )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "request", "start", "time", "to", "ServerCtx"], "add_tokens": "// Unique id of the request. // Start time for the request processing. Time time . Time ctx . ID ++ ctx . Time = time . Now ( )", "del_tokens": "// Unique id of the context. // Used by ServerCtx.Logger(). ctx . ID ++", "commit_type": "add"}
{"commit_tokens": ["add", "sprintf", "-", "style", "Annotate", "()"], "add_tokens": "func ( c * Client ) Annotate ( name string , value string , args ... interface { } ) error { return c . send ( name , 1 , \" \" , fmt . Sprintf ( value , args ... ) )", "del_tokens": "func ( c * Client ) Annotate ( name string , value string ) error { return c . send ( name , 1 , \" \" , value )", "commit_type": "add"}
{"commit_tokens": ["Added", "data", "bits", "logic", "."], "add_tokens": "func setTermios ( fd int , src * termios ) os . Error { uintptr ( unsafe . Pointer ( src ) ) ) func convertOptions ( options OpenOptions ) ( * termios , os . Error ) { var result termios // Data bits switch options . DataBits { case 5 : result . c_cflag |= CS5 case 6 : result . c_cflag |= CS6 case 7 : result . c_cflag |= CS7 case 8 : result . c_cflag |= CS8 default : return nil , os . NewError ( \" \" ) } terminalOptions , err := convertOptions ( options ) if err != nil { return nil , err }", "del_tokens": "func setTermios ( fd int , src termios ) os . Error { uintptr ( unsafe . Pointer ( & src ) ) ) func convertOptions ( options OpenOptions ) termios { terminalOptions := convertOptions ( options )", "commit_type": "add"}
{"commit_tokens": ["fixed", "an", "off", "by", "one", "error"], "add_tokens": "for i := range hosts {", "del_tokens": "for i := 0 ; i <= len ( hosts ) ; i ++ {", "commit_type": "fix"}
{"commit_tokens": ["Add", "RDSEED", "/", "F16C", "and", "fix", "RDRAND", "."], "add_tokens": "F16C // Half-precision floating-point conversion RDSEED // RDSEED instruction is available F16C : \" \" , // Half-precision floating-point conversion RDSEED : \" \" , // RDSEED instruction is available // F16C indicates support of F16C instructions func ( c CPUInfo ) F16C ( ) bool { return c . Features & F16C != 0 } // Rdseed indicates support of RDSEED instruction is available func ( c CPUInfo ) Rdseed ( ) bool { return c . Features & RDSEED != 0 } if c & ( 1 << 30 ) != 0 { rval |= RDRAND } if c & ( 1 << 29 ) != 0 { rval |= F16C } rval |= RDSEED", "del_tokens": "rval |= RDRAND", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "using", "@exclude", "to", "exclude", "comments", "from", "docs"], "add_tokens": "ioutil . WriteFile ( \" \" , data , 0666 )", "del_tokens": "ioutil . WriteFile ( \" \" , data , 0666 )", "commit_type": "add"}
{"commit_tokens": ["Add", "consul", "ACL", "token", "support"], "add_tokens": "consul - alerts start [ - - alert - addr = < addr > ] [ - - consul - addr = < consuladdr > ] [ - - consul - dc = < dc > ] [ - - consul - acl - token = < token > ] [ - - watch - checks ] [ - - watch - events ] - - consul - acl - token = < token > The consul ACL token [ default : \" \" ] . consulAclToken := arguments [ \" \" ] . ( string ) consulClient , err = consul . NewClient ( consulAddr , consulDc , consulAclToken ) log . Println ( \" \" , consulAclToken ) ConsulAclToken : consulAclToken ,", "del_tokens": "consul - alerts start [ - - alert - addr = < addr > ] [ - - consul - addr = < consuladdr > ] [ - - consul - dc = < dc > ] [ - - watch - checks ] [ - - watch - events ] consulClient , err = consul . NewClient ( consulAddr , consulDc )", "commit_type": "add"}
{"commit_tokens": ["add", "more", "logs", "to", "locate", "issue", "related", "SlicedIndexInput"], "add_tokens": "log . Print ( \" \" ) log . Print ( \" \" ) log . Print ( \" \" )", "del_tokens": "log . Print ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Create", "test", "file", "in", "correct", "test", "directory"], "add_tokens": "foobarPath := path . Join ( tmpPath , \" \" ) f , err := os . Create ( foobarPath )", "del_tokens": "f , err := os . Create ( \" \" )", "commit_type": "create"}
{"commit_tokens": ["fix", "validation", "after", "update", "to", "extract", "package"], "add_tokens": "if len ( extracted ) == 1 { e := extracted [ 0 ] if _ , ok := e . ListSlug ( ) ; ok && e . Text == list { return true } } return false", "del_tokens": "return len ( extracted ) == 1 && extracted [ 0 ] . Text == list && extracted [ 0 ] . ListSlug != \" \"", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "function", "on", "CurrentUser"], "add_tokens": "FriendShip InstagramFriendShip Users InstagramUsers CurrentUser CurrentUser type CurrentUser struct { instagram * Instagram UserResponse }", "del_tokens": "Followers * InstagramFollowers Followings * InstagramFollowings FriendShip * InstagramFriendShip Users * InstagramUsers CurrentUser UserResponse type InstagramFollowers struct { instagram * Instagram } type InstagramFollowings struct { instagram * Instagram }", "commit_type": "add"}
{"commit_tokens": ["add", "test", "cases", "for", "LockInternals"], "add_tokens": "const LockPrefix = \" \" if internals , err := newLockInternals ( client , driver , path , LockPrefix , 1 ) ; err != nil { return nil , err } else { return & InterProcessMutex { basePath : path , internals : internals , } , nil } func newLockInternals ( client curator . CuratorFramework , driver LockInternalsDriver , basePath , lockName string , maxLeases int ) ( * lockInternals , error ) { if err := curator . ValidatePath ( basePath ) ; err != nil { return nil , err } basePath : basePath , lockPath : curator . JoinPath ( basePath , lockName ) , } , nil", "del_tokens": "return & InterProcessMutex { basePath : path , internals : newLockInternals ( client , driver , path , \" \" , 1 ) , } , nil func newLockInternals ( client curator . CuratorFramework , driver LockInternalsDriver , path , lockName string , maxLeases int ) * lockInternals { basePath : path , lockPath : curator . JoinPath ( path , lockName ) , }", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "build", "(", "per", "the", "Context", "change", ")"], "add_tokens": "span := opentracing . StartSpan ( \" \" ) ctx := opentracing . BackgroundContextWithSpan ( span )", "del_tokens": "ctx , span := opentracing . BackgroundContextWithSpan ( opentracing . StartSpan ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["added", "mock", ".", "Wait", "(", "time", ".", "Duration", ")", "function", "to", "wait", "for", "mocks", "to", "be", "called", "from", "the", "goroutines"], "add_tokens": "This code was generated automatically using github . com / gojuno / minimock v1 . 1 //Wait waits for all mocked functions to be executed at least once func ( m * { { $ structName } } ) Wait ( timeout time . Duration ) { timeoutCh := time . After ( timeout ) for { ok := true { { range $ methodName , $ method := . } } ok = ok && ( m . { { $ methodName } } Func == nil || m . { { $ methodName } } Counter > 0 ) { { end } } if ok { return } select { case <- time . Tick ( time . Microsecond ) : case <- timeoutCh : { { range $ methodName , $ method := . } } if m . { { $ methodName } } Func != nil && m . { { $ methodName } } Counter == 0 { m . t . Error ( \" \" ) } { { end } } m . t . Fatalf ( \" \" , timeout ) return } } }", "del_tokens": "This code was generated automatically using github . com / gojuno / minimock v1 . 0", "commit_type": "add"}
{"commit_tokens": ["Removed", "bug", "where", "the", "reader", "was", "reassigned", "without", "being", "closed"], "add_tokens": "stdin . Close ( )", "del_tokens": "defer stdin . Close ( )", "commit_type": "remove"}
{"commit_tokens": ["Move", "ConstProvider", "to", "tokenkey", "package", "and", "expose", "it"], "add_tokens": "provider := tokenkey . ConstProvider ( publicKey , \" \" ) provider := tokenkey . ConstProvider ( publicKey , \" \" )", "del_tokens": "// constProvider is a tokenkey Provider that always resturns the same tokenkey type constProvider struct { key * tokenkey . TokenKey } func ( c * constProvider ) Get ( server string , renew bool ) ( * tokenkey . TokenKey , error ) { return c . key , nil } func ( c * constProvider ) Update ( ) error { return nil } func ConstProvider ( publicKey string ) tokenkey . Provider { return & constProvider { key : & tokenkey . TokenKey { Algorithm : \" \" , Key : publicKey , } , } } provider := ConstProvider ( publicKey ) provider := ConstProvider ( publicKey )", "commit_type": "move"}
{"commit_tokens": ["improved", "test", "for", "NewCountingSampler", "(", "iterate", "over", "reservoir", "a", "few", "times", "))"], "add_tokens": "for i := 0 ; i < 1000 ; i ++ { if found != n * 10 {", "del_tokens": "for i := 0 ; i < 100 ; i ++ { if found != n {", "commit_type": "improve"}
{"commit_tokens": ["Improve", "String", "for", "runtime", "objects"], "add_tokens": "case \" \" , \" \" , \" \" , \" \" , \" \" : if desc == \" \" { if len ( r . Properties ) == 0 { return \" \" } desc = \" \" }", "del_tokens": "case \" \" , \" \" : case \" \" : stype = desc desc = \" \"", "commit_type": "improve"}
{"commit_tokens": ["Fix", "a", "Bug", "in", "Pair"], "add_tokens": "if kv , ok := key . ( LNumber ) ; ok && isInteger ( kv ) && int ( kv ) >= 0 && kv < LNumber ( MaxArrayIndex ) {", "del_tokens": "if kv , ok := key . ( LNumber ) ; ok && isInteger ( kv ) && int ( kv ) >= 0 {", "commit_type": "fix"}
{"commit_tokens": ["Use", "private", "fillParams", "and", "remove", "old", "locals", "init"], "add_tokens": "req := & Request { & http . Request { Method : http . MethodGet } , & Context { } , nil , \" \" } route . fillParams ( req )", "del_tokens": "req := & Request { & http . Request { Method : http . MethodGet } , & Context { } , nil , nil , \" \" } route . FillParams ( req )", "commit_type": "use"}
{"commit_tokens": ["use", "ParseInt", "instead", "of", "Atoi", "for", "parsing", "durations"], "add_tokens": "if v , err := strconv . ParseInt ( s , 10 , 64 ) ; err == nil { if v , err := strconv . ParseInt ( string ( text ) , 10 , 64 ) ; err == nil {", "del_tokens": "if v , err := strconv . Atoi ( s ) ; err == nil { if v , err := strconv . Atoi ( string ( text ) ) ; err == nil {", "commit_type": "use"}
{"commit_tokens": ["Change", "lastSequence", "on", "every", "change"], "add_tokens": "if lastSequence != ev . LastSequence { lastSequence = ev . LastSequence err := persistChange ( lastSequence ) if err != nil { log . Panic ( \" \" ) } if lastSequence != resp . LastSequence { lastSequence = resp . LastSequence err := persistChange ( lastSequence ) if err != nil { log . Panic ( \" \" ) } } if lastSequence != resp . LastSequence { lastSequence = resp . LastSequence err := persistChange ( lastSequence ) if err != nil { log . Panic ( \" \" ) } }", "del_tokens": "lastSequence = ev . LastSequence err := persistChange ( lastSequence ) if err != nil { log . Panic ( \" \" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "some", "of", "the", "remaining", "golint", "warnings", "."], "add_tokens": "myRes := rm . hasLink ( name1 , name2 ) log . Printf ( \" \" , name1 , name2 , myRes ) if myRes != res {", "del_tokens": "my_res := rm . hasLink ( name1 , name2 ) log . Printf ( \" \" , name1 , name2 , my_res ) if my_res != res {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "encoding", "nested", "interfaces", "."], "add_tokens": "// Encode each key and value according to their type. // encodeInterface examines the interface represented by the passed reflection // value to detect whether it is an interface that can be encoded if it is, // extracts the underlying value to pass back into the encode function for // encoding according to its type. // // A MarshalError is returned if any issues are encountered while encoding // the interface. func ( enc * Encoder ) encodeInterface ( v reflect . Value ) ( err error ) { if v . IsNil ( ) || ! v . CanInterface ( ) { msg := fmt . Sprintf ( \" \" ) err = marshalError ( \" \" , ErrNilInterface , msg , nil ) return err } // Extract underlying value from the interface and indirect through pointers. ve := reflect . ValueOf ( v . Interface ( ) ) ve = enc . indirect ( ve ) return enc . encode ( ve ) } case reflect . Interface : err = enc . encodeInterface ( ve ) // reflect.Uintptr, reflect.UnsafePointer", "del_tokens": "if vve . Kind ( ) == reflect . Interface { msg := fmt . Sprintf ( \" \" , vv . Type ( ) . String ( ) ) err = marshalError ( \" \" , ErrBadArguments , msg , nil ) return nil , err } // Decode each key and value according to their type. // reflect.Uintptr, reflect.UnsafePointer, reflect.Interface", "commit_type": "add"}
{"commit_tokens": ["make", "cbioFree", "not", "a", "go", "callback"], "add_tokens": "static int cbioFree ( BIO * b ) { return 1 ; }", "del_tokens": "extern int cbioFree ( BIO * b ) ; //export cbioFree func cbioFree ( b * C . BIO ) C . int { return 1 }", "commit_type": "make"}
{"commit_tokens": ["Fix", "+", "test", "for", "keys", "that", "resolve", "to", "directories"], "add_tokens": "filename := d . completeFilename ( key ) fi , err := os . Stat ( filename ) if err != nil { return nil , err } if fi . IsDir ( ) { return nil , os . ErrNotExist } f , err := os . Open ( filename )", "del_tokens": "f , err := os . Open ( d . completeFilename ( key ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "section", "titles", "in", "doc", ".", "go"], "add_tokens": "// Full Stack Traces // Easier Error Checking // Temporary Files are Not // Simple Equality", "del_tokens": "// Use Case 1: Full Stack Traces // Use Case 2: Easier Error Checking // Use Case 3: Temporary Files are Not // Use Case 4: Simple Equality", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectThat ( o . MediaLink , MatchesRegexp ( \" \" ) )", "del_tokens": "ExpectThat ( o . MediaLink , MatchesRegexp ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "batched", "diffing", "of", "slices", "with", "a", "custom", "comparer"], "add_tokens": "case v . NumIgnored > 0 : return false // Some ignore option was used case v . NumTransformed > 0 : return false // Some transform option was used case v . NumCompared > 1 : return false // More than one comparison was used case v . NumCompared == 1 && v . Type . Name ( ) != \" \" : // The need for cmp to check applicability of options on every element // in a slice is a significant performance detriment for large []byte. // The workaround is to specify Comparer(bytes.Equal), // which enables cmp to compare []byte more efficiently. // If they differ, we still want to provide batched diffing. // The logic disallows named types since they tend to have their own // String method, with nicer formatting than what this provides. return false", "del_tokens": "case v . NumIgnored + v . NumCompared + v . NumTransformed > 0 : // TODO: Handle the case where someone uses bytes.Equal on a large slice. return false // Some custom option was used to determined equality", "commit_type": "allow"}
{"commit_tokens": ["Fix", "an", "issue", "when", "unmarshaling", "NXActionNote"], "add_tokens": "func NewPortField ( port uint16 ) * PortField { f := new ( PortField ) f . port = port return f } tcpSrcField := NewPortField ( port ) tcpSrcField := NewPortField ( port ) tcpSrcField := NewPortField ( port ) tcpSrcField := NewPortField ( port )", "del_tokens": "tcpSrcField := new ( PortField ) tcpSrcField . port = port tcpSrcField := new ( PortField ) tcpSrcField . port = port tcpSrcField := new ( PortField ) tcpSrcField . port = port tcpSrcField := new ( PortField ) tcpSrcField . port = port", "commit_type": "fix"}
{"commit_tokens": ["adding", "config", "to", "the", "program"], "add_tokens": "\" \" conf , err := GetConfig ( ) if err != nil { log . Printf ( \" \" , err ) os . Exit ( 1 ) } portStr := fmt . Sprintf ( \" \" , conf . Port ) log . Printf ( \" \" , portStr ) log . Fatal ( http . ListenAndServe ( portStr , router ) )", "del_tokens": "log . Fatal ( http . ListenAndServe ( \" \" , router ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Fatal", "directive", "formatting", "."], "add_tokens": "t . Fatalf ( \" \" , err )", "del_tokens": "t . Fatal ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "content", "type", "for", "JSON", "responses"], "add_tokens": "w . WriteHeader ( status )", "del_tokens": "w . WriteHeader ( status )", "commit_type": "fix"}
{"commit_tokens": ["Make", "integration", "/", "localkube", "work", "with", "new", "controller", "library"], "add_tokens": "\" \" controllerManager := controller . MakeReplicationManager ( etcd . NewClient ( servers ) , controllerManager . Run ( 10 * time . Second )", "del_tokens": "controllerManager := registry . MakeReplicationManager ( etcd . NewClient ( servers ) , go controllerManager . Synchronize ( ) go controllerManager . WatchControllers ( )", "commit_type": "make"}
{"commit_tokens": ["Fix", "clean", "and", "embed", "to", "work", "with", "importPath", "argument", "(", "absolute", "path", "for", "create", "/", "remove", ")"], "add_tokens": "\" \" err := os . Remove ( filepath . Join ( pkg . Dir , filename ) )", "del_tokens": "err := os . Remove ( filename )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "handling", "of", "max", "size", "checks"], "add_tokens": "\" \" bufferedWriter * bufio . Writer bufferedOffset int64 estimatedFooterSize int64 entrySize := int64 ( 8 + len ( key ) + len ( value ) ) if ( cdb . bufferedOffset + entrySize + cdb . estimatedFooterSize + 16 ) > math . MaxUint32 { return ErrTooMuchData } cdb . bufferedOffset += entrySize cdb . estimatedFooterSize += 16 if cdb . bufferedOffset > math . MaxUint32 {", "del_tokens": "const maxUint32 = int64 ( ^ uint32 ( 0 ) ) bufferedWriter * bufio . Writer bufferedOffset int64 cdb . bufferedOffset += int64 ( 8 + len ( key ) + len ( value ) ) if cdb . bufferedOffset > maxUint32 { return ErrTooMuchData } if cdb . bufferedOffset > maxUint32 {", "commit_type": "improve"}
{"commit_tokens": ["Adding", "support", "for", "refreshing", "access", "tokens", "."], "add_tokens": "\" \" ) assertEq ( t , \" \" , atoken . AdditionalData [ \" \" ] )", "del_tokens": "\" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "regression", "formula", "as", "a", "parameter", "so", "it", "can", "be", "accessed", "after", "the", "test", "without", "debug"], "add_tokens": "Formula string // Calculate the regression formula for i , val := range c { if i == 0 { r . Formula = fmt . Sprintf ( \" \" , val ) } else { r . Formula += fmt . Sprintf ( \" \" , r . GetVarName ( i - 1 ) , val ) } } fmt . Printf ( \" \\n \\n \" , r . Formula )", "del_tokens": "for i , val := range c { if i == 0 { fmt . Print ( \" \" , val ) } else { fmt . Print ( \" \" , r . GetVarName ( i - 1 ) , \" \" , val ) } } fmt . Println ( \" \\n \\n \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "where", "config", ".", "KafkaConsumerGroup", "NOT", "nil", "causes", "dereference", "of", "nil", "pointer", "failure"], "add_tokens": "config := sarama . NewConsumerConfig ( ) if cg . config . KafkaConsumerConfig != nil {", "del_tokens": "var config * sarama . ConsumerConfig if cg . config . KafkaConsumerConfig == nil { config = sarama . NewConsumerConfig ( ) } else {", "commit_type": "fix"}
{"commit_tokens": ["add", "LastUpdated", "field", "to", "AggregateSample"], "add_tokens": "Count int // The count of emitted pairs Sum float64 // The sum of values SumSq float64 // The sum of squared values Min float64 // Minimum value Max float64 // Maximum value LastUpdated time . Time // When value was last updated a . LastUpdated = time . Now ( ) return fmt . Sprintf ( \" \" , a . Count , a . Sum , a . LastUpdated ) return fmt . Sprintf ( \" \" , a . Count , a . Min , a . Mean ( ) , a . Max , a . Stddev ( ) , a . Sum , a . LastUpdated )", "del_tokens": "Count int // The count of emitted pairs Sum float64 // The sum of values SumSq float64 // The sum of squared values Min float64 // Minimum value Max float64 // Maximum value return fmt . Sprintf ( \" \" , a . Count , a . Sum ) return fmt . Sprintf ( \" \" , a . Count , a . Min , a . Mean ( ) , a . Max , a . Stddev ( ) , a . Sum )", "commit_type": "add"}
{"commit_tokens": ["add", "comments", "to", "the", "rest", "of", "the", "structs"], "add_tokens": "// Events is part of the respon for VenueService.Events // Event is the Items in Events. // LikesResp is the response for the venue likes endpoint // Links is the response for VenueService.Links // Provider is Provider in a Link. // MenuResp is the response for VenueService.Menu. // MenuProvider is the Provider for the MenuResp. AttributionLink string `json:\"attributionLink\"` // Menus is part of the MenueResp. // FullMenu are the items on a Menu. // Entries is the Entires on a FullMenu. // Entry are the Items on a Entries. // SubEntries are the Entries on an Entry // SubEntry are the Items on a SubEntry", "del_tokens": "// Likesresp is the response for the venue likes endpoint AttributionLink string `json;\"attributionLink\"`", "commit_type": "add"}
{"commit_tokens": ["Make", "(", "*", "Client", ")", ".", "request", "public"], "add_tokens": "err := c . Request ( callflow , \" \" , \" \" + id , nil ) err := c . Request ( list , \" \" , fmt . Sprintf ( \" \" , page ) , nil ) if err := c . Request ( & data , \" \" , \" \" , callflow ) ; err != nil { if err := c . Request ( callflow , \" \" , \" \" + callflow . ID , callflow ) ; err != nil { return c . Request ( nil , \" \" , \" \" + callflow . ID , nil )", "del_tokens": "err := c . request ( callflow , \" \" , \" \" + id , nil ) err := c . request ( list , \" \" , fmt . Sprintf ( \" \" , page ) , nil ) if err := c . request ( & data , \" \" , \" \" , callflow ) ; err != nil { if err := c . request ( callflow , \" \" , \" \" + callflow . ID , callflow ) ; err != nil { return c . request ( nil , \" \" , \" \" + callflow . ID , nil )", "commit_type": "make"}
{"commit_tokens": ["fixed", "issues", "in", "StartSpan", "with", "SpanContext", "holding", "Debug", "flag", "but", "not", "a", "started", "trace", ".", "Added", "unit", "tests", "for", "various", "span", "/", "tracer", "scenarios"], "add_tokens": "tracer * Tracer mustCollect int32 // used as atomic bool (1 = true, 0 = false) if atomic . CompareAndSwapInt32 ( & s . mustCollect , 1 , 0 ) {", "del_tokens": "tracer * Tracer isSampled int32 // used as atomic bool (1 = true, 0 = false) if atomic . CompareAndSwapInt32 ( & s . isSampled , 1 , 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "FeedTag", "and", "Media", "types"], "add_tokens": "// All Item has Images or Videos objects which contains the url(s). // You can use Download function to get the best quality Image or Video from Item. Location struct { Pk int `json:\"pk\"` Name string `json:\"name\"` Address string `json:\"address\"` City string `json:\"city\"` ShortName string `json:\"short_name\"` Lng float64 `json:\"lng\"` Lat float64 `json:\"lat\"` ExternalSource string `json:\"external_source\"` FacebookPlacesID int64 `json:\"facebook_places_id\"` } `json:\"location,omitempty\"` Lat float64 `json:\"lat,omitempty\"` Lng float64 `json:\"lng,omitempty\"` // Download downloads media item (video or image) with the best quality. // // Input parameters are folder and filename. If filename is \"\" will be saved with // the default value name. func ( item * Item ) Download ( folder , name string ) error { / * for _ , image := range item . Images { for _ , c := range image . Versions { if name == \" \" { name = } if err := os . Stat ( } } for _ , video := range item . Videos { } * / return nil }", "del_tokens": "// All Item has", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "issue", "for", "the", "vet", ":", "instances_test", ".", "go", ":", "instances_test", ".", "go", ":", "89", ":", "2", ":", "illegal", "character", "U", "+", "0001", "(", "and", "10", "more", "errors", ")"], "add_tokens": "}", "del_tokens": "} \u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001", "commit_type": "fix"}
{"commit_tokens": ["add", "benchmarks", "remove", "call", "to", "time", ".", "Time", "because", "dogstatsd", "doesn", "t", "care", "about", "it", "(", "gives", "~15%", "perf", "improvement", ")"], "add_tokens": "eng . handle ( CounterType , name , 1 , tags , time . Time { } ) eng . handle ( CounterType , name , value , tags , time . Time { } ) eng . handle ( GaugeType , name , value , tags , time . Time { } ) eng . handle ( HistogramType , name , value , tags , time . Time { } ) eng . handle ( HistogramType , name , value . Seconds ( ) , tags , time . Time { } ) func ( eng * Engine ) handle ( typ MetricType , name string , value float64 , tags [ ] Tag , time time . Time ) { metric . Time = time", "del_tokens": "eng . handle ( CounterType , name , 1 , tags ) eng . handle ( CounterType , name , value , tags ) eng . handle ( GaugeType , name , value , tags ) eng . handle ( HistogramType , name , value , tags ) eng . handle ( HistogramType , name , value . Seconds ( ) , tags ) func ( eng * Engine ) handle ( typ MetricType , name string , value float64 , tags [ ] Tag ) { metric . Time = time . Now ( )", "commit_type": "add"}
{"commit_tokens": ["Changed", "documentation", "for", "Docker", "Redis", "example"], "add_tokens": "// ExampleRedisDocker demonstrates how to launch a Redis container using Raiqub. func Example_redisDocker ( ) {", "del_tokens": "func Example ( ) {", "commit_type": "change"}
{"commit_tokens": ["Adding", "Fuzzing", ":", "fixed", "out", "of", "bounds", "panic", "in", "NT", "parser"], "add_tokens": "return ntToken { } , fmt . Errorf ( \" \" , l . char , l . input ) return ntToken { } , fmt . Errorf ( \" \" , l . char , l . input ) return ntToken { } , fmt . Errorf ( \" \" , l . char , l . input ) pos := l . readPosition", "del_tokens": "panic ( fmt . Sprintf ( \" \" , l . char , l . input ) ) panic ( fmt . Sprintf ( \" \" , l . char , l . input ) ) panic ( fmt . Sprintf ( \" \" , l . char , l . input ) ) l . readChar ( ) pos := l . position func untilLineEnd ( c rune ) bool { return c != '\\n' && c != 0 }", "commit_type": "add"}
{"commit_tokens": ["Use", "CAS", "to", "detect", "concurrent", "mutations", "."], "add_tokens": "root := atomic . LoadPointer ( & t . root ) r , err := t . store . union ( t , ( * nodeLoc ) ( root ) , if ! atomic . CompareAndSwapPointer ( & t . root , root , unsafe . Pointer ( r ) ) { return errors . New ( \" \" ) } root := atomic . LoadPointer ( & t . root ) left , _ , right , err := t . store . split ( t , ( * nodeLoc ) ( root ) , key ) if ! atomic . CompareAndSwapPointer ( & t . root , root , unsafe . Pointer ( r ) ) { return errors . New ( \" \" ) }", "del_tokens": "r , err := t . store . union ( t , ( * nodeLoc ) ( atomic . LoadPointer ( & t . root ) ) , atomic . StorePointer ( & t . root , unsafe . Pointer ( r ) ) // TODO: Use CAS? left , _ , right , err := t . store . split ( t , ( * nodeLoc ) ( atomic . LoadPointer ( & t . root ) ) , key ) atomic . StorePointer ( & t . root , unsafe . Pointer ( r ) ) // TODO: Use CAS?", "commit_type": "use"}
{"commit_tokens": ["Implement", "throttling", "and", "bps", "measurement"], "add_tokens": "\" \" var ThrottlerPool * iothrottler . IOThrottlerPool func init ( ) { ThrottlerPool = iothrottler . NewIOThrottlerPool ( iothrottler . Unlimited ) } // if it takes too long to establish a connection, give up timeoutConn , err := net . DialTimeout ( netw , addr , cTimeout ) // respect global throttle settings throttledConn , err := ThrottlerPool . AddConn ( timeoutConn ) if err != nil { return nil , errors . Wrap ( err , 1 ) } // measure bps monitorConn := & monitoringConn { Conn : throttledConn , } // if we stay idle too long, close idleConn := idletiming . Conn ( monitorConn , rwTimeout , func ( ) { monitorConn . Close ( )", "del_tokens": "conn , err := net . DialTimeout ( netw , addr , cTimeout ) idleConn := idletiming . Conn ( conn , rwTimeout , func ( ) { conn . Close ( )", "commit_type": "implement"}
{"commit_tokens": ["Add", "documentation", "around", "Type", "registration"], "add_tokens": "// Define the general iterator interface, as well as the Base iterator which all // UID returns the unique identifier of the iterator. // FixedIterator wraps iterators that are modifiable by addition of fixed value sets. // Type enumerates the set of Iterator types. // We use a sync.Mutex rather than an RWMutex since the client packages keep // the Type that was returned, so the only possibility for contention is at // initialization. // Register adds a new iterator type to the set of acceptable types, returning // the registered Type. // Calls to Register are idempotent and must be made prior to use of the iterator. // The conventional approach for use is to include a call to Register in a package // init() function, saving the Type to a private package var. // String returns a string representation of the Type.", "del_tokens": "// Define the general iterator interface, as well as the BaseIterator which all", "commit_type": "add"}
{"commit_tokens": ["Use", "GetConsoleCP", "instead", "of", "GetACP"], "add_tokens": "kernel32 = syscall . NewLazyDLL ( \" \" ) procGetConsoleOutputCP = kernel32 . NewProc ( \" \" ) r1 , _ , _ := procGetConsoleOutputCP . Call ( )", "del_tokens": "kernel32 = syscall . NewLazyDLL ( \" \" ) procGetACP = kernel32 . NewProc ( \" \" ) r1 , _ , _ := procGetACP . Call ( )", "commit_type": "use"}
{"commit_tokens": ["added", "tests", "to", "cover", "untested", "code"], "add_tokens": "// we just advanced, so it doesn't match, it must be greater // no need to call next s . currentId = s . currs [ i ] . ID", "del_tokens": "// if it still doesn't have the currentId, next and start over s . currs [ i ] , err = termSearcher . Next ( ) if err != nil { return nil , err } if s . currs [ i ] == nil { s . currentId = \" \" } else { s . currentId = s . currs [ i ] . ID }", "commit_type": "add"}
{"commit_tokens": ["Improve", "language", "model", "fix", "bug", "in", "Yelp"], "add_tokens": "return err } if len ( question ) > 0 { if loc != nil && len ( loc . Name ) > 0 { resp . State [ \" \" ] = loc . Name } resp . Sentence = question return pkg . SaveResponse ( respMsg , resp ) } resp . State [ \" \" ] = loc . Name } // Occurs in the case of \"nearby\" or other contextual place terms, where // no previous context was available to expand it. if len ( resp . State [ \" \" ] . ( string ) ) == 0 { loc , question , err := knowledge . GetLocation ( db , m . User ) if err != nil { // with bayesian classification case \" \" , \" \" , \" \" , \" \" : resp . Sentence = \" \" + b . Name + \" \" + addr", "del_tokens": "// TODO fix bug right here log . Println ( \" \" , loc ) log . Println ( \" \" , question ) log . Println ( \" \" , err ) log . Println ( \" \" ) case \" \" , \" \" , \" \" : resp . Sentence = \" \" + b . Name + \" \" + addr", "commit_type": "improve"}
{"commit_tokens": ["fixed", "bug", "-", "now", "caching", "patterns", "again"], "add_tokens": "processed := false if includeDecimalDigits { _ , processed = numberFormats [ pattern ] } else { _ , processed = numberFormatsNoDecimals [ pattern ] if ! processed { if includeDecimalDigits { numberFormats [ pattern ] = format } else { numberFormatsNoDecimals [ pattern ] = format if includeDecimalDigits { return numberFormats [ pattern ] } return numberFormatsNoDecimals [ pattern ]", "del_tokens": "formatsSlice := numberFormats if ! includeDecimalDigits { formatsSlice = numberFormatsNoDecimals if _ , ok := formatsSlice [ pattern ] ; ! ok { if ! includeDecimalDigits { formatsSlice [ pattern ] = format return formatsSlice [ pattern ]", "commit_type": "fix"}
{"commit_tokens": ["Move", "the", "inverted", "items", "correctly", "."], "add_tokens": "octaves := degree / len ( c ) pos := degree % len ( c ) for _ , p := range c [ pos : ] { if octaves > 0 { p = p . Transpose ( Octave ( octaves ) ) . ( Pitch ) for _ , p := range c [ : pos ] { chord = append ( chord , p . Transpose ( Octave ( octaves + 1 ) ) . ( Pitch ) ) }", "del_tokens": "octave := Octave ( 1 ) for i , p := range c { if i < degree { p = p . Transpose ( octave ) . ( Pitch )", "commit_type": "move"}
{"commit_tokens": ["Changed", "test", "to", "use", "multiple", "describes"], "add_tokens": "d . Describe ( \" \" , func ( d * D ) { d . It ( \" \" , func ( t * T ) { sum := 1 + 1 t . Assert ( sum ) . Equals ( 2 ) } )", "del_tokens": "d . It ( \" \" , func ( t * T ) { sum := 1 + 1 t . Assert ( sum ) . Equals ( 2 )", "commit_type": "change"}
{"commit_tokens": ["Added", "ability", "to", "set", "parameters", "for", "Mechanisms"], "add_tokens": "// Add any parameters passed (For now presume always bytes were passed in, is there another case?) m . Parameter = x . ( [ ] byte )", "del_tokens": "// TODO(miek): Not seen anything as elaborate as Attributes, so for know do nothing.", "commit_type": "add"}
{"commit_tokens": ["Add", "stubs", "for", "new", "MultipartManagementOp", "code"], "add_tokens": "Part [ ] * PartMetadata", "del_tokens": "// part container for particular part of an object type part struct { PartNumber int LastModified time . Time `type:\"timestamp\" timestampFormat:\"iso8601\"` ETag string Size int64 } Part [ ] * part", "commit_type": "add"}
{"commit_tokens": ["fixed", "registration", "of", "the", "help", "action"], "add_tokens": "act = & action { path : path , runner : r , params : map [ string ] * option { } , description : desc } // Inject the \"help\" option (handled specially). helpOption := & option { field : \" \" , short : \" \" , long : \" \" , isFlag : true , desc : \" \" } act . opts = append ( act . opts , helpOption ) act . params [ \" \" ] = helpOption act . params [ \" \" ] = helpOption", "del_tokens": "act = & action { path : path , runner : r , params : map [ string ] * option { } , description : desc } act . opts = append ( act . opts , & option { short : \" \" , long : \" \" , isFlag : true , desc : \" \" } )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "extra", "reference", "to", "digest128"], "add_tokens": "d := digest128 { h1 : uint64 ( seed ) , h2 : uint64 ( seed ) }", "del_tokens": "d := & digest128 { h1 : uint64 ( seed ) , h2 : uint64 ( seed ) }", "commit_type": "remove"}
{"commit_tokens": ["Make", "ocsp", "validate", "the", "signature", "of", "a", "response", "."], "add_tokens": "ocspRes , err := ocsp . ParseResponse ( ocspResBytes , issuerCert ) if ocspRes . Certificate == nil { err = ocspRes . CheckSignatureFrom ( issuerCert ) if err != nil { return nil , err } }", "del_tokens": "\" \" _ , err = ocsp . ParseResponse ( ocspResBytes , nil ) log . Printf ( \" \" , err )", "commit_type": "make"}
{"commit_tokens": ["Allow", "child", "process", "to", "live", "if", "daemon", "dies"], "add_tokens": "/ * if err := system . ParentDeathSignal ( ) ; err != nil { return fmt . Errorf ( \" \" , err ) } * /", "del_tokens": "if err := system . ParentDeathSignal ( ) ; err != nil { return fmt . Errorf ( \" \" , err ) }", "commit_type": "allow"}
{"commit_tokens": ["Improve", "performance", "of", "value", "binding", "by", "checking", "for", "Valuers", "in", "With", "instead", "of", "Log", "."], "add_tokens": "logger Logger keyvals [ ] interface { } hasValuer bool if l . hasValuer { return l . logger . Log ( append ( BindValues ( l . keyvals ... ) , keyvals ... ) ... ) } return l . logger . Log ( append ( l . keyvals , keyvals ... ) ... ) logger : l . logger , keyvals : append ( l . keyvals , keyvals ... ) [ : n : n ] , hasValuer : l . hasValuer || ContainsValuer ( keyvals ) ,", "del_tokens": "logger Logger keyvals [ ] interface { } return l . logger . Log ( append ( BindValues ( l . keyvals ... ) , keyvals ... ) ... ) logger : l . logger , keyvals : append ( l . keyvals , keyvals ... ) [ : n : n ] ,", "commit_type": "improve"}
{"commit_tokens": ["Added", "place", "holders", "to", "deploy", "cmd"], "add_tokens": "Expect ( fakeUI . Errors ) . To ( ContainElement ( \" \" ) )", "del_tokens": "Expect ( err . Error ( ) ) . To ( ContainSubstring ( \" \" ) ) Expect ( fakeUI . Errors ) . To ( ContainElement ( \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "common", "unit", "tests"], "add_tokens": "NodeAddr = net . IP { 0xbe , 0xef , 0xbe , 0xef , 0xbe , 0xef , 0xbe , 0xef , 0xaa , 0xaa , 0xaa , 0xaa , 0x11 , 0x11 , 0 , 0 }", "del_tokens": "NodeAddr = net . IP { 0xbe , 0xef , 0xbe , 0xef , 0xbe , 0xef , 0xbe , 0xef , 0xaa , 0xaa , 0xaa , 0xaa , 0 , 0 , 0 , 0 }", "commit_type": "fix"}
{"commit_tokens": ["add", "f", "as", "same", "as", "H"], "add_tokens": "case 'H' , 'f' :", "del_tokens": "case 'H' :", "commit_type": "add"}
{"commit_tokens": ["updated", "the", "pathutil", "package", "to", "be", "used", "from", "the", "new", "go", "-", "utils", "repo"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["add", "simple", "Exit", "function", "if", "there", "is", "no", "error"], "add_tokens": "gitmedia . Exit ( \" \\n \\n \" , mediafile , tmpfile )", "del_tokens": "gitmedia . Panic ( nil , \" \\n \\n \" , mediafile , tmpfile )", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "Migration", "ID", "in", "DB", "validation", "optional", "."], "add_tokens": "// ValidateDBMigrationIDs will cause migrate to fail if there's unknown migration // IDs in the database ValidateDBMigrationIDs bool TableName : \" \" , IDColumnName : \" \" , IDColumnSize : 255 , UseTransaction : false , ValidateDBMigrationIDs : false , if g . options . ValidateDBMigrationIDs { unknownMigrations , err := g . unknownMigrationsHaveHappened ( ) if err != nil { return err } if unknownMigrations { return ErrUnknownPastMigration }", "del_tokens": "TableName : \" \" , IDColumnName : \" \" , IDColumnSize : 255 , UseTransaction : false , unknownMigrations , err := g . unknownMigrationsHaveHappened ( ) if err != nil { return err } if unknownMigrations { return ErrUnknownPastMigration", "commit_type": "make"}
{"commit_tokens": ["Make", "it", "easier", "to", "figure", "out", "what", "went", "wrong", "on", "server", "."], "add_tokens": "type errorResponse struct { Code int Description string } errorResponse := getErrorResponse ( rawResponse ) message := fmt . Sprintf ( \" \" , rawResponse . StatusCode , errorResponse . Description ) err = errors . New ( message ) errorResponse := getErrorResponse ( rawResponse ) message := fmt . Sprintf ( \" \" , rawResponse . StatusCode , errorResponse . Description ) err = errors . New ( message ) func getErrorResponse ( response * http . Response ) ( eR errorResponse ) { jsonBytes , _ := ioutil . ReadAll ( response . Body ) response . Body . Close ( ) eR = errorResponse { } _ = json . Unmarshal ( jsonBytes , & eR ) return }", "del_tokens": "err = errors . New ( fmt . Sprintf ( \" \" , rawResponse . StatusCode ) ) err = errors . New ( fmt . Sprintf ( \" \" , rawResponse . StatusCode ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "writemutex", "on", "socket", ".", "io"], "add_tokens": "\" \" writeMutex := & sync . Mutex { } writeMutex . Lock ( ) writeMutex . Unlock ( ) // so.Emit(\"disconnect\") so . On ( \" \" , func ( ) { logrus . Warnf ( \" \" ) } )", "del_tokens": "so . Emit ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["change", "to", "my", "fork", "of", "sqlite", "pkg"], "add_tokens": "_ \" \"", "del_tokens": "_ \" \"", "commit_type": "change"}
{"commit_tokens": ["remove", "dependency", "on", "go", "-", "cmp", "for", "tests"], "add_tokens": "\" \" if ! reflect . DeepEqual ( tc . in , tc . out ) { t . Fatalf ( \" \" , tc . out , tc . in )", "del_tokens": "\" \" if ! cmp . Equal ( tc . in , tc . out ) { t . Fatalf ( \" \" , cmp . Diff ( tc . in , tc . out ) )", "commit_type": "remove"}
{"commit_tokens": ["Use", "goconvey", "for", "the", "tests"], "add_tokens": ". \" \" Convey ( \" \" , t , func ( ) { l := Logger ( ) Convey ( \" \" , func ( ) { So ( l . Level ( ) , ShouldEqual , logging . ERROR ) } ) Convey ( \" \" , func ( ) { So ( l . Name ( ) , ShouldEqual , \" \" ) } ) } )", "del_tokens": "l := Logger ( ) if w := l . Level ( ) ; w != logging . ERROR { t . Error ( \" \" , logging . ERROR , w ) }", "commit_type": "use"}
{"commit_tokens": ["added", "example", "and", "improved", "documentation"], "add_tokens": "// See the basic example on how to use this library with a router. The other example shows the short annotation notation // and the direct usage of actions without a router. // * Options with a boolean value are internally handled as flags, i.e. presence of the flag indicates true.", "del_tokens": "// See the basic example on how to use this library. // * Options with a boolean value are internally handled as flags, i.e. presence of the flag indicates true (or // opposite of a defined default value).", "commit_type": "add"}
{"commit_tokens": ["remove", "dates", "from", "example", "logging"], "add_tokens": "stdlog = log . New ( os . Stdout , \" \" , 0 ) errlog = log . New ( os . Stderr , \" \" , 0 )", "del_tokens": "stdlog = log . New ( os . Stdout , \" \" , log . Ldate | log . Ltime ) errlog = log . New ( os . Stderr , \" \" , log . Ldate | log . Ltime )", "commit_type": "remove"}
{"commit_tokens": ["improve", "documentation", "on", "x2j", ".", "Unmarshal", "()"], "add_tokens": "// x2j.Unmarshal([]byte(doc),&s) where s of type string (Overrides xml.Unmarshal().) // x2j.Unmarshal([]byte(doc),&struct) - passed to xml.Unmarshal() // x2j.Unmarshal([]byte(doc),&slice) - passed to xml.Unmarshal()", "del_tokens": "// x2j.Unmarshal([]byte(doc),&s) where s of type string", "commit_type": "improve"}
{"commit_tokens": ["move", "example", "code", "to", "separage", "package"], "add_tokens": "package s3_test \" \" keys := s3 . Keys { s3 . Sign ( r , keys )", "del_tokens": "package s3 keys := Keys { Sign ( r , keys )", "commit_type": "move"}
{"commit_tokens": ["Update", "build", "tags", "such", "that", "we", "can", "properly", "compile", "on", "all", "platforms", "(", "especially", "for", "packagers", ")", "and", "updated", "hack", "/", "PACKAGERS", ".", "md", "to", "mention", "the", "DOCKER_BUILDTAGS", "variable", "that", "will", "need", "to", "be", "set", "for", "binaries", "that", "might", "be", "used", "on", "AppArmor", "(", "such", "as", "Debian", "and", "especially", "Ubuntu", ")"], "add_tokens": "// +build apparmor,linux,amd64", "del_tokens": "// +build apparmor", "commit_type": "update"}
{"commit_tokens": ["Fix", "import", "path", "and", "use", "a", "mobile", "-", "friendly", "test", "page", "as", "an", "example", "."], "add_tokens": "import \" \" remote , _ := godet . Connect ( \" \" , false ) // Navigate to mobile site remote . Navigate ( \" \" ) remote . SaveScreenshot ( \" \" , 0644 , 0 , true )", "del_tokens": "import \" \" remote , _ := godet . Connect ( \" \" , true ) // create new tab tab , _ := remote . NewTab ( \" \" ) // google.com is wonky _ = remote . SaveScreenshot ( \" \" , 0644 , 0 , true )", "commit_type": "fix"}
{"commit_tokens": ["Make", "errors", "in", "inline", "eval", "panics"], "add_tokens": "panic ( fmt . Sprintf ( \" \" , input , err ) )", "del_tokens": "log . Debugf ( \" \" , input , err )", "commit_type": "make"}
{"commit_tokens": ["updated", "fuzz", "to", "use", "detect"], "add_tokens": "// Detect message. l , mt := DetectMessage ( data ) // Check length if l == 0 { // for testing purposes we will not cancel // on incomplete buffers } msg , err := mt . New ( )", "del_tokens": "// Extract the type from the first byte. t := MessageType ( data [ 0 ] >> 4 ) msg , err := t . New ( )", "commit_type": "update"}
{"commit_tokens": ["fixed", "issue", "with", "uaac", "list", "users", "having", "limit", "of", "100", "users"], "add_tokens": "url := fmt . Sprintf ( \" \" , m . Host )", "del_tokens": "url := fmt . Sprintf ( \" \" , m . Host )", "commit_type": "fix"}
{"commit_tokens": ["use", "Content", "by", "default", "in", "atom", "instead", "of", "Summary", "(", "via", "Description", ")", "change", "content", "to", "a", "struct", "and", "set", "Type", "to", "html"], "add_tokens": "XMLName xml . Name `xml:\"summary\"` Content string `xml:\",chardata\"` Type string `xml:\"type,attr\"` } type AtomContent struct { XMLName xml . Name `xml:\"content\"` Content string `xml:\",chardata\"` Type string `xml:\"type,attr\"` Content * AtomContent Rights string `xml:\"rights,omitempty\"` Source string `xml:\"source,omitempty\"` Published string `xml:\"published,omitempty\"` c := & AtomContent { Content : i . Description , Type : \" \" } Content : c ,", "del_tokens": "Content string `xml:\",chardata\"` Type string `xml:\"type,attr\"` Content string `xml:\"content,omitempty\"` Rights string `xml:\"rights,omitempty\"` Source string `xml:\"source,omitempty\"` Published string `xml:\"published,omitempty\"` s := & AtomSummary { i . Description , \" \" } Summary : s ,", "commit_type": "use"}
{"commit_tokens": ["remove", "args", "unit", "from", "MeasureTextWidth", "for", "backward", "compatible"], "add_tokens": "return PointsToUnits ( gp . config . Unit , textWidthPdfUnit ) , nil", "del_tokens": "return PointsToUnits ( units , textWidthPdfUnit ) , nil", "commit_type": "remove"}
{"commit_tokens": ["Fix", "Parsing", "numbers", "for", "indented", "son"], "add_tokens": "return c == ' ' || c == '\\n' || c == ',' || c == '}' || c == ']'", "del_tokens": "return c == ',' || c == '}' || c == ']'", "commit_type": "fix"}
{"commit_tokens": ["add", "--", "list", "-", "options", "functionality", "to", "goopt", "."], "add_tokens": "goopt . Parse ( nil )", "del_tokens": "goopt . Parse ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "and", "update", "version", "."], "add_tokens": "data := & Metadata { Version : VERSION , Type : \" \" }", "del_tokens": "data := & Metadata { Version : \" \" , Type : \" \" }", "commit_type": "fix"}
{"commit_tokens": ["use", "short", "variable", "decs", "and", "extract", "structs", "out", "of", "functions"], "add_tokens": "type RouteMapEntry struct { Name , Struct string } type HandlerInfo struct { Name , Verb , Path , Doc string } path := parent + name path := parent + name", "del_tokens": "var path = parent + name type HandlerInfo struct { Name , Verb , Path , Doc string } var path = parent + name type RouteMapEntry struct { Name , Struct string }", "commit_type": "use"}
{"commit_tokens": ["Add", "config", "parameter", "to", "new", "gelf", "logger", "method"], "add_tokens": "gelfCfg := gomol . NewGelfLoggerConfig ( ) gelfCfg . Hostname = \" \" gelfCfg . Port = 12201 gomol . AddLogger ( gomol . NewGelfLogger ( gelfCfg ) ) defer gomol . ShutdownLoggers ( )", "del_tokens": "gomol . AddLogger ( gomol . NewGelfLogger ( \" \" , 12201 ) ) gomol . ShutdownLoggers ( )", "commit_type": "add"}
{"commit_tokens": ["Make", "failing", "negative", "index", "output", "conform", "to", "dot"], "add_tokens": "dotString = dot ( t , strings . Replace ( fmt . Sprintf ( \" \" , modeName [ Mode ] , r . min , r . max , r . target ) , \" \" , \" \" , - 1 ) ) err = dotFile ( nil , strings . Replace ( fmt . Sprintf ( \" \" , modeName [ Mode ] , r . min , r . max , r . target ) , \" \" , \" \" , - 1 ) , dotString ) err = dotFile ( t , strings . Replace ( fmt . Sprintf ( \" \" , modeName [ Mode ] , r . min , r . max , r . target ) , \" \" , \" \" , - 1 ) , \" \" )", "del_tokens": "dotString = dot ( t , fmt . Sprintf ( \" \" , modeName [ Mode ] , r . min , r . max , r . target ) ) err = dotFile ( nil , fmt . Sprintf ( \" \" , modeName [ Mode ] , r . min , r . max , r . target ) , dotString ) err = dotFile ( t , fmt . Sprintf ( \" \" , modeName [ Mode ] , r . min , r . max , r . target ) , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Add", "method", "Skip", ".", "When", "()"], "add_tokens": "Skip = skipRule { skip : true } if s , ok := rule . ( skipRule ) ; ok && s . skip { if s , ok := rule . ( skipRule ) ; ok && s . skip { type skipRule struct { skip bool } func ( r skipRule ) Validate ( interface { } ) error { // When determines if all rules following it should be skipped. func ( r skipRule ) When ( condition bool ) skipRule { r . skip = condition return r }", "del_tokens": "Skip = & skipRule { } if _ , ok := rule . ( * skipRule ) ; ok { if _ , ok := rule . ( * skipRule ) ; ok { type skipRule struct { } func ( r * skipRule ) Validate ( interface { } ) error {", "commit_type": "add"}
{"commit_tokens": ["Added", "canonical", "import", "path", "obligation"], "add_tokens": "package ecs // import \"engo.io/ecs\"", "del_tokens": "package ecs", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "more", "types"], "add_tokens": "if len ( kn ) <= 0 {", "del_tokens": "if len ( kn ) < 2 {", "commit_type": "add"}
{"commit_tokens": ["using", "FEN", "notiation", "to", "test", "moves"], "add_tokens": "if sq == nil || ! ( sq . rank == R3 || sq . rank == R6 ) {", "del_tokens": "// TODO check for valid enPassant square dependent on turn if sq == nil {", "commit_type": "use"}
{"commit_tokens": ["Fix", "fillStructRecursive", ":", "continue", "after", "first", "pointer"], "add_tokens": "} else if val , ok := valmap [ name ] ; ok { // for flag := range defaultValmap { // fmt.Println(flag) // } // for flag, val := range valmap { // fmt.Printf(\"%s : %+s (default : %+v)\\n\", flag, val, defaultValmap[flag]) // }", "del_tokens": "return nil } if val , ok := valmap [ name ] ; ok { for flag := range defaultValmap { fmt . Println ( flag ) }", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", "definitions"], "add_tokens": "ReturnCount float64 `json:\"returnCount,omitempty\"` // Count of returned entries from this storage. If pathFilter is empty, it is the count of all entries from this storage. // returnCount - Count of returned entries from this storage. If pathFilter is empty, it is the count of all entries from this storage. func ( p * RequestEntriesParams ) Do ( ctxt context . Context , h cdp . Executor ) ( cacheDataEntries [ ] * DataEntry , returnCount float64 , err error ) { return nil , 0 , err return res . CacheDataEntries , res . ReturnCount , nil", "del_tokens": "HasMore bool `json:\"hasMore,omitempty\"` // If true, there are more entries to fetch in the given range. // hasMore - If true, there are more entries to fetch in the given range. func ( p * RequestEntriesParams ) Do ( ctxt context . Context , h cdp . Executor ) ( cacheDataEntries [ ] * DataEntry , hasMore bool , err error ) { return nil , false , err return res . CacheDataEntries , res . HasMore , nil", "commit_type": "update"}
{"commit_tokens": ["updates", "Options", ".", "ShouldSample", "signature", "to", "have", "cleaner", "interface"], "add_tokens": "ShouldSample func ( traceID uint64 ) bool", "del_tokens": "ShouldSample func ( uint64 ) bool", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "setting", "msg_timeout", "in", "Identify", "command"], "add_tokens": "\" \" // MessageTimeout can bet set to configure the server-side message timeout // for messages delivered to this consumer. By default it is not sent to // the server. MessageTimeout time . Duration ClientID string `json:\"client_id,omitempty\"` Hostname string `json:\"hostname,omitempty\"` UserAgent string `json:\"user_agent,omitempty\"` MessageTimeout int `json:\"msg_timeout,omitempty\"` ClientID : c . ClientID , Hostname : c . Hostname , UserAgent : c . UserAgent , MessageTimeout : int ( c . MessageTimeout / time . Millisecond ) , ClientID : body . ClientID , Hostname : body . Hostname , UserAgent : body . UserAgent , MessageTimeout : time . Millisecond * time . Duration ( body . MessageTimeout ) ,", "del_tokens": "ClientID string `json:\"client_id,omitempty\"` Hostname string `json:\"hostname,omitempty\"` UserAgent string `json:\"user_agent,omitempty\"` ClientID : c . ClientID , Hostname : c . Hostname , UserAgent : c . UserAgent , ClientID : body . ClientID , Hostname : body . Hostname , UserAgent : body . UserAgent ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "where", "version", "wouldn", "t", "correctly", "populate"], "add_tokens": "if err != nil { return err } driver . session . Query ( \" \" + tableName + \" \" , versionRow ) . Exec ( ) return uint64 ( version ) - 1 , err", "del_tokens": "return uint64 ( version ) , err", "commit_type": "fix"}
{"commit_tokens": ["Fix", "index", "out", "of", "range", "error"], "add_tokens": "for n , b := range contents { if n >= 512 { break }", "del_tokens": "for _ , b := range contents [ : 512 ] {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "check", "to", "client", "in", "order", "to", "make", "tests", "run", "successfully"], "add_tokens": "var conf * tls . Config // This means we are connecting to \"localhost\". Disable certificate chain check if strings . HasPrefix ( c . IrcAddress , \" \" ) { conf = & tls . Config { InsecureSkipVerify : true , } } else { conf = & tls . Config { }", "del_tokens": "conf := & tls . Config { //InsecureSkipVerify: true,", "commit_type": "add"}
{"commit_tokens": ["Adding", "Shrink", "to", "Stream", "to", "remove", "the", "recvBuffer"], "add_tokens": "// Read the 'ping' // Shrink the internal buffer! stream . Shrink ( ) // Write out the 'pong' stream , err := client . OpenStream ( ) // Send the 'ping' // Read the 'pong' // Shrink the buffer stream . Shrink ( )", "del_tokens": "stream , err := client . Open ( )", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "doc", ".", "go"], "add_tokens": "// This example demonstrates how to use of the openid middlewares to validate incoming", "del_tokens": "// This example demonstrates how to make use of the openid middlewares to validate incoming", "commit_type": "add"}
{"commit_tokens": ["Use", "xdg", "-", "open", "from", "PATH", "instead", "of", "hardcoded", "."], "add_tokens": "cmd := exec . Command ( \" \" , u )", "del_tokens": "cmd := exec . Command ( \" \" , u )", "commit_type": "use"}
{"commit_tokens": ["make", "Decode", "return", "unsigned", ";", "added", "test", "cases"], "add_tokens": "func Decode ( s string ) uint64 { res := uint64 ( 0 ) res += uint64 ( byteOffset ) * uint64 ( math . Pow ( 36 , float64 ( idx ) ) )", "del_tokens": "func Decode ( s string ) int64 { res := int64 ( 0 ) res += int64 ( byteOffset ) * int64 ( math . Pow ( 36 , float64 ( idx ) ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "benchmark", "for", "Unmarshaling", "Stripe", "customer", "example"], "add_tokens": "type fatalF interface { func getBaseData ( b fatalF ) [ ] byte {", "del_tokens": "type fatalFer interface { func getBaseData ( b fatalFer ) [ ] byte {", "commit_type": "add"}
{"commit_tokens": ["Add", "main", "package", "so", "it", "can", "be", "used", "as", "a", "simple", "command"], "add_tokens": "func symmetricTest ( t * testing . T , ext string , cf CompressFunc , dcf DecompressFunc ) {", "del_tokens": "func symmetricTest ( t * testing . T , ext string , cf compressFunc , dcf decompressFunc ) { type ( compressFunc func ( string , [ ] string ) error decompressFunc func ( string , string ) error )", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "debug", "information", "to", "heapster", "startup", "."], "add_tokens": "return nil , fmt . Errorf ( \" \" , HostsFile , err ) glog . Infof ( \" \" , cadvisorHosts ) return nil , fmt . Errorf ( \" \" , HostsFile , err )", "del_tokens": "return nil , err return nil , fmt . Errorf ( \" \" , HostsFile , err )", "commit_type": "add"}
{"commit_tokens": ["Added", "functions", "to", "create", "StringSlice", "and", "move", "StringInt", "to", "bottom"], "add_tokens": "func NewStringSlice ( parts [ ] string ) StringSlice { return StringSlice { parts } // StringInt representes a string or an integer value. type StringInt struct { value string } func ( e * StringInt ) UnmarshalJSON ( b [ ] byte ) error { var num int err := json . Unmarshal ( b , & num ) if err == nil { e . value = strconv . Itoa ( num ) return nil } return json . Unmarshal ( b , & e . value ) } func ( e StringInt ) String ( ) string { return e . value }", "del_tokens": "// StringInt representes a string or an integer value. type StringInt struct { value string } func ( e * StringInt ) UnmarshalJSON ( b [ ] byte ) error { var num int err := json . Unmarshal ( b , & num ) if err == nil { e . value = strconv . Itoa ( num ) return nil } return json . Unmarshal ( b , & e . value ) } func ( e StringInt ) String ( ) string { return e . value // StringMap representes a string or a map of strings.", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "when", "KRPC", "messages", "don", "t", "contain", "a", "valid", "t", "field"], "add_tokens": "func ( m Msg ) T ( ) ( t string ) { tif , ok := m [ \" \" ] if ! ok { return } t , _ = tif . ( string ) return } var d Msg t := s . findResponseTransaction ( d . T ( ) , addr )", "del_tokens": "var d map [ string ] interface { } t := s . findResponseTransaction ( d [ \" \" ] . ( string ) , addr )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "printMessage", "to", "not", "print", "a", "termination", "character", "when", "nocolor", "is", "active", "."], "add_tokens": "s := r + l + p + formatReset ( nc ) func formatReset ( nc bool ) string { s := formatText ( textnormal , nc )", "del_tokens": "s := r + l + p + formatReset ( ) func formatReset ( ) string { s := formatText ( textnormal , false )", "commit_type": "fix"}
{"commit_tokens": ["Added", "BLE", ".", "UpdateRssi", "and", "verbose", "flag", "(", "enable", "/", "disable", "logging", "of", "events", "payload", ")"], "add_tokens": "verbose bool func ( ble * BLE ) SetVerbose ( v bool ) { ble . verbose = v } if ble . verbose { log . Printf ( \" \\n \" , id , args ) } case 54 : deviceUuid := args [ \" \" ] . ( UUID ) rssi := args [ \" \" ] . ( int64 ) if p , ok := ble . peripherals [ deviceUuid . String ( ) ] ; ok { p . rssi = rssi } log . Println ( \" \" , deviceUuid . String ( ) , rssi ) // update rssi func ( ble * BLE ) UpdateRssi ( deviceUuid UUID ) { uuid := deviceUuid . String ( ) if p , ok := ble . peripherals [ uuid ] ; ok { ble . sendCBMsg ( 43 , dict { \" \" : p . uuid } ) } else { log . Println ( \" \" ) } }", "del_tokens": "log . Printf ( \" \\n \" , id , args )", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "where", "Validate", "returns", "wrong", "message"], "add_tokens": "// Capture the prerelease message only once. When it happens the first time // this var is marked var prerelesase bool // Before running the check handle the case there the version is // a prerelease and the check is not searching for prereleases. if c . con . pre == \" \" && v . pre != \" \" { if ! prerelesase { em := fmt . Errorf ( \" \" , v ) e = append ( e , em ) prerelesase = true } } else { if ! c . check ( v ) { em := fmt . Errorf ( c . msg , v , c . orig ) e = append ( e , em ) joy = false }", "del_tokens": "if ! c . check ( v ) { em := fmt . Errorf ( c . msg , v , c . orig ) e = append ( e , em )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unnecessary", "added", "variable", "."], "add_tokens": "addNames = true if addNames {", "del_tokens": "elided := false elided = true if addNames || elided {", "commit_type": "remove"}
{"commit_tokens": ["adding", "size", "zero", "test", "case", "and", "handling"], "add_tokens": "if size <= 0 {", "del_tokens": "if size < 0 {", "commit_type": "add"}
{"commit_tokens": ["fixed", "consumer", "deregistering", "during", "shutting", "down"], "add_tokens": "closed bool if ! oc . closed { oc . closed = true oc . close <- true }", "del_tokens": "oc . close <- true", "commit_type": "fix"}
{"commit_tokens": ["Adding", "UrlForPath", "so", "this", "functionality", "can", "use", "without", "defining", "route"], "add_tokens": "return m . UrlForPath ( m . PathFor ( routeName ) , params ) } func ( m * routeManager ) UrlForPath ( path string , params map [ string ] interface { } ) string {", "del_tokens": "path := m . PathFor ( routeName )", "commit_type": "add"}
{"commit_tokens": ["Make", "testing", "Dependency", "implementations", "private"], "add_tokens": "& fakeDependency { } , & fakeDependency { } , dependency , data := & fakeDependency { } , \" \" dependency , data := & fakeDependency { } , \" \"", "del_tokens": "& FakeDependency { } , & FakeDependency { } , dependency , data := & FakeDependency { } , \" \" dependency , data := & FakeDependency { } , \" \"", "commit_type": "make"}
{"commit_tokens": ["Move", "f", ".", "wg", ".", "Done", "()", "to", "Read", "and", "Write", "to", "avoid", "leaking", "handles"], "add_tokens": "// prepareIo prepares for a new IO operation. // The caller must call f.wg.Done() when the IO is finished, prior to Close() returning. defer f . wg . Done ( ) defer f . wg . Done ( )", "del_tokens": "// prepareIo prepares for a new IO operation f . wg . Done ( ) f . wg . Done ( )", "commit_type": "move"}
{"commit_tokens": ["Add", "GetProviderName", "function", "as", "variable"], "add_tokens": "providerName , err := GetProviderName ( req ) providerName , err := GetProviderName ( req ) var GetProviderName = getProviderName", "del_tokens": "providerName , err := getProviderName ( req ) providerName , err := getProviderName ( req )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "functionType", "s", "Replace"], "add_tokens": "if state . Flag ( '#' ) { fmt . Fprintf ( state , \" t t s [0 ] , t t s [1 ] ) } else { fmt . Fprintf ( state , \" t t s [0 ] , t t s [1 ] ) } t . ts [ 1 ] = tt . Replace ( what , with )", "del_tokens": "fmt . Fprintf ( state , \" t t s [0 ] , t t s [1 ] ) tt = tt . Replace ( what , with )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "private", "logger", "."], "add_tokens": "\" \" const logFlags = 0 var gLogger = log . New ( os . Stderr , \" \" , logFlags ) gLogger . Println ( ) gLogger . Println ( \" \" ) gLogger . Println ( \" \" ) gLogger . Println ( \" \" ) gLogger . Println ( ) gLogger . Println ( \" \" ) gLogger . Println ( ) gLogger . Printf ( \" \" , offsetStr , s . desc ) gLogger . Printf ( \" \" , offsetStr , d ) gLogger . Printf ( \" \" , offsetStr , dashes ) gLogger . Println ( )", "del_tokens": "func init ( ) { log . SetFlags ( 0 ) } log . Println ( ) log . Println ( \" \" ) log . Println ( \" \" ) log . Println ( \" \" ) log . Println ( ) log . Println ( \" \" ) log . Println ( ) log . Printf ( \" \" , offsetStr , s . desc ) log . Printf ( \" \" , offsetStr , d ) log . Printf ( \" \" , offsetStr , dashes ) log . Println ( )", "commit_type": "use"}
{"commit_tokens": ["Update", "benchmark", "timings", "to", "stress", "peerstores", "more"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Using", "new", "go", "-", "martini", "import", "path"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "expected = [ ] byte { fromBinary ( \" \" ) , fromBinary ( \" \" ) }", "del_tokens": "expected = [ ] byte { fromBinary ( \" \" ) , fromBinary ( \" \" ) }", "commit_type": "fix"}
{"commit_tokens": ["use", "atomic", "counter", "for", "message", "seqnos", ";", "timestamp", "is", "insufficient"], "add_tokens": "\" \" // atomic counter for seqnos counter uint64 seqno := make ( [ ] byte , 16 ) counter := atomic . AddUint64 ( & p . counter , 1 ) binary . BigEndian . PutUint64 ( seqno [ : 8 ] , uint64 ( time . Now ( ) . UnixNano ( ) ) ) binary . BigEndian . PutUint64 ( seqno [ 8 : ] , counter )", "del_tokens": "seqno := make ( [ ] byte , 8 ) binary . BigEndian . PutUint64 ( seqno , uint64 ( time . Now ( ) . UnixNano ( ) ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "comment", "(", "lint", ")"], "add_tokens": "// OptionCompletionOnDown allows for Down arrow key to trigger completion.", "del_tokens": "// OptionSwitchKeyBindMode set a key bind mode.", "commit_type": "fix"}
{"commit_tokens": ["update", "the", "WorkDir", "(", "-", "w", ")", "flag", "to", "default", "to", "the", "Dir", "(", "-", "d", ")", "value", "as", "documented"], "add_tokens": "fs . StringVar ( & inv . WorkDir , \" \" , \" \" , \" \" )", "del_tokens": "fs . StringVar ( & inv . WorkDir , \" \" , inv . Dir , \" \" )", "commit_type": "update"}
{"commit_tokens": ["Fix", "typo", "in", ".", "Get", "comment"], "add_tokens": "// A path is a series of keys separated by a dot.", "del_tokens": "// A path is a series of keys searated by a dot.", "commit_type": "fix"}
{"commit_tokens": ["Move", "all", "configuration", "from", "command", "line", "to", "json", "file"], "add_tokens": "\" \" \" \" : \" \" , \" \" : 5 , \" \" : \" \" , \" \" : 5 , \" \" : \" \" , _ , ok := myProxyCommandLineConfiguration . getLogrusFormatter ( & config . LoadedConfig { } ) . ( * log . JSONFormatter ) assert . Equal ( t , os . Stdout , myProxyCommandLineConfiguration . getLogrusOutput ( & config . LoadedConfig { } ) )", "del_tokens": "_ , ok := myProxyCommandLineConfiguration . getLogrusFormatter ( ) . ( * log . JSONFormatter ) assert . Equal ( t , os . Stdout , myProxyCommandLineConfiguration . getLogrusOutput ( ) )", "commit_type": "move"}
{"commit_tokens": ["Added", "tests", "for", "possible", "errors", "."], "add_tokens": "// Possible errors are an invalid URL query parameters (url.EscapeError) or if // the date header isn't in time.RFC1123 format (*time.ParseError).", "del_tokens": "// Possible errors are an invalid URL (url.Error) or if the date header isn't // in time.RFC1123 format (time.ParseError). I haven't actually verified errors.", "commit_type": "add"}
{"commit_tokens": ["Fix", "order", "of", "arguments", "in", "debug"], "add_tokens": "log . Printf ( \" \" , file . GetName ( ) , service . GetName ( ) , templateDir )", "del_tokens": "log . Printf ( \" \" , templateDir , service . GetName ( ) , file . GetName ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "MountedFileSystem", "documentation", "."], "add_tokens": "// A struct representing the status of a mount operation, with methods for // waiting on the mount to complete, waiting for unmounting, and causing // unmounting. // Attempt to mount the supplied file system on the given directory. // mfs.WaitForReady() must be called to find out whether the mount was // successful. options . . . fuse . MountOption ) ( mfs * MountedFileSystem )", "del_tokens": "// XXX: Comments // XXX: Comments options . . . fuse . MountOption ) * MountedFileSystem", "commit_type": "add"}
{"commit_tokens": ["make", "SetFloat64", "test", "every", "32", "-", "bit", "float", "in", "existence", ".", "h", "/", "t", "Bruce", "Dawson"], "add_tokens": "// set z.form == finite inside the quo* methods. // quoCompactCore implements division of two compact decimals. z . form = finite // see quoCompactCore. xc and yc override xb and yb, respectively, if they != // c.Inflated. z . form = finite if x . Sign ( ) == 0 { z . form = zero return z } if x . IsInt ( ) { z . form = finite return z . SetBigMantScale ( x . Num ( ) , 0 ) } z . form = finite if xc == c . Inflated || yc == c . Inflated { return z . quoBigCore ( xb , xc , 0 , int32 ( xp ) , yb , yc , 0 , int32 ( yp ) ) return z . quoCompactCore ( xc , 0 , int32 ( xp ) , yc , 0 , int32 ( yp ) )", "del_tokens": "z . form = finite if xc != c . Inflated && yc != c . Inflated { return z . quoCompactCore ( xc , 0 , int32 ( xp ) , yc , 0 , int32 ( yp ) ) return z . quoBigCore ( xb , xc , 0 , int32 ( xp ) , yb , yc , 0 , int32 ( yp ) )", "commit_type": "make"}
{"commit_tokens": ["Make", "RateCounter", "and", "AvgRateCounter", "memory", "efficient"], "add_tokens": "hits * RateCounter counter * RateCounter hits : NewRateCounter ( intrvl ) , counter : NewRateCounter ( intrvl ) , func ( r * AvgRateCounter ) WithResolution ( resolution int ) * AvgRateCounter { if resolution < 1 { panic ( \" \" ) } r . hits = r . hits . WithResolution ( resolution ) r . counter = r . counter . WithResolution ( resolution ) return r } a . hits . Incr ( 1 ) hits , value := a . hits . Rate ( ) , a . counter . Rate ( )", "del_tokens": "\" \" hits int64 counter Counter atomic . AddInt64 ( & a . hits , 1 ) time . AfterFunc ( a . interval , func ( ) { atomic . AddInt64 ( & a . hits , - 1 ) a . counter . Incr ( - 1 * val ) } ) hits , value := atomic . LoadInt64 ( & a . hits ) , a . counter . Value ( )", "commit_type": "make"}
{"commit_tokens": ["Added", "ability", "to", "ignore", "fields", "by", "tagging", "them", "."], "add_tokens": "E int `testdiff:\"ignore\"` testStruct { 1 , 2 , [ ] int { 1 } , [ 3 ] int { 4 , 5 , 6 } , 9 } , testStruct { 1 , 3 , [ ] int { 1 , 2 } , [ 3 ] int { 4 , 5 , 6 } , 10 } ,", "del_tokens": "testStruct { 1 , 2 , [ ] int { 1 } , [ 3 ] int { 4 , 5 , 6 } } , testStruct { 1 , 3 , [ ] int { 1 , 2 } , [ 3 ] int { 4 , 5 , 6 } } ,", "commit_type": "add"}
{"commit_tokens": ["add", "husl", "support", "add", "missing", "color", "functions", "extend", "test", "coverage", "and", "fix", "some", "bugs", "in", "the", "color", "implementation"], "add_tokens": "color . S /= 100 color . L /= 100 r , g , b = husl . HuslToRGB ( color . H , color . S * 100.0 , color . L * 100.0 )", "del_tokens": "r , g , b = husl . HuslToRGB ( color . H , color . S , color . L )", "commit_type": "add"}
{"commit_tokens": ["Added", "routes", ".", "SelectFields", "(", "yay!", ")"], "add_tokens": "if out , err := SelectFields ( posts , c . Request ( ) ) ; err == nil { return c . JSON ( http . StatusOK , & Response { Data : out , HumanMessage : \" \" , Message : \" \" , Status : http . StatusOK , Success : true , } ) } else { return c . JSON ( http . StatusBadRequest , & Response { HumanMessage : \" \" , Message : err . Error ( ) , Status : http . StatusBadRequest , Success : false , } ) }", "del_tokens": "return c . JSON ( http . StatusOK , & Response { Data : posts , HumanMessage : \" \" , Message : \" \" , Status : http . StatusOK , Success : true , } )", "commit_type": "add"}
{"commit_tokens": ["fix", "naming", "and", "remove", "print"], "add_tokens": "decodingResultChan , closeChan := client . readJSONStream ( resp . Body , decode ) eventOrErrorChan := make ( chan EventOrError ) for decodingResult := range decodingResultChan { event , _ := decodingResult . result . ( Event ) eventOrErrorChan <- EventOrError { Error : decodingResult . err , close ( eventOrErrorChan ) return eventOrErrorChan , closeChan , nil", "del_tokens": "fmt . Printf ( \" \\n \" , event , err ) resultChan , closeChan := client . readJSONStream ( resp . Body , decode ) eventInfoChan := make ( chan EventOrError ) for res := range resultChan { event , _ := res . result . ( Event ) eventInfoChan <- EventOrError { Error : res . err , close ( eventInfoChan ) return eventInfoChan , closeChan , nil", "commit_type": "fix"}
{"commit_tokens": ["Added", "better", "notes", "regarding", "the", "project", "ID", "."], "add_tokens": "// TODO(jacobsa): A project ID is apparently only needed for creating and // listing buckets, presumably since a bucket ID already maps to a unique // project ID (cf. http://goo.gl/Plh3rb). So do we need this at all for our // use case? Probably not.", "del_tokens": "// TODO(jacobsa): I don't know what this is for, and it doesn't seem to // matter.", "commit_type": "add"}
{"commit_tokens": ["make", "Add", "()", "to", "empty", "list", "smarter"], "add_tokens": "if self . coll . Demand ( ) != nil { obj := self . coll . Demand ( ) . ( EqList ) for _ , e := range obj { if e . Equal ( m ) { return }", "del_tokens": "obj := self . coll . Demand ( ) . ( EqList ) for _ , e := range obj { if e . Equal ( m ) { return", "commit_type": "make"}
{"commit_tokens": ["add", "documentation", "for", "new", "base64", "validator"], "add_tokens": "\" \"", "del_tokens": "// \"gopkg.in/bluesuncorp/validator.v5\" \" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "Anonymous", "attribute", "to", "determine", "if", "a", "field", "represents", "an", "embedded", "type"], "add_tokens": "embedded : o . reflectType . Elem ( ) . Field ( i ) . Anonymous ,", "del_tokens": "embedded : true ,", "commit_type": "use"}
