{"commit_tokens": ["changed", "weavebox", "handler", "to", "be", "more", "compact", "and", "easier", "to", "use"], "add_tokens": "app . Get ( \" \" , func ( ctx * Context ) error { return nil } ) admin . Get ( \" \" , func ( ctx * Context ) error { return nil } )", "del_tokens": "app . Get ( \" \" , func ( ctx * Context , w http . ResponseWriter , r * http . Request ) error { return nil } ) admin . Get ( \" \" , func ( ctx * Context , w http . ResponseWriter , r * http . Request ) error { return nil } )", "commit_type": "change"}
{"commit_tokens": ["Fixing", "marshaling", "of", "REST", "XML", "error", "body"], "add_tokens": "XMLName xml . Name `xml:\"ErrorResponse\",json:\"-\"` Error restError } type restError struct { Code : e . Error . Code , Message : e . Error . Message , RequestID : e . Error . RequestID , HostID : e . Error . HostID , \" \" : e . Error . BucketName ,", "del_tokens": "Code : e . Code , Message : e . Message , RequestID : e . RequestID , HostID : e . HostID , \" \" : e . BucketName ,", "commit_type": "fix"}
{"commit_tokens": ["add", "buffered", "writers", "to", "speed", "up", "by", "60%"], "add_tokens": "\" \" var bufWriters [ ] * bufio . Writer w := bufio . NewWriter ( outgoingChan . Writer ) bufWriters = append ( bufWriters , w ) writers = append ( writers , w ) for _ , w := range bufWriters { w . Flush ( ) }", "del_tokens": "writers = append ( writers , outgoingChan . Writer )", "commit_type": "add"}
{"commit_tokens": ["added", "a", "ReadJson", "helper", "function"], "add_tokens": "\" \" // ReadJson will parses the JSON-encoded data in the http // Request object and stores the result in the value // pointed to by v. func ReadJson ( r * http . Request , v interface { } ) error { body , err := ioutil . ReadAll ( r . Body ) r . Body . Close ( ) if err != nil { return err } return json . Unmarshal ( body , v ) }", "del_tokens": "//content, err := json.Marshal(v)", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "few", "various", "typecasting", "bugs", "."], "add_tokens": "attrs := times { uint32 ( atime . Unix ( ) ) , uint32 ( mtime . Unix ( ) ) } attrs := owner { uint32 ( uid ) , uint32 ( gid ) } return c . setstat ( path , ssh_FILEXFER_ATTR_PERMISSIONS , uint32 ( mode ) )", "del_tokens": "attrs := & times { uint32 ( atime . Unix ( ) ) , uint32 ( mtime . Unix ( ) ) } attrs := & owner { uint32 ( uid ) , uint32 ( gid ) } return c . setstat ( path , ssh_FILEXFER_ATTR_PERMISSIONS , mode )", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "parenthesis", "in", "if", "/", "elseif"], "add_tokens": "verifiable , err := p . ReadConditionGroup ( false ) verifiable , err := p . ReadConditionGroup ( false )", "del_tokens": "verifiable , err := p . ReadConditionGroup ( ) verifiable , err := p . ReadConditionGroup ( )", "commit_type": "add"}
{"commit_tokens": ["add", "MarshalJSON", "&", "UnmarshalJSON", "to", "Level"], "add_tokens": "import \" \" func level ( s string ) Level { switch s { case \" \" : return DebugLevel case \" \" : return InfoLevel case \" \" : return NoticeLevel case \" \" : return WarnLevel case \" \" : return ErrorLevel case \" \" : return PanicLevel case \" \" : return AlertLevel case \" \" : return FatalLevel default : return 255 } } // MarshalJSON implementation. func ( l Level ) MarshalJSON ( ) ( [ ] byte , error ) { return [ ] byte ( `\"` + l . String ( ) + `\"` ) , nil } // UnmarshalJSON implementation. func ( l * Level ) UnmarshalJSON ( b [ ] byte ) error { * l = level ( string ( bytes . Trim ( b , `\"` ) ) ) return nil }", "del_tokens": "// TODO: Add a bytes method along with string", "commit_type": "add"}
{"commit_tokens": ["Added", "several", "more", "query", "tests"], "add_tokens": "// DeleteMatching deletes all of the records that match the passed in query // datatype is needed so indexes can be properly updated func ( s * Store ) DeleteMatching ( dataType interface { } , query * Query ) error { return s . Bolt ( ) . View ( func ( tx * bolt . Tx ) error { return s . TxDeleteMatching ( tx , dataType , query ) } ) } // TxDeleteMatching does the same as DeleteMatching, but allows you to specify your own transaction func ( s * Store ) TxDeleteMatching ( tx * bolt . Tx , dataType interface { } , query * Query ) error { toDelete := make ( keyList , 0 ) err := keyOnlyQuery ( tx , dataType , toDelete , query ) if err != nil { return err } for i := range toDelete { err = s . TxDelete ( tx , toDelete [ i ] , dataType ) if err != nil { return err } } return nil }", "del_tokens": "//TODO: DeleteMatching(query)", "commit_type": "add"}
{"commit_tokens": ["Use", "unsynchronised", "lyrics", "/", "text", "instead", "of", "USLT", "in", "common", "ids"], "add_tokens": "id := t . commonIDs [ \" \" ]", "del_tokens": "id := t . commonIDs [ \" \" ]", "commit_type": "use"}
{"commit_tokens": ["Added", "options", "to", "jsonpath", "(", "-", "e", "-", "c", ")", "and", "shortened", "prompt"], "add_tokens": "commander . SetPrompt ( fmt . Sprintf ( \" \" , client . BaseURL ) , 40 ) `jsonpath [-e] [-c] path {json}` , var joptions jsonpath . ProcessOptions options , line := args . GetOptions ( line ) for _ , o := range options { if o == \" \" || o == \" \" { joptions |= jsonpath . Enhanced } else if o == \" \" || o == \" \" { joptions |= jsonpath . Collapse } else { line = \" \" // to force an error break } } fmt . Println ( \" \" ) res := jp . Process ( jbody , joptions )", "del_tokens": "commander . Prompt = fmt . Sprintf ( \" \" , client . BaseURL ) `jsonpath path {json}` , fmt . Println ( \" \" ) res := jp . Process ( jbody )", "commit_type": "add"}
{"commit_tokens": ["Fix", "more", "to", "encode", "Struct", "properly", "with", "tagged", "name", "for", "field", "names"], "add_tokens": "// message should be tagged by \"codec\" or \"msg\" kv := make ( map [ string ] interface { } ) fields := msgtype . NumField ( ) for i := 0 ; i < fields ; i ++ { field := msgtype . Field ( i ) name := field . Name if n1 := field . Tag . Get ( \" \" ) ; n1 != \" \" { name = n1 } else if n2 := field . Tag . Get ( \" \" ) ; n2 != \" \" { name = n2 } kv [ name ] = msg . FieldByIndex ( field . Index ) . Interface ( ) } return f . EncodeAndPostData ( tag , tm , kv )", "del_tokens": "// message should be tagged by \"msg\" return f . EncodeAndPostData ( tag , tm , message )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "issues", "with", "shortname", "template", "func", "introduced", "in", "last", "commit"], "add_tokens": "// Generated shortnames that have conflicts with any scopeConflicts member will // have ArgType.NameConflictSuffix appended. // // Note: recognized types for scopeConflicts are string, []*Field, // []*QueryParam. // store back to short name map a . ShortNameTypeMap [ typ ] = v case [ ] * QueryParam : for _ , f := range k { conflicts [ f . Name ] = true }", "del_tokens": "// Generated shortnames that have conflicts with any scopeConflicts member // (string, []Field, etc) will have ArgType.NameConflictSuffix appended.", "commit_type": "fix"}
{"commit_tokens": ["using", "environment", "variables", "to", "get", "host", "name", "and", "instance"], "add_tokens": "\" \" addr := os . Getenv ( \" \" ) instance := os . Getenv ( \" \" ) var port int64 port = 1433 if instance != \" \" { instances , err := get_instances ( addr ) if err != nil { fmt . Println ( \" \" , err . Error ( ) ) os . Exit ( 1 ) } fmt . Println ( \" \" , instances ) port , err = strconv . ParseInt ( instances [ instance ] [ \" \" ] , 0 , 16 ) if err != nil { fmt . Println ( \" \" , err . Error ( ) ) os . Exit ( 1 ) } conn , err := net . Dial ( \" \" , addr + \" \" + strconv . FormatInt ( port , 10 ) )", "del_tokens": "addr := \" \" instances , err := get_instances ( addr ) if err != nil { fmt . Println ( \" \" , err . Error ( ) ) os . Exit ( 1 ) fmt . Println ( \" \" , instances ) conn , err := net . Dial ( \" \" , addr + \" \" + instances [ \" \" ] [ \" \" ] )", "commit_type": "use"}
{"commit_tokens": ["updated", "documentation", "and", "example", "for", "RPCServerOption"], "add_tokens": "// with `client` representing the metadata for the remote peer Span if available. // In case client == nil, due to the client not being instrumented, this RPC // server span will be a root span.", "del_tokens": "// with `client` representing the metadata for the remote peer Span.", "commit_type": "update"}
{"commit_tokens": ["Improve", "timeouts", "on", "http", "client", "connections", "."], "add_tokens": "type timeoutConn struct { net . Conn } func ( c timeoutConn ) Read ( p [ ] byte ) ( int , error ) { n , err := c . Conn . Read ( p ) c . Conn . SetReadDeadline ( time . Time { } ) return n , err } c , err := net . DialTimeout ( network , addr , * dialTimeout ) if err != nil { return c , err } // The net/http transport CancelRequest feature does not work until after // the TLS handshake is complete. To help catch hangs during the TLS // handshake, we set a deadline on the connection here and clear the // deadline when the first read on the connection completes. This is not // perfect, but it does catch the case where the server accepts and ignores // a connection. c . SetDeadline ( time . Now ( ) . Add ( * requestTimeout ) ) return timeoutConn { c } , nil", "del_tokens": "return net . DialTimeout ( network , addr , * dialTimeout )", "commit_type": "improve"}
{"commit_tokens": ["Add", "torrent", ".", "File", "documentation", "."], "add_tokens": "// SingleFile represents the specific data of the single file torrent file. That // includes length of the file and its recommended name. // MultiFile represents the specific data of the multiple files torrent // file. That includes Name of the directory which will contain all the files // and the files information. // Information of a single file in multiple files torrent file. // File is the type you should use when reading torrent files. See Load and // LoadFromFile functions. All the fields are intended to be read-only. The // \"Info\" field has SingleFile or MultiFile type, use the type switch or type // assertion to determine the exact type. // Load a File from an io.Reader. Returns a non-nil error in case of failure. // Convenience function for loading a torrent.File from a file.", "del_tokens": "// the type is SingleFile or MultiFile", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "actual", "invalid", "routeExpr", "and", "FailoverPredicate", "to", "log", "messages"], "add_tokens": "return nil , fmt . Errorf ( \" \" , routeExpr ) return nil , fmt . Errorf ( \" \" , settings . FailoverPredicate )", "del_tokens": "return nil , fmt . Errorf ( \" \" ) return nil , fmt . Errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "Usage", "ticker", "to", "net", ":", "collects", "usage", ":", "number", "of", "bytes", "received", "/", "transmitted", "since", "prior", "snapshot"], "add_tokens": "// Some hoops to jump through to ensure we don't get a ErrBufferFull.", "del_tokens": "// Some hopes to jump through to ensure we don't get a ErrBufferFull.", "commit_type": "add"}
{"commit_tokens": ["add", "get", "pixel", "color", "return", "hex"], "add_tokens": "version string = \" \" // GetPxColor get pixel color return C.MMRGBHex func GetPxColor ( x , y int ) C . MMRGBHex { cx := C . size_t ( x ) cy := C . size_t ( y ) color := C . get_Pixel_Color ( cx , cy ) return color } // GetPixelColor get pixel color return string", "del_tokens": "version string = \" \" // GetPixelColor get pixel color", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectEq ( \" \" , sysReq . Method )", "del_tokens": "ExpectEq ( \" \" , sysReq . Method )", "commit_type": "fix"}
{"commit_tokens": ["Add", "type", "checking", "component", "of", "the", "checker"], "add_tokens": "// log.Printf(\"%03d: %s\\n\", e.pointer, formatInstruction(current))", "del_tokens": "log . Printf ( \" \\n \" , e . pointer , formatInstruction ( current ) )", "commit_type": "add"}
{"commit_tokens": ["Adding", "tests", "for", "statsite", "sink"], "add_tokens": "var wait <- chan time . Time goto QUIT wait = time . After ( time . Duration ( 5 ) * time . Second ) // Dequeue the messages to avoid backlog case _ , ok := <- s . metricQueue : if ! ok { goto QUIT } QUIT : s . metricQueue = nil", "del_tokens": "s . metricQueue = nil return wait := time . After ( time . Duration ( 5 ) * time . Second ) case <- s . metricQueue : // Dequeue the messages to avoid backlog", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "callerinfo", "is", "always", "accurate"], "add_tokens": "// callerinfo returns a string containing the file and line number of the test call // that failed. func callerinfo ( ) ( string , int , bool ) { file := \" \" line := 0 ok := false for i := 0 ; ; i ++ { _ , file , line , ok = runtime . Caller ( i ) if ! ok { return \" \" , 0 , false } parts := strings . Split ( file , \" \" ) dir := parts [ len ( parts ) - 2 ] file = parts [ len ( parts ) - 1 ] if dir != \" \" || file == \" \" { break } } return file , line , ok } file , line , ok := callerinfo ( ) // decorate + log + public function.", "del_tokens": "_ , file , line , ok := runtime . Caller ( 4 ) // decorate + log + public function.", "commit_type": "make"}
{"commit_tokens": ["add", "Utilization", ".", "SerializeFlatBuilder", "and", "refacotr", "SerializeFlat", "so", "the", "builder", "can", "be", "re", "-", "used"], "add_tokens": "/// SerializeFlat serializes Utilization into Flatbuffer serialized bytes. return u . SerializeFlatBuilder ( bldr ) } // SerializeFlatBuilder serializes Utilization into Flatbuffer serialized // bytes using the received builder. It is assumed that the passed builder // is in a usable state. func ( u * Utilization ) SerializeFlatBuilder ( bldr * fb . Builder ) [ ] byte {", "del_tokens": "// SerializeFlat serializes Utilization into Flatbuffer serialized bytes.", "commit_type": "add"}
{"commit_tokens": ["add", "SetLevelOutput", "-", "customize", "writer", "per", "level"], "add_tokens": "0.1 . 3 const Version = \" \"", "del_tokens": "0.1 . 2 const Version = \" \"", "commit_type": "add"}
{"commit_tokens": ["Adding", "file", "encoding", "option", "for", "GetKey"], "add_tokens": "\" \" // \"$NAME||<default>||<encoding>\". Then the value will be read from from the system // will be returned instead. If the third, optional parameter is // decoded using the appropriate method. // // Current supported <encoding> parameters: // // base64 -- value should be base64 decoded // file -- value should be read from disk if len ( m ) == 3 { switch m [ 2 ] { case \" \" : if buf , err := base64 . StdEncoding . DecodeString ( val ) ; err == nil { val = string ( buf ) } case \" \" : if buf , err := ioutil . ReadFile ( val ) ; err == nil { val = string ( buf ) }", "del_tokens": "// \"$NAME||<default>||base64\". Then the value will be read from from the system // will be returned instead. If the third, optional parameter base64 is // base64 decoded before being returned. if len ( m ) == 3 && m [ 2 ] == \" \" { if buf , err := base64 . StdEncoding . DecodeString ( val ) ; err == nil { val = string ( buf )", "commit_type": "add"}
{"commit_tokens": ["allow", "FSMs", "to", "process", "marker", "events", "that", "are", "not", "the", "FSM", "managed", "state", "markers"], "add_tokens": "Name string Domain string TaskList string Identity string DecisionWorker * DecisionWorker states map [ string ] * FSMState initialState * FSMState Input chan * PollForDecisionTaskResponse DataType interface { } EventDataType EventDataType stop chan bool switch event . EventType { case EventTypeDecisionTaskCompleted , EventTypeDecisionTaskScheduled , EventTypeDecisionTaskStarted , EventTypeDecisionTaskTimedOut : //no-op case EventTypeMarkerRecorded : if ! f . isStateMarker ( event ) { lastEvents = append ( lastEvents , event ) } default :", "del_tokens": "Name string Domain string TaskList string Identity string DecisionWorker * DecisionWorker states map [ string ] * FSMState initialState * FSMState Input chan * PollForDecisionTaskResponse DataType interface { } EventDataType EventDataType stop chan bool t := event . EventType if t != EventTypeMarkerRecorded && t != EventTypeDecisionTaskScheduled && t != EventTypeDecisionTaskCompleted && t != EventTypeDecisionTaskStarted && t != EventTypeDecisionTaskTimedOut {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "bug", "which", "cursor", "forward", "and", "backward"], "add_tokens": "func ( r * Render ) prepareArea ( lines int ) { r . prepareArea ( l )", "del_tokens": "func ( r * Render ) PrepareArea ( lines int ) { r . PrepareArea ( l )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "duplicate", "fmt", ".", "Sprintf", "in", "app", "/", "app", ".", "go"], "add_tokens": "logs . Log . Error ( \" \" , err ) logs . Log . Error ( \" \" , err )", "del_tokens": "\" \" logs . Log . Error ( fmt . Sprintf ( \" \" , err ) ) logs . Log . Error ( fmt . Sprintf ( \" \" , err ) )", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "returned", "values", "for", "SetAttr", ".", "Added", "the", "default_permissions", "mount"], "add_tokens": "attr , err := f . rpc . api . SetAttr ( rctx , a ) recvAttr ( attr , & resp . Attr )", "del_tokens": "_ , err := f . rpc . api . SetAttr ( rctx , a )", "commit_type": "fix"}
{"commit_tokens": ["added", "name", "to", "core", "/", "service"], "add_tokens": "name string log . Println ( spew . Sdump ( \" \" ) service . name = \" \" f , err := os . OpenFile ( fmt . Sprintf ( \" \" , base_path , self . name , self . Id ) , os . O_RDWR | os . O_CREATE | os . O_APPEND , 0666 ) log . Println ( \" \" , err )", "del_tokens": "spew . Dump ( \" \" ) f , err := os . OpenFile ( fmt . Sprintf ( \" \" , base_path , self . Id ) , os . O_RDWR | os . O_CREATE | os . O_APPEND , 0666 ) log . Error ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "Block", "subscriber", "instead", "of", "relying", "on", "sleep"], "add_tokens": "s2BlockedCh := make ( chan bool ) // Block this subscriber <- s2BlockedCh close ( s2BlockedCh )", "del_tokens": "// Slow down this subscriber time . Sleep ( 500 * time . Millisecond )", "commit_type": "fix"}
{"commit_tokens": ["Added", "testing", "for", "persistance", "of", "models"], "add_tokens": "if _ , ok := b . Words [ word ] ; ! ok { return fmt . Sprintf ( \" \\t Cl \\t Do \\t Wo \", l n(b . C o unt), i t(b . D o cumentCount), i t(b . D i ctCount))", "del_tokens": "if _ , ok := b . Words [ word ] ; len ( word ) < 3 || ! ok { return fmt . Sprintf ( \" \\t Cl \\t Wo \", l n(b . C o unt), i t(b . D o cumentCount))", "commit_type": "add"}
{"commit_tokens": ["Add", "closing", "handshake", "code", "to", "echo", "example", "client"], "add_tokens": "\" \" \" \" interrupt := make ( chan os . Signal , 1 ) signal . Notify ( interrupt , os . Interrupt ) done := make ( chan struct { } ) defer close ( done ) return for { select { case t := <- ticker . C : err := c . WriteMessage ( websocket . TextMessage , [ ] byte ( t . String ( ) ) ) if err != nil { log . Println ( \" \" , err ) return } case <- interrupt : log . Println ( \" \" ) // To cleanly close a connection, a client should send a close // frame and wait for the server to close the connection. err := c . WriteMessage ( websocket . CloseMessage , websocket . FormatCloseMessage ( websocket . CloseNormalClosure , \" \" ) ) if err != nil { log . Println ( \" \" , err ) return } select { case <- done : case <- time . After ( time . Second ) : } c . Close ( ) return", "del_tokens": "break for t := range ticker . C { err := c . WriteMessage ( websocket . TextMessage , [ ] byte ( t . String ( ) ) ) if err != nil { log . Println ( \" \" , err ) break", "commit_type": "add"}
{"commit_tokens": ["Remove", "memory", "allocation", "from", "func", "unquote"], "add_tokens": "// bufLength is the length of the buffer used for unquoting messages that // have one or more escape characters (\\) in them. If a message reuires more // space than this, additional memory will need to be allocated. bufLength = 256 // typicalKeywordCount is the number of keywords that can be in a // message before it becomes necessary to allocate additional memory. // The value is set to a number higher than expected in a typical // log message. typicalKeywordCount = 8 List : make ( [ ] [ ] byte , 0 , 2 * typicalKeywordCount ) ,", "del_tokens": "bufLength = 80 List : make ( [ ] [ ] byte , 0 , 16 ) ,", "commit_type": "remove"}
{"commit_tokens": ["Fix", "command", "line", "tool", "update", "Makefile"], "add_tokens": "finder := besticon . IconFinder { } icons , err := finder . FetchIcons ( url )", "del_tokens": "icons , err := besticon . FetchIcons ( url )", "commit_type": "fix"}
{"commit_tokens": ["Removing", "codes", "...", "from", "Send", "()"], "add_tokens": "func ( c Client ) Send ( req * http . Request ) ( * http . Response , error ) { resp , err := SendWithSender ( c , req )", "del_tokens": "func ( c Client ) Send ( req * http . Request , codes ... int ) ( * http . Response , error ) { if len ( codes ) == 0 { codes = [ ] int { http . StatusOK } } resp , err := SendWithSender ( c , req , DoErrorUnlessStatusCode ( codes ... ) )", "commit_type": "remove"}
{"commit_tokens": ["Use", "ioutil", ".", "Discard", "for", "benchmark"], "add_tokens": "\" \" backend := SetBackend ( NewLogBackend ( ioutil . Discard , \" \" , 0 ) ) backend := SetBackend ( NewLogBackend ( ioutil . Discard , \" \" , 0 ) ) colorizer := NewLogBackend ( ioutil . Discard , \" \" , 0 ) backend := SetBackend ( NewLogBackend ( ioutil . Discard , \" \" , log . LstdFlags ) ) backend := SetBackend ( NewLogBackend ( ioutil . Discard , \" \" , log . Llongfile ) )", "del_tokens": "backend := SetBackend ( NewLogBackend ( & bytes . Buffer { } , \" \" , 0 ) ) backend := SetBackend ( NewLogBackend ( & bytes . Buffer { } , \" \" , 0 ) ) colorizer := NewLogBackend ( & bytes . Buffer { } , \" \" , 0 ) backend := SetBackend ( NewLogBackend ( & bytes . Buffer { } , \" \" , log . LstdFlags ) ) backend := SetBackend ( NewLogBackend ( & bytes . Buffer { } , \" \" , log . Llongfile ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "default", "value", "for", "qor", "job", "status"], "add_tokens": "Status string `sql:\"default:'new'\"`", "del_tokens": "Status string", "commit_type": "add"}
{"commit_tokens": ["Create", "widget", "setting", "if", "failed", "to", "find"], "add_tokens": "db . Create ( setting )", "del_tokens": "db . Save ( setting )", "commit_type": "create"}
{"commit_tokens": ["add", "inspect", "info", "to", "container"], "add_tokens": "\" \" info , err := container . Inspect ( ) if err != nil { return nil , err } bytes , err := yaml . Marshal ( info ) if err != nil { return nil , err } return toRPCContainer ( container , string ( bytes ) ) , nil info , err := c . Inspect ( ) if err != nil { continue } bytes , err := yaml . Marshal ( info ) if err != nil { continue } cs = append ( cs , toRPCContainer ( c , string ( bytes ) ) )", "del_tokens": "return toRPCContainer ( container ) , nil cs = append ( cs , toRPCContainer ( c ) )", "commit_type": "add"}
{"commit_tokens": ["Changed", "wait", "timeout", "for", "build"], "add_tokens": "\" \" session . Wait ( 10 * time . Second )", "del_tokens": "session . Wait ( )", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "var", "scope", "to", "included", "playbooks"], "add_tokens": "playbook , err := LoadPlaybook ( args [ 1 ] , ns , env )", "del_tokens": "playbook , err := LoadPlaybook ( args [ 1 ] , env )", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "checking", "for", "writes", "."], "add_tokens": "if _ , err := h . Write ( s2vZero ) ; err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) } if _ , err := h . Write ( strings [ i ] ) ; err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) } if _ , err := h . Write ( t ) ; err != nil { panic ( fmt . Sprintf ( \" \" , err ) ) }", "del_tokens": "h . Write ( s2vZero ) h . Write ( strings [ i ] ) h . Write ( t )", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "basic", "actions", "+", "tests", ".", "Region", ".", "Clip", "."], "add_tokens": "data string", "del_tokens": "data [ ] rune", "commit_type": "add"}
{"commit_tokens": ["Fix", "packr", ".", "Box", "when", "used", "as", "http", ".", "Filesystem"], "add_tokens": "// The Handler created by http.FileSystem checks for those errors and // returns http.StatusNotFound instead of http.StatusInternalServerError. return nil , os . ErrNotExist return nil , os . ErrNotExist", "del_tokens": "return nil , errors . Errorf ( \" \" , cleanName ) return nil , errors . Errorf ( \" \" , cleanName , b . Path )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "syntax", "error", "in", "generated", "code", "."], "add_tokens": "err = client . SOAPClient . PerformAction ( { { $ srv . URNParts . Const } } , \" \" , & request , & response )", "del_tokens": "err = client . SOAPClient . PerformAction ( { { $ srv . URNParts . Const } } , { { . Name } } , & request , & response )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "test", "for", "Unmarshaler", "on", "a", "pointer", "value"], "add_tokens": "var conf2 struct { LogMode * logMode } err = envconfig . Init ( & conf2 ) require . Nil ( t , err ) require . Equal ( t , logFile , * conf2 . LogMode )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "UnmarshalPrimitive", "for", "unmarshal", "bytes", "to", "primitive", "type"], "add_tokens": "\" \" tc . bg = Colors [ strings . ToLower ( bg ) ]", "del_tokens": "tc . bg = Colors [ bg ]", "commit_type": "add"}
{"commit_tokens": ["Add", "Iterator", "for", "iterating", "over", "a", "cdb", "instance"], "add_tokens": "{ [ ] byte ( \" \" ) , [ ] byte ( \" \" ) } ,", "del_tokens": "{ [ ] byte ( \" \" ) , [ ] byte ( \" \" ) } ,", "commit_type": "add"}
{"commit_tokens": ["Implement", "commitSleep", "is", "asm", "."], "add_tokens": "gopark ( commitSleep , & s . waitingG , \" \" , traceEvGoBlockSelect , 0 ) // commitSleep signals to wakers that the given g is now sleeping. Wakers can // then fetch it and wake it. // // The commit may fail if wakers have been asserted after our last check, in // which case they will have set s.waitingG to zero. // // It is written in assembly, so it can be called without a race context. func commitSleep ( g uintptr , waitingG * uintptr ) bool func gopark ( unlockf func ( uintptr , * uintptr ) bool , wg * uintptr , reason string , traceEv byte , traceskip int )", "del_tokens": "// commitSleep signals to wakers that the given g is now sleeping. Wakers can // then fetch it and wake it. // // The commit may fail if wakers have been asserted after our last check, in // which case they will have set s.waitingG to zero. func commitSleep ( g uintptr , s * Sleeper ) bool { for { // Check if the wait was aborted. if atomic . LoadUintptr ( & s . waitingG ) == 0 { return false } // Try to store the G so that wakers know who to wake. if atomic . CompareAndSwapUintptr ( & s . waitingG , preparingG , g ) { return true } } } gopark ( commitSleep , s , \" \" , traceEvGoBlockSelect , 0 ) func gopark ( unlockf func ( uintptr , * Sleeper ) bool , s * Sleeper , reason string , traceEv byte , traceskip int )", "commit_type": "implement"}
{"commit_tokens": ["Added", "badges", "fixed", "golint", "recomendations"], "add_tokens": "// NewAvgRateCounter constructs a new AvgRateCounter, for the interval provided func ( a * AvgRateCounter ) WithResolution ( resolution int ) * AvgRateCounter { a . hits = a . hits . WithResolution ( resolution ) a . counter = a . counter . WithResolution ( resolution ) return a // Hits returns the number of calling method Incr during specified interval // String returns counter's rate formatted to string", "del_tokens": "// NewRateCounter Constructs a new AvgRateCounter, for the interval provided func ( r * AvgRateCounter ) WithResolution ( resolution int ) * AvgRateCounter { r . hits = r . hits . WithResolution ( resolution ) r . counter = r . counter . WithResolution ( resolution ) return r", "commit_type": "add"}
{"commit_tokens": ["Fix", "range", "extension", "logic", "for", "SetRange"], "add_tokens": "v . min = & position { pos : end , val : v . Zero } v . t . Insert ( v . min )", "del_tokens": "v . t . Insert ( & position { pos : end , val : v . Zero } )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unnecessary", "creds", "list", "s", "size", "check"], "add_tokens": "for k , v := range old_auths { if strings . Compare ( k , creds . ServerURL ) == 0 && strings . Compare ( v , creds . Username ) == 0 { if err := helper . Delete ( creds . ServerURL ) ; err != nil { t . Fatal ( err )", "del_tokens": "if len ( old_auths ) >= 1 { for k , v := range old_auths { if strings . Compare ( k , creds . ServerURL ) == 0 && strings . Compare ( v , creds . Username ) == 0 { if err := helper . Delete ( creds . ServerURL ) ; err != nil { t . Fatal ( err ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "GetBinaryStatus", "and", "GetAttributes", "support"], "add_tokens": "\" \" \" \" // ErrUnsupportedAction is returned when you try to perform an action on a piece of hardware // that doesn't support it, e.g. calling FetchAttributes on a non Maker device var ErrUnsupportedAction = errors . New ( \" \" )", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "absolute", "time", "support", "."], "add_tokens": "switch lit := lit . ( type ) { case * TimeLiteral : case * DurationLiteral : return time . Unix ( 0 , int64 ( lit . Val ) ) . UTC ( )", "del_tokens": "if lit , ok := lit . ( * TimeLiteral ) ; ok {", "commit_type": "add"}
{"commit_tokens": ["changed", "ES", "index", "and", "types", "names"], "add_tokens": "const esIndex = \" \" const esinfoType = \" \"", "del_tokens": "const esIndex = \" \" const esinfoType = \" \"", "commit_type": "change"}
{"commit_tokens": ["added", "a", "new", "NewTransaction", "function"], "add_tokens": "TX * tX cn , err := c . NewTransaction ( ) if err != nil { return err } err = fn ( cn ) if err != nil { err = cn . TX . Rollback ( ) } else { err = cn . TX . Commit ( ) } return err } func ( c * Connection ) NewTransaction ( ) ( * Connection , error ) { if c . TX == nil { return cn , err TX : tx , return cn , nil if c . TX == nil { TX : tx , return cn . TX . Rollback ( )", "del_tokens": "tX * tX if c . tX == nil { return err tX : tx , err := fn ( cn ) if err != nil { err = cn . tX . Rollback ( ) } else { err = cn . tX . Commit ( ) } return err if c . tX == nil { tX : tx , return cn . tX . Rollback ( )", "commit_type": "add"}
{"commit_tokens": ["Update", "ksonnet", "binary", "in", "image", "to", "ks", "tip", ".", "Begin", "using", "ksonnet", "as", "library", "instead", "of", "parsing", "stdout"], "add_tokens": "\" \" mod , err := component . DefaultManager . Module ( k . app , \" \" ) if err != nil { return nil , err } ksParams , err := mod . Params ( environment ) for _ , ksParam := range ksParams { value , err := strconv . Unquote ( ksParam . Value ) value = ksParam . Value Component : ksParam . Component , Name : ksParam . Key ,", "del_tokens": "lineSeparator = regexp . MustCompile ( `\\n` ) // count of rows to skip in command-line output const skipRows = 2 out , err := k . ksCmd ( \" \" , \" \" , \" \" , environment ) rows := lineSeparator . Split ( out , - 1 ) for _ , row := range rows [ skipRows : ] { if strings . TrimSpace ( row ) == \" \" { continue } fields := strings . Fields ( row ) component , param , rawValue := fields [ 0 ] , fields [ 1 ] , fields [ 2 ] value , err := strconv . Unquote ( rawValue ) value = rawValue Component : component , Name : param ,", "commit_type": "update"}
{"commit_tokens": ["add", "crypto", "/", "RSA", "signatures", "+", "client", "validation"], "add_tokens": "Verifier Verifier verifier Verifier func ( c * Client ) json ( resp * http . Response , err error , verify bool , v interface { } ) error { if verify { // verify the remote signature if err := c . verifier . Verify ( raw , resp . Header . Get ( \" \" ) ) ; err != nil { return fmt . Errorf ( \" \" ) } } return reqResp , c . json ( resp , err , true , reqResp ) return statResp , c . json ( resp , err , true , statResp ) return cancelResp , c . json ( resp , err , true , cancelResp ) return discResp , c . json ( resp , err , false , discResp ) verifier : opts . Verifier ,", "del_tokens": "func ( c * Client ) json ( resp * http . Response , err error , v interface { } ) error { return reqResp , c . json ( resp , err , reqResp ) return statResp , c . json ( resp , err , statResp ) return cancelResp , c . json ( resp , err , cancelResp ) return discResp , c . json ( resp , err , discResp )", "commit_type": "add"}
{"commit_tokens": ["Fix", "media", "type", "on", "unpacking", "layer"], "add_tokens": "if d . MediaType != string ( schema . MediaTypeImageLayer ) {", "del_tokens": "if d . MediaType != string ( schema . MediaTypeImageConfig ) {", "commit_type": "fix"}
{"commit_tokens": ["implement", "a", "favorite", "pseudo", "feed"], "add_tokens": "case \" \" : } else if action == \" \" { if newerFirst { articles , err = db . GetUserFavoriteArticlesDesc ( user , limit , offset ) } else { articles , err = db . GetUserFavoriteArticles ( user , limit , offset ) } if err != nil { break }", "del_tokens": "case \" \" :", "commit_type": "implement"}
{"commit_tokens": ["Add", "copy", "chown", "handling", "to", "dispatchers"], "add_tokens": "// If set, the owner:group for the destination. This value is passed // to the executor for handling. Chown string log . Printf ( \" \" , c . Src , c . Dest , c . From , c . Download , c . Chown )", "del_tokens": "log . Printf ( \" \" , c . Src , c . Dest , c . From , c . Download )", "commit_type": "add"}
{"commit_tokens": ["Added", "changelog", "for", "the", "release", "and", "bumped", "the", "dev", "version"], "add_tokens": "const Version = 1.1", "del_tokens": "const Version = 1.0", "commit_type": "add"}
{"commit_tokens": ["add", "travis", "ci", "config", "file"], "add_tokens": "assert . EqualValues ( 2 , TestEnumB )", "del_tokens": "assert . Equal ( 2 , TestEnumB )", "commit_type": "add"}
{"commit_tokens": ["fix", "Net", ".", "WalkPrefix", "API", "to", "avoid", "unnecessary", "repetition"], "add_tokens": "return false", "del_tokens": "return true", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "up", "the", "included", "headers", "and", "ordering", "so", "that", "erchef", "won", "t", "freak", "out", "."], "add_tokens": "\" \" ,", "del_tokens": "\" \" , \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Implement", "cookie", "auto", "-", "refresh"], "add_tokens": "func validateCookie ( cookie * http . Cookie , seed string ) ( string , time . Time , bool ) { return \" \" , time . Unix ( 0 , 0 ) , false return string ( rawValue ) , time . Unix ( int64 ( ts ) , 0 ) , true return \" \" , time . Unix ( 0 , 0 ) , false", "del_tokens": "func validateCookie ( cookie * http . Cookie , seed string ) ( string , bool ) { return \" \" , false return string ( rawValue ) , true return \" \" , false", "commit_type": "implement"}
{"commit_tokens": ["Make", "splitAndTrim", "parse", "more", "inteligently", "..."], "add_tokens": "// inArray checks if a byte is contained in an array of bytes func inArray ( s byte , list [ ] byte ) bool { for _ , el := range list { if el == s { return true } } return false } // splitAndTrim splits a range string by spaces and cleans whitespaces var lastChar byte excludeFromSplit := [ ] byte { '>' , '<' , '=' } if s [ i ] == ' ' && ! inArray ( lastChar , excludeFromSplit ) { } else if s [ i ] != ' ' { lastChar = s [ i ] for i , v := range result { result [ i ] = strings . Replace ( v , \" \" , \" \" , - 1 ) }", "del_tokens": "// splitAndTrim splits a range string by spaces and cleans leading and trailing spaces if s [ i ] == ' ' {", "commit_type": "make"}
{"commit_tokens": ["Use", "context", "instead", "of", "golang", ".", "org", "/", "x", "/", "net", "/", "context"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Fixed", "timezone", "in", "PackageFile", ".", "Files", "example"], "add_tokens": "// Lists all the files in a RPM package. fi . ModTime ( ) . UTC ( ) . Format ( \" \" ) , // -rw-r--r-- root root 1662 Nov 25 16:23 /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 // -rw-r--r-- root root 1056 Nov 25 16:23 /etc/yum.repos.d/epel-testing.repo // -rw-r--r-- root root 957 Nov 25 16:23 /etc/yum.repos.d/epel.repo // -rw-r--r-- root root 41 Nov 25 16:23 /usr/lib/rpm/macros.d/macros.epel // -rw-r--r-- root root 2813 Nov 25 16:23 /usr/lib/systemd/system-preset/90-epel.preset // -rwxr-xr-x root root 4096 Nov 25 16:26 /usr/share/doc/epel-release-7 // -rw-r--r-- root root 18385 Nov 25 16:23 /usr/share/doc/epel-release-7/GPL", "del_tokens": "// ExamplePackageFile_Files lists all the files in a RPM package. fi . ModTime ( ) . Format ( \" \" ) , // -rw-r--r-- root root 1662 Nov 26 00:23 /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 // -rw-r--r-- root root 1056 Nov 26 00:23 /etc/yum.repos.d/epel-testing.repo // -rw-r--r-- root root 957 Nov 26 00:23 /etc/yum.repos.d/epel.repo // -rw-r--r-- root root 41 Nov 26 00:23 /usr/lib/rpm/macros.d/macros.epel // -rw-r--r-- root root 2813 Nov 26 00:23 /usr/lib/systemd/system-preset/90-epel.preset // -rwxr-xr-x root root 4096 Nov 26 00:26 /usr/share/doc/epel-release-7 // -rw-r--r-- root root 18385 Nov 26 00:23 /usr/share/doc/epel-release-7/GPL", "commit_type": "fix"}
{"commit_tokens": ["Make", "redaction", "value", "patterns", "configurable"], "add_tokens": "valuePatterns = DefaultValuePatterns ( ) func DefaultValuePatterns ( ) [ ] string { return [ ] string { awsAccessKeyIDPattern , awsSecretAccessKeyPattern , cryptMD5Pattern , cryptSHA256Pattern , cryptSHA512Pattern , privateKeyHeaderPattern } }", "del_tokens": "valuePatterns = [ ] string { awsAccessKeyIDPattern , awsSecretAccessKeyPattern , cryptMD5Pattern , cryptSHA256Pattern , cryptSHA512Pattern , privateKeyHeaderPattern }", "commit_type": "make"}
{"commit_tokens": ["Fix", "issue", "where", "you", "d", "get", "hanging", "connections", "passing", "a", "\\", "r", "into", "fileIds", "."], "add_tokens": "var fileRoute = regexp . MustCompile ( \" \\r \\n \\r \" )", "del_tokens": "var fileRoute = regexp . MustCompile ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "NewReader", "to", "public", "API", "."], "add_tokens": "// NewReader returns an io.Reader to the JPEG thumbnail embedded in the CR2 // image in r. This allows access to the raw bytes of the JPEG thumbnail // without the need to decompress it first. func NewReader ( r io . Reader ) ( io . Reader , error ) { return nil , err return io . NewSectionReader ( d . r , offset , n ) , nil } // Decode reads a CR2 image from r and returns the embedded JPEG thumbnail as // an image.Image. func Decode ( r io . Reader ) ( image . Image , error ) { r , err := NewReader ( r ) if err != nil { return jpeg . Decode ( r )", "del_tokens": "// Decode reads a TIFF image from r and returns it as an image.Image. // The type of Image returned depends on the contents of the TIFF. func Decode ( r io . Reader ) ( img image . Image , err error ) { return m , err2 := jpeg . Decode ( io . NewSectionReader ( d . r , offset , n ) ) if err2 != nil { return m , nil", "commit_type": "add"}
{"commit_tokens": ["add", "more", "headers", "routes", "and", "also", "allow", "POSTING", "to", "/", "files", "/", "<id", ">", "to", "add", "compatibility", "with", "jQuery", "File", "Upload"], "add_tokens": "var filesRoute = regexp . MustCompile ( \" \" ) w . Header ( ) . Add ( \" \" , \" \" ) w . Header ( ) . Add ( \" \" , \" \" ) if r . Method == \" \" { reply ( w , http . StatusOK , \" \" ) return } if r . Method == \" \" && filesRoute . Match ( [ ] byte ( r . URL . Path ) ) { case \" \" : putFile ( w , r , id )", "del_tokens": "if r . Method == \" \" && r . URL . Path == \" \" { } else if r . Method == \" \" && r . URL . Path == \" \" { reply ( w , http . StatusOK , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Updated", "docopt", "string", "to", "contain", "an", "example"], "add_tokens": "will match the parent directory name of the go file you generate . The go type names will be taken from the \" \" json subschema Title element . Example : cat urls . txt | jsonschema2go - o . . / . . / generatedcode . go", "del_tokens": "will match the parent directory name of the go file you generate .", "commit_type": "update"}
{"commit_tokens": ["Fix", "build", "on", "solarish", "platforms"], "add_tokens": "// +build linux darwin solaris", "del_tokens": "// +build linux darwin", "commit_type": "fix"}
{"commit_tokens": ["added", "qualifiers", "to", "determine", "type"], "add_tokens": "\" \" HasFullUrl bool HasUrlPathOnly bool HasFragmentOnly bool // fragment only if strings . HasPrefix ( jsonReferenceString , \" \" ) { r . referencePointer , err = gojsonpointer . NewJsonPointer ( jsonReferenceString ) if err != nil { return nil } r . HasFragmentOnly = true } else { r . referenceUrl , err = url . Parse ( jsonReferenceString ) if err != nil { return nil } if r . referenceUrl . Scheme != \" \" && r . referenceUrl . Host != \" \" { r . HasFullUrl = true } else { r . HasUrlPathOnly = true } if err != nil { return nil } return nil }", "del_tokens": "r . referenceUrl , err = url . Parse ( jsonReferenceString ) if err == nil { return err }", "commit_type": "add"}
{"commit_tokens": ["add", "comments", "on", "exposed", "func", "and", "type", "of", "peer", ".", "go"], "add_tokens": "// GLPeer represents gl context. // Singleton. // GetGLPeer returns a instance of GLPeer. // Since GLPeer is singleton, it is necessary to // call this function to get GLPeer instance. // Initialize initializes GLPeer. // This function must be called inadvance of using GLPeer func ( glpeer * GLPeer ) Initialize ( glctx gl . Context ) { glpeer . glctx = glctx glpeer . images = glutil . NewImages ( glctx ) // LoadTexture return texture that is loaded by the information of arguments. // Loaded texture can assign using AddSprite function. // Finalize finalizes GLPeer. // This is called at termination of application. // Update updates screen. // This is called 60 times per 1 sec. // Reset resets current gl context. // All sprites are also cleaned. // This is called at changing of scene, and // this function is for clean previous scene.", "del_tokens": "func ( glpeer * GLPeer ) Initialize ( in_glctx gl . Context ) { glpeer . glctx = in_glctx glpeer . images = glutil . NewImages ( in_glctx )", "commit_type": "add"}
{"commit_tokens": ["Updated", "message", "listener", "+", "callback"], "add_tokens": "type ListenerMessage func ( m * EventMessage ) ( v interface { } ) v := l ( i . Message ) type CallbackMessage func ( m * EventMessage ) c ( i . Message )", "del_tokens": "type ListenerMessage func ( e Event ) ( v interface { } ) v := l ( i ) type CallbackMessage func ( e Event ) c ( i )", "commit_type": "update"}
{"commit_tokens": ["Added", "README", "with", "basic", "details"], "add_tokens": "func TestRenderUsesTemplateValues ( t * testing . T ) {", "del_tokens": "func TestRendereUsesTemplateValues ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "out", "of", "date", "permission", "field"], "add_tokens": "mutex sync . RWMutex roles Roles parents map [ string ] map [ string ] struct { } roles : make ( Roles ) , parents : make ( map [ string ] map [ string ] struct { } ) ,", "del_tokens": "mutex sync . RWMutex roles Roles permissions Permissions parents map [ string ] map [ string ] struct { } roles : make ( Roles ) , permissions : make ( Permissions ) , parents : make ( map [ string ] map [ string ] struct { } ) ,", "commit_type": "remove"}
{"commit_tokens": ["Update", "uuid", "usage", "to", "conform", "to", "latest", "api"], "add_tokens": "idFull , err := uuid . NewV4 ( ) if err != nil { return err } err = c . flushWithId ( idFull . Bytes ( ) [ 0 : 8 ] )", "del_tokens": "idFull := uuid . NewV4 ( ) err := c . flushWithId ( idFull . Bytes ( ) [ 0 : 8 ] )", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "bug", "where", "Id", "wasn", "t", "being", "set", "properly"], "add_tokens": "// create a new struct and cast it to a ModelInterface model := modelVal . Interface ( ) . ( ModelInterface ) // invoke redis driver to fill in the values of the struct // set the id model . SetId ( id ) // return it", "del_tokens": "\" \" model := modelVal . Interface ( ) modelI , ok := model . ( ModelInterface ) if ! ok { return nil , errors . New ( \" \" ) } modelI . SetId ( id )", "commit_type": "fix"}
{"commit_tokens": ["Make", "machine", "name", "optional", "in", "CLI"], "add_tokens": "store := NewStore ( ) host , err := store . GetActive ( ) if err != nil { log . Errorf ( \" \" ) os . Exit ( 1 ) } name = host . Name store := NewStore ( ) host , err := store . GetActive ( ) if err != nil { log . Errorf ( \" \" ) os . Exit ( 1 ) } name = host . Name } store := NewStore ( ) host , err := store . GetActive ( ) if err != nil { log . Errorf ( \" \" ) os . Exit ( 1 ) } name = host . Name }", "del_tokens": "cli . ShowCommandHelp ( c , \" \" ) os . Exit ( 1 ) store := NewStore ( ) if name == \" \" { cli . ShowCommandHelp ( c , \" \" ) os . Exit ( 1 ) } cli . ShowCommandHelp ( c , \" \" ) os . Exit ( 1 ) } store := NewStore ( ) cli . ShowCommandHelp ( c , \" \" ) os . Exit ( 1 ) } store := NewStore ( )", "commit_type": "make"}
{"commit_tokens": ["Added", "default", "(", "builtin", ")", "font", "to", "immg", "."], "add_tokens": "g := New ( 400 , 200 , color . RGBA { 220 , 220 , 220 , 255 } , nil , 12 )", "del_tokens": "g := New ( 400 , 200 , color . RGBA { 220 , 220 , 220 , 255 } )", "commit_type": "add"}
{"commit_tokens": ["Add", "common", "/", "packet", "/", "connack", ".", "go"], "add_tokens": "\" \" // Reset the buffered writer. w . Reset ( cli . conn ) // Reset the buffered reader. r . Reset ( cli . conn ) // Get the first byte of the Packet. // Extract the MQTT Control Packet Type from the first byte. packetType := b >> 4 // Create the Fixed header. fixedHeader := [ ] byte { b } // Get and decode the Remaining Length. var mp uint32 = 1 // multiplier var rl uint32 // the Remaining Length for { b , err = r . ReadByte ( ) if err != nil { return err } fixedHeader = append ( fixedHeader , b ) rl += uint32 ( b & 127 ) * mp if b & 128 == 0 { break } mp *= 128 } // Create the Remaining (the Variable header and the Payload). remaining := make ( [ ] byte , rl ) if rl > 0 { if _ , err = io . ReadFull ( r , remaining ) ; err != nil { return err } } switch packetType { case packet . TypeCONNACK : p , err := packet . NewCONNACKFromBytes ( fixedHeader , remaining ) if err != nil { return err } fmt . Printf ( \" \" , p ) }", "del_tokens": "fmt . Println ( b )", "commit_type": "add"}
{"commit_tokens": ["Fix", "srcinfo", "failing", "to", "parse", "when", "starting", "with", "\\", "n"], "add_tokens": "buffer := l . input [ l . start : l . pos ] if buffer == \" \\n \" || buffer == \" \\n \\n \" {", "del_tokens": "if l . input [ l . start : l . pos ] == \" \\n \\n \" {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "parseDependency", "for", "version", "restricted", "deps"], "add_tokens": "if c == '<' || c == '>' || c == '=' { eq . WriteRune ( c ) continue break", "del_tokens": "i ++ if c != '<' || c != '>' || c != '=' { break eq . WriteRune ( c )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "wrapping", "for", "multi", "-", "line", "descriptions"], "add_tokens": "if runes [ i ] == '\\n' { } else if linelen == width { buf . WriteString ( \" \\n \" ) if i < len ( runes ) { buf . WriteString ( strings . Repeat ( \" \" , indent ) ) linelen = indent } buf . WriteRune ( runes [ i ] ) } else { buf . WriteRune ( runes [ i ] )", "del_tokens": "if linelen == width { buf . WriteRune ( runes [ i ] )", "commit_type": "fix"}
{"commit_tokens": ["add", "timeutil", ".", "TimeMeta", "update", "csvutil", ".", "Writer", ".", "AddLine", "()"], "add_tokens": "StripRepeatedSep bool StripRepeatedSep : false , stringsutil . JoinInterface ( cells , w . Separator , false , w . ReplaceSeparator , w . SeparatorAlt ) )", "del_tokens": "stringsutil . JoinInterface ( cells , w . Separator , w . ReplaceSeparator , w . SeparatorAlt ) )", "commit_type": "add"}
{"commit_tokens": ["Removed", "printw", "family", "+", "gofmt"], "add_tokens": "windowHeight = 20 windowWidth = 40 y , x := curses . Getmaxyx ( ) curses . Addstr ( \" \" ) window := curses . NewWindow ( windowHeight , windowWidth , ( y - windowHeight ) / 2 , ( x - windowWidth ) / 2 ) window . Box ( 0 , 0 ) window . Mvaddstr ( 0 , 1 , \" \" )", "del_tokens": "windowHeight = 20 windowWidth = 40 y , x := curses . Getmaxyx ( ) curses . Printw ( \" \" ) window := curses . NewWindow ( windowHeight , windowWidth , ( y - windowHeight ) / 2 , ( x - windowWidth ) / 2 ) window . Box ( 0 , 0 ) window . Mvprintw ( 0 , 1 , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Adds", "ability", "to", "check", "if", "token", "will", "expire", "before", "given", "time"], "add_tokens": "return token . ExpiresBefore ( time . Duration ( 0 ) ) } // Determines if the token expires by the current time plus the time buffer func ( token Token ) ExpiresBefore ( timeBuffer time . Duration ) ( bool , error ) { tokenExpiration := parsedJson [ \" \" ] . ( float64 ) bufferedExpiration := time . Unix ( int64 ( tokenExpiration ) , 0 ) . Add ( timeBuffer ) return bufferedExpiration . Before ( time . Now ( ) ) , nil", "del_tokens": "unixTime := parsedJson [ \" \" ] . ( float64 ) expirationTime := time . Unix ( int64 ( unixTime ) , 0 ) return expirationTime . Before ( time . Now ( ) ) , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "functio", "not", "returning", "value"], "add_tokens": "return data [ 2 ]", "del_tokens": "} else { return data [ 2 ]", "commit_type": "fix"}
{"commit_tokens": ["add", "users", ".", "info", "method", "."], "add_tokens": "user , err := api . FindUser ( func ( user * slack . User ) bool {", "del_tokens": "user , err := api . FindUser ( func ( user * slack . Member ) bool {", "commit_type": "add"}
{"commit_tokens": ["fix", "command", "bug", ";", "add", "many", "examples"], "add_tokens": "\" \" func New ( root string , writer io . Writer ) * Cli { return NewWithCommand ( & Command { Name : root , writer : writer } ) } func NewWithCommand ( cmd * Command ) * Cli { app . root = cmd func ( app * Cli ) Root ( ) * Command { return app . root } flagSet . slice = append ( flagSet . slice , fl ) flagSet . Usage = flagSlice ( flagSet . slice ) . String ( ) for _ , fl := range flagSet . slice {", "del_tokens": "func New ( root string ) * Cli { app . root = & Command { Name : root } flags = [ ] * flag { } flags = append ( flags , fl ) flagSet . Usage = flagSlice ( flags ) . String ( ) for _ , fl := range flagSet . flags {", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "variable", "substitution", "for", "regular", "commands"], "add_tokens": "commander . Vars = map [ string ] string {", "del_tokens": "commander . FunctionContext = map [ string ] string {", "commit_type": "add"}
{"commit_tokens": ["Allow", "passing", "http", ".", "RoundTripper", "to", "Client"], "add_tokens": "return NewClientWithTransport ( directoryURL , nil ) } // NewClientWithTransport creates a client of a ACME server by querying the server's // resource directory and attempting to resolve the URL of the terms of service. func NewClientWithTransport ( directoryURL string , t http . RoundTripper ) ( * Client , error ) { nrt := newNonceRoundTripper ( t )", "del_tokens": "// TODO: make underlying transport configurable nrt := newNonceRoundTripper ( nil )", "commit_type": "allow"}
{"commit_tokens": ["Add", "behavior", "validation", "for", "TestManualCancelation"], "add_tokens": "defer func ( ) { if r := recover ( ) ; r != nil { t . Errorf ( \" \" , r ) } } ( ) wg . Done ( ) wg . Wait ( )", "del_tokens": "wg . Done ( ) // should arrive here with no panic", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "setting", "the", "basic", "auth", "password", "."], "add_tokens": "BasicAuthPassword string ProxyPrefix : opts . ProxyPrefix , provider : opts . provider , serveMux : serveMux , redirectUrl : redirectUrl , skipAuthRegex : opts . SkipAuthRegex , compiledRegex : opts . CompiledRegex , PassBasicAuth : opts . PassBasicAuth , BasicAuthPassword : opts . BasicAuthPassword , PassAccessToken : opts . PassAccessToken , CookieCipher : cipher , templates : loadTemplates ( opts . CustomTemplatesDir ) , req . SetBasicAuth ( session . User , p . BasicAuthPassword )", "del_tokens": "ProxyPrefix : opts . ProxyPrefix , provider : opts . provider , serveMux : serveMux , redirectUrl : redirectUrl , skipAuthRegex : opts . SkipAuthRegex , compiledRegex : opts . CompiledRegex , PassBasicAuth : opts . PassBasicAuth , PassAccessToken : opts . PassAccessToken , CookieCipher : cipher , templates : loadTemplates ( opts . CustomTemplatesDir ) , req . SetBasicAuth ( session . User , \" \" )", "commit_type": "add"}
{"commit_tokens": ["fixed", "parsing", "of", "the", "raspberry", "pi", "s", "kernel", "version"], "add_tokens": "func parseVersion ( str string ) ( major , minor , patch int , err error ) { parts := strings . Split ( str , \" \" ) len := len ( parts ) return 0 , 0 , 0 , err return 0 , 0 , 0 , err if len > 2 { part := parts [ 2 ] part = strings . TrimSuffix ( part , \" \" ) if patch , err = strconv . Atoi ( part ) ; err != nil { return 0 , 0 , 0 , err } return major , minor , patch , err } func kernelVersion ( ) ( major , minor , patch int , err error ) { output , err := execOutput ( \" \" , \" \" ) if err != nil { return 0 , 0 , 0 , err } return parseVersion ( output )", "del_tokens": "func kernelVersion ( ) ( major , minor , patch int , err error ) { output , err := execOutput ( \" \" , \" \" ) if err != nil { return } parts := strings . Split ( output , \" \" ) return return if patch , err = strconv . Atoi ( parts [ 2 ] ) ; err != nil { return return", "commit_type": "fix"}
{"commit_tokens": ["Allow", "decoding", "of", "interface", "values"], "add_tokens": "dv = indirect ( dv , false ) dv = indirect ( dv , true ) dv = indirect ( dv , false ) dv = indirect ( dv , false ) func indirect ( v reflect . Value , decodeNull bool ) reflect . Value { if e . Kind ( ) == reflect . Ptr && ! e . IsNil ( ) && ( ! decodeNull || e . Elem ( ) . Kind ( ) == reflect . Ptr ) {", "del_tokens": "dv = indirect ( dv ) dv = indirect ( dv ) dv = indirect ( dv ) dv = indirect ( dv ) func indirect ( v reflect . Value ) reflect . Value { if e . Kind ( ) == reflect . Ptr && ! e . IsNil ( ) && e . Elem ( ) . Kind ( ) == reflect . Ptr {", "commit_type": "allow"}
{"commit_tokens": ["Removed", "references", "to", "GetMultiCache", "."], "add_tokens": "err = nds . GetMulti ( cc , keys , respEntities ) err = nds . GetMulti ( cc , keys , respEntities ) err = nds . GetMulti ( cc , keys , respEntities )", "del_tokens": "err = nds . GetMultiCache ( cc , keys , respEntities ) err = nds . GetMultiCache ( cc , keys , respEntities ) err = nds . GetMultiCache ( cc , keys , respEntities )", "commit_type": "remove"}
{"commit_tokens": ["Added", "graceful", "expiry", "period", "to", "GetNotStaleNow", "()"], "add_tokens": "ExpireGracePeriod time . Duration // time after an expired entry is purged from cache (unless pushed out of LRU) // Remove entries expired for more than a graceful period if b . ExpireGracePeriod == 0 || e . expire . Sub ( now ) > b . ExpireGracePeriod { b . removeEntry ( e ) }", "del_tokens": "b . removeEntry ( e )", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "exceptions", "and", "conditions", "in", "the", "boxfile", "related", "to", "tcp", "/", "udp"], "add_tokens": "name != \" \" { if name == \" \" || name == \" \" {", "del_tokens": "key != \" \" && key != \" \" && name != \" \" && name != \" \" && name != \" \" { if name == \" \" || name == \" \" || name == \" \" || name == \" \" {", "commit_type": "remove"}
{"commit_tokens": ["Adds", "support", "for", "listing", "TCP", "monitors"], "add_tokens": "// Monitors returns a list of all HTTP, HTTPS, Gateway ICMP, ICMP, and TCP monitors. monitorUris := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" } // \"icmp\", \"gateway icmp\", or \"tcp\". // one of \"http\", \"https\", \"icmp\", \"gateway icmp\", or \"tcp\". Fields that", "del_tokens": "// Monitors returns a list of all HTTP, HTTPS, Gateway ICMP, and ICMP monitors. monitorUris := [ ] string { \" \" , \" \" , \" \" , \" \" } // \"icmp\", or \"gateway icmp\". // one of \"http\", \"https\", \"icmp\", or \"gateway icmp\". Fields that", "commit_type": "add"}
{"commit_tokens": ["Change", "graceful", "to", "opt", "-", "in", "to", "signal", "handling"], "add_tokens": "stdSignals = append ( stdSignals , syscall . SIGUSR2 )", "del_tokens": "\" \" log . Print ( \" \" ) AddSignal ( syscall . SIGUSR2 )", "commit_type": "change"}
{"commit_tokens": ["Allowing", "filter", "parsing", "delimiters", "to", "be", "overridden"], "add_tokens": "} else { `tokenizer` : single . Name ,", "del_tokens": "} else { `tokenizer` : single . Name ,", "commit_type": "allow"}
{"commit_tokens": ["Use", "tabwriter", "to", "indent", "map"], "add_tokens": "func ( p * printer ) println ( text string ) { p . print ( text + \" \\n \" ) } p . println ( \" \" ) key := keys [ i ] . Interface ( ) value := p . value . MapIndex ( keys [ i ] ) . Interface ( ) fmt . Fprintf ( p . tw , \" \\t \\t \\n \" , format ( key ) , format ( value ) ) p . tw . Flush ( ) p . println ( \" \" )", "del_tokens": "result := \" \\n \" key := keys [ i ] result += \" \" result += format ( key . Interface ( ) ) result += \" \" result += format ( p . value . MapIndex ( key ) . Interface ( ) ) result += \" \\n \" result += \" \" p . print ( result )", "commit_type": "use"}
{"commit_tokens": ["use", "named", "values", "for", "timeouts"], "add_tokens": "var ( NewStreamTimeout = time . Minute ResetStreamTimeout = time . Minute ) ctx , cancel := context . WithTimeout ( bgCtx , NewStreamTimeout ) ctx , cancel := context . WithTimeout ( bgCtx , ResetStreamTimeout )", "del_tokens": "ctx , cancel := context . WithTimeout ( bgCtx , time . Minute ) ctx , cancel := context . WithTimeout ( bgCtx , time . Minute )", "commit_type": "use"}
{"commit_tokens": ["Add", "interface", "for", "creating", "digests"], "add_tokens": "type ContextOptions struct { Digester Digester Driver Driver } driver Driver root string digester Digester return NewContextWithOptions ( root , ContextOptions { } ) } // NewContextWithOptions returns a Context associate with the root. func NewContextWithOptions ( root string , options ContextOptions ) ( Context , error ) { driver := options . Driver if driver == nil { driver , err = NewSystemDriver ( ) if err != nil { return nil , err } } digester := options . Digester if digester == nil { digester = simpleDigester { digest . Canonical } root : root , driver : driver , digester : digester , f , err := c . driver . Open ( filepath . Join ( c . root , p ) ) if err != nil { return \" \" , err } defer f . Close ( ) return c . digester . Digest ( f )", "del_tokens": "driver Driver root string driver , err := NewSystemDriver ( ) if err != nil { return nil , err root : root , driver : driver , return digestPath ( c . driver , filepath . Join ( c . root , p ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Cursor", ".", "HasMore", "()"], "add_tokens": "return c . resultIndex < len ( c . Result ) || c . cursorData . HasMore", "del_tokens": "return c . cursorData . HasMore", "commit_type": "fix"}
{"commit_tokens": ["Added", "check", "/", "ack", "validation", "for", "StatusUpdate", "message", "."], "add_tokens": "// Only send ack if udpate was not from master or driver if ! from . Equal ( driver . self ) && ! from . Equal ( driver . MasterUPID ) { ackMsg := & mesos . StatusUpdateAcknowledgementMessage { SlaveId : msg . Update . SlaveId , FrameworkId : driver . FrameworkInfo . Id , TaskId : msg . Update . Status . TaskId , Uuid : msg . Update . Uuid , } log . V ( 2 ) . Infoln ( \" \" , from . String ( ) ) if err := driver . messenger . Send ( driver . MasterUPID , ackMsg ) ; err != nil { log . Errorf ( \" \\n \" , err ) return }", "del_tokens": "ackMsg := & mesos . StatusUpdateAcknowledgementMessage { SlaveId : msg . Update . SlaveId , FrameworkId : driver . FrameworkInfo . Id , TaskId : msg . Update . Status . TaskId , Uuid : msg . Update . Uuid , } log . V ( 2 ) . Infoln ( \" \" , from . String ( ) ) if err := driver . messenger . Send ( driver . MasterUPID , ackMsg ) ; err != nil { log . Errorf ( \" \\n \" , err ) return", "commit_type": "add"}
{"commit_tokens": ["Fix", "doc", "comment", "for", "TrackCycles", "to", "remove", "a", "reference", "to", "an", "outdated", "field", "."], "add_tokens": "// Pointer tracking is disabled by default for performance reasons.", "del_tokens": "// Pointer tracking is disabled by default for performance reasons. If you // turn it on, however, be aware that the results of Compare are limited to // comparing only RecursiveContext, which may not be enough to perfectly // guarantee \"deep equality\" if the context does not contain enough signal.", "commit_type": "fix"}
{"commit_tokens": ["add", "in", "support", "for", "batched", "writes"], "add_tokens": "type flatfsBatch struct { func ( fs * Datastore ) Batch ( ) datastore . Batch { return & flatfsBatch { func ( bt * flatfsBatch ) Put ( key datastore . Key , val interface { } ) error { func ( bt * flatfsBatch ) Delete ( key datastore . Key ) error { func ( bt * flatfsBatch ) Commit ( ) error {", "del_tokens": "type flatfsTransaction struct { gets map [ datastore . Key ] datastore . GetCallback func ( fs * Datastore ) StartBatchOp ( ) datastore . Transaction { return & flatfsTransaction { gets : make ( map [ datastore . Key ] datastore . GetCallback ) , func ( bt * flatfsTransaction ) Put ( key datastore . Key , val interface { } ) error { func ( bt * flatfsTransaction ) Delete ( key datastore . Key ) error { func ( bt * flatfsTransaction ) Commit ( ) error { for k , cb := range bt . gets { cb ( bt . ds . Get ( k ) ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "available", "regions", "as", "field", "to", "plan", "struct"], "add_tokens": "for _ , r := range plan . Regions { if r == * id { break", "del_tokens": "ids , err := GetClient ( ) . GetAvailablePlansForRegion ( * id ) if err != nil { log . Fatal ( err ) } if len ( ids ) == 0 { fmt . Println ( ) return } for _ , id := range ids { if id == plan . ID {", "commit_type": "add"}
{"commit_tokens": ["Added", "integrationids", "to", "HttpCheck", "and", "PingCheck"], "add_tokens": "IntegrationIds [ ] int `json:\"integrationids,omitempty\"` IntegrationIds [ ] int `json:\"integrationids,omitempty\"` \" \" : ck . Url , \" \" : strconv . FormatBool ( ck . Encryption ) , \" \" : ck . PostData , \" \" : intListToCDString ( ck . ContactIds ) , \" \" : intListToCDString ( ck . IntegrationIds ) , \" \" : ck . Tags , \" \" : intListToCDString ( ck . IntegrationIds ) ,", "del_tokens": "\" \" : ck . Url , \" \" : strconv . FormatBool ( ck . Encryption ) , \" \" : ck . PostData , \" \" : intListToCDString ( ck . ContactIds ) , \" \" : ck . Tags ,", "commit_type": "add"}
{"commit_tokens": ["Add", "DBTxContext", "DBContextProvider", "abstractions", ".", "Expose", "a", "variant", "get", "schema", "version", "that", "panics", "on", "error", "."], "add_tokens": "// NamedExec executes a query that contains named query parameters, returning result metadata or an error. // NamedQuery executes a query that contains named parameters. Retuns rows returned by the database or an error. // PrepareNamed prepares a query with named parameters. Returns a prepared statement or an error.", "del_tokens": "// Execute a query that contains named query parameters, returning result metadata or an error. // Execute a query that contains named parameters. Retuns rows returned by the database or an error. // Prepares a query with named parameters. Returns a prepared statement or an error.", "commit_type": "add"}
{"commit_tokens": ["Fix", "log", "message", "for", "not", "found", "WIT"], "add_tokens": "log . Printf ( \" \" , ctx . Name )", "del_tokens": "log . Printf ( \" \" , ctx . Name )", "commit_type": "fix"}
{"commit_tokens": ["add", "check", "to", "reuse", "the", "current", "RWMutex", "if", "it", "already", "exists", "."], "add_tokens": "if c . m == nil { c . m = new ( sync . RWMutex ) }", "del_tokens": "c . m = new ( sync . RWMutex )", "commit_type": "add"}
{"commit_tokens": ["add", "flags", "to", "work", "with", "homebrew", "openssl", "by", "default"], "add_tokens": "// #cgo darwin CFLAGS: -Wno-deprecated-declarations -I/usr/local/opt/openssl/include // #cgo darwin LDFLAGS: -L/usr/local/opt/openssl/lib", "del_tokens": "// #cgo darwin CFLAGS: -Wno-deprecated-declarations", "commit_type": "add"}
{"commit_tokens": ["Fix", "delete", "media", "library", "files"], "add_tokens": "Delete bool `json:\",omitempty\"`", "del_tokens": "Delete bool `json:\"-\"`", "commit_type": "fix"}
{"commit_tokens": ["remove", "backup", "config", "from", "brokerconfig"], "add_tokens": "ServiceName string `yaml:\"service_name\"` ServiceID string `yaml:\"service_id\"` DedicatedVMPlanID string `yaml:\"dedicated_vm_plan_id\"` SharedVMPlanID string `yaml:\"shared_vm_plan_id\"` Host string `yaml:\"host\"` DefaultConfigPath string `yaml:\"redis_conf_path\"` ProcessCheckIntervalSeconds int `yaml:\"process_check_interval\"` StartRedisTimeoutSeconds int `yaml:\"start_redis_timeout\"` InstanceDataDirectory string `yaml:\"data_directory\"` InstanceLogDirectory string `yaml:\"log_directory\"` ServiceInstanceLimit int `yaml:\"service_instance_limit\"` Dedicated Dedicated `yaml:\"dedicated\"`", "del_tokens": "ServiceName string `yaml:\"service_name\"` ServiceID string `yaml:\"service_id\"` DedicatedVMPlanID string `yaml:\"dedicated_vm_plan_id\"` SharedVMPlanID string `yaml:\"shared_vm_plan_id\"` Host string `yaml:\"host\"` DefaultConfigPath string `yaml:\"redis_conf_path\"` ProcessCheckIntervalSeconds int `yaml:\"process_check_interval\"` StartRedisTimeoutSeconds int `yaml:\"start_redis_timeout\"` InstanceDataDirectory string `yaml:\"data_directory\"` InstanceLogDirectory string `yaml:\"log_directory\"` ServiceInstanceLimit int `yaml:\"service_instance_limit\"` BackupConfiguration BackupConfiguration `yaml:\"backup\"` Dedicated Dedicated `yaml:\"dedicated\"` } type BackupConfiguration struct { EndpointUrl string `yaml:\"endpoint_url\"` BucketName string `yaml:\"bucket_name\"` AccessKeyId string `yaml:\"access_key_id\"` SecretAccessKey string `yaml:\"secret_access_key\"` Path string `yaml:\"path\"` S3Region string `yaml:\"s3_region\"` BGSaveTimeoutSeconds int `yaml:\"bg_save_timeout\"` func ( backupConfiguration BackupConfiguration ) Enabled ( ) bool { return backupConfiguration . BucketName != \" \" && backupConfiguration . EndpointUrl != \" \" }", "commit_type": "remove"}
{"commit_tokens": ["adding", "a", "todo", "for", "FormatLocalized", "and", "HasRelativeKeywords"], "add_tokens": "/ * TODO", "del_tokens": "/ *", "commit_type": "add"}
{"commit_tokens": ["use", "append", "instead", "of", "for", "loop"], "add_tokens": "ids = append ( ids , IDList ... ) ids = append ( ids , IDList ... )", "del_tokens": "for _ , id := range IDList { ids = append ( ids , id ) } for _ , id := range IDList { ids = append ( ids , id ) }", "commit_type": "use"}
{"commit_tokens": ["Add", "comments", "to", "public", "members", "of", "member", "-", "duration", "(", "golint", ")"], "add_tokens": "// MemberDuration is used to track the periods of time which a user (member) is attached to a card. // ByLongestDuration is a slice of *MemberDuration // Len returns the length of the ByLongestDuration slice. func ( d ByLongestDuration ) Len ( ) int { return len ( d ) } // Less takes two indexes i and j and returns true exactly if the Duration // at i is larger than the Duration at j. // GetMemberDurations returns a slice containing all durations of a card.", "del_tokens": "// Used to track the periods of time which a user (member) is attached to a card. // func ( d ByLongestDuration ) Len ( ) int { return len ( d ) }", "commit_type": "add"}
{"commit_tokens": ["Adds", "membership", "functionality", "to", "internal", "uaa"], "add_tokens": "router . Handle ( \" \" , updateHandler { groups , tokens } ) . Methods ( \" \" ) router . Handle ( \" \" , listMembersHandler { groups , tokens } ) . Methods ( \" \" ) router . Handle ( \" \" , addMemberHandler { groups , tokens } ) . Methods ( \" \" ) router . Handle ( \" \" , checkMembershipHandler { groups , tokens } ) . Methods ( \" \" )", "del_tokens": "router . Handle ( \" \" , updateHandler { groups , tokens } ) . Methods ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "comments", "about", "missing", "endpoints"], "add_tokens": "Missing Project Endpoints Missing Branch Endpoints Missing Child Project Endpoints Missing Tag Endpoints Missing Commit Endpoints Missing Dashboard Endpoints", "del_tokens": "Things TODO Project Endpoints Branch Endpoints Child Project Endpoints Tag Endpoints Commit Endpoints Dashboard Endpoints", "commit_type": "add"}
{"commit_tokens": ["updated", "jsonapi", "and", "fixed", "small", "bug"], "add_tokens": "if rel . Data != nil && rel . Data . One != nil { var nilID * bson . ObjectId ctx . Model . Set ( field . Name , nilID ) ID : oid . Hex ( ) ,", "del_tokens": "if rel . Data . One != nil { ctx . Model . Set ( field . Name , nil ) ID : model . Get ( field . Name ) . ( bson . ObjectId ) . Hex ( ) ,", "commit_type": "update"}
{"commit_tokens": ["Update", "to", "Go", "release", ".", "2010", "-", "10", "-", "27"], "add_tokens": "os . Error ch <- & blobInfo { Error : err } ch <- & blobInfo { Error : err } ch <- & blobInfo { Error : os . ENOSPC } bi := & blobInfo { Error : err }", "del_tokens": "* os . Error ch <- & blobInfo { Error : & err } ch <- & blobInfo { Error : & err } ch <- & blobInfo { Error : & os . ENOSPC } bi := & blobInfo { Error : & err }", "commit_type": "update"}
{"commit_tokens": ["Add", "an", "example", "for", "recursive", "muxing"], "add_tokens": "// This is an example for serving HTTP and HTTPS on the same port.", "del_tokens": "// This is an example is serving HTTP and HTTPS on the same port.", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "-", "serverUrl", "flag", "to", "sblookup", "."], "add_tokens": "apiKeyFlag = flag . String ( \" \" , \" \" , \" \" ) databaseFlag = flag . String ( \" \" , \" \" , \" \" ) serverURLFlag = flag . String ( \" \" , safebrowsing . DefaultServerURL , \" \" ) APIKey : * apiKeyFlag , DBPath : * databaseFlag , Logger : os . Stderr , ServerURL : * serverURLFlag ,", "del_tokens": "apiKeyFlag = flag . String ( \" \" , \" \" , \" \" ) databaseFlag = flag . String ( \" \" , \" \" , \" \" ) APIKey : * apiKeyFlag , DBPath : * databaseFlag , Logger : os . Stderr ,", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "single", "var", "block", "for", "exported", "errors"], "add_tokens": "// These are the package-wide error values. // All error identification should use these values. // https://github.com/golang/go/wiki/Errors#naming var ( // ErrEmptyInput Input must not be empty ErrEmptyInput = statsError { \" \" } // ErrNaN Not a number ErrNaN = statsError { \" \" } // ErrNegative Must not contain negative values ErrNegative = statsError { \" \" } // ErrZero Must not contain zero values ErrZero = statsError { \" \" } // ErrBounds Input is outside of range ErrBounds = statsError { \" \" } // ErrSize Must be the same length ErrSize = statsError { \" \" } // ErrInfValue Value is infinite ErrInfValue = statsError { \" \" } // ErrYCoord Y Value must be greater than zero ErrYCoord = statsError { \" \" } )", "del_tokens": "// Package stats error values, all exported APIs // should use these errors as returned values // https://github.com/golang/go/wiki/Errors#naming // ErrEmptyInput Input must not be empty var ErrEmptyInput = statsError { \" \" } // ErrNaN Not a number var ErrNaN = statsError { \" \" } // ErrNegative Must not contain negative values var ErrNegative = statsError { \" \" } // ErrZero Must not contain zero values var ErrZero = statsError { \" \" } // ErrBounds Input is outside of range var ErrBounds = statsError { \" \" } // ErrSize Must be the same length var ErrSize = statsError { \" \" } // ErrInfValue Value is infinite var ErrInfValue = statsError { \" \" } // ErrYCoord Y Value must be greater than zero var ErrYCoord = statsError { \" \" }", "commit_type": "use"}
{"commit_tokens": ["Adds", "join", "and", "part", "commands"], "add_tokens": "Join ( target string ) Part ( target string )", "del_tokens": "irccon . Privmsg ( e . Arguments [ 1 ] , \" \\n \" )", "commit_type": "add"}
{"commit_tokens": ["change", "logic", "for", "when", "reader", "re", "-", "sends", "RDY"], "add_tokens": "bufferSizeRemaining int64 atomic . StoreInt64 ( & c . bufferSizeRemaining , int64 ( s ) ) atomic . AddInt64 ( & c . bufferSizeRemaining , - 1 ) remain := atomic . LoadInt64 ( & c . bufferSizeRemaining ) s := q . getBufferSize ( ) // refill when at 1, or at 25% whichever comes first if remain <= 1 || remain < ( int64 ( s ) / int64 ( 4 ) ) { atomic . StoreInt64 ( & c . bufferSizeRemaining , int64 ( s ) )", "del_tokens": "// TODO: don't write this every time (for when we have batch requesting enabled) s := q . getBufferSize ( ) - int ( atomic . LoadInt64 ( & c . messagesInFlight ) ) if s >= 1 {", "commit_type": "change"}
{"commit_tokens": ["Remove", "references", "to", "different", "handlers"], "add_tokens": "Interceptors ( ) InterceptorChain NopInterceptorChain", "del_tokens": "Interceptors ( ) WebInterceptorChain NopWebInterceptorChain", "commit_type": "remove"}
{"commit_tokens": ["Fix", "compile", "error", "due", "to", "containerProperties", "rename"], "add_tokens": "func ( container * container ) properties ( query string ) ( * ContainerProperties , error ) { properties := & ContainerProperties { }", "del_tokens": "func ( container * container ) properties ( query string ) ( * containerProperties , error ) { properties := & containerProperties { }", "commit_type": "fix"}
{"commit_tokens": ["Allow", "H", "records", "from", "any", "source"], "add_tokens": "hRegexp = regexp . MustCompile ( `H(.)([A-Z0-9]{3})(.*?:)?(.*?)\\s*\\z` )", "del_tokens": "hRegexp = regexp . MustCompile ( `H([FP])([A-Z0-9]{3})(.*?:)?(.*?)\\s*\\z` )", "commit_type": "allow"}
{"commit_tokens": ["Use", "encoding", "/", "csv", "for", "CSV", "output"], "add_tokens": "\" \" \" \" \" \" err = reportCSV ( w , data ) func reportCSV ( w io . Writer , data * gas . Analyzer ) error { out := csv . NewWriter ( w ) defer out . Flush ( ) for _ , issue := range data . Issues { err := out . Write ( [ ] string { issue . File , strconv . Itoa ( issue . Line ) , issue . What , issue . Severity . String ( ) , issue . Confidence . String ( ) , issue . Code , } ) if err != nil { return err } } return nil }", "del_tokens": "\" \" var csv = `{{ range $index, $issue := .Issues -}} { { - $ issue . File - } } , { { - $ issue . Line - } } , { { - $ issue . What - } } , { { - $ issue . Severity - } } , { { - $ issue . Confidence - } } , { { - printf \" \" $ issue . Code } } { { end } } ` err = reportFromTemplate ( w , csv , data )", "commit_type": "use"}
{"commit_tokens": ["Remove", "explicit", "exclude", "clause", "-", "use", "!", "in", "patterns", "instead", "."], "add_tokens": "\" \\n \\n \" , [ ] itm {", "del_tokens": "\" \\n \\n \\n \" , [ ] itm { { itemExclude , \" \" } , { itemBareString , \" \" } ,", "commit_type": "remove"}
{"commit_tokens": ["Use", "Time", ".", "Equal", "()", "instead", "simple", "comparison", "."], "add_tokens": "if t , ok := j . Claims ( ) . GetTime ( \" \" ) ; ! t . Equal ( iat ) || ! ok {", "del_tokens": "if t , ok := j . Claims ( ) . GetTime ( \" \" ) ; t != iat || ! ok {", "commit_type": "use"}
{"commit_tokens": ["adding", "preference", "for", "set", "values", "over", "defaults"], "add_tokens": "status = http . StatusOK } // Prefer set payload and status over default if path . payload != nil { payload = path . payload } if path . status != 0 { status = path . status", "del_tokens": "if path . status != 0 { status = path . status } else { status = http . StatusOK }", "commit_type": "add"}
{"commit_tokens": ["use", "shared", "pdk", "Byte", "formatter", "in", "network"], "add_tokens": "log . Printf ( \" \" , pdk . Bytes ( m . totalLen ) , m . nexter . Last ( ) ) log . Printf ( \" \" , pdk . Bytes ( m . totalLen ) , m . nexter . Last ( ) )", "del_tokens": "log . Printf ( \" \" , Bytes ( m . totalLen ) , m . nexter . Last ( ) ) log . Printf ( \" \" , Bytes ( m . totalLen ) , m . nexter . Last ( ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "tests", "to", "test", "executor", "driver", "starting", "."], "add_tokens": "workDir : \" \" , if len ( value ) > 0 { driver . workDir = value }", "del_tokens": "// TODO(yifan): Check if the value exists? driver . workDir = value", "commit_type": "add"}
{"commit_tokens": ["implement", "string", "score", "-", "stupid", "but", "useful"], "add_tokens": "// use first 2 runes in string as score var runes uint64 length := len ( t ) if length == 1 { runes = uint64 ( t [ 0 ] ) << 16 } else if length >= 2 { runes = uint64 ( t [ 0 ] ) << 16 + uint64 ( t [ 1 ] ) } score = float64 ( runes )", "del_tokens": "score = 0", "commit_type": "implement"}
{"commit_tokens": ["Add", "Start", "method", "to", "SPVWallet"], "add_tokens": "wallet := spvwallet . NewSPVWallet ( mnemonic , & chaincfg . TestNet3Params , 1000 , 60 , 40 , 20 , \" \" , \" \" , database , \" \" , ml ) go wallet . Start ( )", "del_tokens": "spvwallet . NewSPVWallet ( mnemonic , & chaincfg . TestNet3Params , 1000 , 60 , 40 , 20 , \" \" , \" \" , database , \" \" , ml )", "commit_type": "add"}
{"commit_tokens": ["fix", "fwd", "/", "bck", "search"], "add_tokens": "if l . IsSearchMode ( ) { l . ExitSearchMode ( false ) } if ! l . IsSearchMode ( ) { l . UpdateHistory ( l . buf . Runes ( ) , false ) }", "del_tokens": "l . UpdateHistory ( l . buf . Runes ( ) , false )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "empty", "ids", "to", "return", "empty", "slice", "instead", "of", "nil"], "add_tokens": "ids := [ ] string { }", "del_tokens": "var ids [ ] string", "commit_type": "fix"}
{"commit_tokens": ["Added", "default", "blanks", "to", "most", "User", "info", "columns"], "add_tokens": "sql . Column ( \" \" , sql . String { Length : 255 , NotNull : true , Default : sql . Blank } ) , sql . Column ( \" \" , sql . String { Length : 255 , NotNull : true , Default : sql . Blank } ) , sql . Column ( \" \" , sql . String { Length : 511 , NotNull : true , Default : sql . Blank } ) , sql . Column ( \" \" , sql . String { Length : 511 , NotNull : true , Default : sql . Blank } ) , sql . Column ( \" \" , sql . String { Length : 255 , NotNull : true , Default : sql . Blank } ) ,", "del_tokens": "sql . Column ( \" \" , sql . String { Length : 255 , NotNull : true } ) , sql . Column ( \" \" , sql . String { Length : 255 , NotNull : true } ) , sql . Column ( \" \" , sql . String { Length : 511 , NotNull : true } ) , sql . Column ( \" \" , sql . String { Length : 511 , NotNull : true } ) , sql . Column ( \" \" , sql . String { Length : 255 , NotNull : true } ) ,", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "recent", "log", "change", "in", "joyent", "/", "gocommon"], "add_tokens": "//\"github.com/juju/loggo\" \" \" \" \" var Logger = log . New ( os . Stdout , \" \" , log . LstdFlags )", "del_tokens": "\" \" var Logger = loggo . GetLogger ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["fix", "method", "order", "and", "comment"], "add_tokens": "// UnmarshalJSON method of Event", "del_tokens": "// UnmarshalJSON constructs a Event from JSON-encoded data.", "commit_type": "fix"}
{"commit_tokens": ["Makes", "TrimTree", "have", "no", "return", "type"], "add_tokens": "func ( g * Graph ) TrimTree ( kept NodeSet ) {", "del_tokens": "func ( g * Graph ) TrimTree ( kept NodeSet ) * Graph { return g", "commit_type": "make"}
{"commit_tokens": ["Add", "user", "profile", "and", "notifications"], "add_tokens": "_ , err := o . collection . Upsert ( bson . M { \" \" : invite . User , \" \" : invite . Organization , \" \" : invite . Role , } , invite )", "del_tokens": "_ , err := o . collection . Upsert ( bson . M { \" \" : invite . User , \" \" : invite . Organization , \" \" : invite . Role } , invite )", "commit_type": "add"}
{"commit_tokens": ["Move", "execute", "checkRow", "logic", "when", "XLSX", "file", "open", "speed", "up", "library", "write", "file", "."], "add_tokens": "file , sheetCount , _ = ReadZip ( f ) endCol := titleToNumber ( endR ) + 1 // UpdateLinkedValue fix linked values within a spreadsheet are not updating in // Office Excel 2007 and 2010. This function will be remove value tag when met a // cell have a linked value. Reference https://social.technet.microsoft.com/Forums/office/en-US/e16bae1f-6a2c-4325-8013-e989a3479066/excel-2010-linked-cells-not-updating?forum=excel", "del_tokens": "file , sheetCount , err = ReadZip ( f ) xlsx = checkRow ( xlsx ) xlsx = checkRow ( xlsx ) endCol := titleToNumber ( endR ) // UpdateLinkedValue fix linked values within a spreadsheet are not updating. // This function will be remove value tag when met a cell have a linked value. // Reference https://social.technet.microsoft.com/Forums/office/en-US/e16bae1f-6a2c-4325-8013-e989a3479066/excel-2010-linked-cells-not-updating?forum=excel", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "silly", "bug", "in", "NewWriter", "."], "add_tokens": "authContext := cloud . WithContext ( ctx , b . projID , b . client ) wrapped := storage . NewWriter ( authContext , b . name , attrs . Name ) wrapped : wrapped ,", "del_tokens": "wrapped : & storage . Writer { ObjectAttrs : * attrs , } ,", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "page", "::", "screenshot", "regression"], "add_tokens": "// Automatically resize the screen to the width and height. Autoresize bool `json:\"autoresize\" default:\"true\"` } else if args . Autoresize && args . Width > 0 && args . Height > 0 { `mobile` : false ,", "del_tokens": "} else if args . Width > 0 && args . Height > 0 { `mobile` : true ,", "commit_type": "fix"}
{"commit_tokens": ["add", "base", "bin", "log", "support"], "add_tokens": "} , \" \" : { \" \" : \" \" , \" \" : 1073741824 , \" \" : 3 }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Add", "comments", "to", "fix", "the", "remaining", "golint", "warnings", "."], "add_tokens": "// IdentityStore provides an interface to identity information. // PreKeyStore provides an interface to accessing the local prekeys. // SignedPreKeyStore provides an interface to accessing the local signed prekeys. // SessionStore provides an interface to accessing the local session records.", "del_tokens": "// IdentityStore provides an interface to identity information // PreKeyStore provides an interface to accessing the local prekeys // SignedPreKeyStore provides an interface to accessing the local signed prekeys", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "bad", "use", "of", "searchstrings", "add", "test", "with", "url", "filtering"], "add_tokens": "if indexInStrings ( hosts , parsed . Host ) == - 1 {", "del_tokens": "\" \" // TODO : Reset internal fields, this could be a second Run on a same Crawler if sort . SearchStrings ( hosts , parsed . Host ) >= len ( hosts ) { sort . Strings ( hosts )", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "default", "block", "driver", "that", "filesystem", "drivers", "can", "inherit", "from"], "add_tokens": "\" \" providers = [ ] string { aws . Name , nfs . Name }", "del_tokens": "providers = [ ] string { aws . Name }", "commit_type": "add"}
{"commit_tokens": ["Update", "a", "few", "of", "the", "options", "so", "that", "godoc", "will", "place", "them", "all", "together"], "add_tokens": "func ReadFromStart ( ) FileConfig { return func ( t * File ) error { _ , err := t . file . Seek ( 0 , os . SEEK_SET ) return err } func PollForChanges ( ) FileConfig { return func ( t * File ) error { t . rotationStrat = \" \" // go t.pollForUpdates(pollIntervalFast) // go t.pollForRotations(pollIntervalSlow) return nil } func NotifyOnChanges ( ) FileConfig { return func ( t * File ) error { t . rotationStrat = \" \" // return t.notifyOnChanges() return nil }", "del_tokens": "func ReadFromStart ( t * File ) error { _ , err := t . file . Seek ( 0 , os . SEEK_SET ) return err func PollForChanges ( t * File ) error { t . rotationStrat = \" \" // go t.pollForUpdates(pollIntervalFast) // go t.pollForRotations(pollIntervalSlow) return nil func NotifyOnChanges ( t * File ) error { t . rotationStrat = \" \" // return t.notifyOnChanges() return nil", "commit_type": "update"}
{"commit_tokens": ["Add", "exported", "method", "it", "init", "with", "custom", "session"], "add_tokens": "func NewWithSession ( sess * session . Session , store kv . Service , kmsID string ) ( kv . Service , error ) { func New ( store kv . Service , kmsID string ) ( kv . Service , error ) { sess , err := session . NewSession ( ) if err != nil { return nil , err } return NewWithSession ( sess , store , kmsID ) }", "del_tokens": "func New ( store kv . Service , kmsID string ) ( kv . Service , error ) { sess , err := session . NewSession ( ) if err != nil { return nil , err }", "commit_type": "add"}
{"commit_tokens": ["Add", "regexp", "support", "to", "String"], "add_tokens": "if index < 0 || index >= len ( a . value ) { a . chain . fail ( \" \\n \\n \\n \\n \" , index , 0 , len ( a . value ) )", "del_tokens": "if len ( a . value ) <= index { a . chain . fail ( \" \\n \\n \" , index , len ( a . value ) , dumpValue ( a . value ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "Expand", "a", "fund", "of", "Hyperlink", "instead", "of", "its", "pointer"], "add_tokens": "func ( l Hyperlink ) Expand ( m M ) ( * url . URL , error ) { template , err := uritemplates . Parse ( string ( l ) )", "del_tokens": "func ( l * Hyperlink ) Expand ( m M ) ( * url . URL , error ) { template , err := uritemplates . Parse ( string ( * l ) )", "commit_type": "make"}
{"commit_tokens": ["Fix", "build", "error", "for", "kafka", "/", "sarama"], "add_tokens": "\" \"", "del_tokens": "sarama \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "include", "tag", "for", "encoding", "struct", "fields", "with", "dot", "notation", "in", "the", "root"], "add_tokens": "\" \" fieldName , opts := parseTag ( field . Tag . Get ( tagName ) ) if fieldName == \" \" || fieldName == \" \" { if opts . Has ( \" \" ) && field . Type . Kind ( ) == reflect . Struct { subInput := make ( map [ string ] string ) for k , v := range input { if strings . HasPrefix ( k , fieldName + \" \" ) { subInput [ strings . TrimPrefix ( k , fieldName + \" \" ) ] = v } } subOutput , err := FromStringStringMap ( tagName , val . Field ( i ) . Interface ( ) , subInput ) if err != nil { return nil , err } val . Field ( i ) . Set ( reflect . ValueOf ( subOutput ) ) } str , ok := input [ fieldName ]", "del_tokens": "tagField , _ := parseTag ( field . Tag . Get ( tagName ) ) if tagField == \" \" || tagField == \" \" { str , ok := input [ tagField ]", "commit_type": "add"}
{"commit_tokens": ["Fix", "early", "defer", "panic", "."], "add_tokens": "defer rs . Body . Close ( ) defer rs . Body . Close ( ) defer rs . Body . Close ( )", "del_tokens": "defer rs . Body . Close ( ) defer rs . Body . Close ( ) defer rs . Body . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "example", "names", "to", "Go", "convention"], "add_tokens": "func ExampleProgressBar_Set ( ) { func ExampleProgressBar_Set64 ( ) { func ExampleProgressBar_basic ( ) { func ExampleOptionThrottle ( ) { func ExampleProgressBar_ChangeMax ( ) { func ExampleOptionClearOnFinish ( ) { func ExampleProgressBar_Finish ( ) { func Example_xOutOfY ( ) { func ExampleOptionSetBytes ( ) { func ExampleOptionShowIts_count ( ) { func ExampleOptionShowIts ( ) { func ExampleOptionSetRenderBlankState ( ) { func ExampleProgressBar_Describe ( ) {", "del_tokens": "func ExampleProgressBarSet ( ) { func ExampleProgressBarSet64 ( ) { func ExampleProgressBarBasic ( ) { func ExampleThrottle ( ) { func ExampleChangeMax ( ) { func ExampleFinish ( ) { func ExampleFinish2 ( ) { func ExampleXOutOfY ( ) { func ExampleSetBytes ( ) { func ExampleShowCount ( ) { func ExampleSetIts ( ) { func ExampleProgressBar_RenderBlank ( ) { func ExampleDescribe ( ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "subdir", "support", "for", "pseudo", "directories"], "add_tokens": "Name string `json:\"name\"` // object name ContentType string `json:\"content_type\"` // eg application/directory Bytes int64 `json:\"bytes\"` // size in bytes LastModified string `json:\"last_modified\"` // Last modified time, eg '2011-06-30T08:20:47.736680' Hash string `json:\"hash\"` // MD5 hash, eg \"d41d8cd98f00b204e9800998ecf8427e\" PseudoDirectory bool // Set when using delimiter to show that this directory object does not really exist SubDir string `json:\"subdir\"` // returned only when using delimiter to mark \"pseudo directories\" // // If Delimiter is set in the opts then PseudoDirectory may be set, // with ContentType 'application/directory'. These are not real // objects but represent directories of objects which haven't had an // object created for them. for i := range containers { if containers [ i ] . SubDir != \" \" { containers [ i ] . Name = containers [ i ] . SubDir containers [ i ] . PseudoDirectory = true containers [ i ] . ContentType = \" \" } }", "del_tokens": "Name string `json:\"name\"` // object name ContentType string `json:\"content_type\"` // eg application/directory Bytes int64 `json:\"bytes\"` // size in bytes LastModified string `json:\"last_modified\"` // Last modified time, eg '2011-06-30T08:20:47.736680' Hash string `json:\"hash\"` // MD5 hash, eg \"d41d8cd98f00b204e9800998ecf8427e\"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Stoch", "index", "out", "of", "range", "error"], "add_tokens": "import \" \" //for i, j := lookbackK, lookbackTotal; j < len(inClose); i, j = i+1, j+1 { for i , j := lookbackDSlow + lookbackKSlow , lookbackTotal ; j < len ( inClose ) ; i , j = i + 1 , j + 1 {", "del_tokens": "import ( \" \" ) for i , j := lookbackK , lookbackTotal ; j < len ( inClose ) ; i , j = i + 1 , j + 1 {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "encoding", ".", "TextMarshaler", "TextUnmarshaler"], "add_tokens": "\" \" func setTextUnmarshaler ( lhs reflect . Value , val ast . Value ) ( error , bool ) { if ! lhs . CanAddr ( ) { return nil , false } u , ok := lhs . Addr ( ) . Interface ( ) . ( encoding . TextUnmarshaler ) if ! ok { return nil , false } var data string switch val := val . ( type ) { case * ast . Array : return fmt . Errorf ( \" \" , lhs . Type ( ) ) , true case * ast . String : data = val . Value default : data = val . Source ( ) } return u . UnmarshalText ( [ ] byte ( data ) ) , true } if err , ok := setTextUnmarshaler ( lhs , val ) ; ok { return err } panic ( \" \" )", "del_tokens": "if err := setDatetime ( lhs , v ) ; err != nil { return err } func setDatetime ( fv reflect . Value , v * ast . Datetime ) error { tm , err := v . Time ( ) if err != nil { return err } return set ( fv , tm ) }", "commit_type": "add"}
{"commit_tokens": ["move", "dot", "in", "regex", "to", "avoid", "it", "being", "part", "of", "a", "range"], "add_tokens": "var sanitizeRegexp = regexp . MustCompile ( \" \" )", "del_tokens": "var sanitizeRegexp = regexp . MustCompile ( \" \" )", "commit_type": "move"}
{"commit_tokens": ["Use", "a", "monochrome", "default", "style"], "add_tokens": "\" \" : { ColorDefault , ColorDefault } ,", "del_tokens": "\" \" : { ColorYellow , ColorDefault } ,", "commit_type": "use"}
{"commit_tokens": ["fixed", "typo", "and", "made", "tests", "more", "robust"], "add_tokens": "return \" \" + queue . name + \" \" + consumer return \" \" + queue . name + \" \"", "del_tokens": "return \" \" + queue . name + \" \" + consumer return \" \" + queue . name + \" \"", "commit_type": "fix"}
{"commit_tokens": ["Use", "overwrite", "for", "set", "raw", "dashboards", "."], "add_tokens": "buf . WriteString ( `, \"overwrite\": true}` )", "del_tokens": "buf . WriteString ( `}` )", "commit_type": "use"}
{"commit_tokens": ["Remove", "old", "virtual", "network", "related", "APIs", "and", "rename", "resource", "path", "for", "subnet"], "add_tokens": "ResourceTicket ResourceTicketReservation `json:\"resourceTicket\"` Name string `json:\"name\"` SecurityGroups [ ] string `json:\"securityGroups,omitempty\"` DefaultRouterPrivateIpCidr string `json:\"defaultRouterPrivateIpCidr,omitempty\"`", "del_tokens": "ResourceTicket ResourceTicketReservation `json:\"resourceTicket\"` Name string `json:\"name\"` SecurityGroups [ ] string `json:\"securityGroups,omitempty\"` // Create spec for virtual subnet type VirtualSubnetCreateSpec struct { Name string `json:\"name\"` Description string `json:\"description,omitempty\"` RoutingType string `json:\"routingType\"` Size int `json:\"size\"` ReservedStaticIpSize int `json:\"reservedStaticIpSize,omitempty\"` } // Represents a virtual network type VirtualSubnet struct { ID string `json:\"id\"` Name string `json:\"name\"` Description string `json:\"description,omitempty\"` State string `json:\"state\"` RoutingType string `json:\"routingType\"` IsDefault bool `json:\"isDefault\"` Cidr string `json:\"cidr,omitempty\"` LowIpDynamic string `json:\"lowIpDynamic,omitempty\"` HighIpDynamic string `json:\"highIpDynamic,omitempty\"` LowIpStatic string `json:\"lowIpStatic,omitempty\"` HighIpStatic string `json:\"highIpStatic,omitempty\"` ReservedIpList [ ] string `json:\"reservedIpList\"` SelfLink string `json:\"selfLink\"` } // Represents multiple virtual subnets returned type VirtualSubnets struct { Items [ ] VirtualSubnet `json:\"items\"` }", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "file", "contents", "provided", "in", "first", "GH", "API", "call", "."], "add_tokens": "Content string Data : [ ] byte ( file . Content ) ,", "del_tokens": "RawUrl string `json:\"raw_url\"` var dataURLs [ ] string dataURLs = append ( dataURLs , file . RawUrl + \" \" + gitHubCred ) if err := c . getFiles ( dataURLs , files ) ; err != nil { return nil , err }", "commit_type": "use"}
{"commit_tokens": ["Fix", "incorrect", "usage", "of", "Truncate"], "add_tokens": "y , m , d := now . Date ( ) return time . Date ( y , m , d , now . Hour ( ) , 0 , 0 , 0 , now . Location ( ) )", "del_tokens": "return now . Truncate ( time . Hour )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "wrong", "function", "handle", "read"], "add_tokens": "client . HandleRead ( func ( m messenger . Read , r * messenger . Response ) {", "del_tokens": "client . HandleDelivery ( func ( m messenger . Read , r * messenger . Response ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "other", "variable", "names", "too", "."], "add_tokens": "fileOffsetHigh := uint32 ( off >> 32 ) fileOffsetLow := uint32 ( off & 0xFFFFFFFF ) addr , errno := syscall . MapViewOfFile ( h , dwDesiredAccess , fileOffsetHigh , fileOffsetLow , uintptr ( len ) )", "del_tokens": "file_offset_high := uint32 ( off >> 32 ) file_offset_low := uint32 ( off & 0xFFFFFFFF ) addr , errno := syscall . MapViewOfFile ( h , dwDesiredAccess , file_offset_high , file_offset_low , uintptr ( len ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "more", "compressible", "golden", "input", "for", "the", "tests", "."], "add_tokens": "const ( goldenText = \" \" goldenCompressed = goldenText + \" \" ) src , err := ioutil . ReadFile ( goldenCompressed ) want , err := ioutil . ReadFile ( goldenText ) src , err := ioutil . ReadFile ( goldenText ) want , err := ioutil . ReadFile ( goldenCompressed )", "del_tokens": "// TODO: pi.txt no longer compresses at all, after the Go code implemented the // same algorithmic change as the C++ code: // https://github.com/google/snappy/commit/d53de18799418e113e44444252a39b12a0e4e0cc // // We should use a more compressible test file. src , err := ioutil . ReadFile ( \" \" ) want , err := ioutil . ReadFile ( \" \" ) src , err := ioutil . ReadFile ( \" \" ) want , err := ioutil . ReadFile ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Update", "configuration", "functions", "for", "exclude", "configuration"], "add_tokens": "excludeCfg , err = config . LoadFromFile ( path . Join ( cfgDir , config . ExcludeYML ) )", "del_tokens": "excludeCfg , err = config . GetExcludeCfgFromYML ( path . Join ( cfgDir , config . ExcludeYML ) )", "commit_type": "update"}
{"commit_tokens": ["updated", "README", "to", "include", "the", "video"], "add_tokens": "// Parse an input string and return a Template, and caches the parsed template.", "del_tokens": "// Parse an input string and return a Template.", "commit_type": "update"}
{"commit_tokens": ["move", "concurrent", "map", "to", "its", "own", "repo"], "add_tokens": "\" \" ID string // Randomly generated unique connection ID Data cmap . CMap // Thread-safe data store for storing arbitrary data for this connection session", "del_tokens": "ID string // Randomly generated unique connection ID", "commit_type": "move"}
{"commit_tokens": ["add", "tests", "for", "quoting", "/", "unquoting", "strings", "fix", "bugs", "in", "it"], "add_tokens": "if i + 4 > len ( s ) { return \" \" , errors . New ( \" \\\\ \" ) num , err := strconv . ParseInt ( s [ i : i + 4 ] , 16 , 0 ) if ! escaping { result = append ( result , r ) }", "del_tokens": "if i + 5 <= len ( s ) { return \" \" , errors . New ( \" \\\\ \" ) num , err := strconv . ParseInt ( s [ i + 1 : i + 5 ] , 16 , 0 ) result = append ( result , r )", "commit_type": "add"}
{"commit_tokens": ["Add", "save", "policy", "API", "."], "add_tokens": "func TestReloadPolicy ( t * testing . T ) { func TestSavePolicy ( t * testing . T ) { e := & Enforcer { } e . init ( \" \" , \" \" ) e . savePolicy ( ) }", "del_tokens": "func TestClearPolicy ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "correct", "new", "function", "."], "add_tokens": "c := C . gtk_revealer_new ( )", "del_tokens": "c := C . gtk_search_bar_new ( )", "commit_type": "use"}
{"commit_tokens": ["Fix", "usage", "on", "32bit", "machines"], "add_tokens": "newMatchSliceFn ( 123 , math . MaxInt32 , 1 ) , newMatchSliceFn ( 123 , math . MaxInt32 , 7 ) , newMatchSliceFn ( 0 , math . MaxInt32 , 7 ) ,", "del_tokens": "newMatchSliceFn ( 123 , math . MaxInt64 , 1 ) , newMatchSliceFn ( 123 , math . MaxInt64 , 7 ) , newMatchSliceFn ( 0 , math . MaxInt64 , 7 ) ,", "commit_type": "fix"}
{"commit_tokens": ["Move", "defered", "Unlock", "()", "before", "a", "possible", "function", "return", "."], "add_tokens": "defer wallets . Unlock ( )", "del_tokens": "defer wallets . Unlock ( )", "commit_type": "move"}
{"commit_tokens": ["allows", "for", "debugging", "req", "/", "resp"], "add_tokens": "\" \" \" \" Debug bool rt . Debug = os . Getenv ( \" \" ) == \" \" if r . Debug { b , err := httputil . DumpRequestOut ( req , true ) if err != nil { return nil , err } fmt . Println ( string ( b ) ) } if r . Debug { b , err := httputil . DumpResponse ( res , true ) if err != nil { return nil , err } fmt . Println ( string ( b ) ) }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Fix", "the", "conversion", "from", "empty", "space", "to", "float"], "add_tokens": "\" \" s := strings . TrimSpace ( inValue . String ( ) ) if s == \" \" { return 0 , nil } return strconv . ParseFloat ( s , 64 )", "del_tokens": "return strconv . ParseFloat ( inValue . String ( ) , 64 )", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "check", "to", "make", "sure", "type", "assertion", "was", "successful", ".", "If", "it", "isn", "t", "successful", "return", "nil", "instead", "of", "having", "a", "runtime", "error", "."], "add_tokens": "if s , ok := context . Get ( req , sessionKey ) . ( * session ) ; ok { return s } return nil", "del_tokens": "return context . Get ( req , sessionKey ) . ( * session )", "commit_type": "add"}
{"commit_tokens": ["Fix", "trying", "to", "delete", "non", "-", "reference"], "add_tokens": "CanResolve ( ) bool func ( self * _propertyReference ) CanResolve ( ) bool { return self . Base != nil } // TODO Throw an error if strict return true func ( self * _environmentReference ) CanResolve ( ) bool { return true // FIXME }", "del_tokens": "func ( self _reference_ ) GetBase ( ) * _object { return nil } func ( self _reference_ ) Delete ( ) { panic ( hereBeDragons ( ) ) } return false", "commit_type": "fix"}
{"commit_tokens": ["Fix", "mock", "generation", "of", "ellipsis", "-", "only", "method", "signatures", "."], "add_tokens": "if nargs > 0 { argString += \" \" } argString += fmt . Sprintf ( \" \" , nargs )", "del_tokens": "argString += fmt . Sprintf ( \" \" , nargs )", "commit_type": "fix"}
{"commit_tokens": ["Update", "import", "path", "of", "fsnotify"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "interactive", "option", "when", "only", "a", "path", "is", "provided"], "add_tokens": "func TestCounterfeiterCLIIntegration ( t * testing . T ) { RunSpecs ( t , \" \" )", "del_tokens": "func TestCounterfeiterCLI ( t * testing . T ) { RunSpecs ( t , \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "BytesSize", "in", "pkg", "/", "units"], "add_tokens": "var decimapAbbrs = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } var binaryAbbrs = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } return intToString ( float64 ( size ) , 1000.0 , decimapAbbrs ) } func BytesSize ( size float64 ) string { return intToString ( size , 1024.0 , binaryAbbrs ) } func intToString ( size , unit float64 , _map [ ] string ) string { for size >= unit { size = size / unit return fmt . Sprintf ( \" \" , size , _map [ i ] )", "del_tokens": "var unitAbbrs = [ ... ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } sizef := float64 ( size ) for sizef >= 1000.0 { sizef = sizef / 1000.0 return fmt . Sprintf ( \" \" , sizef , unitAbbrs [ i ] )", "commit_type": "add"}
{"commit_tokens": ["add", "a", "whole", "bunch", "of", "debug", "printouts"], "add_tokens": "if err != nil { log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err ) return err } if err != nil { log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err ) return err } if err != nil { log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err ) } if err != nil { log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err ) return err } log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err ) log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err ) log . WithFields ( log . Fields { \" \" : \" \" , } ) . Debug ( err )", "del_tokens": "utils . Assert ( err ) utils . Assert ( err ) utils . Assert ( err ) utils . Assert ( err )", "commit_type": "add"}
{"commit_tokens": ["Add", "working", "bot", "with", "micro", "commands"], "add_tokens": "\" \" // send and receive events // Register a command Process ( command . Command ) error", "del_tokens": "// sendd and receive events", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "possibility", "of", "using", "password@host", ":", "port"], "add_tokens": "// Use this for connecting to a different redis host/port (+password) // pool := simpleredis.NewConnectionPoolHost(\"password@localhost:6379\")", "del_tokens": "// Use this for connecting to a different redis host/port // pool := simpleredis.NewConnectionPoolHost(\"localhost:6379\")", "commit_type": "add"}
{"commit_tokens": ["Fix", "GC", "race", "in", "bind", "with", "Einhorn"], "add_tokens": "syscall . CloseOnExec ( einhornFdMap ( i ) ) func einhornFdMap ( n int ) int { return fno fno := einhornFdMap ( n ) f := os . NewFile ( uintptr ( fno ) , fmt . Sprintf ( \" \" , n ) )", "del_tokens": "fd := int ( einhornFd ( i ) . Fd ( ) ) syscall . CloseOnExec ( fd ) func einhornFd ( n int ) * os . File { return os . NewFile ( uintptr ( fno ) , name ) f := einhornFd ( n )", "commit_type": "fix"}
{"commit_tokens": ["fix", "missing", "millisecond", "unit", "for", "hystrix", "timeout"], "add_tokens": "hystrix . WithHystrixTimeout ( 1100 * time . Millisecond ) , hystrix . WithHystrixTimeout ( 1100 * time . Millisecond ) ,", "del_tokens": "hystrix . WithHystrixTimeout ( 1100 ) , hystrix . WithHystrixTimeout ( 1100 ) ,", "commit_type": "fix"}
{"commit_tokens": ["add", "new", "user", "connection", "handler"], "add_tokens": "UserConnHandler Version int `yaml:\"version\"` Rules [ ] * Rule `yaml:\"rules\"` if config . Version == 0 { // TODO: log warning config . Version = 1 } if config . Version != 1 { return nil , fmt . Errorf ( \" \" , config . Version ) } case \" \" : rule . ruleType = UserConnHandler", "del_tokens": "Rules [ ] * Rule `yaml:\"rules\"`", "commit_type": "add"}
{"commit_tokens": ["Update", "windows", "tests", "so", "they", "compile", "for", "signature"], "add_tokens": "process := NewExecProcess ( command , false , logger ) execProcess := NewExecProcess ( exec . Command ( WindowsExePath ) , false , logger ) execProcess := NewExecProcess ( exec . Command ( WindowsExePath ) , false , logger )", "del_tokens": "process := NewExecProcess ( command , logger ) execProcess := NewExecProcess ( exec . Command ( WindowsExePath ) , logger ) execProcess := NewExecProcess ( exec . Command ( WindowsExePath ) , logger )", "commit_type": "update"}
{"commit_tokens": ["Adds", "test", "to", "ensure", "that", "by", "default", "a", "newly", "added", "subscriber", "receives", "the", "event", "log", "."], "add_tokens": "s . event <- & Event { Data : [ ] byte ( \" \" ) } Convey ( \" \" , func ( ) { So ( len ( sub . connection ) , ShouldEqual , 1 ) } )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "deleting", "and", "adding", "internal", "data", "groups", "."], "add_tokens": "func ( b * BigIP ) AddInternalDataGroup ( config * DataGroup ) error { return b . post ( config , uriLtm , uriDatagroup , uriInternal ) } func ( b * BigIP ) DeleteInternalDataGroup ( name string ) error { return b . delete ( uriLtm , uriDatagroup , uriInternal , name )", "del_tokens": "func ( b * BigIP ) AddInternalDataGroup ( name string , config * DataGroup ) error { return b . post ( config , uriLtm , )", "commit_type": "add"}
{"commit_tokens": ["add", "Params", "and", "Param", "function"], "add_tokens": "params := Params ( r ) params := Params ( r ) params := Params ( r ) params := Params ( r )", "del_tokens": "params := r . Context ( ) . Value ( RouteParamsID ) . ( map [ string ] string ) params := r . Context ( ) . Value ( RouteParamsID ) . ( map [ string ] string ) params := r . Context ( ) . Value ( RouteParamsID ) . ( map [ string ] string ) params := r . Context ( ) . Value ( RouteParamsID ) . ( map [ string ] string )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bootstrap", "script", "name", "to", "existing", "one"], "add_tokens": "BootstrapScript : \" \" , BootstrapScript : \" \" ,", "del_tokens": "BootstrapScript : \" \" , BootstrapScript : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "to", "copy", "msg", "buffer"], "add_tokens": "// FIXME(dlc), if the callback holds onto these could be not good. // FIXME(dlc): Need to copy, should/can do COW? newMsg := make ( [ ] byte , len ( msg ) ) copy ( newMsg , msg ) // FIXME(dlc): Should we recycle these containers? m := & Msg { Data : newMsg , Subject : subj , Reply : reply , Sub : sub }", "del_tokens": "// FIXME(dlc): Should we recycle these containers? m := & Msg { Data : msg , Subject : subj , Reply : reply , Sub : sub }", "commit_type": "make"}
{"commit_tokens": ["Remove", "queue", "cleanup", "unnecessary", "locking", "close", "rows"], "add_tokens": "//err = queueDeployment(deploymentID, manifest) // //if err == nil { // go serviceDeploymentQueue() //} bypassQueue ( deploymentID , manifest ) func bypassQueue ( depID , manifestString string ) { manifest , err := parseManifest ( manifestString ) if err != nil { return } err = prepareDeployment ( depID , manifest ) if err != nil { log . Errorf ( \" \" , depID ) return } log . Debugf ( \" \" , depID ) incoming <- depID }", "del_tokens": "err = queueDeployment ( deploymentID , manifest ) if err == nil { go serviceDeploymentQueue ( ) }", "commit_type": "remove"}
{"commit_tokens": ["Add", "FSID", "in", "context", "to", "each", "request", "with", "cfs"], "add_tokens": "\" \" fsnum , err := uuid . FromString ( u . Host ) if err != nil { fmt . Print ( \" \" , err ) } fs := newfs ( cfs , rpc , fsnum . String ( ) )", "del_tokens": "fsnum := u . Host fs := newfs ( cfs , rpc )", "commit_type": "add"}
{"commit_tokens": ["add", "DeploymentDeployOperation", "to", "system", "deploy"], "add_tokens": "func ( api * DeploymentsAPI ) Deploy ( id string , config * DeploymentDeployOperation ) ( task * Task , err error ) { body , err := json . Marshal ( config ) if err != nil { return } bytes . NewBuffer ( body ) ,", "del_tokens": "func ( api * DeploymentsAPI ) Deploy ( id string ) ( task * Task , err error ) { bytes . NewBuffer ( [ ] byte ( \" \" ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "environment", "variables"], "add_tokens": "expectedUsage := \" \\n \" expectedHelp := `usage: example [--name NAME] [--value VALUE] [--verbose] [--dataset DATASET] [--optimize OPTIMIZE] [--ids IDS] [--workers WORKERS] INPUT [OUTPUT [OUTPUT ...]] - - workers WORKERS , - w WORKERS number of workers to start Workers int `arg:\"-w,env:WORKERS,help:number of workers to start\"`", "del_tokens": "expectedUsage := \" \\n \" expectedHelp := `usage: example [--name NAME] [--value VALUE] [--verbose] [--dataset DATASET] [--optimize OPTIMIZE] [--ids IDS] INPUT [OUTPUT [OUTPUT ...]]", "commit_type": "add"}
{"commit_tokens": ["Add", "sql", ".", "Null", "{", "type", "}", "to", "the", "supported", "types"], "add_tokens": "\" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" ,", "del_tokens": "\" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Added", "WeekStartDay", "so", "that", "any", "day", "can", "be", "the", "start", "of", "the", "week", ".", "Also", "added", "tests", "and", "fixed", "documentation"], "add_tokens": "var WeekStartDay = time . Sunday", "del_tokens": "var FirstDayMonday bool", "commit_type": "add"}
{"commit_tokens": ["Made", "validation", "/", "formatter", "errors", "more", "clear"], "add_tokens": "} else if err := self . Validator ( value ) ; err != nil { return fmt . Errorf ( \" \" , err ) return nil if v , err := self . Formatter ( value , op ) ; err == nil { return v , nil } else { return v , fmt . Errorf ( \" \" , err ) }", "del_tokens": "return self . Validator ( value ) return self . Formatter ( value , op )", "commit_type": "make"}
{"commit_tokens": ["Adds", "more", "parallelism", "for", "map", "jobs", "."], "add_tokens": "for i := 0 ; i < 200 ; i ++ {", "del_tokens": "for i := 0 ; i < 100 ; i ++ {", "commit_type": "add"}
{"commit_tokens": ["add", "a", "public", "method", "to", "the", "Client", "interface", "that", "returns", "a", "repository", "group", "detail"], "add_tokens": "type ( RepositoryID string GroupID string RepositoryGroup struct { ID GroupID Name string ContentResourceURI string Repositories [ ] Repository } Repository struct { Name string ID RepositoryID ResourceURI string } ClientConfig struct { // The public client interface Client // For Nexus clients, typically http://host:port/nexus BaseURL string // Admin username and password capable of updating the artifact repository Username string Password string // Underlying network client HttpClient * http . Client } ) RepositoryGroup ( GroupID ) ( RepositoryGroup , int , error )", "del_tokens": "type RepositoryID string type GroupID string type ClientConfig struct { // The public client interface Client // For Nexus clients, typically http://host:port/nexus BaseURL string // Admin username and password capable of updating the artifact repository Username string Password string // Underlying network client HttpClient * http . Client }", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "use", "custom", "logger"], "add_tokens": "// Logger generic interface for logger type Logger interface { Printf ( string , ... interface { } ) } Log Logger // convenience method. checks if a logger is set.", "del_tokens": "Log * log . Logger // convenience method. checks if debugging is turned on before printing", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "updating", "posts"], "add_tokens": "Published bool `json:\"published\"` Version int `json:\"version\"`", "del_tokens": "Published bool `json:\"deleted\"`", "commit_type": "add"}
{"commit_tokens": ["Make", "things", "slightly", "more", "Go", "-", "ish"], "add_tokens": "switch dir { case Up : case Down : default :", "del_tokens": "if dir == Up { } else if dir == Down { } else {", "commit_type": "make"}
{"commit_tokens": ["Use", "v2", "of", "go", "logger", "library"], "add_tokens": "\" \" // using the supplied UPP logger func TransactionAwareRequestLoggingHandler ( logger * logger . UPPLogger , h http . Handler ) http . Handler { logger * logger . UPPLogger // writeRequestLog writes a log entry to the supplied UPP logger. func writeRequestLog ( logger * logger . UPPLogger , req * http . Request , transactionID string , url url . URL , responseTime time . Duration , status , size int ) { logger . WithFields ( map [ string ] interface { } {", "del_tokens": "log \" \" // using the supplied logrus.Logger func TransactionAwareRequestLoggingHandler ( logger * log . Logger , h http . Handler ) http . Handler { logger * log . Logger // writeRequestLog writes a log entry to the supplied logrus logger. func writeRequestLog ( logger * log . Logger , req * http . Request , transactionID string , url url . URL , responseTime time . Duration , status , size int ) { logger . WithFields ( log . Fields {", "commit_type": "use"}
{"commit_tokens": ["Remove", "timer", ".", "go", "and", "timer_test", ".", "go"], "add_tokens": "\" \" defer requestLatencyAccumulator ( time . Now ( ) ) requestCount . Increment ( nil ) url := r . URL if strings . HasSuffix ( url . Path , jsonSuffix ) { header := w . Header ( ) header . Set ( ProtocolVersionHeader , APIVersion ) header . Set ( contentTypeHeader , jsonContentType ) writer := decorateWriter ( r , w ) if closer , ok := writer . ( io . Closer ) ; ok { defer closer . Close ( ) registry . dumpToWriter ( writer ) } else { w . WriteHeader ( http . StatusNotFound )", "del_tokens": "var instrumentable InstrumentableCall = func ( ) { requestCount . Increment ( nil ) url := r . URL if strings . HasSuffix ( url . Path , jsonSuffix ) { header := w . Header ( ) header . Set ( ProtocolVersionHeader , APIVersion ) header . Set ( contentTypeHeader , jsonContentType ) writer := decorateWriter ( r , w ) if closer , ok := writer . ( io . Closer ) ; ok { defer closer . Close ( ) } registry . dumpToWriter ( writer ) } else { w . WriteHeader ( http . StatusNotFound ) InstrumentCall ( instrumentable , requestLatencyAccumulator )", "commit_type": "remove"}
{"commit_tokens": ["changed", "and", "added", "component", "creation", "function", "name"], "add_tokens": "return ConstructComponent ( MakeBlueprintName ( b ) , bind , vs , func ( v Views ) trees . SearchableMarkup { // ConstructComponent returns a new Component using the underline TreeView derivative, if `dobind` is true then it binds the reactive binding with the view. The blueprint's dom tree is cloned func ConstructComponent ( name string , bind interface { } , vs Strategy , mx TreeMux , dobind bool ) Components { // CreateComponent returns a new component with the default strategy used but allows customization on the other arguments func CreateComponent ( name string , bind interface { } , mx TreeMux , dobind bool ) Components { return ConstructComponent ( name , bind , nil , mx , dobind ) }", "del_tokens": "return CreateComponent ( MakeBlueprintName ( b ) , bind , vs , func ( v Views ) trees . SearchableMarkup { // CreateComponent returns a new Component using the underline TreeView derivative, if `dobind` is true then it binds the reactive binding with the view. The blueprint's dom tree is cloned func CreateComponent ( name string , bind interface { } , vs Strategy , mx TreeMux , dobind bool ) Components {", "commit_type": "change"}
{"commit_tokens": ["Move", "ParseURL", "helper", "to", "Client"], "add_tokens": "return c . Client . ParseURL ( urlStr )", "del_tokens": "\" \" u , err := url . Parse ( urlStr ) if err != nil { return nil , err } host := strings . Split ( u . Host , \" \" ) if host [ 0 ] == \" \" { host [ 0 ] = strings . Split ( c . Client . URL ( ) . Host , \" \" ) [ 0 ] u . Host = strings . Join ( host , \" \" ) } return u , nil", "commit_type": "move"}
{"commit_tokens": ["Add", "systemd", "-", "cgroup", "support"], "add_tokens": "Command string Root string Debug bool Log string LogFormat Format PdeathSignal syscall . Signal Criu string SystemdCgroup string if r . SystemdCgroup != \" \" { out = append ( out , \" \" , r . SystemdCgroup ) }", "del_tokens": "Command string Root string Debug bool Log string LogFormat Format PdeathSignal syscall . Signal Criu string", "commit_type": "add"}
{"commit_tokens": ["Add", "--", "file", "-", "layer", "type", "to", "diff", "layers", "of", "images"], "add_tokens": "if err := validateArgs ( args , checkDiffArgNum , checkIfValidAnalyzer , checkFilenameFlag ) ; err != nil {", "del_tokens": "var layers bool if err := validateArgs ( args , checkDiffArgNum , checkIfValidAnalyzer , checkFilenameFlag , checkLayersFlag ) ; err != nil { func checkLayersFlag ( _ [ ] string ) error { if layers { for _ , t := range types { if t == \" \" { return nil } } return errors . New ( \" \" ) } return nil } if layers { if err := diffLayers ( imageMap [ image1Arg ] , imageMap [ image2Arg ] ) ; err != nil { return err } } diffCmd . Flags ( ) . BoolVarP ( & layers , \" \" , \" \" , false , \" \" )", "commit_type": "add"}
{"commit_tokens": ["fixing", "sigma", "calc", "on", "empty", "period", "."], "add_tokens": "return 2.0 / ( float64 ( ema . GetPeriod ( ) ) + 1 )", "del_tokens": "return 2.0 / ( float64 ( ema . Period ) + 1 )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "WaitGroup", "instead", "of", "channels", ":", "faster"], "add_tokens": "wg := sync . WaitGroup { } wg . Done ( ) wg . Add ( 1 ) wg . Wait ( )", "del_tokens": "results := make ( chan bool , lx ) results <- true workers_spawned := 0 workers_spawned ++ for n := 0 ; n < workers_spawned ; n ++ { <- results }", "commit_type": "use"}
{"commit_tokens": ["Improved", "the", "specification", "s", "language"], "add_tokens": "c . Specify ( \" \" , func ( ) { c . Specify ( \" \" , func ( ) {", "del_tokens": "c . Specify ( \" \" , func ( ) { c . Specify ( \" \" , func ( ) {", "commit_type": "improve"}
{"commit_tokens": ["Add", "handler", "func", "when", "registering", "new", "job", "types"], "add_tokens": "jobType , err := RegisterJobType ( jobTypeName , func ( ) { } )", "del_tokens": "jobType , err := RegisterJobType ( jobTypeName )", "commit_type": "add"}
{"commit_tokens": ["Remove", "dependency", "on", "errors", "package"], "add_tokens": "panic ( \" \" ) panic ( \" \" ) panic ( \" \" )", "del_tokens": "import \" \" panic ( errors . New ( \" \" ) ) panic ( errors . New ( \" \" ) ) panic ( errors . New ( \" \" ) )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "fallback", "logic", "for", "failed", "URLs"], "add_tokens": "if ( err == nil && postString != \" \" ) || act . FallbackAction == nil {", "del_tokens": "if err != nil || postString != \" \" || act . FallbackAction == nil {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "mutex", "for", "call", "args"], "add_tokens": "{ { if $ method . HasParams } } callArgs [ ] * { { $ mock } } { { $ method . Name } } Params mutex sync . RWMutex { { end } } // Record call args m . { { $ method . Name } } Mock . mutex . Lock ( ) m . { { $ method . Name } } Mock . mutex . Unlock ( ) m . mutex . RLock ( ) argCopy := make ( [ ] * { { $ mock } } { { $ method . Name } } Params , len ( m . callArgs ) ) copy ( argCopy , m . callArgs ) m . mutex . RUnlock ( ) return argCopy", "del_tokens": "{ { if $ method . HasParams } } callArgs [ ] * { { $ mock } } { { $ method . Name } } Params { { end } } // Record call args return m . callArgs", "commit_type": "add"}
{"commit_tokens": ["added", "basic", "persitant", "for", "brands", ";", "general", "fragments"], "add_tokens": "name string log . Println ( spew . Sdump ( \" \" ) ) service . name = \" \" f , err := os . OpenFile ( fmt . Sprintf ( \" \" , base_path , self . name , self . Id ) , os . O_RDWR | os . O_CREATE | os . O_APPEND , 0666 ) service . Index . Shutdown ( )", "del_tokens": "name string log . Println ( spew . Sdump ( \" \" ) service . name = \" \" f , err := os . OpenFile ( fmt . Sprintf ( \" \" , base_path , self . name , self . Id ) , os . O_RDWR | os . O_CREATE | os . O_APPEND , 0666 )", "commit_type": "add"}
{"commit_tokens": ["Add", "mount", "/", "unmount", "calls"], "add_tokens": "func ( self * awsProvider ) Attach ( volInfo api . VolumeID ) ( string , error ) { func ( self * awsProvider ) Mount ( volumeID api . VolumeID , mountpath string ) error { return nil } func ( self * awsProvider ) Unmount ( volumeID api . VolumeID , mountpath string ) error { return nil }", "del_tokens": "func ( self * awsProvider ) Attach ( volInfo api . VolumeID , path string ) ( string , error ) {", "commit_type": "add"}
{"commit_tokens": ["added", "basic", "authenitcation", "in", "memory", "and", "postgres", "with", "commands", "in", "the", "api"], "add_tokens": "func NewPostgresAuthenticator ( user , database , address string ) ( postgresql , error ) {", "del_tokens": "func NewPostgreAuthenticator ( user , database , address string ) ( postgresql , error ) {", "commit_type": "add"}
{"commit_tokens": ["Improve", "the", "array", "print", "code", "."], "add_tokens": "for i , role := range r . roles { if i == 0 { names += role . name } else { names += \" \" + role . name }", "del_tokens": "for _ , role := range r . roles { names += role . name + \" \"", "commit_type": "improve"}
{"commit_tokens": ["CREATE", "TABLE", "and", "DROP", "TABLE", "statements"], "add_tokens": "Column ( \" \" , String { Length : 32 , NotNull : true } ) ,", "del_tokens": "Column ( \" \" , String { \" \" : 32 } ) ,", "commit_type": "create"}
{"commit_tokens": ["Implementing", "Contains", "in", "store", "and", "RDFGraph"], "add_tokens": "import \" \" func ( t * triple ) key ( ) string { return fmt . Sprintf ( \" \" , t . sub , t . pred , t . obj . key ( ) ) } default : otherT , ok := other . ( * triple ) if ! ok { return false } return t . key ( ) == otherT . key ( ) func ( o object ) key ( ) string { if o . isLit { return fmt . Sprintf ( \" \\\" \\\" \" , o . lit . val , o . lit . typ ) } return fmt . Sprintf ( \" \" , o . resourceID ) }", "del_tokens": "case t . Subject ( ) != other . Subject ( ) : return false case t . Predicate ( ) != other . Predicate ( ) : return false return t . Object ( ) . Equal ( other . Object ( ) )", "commit_type": "implement"}
{"commit_tokens": ["Add", "more", "examples", "and", "documentation"], "add_tokens": "// Username for use in HTTP Basic Auth ID string // Password for use in HTTP Basic Auth Token string // HTTP Client to use for making requests // The base URL for all requests to this API, for example, // \"https://fax.twilio.com/v1\" Base string // the server. Defaults to FormURLEncoded. // from the server. Defaults to rest.DefaultErrorParser.", "del_tokens": "ID string Token string Base string // the server. // from the server.", "commit_type": "add"}
{"commit_tokens": ["add", "name", "url", "param", "to", "containers", "/", "create", "(", "breaks", "API", ")"], "add_tokens": "func ( dh * DockerHost ) CreateContainer ( imageName string , options * docker . ContainerConfig , name string ) ( containerId string , e error ) { u := dh . url ( ) + \" \" if name != \" \" { u += \" \" + ( url . Values { \" \" : [ ] string { name } } ) . Encode ( ) } content , _ , e := dh . postJSON ( u , options , container )", "del_tokens": "func ( dh * DockerHost ) CreateContainer ( imageName string , options * docker . ContainerConfig ) ( containerId string , e error ) { content , _ , e := dh . postJSON ( dh . url ( ) + \" \" , options , container )", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "callback", "functon", "to", "perform", "PostPluginit", "()", "once", "all", "plugins", "are"], "add_tokens": "log . Fatalf ( \" \" , err ) log . Fatalf ( \" \" , r . StatusCode )", "del_tokens": "log . Fatalf ( \" \" , err ) log . Fatalf ( \" \" , r . StatusCode )", "commit_type": "use"}
{"commit_tokens": ["Change", "example", "usage", "to", "tutorial"], "add_tokens": "// Tutorial // The Basics example shows how to build a plain graph and how to // efficiently use the Visit iterator, the key abstraction of this package. // // The DFS example contains a full implementation of depth-first search.", "del_tokens": "// Example usage // The package examples show how to build plain graphs and how to efficiently // use the Visit iterator, the vital abstraction of this package.", "commit_type": "change"}
{"commit_tokens": ["Remove", "pointer", "methods", "where", "not", "needed"], "add_tokens": "func ( v Version ) String ( ) string { func ( v Version ) MarshalJSON ( ) ( [ ] byte , error ) { func ( v Version ) LessThan ( versionB Version ) bool { versionA := v func ( v Version ) Slice ( ) [ ] int64 { func ( p PreRelease ) Slice ( ) [ ] string { preRelease := string ( p )", "del_tokens": "func ( v * Version ) String ( ) string { func ( v * Version ) MarshalJSON ( ) ( [ ] byte , error ) { func ( v * Version ) LessThan ( versionB Version ) bool { versionA := * v func ( v * Version ) Slice ( ) [ ] int64 { func ( p * PreRelease ) Slice ( ) [ ] string { preRelease := string ( * p )", "commit_type": "remove"}
{"commit_tokens": ["Adds", "cache", "pressure", "in", "logger"], "add_tokens": "logger . Printf ( \" \\n \" , c . Engine . CacheStress ( ) * 100 ,", "del_tokens": "logger . Printf ( \" \\n \" ,", "commit_type": "add"}
{"commit_tokens": ["allow", "public", "clients", "to", "revoke", "tokens", "with", "just", "an", "ID"], "add_tokens": "// Enforce client authentication for confidential clients if ! client . IsPublic ( ) { if err := f . Hasher . Compare ( client . GetHashedSecret ( ) , [ ] byte ( clientSecret ) ) ; err != nil { return errors . Wrap ( ErrInvalidClient , err . Error ( ) ) }", "del_tokens": "// Enforce client authentication if err := f . Hasher . Compare ( client . GetHashedSecret ( ) , [ ] byte ( clientSecret ) ) ; err != nil { return errors . Wrap ( ErrInvalidClient , err . Error ( ) )", "commit_type": "allow"}
{"commit_tokens": ["add", "stack", "trace", "while", "panic"], "add_tokens": "\" \" \" \" \" \" var buffer bytes . Buffer buffer . WriteString ( fmt . Sprintf ( \" \\r \\n \" , r ) ) for i := 1 ; ; i += 1 { _ , file , line , ok := runtime . Caller ( i ) if ! ok { break } buffer . WriteString ( fmt . Sprintf ( \" \\r \\n \" , file , line ) ) } log . Println ( buffer . String ( ) ) httpWriter . Write ( buffer . Bytes ( ) )", "del_tokens": "log . Println ( \" \" , r )", "commit_type": "add"}
{"commit_tokens": ["Add", "locking", "around", "global", "time", "functions", "."], "add_tokens": "// Copyright 2014 Google Inc. All rights reserved. \" \" mu sync . Mutex defer mu . Unlock ( ) mu . Lock ( ) return getTime ( ) } func getTime ( ) ( Time , error ) { setClockSequence ( - 1 ) defer mu . Unlock ( ) mu . Lock ( ) return clockSequence ( ) } func clockSequence ( ) int { setClockSequence ( - 1 ) defer mu . Unlock ( ) mu . Lock ( ) setClockSequence ( seq ) } func setClockSequence ( seq int ) {", "del_tokens": "// Copyright 2011 Google Inc. All rights reserved. SetClockSequence ( - 1 ) SetClockSequence ( - 1 )", "commit_type": "add"}
{"commit_tokens": ["fixed", "-", "+", "UTF", "digit", "errors"], "add_tokens": "if strings . IndexAny ( str , \" \" ) > 0 { return false } if len ( str ) > 1 { str = strings . TrimPrefix ( str , \" \" ) str = strings . TrimPrefix ( str , \" \" ) } if unicode . IsNumber ( c ) == false { //numbers && minus sign are ok if strings . IndexAny ( str , \" \" ) > 0 { return false } if len ( str ) > 1 { str = strings . TrimPrefix ( str , \" \" ) str = strings . TrimPrefix ( str , \" \" ) } if ! unicode . IsDigit ( c ) { //digits && minus sign are ok", "del_tokens": "if unicode . IsNumber ( c ) == false && c != '-' { //numbers && minus sign are ok if ! unicode . IsDigit ( c ) && c != '-' { //digits && minus sign are ok", "commit_type": "fix"}
{"commit_tokens": ["made", "low", "level", "code", "method", "-", "agnostic"], "add_tokens": "return c . httpDo ( \" \" , url + queryParams , authParams ) resp , err := c . httpDo ( \" \" , url , oauthParams ) func ( c * Consumer ) httpDo ( method string , url string , oauthParams * OrderedParams ) ( * http . Response , os . Error ) { fmt . Println ( \" \" + method + \" \" + url ) req . Method = method", "del_tokens": "return c . get ( url + queryParams , authParams ) resp , err := c . get ( url , oauthParams ) func ( c * Consumer ) get ( url string , oauthParams * OrderedParams ) ( * http . Response , os . Error ) { fmt . Println ( \" \" + url ) req . Method = \" \"", "commit_type": "make"}
{"commit_tokens": ["Fix", "usage", "of", "uuid", ".", "NewV1", "()"], "add_tokens": "uid , err := uuid . NewV1 ( ) if err != nil { panic ( err ) } skt := \" \" + uid . String ( )", "del_tokens": "uid := uuid . NewV1 ( ) . String ( ) skt := \" \" + uid", "commit_type": "fix"}
{"commit_tokens": ["Fix", "osx", "imports", "and", "build"], "add_tokens": "// +build !windows,!linux,!netgo,!android", "del_tokens": "\" \" \" \" _ \" \" \" \" \" \" \" \" \" \"", "commit_type": "fix"}
{"commit_tokens": ["Implement", "node", ".", "slice", "()", "and", "fix", "a", "few", "things", "."], "add_tokens": "func ( l leaf ) depth ( ) depthT { return 0 } // Precondition: start < end func ( l leaf ) slice ( start , end int64 ) node { if start < 0 { start = 0 } if end > int64 ( len ( l ) ) { end = int64 ( len ( l ) ) } // The precondition may have been destroyed by above fixes. if start >= end { // Don't hold a 0-length substring, let the GC have it. return emptyNode } return l [ start : end ] }", "del_tokens": "func ( l leaf ) depth ( ) int { return 0 }", "commit_type": "implement"}
{"commit_tokens": ["Fix", "sizes", "affected", "by", "encoding"], "add_tokens": "nullLength := encodedbytes . EncodingNullLengthForIndex ( f . encoding ) f . size += uint32 ( len ( desc ) + nullLength ) newNullLength := encodedbytes . EncodingNullLengthForIndex ( i ) oldNullLength := encodedbytes . EncodingNullLengthForIndex ( f . encoding ) nullDiff := newNullLength - oldNullLength f . changeSize ( descDiff + nullDiff + textDiff )", "del_tokens": "f . size += uint32 ( len ( desc ) ) f . changeSize ( descDiff + textDiff ) // add null length for this encoding f . size += uint32 ( encodedbytes . EncodingNullLengthForIndex ( f . encoding ) ) func ( f * UnsynchTextFrame ) SetEncoding ( encoding string ) error { prevIndex := f . encoding err := f . DescTextFrame . SetEncoding ( encoding ) if err != nil { return err } n1 := encodedbytes . EncodingNullLengthForIndex ( prevIndex ) n2 := encodedbytes . EncodingNullLengthForIndex ( f . encoding ) f . changeSize ( n2 - n1 ) return nil }", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "sliding", "window", "to", "track", "failures", "/", "successes"], "add_tokens": "counts * window return & Breaker { BackOff : b , nextBackOff : b . NextBackOff ( ) , counts : NewWindow ( DefaultWindowTime , DefaultWindowBuckets ) , } cb . counts . Reset ( ) return cb . counts . Failures ( ) return cb . counts . Successes ( ) cb . counts . Fail ( ) cb . counts . Success ( ) return cb . counts . ErrorRate ( )", "del_tokens": "failures int64 successes int64 return & Breaker { BackOff : b , nextBackOff : b . NextBackOff ( ) } atomic . StoreInt64 ( & cb . failures , 0 ) atomic . StoreInt64 ( & cb . successes , 0 ) return atomic . LoadInt64 ( & cb . failures ) return atomic . LoadInt64 ( & cb . successes ) atomic . AddInt64 ( & cb . failures , 1 ) atomic . AddInt64 ( & cb . successes , 1 ) failures := float64 ( cb . Failures ( ) ) successes := float64 ( cb . Successes ( ) ) total := failures + successes if total == 0.0 { return 0.0 } return failures / total", "commit_type": "use"}
{"commit_tokens": ["Add", "more", "URL", "parameters", "and", "add", "another", "test", "case"], "add_tokens": "body , err := c . httpGetAndCheckResponseReadBody ( cx , youtubeBaseURL + \" \" + id + \" \" )", "del_tokens": "body , err := c . httpGetAndCheckResponseReadBody ( cx , youtubeBaseURL + \" \" + id )", "commit_type": "add"}
{"commit_tokens": ["Remove", "syslog", "dep", "and", "write", "some", "more", "tests"], "add_tokens": "import \" \" // SyslogWriter is an interface matching a syslog.Writer struct. type SyslogWriter interface { io . Writer Debug ( m string ) error Info ( m string ) error Warning ( m string ) error Err ( m string ) error Emerg ( m string ) error Crit ( m string ) error } w SyslogWriter // SyslogLevelWriter wraps a SyslogWriter and call the right syslog level // method matching the zerolog level. func SyslogLevelWriter ( w SyslogWriter ) LevelWriter {", "del_tokens": "import ( \" \" ) w * syslog . Writer // SyslogWriter wraps a syslog.Writer and set the right syslog level // matching the log even level. func SyslogWriter ( w * syslog . Writer ) LevelWriter {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "doc", ".", "go", "styling"], "add_tokens": "// // //", "del_tokens": "//", "commit_type": "fix"}
{"commit_tokens": ["Move", "tty", "into", "container", ".", "json"], "add_tokens": "func Exec ( container * libcontainer . Container , args [ ] string ) ( int , error ) { if container . Tty { if ! container . Tty { if container . Tty {", "del_tokens": "func Exec ( container * libcontainer . Container , tty bool , args [ ] string ) ( int , error ) { if tty { if ! tty { if tty {", "commit_type": "move"}
{"commit_tokens": ["Add", "handling", "errors", "in", "encoding", "."], "add_tokens": "t . Errorf ( \" \" , file , err ) / * * / t . Skip ( \" \" )", "del_tokens": "t . Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["fix", "sam", "stream", "options", "it", "s", "not", "OPTION", "=", "i2cp", ".", "option", "=", "value", "it", "s", "i2cp", ".", "option", "=", "value"], "add_tokens": "optStr += opt + \" \"", "del_tokens": "optStr += \" \" + opt + \" \"", "commit_type": "fix"}
{"commit_tokens": ["fixed", "a", "bug", "with", "gomap"], "add_tokens": "p := unsafe . Pointer ( & b [ 0 ] )", "del_tokens": "p := unsafe . Pointer ( & b )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "IoOptimized", "field", "type"], "add_tokens": "IoOptimized IoOptimized", "del_tokens": "IoOptimized bool", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "that", "had", "bad", "content", "types"], "add_tokens": "ciphertext0Hex = \" \" ciphertext1Hex = \" \" ciphertext2Hex = \" \"", "del_tokens": "ciphertext0Hex = \" \" ciphertext1Hex = \" \" ciphertext2Hex = \" \"", "commit_type": "fix"}
{"commit_tokens": ["implemented", "grant", "callback", "and", "proper", "scope", "support"], "add_tokens": "var model Model // get owner from context model = ctx . Value ( \" \" ) . ( Model ) // check secret err := bcrypt . CompareHashAndPassword ( model . Attribute ( s . ownerSecretAttr . name ) . ( [ ] byte ) , [ ] byte ( secret ) ) if err != nil { return fosite . ErrNotFound } return nil } func ( s * authenticatorStorage ) getOwner ( id string ) ( Model , error ) { return nil , err return Init ( obj . ( Model ) ) , nil", "del_tokens": "return err owner := Init ( obj . ( Model ) ) // check secret err = bcrypt . CompareHashAndPassword ( owner . Attribute ( s . ownerSecretAttr . name ) . ( [ ] byte ) , [ ] byte ( secret ) ) if err != nil { return fosite . ErrNotFound } return nil", "commit_type": "implement"}
{"commit_tokens": ["Add", "-", "h", "as", "the", "short", "form", "of", "the", "help", "/", "usage", "menu", "to", "fall", "in", "line", "with", "most", "people", "s", "expectations", "of", "a", "help", "menu", "flag"], "add_tokens": "addOpt ( opt { [ ] string { \" \" , \" \" } , \" \" , \" \" , false , nil ,", "del_tokens": "addOpt ( opt { [ ] string { \" \" } , \" \" , \" \" , false , nil ,", "commit_type": "add"}
{"commit_tokens": ["use", "io", ".", "Writer", "instead", "of", "bufio", "in", "WriteOptions"], "add_tokens": "import \" \" var ( comma = [ ] byte { ',' } equality = [ ] byte { '=' } semicolon = [ ] byte { ';' } quote = [ ] byte { '\"' } escape = [ ] byte { '\\\\' } ) func WriteOptions ( dest io . Writer , options [ ] Option ) { dest . Write ( comma ) dest . Write ( semicolon ) dest . Write ( equality ) func writeTokenSanitized ( bw io . Writer , bts [ ] byte ) { bw . Write ( quote ) bw . Write ( quote ) bw . Write ( escape ) bw . Write ( bts [ i : i + 1 ] ) bw . Write ( quote )", "del_tokens": "import \" \" func WriteOptions ( dest * bufio . Writer , options [ ] Option ) { dest . WriteByte ( ',' ) dest . WriteByte ( ';' ) dest . WriteByte ( '=' ) func writeTokenSanitized ( bw * bufio . Writer , bts [ ] byte ) { bw . WriteByte ( '\"' ) bw . WriteByte ( '\"' ) bw . WriteByte ( '\\\\' ) bw . WriteByte ( c ) bw . WriteByte ( '\"' )", "commit_type": "use"}
{"commit_tokens": ["Fix", "instantiate", "chaincode", "test", "case"], "add_tokens": "transactionProposalResponse , txID , err := chain . SendInstantiateProposal ( chainCodeID , chainID , args , chainCodePath , chainCodeVersion , [ ] fabricClient . Peer { chain . GetPrimaryPeer ( ) } )", "del_tokens": "transactionProposalResponse , txID , err := chain . SendInstantiateProposal ( chainCodeID , chainID , args , chainCodePath , chainCodeVersion , nil )", "commit_type": "fix"}
{"commit_tokens": ["Make", "go", "routines", "in", "RunContainer", "safer", "when", "attaching", "to", "container"], "add_tokens": "defer wg . Done ( ) if err := d . client . AttachToContainer ( attachOpts ) ; err != nil { glog . Errorf ( \" \" , attachOpts ) } defer wg . Done ( ) if err := d . client . AttachToContainer ( attachOpts2 ) ; err != nil { glog . Errorf ( \" \" , attachOpts2 ) }", "del_tokens": "d . client . AttachToContainer ( attachOpts ) wg . Done ( ) d . client . AttachToContainer ( attachOpts2 ) wg . Done ( )", "commit_type": "make"}
{"commit_tokens": ["fix", "nil", "if", "no", "mutual", "tls"], "add_tokens": "tlsConfig := & tls . Config { }", "del_tokens": "var tlsConf * tls . Config", "commit_type": "fix"}
{"commit_tokens": ["Use", "russross", "version", "of", "blackfriday", "not", "fork"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Use", "--", "first", "-", "parent", "in", "git", "describe", "calls"], "add_tokens": "result , err := trimmedCombinedGitCmdOutput ( gitDir , \" \" , \" \" , \" \" ) return trimmedCombinedGitCmdOutput ( gitDir , \" \" , \" \" , \" \" , \" \" )", "del_tokens": "result , err := trimmedCombinedGitCmdOutput ( gitDir , \" \" , \" \" ) return trimmedCombinedGitCmdOutput ( gitDir , \" \" , \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["fix", "string", "formatting", "in", "test"], "add_tokens": "t . Fatalf ( \" \" , result )", "del_tokens": "t . Fatalf ( \" \" , result )", "commit_type": "fix"}
{"commit_tokens": ["Use", "validVarDeclType", "instead", "of", "validVarType", "and", "delete", "validVarType"], "add_tokens": "if e := f . validVarDeclType ( typ ) ; e != nil { return f . validParamType ( typ . Elem ( ) ) return f . validParamType ( typ . Elem ( ) ) return f . validParamType ( typ . Elem ( ) )", "del_tokens": "if e := f . validVarType ( typ ) ; e != nil { return f . validVarType ( typ . Elem ( ) ) return f . validVarType ( typ . Elem ( ) ) } } return nil } func ( f * File ) validVarType ( typ types . Type ) * Error { if e := f . validVarDeclType ( typ ) ; e != nil { switch typ . ( type ) { default : return e return f . validVarType ( typ . Elem ( ) )", "commit_type": "use"}
{"commit_tokens": ["add", "missing", "url", ".", "QueryEscape", "to", "exchange", "and", "queue"], "add_tokens": "req , err := newGETRequest ( c , \" \" + url . QueryEscape ( vhost ) + \" \" + url . QueryEscape ( exchange ) )", "del_tokens": "req , err := newGETRequest ( c , \" \" + url . QueryEscape ( vhost ) + \" \" + exchange )", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "dht", ".", "NewServer", "and", "change", "StopServing", "to", "Close"], "add_tokens": "if c == nil { c = & ServerConfig { } } err := s . serve ( ) select { case <- s . closed : return default : } if err != nil { panic ( err ) } func ( s * Server ) Close ( ) { s . socket . Close ( )", "del_tokens": "panic ( s . serve ( ) ) func ( s * Server ) StopServing ( ) { s . socket . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "file", "/", "upload", "reply", "check", "condition"], "add_tokens": "// Duplicate updates will get different replies // request: CIS_CentOS_7_Server_L1_v3.0.0.audit // reply: {FileUploaded:CIS_CentOS_7_Server_L1_v3.0.0-6.audit} if 0 == len ( reply . FileUploaded ) { return fmt . Errorf ( \" \" , reply )", "del_tokens": "\" \" if reply . FileUploaded != filepath . Base ( filePath ) { return errors . New ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "buffered", "channels", "for", "new", "connections", "."], "add_tokens": "con = & connection { self , make ( chan * db . Message , 100 ) , make ( chan * db . Message , 100 ) , nil , env . host } con := & connection { self , make ( chan * db . Message , 100 ) , make ( chan * db . Message , 100 ) , conn , nil }", "del_tokens": "con = & connection { self , make ( chan * db . Message ) , make ( chan * db . Message ) , nil , env . host } con := & connection { self , make ( chan * db . Message ) , make ( chan * db . Message ) , conn , nil }", "commit_type": "use"}
{"commit_tokens": ["Remove", "UUID", "lib", "&&", "use", "pseudo", "-", "random", "IDs", "instead"], "add_tokens": "to . fields . set ( k , merged . cpy ( ctx ) ) to . fields . setAt ( i , parent , merged . cpy ( ctx ) ) return newRef ( ctx , opts . meta , p ) , nil return newSplice ( ctx , opts . meta , varexp ) , nil", "del_tokens": "val , e := merged . cpy ( ctx ) if e != nil { return raiseIDGeneration ( ctx , opts . meta , e ) } to . fields . set ( k , val ) val , e := merged . cpy ( ctx ) if e != nil { return raiseIDGeneration ( ctx , opts . meta , e ) } to . fields . setAt ( i , parent , val ) val , err := newRef ( ctx , opts . meta , p ) if err != nil { return nil , raiseIDGeneration ( ctx , opts . meta , err ) } return val , nil val , err := newSplice ( ctx , opts . meta , varexp ) if err != nil { return nil , raiseIDGeneration ( ctx , opts . meta , err ) } return val , nil", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "multiple", "peer", "addresses"], "add_tokens": "var peerAddr = flag . String ( \" \" , \" \" , \" \" ) n , err := list . Join ( strings . Split ( * peerAddr , \" \" ) )", "del_tokens": "var peerAddr = flag . String ( \" \" , \" \" , \" \" ) n , err := list . Join ( [ ] string { * peerAddr } )", "commit_type": "add"}
{"commit_tokens": ["Added", "setgray", "for", "strokes", "and", "fills", ".", "It", "takes", "a", "single", "float64", "of", "the", "gray", "scale"], "add_tokens": "// Set the grayscale fills", "del_tokens": "// Set the grayscale fill", "commit_type": "add"}
{"commit_tokens": ["Move", "auth", "files", "back", "to", "shimmie", "package"], "add_tokens": "package shimmie // Auth is a handler wrapper that checks if a user is authenticated to Shimmie. func ( shim * Shimmie ) Auth ( ctx context . Context , fn func ( context . Context , http . ResponseWriter , * http . Request ) , redirectURL string ) http . HandlerFunc { user , err := shim . Store . GetUser ( username )", "del_tokens": "package auth \" \" // Handler is a handler wrapper that checks if a user is authenticated to Shimmie. func Handler ( ctx context . Context , fn func ( context . Context , http . ResponseWriter , * http . Request ) , redirectURL string ) http . HandlerFunc { user , err := store . GetUser ( ctx , username )", "commit_type": "move"}
{"commit_tokens": ["updated", "use", "of", "args", ".", "GetArgsN"], "add_tokens": "parts := args . GetArgsN ( line , 2 ) // [ condition, body ] if len ( parts ) != 2 { fmt . Println ( \" \" ) return } res , err := cmd . evalConditional ( parts [ 0 ] ) trueBlock , falseBlock , err := cmd . readBlock ( parts [ 1 ] , \" \" )", "del_tokens": "cond , body := args . GetArgsN ( line , 1 ) res , err := cmd . evalConditional ( cond [ 0 ] ) trueBlock , falseBlock , err := cmd . readBlock ( body , \" \" )", "commit_type": "update"}
{"commit_tokens": ["make", "life", "a", "little", "easier"], "add_tokens": "section := config . NewNamedSection ( name ) settings := config . NewAnonymousSection ( )", "del_tokens": "section := config . SectionValue { Name : name , Value : make ( map [ string ] config . ConfigValue ) , Comments : make ( [ ] string , 0 ) , } settings := config . SectionValue { Value : make ( map [ string ] config . ConfigValue ) , Comments : make ( [ ] string , 0 ) , }", "commit_type": "make"}
{"commit_tokens": ["removed", "unnecessary", "logs", "errors", "should", "be", "handled", "by", "the", "app"], "add_tokens": "Err . Log ( err )", "del_tokens": "// Log error Err . Log ( \" \" , \" \" , err ) // Stay idle for 2 seconds // time.Sleep(1000 * 1000 * 2) // Start server again // This is not a graceful restart, since all the clients connected to the server will be disconnected // Graceful restart of the server should be implemented. print ( \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Use", "tabwriter", "to", "print", "usage"], "add_tokens": "\" \" \" \" w := tabwriter . NewWriter ( os . Stdout , 0 , 0 , 3 , ' ' , 0 ) fmt . Fprintln ( w , \" \" + name + \" \\t \" + child . Desc ) w . Flush ( )", "del_tokens": "fmt . Println ( \" \" + name + \" \\r \\t \\t \" + child . Desc )", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "newline", "to", "the", "error", "output"], "add_tokens": "fmt . Println ( message )", "del_tokens": "fmt . Print ( message )", "commit_type": "add"}
{"commit_tokens": ["Fix", "ordering", "bugs", "in", "db"], "add_tokens": "var txn spvwallet . Txn if err != nil { return nil , txn , err } defer rows . Close ( )", "del_tokens": "var txn spvwallet . Txn defer rows . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "remove", "copied", "format", "tests", "and", "stubs"], "add_tokens": "* h = append ( ( * h ) [ : index ] , ( * h ) [ index + 1 : ] ... ) func ( h * Hostlist ) RemoveIpv4Domain ( domain string ) { h . Remove ( h . IndexOfDomainIpv4 ( domain ) ) func ( h * Hostlist ) RemoveIpv6Domain ( domain string ) { h . Remove ( h . IndexOfDomainIpv6 ( domain ) ) func ( h * Hostlist ) Sort ( ) { } // Format takes the current list of Hostnames in this Hostfile and turns it // into a string suitable for use as an /etc/hosts file. // Sorting uses the following logic: // 1. List is sorted by IP address // 2. Commented items are left in place // 3. 127.* appears at the top of the list (so boot resolvers don't break) // 4. When present, localhost will always appear first in the domain list func ( h * Hostlist ) Format ( ) string { out := \" \" for _ , hostname := range * h { out += hostname . Format ( ) + \" \\n \" } return out }", "del_tokens": "// var a *Hostlist // copy(a, h[0:index]) // a = append(a, *h[index:]) // *h[index] = nil // // return a func ( h * Hostlist ) RemoveIpv4 ( domain string ) { func ( h * Hostlist ) RemoveIpv6 ( ) {", "commit_type": "implement"}
{"commit_tokens": ["Added", "attachment", "as", "option", "in", "Context", ".", "File", "function"], "add_tokens": "\" \" // File sends a response with the content of the file. If attachment is true, the // client is prompted to save the file. func ( c * Context ) File ( name string , attachment bool ) error { dir , file := path . Split ( name ) if attachment { c . response . Header ( ) . Set ( ContentDisposition , \" \" + file ) return serveFile ( dir , file , c )", "del_tokens": "\" \" \" \" // File sends a file as attachment. func ( c * Context ) File ( name string ) error { file , err := os . Open ( name ) if err != nil { return err fi , _ := file . Stat ( ) c . response . Header ( ) . Set ( ContentDisposition , \" \" + fi . Name ( ) ) _ , err = io . Copy ( c . response , file ) return err", "commit_type": "add"}
{"commit_tokens": ["Add", "rfcs", "as", "an", "alias", "for", "rfc", "."], "add_tokens": "case \" \" , \" \" : rfcs := strings . Split ( selectorParam , \" \" ) case \" \" , \" \" : rfcs := strings . Split ( selectorParam , \" \" ) if err != nil {", "del_tokens": "case \" \" : rfcs := strings . Split ( selectorParam , \" \" ) case \" \" : rfcs := strings . Split ( selectorParam , \" \" ) if err == nil {", "commit_type": "add"}
{"commit_tokens": ["Improve", "AppAuth", "example", "in", "README", "godoc", "and", "examples"], "add_tokens": "\" \" flags := struct { consumerKey string consumerSecret string } { } flag . StringVar ( & flags . consumerKey , \" \" , \" \" , \" \" ) flag . StringVar ( & flags . consumerSecret , \" \" , \" \" , \" \" ) flag . Parse ( ) flagutil . SetFlagsFromEnv ( flag . CommandLine , \" \" ) if flags . consumerKey == \" \" || flags . consumerSecret == \" \" { // oauth2 configures a client that uses app credentials to keep a fresh token config := & clientcredentials . Config { ClientID : flags . consumerKey , ClientSecret : flags . consumerSecret , TokenURL : \" \" , } // http.Client will automatically authorize Requests httpClient := config . Client ( oauth2 . NoContext )", "del_tokens": "\" \" flags := flag . NewFlagSet ( \" \" , flag . ExitOnError ) accessToken := flags . String ( \" \" , \" \" , \" \" ) flags . Parse ( os . Args [ 1 : ] ) flagutil . SetFlagsFromEnv ( flags , \" \" ) if * accessToken == \" \" { config := & oauth2 . Config { } token := & oauth2 . Token { AccessToken : * accessToken } // OAuth2 http.Client will automatically authorize Requests httpClient := config . Client ( oauth2 . NoContext , token )", "commit_type": "improve"}
{"commit_tokens": ["Added", "query", "and", "more", "tests"], "add_tokens": "func patch ( path string , payload url . Values , body , out interface { } ) error { return request ( \" \" , path , payload , body , out )", "del_tokens": "func patch ( path string , payload url . Values , body interface { } ) error { return request ( \" \" , path , payload , body , nil )", "commit_type": "add"}
{"commit_tokens": ["fix", "version", "check", "on", "dependencies"], "add_tokens": "if version != \" \" && utils . Version ( dep . Version ( ) ) . LessThan ( utils . Version ( version ) ) {", "del_tokens": "if version != \" \" && utils . Version ( cnt . manifest . From . Version ( ) ) . LessThan ( utils . Version ( version ) ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "nil", "checks", "to", "Union", "Intersect", "Except"], "add_tokens": "if in == nil { r . err = ErrNilInput return } if in == nil { r . err = ErrNilInput return } func ( q queryable ) Except ( in [ ] interface { } ) ( r queryable ) { if in == nil { r . err = ErrNilInput return } for _ , v := range in {", "del_tokens": "func ( q queryable ) Except ( except [ ] interface { } ) ( r queryable ) { for _ , v := range except {", "commit_type": "add"}
{"commit_tokens": ["Updated", "due", "to", "change", "in", "store"], "add_tokens": "gstore store . GroupStore", "del_tokens": "gstore api . GroupStore", "commit_type": "update"}
{"commit_tokens": ["Use", "NewMessage", "()", "in", "tests"], "add_tokens": "m := mail . NewMessage ( ) m . From = \" \" m . To = [ ] string { \" \" } m . Subject = \" \" m . CC = [ ] string { \" \" , \" \" } m . Bcc = [ ] string { \" \" }", "del_tokens": "m := mail . Message { From : \" \" , To : [ ] string { \" \" } , Subject : \" \" , CC : [ ] string { \" \" , \" \" } , Bcc : [ ] string { \" \" } , }", "commit_type": "use"}
{"commit_tokens": ["fixed", "bug", "causing", "inputs", "to", "only", "recieve", "single", "space", "deliminated", "tokens"], "add_tokens": "\" \" \" \" \" \" // a scanner to look at the input from stdin scanner := bufio . NewScanner ( os . Stdin ) // wait for a response for scanner . Scan ( ) { // get the availible text in the scanner res := scanner . Text ( ) // if there is no answer if res == \" \" { // use the default res = input . Default } // return the value return res , nil return \" \" , errors . New ( \" \" )", "del_tokens": "// a string to hold the user's input var res string // wait for a newline or carriage return fmt . Scanln ( & res ) // if there is no answer if res == \" \" { // use the default res = input . Default // return the value return res , nil", "commit_type": "fix"}
{"commit_tokens": ["Use", "range", "to", "read", "from", "the", "event", "channel"], "add_tokens": "for event := range stream {", "del_tokens": "for { event , ok := <- stream if ! ok { break }", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "yml", "extension"], "add_tokens": "case \" \" , \" \" : SupportedExts = [ ] string { \" \" , \" \" , \" \" , \" \" }", "del_tokens": "case \" \" : SupportedExts = [ ] string { \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Add", "range", "condition", "sanity", "check", "logic", "."], "add_tokens": "//go:generate stringer -type=Operator // order of appearance matter here // Gt is the greater than operator Gt Range ( ctx context . Context , ei * EntityInfo , columnConditions map [ string ] [ ] Condition , fieldsToRead [ ] string , token string , limit int ) ( [ ] map [ string ] FieldValue , string , error )", "del_tokens": "// Gt is the greater than operator Gt // Condition is used to hold a field name, value, and operator type Condition struct { FieldNameValuePair // Op defines the operator being used for the condition Op Operator } Range ( ctx context . Context , ei * EntityInfo , conditions [ ] Condition , fieldsToRead [ ] string , token string , limit int ) ( multiValues [ ] map [ string ] FieldValue , nextToken string , err error )", "commit_type": "add"}
{"commit_tokens": ["Fix", "syntax", "bug", "product", "suggestion", "lang"], "add_tokens": "size = fmt . Sprintf ( \" \" , strings . TrimSpace ( strings . ToLower ( product . Size ) ) )", "del_tokens": "size = fmt . Sprintf ( \" \" , strings . Trim ( strings . ToLower ( product . Size ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "sorting", "in", "reverse", "order", "."], "add_tokens": "// Specifies the keys to be used by a CSV sort. Keys [ ] string // list of columns to use for sorting Numeric [ ] string // list of columns for which a numerical string comparison is used Reversed [ ] string // list of columns for which the comparison is reversed reverseIndex := utils . NewIndex ( p . Reversed ) if reverseIndex . Contains ( k ) { f := bk . Comparators [ i ] bk . Comparators [ i ] = func ( i , j int ) bool { return ! f ( i , j ) } }", "del_tokens": "// Specifies the keys to be used by a CSV sort. Columns to be used as sort keys are specified with Keys, in order of precedence. Numeric // is the list of keys which for which a numeric comparison should be used. Keys [ ] string Numeric [ ] string", "commit_type": "add"}
{"commit_tokens": ["make", "executor", "disappearing", "test", "a", "bit", "clearer"], "add_tokens": "var convergingExecutor * executor_runner . ExecutorRunner convergingExecutor = executor_runner . New ( convergingExecutor . Start ( executor_runner . Config { // so the task does not get scheduled on the converger MemoryMB : 100 , DiskMB : 100 , ConvergenceInterval : 1 * time . Second , ContainerOwnerName : \" \" , } ) suiteContext . ExecutorRunner . Start ( executor_runner . Config { ConvergenceInterval : 1 * time . Second , HeartbeatInterval : 1 * time . Second , } ) convergingExecutor . KillWithFire ( )", "del_tokens": "var secondExecutor * executor_runner . ExecutorRunner secondExecutor = executor_runner . New ( suiteContext . ExecutorRunner . Start ( executor_runner . Config { MemoryMB : 100 , DiskMB : 100 , ConvergenceInterval : 1 * time . Second } ) secondExecutor . Start ( executor_runner . Config { ConvergenceInterval : 1 * time . Second , HeartbeatInterval : 1 * time . Second , ContainerOwnerName : \" \" } ) secondExecutor . KillWithFire ( )", "commit_type": "make"}
{"commit_tokens": ["Added", "filename", "parameter", "to", "Assembly", ".", "AddReader"], "add_tokens": "readers [ ] * upload } type upload struct { Field string Name string Reader io . Reader readers : make ( [ ] * upload , 0 ) , func ( assembly * Assembly ) AddReader ( field , name string , reader io . Reader ) { assembly . readers = append ( assembly . readers , & upload { Field : field , Name : name , Reader : reader , } ) for _ , reader := range assembly . readers { part , err := writer . CreateFormFile ( reader . Field , reader . Name ) _ , err = io . Copy ( part , reader . Reader )", "del_tokens": "readers map [ string ] io . Reader readers : make ( map [ string ] io . Reader ) , func ( assembly * Assembly ) AddReader ( name string , reader io . Reader ) { assembly . readers [ name ] = reader for index , reader := range assembly . readers { part , err := writer . CreateFormFile ( index , index ) _ , err = io . Copy ( part , reader )", "commit_type": "add"}
{"commit_tokens": ["Adds", "some", "more", "docs", "for", "the", "internal", "/", "documents", "package"], "add_tokens": "// CreateClientRequest represents the JSON transport data structure // for a request to create a Client. type CreateClientRequest struct { // ClientID is the unique identifier specifying the client. ClientID string `json:\"client_id\"` // ClientSecret is the secret value used to fetch a token // for the client. ClientSecret string `json:\"client_secret\"` // Scope is a list of permission values to apply to user tokens that // are granted to the client. Scope [ ] string `json:\"scope\"` // ResourceIDs is a list of audiences for the client. This field // is always [\"none\"]. ResourceIDs [ ] string `json:\"resource_ids\"` // Authorities is a list of permission values applied when the client // fetches their own token. Authorities [ ] string `json:\"authorities\"` // AuthorizedGrantTypes is a list of grant types applied to the client. // AccessTokenValidity is the number of seconds before a token granted // to this client will expire. AccessTokenValidity int `json:\"access_token_validity\"` // ClientResponse represents the JSON transport data structure for // a response containing a Client resource. type ClientResponse struct { // ClientID is the unique identifier specifying the client. ClientID string `json:\"client_id\"` // Scope is a list of permission values to apply to user tokens that // are granted to the client. Scope [ ] string `json:\"scope\"` // ResourceIDs is a list of audiences for the client. This field // is always [\"none\"]. ResourceIDs [ ] string `json:\"resource_ids\"` // Authorities is a list of permission values applied when the client // fetches their own token. Authorities [ ] string `json:\"authorities\"` // AuthorizedGrantTypes is a list of grant types applied to the client. // AccessTokenValidity is the number of seconds before a token granted // to this client will expire. AccessTokenValidity int `json:\"access_token_validity\"`", "del_tokens": "type ClientResponse struct { ClientID string `json:\"client_id\"` Scope [ ] string `json:\"scope\"` ResourceIDs [ ] string `json:\"resource_ids\"` Authorities [ ] string `json:\"authorities\"` AccessTokenValidity int `json:\"access_token_validity\"` type CreateClientRequest struct { ClientID string `json:\"client_id\"` ClientSecret string `json:\"client_secret\"` Scope [ ] string `json:\"scope\"` ResourceIDs [ ] string `json:\"resource_ids\"` Authorities [ ] string `json:\"authorities\"` AccessTokenValidity int `json:\"access_token_validity\"`", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "Unit", "tests", "for", "clientStore"], "add_tokens": "// Register a client if new, otherwise returns the client already registered // and 'isNew' is set to false.", "del_tokens": "// Register a client if new, otherwise returns the client and 'isNew' // will be set to false.", "commit_type": "add"}
{"commit_tokens": ["Fix", "Humanize", "for", "multi", "-", "byte", "runes"], "add_tokens": "r , n := utf8 . DecodeRuneInString ( sentance ) return string ( unicode . ToUpper ( r ) ) + sentance [ n : ]", "del_tokens": "return strings . ToUpper ( sentance [ : 1 ] ) + sentance [ 1 : ]", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "AssertEq ( 20 , len ( mac ) )", "del_tokens": "AssertEq ( 24 , len ( mac ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "location", "-", "manager", "instead", "of", "pool", "-", "manager"], "add_tokens": "// location.Command(\"archive\", \"Archive specific location (WARNING: destructive)\", locations.Archive) // location.Command(\"list\", \"List all locations\", locations.List)", "del_tokens": "location . Command ( \" \" , \" \" , locations . Archive ) location . Command ( \" \" , \" \" , locations . List )", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "flags", "in", "run", "command"], "add_tokens": "args = append ( args , transformRunFlagArgs ( runArgs ) ... ) func transformRunFlagArgs ( args [ ] string ) [ ] string { const flagPrefix = \" \" var newArgs [ ] string for _ , currArg := range args { // if current argument has flag prefix and has content after the prefix, trim the prefix if strings . HasPrefix ( currArg , flagPrefix ) && len ( currArg ) > len ( flagPrefix ) { currArg = strings . TrimPrefix ( currArg , flagPrefix ) } newArgs = append ( newArgs , currArg ) } return newArgs }", "del_tokens": "args = append ( args , runArgs ... )", "commit_type": "add"}
{"commit_tokens": ["Make", "case", "folding", "defaults", "correct", "for", "non", "-", "Linux", "Unix", "systems"], "add_tokens": "// +build windows darwin", "del_tokens": "// +build !linux", "commit_type": "make"}
{"commit_tokens": ["Remove", "blank", "identifiers", "from", "const", "declaration", "."], "add_tokens": "backKey = '\\u007f' escKey = '\\u001B' spaceKey = '\\u0020' tabKey returnKey", "del_tokens": "tabKey = '\\t' backKey = '\\u007f' returnKey = '\\r' escKey = '\\u001B' spaceKey = '\\u0020' _ // Same as tabKey. _ // Same as returnKey.", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "to", "chain", "withfields"], "add_tokens": "data := Fields { } for k , v := range entry . Data { data [ k ] = v } data [ key ] = value return & Entry { Logger : entry . Logger , Data : data } data := Fields { } for k , v := range entry . Data { data [ k ] = v } for k , v := range fields { data [ k ] = v return & Entry { Logger : entry . Logger , Data : data }", "del_tokens": "entry . Data [ key ] = value return entry for key , value := range fields { entry . WithField ( key , value ) return entry", "commit_type": "add"}
{"commit_tokens": ["Updated", "import", "path", "for", "bcrypt"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Implement", "and", "test", "getNextJobs", "()"], "add_tokens": "fieldName , err := redis . String ( fields [ i ] , nil ) if err != nil { priority , err := redis . Int ( fieldValue , nil ) if err != nil { status , err := redis . String ( fieldValue , nil ) if err != nil { job . status = JobStatus ( status )", "del_tokens": "fieldName , ok := fields [ i ] . ( string ) if ! ok { priority , ok := fieldValue . ( int ) if ! ok { status , ok := fieldValue . ( JobStatus ) if ! ok { job . status = status", "commit_type": "implement"}
{"commit_tokens": ["make", "CertificateInfo", "Serial", "type", "to", "*", "big", ".", "Int"], "add_tokens": "\" \" Serial * big . Int func ( c * Certificate ) SetSerial ( serial * big . Int ) error { sno := C . ASN1_INTEGER_new ( ) defer C . ASN1_INTEGER_free ( sno ) bn := C . BN_new ( ) defer C . BN_free ( bn ) serialBytes := serial . Bytes ( ) if bn = C . BN_bin2bn ( ( * C . uchar ) ( unsafe . Pointer ( & serialBytes [ 0 ] ) ) , C . int ( len ( serialBytes ) ) , bn ) ; bn == nil { return errors . New ( \" \" ) } if sno = C . BN_to_ASN1_INTEGER ( bn , sno ) ; sno == nil { return errors . New ( \" \" ) } if C . X509_set_serialNumber ( c . x , sno ) != 1 {", "del_tokens": "Serial int func ( c * Certificate ) SetSerial ( serial int ) error { if C . ASN1_INTEGER_set ( C . X509_get_serialNumber ( c . x ) , C . long ( serial ) ) != 1 {", "commit_type": "make"}
{"commit_tokens": ["create", "CLI", "param", "for", "msgTimeout"], "add_tokens": "const MsgIdLength = 16", "del_tokens": "const ( MsgIdLength = 16 )", "commit_type": "create"}
{"commit_tokens": ["fix", "typo", "provate", "=", ">", "private"], "add_tokens": "Usage : \" \" ,", "del_tokens": "Usage : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "regex", "support", "in", "route", "parameters"], "add_tokens": "import ( \" \" \" \" ) param // /:id or /:id(regex) re * regexp . Regexp", "del_tokens": "import \" \" regexp // TODO: /:id(regex) param // /:id", "commit_type": "add"}
{"commit_tokens": ["used", "glide", "as", "a", "package", "manger"], "add_tokens": "flag . Parse ( ) log . Printf ( \" \\n \" , path )", "del_tokens": "flag . Parse ( )", "commit_type": "use"}
{"commit_tokens": ["change", "signatures", "of", "config", "functions", "..."], "add_tokens": "var KEYBASE_SERVER_URL = \" \" var KEYBASE_CONFIG_FILE = \" \"", "del_tokens": "var PORT = 443 var HOST = \" \"", "commit_type": "change"}
{"commit_tokens": ["Added", "GetArgsN", "that", "return", "the", "specified", "maximum", "number", "of", "arguments", "(", "plus", "the", "remainder", "string", ")"], "add_tokens": "PARSE_STRING = \" \\n \" func TestGetArgsN ( test * testing . T ) { args , rest := GetArgsN ( TEST_STRING , 3 ) test . Logf ( \" \" , args , rest ) }", "del_tokens": "PARSE_STRING = \" \"", "commit_type": "add"}
{"commit_tokens": ["Adding", "Google", "Cloud", "DNS", "provider"], "add_tokens": "client * godo . Client if c . domain == \" \" || c . client == nil { return nil , errors . New ( \" \" ) _ , _ , err := c . client . Domains . CreateRecord ( ctxt , c . domain , & godo . DomainRecordEditRequest { records , _ , err := c . client . Domains . Records ( ctxt , c . domain , & godo . ListOptions { PerPage : 10000 } ) _ , err = c . client . Domains . DeleteRecord ( ctxt , c . domain , record . ID )", "del_tokens": "* godo . Client if c . domain == \" \" || c . Client == nil { return nil , errors . New ( \" \" ) _ , _ , err := c . Domains . CreateRecord ( ctxt , c . domain , & godo . DomainRecordEditRequest { records , _ , err := c . Domains . Records ( ctxt , c . domain , & godo . ListOptions { PerPage : 10000 } ) _ , err = c . Domains . DeleteRecord ( ctxt , c . domain , record . ID )", "commit_type": "add"}
{"commit_tokens": ["adding", "missing", "newlines", "and", "fixing", "last", "comma"], "add_tokens": "fmt . Println ( ) if i < l - 1 { fmt . Println ( \" \" ) } else { fmt . Println ( ) if i < l - 1 { fmt . Println ( \" \" ) } else { fmt . Println ( )", "del_tokens": "if i < l { fmt . Printf ( \" \\n \" ) if i < l { fmt . Printf ( \" \\n \" )", "commit_type": "add"}
{"commit_tokens": ["Makes", "_example", "/", "example", ".", "go", "explicitly", "ignore", "returned", "metadata", "from", "toml", ".", "DecodeFile"], "add_tokens": "if _ , err := toml . DecodeFile ( \" \" , & config ) ; err != nil {", "del_tokens": "if err := toml . DecodeFile ( \" \" , & config ) ; err != nil {", "commit_type": "make"}
{"commit_tokens": ["Added", "http", "downloader", "ignore", "error"], "add_tokens": "\" \" ignoreErrors bool IgnoreErrors bool ignoreErrors : o . IgnoreErrors , if resp . StatusCode != http . StatusOK { errS := fmt . Errorf ( \" \" , path , resp . StatusCode ) if ! d . ignoreErrors { return errS } else { astilog . Error ( errors . Wrap ( errS , \" \" ) ) } } else { // Copy body if _ , err = astiio . Copy ( ctx , resp . Body , buf . b ) ; err != nil { return errors . Wrap ( err , \" \" ) }", "del_tokens": "if resp . StatusCode != http . StatusOK { return fmt . Errorf ( \" \" , path , resp . StatusCode ) } // Create buf // Copy body if _ , err = astiio . Copy ( ctx , resp . Body , buf . b ) ; err != nil { return errors . Wrap ( err , \" \" )", "commit_type": "add"}
{"commit_tokens": ["change", "clientIncoming", "to", "use", "the", "same", "buffer", "for", "all", "messages"], "add_tokens": "data := make ( [ ] byte , 1024 ) if pLengthInt > cap ( data ) { data = make ( [ ] byte , pLengthInt ) } if _ , err := io . ReadFull ( conn , data [ : pLengthInt ] ) ; err != nil { if err := handle ( client , data [ : pLengthInt ] ) ; err != nil {", "del_tokens": "data := make ( [ ] byte , pLengthInt ) if _ , err := io . ReadFull ( conn , data ) ; err != nil { if err := handle ( client , data ) ; err != nil {", "commit_type": "change"}
{"commit_tokens": ["Fix", "some", "order", "(", "readable", ")"], "add_tokens": "// Interface represents a single object in the tree. type Interface interface { // Less returns true when the current item(key) in the receiver // is less than the given argument. Less ( than Interface ) bool }", "del_tokens": "// Interface represents a single object in the tree. type Interface interface { // Less returns true when the current item(key) in the receiver // is less than the given argument. Less ( than Interface ) bool }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tiny", "typo", "in", "docs", "."], "add_tokens": "// for the purposes of this example, the private extended key for the // for the purposes of this example, the private extended key for the", "del_tokens": "// for the purposes of this example, the private exteded key for the // for the purposes of this example, the private exteded key for the", "commit_type": "fix"}
{"commit_tokens": ["Implement", "Tenants", "querying", "and", "creation"], "add_tokens": "// String returns a string representation of type // Tenant is the structure that defines a tenant type TenantDefinition struct { ID string `json:\"id\"` Retentions map [ string ] int `json:\"retentions\"` // Retentions map[MetricType]int `json:\"retentions\"` }", "del_tokens": "// String Get string representation of type", "commit_type": "implement"}
{"commit_tokens": ["Add", "client", "method", "FilePreview", "."], "add_tokens": "It ( \" \" , func ( ) { expectedFile := & wundergo . File { fakeJSONHelper . UnmarshalReturns ( expectedFile , nil ) It ( \" \" , func ( ) { Expect ( file ) . To ( Equal ( expectedFile ) )", "del_tokens": "It ( \" \" , func ( ) { expectedNote := & wundergo . File { fakeJSONHelper . UnmarshalReturns ( expectedNote , nil ) It ( \" \" , func ( ) { Expect ( file ) . To ( Equal ( expectedNote ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "in", "patricia", "tree"], "add_tokens": "root * ptNode maxDepth int // max depth of the tree. root : newNode ( bs ) , maxDepth : max + 1 , buf := make ( [ ] byte , t . maxDepth ) n , _ := io . ReadFull ( r , buf ) return t . root . match ( buf [ : n ] , true ) buf := make ( [ ] byte , t . maxDepth ) n , _ := io . ReadFull ( r , buf ) return t . root . match ( buf [ : n ] , false )", "del_tokens": "root * ptNode buf [ ] byte // preallocated buffer to read data while matching root : newNode ( bs ) , buf : make ( [ ] byte , max + 1 ) , n , _ := io . ReadFull ( r , t . buf ) return t . root . match ( t . buf [ : n ] , true ) n , _ := io . ReadFull ( r , t . buf ) return t . root . match ( t . buf [ : n ] , false )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "parsing", "of", "environment", "variable", "SEAL_HTTP_STATUS"], "add_tokens": "if err != nil {", "del_tokens": "if err == nil {", "commit_type": "fix"}
{"commit_tokens": ["Change", "no", "calls", "found", "error", "to", "incude", "MustFindBox", "()"], "add_tokens": "fmt . Println ( \" \" )", "del_tokens": "fmt . Println ( \" \" )", "commit_type": "change"}
{"commit_tokens": ["change", "rpc", "default", "method", "to", "POST", ";", "add", "Daemon"], "add_tokens": "method := \" \"", "del_tokens": "method := \" \"", "commit_type": "change"}
{"commit_tokens": ["Made", "the", "match", "result", "constants", "typed", "."], "add_tokens": "// A MatchResult is an integer equal to one of the MATCH_* constants below. type MatchResult int MATCH_FALSE MatchResult = 0 MATCH_TRUE MatchResult = 1 MATCH_UNDEFINED MatchResult = - 1", "del_tokens": "MATCH_FALSE = 0 MATCH_TRUE = 1 MATCH_UNDEFINED = - 1 // A MatchResult is an integer equal to one of the MATCH_* constants above. type MatchResult int", "commit_type": "make"}
{"commit_tokens": ["Add", "some", "locking", "to", "avoid", "data", "races"], "add_tokens": "\" \" r * bytes . Buffer w * bytes . Buffer rLock * sync . Mutex wLock * sync . Mutex c2sLock := new ( sync . Mutex ) server . rLock = c2sLock client . wLock = c2sLock s2cLock := new ( sync . Mutex ) client . rLock = s2cLock server . wLock = s2cLock p . rLock . Lock ( ) p . rLock . Unlock ( ) p . rLock . Lock ( ) p . rLock . Unlock ( ) p . wLock . Lock ( ) defer p . wLock . Unlock ( )", "del_tokens": "r * bytes . Buffer w * bytes . Buffer", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "casts", "from", "config", "tests"], "add_tokens": "assert . Equal ( t , \" \" , pg . Name ( ) ) assert . Equal ( t , \" \" , pg . GetValue ( \" \" ) . AsString ( ) ) // TODO this should not require a cast GFM-74 assert . Equal ( t , 42 , pg . Scope ( \" \" ) . GetValue ( \" \" ) . AsInt ( ) )", "del_tokens": "assert . Equal ( t , \" \" , pg . ( providerGroup ) . Name ( ) ) assert . Equal ( t , \" \" , pg . ( providerGroup ) . GetValue ( \" \" ) . AsString ( ) ) assert . Equal ( t , 42 , pg . ( providerGroup ) . Scope ( \" \" ) . GetValue ( \" \" ) . AsInt ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "dim", "attribute", "support", "."], "add_tokens": "dim = \" \" blink = \" \" if strings . Contains ( fgStyle , \" \" ) { buf . WriteString ( dim ) }", "del_tokens": "blink = \" \"", "commit_type": "add"}
{"commit_tokens": ["use", "raw", "string", "literal", "for", "regexp"], "add_tokens": "var durRe = regexp . MustCompile ( `^([0-9]+)([smhd])?$` )", "del_tokens": "var durRe = regexp . MustCompile ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["remove", "uneeded", "conversion", "of", "ip", "-", ">", "string"], "add_tokens": "func ( m addrMap ) B32 ( ip net . IP ) string { if err == nil && cidr . Contains ( ip ) {", "del_tokens": "func ( m addrMap ) B32 ( ip string ) string { i := net . ParseIP ( ip ) if err == nil && cidr . Contains ( i ) {", "commit_type": "remove"}
{"commit_tokens": ["add", "link", "ifb", "and", "fix", "macvtap"], "add_tokens": "case \" \" : link = & Ifb { } case \" \" : case \" \" : parseMacvtapData ( link , data ) func parseMacvtapData ( link Link , data [ ] syscall . NetlinkRouteAttr ) { macv := link . ( * Macvtap ) parseMacvlanData ( & macv . Macvlan , data ) }", "del_tokens": "case \" \" , \" \" :", "commit_type": "add"}
{"commit_tokens": ["fix", "consecutive", "file", "update", "bug"], "add_tokens": "r . kill ( cmd ) r . kill ( cmd ) r . kill ( r . cmd ) func ( r * Runner ) kill ( cmd * exec . Cmd ) { if cmd != nil { cmd . Process . Kill ( ) r . kill ( r . cmd )", "del_tokens": "\" \" mu * sync . Mutex mu : & sync . Mutex { } , r . kill ( ) r . mu . Lock ( ) r . mu . Unlock ( ) r . kill ( ) r . kill ( ) func ( r * Runner ) kill ( ) { r . mu . Lock ( ) defer r . mu . Unlock ( ) if r . cmd != nil { pid := r . cmd . Process . Pid log . Printf ( \" \\n \" , pid ) r . cmd . Process . Kill ( ) r . cmd = nil r . kill ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "save", "image", "for", "virtual", "attributes"], "add_tokens": "results , err := json . Marshal ( b ) return string ( results ) , err", "del_tokens": "return json . Marshal ( b )", "commit_type": "fix"}
{"commit_tokens": ["Add", "couple", "more", "models", "methods", "."], "add_tokens": "RoomId : \"", "del_tokens": "RoomId : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["implement", "certificate", "based", "auth", "for", "service", "principal", "tokens"], "add_tokens": "minor = \" \" patch = \" \"", "del_tokens": "minor = \" \" patch = \" \"", "commit_type": "implement"}
{"commit_tokens": ["Removes", "auth", "code", "from", "nface", "."], "add_tokens": "if err != nil || httpReq == nil {", "del_tokens": "OAuth : \" \" , if err != nil { t . Errorf ( \" \" , err ) } if httpReq . Header . Get ( \" \" ) != \" \" { t . Errorf ( \" \" , httpReq . Header . Get ( \" \" ) ) } } func TestHttpRequestBasicAuth ( t * testing . T ) { req := & Request { Action : POST , BasicAuthUser : \" \" , BasicAuthPass : \" \" , Values : & url . Values { } , } httpReq , err := req . httpRequest ( ) if err != nil { user , pass , ok := httpReq . BasicAuth ( ) if ! ok { t . Error ( \" \" ) } if user != \" \" || pass != \" \" { t . Error ( \" \" ) }", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "typo", "in", "ulimits", "tag", "(", "omitemty", "-", ">", "omitempty", ")"], "add_tokens": "Ulimits Ulimits `yaml:\"ulimits,omitempty\"`", "del_tokens": "Ulimits Ulimits `yaml:\"ulimits,omitemty\"`", "commit_type": "fix"}
{"commit_tokens": ["Add", "nil", "checks", "to", "events", "error", "channel"], "add_tokens": "if ec != nil { ec <- err } if ec != nil { ec <- err }", "del_tokens": "ec <- err ec <- err", "commit_type": "add"}
{"commit_tokens": ["Adds", "missing", "properties", "for", "web_url", "button", "in", "StructuredMessageButton", "."], "add_tokens": "Type string `json:\"type\"` URL string `json:\"url,omitempty\"` Title string `json:\"title,omitempty\"` Payload string `json:\"payload,omitempty\"` WebviewHeightRatio string `json:\"webview_height_ratio,omitempty\"` MessengerExtensions bool `json:\"messenger_extensions,omitempty\"` FallbackURL string `json:\"fallback_url,omitempty\"` WebviewShareButton string `json:\"webview_share_button,omitempty\"`", "del_tokens": "Type string `json:\"type\"` URL string `json:\"url,omitempty\"` Title string `json:\"title,omitempty\"` Payload string `json:\"payload,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["allow", "genesisTime", "IsZero", "-", ">", "now"], "add_tokens": "round , roundStartTime , roundDuration , _ , elapsedRatio := calcRoundInfo ( rs . StartTime ) log . Debug ( \" \" , round , roundStartTime , elapsedRatio )", "del_tokens": "_ , _ , roundDuration , _ , elapsedRatio := calcRoundInfo ( rs . StartTime )", "commit_type": "allow"}
{"commit_tokens": ["Move", "rest", "of", "cgroups", "functions", "into", "cgroups", "pkg"], "add_tokens": "if container . Cgroups != nil { if err := container . Cgroups . Apply ( command . Process . Pid ) ; err != nil { command . Process . Kill ( ) return - 1 , err }", "del_tokens": "\" \" if err := cgroup . ApplyCgroup ( container , command . Process . Pid ) ; err != nil { command . Process . Kill ( ) return - 1 , err", "commit_type": "move"}
{"commit_tokens": ["fixed", "issue", "identifying", "the", "last", "arg", "of", "a", "call"], "add_tokens": "var helperContextKind = \" \" if last . Name ( ) == helperContextKind { } else if last . Kind ( ) == reflect . Map { if last . Name ( ) == helperContextKind { } else if last . Kind ( ) == reflect . Map {", "del_tokens": "var helperContextKind = reflect . ValueOf ( HelperContext { } ) . Kind ( ) . String ( ) var mapKind = reflect . ValueOf ( map [ string ] interface { } { } ) . Kind ( ) . String ( ) switch last . Kind ( ) . String ( ) { case helperContextKind : case mapKind : switch last . Kind ( ) . String ( ) { case helperContextKind : case mapKind :", "commit_type": "fix"}
{"commit_tokens": ["removing", "alias", "of", "the", "package", "from", "result", "file", "types", "if", "result", "file", "is", "placed", "to", "this", "package"], "add_tokens": "\" \" packagePath , err := generator . PackageOf ( opts . InputFile ) if err != nil { die ( err ) } destPackagePath , err := generator . PackageOf ( filepath . Dir ( opts . OutputFile ) ) if err != nil { die ( err ) } gen . ImportWithAlias ( destPackagePath , \" \" ) } ` input = flag . String ( \" \" , \" \" , \" \" )", "del_tokens": "packagePath , err := generator . PackageOf ( opts . InputFile ) if err != nil { die ( err ) } } ` input = flag . String ( \" \" , \" \" , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["make", "sum", "(", "nil", ")", "return", "empty", "hash", "not", "nil"], "add_tokens": "// If the Tree is empty, return nil. return nil", "del_tokens": "if data == nil { return nil } // If the Tree is empty, return the hash of the empty string. return sum ( t . hash , nil )", "commit_type": "make"}
{"commit_tokens": ["Use", "a", "placeholder", "instead", "of", "a", "fake", "key"], "add_tokens": "key := \" \"", "del_tokens": "key := \" \"", "commit_type": "use"}
{"commit_tokens": ["add", "missing", "result", ".", "IncrementScore", "()"], "add_tokens": "result . IncrementScore ( ) return", "del_tokens": "return", "commit_type": "add"}
{"commit_tokens": ["made", "it", "wait", "for", "all", "files", "-", "CURRENTLY", "BROKEN"], "add_tokens": "var filesWg sync . WaitGroup filesWg . Done ( ) // setup a waitgroup and wait for everything to // be done var walkerWg sync . WaitGroup walkerWg . Add ( 1 ) filesWg . Add ( 1 ) // everything is done walkerWg . Done ( ) // wait for all walker calls walkerWg . Wait ( ) filesWg . Wait ( )", "del_tokens": "var wg sync . WaitGroup wg . Add ( 1 ) default : wg . Done ( ) wg . Wait ( )", "commit_type": "make"}
{"commit_tokens": ["Improve", "net", "/", "http", "example"], "add_tokens": "// perm is a Permissions structure that can be used to deny requests // and aquire the UserState. By using `pinterface.IPermissions` instead // of `permissions.Permissions`, the code is compatible with not only // `permissions2`, but also other modules that uses other database // backends, like `permissionbolt` which uses Bolt. // Let the user know, by calling the custom \"permission denied\" function ph . perm . DenyFunction ( ) ( w , req ) // Serve the requested page if permissions were granted // Start listening", "del_tokens": "// perm is the Permissions structure that can be used to deny requests. // By using `pinterface.IPermissions` instead of `permissions.Permissions`, // the code is compatible with not only `permissions2`, but also other modules // that uses other database backends, like `permissionbolt`. // Deny the request http . Error ( w , \" \" , http . StatusForbidden ) // Serve the requested if permissions were granted // Serve on port 3000", "commit_type": "improve"}
{"commit_tokens": ["Updated", "POST", "to", "be", "able", "to", "POST", "xml", "bodies", "and", "Response", "to", "consume", "XML"], "add_tokens": "\" \" type XMLPostMessage struct { Name string Age int Height int } func TestXMLPostRequest ( t * testing . T ) { resp := <- Post ( \" \" , & RequestOptions { Xml : XMLPostMessage { Name : \" \" , Age : 1 , Height : 1 } } ) if resp . Error != nil { t . Fatal ( \" \" , resp . Error ) } if resp . Ok != true { t . Error ( \" \" ) } myJsonStruct := & BasicPostJsonResponse { } if err := resp . Json ( myJsonStruct ) ; err != nil { t . Error ( \" \" , err ) } myXMLStruct := & XMLPostMessage { } xml . Unmarshal ( [ ] byte ( myJsonStruct . Data ) , myXMLStruct ) if myXMLStruct . Age != 1 { t . Errorf ( \" \" , myXMLStruct ) } } if err := resp . Json ( myJsonStruct ) ; err != nil { if err := resp . Json ( myJsonStruct ) ; err != nil {", "del_tokens": "err := resp . Json ( myJsonStruct ) if err != nil { err := resp . Json ( myJsonStruct ) if err != nil {", "commit_type": "update"}
{"commit_tokens": ["Fix", "a", "bug", "in", "namespaced", "selection"], "add_tokens": "Key : xmlnsPrefix ,", "del_tokens": "Key : prefix ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "constants", "and", "documentation"], "add_tokens": "// dlopen() flags. See man dlopen. RTLD_LAZY = int ( C . RTLD_LAZY ) RTLD_NOW = int ( C . RTLD_NOW ) RTLD_GLOBAL = int ( C . RTLD_GLOBAL ) RTLD_LOCAL = int ( C . RTLD_LOCAL ) RTLD_NODELETE = int ( C . RTLD_NODELETE ) RTLD_NOLOAD = int ( C . RTLD_NOLOAD ) // DL represents an opened dynamic library. Use Open // to initialize a DL and use DL.Close when you're finished // with it. Note that when the DL is closed all its loaded // symbols become invalid. // Open opens the shared library identified by the given name // with the given flags. See man dlopen for the available flags // and its meaning. Note that the only difference with dlopen is that // if nor RTLD_LAZY nor RTLD_NOW are specified, Open defaults to // RTLD_NOW rather than returning an error. // Sym loads the symbol identified by the given name into // the out parameter. Note that out must always be a pointer. // See the package documentation to learn how types are mapped // between Go and C. // Close closes the shared library handle. All symbols // loaded from the library will become invalid.", "del_tokens": "RTLD_LAZY = int ( C . RTLD_LAZY ) RTLD_NOW = int ( C . RTLD_NOW )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "type", "in", "lookup", "table"], "add_tokens": "\" \" : LevelWarn ,", "del_tokens": "\" \" : LevelWarn , var levelTab = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "table", "and", "table", "with", "color", "git", "not", "pushing"], "add_tokens": "if len ( colors ) > i { color := colors [ i ] out [ 0 ] = format ( out [ 0 ] , color ) }", "del_tokens": "cellParams [ ] CellColor cellParams : [ ] CellColor { } ,", "commit_type": "fix"}
{"commit_tokens": ["improve", "docs", "for", "New", "and", "NewForUser"], "add_tokens": "// New returns a connected Client, or an error if it can't connect. The user // will be the user the code is running under. // NewForUser returns a connected Client with the user specified, or an error if // it can't connect.", "del_tokens": "// New returns a connected Client, or an error if it can't connect", "commit_type": "improve"}
{"commit_tokens": ["fix", "edge", "case", "where", "no", "data", "on", "one", "side"], "add_tokens": "// JoinPartitionedSorted Join multiple datasets that are sharded by the same key, and locally sorted within the shard var leftValueLength , rightValueLength int if leftHasValue { leftValueLength = len ( leftValuesWithSameKey . Values [ 0 ] . ( [ ] interface { } ) ) } if rightHasValue { rightValueLength = len ( rightValuesWithSameKey . Values [ 0 ] . ( [ ] interface { } ) ) }", "del_tokens": "// Join multiple datasets that are sharded by the same key, and locally sorted within the shard leftValueLength := len ( leftValuesWithSameKey . Values [ 0 ] . ( [ ] interface { } ) ) rightValueLength := len ( rightValuesWithSameKey . Values [ 0 ] . ( [ ] interface { } ) )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "error", "messages", "and", "a", "few", "comments"], "add_tokens": "return nil , fmt . Errorf ( \" \" , filename , err ) // spaces so we can better control formatting during output().", "del_tokens": "return nil , err // spaces so we can better control formatting during output()", "commit_type": "improve"}
{"commit_tokens": ["Add", "support", "for", "sorting", "datasets"], "add_tokens": "// SortReverse sorts the Dataset by a specific column in reverse order. Returns a new Dataset.", "del_tokens": "// Sort sorts the Dataset by a specific column in reverse order. Returns a new Dataset.", "commit_type": "add"}
{"commit_tokens": ["add", "Silence", "()", "to", "suppress", "output", "in", "tests"], "add_tokens": "if l . level < level || silent {", "del_tokens": "if l . level < level {", "commit_type": "add"}
{"commit_tokens": ["remove", "influx", "until", "the", "state", "of", "the", "repository", "settles", "or", "we", "get", "proper", "vendoring", "in", "place"], "add_tokens": "// Register(\"influx\", \"an InfluxDB sink adaptor\", NewInfluxdb, dbConfig{})", "del_tokens": "Register ( \" \" , \" \" , NewInfluxdb , dbConfig { } )", "commit_type": "remove"}
{"commit_tokens": ["add", "separate", "bucket", "for", "pure", "headers", "vs", "stripped", "headers"], "add_tokens": "// copy the original headers in then reduce for http headers rctx . Header = r . Header rctx . HTTPHeader = make ( http . Header , len ( r . Header ) ) // XXX(reed): oversized, esp if not http // find things we need, and for http headers add them to the httph bucket rctx . HTTPHeader . Add ( strings . TrimPrefix ( k , \" \" ) , v )", "del_tokens": "// XXX(reed): could make a new header bucket to dump things into instead of futzing // XXX(reed): we should strip out request url and method too but for invoke they don't exist... r . Header . Del ( k ) r . Header . Del ( k ) r . Header . Del ( k ) r . Header . Del ( k ) r . Header . Add ( strings . TrimPrefix ( k , \" \" ) , v )", "commit_type": "add"}
{"commit_tokens": ["Use", "connected", "bool", "properly", "to", "ensure", "shutdown", "()", "can", "t", "be", "called", "twice", "."], "add_tokens": "conn . connected = true // Guard against double-call of shutdown() if we get an error in send() // as calling sock.Close() will cause recv() to recieve EOF in readstring() if conn . connected { conn . connected = false conn . sock . Close ( ) conn . cSend <- true conn . cLoop <- true conn . dispatchEvent ( & Line { Cmd : \" \" } ) // reinit datastructures ready for next connection // do this here rather than after runLoop()'s for due to race conn . initialise ( ) }", "del_tokens": "conn . connected = false conn . sock . Close ( ) conn . cSend <- true conn . cLoop <- true conn . dispatchEvent ( & Line { Cmd : \" \" } ) // reinit datastructures ready for next connection // do this here rather than after runLoop()'s for due to race conn . initialise ( )", "commit_type": "use"}
{"commit_tokens": ["Use", "xml", ".", "Encoder", ".", "EncodeElement", "()"], "add_tokens": "return e . EncodeElement ( xml . CharData ( se . value ) , se . StartElement )", "del_tokens": "if err := e . EncodeToken ( se . StartElement ) ; err != nil { return err } if err := e . EncodeToken ( xml . CharData ( se . value ) ) ; err != nil { return err } if err := e . EncodeToken ( se . End ( ) ) ; err != nil { return err } return nil", "commit_type": "use"}
{"commit_tokens": ["add", "emojis", "to", "build", "logger", "."], "add_tokens": "color . Magenta ( \" fmt . Println ( \" color . Red ( \" fmt . Println ( \" core . RunCmd ( \" fmt . Println ( \" fmt . Println ( \" fmt . Println ( \" fmt . Println ( \" fmt . Println ( \" core . RunCmd ( \" fmt . Println ( \"", "del_tokens": "color . Magenta ( \" \" ) fmt . Println ( \" \" ) color . Red ( \" \" ) fmt . Println ( \" \" ) core . RunCmd ( \" \" ) fmt . Println ( \" \" ) fmt . Println ( \" \" ) fmt . Println ( \" \" ) fmt . Println ( \" \" ) fmt . Println ( \" \" ) core . RunCmd ( \" \" ) fmt . Println ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Move", "mpd", "watcher", "connection", "into", "own", "type"], "add_tokens": "watch , err := newWatchConn ( * mpdAddr ) defer watch . Close ( )", "del_tokens": "w , err := mpd . NewWatcher ( \" \" , * mpdAddr , \" \" ) defer w . Close ( ) // Log errors. go func ( ) { for err := range w . Error { glog . Error ( err ) } } ( ) // Log events. go func ( ) { for subsystem := range w . Event { glog . Info ( \" \" , subsystem ) broadcastStatus ( ) } } ( )", "commit_type": "move"}
{"commit_tokens": ["Add", "limit", "and", "offset", "for", "requesting", "a", "subset", "of", "the", "results"], "add_tokens": "// TODO: maybe instead of exposing the prev/next URLs, // we can just have functions for retrieving the prev/next page // A link to the Web API Endpoint returning the full // result of this request. FullResult string // The maximum number of items in the response, as set // in the query (or default value if unset). Limit int // The offset of the items returned, as set in the query // (or default value if unset). Offset int // The total number of items available to return. Total int // The URL to the next page of items (if available). Next string // The URL to the previous page of items (if available). // ArtistResult contains artists returned by the Web API. // AlbumResult contains albums returned by the Web API. // PlaylistResult contains playlists returned by the Web API. // TrackResult contains tracks returned by the Web API. a . FullResult = p . Endpoint a . FullResult = p . Endpoint a . FullResult = p . Endpoint a . FullResult = p . Endpoint", "del_tokens": "Endpoint string Limit int Offset int Total int Next string a . Endpoint = p . Endpoint a . Endpoint = p . Endpoint a . Endpoint = p . Endpoint a . Endpoint = p . Endpoint", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "simple", "HTTP", "server", "and", "a", "web", "ui"], "add_tokens": "return nil , fmt . Errorf ( \" \" , res . Status , res . StatusCode , url ) return nil , fmt . Errorf ( \" \" , res . Status , res . StatusCode , url )", "del_tokens": "return nil , fmt . Errorf ( \" \" , res . Status , res . StatusCode ) return nil , fmt . Errorf ( \" \" , res . Status , res . StatusCode )", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "err", "check", "after", "seek"], "add_tokens": "_ , err = wr . output . Seek ( 12 , os . SEEK_SET ) if err != nil { return }", "del_tokens": "wr . output . Seek ( 12 , os . SEEK_SET )", "commit_type": "add"}
{"commit_tokens": ["Add", "secret", "redaction", "support", "to", "lagerflags"], "add_tokens": "LogLevel string `json:\"log_level,omitempty\"` RedactSecrets bool `json:\"redact_secrets,omitempty\"` TimeFormat TimeFormat `json:\"time_format\"` LogLevel : string ( INFO ) , RedactSecrets : false , TimeFormat : FormatUnixEpoch , var redactSecrets bool flagSet . BoolVar ( & redactSecrets , \" \" , false , \" \" , ) func ConfigFromFlags ( ) LagerConfig { return LagerConfig { LogLevel : minLogLevel , RedactSecrets : redactSecrets , TimeFormat : timeFormat , } } if config . RedactSecrets { var err error sink , err = lager . NewRedactingSink ( sink , nil , nil ) if err != nil { panic ( err ) } }", "del_tokens": "LogLevel string `json:\"log_level,omitempty\"` TimeFormat TimeFormat `json:\"time_format\"` LogLevel : string ( INFO ) , TimeFormat : FormatUnixEpoch ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "a", "custom", "envelope", "sender", "(", "overriding", "e", ".", "From", ")", "for", "bounce", "handling", "etc", "."], "add_tokens": "Sender string // override From as SMTP envelope sender (optional) sender , err := e . parseSender ( ) return smtp . SendMail ( addr , a , sender , to , raw ) } // Select and parse an SMTP envelope sender address. Choose Email.Sender if set, or fallback to Email.From. func ( e * Email ) parseSender ( ) ( string , error ) { if e . Sender != \" \" { sender , err := mail . ParseAddress ( e . Sender ) if err != nil { return \" \" , err } return sender . Address , nil } else { from , err := mail . ParseAddress ( e . From ) if err != nil { return \" \" , err } return from . Address , nil } sender , err := e . parseSender ( ) if err = c . Mail ( sender ) ; err != nil {", "del_tokens": "from , err := mail . ParseAddress ( e . From ) return smtp . SendMail ( addr , a , from . Address , to , raw ) from , err := mail . ParseAddress ( e . From ) if err = c . Mail ( from . Address ) ; err != nil {", "commit_type": "allow"}
{"commit_tokens": ["Change", "how", "to", "gracefully", "shutdown", "http", ".", "Server", "."], "add_tokens": "mu sync . Mutex idleConns map [ net . Conn ] struct { } s . idleConns = make ( map [ net . Conn ] struct { } , 10000 ) s . mu . Lock ( ) if state == http . StateIdle { s . idleConns [ c ] = struct { } { } } else { delete ( s . idleConns , c ) } s . mu . Unlock ( ) // interrupt conn.Read for idle connections. s . mu . Lock ( ) for conn := range s . idleConns { conn . SetReadDeadline ( time . Now ( ) ) } s . mu . Unlock ( )", "del_tokens": "// shorten keep-alive timeout s . Server . ReadTimeout = 100 * time . Millisecond", "commit_type": "change"}
{"commit_tokens": ["Added", "read", "stream", "async", "backward"], "add_tokens": "// If the version parameter is nil reading will begin from the start of the stream. // If the take parameter is nil all results to the head of the stream will be read. // // When the method has completed reading the number of events requested it will // close the channel. // // In case of an error, a nil EventResponse will be returned. *Response may be nil in // cases where the error occured before the http request was performed to read // the stream. If the error occured after the http request was made, *Response // will be returned and will contain the raw http response, the the raw http // request, the http status code that was returned and the status message. // An *ErrorResponse will also be returned and this will contain the raw http // response and status and a description of the error. // ReadStreamBackwardAsync reads the stream backward from the version number // provided returning the number of results specified by the take parameter. // // If the version parameter is nil reading will begin from the head of the stream. // If the take parameter is nil all results to the start of the stream will be read. // // When the method has completed reading the number of events requested it will // close the channel. // // In case of an error, a nil EventResponse will be returned. *Response may be nil in // cases where the error occured before the http request was performed to read // the stream. If the error occured after the http request was made, *Response // will be returned and will contain the raw http response, the the raw http // request, the http status code that was returned and the status message. // An *ErrorResponse will also be returned and this will contain the raw http // response and status and a description of the error.", "del_tokens": "// When the method has completed reading the number of events requested it will close the channel. // In case of an error the error will be returned on the channel. If the error occured before the // http request was processed the *Response will be nil. If the error occurred during the http // request then the *Response will contain details of the error and the http request and response.", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "in", "level", ".", "go"], "add_tokens": "func GetLevelName ( levelValue Level ) string { SetLevel ( levelName , levelValue ) } func SetLevel ( levelName string , levelValue Level ) {", "del_tokens": "func GetLeveName ( levelValue Level ) string {", "commit_type": "fix"}
{"commit_tokens": ["changed", "the", "dep", "install", "order", "for", "the", "binary"], "add_tokens": "exec . Command ( \" \" , \" \" , \" \" , \" \" ) , exec . Command ( \" \" , \" \" , \" \" , \" \" ) ,", "del_tokens": "exec . Command ( \" \" , \" \" , \" \" , \" \" ) , exec . Command ( \" \" , \" \" , \" \" , \" \" ) ,", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "int64", "and", "uint64", "primary", "id", "types"], "add_tokens": "switch nId := id . ( type ) { case string : node . Id = nId case int : node . Id = strconv . Itoa ( nId ) case int64 : node . Id = strconv . FormatInt ( nId , 10 ) case uint64 : node . Id = strconv . FormatUint ( nId , 10 ) default : er = ErrBadJSONAPIID break", "del_tokens": "str , ok := id . ( string ) if ok { node . Id = str } else { j , ok := id . ( int ) if ok { node . Id = strconv . Itoa ( j ) } else { er = ErrBadJSONAPIID break }", "commit_type": "add"}
{"commit_tokens": ["Make", "function", "for", "Linux", "and", "move", "helper", "to", "separate", "function", ".", "Not", "sure", "why", "helper", "was", "returning", "float32", "type", "instead", "of", "time", ".", "Time", ".", "Keep", "type", "system", "."], "add_tokens": "import ( \" \" \" \" ) func GetVariantDate ( value int64 ) time . Time { return nil }", "del_tokens": "import \" \"", "commit_type": "make"}
{"commit_tokens": ["Remove", "Std", "from", "StdCollectNum", "and", "StdExpiration", "."], "add_tokens": "// The number of captchas created that triggers garbage collection used // by default store. CollectNum = 100 // Expiration time of captchas used by default store. Expiration = 10 * 60 // 10 minutes var globalStore = NewMemoryStore ( CollectNum , Expiration )", "del_tokens": "// The number of captchas created that triggers garbage collection. StdCollectNum = 100 // Expiration time of captchas. StdExpiration = 10 * 60 // 10 minutes var globalStore = NewMemoryStore ( StdCollectNum , StdExpiration )", "commit_type": "remove"}
{"commit_tokens": ["Adds", "test", "table", "for", "encoding"], "add_tokens": "if len ( parts ) < 2 || parts [ 1 ] == \" \" { if parts [ 1 ] == `\"\"` { return \" \" , omitempty , fmt . Errorf ( \" \" , tag ) } parts2 := strings . Split ( parts [ 1 ] , `\"` ) if len ( parts2 ) < 2 {", "del_tokens": "if len ( parts ) < 1 { parts2 := strings . Split ( parts [ 1 ] , \" \\\" \" ) if len ( parts2 ) < 1 {", "commit_type": "add"}
{"commit_tokens": ["use", "correct", "fmt", "directives", "for", "int", "types"], "add_tokens": "return fmt . Errorf ( \" \" ,", "del_tokens": "return fmt . Errorf ( \" \" ,", "commit_type": "use"}
{"commit_tokens": ["update", "gprmc", "tests", "to", "use", "rm"], "add_tokens": "msg RMC msg : RMC { msg : RMC { err : \" \" , rmc := m . ( RMC ) rmc . BaseSentence = BaseSentence { } assert . Equal ( t , tt . msg , rmc )", "del_tokens": "msg GPRMC msg : GPRMC { msg : GPRMC { err : \" \" , gprmc := m . ( GPRMC ) gprmc . BaseSentence = BaseSentence { } assert . Equal ( t , tt . msg , gprmc )", "commit_type": "update"}
{"commit_tokens": ["Fix", "cgo", "compile", "with", "console", "support"], "add_tokens": "// +build cgo func NewConsoleSocket ( path string ) ( * socket , error ) { return & socket { // socket is a unix socket that accepts the pty master created by runc type socket struct { func ( c * socket ) Path ( ) string { func ( c * socket ) ReceiveMaster ( ) ( console . Console , error ) { func ( c * socket ) Close ( ) error {", "del_tokens": "func NewConsoleSocket ( path string ) ( * ConsoleSocket , error ) { return & ConsoleSocket { // ConsoleSocket is a unix socket that accepts the pty master created by runc type ConsoleSocket struct { func ( c * ConsoleSocket ) Path ( ) string { func ( c * ConsoleSocket ) ReceiveMaster ( ) ( console . Console , error ) { func ( c * ConsoleSocket ) Close ( ) error {", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "less", "stricter", "mutex", "on", "registry", "."], "add_tokens": "m sync . RWMutex r . m . RLock ( ) defer r . m . RUnlock ( ) r . m . RLock ( ) defer r . m . RUnlock ( ) r . m . RLock ( ) defer r . m . RUnlock ( ) r . m . RLock ( ) defer r . m . RUnlock ( )", "del_tokens": "m sync . Mutex r . m . Lock ( ) defer r . m . Unlock ( ) r . m . Lock ( ) defer r . m . Unlock ( ) r . m . Lock ( ) defer r . m . Unlock ( ) r . m . Lock ( ) defer r . m . Unlock ( )", "commit_type": "use"}
{"commit_tokens": ["Implement", "ObjectsWalk", "and", "re", "-", "implement", "ObjectsAll", "and", "ObjectNamesAll", "using", "it"], "add_tokens": "c := swift . Connection { var container string func ExampleConnection_ObjectsWalk ( ) { objects := make ( [ ] string , 0 ) err := c . ObjectsWalk ( container , nil , func ( opts * swift . ObjectsOpts ) ( interface { } , error ) { newObjects , err := c . ObjectNames ( container , opts ) if err == nil { objects = append ( objects , newObjects ... ) } return newObjects , err } ) fmt . Println ( \" \" , objects , err ) }", "del_tokens": "c = swift . Connection {", "commit_type": "implement"}
{"commit_tokens": ["Allow", "upper", "case", "auth", "from", "as", "a", "form", "var"], "add_tokens": "case req . FormValue ( \" \" ) != \" \" : xtoken = req . FormValue ( \" \" ) errChan <- fmt . Errorf ( \" \" , xtoken )", "del_tokens": "errChan <- fmt . Errorf ( \" \" )", "commit_type": "allow"}
{"commit_tokens": ["move", "field", "name", "conversion", "to", "analyzer"], "add_tokens": "Binder * operationBinder parameters := analyzer . ParametersFor ( operation ) Binder : & operationBinder { parameters , consumers } , parameters := h . Handler . ParameterModel ( ) if err := h . Binder . Bind ( req , routeParams , parameters ) ; err != nil { // use renderer to render an error with the appropriate status code //h.Renderer(rw, err) return }", "del_tokens": "\" \" // Binder *requestBinder paramNames := make ( map [ string ] string ) for _ , param := range operation . Parameters { paramNames [ param . Name ] = util . ToGoName ( param . Name ) } // parameters := parameterContainerFor(operation) // Binder: newRequestBinder(parameters, consumers), // parameters := h.Handler.ParameterModel() // if err := h.Binder.Bind(req, routeParams, parameters); err != nil { // // use renderer to render an error with the appropriate status code // //h.Renderer(rw, err) // return // }", "commit_type": "move"}
{"commit_tokens": ["Implement", "a", "Regexp", "match", "mode"], "add_tokens": "NewCaseSensitiveMatcher ( ) , NewRegexpMatcher ( ) ,", "del_tokens": "NewCaseSensitiveMatcher ( ) ,", "commit_type": "implement"}
{"commit_tokens": ["Use", "log", ".", "Println", "instead", "of", "panic"], "add_tokens": "\" \" // must call t.Error or log.Println log . Println ( err )", "del_tokens": "// must fail a non-nil T or panic when err is set panic ( err )", "commit_type": "use"}
{"commit_tokens": ["Fix", "spelling", "of", "private", "and", "init", "FieldNames"], "add_tokens": "Private FieldNames PrivatePresent bool cd . PrivatePresent = true cd . ProxyRevalidate = true if cd . NoCache == nil { cd . NoCache = make ( FieldNames ) } cd . PrivatePresent = true if cd . Private == nil { cd . Private = make ( FieldNames ) } cd . Private [ k ] = true", "del_tokens": "Prviate FieldNames PrviatePresent bool cd . PrviatePresent = true cd . PrviatePresent = true cd . PrviatePresent = true cd . Prviate [ k ] = true", "commit_type": "fix"}
{"commit_tokens": ["use", "downsampling", "turn", "debug", "on"], "add_tokens": "debug = true for y := 0 ; y <= height - scoreDownSample ; y += scoreDownSample { for x := 0 ; x <= width - scoreDownSample ; x += scoreDownSample { //for y := 0; y < height; y++ { //for x := 0; x < width; x++ {", "del_tokens": "debug = false //for y := 0; y <= height-scoreDownSample; y += scoreDownSample { // for x := 0; x <= width-scoreDownSample; x += scoreDownSample { for y := 0 ; y < height ; y ++ { for x := 0 ; x < width ; x ++ {", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "only", "specific", "machines", "run", "reduce", "jobs", "."], "add_tokens": "func Reduce ( job Job , jobPath string , m materializeInfo , host string , shard , modulos uint64 ) error { if ( route . HashResource ( path . Join ( \" \" , jobPath ) ) % modulos ) != shard { // This resource isn't supposed to be located on this machine. return nil } func Materialize ( in_repo , branch , commit , out_repo , jobDir string , shard , modulos uint64 ) error { err := Reduce ( job , jobInfo . Name ( ) , m , containerAddr , shard , modulos )", "del_tokens": "func Reduce ( job Job , jobPath string , m materializeInfo , host string ) error { func Materialize ( in_repo , branch , commit , out_repo , jobDir string ) error { err := Reduce ( job , jobInfo . Name ( ) , m , containerAddr )", "commit_type": "make"}
{"commit_tokens": ["Moved", "repometadata", "into", "yum", "sub", "package"], "add_tokens": "package yum", "del_tokens": "package rpm", "commit_type": "move"}
{"commit_tokens": ["Fix", "length", "encode", "error", "if", "batch", "flush"], "add_tokens": "Int2BytesTo ( out . GetWriteIndex ( ) - idx - 4 , out . RawBuf ( ) [ idx : ] )", "del_tokens": "Int2BytesTo ( out . Readable ( ) - 4 , out . RawBuf ( ) [ idx : ] )", "commit_type": "fix"}
{"commit_tokens": ["Removed", "another", "useless", "pointer", "."], "add_tokens": "func ( n Notification ) Show ( ) ( id uint32 , err error ) {", "del_tokens": "func ( n * Notification ) Show ( ) ( id uint32 , err error ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "better", "error", "message", "on", "failed", "close", "."], "add_tokens": "g . OnError ( fmt . Errorf ( \" \" , r . Method , r . URL . Path , err ) , w , r )", "del_tokens": "g . OnError ( fmt . Errorf ( \" \" , err ) , w , r )", "commit_type": "add"}
{"commit_tokens": ["Add", "log", "when", "CheckKeyValuePairs", "fails", "in", "metadata"], "add_tokens": "consulclient \" \" if err := consulclient . CheckKeyValuePairs ( & configuration , configuration . ApplicationName , strings . Split ( configuration . ConsulProfilesActive , \" \" ) ) ; err != nil { loggingClient . Error ( \" \" + err . Error ( ) , \" \" ) }", "del_tokens": "consulclient \" \" consulclient . CheckKeyValuePairs ( & configuration , configuration . ApplicationName , strings . Split ( configuration . ConsulProfilesActive , \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "tabs", "to", "fix", "docs"], "add_tokens": "// // // limit resource consumption. // // concurrently. If one execution runs into the next, the next will be queued. // //", "del_tokens": "// limit resource consumption. // concurrently. If one execution runs into the next, the next will be queued.", "commit_type": "add"}
{"commit_tokens": ["remove", "FN_", "pre", "check", "for", "base", "vars", "for", "app", "/", "route", "config"], "add_tokens": "ctx , cancel := context . WithCancel ( ctx ) defer cancel ( )", "del_tokens": "ctx , _ = context . WithCancel ( ctx ) if _ , ok := base [ vs [ 0 ] ] ; ! ok { continue }", "commit_type": "remove"}
{"commit_tokens": ["Add", "documentation", "for", "funk", ".", "Initial", "and", "funk", ".", "Tail"], "add_tokens": "// Tail gets all but the first element of array.", "del_tokens": "// Tail gets all but the last element of array.", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "reading", "TCP", "checks"], "add_tokens": "StringToSend string `json:\"stringtosend,omitempty\"` StringToExpect string `json:\"stringtoexpect,omitempty\"`", "del_tokens": "StringToSend string `json:\"stringtosend,omitifempty\"` StringToExpect string `json:\"stringtoexpect,omitifempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "red", "&", "green", "ANSI", "color", "to", "output"], "add_tokens": "if matcher ( expectation . Actual , expected ) { expectation . Example . Succeeded ( message , expectation . Actual , expected ) } else {", "del_tokens": "if ! matcher ( expectation . Actual , expected ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "MockObject", "interface", "."], "add_tokens": "ExpectCall ( o MockObject , methodName string ) PartialExpecation HandleMethodCall ( o MockObject , methodName string , args ... interface { } ) [ ] interface { }", "del_tokens": "ExpectCall ( o interface { } , methodName string ) PartialExpecation HandleMethodCall ( o interface { } , methodName string , args ... interface { } ) [ ] interface { }", "commit_type": "add"}
{"commit_tokens": ["Add", "initial", "support", "for", "calling", "functions", "from", "C", "libraries"], "add_tokens": "package dl case reflect . Func : typ := elem . Type ( ) tr , err := makeTrampoline ( typ , handle ) if err != nil { return err } v := reflect . MakeFunc ( typ , tr ) elem . Set ( v ) case reflect . Ptr : v := reflect . NewAt ( elem . Type ( ) . Elem ( ) , handle ) elem . Set ( v )", "del_tokens": "package dlsym", "commit_type": "add"}
{"commit_tokens": ["fixed", "var", "size", "fields", "to", "byte", "array"], "add_tokens": "return append ( v . value , 0x00 )", "del_tokens": "return v . value", "commit_type": "fix"}
{"commit_tokens": ["Fix", "up", "for", "recent", "btcec", "changes", "."], "add_tokens": "ecPubKey := pubKey", "del_tokens": "ecPubKey := ( * btcec . PublicKey ) ( pubKey )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "hosts", "that", "don", "t", "have", "localhost", "-", ">", "::", "1", "for", "IPv6"], "add_tokens": "func testDialFromListeningPort ( t * testing . T , network , host string ) { ll , err := lc . Listen ( ctx , network , host + \" \" ) rl , err := lc . Listen ( ctx , network , host + \" \" ) testDialFromListeningPort ( t , \" \" , \" \" ) testDialFromListeningPort ( t , \" \" , \" \" )", "del_tokens": "func testDialFromListeningPort ( t * testing . T , network string ) { ll , err := lc . Listen ( ctx , network , \" \" ) rl , err := lc . Listen ( ctx , network , \" \" ) testDialFromListeningPort ( t , \" \" ) testDialFromListeningPort ( t , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "when", "dealing", "with", "errors", "in", "AuthTest"], "add_tokens": "import ( \" \" \" \" ) if ! response_full . Ok { return nil , errors . New ( response_full . Error ) }", "del_tokens": "import \" \"", "commit_type": "fix"}
{"commit_tokens": ["Removed", "commented", "code", "and", "translated", "constante", "that", "was", "in", "portuguese"], "add_tokens": "CHANNEL = \" \" irccon . Join ( CHANNEL ) irccon . Privmsg ( CHANNEL , \" \\n \" )", "del_tokens": "CANAL = \" \" //irccon.VerboseCallbackHandler = true irccon . Join ( CANAL ) irccon . Privmsg ( CANAL , \" \\n \" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "time", "zone", "problem", "by", "using", "now", "parse", "time"], "add_tokens": "startdate , err := now . Parse ( start ) enddate , err := now . Parse ( end ) db . DB . Table ( table ) . Where ( \" \" , startdate , enddate ) . Select ( \" \" ) . Group ( \" \" ) . Scan ( & res )", "del_tokens": "startdate , err := time . Parse ( \" \" , start ) enddate , err := time . Parse ( \" \" , end ) db . DB . Table ( table ) . Where ( \" \" , startdate , enddate ) . Select ( \" \" ) . Group ( \" \" ) . Scan ( & res )", "commit_type": "fix"}
{"commit_tokens": ["Update", "badger", "use", "consumer", "API"], "add_tokens": "ds \" \" dsq \" \" t . Fatalf ( \" \" , len ( keystrs ) , len ( outkeys ) ) t . Fatalf ( \" \" , outkeys [ i ] , s )", "del_tokens": "ds \" \" dsq \" \" t . Fatal ( \" \" ) t . Fatal ( \" \" , outkeys [ i ] , s )", "commit_type": "update"}
{"commit_tokens": ["Use", "cpus", "-", "1", "instead", "of", "maxing", "out"], "add_tokens": "// number of CPUs-1 is <= 0 is specified. cpus := runtime . NumCPU ( ) if cpus < 2 { parallel = 1 } else { parallel = cpus - 1 }", "del_tokens": "// number of CPUs is <= 0 is specified. parallel = runtime . NumCPU ( )", "commit_type": "use"}
{"commit_tokens": ["fixed", "a", "few", "comment", "typos"], "add_tokens": "// ExportScan exports a scan to a File resource. // DownloadExport will download the given export from nessus.", "del_tokens": "// ExportsScan exports a scan to a File resource. // SaveExport will download the given export from nessus.", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unused", "dark", "/", "light", "style", "type", "."], "add_tokens": "style := \" \" expected := \" \"", "del_tokens": "style := \" \" expected := \" \"", "commit_type": "remove"}
{"commit_tokens": ["Fix", "TIMEOUT", "argument", "of", "GETJOB"], "add_tokens": "args = args . Add ( \" \" , int64 ( timeout / time . Millisecond ) )", "del_tokens": "args . Add ( \" \" , timeout / time . Millisecond )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "Sfdisk", "partitioner", "when", "reading", "outpuf", "of", "sfdisk", "-", "s"], "add_tokens": "intSize , err := strconv . Atoi ( strings . Trim ( stdout , \" \\n \" ) )", "del_tokens": "intSize , err := strconv . Atoi ( stdout )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "reader", "for", "signed", "rquests", "."], "add_tokens": "req . Body = ioutil . NopCloser ( bytes . NewReader ( b ) )", "del_tokens": "req . Body = ioutil . NopCloser ( bytes . NewBuffer ( b ) )", "commit_type": "use"}
{"commit_tokens": ["Added", "InsecureStreamManger", "for", "working", "for", "InnerStreamId", "of", "zero"], "add_tokens": "/ * StreamManager returns a ProtectedStreamManager bassed on the db headers , or nil if the type is unsupported * Can be used to lock only certain entries instead of calling * / case 0 : return new ( InsecureStreamManager ) }", "del_tokens": "//StreamManager returns a protected stream manager bassed on the db headers, or nil if the type is unsupported }", "commit_type": "add"}
{"commit_tokens": ["fix", "various", "bugs", "in", "Modf", "Add"], "add_tokens": "tmp := new ( big . Int ) . Set ( & lo . unscaled ) scaled := checked . MulBigPow10 ( tmp , inc )", "del_tokens": "scaled := checked . MulBigPow10 ( & lo . unscaled , inc )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "cleanup", "code", "for", "scan_test", ".", "go"], "add_tokens": "c . Do ( \" \" , \" \" , \" \" , \" \" , \" \" ) c . Do ( \" \" , \" \" , \" \" )", "del_tokens": "c . Send ( \" \" , \" \" ) c . Send ( \" \" , \" \" ) c . Send ( \" \" , \" \" ) c . Send ( \" \" , \" \" ) c . Flush ( ) c . Send ( \" \" , \" \" ) c . Send ( \" \" , \" \" ) c . Flush ( )", "commit_type": "fix"}
{"commit_tokens": ["using", "name", "to", "find", "a", "setting", "and", "update"], "add_tokens": "\" \" : collection . SeoSettingUrl ,", "del_tokens": "\" \" : collection . seoURLFor ( a , res ) ,", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "registering", "service", "methods", "that", "do", "not", "accept", "an", "HTTP", "request", "pointer"], "add_tokens": "passReq bool func ( m * serviceMap ) register ( rcvr interface { } , name string , passReq bool ) error { passReq : passReq , // offset the parameter indexes by one if the // service methods accept an HTTP request pointer var paramOffset int if passReq { paramOffset = 1 } else { paramOffset = 0 } if mtype . NumIn ( ) != 3 + paramOffset { // If the service methods accept an HTTP request pointer if passReq { // First argument must be a pointer and must be http.Request. reqType := mtype . In ( 1 ) if reqType . Kind ( ) != reflect . Ptr || reqType . Elem ( ) != typeOfRequest { continue } // Next argument must be a pointer and must be exported. args := mtype . In ( 1 + paramOffset ) // Next argument must be a pointer and must be exported. reply := mtype . In ( 2 + paramOffset )", "del_tokens": "func ( m * serviceMap ) register ( rcvr interface { } , name string ) error { if mtype . NumIn ( ) != 4 { // First argument must be a pointer and must be http.Request. reqType := mtype . In ( 1 ) if reqType . Kind ( ) != reflect . Ptr || reqType . Elem ( ) != typeOfRequest { continue // Second argument must be a pointer and must be exported. args := mtype . In ( 2 ) // Third argument must be a pointer and must be exported. reply := mtype . In ( 3 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "spelling", "of", "locking", "in", "a", "doc", "string", "."], "add_tokens": "// Funlock is a dummy function which always returns nil on this // system. // On systems which support file locking, Funlock() can be used to // release a file lock which was previously acquired using Flock().", "del_tokens": "// Funlock always returns nil on this system. // On systems which support file lockgin, Funlock() can be used to // release a file lock which was previously acquired using Flock()", "commit_type": "fix"}
{"commit_tokens": ["Allow", "on", "to", "be", "a", "valid", "boolean", "value", "."], "add_tokens": "if value == \" \" { return reflect . ValueOf ( true ) } else if v , err := strconv . ParseBool ( value ) ; err == nil {", "del_tokens": "if v , err := strconv . ParseBool ( value ) ; err == nil {", "commit_type": "allow"}
{"commit_tokens": ["Add", "mssql", "dialect", "for", "transaction", "tests"], "add_tokens": "} , \" \" , \" \" , \" \" ) } , \" \" , \" \" , \" \" )", "del_tokens": "} , \" \" , \" \" ) } , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["fixed", "some", "tests", "and", "improved", "tests", "on", "auth", "for", "oauth2", "with", "state"], "add_tokens": "verifyHasString ( T , \" \" , f . Struct [ 0 ] . DartName ( ) ) verifyHasString ( T , \" \" , f . Struct [ 1 ] . DartName ( ) ) verifyHasString ( T , \" \" , f . Struct [ 2 ] . DartName ( ) ) verifyHasString ( T , \" \" , decl )", "del_tokens": "verifyHasString ( T , \" \" , f . Struct [ 0 ] . Dart ( ) ) verifyHasString ( T , \" \" , f . Struct [ 1 ] . Dart ( ) ) verifyHasString ( T , \" \" , f . Struct [ 2 ] . Dart ( ) ) verifyHasString ( T , \" \" , decl )", "commit_type": "fix"}
{"commit_tokens": ["added", "code", "location", "and", "readme"], "add_tokens": "NumberOfPassedExamples int NumberOfFailedExamples int FailureMessage string", "del_tokens": "NumberOfRunExamples int Column int", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "on", "32bit", "platform"], "add_tokens": "hash ^= int64 ( b ) hash ^= int64 ( b )", "del_tokens": "hash ^= int ( b ) hash ^= int ( b )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "flash", ".", "Error", "flash", ".", "Success", "formatting"], "add_tokens": "if len ( args ) == 0 { f . Out [ \" \" ] = msg } else { f . Out [ \" \" ] = fmt . Sprintf ( msg , args ) } if len ( args ) == 0 { f . Out [ \" \" ] = msg } else { f . Out [ \" \" ] = fmt . Sprintf ( msg , args ) }", "del_tokens": "f . Out [ \" \" ] = fmt . Sprintf ( msg , args ) f . Out [ \" \" ] = fmt . Sprintf ( msg , args )", "commit_type": "fix"}
{"commit_tokens": ["Uses", "random", "paths", "with", "slashes", "for", "storagedriver", "tests", "adds", "edge", "cases"], "add_tokens": "if srcDirname != strings . TrimSuffix ( sp . path ( ) , \" \" ) + \" \" { if dirname != strings . TrimSuffix ( parent . path ( ) , \" \" ) + \" \" {", "del_tokens": "if sp . path ( ) != srcDirname { if dirname != parent . path ( ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "watchonly", "bool", "to", "stxo", "db"], "add_tokens": "create table if not exists stxos ( outpoint text primary key not null , value integer , height integer , scriptPubKey text , watchOnly integer , spendHeight integer , spendTxid text ) ;", "del_tokens": "create table if not exists stxos ( outpoint text primary key not null , value integer , height integer , scriptPubKey text , spendHeight integer , spendTxid text ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "os", ".", "Open", "in", "tests", "for", "weekly", ".", "2011", "-", "04", "-", "13", "."], "add_tokens": "voc , err := os . Open ( \" \" ) output , err := os . Open ( \" \" )", "del_tokens": "voc , err := os . Open ( \" \" , os . O_RDONLY , 0600 ) output , err := os . Open ( \" \" , os . O_RDONLY , 0600 )", "commit_type": "fix"}
{"commit_tokens": ["CHanged", "orders", "of", "fields", "of", "NumberInfo"], "add_tokens": "Name string `json:\"name\"` Created string `json:\"created\"`", "del_tokens": "Created string `json:\"created\"` Name string `json:\"name\"`", "commit_type": "change"}
{"commit_tokens": ["Fixed", "Unique", "constraint", "detection", "for", "sqlite3"], "add_tokens": "if myT , ok := myField . Value ( ) . ( Type ) ; ok { if theirT , ok := theirField . Value ( ) . ( Type ) ; ok { if myT != theirT { // ObjectType fields can be stored as a RawType on backends without // a native object type, so we treat raw fields as object fields if myT == ObjectType && theirT == RawType { continue } // some backends store times as integers, so allow that too if myT == TimeType && theirT == IntType {", "del_tokens": "if myV , ok := myField . Value ( ) . ( Type ) ; ok { if theirV , ok := theirField . Value ( ) . ( Type ) ; ok { if myV != theirV { // the one exception to Type equivalence is that ObjectType fields can be stored // as a RawType on backends without a native object type, so we treat raw fields // as object fields if myV == ObjectType {", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "--", "new", "to", "always", "open", "URL", "in", "a", "new", "tab", "."], "add_tokens": "newtab := flag . Bool ( \" \" , false , \" \" ) if len ( tabs ) == 0 || * newtab {", "del_tokens": "if len ( tabs ) == 0 {", "commit_type": "add"}
{"commit_tokens": ["Allow", "env", "vars", "in", "stream", "URLs"], "add_tokens": "expandedRoute := os . ExpandEnv ( uri ) u , err := url . Parse ( expandedRoute )", "del_tokens": "u , err := url . Parse ( uri )", "commit_type": "allow"}
{"commit_tokens": ["Change", "tls_server_name", "to", "server_host_override", "and", "improve", "README"], "add_tokens": "tlsServerName = flag . String ( \" \" , \" \" , \" \" )", "del_tokens": "tlsServerName = flag . String ( \" \" , \" \" , \" \" )", "commit_type": "change"}
{"commit_tokens": ["Create", "function", "wrappers", "around", "scripts", "to", "make", "them", "easier", "to", "use"], "add_tokens": "tx1 . getAndMoveJobsToExecuting ( jobsReadyAndSortedKey , newScanStringsHandler ( & gotIds ) ) tx . retryOrFailJob ( tc . job , newScanBoolHandler ( & ( gotReturns [ i ] ) ) )", "del_tokens": "tx1 . script ( getAndMoveJobsToExecutingScript , redis . Args { jobsReadyAndSortedKey } , newScanStringsHandler ( & gotIds ) ) tx . script ( retryOrFailJobScript , redis . Args { tc . job . key ( ) , tc . job . id , tc . job . priority } , newScanBoolHandler ( & ( gotReturns [ i ] ) ) )", "commit_type": "create"}
{"commit_tokens": ["Update", "ConvertDoc", "and", "ConvertDocx", "to", "return", "errors", "."], "add_tokens": "func ConvertDoc ( r io . Reader ) ( string , map [ string ] string , error ) { return \" \" , nil , fmt . Errorf ( \" \" , err ) // TODO: Remove this. // TODO: Remove this. // TODO: Remove this. // TODO: Remove this. // TODO: Should errors in either of the above Goroutines stop things from progressing? // TODO: Check for errors instead of len(body) == 0? return body , meta , nil", "del_tokens": "func ConvertDoc ( r io . Reader ) ( string , map [ string ] string ) { log . Println ( \" \" , err ) return \" \" , nil return body , meta", "commit_type": "update"}
{"commit_tokens": ["Fix", "*", "behavior", "to", "be", "standards", "compliant", "."], "add_tokens": "if c . allowedOriginsAll { if c . allowedOriginsAll {", "del_tokens": "if c . allowedOriginsAll && c . allowCredentials { // See https://github.com/rs/cors/issues/55 log . Print ( \" \" ) } if c . allowedOriginsAll && ! c . allowCredentials { if c . allowedOriginsAll && ! c . allowCredentials {", "commit_type": "fix"}
{"commit_tokens": ["make", "use", "of", "google", "query", "string"], "add_tokens": "type dnsResolveOptions struct { Hostnames string `url:\"hostnames\"` } type dnsReverseOptions struct { Ips string `url:\"ips\"` } options := & dnsResolveOptions { Hostnames : strings . Join ( hostnames , \" \" ) , } url , err := c . buildUrl ( resolvePath , options ) options := & dnsReverseOptions { Ips : strings . Join ( ips , \" \" ) , } url , err := c . buildUrl ( reversePath , options )", "del_tokens": "params := QueryStringParams { \" \" : strings . Join ( hostnames , \" \" ) } url , err := c . buildUrl ( resolvePath , params ) params := QueryStringParams { \" \" : strings . Join ( ips , \" \" ) } url , err := c . buildUrl ( reversePath , params )", "commit_type": "make"}
{"commit_tokens": ["make", "random", "numbers", "more", "visible"], "add_tokens": "data [ i ] = math . Floor ( 1000 * r . Float64 ( ) )", "del_tokens": "data [ i ] = r . Float64 ( )", "commit_type": "make"}
{"commit_tokens": ["Add", "another", "testing", "helper", "."], "add_tokens": "// check interfaces var ( _ http . Handler = ( * basicAuthHandler ) ( nil ) )", "del_tokens": "// check interface var _ http . Handler = ( * basicAuthHandler ) ( nil )", "commit_type": "add"}
{"commit_tokens": ["make", "default", "values", "visible", "to", "user"], "add_tokens": "DefaultFileName = \" \" // default logging filename DefaultConfigFileName = \" \" // default configuration filename DefaultTimeFormat = \" \" // defaulttime format bufSize = 1000 // buffer size for writer queueSize = 1000 // chan queue size in async logging return FileLogger ( name , WARNING , BasicFormat , DefaultFileName , false ) return FileLogger ( name , NOTSET , RichFormat , DefaultFileName , false ) logger . timeFormat = DefaultTimeFormat", "del_tokens": "defaultFileName = \" \" // default logging filename configFileName = \" \" // default configuration filename defaultTimeFormat = \" \" // defaulttime format bufSize = 1000 // buffer size for writer queueSize = 1000 // chan queue size in async logging return FileLogger ( name , WARNING , BasicFormat , defaultFileName , false ) return FileLogger ( name , NOTSET , RichFormat , defaultFileName , false ) logger . timeFormat = defaultTimeFormat", "commit_type": "make"}
{"commit_tokens": ["Updating", "the", "Roll", "()", "documentation"], "add_tokens": "// Roll updates the hash of a rolling window from just the entering // byte. You MUST call Write() and provide it with an initial window // of size at least 1 byte before using this method. You can then call // this method for every new byte entering the window. A copy of the // window is internally kept, and is updated along with the internal // state of the checksum every time Roll() is called.", "del_tokens": "// Roll updates the hash of a rolling window from the entering byte. // A copy of the window is internally kept from the last Write(). // This copy is updated along with the internal state of the checksum // in order to determine the new hash very quickly.", "commit_type": "update"}
{"commit_tokens": ["remove", "some", "of", "the", "priority", "level", "options", "given", "from", "rfc5424", "in", "the", "syslog", "collector"], "add_tokens": "msg . Priority = adjustInt ( parsedData [ \" \" ] . ( int ) % 8 ) msg . Priority = adjustInt ( parsedData [ \" \" ] . ( int ) % 8 ) // I need to adjust the possible prioritys from rfc3164 and rfc5424 // to the 5 priority options. func adjustInt ( in int ) int { if in < 3 { return 0 } if in < 5 { return in - 2 } return in - 3 }", "del_tokens": "msg . Priority = parsedData [ \" \" ] . ( int ) % 8 msg . Priority = parsedData [ \" \" ] . ( int ) % 8", "commit_type": "remove"}
{"commit_tokens": ["Make", "web", ".", "go", "compile", "on", "-", "release", ".", "It", "was", "using", "some", "new", "features", "from", "the", "vector", "package"], "add_tokens": "if args . Len ( ) != handlerType . NumIn ( ) { valArgs := make ( [ ] reflect . Value , args . Len ( ) ) for i := 0 ; i < args . Len ( ) ; i ++ { valArgs [ i ] = args . At ( i ) . ( reflect . Value )", "del_tokens": "if len ( args ) != handlerType . NumIn ( ) { valArgs := make ( [ ] reflect . Value , len ( args ) ) for i , j := range ( args ) { valArgs [ i ] = j . ( reflect . Value )", "commit_type": "make"}
{"commit_tokens": ["change", "nonce", "function", "using", "Nano"], "add_tokens": "nonce = uint64 ( time . Now ( ) . UnixNano ( ) ) * 1000", "del_tokens": "nonce = uint64 ( time . Now ( ) . Unix ( ) ) * 1000", "commit_type": "change"}
{"commit_tokens": ["Updated", "Stats", "to", "match", "other", "libraries"], "add_tokens": "// // If debug=true, additional information (left undocumented because it is // greatly subject to change) may be given when calling // TCPMsgRingStats.String(). func ( t * TCPMsgRing ) Stats ( debug bool ) * TCPMsgRingStats { func ( s * TCPMsgRingStats ) String ( ) string { return fmt . Sprintf ( \" \" , s ) }", "del_tokens": "func ( t * TCPMsgRing ) Stats ( ) * TCPMsgRingStats {", "commit_type": "update"}
{"commit_tokens": ["Remove", "logerrv", "package", "in", "favour", "of", "simpler", "Keyvalser", "interface", "."], "add_tokens": "// Cause was copied from https://github.com/pkg/errors", "del_tokens": "// Cause has been copied from https://github.com/pkg/errors // Licence: BSD 2-clause: https://github.com/pkg/errors/blob/master/LICENSE", "commit_type": "remove"}
{"commit_tokens": ["fixed", "a", "pointer", "related", "bug"], "add_tokens": "func ( item * Item ) Export ( ) map [ string ] interface { } {", "del_tokens": "func ( item Item ) Export ( ) map [ string ] interface { } {", "commit_type": "fix"}
{"commit_tokens": ["added", "an", "nfs", "driver", "skeleton"], "add_tokens": "providers = [ ] string { aws . Name }", "del_tokens": "providers = [ ] string { ebs . Name }", "commit_type": "add"}
{"commit_tokens": ["Add", "default", "buffer", "size", "to", "couchQuery"], "add_tokens": "const ( defaultBufferSize = 50 ) BufferSize : defaultBufferSize , q . BufferSize = defaultBufferSize", "del_tokens": "BufferSize : 50 ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "os", ".", "stdErr", "from", "log", ".", "Println"], "add_tokens": "log . Println ( strings . TrimSpace ( msg ) )", "del_tokens": "log . Println ( os . Stderr , strings . TrimSpace ( msg ) )", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "formatter", "swapping", "race", "condition"], "add_tokens": "msg [ ] byte // use our formatter instead of entry.String() msg , err = hook . formatter . Format ( entry ) msg [ ] byte // use our formatter instead of entry.String() msg , err = hook . formatter . Format ( entry ) fd . Write ( msg )", "del_tokens": "// use our formatter formatter := entry . Logger . Formatter entry . Logger . Formatter = hook . formatter defer func ( ) { // assign back original formatter entry . Logger . Formatter = formatter } ( ) msg string msg , err = entry . String ( ) msg string msg , err = entry . String ( ) fd . WriteString ( msg )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "Decoder", ".", "Header", "documentation"], "add_tokens": "// Header returns the first line that came from the reader, or returns the // defined header by the caller.", "del_tokens": "// Header returns the first line that came from the reader.", "commit_type": "improve"}
{"commit_tokens": ["adding", "additional", "logging", "for", "special", "character", "filtering", "issue"], "add_tokens": "Describe ( \" \" , func ( ) { Context ( \" \" , func ( ) { It ( \" \" , func ( ) { entry , err := ldapManager . GetLdapUser ( config , \" \" , \" \" ) Ω( e rr) . S hould( B eNil( ) ) Ω( e ntry) . S houldNot( B eNil( ) ) } ) } )", "del_tokens": "Describe ( \" \" , func ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "example", "use", "sandbox", "page", "for", "edit"], "add_tokens": "\" \" // the username and passsword are required, but the domain is not err = client . Login ( config . Username , config . Password ) page , err := client . Read ( \" \" ) for _ , rev := range page . Revisions { fmt . Println ( rev . Body ) \" \" : \" \" , userStrs := [ ] string { \" \" , config . Username , \" \" } editConfig [ \" \" ] = strings . Join ( userStrs , \" \" ) fmt . Println ( editConfig [ \" \" ] )", "del_tokens": "// The username and passsword are required client . Username = config . Username client . Password = config . Password // But the domain is not err = client . Login ( ) resp , err := client . Read ( \" \" ) for _ , page := range resp . Query . Pages { for _ , rev := range page . Revisions { fmt . Println ( rev . Body ) } \" \" : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["move", "android", "in", "its", "own", "folder"], "add_tokens": "// created: 21/11/2010 by Laurent Le Goff, Stani Michiels", "del_tokens": "// created: 21/11/2010 by Laurent Le Goff", "commit_type": "move"}
{"commit_tokens": ["Implement", "docker", "exec", "with", "standalone", "client", "lib", "."], "add_tokens": "func ( cli * Client ) ContainerAttach ( options types . ContainerAttachOptions ) ( types . HijackedResponse , error ) {", "del_tokens": "func ( cli * Client ) ContainerAttach ( options types . ContainerAttachOptions ) ( * types . HijackedResponse , error ) {", "commit_type": "implement"}
{"commit_tokens": ["Add", "store", "customer", "support", "address", "to", "setting"], "add_tokens": "setting := Admin . AddResource ( & models . Setting { } , & admin . Config { Singleton : true } ) setting . UseTheme ( \" \" ) setting . Meta ( & admin . Meta { Name : \" \" , Type : \" \" } ) setting . Meta ( & admin . Meta { Name : \" \" , Type : \" \" } )", "del_tokens": "Admin . AddResource ( & models . Setting { } , & admin . Config { Singleton : true } )", "commit_type": "add"}
{"commit_tokens": ["Fix", "naming", "of", "DelegatorCarrier", "format"], "add_tokens": "{ basictracer . Delegator , basictracer . DelegatingCarrier ( & verbatimCarrier { b : map [ string ] string { } } ) } ,", "del_tokens": "{ basictracer . Accessor , basictracer . DelegatingCarrier ( & verbatimCarrier { b : map [ string ] string { } } ) } ,", "commit_type": "fix"}
{"commit_tokens": ["Moved", "to", "new", "FHIR", "models", "where", "the", "is", "a", "single", "Bundle", "type"], "add_tokens": "conditions , conditionErr := fhir . GetPatientConditions ( fhir . ResourcesForPatientUrl ( fhirEndpointUrl , patientId , \" \" ) ) chadScore := CalculateConditionPortion ( conditions , pie ) func CalculateConditionPortion ( patientConditions [ ] models . Condition , pie * Pie ) int { if FuzzyFindInConditions ( condition . Code , condition . System , patientConditions ) { func FuzzyFindInConditions ( codeStart , codeSystem string , conditions [ ] models . Condition ) bool { for _ , condition := range conditions { for _ , coding := range condition . Code . Coding {", "del_tokens": "conditionBundle , conditionErr := fhir . GetPatientConditions ( fhir . ResourcesForPatientUrl ( fhirEndpointUrl , patientId , \" \" ) ) chadScore := CalculateConditionPortion ( conditionBundle , pie ) func CalculateConditionPortion ( conditionBundle * models . ConditionBundle , pie * Pie ) int { if FuzzyFindConditionInBundle ( condition . Code , condition . System , conditionBundle ) { func FuzzyFindConditionInBundle ( codeStart , codeSystem string , bundle * models . ConditionBundle ) bool { for _ , entry := range bundle . Entry { for _ , coding := range entry . Resource . Code . Coding {", "commit_type": "move"}
{"commit_tokens": ["Add", "a", "method", "to", "accept", "a", "timestamp", "when", "logging"], "add_tokens": "import \" \" // LogWithTime will log a message at the provided level to all added loggers with the timestamp set to the // value of ts. func ( b * Base ) LogWithTime ( level LogLevel , ts time . Time , m * Attrs , msg string , a ... interface { } ) error { nm := newMessage ( ts , b , level , m , msg , a ... ) // Log will log a message at the provided level to all added loggers with the timestamp set to the time // Log was called. func ( b * Base ) Log ( level LogLevel , m * Attrs , msg string , a ... interface { } ) error { return b . LogWithTime ( level , clock ( ) . Now ( ) , m , msg , a ... ) }", "del_tokens": "// Log will log a message at the provided level to all added loggers func ( b * Base ) Log ( level LogLevel , m * Attrs , msg string , a ... interface { } ) error { nm := newMessage ( clock ( ) . Now ( ) , b , level , m , msg , a ... )", "commit_type": "add"}
{"commit_tokens": ["Add", "setting", "of", "tring", "to", "interface", "{}", "values"], "add_tokens": "dm := make ( dataMap , l ) case reflect . Interface : if ! ok { return } v . Set ( reflect . ValueOf ( arr [ idx ] ) ) set = true", "del_tokens": "dm := make ( dataMap , l , l ) case reflect . Interface , reflect . Invalid : return", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "cases", "for", "parseLine"], "add_tokens": "// \"fmt\" \" \" hostfile := hostess . NewHostfile ( hostess . GetHostsPath ( ) ) hostfile . Load ( ) hostfile . Parse ( )", "del_tokens": "// \"github.com/cbednarski/hostess\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "conditions", "in", "pool", ".", "go", "."], "add_tokens": "testPool . Put ( conn ) func TestPool_Close ( t * testing . T ) { testPool . Close ( ) t . Errorf ( \" \" ) testPool . Put ( conn ) t . Errorf ( \" \" , testPool . MaximumCapacity ( ) ) t . Errorf ( \" \" , testPool . MaximumCapacity ( ) ) p . Close ( )", "del_tokens": "err = testPool . Put ( conn ) if err != nil { t . Errorf ( \" \" , err ) } func TestPool_Destroy ( t * testing . T ) { testPool . Destroy ( ) t . Errorf ( \" \" ) err := testPool . Put ( conn ) if err == nil { t . Errorf ( \" \" , err ) } t . Errorf ( \" \" , testPool . MaximumCapacity ( ) ) t . Errorf ( \" \" , testPool . MaximumCapacity ( ) ) p . Destroy ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "repo", "path", "in", "config_test", ".", "go"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["add", "missing", "comments", "on", "flags", "and", "colors"], "add_tokens": "// Control what's printed in the header line. // See https://golang.org/pkg/log/#pkg-constants for an explanation of how // these flags work. // ANSI color escape codes endColor color = \" \\033 \" // \"reset everything\"", "del_tokens": "endColor color = \" \\033 \" // ANSI escape code for \"reset everything\"", "commit_type": "add"}
{"commit_tokens": ["add", "Mux", "tests", "better", "example"], "add_tokens": "// The BasicAuthProvider interface gets the credentials to use to perform the request // with Basic Authentication. type BasicAuthProvider interface { BasicAuth ( ) ( user string , pwd string ) // The ReaderProvider interface gets the Reader to use as the Body of the request. It has // higher priority than the ValuesProvider interface, so that if both interfaces are implemented, // the ReaderProvider is used. type ReaderProvider interface { Reader ( ) io . Reader // The ValuesProvider interface gets the values to send as the Body of the request. It has // lower priority than the ReaderProvider interface, so that if both interfaces are implemented, // the ReaderProvider is used. If the request has no explicit Content-Type set, it will be automatically // set to \"application/x-www-form-urlencoded\". type ValuesProvider interface { // The CookiesProvider interface gets the cookies to send with the request. type CookiesProvider interface { // The HeaderProvider interface gets the headers to set on the request. If an Authorization // header is set, it will be overridden by the BasicAuthProvider, if implemented. type HeaderProvider interface { // The Cmd struct defines a basic Command implementation.", "del_tokens": "// TODO : Naming, and take into account those additional interfaces. type BasicAuth interface { Credentials ( ) ( string , string ) type BodyReader interface { Body ( ) io . Reader type BodyKeyValuer interface { type Cookier interface { type Headerer interface { // The Cmd struct defines a basic command implementation.", "commit_type": "add"}
{"commit_tokens": ["fixed", "goroutine", "leak", "after", ".", "Stop", "()", "is", "called"], "add_tokens": "if len ( h . runners ) != len ( cfgs ) { return nil , nil , fmt . Errorf ( \" \" )", "del_tokens": "if len ( h . tickers ) != len ( cfgs ) { return nil , nil , fmt . Errorf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "deploy", ".", "go", "."], "add_tokens": "sTemplate , err := template . New ( \" \" ) . ParseFiles ( \" \" )", "del_tokens": "sTemplate , err := template . New ( \" \" ) . ParseFiles ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["added", "utp", "listen", "/", "dial"], "add_tokens": "utp \" \" // Dialer is just an embedded net.Dialer, with all its options. var nconn net . Conn switch rnet { case \" \" : nconn , err = d . Dialer . Dial ( rnet , rnaddr ) if err != nil { return nil , err } case \" \" : // construct utp dialer, with options on our net.Dialer utpd := utp . Dialer { Timeout : d . Dialer . Timeout , LocalAddr : d . Dialer . LocalAddr , } nconn , err = utpd . Dial ( rnet , rnaddr ) if err != nil { return nil , err } var nl net . Listener switch lnet { case \" \" : nl , err = utp . Listen ( lnet , lnaddr ) if err != nil { return nil , err } case \" \" : nl , err = net . Listen ( lnet , lnaddr ) if err != nil { return nil , err }", "del_tokens": "// Dialer is just an embed net.Dialer, with all its options. nconn , err := d . Dialer . Dial ( rnet , rnaddr ) if err != nil { return nil , err nl , err := net . Listen ( lnet , lnaddr ) if err != nil { return nil , err", "commit_type": "add"}
{"commit_tokens": ["Fix", "Pdbgf", "format", "for", "depth"], "add_tokens": "fmt . Printf ( \" \\n \" , nbskip , addOneForSkip ) nbInitialSkips = nbskip - addOneForSkip depth = finalDepth - nbInitialSkips - 1 if depth >= 0 { spaces = strings . Repeat ( \" \" , depth * 2 )", "del_tokens": "nbInitialSkips = nbskip + addOneForSkip depth = finalDepth - nbInitialSkips if depth >= 2 { spaces = strings . Repeat ( \" \" , depth - 2 )", "commit_type": "fix"}
{"commit_tokens": ["use", "dns", "-", "ipns", "for", "basehash", "path"], "add_tokens": "ipfsVersionPath = \" \"", "del_tokens": "ipfsVersionPath = \" \"", "commit_type": "use"}
{"commit_tokens": ["Use", "s3", "head", "instead", "of", "get", "to", "retrieve", "item", "metadata"], "add_tokens": "// Item returns a stow.Item instance of a container based on the name of the container and the key representing. The // retrieved item only contains metadata about the object. This ensures that only the minimum amount of information is // transferred. Calling item.Open() will actually do a get request and open a stream to read from. params := & s3 . HeadObjectInput { res , err := c . client . HeadObject ( params )", "del_tokens": "// Item returns a stow.Item instance of a container based on the // name of the container and the key representing params := & s3 . GetObjectInput { res , err := c . client . GetObject ( params ) defer res . Body . Close ( )", "commit_type": "use"}
{"commit_tokens": ["Add", "PersistentDatastore", "interface", "and", "implement", "it", "on", "wrappers"], "add_tokens": "// error correction. // don't free disk space by just removing data from them. // PersistentDatastore is an interface that should be implemented by datastores // which can report disk usage. type PersistentDatastore interface { Datastore // DiskUsage returns the space used by a datastore, in bytes. DiskUsage ( ) ( uint64 , error ) } // DiskUsage checks if a Datastore is a // PersistentDatastore and returns its DiskUsage(), // otherwise returns 0. func DiskUsage ( d Datastore ) ( uint64 , error ) { persDs , ok := d . ( PersistentDatastore ) if ! ok { return 0 , nil } return persDs . DiskUsage ( ) }", "del_tokens": "// error correction // don't free disk space by just removing data from them", "commit_type": "add"}
{"commit_tokens": ["Changed", "url", "for", "test", "case", "to", "address", "failed", "unit", "tests", "."], "add_tokens": "\" \" : true ,", "del_tokens": "\" \" : true ,", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "dns", "commands"], "add_tokens": "Status string `xml:\"Status,attr\"` Command string `xml:\"RequestedCommand\"'` Domains [ ] DomainGetListResult `xml:\"CommandResponse>DomainGetListResult>Domain\"` DomainInfo DomainInfo `xml:\"CommandResponse>DomainGetInfoResult\"` DomainDNSHosts DomainDNSGetHostsResult `xml:\"CommandResponse>DomainDNSGetHostsResult\"` DomainDNSSetHosts DomainDNSSetHostsResult `xml:\"CommandResponse>DomainDNSSetHostsResult\"` Errors [ ] ApiError `xml:\"Errors>Error\"`", "del_tokens": "Status string `xml:\"Status,attr\"` Command string `xml:\"RequestedCommand\"'` Domains [ ] DomainGetListResult `xml:\"CommandResponse>DomainGetListResult>Domain\"` DomainInfo DomainInfo `xml:\"CommandResponse>DomainGetInfoResult\"` Errors [ ] ApiError `xml:\"Errors>Error\"`", "commit_type": "add"}
{"commit_tokens": ["update", "Tick", "to", "use", "the", "FSM", "errorState", "to", "process", "any", "error", "events", "and", "give", "us", "a", "good", "state", "and", "data", "to", "use", "when", "errors", "have", "occurred"], "add_tokens": "if state , _ := fsm . findSerializedState ( secondEvents ) ; state . StateName != \" \" { _ , err := f . panicSafeDecide ( s , HistoryEvent { } , nil )", "del_tokens": "if state , _ := fsm . findSerializedState ( secondEvents ) ; state . State != \" \" { _ , err := f . decide ( s , HistoryEvent { } , nil )", "commit_type": "update"}
{"commit_tokens": ["add", "flag", "to", "test", "network", "intercept", "if", "available"], "add_tokens": "debugger * Gcd testListener net . Listener testSkipNetworkIntercept bool testPath string testDir string testPort string testServerAddr string // TODO: remove this once mainline chrome supports it. flag . BoolVar ( & testSkipNetworkIntercept , \" \" , true , \" \" ) if testSkipNetworkIntercept { //target.Debug(true) //target.DebugEvents(true)", "del_tokens": "debugger * Gcd testListener net . Listener testPath string testDir string testPort string testServerAddr string //flag.StringVar(&testPath, \"chrome\", \"C:\\\\Users\\\\isaac\\\\AppData\\\\Local\\\\Google\\\\Chrome SxS\\\\Application\\\\chrome.exe\", \"path to chrome\") // TODO: test in osx to see if this just doesn't work in Windows yet. if runtime . GOOS == \" \" { target . Debug ( true ) target . DebugEvents ( true )", "commit_type": "add"}
{"commit_tokens": ["add", "RowsStrict", "and", "RowStrict", "for", "strict", "scanning"], "add_tokens": "rows , err := db . Query ( \" \" ) func ExampleRowStrict ( ) { db := exampleDB ( ) rows , err := db . Query ( \" \" ) if err != nil { panic ( err ) } var person struct { ID int Name string `db:\"name\"` } err = scan . RowStrict ( & person , rows ) if err != nil { panic ( err ) } json . NewEncoder ( os . Stdout ) . Encode ( & person ) // Output: // {\"ID\":0,\"Name\":\"brett\"} } rows , err := db . Query ( \" \" ) func ExampleRowsStrict ( ) { db := exampleDB ( ) rows , err := db . Query ( \" \" ) if err != nil { panic ( err ) } var persons [ ] struct { ID int Name string `db:\"name\"` } err = scan . Rows ( & persons , rows ) if err != nil { panic ( err ) } json . NewEncoder ( os . Stdout ) . Encode ( & persons ) // Output: // [{\"ID\":0,\"Name\":\"brett\"},{\"ID\":0,\"Name\":\"fred\"}] }", "del_tokens": "rows , err := db . Query ( \" \" ) rows , err := db . Query ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "e", "for", "number", "parsing"], "add_tokens": "for isDigit ( s . peek ( ) ) || s . peek ( ) == '.' || s . peek ( ) == 'e' {", "del_tokens": "for isDigit ( s . peek ( ) ) || s . peek ( ) == '.' {", "commit_type": "allow"}
{"commit_tokens": ["Use", "identifiers", "not", "hardcoded", "values", "."], "add_tokens": "\" \" msgType := int32 ( textsecure . Envelope_CIPHERTEXT ) msgType = int32 ( textsecure . Envelope_PREKEY_BUNDLE )", "del_tokens": "msgType := int32 ( 1 ) // textsecure.Envelope_CIPHERTEXT msgType = int32 ( 3 ) // textsecure.Envelope_PREKEY_BUNDLE", "commit_type": "use"}
{"commit_tokens": ["Adding", "lshw", ".", "Cmd", "()"], "add_tokens": "\" \" func ( l * lshw ) Cmd ( ) string { return strings . Join ( l . cmd . Args , \" \" ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "local", "halgo", "for", "examples"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["fix", "bug", "in", "CallParamValue", "TestHelloWorld", "now", "works"], "add_tokens": "// walk recursively goes through each node and translates the nodes to // javascript, writing the result to s.wr s . js ( param . Key , \" \" ) ( & state { wr : & buf , scope : s . scope } ) . walk ( param . Value )", "del_tokens": "// walk recursively goes through each node and executes the indicated logic and // writes the output // TODO: Reference to data item. if err := Write ( & buf , param . Value ) ; err != nil { s . errorf ( \" \" , err ) } // TODO: unify the range implementation", "commit_type": "fix"}
{"commit_tokens": ["Added", "todo", "and", "formatting", "changes", "."], "add_tokens": "// TODO(bdowns328) Make select post match random.", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "import", "path", "of", "gorp", "in", "test"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "goroutine", "leak", "caused", "by", "connection", "error", "during", "IDLE"], "add_tokens": "defaultPollInterval = time . Minute Stop : stop , close ( stopOrRestart )", "del_tokens": "defaultPollInterval = time . Minute Stop : stop ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "GetProfilesForDirectMessageList", "to", "get", "users", "of", "all", "teams"], "add_tokens": "m . log . Debugf ( \" \" , v . Name , v . Id ) m . log . Debugf ( \" \" , v . Id , v . Name ) mmusers , _ := m . Client . GetProfilesForDirectMessageList ( m . Team . Id )", "del_tokens": "m . log . Debug ( \" \" , v . Name , \" \" , v . Id ) m . log . Debug ( \" \" , v . Id , \" \" , v . Name ) mmusers , _ := m . Client . GetProfiles ( m . Client . GetTeamId ( ) , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Improve", "a", "bit", "the", "documentation", "."], "add_tokens": "// Package ethtool aims to provide a library giving a simple access to the // Linux SIOCETHTOOL ioctl operations. It can be used to retrieve informations // from a network device like statistics, driver related informations or // even the peer of a VETH interface. // Maximum size of an interface name // ioctl ethtool request // MAX_GSTRINGS maximum number of stats entries that ethtool can // retrieve currently. // DriverName returns the driver name of the given interface. // Stats retrieves stats of the given interface name.", "del_tokens": "// MAX_GSTRINGS maximum number of stats entries that ethtool can retrieve currently. // Stats retrieves stats of the given interface name", "commit_type": "improve"}
{"commit_tokens": ["Made", "canvas", "demo", "more", "illustrative"], "add_tokens": "batch . Draw ( region , - 200 , 0 , 512 , 320 , .5 , .5 , 0 , nil ) batch . Draw ( region , 100 , 200 , 512 , 320 , .5 , .5 , 0 , nil ) batch . Draw ( region , 200 , - 100 , 512 , 320 , .5 , .5 , 0 , nil )", "del_tokens": "batch . Draw ( region , 0 , 0 , 512 , 320 , .5 , .5 , 0 , nil )", "commit_type": "make"}
{"commit_tokens": ["add", "license", "header", "and", "update", "README"], "add_tokens": "// Copyright (C) 2017 Minio Inc. // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // Package aead implements the DARP format and provides an API for // en/drcrypting data streams. package aead // import \"github.com/minio/aead\"", "del_tokens": "package aead", "commit_type": "add"}
{"commit_tokens": ["Fix", "nil", "pointer", "when", "we", "initialise", "the", "transport", "for", "the", "first", "time"], "add_tokens": "if oldTr != nil { if err := oldTr . Stop ( ) ; err != nil { return err }", "del_tokens": "if err := oldTr . Stop ( ) ; err != nil { return err", "commit_type": "fix"}
{"commit_tokens": ["add", "test", "for", "Logger", ".", "Fatal", "()"], "add_tokens": "var exit func ( code int ) = os . Exit // this is for testing so we can prevent an actual exit exit ( 1 )", "del_tokens": "os . Exit ( 1 )", "commit_type": "add"}
{"commit_tokens": ["add", "rest", "package", "from", "https", ":", "//", "github", ".", "com", "/", "browny", "/", "goweb", "-", "scaffold"], "add_tokens": "\" \" \" \" \" \" var handler rest . Handler router := rest . BuildRouter ( handler ) n := negroni . Classic ( ) n . Use ( negroni . HandlerFunc ( cors ) ) n . UseHandler ( router ) n . Run ( fmt . Sprintf ( \" \" , 3456 ) ) } // cors middleware (cross-origin resource sharing) func cors ( rw http . ResponseWriter , req * http . Request , next http . HandlerFunc ) { // Setting Access-Control-Allow-Origin to wildcard grants too much access. // Turn this on only if it is necessary. // rw.Header().Set(\"Access-Control-Allow-Origin\", \"*\") rw . Header ( ) . Set ( \" \" , \" \" ) if req . Method == \" \" { method := req . Header . Get ( \" \" ) if method == \" \" { http . Error ( rw , \" \" , http . StatusBadRequest ) return } rw . Header ( ) . Set ( \" \" , \" \" ) return } next ( rw , req )", "del_tokens": "fmt . Println ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "find", "queue", "subscriber", "to", "reduce", "chances", "to", "always", "get", "the", "first"], "add_tokens": "sub . RLock ( ) sub . RUnlock ( ) len := len ( sl ) if len > 1 && rsub == sl [ 0 ] { copy ( sl , sl [ 1 : len ] ) sl [ len - 1 ] = rsub } ss . Lock ( ) ss . Unlock ( )", "del_tokens": "sub . Lock ( ) sub . Unlock ( ) ss . RLock ( ) ss . RUnlock ( )", "commit_type": "fix"}
{"commit_tokens": ["Make", "randomNeighbours", "()", "pick", "fairly"], "add_tokens": "\" \" var total int64 = 0 weights := make ( map [ PeerName ] int64 ) // First iterate the whole set, counting how often each neighbour appears total ++ weights [ dst ] ++ } } needed := int ( math . Min ( math . Log2 ( float64 ( len ( r . unicastAll ) ) ) , float64 ( len ( weights ) ) ) ) destinations := make ( [ ] PeerName , 0 , needed ) for len ( destinations ) < needed { // Pick a random point on the distribution and linear search for it rnd := rand . Int63n ( total ) for dst , count := range weights { if rnd < count { destinations = append ( destinations , dst ) // Remove the one we selected from consideration delete ( weights , dst ) total -= count rnd -= count return destinations", "del_tokens": "destinations := make ( peerNameSet ) count := int ( math . Log2 ( float64 ( len ( r . unicastAll ) ) ) ) // depends on go's random map iteration destinations [ dst ] = struct { } { } if len ( destinations ) >= count { res := make ( [ ] PeerName , 0 , len ( destinations ) ) for dst := range destinations { res = append ( res , dst ) } return res", "commit_type": "make"}
{"commit_tokens": ["Add", "ability", "to", "specify", "the", "default", "scheme"], "add_tokens": "type Transformer func ( rawURL string ) string func DefaultToHTTP ( rawURL string ) string { return defaultToScheme ( rawURL , \" \" ) } func DefaultToHTTPS ( rawURL string ) string { return defaultToScheme ( rawURL , \" \" ) } func defaultToScheme ( rawURL , defaultScheme string ) string { rawURL = defaultScheme + \" \" + rawURL rawURL = defaultScheme + \" \" + rawURL } return rawURL } // Parse parses raw URL string into the net/url URL struct. // It uses the url.Parse() internally, but it slightly changes // its behavior: // 1. It forces the default scheme and port to http // 2. It favors absolute paths over relative ones, thus \"example.com\" // is parsed into url.Host instead of url.Path. // 4. It lowercases the Host (not only the Scheme). func Parse ( rawURL string ) ( * url . URL , error ) { return ParseWithTransforms ( rawURL , DefaultToHTTP ) } func ParseWithTransforms ( rawURL string , transformers ... Transformer ) ( * url . URL , error ) { for _ , transformer := range transformers { rawURL = transformer ( rawURL )", "del_tokens": "// Parse parses raw URL string into the net/url URL struct. // It uses the url.Parse() internally, but it slightly changes // its behavior: // 1. It forces the default scheme and port. // 2. It favors absolute paths over relative ones, thus \"example.com\" // is parsed into url.Host instead of url.Path. // 4. It lowercases the Host (not only the Scheme). func Parse ( rawURL string ) ( * url . URL , error ) { rawURL = \" \" + rawURL rawURL = \" \" + rawURL", "commit_type": "add"}
{"commit_tokens": ["add", "DriverErr", "to", "retrieve", "the", "original", "database", "error"], "add_tokens": "type dbErr struct { msg string err error } func ( err * dbErr ) Error ( ) string { return fmt . Sprintf ( \" \" , err . msg , err . err ) } // DriverErr returns the original error as returned by the database driver // if the error comes from the driver, with the second value set to true. // Otherwise, it returns err itself with false as second value. func DriverErr ( err error ) ( error , bool ) { if dbe , ok := err . ( * dbErr ) ; ok { return dbe . err , true } return err , false } return & dbErr { msg : \" \" , err : err } return & dbErr { msg : \" \" , err : err } return & dbErr { msg : \" \" , err : err } return & dbErr { msg : \" \" , err : err } return & dbErr { msg : \" \" , err : err } return & dbErr { msg : \" \" , err : err }", "del_tokens": "return fmt . Errorf ( \" \" , err ) return fmt . Errorf ( \" \" , err ) return fmt . Errorf ( \" \" , err ) return fmt . Errorf ( \" \" , err ) return fmt . Errorf ( \" \" , err ) return fmt . Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Adds", "support", "for", "labeled", "metrics", "and", "metrics", "filtering", "."], "add_tokens": "expectedError := errors . New ( \" \" ) expect := \" \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\" \"", "del_tokens": "expectedError := errors . New ( \" \" ) expect := \" \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\" \"", "commit_type": "add"}
{"commit_tokens": ["add", "heartbeat", "support", "for", "ssh", "forward"], "add_tokens": "Version = \" \" rawCert , rawKey := defaultRawCert , defaultRawKey if defaultRawCert == nil || defaultRawKey == nil { rawCert , rawKey = generateKeyPair ( ) }", "del_tokens": "Version = \" \" rawCert , rawKey := generateKeyPair ( )", "commit_type": "add"}
{"commit_tokens": ["Adding", "method", "to", "get", "stream", "as", "net", ".", "Conn"], "add_tokens": "// Open is used to create a new stream as a net.Conn func ( s * Session ) Open ( ) ( net . Conn , error ) { return s . OpenStream ( ) } // OpenStream is used to create a new stream func ( s * Session ) OpenStream ( ) ( * Stream , error ) {", "del_tokens": "// Open is used to create a new stream func ( s * Session ) Open ( ) ( * Stream , error ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "for", "(", "expr", ")", "{}", "for", "{}", "."], "add_tokens": "// ForStmt provide \"for in\" expression statement. // LoopStmt provide \"for expr\" expression statement. type LoopStmt struct { StmtImpl Expr Expr Stmts [ ] Stmt }", "del_tokens": "// ForStmt provide \"for\" expression statement.", "commit_type": "add"}
{"commit_tokens": ["use", "a", "server", "stuct", "to", "not", "pass", "around", "to", "much", "stuff"], "add_tokens": "\" \" conn net . Conn reader * bufio . Reader writer * bufio . Writer * server . Server func NewContext ( conn net . Conn , server * server . Server ) * Context { return & Context { conn , reader , writer , server , false , false } context . Logger . Printf ( \" \\r \\n \" , context . conn . RemoteAddr ( ) , line ) interpreter := Interpreter { context }", "del_tokens": "\" \" \" \" \" \" conn net . Conn reader * bufio . Reader writer * bufio . Writer logger * log . Logger cfg * config . Config backend backends . Abstract func NewContext ( conn net . Conn , logger * log . Logger , cfg * config . Config , backend backends . Abstract ) * Context { return & Context { conn : conn , reader : reader , writer : writer , logger : logger , cfg : cfg , backend : backend , } context . logger . Printf ( \" \\r \\n \" , context . conn . RemoteAddr ( ) , line ) interpreter := Interpreter { context , context . backend }", "commit_type": "use"}
{"commit_tokens": ["Change", "wording", "of", "init", "panic", "check", "message", "."], "add_tokens": "panic ( fmt . Sprintf ( \" \" , f . name ) )", "del_tokens": "panic ( fmt . Sprintf ( \" \" , f . name ) )", "commit_type": "change"}
{"commit_tokens": ["add", "helper", "func", "for", "primary", "keys"], "add_tokens": "PrimaryKeys [ ] PrimaryKey md . PrimaryKeys = getPrimaryKeys ( utd )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Move", "some", "tests", "to", "alwaysNegative"], "add_tokens": "{ `1.1` , nil } , { `.1.` , nil } , { `1.1.1` , nil } , { `1:1` , nil } , { `:1:` , nil } , { `1:1:1` , nil } ,", "del_tokens": "{ `1.1.1` , nil } , { `1.1..1` , nil } , { `1:1` , nil } , { `:2:` , nil } , { `1:2:3` , nil } ,", "commit_type": "move"}
{"commit_tokens": ["Add", "timeout", "attribute", "to", "command"], "add_tokens": "\" \" Timeout int64 `json:\"timeout\"` sysCommand := sys . NewCommand ( c . Command , sys ) sysCommand . SetTimeout ( c . Timeout ) results = append ( results , ValidateValue ( c , \" \" , c . ExitStatus , sysCommand . ExitStatus ) ) results = append ( results , ValidateContains ( c , \" \" , c . Stdout , sysCommand . Stdout ) ) results = append ( results , ValidateContains ( c , \" \" , c . Stderr , sysCommand . Stderr ) ) Timeout : ( 10 * int64 ( time . Second ) / int64 ( time . Millisecond ) ) ,", "del_tokens": "syscommand := sys . NewCommand ( c . Command , sys ) results = append ( results , ValidateValue ( c , \" \" , c . ExitStatus , syscommand . ExitStatus ) ) results = append ( results , ValidateContains ( c , \" \" , c . Stdout , syscommand . Stdout ) ) results = append ( results , ValidateContains ( c , \" \" , c . Stderr , syscommand . Stderr ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "layer", "functionality", ".", "This", "allows", "content", "to", "be", "placed", "into", "layers", "the", "visibility", "of", "which", "can", "be", "controlled", "from", "the", "document", "reader", "."], "add_tokens": "f . layerInit ( ) f . EndLayer ( ) // Layers f . layerPutResourceDict ( ) f . layerPutLayers ( ) // Layers f . layerPutCatalog ( ) f . layerEndDoc ( )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "AfterConnect", "callback", "for", "ConnectionPool"], "add_tokens": "type ConnectionPoolOptions struct { MaxConnections int // max simultaneous connections to use (currently all are immediately connected) AfterConnect func ( * Connection ) error } parameters ConnectionParameters // parameters used when establishing connection options ConnectionPoolOptions // NewConnectionPool creates a new ConnectionPool. parameters are passed through to // Connect directly. func NewConnectionPool ( parameters ConnectionParameters , options ConnectionPoolOptions ) ( p * ConnectionPool , err error ) { p . connectionChannel = make ( chan * Connection , options . MaxConnections ) p . options = options for i := 0 ; i < p . options . MaxConnections ; i ++ { if p . options . AfterConnect != nil { err = p . options . AfterConnect ( c ) if err != nil { return } } for i := 0 ; i < p . options . MaxConnections ; i ++ {", "del_tokens": "parameters ConnectionParameters // options used when establishing connection MaxConnections int // NewConnectionPool creates a new ConnectionPool. options are passed through to // Connect directly. MaxConnections is max simultaneous connections to use // (currently all are immediately connected). func NewConnectionPool ( parameters ConnectionParameters , MaxConnections int ) ( p * ConnectionPool , err error ) { p . connectionChannel = make ( chan * Connection , MaxConnections ) p . MaxConnections = MaxConnections for i := 0 ; i < p . MaxConnections ; i ++ { for i := 0 ; i < p . MaxConnections ; i ++ {", "commit_type": "add"}
{"commit_tokens": ["fix", "ln", "and", "f", "methods"], "add_tokens": "func ( self * Journaler ) sendf ( priority journal . Priority , message string , a [ ] interface { } ) { self . send ( priority , fmt . Sprintf ( message , a ... ) ) func ( self * Journaler ) sendln ( priority journal . Priority , a [ ] interface { } ) { self . send ( priority , fmt . Sprintln ( a ... ) )", "del_tokens": "func ( self * Journal ) sendf ( priority journal . Priority , message string , a ... interface { } ) { self . send ( priority , fmt . Sprintf ( message , a ) ) func ( self * Journal ) sendln ( priority journal . Priority , message string , a ... interface { } ) { self . send ( priority , fmt . Sprintln ( message , a ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "for", "array", "decoding"], "add_tokens": "return 0 , InvalidJSONError ( \" \" )", "del_tokens": "return dec . cursor , nil", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Mset", "convenience", "method", "."], "add_tokens": "// Mset func ( rd * Redis ) Mset ( args ... interface { } ) * ResultSet { return rd . Command ( \" \" , args ... ) }", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "trailing", "newline", "to", "the", "test", "case"], "add_tokens": "10.37 . 12.18 devsite . com m . devsite . com `", "del_tokens": "10.37 . 12.18 devsite . com m . devsite . com `", "commit_type": "add"}
{"commit_tokens": ["fix", "keys", ".", "go", "with", "golint"], "add_tokens": "// Del removes the specified keys. // Dump serialize the value stored at key in a Redis-specific format and return it to the user. // Exists returns true if key exists. // Expire set a second timeout on key. // ExpireAt has the same effect and semantic as expire, // Keys returns all keys matching pattern. // Move moves key from the currently selected database (see SELECT) // to the specified destination database. // Object inspects the internals of Redis Objects associated with keys. // Persist removes the existing timeout on key, // PExpire works exactly like EXPIRE // PExpireAt has the same effect and semantic as EXPIREAT, // PTTL returns the remaining time to live of a key that has an expire set, // RandomKey returns a random key from the currently selected database. // Rename renames key to newkey. // Renamenx renames key to newkey if newkey does not yet exist. // Restore creates a key associated with a value that is obtained by deserializing // TTL returns the remaining time to live of a key that has a timeout. // Type returns the string representation of the type of the value stored at key. // Scan command:", "del_tokens": "// Removes the specified keys. // Serialize the value stored at key in a Redis-specific format and return it to the user. // Returns if key exists. // Set a timeout on key. // EXPIREAT has the same effect and semantic as EXPIRE, // Returns all keys matching pattern. // Move key from the currently selected database (see SELECT) to the specified destination database. // The OBJECT command allows to inspect the internals of Redis Objects associated with keys. // Remove the existing timeout on key, // This command works exactly like EXPIRE // PEXPIREAT has the same effect and semantic as EXPIREAT, // Like TTL this command returns the remaining time to live of a key that has an expire set, // Return a random key from the currently selected database. // Renames key to newkey. // Renames key to newkey if newkey does not yet exist. // Create a key associated with a value that is obtained by deserializing // Returns the remaining time to live of a key that has a timeout. // Returns the string representation of the type of the value stored at key.", "commit_type": "fix"}
{"commit_tokens": ["create", "a", "subscription", "in", "the", "db"], "add_tokens": "s := HubbubSubscription { Link : f . HubLink , FeedLink : f . Link } return h . db . UpdateHubbubSubscription ( s )", "del_tokens": "return nil", "commit_type": "create"}
{"commit_tokens": ["Fix", "an", "issue", "with", "overriding", "existing", "declarations"], "add_tokens": "declared = declared . Copy ( ) // Skip redundant declarations - they have to already have the same // value. if declaredNamespace , ok := declared . prefixes [ prefix ] ; ok { if value , ok := scope . prefixes [ prefix ] ; ok && declaredNamespace == value { continue } el . Attr = append ( el . Attr , declared . declare ( prefix , namespace ) ) err := transformExcC14n ( scope , declared , child , inclusiveNamespaces )", "del_tokens": "newDeclared := declared . Copy ( ) if _ , ok := newDeclared . prefixes [ prefix ] ; ok { continue el . Attr = append ( el . Attr , newDeclared . declare ( prefix , namespace ) ) err := transformExcC14n ( scope , newDeclared , child , inclusiveNamespaces )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "visual", "indicator", "on", "the", "box", "widget", "when", "b", ".", "IsFocused", "==", "true"], "add_tokens": "// NewPadder returns a new Padder. // OnEvent handles an event and propagates it the widget. // SetFocused set the focus on the widget. // IsFocused returns true if the widget is focused. func ( p * Padder ) IsFocused ( ) bool { return p . widget . IsFocused ( ) }", "del_tokens": "// Padder returns a new Padder.", "commit_type": "add"}
{"commit_tokens": ["add", "ability", "to", "show", "the", "count"], "add_tokens": "showIterationsCount bool // OptionShowCount will also print current count out of total func OptionShowCount ( ) Option { return func ( p * ProgressBar ) { p . config . showIterationsCount = true } } if c . showIterationsPerSecond && ! c . showIterationsCount { } else if ! c . showIterationsPerSecond && c . showIterationsCount { bytesString = fmt . Sprintf ( \" \" , s . currentNum , c . max ) } else if c . showIterationsPerSecond && c . showIterationsCount { bytesString = fmt . Sprintf ( \" \" , s . currentNum , c . max , float64 ( s . currentNum ) / time . Since ( s . startTime ) . Seconds ( ) )", "del_tokens": "if c . showIterationsPerSecond {", "commit_type": "add"}
{"commit_tokens": ["use", "new", "TTL", "interface", "in", "tests", "."], "add_tokens": "err = txn . ( ds . TTL ) . PutWithTTL ( key , bytes , time . Second ) ttltxn := txn . ( ds . TTL ) ttltxn = txn . ( ds . TTL )", "del_tokens": "err = txn . ( ds . TTLDatastore ) . PutWithTTL ( key , bytes , time . Second ) ttltxn := txn . ( ds . TTLDatastore ) ttltxn = txn . ( ds . TTLDatastore )", "commit_type": "use"}
{"commit_tokens": ["fix", "lint", "error", "with", "comments"], "add_tokens": "// ListMembers lists the members for an organization. If the authenticated // user is an owner of the organization, this will return both concealed and // public members, otherwise it will only return public members. // ListPublicMembers lists the public members for an organization.", "del_tokens": "// List the members for an organization. If the authenticated user is an owner // of the organization, this will return both concealed and public members, // otherwise it will only return public members. // List the public members for an organization.", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "local", "timezones", "in", "RFC3164", "parsing"], "add_tokens": "location * time . Location buff : buff , cursor : 0 , l : len ( buff ) , location : time . UTC , func ( p * Parser ) Location ( location * time . Location ) { p . location = location } ts , err = time . ParseInLocation ( tsFmt , string ( sub ) , p . location )", "del_tokens": "buff : buff , cursor : 0 , l : len ( buff ) , ts , err = time . Parse ( tsFmt , string ( sub ) )", "commit_type": "add"}
{"commit_tokens": ["Using", "a", "different", "number", "-", "of", "-", "leading", "-", "zeros", "func", "in", "util", ".", "go"], "add_tokens": "codec . Uncompress ( data , rinpos , len ( data ) , recovered , routpos )", "del_tokens": "codec . Decompress ( data , rinpos , len ( data ) , recovered , routpos )", "commit_type": "use"}
{"commit_tokens": ["add", "Hosts", "for", "port", "2197"], "add_tokens": "Development = \" \" Development2197 = \" \" Production = \" \" Production2197 = \" \"", "del_tokens": "Development = \" \" Production = \" \"", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "linter", "a", "little", "happier", ".", "Also", "added", "Chrome", "Canary", "for", "OSX", "and", "headless_shell", "for", "linux", "."], "add_tokens": "// NavigationCancelAndIgnore cancels the navigation and makes the requester of the navigation acts like the request was never made. // NavigationResponse define the type for ProcessNavigation `response` if frameid , ok := res [ \" \" ] ; ! ok { return frameid . ( string ) , nil func ( remote * RemoteDebugger ) ProcessNavigation ( navigationID int , navigation NavigationResponse ) error { \" \" : navigationID , func ( remote * RemoteDebugger ) SendRune ( c rune ) error { if _ , err := remote . sendRequest ( \" \" , Params { _ , err := remote . sendRequest ( \" \" , Params { if err := remote . DomainEvents ( domain . Name , enable ) ; err != nil { return err }", "del_tokens": "// CancelAndIgnore cancels the navigation and makes the requester of the navigation acts like the request was never made. if frameId , ok := res [ \" \" ] ; ! ok { return frameId . ( string ) , nil func ( remote * RemoteDebugger ) ProcessNavigation ( navigationId int , navigation NavigationResponse ) error { \" \" : navigationId , func ( remote * RemoteDebugger ) SendRune ( c rune ) ( err error ) { if _ , err = remote . sendRequest ( \" \" , Params { _ , err = remote . sendRequest ( \" \" , Params { remote . DomainEvents ( domain . Name , enable )", "commit_type": "make"}
{"commit_tokens": ["Add", "ConsumergroupList", "and", "ConsumergroupInstanceList", "types", "to", "replace", "maps", "."], "add_tokens": "if cg := cgs . Find ( cg . Name ) ; cg != nil { t . Error ( \" \" ) if i := instances . Find ( instance1 . ID ) ; i == nil { if i := instances . Find ( instance2 . ID ) ; i == nil {", "del_tokens": "if _ , ok := cgs [ cg . Name ] ; ok { t . Error ( \" \" ) if _ , ok := instances [ instance1 . ID ] ; ! ok { if _ , ok := instances [ instance1 . ID ] ; ! ok {", "commit_type": "add"}
{"commit_tokens": ["Fix", "round", "-", "off", "error", "in", "representation", "of", "date", "and", "time", "values"], "add_tokens": "f . SetCellDefault ( sheet , axis , strconv . FormatFloat ( float64 ( timeToExcelTime ( timeToUTCTime ( value . ( time . Time ) ) ) ) , 'f' , - 1 , 64 ) )", "del_tokens": "f . SetCellDefault ( sheet , axis , strconv . FormatFloat ( float64 ( timeToExcelTime ( timeToUTCTime ( value . ( time . Time ) ) ) ) , 'f' , - 1 , 32 ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "messages", "showing", "top", "-", "level", "key", "names", "."], "add_tokens": "if len ( p . currentKey ) == 0 { return p . context . String ( ) if len ( p . context ) == 0 { return p . currentKey } return fmt . Sprintf ( \" \" , p . context , p . currentKey )", "del_tokens": "if len ( p . currentKey ) > 0 { return fmt . Sprintf ( \" \" , p . context , p . currentKey ) return p . context . String ( )", "commit_type": "fix"}
{"commit_tokens": ["Use", "buildURI", "helper", "in", "ApplicationByVersion"], "add_tokens": "uri := fmt . Sprintf ( \" \" , buildURI ( name ) , version ) if err := r . apiGet ( uri , nil , & app ) ; err != nil {", "del_tokens": "if err := r . apiGet ( fmt . Sprintf ( \" \" , marathonAPIApps , trimRootPath ( name ) , version ) , nil , & app ) ; err != nil {", "commit_type": "use"}
{"commit_tokens": ["Added", "pagination", "to", "account", ".", "Feed"], "add_tokens": "func ( account * Account ) Feed ( minTime [ ] byte ) * FeedMedia { media := & FeedMedia { } media . inst = insta media . timestamp = timestamp media . endpoint = urlUserFeed media . uid = account . ID return media", "del_tokens": "func ( account * Account ) Feed ( minTime [ ] byte ) ( * FeedMedia , error ) { timestamp := b2s ( minTime ) body , err := insta . sendRequest ( & reqOptions { Endpoint : fmt . Sprintf ( urlUserFeed , account . ID ) , Query : map [ string ] string { \" \" : \" \" , \" \" : insta . rankToken , \" \" : timestamp , \" \" : \" \" , } , } , ) if err == nil { media := & FeedMedia { } err = json . Unmarshal ( body , media ) media . inst = insta media . endpoint = urlUserFeed media . uid = account . ID return media , err } return nil , err", "commit_type": "add"}
{"commit_tokens": ["Add", "pid", "and", "stdio", "to", "process", "state"], "add_tokens": "stdio := p . Stdio ( ) Pid : p . ID ( ) , SystemPid : uint32 ( p . SystemPid ( ) ) , Terminal : oldProc . Terminal , Args : oldProc . Args , Env : oldProc . Env , Cwd : oldProc . Cwd , Stdin : stdio . Stdin , Stdout : stdio . Stdout , Stderr : stdio . Stderr ,", "del_tokens": "Pid : p . ID ( ) , Terminal : oldProc . Terminal , Args : oldProc . Args , Env : oldProc . Env , Cwd : oldProc . Cwd ,", "commit_type": "add"}
{"commit_tokens": ["fix", "CI", "and", "remove", "docker", "/", "dir"], "add_tokens": "type dockerAuthConfigObsolete struct { type dockerAuthConfig struct { type dockerConfigFile struct { AuthConfigs map [ string ] dockerAuthConfig `json:\"auths\"` var dockerAuth dockerConfigFile var dockerAuthOld map [ string ] dockerAuthConfigObsolete type apiErr struct { errors [ ] apiErr Errors [ ] apiErr", "del_tokens": "type DockerAuthConfigObsolete struct { type DockerAuthConfig struct { type DockerConfigFile struct { AuthConfigs map [ string ] DockerAuthConfig `json:\"auths\"` var dockerAuth DockerConfigFile var dockerAuthOld map [ string ] DockerAuthConfigObsolete type APIErr struct { errors [ ] APIErr Errors [ ] APIErr", "commit_type": "fix"}
{"commit_tokens": ["Move", "keystore", "mock", "into", "datastore_test"], "add_tokens": "for _ , peer := range w . peerManager . ConnectedPeers ( ) {", "del_tokens": "for _ , peer := range w . peerManager . connectedPeers {", "commit_type": "move"}
{"commit_tokens": ["Fix", "bug", "in", "REPL", "introduced", "by", "last", "commit"], "add_tokens": "results := make ( [ ] interface { } , 0 , 10 ) results = append ( results , ( * vals ) [ 0 ] . Interface ( ) ) results = append ( results , ( * vals ) )", "del_tokens": "var results * ( [ ] interface { } ) * results = append ( * results , ( * vals ) [ 0 ] . Interface ( ) ) * results = append ( * results , ( * vals ) )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "init", "tokens", "within", "*", "InitToken"], "add_tokens": "return fmt . Sprintf ( \" \" , int ( p . DefaultLeaseTTL . Seconds ( ) ) ) return fmt . Sprintf ( \" \" , int ( p . MaxLeaseTTL . Seconds ( ) ) )", "del_tokens": "Config : p . getMountConfigInput ( ) , return fmt . Sprintf ( \" \" , int ( p . DefaultLeaseTTL . Seconds ( ) ) ) return fmt . Sprintf ( \" \" , int ( p . MaxLeaseTTL . Seconds ( ) ) )", "commit_type": "implement"}
{"commit_tokens": ["Implemented", "support", "to", "run", "as", "a", "different", "user", "(", "through", "the", "-", "u", "flag", ")"], "add_tokens": "User string if container . Config . User != \" \" { params = append ( params , \" \" , container . Config . User ) } params = append ( params , \" \" , container . Path )", "del_tokens": "container . Path ,", "commit_type": "implement"}
{"commit_tokens": ["fix", "example", "botContext", ".", "Run", "()"], "add_tokens": "\" \" bot . Run ( func ( event plugins . BotEvent ) { if event . ChannelName ( ) == \" \" { event . Reply ( \" \" ) } } )", "del_tokens": "bot . WebSocketRTM ( )", "commit_type": "fix"}
{"commit_tokens": ["remove", "the", "use", "of", "flags", "and", "allow", "applications", "to", "set", "the", "GCM", "endpoint"], "add_tokens": "// FCMServerEndpoint defines the endpoint for the FCM connection server by Firebase. FCMServerEndpoint = \" \" // GCMEndpoint by default points to the GCM connection server owned by Google, // but can be otherwise set to a differnet URL if needed (e.g. FCMServerEndpoint). var GCMEndpoint = ConnectionServerEndpoint req , err := http . NewRequest ( \" \" , GCMEndpoint , bytes . NewBuffer ( msgJSON ) )", "del_tokens": "\" \" // FcmServerEndpoint defines the endpoint for the FCM connection server by Firebase. FcmServerEndpoint = \" \" // can be replaced by flag. var gcmEndpoint = ConnectionServerEndpoint func init ( ) { flag . StringVar ( & gcmEndpoint , \" \" , ConnectionServerEndpoint , \" \" ) } req , err := http . NewRequest ( \" \" , gcmEndpoint , bytes . NewBuffer ( msgJSON ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "basic", "call", "return", "and", "error", "functionality", "."], "add_tokens": "\" \" type RPCError struct { URI string Description string Details interface { } } // Error returns an error description. func ( e RPCError ) Error ( ) string { return fmt . Sprintf ( \" \" , e . URI , e . Description ) errorURI = er . URI desc = er . Description details = er . Details", "del_tokens": "type RPCError interface { error URI ( ) string Description ( ) string Details ( ) interface { } errorURI = er . URI ( ) desc = er . Description ( ) details = er . Details ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "set", "fields", "as", "ignored", "."], "add_tokens": "tmap . columns = make ( [ ] * ColumnMap , 0 , n ) cm := & ColumnMap { Transient : columnName == \" \" , tmap . columns = append ( tmap . columns , cm ) if cm . fieldName == \" \" { tmap . version = tmap . columns [ len ( tmap . columns ) - 1 ] m . tables = append ( m . tables , tmap ) if fieldName == \" \" { continue } else if fieldName == \" \" {", "del_tokens": "tmap . columns = make ( [ ] * ColumnMap , n , n ) tmap . columns [ i ] = & ColumnMap { if tmap . columns [ i ] . fieldName == \" \" { tmap . version = tmap . columns [ i ] // append to slice // expand slice as necessary n = len ( m . tables ) if ( n + 1 ) > cap ( m . tables ) { newArr := make ( [ ] * TableMap , n , 2 * ( n + 1 ) ) copy ( newArr , m . tables ) m . tables = newArr } m . tables = m . tables [ 0 : n + 1 ] m . tables [ n ] = tmap if fieldName == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Adds", "support", "for", "multiple", "filters"], "add_tokens": "cmd := \" \" + hdr + \" \" + val + \" \\n \\n \" fmt . Fprint ( self . conn , cmd ) if rply , err := self . readHeaders ( ) ; err != nil || ! strings . Contains ( rply , \" \" ) { return errors . New ( \" \" ) }", "del_tokens": "cmd := \" \" cmd += \" \" + hdr + \" \" + val } cmd += \" \\n \\n \" fmt . Fprint ( self . conn , cmd ) if rply , err := self . readHeaders ( ) ; err != nil || ! strings . Contains ( rply , \" \" ) { return errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "reverse", "as", "a", "template", "function", "."], "add_tokens": "return in [ off : len ( in ) ] , nil", "del_tokens": "return in [ off : len ( in ) ] } // ReverseIfAddrs reverses an IfAddrs. func ReverseIfAddrs ( inputIfAddrs IfAddrs ) IfAddrs { reversedIfAddrs := append ( IfAddrs ( nil ) , inputIfAddrs ... ) for i := len ( reversedIfAddrs ) / 2 - 1 ; i >= 0 ; i -- { opp := len ( reversedIfAddrs ) - 1 - i reversedIfAddrs [ i ] , reversedIfAddrs [ opp ] = reversedIfAddrs [ opp ] , reversedIfAddrs [ i ] } return reversedIfAddrs", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "issue", "from", "recent", "changes"], "add_tokens": "v := os . Getenv ( m [ 0 ] [ 1 : ] )", "del_tokens": "v := os . Getenv ( m [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "usage", "from", "cli", "to", "minikube"], "add_tokens": "Use : \" \" , Long : `Minikube is a CLI tool that provisions and manages single-node Kubernetes clusters optimized for development workflows.` ,", "del_tokens": "Use : \" \" , Long : `Minikube is a CLI tool that provisions and manages single-node Kubernetes clusters optimized for development workflows . `,", "commit_type": "update"}
{"commit_tokens": ["Adds", "LSUB", "test", "adds", "empty", "list", "test", "fixes", "empty", "list", "read"], "add_tokens": "ok := true case listEnd : ok = false if ok { fields = append ( fields , field ) }", "del_tokens": "fields = append ( fields , field )", "commit_type": "add"}
{"commit_tokens": ["Improve", "context", "add", "more", "test", "."], "add_tokens": "// Any returns the value on this ctx by key. If key is instance of Any and // logger middleware used ctx.SetAny and ctx.Any to implement \"logger.FromCtx\": func ( ctx * Context ) IP ( ) net . IP { return net . ParseIP ( ra ) // QueryValues returns all query params for the provided name. func ( ctx * Context ) QueryValues ( name string ) [ ] string { if ctx . query == nil { ctx . query = ctx . Req . URL . Query ( ) } return ctx . query [ name ] }", "del_tokens": "// Any returns the value on this ctx for key. If key is instance of Any and // logger middleware used ctx.SetAny and ctx.Any to implement FromCtx: func ( ctx * Context ) IP ( ) string { return ra", "commit_type": "improve"}
{"commit_tokens": ["use", "reference", "data", "type", "instead"], "add_tokens": "return NewReference ( name , startingSection ) , nil", "del_tokens": "value , err := startingSection . Resolve ( name ) if err != nil { err = errors . New ( \" \" + err . Error ( ) ) } return value , nil", "commit_type": "use"}
{"commit_tokens": ["Allow", "remote", "TAR", "to", "accept", "ENV", "VARs"], "add_tokens": "return fmt . Sprintf ( \" \\\" \\\" \" , dir )", "del_tokens": "return fmt . Sprintf ( \" \" , dir )", "commit_type": "allow"}
{"commit_tokens": ["Add", "RRHistory", "()", "+", "tests"], "add_tokens": "func TestRRHistory ( t * testing . T ) { // test an IP outMap , err := inv . RRHistory ( \" \" , \" \" ) // test a domain outMap , err = inv . RRHistory ( \" \" , \" \" ) if err != nil { t . Fatal ( err ) } hasKeys ( outMap , [ ] string { \" \" , \" \" } , t ) // trying an unsupported query type should return an error outMap , err = inv . RRHistory ( \" \" , \" \" ) if outMap != nil || err == nil { t . Fatal ( \" \" ) }", "del_tokens": "func TestIp ( t * testing . T ) { outMap , err := inv . Ip ( \" \" ) func TestDomain ( t * testing . T ) { outMap , err := inv . Domain ( \" \" ) if err != nil { t . Fatal ( err ) } hasKeys ( outMap , [ ] string { \" \" , \" \" } , t ) }", "commit_type": "add"}
{"commit_tokens": ["Adds", "#log", "and", "#lookup", "helpers"], "add_tokens": "case reflect . Array , reflect . Slice : if i , err := strconv . Atoi ( fieldName ) ; ( err == nil ) && ( i < ctx . Len ( ) ) { result = ctx . Index ( i ) } log . Printf ( \" \" , Str ( result ) )", "del_tokens": "log . Printf ( \" \" , Str ( result ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "commented", "out", "code", "to", "tutorial", "3"], "add_tokens": "//Model := mathgl.Scale3D(2.,2.,2.).Mul(mathgl.HomogRotate3DX(25.0)).Mul(mathgl.Translate3D(.5,.2,-.7)) MVP := Projection . Mul ( View ) . Mul ( Model ) // Remember, transform multiplication order is \"backwards\"", "del_tokens": "MVP := Projection . Mul ( View ) . Mul ( Model )", "commit_type": "add"}
{"commit_tokens": ["change", "Config", ".", "writeTo", "to", "AccessTokens", ".", "writeTo"], "add_tokens": "Username string // Client username Password string // Client password (usually not required) Address string // Server address, including port (e.g. localhost:64738) Tokens AccessTokens // Server access tokens type AccessTokens [ ] string func ( at AccessTokens ) writeTo ( w io . Writer ) ( int64 , error ) { Tokens : at ,", "del_tokens": "Username string // Client username Password string // Client password (usually not required) Address string // Server address, including port (e.g. localhost:64738) Tokens [ ] string // Server access tokens func ( c * Config ) writeTo ( w io . Writer ) ( int64 , error ) { Tokens : c . Tokens ,", "commit_type": "change"}
{"commit_tokens": ["Fix", "homedir", "for", "Windows", "."], "add_tokens": "homedir \" \" homeDir , err := homedir . Dir ( ) if err != nil { homeDir = \" \" } return filepath . Join ( homeDir , \" \" )", "del_tokens": "return filepath . Join ( os . Getenv ( \" \" ) , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["added", "unit", "tests", "for", "tagging"], "add_tokens": "if col . fieldName == field || col . ColumnName == field {", "del_tokens": "if col . fieldName == field {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "%", "operator"], "add_tokens": "ast . BopPercent : \" \" ,", "del_tokens": "//bopPercent,", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "with", "ipv6"], "add_tokens": "return net . JoinHostPort ( ip , oport )", "del_tokens": "\" \" return fmt . Sprintf ( \" \" , ip , oport )", "commit_type": "fix"}
{"commit_tokens": ["Improve", "performance", "which", "using", "poolBuffer", "instead", "of", "bytes", ".", "NewBuffer", "."], "add_tokens": "buf := poolBuffer . Get ( ) bytes := buf . Bytes ( ) poolBuffer . Put ( buf ) return bytes", "del_tokens": "\" \" buf := & bytes . Buffer { } return buf . Bytes ( )", "commit_type": "improve"}
{"commit_tokens": ["Add", "login", "support", "for", "cassandra"], "add_tokens": "\" \" \" \" \" \" \" \" // Check if url user struct is null if u . User != nil { password , passwordSet := u . User . Password ( ) if passwordSet == false { return fmt . Errorf ( \" \" ) } cluster . Authenticator = gocql . PasswordAuthenticator { Username : u . User . Username ( ) , Password : password , } }", "del_tokens": "\" \" \" \" \" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "weighted", "values", "[", "ciskip", "]"], "add_tokens": "totalCount := h . bins [ minDeltaIndex - 1 ] . count + h . bins [ minDeltaIndex ] . count value : ( h . bins [ minDeltaIndex - 1 ] . value * h . bins [ minDeltaIndex - 1 ] . count + h . bins [ minDeltaIndex ] . value * h . bins [ minDeltaIndex ] . count ) / totalCount , // weighted average count : totalCount , // summed heights", "del_tokens": "value : ( h . bins [ minDeltaIndex - 1 ] . value + h . bins [ minDeltaIndex ] . value ) / 2 , // average value count : h . bins [ minDeltaIndex - 1 ] . count + h . bins [ minDeltaIndex ] . count , // summed heights", "commit_type": "use"}
{"commit_tokens": ["Add", "scalar", "datatype", "reverse", "lookup", "fun"], "add_tokens": "// lookupScalarTypeFromString returns the ScalarType for the given string func lookupScalarTypeFromString ( s string ) ScalarType { // lookupStringFromScalarType returns the string representation of a given ScalarType func lookupStringFromScalarType ( st ScalarType ) string { return scalarTypesMap [ st ] }", "del_tokens": "// getScalarType returns the ScalarType for the given stringified version func lookupScalarType ( s string ) ScalarType {", "commit_type": "add"}
{"commit_tokens": ["Fix", "EC2", "request", "param", "names", "."], "add_tokens": "return fmt . Sprintf ( \" \" , m . Name , strings . Join ( path , \" \" ) )", "del_tokens": "name := m . LocationName if name == \" \" { name = m . Name } return fmt . Sprintf ( \" \" , name , strings . Join ( path , \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "mode", "consistently", ":", "replace", "cpumode", "in", "thread_cpu_seconds_total", "."], "add_tokens": "if result . labels [ \" \" ] == \" \" { } else if result . labels [ \" \" ] == \" \" {", "del_tokens": "if result . labels [ \" \" ] == \" \" { } else if result . labels [ \" \" ] == \" \" {", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "problem", "to", "support", "either", "boolean", "or", "string", "value", "for", "IoOptimized", "value"], "add_tokens": "\" \" \" \" IoOptimized StringOrBool type StringOrBool struct { Value bool } // UnmarshalJSON implements the json.Unmarshaller interface. func ( io * StringOrBool ) UnmarshalJSON ( value [ ] byte ) error { if value [ 0 ] == '\"' { var str string err := json . Unmarshal ( value , & str ) if err == nil { io . Value = ( str == \" \" || str == \" \" ) } return err } var boolVal bool err := json . Unmarshal ( value , & boolVal ) if err == nil { io . Value = boolVal } return err } func ( io StringOrBool ) Bool ( ) bool { return io . Value } func ( io StringOrBool ) String ( ) string { return strconv . FormatBool ( io . Value ) }", "del_tokens": "IoOptimized IoOptimized", "commit_type": "fix"}
{"commit_tokens": ["add", "mapping", "for", "entries", "in", "facet", "response"], "add_tokens": "Terms [ ] * FacetTerm `json:\"terms,omitempty\"` Entries [ ] * Entry `json:\"entries,omitempty\"`", "del_tokens": "Terms [ ] * FacetTerm `json:\"terms\"`", "commit_type": "add"}
{"commit_tokens": ["Removed", "unneeded", "if", "statement", "inside", "the", "checkBot", "function", "."], "add_tokens": "p . checkBot ( sections [ 0 ] . comment ) reg , _ := regexp . Compile ( \" \" ) for _ , v := range comment { if reg . Match ( [ ] byte ( v ) ) { p . bot = true return", "del_tokens": "p . checkBot ( sections [ 0 ] . comment ) if ! p . bot { reg , _ := regexp . Compile ( \" \" ) for _ , v := range comment { if reg . Match ( [ ] byte ( v ) ) { p . bot = true return }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "order", "of", "assert", "reporting"], "add_tokens": "t . Errorf ( \" \" , b , a ) return t . Errorf ( \" \" , b , a ) t . Errorf ( \" \" , b , a ) return t . Errorf ( \" \" , b , a )", "del_tokens": "t . Fatalf ( \" \" , a , b ) t . Fatalf ( \" \" , a , b ) t . Fatalf ( \" \" , a , b ) t . Fatalf ( \" \" , a , b )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typos", "in", "docs", ";", "fixed", "godoc", "URL", "in", "README", "."], "add_tokens": "err = fmt . Errorf ( \" \" , report . Type , repository . Type ) err = fmt . Errorf ( \" \" , authorName )", "del_tokens": "err = fmt . Errof ( \" \" , report . Type , repository . Type ) err = fmt . Errof ( \" \" , authorName )", "commit_type": "fix"}
{"commit_tokens": ["moved", "GetAllJobs", "tests", "to", "supervisor", "tests"], "add_tokens": "/ * * /", "del_tokens": "", "commit_type": "move"}
{"commit_tokens": ["update", "runonce", "test", "to", "use", "stager", "s", "NATS", "interface"], "add_tokens": "\" \" var executorRunner * executor_runner . ExecutorRunner var natsRunner * natsrunner . NATSRunner executorRunner = executor_runner . New ( natsRunner = natsrunner . NewNATSRunner ( 4222 ) if gardenRunner != nil { gardenRunner . Stop ( ) } natsRunner . Stop ( ) if gardenRunner != nil { // local gardenRunner . DestroyContainers ( ) } else { // remove nukeAllWardenContainers ( ) } func nukeAllWardenContainers ( ) { listResponse , err := wardenClient . List ( ) Ω( e rr) . S houldNot( H aveOccurred( ) ) handles := listResponse . GetHandles ( ) for _ , handle := range handles { _ , err := wardenClient . Destroy ( handle ) Ω( e rr) . S houldNot( H aveOccurred( ) ) } }", "del_tokens": "var runner * executor_runner . ExecutorRunner runner = executor_runner . New ( gardenRunner . Stop ( ) gardenRunner . DestroyContainers ( )", "commit_type": "update"}
{"commit_tokens": ["move", "first", "bits", "of", "marshaler", "to", "templates"], "add_tokens": "if typ . Implements ( marshalerBufType ) || typeInInception ( ic , typ ) || typ . Implements ( marshalerType ) || reflect . PtrTo ( typ ) . Implements ( marshalerType ) { out += tplStr ( encodeTpl [ \" \" ] , handleMarshaler { IC : ic , Name : name , MarshalJSONBuf : typ . Implements ( marshalerBufType ) || typeInInception ( ic , typ ) , Marshaler : typ . Implements ( marshalerType ) || reflect . PtrTo ( typ ) . Implements ( marshalerType ) , } )", "del_tokens": "if typ . Implements ( marshalerBufType ) || typeInInception ( ic , typ ) { out += \" \" + name + \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" return out } if typ . Implements ( marshalerType ) { out += \" \" + name + \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \"", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "specifying", "hook", "arguments"], "add_tokens": "parts := strings . Split ( pre , \" \" ) args := [ ] string { } path := parts [ 0 ] if len ( parts ) > 1 { args = parts [ 1 : ] } rspec . Hooks . Prestart = append ( rspec . Hooks . Prestart , specs . Hook { Path : path , Args : args } ) parts := strings . Split ( post , \" \" ) args := [ ] string { } path := parts [ 0 ] if len ( parts ) > 1 { args = parts [ 1 : ] } rspec . Hooks . Poststop = append ( rspec . Hooks . Poststop , specs . Hook { Path : path , Args : args } )", "del_tokens": "rspec . Hooks . Prestart = append ( rspec . Hooks . Prestart , specs . Hook { Path : pre } ) rspec . Hooks . Poststop = append ( rspec . Hooks . Poststop , specs . Hook { Path : post } )", "commit_type": "add"}
{"commit_tokens": ["Added", "parallel", "scp", "moved", "Download", "and", "Upload", "functions", "from", "client", "app", "to", "api"], "add_tokens": "\" \" * sync . Mutex Mutex : & sync . Mutex { } , proxy . Lock ( ) defer proxy . Unlock ( ) func ConnectToNode ( optionalProxy * ProxyClient , nodeAddress string , authMethods [ ] ssh . AuthMethod , user string ) ( * NodeClient , error ) { if optionalProxy != nil { return optionalProxy . ConnectToNode ( nodeAddress , authMethods , user ) }", "del_tokens": "func ConnectToNode ( nodeAddress string , authMethods [ ] ssh . AuthMethod , user string ) ( * NodeClient , error ) {", "commit_type": "add"}
{"commit_tokens": ["Allow", "reconstructing", "into", "pre", "-", "allocated", "memory", "."], "add_tokens": "// You indicate that a shard is missing by setting it to nil or zero-length. // If a shard is zero-length but has sufficient capacity, that memory will // be used, otherwise a new []byte will be allocated. // You indicate that a shard is missing by setting it to nil or zero-length. // If a shard is zero-length but has sufficient capacity, that memory will // be used, otherwise a new []byte will be allocated. // You indicate that a shard is missing by setting it to nil or zero-length. // If a shard is zero-length but has sufficient capacity, that memory will // be used, otherwise a new []byte will be allocated. // You indicate that a shard is missing by setting it to nil or zero-length. // If a shard is zero-length but has sufficient capacity, that memory will // be used, otherwise a new []byte will be allocated. if cap ( shards [ iShard ] ) >= shardSize { shards [ iShard ] = shards [ iShard ] [ 0 : shardSize ] } else { shards [ iShard ] = make ( [ ] byte , shardSize ) } if cap ( shards [ iShard ] ) >= shardSize { shards [ iShard ] = shards [ iShard ] [ 0 : shardSize ] } else { shards [ iShard ] = make ( [ ] byte , shardSize ) }", "del_tokens": "// You indicate that a shard is missing by setting it to nil. // You indicate that a shard is missing by setting it to nil. // You indicate that a shard is missing by setting it to nil. // You indicate that a shard is missing by setting it to nil. shards [ iShard ] = make ( [ ] byte , shardSize ) shards [ iShard ] = make ( [ ] byte , shardSize )", "commit_type": "allow"}
{"commit_tokens": ["Add", "ParseAndFail", "()", "to", "FlagSet", "type"], "add_tokens": "globalFlagSet = NewFlagSet ( filepath . Base ( os . Args [ 0 ] ) , v ) globalFlagSet . ParseAndFail ( os . Args [ 1 : ] )", "del_tokens": "err := Parse ( v ) if err != nil { errCode := 0 if err != ErrHelpRequest { errCode = 1 fmt . Printf ( \" \\n \" , err ) } PrintHelp ( ) os . Exit ( errCode ) }", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "so", "I", "can", "actually", "get", "the", "JSON"], "add_tokens": "fmt . Println ( cont )", "del_tokens": "fmt . Fprintln ( w , cont )", "commit_type": "make"}
{"commit_tokens": ["Fix", "ptmx", "issue", "on", "libcontainer"], "add_tokens": "command . ExtraFiles = [ ] * os . File { master }", "del_tokens": "//command.ExtraFiles = []*os.File{master}", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "localkube", "download", "support", "compression", "."], "add_tokens": "sudo curl -- compressed - L % s - o / usr / local / bin / localkube", "del_tokens": "sudo curl - L % s - o / usr / local / bin / localkube", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "authenticate", "tests", "#minor"], "add_tokens": "var usr chef . User usr = chef . User { UserName : \" \" , Email : \" \" , FirstName : \" \" , DisplayName : \" \" , createUser ( client , usr ) var ar chef . Authenticate ar . UserName = \" \" fmt . Printf ( \" \\n \" , err ) ar . Password = \" \" fmt . Printf ( \" \\n \" , err ) // Cleanup deleteUser ( client , \" \" ) // deleteUser uses the chef server api to delete a single user func deleteUser ( client * chef . Client , name string ) ( err error ) { err = client . Users . Delete ( name ) if err != nil { fmt . Fprintln ( os . Stderr , \" \" , err ) } return }", "del_tokens": "var usr1 chef . User usr1 = chef . User { UserName : \" \" , Email : \" \" , FirstName : \" \" , DisplayName : \" \" , userResult := createUser ( client , usr1 ) var ar Authenticate ar . UserName = \" \" fmt . Printf ( \" \" , err ) ar . Password = \" \" fmt . Printf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Fix", "sup", "exit", "status", "and", "error", "message"], "add_tokens": "\" \" // TODO: Prefix should be with color. fmt . Fprintf ( os . Stderr , \" \\n \" , c . Prefix ( ) , e . ExitStatus ( ) ) os . Exit ( e . ExitStatus ( ) ) // TODO: Prefix should be with color. fmt . Fprintf ( os . Stderr , \" \\n \" , c . Prefix ( ) , err ) os . Exit ( 1 )", "del_tokens": "log . Fatalf ( \" \" , c . Prefix ( ) , e . ExitStatus ( ) ) log . Fatalf ( \" \" , c . Prefix ( ) , err ) //TODO: We should not exit 0, if there was an error.", "commit_type": "fix"}
{"commit_tokens": ["Add", "log", "truncation", "and", "AppendEntries", "overwrite", "."], "add_tokens": "if err := s . log . Truncate ( req . PrevLogIndex , req . PrevLogTerm ) ; err != nil { return NewAppendEntriesResponse ( s . currentTerm , false ) , err", "del_tokens": "if req . PrevLogIndex == 0 && req . PrevLogTerm == 0 { if index , _ := s . log . CommitInfo ( ) ; index > 0 { return NewAppendEntriesResponse ( s . currentTerm , false ) , fmt . Errorf ( \" \" , req . PrevLogIndex , req . PrevLogTerm ) } } else if ! s . log . ContainsEntry ( req . PrevLogIndex , req . PrevLogTerm ) { return NewAppendEntriesResponse ( s . currentTerm , false ) , fmt . Errorf ( \" \" , req . PrevLogIndex , req . PrevLogTerm )", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "private", "embedded", "non", "pointer", "field", "for", "gostring", "and", "deepcopy"], "add_tokens": "p . P ( \" \" , g . GetFuncName ( types . NewPointer ( fieldType ) ) , wrap ( thisField ) )", "del_tokens": "p . P ( \" \" , g . GetFuncName ( fieldType ) , thatField , thisField )", "commit_type": "add"}
{"commit_tokens": ["Make", "/", "drip", "more", "compatible", "with", "httpbin", "s", "implementation", ":"], "add_tokens": "var testDefaultParams = DefaultParams { DripDelay : 0 , DripDuration : 100 * time . Millisecond , DripNumBytes : 10 , } WithDefaultParams ( testDefaultParams ) , assertHeader ( t , w , \" \" , \" \" ) assertHeader ( t , w , \" \" , strconv . Itoa ( test . numbytes ) ) // For this test, we expect the client to time out and cancel the // request after 10ms. The handler should immediately write a 200 OK // status before the client timeout, preventing a client error, but it // will wait 500ms to write anything to the response body. // // So, we're testing that a) the client got an immediate 200 OK but // that b) the response body was empty. if err != nil { t . Fatalf ( \" \" , err ) } defer resp . Body . Close ( ) body , _ := ioutil . ReadAll ( resp . Body ) if err != nil { t . Fatalf ( \" \" , err ) } if len ( body ) != 0 { t . Fatalf ( \" \" , string ( body ) )", "del_tokens": "assertHeader ( t , w , \" \" , \" \" ) if err == nil { body , _ := ioutil . ReadAll ( resp . Body ) t . Fatalf ( \" \" , resp . StatusCode , body )", "commit_type": "make"}
{"commit_tokens": ["change", "example", "to", "use", "in", "-", "memory", "message", "queue"], "add_tokens": "func ( d * Database ) Write ( req * dbState ) error {", "del_tokens": "func ( d * Database ) Write ( req dbState ) error {", "commit_type": "change"}
{"commit_tokens": ["Adds", "STORE", "support", "to", "server"], "add_tokens": "if ch == nil && ! strings . HasSuffix ( item , common . SilentOp ) { item += common . SilentOp", "del_tokens": "if ch == nil && ! strings . HasSuffix ( item , \" \" ) { item += \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "readme", "example", "code", "to", "test", "to", "make", "sure", "it", "actually", "builds", ".", "Fixed", "a", "problem", "that", "found", "with", "both", "gelf", "and", "loggly", "loggers", ".", "Yay", "for", "tests!"], "add_tokens": "base * Base client * golf . Client logger * golf . Logger isInitialized bool func ( l * GelfLogger ) IsInitialized ( ) bool { return l . isInitialized } l . isInitialized = true err := l . client . Close ( ) if err != nil { return err } l . isInitialized = false return nil", "del_tokens": "base * Base client * golf . Client logger * golf . Logger return l . client . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "running", "wallet", "on", "testnet3", "."], "add_tokens": "func NewWallet ( name , desc string , passphrase [ ] byte , net btcwire . BitcoinNet ) ( * Wallet , error ) { net : net ,", "del_tokens": "func NewWallet ( name , desc string , passphrase [ ] byte ) ( * Wallet , error ) { net : btcwire . MainNet ,", "commit_type": "add"}
{"commit_tokens": ["add", "Settings", "including", "timeout", "proxy", "transport", "client", "..."], "add_tokens": "// WrapResponse create a Response which wraps *http.Response func WrapResponse ( resp * http . Response ) ( r * Response ) { // GetReponse return the raw *http.Response inside the Response. func ( r * Response ) GetResponse ( ) * http . Response {", "del_tokens": "// NewResponse create a Response which wraps *http.Response func NewResponse ( resp * http . Response ) ( r * Response ) { // Reponse return the raw *http.Response inside the Response. func ( r * Response ) Response ( ) * http . Response {", "commit_type": "add"}
{"commit_tokens": ["Move", "from", "JSON", "to", "Gob"], "add_tokens": "import ( \" \" \" \" \" \" ) func GetAsset ( name string ) * gob . Decoder { return gob . NewDecoder ( bytes . NewReader ( b ) )", "del_tokens": "import \" \" func GetAsset ( name string ) [ ] byte { return b", "commit_type": "move"}
{"commit_tokens": ["improve", "performance", "of", "wildcard", "domain", "matching"], "add_tokens": "return len ( s ) >= len ( w . prefix ) + len ( w . suffix ) && strings . HasPrefix ( s , w . prefix ) && strings . HasSuffix ( s , w . suffix )", "del_tokens": "return len ( s ) >= len ( w . prefix + w . suffix ) && strings . HasPrefix ( s , w . prefix ) && strings . HasSuffix ( s , w . suffix )", "commit_type": "improve"}
{"commit_tokens": ["add", "exitCh", "to", "crashed", "subscriber", "so", "we", "can", "exit", "goroutine", "cleanly"], "add_tokens": "select { case <- t . crashedCh < - \" \" : case <- t . exitCh : } reason := \" \" reason = header . Params . Reason } select { case <- t . crashedCh < - reason : case <- t . exitCh :", "del_tokens": "t . crashedCh <- \" \" t . crashedCh <- header . Params . Reason } else { t . crashedCh <- \" \"", "commit_type": "add"}
{"commit_tokens": ["Using", "errgroup", "on", "Download", "method"], "add_tokens": "ProgressBar ( context . Context ) error func ( d Data ) ProgressBar ( ctx context . Context ) error { return nil return errors . Wrap ( err , \" \" ) return nil", "del_tokens": "ProgressBar ( context . Context , * Ch ) func ( d Data ) ProgressBar ( ctx context . Context , ch * Ch ) { return ch . Err <- errors . Wrap ( err , \" \" ) return ch . Done <- true return", "commit_type": "use"}
{"commit_tokens": ["Update", "ci", "and", "readme", "."], "add_tokens": "_ , err = pool . GetWithTimeout ( time . Duration ( 1 ) * time . Second )", "del_tokens": "_ , err = pool . GetWithTimeout ( 10000 )", "commit_type": "update"}
{"commit_tokens": ["Added", "PING", "to", "provide", "flush", "semantics"], "add_tokens": "go c . parse ( [ ] byte ( \" \\r \\n \\r \\n \\r \\n \\r \\n \" ) ) go c . parse ( [ ] byte ( \" \\r \\n \\r \\n \\r \\n \\r \\n \" ) )", "del_tokens": "go c . parse ( [ ] byte ( \" \\r \\n \\r \\n \\r \\n \" ) ) go c . parse ( [ ] byte ( \" \\r \\n \\r \\n \\r \\n \" ) )", "commit_type": "add"}
{"commit_tokens": ["make", "explicit", "that", "the", "default", "implementation", "is", "async"], "add_tokens": "std . ( * AsyncClient ) . wait ( ) object := std . ( * AsyncClient ) . errorRequest ( r ) clean := filterParams ( std . ( * AsyncClient ) . FilterFields , values )", "del_tokens": "Wait ( ) object := std . ( * Rollbar ) . errorRequest ( r ) clean := filterParams ( std . ( * Rollbar ) . FilterFields , values )", "commit_type": "make"}
{"commit_tokens": ["Added", "missing", "fields", "for", "Conferences"], "add_tokens": "ID string `json:\"id\"` State string `json:\"state\"` From string `json:\"from\"` CreatedTime string `json:\"createdTime\"` CompletedTime string `json:\"completedTime\"` ActiveMembers int `json:\"activeMembers\"` CallbackURL string `json:\"callbackUrl\"` CallbackTimeout int `json:\"callbackTimeout,string\"` CallbackHTTPMethod string `json:\"callbackHttpMethod\"` FallbackURL string `json:\"fallbackUrl\"` Hold bool `json:\"hold,string\"` Mute bool `json:\"mute,string\"` Tag string `json:\"tag\"` From string `json:\"from,omitempty\"` CallbackURL string `json:\"callbackUrl,omitempty\"` CallbackTimeout int `json:\"callbackTimeout,string,omitempty\"` FallbackURL string `json:\"fallbackUrl,omitempty\"` Tag string `json:\"tag,omitempty\"` Profile string `json:\"profile,omitempty\"` CallbackHTTPMethod string `json:\"callbackHttpMethod,omitempty\"` State string `json:\"state,omitempty\"` CallbackURL string `json:\"callbackUrl,omitempty\"` CallbackTimeout int `json:\"callbackTimeout,string,omitempty\"` FallbackURL string `json:\"fallbackUrl,omitempty\"` Hold bool `json:\"hold,string,omitempty\"` Mute bool `json:\"mute,string,omitempty\"` Tag string `json:\"tag,omitempty\"` CallbackHTTPMethod string `json:\"callbackHttpMethod,omitempty\"`", "del_tokens": "ID string `json:\"id\"` State string `json:\"state\"` From string `json:\"from\"` CreatedTime string `json:\"createdTime\"` CompletedTime string `json:\"completedTime\"` ActiveMembers int `json:\"activeMembers\"` CallbackURL string `json:\"callbackUrl\"` CallbackTimeout int `json:\"callbackTimeout,string\"` FallbackURL string `json:\"fallbackUrl\"` Hold bool `json:\"hold,string\"` Mute bool `json:\"mute,string\"` Tag string `json:\"tag\"` From string `json:\"from,omitempty\"` CallbackURL string `json:\"callbackUrl,omitempty\"` CallbackTimeout int `json:\"callbackTimeout,string,omitempty\"` FallbackURL string `json:\"fallbackUrl,omitempty\"` Tag string `json:\"tag,omitempty\"` State string `json:\"state,omitempty\"` CallbackURL string `json:\"callbackUrl,omitempty\"` CallbackTimeout int `json:\"callbackTimeout,string,omitempty\"` FallbackURL string `json:\"fallbackUrl,omitempty\"` Hold bool `json:\"hold,string,omitempty\"` Mute bool `json:\"mute,string,omitempty\"` Tag string `json:\"tag,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Implement", "an", "universal", "importer", "that", "supports", "in", "URLs", "in", "import", "statements", "and", "library", "search", "paths"], "add_tokens": "flagSUrl = \" \" RootCmd . PersistentFlags ( ) . StringSliceP ( flagSUrl , \" \" , nil , \" \" ) sURLs , err := flags . GetStringSlice ( flagSUrl ) if err != nil { return nil , err } for _ , u := range sURLs { log . Debugln ( \" \" , u ) searchPaths = append ( searchPaths , u ) } wd , err := os . Getwd ( ) if err != nil { return nil , err } importer , err := utils . MakeUniversalImporter ( wd , searchPaths ) if err != nil { return nil , err } vm . Importer ( importer )", "del_tokens": "vm . Importer ( & jsonnet . FileImporter { JPaths : searchPaths } )", "commit_type": "implement"}
{"commit_tokens": ["Added", "ErrorsByField", "function", "that", "returns", "all", "errors", "of", "ValidateStruct", "as", "a", "map", "[", "string", "]", "string", "(", "key", ":", "field", "name", "value", ":", "field", "error", "message", ")", "."], "add_tokens": "// validated by ValidateStruct or empty string if there are no errors // or this field doesn't exists or doesn't have any errors. return ErrorsByField ( e ) [ field ] } // ErrorsByField returns map of errors of the struct validated // by ValidateStruct or empty map if there are no errors. func ErrorsByField ( e error ) map [ string ] string { m := make ( map [ string ] string ) if e == nil { return m } if len ( item ) == 0 { continue errorByField := strings . Split ( item , \" \" ) m [ errorByField [ 0 ] ] = errorByField [ 1 ] return m", "del_tokens": "// validated by ValidateStruct or empty string // if there are no errors/this field doesn't exists or hasn't errors if strings . HasPrefix ( item , field + \" \" ) { item := strings . TrimPrefix ( item , field + \" \" ) return item return \" \"", "commit_type": "add"}
{"commit_tokens": ["fix", "user", "pk", "in", "strconv"], "add_tokens": "_ , err = insta . Follow ( strconv . FormatInt ( user . User . Pk , 10 ) ) _ , err = insta . Follow ( strconv . FormatInt ( user . User . Pk , 10 ) )", "del_tokens": "_ , err = insta . Follow ( strconv . Itoa ( user . User . Pk ) ) _ , err = insta . UnFollow ( strconv . Itoa ( user . User . Pk ) )", "commit_type": "fix"}
{"commit_tokens": ["use", "the", "http", "transport", "on", "the", "registry", "to", "support", "-", "k"], "add_tokens": "req , err := http . NewRequest ( \" \" , url , nil ) if err != nil { return \" \" , err } resp , err := r . Client . Do ( req )", "del_tokens": "resp , err := http . Get ( url )", "commit_type": "use"}
{"commit_tokens": ["Add", "hour_minute", "rule", "for", "ru", "locale"], "add_tokens": "https : //play.golang.org/p/hXl7C8MWNr \" \" + \" \\\\ -) + \" \" + \" \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \" +", "del_tokens": "https : //play.golang.org/p/xaGoNLMpo5 \" \\\\ \" + \" \\\\ -| .) + \" \\\\ \" + \" \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \" +", "commit_type": "add"}
{"commit_tokens": ["Adding", "additional", "tests", "to", "assert", "the", "behvaior", "of", "SQL", "Mappers"], "add_tokens": "// Ensures that creating a new SQL Mapper does not encounter an error upon initialization // And also matches the expected database connections and sql configurations. // Ensures that creating a new SQLMapper and getting its SQL DB Connection // is the same *sql.DB used in initialization. func TestSqlDbConn ( t * testing . T ) { conf := sqlConfFromEnv ( ) db , _ := sql . Open ( conf . driver , conf . openStr ) env := os . Getenv ( \" \" ) filepath := fmt . Sprintf ( \" \" , env ) s , _ := NewSQLMapper ( filepath , db ) if s . SqlDbConn ( ) != db { t . Error ( \" \" ) } }", "del_tokens": "// Ensures that", "commit_type": "add"}
{"commit_tokens": ["move", "defer", "resp", ".", "body", ".", "close", "after", "error", "checking", "so", "panic", "(", "err", ")", "could", "be", "called", "(", "https", ":", "//", "groups", ".", "google", ".", "com", "/", "d", "/", "msg", "/", "golang", "-", "nuts", "/", "IgFmMqD65t4", "/", "zWHpOOS4ZOsJ", ")"], "add_tokens": "defer resp . Body . Close ( ) defer resp . Body . Close ( )", "del_tokens": "defer resp . Body . Close ( ) defer resp . Body . Close ( )", "commit_type": "move"}
{"commit_tokens": ["added", "hex", "decoding", "to", "Entry", ".", "UnmarshalJSON"], "add_tokens": "if p , err := hex . DecodeString ( v ) ; err != nil { break } else { e . ExtIDs = append ( e . ExtIDs , p ) } p , _ := hex . DecodeString ( j . Content ) e . Content = p", "del_tokens": "e . ExtIDs = append ( e . ExtIDs , [ ] byte ( v ) ) e . Content = [ ] byte ( j . Content )", "commit_type": "add"}
{"commit_tokens": ["Changed", "Swedish", "postalcode", "to", "be", "correct", "and", "added", "documentation", "for", "postalcode", "generation", "to", "readme"], "add_tokens": "return Digits ( 5 )", "del_tokens": "return \" \" + Letters ( 3 ) + \" \" + Digits ( 2 ) //return Letters(3) + \" \" + Digits(2)", "commit_type": "change"}
{"commit_tokens": ["Make", "ast_test", "inputs", "be", "exactly", "equivalent"], "add_tokens": "ins : [ ] string { \" \" , \" \\n \" } , want : [ ] node { comment { text : \" \" } , } , ins : [ ] string { \" \" , \" \" , \" \" } ,", "del_tokens": "ins : [ ] string { \" \" , \" \" , \" \\n \" } , want : nil , ins : [ ] string { \" \" , \" \" , \" \" , \" \\n \" } ,", "commit_type": "make"}
{"commit_tokens": ["Update", "the", "package", "overview", "."], "add_tokens": "// Helper code for starting a daemon process. // This package assumes that the user invokes a tool, which invokes a daemon // process. Though the tool starts the daemon process with stdin, stdout, and // stderr closed (using Run), the daemon should be able to communicate status // to the user while it starts up (using StatusWriter), causing the tool to // exit in success or failure only when it is clear whether the daemon has // sucessfully started (which it signal using SignalOutcome). package daemonize", "del_tokens": "// Helper code for daemonizing gcsfuse, synchronizing on successful mount. // The details of this package are subject to change. package daemon", "commit_type": "update"}
{"commit_tokens": ["make", "agent", "http", "port", "configurable"], "add_tokens": "serverMiddleware . Run ( \" \" + config . Port )", "del_tokens": "serverMiddleware . Run ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Fix", "detection", "of", "hooks", "interface", "being", "implemented"], "add_tokens": "if ImplementsPreJSONMarshaler ( & v ) { if ImplementsPostJSONUnmarshaler ( & v ) { func ImplementsPostJSONUnmarshaler ( v interface { } ) bool { _ , ok := v . ( PostJSONUnmarshaler ) return ok", "del_tokens": "if _ , ok := v . ( PreJSONMarshaler ) ; ok { if _ , ok := v . ( PostJSONUnmarshaler ) ; ok { func ImplementsPostJSONUnmarshaler ( v interface { } ) ( interface { } , bool ) { v , ok := v . ( PostJSONUnmarshaler ) return v , ok", "commit_type": "fix"}
{"commit_tokens": ["use", "CheckPanic", "from", "utils", "for", "testing"], "add_tokens": "\" \" ok := gorivets . CheckPanic ( func ( ) { lc . getAppendersFromList ( \" \" ) } ) pnc := gorivets . CheckPanic ( pnc := gorivets . CheckPanic ( pnc := gorivets . CheckPanic ( pnc = gorivets . CheckPanic ( pnc := gorivets . CheckPanic (", "del_tokens": "ok := checkPanic ( func ( ) { lc . getAppendersFromList ( \" \" ) } ) pnc := checkPanic ( pnc := checkPanic ( pnc := checkPanic ( pnc = checkPanic ( pnc := checkPanic (", "commit_type": "use"}
{"commit_tokens": ["Moved", "this", "method", "closer", "to", "type", "def"], "add_tokens": "func ( p PartialWorldCoord ) String ( ) string { return fmt . Sprintf ( \" \" , p . WorldCoord , p . Percentage ) }", "del_tokens": "func ( p PartialWorldCoord ) String ( ) string { return fmt . Sprintf ( \" \" , p . WorldCoord , p . Percentage ) }", "commit_type": "move"}
{"commit_tokens": ["Use", "ExactString", "()", "only", "for", "strings"], "add_tokens": "var typeName string val := c . Val ( ) . String ( ) case types . UntypedString : val = c . Val ( ) . ExactString ( ) case types . String : val = c . Val ( ) . ExactString ( ) typeName = t . Name ( ) case types . UntypedBool , types . UntypedInt , types . UntypedRune , types . UntypedFloat , types . UntypedComplex , types . UntypedNil : typeName = g . TypeOf ( t ) _ , err := fmt . Fprintf ( g , \" \\n \" , c . Name ( ) , typeName , val )", "del_tokens": "var err error var typeName string case types . UntypedBool , types . UntypedInt , types . UntypedRune , types . UntypedFloat , types . UntypedComplex , types . UntypedString , types . UntypedNil : _ , err = fmt . Fprintf ( g , \" \\n \" , c . Name ( ) , typeName , c . Val ( ) . ExactString ( ) ) _ , err = fmt . Fprintf ( g , \" \\n \" , c . Name ( ) , g . TypeOf ( t ) , c . Val ( ) . ExactString ( ) )", "commit_type": "use"}
{"commit_tokens": ["add", "proc", "struct", ";", "mem", ".", "InfoProfiler", "std", "global", ";", "refactor", "to", "use", "profiler", "and", "eliminate", "prior", "globals", ":", "addresses", "concurrency", "issues", "raised", "by", "prior", "design"], "add_tokens": "func TestGetInfoSerializeDeserializeFlat ( t * testing . T ) { var inf * Info func BenchmarkGetMemInfo ( b * testing . B ) { p , _ := NewInfoProfiler ( ) inf , _ = p . Get ( ) _ = inf } func BenchmarkGetMemInfoFlat ( b * testing . B ) { var infF [ ] byte p , _ := NewInfoProfiler ( ) for i := 0 ; i < b . N ; i ++ { infF , _ = p . GetFlat ( ) } _ = infF", "del_tokens": "func TestGetData ( t * testing . T ) { var inf Info func BenchmarkReadMemInfo ( b * testing . B ) { inf , _ = GetInfo ( ) // b.Logf(\"%#v\\n\", inf)", "commit_type": "add"}
{"commit_tokens": ["Fix", "missing", "Id", "field", "in", "fxpRename"], "add_tokens": "l := 1 + 4 + // type(byte) + uint32 b = marshalUint32 ( b , p . Id )", "del_tokens": "l := 1 + // type(byte)", "commit_type": "fix"}
{"commit_tokens": ["added", "all", "=", "true", "option", "for", "list", "images"], "add_tokens": "func ( client * Client ) ListImages ( all bool ) ( [ ] * Image , error ) { vals := url . Values { } if all { vals . Set ( \" \" , \" \" ) } if len ( vals ) > 0 { uri = uri + \" \" + vals . Encode ( ) }", "del_tokens": "func ( client * Client ) ListImages ( ) ( [ ] * Image , error ) {", "commit_type": "add"}
{"commit_tokens": ["use", "os", ".", "RemoveAll", "instead", "of", "rm", "-", "r"], "add_tokens": "return os . RemoveAll ( path )", "del_tokens": "return exec . Command ( \" \" , \" \" , path ) . Run ( )", "commit_type": "use"}
{"commit_tokens": ["Make", "public", "access", "to", "default", "client"], "add_tokens": "DefaultClient = New ( Configuration { } ) Config = DefaultClient . Config DefaultClient . Configure ( c ) DefaultClient . SetContext ( c ) return DefaultClient . Notify ( newError ( err , 2 ) , extra ... ) DefaultClient . Notify ( newError ( err , 2 ) ) DefaultClient . Flush ( ) return DefaultClient . Handler ( h )", "del_tokens": "client = New ( Configuration { } ) Config = client . Config client . Configure ( c ) client . SetContext ( c ) return client . Notify ( newError ( err , 2 ) , extra ... ) client . Notify ( newError ( err , 2 ) ) client . Flush ( ) return client . Handler ( h )", "commit_type": "make"}
{"commit_tokens": ["Fix", "counting", "logic", "to", "avoid", "double", "counting"], "add_tokens": "if _ , ok := trg [ to ] ; ok { return } r . lhCount ++ if _ , ok := trg [ to ] ; ! ok { return }", "del_tokens": "r . lhCount ++", "commit_type": "fix"}
{"commit_tokens": ["Fix", "code", "review", "comments", "."], "add_tokens": "if rw . redirect { if ! rw . rewriteBody {", "del_tokens": "if rw . redirect == true { if rw . rewriteBody != true {", "commit_type": "fix"}
{"commit_tokens": ["Use", "variadic", "parameters", "instead", "of", "passing", "a", "list"], "add_tokens": "return AuthChain ( endpoints , accessCheckFunction ) func AuthChain ( endpoints oauth2 . Endpoint , accessCheckFunctions ... AccessCheckFunction ) gin . HandlerFunc {", "del_tokens": "accessCheckFunctions := [ ] AccessCheckFunction { accessCheckFunction } return AuthChain ( accessCheckFunctions , endpoints ) func AuthChain ( accessCheckFunctions [ ] AccessCheckFunction , endpoints oauth2 . Endpoint ) gin . HandlerFunc {", "commit_type": "use"}
{"commit_tokens": ["updating", "to", "match", "weekly", "2011", "-", "11", "-", "02"], "add_tokens": "import \" \" func ( f * File ) ReadRaw ( data [ ] byte ) ( read int64 , err error ) { func ( f * File ) WriteRaw ( data [ ] byte ) ( written int64 , err error ) {", "del_tokens": "import ( \" \" \" \" ) func ( f * File ) ReadRaw ( data [ ] byte ) ( read int64 , err os . Error ) { func ( f * File ) WriteRaw ( data [ ] byte ) ( written int64 , err os . Error ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "data", "race", "on", "iteration"], "add_tokens": "s . lock . RLock ( ) entry , err := s . entries . Get ( index ) s . lock . RUnlock ( ) return entry , err keys = make ( [ ] uint32 , len ( s . hashmap ) )", "del_tokens": "return s . entries . Get ( index ) keys = make ( [ ] uint32 , len ( s . hashmap ) )", "commit_type": "fix"}
{"commit_tokens": ["fix", "issue", "with", "range", "parsing", "while", "ignoring", "case", "and", "\\", "u", "hex", "parsing"], "add_tokens": "toAdd := [ ] singleRange { } toAdd = append ( toAdd , r ) for _ , r := range toAdd { c . addLowercaseRange ( r . first , r . last ) } if lc . chMin > chMax { return", "del_tokens": "c . addLowercaseRange ( r . first , r . last ) if lc . chMin <= chMax { break", "commit_type": "fix"}
{"commit_tokens": ["Allow", "for", "basic", "configuration", ".", "(", "May", "change", "the", "semantics", "later", ")", "."], "add_tokens": "wp . workers = make ( [ ] * worker , Config . Pool . NumWorkers ) wp . jobs = make ( chan * Job , Config . Pool . BatchSize ) if err := wp . sendNextJobs ( Config . Pool . BatchSize ) ; err != nil { if err := wp . sendNextJobs ( Config . Pool . BatchSize ) ; err != nil { jobs , err := getNextJobs ( Config . Pool . BatchSize )", "del_tokens": "\" \" var ( // NumWorkers is the number of workers to run // Each worker will run inside its own goroutine // and execute jobs asynchronously. NumWorkers = runtime . GOMAXPROCS ( 0 ) // BatchSize is the number of jobs to send through // the jobs channel at once. Increasing BatchSize means // the worker pool will query the database less frequently, // so you would get higher performance. However this comes // at the cost that jobs with lower priority may sometimes be // executed before jobs with higher priority, because the jobs // with higher priority were not ready yet the last time the pool // queried the database. Decreasing BatchSize means more // frequent queries to the database and lower performance, but // greater likelihood of executing jobs in perfect order with regards // to priority. Setting BatchSize to 1 gaurantees that higher priority // jobs are always executed first as soon as they are ready. BatchSize = NumWorkers // MaxWait is the maximum time the pool will wait before checking the // database for queued jobs. The pool may query the database more frequently // than MaxWait if it thinks there is likely to be new queued job. (e.g., // if it knows the time parameter of a job was satisfied since the last // time it checked). MaxWait = 200 * time . Millisecond ) wp . workers = make ( [ ] * worker , NumWorkers ) wp . jobs = make ( chan * Job , BatchSize ) if err := wp . sendNextJobs ( BatchSize ) ; err != nil { if err := wp . sendNextJobs ( BatchSize ) ; err != nil { jobs , err := getNextJobs ( BatchSize )", "commit_type": "allow"}
{"commit_tokens": ["Add", "first", "test", ":", "nonce", "overflow", "in", "messages", "must", "be", "handled", "consistently", "."], "add_tokens": "type shortNoncer interface { prefixAndBump ( prefix [ 16 ] byte ) ( [ 24 ] byte , [ 8 ] byte , error ) } clientShortNonce shortNoncer , func ( c * initiateCommand ) build ( clientShortNonce shortNoncer , func ( c * readyCommand ) build ( serverShortNonce shortNoncer , func ( c * messageCommand ) build ( sn shortNoncer , priv Privkey , pub Pubkey , data [ ] byte , sentByServer bool ) error { func ( c * messageCommand ) validate ( expectedNonce * shortNonce , priv Privkey , pub Pubkey , sentByServer bool ) ( [ ] byte , error ) {", "del_tokens": "clientShortNonce * shortNonce , func ( c * initiateCommand ) build ( clientShortNonce * shortNonce , func ( c * readyCommand ) build ( serverShortNonce * shortNonce , func ( c * messageCommand ) build ( sn * shortNonce , priv Privkey , pub Pubkey , data [ ] byte , serverSending bool ) error { func ( c * messageCommand ) validate ( expectedNonce * shortNonce , priv Privkey , pub Pubkey , serverSending bool ) ( [ ] byte , error ) {", "commit_type": "add"}
{"commit_tokens": ["add", "default", "post", "release", "for", "incrementing"], "add_tokens": "func ( v Version ) IncrementPostRelease ( defaultPostRelease VersionSegment ) ( Version , error ) { var newPostRelease VersionSegment var err error if defaultPostRelease . Empty ( ) { return Version { } , errors . New ( \" \" ) } if v . PostRelease . Empty ( ) { newPostRelease = defaultPostRelease . Copy ( ) } else { newPostRelease , err = v . PostRelease . Increment ( ) if err != nil { return Version { } , err } return NewVersion ( v . Release . Copy ( ) , v . PreRelease . Copy ( ) , newPostRelease )", "del_tokens": "func ( v Version ) IncrementPostRelease ( ) ( Version , error ) { incPostRelease , err := v . PostRelease . Increment ( ) if err != nil { return Version { } , err return NewVersion ( v . Release . Copy ( ) , v . PreRelease . Copy ( ) , incPostRelease )", "commit_type": "add"}
{"commit_tokens": ["Add", "tokens", "and", "move", "message", "ids"], "add_tokens": "c . oboundP <- & PacketAndToken { p : ping , t : nil }", "del_tokens": "c . oboundP <- ping", "commit_type": "add"}
{"commit_tokens": ["adds", "FleschKincaid", "reading", "ease", "test"], "add_tokens": "func FleschKincaidEase ( text string ) float64 { words := Words ( text ) numWords := float64 ( len ( words ) ) numSentences := float64 ( len ( Sentences ( text ) ) ) numSyllables := 0 for _ , word := range words { numSyllables += SyllableCount ( word ) } return 206.835 - 1.015 * ( numWords / numSentences ) - 84.6 * ( float64 ( numSyllables ) / numWords )", "del_tokens": "func ReadingEase ( text string ) float64 { return 0.0 } func ReadingGradeLevel ( text string ) float64 { return 0.0", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "infinite", "loop", "of", "client"], "add_tokens": "break //break case common . WORK_DATA , common . WORK_WARNING , common . WORK_STATUS , default : break close ( client . in )", "del_tokens": "break continue case common . WORK_DATA , common . WORK_WARNING , common . WORK_STATUS , // close(client.in)", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "writing", "to", "a", "custom", "io", "Writer", "(", "for", "example", ":", "an", "http", "writer", ")"], "add_tokens": "CreateWriter ( name string , w io . Writer ) error return nil } // Create a new Tar and write it to a given writer func ( z * ZipFile ) CreateWriter ( name string , w io . Writer ) error { z . Writer = zip . NewWriter ( w ) z . Name = name file , err := os . Create ( t . Name ) if err != nil { return err } return t . CreateWriter ( name , file ) } // Create a new Tar and write it to a given writer func ( t * TarFile ) CreateWriter ( name string , w io . Writer ) error { t . GzWriter = gzip . NewWriter ( w ) t . Writer = tar . NewWriter ( w )", "del_tokens": "file * os . File z . file = file //Close close the zip file func ( z * ZipFile ) Close ( ) error { err := z . Writer . Close ( ) z . file . Close ( ) return err } file , err := os . Create ( t . Name ) if err != nil { return err } t . GzWriter = gzip . NewWriter ( file ) t . Writer = tar . NewWriter ( file )", "commit_type": "add"}
{"commit_tokens": ["Fix", "not", "allowed", "error", "return"], "add_tokens": "l . acceptQueue <- & connErr { nil , ErrProxyAddressNotAllowed }", "del_tokens": "l . acceptQueue <- & connErr { nil , err }", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "examples", "to", "README", "and", "doc", ".", "go", "."], "add_tokens": "// if you assert many times, use the below: // // import ( // \"testing\" // \"github.com/stretchr/testify/assert\" // ) // // func TestSomething(t *testing.T) { // assert := assert.New(t) // // var a string = \"Hello\" // var b string = \"Hello\" // // assert.Equal(a, b, \"The two words should be the same.\") // } // // // assert package contains Assertions object. it has assertion methods. // // Here is an overview of the assert functions: // assert.Equal(expected, actual [, message [, format-args]) // // assert.NotEqual(notExpected, actual [, message [, format-args]]) // // assert.True(actualBool [, message [, format-args]]) // // assert.False(actualBool [, message [, format-args]]) // // assert.Nil(actualObject [, message [, format-args]]) // // assert.NotNil(actualObject [, message [, format-args]]) // // assert.Empty(actualObject [, message [, format-args]]) // // assert.NotEmpty(actualObject [, message [, format-args]]) // // assert.Error(errorObject [, message [, format-args]]) // // assert.NoError(errorObject [, message [, format-args]]) // // assert.Implements((*MyInterface)(nil), new(MyObject) [,message [, format-args]]) // // assert.IsType(expectedObject, actualObject [, message [, format-args]]) // // assert.Contains(string, substring [, message [, format-args]]) // // assert.NotContains(string, substring [, message [, format-args]]) // // assert.Panics(func(){ // // // call code that should panic // // } [, message [, format-args]]) // // assert.NotPanics(func(){ // // // call code that should not panic // // } [, message [, format-args]]) // // assert.WithinDuration(timeA, timeB, deltaTime, [, message [, format-args]])", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "unpack", "errors", "encountered", "when", "diffing", "gcr", ".", "io", "/", "gcp", "-", "runtimes", "/", "ubuntu"], "add_tokens": "// Remove the .wh file if it was extracted. if _ , err := os . Stat ( rmPath ) ; ! os . IsNotExist ( err ) { if err := os . Remove ( rmPath ) ; err != nil { logrus . Error ( err ) } // Remove the whited-out path. newName := strings . Replace ( rmPath , \" \" , \" \" , 1 ) logrus . Debugf ( \" \" , baseDir , target ) // It's possible we end up creating files that can't be overwritten based on their permissions. // Explicitly delete an existing file before continuing. if _ , err := os . Stat ( target ) ; ! os . IsNotExist ( err ) { logrus . Debugf ( \" \" , target ) if err := os . Remove ( target ) ; err != nil { return err } } currFile , err := os . Create ( target ) logrus . Errorf ( \" \" , target , err )", "del_tokens": "newName := strings . Replace ( rmPath , \" \" , \" \" , 1 ) if err := os . Remove ( rmPath ) ; err != nil { logrus . Error ( err ) currFile , err := os . OpenFile ( target , os . O_CREATE | os . O_TRUNC | os . O_WRONLY , mode ) logrus . Errorf ( \" \" , target )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "wrong", "package", "import", "."], "add_tokens": "\" \" assert := audit . NewTestingAssertion ( t , true ) assert := audit . NewTestingAssertion ( t , true )", "del_tokens": "\" \" assert := testing . NewTestingAssertion ( t , true ) assert := testing . NewTestingAssertion ( t , true )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "in", "a", "NewSQLMapper", "method", "such", "that", "consumers", "of", "the", "library", "can", "now", "create", "new", "SQLMappers", "on", "demand", "and", "supply", "their", "own", "database", "connections", ".", "Also", "introduced", "a", "method", "that", "allows", "SQLMappers", "to", "return", "their", "SQL", "Database", "connection", "for", "inspection", ".", "Also", "altered", "some", "comments", "so", "that", "they", "weren", "t", "line", "breaking", "in", "standard", "emacs", "buffers"], "add_tokens": "// Retrieves the SQL configuration specified in config.yml // that resides at the root level of the project. // Returns a pointer to a SQLMapper if successful, or an error // if there is an issue opening a database connection.", "del_tokens": "// Retrieves the SQL configuration specified in the config.yml file that resides at the root level of the project. // Returns a pointer to a SQLMapper if successful, or an error if there is an issue opening a database connection.", "commit_type": "add"}
{"commit_tokens": ["Adds", "documentation", "for", "Block", "special", "case"], "add_tokens": "comment : \" \" ,", "del_tokens": "comment : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "subtle", "bug", "in", "ginkgo", "parallel", "mode"], "add_tokens": "fmt . Printf ( \" \\n \\n \" ) passed = <- completions && passed doneStreaming := make ( chan bool , 2 ) streamPipe := func ( pipe io . ReadCloser ) { io . Copy ( stream , pipe ) doneStreaming <- true } go streamPipe ( stdout ) go streamPipe ( stderr ) <- doneStreaming <- doneStreaming", "del_tokens": "passed = passed && <- completions go io . Copy ( stream , stdout ) go io . Copy ( stream , stderr )", "commit_type": "fix"}
{"commit_tokens": ["Add", "nano", "ledger", "to", "key", "manager"], "add_tokens": "const ( NameLedger = \" \" TypeLedger = 0x10 ) // PubKey should be private, but we want to encode it via go-wire // so we can view the address later, even without having the ledger // attached CachedPubKey crypto . PubKey if pk . CachedPubKey . Empty ( ) { pk . CachedPubKey = pub if pk . CachedPubKey . Empty ( ) { pk . CachedPubKey , _ , err = signLedger ( dev , [ ] byte { 0 } ) return pk . CachedPubKey , nil RegisterImplementation ( & PrivKeyLedger { } , NameLedger , TypeLedger ) . RegisterImplementation ( PubKeyLedger { } , NameLedger , TypeLedger )", "del_tokens": "pubKey crypto . PubKey if pk . pubKey . Empty ( ) { pk . pubKey = pub if pk . pubKey . Empty ( ) { pk . pubKey , _ , err = signLedger ( dev , [ ] byte { 0 } ) return pk . pubKey , nil RegisterImplementation ( & PrivKeyLedger { } , \" \" , 0x10 ) . RegisterImplementation ( PubKeyLedger { } , \" \" , 0x10 )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "multiple", "named", "return", "variables", "of", "the", "same", "type"], "add_tokens": "elided := false if ! addNames { for _ , param := range list . List { if len ( param . Names ) > 1 { elided = true break } } } if addNames || elided {", "del_tokens": "if addNames {", "commit_type": "add"}
{"commit_tokens": ["Use", "typed", "client", "for", "bundle", "informer"], "add_tokens": "bundleInf := client . BundleInformer ( bundleClient . SmithV1 ( ) , a . Namespace , a . ResyncPeriod )", "del_tokens": "bundleInf := client . BundleInformer ( bundleClient . SmithV1 ( ) . RESTClient ( ) , a . Namespace , a . ResyncPeriod )", "commit_type": "use"}
{"commit_tokens": ["Fix", "some", "dataraces", "detected", "with", "-", "race"], "add_tokens": "forwarder . threadsWaitingToDie . Add ( 1 )", "del_tokens": "forwarder . threadsWaitingToDie . Add ( 1 )", "commit_type": "fix"}
{"commit_tokens": ["improve", "tests", "about", "redirect", "and", "response"], "add_tokens": "} if newResp != nil {", "del_tokens": "return nil , err } else if newResp != nil { } else if err != nil { return nil , err", "commit_type": "improve"}
{"commit_tokens": ["Update", "message", "model", "to", "include", "reserved", "ranges", "and", "names"], "add_tokens": "// ReservedRangeElement ... type ReservedRangeElement struct { Documentation string Start int End int } Name string QualifiedName string Documentation string Options [ ] OptionElement Fields [ ] FieldElement Enums [ ] EnumElement OneOfs [ ] OneOfElement Extensions [ ] ExtensionsElement ReservedRanges [ ] ReservedRangeElement ReservedNames [ ] string", "del_tokens": "Name string QualifiedName string Documentation string Options [ ] OptionElement Fields [ ] FieldElement Enums [ ] EnumElement OneOfs [ ] OneOfElement Extensions [ ] ExtensionsElement", "commit_type": "update"}
{"commit_tokens": ["Updating", "build", "for", "new", "version", "of", "etcd", "registry", "."], "add_tokens": "trans := & http . Transport { reg := registry . NewEtcdRegistry ( eClient , \" \" )", "del_tokens": "trans := http . Transport { reg := registry . New ( eClient , \" \" )", "commit_type": "update"}
{"commit_tokens": ["move", "br", "inside", "brotli", "folder"], "add_tokens": "package brotli \" \" var BrCompressor = middleware . CompressConfig { Skipper : middleware . DefaultSkipper , New : func ( ) middleware . Compressor { Vary : middleware . DefaultCompressVary , Types : middleware . DefaultCompressTypes , MinLength : middleware . DefaultCompressMinLength ,", "del_tokens": "// +build cgo package middleware var BrCompressor = CompressConfig { Skipper : DefaultSkipper , New : func ( ) Compressor { Vary : defaultCompressVary , Types : defaultCompressTypes , MinLength : defaultCompressMinLength ,", "commit_type": "move"}
{"commit_tokens": ["Fix", "user", "list", "to", "properly", "show", "pull", "instead", "of", "explicit"], "add_tokens": "pullUsers = append ( pullUsers , user )", "del_tokens": "pullUsers = append ( pushUsers , user )", "commit_type": "fix"}
{"commit_tokens": ["Move", "/", "rename", "test", "-", "sender", "into", "examples", "/", "statsd", "-", "emitter"], "add_tokens": "failed int64 if ! debug_enabled { return fmt . Sprintf ( \" \" , key , strconv . FormatInt ( val , 10 ) , tipe ) return fmt . Sprintf ( \" \" , key , strconv . FormatFloat ( val , 'f' , - 1 , 64 ) , tipe ) log . SetPrefix ( \" \" ) bytes . add ( sendGaugef ( conn , \" \" , float64 ( now . UnixNano ( ) ) / 1000000000 ) ) success , failed , success + failed )", "del_tokens": "failed int64 if ( ! debug_enabled ) { return fmt . Sprintf ( \" \" , key , strconv . FormatInt ( val , 10 ) , tipe ) return fmt . Sprintf ( \" \" , key , strconv . FormatFloat ( val , 'f' , - 1 , 64 ) , tipe ) log . SetPrefix ( \" \" ) bytes . add ( sendGaugef ( conn , \" \" , float64 ( now . UnixNano ( ) ) / 1000000000 ) ) success , failed , success + failed )", "commit_type": "move"}
{"commit_tokens": ["Add", "an", "option", "to", "start", "consuming", "from", "latest"], "add_tokens": "// WithStartFrmLatest will make sure the client start consuming // events starting from the most recent event in kinesis. This // option discards the checkpoints. func WithStartFromLatest ( ) ClientOption { return func ( kc * KinesisClient ) { kc . fromLatest = true } } svc kinesisiface . KinesisAPI fromLatest bool if c . fromLatest { params . ShardIteratorType = aws . String ( \" \" ) } else if lastSeqNum != \" \" {", "del_tokens": "svc kinesisiface . KinesisAPI if lastSeqNum != \" \" {", "commit_type": "add"}
{"commit_tokens": ["Allow", "streaming", "COPY", "/", "ADD", "from", "an", "archive", "on", "disk"], "add_tokens": "func CalcCopyInfo ( origPath , rootPath string , allowWildcards bool ) ( [ ] CopyInfo , error ) { subInfos , err := CalcCopyInfo ( trimLeadingPath ( strings . TrimPrefix ( path , rootPath ) ) , rootPath , false ) copyInfos = append ( copyInfos , CopyInfo { FileInfo : info , Path : info . Name ( ) , FromDir : true } ) return [ ] CopyInfo { { FileInfo : fi , Path : origPath } } , nil func DownloadURL ( src , dst , tempDir string ) ( [ ] CopyInfo , string , error ) { tmpDir , err := ioutil . TempDir ( tempDir , \" \" )", "del_tokens": "func CalcCopyInfo ( origPath , rootPath string , allowLocalDecompression , allowWildcards bool ) ( [ ] CopyInfo , error ) { subInfos , err := CalcCopyInfo ( trimLeadingPath ( strings . TrimPrefix ( path , rootPath ) ) , rootPath , allowLocalDecompression , false ) copyInfos = append ( copyInfos , CopyInfo { FileInfo : info , Path : info . Name ( ) , Decompress : allowLocalDecompression , FromDir : true } ) return [ ] CopyInfo { { FileInfo : fi , Path : origPath , Decompress : allowLocalDecompression } } , nil func DownloadURL ( src , dst string ) ( [ ] CopyInfo , string , error ) { tmpDir , err := ioutil . TempDir ( \" \" , \" \" )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "confusion", "in", "Message", ".", "Force"], "add_tokens": "var payload [ ] byte // Try to reuse the buffer if possible if uint32 ( cap ( curBuf ) ) >= payloadSz { payload = curBuf [ : payloadSz ] payload = make ( [ ] byte , payloadSz ) _ , err := io . ReadFull ( m . union , payload )", "del_tokens": "var buf [ ] byte if uint32 ( cap ( curBuf ) ) < payloadSz { buf = make ( [ ] byte , len ( curBuf ) , payloadSz ) copy ( buf , curBuf ) buf = curBuf payload := buf [ : payloadSz ] _ , err := io . ReadFull ( m . future , payload )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "lock", "os", "thread", "in", "event", "loop"], "add_tokens": "import \" \"", "del_tokens": "import ( \" \" \" \" ) // allocate whole OS thread, so nothing can get scheduled over eventloop runtime . LockOSThread ( )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "whitespace", "issue", "when", "reading", "tokens", "from", "stdin"], "add_tokens": "\" \" flagDebug = flag . Bool ( \" \" , false , \" \" ) // trim possible whitespace from token tokData = regexp . MustCompile ( `\\s*$` ) . ReplaceAll ( tokData , [ ] byte { } ) if * flagDebug { fmt . Fprintf ( os . Stderr , \" \\n \" , len ( tokData ) ) } fmt . Fprintf ( os . Stderr , \" \\n \\n \" , token . Header ) fmt . Fprintf ( os . Stderr , \" \\n \\n \" , token . Claims ) } else if * flagDebug { fmt . Println ( \" \" , len ( tokData ) )", "del_tokens": "flagDebug = flag . Bool ( \" \" , false , \" \" ) fmt . Printf ( \" \\n \\n \" , token . Header ) fmt . Printf ( \" \\n \\n \" , token . Claims )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "crash", "on", "botname", ".", "Small", "cleanup", ".", "Go", "fmt"], "add_tokens": "\" \" var flog FancyLog command := \" \" if len ( parts ) == 2 { command = parts [ 1 ] } switch command { return \" \" + nick", "del_tokens": "\" \" \" \" var flog FancyLog ; switch parts [ 1 ] { return \" \" + nick log . Warnf ( \" \\n \" , ircChannel , string ( debug . Stack ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["removed", "brands", "and", "updated", "tests"], "add_tokens": "ServiceName : \" \" ,", "del_tokens": "ServiceName : \" \" ,", "commit_type": "remove"}
{"commit_tokens": ["Move", "the", "temp", "file", "to", "the", "destination", "."], "add_tokens": "err = os . Rename ( file . Name ( ) , * flagDest + \" \" ) if err != nil { fmt . Println ( err ) // TODO: err signal return }", "del_tokens": "os . Rename ( file . Name ( ) , * flagDest + \" \" )", "commit_type": "move"}
{"commit_tokens": ["Use", "fastsha256", "in", "Hash160", "."], "add_tokens": "\" \" return calcHash ( calcHash ( buf , fastsha256 . New ( ) ) , ripemd160 . New ( ) )", "del_tokens": "\" \" return calcHash ( calcHash ( buf , sha256 . New ( ) ) , ripemd160 . New ( ) )", "commit_type": "use"}
{"commit_tokens": ["Allow", "for", "patterns", "in", "default", "file", "patterns"], "add_tokens": "\" \" var ( emptyBrew = Homebrew { } filePatterns = [ ] string { \" \" , \" \" , \" \" } ) for _ , pattern := range filePatterns { matches , err := globPath ( pattern ) if err != nil { log . Fatalf ( \" \" , pattern , err ) config . Files = append ( config . Files , matches ... )", "del_tokens": "var emptyBrew = Homebrew { } for _ , f := range [ ] string { \" \" , \" \" , \" \" } { if _ , err := os . Stat ( f ) ; err == nil { config . Files = append ( config . Files , f )", "commit_type": "allow"}
{"commit_tokens": ["Implement", "more", "of", "the", "planned", "404s"], "add_tokens": "err := dataStore . WriteFileChunk ( id , contentRange . Start , contentRange . End , r . Body ) if os . IsNotExist ( err ) { reply ( w , http . StatusNotFound , err . Error ( ) ) return } else if err != nil { if os . IsNotExist ( err ) { reply ( w , http . StatusNotFound , err . Error ( ) ) return } else if err != nil { if os . IsNotExist ( err ) { reply ( w , http . StatusNotFound , err . Error ( ) ) return } else if err != nil { err = dataStore . WriteFileChunk ( fileId , start , end , r . Body ) if os . IsNotExist ( err ) { reply ( w , http . StatusNotFound , err . Error ( ) ) return } else if err != nil {", "del_tokens": "if err := dataStore . WriteFileChunk ( id , contentRange . Start , contentRange . End , r . Body ) ; err != nil { // @TODO: Could be a 404 as well if err != nil { // @TODO: Could be a 404 as well if err != nil { // @TODO: Could be a 404 as well if err := dataStore . WriteFileChunk ( fileId , start , end , r . Body ) ; err != nil { // @TODO: Could be a 404 as well", "commit_type": "implement"}
{"commit_tokens": ["Make", "serialization", "compatible", "with", "the", "java", "version"], "add_tokens": "means := make ( [ ] float64 , numCentroids ) var delta float32 var x float64 for i := 0 ; i < int ( numCentroids ) ; i ++ { err = binary . Read ( buf , endianess , & delta ) x += float64 ( delta ) means [ i ] = x for i := 0 ; i < int ( numCentroids ) ; i ++ { t . Add ( means [ i ] , decUint )", "del_tokens": "means := make ( [ ] float32 , numCentroids ) var i int32 for i = 0 ; i < numCentroids ; i ++ { err = binary . Read ( buf , endianess , & means [ i ] ) var x float64 for i = 0 ; i < numCentroids ; i ++ { t . Add ( float64 ( means [ i ] ) + x , decUint ) x = float64 ( means [ i ] )", "commit_type": "make"}
{"commit_tokens": ["add", "missing", "data", "to", "log", "lines"], "add_tokens": "f . log ( \" \" , * decisionTask . WorkflowType . Name , * decisionTask . WorkflowExecution . WorkflowID , * decisionTask . WorkflowExecution . RunID , err . Error ( ) ) f . log ( \" \" , * decisionTask . WorkflowType . Name , * decisionTask . WorkflowExecution . WorkflowID , * decisionTask . WorkflowExecution . RunID , err . Error ( ) ) f . log ( \" \" , * decisionTask . WorkflowType . Name , * decisionTask . WorkflowExecution . WorkflowID , * decisionTask . WorkflowExecution . RunID , repErr . Error ( ) )", "del_tokens": "f . log ( \" \" , err . Error ( ) ) f . log ( \" \" , err . Error ( ) ) f . log ( \" \" , repErr . Error ( ) )", "commit_type": "add"}
{"commit_tokens": ["add", "MustDropTable", "method", "for", "dialect"], "add_tokens": "//DropTableSql(tableName string) string MustDropTable ( tableName string ) error func ( db * Base ) MustDropTable ( tableName string ) error { _ , err := db . db . Exec ( db . DropTableSql ( tableName ) ) return err }", "del_tokens": "DropTableSql ( tableName string ) string // Get data from db cell to a struct's field //GetData(col *Column, fieldValue *reflect.Value, cellData interface{}) error // Set field data to db //SetData(col *Column, fieldValue *refelct.Value) (interface{}, error)", "commit_type": "add"}
{"commit_tokens": ["Move", "ari_structs", "into", "the", "nv", "package"], "add_tokens": "package nv", "del_tokens": "package main", "commit_type": "move"}
{"commit_tokens": ["add", "TrimLeadingSpaces", "and", "update", "Trim", "related", "benchmarks"], "add_tokens": "// it. Only 0x20, tabs, NL are considered space characters. // TrimLeadingpaces removes the leading spaces from a slice and returns it. // Only 0x20 and tabs are considered space characters. func TrimLeadingSpaces ( p [ ] byte ) [ ] byte { for i := 0 ; i < len ( p ) ; i ++ { if p [ i ] != 0x20 && p [ i ] != '\\t' { return p [ i : ] } } // it was all spaces return p [ : 0 ] }", "del_tokens": "// it. Only 0x20 and NL are considered space characters.", "commit_type": "add"}
{"commit_tokens": ["Use", "url", ".", "URL", "and", "url", ".", "Values", "APIs", "to", "manage", "URLs"], "add_tokens": "var ( apiBaseURL = url . URL { Scheme : \" \" , Host : \" \" , Path : \" \" } v := url . Values { } v . Add ( key , value ) u := apiBaseURL u . RawQuery = v . Encode ( ) return u . String ( )", "del_tokens": "\" \" const ( apiBaseURL = \" \" parts := make ( [ ] string , 0 , len ( query ) ) parts = append ( parts , strings . Join ( [ ] string { url . QueryEscape ( key ) , url . QueryEscape ( value ) } , \" \" ) ) return apiBaseURL + strings . Join ( parts , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Moved", "some", "select", "insert", "update", "from", "gorp", ".", "DbMap", "to", "DbGorp"], "add_tokens": "Db * gorp . DbGorp if err := gorp . InitDb ( gorp . Db ) ; err != nil { // Force a failure revel . RevelLog . Panicf ( \" \" )", "del_tokens": "Db * gorp . DbGorp if err := gorp . InitDb ( gorp . Db ) ; err != nil { revel . ERROR . Panicf ( \" \" )", "commit_type": "move"}
{"commit_tokens": ["remove", "short", "commands", "delete", "log", "fix"], "add_tokens": "\" \" func deleteStepLib ( c * cli . Context ) error { return fmt . Errorf ( \" \" ) log . Infof ( \" \" , collectionURI ) return fmt . Errorf ( \" \" , collectionURI )", "del_tokens": "func deleteCollection ( c * cli . Context ) error { log . Debugln ( \" \" ) log . Fatalln ( \" \" ) log . Errorf ( \" \" , collectionURI )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "a", "race", "alert", "when", "fiddling", "the", "resendTimer"], "add_tokens": "unackedSends [ ] * send acked chan struct { } // Closed with Conn lock. resend func ( ) timedOut func ( ) mu sync . Mutex s . mu . Lock ( ) defer s . mu . Unlock ( ) go s . resend ( ) s . mu . Lock ( ) s . mu . Unlock ( ) send := & send { send . mu . Lock ( ) send . mu . Unlock ( ) return c . unackedSends [ i ] send . mu . Lock ( ) defer send . mu . Unlock ( )", "del_tokens": "unackedSends [ ] send acked chan struct { } resend func ( ) timedOut func ( ) s . resend ( ) send := send { return & c . unackedSends [ i ]", "commit_type": "fix"}
{"commit_tokens": ["Use", "extracted", "go", "-", "libp2p", "-", "crypto", "-", "secio", "-", "peer", "packages"], "add_tokens": "peer \" \"", "del_tokens": "peer \" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "curies", "as", "an", "array"], "add_tokens": "l := LinkCollection { NewLink ( href , LinkAttr { \" \" : name } , LinkAttr { \" \" : templated } ) , } r . AddLinkCollection ( \" \" , l )", "del_tokens": "l := NewLink ( href , LinkAttr { \" \" : name } , LinkAttr { \" \" : templated } ) r . AddLink ( \" \" , l )", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "VectorizeBytes", "/", "SimhashBytes", "functions"], "add_tokens": "var f [ ] Feature var w [ ] [ ] byte f = fs . GetFeatures ( ) w = boundaries . FindAll ( testString , - 1 ) func BenchmarkVectorizeBytes ( b * testing . B ) { for i := 0 ; i < b . N ; i ++ { VectorizeBytes ( w ) } } func BenchmarkSimhash ( b * testing . B ) { for i := 0 ; i < b . N ; i ++ { Simhash ( & WordFeatureSet { testString } ) } } func BenchmarkSimhashBytes ( b * testing . B ) { for i := 0 ; i < b . N ; i ++ { SimhashBytes ( w ) } }", "del_tokens": "f := fs . GetFeatures ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "travis", "build", "and", "coveralls", "code", "coverage"], "add_tokens": "u := strings . Replace ( string ( b ) , \" \" , \" \" + address + \" \" , 1 ) return u if len ( r . ResourceSets ) <= 0 || len ( r . ResourceSets [ 0 ] . Resources ) <= 0 { return c := r . ResourceSets [ 0 ] . Resources [ 0 ] . Point . Coordinates l = geo . Location { c [ 0 ] , c [ 1 ] } if len ( r . ResourceSets ) <= 0 || len ( r . ResourceSets [ 0 ] . Resources ) <= 0 { return address = r . ResourceSets [ 0 ] . Resources [ 0 ] . Address . FormattedAddress", "del_tokens": "return strings . Replace ( string ( b ) , \" \" , \" \" + address + \" \" , 1 ) if len ( r . ResourceSets [ 0 ] . Resources ) > 0 { c := r . ResourceSets [ 0 ] . Resources [ 0 ] . Point . Coordinates l = geo . Location { c [ 0 ] , c [ 1 ] } if len ( r . ResourceSets [ 0 ] . Resources ) > 0 { address = r . ResourceSets [ 0 ] . Resources [ 0 ] . Address . FormattedAddress", "commit_type": "add"}
{"commit_tokens": ["Fix", "client", "lib", "errors", "documentation", "."], "add_tokens": "// ErrConnectionFailed is a error raised when the connection between the client and the server failed. // IsErrImageNotFound returns true if the error is caused // IsErrUnauthorized returns true if the error is caused", "del_tokens": "// IsImageNotFound returns true if the error is caused // IsUnauthorized returns true if the error is caused", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "few", "rogue", "runtime", "-", "schema", "imports"], "add_tokens": "return & models . ActualLRP { } , models . ErrResourceNotFound", "del_tokens": "\" \" return & models . ActualLRP { } , bbserrors . ErrStoreResourceNotFound", "commit_type": "fix"}
{"commit_tokens": ["Make", "GlobalLevel", "and", "DisableSampling", "thread", "safe"], "add_tokens": "var now = time . Now", "del_tokens": "var ( // TimestampFieldName is the field name used for the timestamp field. TimestampFieldName = \" \" // LevelFieldName is the field name used for the level field. LevelFieldName = \" \" // MessageFieldName is the field name used for the message field. MessageFieldName = \" \" // ErrorFieldName is the field name used for error fields. ErrorFieldName = \" \" // SampleFieldName is the name of the field used to report sampling. SampleFieldName = \" \" // TimeFieldFormat defines the time format of the Time field type. TimeFieldFormat = time . RFC3339 now = time . Now )", "commit_type": "make"}
{"commit_tokens": ["Adds", "support", "for", "calling", "the", "prefix", "method", "on", "the", "last", "sub", "-", "index", "for", "a", "compound", "index", "."], "add_tokens": "func ( c * CompoundIndex ) PrefixFromArgs ( args ... interface { } ) ( [ ] byte , error ) { if len ( args ) > len ( c . Indexes ) { return nil , fmt . Errorf ( \" \" ) } var out [ ] byte for i , arg := range args { if i + 1 < len ( args ) { val , err := c . Indexes [ i ] . FromArgs ( arg ) if err != nil { return nil , fmt . Errorf ( \" \" , i , err ) } out = append ( out , val ... ) } else { prefixIndexer , ok := c . Indexes [ i ] . ( PrefixIndexer ) if ! ok { return nil , fmt . Errorf ( \" \" , i ) } val , err := prefixIndexer . PrefixFromArgs ( arg ) if err != nil { return nil , fmt . Errorf ( \" \" , i , err ) } out = append ( out , val ... ) } } return out , nil }", "del_tokens": "return c . PrefixFromArgs ( args ... ) } func ( c * CompoundIndex ) PrefixFromArgs ( args ... interface { } ) ( [ ] byte , error ) {", "commit_type": "add"}
{"commit_tokens": ["use", "nomockutil", "to", "get", "userId", "from", "JWT", "token"], "add_tokens": "\" \" userId , err := nomockutil . GetSubjectInToken ( p . token )", "del_tokens": "\" \" userId , err := authutil . GetSubjectInToken ( p . token )", "commit_type": "use"}
{"commit_tokens": ["Add", "ChannelList", "for", "listing", "channels", "."], "add_tokens": "users := map [ string ] string { } slackUsers , err := slackerAPI . UsersList ( ) if err != nil { fmt . Printf ( \" \\n \" , err . Error ( ) ) os . Exit ( 1 ) } for _ , user := range slackUsers { users [ user . ID ] = user . Profile . RealName } msg := slacker . RTMMessage { Text : \" \" , broker . Publish ( msg ) } func printMessage ( e slacker . RTMEvent , users map [ string ] string ) { msg , err := e . Message ( ) if err != nil { return } var uName string uName , ok := users [ msg . User ] if ! ok { uName = \" \" } fmt . Printf ( \" \\n \" , uName , msg . Text )", "del_tokens": "\" \" for { select { case event := <- broker . Events ( ) : fmt . Println ( event . Type ) default : time . Sleep ( 10 * time . Millisecond ) }", "commit_type": "add"}
{"commit_tokens": ["added", "support", "to", "xml", ":", "space", "attribute"], "add_tokens": "func ( n * Node ) sanitizedData ( preserveSpaces bool ) string { if preserveSpaces { return n . Data } return strings . TrimSpace ( n . Data ) } func calculatePreserveSpaces ( n * Node , pastValue bool ) bool { if attr := n . SelectAttr ( \" \" ) ; attr == \" \" { return true } else if attr == \" \" { return false } return pastValue } func outputXML ( buf * bytes . Buffer , n * Node , preserveSpaces bool ) { preserveSpaces = calculatePreserveSpaces ( n , preserveSpaces ) xml . EscapeText ( buf , [ ] byte ( n . sanitizedData ( preserveSpaces ) ) ) outputXML ( buf , child , preserveSpaces ) outputXML ( & buf , n , false ) outputXML ( & buf , n , false )", "del_tokens": "func outputXML ( buf * bytes . Buffer , n * Node ) { xml . EscapeText ( buf , [ ] byte ( strings . TrimSpace ( n . Data ) ) ) outputXML ( buf , child ) outputXML ( & buf , n ) outputXML ( & buf , n )", "commit_type": "add"}
{"commit_tokens": ["improve", "cleaning", "up", "in", "dht", "tests", "."], "add_tokens": "defer dhtA . Halt ( ) defer dhtB . Halt ( ) defer dhtA . Halt ( ) defer dhtB . Halt ( ) defer func ( ) { for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } } ( ) defer func ( ) { for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } } ( ) go func ( ) { for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } } ( )", "del_tokens": "dhtA . Halt ( ) dhtB . Halt ( ) for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) } for i := 0 ; i < 4 ; i ++ { dhts [ i ] . Halt ( ) }", "commit_type": "improve"}
{"commit_tokens": ["Use", "testify", "/", "assert", "for", "tests", "."], "add_tokens": "import \" \" for _ , tc := range tt { assert . Equal ( t , tc . out , codegenComment ( tc . in ) )", "del_tokens": "for i , tc := range tt { got := codegenComment ( tc . in ) expected := tc . out if got != expected { t . Errorf ( \" \\n \\n \" , i , got , expected ) }", "commit_type": "use"}
{"commit_tokens": ["fix", "golint", "and", "vet", "warnings"], "add_tokens": "// TypesMigrator is composed of a DomainMigrator, a WorkflowTypeMigrator and an ActivityTypeMigrator. // Migrate runs Migrate on the underlying DomainMigrator, a WorkflowTypeMigrator and ActivityTypeMigrator. // DomainMigrator will register or deprecate the configured domains as required. // Migrate asserts that DeprecatedDomains are deprecated or deprecates them, then asserts that RegisteredDomains are registered or registers them. panic ( err ) log . Printf ( \" \" , domain , err . Error ( ) ) // WorkflowTypeMigrator will register or deprecate the configured workflow types as required. // Migrate asserts that DeprecatedWorkflowTypes are deprecated or deprecates them, then asserts that RegisteredWorkflowTypes are registered or registers them. panic ( err ) // ActivityTypeMigrator will register or deprecate the configured activity types as required. // Migrate asserts that DeprecatedActivityTypes are deprecated or deprecates them, then asserts that RegisteredActivityTypes are registered or registers them. panic ( err )", "del_tokens": "} else { panic ( err ) log . Printf ( \" \" , err . Error ( ) ) } else { panic ( err ) } else { panic ( err )", "commit_type": "fix"}
{"commit_tokens": ["use", "SupportLazyMode", "to", "get", "whether", "the", "hypervisor", "support", "lazy", "mode"], "add_tokens": "var lazy bool = hypervisor . HDriver . SupportLazyMode ( ) && vmId == \" \" var lazy bool = hypervisor . HDriver . SupportLazyMode ( ) var lazy bool = hypervisor . HDriver . SupportLazyMode ( )", "del_tokens": "var lazy = false if daemon . Hypervisor == \" \" && vmId == \" \" { lazy = true } var lazy = false if daemon . Hypervisor == \" \" { lazy = true } var lazy = false if daemon . Hypervisor == \" \" { lazy = true }", "commit_type": "use"}
{"commit_tokens": ["remove", "systematic", "detach", "add", "SetAutoDetach", "method"], "add_tokens": "// SetAutoDetach Enable/disable libusb's automatic kernel driver detachment. // When this is enabled libusb will automatically detach the kernel driver // on an interface when claiming the interface, and attach it when releasing the interface. // Automatic kernel driver detachment is disabled on newly opened device handles by default. func ( d * Device ) SetAutoDetach ( autodetach int ) error { errno := C . libusb_set_auto_detach_kernel_driver ( d . handle , C . int ( autodetach ) , ) // TODO LIBUSB_ERROR_NOT_SUPPORTED (-12) handling // if any errors occur if errno < 0 { return fmt . Errorf ( \" \" , usbError ( errno ) ) } return nil }", "del_tokens": "// Detach the interface if errno := C . libusb_detach_kernel_driver ( d . handle , C . int ( iface ) ) ; errno < 0 { fmt . Errorf ( \" \" , usbError ( errno ) ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "name", "field", "to", "created", "/", "updated", "output", "as", "well"], "add_tokens": "f . Log . WithFields ( log . Fields { \" \" : * updated . Version , \" \" : f . FunctionName , } ) . Info ( \" \" ) f . Log . WithFields ( log . Fields { \" \" : * created . Version , \" \" : f . FunctionName , } ) . Info ( \" \" )", "del_tokens": "f . Log . WithField ( \" \" , * updated . Version ) . Info ( \" \" ) f . Log . WithField ( \" \" , * created . Version ) . Info ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Use", "http", ".", "StatusOK", "instead", "of", "200"], "add_tokens": "if resp . StatusCode != http . StatusOK {", "del_tokens": "if resp . StatusCode != 200 {", "commit_type": "use"}
{"commit_tokens": ["Fix", "kube", "-", "deploy", "issues", "from", "upstream", "rebase"], "add_tokens": "klatest \" \" latest \" \" client , err := kubeclient . New ( masterServer , klatest . Version , nil ) osClient , err := osclient . New ( masterServer , latest . Version , nil ) controller := & api . ReplicationController {", "del_tokens": "client , err := kubeclient . New ( masterServer , nil ) osClient , err := osclient . New ( masterServer , nil ) controller := api . ReplicationController {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "specifying", "short", "pod", "IDs", "for", "container", "create"], "add_tokens": "sbID := req . GetPodSandboxId ( ) if sbID == \" \" { return nil , fmt . Errorf ( \" \" ) } sandboxID , err := s . podIDIndex . Get ( sbID ) if err != nil { return nil , fmt . Errorf ( \" \" , sbID , err ) } sb := s . getSandbox ( sandboxID ) return nil , fmt . Errorf ( \" \" , sandboxID ) if _ , err = os . Stat ( containerDir ) ; err == nil { if err = os . MkdirAll ( containerDir , 0755 ) ; err != nil {", "del_tokens": "// The id of the PodSandbox podSandboxID := req . GetPodSandboxId ( ) sb := s . getSandbox ( podSandboxID ) return nil , fmt . Errorf ( \" \" , podSandboxID ) if _ , err := os . Stat ( containerDir ) ; err == nil { if err := os . MkdirAll ( containerDir , 0755 ) ; err != nil {", "commit_type": "allow"}
{"commit_tokens": ["Adds", "*", "Trace", ".", "Format", "method"], "add_tokens": "import ( \" \" \" \" ) // Format satisfies the Formatter interface from fmt func ( s * Trace ) Format ( state fmt . State , verb rune ) { if s != nil { for _ , el := range * s { fmt . Fprintf ( state , \" \" , el . PackageName , el . MethodName , el . FileName , el . LineNumber ) } } }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["fix", "intersection", "with", "two", "sets"], "add_tokens": "if ! set1 . Has ( item ) || ! set2 . Has ( item ) { result . Remove ( item ) } if ! set . Has ( item ) {", "del_tokens": "if ! set . Has ( item ) || ! set1 . Has ( item ) || ! set2 . Has ( item ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "to", "make", "golint", "happy", "."], "add_tokens": "// FTP status codes, defined in RFC 959", "del_tokens": "// Positive Preliminary reply // Positive Completion reply // Positive Intermediate reply // Transient Negative Completion reply // Permanent Negative Completion reply", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "context", "for", "publish", "to", "async", "operations", "work", "outside", "of", "rpc", "s"], "add_tokens": "res := t . Publish ( context . Background ( ) , & pubsub . Message {", "del_tokens": "res := t . Publish ( ctx , & pubsub . Message {", "commit_type": "use"}
{"commit_tokens": ["Updated", "README", ".", "md", "and", "host", "example", "to", "use", "the", "new", "Subrouter", "()", "method"], "add_tokens": "// Group by /api basepath api := l . Group ( \" \" ) v1 := api . Subrouter ( ) . Host ( \" \" ) v1 . Get ( \" \" , handler ( \" \" ) ) v2 := api . Subrouter ( ) . Host ( \" \" ) v2 . Get ( \" \" , handler ( \" \" ) )", "del_tokens": "v1 := l . Group ( \" \" ) v1 . Host ( \" \" ) . Get ( \" \" , handler ( \" \" ) ) v2 := l . Group ( \" \" ) v2 . Host ( \" \" ) . Get ( \" \" , handler ( \" \" ) )", "commit_type": "update"}
{"commit_tokens": ["Changing", "interface", "between", "camput", "and", "schema", "in", "prep", "for", "directory", "work", "."], "add_tokens": "\" \" fileName := \" \" fi , _ := os . Lstat ( fileName ) m := NewCommonFileMap ( fileName , fi )", "del_tokens": "m := newMapForFileName ( \" \" )", "commit_type": "change"}
{"commit_tokens": ["add", "spies", "to", "test", "call", "counts"], "add_tokens": "// Helper log function, takes care of filtering based on level", "del_tokens": "// TODO : If run as a goroutine, can the caller modify fields on the struct? Provide IsRunning(), Stop(), Pause()? // Help log function, takes care of filtering based on level", "commit_type": "add"}
{"commit_tokens": ["Fix", "Consumer", "leader", "change", "failure"], "add_tokens": "case proto . ErrLeaderNotAvailable , proto . ErrNotLeaderForPartition , proto . ErrBrokerNotAvailable , proto . ErrUnknownTopicOrPartition :", "del_tokens": "case proto . ErrLeaderNotAvailable , proto . ErrNotLeaderForPartition , proto . ErrBrokerNotAvailable :", "commit_type": "fix"}
{"commit_tokens": ["create", "File", "struct", "to", "hold", "file", "s", "directory", "information"], "add_tokens": "if w . Files [ 0 ] . Dir != \" \" { t . Errorf ( \" \" , \" \" , w . Files [ 0 ] . Dir ) } if w . Files [ 1 ] . Dir != \" \" { t . Errorf ( \" \" , \" \" , w . Files [ 1 ] . Dir ) } if w . Files [ 3 ] . Dir != \" \" { t . Errorf ( \" \" , \" \" , w . Files [ 3 ] . Dir ) } fileList , err := ListFiles ( testDir ) if fileList [ 0 ] . Info . Name ( ) != filepath . Base ( testDir ) { fileList [ 0 ] . Info . Name ( ) ) if fileList [ 1 ] . Info . Name ( ) != \" \" { fileList [ 1 ] . Info . Name ( ) )", "del_tokens": "fInfoList , err := ListFiles ( testDir ) if fInfoList [ 0 ] . Name ( ) != filepath . Base ( testDir ) { fInfoList [ 0 ] . Name ( ) ) if fInfoList [ 1 ] . Name ( ) != \" \" { fInfoList [ 1 ] . Name ( ) )", "commit_type": "create"}
{"commit_tokens": ["Make", "sure", "volumes", "are", "there", "after", "restarts"], "add_tokens": "\" \" \" \" runner * matterMasterRunner runner = newRunner ( matterMasterPath , port , volumeDir ) runner . start ( ) runner . stop ( ) runner . cleanup ( ) Ω( g etVolumeResponse) . S hould( C onsistOf( c reateVolumeResponse) )", "del_tokens": "\" \" \" \" \" \" \" \" \" \" \" \" \" \" process ifrit . Process runner := ginkgomon . New ( ginkgomon . Config { Name : \" \" , Command : exec . Command ( matterMasterPath , \" \" , strconv . Itoa ( port ) , \" \" , volumeDir , ) , StartCheck : \" \" , } ) process = ginkgomon . Invoke ( runner ) process . Signal ( os . Kill ) Eventually ( process . Wait ( ) ) . Should ( Receive ( ) ) err := os . RemoveAll ( volumeDir ) Ω( e rr) . S houldNot( H aveOccurred( ) ) Ω( g etVolumeResponse) . S hould( C ontainElement( c reateVolumeResponse) )", "commit_type": "make"}
{"commit_tokens": ["Fix", "races", "on", "command", "fields"], "add_tokens": "response := cmd . getResponse ( ) if response == nil { if ! cmd . Called ( ) {", "del_tokens": "cmd . called = true if len ( cmd . responses ) == 0 { response := cmd . responses [ 0 ] if len ( cmd . responses ) > 1 { cmd . responses = cmd . responses [ 1 : ] } if ! cmd . called {", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", "definitions"], "add_tokens": "Type ResourceType `json:\"type\"` // Resource type. InterceptionID InterceptionID `json:\"interceptionId\"` // Each request the page makes will have a unique id, however if any redirects are encountered while processing that fetch, they will be reported with the same id as the original fetch. Likewise if HTTP authentication is needed then the same fetch id will be used. Request * Request `json:\"request\"` FrameID cdp . FrameID `json:\"frameId\"` // The id of the frame that initiated the request. ResourceType ResourceType `json:\"resourceType\"` // How the requested resource will be used. IsNavigationRequest bool `json:\"isNavigationRequest\"` // Whether this is a navigation request, which can abort the navigation completely. IsDownload bool `json:\"isDownload,omitempty\"` // Set if the request is a navigation that will result in a download. Only present after response is received from the server (i.e. HeadersReceived stage). RedirectURL string `json:\"redirectUrl,omitempty\"` // Redirect location, only sent if a redirect was intercepted. AuthChallenge * AuthChallenge `json:\"authChallenge,omitempty\"` // Details of the Authorization Challenge encountered. If this is set then continueInterceptedRequest must contain an authChallengeResponse. ResponseErrorReason ErrorReason `json:\"responseErrorReason,omitempty\"` // Response error if intercepted at response stage or if redirect occurred while intercepting request. ResponseStatusCode int64 `json:\"responseStatusCode,omitempty\"` // Response code if intercepted at response stage or if redirect occurred while intercepting request or auth retry occurred. ResponseHeaders Headers `json:\"responseHeaders,omitempty\"` // Response headers if intercepted at the response stage or if redirect occurred while intercepting request or auth retry occurred. Type ResourceType `json:\"type,omitempty\"` // Type of this resource. Type ResourceType `json:\"type\"` // Resource type.", "del_tokens": "\" \" Type page . ResourceType `json:\"type\"` // Resource type. InterceptionID InterceptionID `json:\"interceptionId\"` // Each request the page makes will have a unique id, however if any redirects are encountered while processing that fetch, they will be reported with the same id as the original fetch. Likewise if HTTP authentication is needed then the same fetch id will be used. Request * Request `json:\"request\"` FrameID cdp . FrameID `json:\"frameId\"` // The id of the frame that initiated the request. ResourceType page . ResourceType `json:\"resourceType\"` // How the requested resource will be used. IsNavigationRequest bool `json:\"isNavigationRequest\"` // Whether this is a navigation request, which can abort the navigation completely. IsDownload bool `json:\"isDownload,omitempty\"` // Set if the request is a navigation that will result in a download. Only present after response is received from the server (i.e. HeadersReceived stage). RedirectURL string `json:\"redirectUrl,omitempty\"` // Redirect location, only sent if a redirect was intercepted. AuthChallenge * AuthChallenge `json:\"authChallenge,omitempty\"` // Details of the Authorization Challenge encountered. If this is set then continueInterceptedRequest must contain an authChallengeResponse. ResponseErrorReason ErrorReason `json:\"responseErrorReason,omitempty\"` // Response error if intercepted at response stage or if redirect occurred while intercepting request. ResponseStatusCode int64 `json:\"responseStatusCode,omitempty\"` // Response code if intercepted at response stage or if redirect occurred while intercepting request or auth retry occurred. ResponseHeaders Headers `json:\"responseHeaders,omitempty\"` // Response headers if intercepted at the response stage or if redirect occurred while intercepting request or auth retry occurred. Type page . ResourceType `json:\"type,omitempty\"` // Type of this resource. Type page . ResourceType `json:\"type\"` // Resource type.", "commit_type": "update"}
{"commit_tokens": ["improved", "parser", "tests", "to", "check", "AST", "s"], "add_tokens": "template string \" \" , \" \" , lexer = newLexer ( test . template , \" \" , \" \" )", "del_tokens": "lexer * lexer newLexer ( \" \" , \" \" , \" \" ) , newLexer ( \" \" , \" \" , \" \" ) , lexer = test . lexer", "commit_type": "improve"}
{"commit_tokens": ["Fix", "package", "names", "of", "tests", "."], "add_tokens": "package gomock_test", "del_tokens": "package controller_test", "commit_type": "fix"}
{"commit_tokens": ["Using", "regex", "Quote", "in", "escapeQuery"], "add_tokens": "s1 := regexp . QuoteMeta ( s )", "del_tokens": "s1 := strings . NewReplacer ( \" \" , \" \\\\ \" , \" \" , \" \\\\ \" , \" \" , \" \\\\ \" , \" \\n \" , \" \" , \" \\r \" , \" \" , \" \\t \" , \" \" , ) . Replace ( s )", "commit_type": "use"}
{"commit_tokens": ["Fix", "the", "doc", "strings", "."], "add_tokens": "// brush.Black(\"I'm color Black\") // brush.White(\"I'm color White\") // brush.LightGray(\"I'm color LightGray\") // brush.Blue(\"I'm color Blue\") // brush.Cyan(\"I'm color Cyan\") // brush.Green(\"I'm color Green\") // brush.Purple(\"I'm color Purple\") // brush.Red(\"I'm color Red\") // brush.Yellow(\"I'm color Yellow\") // brush.DarkBlue(\"I'm color DarkBlue\") // brush.DarkCyan(\"I'm color DarkCyan\") // brush.DarkGray(\"I'm color DarkGray\") // brush.DarkGreen(\"I'm color DarkGreen\") // brush.DarkPurple(\"I'm color DarkPurple\") // brush.DarkRed(\"I'm color DarkRed\") // brush.DarkYellow(\"I'm color DarkYellow\")", "del_tokens": "// color.Black(\"I'm color Black\") // color.White(\"I'm color White\") // color.LightGray(\"I'm color LightGray\") // color.Blue(\"I'm color Blue\") // color.Cyan(\"I'm color Cyan\") // color.Green(\"I'm color Green\") // color.Purple(\"I'm color Purple\") // color.Red(\"I'm color Red\") // color.Yellow(\"I'm color Yellow\") // color.DarkBlue(\"I'm color DarkBlue\") // color.DarkCyan(\"I'm color DarkCyan\") // color.DarkGray(\"I'm color DarkGray\") // color.DarkGreen(\"I'm color DarkGreen\") // color.DarkPurple(\"I'm color DarkPurple\") // color.DarkRed(\"I'm color DarkRed\") // color.DarkYellow(\"I'm color DarkYellow\")", "commit_type": "fix"}
{"commit_tokens": ["Implement", "view", "s", "buffer", "and", "draw"], "add_tokens": "\" \" func start ( g * gocui . Gui ) error { if err := keybindings ( g ) ; err != nil { return err } if err := g . SetCurrentView ( \" \" ) ; err != nil { return err } if v := g . GetView ( \" \" ) ; v != nil { fmt . Fprintln ( v , \" \" ) } if v := g . GetView ( \" \" ) ; v != nil { fmt . Fprintln ( v , \" \" ) fmt . Fprintln ( v , \" \" ) fmt . Fprintln ( v , \" \" ) fmt . Fprintln ( v , \" \" ) } if v := g . GetView ( \" \" ) ; v != nil { fmt . Fprintln ( v , \" \" ) } g . ShowCursor = true return nil }", "del_tokens": "func start ( g * gocui . Gui ) error { if err := keybindings ( g ) ; err != nil { return err } if err := g . SetCurrentView ( \" \" ) ; err != nil { return err } g . ShowCursor = true return nil }", "commit_type": "implement"}
{"commit_tokens": ["Add", "support", "for", "environment", "variables"], "add_tokens": "\" \" apachelog \" \" func TestEnvironmentVariable ( t * testing . T ) { // Well.... let's see. I don't want to change the user's env var, // so let's just scan for something already present in the environment variable list for _ , v := range os . Environ ( ) { vs := strings . SplitN ( v , \" \" , 2 ) t . Logf ( \" \" , vs [ 0 ] ) al , err := apachelog . New ( fmt . Sprintf ( `%%{%s}e` , vs [ 0 ] ) ) if ! assert . NoError ( t , err , \" \" ) { return } var ctx Context var buf bytes . Buffer al . WriteLog ( & buf , & ctx ) var expected = \" \" if vs [ 1 ] != \" \" { expected = vs [ 1 ] } // Be careful, the log line has a trailing new line expected = expected + \" \\n \" if ! assert . Equal ( t , expected , buf . String ( ) ) { return } } }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "flag", "to", "enable", "/", "disable", "cookie", "s", "HttpOnly", "flag", "."], "add_tokens": "CookieHttpOnly bool log . Printf ( \" \" , opts . CookieHttpsOnly , opts . CookieHttpOnly , opts . CookieExpire , domain ) CookieHttpOnly : opts . CookieHttpOnly , HttpOnly : p . CookieHttpOnly , HttpOnly : p . CookieHttpOnly ,", "del_tokens": "log . Printf ( \" \" , opts . CookieHttpsOnly , opts . CookieExpire , domain ) HttpOnly : true , HttpOnly : true ,", "commit_type": "add"}
{"commit_tokens": ["Change", "logrus", "level", "to", "syslog", "one", "translation"], "add_tokens": "func logrusLevelToSylog ( level logrus . Level ) int32 { // Till warn, logrus levels are lower than syslog by 1 // (logrus has no equivalent of syslog LOG_NOTICE) if level <= logrus . WarnLevel { return int32 ( level ) + 1 } // From info, logrus levels are lower than syslog by 2 return int32 ( level ) + 2 } level := logrusLevelToSylog ( entry . Level )", "del_tokens": "level := int32 ( entry . Level ) + 2 // logrus levels are lower than syslog by 2", "commit_type": "change"}
{"commit_tokens": ["add", "more", "test", "case", "for", "InheritedINI"], "add_tokens": "\" \" v , ok = ini . SectionGet ( \" \" , \" \" ) assert . Equal ( t , v , \" \" ) assert . Equal ( t , ok , true ) v , ok = ini . SectionGet ( \" \" , \" \" ) assert . Equal ( t , v , \" \" ) assert . Equal ( t , ok , true ) v , ok = ini . SectionGet ( \" \" , \" \" ) assert . Equal ( t , v , \" \" ) assert . Equal ( t , ok , true ) v , ok = ini . SectionGet ( \" \" , \" \" ) assert . Equal ( t , v , \" \" ) assert . Equal ( t , ok , true ) v , ok = ini . SectionGet ( \" \" , \" \" ) assert . Equal ( t , v , \" \" ) assert . Equal ( t , ok , false ) v , ok = ini . SectionGet ( \" \" , \" \" ) assert . Equal ( t , v , \" \" ) assert . Equal ( t , ok , true )", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Implemented", "controller", "hooks", "for", "PostUserConfirm"], "add_tokens": "RouteKey contextKey = \" \" DbKey contextKey = \" \" RendererKey contextKey = \" \" TokenClaimsKey contextKey = \" \" TokenAuthorityKey contextKey = \" \" CurrentUserKey contextKey = \" \" CurrentObjectKey contextKey = \" \" ControllerHooksMapKey contextKey = \" \" // SetControllerHooksMapCtx Set the TokenAuthority reference for the given request context func ( ctx * Context ) SetControllerHooksMapCtx ( r * http . Request , val * domain . ControllerHooksMap ) * domain . ControllerHooksMap { context . Set ( r , ControllerHooksMapKey , val ) return val } // GetControllerHooksMapCtx the TokenAuthority reference for the given request context func ( ctx * Context ) GetControllerHooksMapCtx ( r * http . Request ) * domain . ControllerHooksMap { if r := context . Get ( r , ControllerHooksMapKey ) ; r != nil { return r . ( * domain . ControllerHooksMap ) } return nil }", "del_tokens": "RouteKey contextKey = \" \" DbKey contextKey = \" \" RendererKey contextKey = \" \" TokenClaimsKey contextKey = \" \" TokenAuthorityKey contextKey = \" \" CurrentUserKey contextKey = \" \" CurrentObjectKey contextKey = \" \"", "commit_type": "implement"}
{"commit_tokens": ["Changing", "the", "receiver", "on", "the", "MarshalJSON"], "add_tokens": "func ( f FHIRDateTime ) MarshalJSON ( ) ( [ ] byte , error ) {", "del_tokens": "func ( f * FHIRDateTime ) MarshalJSON ( ) ( [ ] byte , error ) {", "commit_type": "change"}
{"commit_tokens": ["Added", "stemcell", "tarball", "existence", "validation"], "add_tokens": "session , err := bmtestutils . RunBoshMicro ( \" \" , tmpFile . Name ( ) , tmpFile . Name ( ) )", "del_tokens": "session , err := bmtestutils . RunBoshMicro ( \" \" , tmpFile . Name ( ) )", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "function", "type", "to", "implement", "ListenerFunc"], "add_tokens": "// ListenerFunc is a Listener implementation which invokes itself when Handle is called. type ListenerFunc func ( e Event , b [ ] byte ) func ( l ListenerFunc ) Handle ( e Event , b [ ] byte ) { l ( e , b ) }", "del_tokens": "type listenerFunc struct { handle func ( e Event , b [ ] byte ) } func ( l listenerFunc ) Handle ( e Event , b [ ] byte ) { l . handle ( e , b ) } // ListenerFunc creates a Listener which invokes the provided function. func ListenerFunc ( fn func ( e Event , b [ ] byte ) ) Listener { return & listenerFunc { fn } }", "commit_type": "use"}
{"commit_tokens": ["improve", "error", "message", "in", "tests"], "add_tokens": "t . Fatalf ( \" \" , pair . decoded , err ) t . Fatalf ( \" \" , pair . encoded , err )", "del_tokens": "t . Errorf ( \" \" , pair . decoded ) t . Errorf ( \" \" , pair . encoded )", "commit_type": "improve"}
{"commit_tokens": ["Add", "connectivity", "check", "in", "NewConn", "."], "add_tokens": "func NewConn ( host string , port int , poolsize int , timeout time . Duration ) ( * Conn , error ) { _ , _ , err := c . doRPC ( \" \" , nil ) if err != nil { return nil , err } return c , nil", "del_tokens": "func NewConn ( host string , port int , poolsize int , timeout time . Duration ) * Conn { return c", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "deepcopy", "testcase", "for", "pointers"], "add_tokens": "BoolPtrField * bool IntPtrField * int StringPtrField * string FloatPtrField * float64 } type Struct_PrimitivePointers_Alias Struct_PrimitivePointers type Struct_Embed_Struct_PrimitivePointers struct { Struct_PrimitivePointers } type Struct_Embed_Pointer struct { * int } type Struct_Struct_PrimitivePointers struct { StructField Struct_PrimitivePointers } // Everything type Struct_Everything struct { BoolField bool IntField int StringField string FloatField float64 StructField Struct_Primitives EmptyStructField Struct_Empty ManualStructField ManualStruct BoolPtrField * bool IntPtrField * int StringPtrField * string FloatPtrField * float64 PrimitivePointersField Struct_PrimitivePointers", "del_tokens": "// Everything type Struct_Everything struct { BoolField bool IntField int StringField string FloatField float64 StructField Struct_Primitives EmptyStructField Struct_Empty ManualStructField ManualStruct } / * BoolField * bool IntField * int StringField * string FloatField * float64 * /", "commit_type": "add"}
{"commit_tokens": ["Add", "basic", "frame", "and", "ctr", "command", "line", "client"], "add_tokens": "const Usage = `High performance conatiner daemon` app . Version = containerd . Version", "del_tokens": "const ( Version = \" \" Usage = `High performance conatiner daemon` ) app . Version = Version", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "firewall", "in", "server", "list", "/", "create"], "add_tokens": "FirewallGroupID string `json:\"FIREWALLGROUPID\"` FirewallGroupID string if value == \" \" || value == \" \" { value = fmt . Sprintf ( \" \" , fields [ \" \" ] ) if value == \" \" || value == \" \" { value = \" \" } s . FirewallGroupID = value if options . FirewallGroupID != \" \" { values . Add ( \" \" , options . FirewallGroupID ) }", "del_tokens": "if value == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Move", "Verify", "errors", "to", "shimmie", "package"], "add_tokens": "return nil , shimmie . ErrNotFound return nil , shimmie . ErrWrongCredentials", "del_tokens": "\" \" // Errors returned by Verify. var ( ErrWrongCredentials = errors . New ( \" \" ) ErrNotFound = errors . New ( \" \" ) ) return nil , ErrNotFound return nil , ErrWrongCredentials", "commit_type": "move"}
{"commit_tokens": ["add", "embedding", "of", "json", ".", "Encoder", "for", "access", "to", "SetIndent", "()", "etc"], "add_tokens": "* j . Encoder mu sync . Mutex Encoder : j . NewEncoder ( w ) , return h . Encoder . Encode ( e )", "del_tokens": "mu sync . Mutex enc * j . Encoder enc : j . NewEncoder ( w ) , return h . enc . Encode ( e )", "commit_type": "add"}
{"commit_tokens": ["Use", "spf13", "/", "cobra", "for", "docker", "commit"], "add_tokens": "// RequiresRangeArgs returns an error if there is not at least min args and at most max args func RequiresRangeArgs ( min int , max int ) cobra . PositionalArgs {", "del_tokens": "// RequiresMinMaxArgs returns an error if there is not at least min args and at most max args func RequiresMinMaxArgs ( min int , max int ) cobra . PositionalArgs {", "commit_type": "use"}
{"commit_tokens": ["fixed", "bug", "with", "case", "-", "sensitive", "headers", "added", "support", "for", "giving", "a", "named", "subresource", "instead", "of", "wire", "type"], "add_tokens": "v , ok := self . h [ strings . ToLower ( s ) ] result [ strings . ToLower ( k ) ] = strings . TrimSpace ( v [ 0 ] )", "del_tokens": "_ \" \" v , ok := self . h [ s ] result [ k ] = strings . TrimSpace ( v [ 0 ] )", "commit_type": "fix"}
{"commit_tokens": ["use", "CommandRunner", "for", "cgroups", "management"], "add_tokens": "cgroupsManager := cgroups_manager . New ( \" \" , id , p . runner )", "del_tokens": "cgroupsManager := cgroups_manager . New ( \" \" , id )", "commit_type": "use"}
{"commit_tokens": ["Adding", "error", "handling", "to", "storage", "get", "call"], "add_tokens": "type GenericError struct { bucket string path string } type ObjectNotFound GenericError func ( self ObjectNotFound ) Error ( ) string { return \" \" + self . bucket + \" \" + self . path } func ( storage * Storage ) CopyObjectToWriter ( w io . Writer , bucket string , object string ) ( int64 , error ) { written , err := io . Copy ( w , objectBuffer ) return written , err return 0 , ObjectNotFound { bucket : bucket , path : object }", "del_tokens": "func ( storage * Storage ) CopyObjectToWriter ( w io . Writer , bucket string , object string ) error { _ , err := io . Copy ( w , objectBuffer ) return err return errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "EPSV", "for", "domains", "with", "multiple", "A", "entries", "."], "add_tokens": "tconn , err := net . DialTimeout ( \" \" , addr , timeout ) // Use the resolved IP address in case addr contains a domain name // If we use the domain name, we might not resolve to the same IP. remoteAddr := tconn . RemoteAddr ( ) . String ( ) host , _ , err := net . SplitHostPort ( remoteAddr )", "del_tokens": "host , _ , err := net . SplitHostPort ( addr ) tconn , err := net . DialTimeout ( \" \" , addr , timeout )", "commit_type": "fix"}
{"commit_tokens": ["Use", "string", "for", "voice", "response", "price", "add", "price_unit"], "add_tokens": "Sid string `json:\"sid\"` DateCreated string `json:\"date_created\"` DateUpdated string `json:\"date_updated\"` ParentCallSid string `json:\"parent_call_sid\"` AccountSid string `json:\"account_sid\"` To string `json:\"to\"` ToFormatted string `json:\"to_formatted\"` From string `json:\"from\"` FromFormatted string `json:\"from_formatted\"` PhoneNumberSid string `json:\"phone_number_sid\"` Status string `json:\"status\"` StartTime string `json:\"start_time\"` EndTime string `json:\"end_time\"` Duration int `json:\"duration,string\"` PriceUnit string `json:\"price_unit\"` Price * string `json:\"price,omitempty\"` Direction string `json:\"direction\"` AnsweredBy string `json:\"answered_by\"` ApiVersion string `json:\"api_version\"` Annotation string `json:\"annotation\"` ForwardedFrom string `json:\"forwarded_from\"` GroupSid string `json:\"group_sid\"` CallerName string `json:\"caller_name\"` Uri string `json:\"uri\"`", "del_tokens": "Sid string `json:\"sid\"` DateCreated string `json:\"date_created\"` DateUpdated string `json:\"date_updated\"` ParentCallSid string `json:\"parent_call_sid\"` AccountSid string `json:\"account_sid\"` To string `json:\"to\"` ToFormatted string `json:\"to_formatted\"` From string `json:\"from\"` FromFormatted string `json:\"from_formatted\"` PhoneNumberSid string `json:\"phone_number_sid\"` Status string `json:\"status\"` StartTime string `json:\"start_time\"` EndTime string `json:\"end_time\"` Duration int `json:\"duration,string\"` Price * float32 `json:\"price,omitempty\"` Direction string `json:\"direction\"` AnsweredBy string `json:\"answered_by\"` ApiVersion string `json:\"api_version\"` Annotation string `json:\"annotation\"` ForwardedFrom string `json:\"forwarded_from\"` GroupSid string `json:\"group_sid\"` CallerName string `json:\"caller_name\"` Uri string `json:\"uri\"` // TODO: handle price_unit", "commit_type": "use"}
{"commit_tokens": ["update", "tests", "to", "honor", "the", "fact", "that", "buildpack", "dirs", "are", "md5", "hashes"], "add_tokens": "alwaysDetectsHash := \" \" //md5 hash of \"always-detects\" cp ( path . Join ( buildpackFixtures , \" \" ) , path . Join ( buildpacksDir , alwaysDetectsHash ) ) nestedBuildpack := \" \" nestedBuildpackHash := \" \" nestedBuildpackDir := path . Join ( buildpacksDir , nestedBuildpackHash ) \" \" , nestedBuildpack ,", "del_tokens": "cp ( path . Join ( buildpackFixtures , \" \" ) , buildpacksDir ) nestedBuildpackDir := path . Join ( buildpacksDir , \" \" ) \" \" , \" \" ,", "commit_type": "update"}
{"commit_tokens": ["Use", "SplitHostPart", "instead", "of", "string", "substitutions"], "add_tokens": "var port int _ , sport , err := net . SplitHostPort ( l . Addr ( ) . String ( ) ) if err == nil { port , err = strconv . Atoi ( sport ) } var port int _ , sport , err := net . SplitHostPort ( l . Addr ( ) . String ( ) ) if err == nil { port , err = strconv . Atoi ( sport ) }", "del_tokens": "port , err := strconv . Atoi ( strings . Replace ( l . Addr ( ) . String ( ) , \" \" , \" \" , 1 ) ) port , err := strconv . Atoi ( strings . Replace ( l . Addr ( ) . String ( ) , \" \" , \" \" , 1 ) )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "generic", "key", "layout", "."], "add_tokens": "fw , mono = 0.51 * float32 ( fh ) , false fw , mono = 0.62 * float32 ( fh ) , true // fmt.Printf(\"FontMetric of %s/%d: %.1f x %d %t\\n\", style.Font, style.FontSize, fw, fh, mono)", "del_tokens": "fw , mono = 0.55 * float32 ( fh ) , false fw , mono = 0.65 * float32 ( fh ) , true fmt . Printf ( \" \\n \" , style . Font , style . FontSize , fw , fh , mono )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "name_template", "version", "vs", "tag", "issue"], "add_tokens": "Tag string Version : ctx . Version , Tag : ctx . Git . CurrentTag ,", "del_tokens": "Version : ctx . Git . CurrentTag ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "problem", "with", "replicationController", "ops", "in", "kube", "command"], "add_tokens": "matchFound := c . executeConfigRequest ( method , clients ) || c . executeControllerRequest ( method , kubeClient ) || c . executeAPIRequest ( method , clients ) glog . Fatal ( \" \" )", "del_tokens": "matchFound := c . executeConfigRequest ( method , clients ) || c . executeAPIRequest ( method , clients ) || c . executeControllerRequest ( method , kubeClient ) glog . Fatal ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["change", "integer", "to", "constant", "value", "dequeued"], "add_tokens": "popped . data = dequeued", "del_tokens": "popped . data = - 1", "commit_type": "change"}
{"commit_tokens": ["Implement", "application", "manager", "unit", "tests"], "add_tokens": "appComparator AppComparator comparisonResult , err := m . appComparator . CompareAppState ( appRepoPath , app ) // NewAppManager creates new instance of app manager. func NewAppManager ( gitClient git . Client , repoService repository . RepositoryServiceServer , appComparator AppComparator , statusRefreshTimeout time . Duration ) * Manager { appComparator : appComparator ,", "del_tokens": "comparisonResult , err := m . compareAppState ( appRepoPath , app ) func ( m * Manager ) compareAppState ( appRepoPath string , app * v1alpha1 . Application ) ( * v1alpha1 . ComparisonResult , error ) { // TODO (amatyushentsev): Implement actual comparison return & v1alpha1 . ComparisonResult { Status : v1alpha1 . ComparisonStatusEqual , ComparedTo : app . Spec . Source , ComparedAt : metav1 . Time { Time : time . Now ( ) . UTC ( ) } , } , nil } // NewAppManager creates new instance of app.Manager func NewAppManager ( gitClient git . Client , repoService repository . RepositoryServiceServer , statusRefreshTimeout time . Duration ) * Manager {", "commit_type": "implement"}
{"commit_tokens": ["Add", "build", "when", "push", "to", "gitlab"], "add_tokens": "models . AddGitlabBuild ( hook ) return", "del_tokens": "var result string result = \" \" result = \" \" c . Ctx . WriteString ( result )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "xml", "stream", "parsing", "where", "a", "previously", "unmatched", "node", "causing", "all", "subsequent", "valid", "matches", "fail", "."], "add_tokens": "// otherwise, this isn't our target node, clean things up. // note we also remove the underlying *Node from the node tree, to prevent // future stream node candidate selection error. RemoveFromTree ( p . streamNode ) p . prev = p . streamNodePrev", "del_tokens": "// otherwise, this isn't our target node. clean things up.", "commit_type": "fix"}
{"commit_tokens": ["Add", "logic", "to", "generate", "blank", "ident", "for", "fn", "params"], "add_tokens": "for _ , param := range p . params ( field ) { // only for method parameters: // assign a blank identifier \"_\" to an anonymous parameter if param . Name == \" \" { param . Name = \" \" } fn . Params = append ( fn . Params , param ) }", "del_tokens": "fn . Params = append ( fn . Params , p . params ( field ) ... )", "commit_type": "add"}
{"commit_tokens": ["Fix", "wrong", "number", "of", "arguments", "."], "add_tokens": "t . Errorf ( \" \" , test . id )", "del_tokens": "t . Errorf ( \" \" , test . id , err )", "commit_type": "fix"}
{"commit_tokens": ["make", "graphDriver", "look", "like", "the", "rest"], "add_tokens": "\" \" \" \" resp , err := pluginRequest ( client , \" \" , & graphPlugin . InitRequest { Home : \" \" } ) func pluginRequest ( client * http . Client , method string , req * graphPlugin . InitRequest ) ( * graphPlugin . ErrorResponse , error ) { b , err := json . Marshal ( req ) if err != nil { return nil , err } resp , err := client . Post ( \" \" + method , \" \" , bytes . NewReader ( b ) ) if err != nil { return nil , err } var gResp graphPlugin . ErrorResponse err = json . NewDecoder ( resp . Body ) . Decode ( & gResp ) if err != nil { return nil , err } return & gResp , nil }", "del_tokens": "const url = \" \" resp , err := graphPlugin . CallInit ( url , client , graphPlugin . InitRequest { Home : \" \" } )", "commit_type": "make"}
{"commit_tokens": ["Added", "methods", "to", "flatten", "a", "multi", "-", "level", "map"], "add_tokens": "SystemAssignee = \" \" SystemCreator = \" \" // The keys in the flattened response JSON of a typical Github issue. GithubTitle = \" \" GithubDescription = \" \" GithubState = \" \" GithubId = \" \" GithubCreator = \" \" GithubAssignee = \" \" // The keys in the flattened response JSON of a typical Jira issue. JiraTitle = \" \" JiraBody = \" \" JiraState = \" \" JiraId = \" \" JiraCreator = \" \" JiraAssignee = \" \" ProviderGithub = \" \" ProviderJira = \" \" AttributeExpression ( GithubTitle ) : SystemTitle , AttributeExpression ( GithubDescription ) : SystemDescription , AttributeExpression ( GithubState ) : SystemStatus , AttributeExpression ( GithubId ) : SystemRemoteItemId , AttributeExpression ( GithubCreator ) : SystemCreator , AttributeExpression ( GithubAssignee ) : SystemAssignee , } , ProviderJira : WorkItemMap { AttributeExpression ( JiraTitle ) : SystemTitle , AttributeExpression ( JiraBody ) : SystemDescription , AttributeExpression ( JiraState ) : SystemStatus , AttributeExpression ( JiraId ) : SystemRemoteItemId , AttributeExpression ( JiraCreator ) : SystemCreator , AttributeExpression ( JiraAssignee ) : SystemAssignee , j = Flatten ( j ) j = Flatten ( j )", "del_tokens": "ProviderGithub = \" \" ProviderJira = \" \" AttributeExpression ( \" \" ) : SystemTitle , AttributeExpression ( \" \" ) : SystemDescription , AttributeExpression ( \" \" ) : SystemStatus , AttributeExpression ( \" \" ) : SystemRemoteItemId , // TODO for sbose: Flatten !", "commit_type": "add"}
{"commit_tokens": ["add", "SegWit", "to", "support", "channel", "types"], "add_tokens": "// Use SegWit, assumes CSV+CLTV SEGWIT FundingType = iota // Use SIGHASH_NOINPUT, assumes CSV+CLTV SIGHASH // Use CSV without reserve // RLOCK?", "del_tokens": "//Use SIGHASH_NOINPUT, assumes CSV SIGHASH FundingType = iota //Use CSV without reserve", "commit_type": "add"}
{"commit_tokens": ["Use", "systemctl", "restart", "when", "restarting", "instead", "of", "stop", "/", "start"], "add_tokens": "return run ( \" \" , \" \" , s . Name + \" \" )", "del_tokens": "\" \" err := s . Stop ( ) if err != nil { return err } time . Sleep ( 50 * time . Millisecond ) return s . Start ( )", "commit_type": "use"}
{"commit_tokens": ["fix", "some", "cases", "where", "we", "aren", "t", "returning", "EOF", "in", "BlockReader"], "add_tokens": "if br . packet . last { return 0 , io . EOF } if err == io . EOF { if err == io . EOF { if err == io . EOF {", "del_tokens": "if err != io . EOF { if err != io . EOF { if err != io . EOF {", "commit_type": "fix"}
{"commit_tokens": ["Add", "required", "cache", "to", "tests"], "add_tokens": "\" \" var icaCache = lru . New ( 200 ) result := do ( icaCache , der , nil , true , true )", "del_tokens": "result := do ( der , nil , true , true )", "commit_type": "add"}
{"commit_tokens": ["Add", "formatter", "for", "service", "inspect"], "add_tokens": "// Format keys used to specify certain kinds of output formats TableFormatKey = \" \" RawFormatKey = \" \" PrettyFormatKey = \" \"", "del_tokens": "// TableFormatKey is the key used to format as a table TableFormatKey = \" \" // RawFormatKey is the key used to format as raw JSON RawFormatKey = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fixed", "IO", "edge", "cases", "on", "docker", "client", ".", "Wait", "for", "stdin", "to", "close", "before", "exiting", "if", "it", "s", "a", "pipe", "but", "not", "if", "it", "s", "a", "terminal", ".", "Correctly", "send", "stdin", "EOF", "to", "the", "server", "with", "TCP", "half", "-", "close"], "add_tokens": "\" \" receive_stdout := future . Go ( func ( ) error { _ , err := io . Copy ( os . Stdout , conn ) return err } ) send_stdin := future . Go ( func ( ) error { _ , err := io . Copy ( conn , os . Stdin ) if err := conn . CloseWrite ( ) ; err != nil { log . Printf ( \" \" + err . Error ( ) ) return err } ) if err := <- receive_stdout ; err != nil { if IsTerminal ( 0 ) { Restore ( 0 , oldState ) } else { if err := <- send_stdin ; err != nil { Fatal ( err ) } }", "del_tokens": "go func ( ) { if _ , err := io . Copy ( os . Stdout , conn ) ; err != nil { Fatal ( err ) Restore ( 0 , oldState ) os . Exit ( 0 ) } ( ) if _ , err := io . Copy ( conn , os . Stdin ) ; err != nil { Restore ( 0 , oldState )", "commit_type": "fix"}
{"commit_tokens": ["Added", "examples", "and", "moved", "example", ".", "xml"], "add_tokens": "fmt . Fprintln ( fd , \" \\\" \\\" \\\\ \" ) fmt . Fprintln ( fd , \" \\\" \\\" \\\\ \" ) os . Rename ( configfile , \" \" + configfile ) // Keep this so that an example with the documentation is available", "del_tokens": "fmt . Fprintln ( fd , \" \\\" \\\" \\\\ \" ) fmt . Fprintln ( fd , \" \\\" \\\" \\\\ \" ) //os.Rename(configfile, \"../\" + configfile) // Keep this so that an example with the documentation is available", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "to", "customhttp", "package"], "add_tokens": "f . ErrorTemplate . Execute ( w , err )", "del_tokens": "f . ErrorTemplate . Execute ( w , err )", "commit_type": "add"}
{"commit_tokens": ["Update", "AddrManagerDatastore", "to", "require", "a", "Batching", "Datastore"], "add_tokens": "\" \" \" \" \" \" func setupBadgerDatastore ( t * testing . T ) ( datastore . Batching , func ( ) ) {", "del_tokens": "\" \" \" \" \" \" func setupBadgerDatastore ( t * testing . T ) ( datastore . Datastore , func ( ) ) {", "commit_type": "update"}
{"commit_tokens": ["Using", "mount", "-", "t", "fuse", "instead", "of", "sshfs"], "add_tokens": "cmdStr := fmt . Sprintf ( \" \" , c . SshfsPath , c . Common . User , c . Common . Host , remoteShare , localMount , c . Common . Port ) if err := utils . CmdPipe ( \" \" , c . Common . Password , \" \" , cmdStr ) ; err != nil { cmd := exec . Command ( \" \" )", "del_tokens": "cmdStr := fmt . Sprintf ( \" \" , c . Common . User , c . Common . Host , remoteShare , localMount , c . Common . Port ) if err := utils . CmdPipe ( \" \" , c . Common . Password , c . SshfsPath , cmdStr ) ; err != nil { cmd := exec . Command ( c . SshfsPath )", "commit_type": "use"}
{"commit_tokens": ["Use", "bitwise", "AND", "instead", "of", "remainder", "for", "alignment"], "add_tokens": "if dec . pos % n != 0 { newpos := ( dec . pos + n - 1 ) & ^ ( n - 1 )", "del_tokens": "newpos := dec . pos if newpos % n != 0 { newpos += ( n - ( newpos % n ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "full", "stop", "and", "end", "of", "Godoc", "string", "."], "add_tokens": "// and a boolean to check if the value has been set.", "del_tokens": "// and a boolean to check if the value has been set", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "EchoReponse", "methods", "for", "adding", "a", "new", "standard", "card", "that", "can", "include", "a", "picture", ".", "Original", "Card", "()", "method", "is", "an", "alias", "of", "CardSimple", "()"], "add_tokens": "return this . SimpleCard ( title , content ) } func ( this * EchoResponse ) SimpleCard ( title string , content string ) * EchoResponse { func ( this * EchoResponse ) StandardCard ( title string , content string , smallImg string , largeImg string ) * EchoResponse { this . Response . Card = & EchoRespPayload { Type : \" \" , Title : title , Content : content , } if smallImg != \" \" { this . Response . Card . Image . SmallImageURL = smallImg } if largeImg != \" \" { this . Response . Card . Image . LargeImageURL = largeImg } return this } type EchoRespImage struct { SmallImageURL string `json:\"smallImageUrl,omitempty\"` LargeImageURL string `json:\"largeImageUrl,omitempty\"` } Type string `json:\"type,omitempty\"` Title string `json:\"title,omitempty\"` Text string `json:\"text,omitempty\"` SSML string `json:\"ssml,omitempty\"` Content string `json:\"content,omitempty\"` Image EchoRespImage `json:\"image,omitempty\"`", "del_tokens": "Type string `json:\"type,omitempty\"` Title string `json:\"title,omitempty\"` Text string `json:\"text,omitempty\"` SSML string `json:\"ssml,omitempty\"` Content string `json:\"content,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Use", "atomic", "operations", "in", "NewBasic", "remove", "overflow", "check", "and", "add", "benchmarks", "."], "add_tokens": "\" \" idInc uint64 return BasicEntity { id : atomic . AddUint64 ( & idInc , 1 ) } idInc ++ entities [ i ] = BasicEntity { id : idInc }", "del_tokens": "\" \" \" \" id_incr uint64 counterLock . Lock ( ) id_incr ++ if id_incr >= math . MaxUint64 { log . Println ( \" \" ) id_incr = 1 } counterLock . Unlock ( ) return BasicEntity { id_incr } id_incr ++ if id_incr >= math . MaxUint64 { log . Println ( \" \" ) id_incr = 1 } entities [ i ] = BasicEntity { id_incr }", "commit_type": "use"}
{"commit_tokens": ["Add", "fix", "command", "/", "shell", "output", "add", "RunCapture"], "add_tokens": "env := NewEnv ( NewNestedScope ( nil ) , DefaultConfig ) _ , _ , err := RunCapture ( \" \" ) if err != nil { _ , _ , err := RunCapture ( \" \" ) if err != nil { t . Fatalf ( \" \" )", "del_tokens": "env := & Environment { Vars : NewNestedScope ( nil ) } i := Main ( [ ] string { \" \" , \" \" } ) if i != 0 { i := Main ( [ ] string { \" \" , \" \" } ) if i != 0 { t . Fatalf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "bogus", "duration", "handling", "in", "IOContext", ".", "Lock", "*"], "add_tokens": "tv := syscall . NsecToTimeval ( duration . Nanoseconds ( ) ) tv := syscall . NsecToTimeval ( duration . Nanoseconds ( ) )", "del_tokens": "tv := syscall . NsecToTimeval ( time . Now ( ) . Add ( duration ) . UnixNano ( ) ) tv := syscall . NsecToTimeval ( time . Now ( ) . Add ( duration ) . UnixNano ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "MutableSource", "type", "that", "allows", "for", "basic", "image", "modifications", "."], "add_tokens": "src , err = cache . NewFileCache ( cacheDir , ref )", "del_tokens": "src , err = cache . NewFileCache ( cacheDir , ref , src )", "commit_type": "add"}
{"commit_tokens": ["Adding", "an", "end", "time", "to", "the", "medication", "if", "the", "condition", "abates"], "add_tokens": "med := GenerateMedication ( conditionMetadata . MedicationID , c . OnsetDateTime , c . AbatementDate , mmd )", "del_tokens": "med := GenerateMedication ( conditionMetadata . MedicationID , c . OnsetDateTime , mmd )", "commit_type": "add"}
{"commit_tokens": ["add", "version", "and", "changelog", "info"], "add_tokens": "Version = \" \"", "del_tokens": "Version = \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "nascent", "Travis", "CI", "configuration", "."], "add_tokens": "func ( l * LevelDBMetricPersistence ) GetFingerprintLabelPairs ( f model . Fingerprint ) ( model . LabelPairs , error ) { panic ( \" \" ) } func ( l * LevelDBMetricPersistence ) GetMetricFingerprintsForLabelPairs ( p [ ] * model . LabelPairs ) ( [ ] * model . Fingerprint , error ) { panic ( \" \" ) } func ( l * LevelDBMetricPersistence ) RecordFingerprintWatermark ( s * model . Sample ) error { panic ( \" \" ) }", "del_tokens": "log . Printf ( \" \\n \" ) log . Printf ( \" \\n \" , getAll ) log . Printf ( \" \\n \" , pair ) log . Printf ( \" \\n \" , member ) log . Printf ( \" \\n \" , member . Signature ) log . Printf ( \" \\n \" , fingerprints ) log . Printf ( \" \\n \" , labelPairCollectionRaw ) log . Printf ( \" \\n \" , intermediate )", "commit_type": "add"}
{"commit_tokens": ["Changed", "language", "spec", ":", "removed", "::"], "add_tokens": "if ! isLetter ( s . peek ( ) ) && ! isDigit ( s . peek ( ) ) {", "del_tokens": "if s . peek ( ) == ':' { s . next ( ) if s . peek ( ) != ':' { s . back ( ) s . back ( ) break } s . next ( ) ret = append ( ret , ':' ) ret = append ( ret , ':' ) continue } else if ! isLetter ( s . peek ( ) ) && ! isDigit ( s . peek ( ) ) {", "commit_type": "change"}
{"commit_tokens": ["update", "doc", "and", "change", "rootfs", "to", "files"], "add_tokens": "utils . CopyDir ( cnt . path + \" \" , cnt . path + targetRootfs )", "del_tokens": "utils . CopyDir ( cnt . path + \" \" , cnt . path + targetRootfs )", "commit_type": "update"}
{"commit_tokens": ["Update", "README", "to", "accommodate", "new", "response", "structures", "."], "add_tokens": "data , err := inv . DomainRRHistory ( \" \" ) which returns a DomainRRHistory object . The official OpenDNS Investigate Documentation can be found at : https : //sgraph.opendns.com/docs/api", "del_tokens": "data , err := inv . RRHistory ( \" \" ) which returns the map : map [ rrs_tf : [ map [ first_seen : 2014 - 02 - 18 last_seen : 2014 - 05 - 20 rrs : [ map [ name : www . test . com . ttl : 3600 class : IN type : CNAME rr : test . blockdos . com . ] ] ] ] features : map [ cname : true base_domain : test . com ] ]", "commit_type": "update"}
{"commit_tokens": ["Add", "error", "propagation", "to", "web", "UI", "via", "special", "JSON", "error", "type", "."], "add_tokens": "Value string Value : err . Error ( ) ,", "del_tokens": "Error string Error : err . Error ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "doc", "file", "for", "the", "embed", "tool"], "add_tokens": "// Fallback instructs the filesystem to fall back to the operating system // Add inserts a new named file representation into the filesystem. The size, // // If the file name represents a relative path, it will be converted to an // absolute path where it's base directory is root of the filesystem. E.g.: // // relative/path -> /relative/path // ./relative/path -> /relative/path // /absolute/path -> /absolute/path func ( fs * FileSystem ) Add ( name string , size int64 , mode os . FileMode , modTime time . Time , data string , ) error {", "del_tokens": "// Fallback instructs the file system to fall back to the operating system // Add inserts a new named file representation into the file system. The size, func ( fs * FileSystem ) Add ( name string , size int64 , mode os . FileMode , modTime time . Time , data string ) error {", "commit_type": "add"}
{"commit_tokens": ["added", "stubs", "for", "twitter", "authentication"], "add_tokens": "// Twitter allocates and returns a new AuthHandler, using the TwitterProvider. func Twitter ( key , secret , callback string ) * AuthHandler { return New ( NewGoogleProvider ( key , secret , callback ) ) } DefaultFailure ( w , r , err ) DefaultSuccess ( w , r , user ) // DefaultSuccess will redirect a User, using an http.Redirect, to the var DefaultSuccess = func ( w http . ResponseWriter , r * http . Request , u User ) { // DefaultFailure will return an http Forbidden code indicating a failed var DefaultFailure = func ( w http . ResponseWriter , r * http . Request , err error ) {", "del_tokens": "defaultFailure ( w , r , err ) defaultSuccess ( w , r , user ) // defaultSuccess will redirect a User, using an http.Redirect, to the func defaultSuccess ( w http . ResponseWriter , r * http . Request , u User ) { // defaultFailure will return an http Forbidden code indicating a failed func defaultFailure ( w http . ResponseWriter , r * http . Request , err error ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "off", "-", "by", "-", "one", "line", "numbering", "error", "in", "gomega", "async", "matchers"], "add_tokens": "actual . fail ( fmt . Sprintf ( \" \\n \" , preamble , time . Since ( timer ) . Seconds ( ) , description , message , errMsg ) , 3 + actual . offset )", "del_tokens": "actual . fail ( fmt . Sprintf ( \" \\n \" , preamble , time . Since ( timer ) . Seconds ( ) , description , message , errMsg ) , 2 + actual . offset )", "commit_type": "fix"}
{"commit_tokens": ["add", "buffering", "to", "reader", "brings", "huge", "perf", "improvements", "on", "decoding", "operations"], "add_tokens": "w : Writer { w : config . Output } , w : Writer { w : config . Output } ,", "del_tokens": "w : Writer { W : config . Output } , w : Writer { W : config . Output } , t string", "commit_type": "add"}
{"commit_tokens": ["Add", "tls", "and", "normal", "server", "listen", "testing", "."], "add_tokens": "func RunHTTPServer ( ) error { var err error err = GetMainEngine ( ) . RunTLS ( \" \" + PushConf . Core . Port , PushConf . Core . CertPath , PushConf . Core . KeyPath ) err = GetMainEngine ( ) . Run ( \" \" + PushConf . Core . Port ) return err", "del_tokens": "func RunHTTPServer ( ) { GetMainEngine ( ) . RunTLS ( \" \" + PushConf . Core . Port , PushConf . Core . CertPath , PushConf . Core . KeyPath ) GetMainEngine ( ) . Run ( \" \" + PushConf . Core . Port )", "commit_type": "add"}
{"commit_tokens": ["add", "style", "fro", "Table", "render"], "add_tokens": "type CellStyleFunc func ( row , col int , cell string ) string func WriteTable ( w io . Writer , table Table , styles ... CellStyleFunc ) { writeTableRow ( w , table , i , widthArray , styles ... ) func writeTableRow ( w io . Writer , table Table , rowIndex int , widthArray [ ] int , styles ... CellStyleFunc ) { s := fmt . Sprintf ( format , table . Get ( rowIndex , j ) ) for _ , fn := range styles { s = fn ( rowIndex , j , s ) } fmt . Fprintf ( w , s )", "del_tokens": "func WriteTable ( w io . Writer , table Table ) { writeTableRow ( w , table , i , widthArray ) func writeTableRow ( w io . Writer , table Table , rowIndex int , widthArray [ ] int ) { fmt . Fprintf ( w , format , table . Get ( rowIndex , j ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "full", "Warning", "functions", "on", "default", "logger", "to", "mirror", "other", "levels"], "add_tokens": "return Warning ( msg ) return Warningf ( msg , a ... ) return Warningm ( m , msg , a ... ) } // Warning executes the same function on the default Base instance func Warning ( msg string ) error { return curDefault . Warning ( msg ) } // Warningf executes the same function on the default Base instance func Warningf ( msg string , a ... interface { } ) error { return curDefault . Warningf ( msg , a ... ) } // Warningm executes the same function on the default Base instance func Warningm ( m * Attrs , msg string , a ... interface { } ) error { return curDefault . Warningm ( m , msg , a ... )", "del_tokens": "return curDefault . Warn ( msg ) return curDefault . Warnf ( msg , a ... ) return curDefault . Warnm ( m , msg , a ... )", "commit_type": "add"}
{"commit_tokens": ["added", "Array", "()", "function", "to", "matrix", "types"], "add_tokens": "\" \" Zero = T { } // Array returns the elements of the matrix as array pointer. func ( mat * T ) Array ( ) * [ 4 ] float32 { return ( * [ 4 ] float32 ) ( unsafe . Pointer ( mat ) ) }", "del_tokens": "Zero = T { }", "commit_type": "add"}
{"commit_tokens": ["Add", "endpoint", "for", "all", "time", "stats", ".", "Add", "support", "for", "old", "legacy", "tie", "break", "mechanism", "for", "use", "with", "older", "seasons", "."], "add_tokens": "standings . ByWinnings ( season < 2013 ) YellowPeriods [ ] tournaments . YellowPeriod `json:\"yellowPeriods\"` //PeriodStats []PeriodStats } seasonStats := new ( SeasonStats ) yellows := tournaments . YellowPeriods ( tList ) seasonStats . YellowPeriods = yellows encoder := json . NewEncoder ( w ) encoder . Encode ( seasonStats ) return nil } func getAllSeasonsStats ( c web . C , w http . ResponseWriter , r * http . Request ) * appError { w . Header ( ) . Set ( \" \" , \" \" ) tList , err := tournaments . AllTournaments ( ) if err != nil { return & appError { err , \" \" , 404 } } type SeasonStats struct { YellowPeriods [ ] tournaments . YellowPeriod `json:\"yellowPeriods\"`", "del_tokens": "standings . ByWinnings ( ) YellowPeriods [ ] tournaments . YellowPeriod", "commit_type": "add"}
{"commit_tokens": ["Fix", "compile", "error", ":", "use", "diskv", ".", "WriteStream", "not", "old", "diskv", ".", "WriteAndSync", "method", "."], "add_tokens": "\" \" c . d . WriteStream ( key , bytes . NewReader ( resp ) , true )", "del_tokens": "c . d . WriteAndSync ( key , resp )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "logic", "to", "detect", "and", "create", "block", "/", "char", "devices"], "add_tokens": "if st . Mode & syscall . S_IFMT == syscall . S_IFBLK || st . Mode & syscall . S_IFMT == syscall . S_IFCHR { if st . Mode & syscall . S_IFMT == syscall . S_IFBLK { if st . Mode & syscall . S_IFMT == syscall . S_IFCHR {", "del_tokens": "if st . Mode & syscall . S_IFBLK != 0 || st . Mode & syscall . S_IFCHR != 0 { if st . Mode & syscall . S_IFBLK != 0 { fmt . Printf ( \" \" ) if st . Mode & syscall . S_IFCHR != 0 { fmt . Printf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "hash", "for", "path", "-", ">", "id", "map", "."], "add_tokens": "keys , err := redis . Values ( c . Do ( \" \" , \" \" ) ) for _ , key := range keys { t . Errorf ( \" \" , key ) } keys , err = redis . Values ( c . Do ( \" \" , \" \" ) ) for _ , key := range keys { t . Errorf ( \" \" , key ) c . Do ( \" \" , \" \" , path , id ) t . Fatalf ( \" \" , len ( values ) )", "del_tokens": "if n , err := c . Do ( \" \" ) ; n != int64 ( 0 ) || err != nil { t . Errorf ( \" \" , n , err ) c . Do ( \" \" , \" \" + path , id ) t . Errorf ( \" \" , len ( values ) )", "commit_type": "use"}
{"commit_tokens": ["Adding", "a", "default", "send", "handler"], "add_tokens": "\" \" \" \" \" \" SendHandler allows the customization of how API responses are sent and logged . This is used by all jshapi . Resource objects . * / var SendHandler = DefaultSender ( log . New ( os . Stderr , \" \" , log . LstdFlags ) ) / * New initializes a new top level API Resource without doing any additional setup . * / // create a logger, the std log package works, as do most other loggers // std.Logger interface defined here: // https://github.com/derekdowling/go-stdlogger/blob/master/logger.go logger := log . New ( os . Stderr , \" \" , log . LstdFlags ) api := jshapi . Default ( \" \" , false , logger ) func Default ( prefix string , debug bool , logger std . Logger ) * API { SendHandler = DefaultSender ( logger ) gojilogger := gojilogger . New ( logger , debug )", "del_tokens": "New initializes a new top level API Resource Handler without . * / // optionally, set your own logger that can do custom things jshapi . Logger = yourLogger api := jshapi . Default ( \" \" , false ) func Default ( prefix string , debug bool ) * API { gojilogger := gojilogger . New ( Logger , debug )", "commit_type": "add"}
{"commit_tokens": ["Added", "with", "/", "only", "-", "options", "for", "include", "-", "tag", "."], "add_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "del_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "test", "polution", "of", "checksum", "global", "var"], "add_tokens": "downloadedFile , downloadCachingInfo , downloadErr = downloader . Download ( serverUrl , createDestFile , cacheddownloader . CachingInfoType { } , cacheddownloader . ChecksumInfoType { } , cancelChan ) checksum := cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : \" \" } checksum := cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : \" \" } checksum := cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : hexMsg } checksum := cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : hexMsg } checksum := cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : hexMsg }", "del_tokens": "var checksum cacheddownloader . ChecksumInfoType downloadedFile , downloadCachingInfo , downloadErr = downloader . Download ( serverUrl , createDestFile , cacheddownloader . CachingInfoType { } , checksum , cancelChan ) checksum = cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : \" \" } checksum = cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : \" \" } checksum = cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : hexMsg } checksum = cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : hexMsg } checksum = cacheddownloader . ChecksumInfoType { Algorithm : \" \" , Value : hexMsg }", "commit_type": "fix"}
{"commit_tokens": ["adds", "method", "to", "set", "the", "user", "-", "agent", "header"], "add_tokens": "// Provide meaningful User-Agent informations. c . SetClientInfo ( \" \" , \" \" , \" \" , ) userAgentHeader string } // SetClientInfo sets the HTTP user-agent header of the WS2Client. Please // provide meaningful information about your application as described at: // https://musicbrainz.org/doc/XML_Web_Service/Rate_Limiting#Provide_meaningful_User-Agent_strings func ( c * WS2Client ) SetClientInfo ( application string , version string , contact string ) { c . userAgentHeader = application + \" \" + version + \" \" + contact + \" \" req . Header . Set ( \" \" , c . userAgentHeader )", "del_tokens": "// set user-agent as described on this page: // https://musicbrainz.org/doc/XML_Web_Service/Rate_Limiting#Provide_meaningful_User-Agent_strings req . Header . Set ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Allows", "user", "-", "configured", "http", ".", "Client", "to", "be", "passed", "into", "NewTwilioClient", "."], "add_tokens": "func NewTwilioClient ( accountSid , authToken string , HTTPClient * http . Client ) * Twilio { if HTTPClient == nil { HTTPClient = http . DefaultClient } return & Twilio { accountSid , authToken , twilioUrl , HTTPClient }", "del_tokens": "func NewTwilioClient ( accountSid , authToken string ) * Twilio { return & Twilio { accountSid , authToken , twilioUrl , http . DefaultClient }", "commit_type": "allow"}
{"commit_tokens": ["Fix", "container", "exit", "without", "restore", "terminal"], "add_tokens": "restoreAndCloseStdin := func ( ) { } go func ( ) { io . Copy ( stdin , os . Stdin ) restoreAndCloseStdin ( ) restoreAndCloseStdin ( ) restoreAndCloseStdin ( )", "del_tokens": "go func ( ) { io . Copy ( stdin , os . Stdin )", "commit_type": "fix"}
{"commit_tokens": ["Add", "Subject", "Section", "and", "Topic", "-", "more", "to", "come", "later", "and", "the", "type", "URIs", "need", "to", "be", "checked", "with", "Guy"], "add_tokens": "\" \" var classificationLabels = append ( thingLabels , \" \" ) var subjectLabels = append ( classificationLabels , \" \" ) var sectionLabels = append ( classificationLabels , \" \" ) var topicLabels = append ( conceptLabels , \" \" ) var subjectURIs = [ ] string { baseURI + \" \" } var sectionURIs = [ ] string { baseURI + \" \" } var topicURIs = [ ] string { baseURI + \" \" } func TestTypeURIsForSubject ( t * testing . T ) { assert . New ( t ) . EqualValues ( subjectURIs , TypeURIs ( subjectLabels ) ) } func TestTypeURIsForSection ( t * testing . T ) { assert . New ( t ) . EqualValues ( sectionURIs , TypeURIs ( sectionLabels ) ) } func TestTypeURIsForTopic ( t * testing . T ) { assert . New ( t ) . EqualValues ( topicURIs , TypeURIs ( topicLabels ) ) }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "standard", "middleware", "chaining"], "add_tokens": "wfn := func ( w http . ResponseWriter , r * http . Request ) { next . ServeHTTPC ( ctx , w , r ) } mw ( http . HandlerFunc ( wfn ) ) . ServeHTTP ( w , r )", "del_tokens": "var ww http . ResponseWriter var rr * http . Request hfn := http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { ww , rr = w , r } ) wfn := mw ( hfn ) . ServeHTTP wfn ( w , r ) next . ServeHTTPC ( ctx , ww , rr )", "commit_type": "fix"}
{"commit_tokens": ["Move", "method", "HasSingleStageFlow", "()", "back", "to", "the", "corresponding", "struct"], "add_tokens": "// RespUserDisplayName is the JSON response for https://matrix.org/docs/spec/client_server/r0.2.0.html#get-matrix-client-r0-profile-userid-displayname type RespUserDisplayName struct { DisplayName string `json:\"displayname\"` }", "del_tokens": "// RespUserDisplayName is the JSON response for https://matrix.org/docs/spec/client_server/r0.2.0.html#get-matrix-client-r0-profile-userid-displayname type RespUserDisplayName struct { DisplayName string `json:\"displayname\"` }", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "Maven", "build", "in", "java", "chaincodes"], "add_tokens": "fmt . Sprintf ( \" \" ,", "del_tokens": "fmt . Sprintf ( \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", "definitions"], "add_tokens": "EventPageFrameRequestedNavigation = \" \" case EventPageFrameRequestedNavigation : v = new ( page . EventFrameRequestedNavigation )", "del_tokens": "EventPageFrameClearedScheduledNavigation = \" \" EventPageFrameScheduledNavigation = \" \" case EventPageFrameClearedScheduledNavigation : v = new ( page . EventFrameClearedScheduledNavigation ) case EventPageFrameScheduledNavigation : v = new ( page . EventFrameScheduledNavigation )", "commit_type": "update"}
{"commit_tokens": ["Fix", "OsqueryInt", "unmarshal", "bug", "with", "newer", "versions", "of", "osquery"], "add_tokens": "\" \" s := string ( buff ) if strings . Contains ( s , `\"` ) { unquoted , err := strconv . Unquote ( s ) if err != nil { return & json . UnmarshalTypeError { Value : string ( buff ) , Type : reflect . TypeOf ( oi ) , Struct : \" \" , } } s = unquoted } if len ( s ) == 0 { * oi = OsqueryInt ( 0 ) parsedInt , err := strconv . ParseInt ( s , 10 , 32 ) * oi = OsqueryInt ( parsedInt )", "del_tokens": "// zero value if string ( buff ) == `\"\"` { val , err := strconv . Atoi ( string ( buff [ 1 : len ( buff ) - 1 ] ) ) * oi = OsqueryInt ( val )", "commit_type": "fix"}
{"commit_tokens": ["Add", "filename", "display", "option", "Llongfile", "and", "Lshortfile"], "add_tokens": "\" \" gopath = \" \" gopath string fileDisplay log . FilenameDisplay fileDisplay : log . Lshortfile , // SetFilenameDisplay tells HTTP the filename, when present, how to display func ( h * HTTP ) SetFilenameDisplay ( fd log . FilenameDisplay ) { h . fileDisplay = fd } // pre-setup if h . fileDisplay == log . Llongfile { // gather $GOPATH for use in stripping off of full name // if not found still ok as will be blank h . gopath = os . Getenv ( gopath ) if len ( h . gopath ) != 0 { h . gopath += string ( os . PathSeparator ) + \" \" + string ( os . PathSeparator ) } } if h . fileDisplay == log . Lshortfile { for i = len ( file ) - 1 ; i > 0 ; i -- { if file [ i ] == '/' { file = file [ i + 1 : ] break } } else { file = file [ len ( h . gopath ) : ]", "del_tokens": "for i := len ( file ) - 1 ; i > 0 ; i -- { if file [ i ] == '/' { file = file [ i + 1 : ] break", "commit_type": "add"}
{"commit_tokens": ["Move", "unmarshal", "tests", "to", "grafana", "package", "."], "add_tokens": "package grafana var board Board var board Board var board Board func TestUnmarshal_EmptyDashboardWithLinks26 ( t * testing . T ) { var board Board raw , _ := ioutil . ReadFile ( \" \" ) err := json . Unmarshal ( raw , & board ) if err != nil { t . Error ( err ) } } var board Board", "del_tokens": "package client \" \" var board grafana . Board var board grafana . Board var board grafana . Board var board grafana . Board", "commit_type": "move"}
{"commit_tokens": ["Add", "timeout", "middleware", "to", "svc", "stack"], "add_tokens": "HandlerTimeout time . Duration h := httpx . Handler ( opts . Router ) if opts . HandlerTimeout != 0 { // Timeout requests after the given Timeout duration. h = middleware . TimeoutHandler ( h , opts . HandlerTimeout ) } h = middleware . BasicRecover ( h )", "del_tokens": "var h httpx . Handler h = middleware . BasicRecover ( opts . Router )", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "to", "increment", "links", "count", "before", "checking", "max", "links", "and", "set", "the", "correct", "max", "file", "size"], "add_tokens": "b . linkcnt ++", "del_tokens": "b . linkcnt ++", "commit_type": "make"}
{"commit_tokens": ["fix", ":", "backend", "name", "for", "Stateful", "services", "."], "add_tokens": "import ( \" \" )", "del_tokens": "import \" \"", "commit_type": "fix"}
{"commit_tokens": ["Update", "gRPC", "and", "fix", "tests"], "add_tokens": "fullMethodName , ok := grpc . MethodFromServerStream ( serverStream )", "del_tokens": "\" \" lowLevelServerStream , ok := transport . StreamFromContext ( serverStream . Context ( ) ) fullMethodName := lowLevelServerStream . Method ( )", "commit_type": "update"}
{"commit_tokens": ["changed", "const", "to", "be", "listed", "in", "var", "section", "in", "common", "as", "they", "are", "not", "really", "constants", ".", "go", "fmt"], "add_tokens": "var ( dataUnits = [ 3 ] string { \" \" , \" \" , \" \" }", "del_tokens": "const ( ) var ( dataUnits = [ 3 ] string { \" \" , \" \" , \" \" }", "commit_type": "change"}
{"commit_tokens": ["add", "safe", "defaults", "for", "auth", "that", "match", "cassettes"], "add_tokens": "func getenv ( key , defaultValue string ) string { if value , ok := os . LookupEnv ( key ) ; ok { return value } return defaultValue } DynCustomerName = getenv ( \" \" , \" \" ) DynUsername = getenv ( \" \" , \" \" ) DynPassword = getenv ( \" \" , \" \" ) testZone = getenv ( \" \" , \" \" )", "del_tokens": "DynCustomerName = os . Getenv ( \" \" ) DynUsername = os . Getenv ( \" \" ) DynPassword = os . Getenv ( \" \" ) testZone = os . Getenv ( \" \" ) func TestSetup ( t * testing . T ) { if len ( DynCustomerName ) == 0 { t . Fatal ( \" \" ) } if len ( DynUsername ) == 0 { t . Fatal ( \" \" ) } if len ( DynPassword ) == 0 { t . Fatal ( \" \" ) } if len ( testZone ) == 0 { t . Fatal ( \" \" ) } }", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "to", "v3", "of", "the", "jwt", "-", "go", "dependacy"], "add_tokens": "vClaims := vToken . Claims . ( jwt . MapClaims ) if vClaims [ rule . Claim ] == rule . Value { if vClaims [ rule . Claim ] != rule . Value { if vClaims [ rule . Claim ] == rule . Value { if vClaims [ rule . Claim ] != rule . Value { for claim , value := range vClaims {", "del_tokens": "if vToken . Claims [ rule . Claim ] == rule . Value { if vToken . Claims [ rule . Claim ] != rule . Value { if vToken . Claims [ rule . Claim ] == rule . Value { if vToken . Claims [ rule . Claim ] != rule . Value { for claim , value := range vToken . Claims {", "commit_type": "upgrade"}
{"commit_tokens": ["adding", "*", "Tag", "missing", "methods", "and", "covering", "some", "documentation", "that", "is", "missing"], "add_tokens": "//Form is the bootstrap version of Form //New creates a bootstrap Form from passed options //CheckboxTag builds a bootstrap checkbox with passed options //InputTag builds a bootstrap input[type=text] with passed options //FileTag builds a bootstrap input[type=file] with passed options //RadioButton builds a bootstrap input[type=radio] with passed options return f . RadioButtonTag ( opts ) } //RadioButtonTag builds a bootstrap input[type=radio] with passed options func ( f Form ) RadioButtonTag ( opts tags . Options ) * tags . Tag { //SelectTag builds a bootstrap select with passed options //TextArea builds a bootstrap textarea with passed options return f . TextAreaTag ( opts ) } //TextAreaTag builds a bootstrap textarea with passed options func ( f Form ) TextAreaTag ( opts tags . Options ) * tags . Tag {", "del_tokens": "//Form is the bootstrap extension of Form //New builds a new bootstrap form from passed options //CheckboxTag adds an input type=checkbox //InputTag adds an input type=text by default //FileTag adds an input type=file to the form //RadioButton adds an input type=radio to the form //SelectTag adds a select tag to the form //TextArea adds a textarea tag to the form", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "logical", "error", ".", "check", "for", "transporter", "first"], "add_tokens": "if token == \" \" { // this is a little bit of magic so that transformers (which are added by the transform fn get the right kind) givenOptions [ \" \" ] = \" \" }", "del_tokens": "if token == \" \" { // this is a little bit of magic so that transformers (which are added by the transform fn get the right kind) kind = \" \" }", "commit_type": "fix"}
{"commit_tokens": ["Implement", "/", "traefik", "/", "alias", "for", "KV", "stores", "."], "add_tokens": "// Allow `/traefik/alias` to superesede `provider.Prefix` strings . TrimSuffix ( provider . get ( provider . Prefix , provider . Prefix + \" \" ) , \" \" ) ,", "del_tokens": "provider . Prefix ,", "commit_type": "implement"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// DelByFormat removes the specified format, returns true when an item was actually removed", "del_tokens": "// DelByType removes the specified format, returns true when an item was actually removed", "commit_type": "fix"}
{"commit_tokens": ["Use", "requestURI", "for", "handle", "URL"], "add_tokens": "c . Assert ( r . URL . EscapedPath ( ) , Equals , \" \" )", "del_tokens": "c . Assert ( r . URL . Path , Equals , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Use", "inteface", "to", "asbtract", "key", "discover"], "add_tokens": "type SecretProvider interface { GetSecret ( req * http . Request ) ( interface { } , error ) } type SecretProviderFunc func ( req * http . Request ) ( interface { } , error ) func ( f SecretProviderFunc ) GetSecret ( req * http . Request ) ( interface { } , error ) { return f ( req ) } func NewKeyProvider ( key interface { } ) SecretProvider { return SecretProviderFunc ( func ( req * http . Request ) ( interface { } , error ) { return key , nil } ) } secretProvider SecretProvider func NewConfiguration ( provider SecretProvider , audience , issuer string , method jose . SignatureAlgorithm ) Configuration { secretProvider : provider , key , err := v . config . secretProvider . GetSecret ( r ) if err != nil { return nil , err } err = token . Claims ( key , & claims )", "del_tokens": "key [ ] byte func NewConfiguration ( key [ ] byte , audience , issuer string , method jose . SignatureAlgorithm ) Configuration { key : key , err = token . Claims ( v . config . key , & claims )", "commit_type": "use"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", "definitions"], "add_tokens": "CommandIndexedDBGetMetadata = indexeddb . CommandGetMetadata case CommandIndexedDBGetMetadata : v = new ( indexeddb . GetMetadataReturns )", "del_tokens": "CommandIndexedDBGetKeyGeneratorCurrentNumber = indexeddb . CommandGetKeyGeneratorCurrentNumber case CommandIndexedDBGetKeyGeneratorCurrentNumber : v = new ( indexeddb . GetKeyGeneratorCurrentNumberReturns )", "commit_type": "update"}
{"commit_tokens": ["add", "initial", "support", "for", "environments"], "add_tokens": "secrets , err = secretsyml . ParseFromFile ( ac . Filepath , ac . Environment , ac . Subs ) secrets , err = secretsyml . ParseFromString ( ac . YamlInline , ac . Environment , ac . Subs )", "del_tokens": "secrets , err = secretsyml . ParseFromFile ( ac . Filepath , ac . Subs ) secrets , err = secretsyml . ParseFromString ( ac . YamlInline , ac . Subs )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "using", "a", "custom", "HTTP", "client"], "add_tokens": "Client * http . Client if resp , err := m . Client . Get ( url ) ; err != nil { return NewFromClient ( http . DefaultClient , token , apiURL ) } // Creates a client instance using the specified client instance. This is useful // when using a proxy. func NewFromClient ( c * http . Client , token , apiURL string ) Mixpanel { Client : c ,", "del_tokens": "if resp , err := http . Get ( url ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Add", "popcntgo", "tag", "to", "force", "popcnt", "implementation", "to", "be", "pure", "-", "Go"], "add_tokens": "// +build !amd64 appengine popcntgo", "del_tokens": "// +build !amd64 appengine", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "special", "char", "test"], "add_tokens": "{ `foo.com/a.,:;-+_()?@&=$~!*%'\"a` , `foo.com/a.,:;-+_()?@&=$~!*%'\"a` } , //{`foo.com/path_(more)`, `foo.com/path_(more)`},", "del_tokens": "//{`test.foo.com/path_(more)`, `test.foo.com/path_(more)`},", "commit_type": "add"}
{"commit_tokens": ["Add", "v1", "tracing", "support", "to", "golib"], "add_tokens": "\" \" const ( // ClientVersion is the version of this library and is embedded into the user agent ClientVersion = \" \" // IngestEndpointV2 is the v2 version of the signalfx ingest endpoint IngestEndpointV2 = \" \" // EventIngestEndpointV2 is the v2 version of the signalfx event endpoint EventIngestEndpointV2 = \" \" // TraceIngestEndpointV1 is the v1 version of the signalfx trace endpoint TraceIngestEndpointV1 = \" \" // DefaultTimeout is the default time to fail signalfx datapoint requests if they don't succeed DefaultTimeout = time . Second * 5 ) TraceEndpoint string jsonMarshal func ( v interface { } ) ( [ ] byte , error ) // AddSpans forwards the traces to SignalFx. func ( h * HTTPSink ) AddSpans ( ctx context . Context , traces [ ] * trace . Span ) ( err error ) { if len ( traces ) == 0 { return nil } return h . doBottom ( ctx , func ( ) ( io . Reader , bool , error ) { b , err := h . jsonMarshal ( traces ) if err != nil { return nil , false , errors . Annotate ( err , \" \" ) } return h . getReader ( b ) } , \" \" , h . TraceEndpoint ) } TraceEndpoint : TraceIngestEndpointV1 , jsonMarshal : json . Marshal ,", "del_tokens": "// ClientVersion is the version of this library and is embedded into the user agent const ClientVersion = \" \" // IngestEndpointV2 is the v2 version of the signalfx ingest endpoint const IngestEndpointV2 = \" \" // EventIngestEndpointV2 is the v2 version of the signalfx event endpoint const EventIngestEndpointV2 = \" \" // DefaultTimeout is the default time to fail signalfx datapoint requests if they don't succeed const DefaultTimeout = time . Second * 5", "commit_type": "add"}
{"commit_tokens": ["Move", "worker", "pre", "-", "flush", "aggregation", "into", "server", "struct"], "add_tokens": "Workers : workers , for range ticker . C { server . Flush ( veneur . Config . Interval , veneur . Config . FlushLimit )", "del_tokens": "for t := range ticker . C { metrics := make ( [ ] [ ] veneur . DDMetric , veneur . Config . NumWorkers ) for i , w := range workers { log . WithFields ( log . Fields { \" \" : i , \" \" : t , } ) . Debug ( \" \" ) metrics = append ( metrics , w . Flush ( veneur . Config . Interval ) ) } server . Flush ( metrics , veneur . Config . FlushLimit )", "commit_type": "move"}
{"commit_tokens": ["Use", "hex", "encode", "/", "decode"], "add_tokens": "\" \" encrypted , _ := Aes128Encrypt ( \" \" , \" \" , testedData , hex . EncodeToString ) decrypted , _ := Aes128Decrypt ( \" \" , \" \" , encrypted , hex . DecodeString )", "del_tokens": "\" \" encode := func ( data [ ] byte ) string { return base32 . StdEncoding . EncodeToString ( data ) } encrypted , _ := Aes128Encrypt ( \" \" , \" \" , testedData , encode ) decode := func ( data string ) ( [ ] byte , error ) { return base32 . StdEncoding . DecodeString ( data ) } decrypted , _ := Aes128Decrypt ( \" \" , \" \" , encrypted , decode )", "commit_type": "use"}
{"commit_tokens": ["Fix", "Expand", "for", "path", "of", "len", "<", "=", "1", "."], "add_tokens": "if len ( path ) == 0 || path [ 0 ] != '~' { if len ( path ) > 1 && path [ 1 ] != '/' && path [ 1 ] != '\\\\' {", "del_tokens": "if path [ 0 ] != '~' { if path [ 1 ] != '/' && path [ 1 ] != '\\\\' {", "commit_type": "fix"}
{"commit_tokens": ["Use", "release", "summaries", "as", "git", "commit", "messages"], "add_tokens": "res = append ( res , s . releaseActionCommitAndPush ( \" \" ) ) res = append ( res , s . releaseActionCommitAndPush ( fmt . Sprintf ( \" \" , target ) ) ) res = append ( res , s . releaseActionCommitAndPush ( fmt . Sprintf ( \" \" , id ) ) ) res = append ( res , s . releaseActionCommitAndPush ( fmt . Sprintf ( \" \" , target , serviceID ) ) ) func ( s * releaser ) releaseActionCommitAndPush ( msg string ) flux . ReleaseAction { return s . repo . CommitAndPush ( rc . RepoPath , rc . RepoKey , msg )", "del_tokens": "res = append ( res , s . releaseActionCommitAndPush ( ) ) res = append ( res , s . releaseActionCommitAndPush ( ) ) res = append ( res , s . releaseActionCommitAndPush ( ) ) res = append ( res , s . releaseActionCommitAndPush ( ) ) func ( s * releaser ) releaseActionCommitAndPush ( ) flux . ReleaseAction { return s . repo . CommitAndPush ( rc . RepoPath , rc . RepoKey , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Add", "go", "fmt", "to", "bin", "/", "test"], "add_tokens": "startMysqlInJoinMonitoredReturns struct {", "del_tokens": "startMysqlInJoinMonitoredReturns struct {", "commit_type": "add"}
{"commit_tokens": ["added", "css", "and", "js", "watching", "for", "bin"], "add_tokens": "var assetsWatcher , binWatcher * assets . Watcher var err error assetsWatcher , err = assets . NewWatch ( assets . WatcherConfig { if binWatcher != nil { binWatcher . ForceNotify ( ) } binWatcher , err = assets . NewWatch ( assets . WatcherConfig {", "del_tokens": "assetsWatcher , err := assets . NewWatch ( assets . WatcherConfig { binWatcher , err := assets . NewWatch ( assets . WatcherConfig {", "commit_type": "add"}
{"commit_tokens": ["update", "tests", "to", "support", "new", "libargon2"], "add_tokens": "\" \" Version : argon2 . Version10 , Version : argon2 . Version10 , // $argon2i$v=16$m=65536,t=2,p=4$c29tZXNhbHQAAAAAAAAAAA$QWLzI4TY9HkL2ZTLc8g6SinwdhZewYrzz9zxCo0bkGY", "del_tokens": "\" \" // $argon2i$m=65536,t=2,p=4$c29tZXNhbHQAAAAAAAAAAA$QWLzI4TY9HkL2ZTLc8g6SinwdhZewYrzz9zxCo0bkGY", "commit_type": "update"}
{"commit_tokens": ["Allow", "to", "parse", "relative", "url", "templates", "."], "add_tokens": "return url . Parse ( expanded )", "del_tokens": "return url . ParseRequestURI ( expanded )", "commit_type": "allow"}
{"commit_tokens": ["fix", "string", "with", "operator", "prefix", "is", "lexed", "as", "operator", "bug"], "add_tokens": "} else if isAlpha ( op ) { // If operator is alphabetic (such as \"in\" or \"is\"), // we avoid matching \"include\" or functions like \"is_currently_on\" // For such operators to be valid, they need to have a space after. lenOp := len ( op ) if ( l . pos + lenOp + 1 ) <= len ( l . input ) && l . input [ l . pos + lenOp : l . pos + lenOp + 1 ] != \" \" { // Check if a string only contains alphabetic characters func isAlpha ( s string ) bool { for _ , r := range s { if ! unicode . IsLetter ( r ) { return false } } return true }", "del_tokens": "} else if op == \" \" || op == \" \" { // Avoid matching \"include\" or functions like \"is_currently_on\" if l . input [ l . pos + 2 : l . pos + 3 ] != \" \" {", "commit_type": "fix"}
{"commit_tokens": ["add", "NextFilteredUntil", "...", "()", "with", "tests"], "add_tokens": "t . Errorf ( \" \" , class , sel . Get ( 0 ) ) func AssertSelectionIs ( t * testing . T , sel * Selection , is ... string ) { for i := 0 ; i < sel . Length ( ) ; i ++ { if ! sel . Eq ( i ) . Is ( is [ i ] ) { t . Errorf ( \" \" , i , is [ i ] , sel . Get ( i ) ) } } }", "del_tokens": "t . Errorf ( \" \" , class )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "receiver", "names", "on", "model", "types", "and", "enum", "naming"], "add_tokens": "// calculate val, chopping off redundant type name if applicable val := snaker . SnakeToCamel ( strings . ToLower ( e . EnumValue ) ) if strings . HasSuffix ( strings . ToLower ( val ) , strings . ToLower ( goType ) ) { v := val [ : len ( val ) - len ( goType ) ] if len ( v ) > 0 { val = v } } e . Value = val", "del_tokens": "e . Value = snaker . SnakeToCamel ( strings . ToLower ( e . EnumValue ) )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "a", "bootstrap", "KS", "test", "and", "included", "a", "description", "in", "the", "README"], "add_tokens": "if exists ( \" \" , conf . Methods ) || exists ( \" \" , conf . Methods ) {", "del_tokens": "if exists ( \" \" , conf . Methods ) {", "commit_type": "implement"}
{"commit_tokens": ["Add", "VDepth", "variant", "to", "allow", "for", "correct", "use", "of", "vmodule", "etc", "from", "packages"], "add_tokens": "func ( l * Log ) VDepth ( depth int , level Level ) bool { if runtime . Callers ( l . skip + depth , l . pcs [ : ] ) == 0 { func ( l * Log ) V ( level Level ) bool { return l . VDepth ( 1 , level ) }", "del_tokens": "func ( l * Log ) V ( level Level ) bool { if runtime . Callers ( l . skip , l . pcs [ : ] ) == 0 {", "commit_type": "add"}
{"commit_tokens": ["Remove", "support", "for", "deprecated", "Go", "versions"], "add_tokens": "\" \" runtime . SetMutexProfileFraction ( 1 ) runtime . SetMutexProfileFraction ( 0 ) if err := trace . Start ( f ) ; err != nil { trace . Stop ( )", "del_tokens": "enableMutexProfile ( ) disableMutexProfile ( ) if err := startTrace ( f ) ; err != nil { stopTrace ( )", "commit_type": "remove"}
{"commit_tokens": ["Changed", "some", "variable", "names", "."], "add_tokens": "cc := nds . NewContext ( c ) cc = nds . NewContext ( c ) cc := nds . NewContext ( c )", "del_tokens": "cc := nds . NewCacheContext ( c ) cc = nds . NewCacheContext ( c ) cc := nds . NewCacheContext ( c )", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "failing", "test", "for", "IIP"], "add_tokens": "In <- chan int c . Out <- 2 * i c . Out <- 2 * i 12 : 24 , 7 : 14 , actual := <- out defer close ( c . Sum ) }", "del_tokens": "In <- chan int c . Out <- 2 * i c . Out <- 2 * i 12 : 24 , 7 : 14 , actual := <- out closeOuts := func ( ) { close ( c . Sum ) } defer closeOuts ( ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "documentations", "for", "command", "line", "option", "to", "get", "SSH"], "add_tokens": "\" \" : { \" \" , \" \" } , \" \" : { \" \" , \" \" } , \" \" : { \" \" , \" \" } ,", "del_tokens": "\" \" : { \" \" , \" \" } , \" \" : { \" \" , \" \" } , \" \" : { \" \" , \" \" } ,", "commit_type": "add"}
{"commit_tokens": ["Implement", "docker", "import", "with", "the", "standalone", "client", "lib", "."], "add_tokens": "// CreateImageOptions holds information to create images.", "del_tokens": "// CreateImageOptions holds information to create images", "commit_type": "implement"}
{"commit_tokens": ["update", "version", "of", "go", "-", "multiaddr"], "add_tokens": "manet \" \" logging \" \" ma \" \"", "del_tokens": "logging \" \" ma \" \" manet \" \"", "commit_type": "update"}
{"commit_tokens": ["added", "directory", "of", "symbolic", "links", "(", "with", "directory", "loop", ")"], "add_tokens": "expected := [ ] string { \" \" , \" \" , \" \" , \" \" } & godirwalk . Dirent { Name : \" \" , ModeType : os . ModeDir , } ,", "del_tokens": "expected := [ ] string { \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["added", "graceful", "period", "to", "Stop"], "add_tokens": "import \" \" Stop ( wait time . Duration ) <- chan Signal func All ( wait time . Duration , stoppers ... Stopper ) <- chan Signal { allChans = append ( allChans , stopper . Stop ( wait ) )", "del_tokens": "Stop ( ) <- chan Signal func All ( stoppers ... Stopper ) <- chan Signal { allChans = append ( allChans , stopper . Stop ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "an", "ignored", "name", "being", "a", "file", "."], "add_tokens": "if info . IsDir ( ) { return filepath . SkipDir } else { return nil }", "del_tokens": "return filepath . SkipDir", "commit_type": "fix"}
{"commit_tokens": ["remove", "deprecated", "X", "-", "headers"], "add_tokens": "\" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" ,", "del_tokens": "\" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , \" \" : \" \" ,", "commit_type": "remove"}
{"commit_tokens": ["Add", "error", "code", "to", "response", "for", "/", "tasks", "api", "."], "add_tokens": "const statusInternalServerError = 500 if ok { tasksResponse = NewTasksResponse ( dockerTaskEngine . State ( ) ) } else { w . WriteHeader ( statusInternalServerError ) w . WriteHeader ( statusNotImplemented )", "del_tokens": "if ok != true { } else { tasksResponse = NewTasksResponse ( dockerTaskEngine . State ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "bits", "added", "examples"], "add_tokens": "ID int64 `json:\"id\"` Time int64 `json:\"time\"` ID int64 `json:\"id\"` ID int64 `json:\"id\"`", "del_tokens": "ID string `json:\"id\"` Time int64 `json:\"time\"` ID string `json:\"id\"` ID string `json:\"id\"`", "commit_type": "fix"}
{"commit_tokens": ["Changed", "constants", "to", "private", "cammel", "-", "cased"], "add_tokens": "goInstaAPIUrl = \" \" goInstaUserAgent = \" \" goInstaIGSigKey = \" \"", "del_tokens": "GOINSTA_API_URL = \" \" GOINSTA_USER_AGENT = \" \" GOINSTA_IG_SIG_KEY = \" \"", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", "test", "groups"], "add_tokens": "group string // StartGroup starts a new test groups. Errors will be prefixed with the name of // this group until EndGroup is called. func ( e * Expect ) StartGroup ( name string ) { e . group = name } // EndGroup closes a test group. See StartGroup. func ( e * Expect ) EndGroup ( ) { e . group = \" \" } scope := e . scope if e . group != \" \" { scope += \" \" + e . group } fmt . Printf ( \" \\t \\n \" , file , line , scope , message )", "del_tokens": "fmt . Printf ( \" \\t \\n \" , file , line , e . scope , message )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "slices", "and", "arrays", "in", "Decoder", ".", "Decode"], "add_tokens": "// pointed to by v. If v is nil or not a pointer to a struct slice, Unmarshal // returns an InvalidUnmarshalError. val := reflect . ValueOf ( v ) if val . Kind ( ) != reflect . Ptr || val . IsNil ( ) { if val . Type ( ) . Elem ( ) . Kind ( ) != reflect . Slice { return & InvalidUnmarshalError { Type : val . Type ( ) } typ := val . Type ( ) . Elem ( ) if walkType ( typ . Elem ( ) ) . Kind ( ) != reflect . Struct { return & InvalidUnmarshalError { Type : val . Type ( ) } } val . Elem ( ) . Set ( slice . Slice3 ( 0 , i , i ) )", "del_tokens": "// pointed to by v. If v is nil or not a pointer to a slice, Unmarshal returns // an InvalidUnmarshalError. vv := reflect . ValueOf ( v ) if vv . Kind ( ) != reflect . Ptr || vv . IsNil ( ) { if vv . Type ( ) . Elem ( ) . Kind ( ) != reflect . Slice { return & InvalidUnmarshalError { Type : vv . Type ( ) } typ := vv . Type ( ) . Elem ( ) vv . Elem ( ) . Set ( slice . Slice3 ( 0 , i , i ) )", "commit_type": "add"}
{"commit_tokens": ["use", "a", "temp", "buffer", "so", "that", "a", "request", "/", "response", "pair", "always", "appears", "in", "order"], "add_tokens": "\" \" \" \" sync . Mutex // Use a temp buffer so that a request/response pair always appears in order. var buf bytes . Buffer fmt . Fprintf ( & buf , \" \" , requestDump ) fmt . Fprintf ( & buf , \" \" , responseDump ) interceptor . Lock ( ) io . Copy ( interceptor . out , & buf ) interceptor . Unlock ( )", "del_tokens": "fmt . Fprintf ( interceptor . out , \" \" , requestDump ) fmt . Fprintf ( interceptor . out , \" \" , responseDump )", "commit_type": "use"}
{"commit_tokens": ["Add", "Examples", "to", "test", "files"], "add_tokens": "s2 := [ ] float64 { 1 , 2 , 3 , 5 , 6 } a , _ := Correlation ( s1 , s2 )", "del_tokens": "s3 := [ ] float64 { 1 , 2 , 3 , 5 , 6 } a , _ := Correlation ( s1 , s3 )", "commit_type": "add"}
{"commit_tokens": ["Updated", "function", "signature", "in", "ssh", "-", "docker", "example", ".", "Added", "Dockerfile", "for", "example", ".", "Added", "readme", "for", "ssh", "-", "docker", "example", "."], "add_tokens": "status , cleanup , err := dockerRun ( cfg , sess ) func dockerRun ( cfg * container . Config , sess ssh . Session ) ( status int64 , cleanup func ( ) , err error ) { statusChan , chanErr := docker . ContainerWait ( ctx , res . ID , container . WaitConditionNotRunning ) if chanErr != nil { err = <- chanErr s := <- statusChan status = s . StatusCode", "del_tokens": "err , status , cleanup := dockerRun ( cfg , sess ) func dockerRun ( cfg * container . Config , sess ssh . Session ) ( err error , status int64 , cleanup func ( ) ) { status , err = docker . ContainerWait ( ctx , res . ID ) if err != nil { err = <- outputErr", "commit_type": "update"}
{"commit_tokens": ["Fix", "history", "and", "add", "tests"], "add_tokens": "h . tmp = make ( [ ] string , len ( h . histories ) ) for i := range h . histories { h . tmp [ i ] = h . histories [ i ] }", "del_tokens": "copy ( h . tmp , h . histories )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "documentation", "and", "example", "."], "add_tokens": "es . SendEventMessage ( \" \" , \" \" , strconv . Itoa ( id ) )", "del_tokens": "es . SendMessage ( \" \" , \" \" , strconv . Itoa ( id ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "test", "for", "crypto", "handshake"], "add_tokens": "// Decrypt challenge and send plaintext to partner func GenKeypair ( bits int ) ( * KeyPair , error ) { priv , err := rsa . GenerateKey ( rand . Reader , bits ) Pub : & priv . PublicKey ,", "del_tokens": "func GenKeypair ( ) ( * KeyPair , error ) { priv , err := rsa . GenerateKey ( rand . Reader , 4096 ) Pub : priv . PublicKey ,", "commit_type": "add"}
{"commit_tokens": ["Add", "BenchmarkProcessor002ParseOnly", "to", "get", "at", "least", "a", "hint", "of", "the", "JSON", "speed", "."], "add_tokens": "// // BenchmarkProcessor002ParseOnly in the extraction package is not quite // comparable to the benchmarks here, but it gives an idea: JSON parsing is even // slower than text parsing and needs a comparable amount of allocs.", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "day", "-", "of", "-", "month", "frame"], "add_tokens": "type DayOfMonthMapper struct { } // ID maps a timestamp to a day of month bucket (1-31) func ( m DayOfMonthMapper ) ID ( ti ... interface { } ) ( rowIDs [ ] int64 , err error ) { t := ti [ 0 ] . ( time . Time ) return [ ] int64 { int64 ( t . Day ( ) ) } , nil } // ID maps a timestamp to a month bucket (1-12)", "del_tokens": "// ID maps a timestamp to a month bucket", "commit_type": "add"}
{"commit_tokens": ["Remove", "unnecessary", "argument", "to", "createSigningString", "."], "add_tokens": "signingString , err := vg . createSigningString ( r ) func ( vg * VanGoH ) createSigningString ( r * http . Request ) ( string , error ) {", "del_tokens": "signingString , err := vg . createSigningString ( w , r ) func ( vg * VanGoH ) createSigningString ( w http . ResponseWriter , r * http . Request ) ( string , error ) {", "commit_type": "remove"}
{"commit_tokens": ["Improve", "check", "of", "async", "job", "status"], "add_tokens": "// Check status of the job we issued. // 0 - pending / in progress // 1 - succedded // 2 - failed // 3 - cancelled switch status { case 0 : continue case 1 : case 2 : err := fmt . Errorf ( \" \" ) result <- err return case 3 : err := fmt . Errorf ( \" \" ) result <- err return case <- done : case err := <- result : case <- time . After ( timeout ) : // WaitForVirtualMachineState simply blocks until the virtual machine // is in the specified state. case <- done : case err := <- result : case <- time . After ( timeout ) :", "del_tokens": "// job is completed, we can exit if status == 1 { case <- done : case err := <- result : case <- time . After ( timeout ) : // waitForAsyncJob simply blocks until the virtual machine is in the // specified state. case <- done : case err := <- result : case <- time . After ( timeout ) :", "commit_type": "improve"}
{"commit_tokens": ["Update", "Export", "to", "break", "by", "locale"], "add_tokens": "err := utrans . VerifyTranslations ( )", "del_tokens": "err = utrans . VerifyTranslations ( )", "commit_type": "update"}
{"commit_tokens": ["Moved", "debug", "output", "into", "the", "fuseutil", "package", "."], "add_tokens": "server := & fusefs . Server { FS : fs , Debug : getDebugFunc ( ) , } if err := server . Serve ( c ) ; err != nil {", "del_tokens": "if err := fusefs . Serve ( c , fs ) ; err != nil {", "commit_type": "move"}
{"commit_tokens": ["Add", "func", "to", "create", "ksuid", "from", "passed", "-", "in", "time"], "add_tokens": "return NewRandomWithTime ( time . Now ( ) ) } func NewRandomWithTime ( t time . Time ) ( ksuid KSUID , err error ) { ts := timeToCorrectedUTCTimestamp ( t )", "del_tokens": "ts := timeToCorrectedUTCTimestamp ( time . Now ( ) )", "commit_type": "add"}
{"commit_tokens": ["Adds", "EXPUNGE", "support", "in", "server"], "add_tokens": "func ( cmd * Expunge ) Command ( ) * imap . Command { func ( cmd * Expunge ) Parse ( fields [ ] interface { } ) error { return nil }", "del_tokens": "func ( c * Expunge ) Command ( ) * imap . Command {", "commit_type": "add"}
{"commit_tokens": ["Use", "string", "rather", "than", "[]", "byte", "for", "ketama", "hash", ".", "Easier", "to", "understand", "for", "users"], "add_tokens": "Label ( ) string", "del_tokens": "Label ( ) [ ] byte", "commit_type": "use"}
{"commit_tokens": ["Added", "logging", "for", "requests", "and", "story", "packages"], "add_tokens": "EnableReqLog : true ,", "del_tokens": "EnableReqLog : false ,", "commit_type": "add"}
{"commit_tokens": ["Move", "wire", "header", "API", "into", "subpackage"], "add_tokens": "package textproto func newTestHeader ( ) Header { var h Header func TestHeader ( t * testing . T ) { func TestHeader_Set ( t * testing . T ) { func TestHeader_Del ( t * testing . T ) { func TestHeader_Fields_Del ( t * testing . T ) { func TestHeader_FieldsByKey_Del ( t * testing . T ) { if err := writeHeader ( & b , h ) ; err != nil { if err := writeHeader ( & b , h ) ; err != nil {", "del_tokens": "package message func newTestHeader ( ) Header2 { var h Header2 func TestHeader2 ( t * testing . T ) { func TestHeader2_Set ( t * testing . T ) { func TestHeader2_Del ( t * testing . T ) { func TestHeader2_Fields_Del ( t * testing . T ) { func TestHeader2_FieldsByKey_Del ( t * testing . T ) { if err := writeHeader2 ( & b , h ) ; err != nil { if err := writeHeader2 ( & b , h ) ; err != nil {", "commit_type": "move"}
{"commit_tokens": ["Add", "paused", "field", "to", "db", ".", "CreateJob", "()"], "add_tokens": "Paused bool `json:\"paused\"` id , err := self . Data . CreateJob ( params . Target , params . Store , params . Schedule , params . Retention , params . Paused )", "del_tokens": "id , err := self . Data . CreateJob ( params . Target , params . Store , params . Schedule , params . Retention )", "commit_type": "add"}
{"commit_tokens": ["add", "check", "to", "scheduler", "configs"], "add_tokens": "// Check provisioner configs // Check Docker configs err = CheckScheduler ( ) if err != nil { return err } // Check default configs to Docker. func CheckScheduler ( ) error { if scheduler , err := Get ( \" \" ) ; err == nil && scheduler == true { if servers , err := Get ( \" \" ) ; err == nil && servers != nil { return fmt . Errorf ( \" \" ) } for _ , value := range [ ] string { \" \" , \" \" } { if _ , err := Get ( value ) ; err != nil { return fmt . Errorf ( \" \" , value ) } } return nil } if servers , err := Get ( \" \" ) ; err != nil || servers == nil { return fmt . Errorf ( \" \" ) } return nil }", "del_tokens": "// Check docker configs", "commit_type": "add"}
{"commit_tokens": ["Make", "empty", "goss", ".", "yaml", "error", ".", "Drop", "implicit", "STDIN"], "add_tokens": "var path , source string specFile := c . GlobalString ( \" \" ) if specFile == \" \" { source = \" \" source = specFile if len ( gossConfig . Resources ( ) ) == 0 { fmt . Printf ( \" \\n \" , source ) os . Exit ( 1 ) }", "del_tokens": "var path string if ! c . GlobalIsSet ( \" \" ) && hasStdin ( ) { specFile := c . GlobalString ( \" \" ) func hasStdin ( ) bool { if fi , err := os . Stdin . Stat ( ) ; err == nil { mode := fi . Mode ( ) if ( mode & os . ModeNamedPipe != 0 ) || mode . IsRegular ( ) { return true } } return false }", "commit_type": "make"}
{"commit_tokens": ["Fix", "segtostr", "neg", "int", "handling", "finish", "bhvr", "tests", "."], "add_tokens": "j := i + 1 if i < 0 { i -- } s , err := Span ( path , i , j )", "del_tokens": "s , err := Span ( path , i , i + 1 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "verification_status", "to", "account", "schema"], "add_tokens": "AccountID string `json:\"account_id\"` Balances AccountBalances `json:\"balances\"` Mask string `json:\"mask\"` Name string `json:\"name\"` OfficialName string `json:\"official_name\"` Subtype string `json:\"subtype\"` Type string `json:\"type\"` VerificationStatus string `json:\"verification_status\"`", "del_tokens": "AccountID string `json:\"account_id\"` Balances AccountBalances `json:\"balances\"` Mask string `json:\"mask\"` Name string `json:\"name\"` OfficialName string `json:\"official_name\"` Subtype string `json:\"subtype\"` Type string `json:\"type\"`", "commit_type": "add"}
{"commit_tokens": ["improve", "logging", "for", "SSL", "flow"], "add_tokens": "log . Fatalf ( \" \" , Config . ConfigDir )", "del_tokens": "log . Fatalf ( \" \" + Config . ConfigDir )", "commit_type": "improve"}
{"commit_tokens": ["Adding", "basic", "test", "on", "the", "telemetry"], "add_tokens": "func ( s * sender ) flushTelemetryMetrics ( ) SenderMetrics {", "del_tokens": "func ( s * sender ) flushMetrics ( ) SenderMetrics {", "commit_type": "add"}
{"commit_tokens": ["add", "tls", "to", "docker", "connection"], "add_tokens": "const dockerPort = \" \"", "del_tokens": "const dockerPort = \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "ApplicationID", "to", "log", "Entry", "s", "+", "minor", "efficiency", "updates"], "add_tokens": "WG * sync . WaitGroup `json:\"-\"` ApplicationID string `json:\"appId\"` Level Level `json:\"level\"` Timestamp time . Time `json:\"timestamp\"` Message string `json:\"message\"` Fields [ ] Field `json:\"fields\"`", "del_tokens": "WG * sync . WaitGroup `json:\"-\"` Level Level `json:\"level\"` Timestamp time . Time `json:\"timestamp\"` Message string `json:\"message\"` Fields [ ] Field `json:\"fields\"` if entry . WG == nil { entry . WG = new ( sync . WaitGroup ) }", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "decimal", "and", "percent", "regexps"], "add_tokens": "decimal = regexp . MustCompile ( `^[0-9]+(.[0-9]+?)$` ) percent = regexp . MustCompile ( `^[0-9]+(.[0-9]+?)%$` )", "del_tokens": "decimal = regexp . MustCompile ( `^[0-9]+.[0-9]+$` ) percent = regexp . MustCompile ( `^[0-9]+.[0-9]+%$` )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "out", "-", "of", "-", "cluster", "flag"], "add_tokens": "provisioner = flag . String ( \" \" , \" \" , \" \" ) master = flag . String ( \" \" , \" \" , \" \" ) kubeconfig = flag . String ( \" \" , \" \" , \" \" ) runServer = flag . Bool ( \" \" , true , \" \" ) useGanesha = flag . Bool ( \" \" , true , \" \" ) if * master != \" \" || * kubeconfig != \" \" {", "del_tokens": "provisioner = flag . String ( \" \" , \" \" , \" \" ) outOfCluster = flag . Bool ( \" \" , false , \" \" ) master = flag . String ( \" \" , \" \" , \" \" ) kubeconfig = flag . String ( \" \" , \" \" , \" \" ) runServer = flag . Bool ( \" \" , true , \" \" ) useGanesha = flag . Bool ( \" \" , true , \" \" ) if * outOfCluster {", "commit_type": "remove"}
{"commit_tokens": ["fix", "handling", "of", "new", "streams", "on", "peer", "reconnects"], "add_tokens": "ch , ok := p . peers [ pid ] close ( ch ) ch , ok := p . peers [ pid ] if ok { close ( ch ) } func msgID ( pmsg * pb . Message ) string { return string ( pmsg . GetFrom ( ) ) + string ( pmsg . GetSeqno ( ) ) } id := msgID ( pmsg )", "del_tokens": "_ , ok := p . peers [ pid ] s . Close ( ) continue id := string ( pmsg . GetFrom ( ) ) + string ( pmsg . GetSeqno ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "resource", "numbering", "and", "remove", "public", "elements"], "add_tokens": "//id := <-newid coff . AddResource ( 16 , 1 , sizedReader { & v . Buffer } ) type gRPICONDIR struct { Entries [ ] gRPICONDIRENTRY func ( group gRPICONDIR ) Size ( ) int64 { type gRPICONDIRENTRY struct { group := gRPICONDIR { ICONDIR : ico . ICONDIR { group . Entries = append ( group . Entries , gRPICONDIRENTRY { icon . IconDirEntryCommon , id } )", "del_tokens": "id := <- newid coff . AddResource ( 16 , id , sizedReader { & v . Buffer } ) type GRPICONDIR struct { Entries [ ] GRPICONDIRENTRY func ( group GRPICONDIR ) Size ( ) int64 { type GRPICONDIRENTRY struct { group := GRPICONDIR { ICONDIR : ico . ICONDIR { group . Entries = append ( group . Entries , GRPICONDIRENTRY { icon . IconDirEntryCommon , id } )", "commit_type": "update"}
{"commit_tokens": ["Add", "convert", "func", "to", "format", "headers", "and", "methods", "of", "http"], "add_tokens": "type converter func ( string ) string exposeHeaders := convert ( normalize ( c . ExposeHeaders ) , http . CanonicalHeaderKey ) allowMethods := convert ( normalize ( c . AllowMethods ) , strings . ToUpper ) allowHeaders := convert ( normalize ( c . AllowHeaders ) , http . CanonicalHeaderKey ) // Always set Vary headers // see https://github.com/rs/cors/issues/10, // https://github.com/rs/cors/commit/dbdca4d95feaa7511a46e6f1efb3b3aa505bc43f#commitcomment-12352001 headers . Add ( \" \" , \" \" ) headers . Add ( \" \" , \" \" ) headers . Add ( \" \" , \" \" ) func convert ( s [ ] string , c converter ) [ ] string { var out [ ] string for _ , i := range s { out = append ( out , c ( i ) ) } return out }", "del_tokens": "exposeHeaders := normalize ( c . ExposeHeaders ) allowMethods := normalize ( c . AllowMethods ) allowHeaders := normalize ( c . AllowHeaders ) headers . Set ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "sign", "RPMs"], "add_tokens": "lead , err := readExact ( f , 96 ) return nil , fmt . Errorf ( \" \" , err . Error ( ) )", "del_tokens": "lead := make ( [ ] byte , 96 ) s , err := f . Read ( lead ) if s != 96 { return nil , fmt . Errorf ( \" \" , s ) } return nil , err", "commit_type": "add"}
{"commit_tokens": ["updated", "to", "one", "relationship", "test"], "add_tokens": "QueryFilters : [ ] Filter { // TODO: this should be automatically inferred somehow. { Param : \" \" , Field : \" \" } , } , var link string // create relating post link = obj . Path ( \" \" ) . Data ( ) . ( string ) } ) // get related post r . GET ( link ) . Run ( server , func ( r gofight . HTTPResponse , rq gofight . HTTPRequest ) { json , _ := gabs . ParseJSONBuffer ( r . Body ) obj := json . Path ( \" \" ) . Index ( 0 ) assert . Equal ( t , http . StatusOK , r . Code ) assert . Equal ( t , 1 , countChildren ( json . Path ( \" \" ) ) ) assert . Equal ( t , \" \" , obj . Path ( \" \" ) . Data ( ) . ( string ) ) assert . True ( t , bson . IsObjectIdHex ( obj . Path ( \" \" ) . Data ( ) . ( string ) ) ) assert . Equal ( t , \" \" , obj . Path ( \" \" ) . Data ( ) . ( string ) )", "del_tokens": "// create related comment", "commit_type": "update"}
{"commit_tokens": ["use", "net", ".", "ParseIP", "for", "IP", "format", "checking", "which", "supports", "all", "possible", "formats", "without", "the", "use", "of", "regular", "expressions"], "add_tokens": "\" \" return net . ParseIP ( str ) != nil ip := net . ParseIP ( str ) return ip != nil && ip . To4 ( ) != nil ip := net . ParseIP ( str ) return ip != nil && ip . To4 ( ) == nil", "del_tokens": "return IsIPv4 ( str ) || IsIPv6 ( str ) if ! rxIPv4 . MatchString ( str ) { return false } parts := strings . Split ( str , \" \" ) isIPv4 := true for i := 0 ; i < len ( parts ) ; i ++ { partI , _ := ToInt ( parts [ i ] ) isIPv4 = isIPv4 && ( ( partI >= 0 ) && ( partI <= 255 ) ) } return isIPv4 return rxIPv6 . MatchString ( str )", "commit_type": "use"}
{"commit_tokens": ["Add", "docs", "for", "EncodingCodec", "(", "s", ")"], "add_tokens": "//EncodingCodec implements marshaling and unmarshaling of seralized data. //JSONCodec is an EncodingCodec implementation to send/receieve JSON data //over AMQP. //GobCodec is an EncodingCodec implementation to send/recieve Gob data //over AMQP. type GobCodec struct { }", "del_tokens": "type GobCodec struct { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "CPUProfile", "comment"], "add_tokens": "// CPUProfile controls if cpu profiling will be enabled. It disables any previous profiling settings.", "del_tokens": "// CPUProfile controls if cpu profiling will be enabled. It disables an previous profiling settings.", "commit_type": "fix"}
{"commit_tokens": ["Add", "gccgo", "to", "generic", "build"], "add_tokens": "// +build 386 arm arm64 ppc64 ppc64le appengine gccgo", "del_tokens": "// +build 386 arm arm64 ppc64 ppc64le appengine", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "page", "for", "pre", "-", "generated", "User", "tokens", "to", "access", "backend"], "add_tokens": "Origin ( \" \" , func ( ) {", "del_tokens": "Origin ( \" \" , func ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "NewBlockFromReader", "and", "NewTxFromReader", "."], "add_tokens": "\" \" br := bytes . NewReader ( serializedBlock ) b , err := NewBlockFromReader ( br ) if err != nil { return nil , err } b . serializedBlock = serializedBlock return b , nil } // NewBlockFromReader returns a new instance of a bitcoin block given a // Reader to deserialize the block. See Block. func NewBlockFromReader ( r io . Reader ) ( * Block , error ) { err := msgBlock . Deserialize ( r ) msgBlock : & msgBlock , blockHeight : BlockHeightUnknown ,", "del_tokens": "br := bytes . NewReader ( serializedBlock ) err := msgBlock . Deserialize ( br ) msgBlock : & msgBlock , serializedBlock : serializedBlock , blockHeight : BlockHeightUnknown ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "deprecated", "TxShas", "func", "from", "btcutil", ".", "Block", "."], "add_tokens": "msgBlock * btcwire . MsgBlock // Underlying MsgBlock serializedBlock [ ] byte // Serialized bytes for the block blockSha * btcwire . ShaHash // Cached block hash blockHeight int64 // Height in the main block chain transactions [ ] * Tx // Transactions txnsGenerated bool // ALL wrapped transactions generated", "del_tokens": "msgBlock * btcwire . MsgBlock // Underlying MsgBlock serializedBlock [ ] byte // Serialized bytes for the block blockSha * btcwire . ShaHash // Cached block hash blockHeight int64 // Height in the main block chain txShas [ ] * btcwire . ShaHash // Cached transaction hashes txShasGenerated bool // ALL transaction hashes generated transactions [ ] * Tx // Transactions txnsGenerated bool // ALL wrapped transactions generated // TxShas returns a slice of hashes for all transactions in the Block. This is // equivalent to calling TxSha on each underlying btcwire.MsgTx, however it // caches the result so subsequent calls are more efficient. // // DEPRECATED - This function will be removed in the next version and // should not be used. Instead, use Transactions() and .Sha() on each // transaction. func ( b * Block ) TxShas ( ) ( [ ] * btcwire . ShaHash , error ) { // Return cached hashes if they have ALL already been generated. This // flag is necessary because the transaction hashes are lazily generated // in a sparse fashion. if b . txShasGenerated { return b . txShas , nil } // Generate slice to hold all of the transaction hashes if needed. if len ( b . txShas ) == 0 { b . txShas = make ( [ ] * btcwire . ShaHash , len ( b . msgBlock . Transactions ) ) } // Generate and cache the transaction hashes for all that haven't already // been done. for i , hash := range b . txShas { if hash == nil { // Ignore the errors since the only way these can fail // is if the index is out of range which is not possible // here due to the range. tx , _ := b . Tx ( i ) b . txShas [ i ] = tx . Sha ( ) } } b . txShasGenerated = true return b . txShas , nil }", "commit_type": "remove"}
{"commit_tokens": ["Add", "tests", "to", "connection", ".", "go"], "add_tokens": "var sendNativeRequest = func ( request * Request ) * Response { Timeout : time . Duration ( 60 ) * time . Second , logger . Infof ( \" \" , request . Method , request . URL , request . Parameters ) logger . Debugf ( \" \" , request . Method , request . URL , request . Parameters ) case ResponseCodeSuccess , ResponseCodeCreated , ResponseCodeEmpty : case ResponseCodeMultipleChoices : request . URL += \" \" return c . Start ( request )", "del_tokens": "\" \" TransactionID string func sendNativeRequest ( request * Request ) * Response { Timeout : time . Duration ( 60 ) * time . Millisecond , TransactionID : uuid . New ( ) , logger . Infof ( \" \" , request . Method , request . URL , request . Parameters , c . TransactionID ) logger . Debugf ( \" \" , response . Code , c . TransactionID ) case ResponseCodeMultipleChoices : request . URL += \" \" return c . Start ( request ) case ResponseCodeSuccess , ResponseCodeCreated : case ResponseCodeEmpty : return response , nil", "commit_type": "add"}
{"commit_tokens": ["add", "first", "error", "type", "modify", "factory", "method"], "add_tokens": "\" \" var ( // ErrorFull is returned when the amount requested to add exceeds the remaining space in the bucket. ErrorFull = errors . New ( \" \" ) ) // Create a bucket with a name, capacity, and rate. // rait is how long it takes for full capacity to drain. Create ( name string , capacity uint , rate time . Duration ) Bucket", "del_tokens": "Create ( string ) Bucket", "commit_type": "add"}
{"commit_tokens": ["Fix", "range", "description", "in", "comment"], "add_tokens": "// DoRange performs fn on all values stored in the tree over the interval [from, to) from left // DoRangeReverse performs fn on all values stored in the tree over the interval (to, from] from", "del_tokens": "// DoRange performs fn on all values stored in the tree over the interval [from, to] from left // DoRangeReverse performs fn on all values stored in the tree over the interval [to, from] from", "commit_type": "fix"}
{"commit_tokens": ["Make", "a", "test", "less", "environment", "-", "dependent"], "add_tokens": "Ω( l en( p ols) ) . S hould( B eNumerically( \" > , ) ) Ω( p ols[ 0 ] . N ame) . S houldNot( B eNil( ) ) Ω( p ols[ 1 ] . N ame) . S houldNot( B eNil( ) )", "del_tokens": "Ω( l en( p ols) ) . S hould( E qual( 2 ) ) Ω( p ols[ 0 ] . N ame) . S hould( E qual( \" w ) ) Ω( p ols[ 1 ] . N ame) . S hould( E qual( \" w ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "websocket", "proxying"], "add_tokens": "// because net.SplitHostPort errors if no port // lumber.Trace(\"[NANOBOX-ROUTER] Request Headers: '%+q'\", req.Header) // todo: maybe? or just check target's scheme lumber . Trace ( \" \" , req . URL ) if strings . ToLower ( req . Header . Get ( \" \" ) ) == \" \" { lumber . Trace ( \" \" ) ServeWS ( rw , req , proxy . reverseProxy ) } else { proxy . reverseProxy . ServeHTTP ( rw , req ) } lumber . Trace ( \" \" , host + path )", "del_tokens": "proxy . reverseProxy . ServeHTTP ( rw , req ) lumber . Trace ( \" \" , host + path )", "commit_type": "add"}
{"commit_tokens": ["Add", "code", "documentation", "and", "tests"], "add_tokens": "// Copyright 2014 Rafael Dantas Justo. All rights reserved. // Use of this source code is governed by a GPL // license that can be found in the LICENSE file. // redigomock is a mock for redigo library (redis client) // Cmd stores the registered information about a command to return it later when request by a // command execution Response interface { } // Response to send back when this command/arguments are called Err error // Error to send back when this command/arguments are called // Command register a command in the mock system using the same arguments of a Do or Send commands. // It will return a registered command object where you can set the response or error println ( \" \" + generateKey ( commandName , args ) ) var cmd Cmd // Expect sets a response for this command. Everytime a Do or Receive methods are executed for a // registered command this response or error will be returned. You cannot set a response and a error // for the same command/arguments // ExpectMap works in the same way of the Expect command, but has a key/value input to make it // easier to build test environments // ExpectError allows you to force an error when executing a command/arguments func ( c * Cmd ) ExpectError ( err error ) { // generateKey build an id for the command/arguments to make it easier to find in the registered // commands", "del_tokens": "CommandName string Args [ ] interface { } Response interface { } Err error cmd := Cmd { CommandName : commandName , Args : args , } func ( c * Cmd ) Error ( err error ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "linux", "tun", "driver", "should", "work"], "add_tokens": "dst . sin_family = AF_INET ; if ( ! inet_aton ( dstaddr , & dst . sin_addr ) ) { printf ( \" \\n \" , dstaddr ) ; close ( fd ) ; return - 1 ; } src . sin_family = AF_INET ; if ( ! inet_aton ( addr , & src . sin_addr ) ) { printf ( \" \\n \" , addr ) ; close ( fd ) ; return - 1 ; }", "del_tokens": "inet_aton ( dstaddr , & dst . sin_addr ) ; inet_aton ( addr , & src . sin_addr ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "code", "coverage", "for", "unit", "and", "integration", "tests"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Make", "gofmt", "and", "golint", "happy", "."], "add_tokens": "Name : line [ iWhitespace + 1 : ] , // RetrFrom issues a RETR FTP command to fetch the specified file from the remote // StorFrom issues a STOR FTP command to store a file to the remote FTP server.", "del_tokens": "Name : line [ iWhitespace + 1 : len ( line ) ] , // Retr issues a RETR FTP command to fetch the specified file from the remote // Stor issues a STOR FTP command to store a file to the remote FTP server.", "commit_type": "make"}
{"commit_tokens": ["add", "basic", "header", "to", "message", "protocol"], "add_tokens": "\" \" header := make ( [ ] byte , 4 ) // so max message size is 9999 bytes for now // read the content length header n , err := conn . Read ( header ) // calculate the content length th := bytes . TrimRight ( header , \" \" ) n , err = strconv . Atoi ( string ( th ) ) if err != nil || n == 0 { log . Fatalln ( \" \" , err ) break } log . Println ( \" \" , n ) // read the message content n , err = conn . Read ( msg ) if err != nil || n == 0 { log . Fatalln ( \" \" , err ) break }", "del_tokens": "buf := make ( [ ] byte , 4096 ) // same limit as Google Cloud Messaging for simplicity n , err := conn . Read ( buf ) copy ( msg , buf [ : n ] )", "commit_type": "add"}
{"commit_tokens": ["Adding", "peer", "manipulation", "util", "functions"], "add_tokens": "\" \" asyncNotifyCh ( ch ) } } // asyncNotifyCh is used to do an async channel send // to a singel channel without blocking. func asyncNotifyCh ( ch chan struct { } ) { select { case ch <- struct { } { } : default : } } // excludePeer is used to exclude a single peer from a list of peers func excludePeer ( peers [ ] net . Addr , peer net . Addr ) [ ] net . Addr { otherPeers := make ( [ ] net . Addr , 0 , len ( peers ) ) for _ , p := range peers { if p . String ( ) != peer . String ( ) { otherPeers = append ( otherPeers , p ) return otherPeers } // peerContained checks if a given peer is contained in a list func peerContained ( peers [ ] net . Addr , peer net . Addr ) bool { for _ , p := range peers { if p . String ( ) == peer . String ( ) { return true } } return false } // addUniquePeer is used to add a peer to a list of existing // peers only if it is not already contained func addUniquePeer ( peers [ ] net . Addr , peer net . Addr ) [ ] net . Addr { if peerContained ( peers , peer ) { return peers } else { return append ( peers , peer ) }", "del_tokens": "select { case ch <- struct { } { } : default :", "commit_type": "add"}
{"commit_tokens": ["use", "a", "custom", "sqlite3", "build", "tag", "to", "enable", "the", "driver"], "add_tokens": "// +build sqlite3,cgo", "del_tokens": "// +build cgo", "commit_type": "use"}
{"commit_tokens": ["add", "Warningf", "to", "complete", "dgraph", "-", "io", "/", "badger", ".", "Logger", "interface"], "add_tokens": "0.0 . 13 const Version = \" \"", "del_tokens": "0.0 . 12 const Version = \" \"", "commit_type": "add"}
{"commit_tokens": ["Removed", "bookmarks", "open", "and", "close"], "add_tokens": "err := b . Save ( \" \" , \" \" )", "del_tokens": "err := b . Open ( ) ut . AssertNil ( err ) err = b . Save ( \" \" , \" \" ) err = b . Close ( ) ut . AssertNil ( err )", "commit_type": "remove"}
{"commit_tokens": ["changed", "base", "64", "to", "hex"], "add_tokens": "// \"encoding/base64\" e . Data , err = hex . DecodeString ( j . Data )", "del_tokens": "\" \" e . Data , err = base64 . StdEncoding . DecodeString ( j . Data )", "commit_type": "change"}
{"commit_tokens": ["Allow", "var", "def", "to", "infer", "type", "from", "right", "-", "hand", "side", "."], "add_tokens": "var Block100000 = btcwire . MsgBlock {", "del_tokens": "var Block100000 btcwire . MsgBlock = btcwire . MsgBlock {", "commit_type": "allow"}
{"commit_tokens": ["fix", "a", "few", "race", "conditions", "and", "add", "in", "newlines", "to", "print", "statements"], "add_tokens": "return ( uint64 ( rand . Uint32 ( ) ) << 32 ) | uint64 ( rand . Uint32 ( ) ) u . DErr ( \" \\n \" , err . Error ( ) ) u . DOut ( \" \\n \" , key ) u . PErr ( \" \\n \" , dht . self . ID . Pretty ( ) , closer [ 0 ] . GetAddr ( ) ) u . DOut ( \" \\n \" , roundtrip . String ( ) )", "del_tokens": "//return (uint64(rand.Uint32()) << 32) & uint64(rand.Uint32()) return uint64 ( rand . Uint32 ( ) ) u . DErr ( err . Error ( ) ) u . DOut ( \" \" , key ) u . PErr ( \" \" , dht . self . ID . Pretty ( ) , closer [ 0 ] . GetAddr ( ) ) u . DOut ( \" \" , roundtrip . String ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Make", "Client", "validates", "server", "certificates", "."], "add_tokens": "pkey string skey string httpClient := & http . Client { Transport : transport } return & Client { httpClient , false , pkey , skey } , nil req . SetBasicAuth ( c . skey , \" \" ) req . SetBasicAuth ( c . pkey , \" \" )", "del_tokens": "PublicKey string SecretKey string return & Client { & http . Client { } , pkey , skey , false } , nil req . SetBasicAuth ( c . SecretKey , \" \" ) req . SetBasicAuth ( c . PublicKey , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Remove", "unnecesary", "field", "in", "constants"], "add_tokens": "return & ConstNodeBasicLit { * expr . ( * ast . BasicLit ) , v } return & ConstNodeBinaryExpr { * expr . ( * ast . BinaryExpr ) , v } return & ConstNodeIdent { * expr . ( * ast . Ident ) , v } return & ConstNodeUnaryExpr { * expr . ( * ast . UnaryExpr ) , v } return expr", "del_tokens": "node * ast . Node node * ast . Node node * ast . Node node * ast . Node return & ConstNodeBasicLit { * expr . ( * ast . BasicLit ) , v , & expr } return & ConstNodeBinaryExpr { * expr . ( * ast . BinaryExpr ) , v , & expr } return & ConstNodeIdent { * expr . ( * ast . Ident ) , v , & expr } return & ConstNodeUnaryExpr { * expr . ( * ast . UnaryExpr ) , v , & expr } return expr", "commit_type": "remove"}
{"commit_tokens": ["move", "the", "Register", "calls", "to", "the", "bottom"], "add_tokens": "func init ( ) { Register ( HostBBB , func ( rev int ) * Descriptor { return & Descriptor { GPIODriver : func ( ) GPIODriver { return newGPIODriver ( bbbPins , newDigitalPin , newBBBAnalogPin , newBBBPWMPin ) } , I2CDriver : newI2CDriver , LEDDriver : func ( ) LEDDriver { return newLEDDriver ( bbbLEDMap ) } , } } ) }", "del_tokens": "func init ( ) { Register ( HostBBB , func ( rev int ) * Descriptor { return & Descriptor { GPIODriver : func ( ) GPIODriver { return newGPIODriver ( bbbPins , newDigitalPin , newBBBAnalogPin , newBBBPWMPin ) } , I2CDriver : newI2CDriver , LEDDriver : func ( ) LEDDriver { return newLEDDriver ( bbbLEDMap ) } , } } ) }", "commit_type": "move"}
{"commit_tokens": ["Update", "example", "to", "support", "current", "interface"], "add_tokens": "helper . Tempfile = * optTempfile helper . Run ( )", "del_tokens": "\" \" if * optTempfile != \" \" { helper . Tempfile = * optTempfile } else { helper . Tempfile = fmt . Sprintf ( \" \" , * optHost , * optPort ) } if os . Getenv ( \" \" ) != \" \" { helper . OutputDefinitions ( ) } else { helper . OutputValues ( ) }", "commit_type": "update"}
{"commit_tokens": ["Add", "generate", "multisig", "script", "method"], "add_tokens": "var watchedHits uint32 watchedHits ++ if hits > 0 || watchedHits > 0 { if hits > 0 { ts . PopulateAdrs ( ) ts . db . Txns ( ) . Put ( tx ) }", "del_tokens": "if hits > 0 { ts . PopulateAdrs ( ) ts . db . Txns ( ) . Put ( tx )", "commit_type": "add"}
{"commit_tokens": ["Add", "documentation", "and", "tests", "for", "NaN", "values"], "add_tokens": "// format. NaN values are encoded as 'NaN' string.", "del_tokens": "// format.", "commit_type": "add"}
{"commit_tokens": ["Used", "protocol", "from", "addressable", "to", "build", "the", "url"], "add_tokens": "", "del_tokens": "// CHN: Should be added protocol from Addressable instead of include it the address param. // CHN: We will maintain this behaviour for compatibility with Java", "commit_type": "use"}
{"commit_tokens": ["fixes", "a", "bug", "parsing", "version", "numbers", "with", "a", "hyphen", "at", "the", "end"], "add_tokens": "versionNumber := strings . Split ( str , \" \" ) parts := strings . Split ( versionNumber [ 0 ] , \" \" )", "del_tokens": "parts := strings . Split ( str , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Update", "a", "bunch", "of", "comments"], "add_tokens": "// TODO: (Mayyyybe) Abstract changes/fills/rotations from polling or event based. I.e. have a rotate function that waits for a message on a rotateNow channel, have a fill buffer function that just waits for messages on the fillBufferNow channel, etc. This way the way the logic around filling of buffers is abstracted away from the choice of which strategy to use (polling vs inotify). // File is the container for all the logic around tailing a single file", "del_tokens": "// File needs a description // // TODO: (Mayyyybe) Abstract changes/fills/rotations from polling or event based. I.e. have a rotate function that waits for a message on a rotateNow channel, have a fill buffer function that just waits for messages on the fillBufferNOw channel, etc. This way the choice of polling vs event based is handled purely by the args (probably have them) spin up a goroutine that feeds those channels", "commit_type": "update"}
{"commit_tokens": ["Add", "missing", "Stop", "()", "to", "ExampleProfilePath"], "add_tokens": "defer profile . Start ( profile . ProfilePath ( os . Getenv ( \" \" ) ) ) . Stop ( )", "del_tokens": "defer profile . Start ( profile . ProfilePath ( os . Getenv ( \" \" ) ) )", "commit_type": "add"}
{"commit_tokens": ["add", "slice", "and", "map", "flags"], "add_tokens": "key , val := dashOne + arg [ 0 : 1 ] , args [ i ] [ 2 : ] // 2=len(\"-F\")", "del_tokens": "key , val := dashOne + arg [ 0 : 1 ] , arg [ 1 : ]", "commit_type": "add"}
{"commit_tokens": ["Add", "xml", "annotation", "to", "struct"], "add_tokens": "SubValues [ ] dictionaryList `xml:\"subValue\"`", "del_tokens": "SubValues [ ] dictionaryList", "commit_type": "add"}
{"commit_tokens": ["add", "test", "cases", "for", "logging", "empty", "string"], "add_tokens": "\" \" \" \" logger . Output ( time . Now ( ) , InfoLevel , \" \" ) assert . True ( strings . HasSuffix ( buf . String ( ) , \" \\n \" ) ) buf . Reset ( ) logger . Output ( time . Now ( ) , InfoLevel , \" \" ) assert . True ( strings . HasSuffix ( buf . String ( ) , \" \\n \" ) ) buf . Reset ( )", "del_tokens": "\" \" \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "documentation", "to", "point", "at", "new", "location", "."], "add_tokens": "// import _ \"github.com/jbuchbinder/gopnm\"", "del_tokens": "// import _ \"github.com/harrydb/go/img/pnm\"", "commit_type": "fix"}
{"commit_tokens": ["move", "account", "from", "zalando", "to", "personal", "account"], "add_tokens": "\" \" \" \"", "del_tokens": "\" \" \" \"", "commit_type": "move"}
{"commit_tokens": ["change", "%s", "to", "%v", "to", "fix", "stricter", "formatting", "in", "Go", "tip"], "add_tokens": "t . Fatalf ( \" \" , target , frame . Fields ( ) )", "del_tokens": "t . Fatalf ( \" \" , target , frame . Fields ( ) )", "commit_type": "change"}
{"commit_tokens": ["added", "support", "for", "partially", "length", "prefixed", "streams"], "add_tokens": "\" \" // partially length prefixed stream // http://msdn.microsoft.com/en-us/library/dd340469.aspx func readPLPType ( column * columnStruct , r io . Reader ) ( res [ ] byte , err error ) { var size uint64 err = binary . Read ( r , binary . LittleEndian , & size ) ; if err != nil { return } var buf * bytes . Buffer switch size { case 0xffffffffffffffff : // null return nil , nil case 0xfffffffffffffffe : // size unknown buf = bytes . NewBuffer ( make ( [ ] byte , 0 , 1000 ) ) default : buf = bytes . NewBuffer ( make ( [ ] byte , 0 , size ) ) } for true { var chunksize uint32 err = binary . Read ( r , binary . LittleEndian , & chunksize ) ; if err != nil { return } if chunksize == 0 { break } _ , err = io . CopyN ( buf , r , int64 ( chunksize ) ) ; if err != nil { return } } return buf . Bytes ( ) , nil } column . Reader = readPLPType", "del_tokens": "panic ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "sorting", "with", "same", "primary", "keys"], "add_tokens": "for i := 0 ; i < indirectValues . Len ( ) ; i ++ { for _ , primaryKey := range sortableCollection . PrimaryKeys { break", "del_tokens": "for _ , primaryKey := range sortableCollection . PrimaryKeys { for i := 0 ; i < indirectValues . Len ( ) ; i ++ {", "commit_type": "fix"}
{"commit_tokens": ["use", "glide", "to", "vendoring", "dependencies"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["use", "tab", "for", "logging", "and", "tracing"], "add_tokens": "\" \" \" \" ctx , span := tracing . StartSpanFromContext ( ctx , \" \" ) tab . For ( ctx ) . Debug ( fmt . Sprintf ( \" \" , audience , token . TokenType , token . Expiry ) ) tab . For ( ctx ) . Error ( err ) tab . For ( ctx ) . Debug ( fmt . Sprintf ( \" \" , res . Code , res . Description ) )", "del_tokens": "\" \" \" \" span , ctx := tracing . StartSpanFromContext ( ctx , \" \" ) log . For ( ctx ) . Debug ( fmt . Sprintf ( \" \" , audience , token . TokenType , token . Expiry ) ) log . For ( ctx ) . Error ( err ) log . For ( ctx ) . Debug ( fmt . Sprintf ( \" \" , res . Code , res . Description ) )", "commit_type": "use"}
{"commit_tokens": ["Implement", "RG", "/", "PG", "/", "CO", "line", "writes"], "add_tokens": "c . Check ( brr . Header ( ) , check . DeepEquals , br . Header ( ) ) c . Check ( brr . Header ( ) . RGs ( ) , check . DeepEquals , br . Header ( ) . RGs ( ) ) c . Check ( brr . Header ( ) . Progs ( ) , check . DeepEquals , br . Header ( ) . Progs ( ) )", "del_tokens": "// c.Check(brr.Header(), check.DeepEquals, br.Header()) // c.Check(brr.Header().RGs(), check.DeepEquals, br.Header().RGs()) // c.Check(brr.Header().Progs(), check.DeepEquals, br.Header().Progs())", "commit_type": "implement"}
{"commit_tokens": ["Fix", "golint", "error", "for", "unnecessary", "else", "block", "after", "return", "."], "add_tokens": "headerMap [ v ] = true", "del_tokens": "} else { headerMap [ v ] = true", "commit_type": "fix"}
{"commit_tokens": ["Use", "built", "-", "in", "copy"], "add_tokens": "copy ( c , other )", "del_tokens": "for i := 0 ; i < len ( c ) && i < len ( other ) ; i ++ { c [ i ] = other [ i ] }", "commit_type": "use"}
{"commit_tokens": ["Fix", "test", "broken", "by", "html2text", "change"], "add_tokens": "assert . Contains ( t , mime . Text , \" \" )", "del_tokens": "assert . Contains ( t , mime . Text , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["add", "fuzz", "testing", "and", "start", "fixing", "crashers", "found"], "add_tokens": "end = dec . cursor + 1 return dec . atoi64 ( start , end - 1 ) if start == end { dec . raiseInvalidJSONErr ( dec . cursor ) return 0 } return dec . atoi64 ( start , end - 1 )", "del_tokens": "end = dec . cursor return dec . atoi64 ( start , end ) return dec . atoi64 ( start , end )", "commit_type": "add"}
{"commit_tokens": ["use", "batching", "datastore", "for", "providers", "storage"], "add_tokens": "\" \" syncds \" \"", "del_tokens": "\" \" syncds \" \"", "commit_type": "use"}
{"commit_tokens": ["added", "pointer", "to", "referenced", "jsonschema", "if", "any"], "add_tokens": "refSchema * jsonSchema ref * gojsonreference . JsonReference schema * gojsonreference . JsonReference", "del_tokens": "ref * gojsonreference . JsonReference schema * gojsonreference . JsonReference", "commit_type": "add"}
{"commit_tokens": ["Fix", "data", "race", "add", "queuing", "of", "scheduled", "jobs"], "add_tokens": "now := fmt . Sprintf ( \" \" , timeFloat ( time . Now ( ) ) ) if _ , err = conn . Do ( \" \" , w . nsKey ( \" \" + parsedMsg . Queue ) , msgBytes ) ; err != nil { nextRetry := timeFloat ( time . Now ( ) ) + retryDelay ( job . RetryCount ) func timeFloat ( t time . Time ) float64 {", "del_tokens": "now := fmt . Sprintf ( \" \" , currentTimeFloat ( ) ) conn . Send ( \" \" ) conn . Send ( \" \" , w . nsKey ( \" \" ) , parsedMsg . Queue ) conn . Send ( \" \" , w . nsKey ( \" \" + parsedMsg . Queue ) , msgBytes ) _ , err = conn . Do ( \" \" ) if err != nil { nextRetry := currentTimeFloat ( ) + retryDelay ( job . RetryCount ) func currentTimeFloat ( ) float64 {", "commit_type": "fix"}
{"commit_tokens": ["changed", "bincontext", "to", "Set", "()", "to", "make", "the", "api", "more", "cleaner"], "add_tokens": "context : context . Background ( ) , // Set stores any value by key in the underlying context. A commom case to // use Set is to pass your database object safely trough each request. // Set is threadsafe and can be used concurently. To get the value in a handler // use the context's Get(key string) inteface{} function. func ( w * Weavebox ) Set ( key string , value interface { } ) { w . context = context . WithValue ( w . context , key , value )", "del_tokens": "// BindContext lets you provide a context that will live a full http roundtrip // BindContext is mostly used in a func main() to provide init variables that // may be created only once, like a database connection. If BindContext is not // called, weavebox will use a context.Background() func ( w * Weavebox ) BindContext ( ctx context . Context ) { w . context = ctx", "commit_type": "change"}
{"commit_tokens": ["Added", "ability", "to", "inject", "error", "msg", "into", "internal", "eventbus", "added", "better", "error", "handling", "added", "error", "tests", "."], "add_tokens": "log . Errorf ( \" \\n \" , err ) driver . messenger . Install ( driver . frameworkError , & mesosproto . FrameworkErrorMessage { } ) func ( driver * MesosExecutorDriver ) frameworkError ( from * upid . UPID , pbMsg proto . Message ) { log . Infoln ( \" \" ) msg := pbMsg . ( * mesosproto . FrameworkErrorMessage ) driver . exec . Error ( driver , msg . GetMessage ( ) ) } stat := driver . Stop ( )", "del_tokens": "msg := fmt . Sprintf ( \" \\n \" , err ) log . Errorf ( msg ) driver . exec . Error ( driver , msg )", "commit_type": "add"}
{"commit_tokens": ["Remove", "a", "few", "stale", "TODOs"], "add_tokens": "panic ( fmt . Sprintf ( \" \" , node ) )", "del_tokens": "// TODO(dcunnin): this // TODO(dcunnin): this // TODO(dcunnin): Need to handle bopPercent, bopManifestUnequal, bopManifestEqual panic ( \" \" ) // TODO(dcunnin): wrap in std local", "commit_type": "remove"}
{"commit_tokens": ["Fix", "error", "handling", "in", "Container", ".", "Id", "()"], "add_tokens": "if outErr == nil {", "del_tokens": "if err == nil {", "commit_type": "fix"}
{"commit_tokens": ["Add", "another", "Merge", "test", "."], "add_tokens": "// this uint64's big-endian murmur3 has rho > 31 const murmurRho32 uint64 = 3395916422 // both dense, but we need to be converted to 6 bits per register other . Add ( intToBytes ( murmurRho32 ) ) err = h . Merge ( other ) if err != nil { t . Fatal ( err ) } if e := estimateError ( h . Count ( ) , 150001 ) ; e > 0.01 { t . Errorf ( \" \" , h . Count ( ) , 150000 , e ) } if uint32 ( len ( h . data ) ) != 6 * h . m / 8 { t . Errorf ( \" \" ) } h . Add ( intToBytes ( murmurRho32 ) ) h . Add ( intToBytes ( murmurRho32 ) )", "del_tokens": "// this uint64's big-endian murmur3 has rho > 31 h . Add ( intToBytes ( 3395916422 ) ) h . Add ( intToBytes ( 3395916422 ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "info", "for", "docker", "events"], "add_tokens": "// ContainerEventType is the event type that containers generate ContainerEventType = \" \" // DaemonEventType is the event type that daemon generate DaemonEventType = \" \" // ImageEventType is the event type that images generate ImageEventType = \" \" // NetworkEventType is the event type that networks generate NetworkEventType = \" \" // PluginEventType is the event type that plugins generate PluginEventType = \" \" // VolumeEventType is the event type that volumes generate VolumeEventType = \" \" // Actor describes something that generates events, // like a container, or a network, or a volume. // It has a defined name and a set or attributes. // The container attributes are its labels, other actors // can generate these attributes from other properties. type Actor struct { ID string Attributes map [ string ] string } // Message represents the information an event contains // Deprecated information from JSONMessage. // With data only in container events. Status string `json:\"status,omitempty\"` ID string `json:\"id,omitempty\"` From string `json:\"from,omitempty\"` Type string Action string Actor Actor Time int64 `json:\"time,omitempty\"` TimeNano int64 `json:\"timeNano,omitempty\"` Node SwarmNode `json:\"node,omitempty\"` // type Event struct { // Id string `json:\"id\"` // Status string `json:\"status\"` // From string `json:\"from\"` // Time int64 `json:\"time\"` // Node SwarmNode `json:\"node,omitempty\"` // }", "del_tokens": "Id string `json:\"id\"` Status string `json:\"status\"` From string `json:\"from\"` Time int64 `json:\"time\"` Node SwarmNode `json:\"node,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Allow", "non", "-", "blocking", "device", "receiver", "with", "timeout", "and", "warning"], "add_tokens": "common . Log . Debugf ( \" \" , seq , d . id ) go func ( ) { var timeout <- chan time . Time if d . timeout == nil || * d . timeout == 0 { timeout = make ( <- chan time . Time ) } else { timeout = time . After ( * d . timeout ) } select { case res . ch <- pktResponse : case <- res . done : d . delSeq ( seq ) case <- timeout : common . Log . Warnf ( \" \" , seq , d . id ) } res . wg . Done ( ) } ( )", "del_tokens": "common . Log . Debugf ( \" \" , seq , d . id ) select { case res . ch <- pktResponse : case <- res . done : d . delSeq ( seq ) } res . wg . Done ( )", "commit_type": "allow"}
{"commit_tokens": ["Add", "some", "values", "to", "context", "sent", "to", "the", "upstream", "request", "to", "fix"], "add_tokens": "\" \" var ( contextKeysToPreserve = [ ] caddy . CtxKey { httpserver . OriginalURLCtxKey , httpserver . ReplacerCtxKey , httpserver . RemoteUserCtxKey , httpserver . MitmCtxKey , httpserver . RequestIDCtxKey , \" \" , \" \" , } ) updatedContext := context . Background ( ) // The problem of cloning the context is that the original one has some values used by // other middlewares. If those values are not present they break, #22 is an example. // However there isn't a way to know which values a context has. I took the ones that // I found on caddy code. If in a future there are new ones this might break. // In that case this will have to change to another way for _ , key := range contextKeysToPreserve { value := req . Context ( ) . Value ( key ) if value != nil { updatedContext = context . WithValue ( updatedContext , key , value ) } } updatedReq := req . WithContext ( updatedContext ) // Wait headers to be sent", "del_tokens": "updatedReq := req . WithContext ( context . Background ( ) ) // Wait headers to de sent", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "broken", "implementation", "of", "stringToSign", "."], "add_tokens": "\" \" // Grab the HTTP headers specifically called out by the signing algorithm. date , ok := r . Headers [ \" \" ] if ! ok { return \" \" , errors . New ( \" \" ) } contentMd5 := r . Headers [ \" \" ] contentType := r . Headers [ \" \" ] // We don't yet support CanonicalizedAmzHeaders. canonicalizedAmzHeaders := \" \" // We currently only support simple path-style requests. canonicalizedResource := r . Path // Put everything together. return fmt . Sprintf ( \" \\n \\n \\n \\n \" , r . Verb , contentMd5 , contentType , date , canonicalizedAmzHeaders , canonicalizedResource ) , nil", "del_tokens": "return \" \" , errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Updated", "generator", "to", "add", "policies", "to", "resources"], "add_tokens": "var ( // ResourcesThatSupportUpdatePolicies defines which CloudFormation resources support UpdatePolicies // see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html ResourcesThatSupportUpdatePolicies = [ ] string { \" \" , \" \" , } // ResourcesThatSupportCreationPolicies defines which CloudFormation resources support CreationPolicies // see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-creationpolicy.html ResourcesThatSupportCreationPolicies = [ ] string { \" \" , \" \" , \" \" , } ) // Check if this resource type allows specifying a CloudFormation UpdatePolicy hasUpdatePolicy := false for _ , res := range ResourcesThatSupportUpdatePolicies { if name == res { hasUpdatePolicy = true break } } // Check if this resource type allows specifying a CloudFormation CreationPolicy hasCreationPolicy := false for _ , res := range ResourcesThatSupportCreationPolicies { if name == res { hasCreationPolicy = true break } } Name string StructName string Basename string Resource Resource IsCustomProperty bool Version string HasUpdatePolicy bool HasCreationPolicy bool Name : name , StructName : sname , Basename : basename , Resource : resource , IsCustomProperty : isCustomProperty , Version : spec . ResourceSpecificationVersion , HasUpdatePolicy : hasUpdatePolicy , HasCreationPolicy : hasCreationPolicy ,", "del_tokens": "Name string StructName string Basename string Resource Resource IsCustomProperty bool Version string Name : name , StructName : sname , Basename : basename , Resource : resource , IsCustomProperty : isCustomProperty , Version : spec . ResourceSpecificationVersion ,", "commit_type": "update"}
{"commit_tokens": ["Update", "the", "api", "for", "updating", "node", "statuses", "."], "add_tokens": "UpdateNodeStatuses ( time . Duration , time . Duration )", "del_tokens": "UpdateNodeStatuses ( time . Duration )", "commit_type": "update"}
{"commit_tokens": ["Remove", "depenance", "on", "external", "libs", "for", "unique", "id"], "add_tokens": "IdGen = NewAutoIncId ( )", "del_tokens": "IdGen = NewObjectId ( )", "commit_type": "remove"}
{"commit_tokens": ["added", "test", "to", "compare", "result", "of", "Synthdef", "write", "to", "sclang", "-", "generated", "synth"], "add_tokens": "err = binary . Write ( w , byteOrder , int16 ( 1 ) ) fmt . Println ( \" \" , la , lb )", "del_tokens": "err = binary . Write ( w , byteOrder , int32 ( 1 ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "acme", ".", "Logger", "optional", ";", "otherwise", "use", "standard", "log", ".", "Logger"], "add_tokens": "t . Fatalf ( \" \" , expected , actual )", "del_tokens": "t . Fatal ( \" \" , expected , actual )", "commit_type": "make"}
{"commit_tokens": ["Remove", "dnspool", ":", "disable", "cgo", "to", "limit", "thread", "creation", "caused", "by", "DNS", "."], "add_tokens": "remote , err := net . Dial ( \" \" , host )", "del_tokens": "\" \" remote , err := dnspool . Dial ( host ) dnspool . SetGoroutineNumber ( dnsGoroutineNum )", "commit_type": "remove"}
{"commit_tokens": ["Allow", "to", "merge", "non", "-", "empty", "cells", "that", "are", "identical", "to", "the", "ones", "above", "."], "add_tokens": "\" \" border = flag . Bool ( \" \" , true , \" \" ) for _ , v := range os . Args {", "del_tokens": "\" \" border = flag . Bool ( \" \" , true , \" \" ) for _ , v := range os . Args {", "commit_type": "allow"}
{"commit_tokens": ["remove", "request", "&", "response", "please", "use", "context"], "add_tokens": "}", "del_tokens": "} type Responser interface { SetResponse ( ResponseWriter ) } type HttpResponser interface { SetResponse ( http . ResponseWriter ) } type Resp struct { ResponseWriter } func ( resp * Resp ) SetResponse ( r ResponseWriter ) { resp . ResponseWriter = r } func Responses ( ) HandlerFunc { return func ( ctx * Context ) { if action := ctx . Action ( ) ; action != nil { if s , ok := action . ( Responser ) ; ok { s . SetResponse ( ctx ) } } ctx . Next ( ) } }", "commit_type": "remove"}
{"commit_tokens": ["Changed", "link", "to", "sqlite3", "driver", "lib"], "add_tokens": "_ \" \"", "del_tokens": "_ \" \"", "commit_type": "change"}
{"commit_tokens": ["Add", "android", "support", "for", "proc", "filesystems"], "add_tokens": "// +build !go1.8,android !go1.8,linux !go1.8,netbsd !go1.8,solaris !go1.8,dragonfly case \" \" , \" \" :", "del_tokens": "// +build !go1.8,linux !go1.8,netbsd !go1.8,solaris !go1.8,dragonfly case \" \" :", "commit_type": "add"}
{"commit_tokens": ["add", "more", "tests", "and", "go", "doc"], "add_tokens": "// Set a Logger // Set a shared http.Client // Clear GoReq data for another new request only keep client and logger. //Set GET HttpMethod with a url. //Set POST HttpMethod with a url. //Set HEAD HttpMethod with a url. //Set PUT HttpMethod with a url. //Set DELETE HttpMethod with a url. //Set PATCH HttpMethod with a url. //Set headers with multiple fields. // for example: // New().Get(ts.URL). // SetHeaders(`{'Content-Type' = 'text/plain','X-Test-Tag'='test'}`). // End() //or // headers := struct { // ContentType string `json:\"Content-Type\"` // XTestTag string `json:\"X-Test-Tag\"` // } {ContentType:\"text/plain\",XTestTag:\"test\"} // // New().Get(ts.URL). // SetHeaders(headers). // End() \" \" : \" \" , //Set timeout for connections. // Set redirect policy. //", "del_tokens": "// Clear GoReq data for another new request. //set headers with multiple fields. \" \" : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Move", "app", "package", "to", "the", "top", "level"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["Add", "rethink", "package", ".", "Formatting", "on", "handyfile", "/", "file", ".", "go", "."], "add_tokens": "}", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["add", "Host", "as", "an", "option", "to", "the", "App"], "add_tokens": "{ { . | downcase } } . New ( os . Getenv ( \" \" ) , os . Getenv ( \" \" ) , fmt . Sprintf ( \" \" , App ( ) . Host , \" \" ) ) ,", "del_tokens": "{ { . | downcase } } . New ( os . Getenv ( \" \" ) , os . Getenv ( \" \" ) , fmt . Sprintf ( \" \" , HOST , \" \" ) ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "change", "checker", "service", "for", "IsModified", "etc", "and", "also", "added", "cascade", "support", "although", "didn", "t", "yet", "implement", "it", "in", "the", "save", "flow"], "add_tokens": "GetCascade ( ) [ ] * CascadeConfig toCascade := conv . GetCascade ( ) update1 := map [ string ] map [ string ] interface { } { \" \" : map [ string ] interface { } { } , } update1 [ \" \" ] [ conf . ThroughProp ] = bson . M { \" \" : id ,", "del_tokens": "GetCascade ( map [ string ] interface { } ) [ ] * CascadeConfig toCascade := conv . GetCascade ( preparedForSave ) log . Println ( \" \" ) // Remove self from previous relations update1 := map [ string ] interface { } { \" \" : map [ string ] interface { } { \" \" : id , } ,", "commit_type": "add"}
{"commit_tokens": ["add", "consts", "for", "EventType", "and", "DecisionType"], "add_tokens": "DecisionType : DecisionTypeScheduleActivityTask , func ( d * DecisionWorker ) StartChildWorkflowExecutionDecision ( workflowType string , workflowVersion string , childPolicy string , taskList string , tags [ ] string , input interface { } ) ( * Decision , error ) { DecisionType : DecisionTypeStartChildWorkflowExecution , DecisionType : DecisionTypeRecordMarker , DecisionType : DecisionTypeCompleteWorkflowExecution ,", "del_tokens": "DecisionType : \" \" , func ( d * DecisionWorker ) StartChildWorkflowExecutionDecision ( workflowType string , workflowVersion string , childPolicy string , taskList string , tags [ ] string , input string ) ( * Decision , error ) { DecisionType : \" \" , DecisionType : \" \" , DecisionType : \" \" ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "duplicate", "config", "sample", "in", "testdata", "."], "add_tokens": "config , err := ParseConfig ( \" \" ) config , err := ParseConfig ( \" \" )", "del_tokens": "config , err := ParseConfig ( \" \" ) config , err := ParseConfig ( \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "Marshall", "of", "CommandResponse", "struct"], "add_tokens": "res := struct { Id * bson . ObjectId `json:\"id\"` Name * string `json:\"name\"` AdminState AdminState `json:\"adminState\"` OperatingState OperatingState `json:\"operatingState\"` LastConnected int64 `json:\"lastConnected\"` LastReported int64 `json:\"lastReported\"` Labels [ ] string `json:\"labels\"` Location interface { } `json:\"location\"` Commands [ ] Command `json:\"commands\"` } { res . Id = & cr . Id res . Name = & cr . Name return json . Marshal ( res )", "del_tokens": "test := CommandResponse { test . Id = cr . Id test . Name = cr . Name return json . Marshal ( test )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// NewClientWithCustomTimeout returns a new Bittrex HTTP client with custom timeout", "del_tokens": "// NewClient returns a new Bittrex HTTP client with custom timeout", "commit_type": "fix"}
{"commit_tokens": ["Add", "string", "comparison", "operators", ".", "Reinstate", "some", "of", "the", "binary", "operations", "tests", "that", "still", "work", "."], "add_tokens": "var b bool is_bool := false case token . ADD : r = xx + yy case token . EQL : b = xx == yy ; is_bool = true case token . NEQ : b = xx != yy ; is_bool = true case token . LEQ : b = xx <= yy ; is_bool = true case token . GEQ : b = xx >= yy ; is_bool = true case token . LSS : b = xx < yy ; is_bool = true case token . GTR : b = xx > yy ; is_bool = true if is_bool { return reflect . ValueOf ( b ) , err } else { return reflect . ValueOf ( r ) . Convert ( x . Type ( ) ) , err }", "del_tokens": "case token . ADD : r = xx + yy return reflect . ValueOf ( r ) . Convert ( x . Type ( ) ) , err", "commit_type": "add"}
{"commit_tokens": ["Using", "elevate", "for", "certificate", "installation", "on", "OS", "X"], "add_tokens": "\" \" cmd := elevate . WithPrompt ( \" \" ) . Command ( \" \" , \" \" , \" \" , \" \" , OSX_SYSTEM_KEYCHAIN_PATH , tempFileName )", "del_tokens": "cmd := exec . Command ( \" \" , \" \" , \" \" , \" \" , OSX_SYSTEM_KEYCHAIN_PATH , tempFileName )", "commit_type": "use"}
{"commit_tokens": ["Add", "a", "PurgeVistitorFunc", "that", "is", "called", "on", "every", "key", "during", "a", "Purge", "()"], "add_tokens": "numbers := cacheSize + 1 func TestARCPurgeCache ( t * testing . T ) { cacheSize := 10 purgeCount := 0 gc := New ( cacheSize ) . ARC ( ) . LoaderFunc ( loader ) . PurgeVisitorFunc ( func ( k , v interface { } ) { purgeCount ++ } ) . Build ( ) for i := 0 ; i < cacheSize ; i ++ { _ , err := gc . Get ( fmt . Sprintf ( \" \" , i ) ) if err != nil { t . Errorf ( \" \" , err ) } } gc . Purge ( ) if purgeCount != cacheSize { t . Errorf ( \" \" ) } }", "del_tokens": "numbers := 11", "commit_type": "add"}
{"commit_tokens": ["Fix", "and", "add", "a", "test", "for", "a", "race", "in", "the", "buffered", "client"], "add_tokens": "stop chan struct { } client . stop = make ( chan struct { } , 1 ) ticker := time . NewTicker ( c . flushTime ) for { select { case <- ticker . C : c . Lock ( ) if len ( c . commands ) > 0 { // FIXME: eating error here c . flush ( ) } c . Unlock ( ) case <- c . stop : ticker . Stop ( ) select { case c . stop <- struct { } { } : default : }", "del_tokens": "stop bool for _ = range time . Tick ( c . flushTime ) { if c . stop { c . Lock ( ) if len ( c . commands ) > 0 { // FIXME: eating error here c . flush ( ) } c . Unlock ( ) c . stop = true", "commit_type": "fix"}
{"commit_tokens": ["Add", "bunt", "db", "testing", "."], "add_tokens": "conf . Stat . BoltDB . Path = \" \" conf . Stat . BuntDB . Path = \" \" conf . Stat . LevelDB . Path = \" \"", "del_tokens": "conf . Stat . BoltDB . Path = \" \" conf . Stat . BuntDB . Path = \" \" conf . Stat . LevelDB . Path = \" \"", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "nil", "as", "a", "builtin", "value"], "add_tokens": "if value , ok = p . ReadBuiltin ( ) ; ok == false { func ( p * Parser ) ReadBuiltin ( ) ( Value , bool ) { if p . ConsumeIf ( [ ] byte ( \" \" ) ) { return nilValue , true }", "del_tokens": "if value , ok = p . ReadBoolean ( ) ; ok == false { func ( p * Parser ) ReadBoolean ( ) ( Value , bool ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "with", "City", "Lite", "database", "support"], "add_tokens": "if gi . dbType == dbCityEditionRev0 || gi . dbType == dbCityEditionRev1 { if gi . dbType != dbCountryEdition && gi . dbType != dbCityEditionRev0 && gi . dbType != dbCityEditionRev1 {", "del_tokens": "if gi . dbType == dbCityEditionRev0 || gi . dbType == dbCityEditionRev0 { if gi . dbType != dbCountryEdition && gi . dbType != dbCityEditionRev0 && gi . dbType != dbCityEditionRev0 {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "getv", "with", "empty", "default", "value"], "add_tokens": "if len ( v ) > 0 { // Take default return v [ 0 ] , nil", "del_tokens": "defaultValue := \" \" if len ( v ) > 0 { defaultValue = v [ 0 ] } if defaultValue != \" \" { return defaultValue , nil", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "directory", "-", ">", "directories"], "add_tokens": "// then contains version directories which in turn contains all the files", "del_tokens": "// then contains version directory which in turn contains all the files", "commit_type": "fix"}
{"commit_tokens": ["Implement", "packet", "sending", "in", "a", "goroutine"], "add_tokens": "// The maximum number of packets that will be buffered waiting to be delivered. // Packets will be dropped if the buffer is full. var MaxQueueBuffer = 100 client := & Client { Transport : & HTTPTransport { } , Tags : tags , queue : make ( chan * Packet , MaxQueueBuffer ) } go client . worker ( ) Transport Transport ErrorHandler func ( * Packet , error ) DropHandler func ( * Packet ) queue chan * Packet func ( client * Client ) worker ( ) { for packet := range client . queue { err := client . Send ( packet ) if err != nil && client . ErrorHandler != nil { client . ErrorHandler ( packet , err ) } } } func ( client * Client ) Report ( packet * Packet ) { select { case client . queue <- packet : default : // send would block, drop the packet if client . DropHandler != nil { client . DropHandler ( packet ) } } } func ( client * Client ) Close ( ) { close ( client . queue ) }", "del_tokens": "client := & Client { Transport : & HTTPTransport { } , Tags : tags } Transport Transport", "commit_type": "implement"}
{"commit_tokens": ["Change", "function", "name", "to", "GetPasswd"], "add_tokens": "// Returns password byte array read from terminal without input being echoed. // Array of bytes does not include end-of-line characters. func GetPasswd ( ) [ ] byte { if v == 127 || v == 8 { if len ( pass ) > 0 { pass = pass [ : len ( pass ) - 1 ] } } else if v == 13 || v == 10 { break } else { pass = append ( pass , v ) }", "del_tokens": "func GetPass ( ) [ ] byte { if v == 127 || v == 8 { if len ( pass ) > 0 { pass = pass [ : len ( pass ) - 1 ] } } else if v == 13 || v == 10 { break } else { pass = append ( pass , v ) }", "commit_type": "change"}
{"commit_tokens": ["Use", "the", "info", "struct", "which", "was", "already", "defined"], "add_tokens": "Info Info `json:\"info\"`", "del_tokens": "Info struct { StatusCode int `json:\"statuscode\"` Copyright struct { Text string `json:\"text\"` ImageUrl string `json:\"imageUrl\"` ImageAltText string `json:\"imageAltText\"` } `json:\"copyright\"` } `json:\"info\"`", "commit_type": "use"}
{"commit_tokens": ["Updated", "the", "year", "on", "license", "."], "add_tokens": "// Copyright 2013 commandmocker authors. All rights reserved.", "del_tokens": "// Copyright 2012 commandmocker authors. All rights reserved.", "commit_type": "update"}
{"commit_tokens": ["Fixed", "an", "indexing", "problem", "with", "influx", "client", "data", "received", ".", "Truncated", "data", "in", "anomalyzer", "."], "add_tokens": "//Updated: initialtime, Function : function , var index int // this query outputs the columns: [time value] index = 1 // this query outputs the columns : [time squequenc_number value] index = 2 val = points [ i ] [ index ] . ( json . Number )", "del_tokens": "// validate duration //duration, err := validateDuration(granularity) //if err != nil { // return InfluxAnomalyClient{}, err //} Updated : time . Now ( ) , Function : function , fmt . Printf ( \" \\n \" , query ) val = points [ i ] [ 1 ] . ( json . Number ) // get rid of old data var newArray [ ] float64 c . Anomalyzer . Data = newArray", "commit_type": "fix"}
{"commit_tokens": ["Fix", "detection", "of", "trace", "enabling"], "add_tokens": "trace := os . Getenv ( fmt . Sprintf ( \" \" , key ) )", "del_tokens": "trace := os . Getenv ( fmt . Sprintf ( \" \" , key ) ) if trace == \" \" || strings . ToLower ( trace ) == \" \" { tracer . enabled = false } if ! tracer . enabled && ! tracer . performance { return tracer }", "commit_type": "fix"}
{"commit_tokens": ["add", "sorting", "to", "iso", "os", "regions", "reservedip", "scripts"], "add_tokens": "\" \" type ips [ ] IP func ( s ips ) Len ( ) int { return len ( s ) } func ( s ips ) Swap ( i , j int ) { s [ i ] , s [ j ] = s [ j ] , s [ i ] } func ( s ips ) Less ( i , j int ) bool { // sort order: label, iptype, subnet if s [ i ] . Label < s [ j ] . Label { return true } else if s [ i ] . Label > s [ j ] . Label { return false } if s [ i ] . IPType < s [ j ] . IPType { return true } else if s [ i ] . IPType > s [ j ] . IPType { return false } return s [ i ] . Subnet < s [ j ] . Subnet } ipList := make ( [ ] IP , 0 ) ipList = append ( ipList , ip ) sort . Sort ( ips ( ipList ) ) return ipList , nil", "del_tokens": "ips := make ( [ ] IP , 0 ) ips = append ( ips , ip ) return ips , nil", "commit_type": "add"}
{"commit_tokens": ["moving", "to", "use", "map", "key", "/", "values"], "add_tokens": "for _ , k := range rv . Index ( i ) . MapKeys ( ) { label := k . Interface ( ) . ( string ) so = append ( so , SelectOption { Value : m [ label ] , Label : label } ) }", "del_tokens": "so = append ( so , SelectOption { Value : m [ \" \" ] , Label : m [ \" \" ] } )", "commit_type": "move"}
{"commit_tokens": ["add", "tests", "for", "canary", "flag", "reading"], "add_tokens": "\" \" test . expectedLog [ \" \" ] = false func TestMiddlewareCanaryFlag ( t * testing . T ) { os . Setenv ( \" \" , \" \" ) defer os . Unsetenv ( \" \" ) assert := assert . New ( t ) lggr := logger . New ( \" \" ) out := & bytes . Buffer { } lggr . SetConfig ( \" \" , logger . Info , kv . Format , out ) handler := New ( http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { } ) , lggr ) rw := & bufferWriter { } handler . ServeHTTP ( rw , & http . Request { Method : \" \" , URL : & url . URL { Host : \" \" , Path : \" \" , } , } ) var result map [ string ] interface { } assert . Nil ( json . NewDecoder ( out ) . Decode ( & result ) ) log . Printf ( \" \" , result ) assert . Equal ( true , result [ \" \" ] ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "Client", ".", "ListAll", "()"], "add_tokens": "// List returns entries in dir `name`. Up to `n` entries, or all when `n` <= 0. func ( c * Client ) List ( name string , n int ) ( ents [ ] os . FileInfo , err error ) { // ListAll returns all entries in dir `name`. func ( c * Client ) ListAll ( name string ) ( [ ] os . FileInfo , error ) { return c . List ( name , 0 ) }", "del_tokens": "// ListCount lists entries in dir `name`. Up to `n` entries, or all when `n` <= 0. func ( c * Client ) ListCount ( name string , n int ) ( ents [ ] os . FileInfo , err error ) {", "commit_type": "add"}
{"commit_tokens": ["added", "httpTimeout", "field", "to", "client", "struct"], "add_tokens": "apiKey string apiSecret string httpClient * http . Client httpTimeout time . Duration return & client { apiKey , apiSecret , & http . Client { } , 30 * time . Second } timeout := httpClient . Timeout return & client { apiKey , apiSecret , httpClient , timeout } connectTimer := time . NewTimer ( c . httpTimeout )", "del_tokens": "apiKey string apiSecret string httpClient * http . Client return & client { apiKey , apiSecret , & http . Client { } } return & client { apiKey , apiSecret , httpClient } connectTimer := time . NewTimer ( DEFAULT_HTTPCLIENT_TIMEOUT * time . Second )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "case", "sensitivity", "bug", "with", "override", "values"], "add_tokens": "fmt . Println ( \" \" ) pretty . Println ( aliases )", "del_tokens": "key = strings . ToLower ( key )", "commit_type": "fix"}
{"commit_tokens": ["Add", "deployment", "migration", "data", "type", "."], "add_tokens": "type MigrationStatus struct { CompletedDataMigrationCycles int `json:\"completedDataMigrationCycles\"` DataMigrationCycleProgress int `json:\"dataMigrationCycleProgress\"` DataMigrationCycleSize int `json:\"dataMigrationCycleSize\"` VibsUploaded int `json:\"vibsUploaded\"` VibsUploading int `json:\"vibsUploading\"` } NTPEndpoint string `json:\"ntpEndpoint,omitempty\"` UseImageDatastoreForVms bool `json:\"useImageDatastoreForVms,omitempty\"` Auth * AuthInfo `json:\"auth\"` Kind string `json:\"kind\"` SyslogEndpoint string `json:\"syslogEndpoint,omitempty\"` Stats * StatsInfo `json:\"stats,omitempty\"` State string `json:\"state\"` ID string `json:\"id\"` ImageDatastores [ ] string `json:\"imageDatastores\"` SelfLink string `json:\"selfLink\"` Migration * MigrationStatus `json:\"migrationStatus,omitempty\"`", "del_tokens": "NTPEndpoint string `json:\"ntpEndpoint,omitempty\"` UseImageDatastoreForVms bool `json:\"useImageDatastoreForVms,omitempty\"` Auth * AuthInfo `json:\"auth\"` Kind string `json:\"kind\"` SyslogEndpoint string `json:\"syslogEndpoint,omitempty\"` Stats * StatsInfo `json:\"stats,omitempty\"` State string `json:\"state\"` ID string `json:\"id\"` ImageDatastores [ ] string `json:\"imageDatastores\"` SelfLink string `json:\"selfLink\"`", "commit_type": "add"}
{"commit_tokens": ["update", "TH", "calendar", "test", "case"], "add_tokens": "Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \"", "del_tokens": "Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \" Equal ( t , dt , \"", "commit_type": "update"}
{"commit_tokens": ["fix", "data", "race", "in", "test"], "add_tokens": "wg . Add ( 1 )", "del_tokens": "wg . Add ( 1 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "newlines", "at", "the", "end", "of", "help", "text"], "add_tokens": "{ { if len . Short } } - { { index . Short 0 } } , { { end } } { { if len . Long } } -- { { index . Long 0 } } { { end } } { { . Description } } { { if . Obligatory } } ( * ) { { end } } { { end } } { { end } } { { end } } `", "del_tokens": "{ { if len . Short } } - { { index . Short 0 } } , { { end } } { { if len . Long } } -- { { index . Long 0 } } { { end } } { { . Description } } { { if . Obligatory } } ( * ) { { end } } { { end } } { { end } } { { end } } `", "commit_type": "add"}
{"commit_tokens": ["Make", "target", "heating", "cooling", "mode", "writeable"], "add_tokens": "return NewHeatingCoolingMode ( current , CharTypeHeatingCoolingModeTarget , PermsAll ( ) )", "del_tokens": "return NewHeatingCoolingMode ( current , CharTypeHeatingCoolingModeTarget , PermsRead ( ) )", "commit_type": "make"}
{"commit_tokens": ["implemented", "barrier", "for", "fetcher", "threads", "synchronization"], "add_tokens": "callback func ( ) func NewBarrier ( size int32 , callback func ( ) ) * Barrier { barrier . callback = callback if b . size == 0 { if b . size != 0 { for b . size != 0 { } ) b . barrierReachedCond . Broadcast ( ) b . callback ( ) } func ( b * Barrier ) reset ( size int32 ) { inLock ( & b . barrierReachedLock , func ( ) { if b . size != 0 { panic ( \" \" ) } b . size = size", "del_tokens": "broken bool func NewBarrier ( size int32 ) * Barrier { if b . broken { if b . size > 0 { for b . size > 0 { b . broken = true b . barrierReachedCond . Broadcast ( )", "commit_type": "implement"}
{"commit_tokens": ["Use", "the", "Config", "struct", "to", "configure", "the", "pass", "backend"], "add_tokens": "pass := & passKeyring { passcmd : cfg . PassCmd , dir : cfg . PassDir , prefix : cfg . PassPrefix , } if cfg . PassCmd == \" \" { pass . passcmd = \" \" } if cfg . PassDir == \" \" { pass . dir = filepath . Join ( os . Getenv ( \" \" ) , \" \" ) } return pass , nil", "del_tokens": "return & passKeyring { prefix : \" \" , } , nil", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "new", "HTTP", "Method", "aware", "Trie"], "add_tokens": "routes = append ( routes , Route { HttpMethod : \" \" , PathExp : path , } ) r . findRouteFromURL ( \" \" , urlObj ) r . findRouteFromURL ( \" \" , urlObj )", "del_tokens": "routes = append ( routes , Route { PathExp : path } ) r . findRouteFromURL ( urlObj ) r . findRouteFromURL ( urlObj )", "commit_type": "use"}
{"commit_tokens": ["Remove", "auto", "-", "encoding", "from", "building", "a", "data", "message", "."], "add_tokens": "func InitDataRow ( m * Message , encodedData [ ] [ ] byte ) { dataSize := 0 for _ , colVal := range encodedData { dataSize += len ( colVal ) } msgBytes := make ( [ ] byte , 0 , 2 + dataSize ) colCount := int16 ( len ( encodedData ) ) for _ , colVal := range encodedData { buf . Write ( colVal )", "del_tokens": "// InitDataRow initializes the Message m as a DataRow message with // data from the value array cols. func InitDataRow ( m * Message , cols [ ] interface { } ) { msgBytes := make ( [ ] byte , 0 , 2 + len ( cols ) * 4 ) colCount := int16 ( len ( cols ) ) for _ , val := range cols { // TODO: allow format specification encodeValue ( buf , val , ENC_FMT_TEXT )", "commit_type": "remove"}
{"commit_tokens": ["fix", "validator", "bug", "for", "validating", "email", ";", "add", "max", "length", "of", "packet"], "add_tokens": "func NewSet ( ) * ValidatorList { set := ValidatorList ( make ( [ ] Validator , 0 ) ) return & set }", "del_tokens": "\" \" var emailRegexp = regexp . MustCompilePOSIX ( \" \\\\ \\\\ \\\\ \" ) func IsValidEmail ( email string ) bool { return emailRegexp . MatchString ( email ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "logger", "to", "client", "/", "worker", "."], "add_tokens": "import ( \" \" \" \" ) func newBufferedWorker ( ) BufferedWorker { worker := BufferedWorker { ch : make ( chan Envelope , 100 ) } for w := range worker . ch { worker . log . Printf ( \" \\n \" , err ) worker . log . Printf ( \" \\n \" , err ) type BufferedWorker struct { ch chan Envelope log * log . Logger } func ( w BufferedWorker ) Push ( work Envelope ) error { case w . ch <- work : func ( w BufferedWorker ) Flush ( ) error { w . ch <- func ( ) error {", "del_tokens": "import \" \" func newBufferedWorker ( ) Worker { worker := make ( BufferedWorker , 100 ) for w := range worker { fmt . Printf ( \" \\n \" , err ) fmt . Printf ( \" \\n \" , err ) type BufferedWorker chan Envelope func ( worker BufferedWorker ) Push ( work Envelope ) error { case worker <- work : func ( worker BufferedWorker ) Flush ( ) error { worker <- func ( ) error {", "commit_type": "add"}
{"commit_tokens": ["Created", "/", "Modified", "now", "get", "set", "on", "model", "as", "well", "as", "modelMap", "if", "they", "are", "valid", "fields"], "add_tokens": "// Add created/modified time. Also set on the model itself if it has those fields. now := time . Now ( ) if has , _ := reflections . HasField ( mod , \" \" ) ; has { reflections . SetField ( mod , \" \" , now ) } modelMap [ \" \" ] = now } if has , _ := reflections . HasField ( mod , \" \" ) ; has { reflections . SetField ( mod , \" \" , now ) // col := c.Collection()", "del_tokens": "// Add created/modified time modelMap [ \" \" ] = time . Now ( ) // sess := c.Connection.Session.Copy()", "commit_type": "create"}
{"commit_tokens": ["Update", "the", "index", "in", "case", "we", "got", "a", "new", "version", "but", "the", "data", "is", "the", "same"], "add_tokens": "// Update the index in case we got a new version, but the data is the same view . LastIndex = qm . LastIndex", "del_tokens": "view . LastIndex = qm . LastIndex", "commit_type": "update"}
{"commit_tokens": ["allow", "peers", "to", "realize", "that", "they", "are", "actually", "a", "provider", "for", "a", "value"], "add_tokens": "\" \" dht . providers = NewProviderManager ( p . ID ) has , err := dht . datastore . Has ( ds . NewKey ( pmes . GetKey ( ) ) ) if err != nil { dht . netChan . Errors <- err } if has { providers = append ( providers , dht . self ) } func ( dht * IpfsDHT ) loadProvidableKeys ( ) error { kl := dht . datastore . KeyList ( ) for _ , k := range kl { dht . providers . AddProvider ( u . Key ( k . Bytes ( ) ) , dht . self ) } return nil } // Builds up list of peers by requesting random peer IDs func ( dht * IpfsDHT ) Bootstrap ( ) { id := make ( [ ] byte , 16 ) rand . Read ( id ) dht . FindPeer ( peer . ID ( id ) , time . Second * 10 ) }", "del_tokens": "dht . providers = NewProviderManager ( )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "enable", "and", "disable", "urls", "for", "contact", "go", "sdk", "request"], "add_tokens": "resp , err := cli . sendRequest ( cli . buildPostRequest ( contactURL + \" \" , req ) ) resp , err := cli . sendRequest ( cli . buildPostRequest ( contactURL + \" \" , req ) )", "del_tokens": "resp , err := cli . sendRequest ( cli . buildPostRequest ( contactURL , req ) ) resp , err := cli . sendRequest ( cli . buildPostRequest ( contactURL , req ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "template", ".", "Rendered", "()"], "add_tokens": "// ConfigTemplate is the representation of an input template, output location, // and optional command to execute when rendered", "del_tokens": "// ConfigTemplate is the representation of an input template, output location, and // optional command to execute when rendered", "commit_type": "remove"}
{"commit_tokens": ["Add", "color", "to", "warnings", "errors", "and", "protip", "logging"], "add_tokens": "const ERROR = \" \\033 \\033 \" const WARNING = \" \\033 \\033 \" const PROTIP = \" \\033 \\033 \" Expect ( buf . String ( ) ) . To ( ContainSubstring ( ERROR + \" \" ) ) patchWarning := WARNING + \" \" + const warning = WARNING + \" \" const warning = WARNING + \" \"", "del_tokens": "Expect ( buf . String ( ) ) . To ( ContainSubstring ( \" \" ) ) patchWarning := \" \" + const warning = \" \" const warning = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fixing", "chromedp", "-", "gen", "and", "updating", "protocol", ".", "json"], "add_tokens": "func setup ( ) { types := map [ string ] bool { } if * internal . FlagRedirect { types [ \" \" ] = true types [ \" \" ] = true types [ \" \" ] = true } // set the cdp types internal . SetCDPTypes ( types ) // set up the internal types setup ( ) \" \" : \" \" , \" \" : \" \" ,", "del_tokens": "func init ( ) { // set the internal types internal . SetCDPTypes ( map [ string ] bool { } )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "volume", "root", "injection", "."], "add_tokens": "handler VolumeDriver mux * http . ServeMux h := & VolumeHandler { handler , http . NewServeMux ( ) }", "del_tokens": "Root string `json:\",omitempty\"` rootDirectory string handler VolumeDriver mux * http . ServeMux return NewVolumeHandlerWithRoot ( DefaultDockerRootDirectory , handler ) } func NewVolumeHandlerWithRoot ( rootDirectory string , handler VolumeDriver ) * VolumeHandler { h := & VolumeHandler { rootDirectory , handler , http . NewServeMux ( ) } req . Root = h . rootDirectory", "commit_type": "remove"}
{"commit_tokens": ["fixed", "some", "metric", "/", "query", "bugs", ".", "Made", "post", "package", "write", "to", "null", "logger", "by", "default"], "add_tokens": "Log * log . Logger Log : log . New ( NullWriter { } , \" \" , 0 ) , panic ( fmt . Sprintf ( \" \\n \" , c . Simid ) ) c . Log . Println ( \" \" ) c . Log . Println ( \" \" ) c . Log . Printf ( \" \\n \" , c . Simid ) c . Log . Println ( \" \" ) c . Log . Printf ( \" \\n \" , len ( roots ) ) c . Log . Printf ( \" \\n \" , i ) c . Log . Println ( \" \" ) c . Log . Printf ( \" \\n \" , c . resCount )", "del_tokens": "fmt . Println ( \" \" ) fmt . Println ( \" \" ) panic ( fmt . Errorf ( \" \\n \" , c . Simid ) ) fmt . Println ( \" \" ) fmt . Println ( \" \" ) fmt . Printf ( \" \\n \" , c . Simid ) fmt . Println ( \" \" ) fmt . Printf ( \" \\n \" , len ( roots ) ) fmt . Printf ( \" \\n \" , i ) fmt . Println ( \" \" ) fmt . Printf ( \" \\n \" , c . resCount )", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "use", "s3", "package", "namespace"], "add_tokens": "// Sparta package to support AWS S3 package s3", "del_tokens": "package spartaS3", "commit_type": "update"}
{"commit_tokens": ["Make", "sure", "try", "match", "fingerprint", "returns", "a", "payload", "that", "contains", "sourceApplication"], "add_tokens": "Referrer string `json:\"sourceApplication\"`", "del_tokens": "Referrer string", "commit_type": "make"}
{"commit_tokens": ["remove", "unnecessary", "pointer", "dereference", "."], "add_tokens": "func toMsgpackRecordSet ( tag string , bin [ ] byte ) [ ] byte { b . WriteMpStringHead ( len ( bin ) ) b . Write ( bin )", "del_tokens": "func toMsgpackRecordSet ( tag string , bin * [ ] byte ) [ ] byte { b . WriteMpStringHead ( len ( * bin ) ) b . Write ( * bin )", "commit_type": "remove"}
{"commit_tokens": ["Add", "Description", "field", "to", "SnatPool"], "add_tokens": "Name string `json:\"name,omitempty\"` Partition string `json:\"partition,omitempty\"` FullPath string `json:\"fullPath,omitempty\"` Description string `json:\"description,omitempty\"` Generation int `json:\"generation,omitempty\"` Members [ ] string `json:\"members,omitempty\"`", "del_tokens": "Name string `json:\"name,omitempty\"` Partition string `json:\"partition,omitempty\"` FullPath string `json:\"fullPath,omitempty\"` Generation int `json:\"generation,omitempty\"` Members [ ] string `json:\"members,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "to", "/", "from", "SignedBase64"], "add_tokens": "segs := strings . Split ( selStr , PathSeparator )", "del_tokens": "segs := strings . Split ( selStr , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Make", "Cookie", "a", "receive", "-", "only", "channel"], "add_tokens": "type Cookie <- chan * Reply o . conn . replies [ msg . Serial ] = c", "del_tokens": "type Cookie chan * Reply o . conn . replies [ msg . Serial ] = Cookie ( c )", "commit_type": "make"}
{"commit_tokens": ["Add", "doc", "to", "t", ".", "go"], "add_tokens": "taskSet = & tasking . TaskSet { Name : name , Dir : p . Dir , PkgObj : p . PkgObj , ImportPath : importPath , Tasks : tasks , }", "del_tokens": "taskSet = & tasking . TaskSet { Name : name , Dir : p . Dir , PkgObj : p . PkgObj , ImportPath : importPath , Tasks : tasks }", "commit_type": "add"}
{"commit_tokens": ["add", "a", "counter", "for", "test", "log"], "add_tokens": "//go:generate counterfeiter -o shims/fake/fake_logger.go . Logger", "del_tokens": "//go:generate counterfeiter -o ../fakes/fake_logger.go . Logger", "commit_type": "add"}
{"commit_tokens": ["update", "CoerceString", "to", "support", "empty", "string"], "add_tokens": "\" \" : 4 , \" \" : 45.3 , \" \" : \" \" , \" \" : \" \" , \" \" : true , \" \" : \" \" , assert . Equal ( t , 0 , len ( CoerceStrings ( data [ \" \" ] ) ) , \" \" , data [ \" \" ] ) assert . Equal ( t , [ ] string { \" \" } , CoerceStrings ( data [ \" \" ] ) , \" \" , data [ \" \" ] ) assert . Equal ( t , [ ] string { \" \" } , CoerceStrings ( data [ \" \" ] ) , \" \" , data [ \" \" ] )", "del_tokens": "\" \" : 4 , \" \" : 45.3 , \" \" : \" \" , \" \" : \" \" , \" \" : true ,", "commit_type": "update"}
{"commit_tokens": ["removed", "last", "reference", "to", "sqlite"], "add_tokens": "// _ \"github.com/mattes/migrate/driver/sqlite3\"", "del_tokens": "_ \" \"", "commit_type": "remove"}
{"commit_tokens": ["changing", "how", "Distributor", "works", "adding", "Partition"], "add_tokens": "run ( NewPartition ( NewDistributor ( c , c2 ) ) )", "del_tokens": "dc := NewDistributed ( c , c2 ) run ( dc )", "commit_type": "change"}
{"commit_tokens": ["Add", "IgnoreUnknownKeys", "()", "option", "to", "the", "decoder", "."], "add_tokens": "// reflect.Value.FieldByString(). Multiple parts are required for slices of", "del_tokens": "// reflect.Value.FieldByIndex(). Multiple parts are required for slices of", "commit_type": "add"}
{"commit_tokens": ["moved", "common", "code", "to", "clearSkipHeader", "()"], "add_tokens": "req . clearSkipHeader ( ) } func ( req * Request ) clearSkipHeader ( ) { resp . clearSkipHeader ( ) } func ( resp * Response ) clearSkipHeader ( ) { req . clearSkipHeader ( ) resp . clearSkipHeader ( )", "del_tokens": "req . Body = req . Body [ : 0 ] req . URI . Clear ( ) req . parsedURI = false req . PostArgs . Clear ( ) req . parsedPostArgs = false resp . Body = resp . Body [ : 0 ]", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "filtering", "version", "bundles", "when", "collecting", "them"], "add_tokens": "// within the given version bundles define for their own components. Duplicate // versions for same bundle name (e.g. in case of different Provider // implementations) are removed. To control bundles selected for aggregation, // filter them before aggregation.", "del_tokens": "// within the given version bundles define for their own components.", "commit_type": "add"}
{"commit_tokens": ["Move", "excluded", "IPs", "to", "the", "config", "file", "."], "add_tokens": "func getPublishedIP ( excluded [ ] string ) ( string , error ) { for _ , excludeIP := range excluded { if address . String ( ) == excludeIP { continue }", "del_tokens": "func getPublishedIP ( excluded map [ string ] bool ) ( string , error ) { if excluded [ address . String ( ) ] { continue", "commit_type": "move"}
{"commit_tokens": ["use", "v2", "query", "in", "embedded", "example"], "add_tokens": "json . Unmarshal ( [ ] byte ( `\"all\"` ) , & query ) if err := db . EvalQueryV2 ( query , A , & result ) ; err != nil { // map keys are query results - result document IDs", "del_tokens": "json . Unmarshal ( [ ] byte ( `[\"all\"]` ) , & query ) if err := db . EvalQuery ( query , A , & result ) ; err != nil { // query results are in map keys", "commit_type": "use"}
{"commit_tokens": ["Makes", "it", "so", "harness", "can", "bootstrap", "using", "the", "new", "GoRequest", "/", "response", "wrappers"], "add_tokens": "alias , ok := aliases [ importPath ] for containsValue ( aliases , alias ) || alias == \" \" {", "del_tokens": "alias , ok := aliases [ importPath ] for containsValue ( aliases , alias ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "canonical", "file", "URL", "detection", "on", "Windows", "."], "add_tokens": "\" \" \" \" if runtime . GOOS == \" \" { // on Windows, a file URL may have an extra leading slash, and if it // doesn't then its first component will be treated as the host by the // Go runtime if refUrl . Host == \" \" && strings . HasPrefix ( refUrl . Path , \" \" ) { r . HasFullFilePath = filepath . IsAbs ( refUrl . Path [ 1 : ] ) } else { r . HasFullFilePath = filepath . IsAbs ( refUrl . Host + refUrl . Path ) } } else { r . HasFullFilePath = filepath . IsAbs ( refUrl . Path ) }", "del_tokens": "r . HasFullFilePath = filepath . IsAbs ( refUrl . Path )", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "irregular", "&", "uncountable", "inflection"], "add_tokens": "{ \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , var uncountableInflections = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "del_tokens": "var uncountableInflections = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["update", "godoc", "and", "paste", "string", "name"], "add_tokens": "// UnicodeType tap uint32 unicode // TypeString type string, support unicode // PasteStr paste string, support UTF-8 func PasteStr ( str string ) {", "del_tokens": "// UnicodeType unicode tap uint32 // TypeString type string // TypeStrP paste string, support UTF-8 func TypeStrP ( str string ) {", "commit_type": "update"}
{"commit_tokens": ["fixed", "test", "to", "handle", "new", "header", "format"], "add_tokens": "params := strings . Split ( paramsStr , \" \" , - 1 )", "del_tokens": "params := strings . Split ( paramsStr , \" \\n \" , - 1 )", "commit_type": "fix"}
{"commit_tokens": ["Adds", "a", "kinesis", "-", "cli", "using", "the", "api", "from", "the", "command", "line"], "add_tokens": "const ( ACCESS_ENV_KEY = \" \" SECRET_ENV_KEY = \" \" ) auth . AccessKey = os . Getenv ( ACCESS_ENV_KEY ) auth . SecretKey = os . Getenv ( SECRET_ENV_KEY )", "del_tokens": "auth . AccessKey = os . Getenv ( \" \" ) auth . SecretKey = os . Getenv ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["use", "mime", "package", "to", "extract", "boundary"], "add_tokens": "\" \" _ , params , err := mime . ParseMediaType ( contentType ) if err == nil { return params [ \" \" ] return \" \"", "del_tokens": "var boundary string // first searching for the 'boundary=' token boundaryIdx := strings . Index ( contentType , \" \" ) if boundaryIdx > - 1 && len ( contentType ) > boundaryIdx + 9 { // then id check if what is the next char after '=' firstCharIdx := boundaryIdx + 9 if contentType [ firstCharIdx ] == '\"' { // ok, searching for the close quote closeQuoteIdx := strings . Index ( contentType [ firstCharIdx + 1 : ] , \" \\\" \" ) if closeQuoteIdx > - 1 { boundary = contentType [ firstCharIdx + 1 : firstCharIdx + closeQuoteIdx + 1 ] } } else { // that mean the boundary not quoted, check for ';' or 'space' // or any kind of newline terminateIdx := strings . IndexAny ( contentType [ firstCharIdx : ] , \" \\r \\n \" ) if terminateIdx > - 1 { boundary = contentType [ firstCharIdx : firstCharIdx + terminateIdx ] } else { // the boundary is the last param of contentType boundary = contentType [ firstCharIdx : ] } } return boundary", "commit_type": "use"}
{"commit_tokens": ["Remove", "dependency", "on", "protocol", "version", "."], "add_tokens": "// SetBlockBytes sets the internal serialized block byte buffer to the passed // buffer. It is used to inject errors and is only available to the test // package. b . serializedBlock = buf", "del_tokens": "// SetBlockBytes sets the internal raw block byte buffer to the passed buffer. // It is used to inject errors and only available to the test package. b . rawBlock = buf", "commit_type": "remove"}
{"commit_tokens": ["update", "doc", "for", "new", "features"], "add_tokens": "// SendToDevices Send multicast Message to a list of devices // SendToTopic Send Message to a topic", "del_tokens": "// SendToDevices Send multicast Message to devices // SendToTopic TODO NOT IMPLEMENTED", "commit_type": "update"}
{"commit_tokens": ["Implement", "dense", "(", "normal", ")", "HLL", "++", "mode", "."], "add_tokens": "func ( iter * sparseReader ) Next ( ) uint32 { v := iter . Peek ( ) iter . Advance ( ) return v } h . tmpSet = make ( [ ] uint32 , 0 )", "del_tokens": "h . tmpSet = h . tmpSet [ 0 : 0 ]", "commit_type": "implement"}
{"commit_tokens": ["Removing", "AX", "stuttering", "from", "accessibility", "domain", "types"], "add_tokens": "Nodes [ ] * Node `json:\"nodes,omitempty\"` // The Accessibility.AXNode for this DOM node, if it exists, plus its ancestors, siblings and children, if requested. func ( p * GetPartialAXTreeParams ) Do ( ctxt context . Context , h cdp . Executor ) ( nodes [ ] * Node , err error ) {", "del_tokens": "Nodes [ ] * AXNode `json:\"nodes,omitempty\"` // The Accessibility.AXNode for this DOM node, if it exists, plus its ancestors, siblings and children, if requested. func ( p * GetPartialAXTreeParams ) Do ( ctxt context . Context , h cdp . Executor ) ( nodes [ ] * AXNode , err error ) {", "commit_type": "remove"}
{"commit_tokens": ["use", "some", "environment", "variables", "to", "skip", "db", "types", "if", "they", "aren", "t", "available"], "add_tokens": "// The following environment variables, if set, will be used: // // Sqlite: // * SQLX_SQLITEPATH // // Postgres: // * SQLX_PGUSER // * SQLX_PGPASS // // MySQL: // * SQLX_MYSQLUSER // * SQLX_MYSQLPASS // // To disable testing against any of these databases, set one of: // * SQLX_NOPG, SQLX_NOMYSQL, SQLX_NOSQLITE if len ( os . Getenv ( \" \" ) ) > 0 { TestPostgres = false fmt . Printf ( \" \\n \" ) return } var username , password string password = os . Getenv ( \" \" ) dsn := fmt . Sprintf ( \" \" , username ) if len ( password ) > 0 { dsn = fmt . Sprintf ( \" \" , username , password ) } pgdb , err = Connect ( \" \" , dsn ) if len ( os . Getenv ( \" \" ) ) > 0 { TestSqlite = false fmt . Printf ( \" \\n \" ) return } if len ( os . Getenv ( \" \" ) ) > 0 { TestSqlite = false fmt . Printf ( \" \\n \" ) return }", "del_tokens": "var username string pgdb , err = Connect ( \" \" , \" \" + username + \" \" )", "commit_type": "use"}
{"commit_tokens": ["Added", "ability", "to", "extend", "connections", "."], "add_tokens": "// extension interface { } socket : s , router : r , send : make ( chan * message , sendChannelSize ) , extension : nil , func ( conn * Connection ) extend ( e interface { } ) { conn . extension = e }", "del_tokens": "socket : s , router : r , send : make ( chan * message , sendChannelSize ) ,", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "for", "model", "code", "generation"], "add_tokens": "\" \" mv . addModelNeedParse ( models ) models map [ string ] [ ] string modelsParse map [ string ] bool func ( mv * modelVisitor ) addModelNeedParse ( models [ ] string ) { mv . modelsParse = make ( map [ string ] bool ) for _ , m := range models { if m != \" \" { mv . modelsParse [ m ] = true } } } return goutil . IsExported ( model ) && ( len ( mv . modelsParse ) == 0 || mv . modelsParse [ model ] ) fmt . Println ( model , mv . needParse ( model ) )", "del_tokens": "mv . addModels ( models ) models map [ string ] [ ] string if ! goutil . IsExported ( model ) { return false } if mv . models != nil && len ( mv . models ) > 0 { if _ , has := mv . models [ model ] ; ! has { return false } } return true", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "we", "really", "close", "the", "response", "body", "if", "we", "are", "going", "to", "return", "a", "nil", "response"], "add_tokens": "// // CloseResponse makes sure we close the response body // func CloseResponse ( r * http . Response ) { if r != nil && r . Body != nil { io . Copy ( ioutil . Discard , r . Body ) r . Body . Close ( ) } } CloseResponse ( & r . Response ) CloseResponse ( resp ) CloseResponse ( resp ) CloseResponse ( resp )", "del_tokens": "if r != nil && r . Body != nil { io . Copy ( ioutil . Discard , r . Body ) r . Body . Close ( ) }", "commit_type": "make"}
{"commit_tokens": ["Fix", "recursive", "case", "on", "Windows", "platforms"], "add_tokens": "for _ , relativePath := range paths { path , err := filepath . Abs ( relativePath ) if filepath . Base ( relativePath ) == \" \" {", "del_tokens": "for _ , path := range paths { path , err := filepath . Abs ( path ) if filepath . Base ( path ) == \" \" {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "containers", "from", "state", "on", "pod", "remove"], "add_tokens": "podInfraContainerName := sb . name + \" \" var podInfraContainer * oci . Container if podInfraContainerName == c . Name ( ) { podInfraContainer = c s . removeContainer ( c ) s . removeContainer ( podInfraContainer )", "del_tokens": "podInfraContainer := sb . name + \" \" if podInfraContainer == c . Name ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Remove", "examples", "from", "godoc", "."], "add_tokens": "func ExampleClient_Pipelined ( ) { func Example_CustomCommand ( ) { Get := func ( client * redis . Client , key string ) * redis . StringCmd { cmd := redis . NewStringCmd ( \" \" , key ) client . Process ( cmd ) return cmd }", "del_tokens": "func ExamplePipeline2 ( ) { func Get ( client * redis . Client , key string ) * redis . StringCmd { cmd := redis . NewStringCmd ( \" \" , key ) client . Process ( cmd ) return cmd } func ExampleCustomCommand ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "partner", "overrides", "to", "referral", "request"], "add_tokens": "TrackingID string `json:\"tracking_id\"` PartnerConfigOverride * PartnerConfigOverride `json:\"partner_config_override,omitemtpy\"` Operations [ ] Operation `json:\"operations,omitempty\"` Products [ ] string `json:\"products,omitempty\"` LegalConsents [ ] Consent `json:\"legal_consents,omitempty\"` } PartnerConfigOverride struct { PartnerLogoURL string `json:\"partner_logo_url,omitempty\"` ReturnURL string `json:\"return_url,omitempty\"` ReturnURLDescription string `json:\"return_url_description,omitempty\"` ActionRenewalURL string `json:\"action_renewal_url,omitempty\"` ShowAddCreditCard * bool `json:\"show_add_credit_card,omitempty\"`", "del_tokens": "TrackingID string `json:\"tracking_id\"` Operations [ ] Operation `json:\"operations,omitempty\"` Products [ ] string `json:\"products,omitempty\"` LegalConsents [ ] Consent `json:\"legal_consents,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "implementation", "for", "starting", "container"], "add_tokens": "func ( s * Server ) StartContainer ( ctx context . Context , req * pb . StartContainerRequest ) ( * pb . StartContainerResponse , error ) { containerName := req . ContainerId if * containerName == \" \" { return nil , fmt . Errorf ( \" \" ) } c := s . state . containers [ * containerName ] if c == nil { return nil , fmt . Errorf ( \" \" , * containerName ) } if err := s . runtime . StartContainer ( c ) ; err != nil { return nil , fmt . Errorf ( \" \" , c . Name ( ) , * containerName , err ) } return & pb . StartContainerResponse { } , nil", "del_tokens": "func ( s * Server ) StartContainer ( context . Context , * pb . StartContainerRequest ) ( * pb . StartContainerResponse , error ) { return nil , nil", "commit_type": "add"}
{"commit_tokens": ["Use", "Fdatasync", "instead", "of", "O_SYNC"], "add_tokens": "\" \" \" \" l . fd , err = os . OpenFile ( fname , os . O_RDWR | os . O_CREATE , 0666 ) var bufPool = sync . Pool { New : func ( ) interface { } { return & bytes . Buffer { } } , } buf := bufPool . Get ( ) . ( * bytes . Buffer ) defer func ( ) { buf . Reset ( ) bufPool . Put ( buf ) } ( ) var h header if err != nil { return ptrs , errors . Wrap ( err , \" \" ) } err = syscall . Fdatasync ( int ( l . fd . Fd ( ) ) )", "del_tokens": "l . fd , err = os . OpenFile ( fname , os . O_RDWR | os . O_CREATE | os . O_SYNC , 0666 ) x . Check ( err ) _ , err = l . fd . Write ( [ ] byte ( \" \" ) ) var buf bytes . Buffer var h header", "commit_type": "use"}
{"commit_tokens": ["Make", "the", "do", "request", "method", "public", "."], "add_tokens": "response , err := authy . DoRequest ( \" \" , path , params ) response , err := authy . DoRequest ( \" \" , path , params ) response , err := authy . DoRequest ( \" \" , path , params ) response , err := authy . DoRequest ( \" \" , path , params ) func ( authy * Authy ) DoRequest ( method string , path string , params url . Values ) ( * http . Response , error ) {", "del_tokens": "response , err := authy . doRequest ( \" \" , path , params ) response , err := authy . doRequest ( \" \" , path , params ) response , err := authy . doRequest ( \" \" , path , params ) response , err := authy . doRequest ( \" \" , path , params ) func ( authy * Authy ) doRequest ( method string , path string , params url . Values ) ( * http . Response , error ) {", "commit_type": "make"}
{"commit_tokens": ["Removed", "unneccessary", "i", "/", "o"], "add_tokens": "fmt . Fprint ( w , \" \" ) fmt . Fprint ( w , \" \" )", "del_tokens": "fmt . Fprint ( w , getContentOfFile ( \" \" ) ) fmt . Fprint ( w , getContentOfFile ( \" \" ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "non", "-", "interspersed", "option", "/", "non", "-", "option", "args", "."], "add_tokens": "name string parsed bool actual map [ string ] * Flag formal map [ string ] * Flag shorthands map [ byte ] * Flag args [ ] string // arguments after flags exitOnError bool // does the program exit if there's an error? errorHandling ErrorHandling output io . Writer // nil means stderr; use out() accessor noInterspersed bool // do not allow interspersed option/non-option args if f . noInterspersed { f . args = append ( f . args , s ) f . args = append ( f . args , args ... ) return nil } // Do not support interspersed option/non-option arguments. func NoInterspersed ( ) { commandLine . NoInterspersed ( ) } func ( f * FlagSet ) NoInterspersed ( ) { f . noInterspersed = true }", "del_tokens": "name string parsed bool actual map [ string ] * Flag formal map [ string ] * Flag shorthands map [ byte ] * Flag args [ ] string // arguments after flags exitOnError bool // does the program exit if there's an error? errorHandling ErrorHandling output io . Writer // nil means stderr; use out() accessor", "commit_type": "add"}
{"commit_tokens": ["Add", "most", "pieces", "of", "the", "new", "parser"], "add_tokens": "func tokenizeRaw ( data [ ] byte , f func ( token , [ ] byte ) , tokenError func ( int , int , [ ] byte ) error ) error { return tokenError ( ts , te , data ) return tokenError ( ts , te , data ) return nil", "del_tokens": "func tokenizeRaw ( data [ ] byte , f func ( token , [ ] byte ) ) bool { return false return false return true", "commit_type": "add"}
{"commit_tokens": ["Fix", "parsing", "SET", "timestamp", "=", "N", "in", "slow", "log", "."], "add_tokens": "var setRe = regexp . MustCompile ( `^SET (?:last_insert_id|insert_id|timestamp)` )", "del_tokens": "var setRe = regexp . MustCompile ( `SET (?:last_insert_id|insert_id|timestamp)` )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "parsing", "of", "transfer", "lines"], "add_tokens": "tos = c . RemainingArgs ( ) if x := net . ParseIP ( tos [ i ] ) ; x == nil { return nil , nil , fmt . Errorf ( \" \" , tos [ i ] ) } froms = c . RemainingArgs ( ) if x := net . ParseIP ( froms [ i ] ) ; x == nil { return nil , nil , fmt . Errorf ( \" \" , froms [ i ] ) }", "del_tokens": "if ! c . NextArg ( ) { return nil , nil , c . ArgErr ( ) } tos := c . RemainingArgs ( ) if x := net . ParseIP ( tos [ i ] ) ; x == nil { return nil , nil , fmt . Errorf ( \" \" , tos [ i ] ) } froms := c . RemainingArgs ( ) if x := net . ParseIP ( froms [ i ] ) ; x == nil { return nil , nil , fmt . Errorf ( \" \" , froms [ i ] ) }", "commit_type": "fix"}
{"commit_tokens": ["added", "unit", "tests", "for", "Message", "TypeTags", "()", "and", "String", "()"], "add_tokens": "func ( msg * Message ) TypeTags ( ) ( string , error ) { if msg == nil { return \" \" , fmt . Errorf ( \" \" ) } tags := \" \" if msg == nil { return \" \" } // PrintMessage pretty prints an OSC message to the standard output. func PrintMessage ( msg * Message ) { fmt . Println ( msg ) }", "del_tokens": "func ( msg * Message ) TypeTags ( ) ( tags string , err error ) { tags = \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "ordinary", "least", "squares", "online", "learning", "optionality", "(", "with", "channels", "like", "every", "other", "model", ")"], "add_tokens": "// respectively.) textY[i] should be the observed // result of the inputs testX[i].: // // Example Model Usage (Batch Ordinary Least Squares) // // if you're passing in no training set directly because you want // to learn using the online method then just declare the number of // features (it's an integer) as an extra arg after the rest // of the arguments func NewLeastSquares ( method base . OptimizationMethod , alpha , regularization float64 , maxIterations int , trainingSet [ ] [ ] float64 , expectedResults [ ] float64 , features ... int ) * LeastSquares { if len ( features ) != 0 { params = make ( [ ] float64 , features [ 0 ] + 1 ) } else if trainingSet == nil || len ( trainingSet ) == 0 { params = make ( [ ] float64 , len ( trainingSet [ 0 ] ) + 1 ) if len ( point . Y ) != 1 { errors <- fmt . Errorf ( \" \" , point ) }", "del_tokens": "// respectively): func NewLeastSquares ( method base . OptimizationMethod , alpha , regularization float64 , maxIterations int , trainingSet [ ] [ ] float64 , expectedResults [ ] float64 ) * LeastSquares { if trainingSet == nil || len ( trainingSet ) == 0 { params = make ( [ ] float64 , len ( ( trainingSet ) [ 0 ] ) + 1 )", "commit_type": "add"}
{"commit_tokens": ["use", "existing", "default", "size", "constants", "in", "LState", ".", "NewTable"], "add_tokens": "return newLTable ( defaultArrayCap , defaultHashCap )", "del_tokens": "// TODO change size return newLTable ( 32 , 32 )", "commit_type": "use"}
{"commit_tokens": ["Improve", "Array", "performance", "and", "overall", "compliance"], "add_tokens": "jsonparser . ArrayEach ( largeFixture , func ( value [ ] byte , dataType int , offset int , err error ) { } , \" \" ) jsonparser . ArrayEach ( largeFixture , func ( value [ ] byte , dataType int , offset int , err error ) { } , \" \" , \" \" )", "del_tokens": "users , _ , _ , _ := jsonparser . Get ( largeFixture , \" \" ) jsonparser . ArrayEach ( users , func ( value [ ] byte , dataType int , offset int , err error ) { } ) topics , _ , _ , _ := jsonparser . Get ( largeFixture , \" \" , \" \" ) jsonparser . ArrayEach ( topics , func ( value [ ] byte , dataType int , offset int , err error ) { } )", "commit_type": "improve"}
{"commit_tokens": ["Add", "context", "support", "for", "standard", "lib", "Handlers"], "add_tokens": "w := httptest . NewRecorder ( ) testCtxHandler := http . HandlerFunc ( func ( w http . ResponseWriter , r * http . Request ) { val , ok := r . Context ( ) . Value ( certauth . HasAuthorizedCN ) . ( string ) if ! ok { t . Fatal ( \" \" ) } expect ( t , val , \" \" ) } ) w = httptest . NewRecorder ( ) auth . Handler ( testCtxHandler ) . ServeHTTP ( w , req )", "del_tokens": "w := httptest . NewRecorder ( )", "commit_type": "add"}
{"commit_tokens": ["add", "more", "test", "and", "fix", "evict", "dead", "lock", "bug", "."], "add_tokens": "defer this . evictionLock . Unlock ( )", "del_tokens": "this . evictionLock . Unlock ( )", "commit_type": "add"}
{"commit_tokens": ["Changed", "order", "of", "Unmarshal", "helper", "arguments", "to", "match", "encoding", "/", "json", "."], "add_tokens": "\" \" func Unmarshal ( data [ ] byte , v Unmarshaler ) error { func UnmarshalFromReader ( r io . Reader , v Unmarshaler ) error {", "del_tokens": "\" \" func Unmarshal ( v Unmarshaler , data [ ] byte ) error { func UnmarshalFromReader ( v Unmarshaler , r io . Reader ) error {", "commit_type": "change"}
{"commit_tokens": ["Change", "how", "diffs", "are", "generated"], "add_tokens": "import \" \" WriteTo ( io . Writer ) ( int64 , error ) type Statements [ ] Stmt Columns [ ] * CreateTableColumnStatement Indexes [ ] * CreateTableIndexStatement Options [ ] * CreateTableOptionStatement", "del_tokens": "String ( ) string Columns [ ] CreateTableColumnStatement Indexes [ ] CreateTableIndexStatement Options [ ] CreateTableOptionStatement", "commit_type": "change"}
{"commit_tokens": ["Add", "new", "method", "to", "create", "a", "sandbox", "api", "."], "add_tokens": "return & Authy { ApiKey : apiKey , ApiUrl : apiUrl , } } func NewSandboxAuthyApi ( apiKey string ) * Authy { apiUrl := \" \" return & Authy { ApiKey : apiKey , ApiUrl : apiUrl , }", "del_tokens": "return & Authy { apiKey , apiUrl }", "commit_type": "add"}
{"commit_tokens": ["moved", "OperationXxx", "consts", "to", "moss", ".", "go"], "add_tokens": "// See the OperationXxx consts. // Max key length is 2^24, from 24 bits key length. const maskKeyLength = uint64 ( 0x00FFFFFF00000000 ) // Max val length is 2^28, from 28 bits val length. const maskValLength = uint64 ( 0x000000000FFFFFFF )", "del_tokens": "const maskKeyLength = uint64 ( 0x00FFFFFF00000000 ) // 24 bits key length. const maskValLength = uint64 ( 0x000000000FFFFFFF ) // 28 bits val length. const OperationSet = uint64 ( 0x0100000000000000 ) const OperationDel = uint64 ( 0x0200000000000000 ) const OperationMerge = uint64 ( 0x0300000000000000 )", "commit_type": "move"}
{"commit_tokens": ["Add", "godocs", "to", "functions", "written", "so", "far", ".", "(", "WIP", ")", "CreateRoute", "."], "add_tokens": "// A Route structure contains information on a configured or to-be-configured route. // The Priority field indicates how soon the route works relative to other configured routes. // Routes of equal priority are consulted in chronological order. // The Description field provides a human-readable description for the route. // Mailgun ignores this field except to provide the description when viewing the Mailgun web control panel. // The Expression field lets you specify a pattern to match incoming messages against. // The Actions field contains strings specifying what to do // with any message which matches the provided expression. // The CreatedAt field provides a time-stamp for when the route came into existence. // Finally, the ID field provides a unique identifier for this route. // // When creating a new route, the SDK only uses a subset of the fields of this structure. // In particular, CreatedAt and ID are meaningless in this context, and will be ignored. // Only Priority, Description, Expression, and Actions need be provided. // GetRoutes returns the complete set of routes configured for your domain. // You use routes to configure how to handle returned messages, or // messages sent to a specfic address on your domain. // See the Mailgun documentation for more information. // CreateRoute installs a new route for your domain. // The route structure you provide serves as a template, and // only a subset of the fields influence the operation. // See the Route structure definition for more details. r := simplehttp . NewHTTPRequest ( generatePublicApiUrl ( routesEndpoint ) ) r . SetBasicAuth ( basicAuthUser , mg . ApiKey ( ) ) p := simplehttp . NewUrlEncodedPayload ( ) p . AddValue ( \" \" , strconv . Itoa ( prototype . Priority ) ) p . AddValue ( \" \" , prototype . Description ) p . AddValue ( \" \" , prototype . Expression ) for _ , action := range prototype . Actions { p . AddValue ( \" \" , action ) } var envelope struct { Message string Route } _ , err := r . MakePostRequest ( p ) return envelope . Route , err", "del_tokens": "\" \" return Route { } , fmt . Errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "when", "MinSize", "==", "MaxSize"], "add_tokens": "if genParams . MaxSize == genParams . MinSize { len = genParams . MaxSize } else { len = genParams . Rng . Intn ( genParams . MaxSize - genParams . MinSize ) + genParams . MinSize }", "del_tokens": "len = genParams . Rng . Intn ( genParams . MaxSize - genParams . MinSize ) + genParams . MinSize", "commit_type": "fix"}
{"commit_tokens": ["Use", "command", "passed", "into", "p", ".", "Parse", "(", "...", ")", "write", "methods"], "add_tokens": "cmd := p . cmd if p . lastCmd != nil { cmd = p . lastCmd } p . writeUsageForCommand ( w , cmd ) cmd := p . cmd if p . lastCmd != nil { cmd = p . lastCmd } p . writeHelpForCommand ( w , cmd )", "del_tokens": "p . writeUsageForCommand ( w , p . cmd ) p . writeHelpForCommand ( w , p . cmd )", "commit_type": "use"}
{"commit_tokens": ["Make", "decompressor", "conditional", "on", "reader", "interface"], "add_tokens": "func decompressor ( r io . Reader ) ( io . Reader , error ) { ra , ok := r . ( io . ReaderAt ) if ! ok { return r , nil } _ , err := ra . ReadAt ( buf [ : ] , 0 )", "del_tokens": "type readAtReader interface { io . Reader io . ReaderAt } func decompressor ( r readAtReader ) ( io . Reader , error ) { _ , err := r . ReadAt ( buf [ : ] , 0 )", "commit_type": "make"}
{"commit_tokens": ["add", "all", "the", ".", "back"], "add_tokens": "// Currency represents money currency information required for formatting. // currencies represents a collection of currency. // AddCurrency lets you insert or update currency in currencies list. // Formatter returns currency formatter representing. // Grapheme and Code fields will be changed by currency code. // get extended currency using currencies list.", "del_tokens": "// Currency represents money currency information required for formatting // currencies represents a collection of currency // AddCurrency lets you insert or update currency in currencies list // Formatter returns currency formatter representing // Grapheme and Code fields will be changed by currency code // get extended currency using currencies list", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "channel", "instead", "of", "a", "wait", "group"], "add_tokens": "closed chan struct { } defer close ( link . closed ) case <- link . closed :", "del_tokens": "\" \" group sync . WaitGroup link . group . Add ( 1 ) defer link . group . Done ( ) done := make ( chan struct { } ) case <- done : link . group . Wait ( ) close ( done )", "commit_type": "use"}
{"commit_tokens": ["change", "to", "use", "lambda", ".", "json"], "add_tokens": "// from the \"lambda.json\" file on disk. Operations are performed // Open the lambda.json file and prime the config. p , err := os . Open ( filepath . Join ( f . Path , \" \" ) )", "del_tokens": "// from the \"package.json\" file on disk. Operations are performed // Open the package.json file and prime the config. p , err := os . Open ( filepath . Join ( f . Path , \" \" ) )", "commit_type": "change"}
{"commit_tokens": ["Fix", "potential", "close", "on", "nil", "body"], "add_tokens": "defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( )", "del_tokens": "defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( ) defer resp . Body . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "less", "unusual", "looking", "random", "number", "seed", "when", "testing", "."], "add_tokens": "rng := rand . New ( rand . NewSource ( 1 ) )", "del_tokens": "rng := rand . New ( rand . NewSource ( 27354294 ) )", "commit_type": "use"}
{"commit_tokens": ["Make", "snapshot", "server", "change", "server", "start", "in", "the", "post", "init", "plugin", "hook"], "add_tokens": "apid . RegisterPostPlugin ( postinitPlugin ) } func postinitPlugin ( services apid . Services ) error { log . Debug ( \" \" ) /* call to Download Snapshot info */ go DownloadSnapshot ( ) /* Begin Looking for changes periodically */ log . Debug ( \" \" ) go updatePeriodicChanges ( ) events . Listen ( ApigeeSyncEventSelector , & handler { } ) log . Debug ( \" \" ) return nil", "del_tokens": "/* call to Download Snapshot info */ go DownloadSnapshot ( ) /* Begin Looking for changes periodically */ log . Debug ( \" \" ) go updatePeriodicChanges ( ) events . Listen ( ApigeeSyncEventSelector , & handler { } )", "commit_type": "make"}
{"commit_tokens": ["updated", "for", "stroagepool", "and", "href"], "add_tokens": "func ( client * Client ) FindSystem ( instanceID , href string ) ( * System , error ) { return & System { } , fmt . Errorf ( \" \" , err ) return outSystem , nil return & System { } , fmt . Errorf ( \" \" )", "del_tokens": "func ( client * Client ) FindSystem ( instanceID , href string ) ( System , error ) { return System { } , fmt . Errorf ( \" \" , err ) return * outSystem , nil return System { } , fmt . Errorf ( \" \" )", "commit_type": "update"}
{"commit_tokens": ["Add", "new", "datetime", "type", "for", "Rfc1123", "format"], "add_tokens": "if err != nil { t . Errorf ( \" \" , err ) } if err != nil { t . Errorf ( \" \" , err ) } if err != nil { t . Errorf ( \" \" , err ) } var _ time . Time = d . ToTime ( )", "del_tokens": "if ! ( reflect . DeepEqual ( d . ToTime ( ) , ti ) ) { t . Errorf ( \" \" ) }", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", ":", "themshelves", "-", ">", "themselves"], "add_tokens": "// Marshaler is the interface implemented by objects that can marshal themselves into valid TOML.", "del_tokens": "// Marshaler is the interface implemented by objects that can marshal themshelves into valid TOML.", "commit_type": "fix"}
{"commit_tokens": ["added", "complete", "and", "cancel", "to", "interface"], "add_tokens": "future . cancel ( )", "del_tokens": "switch f := future . ( type ) { case * PublishFuture : f . cancel ( ) case * SubscribeFuture : f . cancel ( ) case * UnsubscribeFuture : f . cancel ( ) }", "commit_type": "add"}
{"commit_tokens": ["using", "a", "Pool", "interface", "rather", "than", "struct", "*", "redis", ".", "Pool"], "add_tokens": "type Pool interface { Get ( ) redis . Conn } var _ = Pool ( & redis . Pool { } ) nodes [ ] Pool nodes := make ( [ ] Pool , len ( addrs ) ) nodes [ i ] = Pool ( node ) func NewMutexWithPool ( name string , nodes [ ] Pool ) ( * Mutex , error ) {", "del_tokens": "nodes [ ] * redis . Pool nodes := make ( [ ] * redis . Pool , len ( addrs ) ) nodes [ i ] = node func NewMutexWithPool ( name string , nodes [ ] * redis . Pool ) ( * Mutex , error ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "logic", "to", "ignore", "unmarked", "fields", "when", "generating", "list", "of", "properties", ".", "Tests", "are", "provided", "."], "add_tokens": "if name == \" \" { continue } var name string if parts [ 0 ] != \" \" && parts [ 0 ] != \" \" {", "del_tokens": "name := f . Name if parts [ 0 ] != \" \" {", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "WatchAll", "test", "case", "for", "create", "to", "wait", "a", "little", "before", "triggering", "create"], "add_tokens": "// trigger create after a slight pause to ensure that events are not missed time . Sleep ( time . Second )", "del_tokens": "// trigger create", "commit_type": "fix"}
{"commit_tokens": ["Updated", "with", "UDP", "/", "TCP"], "add_tokens": "// NMap is a great tool, but it's very hard to script when using Go. // This project is meant to make life easier when doing network scanning", "del_tokens": "// NMap is a great tool, but it's very hard to script when trying to use Go. // This project is meant to make life easier when trying to do network scanning", "commit_type": "update"}
{"commit_tokens": ["Make", "this", "library", "build", "on", "FreeBSD"], "add_tokens": "// // /* // * FreeBSD does not contain acl_size and even when it was there, it seemd // * to have been non-functional anyway. See FreeBSD r274722. // */ // #ifdef __FreeBSD__ // #include <errno.h> // # endif // ssize_t acl_size_wrapper(acl_t acl) { // #ifdef __FreeBSD__ // errno = ENOSYS; // return (-1); // #else // return acl_size(acl); // #endif // } return int64 ( C . acl_size_wrapper ( acl . a ) )", "del_tokens": "return int64 ( C . acl_size ( acl . a ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "test", "for", "negative", "case"], "add_tokens": "\" \" const unexpectedMsg = \" \" log . Warn ( unexpectedMsg ) contents , err := ioutil . ReadAll ( tmpfile ) if err != nil { } if ! bytes . Contains ( contents , [ ] byte ( \" \\\" \" + expectedMsg + \" \\\" \" ) ) { if bytes . Contains ( contents , [ ] byte ( \" \\\" \" + unexpectedMsg + \" \\\" \" ) ) { t . Errorf ( \" \" , contents , unexpectedMsg , fname ) }", "del_tokens": "\" \" if contents , err := ioutil . ReadAll ( tmpfile ) ; err != nil { } else if matched , err := regexp . Match ( \" \\\" \" + expectedMsg + \" \\\" \" , contents ) ; err != nil || ! matched {", "commit_type": "add"}
{"commit_tokens": ["Remove", "logrus", "dependency", "from", "any", "packages", "in", "go", "-", "connections"], "add_tokens": "Logger logger func NewTCPProxy ( frontendAddr , backendAddr * net . TCPAddr , ops ... func ( * TCPProxy ) ) ( * TCPProxy , error ) { proxy := & TCPProxy { Logger : & noopLogger { } , } for _ , op := range ops { op ( proxy ) } return proxy , nil proxy . Logger . Printf ( \" \\n \" , proxy . backendAddr , err ) proxy . Logger . Printf ( \" \" , proxy . frontendAddr , proxy . backendAddr , err )", "del_tokens": "\" \" func NewTCPProxy ( frontendAddr , backendAddr * net . TCPAddr ) ( * TCPProxy , error ) { return & TCPProxy { } , nil logrus . Printf ( \" \\n \" , proxy . backendAddr , err ) logrus . Printf ( \" \" , proxy . frontendAddr , proxy . backendAddr , err )", "commit_type": "remove"}
{"commit_tokens": ["Change", "Sirupsen", "to", "lowercase", "as", "specified", "in", "the", "logrus", "library", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "change"}
{"commit_tokens": ["fix", "validate", "test", "to", "reconcile", "recursive", "refs", "with", "temp", "files"], "add_tokens": "\" \" var err error b , _ := testDescription . Schema . MarshalJSON ( ) tmpFile , err := ioutil . TempFile ( os . TempDir ( ) , \" \" ) assert . NoError ( t , err ) tmpFile . Write ( b ) tmpFile . Close ( ) opts := & spec . ExpandOptions { RelativeBase : tmpFile . Name ( ) , SkipSchemas : false , ContinueOnError : false , } err = spec . ExpandSchemaWithBasePath ( testDescription . Schema , nil , opts ) os . Remove ( tmpFile . Name ( ) )", "del_tokens": "err := spec . ExpandSchema ( testDescription . Schema , nil , nil /*new(noopResCache)*/ )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "a", "custom", "HTTP", "client"], "add_tokens": "Client * http . Client if m . Client != nil { return m . Client . Do ( req ) } else { return http . DefaultClient . Do ( req ) }", "del_tokens": "return http . DefaultClient . Do ( req )", "commit_type": "allow"}
{"commit_tokens": ["Add", "a", "default", "client", "and", "wrapper", "functions", "similar", "to", "net", "/", "http", "."], "add_tokens": "\" \" \" \" // Search is a wrapper around DefaultClient.Search. func Search ( query string , t SearchType ) ( * SearchResult , error ) { return DefaultClient . Search ( query , t ) } // being searched, include \"genre\", \"upc\", and \"isrc\". // TODO: need to provide API for specifying limit/offset if resp . StatusCode != http . StatusOK { var e struct { E Error `json:\"error\"` } err = json . NewDecoder ( resp . Body ) . Decode ( & e ) if err != nil { return nil , errors . New ( \" \" ) } return nil , e . E }", "del_tokens": "// being searched, indclude \"genre\", \"upc\", and \"isrc\".", "commit_type": "add"}
{"commit_tokens": ["moved", "set", "max", "events", "control", "structures", "above", "conditionals"], "add_tokens": "if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP }", "del_tokens": "if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP } if w . maxEventsPerCycle > 0 && numEvents >= w . maxEventsPerCycle { goto SLEEP }", "commit_type": "move"}
{"commit_tokens": ["Added", "an", "environment", "object", "modified", "JSON", "utility", "response", "methods", "added", "Hello", "route", "handler", "as", "an", "example"], "add_tokens": "\" \" // - AutomaticOptions automatically responds to OPTIONS requests // Set up a new environment object env . G = & env . Environment { Log : log , Config : & env . Config { BindAddress : * bindAddress , APIVersion : * apiVersion , LogFormatterType : * logFormatterType , } , }", "del_tokens": "// - AutomaticOptions", "commit_type": "add"}
{"commit_tokens": ["fixed", "small", "bug", "introduced", "during", "race", "condition", "frustration"], "add_tokens": "for e := peerList . Front ( ) ; e != nil ; e = e . Next ( ) { if e == nil {", "del_tokens": "if peerList == nil { return peerSorterArr { } } e := peerList . Front ( ) for ; e != nil ; { if e != nil { e = e . Next ( )", "commit_type": "fix"}
{"commit_tokens": ["Added", "configuration", "for", "fetching", "topic", "metadata", "retries", "restarting", "connections", "fix"], "add_tokens": "go func ( ) { ba . askNextBatch <- topicPartition } ( ) ba . stopProcessing <- true", "del_tokens": "ba . askNextBatch <- topicPartition", "commit_type": "add"}
{"commit_tokens": ["use", "yaml", "naming", "scheme", "which", "is", "snake", "case"], "add_tokens": "Realm string `yaml:\"realm,omitempty\"` // p.e. \"employees\", \"services\" Uid string `yaml:\"uid,omitempty\"` // UnixName Cn string `yaml:\"cn,omitempty\"` // RealName", "del_tokens": "Realm string `yaml:\"Realm,omitempty\"` // p.e. \"employees\", \"services\" Uid string `yaml:\"Uid,omitempty\"` // UnixName Cn string `yaml:\"Cn,omitempty\"` // RealName", "commit_type": "use"}
{"commit_tokens": ["added", "small", "and", "medium", "tests"], "add_tokens": "Nsec : int64 ( mt . lastAdvertisedTime . Nanosecond ( ) ) , metric . Data = & rpc . Metric_StringData { StringData : t } metric . Data = & rpc . Metric_Float64Data { Float64Data : t } metric . Data = & rpc . Metric_Float32Data { Float32Data : t } metric . Data = & rpc . Metric_Int32Data { Int32Data : t } metric . Data = & rpc . Metric_Int64Data { Int64Data : int64 ( t ) } metric . Data = & rpc . Metric_Int64Data { Int64Data : t } metric . Data = & rpc . Metric_BytesData { BytesData : t } metric . Data = & rpc . Metric_BoolData { BoolData : t }", "del_tokens": "Nsec : int64 ( mt . Timestamp . Nanosecond ( ) ) , metric . Data = & rpc . Metric_StringData { t } metric . Data = & rpc . Metric_Float64Data { t } metric . Data = & rpc . Metric_Float32Data { t } metric . Data = & rpc . Metric_Int32Data { t } metric . Data = & rpc . Metric_Int64Data { int64 ( t ) } metric . Data = & rpc . Metric_Int64Data { t } metric . Data = & rpc . Metric_BytesData { t } metric . Data = & rpc . Metric_BoolData { t }", "commit_type": "add"}
{"commit_tokens": ["remove", "the", "go", "-", "libp2p", "-", "pubsub", "dependency"], "add_tokens": "is . Equal ( r . Data , \" \" ) is . Equal ( r . Data , \" \" ) is . Equal ( r . Data , \" \" )", "del_tokens": "is . Equal ( r . Data ( ) , \" \" ) is . Equal ( r . Data ( ) , \" \" ) is . Equal ( r . Data ( ) , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "in", "where", "the", "newline", "should", "just", "replace", "the", "space"], "add_tokens": "j := i - 0 copy ( plainRuneNew [ j + 1 : ] , plainRuneNew [ j : ] ) plainRuneNew [ j ] = plainWrappedRune [ j ]", "del_tokens": "tmpCell = append ( tmpCell , Cell { 0 , 0 , 0 } ) copy ( tmpCell [ i + 1 : ] , tmpCell [ i : ] ) copy ( plainRuneNew [ i + 1 : ] , plainRuneNew [ i : ] ) plainRuneNew [ i ] = plainWrappedRune [ i ]", "commit_type": "fix"}
{"commit_tokens": ["Move", "endpoint", "URL", "to", "config", "to", "enable", "sending", "from", "other", "regions"], "add_tokens": "// Endpoint is the AWS endpoint to use for requests. Endpoint string Endpoint : \" \" , return sesPost ( data , c . Endpoint , c . AccessKeyID , c . SecretAccessKey ) return sesPost ( data , c . Endpoint , c . AccessKeyID , c . SecretAccessKey ) return sesPost ( data , c . Endpoint , c . AccessKeyID , c . SecretAccessKey ) func sesGet ( data url . Values , endpoint , accessKeyID , secretAccessKey string ) ( string , error ) { func sesPost ( data url . Values , endpoint , accessKeyID , secretAccessKey string ) ( string , error ) {", "del_tokens": "const ( endpoint = \" \" ) return sesPost ( data , c . AccessKeyID , c . SecretAccessKey ) return sesPost ( data , c . AccessKeyID , c . SecretAccessKey ) return sesPost ( data , c . AccessKeyID , c . SecretAccessKey ) func sesGet ( data url . Values , accessKeyID , secretAccessKey string ) ( string , error ) { func sesPost ( data url . Values , accessKeyID , secretAccessKey string ) ( string , error ) {", "commit_type": "move"}
{"commit_tokens": ["update", "reminder", "state", "with", "CAS", "instead", "of", "Put"], "add_tokens": "reminderstatus . Value = newreminder _ , _ , err := kvApi . CAS ( reminderstatus , nil )", "del_tokens": "_ , err := kvApi . Put ( & consulapi . KVPair { Key : reminderkey , Value : newreminder } , nil )", "commit_type": "update"}
{"commit_tokens": ["Fix", "error", "handling", "in", "gpio", ".", "OpenPin"], "add_tokens": "if err != nil { return nil , err defer exportFile . Close ( ) if _ , err := exportFile . Write ( p . numberAsBytes ) ; err != nil { return nil , err } p . SetMode ( mode ) valueFile , err := os . Create ( fmt . Sprintf ( \" \" , gpioPathPrefix , numString , valuePathSuffix ) ) p . valueFile = valueFile p . err = err return p , nil", "del_tokens": "exportFile . Write ( p . numberAsBytes ) exportFile . Close ( ) p . err = err if err == nil { p . SetMode ( mode ) valueFile , err := os . Create ( fmt . Sprintf ( \" \" , gpioPathPrefix , numString , valuePathSuffix ) ) p . valueFile = valueFile p . err = err return p , p . err", "commit_type": "fix"}
{"commit_tokens": ["Add", "type", "conversion", "in", "tracker", "items", "to", "work", "items", "mapping"], "add_tokens": "AttributeMapper { AttributeExpression ( \" \" ) , AttributeConverter ( StringConverter { } ) } : models . SystemTitle , _ , ok := OneLevelMap [ string ( k . expression ) ] _ , ok := OneLevelMap [ string ( k . expression ) ] if k . expression == GithubAssignee { _ , ok := OneLevelMap [ string ( k . expression ) ] _ , ok := OneLevelMap [ string ( k . expression ) ] if k . expression == JiraAssignee {", "del_tokens": "AttributeExpression ( \" \" ) : models . SystemTitle , _ , ok := OneLevelMap [ string ( k ) ] _ , ok := OneLevelMap [ string ( k ) ] if k == GithubAssignee { _ , ok := OneLevelMap [ string ( k ) ] _ , ok := OneLevelMap [ string ( k ) ] if k == JiraAssignee {", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "the", "new", "version", "with", "transaction", "id", "in", "the", "methods"], "add_tokens": "func ( pcd service ) Read ( uuid string , transId string ) ( interface { } , bool , error ) { func ( pcd service ) Write ( thing interface { } , transId string ) error { func ( pcd service ) Delete ( uuid string , transId string ) ( bool , error ) {", "del_tokens": "func ( pcd service ) Read ( uuid string ) ( interface { } , bool , error ) { func ( pcd service ) Write ( thing interface { } ) error { func ( pcd service ) Delete ( uuid string ) ( bool , error ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "usage", "to", "get", "access", "to", "the", "underlying", "objects", "in", "the", "document"], "add_tokens": "atomFeed := ( & Atom { Feed : feed } ) . AtomFeed ( ) rssFeed := ( & Rss { Feed : feed } ) . RssFeed ( ) jsonFeed := ( & JSON { Feed : feed } ) . JSONFeed ( )", "del_tokens": "atomFeed := & Atom { feed } . AtomFeed ( ) rssFeed := & Rss { feed } . RssFeed ( ) jsonFeed := & JSON { feed } . JSONFeed ( )", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "the", "validate", "tag"], "add_tokens": "var errors errorList if e , ok := err . ( errorList ) ; ok { errors = e } else { errors = errorList { err } } fmt . Fprintf ( w , \" \\n \" , col . titles ( \" \" ) ) for _ , e := range errors { fmt . Fprintf ( w , \" \\n \" , col . errors ( e . Error ( ) ) ) } fmt . Fprintln ( w )", "del_tokens": "fmt . Fprintf ( w , \" \\n \\n \\n \" , col . titles ( \" \" ) , col . errors ( err . Error ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "collection", "name", "to", "error", "message"], "add_tokens": "// Unlock unlocks a collection. return fmt . Errorf ( \" \" , collection )", "del_tokens": "// Unlock unlocks a collection return fmt . Errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["implement", "kd", "kite", "install", "sub", "-", "command"], "add_tokens": "kdPath := getKdPath ( ) // getKdPath returns absolute of ~/.kd func getKdPath ( ) string { usr , err := user . Current ( ) if err != nil { panic ( err ) } return filepath . Join ( usr . HomeDir , \" \" ) }", "del_tokens": "usr , err := user . Current ( ) if err != nil { return } kdPath := filepath . Join ( usr . HomeDir , \" \" )", "commit_type": "implement"}
{"commit_tokens": ["updated", "client", "to", "accept", "a", "token", "when", "created", "to", "allow", "for", "authentication"], "add_tokens": "\" \" host string // token string // func New ( host , authtoken string ) ( * TCP , error ) { token : authtoken , // if the client needs to auth we'll manually send an auth message if auth . DefaultAuth != nil { return c . encoder . Encode ( & mist . Message { Command : \" \" , Data : c . token } ) }", "del_tokens": "host string func New ( host string ) ( * TCP , error ) {", "commit_type": "update"}
{"commit_tokens": ["Update", "bool", "to", "new", "form"], "add_tokens": "assert . True ( b == true && err == nil , \" \" ) assert . True ( b == false && err == nil , \" \" ) assert . True ( b == false && err != nil , \" \" )", "del_tokens": "assert . True ( b . Boolean ( ) == true && err == nil , \" \" ) assert . True ( b . Boolean ( ) == false && err == nil , \" \" ) assert . True ( b == nil && err != nil , \" \" )", "commit_type": "update"}
{"commit_tokens": ["Make", "CLI", "support", "parameter", "Args", "with", "or", "without", "Function"], "add_tokens": "sm := make ( map [ string ] interface { } ) sm [ strings . ToLower ( k ) ] = m [ k ] } _ , argsPresent := sm [ \" \" ] _ , funcPresent := sm [ \" \" ] if ! argsPresent || ( len ( m ) == 2 && ! funcPresent ) || len ( m ) > 2 { return fmt . Errorf ( \" \" ) return errors . New ( \" \" )", "del_tokens": "if len ( m ) != 2 { return fmt . Errorf ( \" \" ) } switch strings . ToLower ( k ) { case \" \" : case \" \" : default : return fmt . Errorf ( \" \" , k ) } return errors . New ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["added", "is", ".", "Relaxed", "(", "t", ")"], "add_tokens": "t T last string l sync . Mutex relaxed bool if ! i . relaxed { i . t . FailNow ( ) } if ! i . relaxed { i . t . FailNow ( ) } // Relaxed creates a new I capable of making // assertions, but will not fail immediately // allowing all assertions to run. func Relaxed ( t T ) I { return & i { t : t , relaxed : true } }", "del_tokens": "t T last string l sync . Mutex i . t . FailNow ( ) i . t . FailNow ( )", "commit_type": "add"}
{"commit_tokens": ["Changed", "exit", "code", "to", "1"], "add_tokens": "os . Exit ( 1 )", "del_tokens": "os . Exit ( - 1 )", "commit_type": "change"}
{"commit_tokens": ["fix", "Neg", "so", "it", "handles", "zero", "and", "NaN", "properly"], "add_tokens": "MaxPrecision = math . MaxInt32 // largest allowed Context precision. MinPrecision = 1 // smallest allowed Context precision. const ( // DefaultPrecision is the default precision used for decimals created as // literals or using new. DefaultPrecision = 16 // DefaultTraps is the default traps used for decimals created as literals // or using new. DefaultTraps = ^ ( Inexact | Rounded | Subnormal ) ) const ( noPrecision = - 1 noTraps Condition = 1 )", "del_tokens": "MaxPrec = math . MaxInt32 // largest allowed context precision. MinPrec = 0 // smallest allowed context precision. // DefaultPrecision is the default precision used for decimals created as // literals or using new. const DefaultPrecision = 16 const noPrecision = - 1 // DefaultTraps is the default traps used for decimals created as literals or // using new. const DefaultTraps = ^ ( Inexact | Rounded | Subnormal ) const noTraps Condition = 1", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "SQLite", "autoincrement", "with", "table", "SQL", "."], "add_tokens": "ManualPk bool // manual_pk `c.relname, ` + // ::varchar AS table_name `false ` + // ::boolean AS manual_pk err = q . Scan ( & t . Type , & t . TableName , & t . ManualPk )", "del_tokens": "`c.relname ` + // ::varchar AS table_name err = q . Scan ( & t . Type , & t . TableName )", "commit_type": "add"}
{"commit_tokens": ["Adding", "the", "retrieval", "of", "data", "for", "predicate", "possible", "bindings", "."], "add_tokens": "S * node . Node SBinding string SAlias string STypeAlias string SIDAlias string PID string PIDAlias string PAnchorAlias string", "del_tokens": "S * node . Node SBinding string SAlias string STypeAlias string SIDAlias string PID string PIDAlias string PAnchorAlias string", "commit_type": "add"}
{"commit_tokens": ["Fix", "enterprise", "seeds", "can", "t", "compile"], "add_tokens": "rule . Value . Scan ( ruleData . Value ) benefit . Value . Scan ( benefitData . Value )", "del_tokens": "rule . Value = ruleData . Value benefit . Value = benefitData . Value", "commit_type": "fix"}
{"commit_tokens": ["Added", "writer", ".", "WriteChunked", "support", "."], "add_tokens": "\" \" // WriteBody writes the contents of r to the wire. // WriteChunked writes the contents of r in chunked format to the wire. func ( w * writer ) WriteChunked ( r io . Reader ) error { if w . phase != body { return & phaseError { body , w . phase } } cw := httputil . NewChunkedWriter ( w ) if _ , err := io . Copy ( cw , r ) ; err != nil { return nil } w . phase = requestline return cw . Close ( ) }", "del_tokens": "// Write body writer the buffer on the wire.", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "sqlite3_test", "import", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Use", "Response", "instead", "of", "underlying", "ResponseWriter"], "add_tokens": "txn := agent . StartTransaction ( c . Request ( ) . URL ( ) . Path , c . Response ( ) , c . Request ( ) . Request )", "del_tokens": "txn := agent . StartTransaction ( c . Request ( ) . URL ( ) . Path , c . Response ( ) . ResponseWriter , c . Request ( ) . Request )", "commit_type": "use"}
{"commit_tokens": ["Add", "cases", "to", "pass", "only", "-", "h", "or", "--", "help", "."], "add_tokens": "{ \" \" } , } for _ , testCase := range testCases { buf := new ( bytes . Buffer ) helpText := \" \" cli := & CLI { Args : testCase , Commands : map [ string ] CommandFactory { \" \" : func ( ) ( Command , error ) { return new ( MockCommand ) , nil } , } , HelpFunc : func ( map [ string ] CommandFactory ) string { return helpText } , HelpWriter : buf , } code , err := cli . Run ( ) if err != nil { t . Errorf ( \" \" , testCase , err ) continue } if code != 0 { t . Errorf ( \" \" , testCase , code ) continue } if ! strings . Contains ( buf . String ( ) , helpText ) { t . Errorf ( \" \" , testCase , buf . String ( ) ) } } } func TestCLIRun_printHelpIllegal ( t * testing . T ) { testCases := [ ] [ ] string { { } ,", "del_tokens": "{ } ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "actionChan", "from", "LocalConnection"], "add_tokens": "go conn . run ( errorChan , finished , acceptNewPeer ) func ( conn * LocalConnection ) run ( errorChan <- chan error , finished chan <- struct { } , acceptNewPeer bool ) { err = conn . actorLoop ( errorChan ) func ( conn * LocalConnection ) actorLoop ( errorChan <- chan error ) ( err error ) {", "del_tokens": "actionChan chan <- connectionAction actionChan := make ( chan connectionAction , ChannelSize ) actionChan : actionChan , go conn . run ( actionChan , errorChan , finished , acceptNewPeer ) // Send an actor request to the actorLoop, but don't block if actorLoop has // exited. See http://blog.golang.org/pipelines for pattern. func ( conn * LocalConnection ) sendAction ( action connectionAction ) { select { case conn . actionChan <- action : case <- conn . finished : } } func ( conn * LocalConnection ) run ( actionChan <- chan connectionAction , errorChan <- chan error , finished chan <- struct { } , acceptNewPeer bool ) { err = conn . actorLoop ( actionChan , errorChan ) func ( conn * LocalConnection ) actorLoop ( actionChan <- chan connectionAction , errorChan <- chan error ) ( err error ) { case action := <- actionChan : err = action ( ) // The actor closure used by LocalConnection. If an action returns an error, // it will terminate the actor loop, which terminates the connection in turn. type connectionAction func ( ) error", "commit_type": "remove"}
{"commit_tokens": ["Added", "tests", "for", "validating", "request", "sizes"], "add_tokens": "// DidResume specifies that the file transfer resumed a previously // incomplete transfer. DidResume bool", "del_tokens": "// canResume specifies whether the server support ranged transfers for // resuming previous transfers. canResume bool", "commit_type": "add"}
{"commit_tokens": ["make", "CreateDirMust", "()", "return", "the", "dir"], "add_tokens": "func CreateDirMust ( path string ) string { return path", "del_tokens": "func CreateDirMust ( path string ) {", "commit_type": "make"}
{"commit_tokens": ["fix", "url", "generation", "for", "internal", "etcd", "discovery", "(", "cloudconfig", "/", "ignition", ")"], "add_tokens": "if mgr . useInternalEtcdDiscovery { mgr . etcdDiscoveryUrl = mgr . thisHost ( ) + \" \" }", "del_tokens": "mgr . etcdDiscoveryUrl = mgr . thisHost ( ) + \" \"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "calloc", "call", "with", "correct", "binary", "size", "."], "add_tokens": "cdashes := ( * C . double ) ( C . calloc ( 8 , C . size_t ( dashCount ) ) )", "del_tokens": "cdashes := ( * C . double ) ( C . calloc ( 4 , C . size_t ( dashCount ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "configure", "SSL", "for", "load", "balancers"], "add_tokens": "config , ok := r . context . RancherConfig [ r . name ] if ok { lbServiceOpts := & rancherClient . LoadBalancerService { } if err := populateCerts ( r . context . Client , lbServiceOpts , & config ) ; err != nil { return nil , err } if _ , err = r . context . Client . LoadBalancerService . Create ( lbServiceOpts ) ; err != nil {", "del_tokens": "if config , ok := r . context . RancherConfig [ r . name ] ; ok { _ , err = r . context . Client . LoadBalancerService . Create ( & rancherClient . LoadBalancerService { } ) if err != nil {", "commit_type": "add"}
{"commit_tokens": ["Updated", "README", "with", "new", "methods", "and", "cleaned", "up", "comments", "for", "those", "methods", "."], "add_tokens": "// BridgeFromName returns a tenus network bridge from an existing bridge of given name on the Linux host. // It returns error if the bridge of the given name cannot be found.", "del_tokens": "// NewBridgeFrom returns a network bridge on Linux host from the name passed as a parameter. // It is equivalent of running: ip link add name ${ifcName} type bridge // It returns error if the bridge can not be created.", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "raw", "connection", "interface", "."], "add_tokens": "rawConnIdx int // OpenRawConn opens a \"raw\" connection to the server which allows you to run any control // or data command you want. See the RawConn interface for more details. The RawConn will // not participate in the Client's pool (i.e. does not count against ConnectionsPerHost). func ( c * Client ) OpenRawConn ( ) ( RawConn , error ) { c . mu . Lock ( ) idx := c . rawConnIdx host := c . hosts [ idx % len ( c . hosts ) ] c . rawConnIdx ++ c . mu . Unlock ( ) return c . openConn ( - ( idx + 1 ) , host ) } if idx >= 0 { c . allCons [ idx ] = pconn }", "del_tokens": "c . allCons [ idx ] = pconn", "commit_type": "add"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// RemoteAddr returns the remote address", "del_tokens": "// LocalAddr returns the remote address", "commit_type": "fix"}
{"commit_tokens": ["Add", "gc", "build", "tag", "for", "the", "asm", "code", "."], "add_tokens": "// +build !amd64 !gc", "del_tokens": "// +build !amd64", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "resolveImage", "native", "function"], "add_tokens": "func resolveImage ( resolver Resolver , image string ) ( string , error ) { n , err := ParseImageName ( image ) if err != nil { return \" \" , err } if err := resolver . Resolve ( & n ) ; err != nil { return \" \" , err } return n . String ( ) , nil } // RegisterNativeFuncs adds kubecfg's native jsonnet functions to provided VM func RegisterNativeFuncs ( vm * jsonnet . VM , resolver Resolver ) { vm . NativeCallback ( \" \" , [ ] string { \" \" } , func ( image string ) ( string , error ) { return resolveImage ( resolver , image ) } )", "del_tokens": "func RegisterNativeFuncs ( vm * jsonnet . VM ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "the", "deprecated", "interface", "."], "add_tokens": "func NewMemStore ( maxKeys int ) GCRAStore { // The interface for `NewMemStore` is part of the public interface so // adding an error return would be a breaking change so we panic instead. // As of this writing, `lru.New` can only return an error if you pass // maxKeys <= 0 so this should never occur. panic ( err ) return m", "del_tokens": "func NewMemStore ( maxKeys int ) ( GCRAStore , error ) { return nil , err return m , nil", "commit_type": "add"}
{"commit_tokens": ["fixed", "the", "truncatechars", "-", "filter", "and", "added", "tests", "for", "it", "."], "add_tokens": "s := in . String ( ) newLen := param . Integer ( ) if newLen < len ( s ) { if newLen >= 3 { return AsValue ( fmt . Sprintf ( \" \" , s [ : newLen - 3 ] ) ) , nil } // Not enough space for the ellipsis return AsValue ( s [ : newLen ] ) , nil return in , nil", "del_tokens": "if ! in . CanSlice ( ) { return nil , errors . New ( \" \" ) return in . Slice ( 0 , param . Integer ( ) ) , nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "panic", "whe", "reflecting", "on", "Zero", "Type"], "add_tokens": "err_str := fmt . Sprintf ( \" \" , path , val_type , json_json )", "del_tokens": "err_str := fmt . Sprintf ( \" \" , path , val_type , json_val . Type ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "minor", "optimization", "for", "structonly", "&", "nostructlevel", "checks"], "add_tokens": "switch t { case diveTag : case omitempty : case structOnlyTag : cTag . isStructOnly = true case noStructLevelTag : cTag . isNoStructLevel = true", "del_tokens": "if t == diveTag { } if t == omitempty {", "commit_type": "add"}
{"commit_tokens": ["Added", "overall", "documentation", "to", "Bundle", "."], "add_tokens": "// A collection of concurrently-executing operations, each of which may fail. // // Operations are defined by functions that accept a context and return an // error. If any operation returns a non-nil error, all concurrent and future // operations will have their contexts cancelled . When Join() is called on a // bundle with one or more operations that returned an error, it always returns // the first error (i.e. that which led to the cancellation of others). // // Bundles can be used to set up pipelines of concurrent actors sending data to // each other, conveniently cancelling the pipeline if anything fails. A // typical use looks like the following: // // // Run a pipeline that consists of one goroutine listing object names, // // while N goroutines concurrently delete the listed objects one by one. // // If any listing or deletion operation fails, cancel the whole pipeline // // and return the error. // func deleteAllObjects(ctx context.Context, N int) error { // bundle := syncutil.NewBundle(ctx) // // // List objects into a channel. Assuming that listObjects responds to // // cancellation of its context, it will not get stuck blocking forever // // on a write into objectNames if the deleters return early in error // // before draining the channel. // objectNames := make(chan string) // bundle.Add(func(ctx context.Context) error { // return listObjects(ctx, objectNames) // }) // // // Run N deletion workers. // for i := 0; i < N; i++ { // bundle.Add(func(ctx context.Context) error { // for name := range objectNames { // if err := deleteObject(ctx, name); err != nil { // return err // } // } // }) // } // // // Wait for the whole pipeline to finish, and return its status. // return bundle.Wait() // } //", "del_tokens": "// XXX: Comments", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "to", "deep", "copy", "the", "field", "indices"], "add_tokens": "field . Index = make ( [ ] int , len ( path ) + 1 ) copy ( field . Index , append ( path , i ) )", "del_tokens": "field . Index = append ( path , i )", "commit_type": "make"}
{"commit_tokens": ["Fix", "subscriber", "name", "in", "prometheus"], "add_tokens": "cb := func ( ctx context . Context , m Msg ) error { oV = [ ] reflect . Value { reflect . ValueOf ( ctx ) , obj } oV = [ ] reflect . Value { reflect . ValueOf ( ctx ) , reflect . ValueOf ( m . Metadata ) , obj } pubsubHandled . WithLabelValues ( topic , c . ServiceName , strconv . FormatBool ( errInterface == nil ) ) . Inc ( ) subscriberSize . WithLabelValues ( topic , c . ServiceName ) . Add ( float64 ( len ( m . Data ) ) )", "del_tokens": "cb := func ( c context . Context , m Msg ) error { oV = [ ] reflect . Value { reflect . ValueOf ( c ) , obj } oV = [ ] reflect . Value { reflect . ValueOf ( c ) , reflect . ValueOf ( m . Metadata ) , obj } pubsubHandled . WithLabelValues ( topic , subscriberName , strconv . FormatBool ( errInterface == nil ) ) . Inc ( ) subscriberSize . WithLabelValues ( topic , subscriberName ) . Add ( float64 ( len ( m . Data ) ) )", "commit_type": "fix"}
{"commit_tokens": ["update", "scene", "to", "put", "sprites", "as", "left", "-", "bottom", "side", "as", "(", "0", "0", ")"], "add_tokens": "self . initCtrlUp ( ) self . ctrlup . X = ( self . ctrlup . W / 2 ) + CTRL_MARGIN_LEFT self . ctrlup . Y = CTRL_MARGIN_BOTTOM + self . ctrldown . H + CTRL_MARGIN_BETWEEN + ( self . ctrlup . H / 2 ) self . ctrldown . X = ( self . ctrldown . W / 2 ) + CTRL_MARGIN_LEFT self . ctrldown . Y = CTRL_MARGIN_BOTTOM + ( self . ctrldown . H / 2 )", "del_tokens": "self . initCtrlUp ( ) self . ctrlup . X = ( self . ctrlup . W / 2 ) + 10 self . ctrlup . Y = config . SCREEN_HEIGHT - ( self . ctrlup . H / 2 ) - self . ctrlup . H - CTRL_MARGIN_BOTTOM - CTRL_MARGIN_BETWEEN self . ctrldown . X = ( self . ctrldown . W / 2 ) + 10 self . ctrldown . Y = config . SCREEN_HEIGHT - ( self . ctrldown . H / 2 ) - CTRL_MARGIN_BOTTOM", "commit_type": "update"}
{"commit_tokens": ["use", "%v", "to", "print", "out", "value", "instead", "of", "casting", "to", "string"], "add_tokens": "fmt . Println ( \" \" , out . Hits . Hits [ 0 ] . Source )", "del_tokens": "fmt . Println ( string ( out . Hits . Hits [ 0 ] . Source ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "docstrings", "for", "PartitionAny", "and", "Offset", "*", "constants"], "add_tokens": "// PartitionAny represents any partition (for partitioning), // or unspecified value (for all other cases) // OffsetBeginning represents the earliest offset (logical) // OffsetEnd represents the latest offset (logical) // OffsetInvalid represents an invalid/unspecified offset // OffsetStored represents a stored offset", "del_tokens": "// Any partition (for partitioning), or unspecified value (for all other cases) // Earliest offset (logical) // Latest offset (logical) // Invalid/unspecified offset // Use stored offset", "commit_type": "fix"}
{"commit_tokens": ["Fix", "conversion", "for", "empty", "interface", "slices"], "add_tokens": "if err := mapstructure . Decode ( input , & stringVal ) ; err == nil { if err := mapstructure . Decode ( input , & mapVal ) ; err == nil { if err := mapstructure . Decode ( input , & sliceVal ) ; err == nil {", "del_tokens": "if err := mapstructure . WeakDecode ( input , & stringVal ) ; err == nil { if err := mapstructure . WeakDecode ( input , & mapVal ) ; err == nil { if err := mapstructure . WeakDecode ( input , & sliceVal ) ; err == nil {", "commit_type": "fix"}
{"commit_tokens": ["add", "rudamentary", "tests", "of", "the", "composer", "implementations"], "add_tokens": "if m . message != \" \" { out = append ( out , fmt . Sprintf ( tmpl , \" \" , m . message ) ) }", "del_tokens": "out = append ( out , fmt . Sprintf ( tmpl , \" \" , m . message ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "documentation", "for", "the", "metrics", "package"], "add_tokens": "// metrics.SetEmpireDefaultTags()", "del_tokens": "// metrics.SetAppName(\"myFancyApp\")", "commit_type": "add"}
{"commit_tokens": ["fixed", "Spill", "added", "more", "test", "cases"], "add_tokens": "towrite := [ ] byte ( \" \" ) m , _ := buf . Write ( towrite ) if m != len ( towrite ) { t . Errorf ( \" \" , m , len ( towrite ) ) } t . Error ( \" \" + string ( data [ : n ] ) ) } } func TestNoSpill ( t * testing . T ) { buf := NewSpill ( New ( 1024 ) , nil ) buf . Write ( [ ] byte ( \" \" ) ) data := make ( [ ] byte , 12 ) n , _ := buf . Read ( data ) if ! bytes . Equal ( data [ : n ] , [ ] byte ( \" \" ) ) { t . Error ( \" \" + string ( data [ : n ] ) )", "del_tokens": "buf . Write ( [ ] byte ( \" \" ) ) t . Error ( \" \" + string ( data [ : n ] ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "examples", "and", "make", "into", "swift", "package"], "add_tokens": "package swift", "del_tokens": "package main func main ( ) { c := Connection { username : \" \" , api_key : \" \" , authurl : \" \" , } err := c . Authenticate ( ) if err != nil { panic ( err ) } fmt . Println ( c ) containers , err := c . ListContainers ( nil ) fmt . Println ( containers , err ) containerinfos , err2 := c . ListContainersInfo ( nil ) fmt . Println ( containerinfos , err2 ) container , err3 := c . ListObjects ( \" \" , nil ) fmt . Println ( container , err3 ) containerinfo , err4 := c . ListObjectsInfo ( \" \" , nil ) fmt . Println ( containerinfo , err4 ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "square", "brackets", "to", "log", "level"], "add_tokens": "levelStrings = [ ... ] string { \" \" , \" \" , \" \" , \" \" , \" \" }", "del_tokens": "levelStrings = [ ... ] string { \" \" , \" \" , \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Add", "Reset", "()", "to", "cache"], "add_tokens": "import \" \" const ErrCannotRetrieveEntry = iteratorError ( \" \" ) mutex sync . Mutex it . mutex . Lock ( ) defer it . mutex . Unlock ( ) it . mutex . Lock ( ) defer it . mutex . Unlock ( )", "del_tokens": "import ( \" \" \" \" ) var ErrCannotRetrieveEntry = errors . New ( \" \" ) sync . Mutex it . Lock ( ) defer it . Unlock ( ) it . Lock ( ) defer it . Unlock ( )", "commit_type": "add"}
{"commit_tokens": ["add", "support", "of", "separate", "stderr", "output", "of", "container"], "add_tokens": "containers [ i ] . Tty = ctx . attachId ctx . attachId ++ containers [ i ] . Stderr = ctx . attachId ctx . attachId ++ ctx . ptys . ttys [ containers [ i ] . Tty ] = newAttachments ( i , true ) ctx . ptys . ttys [ containers [ i ] . Stderr ] = newAttachments ( i , true )", "del_tokens": "if spec . Tty { containers [ i ] . Tty = ctx . attachId ctx . attachId ++ ctx . ptys . ttys [ containers [ i ] . Tty ] = newAttachments ( i , true ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "public", "session", "CloseChan", "method"], "add_tokens": "if _ , err = stream . Write ( [ ] byte ( \" \" ) ) ; err != nil { if _ , err = stream . Write ( [ ] byte ( \" \" ) ) ; err != nil {", "del_tokens": "if _ , err := stream . Write ( [ ] byte ( \" \" ) ) ; err != nil { if _ , err := stream . Write ( [ ] byte ( \" \" ) ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Make", "successive", "invocation", "of", "api15gen", "produce", "the", "same", "code"], "add_tokens": "fields := [ ] string { } for _ , param := range p { fields = append ( fields , fmt . Sprintf ( \" \\\" \\\" \" , param . NativeName , param . Name ) )", "del_tokens": "fields := make ( [ ] string , len ( p ) ) for i , param := range p { fields [ i ] = fmt . Sprintf ( \" \\\" \\\" \" , param . NativeName , param . Name )", "commit_type": "make"}
{"commit_tokens": ["Added", "queue", "size", "to", "reporthandler", "and", "debug", "option"], "add_tokens": "Backoff int Debug bool if config . Debug { LogLevel ( logrus . DebugLevel ) } reportHandler : newReportHandler ( config . Retries , config . Backoff , config . QueueSize ) ,", "del_tokens": "reportHandler : newReportHandler ( config . Retries ) ,", "commit_type": "add"}
{"commit_tokens": ["Create", "namespaced", "context", "memcache", "locks", "."], "add_tokens": "memcacheCtx , err := memcacheContext ( tc ) if err != nil { return err } return memcacheSetMulti ( memcacheCtx , tx . lockMemcacheItems )", "del_tokens": "return memcacheSetMulti ( tc , tx . lockMemcacheItems )", "commit_type": "create"}
{"commit_tokens": ["Adding", "String", "()", "methods", "to", "make", "it", "simpler", "to", "debug", "dumped", "SendableErrors"], "add_tokens": "String ( ) string // Error is a safe for public consumption error message msg := fmt . Sprintf ( \" \" , e . Title , e . Detail ) if e . Source . Pointer != \" \" { msg += fmt . Sprintf ( \" \" , e . Source . Pointer ) } return msg } // String is a convenience function that prints out the full error including the // ISE which is useful when debugging, NOT to be used for returning errors to user, // use e.Error() for that func ( e * Error ) String ( ) string { return fmt . Sprintf ( \" \" , e . Error ( ) , e . ISE ) // String prints a formatted error list including ISE's, useful for debugging func ( e * ErrorList ) String ( ) string { err := \" \" for _ , e := range e . Errors { err = strings . Join ( [ ] string { err , fmt . Sprintf ( \" \" , e . String ( ) ) } , \" \\n \" ) } return err }", "del_tokens": "return fmt . Sprintf ( \" \" , e . Title , e . Detail , e . Source . Pointer )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "inode", ".", "AddChild", "."], "add_tokens": "dt fuseutil . DirentType ) { e := fuseutil . Dirent { Offset : fuse . DirOffset ( len ( inode . entries ) + 1 ) , Inode : id , Name : name , Type : dt , } inode . entries = append ( inode . entries , e ) }", "del_tokens": "dt fuseutil . DirentType )", "commit_type": "implement"}
{"commit_tokens": ["Updating", ".", "travis", "stuff", "-", ">", "tests", "are", "missing", "like", "entirely"], "add_tokens": "func TestJustToTest ( t * testing . T ) {", "del_tokens": "func TestMessageHandler ( t * testing . T ) { go func ( ) { server := newOutboundServer ( t ) server . Listen ( ) } ( )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "RabbitMQ", "plus", "some", "other", "stuff", "that", "apparently", "wasn", "t", "committed", "before", "..."], "add_tokens": "bus = new ( RabbitMQ )", "del_tokens": "log . Fatal ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["use", "sync", ".", "Once", "to", "prevent", "multiple", "executions", "of", "a", "fallback", "for", "a", "single", "execution", "of", "a", "command"], "add_tokens": "", "del_tokens": "", "commit_type": "use"}
{"commit_tokens": ["add", "helper", "func", "for", "primary", "keys"], "add_tokens": "funcMap [ \" \" ] = pkAttributes", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "initialize", "method", "to", "app", "to", "set", "configuration", "dependent", "properties"], "add_tokens": "// unique id for this application (node) uid string // hub to manage client connections hub * hub // adminHub to manage admin connections adminHub * adminHub // nodes is a map with information about nodes known nodes map [ string ] interface { } // engine to use - in memory or redis engine string // name of this node - based on hostname and port name string // reference to structure to work with projects and namespaces structure * structure // prefix before each channel channelPrefix string // channel name for admin messages adminChannel string // channel name for internal control messages between nodes controlChannel string // in seconds, how often connected clients must update presence info presencePingInterval int // in seconds, how long to consider presence info valid after receiving presence ping presenceExpireInterval int // initialize used to set configuration dependent application properties func ( app * application ) initialize ( ) { app . channelPrefix = viper . GetString ( \" \" ) app . adminChannel = app . channelPrefix + \" \" + \" \" app . controlChannel = app . channelPrefix + \" \" + \" \" app . presencePingInterval = viper . GetInt ( \" \" ) app . presenceExpireInterval = viper . GetInt ( \" \" ) }", "del_tokens": "\" \" uid string hub * hub adminHub * adminHub nodes map [ string ] interface { } engine string revisionTime time . Time name string structure * structure", "commit_type": "add"}
{"commit_tokens": ["Add", "addProcess", "cli", "exec", "command"], "add_tokens": "c = getClient ( ) id = context . Args ( ) . First ( ) resp , err := c . ListCheckpoint ( netcontext . Background ( ) , & types . ListCheckpointRequest { c := getClient ( ) if _ , err := c . CreateCheckpoint ( netcontext . Background ( ) , & types . CreateCheckpointRequest { c := getClient ( ) if _ , err := c . DeleteCheckpoint ( netcontext . Background ( ) , & types . DeleteCheckpointRequest {", "del_tokens": "cli = getClient ( ) id = context . Args ( ) . First ( ) resp , err := cli . ListCheckpoint ( netcontext . Background ( ) , & types . ListCheckpointRequest { cli := getClient ( ) if _ , err := cli . CreateCheckpoint ( netcontext . Background ( ) , & types . CreateCheckpointRequest { cli := getClient ( ) if _ , err := cli . DeleteCheckpoint ( netcontext . Background ( ) , & types . DeleteCheckpointRequest {", "commit_type": "add"}
{"commit_tokens": ["fix", "resource", "types", "declaration", "and", "examples"], "add_tokens": "for i , rts := range apiDef . ResourceTypes { for k := range rts { rt := rts [ k ] rt . postProcess ( k ) rts [ k ] = rt } apiDef . ResourceTypes [ i ] = rts", "del_tokens": "for k := range apiDef . ResourceTypes { rt := apiDef . ResourceTypes [ k ] rt . postProcess ( k ) apiDef . ResourceTypes [ k ] = rt", "commit_type": "fix"}
{"commit_tokens": ["Added", "function", "to", "get", "the", "EchoRequest", "from", "context", "."], "add_tokens": "/ * // /* Endpoints pageRouter := mux . NewRouter ( ) pageRouter . HandleFunc ( \" \" , HomePage ) pageRouter . HandleFunc ( \" \" , AboutPage ) router . PathPrefix ( \" \" ) . Handler ( negroni . New ( negroni . Wrap ( pageRouter ) , ) ) * / func GetEchoRequest ( r * http . Request ) * EchoRequest { return context . Get ( r , \" \" ) . ( * EchoRequest ) }", "del_tokens": "// /* Endpoints pageRouter := mux . NewRouter ( ) pageRouter . HandleFunc ( \" \" , HomePage ) pageRouter . HandleFunc ( \" \" , AboutPage ) router . PathPrefix ( \" \" ) . Handler ( negroni . New ( negroni . Wrap ( pageRouter ) , ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "test", "for", "anonymous", "function"], "add_tokens": "if \" \" != line && \" \" != line && \" \" != line {", "del_tokens": "if \" = ine", "commit_type": "fix"}
{"commit_tokens": ["add", "httputil", "and", "osutil", "functions"], "add_tokens": "func GetWriteFile ( url string , filename string , perm os . FileMode ) ( [ ] byte , error ) { return [ ] byte { } , err return [ ] byte { } , err return bytes , err", "del_tokens": "func GetWriteFile ( url string , filename string , perm os . FileMode ) error { return err return err return err", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "prompt", "package"], "add_tokens": "if err := p . rw . Outputln ( p . headerMsg ) ; err != nil { _ = p . rw . Outputln ( res ) //Once function starts interactive mode (one round). func ( p * Prompt ) Once ( ) error { if p == nil { return ErrTerminate } if len ( p . headerMsg ) > 0 { if err := p . rw . Outputln ( p . headerMsg ) ; err != nil { return err } } s , ok := p . get ( ) if ! ok { return ErrTerminate } if err := p . scanner . Err ( ) ; err != nil { return err } if res , err := p . function ( s ) ; err != nil { _ = p . rw . Outputln ( res ) if err != ErrTerminate { return err } return nil } else if err := p . rw . Outputln ( res ) ; err != nil { return err } return nil }", "del_tokens": "const ( headerStr = \" \" ) if err := p . rw . Outputln ( headerStr ) ; err != nil { _ = p . rw . Outputln ( )", "commit_type": "fix"}
{"commit_tokens": ["Creates", "a", "helper", "to", "parse", "request", "data", "into", "a", "per", "action", "structure"], "add_tokens": "Agent string `json:\"agent\"` Action string `json:\"action\"` Data json . RawMessage `json:\"data\"` a . Log . Debugf ( \" \" , string ( rpcrequest . Data ) ) // ParseRequestData parses the request parameters received from the client into a target structure // // Example used in a action: // // var rparams struct { // Package string `json:\"package\"` // } // // if !mcorpc.ParseRequestData(&rparams, req, reply) { // // the function already set appropriate errors on reply // return // } // // // do stuff with rparams.Package func ParseRequestData ( target interface { } , request * Request , reply * Reply ) bool { err := json . Unmarshal ( request . Data , target ) if err != nil { reply . Statuscode = InvalidData reply . Statusmsg = fmt . Sprintf ( \" \" , request . Agent , request . Action , err ) return false } return true }", "del_tokens": "Agent string `json:\"agent\"` Action string `json:\"action\"`", "commit_type": "create"}
{"commit_tokens": ["Changed", "json", "format", "to", "use", "maps"], "add_tokens": "func ( g * Group ) ID ( ) string { return g . Groupname } func ( g * Group ) Validate ( sys * system . System ) [ ] TestResult { sysgroup := sys . NewGroup ( g . Groupname , sys ) results = append ( results , ValidateValue ( g . Groupname , \" \" , g . Exists , sysgroup . Exists ) ) if ! g . Exists { results = append ( results , ValidateValue ( g . Gid , \" \" , g . Gid , sysgroup . Gid ) )", "del_tokens": "func ( s * Group ) Validate ( sys * system . System ) [ ] TestResult { sysgroup := sys . NewGroup ( s . Groupname , sys ) results = append ( results , ValidateValue ( s . Groupname , \" \" , s . Exists , sysgroup . Exists ) ) if ! s . Exists { results = append ( results , ValidateValue ( s . Gid , \" \" , s . Gid , sysgroup . Gid ) )", "commit_type": "change"}
{"commit_tokens": ["Implement", "keybindings", ".", "Rename", "AddView", "to", "SetView", "."], "add_tokens": "if _ , err := g . SetView ( \" \" , - 1 , - 1 , int ( 0.2 * float32 ( maxX ) ) , maxY - 5 ) ; err != nil { if _ , err := g . SetView ( \" \" , int ( 0.2 * float32 ( maxX ) ) , - 1 , maxX , maxY - 5 ) ; err != nil { if _ , err := g . SetView ( \" \" , - 1 , maxY - 5 , maxX , maxY ) ; err != nil {", "del_tokens": "if _ , err := g . AddView ( \" \" , - 1 , - 1 , int ( 0.2 * float32 ( maxX ) ) , maxY - 5 ) ; err != nil { if _ , err := g . AddView ( \" \" , int ( 0.2 * float32 ( maxX ) ) , - 1 , maxX , maxY - 5 ) ; err != nil { if _ , err := g . AddView ( \" \" , - 1 , maxY - 5 , maxX , maxY ) ; err != nil {", "commit_type": "implement"}
{"commit_tokens": ["fix", "a", "bug", "when", "a", "file", "isn", "t", "mono"], "add_tokens": "// 22050, 16bit, mono { \" \" , \" \" } , // 44100, 16bit, mono { \" \" , \" \" } , // 44100, 16bit, stereo { \" \" , \" \" } ,", "del_tokens": "{ \" \" , \" \" } ,", "commit_type": "fix"}
{"commit_tokens": ["allow", ".", "/", "foo", "relative", "urls"], "add_tokens": "TIMEOUT = 30 * time . Second KEEPALIVE = 30 * time . Second TLSHANDSHAKETIMEOUT = 10 * time . Second logger . Debugf ( \" \" , req . Method , req . URL ) defer logger . Debugf ( \" \" , req . Method , req . URL ) Timeout : TIMEOUT , // KeepAlive: KEEPALIVE, } ) . Dial", "del_tokens": "TIMEOUT = 30 * time . Second KEEPALIVE = 30 * time . Second TLSHANDSHAKETIMEOUT = 10 * time . Second logger . Debugf ( \" \" , req . Method , req . RequestURI ) defer logger . Debugf ( \" \" , req . Method , req . RequestURI ) Timeout : TIMEOUT , // KeepAlive: KEEPALIVE, } ) . Dial", "commit_type": "allow"}
{"commit_tokens": ["use", "ErrNotFound", "for", "deleting", "missing", "item"], "add_tokens": "var ( // ErrNotFound is returned when the requested item is not found ErrNotFound = fmt . Errorf ( \" \" ) ) return ErrNotFound", "del_tokens": "return fmt . Errorf ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["Add", "NOTICE", "level", "change", "formatter", "to", "an", "object", "try", "a", "new", "package", "name", "add", "log", "hijacking", "and", "add", "syslog", "support"], "add_tokens": "package capnslog } func NewStringFormatter ( w io . Writer ) * StringFormatter { return & StringFormatter { w : bufio . NewWriter ( w ) , } func NewGlogFormatter ( w io . Writer ) * GlogFormatter { g := & GlogFormatter { } g . w = bufio . NewWriter ( w ) return g } g . StringFormatter . Format ( pkg , level , depth + 1 , entries ... )", "del_tokens": "package corelog SetWriter ( w io . Writer ) func ( s * StringFormatter ) SetWriter ( w io . Writer ) { s . w = bufio . NewWriter ( w ) } g . StringFormatter . Format ( pkg , level , depth , entries ... )", "commit_type": "add"}
{"commit_tokens": ["adding", "GetRunningVersion", "/", "GetLatestRelease", "/", "CheckLatest"], "add_tokens": "\" \" running , err := api . GetRunningVersion ( ) latest , err := api . GetLatestRelease ( ) if err != nil { log . Fatal ( err ) fmt . Printf ( \" \\n \" , latest ) fmt . Printf ( \" \\n \" , running ) if ! api . CheckLatest ( running , latest ) { os . Exit ( 1 ) }", "del_tokens": "\" \" versions , err := api . GetVersions ( ) candidates := api . Versions { } for _ , version := range api . FilterVersionsToPlatform ( versions ) { // Make sure we skip any version where the version // does not equal the full version. This happens when // there's a qualifier in the version such as 'alpha' // or 'beta'. if version . Version . String ( ) != version . FullVersion { continue } candidates = append ( candidates , version ) sort . Sort ( candidates ) latest := candidates [ len ( candidates ) - 1 ] fmt . Println ( latest ) //runt //for _, value := range candidates { // fmt.Println(value) //}", "commit_type": "add"}
{"commit_tokens": ["add", "version", "flag", "add", "magefile", "for", "building"], "add_tokens": "force , verbose , list , help , mageInit , keep , showVersion bool timestamp , commitHash , gitTag string flag . BoolVar ( & showVersion , \" \" , false , \" \" ) if showVersion { fmt . Println ( \" \" , gitTag ) fmt . Println ( \" \" , timestamp ) fmt . Println ( \" \" , commitHash ) return 0 }", "del_tokens": "force , verbose , list , help , mageInit , keep bool tags string", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "SL_Virtual_Guest#getPowerState", "method"], "add_tokens": "response , err := slvgs . client . DoRawHttpRequest ( fmt . Sprintf ( \" \" , slvgs . GetName ( ) , instanceId ) , \" \" , new ( bytes . Buffer ) ) return false , errors . New ( fmt . Sprintf ( \" \" , instanceId , res ) ) func ( slvgs * softLayer_Virtual_Guest_Service ) GetPowerState ( instanceId int ) ( datatypes . SoftLayer_Virtual_Guest_Power_State , error ) { response , err := slvgs . client . DoRawHttpRequest ( fmt . Sprintf ( \" \" , slvgs . GetName ( ) , instanceId ) , \" \" , new ( bytes . Buffer ) ) if err != nil { return datatypes . SoftLayer_Virtual_Guest_Power_State { } , err } vgPowerState := datatypes . SoftLayer_Virtual_Guest_Power_State { } err = json . Unmarshal ( response , & vgPowerState ) if err != nil { return datatypes . SoftLayer_Virtual_Guest_Power_State { } , err } return vgPowerState , nil }", "del_tokens": "response , err := slvgs . client . DoRawHttpRequest ( fmt . Sprintf ( \" \" , instanceId ) , \" \" , new ( bytes . Buffer ) ) return false , errors . New ( fmt . Sprintf ( \" \" , instanceId , res ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "private", "networks", "support", "to", "listener", "and", "dialer"], "add_tokens": "ipnet \" \" // Protector makes dialer part of a private network. // It includes implementation details how connection are protected. // Can be nil, then dialer is in public network. Protector ipnet . Protector func NewDialer ( p peer . ID , pk ci . PrivKey , pro ipnet . Protector , wrap WrapFunc ) * Dialer { Protector : pro , logdial [ \" \" ] = ( d . Protector != nil ) if d . Protector == nil && ipnet . ShouldForcePrivateNetwork ( ) { log . Error ( \" \" + \" \" ) return nil , ipnet . ErrNotInPrivateNetwork } if d . Protector != nil { pconn , err := d . Protector . Protect ( c ) if err != nil { c . Close ( ) errOut = err return } c = pconn }", "del_tokens": "func NewDialer ( p peer . ID , pk ci . PrivKey , wrap WrapFunc ) * Dialer {", "commit_type": "add"}
{"commit_tokens": ["Add", "deleting", "role", "function", "to", "role", "manager", "."], "add_tokens": "// Add the inheritance link between role: name1 and role: name2. // aka role: name1 inherits role: name2. // Delete the inheritance link between role: name1 and role: name2. // aka role: name1 does not inherit role: name2 any more. func ( rm * RoleManager ) DeleteLink ( name1 string , name2 string ) { if ! rm . hasRole ( name1 ) || ! rm . hasRole ( name2 ) { return } role1 := rm . createRole ( name1 ) role2 := rm . createRole ( name2 ) role1 . deleteRole ( role2 ) } func ( r * Role ) deleteRole ( role * Role ) { for i , rr := range r . roles { if rr . name == role . name { r . roles = append ( r . roles [ : i ] , r . roles [ i + 1 : ] ... ) return } } }", "del_tokens": "// Add the link between role: name1 and role: name2. // aka name1 inherits role: name2.", "commit_type": "add"}
{"commit_tokens": ["improve", "dfa", "building", "cache", "in", "regexp", "and", "levenshtein"], "add_tokens": "\" \" dfa * dfa lev * dynamicLevenshtein cache map [ string ] int keyBuf [ ] byte func levStateKey ( levState [ ] int , buf [ ] byte ) [ ] byte { if cap ( buf ) < 8 * len ( levState ) { buf = make ( [ ] byte , 8 * len ( levState ) ) } else { buf = buf [ 0 : 8 * len ( levState ) ] } for i , state := range levState { binary . LittleEndian . PutUint64 ( buf [ i * 8 : ] , uint64 ( state ) ) } return buf } b . keyBuf = levStateKey ( levState , b . keyBuf ) v , ok := b . cache [ string ( b . keyBuf ) ] b . cache [ string ( b . keyBuf ) ] = newV", "del_tokens": "dfa * dfa lev * dynamicLevenshtein cache map [ string ] int k := fmt . Sprintf ( \" \" , levState ) v , ok := b . cache [ k ] b . cache [ k ] = newV", "commit_type": "improve"}
{"commit_tokens": ["improve", "parse", ".", "fi", "domain"], "add_tokens": "if strings . Contains ( v , \" \" ) { vv := strings . SplitN ( v , \" \" , 2 ) vv [ 0 ] = strings . Trim ( vv [ 0 ] , \" \" ) if token == \" \" && vv [ 0 ] == \" \" { vv [ 0 ] = \" \" v = fmt . Sprintf ( \" \" , vv [ 0 ] , vv [ 1 ] ) } if token != \" \" {", "del_tokens": "if token != \" \" { // special case as for various reasons this was causing lots of issues if token == \" \" && strings . Contains ( v , \" \" ) { v = strings . Replace ( v , \" \" , \" \" , 1 )", "commit_type": "improve"}
{"commit_tokens": ["Use", "a", "custom", "ringbuffer", "queue", "."], "add_tokens": "buffer * queue ch := & InfiniteChannel { make ( chan interface { } ) , make ( chan interface { } ) , newQueue ( ) } return ch . buffer . length ( ) for ch . buffer . length ( ) > 0 { ch . output <- ch . buffer . peek ( ) ch . buffer . dequeue ( ) if ch . buffer . length ( ) == 0 { ch . buffer . enqueue ( elem ) ch . buffer . enqueue ( elem ) case ch . output <- ch . buffer . peek ( ) : ch . buffer . dequeue ( )", "del_tokens": "buffer [ ] interface { } ch := & InfiniteChannel { make ( chan interface { } ) , make ( chan interface { } ) , nil } return len ( ch . buffer ) for _ , elem := range ch . buffer { ch . output <- elem if len ( ch . buffer ) == 0 { ch . buffer = append ( ch . buffer , elem ) ch . buffer = append ( ch . buffer , elem ) case ch . output <- ch . buffer [ 0 ] : ch . buffer = ch . buffer [ 1 : ]", "commit_type": "use"}
{"commit_tokens": ["remove", "container", "should", "not", "block", "run", "and", "wait"], "add_tokens": "defer func ( ) { go c . removeOneContainer ( container , containerJSON ) } ( )", "del_tokens": "defer c . removeOneContainer ( container , containerJSON )", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "better", "explanation", "to", "the", "purpose", "of", "the", "HTTPClient", "interface", "."], "add_tokens": "// SetHTTPClient sets the http client for performing API requests. // This method allows overriding the default http client with any // implementation of the HTTPClient interface. It is typically used // to have finer control of the http request.", "del_tokens": "// SetHTTPClient sets the HTTP client for performing API requests.", "commit_type": "add"}
{"commit_tokens": ["fix", "token", "url", "to", "switch", "to", "new", "endpoint"], "add_tokens": "TokenURL : \" \" ,", "del_tokens": "TokenURL : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "up", "help", "text", "for", "keys", "recover"], "add_tokens": "Short : \" \" , Long : `Recover a private key from a seed phrase. I really hope you wrote this down when you created the new key . The seed is only displayed on creation , never again . You can also use this to copy a key between multiple testnets , simply by \" \" the key in the other nets you want to copy to . Of course , it has no coins on the other nets , just the same address . `, RunE : runRecoverCmd ,", "del_tokens": "Short : \" \" , RunE : runRecoverCmd ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "default", "not", "used", "Eval", "test"], "add_tokens": "input : \" \" ,", "del_tokens": "input : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "single", "-", "use", "private", "method"], "add_tokens": "for i , el := range all { if el == pkg { all = append ( all [ : i ] , all [ i + 1 : ] ... ) return all", "del_tokens": "all = remove ( all , pkg ) return all } func remove ( list [ ] * bmrel . Package , element * bmrel . Package ) [ ] * bmrel . Package { for i , pkg := range list { if element == pkg { return append ( list [ : i ] , list [ i + 1 : ] ... ) return list", "commit_type": "remove"}
{"commit_tokens": ["Fix", "setting", "target", "scale", "to", "zero", "on", "start"], "add_tokens": "if service , err := rToService . RancherService ( ) ; err != nil { } else if service == nil { if err := rToService . Create ( ) ; err != nil { return err } if err := rToService . Scale ( 0 ) ; err != nil { return err }", "del_tokens": "if err := rToService . Create ( ) ; err != nil { } if err := rToService . Scale ( 0 ) ; err != nil { return err", "commit_type": "fix"}
{"commit_tokens": ["Added", "iterator", "unit", "test", "."], "add_tokens": "// entry will // i hate this, but it is really the best way parent * node", "del_tokens": "parent * node // i hate this, but it is really the best way cache [ ] * node // we'll not need this for the leaf node xft . cache = make ( [ ] * node , bits )", "commit_type": "add"}
{"commit_tokens": ["Improve", "Windows", "compatibility", "for", "Match", "and", "Glob"], "add_tokens": "\" \" return matchWithSeparator ( pattern , name , os . PathSeparator ) // On Windows systems, this will return the drive name ('C:'), on others, // it will return an empty string. volumeName := filepath . VolumeName ( pattern ) // If the first pattern component is equal to the volume name, then the // pattern is an absolute path. if patternComponents [ 0 ] == volumeName { return doGlob ( fmt . Sprintf ( \" \" , volumeName , string ( os . PathSeparator ) ) , patternComponents [ 1 : ] , matches )", "del_tokens": "return matchWithSeparator ( pattern , name , '/' ) // if the first pattern component is blank, the pattern is an absolute path. if patternComponents [ 0 ] == \" \" { return doGlob ( string ( filepath . Separator ) , patternComponents , matches )", "commit_type": "improve"}
{"commit_tokens": ["Fix", "parsing", "A", "records", "."], "add_tokens": "domain := p . setDomain ( t ) if ips , err := net . LookupIP ( domain ) ; err != nil {", "del_tokens": "var host string if ! isEmpty ( & t . Value ) { host = t . Value } else { host = p . Domain } if ips , err := net . LookupIP ( host ) ; err != nil { var wg sync . WaitGroup wg . Add ( len ( ips ) )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "helper", "to", "get", "gauge", "home", "directory"], "add_tokens": "func GetGaugeHomeDirectory ( ) ( string , error ) { return filepath . Join ( userHome , dotGauge ) , nil } func GetPrimaryPluginsInstallDir ( ) ( string , error ) { gaugeHome , err := GetGaugeHomeDirectory ( ) if err != nil { return \" \" , err } return filepath . Join ( gaugeHome , Plugins ) , nil", "del_tokens": "func GetPrimaryPluginsInstallDir ( ) ( string , error ) { return filepath . Join ( userHome , dotGauge , Plugins ) , nil", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "fetching", "older", "and", "newer", "messages", ".", "Add", "tests"], "add_tokens": "Language string // if Language is a valid 2 characters identifier, show posts from users (users selected enabling/disabling following & folowers) speaking that Language N int // number of post to return (min 1, max 20) Older int64 // if specified, tells to the function using this struct to return N posts OLDER (created before) than the post with the specified \"Older\" ID Newer int64 // if specified, tells to the function using this struct to return N posts NEWER (created after) the post with the specified \"Newer\"\" ID if options . N > 0 && options . N < 20 { if options . Older != 0 { query = query . Where ( \" \" , options . Older ) } if options . Newer != 0 { query = query . Where ( \" \" , options . Newer )", "del_tokens": "Language string // if Language is a valid 2 characters identifier, show posts from users (users selected enabling/disabling following & folowers) speaking that Language N int // number of post to return (min 1, max 20) After int // if specified, tells to the function using this struct to return N posts after the post with the specified \"After\" ID if options . N > 0 && options . N <= 20 { if options . After != 0 { query = query . Where ( \" \" , options . After )", "commit_type": "add"}
{"commit_tokens": ["Add", "SSL", "support", "for", "KV", "."], "add_tokens": "type cfgNodeExt struct { Services struct { Kv uint16 `json:\"kv\"` Capi uint16 `json:\"capi\"` Mgmt uint16 `json:\"mgmt\"` KvSsl uint16 `json:\"kvSSL\"` CapiSsl uint16 `json:\"capiSSL\"` MgmtSsl uint16 `json:\"mgmtSSL\"` } `json:\"services\"` Hostname string `json:\"hostname\"` } VBucketServerMap cfgVBucketServerMap `json:\"vBucketServerMap\"` Nodes [ ] cfgNode `json:\"nodes\"` NodesExt [ ] cfgNodeExt `json:\"nodesExt,omitempty\"`", "del_tokens": "VBSMJson cfgVBucketServerMap `json:\"vBucketServerMap\"` NodesJSON [ ] cfgNode `json:\"nodes\"`", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "few", "more", "controls"], "add_tokens": "termbox . SetCell ( x1 , y1 , '+' , fg , bg ) FillWithChar ( '-' , x1 + 1 , y1 , x2 - 1 , y1 , fg , bg ) termbox . SetCell ( x2 , y1 , '+' , fg , bg ) termbox . SetCell ( x1 , y2 , '+' , fg , bg ) FillWithChar ( '-' , x1 + 1 , y2 , x2 - 1 , y2 , fg , bg ) termbox . SetCell ( x2 , y2 , '+' , fg , bg ) if numSpaces >= 0 { return fmt . Sprintf ( \" \" , txt , strings . Repeat ( \" \" , numSpaces ) ) } return txt", "del_tokens": "termbox . SetCell ( x1 , y1 , '┌', f , b ) FillWithChar ( '─', x +1 , y , x -1 , y , f , b ) termbox . SetCell ( x2 , y1 , '┐', f , b ) termbox . SetCell ( x1 , y2 , '└', f , b ) FillWithChar ( '─', x +1 , y , x -1 , y , f , b ) termbox . SetCell ( x2 , y2 , '┘', f , b ) return fmt . Sprintf ( \" \" , txt , strings . Repeat ( \" \" , numSpaces ) )", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "that", "install", "/", "enable", "dirs", "exist"], "add_tokens": "err := s . fs . MkdirAll ( path , os . FileMode ( 0755 ) ) return \" \" , bosherr . WrapError ( err , \" \" ) err := s . fs . MkdirAll ( filepath . Dir ( enablePath ) , os . FileMode ( 0755 ) ) if err != nil { return bosherr . WrapError ( err , \" \" ) } err = s . fs . Symlink ( installPath , enablePath )", "del_tokens": "err := s . fs . MkdirAll ( path , os . ModeDir ) return \" \" , bosherr . WrapError ( err , \" \" ) err := s . fs . Symlink ( installPath , enablePath )", "commit_type": "make"}
{"commit_tokens": ["Improve", "test", "coverage", ".", "Correct", "*", "unary", "operator"], "add_tokens": "return refVal . Elem ( ) . Interface ( ) , nil", "del_tokens": "return refVal . Elem ( ) , nil", "commit_type": "improve"}
{"commit_tokens": ["Add", "tests", "for", "the", "adapter", "functions", "."], "add_tokens": "var mConverter = new ( MarathonConverter ) services := mConverter . convertToServices ( [ ] * gomarathon . Application { & app1 , & app2 } ) service := mConverter . convertToService ( & application ) apps := mConverter . convertToApps ( [ ] * api . Service { & service1 , & service2 } ) app := mConverter . convertToApp ( & service )", "del_tokens": "services := convertToServices ( [ ] * gomarathon . Application { & app1 , & app2 } ) service := convertToService ( & application ) apps := convertToApps ( [ ] * api . Service { & service1 , & service2 } ) app := convertToApp ( & service )", "commit_type": "add"}
{"commit_tokens": ["Fix", "preserving", "existing", "query", "parameters", "in", "redirect_uri"], "add_tokens": "var q url . Values if r . RedirectInFragment { // start with empty set for fragment q = url . Values { } } else { // add parameters to existing query q = u . Query ( ) }", "del_tokens": "q := u . Query ( ) u . RawQuery = \" \"", "commit_type": "fix"}
{"commit_tokens": ["Use", "bytes", ".", "Reader", "instead", "of", "bytes", ".", "Buffer"], "add_tokens": "return d . WriteStream ( key , bytes . NewReader ( val ) , false ) buf := bytes . NewReader ( val )", "del_tokens": "return d . WriteStream ( key , bytes . NewBuffer ( val ) , false ) buf := bytes . NewBuffer ( val )", "commit_type": "use"}
{"commit_tokens": ["Add", "tests", "and", "remove", "dead", "code"], "add_tokens": "func before ( funcs ... httptransport . BeforeFunc ) httpClientOption { return func ( c * httpClient ) { c . before = append ( c . before , funcs ... ) }", "del_tokens": "func before ( f httptransport . BeforeFunc ) httpClientOption { return func ( c * httpClient ) { c . before = append ( c . before , f ) }", "commit_type": "add"}
{"commit_tokens": ["Add", "sample", ".", "Fix", "README", ".", "Add", "LICENSE", ".", "Stuff", "."], "add_tokens": "name string brush Brush fg Paint got := test . brush ( test . name ) fmt . Printf ( \" \\n \" , Red ( \" \" ) ) // or rename them and invoke them yel := Yellow", "del_tokens": "name string styleFunc func ( ) Brush fg Paint got := test . styleFunc ( ) ( test . name ) yel := Yellow ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "Timetracking", "JIRA", "issue", "field", "handling"], "add_tokens": "Timetracking * Timetracking `json:\"timetracking,omitempty\" structs:\"timetracking,omitempty\"` // Timetracking represents the timetracking fields of a JIRA issue. type Timetracking struct { OriginalEstimate string `json:\"originalEstimate,omitempty\" structs:\"originalEstimate,omitempty\"` RemainingEstimate string `json:\"remainingEstimate,omitempty\" structs:\"remainingEstimate,omitempty\"` TimeSpent string `json:\"timeSpent,omitempty\" structs:\"timeSpent,omitempty\"` OriginalEstimateSeconds int `json:\"originalEstimateSeconds,omitempty\" structs:\"originalEstimateSeconds,omitempty\"` RemainingEstimateSeconds int `json:\"remainingEstimateSeconds,omitempty\" structs:\"remainingEstimateSeconds,omitempty\"` TimeSpentSeconds int `json:\"timeSpentSeconds,omitempty\" structs:\"timeSpentSeconds,omitempty\"` } Name string `json:\"name,omitempty\" structs:\"name,omitempty\"`", "del_tokens": "// * \"timetracking\": {}, Name string `json:\"name,omitempty\" structs:name,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "sign", "subcommand", "to", "generate", "a", "signed", "URL", "for", "a", "specified", "object"], "add_tokens": "\" \" bosh - gcscli - c config . json exists < remote - blob > # Generate a signed url for an object bosh - gcscli - c config . json sign < remote - blob > < http action > < expiry > Where : - < http action > is GET , PUT , or DELETE - < expiry > is a duration string less than 7 days ( e . g . \" \" ) ` case \" \" : if len ( nonFlagArgs ) != 4 { log . Fatalf ( \" \\n \" , len ( nonFlagArgs ) ) } id , action , expiry := nonFlagArgs [ 1 ] , nonFlagArgs [ 2 ] , nonFlagArgs [ 3 ] var expiryDuration time . Duration expiryDuration , err = time . ParseDuration ( expiry ) if err != nil { log . Fatalf ( \" \" , err ) } url := \" \" url , err = blobstoreClient . Sign ( id , action , expiryDuration ) if err == nil { os . Stdout . WriteString ( url ) }", "del_tokens": "bosh - gcscli - c config . json exists < remote - blob > `", "commit_type": "add"}
{"commit_tokens": ["Add", "thread", "-", "safety", "to", "RequestContext"], "add_tokens": "import ( \" \" \" \" ) mutex sync . RWMutex r . mutex . Lock ( ) r . mutex . Unlock ( ) r . mutex . RLock ( ) defer r . mutex . RUnlock ( ) r . mutex . Lock ( ) r . mutex . Unlock ( ) r . mutex . RLock ( ) r . mutex . RUnlock ( ) // Note: Calling Error from different threads can cause race conditions. Also // calling Error more than once causes a runtime panic! var contextMutex sync . RWMutex contextMutex . RLock ( ) defer contextMutex . RUnlock ( ) contextMutex . Lock ( ) contextMutex . Unlock ( )", "del_tokens": "import \" \" // Note: calling Error twice will cause a runtime panic!", "commit_type": "add"}
{"commit_tokens": ["Adds", "source", "IP", "in", "built", "-", "in", "logger"], "add_tokens": "stdlogger := log . New ( os . Stdout , \" \" , 0 ) //errlogger := log.New(os.Stderr, \"\", 0) // save the IP of the requester requester := c . Req . Header . Get ( \" \" ) // if the requester-header is empty, check the forwarded-header if requester == \" \" { requester = c . Req . Header . Get ( \" \" ) } // if the requester is still empty, use the hard-coded address from the socket if requester == \" \" { requester = c . Req . RemoteAddr } stdlogger . Printf ( \" \\n \" , requester , stdlogger . Println ( c . Errors . String ( ) )", "del_tokens": "\" \" logger := log . New ( os . Stdout , \" \" , 0 ) logger . Printf ( \" \\n \" , fmt . Println ( c . Errors . String ( ) )", "commit_type": "add"}
{"commit_tokens": ["Change", "String", "to", "return", "the", "long", "form", "by", "default"], "add_tokens": "func ( id ID ) String ( ) string { return id . Pretty ( ) } func ( id ID ) ShortString ( ) string {", "del_tokens": "func ( id ID ) String ( ) string {", "commit_type": "change"}
{"commit_tokens": ["Updating", "Collection", "interface", "to", "enable", "the", "Collection", "to", "accept", "geniric", "objects", "and", "to", "return", "them"], "add_tokens": "Create ( interface { } ) error Read ( query . Definition ) ( interface { } , error ) ReadOne ( string ) ( interface { } , error ) Update ( interface { } ) error UpdateOne ( interface { } ) error Destroy ( interface { } ) error DestroyOne ( interface { } ) error", "del_tokens": "Create ( ) error Read ( query . Definition ) error ReadOne ( string ) error Update ( ) error UpdateOne ( string ) error Destroy ( ) error DestroyOne ( string ) error", "commit_type": "update"}
{"commit_tokens": ["Add", "an", "onEvict", "function", "called", "when", "an", "element", "is", "removed", "."], "add_tokens": "onEvicted func ( key interface { } , value interface { } ) // Evict each element in the list. for c . Len ( ) > 0 { c . RemoveOldest ( ) } if c . onEvicted != nil { c . onEvicted ( kv . key , kv . value ) }", "del_tokens": "c . lock . Lock ( ) defer c . lock . Unlock ( ) c . evictList = list . New ( ) c . items = make ( map [ interface { } ] * list . Element , c . size )", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "print", "output", "of", "submit", "in", "json", "."], "add_tokens": "printWorkflow ( getArgs . output , wf ) } func printWorkflow ( outFmt string , wf * wfv1 . Workflow ) { case \" \" : fmt . Println ( wf . ObjectMeta . Name ) printWorkflowHelper ( wf ) func printWorkflowHelper ( wf * wfv1 . Workflow ) {", "del_tokens": "outFmt := getArgs . output printWorkflow ( wf ) func printWorkflow ( wf * wfv1 . Workflow ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "param", "name", "to", "camel", "case", "."], "add_tokens": "case \" \" , \" \" , \" \" , \" \" :", "del_tokens": "case \" \" , \" \" , \" \" : case \" \" :", "commit_type": "change"}
{"commit_tokens": ["Add", "json", "omitempty", "tag", "to", "FormErrors", "fields"], "add_tokens": "Errors [ ] string `json:\"errors,omitempty\"` FieldErrors map [ string ] [ ] string `json:\"field-errors,omitempty\"`", "del_tokens": "Errors [ ] string `json:\"errors\"` FieldErrors map [ string ] [ ] string `json:\"field-errors\"`", "commit_type": "add"}
{"commit_tokens": ["fix", "syntax", "error", "in", "docs", "for", "complex", "datatype"], "add_tokens": "var person = & Person { }", "del_tokens": "var person & Person { }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Ctrl", "+", "U", "Behavior", "(", "Delete", "line", "before", "cursor", ")"], "add_tokens": "i . value = i . value [ i . cursor + len ( i . value ) : ]", "del_tokens": "i . value = i . value [ i . cursor : ]", "commit_type": "fix"}
{"commit_tokens": ["Use", "http", "status", "code", "constants", "instead", "of", "hardcoding"], "add_tokens": "var NotImplemented = & ErrorResponse { http . StatusNotImplemented , \" \" } var NotFound = & ErrorResponse { http . StatusNotFound , \" \" } var Forbidden = & ErrorResponse { http . StatusForbidden , \" \" } return & ErrorResponse { http . StatusBadRequest , err . Error ( ) } return & ErrorResponse { http . StatusInternalServerError , err . Error ( ) }", "del_tokens": "var NotImplemented = & ErrorResponse { 501 , \" \" } var NotFound = & ErrorResponse { 404 , \" \" } var Forbidden = & ErrorResponse { 403 , \" \" } return & ErrorResponse { 400 , err . Error ( ) } return & ErrorResponse { 500 , err . Error ( ) }", "commit_type": "use"}
{"commit_tokens": ["Update", "README", "for", "method", "Parse", "()"], "add_tokens": "err = errors . New ( \" \" + str )", "del_tokens": "err = errors . New ( \" \" + str )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "TLS", "for", "Transmitter"], "add_tokens": "\" \" // NewTransmitter creates and initializes a new Transmitter. return newTransmitter ( host , port , eli , bindParams , nil ) } // NewTransmitterTLs creates and initializes a new Transmitter using TLS. func NewTransmitterTLS ( host string , port int , eli int , bindParams Params , config * tls . Config ) ( * Transmitter , error ) { if config == nil { config = & tls . Config { } } return newTransmitter ( host , port , eli , bindParams , config ) } // eli = EnquireLink Interval in Seconds func newTransmitter ( host string , port int , eli int , bindParams Params , config * tls . Config ) ( * Transmitter , error ) { var err error if config == nil { err = tx . Connect ( host , port ) } else { err = tx . ConnectTLS ( host , port , config ) } if err != nil {", "del_tokens": "// eli = EnquireLink Interval in Seconds if err := tx . Connect ( host , port ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Move", "desc", "to", "top", "of", "a", "file", "."], "add_tokens": "/ * This is a simple example of usage of Grafana client for copying datasources and saving them to a disk . It is useful for Grafana backups ! Usage : backup - datasources http : //grafana.host:3000 api-key-string-here You need get API key with Admin rights from your Grafana ! * /", "del_tokens": "/ * This is a simple example of usage of Grafana client for copying datasources and saving them to a disk . It is useful for Grafana backups ! Usage : backup - datasources http : //grafana.host:3000 api-key-string-here You need get API key with Admin rights from your Grafana ! * /", "commit_type": "move"}
{"commit_tokens": ["remove", "key", "serialization", "construct", "conn", "from", "ipnet", ".", "PSK"], "add_tokens": "testPSK := make ( [ ] byte , 32 ) // null bytes are as good test key as any other key psk1 , err := NewProtectedConn ( testPSK , conn1 ) psk2 , err := NewProtectedConn ( testPSK , conn2 )", "del_tokens": "var testPSK = [ 32 ] byte { } // null bytes are as good test key as any other key psk1 , err := newPSKConn ( & testPSK , conn1 ) psk2 , err := newPSKConn ( & testPSK , conn2 )", "commit_type": "remove"}
{"commit_tokens": ["fix", "off", "by", "one", "for", ":", "before", "/", ":", "after"], "add_tokens": "number int insert bool if after && num != len ( i . Array ) { func ( i ArrayInsertionIndex ) Update ( array [ ] interface { } , obj interface { } ) [ ] interface { } { if i . insert { var newAry [ ] interface { } newAry = append ( newAry , array [ : i . number ] ... ) // not inclusive newAry = append ( newAry , obj ) newAry = append ( newAry , array [ i . number : ] ... ) // inclusive return newAry } array [ i . number ] = obj return array }", "del_tokens": "Number int Insert bool if before { num -= 1 if num < 0 { num = 0 } } if after {", "commit_type": "fix"}
{"commit_tokens": ["Moved", "metadata", "logging", "a", "little", "bit"], "add_tokens": "Logger . Info ( \" \" , topics )", "del_tokens": "Logger . Info ( \" \" , topics )", "commit_type": "move"}
{"commit_tokens": ["add", "func", "to", "create", "a", "new", "pool", "with", "a", "limit"], "add_tokens": "// NewWithActiveLimit makes and returns a pointer to a new Connector instance. It sets some // defaults on the ConnectionParam object, such as the policy, which defaults to // a LogReconnectPolicy with a base of 10ms. A call to this function does not // produce a connection. func NewWithActiveLimit ( param ConnectionParam , maxIdle int , maxActive int ) ( * redis . Pool , ReconnectPolicy ) { if param . Policy == nil { param . Policy = & LogReconnectPolicy { Base : 10 , Factor : time . Millisecond } } return & redis . Pool { Dial : connect ( param ) , MaxIdle : maxIdle , MaxActive : maxActive } , param . Policy } return & redis . Pool { Dial : connect ( param ) , MaxIdle : maxIdle , MaxActive : 0 } , param . Policy", "del_tokens": "return redis . NewPool ( connect ( param ) , maxIdle ) , param . Policy", "commit_type": "add"}
{"commit_tokens": ["Remove", "repo", "self", "-", "references", "in", "go", "get", "and", "in", "imports"], "add_tokens": "// import ...", "del_tokens": "package main import \" \" import \" \"", "commit_type": "remove"}
{"commit_tokens": ["changed", "to", "not", "use", "pkg", "-", "config", "brittle", "on", "some", "platforms"], "add_tokens": "// #cgo LDFLAGS: -licuuc -licudata", "del_tokens": "// #cgo pkg-config: icu-uc", "commit_type": "change"}
{"commit_tokens": ["Allow", "applying", "patch", "to", "/", "dev", "/", "null", "(", "regression", ")"], "add_tokens": "if actx . TargetPath == \" \" { targetInfo , err := os . Lstat ( actx . TargetPath ) if targetInfo . IsDir ( ) { targetPool = targetContainer . NewFilePool ( actx . TargetPath ) } else { fr , err := os . Open ( actx . TargetPath ) if err != nil { return err } zr , err := zip . NewReader ( fr , targetInfo . Size ( ) ) if err != nil { return err } targetPool = targetContainer . NewZipPool ( zr ) }", "del_tokens": "targetInfo , err := os . Lstat ( actx . TargetPath ) if err != nil { return err } if targetInfo . IsDir ( ) { fr , err := os . Open ( actx . TargetPath ) zr , err := zip . NewReader ( fr , targetInfo . Size ( ) ) if err != nil { return err } targetPool = targetContainer . NewZipPool ( zr )", "commit_type": "allow"}
{"commit_tokens": ["Use", "defer", "to", "rollback", "transactions"], "add_tokens": "commitSuccess := false defer func ( ) { if ! commitSuccess { err := db . RollbackTransaction ( ) if err != nil { log . Error ( \" \" , err . Error ) } } } ( ) } else { commitSuccess = true", "del_tokens": "err2 := db . RollbackTransaction ( ) if err2 != nil { log . Error ( \" \" , err2 . Error ( ) ) }", "commit_type": "use"}
{"commit_tokens": ["Fix", "messages", "to", "show", "master", "ip", "rather", "than", "a", "pointer", "address", "."], "add_tokens": "const ( // Cadvisor port in kubernetes. cadvisorPort = 4194 kubeClientVersion = \" \" ) Version : kubeClientVersion , glog . Infof ( \" \\n \" , * argMaster , kubeClientVersion ) desc += fmt . Sprintf ( \" \\t \\n \" , * argMaster , kubeClientVersion )", "del_tokens": "// Cadvisor port in kubernetes. const cadvisorPort = 4194 Version : \" \" , glog . Infof ( \" \\n \" , kubeClient ) desc += fmt . Sprintf ( \" \\t \\n \" , self . client )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "small", "bug", "introduced", "during", "race", "condition", "frustration"], "add_tokens": "for e := peerList . Front ( ) ; e != nil ; e = e . Next ( ) { if e == nil {", "del_tokens": "if peerList == nil { return peerSorterArr { } } e := peerList . Front ( ) for ; e != nil ; { if e != nil { e = e . Next ( )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "MessagePack", "library", "to", "github", ".", "com", "/", "ugorji", "/", "go", "/", "codec"], "add_tokens": "\" \" \" \" var ( mapStrIntfTyp = reflect . TypeOf ( map [ string ] interface { } ( nil ) ) sliceByteTyp = reflect . TypeOf ( [ ] byte ( nil ) ) timeTyp = reflect . TypeOf ( time . Time { } ) mh codec . MsgpackHandle ) func init ( ) { mh . MapType = mapStrIntfTyp mh . AddExt ( sliceByteTyp , 0 , mh . BinaryEncodeExt , mh . BinaryDecodeExt ) mh . AddExt ( timeTyp , 1 , mh . TimeEncodeExt , mh . TimeDecodeExt ) } if data , dumperr := toMsgpack ( msg ) ; dumperr != nil { fmt . Println ( data ) // fmt.Println(&msg) if len ( msg ) > f . Config . BufferLimit { func toMsgpack ( val interface { } ) ( packed [ ] byte , err error ) { enc := codec . NewEncoderBytes ( & packed , & mh ) err = enc . Encode ( val ) return }", "del_tokens": "msgpack \" \" if data , dumperr := msgpack . Marshal ( msg ) ; dumperr != nil { if len ( data ) > f . Config . BufferLimit {", "commit_type": "update"}
{"commit_tokens": ["Use", "proper", "logger", "in", "shutdown", "path"], "add_tokens": "s . Logger ( ) . Info ( \" \" , \" \" , shutdown . Reason )", "del_tokens": "\" \" log . Printf ( \" \\n \\n \" , shutdown . Reason )", "commit_type": "use"}
{"commit_tokens": ["Use", "a", "private", "struct", "for", "adding", "the", "fixed", "version", "to", "an", "existing", "issue", "."], "add_tokens": "var change struct { Update struct { FixedVersions [ 1 ] struct { Add struct { FixVersion string } `json:\"add\"` } `json:\"fixVersion\"` } `json:\"update\"` } if err := json . Unmarshal ( data , & change ) ; err != nil { fmt . Printf ( \" \\n \" , change ) if change . Update . FixedVersions [ 0 ] . Add . FixVersion != \" \" { t . Fatalf ( \" \\n \" , change . Update . FixedVersions [ 0 ] . Add . FixVersion )", "del_tokens": "var issue updateIssue if err := json . Unmarshal ( data , & issue ) ; err != nil { fmt . Printf ( \" \\n \" , issue ) if issue . update . fixVersions [ 0 ] . add != \" \" { t . Fatalf ( \" \\n \" , issue . update . fixVersions [ 0 ] . add ) w . WriteHeader ( 204 )", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "support", "latest", "backoff", "library"], "add_tokens": "100 * time . Millisecond , time . Minute , ) ,", "del_tokens": "backoff . DefaultMultiplier , backoff . DefaultRandFactor , backoff . DefaultMinInterval , 1 * time . Minute ) ,", "commit_type": "update"}
{"commit_tokens": ["Changing", "the", "type", "of", "the", "value", "of", "the", "digest", "from", "uint64", "to", "Pol"], "add_tokens": "value Pol cache . Lock ( ) defer cache . Unlock ( ) d . value |= Pol ( b ) d . value = d . value . Mod ( d . pol ) return uint64 ( d . value ) d . value ^= d . tables . out [ leave ] d . value |= Pol ( enter ) d . value ^= d . tables . mod [ index ]", "del_tokens": "value uint64 cache . Lock ( ) defer cache . Unlock ( ) d . value |= uint64 ( b ) d . value = uint64 ( Pol ( d . value ) . Mod ( d . pol ) ) return d . value d . value ^= uint64 ( d . tables . out [ leave ] ) d . value |= uint64 ( enter ) d . value ^= uint64 ( d . tables . mod [ index ] )", "commit_type": "change"}
{"commit_tokens": ["Add", "image_aspect_ratio", "property", "to", "attachments"], "add_tokens": "type ImageAspectRatio string // ImageAspectRatio is horizontal (1.91:1). Default. HorizontalImageAspectRatio ImageAspectRatio = \" \" // ImageAspectRatio is square. SquareImageAspectRatio ImageAspectRatio = \" \" TemplateType string `json:\"template_type,omitempty\"` TopElementStyle TopElementStyle `json:\"top_element_style,omitempty\"` Text string `json:\"text,omitempty\"` ImageAspectRatio ImageAspectRatio `json:\"image_aspect_ratio,omitempty\"` Elements * [ ] StructuredMessageElement `json:\"elements,omitempty\"` Buttons * [ ] StructuredMessageButton `json:\"buttons,omitempty\"` Url string `json:\"url,omitempty\"`", "del_tokens": "TemplateType string `json:\"template_type,omitempty\"` TopElementStyle TopElementStyle `json:\"top_element_style,omitempty\"` Text string `json:\"text,omitempty\"` Elements * [ ] StructuredMessageElement `json:\"elements,omitempty\"` Buttons * [ ] StructuredMessageButton `json:\"buttons,omitempty\"` Url string `json:\"url,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Remove", "one", "line", "from", "the", "debug", "stack", "for", "easier", "readability"], "add_tokens": "return newErr ( debug . Stack ( ) , nil , false , info , publicMsg ) return newErr ( debug . Stack ( ) , wrapErr , false , info , publicMsg ) return newErr ( debug . Stack ( ) , nil , true , info , publicMsg ) return newErr ( debug . Stack ( ) , fmt . Errorf ( format , argv ... ) , false , info , nil ) func newErr ( stack [ ] byte , wrappedErr error , isUserErr bool , info Info , publicMsgParts [ ] interface { } ) Err {", "del_tokens": "return newErr ( nil , false , info , publicMsg ) return newErr ( wrapErr , false , info , publicMsg ) return newErr ( nil , true , info , publicMsg ) return newErr ( fmt . Errorf ( format , argv ... ) , false , info , nil ) func newErr ( wrappedErr error , isUserErr bool , info Info , publicMsgParts [ ] interface { } ) Err { stack := debug . Stack ( )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "support", "for", "optimistic", "locking", ":"], "add_tokens": "// singleColOptlock has a primary key composed of a single column. See // newTestStatementsDB. Additionally, the V column is used for optimistic // locking. type singleColOptlock struct { A int `db:\"a\"` B int `db:\"b\"` V int `db:\"v,optlock\"` } keys int 1 , 3 , 1 , { \" \" , singleColOptlock { } , 1 , nil , } , Columns : table . Columns [ : d . keys ] , return 1 , nil { [ ] interface { } { & singleColOptlock { 1 , 2 , 3 } } , [ ] string { \" \" + \" \" , } , } ,", "del_tokens": "Columns : table . Columns [ : len ( table . Columns ) - 1 ] , return 0 , nil", "commit_type": "add"}
{"commit_tokens": ["make", "Route", "s", "parse", "public"], "add_tokens": "if result , ok := r . Parse ( args ... ) ; ok {", "del_tokens": "if result , ok := r . parse ( args ... ) ; ok {", "commit_type": "make"}
{"commit_tokens": ["Add", "h2", "support", "to", "mint", "-", "server", "-", "https"], "add_tokens": "logf ( logTypeHandshake , \" \" , clientALPN . protocols ) logf ( logTypeHandshake , \" \" , proto ) eeList := extensionList { } err = eeList . Add ( serverALPN ) ee := encryptedExtensionsBody ( eeList )", "del_tokens": "ee := encryptedExtensionsBody ( [ ] extension { } ) err = sh . extensions . Add ( serverALPN )", "commit_type": "add"}
{"commit_tokens": ["Implemented", "checksum", "validation", "for", "skipped", "downloads"], "add_tokens": "// error in os.Stat if resp . Size > 0 && resp . Size == resp . bytesResumed { resp . DidResume = true // validate checksum if err := resp . checksum ( ) ; err != nil { return resp , resp . close ( err ) }", "del_tokens": "// error is os.Stat if resp . Size > 0 && resp . Size == resp . BytesTransferred ( ) {", "commit_type": "implement"}
{"commit_tokens": ["add", "api", "key", "support", "to", "current", ".", "go"], "add_tokens": "import ( \" \" \" \" ) const keyError = \" \" forecastBase = \" \" func getKey ( ) string { key := os . Getenv ( \" \" ) if ! ValidAPIKey ( key ) { log . Fatalln ( keyError ) } return key } // ValidAPIKey makes sure that the key given is a valid one func ValidAPIKey ( key string ) bool { if len ( key ) == 32 { return true } return false }", "del_tokens": "forecastBase = \" \"", "commit_type": "add"}
{"commit_tokens": ["allow", "a", "property", "name", "to", "be", "properties"], "add_tokens": "return p [ len ( p ) - 1 ] == \" \" && p [ len ( p ) - 2 ] != \" \"", "del_tokens": "return p [ len ( p ) - 1 ] == \" \"", "commit_type": "allow"}
{"commit_tokens": ["Remove", "libcompose", "CLI", "warning", "on", "startup"], "add_tokens": "\" \" func beforeApp ( c * cli . Context ) error { if c . GlobalBool ( \" \" ) { logrus . SetLevel ( logrus . DebugLevel ) } return nil } app . Before = beforeApp", "del_tokens": "cliApp \" \" app . Before = cliApp . BeforeApp", "commit_type": "remove"}
{"commit_tokens": ["Add", "the", "API", "of", "getting", "roles", "for", "a", "user", "."], "add_tokens": "import ( \" \" ) func ( rm * RoleManager ) getRoles ( name string ) [ ] string { if rm . hasRole ( name ) { return rm . createRole ( name ) . getRoles ( ) } else { return nil } } } func ( r * Role ) getRoles ( ) [ ] string { names := [ ] string { } for _ , role := range r . roles { names = append ( names , role . name ) } return names }", "del_tokens": "import \" \" }", "commit_type": "add"}
{"commit_tokens": ["move", "rpc", "and", "semver", "into", "packages"], "add_tokens": "\" \" var requiredChainServerAPI = semver . Semver { major : 2 , minor : 0 , patch : 0 } var nodeVer semver . Semver nodeVer = semver . Semver { dcrdVer . Major , dcrdVer . Minor , dcrdVer . Patch } if ! semver . SemverCompatible ( requiredChainServerAPI , nodeVer ) {", "del_tokens": "var requiredChainServerAPI = semver { major : 2 , minor : 0 , patch : 0 } cfg := & config { DisableDaemonTLS : disableTLS , DcrdCert : cert , DcrdUser : user , DcrdPass : pass , DcrdServ : host , } return connectNodeRPC ( cfg ) } func connectNodeRPC ( cfg * config ) ( * dcrrpcclient . Client , semver , error ) { var nodeVer semver nodeVer = semver { dcrdVer . Major , dcrdVer . Minor , dcrdVer . Patch } if ! semverCompatible ( requiredChainServerAPI , nodeVer ) {", "commit_type": "move"}
{"commit_tokens": ["adds", "validation", "for", "required", "properties", "in", "definitions"], "add_tokens": "\" \" res . AddErrors ( errors . New ( 422 , \" \" , p ) ) res := new ( Result ) for d , v := range s . spec . Spec ( ) . Definitions { REQUIRED : for _ , pn := range v . Required { if _ , ok := v . Properties [ pn ] ; ok { continue } for pp := range v . PatternProperties { re := regexp . MustCompile ( pp ) if re . MatchString ( pn ) { continue REQUIRED } } if v . AdditionalProperties != nil { if v . AdditionalProperties . Allows { continue } if v . AdditionalProperties . Schema != nil { continue } } res . AddErrors ( errors . New ( 422 , \" \" , pn , d ) ) } } return res", "del_tokens": "res . AddErrors ( errors . New ( 422 , \" \" , p ) ) return nil", "commit_type": "add"}
{"commit_tokens": ["Use", "strings", ".", "IndexByte", "to", "find", "next", "slash"], "add_tokens": "nextSlash := strings . IndexByte ( path , '/' ) if nextSlash < 0 { nextSlash = pathLen", "del_tokens": "nextSlash := 0 for nextSlash < pathLen && path [ nextSlash ] != '/' { nextSlash ++", "commit_type": "use"}
{"commit_tokens": ["Added", "all", "list", "operations", "(", "except", "sort", ")"], "add_tokens": "* /", "del_tokens": "* /", "commit_type": "add"}
{"commit_tokens": ["added", "a", "multiple", "format", "check", "to", "item", ".", "format", "()", "and", "added", "tests", "to", "format", "and", "item"], "add_tokens": "func ( item * Item ) Export ( ) ( map [ string ] interface { } , error ) { formatNames := make ( [ ] string , 0 ) for _ , format := range item . formats { for _ , formatName := range formatNames { if formatName == format . Name ( ) { return nil , & ItemFormatError { err : \" \" + \" \" } } } formatNames = append ( formatNames , format . Name ( ) ) ; } for _ , format := range item . formats { return out , nil } // An error struct used to represent an error related to item formats. type ItemFormatError struct { err string } // This function returns the message associated with the ItemFormatError // error struct. func ( e ItemFormatError ) Error ( ) string { return e . err", "del_tokens": "func ( item * Item ) Export ( ) map [ string ] interface { } { for _ , format := range item . formats { return out", "commit_type": "add"}
{"commit_tokens": ["add", "rds", "related", "APIs", "and", "structs"], "add_tokens": "time . Sleep ( DefaultWaitForInterval * time . Second ) Pack string `json:\"pack,omitempty\"` ActivityId string `json:\"activityId,omitempty\"`", "del_tokens": "Pack string `json:\"pack,omitempty\" yaml:\"pack,omitempty\"` ActivityId string `json:\"activityId,omitempty\" yaml:\"activityId,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["change", "default", "prompt", "to", ">>>"], "add_tokens": "defaultPrompt = \" \"", "del_tokens": "defaultPrompt = \" \"", "commit_type": "change"}
{"commit_tokens": ["Move", "stats", "to", "separate", "struct"], "add_tokens": "- optimize - parser : boolean , if set , the options Debug , Memoize and Statistics are removed from the resulting parser . This saves a few cpu cycles , when using the - Statistics ( * Stats ) Option", "del_tokens": "- optimize - parser : boolean , if set , the options Debug and Memoize are removed from the resulting parser . This saves a few cpu cycles , when using the", "commit_type": "move"}
{"commit_tokens": ["Move", "line", "parsing", "done", "in", "dispatchEvent", "into", "ParseLine", "()", "."], "add_tokens": "if line != nil { conn . dispatchEvent ( line ) }", "del_tokens": "conn . dispatchEvent ( line )", "commit_type": "move"}
{"commit_tokens": ["update", "tests", "to", "be", "compatible", "with", "go", "modules", "and", "go", "test", "all"], "add_tokens": "\" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , // needs github.com in the path \" \" : true , \" \" : true , // llog is not always llog/ with go modules \" \" : true , _ , file , _ , _ := runtime . Caller ( 1 ) t . Logf ( \" \" , file )", "del_tokens": "\" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true ,", "commit_type": "update"}
{"commit_tokens": ["Fix", "https", ":", "//", "github", ".", "com", "/", "kataras", "/", "iris", "/", "issues", "/", "231"], "add_tokens": "// DisableSubdomainPersistance set it to dissallow your iris subdomains to have access to the session cookie // defaults to false DisableSubdomainPersistance bool Provider : \" \" , // the default provider is \"memory\", if you set it to \"\" means that sessions are disabled. Cookie : DefaultCookieName , Expires : CookieExpireNever , GcDuration : DefaultSessionGcDuration , DisableSubdomainPersistance : false ,", "del_tokens": "Provider : \" \" , // the default provider is \"memory\", if you set it to \"\" means that sessions are disabled. Cookie : DefaultCookieName , Expires : CookieExpireNever , GcDuration : DefaultSessionGcDuration ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "bugs", "in", "zoom_test", ".", "go", ".", "Add", "an", "index", "for", "saved", "models", "and", "test", "for", "it", ".", "Still", "need", "to", "delete", "from", "the", "index", "on", "Delete", "()"], "add_tokens": "// make sure it was added to the database ismem , err := zoom . SetContains ( \" \" , p . Id , nil ) if err != nil { c . Error ( err ) } c . Assert ( ismem , Equals , true ) result , err := zoom . FindById ( \" \" , myTypes . Id ) resultTypes , ok := result . ( * AllTypes ) c . Error ( \" \" )", "del_tokens": "result , err := zoom . FindById ( \" \" , myTypes . Id ) resultTypes , ok := result . ( * myTypes ) c . Error ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "data", "race", "of", "loadWorkers", "()", "<", "-", ">", "processing", "()"], "add_tokens": "workersM * sync . Mutex m . workersM . Lock ( ) m . workersM . Unlock ( ) m . workersM . Lock ( ) m . workersM . Unlock ( ) & sync . Mutex { } ,", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["make", "same", "changes", "to", "disjunction", "and", "make", "nil", "safe"], "add_tokens": "var mustSearcher * search . ConjunctionSearcher ms , err := q . Must . Searcher ( i , explain ) if ms != nil { mustSearcher = ms . ( * search . ConjunctionSearcher ) } var shouldSearcher * search . DisjunctionSearcher ss , err := q . Should . Searcher ( i , explain ) if ss != nil { shouldSearcher = ss . ( * search . DisjunctionSearcher ) } var mustNotSearcher * search . DisjunctionSearcher mns , err := q . MustNot . Searcher ( i , explain ) if mns != nil { mustNotSearcher = mns . ( * search . DisjunctionSearcher ) } return search . NewBooleanSearcher ( i . i , mustSearcher , shouldSearcher , mustNotSearcher , explain )", "del_tokens": "var err error var mustSearcher search . Searcher mustSearcher , err = q . Must . Searcher ( i , explain ) var shouldSearcher search . Searcher shouldSearcher , err = q . Should . Searcher ( i , explain ) var mustNotSearcher search . Searcher mustNotSearcher , err = q . MustNot . Searcher ( i , explain ) return search . NewBooleanSearcher ( i . i , mustSearcher . ( * search . ConjunctionSearcher ) , shouldSearcher . ( * search . DisjunctionSearcher ) , mustNotSearcher . ( * search . DisjunctionSearcher ) , explain )", "commit_type": "make"}
{"commit_tokens": ["Added", "blank", "nodes", "and", "reification"], "add_tokens": "import ( \" \" \" \" \" \" ) func TestBlankNode ( t * testing . T ) { for i := uint64 ( 0 ) ; i < 10 ; i ++ { b := NewBlankNode ( ) ss := strings . Split ( b . String ( ) , \" \" ) if len ( ss ) != 4 { t . Errorf ( \" \" , b ) } if got , want := ss [ 3 ] , fmt . Sprintf ( \" \" , i ) ; got != want { t . Errorf ( \" \" , b , got , want ) } } }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "Get", "()", "to", "http", "client"], "add_tokens": "statusCode , body , err := Get ( nil , \" \" ) if err != nil { t . Fatalf ( \" \" , statusCode , body )", "del_tokens": "var req Request var resp Response req . Header . Set ( \" \" , \" \" ) if err := Do ( & req , & resp ) ; err != nil { t . Fatalf ( \" \" , resp . Header . StatusCode , resp . Body )", "commit_type": "add"}
{"commit_tokens": ["Add", "default", "values", "to", "Build", "variables"], "add_tokens": "Commit = \" \" BuildTime = \" \"", "del_tokens": "Commit string BuildTime string", "commit_type": "add"}
{"commit_tokens": ["Use", "HTTPS", "if", "reference", "to", "html", "template", "in", "cross", "-", "origin"], "add_tokens": "\" \" : \" \" ,", "del_tokens": "\" \" : \" \" ,", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "...", "syntax", "for", "recursive", "analysis"], "add_tokens": "adjustedPath , recursive := checkRecursive ( path ) root , err := filepath . Abs ( adjustedPath ) if walkPath ( root , recursive ) { func checkRecursive ( path string ) ( adjustedPath string , recursive bool ) { pathLen := len ( path ) if pathLen >= 5 && path [ pathLen - 3 : ] == \" \" { return path [ : pathLen - 3 ] , true } return path , false } func walkPath ( root string , recursive bool ) bool { if path != root && ( ! recursive ||", "del_tokens": "root , err := filepath . Abs ( path ) if walkPath ( root ) { func walkPath ( root string ) bool { if path != root && ( * dontRecurseFlag ||", "commit_type": "add"}
{"commit_tokens": ["fix", "url", "path", "generation", "in", "windows", "are", "using", "backslash", "instead", "of", "/"], "add_tokens": "\" \" req . URL . Path = path . Join ( r . BasePath , req . URL . Path )", "del_tokens": "\" \" req . URL . Path = filepath . Join ( r . BasePath , req . URL . Path )", "commit_type": "fix"}
{"commit_tokens": ["Moved", "Seek", "into", "individual", "implementations"], "add_tokens": "// Hash creates a hash of the audio file data provided by the io.ReadSeeker which metadata // (ID3, MP4) invariant. _ , err := r . Seek ( 0 , os . SEEK_SET ) if err != nil { return \" \" , fmt . Errorf ( \" \" , err ) } // HashAtoms constructs a hash of MP4 audio file data provided by the io.ReadSeeker which is metadata invariant. _ , err := r . Seek ( 0 , os . SEEK_SET ) if err != nil { return \" \" , fmt . Errorf ( \" \" , err ) } // HashID3v1 constructs a hash of MP3 audio file data (assumed to have ID3v1 tags) provided by the // io.ReadSeeker which is metadata invariant. return \" \" , fmt . Errorf ( \" \" , err ) // HashID3v2 constructs a hash of MP3 audio file data (assumed to have ID3v2 tags) provided by the // io.ReadSeeker which is metadata invariant. _ , err := r . Seek ( 0 , os . SEEK_SET ) if err != nil { return \" \" , fmt . Errorf ( \" \" , err ) }", "del_tokens": "// Hash creates a hash of the audio file data provided by the io.ReadSeeker // which ignores metadata (ID3, MP4) associated with the file. _ , err = r . Seek ( 0 , os . SEEK_SET ) if err != nil { return \" \" , err } return \" \" , err", "commit_type": "move"}
{"commit_tokens": ["Move", "Agent", "package", "out", "of", ".", "/", "cmd", "/", "..."], "add_tokens": "package agent func NewAgent ( config * ssh . ServerConfig ) * Agent { return & Agent { config : config , } } request , err := ParseRequest ( req ) type Request struct { func ParseRequest ( req * ssh . Request ) ( * Request , error ) { request := & Request { JSON : string ( raw . Value ) } func ( req * Request ) Run ( output chan string ) error {", "del_tokens": "package main request , err := ParseAgentRequest ( req ) type AgentRequest struct { func ParseAgentRequest ( req * ssh . Request ) ( * AgentRequest , error ) { request := & AgentRequest { JSON : string ( raw . Value ) } func ( req * AgentRequest ) Run ( output chan string ) error {", "commit_type": "move"}
{"commit_tokens": ["Fix", "hdkeychain", "to", "avoid", "zeroing", "net", "version", "bytes", "."], "add_tokens": "k . version = nil", "del_tokens": "zero ( k . version )", "commit_type": "fix"}
{"commit_tokens": ["Make", "all", "transfer", "types", "use", "a", "generic", "endpoint", ".", "transfer", "()", "function"], "add_tokens": "func ( e EndpointInfo ) TransferType ( ) TransferType { return TransferType ( e . Attributes ) & TRANSFER_TYPE_MASK } e . Number ( ) , e . Direction ( ) , e . TransferType ( ) , if ei . TransferType ( ) == TRANSFER_TYPE_ISOCHRONOUS {", "del_tokens": "e . Number ( ) , e . Direction ( ) , TransferType ( e . Attributes ) & TRANSFER_TYPE_MASK , if TransferType ( ei . Attributes ) & TRANSFER_TYPE_MASK == TRANSFER_TYPE_ISOCHRONOUS {", "commit_type": "make"}
{"commit_tokens": ["Fix", "compilation", "since", "pull", "function", "now", "returns", "err"], "add_tokens": "filenameA , _ := release . Pull ( releaseURLA ) filenameB , _ := release . Pull ( releaseURLB )", "del_tokens": "filenameA := release . Pull ( releaseURLA ) filenameB := release . Pull ( releaseURLB )", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "verb", "of", "bool", "value"], "add_tokens": "t . Errorf ( \" \" , params , v , ok ) b . Errorf ( \" \" , params , v , ok )", "del_tokens": "t . Errorf ( \" \" , params , v , ok ) b . Errorf ( \" \" , params , v , ok )", "commit_type": "fix"}
{"commit_tokens": ["fix", "incoming", "audio", "issue", "where", "the", "sound", "would", "be", "garbled", "if", "multiple"], "add_tokens": "\" \" if pcm , err := user . decoder . Decode ( opus , 1920 , false ) ; err != nil { decoder , _ := gopus . NewDecoder ( SampleRate , 1 ) user . decoder = decoder", "del_tokens": "if pcm , err := client . audio . decoder . Decode ( opus , 1920 , false ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "protocol", "version", "check", "."], "add_tokens": "return nil , 0 , errors . New ( \" \" )", "del_tokens": "panic ( \" \" ) if recvMsg . getVersion ( ) != opt . Version { return nil , 0 , errors . New ( \" \" ) }", "commit_type": "remove"}
{"commit_tokens": ["allow", "reading", "from", "stdin", "and", "file"], "add_tokens": "// channel. It returns when all MetricFamilies are parsed and put on the if err := ParseReader ( resp . Body , ch ) ; err != nil { return err // ParseReader consumes an io.Reader and pushes it to the MetricFamily // channel. It returns when all MetricFamilies are parsed and put on the // channel. func ParseReader ( in io . Reader , ch chan <- * dto . MetricFamily ) error { defer close ( ch ) // We could do further content-type checks here, but the // fallback for now will anyway be the text format // version 0.0.4, so just go for it and see if it works. var parser expfmt . TextParser metricFamilies , err := parser . TextToMetricFamilies ( in ) if err != nil { return fmt . Errorf ( \" \" , err ) } for _ , mf := range metricFamilies { ch <- mf } return nil }", "del_tokens": "defer close ( ch ) // channel. It returns when all all MetricFamilies are parsed and put on the // We could do further content-type checks here, but the // fallback for now will anyway be the text format // version 0.0.4, so just go for it and see if it works. var parser expfmt . TextParser metricFamilies , err := parser . TextToMetricFamilies ( resp . Body ) if err != nil { return fmt . Errorf ( \" \" , err ) } for _ , mf := range metricFamilies { ch <- mf", "commit_type": "allow"}
{"commit_tokens": ["Add", ".", "travis", ".", "yml", "and", "a", "Makefile"], "add_tokens": "package sessions", "del_tokens": "package sessions", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "of", "draw2dgl", "in", "docstring", "of", "draw2d", ".", "go"], "add_tokens": "// (draw2dpdf) and opengl (draw2dgl), which can also be used on the", "del_tokens": "// (draw2dpdf) and opengl (draw2dopengl), which can also be used on the", "commit_type": "fix"}
{"commit_tokens": ["added", "ipv6", "link", "-", "local", "loopback"], "add_tokens": "\" \" // IP6LinkLocalLoopback is the ip6 link-local loopback multiaddr IP6LinkLocalLoopback = ma . StringCast ( \" \" ) b := m . Bytes ( ) // /ip4/127 prefix (_entire_ /8 is loopback...) if bytes . HasPrefix ( b , [ ] byte { 4 , 127 } ) { return true } // /ip6/::1 if IP6Loopback . Equal ( m ) || IP6LinkLocalLoopback . Equal ( m ) { return true } return false", "del_tokens": "return m . Equal ( IP4Loopback ) || m . Equal ( IP6Loopback )", "commit_type": "add"}
{"commit_tokens": ["Add", "subject", "to", "async", "error", "callback", "."], "add_tokens": "Errorf ( \" \" , sub . Subject , err )", "del_tokens": "Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Make", "WebSocket", ".", "ReadyState", "use", "the", "ReadyState", "constants"], "add_tokens": "ReadyState ReadyState `js:\"readyState\"` URL string `js:\"url\"`", "del_tokens": "ReadyState uint16 `js:\"readyState\"` URL string `js:\"url\"`", "commit_type": "make"}
{"commit_tokens": ["Update", "disto", "run", "command", "to", "accept", "arguments"], "add_tokens": "const ( productFlagName = \" \" argsFlagName = \" \" ) Name : productFlagName , flag . StringSlice { Name : argsFlagName , Usage : \" \" , Optional : true , } , product := ctx . String ( productFlagName ) return errors . Errorf ( \" \" , productFlagName , programNames ) return DoRun ( buildSpecsWithDeps [ 0 ] . Spec , ctx . Slice ( argsFlagName ) , ctx . App . Stdout , ctx . App . Stderr )", "del_tokens": "const productFlag = \" \" Name : productFlag , product := ctx . String ( productFlag ) return errors . Errorf ( \" \" , productFlag , programNames ) return DoRun ( buildSpecsWithDeps [ 0 ] . Spec , nil , ctx . App . Stdout , ctx . App . Stderr )", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "a", "e2e", "-", "not", "-", "required", "label"], "add_tokens": "if test . hasLabel != HasLabel ( test . labels , test . label ) { if test . hasLabel != HasLabels ( test . labels , test . seekLabels ) {", "del_tokens": "if test . hasLabel != hasLabel ( test . labels , test . label ) { if test . hasLabel != hasLabels ( test . labels , test . seekLabels ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "sprintf", "conversion", "issues"], "add_tokens": "return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , updateCount , len ( keys ) ) } ) return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , documentCount , len ( keys ) ) } )", "del_tokens": "return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , updateCount , len ( keys ) ) } ) return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , documentCount , len ( keys ) ) } )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "TODO", "comments", "from", "template", ".", "go"], "add_tokens": "// panic(\"mock out the {{.Name}} method\") // // use mocked{{.InterfaceName}} in code that requires {{.InterfaceName}} // // and then make assertions.", "del_tokens": "// panic(\"TODO: mock out the {{.Name}} method\") // // TODO: use mocked{{.InterfaceName}} in code that requires {{.InterfaceName}} // // and then make assertions.", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "gc", "/", "cmd", "tests"], "add_tokens": "// disabled, FindProjectRoot uses os.Stat func testFindProjectroot ( t * testing . T ) { want : \" \" ,", "del_tokens": "func TestFindProjectroot ( t * testing . T ) { want : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Removes", "destination", "on", "ALL", "proxy", "errors", "."], "add_tokens": "var version = \" \" if true || strings . Contains ( etype . String ( ) , \" \" ) { // == reflect.TypeOf(net.OpError{}) { // couldn't figure out a better way to do this", "del_tokens": "var version = \" \" if strings . Contains ( etype . String ( ) , \" \" ) { // == reflect.TypeOf(net.OpError{}) { // couldn't figure out a better way to do this", "commit_type": "remove"}
{"commit_tokens": ["Change", "a", "bunch", "of", "==", "to", "<", "=", "to", "fix", "infinite", "paging", "."], "add_tokens": "if response . LastPage == 0 || response . LastPage <= page { if response . LastPage == 0 || response . LastPage <= page { if response . LastPage == 0 || response . LastPage <= page {", "del_tokens": "if response . LastPage == 0 || response . LastPage == page { if response . LastPage == 0 || response . LastPage == page { if response . LastPage == 0 || response . LastPage == page {", "commit_type": "change"}
{"commit_tokens": ["Add", "an", "EscapeGlobString", "function", "for", "escaping", "whole", "strings"], "add_tokens": "// Escaper is the character used to escape a meaningful character Escaper = '\\\\'", "del_tokens": "// Escaper is the character used to escape a meaningful character Escaper = '\\\\'", "commit_type": "add"}
{"commit_tokens": ["changed", "notBefore", "notAfter", "to", "timestamp", "type"], "add_tokens": "nbtime := cert . NotBefore . UTC ( ) natime := cert . NotAfter . UTC ( ) stored . Validity . NotBefore = fmt . Sprintf ( \" \" , nbtime . Year ( ) , nbtime . Month ( ) , nbtime . Day ( ) , nbtime . Hour ( ) , nbtime . Minute ( ) , nbtime . Second ( ) ) stored . Validity . NotAfter = fmt . Sprintf ( \" \" , natime . Year ( ) , natime . Month ( ) , natime . Day ( ) , natime . Hour ( ) , natime . Minute ( ) , natime . Second ( ) )", "del_tokens": "stored . Validity . NotBefore = cert . NotBefore . UTC ( ) . String ( ) stored . Validity . NotAfter = cert . NotAfter . UTC ( ) . String ( )", "commit_type": "change"}
{"commit_tokens": ["use", "waitGroup", "instead", "of", "done", "channel"], "add_tokens": "\" \" wg := sync . WaitGroup { } wg . Add ( 1 ) wg . Done ( ) go func ( ) { // close channel when all workers are finished wg . Wait ( ) close ( responses ) } ( )", "del_tokens": "workerDone := make ( chan bool , workers ) // start work queue go func ( ) { // close channel when all workers are finished for i := 0 ; i < workers ; i ++ { <- workerDone } close ( responses ) } ( ) workerDone <- true", "commit_type": "use"}
{"commit_tokens": ["Fix", "broken", "test", "on", "darwin", "."], "add_tokens": "if got != \" \" { t . Errorf ( \" \" , got ) }", "del_tokens": "want := \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "dataset", "type", "constants", "for", "easier", "type", "checking"], "add_tokens": "// ZFS dataset types, which can indicate if a dataset is a filesystem, // snapshot, or volume. const ( DatasetFilesystem = \" \" DatasetSnapshot = \" \" DatasetVolume = \" \" ) return listByType ( DatasetSnapshot , filter ) return listByType ( DatasetFilesystem , filter ) return listByType ( DatasetVolume , filter ) if d . Type != DatasetSnapshot { if d . Type != DatasetSnapshot { if d . Type != DatasetSnapshot {", "del_tokens": "return listByType ( \" \" , filter ) return listByType ( \" \" , filter ) return listByType ( \" \" , filter ) if d . Type != \" \" { if d . Type != \" \" { if d . Type != \" \" {", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "comments", "and", "fixed", "code", "to", "comply", "with", "Google", "s", "golint", "(", "https", ":", "//", "github", ".", "com", "/", "golang", "/", "lint", ")", "."], "add_tokens": "geocodeURL = \" \" + reverseGeocodeURL = \" \" + // Geocode returns the latitude and longitude for a certain address resp , err := http . Get ( geocodeURL + url . QueryEscape ( query ) ) // ReverseGeocode returns the address for a certain latitude and longitude resp , err := http . Get ( reverseGeocodeURL + fmt . Sprintf ( \" \" , lat ) + \" \" + fmt . Sprintf ( \" \" , lng ) )", "del_tokens": "geocodeUrl = \" \" + reverseGeocodeUrl = \" \" + resp , err := http . Get ( geocodeUrl + url . QueryEscape ( query ) ) resp , err := http . Get ( reverseGeocodeUrl + fmt . Sprintf ( \" \" , lat ) + \" \" + fmt . Sprintf ( \" \" , lng ) )", "commit_type": "add"}
{"commit_tokens": ["use", "iterator", "to", "read", "many", "consistently", "in", "api"], "add_tokens": "if it . it != nil { C . leveldb_iter_destroy ( it . it ) it . it = nil } func NewRangeIterator ( i * Iterator , r * Range ) * RangeLimitIterator { return rangeLimitIterator ( i , r , & Limit { 0 , - 1 } , IteratorForward ) } func NewRevRangeIterator ( i * Iterator , r * Range ) * RangeLimitIterator { return rangeLimitIterator ( i , r , & Limit { 0 , - 1 } , IteratorBackward ) }", "del_tokens": "C . leveldb_iter_destroy ( it . it ) it . it = nil", "commit_type": "use"}
{"commit_tokens": ["Add", "missing", "double", "-", "quote", "in", "json", "tag", "for", "Runs"], "add_tokens": "} `json:\"runs\"`", "del_tokens": "} `json:\"runs`", "commit_type": "add"}
{"commit_tokens": ["Fix", "build", "error", "due", "to", "cgo", "import", "misuse", "remove", "unused", "import"], "add_tokens": "import \" \" Syslog ( p , fmt . Sprintf ( format , a ... ) )", "del_tokens": "\" \" Syslog ( p , fmt . Sprintf ( format , a ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "call", "required", "params", "validation"], "add_tokens": "\" \" type callSubresource struct { SubresourceUris callSubresource `json:\"subresource_uris\"` if ( p . Url == \" \" ) && ( p . ApplicationSid == \" \" ) { return nil , errors . New ( \" \" ) }", "del_tokens": "type CallSubresource struct { SubresourceUris CallSubresource `json:\"subresource_uris\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "test", "(", "due", "to", "DSTU2", "renaming", "totalResults", "to", "total", ")"], "add_tokens": "c . Assert ( patientBundle . Total , Equals , len ( result ) )", "del_tokens": "c . Assert ( patientBundle . TotalResults , Equals , len ( result ) ) c . Assert ( patientBundle . Title , Equals , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "partial", "path", "match", "in", "the", "skip", "option"], "add_tokens": "if strings . Contains ( p , glob . GLOB ) { if glob . Glob ( p , path ) { if logger != nil { logger . Printf ( \" \\n \" , path ) } return true } else { // check if only a sub-folder of the path is excluded if strings . Contains ( path , p ) { if logger != nil { logger . Printf ( \" \\n \" , path ) } return true }", "del_tokens": "if glob . Glob ( p , path ) { if logger != nil { logger . Printf ( \" \\n \" , path ) return true //log.Printf(\"including: %s\\n\", path)", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "disable", "logging", "of", "VolumeContext"], "add_tokens": "reqw io . Writer repw io . Writer disableLogVolCtx bool // WithDisableLogVolumeContext is an Option that disables logging the VolumeContext // field in the logging interceptor func WithDisableLogVolumeContext ( ) Option { return func ( o * opts ) { o . disableLogVolCtx = true } } s . rprintReqOrRep ( w , req ) s . rprintReqOrRep ( w , rep ) func ( s * interceptor ) rprintReqOrRep ( w io . Writer , obj interface { } ) { if s . opts . disableLogVolCtx && strings . Contains ( name , \" \" ) { continue }", "del_tokens": "reqw io . Writer repw io . Writer rprintReqOrRep ( w , req ) rprintReqOrRep ( w , rep ) func rprintReqOrRep ( w io . Writer , obj interface { } ) {", "commit_type": "add"}
{"commit_tokens": ["updating", "docs", "to", "explain", "fmtStr"], "add_tokens": "// True fails the test if b is false. on failure, it calls // t.Errorf(fmtStr, vals...) // False is the equivalent of True(t, !b, fmtStr, vals...). // Nil uses reflect.DeepEqual(i, nil) to determine if i is nil. // if it's not, Nil calls t.Errorf(fmtStr, vals...) // NoErr calls t.Errorf if e is not nil. // it's used in the error string if actual != expected.", "del_tokens": "// True calls t.Errorf if the provided bool is false, does nothing // otherwise // False is the equivalent of True(t, !b, fmtStr, vals...) // Nil calls t.Errorf if i is not nil // NoErr calls t.Errorf if e is not nil // it's used in the error string if actual != expected", "commit_type": "update"}
{"commit_tokens": ["Add", "method", "to", "report", "panics", "."], "add_tokens": "e error , stack [ ] * stackEntry , r * http . Request , context map [ string ] string , session map [ string ] interface { } , jsonn := newJSONNotice ( e , stack , r , context , session ) e error , stack [ ] * stackEntry , r * http . Request , context map [ string ] string , session map [ string ] interface { } , Backtrace : stack ,", "del_tokens": "e error , r * http . Request , context map [ string ] string , session map [ string ] interface { } , jsonn := newJSONNotice ( e , r , context , session ) e error , r * http . Request , context map [ string ] string , session map [ string ] interface { } , Backtrace : stack ( 4 ) ,", "commit_type": "add"}
{"commit_tokens": ["using", "var", "to", "log", "fields"], "add_tokens": "var (", "del_tokens": "const (", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "WrappedTokenUnsealer", "to", "allow", "users", "to", "unseal", "Gatekeeper", "with", "a", "token", "created", "and", "stored", "with", "Vault", "response", "wrapping", "by", "providing", "the", "temp", "token", "which", "wraps", "the", "stored", "token", "."], "add_tokens": "SelfRecreate bool ListenAddress string TlsCert string TlsKey string Mesos string MaxTaskLife time . Duration AppIdAuth AppIdUnsealer CubbyAuth CubbyUnsealer WrappedTokenAuth WrappedTokenUnsealer flag . StringVar ( & config . WrappedTokenAuth . TempToken , \" \" , defaultEnvVar ( \" \" , \" \" ) , \" \" ) } else if config . WrappedTokenAuth . TempToken != \" \" { log . Println ( \" \" ) if err := unseal ( config . WrappedTokenAuth ) ; err != nil { log . Println ( \" \" ) log . Println ( \" \" , err ) os . Exit ( 1 ) } log . Println ( \" \" )", "del_tokens": "SelfRecreate bool ListenAddress string TlsCert string TlsKey string Mesos string MaxTaskLife time . Duration AppIdAuth AppIdUnsealer CubbyAuth CubbyUnsealer", "commit_type": "add"}
{"commit_tokens": ["Allow", "birpc", "codecs", "to", "pass", "extra", "arguments", "to", "rpc", "methods", "."], "add_tokens": "func ( c * Chat ) Message ( msg * Incoming , _ * nothing , ws * websocket . Conn ) error { log . Printf ( \" \\n \" , ws . Request ( ) . RemoteAddr , msg )", "del_tokens": "func ( c * Chat ) Message ( msg * Incoming , _ * nothing ) error { log . Printf ( \" \\n \" , msg )", "commit_type": "allow"}
{"commit_tokens": ["Adding", "time", "to", "mysql", "types"], "add_tokens": "case \" \" , \" \" , \" \" , \" \" :", "del_tokens": "case \" \" , \" \" , \" \" :", "commit_type": "add"}
{"commit_tokens": ["Improved", "marshal", "map", "code", "(", "DRY", ")"], "add_tokens": "result , err := ConvertToMarshalMap ( convert1 , nil ) expect . Equal ( 2 , len ( result ) ) result , err = ConvertToMarshalMap ( convert2 , nil ) expect . Equal ( 2 , len ( result ) ) result , err = ConvertToMarshalMap ( convert3 , nil ) expect . Equal ( 2 , len ( result ) ) // Strip non-string keys result , err = ConvertToMarshalMap ( convert4 , nil ) expect . NoError ( err ) expect . Equal ( 2 , len ( result ) )", "del_tokens": "_ , err := ConvertToMarshalMap ( convert1 , nil ) _ , err = ConvertToMarshalMap ( convert2 , nil ) _ , err = ConvertToMarshalMap ( convert3 , nil ) // Simple, non-convertible AnyMap _ , err = ConvertToMarshalMap ( convert4 , nil ) expect . NotNil ( err )", "commit_type": "improve"}
{"commit_tokens": ["Added", "an", "Int", "()", "flag", "and", "fixed", "a", "bug", "that", "doesn", "t", "recognize", "single", "-", "letter", "arguments"], "add_tokens": "\" \" // Create a required-argument flag that accepts int values // Parameters: // names []string These are the names that are accepted on the command-line for this flag, e.g. -v --verbose // def int Default value for the flag // help string The help text (automatically Expand()ed) to display for this flag // Returns: // *string This points to a string whose value is updated as this flag is changed func Int ( names [ ] string , d int , help string ) * int { var err os . Error i := new ( int ) * i = d f := func ( istr string ) os . Error { * i , err = strconv . Atoi ( istr ) return err } ReqArg ( names , strconv . Itoa ( d ) , help , f ) return i } len ( os . Args [ i + skip + 1 ] ) >= 1 && } else if o . allowsArg != \" \" && len ( os . Args ) > i + 1 && len ( os . Args [ i + 1 ] ) >= 1 && os . Args [ i + 1 ] [ 0 ] != '-' {", "del_tokens": "len ( os . Args [ i + skip + 1 ] ) > 1 && } else if o . allowsArg != \" \" && len ( os . Args ) > i + 1 && len ( os . Args [ i + 1 ] ) > 1 && os . Args [ i + 1 ] [ 0 ] != '-' {", "commit_type": "add"}
{"commit_tokens": ["add", "fetchLastValuesSafe", "to", "detect", "state", "recently", "updated"], "add_tokens": "var errStateUpdated = errors . New ( \" \" ) func ( h * MackerelPlugin ) fetchLastValuesSafe ( now time . Time ) ( metricValues MetricValues , err error ) { m , err := h . FetchLastValues ( ) if err != nil { return m , err } if now . Sub ( m . Timestamp ) < time . Second { return m , errStateUpdated } return m , nil } lastMetricValues , err := h . fetchLastValuesSafe ( metricValues . Timestamp )", "del_tokens": "lastMetricValues , err := h . FetchLastValues ( )", "commit_type": "add"}
{"commit_tokens": ["fixing", "utc", "call", "to", "target", "time"], "add_tokens": "return Elapsed ( ms , diff ) * time . Millisecond", "del_tokens": "return time . Duration ( ElapsedIn ( ms , diff ) ) * time . Millisecond", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "godoc", "stuff", "to", "be", "a", "little", "more", "readable"], "add_tokens": "// Info works just like log.Print, but with a Cyan \"==> Info:\" prefix. // Debug works just like log.Print, but with a Magenta \"==> Debug:\" prefix. // Warn works just like log.Print, but with a Yellow \"==> Warn:\" prefix. // Fatal works just like log.Fatal, but with a Red \"==> Fatal:\" prefix. // Panic works just like log.Panic, but with a Red \"==> Panic:\" prefix. // Infof works just like log.Printf, but with a Cyan \"==> Info:\" prefix. // Debugf works just like log.Printf, but with a Magenta \"==> Debug:\" prefix. // Warnf works just like log.Printf, but with a Yellow \"==> Warn:\" prefix. // Fatalf works just like log.Fatalf, but with a Red \"==> Fatal:\" prefix. // Panicf works just like log.Panicf, but with a Red \"==> Panic:\" prefix. // Infoln works just like log.Println, but with a Cyan \"==> Info:\" prefix. // Debugln works just like log.Println, but with a Magenta \"==> Debug:\" prefix. // Warnln works just like log.Println, but with a Yellow \"==> Warn:\" prefix. // Fatalln works just like log.Fatalln, but with a Red \"==> Fatal:\" prefix. // Panicln works just like log.Panicln, but with a Red \"==> Panic:\" prefix.", "del_tokens": "// Info works just like log.Print however adds the Info prefix. // Debug works just like log.Print however adds the Debug prefix. // Warn works just like log.Print however adds the Warn prefix. // Fatal works just like log.Fatal however adds the Fatal prefix. // Panic works just like log.Panic however adds the Panic prefix. // Infof works just like log.Printf however adds the Info prefix. // Debugf works just like log.Printf however adds the Debug prefix. // Warnf works just like log.Printf however adds the Warn prefix. // Fatalf works just like log.Fatalf however adds the Fatal prefix. // Panicf works just like log.Panicf however adds the Panic prefix. // Infoln works just like log.Println however adds the Info prefix // Debugln works just like log.Println however adds the Debug prefix. // Warnln works just like log.Println however adds the Warnln prefix // Fatalln works just like log.Fatalln however adds the Fatal prefix // Panicln works just like log.Panicln however adds the Panic prefix", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "unit", "test", "for", "meta", "lookups", "."], "add_tokens": "// For dependency injection in tests. var newRegion = func ( host string , port uint16 ) ( * region . Client , error ) { return region . NewClient ( host , port ) } client , err := newRegion ( host , port )", "del_tokens": "client , err := region . NewClient ( host , port )", "commit_type": "add"}
{"commit_tokens": ["fix", "an", "issue", "with", "broadcast", "wave", "formatted", "audio", "files"], "add_tokens": "\" \" // unexpected chunk order, might be a bext chunk rewindBytes += int64 ( chunk . Size ) + 8 // drain the chunk io . CopyN ( ioutil . Discard , d . r , int64 ( chunk . Size ) )", "del_tokens": "// unexpected chunk order rewindBytes += int64 ( chunk . Size )", "commit_type": "fix"}
{"commit_tokens": ["Add", "-", "f", "to", "rm", "to", "suppress", "errors", "on", "non", "-", "existence", "."], "add_tokens": "rmf = rmOpts . Bool ( 'f' ) status = rm ( rmOpts . Args ( ) , * rmr , * rmf )", "del_tokens": "status = rm ( rmOpts . Args ( ) , * rmr )", "commit_type": "add"}
{"commit_tokens": ["Adds", "correct", "body", "and", "subject", "for", "emails", "from", "the", "/", "spaces", "endpoint"], "add_tokens": "Kind string `json:\"kind\"` Text string `json:\"text\"` KindDescription string `json:\"kind_description\"` SourceDescription string `json:\"source_description\"` Subject string `json:\"subject\"` Errors [ ] string", "del_tokens": "Kind string Text string Errors [ ] string", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "the", "memory", "read", "model", "did", "not", "return", "results", "in", "insert", "order"], "add_tokens": "if ! reflect . DeepEqual ( result [ 0 ] , model1Alt ) || ! reflect . DeepEqual ( result [ 1 ] , model2 ) {", "del_tokens": "if ( ! reflect . DeepEqual ( result [ 0 ] , model1Alt ) || ! reflect . DeepEqual ( result [ 1 ] , model2 ) ) && ( ! reflect . DeepEqual ( result [ 0 ] , model2 ) || ! reflect . DeepEqual ( result [ 1 ] , model1Alt ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "use", "the", "new", "ioprogress", "library", "."], "add_tokens": "bar := ioprogress . DrawTextFormatBarForW ( barSize , os . Stderr )", "del_tokens": "bar := ioprogress . DrawTextFormatBar ( barSize )", "commit_type": "update"}
{"commit_tokens": ["fixed", "no", "relation", "code", "and", "change", "user", "agent"], "add_tokens": "info . Header ( \" \" , \" \" )", "del_tokens": "\" \" info . Header ( \" \" , configs . Settings . UserAgent ) func GenMetaTitle ( params map [ string ] string ) string { v := configs . Settings . AppName if name , ok := params [ \" \" ] ; ok { return fmt . Sprintf ( \" n a e ) } else { return fmt . Sprintf ( \" } } func GenMetaKeywords ( params map [ string ] string ) string { if name , ok := params [ \" \" ] ; ok { return fmt . Sprintf ( \" \" , configs . Settings . Keywords , name ) } else { return configs . Settings . Keywords } } func GenMetaDescription ( params map [ string ] string ) string { if name , ok := params [ \" \" ] ; ok { return fmt . Sprintf ( \" . S ttings. D escripti o n, name) } else { return configs . Settings . Description } }", "commit_type": "fix"}
{"commit_tokens": ["Added", "logic", "to", "get", "a", "single", "pipeline", "instance"], "add_tokens": "DeletePipelineConfigCommandName = \" \" Category : \" \" ,", "del_tokens": "DeletePipelineConfigCommandName = \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "properties", "on", "some", "of", "the", "structs"], "add_tokens": "// Info contains various details about Users, Channels, Bots and the authenticated user IMs [ ] IM `json:\"ims,omitempty\"`", "del_tokens": "// Info contains various details about Users, Channels, Bots and the authenticated", "commit_type": "add"}
{"commit_tokens": ["use", "json", ".", "RawMessage", "for", "faster", "and", "cheaper", "JSON", "checks"], "add_tokens": "var js json . RawMessage", "del_tokens": "var js map [ string ] interface { }", "commit_type": "use"}
{"commit_tokens": ["Add", "LOG_EXCEPT", "for", "filtering", "out", "specific", "packages"], "add_tokens": "// In case AllEnabled is enabled and you want to filter some packages, you can pass LOG_EXCEPT=foo,bar Except map [ string ] bool if AllEnabled { Except = initExcept ( ) } return readPackageNames ( val ) , false } func initExcept ( ) map [ string ] bool { return readPackageNames ( os . Getenv ( \" \" ) ) } func readPackageNames ( val string ) map [ string ] bool { return all", "del_tokens": "return all , false", "commit_type": "add"}
{"commit_tokens": ["Update", "README", "for", "how", "to", "extend", "TimeFormats"], "add_tokens": "onlyTime := regexp . MustCompile ( `^\\s*\\d+(:\\d+)*\\s*$` ) . MatchString ( str ) // match 15:04:05, 15 onlyTime = onlyTime && ( parseTime [ 3 ] == 1 ) && ( parseTime [ 4 ] == 1 ) if ( i == 3 || i == 4 ) && onlyTime {", "del_tokens": "hasDate := regexp . MustCompile ( `-\\d` ) . MatchString ( str ) if ( i == 3 || i == 4 ) && ! hasDate {", "commit_type": "update"}
{"commit_tokens": ["Fix", "size", "of", "m", "union", "in", "v4l2_buffer", "for", "32", "platforms"], "add_tokens": "union [ unsafe . Sizeof ( __p ) ] uint8 timeoutNsec := int64 ( timeout ) * oneSecInNsec", "del_tokens": "union [ 8 ] uint8 timeoutNsec := int64 ( timeout ) * oneSecInNsec", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "doc", ".", "go"], "add_tokens": "// assert.NoError(t, errorObject [, message [, format-args]])", "del_tokens": "// assert.NotError(t, errorObject [, message [, format-args]])", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "bug", "found", "in", "testing"], "add_tokens": "if len ( durations ) <= durationIndex {", "del_tokens": "if len ( durations ) >= durationIndex {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "ssh", "copy", "to", "use", "scp"], "add_tokens": "letterBytes = \" \"", "del_tokens": "letterBytes = \" \"", "commit_type": "update"}
{"commit_tokens": ["Remove", "unneeded", "dbg", "msg", ";", "only", "send", "when", "can"], "add_tokens": "if ! r . testMode { // Only attempt to send spans if we're announced. if sensor . agent . canSend ( ) { log . debug ( \" \" , len ( r . spans ) ) r . send ( ) }", "del_tokens": "if r . testMode { log . debug ( \" \" ) } else { log . debug ( \" \" , len ( r . spans ) ) r . send ( )", "commit_type": "remove"}
{"commit_tokens": ["Make", "client", "public", "so", "one", "can", "override", "it", "e", ".", "g", ".", "for", "setting", "proxy", "transport"], "add_tokens": "Client * http . Client Client : http . DefaultClient , resp , err := c . Client . Do ( req ) resp , err := c . Client . Do ( req ) resp , err := c . Client . Do ( req ) resp , err := c . Client . Do ( req )", "del_tokens": "client * http . Client client : http . DefaultClient , resp , err := c . client . Do ( req ) resp , err := c . client . Do ( req ) resp , err := c . client . Do ( req ) resp , err := c . client . Do ( req )", "commit_type": "make"}
{"commit_tokens": ["Change", "the", "embed", "-", "go", "mechanism", "to", "generate", "a", "single", "source", "file", "per", "package"], "add_tokens": "{ { range . Boxes } } } { { end } } `) type embedFileDataType struct { Boxes [ ] * boxDataType } type boxDataType struct {", "del_tokens": "} `) type boxDataType struct {", "commit_type": "change"}
{"commit_tokens": ["Adds", "multipart", "body", "Read", "test"], "add_tokens": "const testMultipartBody = \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" func TestNewMultipart_read ( t * testing . T ) { e := testMakeMultipart ( ) if b , err := ioutil . ReadAll ( e ) ; err != nil { t . Error ( \" \" , err ) } else if s := string ( b ) ; s != testMultipartBody { t . Errorf ( \" \" , testMultipartBody , s ) } } testMultipartBody", "del_tokens": "\" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \"", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "time", ".", "RFC3339", "time", ".", "RFC3339Nano", "in", "AppStats", ".", "Usage", ".", "Time", "field", "since", "actual", "values", "from", "a", "running", "instance", "of", "Cloud", "Foundry", "have", "proven", "to", "return", "values", "in", "the", "RFC3339Nano", "format", ".", "Adjusted", "the", "UnmarshalJSON", "field", "for", "the", "custom", "sinceTime", "type", "so", "that", "it", "can", "allow", "for", "more", "formats", "to", "be", "attempted", "before", "giving", "up", "and", "erroring", "out", ".", "Added", "test", "conditions", "for", "this", "third", "time", "format"], "add_tokens": "possibleFormats := [ ... ] string { time . RFC3339 , time . RFC3339Nano , \" \" } var value time . Time for _ , possibleFormat := range possibleFormats { if value , err = time . Parse ( possibleFormat , timeString ) ; err == nil { * s = statTime { value } return nil return fmt . Errorf ( \" \" , timeString , possibleFormats )", "del_tokens": "// RFC3339 time format if ( string ( timeString [ 10 ] ) == \" \" && string ( timeString [ 19 ] ) == \" \" ) { time , err := time . Parse ( \" \" , timeString ) if err != nil { return err } * s = statTime { time } // Unix epoch time format } else { time , err := time . Parse ( \" \" , timeString ) if err != nil { return err * s = statTime { time } if err != nil { return err } return nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "potential", "problem", "in", "Pipe", "and", "add", "comment", "."], "add_tokens": "func Pipe ( src , dst net . Conn , end chan int ) { // Should not use io.Copy here. // io.Copy will try to use the ReadFrom interface of TCPConn, but the src // here is not a regular file, so sendfile is not applicable. // io.Copy will fallback to the normal copy after discovering this, // introducing unnecessary overhead. // read may return EOF with num > 0 // should always process num > 0 bytes before handling error if num > 0 { if _ , err = dst . Write ( buf [ 0 : num ] ) ; err != nil { break if num == 0 { // num == 0 should associate with EOF break } if err != nil { log . Println ( \" \" , err ) break end <- 1", "del_tokens": "func Pipe ( src net . Conn , dst net . Conn , end chan int ) { if err == nil { _ , err := dst . Write ( buf [ 0 : num ] ) if err != nil { end <- 1 return } else { log . Println ( \" \" , err ) end <- 1 return if num == 0 { end <- 1 return", "commit_type": "fix"}
{"commit_tokens": ["Create", "skeleton", "for", "revocation", "methods"], "add_tokens": "package revocation return nil", "del_tokens": "package wallet // TODO(roasbeef): port Rusty's hash-chain stuff // * or just use HD chains based off of CodeShark's proposal?", "commit_type": "create"}
{"commit_tokens": ["Update", "README", "with", "heredoc", "description"], "add_tokens": "heredocStartPattern = regexp . MustCompile ( `^<<(-)?(?:[ \\f\\r\\t\\v])*([a-zA-Z0-9_]+)\\n` )", "del_tokens": "heredocStartPattern = regexp . MustCompile ( `^<<(-)?(?:[ \\f\\r\\t\\v])*(.+)\\n` )", "commit_type": "update"}
{"commit_tokens": ["fix", "loopback", "/", "link", "-", "local", "checks"], "add_tokens": "if IsIPLoopback ( newMultiaddr ( t , \" \" ) ) { t . Error ( \" \" ) } isLinkLocal := ( a & 0xffc0 == 0xfe80 || a & 0xff0f == 0xff02 )", "del_tokens": "isLinkLocal := ( a == 0xfe80 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "unmarshalling", "into", "pointer", "fields"], "add_tokens": "\" \" blah := 0 sptr := \" \" sptr2 := \" \" b := bytes . NewBufferString ( `foo,BAR,Baz,Blah,SPtr f , 1 , baz , , * string e , 3 , b , , `) expected := Sample { Foo : \" \" , Bar : 1 , Baz : \" \" , Blah : & blah , SPtr : & sptr } if ! reflect . DeepEqual ( expected , samples [ 0 ] ) { expected = Sample { Foo : \" \" , Bar : 3 , Baz : \" \" , Blah : & blah , SPtr : & sptr2 } if ! reflect . DeepEqual ( expected , samples [ 1 ] ) {", "del_tokens": "b := bytes . NewBufferString ( `foo,BAR,Baz f , 1 , baz e , 3 , b `) expected := Sample { Foo : \" \" , Bar : 1 , Baz : \" \" } if expected != samples [ 0 ] { expected = Sample { Foo : \" \" , Bar : 3 , Baz : \" \" } if expected != samples [ 1 ] {", "commit_type": "add"}
{"commit_tokens": ["Make", "WriteHeader", "set", "status", "before", "calling", "beforeFuncs", "so", "middlewares", "can", "do", "stuff", "based", "on", "the", "resulting", "status", "code", "of", "the", "request"], "add_tokens": "rw . status = s", "del_tokens": "rw . status = s", "commit_type": "make"}
{"commit_tokens": ["Add", "plot", ":", "timings", "CLI", "test"], "add_tokens": "rate , duration , targetsf , ordering , _ , output := defaultArguments ( ) for _ , reporter := range [ ] string { \" \" , \" \" } { err := run ( rate , duration , targetsf , ordering , reporter , output ) if err != nil { t . Errorf ( \" \" , reporter , err ) }", "del_tokens": "rate , duration , targetsf , ordering , reporter , output := defaultArguments ( ) err := run ( rate , duration , targetsf , ordering , reporter , output ) if err != nil { t . Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Improves", "error", "handling", "in", "cmd", "updates", "README"], "add_tokens": "parseErr := func ( input string ) error { return fmt . Errorf ( \" \" , input ) } return nil , parseErr ( flag . Arg ( 0 ) ) return nil , parseErr ( flag . Arg ( 1 ) ) return nil , parseErr ( flag . Arg ( 2 ) )", "del_tokens": "return nil , err return nil , err return nil , err", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "a", "dumb", "test", "bug", "."], "add_tokens": "t . clock . AdvanceTime ( fs . DirListingCacheTTL + time . Millisecond )", "del_tokens": "t . clock . AdvanceTime ( fs . DirListingCacheTTL - time . Millisecond )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "retry", "for", "a", "network", "issue"], "add_tokens": "import \" \" errorMsg := \" \" if len ( errorMsg ) > 0 { errorMsg = fmt . Sprintf ( \" \" , errorMsg , t . hosts [ it ] , err ) } else { errorMsg = fmt . Sprintf ( \" \" , t . hosts [ it ] , err ) } continue return nil , errors . New ( fmt . Sprintf ( \" \" , errorMsg ) )", "del_tokens": "return nil , err return nil , errors . New ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "an", "example", "usage", "to", "the", "README", ".", "md"], "add_tokens": "s := NewStack ( ) func Test_GithubExample ( t * testing . T ) { stack := NewStack ( ) // Stack supports any type // so we just push whatever // we want here stack . Push ( 75 ) stack . Push ( 124 ) stack . Push ( \" \" ) for stack . Size ( ) > 0 { _ = stack . Pop ( ) } if stack . Size ( ) != 0 { t . Fatalf ( \" \" ) } } top * Element next * Element", "del_tokens": "s := NewStack ( ) top * Element next * Element", "commit_type": "add"}
{"commit_tokens": ["add", "uaa", "auth", "option", "to", "client"], "add_tokens": "client , _ = NewClient ( config )", "del_tokens": "client = NewClient ( config )", "commit_type": "add"}
{"commit_tokens": ["use", "assert", "and", "add", "test"], "add_tokens": "\" \" func TestIncludesAny ( t * testing . T ) { assert . True ( t , IncludesAny ( \" \" , [ ] string { \" \" , \" \" , \" \" } ) , ) assert . False ( t , IncludesAny ( \" \" , [ ] string { \" \" , \" \" , \" \" } ) , )", "del_tokens": "func TestSum ( t * testing . T ) { actual := Sum ( 10 , 20 ) expected := 30 if actual != expected { t . Errorf ( \" \\n \" , actual , expected ) }", "commit_type": "use"}
{"commit_tokens": ["Add", "paging", "support", "to", "domain", "list"], "add_tokens": "opts := & struct { Page int `xmlrpc:\"page\"` } { 0 } const perPage = 100 params := [ ] interface { } { self . Key , opts } for { var res [ ] interface { } if err := self . Call ( \" \" , params , & res ) ; err != nil { return nil , err } for _ , r := range res { domain := ToDomainInfoBase ( r . ( map [ string ] interface { } ) ) domains = append ( domains , domain ) } if len ( res ) < perPage { break } opts . Page ++", "del_tokens": "var res [ ] interface { } params := [ ] interface { } { self . Key } if err := self . Call ( \" \" , params , & res ) ; err != nil { return nil , err } for _ , r := range res { domain := ToDomainInfoBase ( r . ( map [ string ] interface { } ) ) domains = append ( domains , domain )", "commit_type": "add"}
{"commit_tokens": ["fix", "tests", "for", "gzip", "handler"], "add_tokens": "if trimmed == \" \" || strings . Contains ( trimmed , \" \" ) { // TODO : Does not work in browser, returns application/x-gzip? But usually, the content-type // should be explicitly set somewhere down the path of chained handlers...", "del_tokens": "// TODO : May not work in usual cases, one value, but comma-separated? if trimmed == \" \" || trimmed == \" \" {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "deploying", "Java", "chaincode", "from", "remote", "git", "repositories"], "add_tokens": "\" \" var tmp string tmp , err = ioutil . TempDir ( \" \" , \" \" ) if err != nil { return \" \" , fmt . Errorf ( \" \" , err ) } var out bytes . Buffer cmd := exec . Command ( \" \" , \" \" , path , tmp ) cmd . Stderr = & out cmderr := cmd . Run ( ) if cmderr != nil { return \" \" , fmt . Errorf ( \" \" , cmderr ) } return tmp , nil if strings . HasPrefix ( codepath , \" \" ) || strings . HasPrefix ( codepath , \" \" ) {", "del_tokens": "//TODO return \" \" , nil if strings . HasPrefix ( codepath , \" \" ) { ishttp = true codepath = codepath [ 7 : ] codepath , err = getCodeFromHTTP ( codepath ) } else if strings . HasPrefix ( codepath , \" \" ) { codepath = codepath [ 8 : ]", "commit_type": "allow"}
{"commit_tokens": ["Added", "support", "to", "connect", "to", "OVSDB", "server", "using", "Unix", "socket"], "add_tokens": "\" \" // ConnectUsingProtocol creates an OVSDB connection and returns and OvsdbClient func ConnectUsingProtocol ( protocol string , target string ) ( * OvsdbClient , error ) { conn , err := net . Dial ( protocol , target ) // Connect creates an OVSDB connection and returns and OvsdbClient func Connect ( ipAddr string , port int ) ( * OvsdbClient , error ) { if ipAddr == \" \" { ipAddr = DefaultAddress } if port <= 0 { port = DefaultPort } target := fmt . Sprintf ( \" \" , ipAddr , port ) return ConnectUsingProtocol ( \" \" , target ) } // ConnectWithUnixSocket makes a OVSDB Connection via a Unix Socket func ConnectWithUnixSocket ( socketFile string ) ( * OvsdbClient , error ) { if _ , err := os . Stat ( socketFile ) ; os . IsNotExist ( err ) { return nil , errors . New ( \" \" ) } return ConnectUsingProtocol ( \" \" , socketFile ) }", "del_tokens": "// Connect creates an OVSDB connection and returns and OvsdbClient func Connect ( ipAddr string , port int ) ( * OvsdbClient , error ) { if ipAddr == \" \" { ipAddr = DefaultAddress } if port <= 0 { port = DefaultPort } target := fmt . Sprintf ( \" \" , ipAddr , port ) conn , err := net . Dial ( \" \" , target )", "commit_type": "add"}
{"commit_tokens": ["Adds", "example", "updates", "package", "name"], "add_tokens": "package xtermcolor", "del_tokens": "package xtermcolors", "commit_type": "add"}
{"commit_tokens": ["adds", "a", "function", "to", "convert", "swagger", "names", "to", "golint", "valid", "names"], "add_tokens": "\" \" Consumes [ ] string Consumers map [ string ] Consumer Produces [ ] string Producers map [ string ] Producer Operation * swagger . Operation Handler OperationHandler Analyzer * specAnalyzer ParamNames map [ string ] string paramNames := make ( map [ string ] string ) for _ , param := range operation . Parameters { paramNames [ param . Name ] = util . ToGoName ( param . Name ) }", "del_tokens": "Consumes [ ] string Consumers map [ string ] Consumer Produces [ ] string Producers map [ string ] Producer Operation * swagger . Operation Handler OperationHandler Analyzer * specAnalyzer", "commit_type": "add"}
{"commit_tokens": ["Added", "pass", "-", "through", "if", "more", "than", "one", "calls", "to", "FallOnSword", "are", "made"], "add_tokens": "select { case d . callChannel <- struct { } { } : default : }", "del_tokens": "d . callChannel <- struct { } { }", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "coverage", "for", "Date", "type"], "add_tokens": "Unique bool attrs := make ( [ ] string , 0 ) if s . PrimaryKey { attrs = append ( attrs , \" \" ) } attrs = append ( attrs , \" \" ) } if s . Unique { attrs = append ( attrs , \" \" ) } if len ( attrs ) > 0 { compiled += fmt . Sprintf ( \" \" , strings . Join ( attrs , \" \" ) )", "del_tokens": "compiled += \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "formatting", "directive", "in", "tests"], "add_tokens": "t . Errorf ( \" \" , message , m . Message ) t . Errorf ( \" \" , 0 , m . Code )", "del_tokens": "t . Error ( \" \" , message , m . Message ) t . Error ( \" \" , 0 , m . Code )", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "millipedes", "with", "tail"], "add_tokens": "Tail string Tail : \" Tail : \" // GetTail returns a the tail of the millipede func ( s * Skin ) GetTail ( ) string { s . checkDirection ( ) if s . currentDirection . Tail == \" \" { return \" \" } s . Width ( ) tail := s . currentDirection . Tail tail = s . adaptWidth ( tail ) return strings . TrimRight ( tail , \" \" ) } if s . currentDirection . Tail != \" \" { tailWidth := utf8 . RuneCountInString ( s . currentDirection . Tail ) if tailWidth > s . maxWidth { s . maxWidth = tailWidth }", "del_tokens": "//Tail string / * if s . currentDirection . Tail != \" \" { tailWidth := utf8 . RuneCountInString ( s . currentDirection . Tail ) if tailWidth > s . maxWidth { s . maxWidth = tailWidth } * /", "commit_type": "add"}
{"commit_tokens": ["Add", "addressable", "ports", "support", "for", "IIPs"], "add_tokens": "// \"e33\": new(echo), \" \" : new ( router ) , // {\"e33\", \"Out\", \"r\", \"In[e3]\"}, { \" \" , \" \" , 3 } , // {\"e33\", \"In\", 3},", "del_tokens": "\" \" : new ( echo ) , \" \" : new ( router ) , { \" \" , \" \" , \" \" , \" \" } , // {\"r\", \"In[e3]\", 3}, { \" \" , \" \" , 3 } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "function", "to", "build", "more", "useful", "error", "messages", "for", "debugging", "."], "add_tokens": "import ( \" \" \" \" ) / * ErrorWithCauseChain formats err and all its causes if it 's an * Err , else returns err . Error ( ) . * / func ErrorWithCauseChain ( err error ) string { var buffer bytes . Buffer for { if wrappedErr , ok := err . ( * Err ) ; ok && wrappedErr . Cause != nil { fmt . Fprintln ( & buffer , wrappedErr . Error ( ) ) fmt . Fprint ( & buffer , \" \" ) err = wrappedErr . Cause } else { break } } buffer . WriteString ( err . Error ( ) ) return buffer . String ( ) }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Changed", "algorithm", "to", "use", "sleep", "where", "relevant", "."], "add_tokens": "diff := time . Now ( ) . Sub ( r . times [ 0 ] ) if diff < r . interval { time . Sleep ( r . interval - diff ) r . times = r . times [ 1 : ]", "del_tokens": "if time . Now ( ) . Sub ( r . times [ 0 ] ) > r . interval { r . times = r . times [ 1 : ]", "commit_type": "change"}
{"commit_tokens": ["Add", "NewWithReadline", "to", "have", "a", "shell", "with", "custom", "readline", "Instance"], "add_tokens": "return NewWithReadline ( rl ) } // NewWithReadline creates a new shell with a custom readline instance. func NewWithReadline ( rl * readline . Instance ) * Shell { writer : rl . Config . Stdout ,", "del_tokens": "writer : conf . Stdout ,", "commit_type": "add"}
{"commit_tokens": ["updated", "regex", "for", "faster", "URI", "pattern", "matching"], "add_tokens": "//Regex prepared based on http://stackoverflow.com/a/4669750/1359163, https://tools.ietf.org/html/rfc3986 //const urlchars = `([a-zA-Z0-9\\*\\-+._~!$()=&',;:@%]+)` //Though this allows invalid characters in the URI parameter, it has better performance. const urlchars = `([^/]+)`", "del_tokens": "const urlchars = `([a-zA-Z0-9\\_%\\-\\.\\@]+)`", "commit_type": "update"}
{"commit_tokens": ["Fix", "wrong", "type", "for", "isDefault", "field", "of", "VirtualSubnet", "class"], "add_tokens": "IsDefault bool `json:\"isDefault\"`", "del_tokens": "IsDefault string `json:\"isDefault\"`", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "delete", "public", "ip"], "add_tokens": "func ( s * Service ) GetPublicIP ( name string , ip string ) ( * PublicIP , error ) { url := fmt . Sprintf ( \" \" , s . client . Config . BaseURL , s . client . Config . Alias , name , ip ) resp := & PublicIP { } err := s . client . Get ( url , resp ) return resp , err } func ( s * Service ) DeletePublicIP ( name , ip string ) ( * IPResponse , error ) { resp := & IPResponse { } err := s . client . Delete ( url , resp ) ID string `json:\"id\"`", "del_tokens": "func ( s * Service ) GetPublicIP ( name string , ip string ) ( * PublicIP , error ) { resp := & PublicIP { } err := s . client . Get ( url , resp ) Id string `json:\"id\"`", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "redundant", "code", "in", "diff", "calculation"], "add_tokens": "func pointerSet ( j [ ] byte ) ( map [ string ] bool , error ) { a , err := ListPointers ( j ) if err != nil { return nil , err } rv := map [ string ] bool { } for _ , v := range a { rv [ v ] = true } return rv , nil } amap , err := pointerSet ( a ) bmap , err := pointerSet ( b ) for v := range amap { for v := range bmap {", "del_tokens": "alist , err := ListPointers ( a ) blist , err := ListPointers ( b ) amap := map [ string ] bool { } bmap := map [ string ] bool { } for _ , v := range alist { amap [ v ] = true } for _ , v := range blist { bmap [ v ] = true } for _ , v := range alist { for _ , v := range blist {", "commit_type": "remove"}
{"commit_tokens": ["Updated", "queue", "to", "store", "a", "pointer", "to", "Deque", "instead", "of", "copy"], "add_tokens": "* Deque Deque : NewDeque ( ) ,", "del_tokens": "Deque Deque : * NewDeque ( ) ,", "commit_type": "update"}
{"commit_tokens": ["Implemented", "a", "poll", "based", "wait", "impl", "for", "non", "-", "child", "processes"], "add_tokens": "go func ( pid int ) { Wait ( pid ) } ( p . Pid )", "del_tokens": "go func ( ) { p . Wait ( ) } ( )", "commit_type": "implement"}
{"commit_tokens": ["add", "host", "buffer", "factor", "option"], "add_tokens": "this . workers , this . push = make ( map [ string ] * worker , hostCount ) , make ( chan * workerResponse , hostCount ) this . workers , this . push = make ( map [ string ] * worker , this . Options . HostBufferFactor * hostCount ) , make ( chan * workerResponse , this . Options . HostBufferFactor * hostCount )", "del_tokens": "this . workers , this . push = make ( map [ string ] * worker , hostCount ) , make ( chan * workerResponse , hostCount ) this . workers , this . push = make ( map [ string ] * worker , 10 * hostCount ) , make ( chan * workerResponse , 10 * hostCount )", "commit_type": "add"}
{"commit_tokens": ["changed", "queue", "test", "to", "test", "if", "data", "is", "-", "1", "not", "a", "bit", "in", "state"], "add_tokens": "nodesBase [ i ] . state = 1 << 31 - 1 if nodes . HeapContains ( v ) && newWeight < v . state { v . state = newWeight", "del_tokens": "nodesBase [ i ] . state = 2 << 30 - 1 nodesBase [ i ] . state |= queued start . node . state |= queued if nodes . QueueContains ( v ) && newWeight < ( v . state & ^ queued ) { v . state = newWeight | queued", "commit_type": "change"}
{"commit_tokens": ["adding", "initial", "implementation", "of", "mail", "sending"], "add_tokens": "import ( )", "del_tokens": "import ( \" \" ) func parseString ( body [ ] byte , err error ) ( string , error ) { if err != nil { return \" \" , err } return strconv . Unquote ( string ( body ) ) }", "commit_type": "add"}
{"commit_tokens": ["fix", "delete", "method", "copy", "pasta"], "add_tokens": "req , err := c . NewRequest ( http . MethodDelete , url , nil )", "del_tokens": "req , err := c . NewRequest ( http . MethodPut , url , nil )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "right", "shift", "of", "negative", "numbers", "."], "add_tokens": "return fmt . Sprintf ( \" \" , toJavaScriptType ( basic ) , ex , c . translateExprToType ( e . Y , types . Typ [ types . Uint ] ) ) if e . Op == token . SHR && basic . Info ( ) & types . IsUnsigned != 0 {", "del_tokens": "return fmt . Sprintf ( \" \" , ex , c . translateExprToType ( e . Y , types . Typ [ types . Uint ] ) ) if e . Op == token . SHR {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "printing", "of", "FPS", "value"], "add_tokens": "value := format . ValueForKey ( \" \" ) if value == nil { fps = fmt . Sprintf ( \" \" , value )", "del_tokens": "if format . ValueForKey ( \" \" ) == nil { fps = format . ValueForKey ( \" \" ) . ( string )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "underscores", "form", "private", "variables", "."], "add_tokens": "timeMu sync . Mutex lasttime uint64 // last time we returned clockSeq uint16 // clock sequence for this run if clockSeq == 0 { clockSeq = ( ( clockSeq + 1 ) & 0x3fff ) | 0x8000 return Time ( now ) , clockSeq , nil if clockSeq == 0 { return int ( clockSeq & 0x3fff ) old_seq := clockSeq clockSeq = uint16 ( seq & 0x3fff ) | 0x8000 // Set our variant if old_seq != clockSeq {", "del_tokens": "timeMu sync . Mutex lasttime uint64 // last time we returned clock_seq uint16 // clock sequence for this run if clock_seq == 0 { clock_seq = ( ( clock_seq + 1 ) & 0x3fff ) | 0x8000 return Time ( now ) , clock_seq , nil if clock_seq == 0 { return int ( clock_seq & 0x3fff ) old_seq := clock_seq clock_seq = uint16 ( seq & 0x3fff ) | 0x8000 // Set our variant if old_seq != clock_seq {", "commit_type": "remove"}
{"commit_tokens": ["made", "to", "or", "test", "work"], "add_tokens": "bc . bitmap [ i ] |= ( 1 << ( value2 . content [ k ] % 64 ) ) i := uint ( ToIntUnsigned ( self . content [ k ] ) ) >> 6 bc . bitmap [ i ] |= ( 1 << ( self . content [ k ] % 64 ) ) nl := Union2by2 ( value1 . content , value2 . content , answer . content ) answer . content = answer . content [ : nl ] //what is this voodo?", "del_tokens": "bc . bitmap [ i ] |= ( 1 << value2 . content [ k ] ) i := int ( uint ( ToIntUnsigned ( self . content [ k ] ) ) >> 6 ) bc . bitmap [ i ] |= ( 1 << self . content [ k ] ) Union2by2 ( value1 . content , value2 . content , answer . content )", "commit_type": "make"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectEq ( \" \\x00 \" , objects . Results [ 1 ] . Name ) ExpectEq ( \" \" , objects . Results [ 2 ] . Name ) ExpectEq ( \" \\xff \" , objects . Results [ 3 ] . Name )", "del_tokens": "ExpectEq ( \" \\x00 \" , objects . Results [ 0 ] . Name ) ExpectEq ( \" \" , objects . Results [ 1 ] . Name ) ExpectEq ( \" \\xff \" , objects . Results [ 1 ] . Name )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "endpoint", "embedded", "in", "the", "playground", "s", "html", "template"], "add_tokens": "Endpoint : r . URL . Path ,", "del_tokens": "Endpoint : \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "Create", "Start", "Stop", "Kill", "containers"], "add_tokens": "Id string Path string Args [ ] string State struct { Running bool Pid int ExitCode int Ghost bool Image string IpAddress string Gateway string Bridge string Ports map [ string ] [ ] PortBinding SysInitPath string Volumes map [ string ] string HostConfig * HostConfig PublicPort int Type string Id string Names [ ] string Image string Command string Created int Status string Ports [ ] Port SizeRw int", "del_tokens": "Id string Path string Args [ ] string State struct { Running bool Pid int ExitCode int Ghost bool Image string IpAddress string Gateway string Bridge string Ports map [ string ] [ ] PortBinding SysInitPath string Volumes map [ string ] string HostConfig * HostConfig PublicPort int Type string Id string Names [ ] string Image string Command string Created int Status string Ports [ ] Port SizeRw int", "commit_type": "add"}
{"commit_tokens": ["add", "windows", "as", "a", "build", "target", "to", "_stubs", ".", "go", "files"], "add_tokens": "// +build !cgo,!plan9 windows android", "del_tokens": "// +build !cgo,!plan9 android", "commit_type": "add"}
{"commit_tokens": ["Use", "print", "functions", "if", "there", "is", "no", "format"], "add_tokens": "if len ( a ) == 0 { c . Print ( format ) return } return c . SprintFunc ( ) ( format )", "del_tokens": "if len ( a ) == 0 { a = append ( a , format ) format = \" \" } a = append ( a , format ) format = \" \"", "commit_type": "use"}
{"commit_tokens": ["Fix", "auth", "with", "clair", "on", "Basic", "realm", "=", "Registry"], "add_tokens": "if ! strings . Contains ( err . Error ( ) , `malformed auth challenge header: 'Basic realm=\"Registry` ) {", "del_tokens": "if ! strings . Contains ( err . Error ( ) , `malformed auth challenge header: 'Basic realm=\"Registry Realm\"'` ) {", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", ".", "json"], "add_tokens": "URL string `json:\"url,omitempty\"` // Initiator URL, set for Parser type or for Script type (when script is importing module) or for SignedExchange type. InitiatorTypeParser InitiatorType = \" \" InitiatorTypeScript InitiatorType = \" \" InitiatorTypePreload InitiatorType = \" \" InitiatorTypeSignedExchange InitiatorType = \" \" InitiatorTypeOther InitiatorType = \" \" case InitiatorTypeSignedExchange : * t = InitiatorTypeSignedExchange", "del_tokens": "URL string `json:\"url,omitempty\"` // Initiator URL, set for Parser type or for Script type (when script is importing module). InitiatorTypeParser InitiatorType = \" \" InitiatorTypeScript InitiatorType = \" \" InitiatorTypePreload InitiatorType = \" \" InitiatorTypeOther InitiatorType = \" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "bit", "more", "godoc"], "add_tokens": "// None is the buffer capacity for channels that have no buffer at all. None BufferCap = 0 // Infinity is the buffer capacity for channels with no limit on their buffer size.", "del_tokens": "None BufferCap = 0", "commit_type": "add"}
{"commit_tokens": ["implement", "lazyBuilder", "and", "rename", "FunkBuilder"], "add_tokens": "// Builder ... type Builder interface { Chunk ( size int ) Builder Compact ( ) Builder Drop ( in interface { } , n int ) Builder Filter ( predicate interface { } ) Builder FlattenDeep ( ) Builder ForEach ( predicate interface { } ) Builder ForEachRight ( predicate interface { } ) Builder Initial ( ) Builder Intersect ( y interface { } ) Builder Map ( mapFunc interface { } ) Builder Reverse ( ) Builder Shuffle ( ) Builder Uniq ( ) Builder", "del_tokens": "type FunkBuilder interface { Chunk ( size int ) FunkBuilder Compact ( ) FunkBuilder Drop ( in interface { } , n int ) FunkBuilder Filter ( predicate interface { } ) FunkBuilder FlattenDeep ( ) FunkBuilder ForEach ( predicate interface { } ) FunkBuilder ForEachRight ( predicate interface { } ) FunkBuilder Initial ( ) FunkBuilder Intersect ( y interface { } ) FunkBuilder Map ( mapFunc interface { } ) FunkBuilder Reverse ( ) FunkBuilder Shuffle ( ) FunkBuilder Uniq ( ) FunkBuilder", "commit_type": "implement"}
{"commit_tokens": ["Update", "to", "new", "turnpike", "api"], "add_tokens": "self . Client , err = turnpike . NewWebsocketClient ( self . serialization , self . url , nil , nil , nil )", "del_tokens": "self . Client , err = turnpike . NewWebsocketClient ( self . serialization , self . url , nil , nil )", "commit_type": "update"}
{"commit_tokens": ["Added", "ParseAttributeList", "function", "fixed", "lint", "issues"], "add_tokens": "// DeviceAttributes contains values returned from the FetchAttributes call", "del_tokens": "// DeviceAttributes continas values returned from the FetchAttributes call", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "testcases", "for", "SetWithFlags"], "add_tokens": "err = SetWithFlags ( tmp . Name ( ) , UserPrefix + \" \" , [ ] byte ( \" \" ) , 0 ) err = SetWithFlags ( tmp . Name ( ) , UserPrefix + \" \" , [ ] byte ( \" \" ) , XATTR_CREATE ) if err == nil { t . Fatalf ( \" \" ) } t . Log ( err ) err = Remove ( tmp . Name ( ) , UserPrefix + \" \" ) checkIfError ( t , err ) err = SetWithFlags ( tmp . Name ( ) , UserPrefix + \" \" , [ ] byte ( \" \" ) , XATTR_REPLACE ) if err == nil { t . Fatalf ( \" \" ) } t . Log ( err )", "del_tokens": "err = SetWithFlags ( tmp . Name ( ) , UserPrefix + \" \" , [ ] byte ( \" \" ) , XATTR_CREATE )", "commit_type": "add"}
{"commit_tokens": ["Add", "filesystem", "to", "media", "library"], "add_tokens": "var ErrNotImplemented = errors . New ( \" \" ) Option Option File multipart . File func ( b Base ) Store ( path string , header * multipart . FileHeader ) error { if src , err := header . Open ( ) ; err == nil { b . File = src return nil } else { return err } return ErrNotImplemented return nil , ErrNotImplemented return ErrNotImplemented func ( b Base ) ParseOption ( option string ) { } func ( b Base ) GetOption ( ) Option { return Option { } }", "del_tokens": "var NotImplementError = errors . New ( \" \" ) file multipart . File func ( b Base ) Store ( path string , file multipart . File , header * multipart . FileHeader ) error { b . file = file // save return NotImplementError return nil , NotImplementError return NotImplementError", "commit_type": "add"}
{"commit_tokens": ["add", "filter", "for", "IAM", "roles", "managed", "by", "AWS"], "add_tokens": "import ( \" \" \" \" \" \" ) path string path : * out . Path , func ( e * IamRole ) Filter ( ) error { if strings . HasPrefix ( e . path , \" \" ) { return fmt . Errorf ( \" \" ) } return nil }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["update", "the", "rest", "of", "the", "frame", "names", "in", "code"], "add_tokens": "if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) {", "del_tokens": "if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) { if bm . Frame == \" \" && strings . Contains ( err . Error ( ) , \" \" ) {", "commit_type": "update"}
{"commit_tokens": ["updated", "game", "move", "now", "takes", "a", "move", "object", "moveSq", "added"], "add_tokens": "if err := g . MoveSq ( F3 , F7 , NoPiece ) ; err != nil { if err := g . MoveSq ( B1 , B6 , NoPiece ) ; err != nil { if err := g . MoveSq ( D7 , D8 , Queen ) ; err != nil {", "del_tokens": "if err := g . Move ( F3 , F7 , NoPiece ) ; err != nil { if err := g . Move ( B1 , B6 , NoPiece ) ; err != nil { if err := g . Move ( D7 , D8 , Queen ) ; err != nil {", "commit_type": "update"}
{"commit_tokens": ["adding", "HttpClient", "public", "property", "to", "Client", "so", "that", "it", "can", "be", "overridden", "with", "Proxy", "support", "custom", "headers", "&", "GoVCR", "for", "testing", "."], "add_tokens": "HttpClient * http . Client c . HttpClient = new ( http . Client ) resp , err := c . HttpClient . Do ( req )", "del_tokens": "client := new ( http . Client ) resp , err := client . Do ( req )", "commit_type": "add"}
{"commit_tokens": ["add", "size", "for", "flush", "chan"], "add_tokens": "flushSize = 1 // chen queue used to flush the writer logger . flush = make ( chan bool , flushSize )", "del_tokens": "logger . flush = make ( chan bool )", "commit_type": "add"}
{"commit_tokens": ["Move", "Title", "()", "call", "to", "printHeader", "()", "and", "printFooter", "()"], "add_tokens": "t . headers = append ( t . headers , v ) t . footers = append ( t . footers , v ) Pad ( Title ( t . headers [ i ] ) , SPACE , v ) , Pad ( Title ( t . footers [ i ] ) , SPACE , v ) ,", "del_tokens": "t . headers = append ( t . headers , Title ( v ) ) t . footers = append ( t . footers , Title ( v ) ) Pad ( t . headers [ i ] , SPACE , v ) , Pad ( t . footers [ i ] , SPACE , v ) ,", "commit_type": "move"}
{"commit_tokens": ["Added", "base", "logging", "/", "tracing"], "add_tokens": "VERSION = \" \"", "del_tokens": "VERSION = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "when", "prefix", "matches", "a", "static", "and", "wildcard", "node"], "add_tokens": "if len ( search ) < len ( nn . prefix ) { nn = wn } else { stsearch := search [ len ( nn . prefix ) : ] if stsearch != \" \" { sn := nn . findNode ( ntStatic , stsearch , params ) // As static leaf couldn't be found, use the wild node if sn == nil { nn = wn }", "del_tokens": "stsearch := search [ len ( nn . prefix ) : ] if stsearch != \" \" { sn := nn . findNode ( ntStatic , stsearch , params ) // As static leaf couldn't be found, use the wild node if sn == nil { nn = wn", "commit_type": "fix"}
{"commit_tokens": ["Updated", "tests", "with", "new", "function", "signature"], "add_tokens": "func TestParseWithDefaultScheme ( t * testing . T ) { url , err := urlx . ParseWithDefaultScheme ( tt . in , \" \" )", "del_tokens": "func TestParseWithTransform ( t * testing . T ) { url , err := urlx . ParseWithTransforms ( tt . in , urlx . DefaultToHTTPS )", "commit_type": "update"}
{"commit_tokens": ["add", "travis", "build", "apply", "linting", "comments"], "add_tokens": "_ , err := m . MarshalJSON ( ) if err != nil { b . FailNow ( ) } err , set := GetSetSyncMap ( & m , finished ) if err != nil { b . FailNow ( ) } _ , set := GetSetSyncMap ( & m , finished ) get , _ := GetSetSyncMap ( & m , finished ) get , set := GetSetSyncMap ( & m , finished ) get , set := GetSetSyncMap ( & m , finished ) func GetSetSyncMap ( m * sync . Map , finished chan struct { } ) ( set func ( key , value string ) , get func ( key , value string ) ) {", "del_tokens": "m . MarshalJSON ( ) _ , set := GetSetSyncMap ( m , finished ) _ , set := GetSetSyncMap ( m , finished ) get , _ := GetSetSyncMap ( m , finished ) get , set := GetSetSyncMap ( m , finished ) get , set := GetSetSyncMap ( m , finished ) func GetSetSyncMap ( m sync . Map , finished chan struct { } ) ( set func ( key , value string ) , get func ( key , value string ) ) {", "commit_type": "add"}
{"commit_tokens": ["make", "Short", "value", "on", "Field", "struct", "a", "bool", "instead", "of", "a", "string"], "add_tokens": "Short bool `json:\"short,omitempty\"`", "del_tokens": "Short string `json:\"short,omitempty\"`", "commit_type": "make"}
{"commit_tokens": ["remove", "data", "-", "goapp", "-", "root", "node"], "add_tokens": "if len ( config . DefaultURL ) == 0 { cmd := exec . Command ( \" \" , u . String ( ) ) return cmd . Run ( )", "del_tokens": "if len ( config . DefaultURL ) != 0 { return exec . Command ( \" \" , u . String ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "-", "v", "add", "stack", ".", "Args", ".", "Processed", "."], "add_tokens": "Values [ ] Arg // Values is the arguments as shown on the stack trace. They are mangled via simplification. Processed [ ] string // Processed is the arguments generated from processing the source files. It can have a length lower than Values. Elided bool // If set, it means there was a trailing \", ...\" var v [ ] string if len ( a . Processed ) != 0 { v = make ( [ ] string , 0 , len ( a . Processed ) ) for _ , item := range a . Processed { v = append ( v , item ) } } else { v = make ( [ ] string , 0 , len ( a . Values ) ) for _ , item := range a . Values { v = append ( v , item . String ( ) ) } nameArguments ( goroutines ) return goroutines , scanner . Err ( ) } // Private stuff. func nameArguments ( goroutines [ ] Goroutine ) {", "del_tokens": "Values [ ] Arg Elided bool // If set, it means there was a trailing \", ...\" v := make ( [ ] string , 0 , len ( a . Values ) ) for _ , item := range a . Values { v = append ( v , item . String ( ) ) return goroutines , scanner . Err ( ) // Private stuff.", "commit_type": "add"}
{"commit_tokens": ["change", "Each", "()", "signature", "to", "receive", "a", "*", "Selection", "containing", "only", "the", "node", "instead", "of", "the", "node"], "add_tokens": "func ( this * Selection ) Each ( f func ( int , * Selection ) ) * Selection { f ( i , & Selection { [ ] * html . Node { n } , this . document } )", "del_tokens": "func ( this * Selection ) Each ( f func ( int , * html . Node ) ) * Selection { f ( i , n )", "commit_type": "change"}
{"commit_tokens": ["added", "test", "for", "more", "complex", "nested", "conjunction"], "add_tokens": "if s . currs [ i ] != nil && s . currs [ i ] . ID != s . currentId { } else if s . currs [ i ] == nil { s . currentId = \" \" continue OUTER var err error for i , searcher := range s . searchers { s . currs [ i ] , err = searcher . Advance ( ID ) if err != nil { return nil , err } }", "del_tokens": "if s . currs [ i ] . ID != s . currentId {", "commit_type": "add"}
{"commit_tokens": ["Remove", "verbose", "logging", "for", "non", "errors"], "add_tokens": "log . Printf ( \" \\n \" , proxy . backendAddr , err ) return log . Printf ( \" \" , proxy . frontendAddr , proxy . backendAddr , err )", "del_tokens": "log . Printf ( \" \\n \" , proxy . backendAddr , err . Error ( ) ) log . Printf ( \" \" , client . RemoteAddr ( ) , backend . RemoteAddr ( ) ) goto done done : log . Printf ( \" \" , transferred , client . RemoteAddr ( ) , backend . RemoteAddr ( ) ) log . Printf ( \" \" , proxy . frontendAddr , proxy . backendAddr ) log . Printf ( \" \" , proxy . frontendAddr , proxy . backendAddr , err . Error ( ) )", "commit_type": "remove"}
{"commit_tokens": ["Added", "some", "additional", "elements", "(", "AuthnStatement", "AudienceRestrictions", ")", "to", "Response", ".", "Added", "utility", "methods", "to", "populate", ".", "Minor", "fixes", "that", "were", "producing", "invalid", "SAML"], "add_tokens": "Transform : [ ] Transform { Transform { } } ,", "del_tokens": "Transform : Transform { } ,", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "register", "the", "same", "handler", "function", "for", "different", "routes", "."], "add_tokens": "// backward compatibility if spec . Path != \" \" { spec . Paths = [ ] string { spec . Path } for _ , path := range spec . Paths { // register a handler in the router route := app . router . HandleFunc ( path , handler ) . Methods ( spec . Methods ... ) if len ( spec . Headers ) != 0 { route . Headers ( spec . Headers ... ) } // vulcan registration if app . registry != nil && spec . Register != false { app . registerLocation ( spec . Methods , path , spec . Scopes , spec . Middlewares ) }", "del_tokens": "// register the handler in the router route := app . router . HandleFunc ( spec . Path , handler ) . Methods ( spec . Methods ... ) if len ( spec . Headers ) != 0 { route . Headers ( spec . Headers ... ) // vulcan registration if app . registry != nil && spec . Register != false { app . registerLocation ( spec . Methods , spec . Path , spec . Scopes , spec . Middlewares )", "commit_type": "add"}
{"commit_tokens": ["added", "HTTP2", "support", "for", "TLS", "servers"], "add_tokens": "// HTTP2 enables the HTTP2 protocol on the server. HTTP2 wil be default proto // the future. Currently no browser supports HTTP/2 unencrypted. HTTP2 bool return ListenAndServe ( portStr , w , w . HTTP2 ) // ServeTLS uses the HTTP2 protocol by default", "del_tokens": "return ListenAndServe ( portStr , w )", "commit_type": "add"}
{"commit_tokens": ["Add", "constructors", "with", "tls", ".", "Certificate", "fix", "tests"], "add_tokens": "\" \" func newClientWithConn ( gw string , conn Conn ) Client { return c } func NewClientWithCert ( gw string , cert tls . Certificate ) Client { conn := NewConnWithCert ( gw , cert ) return newClientWithConn ( gw , conn ) return newClientWithConn ( gw , conn ) , nil return newClientWithConn ( gw , conn ) , nil", "del_tokens": "func newClientWithConn ( gw string , conn Conn ) ( Client , error ) { return c , nil return newClientWithConn ( gw , conn ) return newClientWithConn ( gw , conn )", "commit_type": "add"}
{"commit_tokens": ["add", "mutual", "tls", "for", "formic", "<", "-", ">", "oort", "comms"], "add_tokens": "func NewOortFS ( vaddr , gaddr string , grpcOpts ... grpc . DialOption ) ( * OortFS , error ) { o . vstore , err = api . NewValueStore ( vaddr , 10 , grpcOpts ... ) o . gstore , err = api . NewGroupStore ( gaddr , 10 , grpcOpts ... )", "del_tokens": "func NewOortFS ( vaddr , gaddr string , insecureSkipVerify bool , grpcOpts ... grpc . DialOption ) ( * OortFS , error ) { o . vstore , err = api . NewValueStore ( vaddr , 10 , insecureSkipVerify , grpcOpts ... ) o . gstore , err = api . NewGroupStore ( gaddr , 10 , insecureSkipVerify , grpcOpts ... )", "commit_type": "add"}
{"commit_tokens": ["Add", "reset", "capability", "to", "tag", "slice", "iterator", "so", "it", "can", "be", "reused"], "add_tokens": "// NewTagIterator returns a new TagSliceIterator over the given Tags. func NewTagIterator ( tags ... Tag ) TagSliceIterator { // NewTagSliceIterator returns a TagSliceIterator over a slice. func NewTagSliceIterator ( tags Tags ) TagSliceIterator { iter := & tagSliceIter { } iter . Reset ( tags ) func ( i * tagSliceIter ) Reset ( tags Tags ) { i . backingSlice = tags i . currentIdx = - 1 i . currentTag = Tag { } }", "del_tokens": "// NewTagIterator returns a new TagIterator over the given Tags. func NewTagIterator ( tags ... Tag ) TagIterator { // NewTagSliceIterator returns a TagIterator over a slice. func NewTagSliceIterator ( tags Tags ) TagIterator { iter := & tagSliceIter { backingSlice : tags , currentIdx : - 1 , }", "commit_type": "add"}
{"commit_tokens": ["Implemented", "fuse", ".", "Unmount", "."], "add_tokens": "func ( mfs * MountedFileSystem ) Unmount ( ) error { return fuse . Unmount ( mfs . dir ) }", "del_tokens": "func ( mfs * MountedFileSystem ) Unmount ( ) error", "commit_type": "implement"}
{"commit_tokens": ["Adds", "SELECT", "support", "to", "server"], "add_tokens": "\" \" func ( cmd * Select ) Command ( ) * imap . Command { if cmd . ReadOnly { Arguments : [ ] interface { } { cmd . Mailbox } , } } func ( cmd * Select ) Parse ( fields [ ] interface { } ) error { if len ( fields ) < 1 { return errors . New ( \" \" ) var ok bool if cmd . Mailbox , ok = fields [ 0 ] . ( string ) ; ! ok { return errors . New ( \" \" ) } return nil", "del_tokens": "func ( c * Select ) Command ( ) * imap . Command { if c . ReadOnly { Arguments : [ ] interface { } { c . Mailbox } ,", "commit_type": "add"}
{"commit_tokens": ["Change", "doc", "+", "add", "examples", "tests"], "add_tokens": "This is a Go implementation of VerbalExpressions for other languages . Check http : //VerbalExpressions.github.io to know the other implementations.", "del_tokens": "This is a Go implementation of VerbalExpressions for other languages . Check https : //github.com/VerbalExpressions to know the other implementations.", "commit_type": "change"}
{"commit_tokens": ["fixed", "ordering", "of", "map", "output", "in", "example", "test"], "add_tokens": "fmt . Printf ( \" \\n \" , token . Claims , claims [ \" \" ] , claims [ \" \" ] ) //Output: <jwt.MapClaim> foo:bar exp:3600", "del_tokens": "fmt . Printf ( \" \\n \" , token . Claims ) //Output: map[foo:bar exp:3600]", "commit_type": "fix"}
{"commit_tokens": ["Changed", "to", "HTTPS", "REST", "connection"], "add_tokens": "DISCORD = \" \" // TODO consider removing", "del_tokens": "DISCORD = \" \" // TODO consider removing", "commit_type": "change"}
{"commit_tokens": ["Add", "tests", "for", "the", "default", "cell", "value"], "add_tokens": "f1 . UpdateLinkedValue ( ) f1 . SetCellDefault ( \" \" , \" \" , strconv . FormatFloat ( float64 ( 100.1588 ) , 'f' , - 1 , 32 ) ) f1 . SetCellDefault ( \" \" , \" \" , strconv . FormatFloat ( float64 ( - 100.1588 ) , 'f' , - 1 , 64 ) ) f1 . SetCellValue ( \" \" , \" \" , float32 ( 42.65418 ) ) f1 . SetCellValue ( \" \" , \" \" , float64 ( - 42.65418 ) )", "del_tokens": "f1 . UpdateLinkedValue ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "pulse", "update", "on", "backend", "removal"], "add_tokens": "if _ , ok := ctx . backends [ rsID ] ; ! ok || u . Metrics . Status == pulse . StatusRemoved { if _ , exists := stash [ u . Source ] ; exists { log . Debugf ( \" \" , u . Source ) delete ( stash , u . Source ) } log . Debugf ( \" \" , u . Source )", "del_tokens": "if _ , ok := ctx . backends [ rsID ] ; ! ok {", "commit_type": "fix"}
{"commit_tokens": ["Add", "recoverability", "in", "the", "Pipeline"], "add_tokens": "\" \" // determine whether the error is recoverable func ( p Pipeline ) isRecoverableError ( err error ) bool { cErr , ok := err . ( * kinesis . Error ) if ok && cErr . Code == \" \" { return true } return false } // handle the aws exponential backoff // http://docs.aws.amazon.com/general/latest/gr/api-retries.html func ( p Pipeline ) handleAwsWaitTimeExp ( attempts int ) { // wait up to 5 minutes based on the aws exponential backoff algorithm logger . Printf ( \" \" ) waitTime := time . Duration ( math . Min ( 100 * math . Pow ( 2 , float64 ( attempts ) ) , 300000 ) ) * time . Millisecond time . Sleep ( waitTime ) } consecutiveErrorAttempts := 0 if p . isRecoverableError ( err ) { logger . Printf ( \" \\n \" , err ) consecutiveErrorAttempts ++ p . handleAwsWaitTimeExp ( consecutiveErrorAttempts ) continue } else { logger . Fatalf ( \" \\n \" , err ) } } else { consecutiveErrorAttempts = 0", "del_tokens": "logger . Fatalf ( \" \\n \" , err )", "commit_type": "add"}
{"commit_tokens": ["add", "content", "field", "in", "rss2"], "add_tokens": "Content : \" \" , expect := `{\"title\":\"music feed\",\"links\":[\"https://yahoo.co.jp\"],\"description\":\"this is rss2 feed\",\"image\":{\"title\":\"hoge.png\",\"url\":\"http://hoge.png\",\"link\":\"https://twitter.com\",\"width\":300,\"height\":500},\"copyright\":\"Mr.hoge\",\"pubdate\":\"1900-1-1\",\"updated\":\"2000-1-1\",\"categories\":[\"sports\",\"music\"],\"items\":[{\"id\":\"0123456789\",\"title\":\"rss2 article\",\"links\":[\"https://facebook.com\"],\"description\":\"\\u003cp\\u003ehahaha\\u003c/p\\u003e\",\"content\":\"\\u003cp\\u003ethis is content\\u003c/p\\u003e\",\"pubdate\":\"this is publish date\",\"authors\":[{\"name\":\"naoto\",\"email\":\"\"}],\"categories\":[\"sports\",\"music\"],\"enclosure\":{\"url\":\"\",\"length\":0,\"type\":\"\"}}]}`", "del_tokens": "expect := `{\"title\":\"music feed\",\"links\":[\"https://yahoo.co.jp\"],\"description\":\"this is rss2 feed\",\"image\":{\"title\":\"hoge.png\",\"url\":\"http://hoge.png\",\"link\":\"https://twitter.com\",\"width\":300,\"height\":500},\"copyright\":\"Mr.hoge\",\"pubdate\":\"1900-1-1\",\"updated\":\"2000-1-1\",\"categories\":[\"sports\",\"music\"],\"items\":[{\"id\":\"0123456789\",\"title\":\"rss2 article\",\"links\":[\"https://facebook.com\"],\"description\":\"\\u003cp\\u003ehahaha\\u003c/p\\u003e\",\"pubdate\":\"this is publish date\",\"authors\":[{\"name\":\"naoto\",\"email\":\"\"}],\"categories\":[\"sports\",\"music\"],\"enclosure\":{\"url\":\"\",\"length\":0,\"type\":\"\"}}]}`", "commit_type": "add"}
{"commit_tokens": ["Add", "golangci", "-", "lint", "configuration"], "add_tokens": "fmt . Print ( usage ) for range c {", "del_tokens": "fmt . Printf ( usage ) for _ = range c {", "commit_type": "add"}
{"commit_tokens": ["Add", "Function", "DefaultAccounting", "and", "NewAccounting"], "add_tokens": "isInitialized bool // is set to true if used via DefaultAccounting or NewAccounting } // DefaultAccounting returns the Accounting with default settings func DefaultAccounting ( symbol string , precision int ) * Accounting { ac := & Accounting { Symbol : symbol , Precision : precision } ac . init ( ) ac . isInitialized = true return ac } // NewAccounting returns the Accounting with default settings func NewAccounting ( symbol string , precision int , thousand , decimal , format , formatNegative , formatZero string ) * Accounting { ac := & Accounting { Symbol : symbol , Precision : precision , Thousand : thousand , Decimal : decimal , Format : format , FormatNegative : formatNegative , FormatZero : formatZero , } ac . isInitialized = true return ac if ! accounting . isInitialized { accounting . init ( ) } if ! accounting . isInitialized { accounting . init ( ) } if ! accounting . isInitialized { accounting . init ( ) } if ! accounting . isInitialized { accounting . init ( ) } if ! accounting . isInitialized { accounting . init ( ) }", "del_tokens": "accounting . init ( ) accounting . init ( ) accounting . init ( ) accounting . init ( ) accounting . init ( )", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "use", "the", "Python", "version", "as", "my", "base", "."], "add_tokens": "\" \" \" \" \" \" func main ( ) { fmt . Println ( adjacency . AdjacencyGph . Qwerty . CalculateAvgDegree ( ) ) fmt . Println ( adjacency . AdjacencyGph . Dvorak . CalculateAvgDegree ( ) ) fmt . Println ( adjacency . AdjacencyGph . Keypad . CalculateAvgDegree ( ) ) fmt . Println ( adjacency . AdjacencyGph . MacKeypad . CalculateAvgDegree ( ) ) fmt . Println ( math . NChoseK ( 100 , 2 ) ) fmt . Println ( matching . DateSepMatch ( \" \" ) )", "del_tokens": "// \"zxcvbn-go/adjacency\" \" \" func main ( ) { // fmt.Println(adjacency.AdjacencyGph) fmt . Println ( len ( frequency . FreqLists . Passwords ) )", "commit_type": "change"}
{"commit_tokens": ["Added", "comments", "for", "Unmarshal", "function"], "add_tokens": "// Unmarshal function is used in the case when user want his yaml file to be unmarshalled to structure pointer // Unmarshal function accepts a pointer and in called function anyone can able to get the data in passed object // Unmarshal only accepts a pointer values // Unmarshal returns error if obj values are 0. nil and value type. // Procedure: // 1. Unmarshal first checks the passed object type using reflection. // 2. Based on type Unmarshal function will check and set the values // ex: If type is basic types like int, string, float then it will assigb directly values, // If type is map, ptr and struct then it will again send for unmarshal untill it find the basic type and set the values", "del_tokens": "// Unmarshal deserialize config into structure", "commit_type": "add"}
{"commit_tokens": ["Add", "log", "message", "when", "rotating", "files"], "add_tokens": "LOG levels = [ ... ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } timeFormat = TIMEFORMAT", "del_tokens": "levels = [ ... ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } timeFormat = \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "possibility", "of", "using", "password@host", ":", "port"], "add_tokens": "// Use this for connecting to a different redis host/port (+password) // pool := simpleredis.NewConnectionPoolHost(\"password@localhost:6379\")", "del_tokens": "// Use this for connecting to a different redis host/port // pool := simpleredis.NewConnectionPoolHost(\"localhost:6379\")", "commit_type": "add"}
{"commit_tokens": ["Add", "proper", "support", "for", "error", "-", ">", "string", "and", "Stringer", "-", ">", "string", "."], "add_tokens": "\" \" type foo struct { val string } func ( x foo ) String ( ) string { return x . val } func TestStringerToString ( t * testing . T ) { var x foo x . val = \" \" assert . Equal ( t , \" \" , ToString ( x ) ) } type fu struct { val string } func ( x fu ) Error ( ) string { return x . val } func TestErrorToString ( t * testing . T ) { var x fu x . val = \" \" assert . Equal ( t , \" \" , ToString ( x ) ) }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "copy", "-", "paste", "error", "in", "WithTokenCookieName"], "add_tokens": "p . tokenCookieName = param", "del_tokens": "p . methodOverrideParam = param", "commit_type": "fix"}
{"commit_tokens": ["Update", "simple", ".", "go", "(", "very", "small", "change", ")"], "add_tokens": "sqlStmt := ` _ , err = db . Exec ( sqlStmt ) log . Printf ( \" \\n \" , err , sqlStmt )", "del_tokens": "sql := ` _ , err = db . Exec ( sql ) log . Printf ( \" \\n \" , err , sql )", "commit_type": "update"}
{"commit_tokens": ["Add", "test", "for", "multiple", "controllers", "locking", "pvc"], "add_tokens": "glog . Errorf ( \" \" , claimToClaimKey ( claim ) , storageClass . Name , err ) pvcCh , err := ctrl . watchPVC ( claim . Name , claim . Namespace , claim . ResourceVersion , stopChannel ) func ( ctrl * ProvisionController ) watchPVC ( name , namespace , resourceVersion string , stopChannel chan struct { } ) ( <- chan watch . Event , error ) { FieldSelector : pvcSelector , Watch : true , ResourceVersion : resourceVersion ,", "del_tokens": "glog . Errorf ( \" \" , claimToClaimKey ( claim ) , claim . Name , err ) pvcCh , err := ctrl . watchPVC ( claim . Name , claim . Namespace , stopChannel ) func ( ctrl * ProvisionController ) watchPVC ( name , namespace string , stopChannel chan struct { } ) ( <- chan watch . Event , error ) { FieldSelector : pvcSelector , Watch : true ,", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "injected", "value", "is", "used", "internally", "."], "add_tokens": "if ret . AuthorizeData . IsExpiredAt ( s . Now ( ) ) {", "del_tokens": "if ret . AuthorizeData . IsExpired ( ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "additional", "support", "of", "yaml", "file", "extension"], "add_tokens": "if ! fileinfo . IsDir ( ) && ( filepath . Ext ( fileinfo . Name ( ) ) == \" \" || filepath . Ext ( fileinfo . Name ( ) ) == \" \" ) {", "del_tokens": "if ! fileinfo . IsDir ( ) && filepath . Ext ( fileinfo . Name ( ) ) == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Add", "PEM", "encode", "error", "checking"], "add_tokens": "return nil , nil , fmt . Errorf ( \" \" , err ) err = pem . Encode ( certBuf , & pem . Block { Type : \" \" , Bytes : derBytes } ) if err != nil { return nil , nil , fmt . Errorf ( \" \" , err ) } return nil , nil , fmt . Errorf ( \" \" , err ) err = pem . Encode ( keyBuf , & pem . Block { Type : \" \" , Bytes : keybytes } ) if err != nil { return nil , nil , fmt . Errorf ( \" \" , err ) }", "del_tokens": "return nil , nil , fmt . Errorf ( \" \\n \" , err ) pem . Encode ( certBuf , & pem . Block { Type : \" \" , Bytes : derBytes } ) return nil , nil , err pem . Encode ( keyBuf , & pem . Block { Type : \" \" , Bytes : keybytes } )", "commit_type": "add"}
{"commit_tokens": ["Add", "element", ".", "Image", "and", "Browser", ".", "Images", "()"], "add_tokens": "// Images returns an array of every image found in the page. Images ( ) [ ] * Image // ID is the value of the id attribute if available. // Image stores the properties of an image. type Image struct { // ID is the value of the id attribute if available. ID string // Src is the value of the image src attribute. Src string // Alt is the value of the image alt attribute if available. Alt string // Title is the value of the image title attribute if available. Title string }", "del_tokens": "// ID is the value of the id attribute or empty when there is no id.", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "datagram", "message", "due", "to", "shared", "buffer"], "add_tokens": "datagramPool sync . Pool return & Server { tlsPeerNameFunc : defaultTlsPeerName , datagramPool : sync . Pool { New : func ( ) interface { } { return make ( [ ] byte , 65536 ) } , } } buf := s . datagramPool . Get ( ) . ( [ ] byte ) s . datagramPool . Put ( msg . message [ : cap ( msg . message ) ] )", "del_tokens": "return & Server { tlsPeerNameFunc : defaultTlsPeerName } buf := make ( [ ] byte , 65536 )", "commit_type": "fix"}
{"commit_tokens": ["Added", "String", "to", "Compiles", "interface", "to", "make", "sure", "all", "clauses", "have", "a", "dialect", "neutral", "logging", "output"], "add_tokens": "name := users . C [ \" \" ] column := ColumnClause { table : users , name : name . Name ( ) } expect . SQL ( `\"users\".\"name\"` , column ) // String and Int clause TODO remove these as the skip parameterization expect . SQL ( `'name'` , StringClause { Name : \" \" } ) expect . SQL ( `3` , IntClause { D : 3 } ) // Func clause expect . SQL ( `LOWER(\"users\".\"name\")` , FuncClause { Inner : column , F : \" \" } )", "del_tokens": "expect . SQL ( `\"users\".\"id\"` , ColumnClause { table : users , name : id . Name ( ) } )", "commit_type": "add"}
{"commit_tokens": ["Add", "processing", "of", "discover", "event", "(", "not", "100%", "complete", ")"], "add_tokens": "time . Sleep ( 10 * time . Second ) time . Sleep ( 2 * time . Second )", "del_tokens": "/ * ble . sendCBMsg ( 0 , dict { \" \" : 1 , \" \" : \" \" , } ) * / time . Sleep ( 5 * time . Second ) time . Sleep ( 5 * time . Second )", "commit_type": "add"}
{"commit_tokens": ["add", "(", "untested", ")", "function", "to", "set", "webhook", "with", "certificate"], "add_tokens": "Clear bool URL * url . URL Certificate interface { } func ( bot * BotAPI ) SetWebhook ( config WebhookConfig ) ( APIResponse , error ) { if config . Certificate == nil { v := url . Values { } if ! config . Clear { v . Add ( \" \" , config . URL . String ( ) ) } return bot . MakeRequest ( \" \" , v ) } params := make ( map [ string ] string ) resp , err := bot . UploadFile ( \" \" , params , \" \" , config . Certificate ) if err != nil { return APIResponse { } , err } var apiResp APIResponse json . Unmarshal ( resp . Result , & apiResp ) if bot . Debug { log . Printf ( \" \\n \" , apiResp ) return apiResp , nil", "del_tokens": "Clear bool URL * url . URL func ( bot * BotAPI ) SetWebhook ( config WebhookConfig ) ( APIResponse , error ) { v := url . Values { } if ! config . Clear { v . Add ( \" \" , config . URL . String ( ) ) return bot . MakeRequest ( \" \" , v )", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "fields", "and", "consts", "."], "add_tokens": "// ids hash maps import path to package id", "del_tokens": "// ids hset maps import path to package id", "commit_type": "remove"}
{"commit_tokens": ["add", "Operation", "for", "documentation", "maps", "to", "nickname", "in", "Swagger"], "add_tokens": "operation := Operation { HttpMethod : route . Method , Summary : route . Doc , ResponseClass : asDataType ( route . WriteSample ) , Nickname : route . Operation }", "del_tokens": "operation := Operation { HttpMethod : route . Method , Summary : route . Doc , ResponseClass : asDataType ( route . WriteSample ) }", "commit_type": "add"}
{"commit_tokens": ["add", "a", "NewLine", "option", "that", "can", "be", "disabled", "although", "users", "can", "customize", "the", "log", "message", "no", "matter", "what"], "add_tokens": "// See `github.com/kataras/pio#NewLine` and `Logger#NewLine` too.", "del_tokens": "// See `github.com/kataras/pio#NewLine` too.", "commit_type": "add"}
{"commit_tokens": ["added", "more", "information", "to", "access", "logger"], "add_tokens": "requestLine := fmt . Sprintf ( \" \" , req . Method , req . URL . String ( ) , req . Proto )", "del_tokens": "requestLine := fmt . Sprintf ( \" \" , req . Method , req . URL . Path , req . Proto )", "commit_type": "add"}
{"commit_tokens": ["fix", "vet", "errors", "revealed", "by", "tip", "go", "test"], "add_tokens": "return false , fmt . Errorf ( \" \" ,", "del_tokens": "return false , fmt . Errorf ( \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "rate", "limiting", "and", "http", "caching", "to", "the", "github", "client", "."], "add_tokens": "\" \" \" \" type RateLimitRoundTripper struct { delegate http . RoundTripper throttle util . RateLimiter } func ( r * RateLimitRoundTripper ) RoundTrip ( req * http . Request ) ( resp * http . Response , err error ) { r . throttle . Accept ( ) return r . delegate . RoundTrip ( req ) } var client * http . Client cacheTransport := httpcache . NewMemoryCacheTransport ( ) rateLimitTransport := & RateLimitRoundTripper { delegate : cacheTransport , // Global limit is 5000 Q/Hour, try to only use 1800 to make room for other apps throttle : util . NewTokenBucketRateLimiter ( 0.5 , 10 ) , } client = & http . Client { Transport : & oauth2 . Transport { Base : rateLimitTransport , Source : oauth2 . ReuseTokenSource ( nil , ts ) , } , } } else { rateLimitTransport := & RateLimitRoundTripper { delegate : cacheTransport , throttle : util . NewTokenBucketRateLimiter ( 0.01 , 10 ) , } client = & http . Client { Transport : rateLimitTransport , } return github . NewClient ( client )", "del_tokens": "tc := oauth2 . NewClient ( oauth2 . NoContext , ts ) return github . NewClient ( tc ) return github . NewClient ( nil )", "commit_type": "add"}
{"commit_tokens": ["make", "compatible", "with", "uppercase", "file", "extensions"], "add_tokens": "\" \" switch strings . ToLower ( path . Ext ( filename ) ) {", "del_tokens": "switch path . Ext ( filename ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "a", "number", "error", "in", "doc", "."], "add_tokens": "// the response, at most 1000. The default is 100.", "del_tokens": "// the response. The default is 1000.", "commit_type": "fix"}
{"commit_tokens": ["Move", "inline", "ZipFile", "CustomResource", "config", "to", "Zip", "archive", "references"], "add_tokens": "\" \" , \" \" } , func ensureConfiguratorLambdaResource ( awsPrincipalName string , sourceArn string , resources ArbitraryJSONObject , S3Bucket string , S3Key string , logger * logrus . Logger ) ( string , error ) { resourceFilename := strings . ToLower ( awsServiceName ) // NOTE: This brittle function name has an analog in ./resources/index.js b/c the // AWS Lamba execution treats the entire ZIP file as a module. So all module exports // need to be forwarded through the module's index.js file. handlerName := fmt . Sprintf ( \" \" , resourceFilename ) logger . Debug ( \" \" , handlerName ) \" \" : S3Bucket , \" \" : S3Key , \" \" : handlerName ,", "del_tokens": "\" \" } , func ensureConfiguratorLambdaResource ( awsPrincipalName string , sourceArn string , resources ArbitraryJSONObject , logger * logrus . Logger ) ( string , error ) { // NOTE: This path depends on `go generate` already having processed the provision // directory with the https://github.com/tdewolff/minify/tree/master/cmd/minify contents scriptHandlerPath := fmt . Sprintf ( \" \" , strings . ToLower ( awsServiceName ) ) logger . Debug ( \" \" , scriptHandlerPath ) \" \" : FSMustString ( false , scriptHandlerPath ) , \" \" : \" \" ,", "commit_type": "move"}
{"commit_tokens": ["Add", "Support", "for", "logitech", "mx", "keys"], "add_tokens": "stringifiedBuffer := string ( buff ) if strings . Contains ( strings . ToLower ( stringifiedBuffer ) , \" \" ) { if strings . Contains ( strings . ToLower ( stringifiedBuffer ) , \" \" ) || strings . Contains ( stringifiedBuffer , \" \" ) {", "del_tokens": "if strings . Contains ( strings . ToLower ( string ( buff ) ) , \" \" ) { if strings . Contains ( strings . ToLower ( string ( buff ) ) , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Allow", "custom", "port", "for", "http", "/", "https", "scheme", "."], "add_tokens": "// alter path and host if we're sure its not a port if _ , err := strconv . Atoi ( s [ 1 ] ) ; err != nil { u . Host = s [ 0 ] u . Path = path . Join ( s [ 1 ] , u . Path ) }", "del_tokens": "u . Host = s [ 0 ] u . Path = path . Join ( s [ 1 ] , u . Path )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "typo", "in", "parse", "tests"], "add_tokens": "t . Error ( \" \" ) t . Error ( \" \" ) t . Error ( \" \" )", "del_tokens": "t . Error ( \" \" ) t . Error ( \" \" ) t . Error ( \" \" ) fmt . Println ( actual . Encoding , expected . Encoding )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "ctx", ".", "Timing", "method"], "add_tokens": "// Timing runs fn with the given time limit. If a call runs for longer than its time limit or panic, // it will return context.DeadlineExceeded error or panic error. func ( ctx * Context ) Timing ( dt time . Duration , fn func ( context . Context ) ) ( err error ) { ch := make ( chan struct { } ) fn ( ct ) case <- ch :", "del_tokens": "// Timing runs fn with the given time limit. If a call runs for longer than its time limit, // it will return context.DeadlineExceeded as error, otherwise return fn's result. func ( ctx * Context ) Timing ( dt time . Duration , fn func ( context . Context ) interface { } ) ( res interface { } , err error ) { ch := make ( chan interface { } ) ch <- fn ( ct ) case res = <- ch :", "commit_type": "change"}
{"commit_tokens": ["Fix", "misleading", "docstring", "for", "Link"], "add_tokens": "// Link returns a channel that fires if ANY of the constituent Doners have fired", "del_tokens": "// Link ties the lifetime of the Doners to each other. Link returns a channel // that fires if ANY of the constituent Doners have fired.", "commit_type": "fix"}
{"commit_tokens": ["updated", "readme", "and", "code", "comments"], "add_tokens": "// resultSelector takes outer element and inner element as inputs // and returns a value which will be an element in the resulting query. // resultSelector takes outer element and inner element as inputs // and returns a value which will be an element in the resulting query.", "del_tokens": "// resultSelector takes key of inner element and key of outer element as input // and returns a value and these values are returned as a new query. // resultSelector takes key of inner element and key of outer element as input // and returns a value and these values are returned as a new query.", "commit_type": "update"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// ErrorCorrect returns all byte-arrays which are Levenshtein distance of 1 away from Word", "del_tokens": "// Returns all byte-arrays which are Levenshtein distance of 1 away from Word", "commit_type": "fix"}
{"commit_tokens": ["Move", "waitForTask", "method", "to", "Client", "type"], "add_tokens": "return f . c . waitForTask ( task )", "del_tokens": "\" \" func ( f FileManager ) waitForTask ( t tasks . Task ) error { info , err := t . Wait ( ) if err != nil { return err } if info . Error != nil { return errors . New ( info . Error . LocalizedMessage ) } return nil } return f . waitForTask ( task )", "commit_type": "move"}
{"commit_tokens": ["Created", "generic", "apps", "event", "type", "and", "list", "method"], "add_tokens": "func TestListAppCreateEvents ( t * testing . T ) { appEvents , err := client . ListAppEvents ( \" \" ) So ( err . Error ( ) , ShouldEqual , \" \" ) appEvents , err = client . ListAppEvents ( AppCreate )", "del_tokens": "func TestListAppCreateEvent ( t * testing . T ) { appEvents , err := client . ListAppCreateEvent ( )", "commit_type": "create"}
{"commit_tokens": ["Allow", "fs", "to", "delete", "long", "paths", "in", "Windows"], "add_tokens": "fsWrapper \" \" _ , err := fs . Stat ( path ) sourceInfo , err := fs . Stat ( srcPath ) err = fsWrapper . RemoveAll ( fileOrDir ) func ( fs * osFileSystem ) Stat ( fileOrDir string ) ( fileInfo os . FileInfo , err error ) { return fsWrapper . Stat ( fileOrDir ) } existingStat , err := fs . Stat ( filePath )", "del_tokens": "_ , err := os . Stat ( path ) sourceInfo , err := os . Stat ( srcPath ) err = os . RemoveAll ( fileOrDir ) existingStat , err := os . Stat ( filePath )", "commit_type": "allow"}
{"commit_tokens": ["adding", "support", "for", "sample", "loop", "data", "parsing"], "add_tokens": "// CIDSmpl is the chunk ID for a smpl chunk CIDSmpl = [ 4 ] byte { 's' , 'm' , 'p' , 'l' } // The entire file will be read and should be rewinded if more data must be // accessed. switch chunk . ID { case CIDList : if d . Metadata != nil && d . Metadata . SamplerInfo != nil { // we got everything we were looking for break } case CIDSmpl : if err = DecodeSamplerChunk ( d , chunk ) ; err != nil { if err != io . EOF { d . err = err } }", "del_tokens": "// Because the chunk might be located at the end of the file, the entire file will be read // and should be rewinded if more data must be accessed. if chunk . ID == CIDList { break", "commit_type": "add"}
{"commit_tokens": ["Make", "resident", "memory", "size", "expectation", "less", "precise"], "add_tokens": "Expect ( pMem . Size ) . To ( BeNumerically ( \" \" , pMem . Resident ) ) Expect ( pNoMem . Size ) . To ( BeNumerically ( \" \" , pNoMem . Resident ) )", "del_tokens": "Expect ( pMem . Size ) . To ( BeNumerically ( \" \" , 18000000 , 5 * 1024 * 1024 ) ) Expect ( pNoMem . Size ) . To ( BeNumerically ( \" \" , 3400000 , 5 * 1024 * 1024 ) )", "commit_type": "make"}
{"commit_tokens": ["Use", "generic", "net", ".", "Conn", "instead", "of", "TCPConn"], "add_tokens": "conn net . Conn func NewMessageStream ( conn net . Conn , parser Parser ) * MessageStream {", "del_tokens": "conn * net . TCPConn func NewMessageStream ( conn * net . TCPConn , parser Parser ) * MessageStream {", "commit_type": "use"}
{"commit_tokens": ["Fix", "order", "of", "bindings", "in", "batch"], "add_tokens": "batch . blendSrcFunc = gl . SRC_ALPHA //batch.blendSrcFunc = gl.ONE gl . BindBuffer ( gl . ARRAY_BUFFER , 0 ) gl . UseProgram ( 0 ) b . lastTexture = nil", "del_tokens": "// batch.blendSrcFunc = gl.SRC_ALPHA batch . blendSrcFunc = gl . ONE gl . BindBuffer ( gl . ARRAY_BUFFER , 0 ) gl . UseProgram ( 0 )", "commit_type": "fix"}
{"commit_tokens": ["update", "unidecode", "package", "import", "path"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "setting", "mgo", ".", "DialInfo"], "add_tokens": "DialInfo * mgo . DialInfo if m . Config . DialInfo == nil { if m . Config . DialInfo , err = mgo . ParseURL ( m . Config . ConnectionString ) ; err != nil { panic ( fmt . Sprintf ( \" \" , m . Config . ConnectionString , err . Error ( ) ) ) } } session , err := mgo . DialWithInfo ( m . Config . DialInfo )", "del_tokens": "session , err := mgo . Dial ( m . Config . ConnectionString )", "commit_type": "add"}
{"commit_tokens": ["use", "MailDir", ".", "File", "not", "MailDir", ".", "TempFile"], "add_tokens": "fname = d . File ( )", "del_tokens": "fname = d . TempFile ( )", "commit_type": "use"}
{"commit_tokens": ["Use", "atomic", "store", "instead", "of", "raw", "mutex", "per", "watched", "type"], "add_tokens": "\" \" // TODO(ppknap) : impl/doc. atomic . StoreUint32 ( & w . mask , uint32 ( event ) )", "del_tokens": "sync . Mutex // TODO(ppknap) : doc. w . Lock ( ) w . mask = uint32 ( event ) w . Unlock ( )", "commit_type": "use"}
{"commit_tokens": ["use", "40", "goroutines", "for", "processing", "nsq", "messages", "."], "add_tokens": "log . Printf ( \" \\n \" , m . Id ) log . Printf ( \" \\n \" , m . Id ) resp , err := es . Index ( \" \" , \" \" , m . Id , nil , m ) log . Printf ( \" \\n \" , resp ) if err != nil { return err }", "del_tokens": "log . Printf ( \" \\n \" , m . Id ) resp , err := es . Index ( \" \" , \" \" , m . Id , nil , m ) log . Printf ( \" \\n \" , resp ) if err != nil { return err }", "commit_type": "use"}
{"commit_tokens": ["add", "current", "mem", ".", "GetInfo", "implementation", "to", "benchmark"], "add_tokens": "defer f . Close ( ) defer f . Close ( ) } func BenchmarkGetMemInfoCurrent ( b * testing . B ) { var val MemInfo b . StopTimer ( ) f , err := os . Open ( \" \" ) if err != nil { fmt . Println ( \" \" ) } defer f . Close ( ) b . StartTimer ( ) for i := 0 ; i < b . N ; i ++ { val , _ = GetMemInfoCurrent ( f ) } _ = val", "del_tokens": "f . Close ( ) f . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "marshalling", "TextMarshaler", "and", "Stringer"], "add_tokens": "\" \" // types which are e.g. structs, slices or maps and implement one of the following interfaces should not be // marshalled by sheriff because they'll be correctly marshalled by json.Marshal instead. // Otherwise (e.g. net.IP) a byte slice may be output as a list of uints instead of as an IP string. switch val . ( type ) { case json . Marshaler , encoding . TextMarshaler , fmt . Stringer :", "del_tokens": "// TODO(mweibel): This is a hack for struct types which conform to json.Marshaler (such as time.Time). // This makes sure those struct types aren't marshalled by sheriff if they appear as a field. if _ , ok := val . ( json . Marshaler ) ; ok {", "commit_type": "fix"}
{"commit_tokens": ["fix", "initialism", "of", "ID", "in", "names"], "add_tokens": "// PlayID plays the song identified by id. If id is negative, start playing func ( c * Client ) PlayID ( id int ) error { // SeekID is identical to Seek except the song is identified by it's id func ( c * Client ) SeekID ( id , time int ) error { // DeleteID deletes the song identified by id. func ( c * Client ) DeleteID ( id int ) error { // MoveID moves songid to position on the plyalist. func ( c * Client ) MoveID ( songid , position int ) error { // AddID adds the file/directory uri to playlist and returns the identity func ( c * Client ) AddID ( uri string , pos int ) ( int , error ) { // The returned jobID identifies the update job, enqueued by MPD.", "del_tokens": "// BUG(fhs): Initialism is used for several methods with \"ID\" in the name // (e.g. PlayId should be PlayID). // PlayId plays the song identified by id. If id is negative, start playing func ( c * Client ) PlayId ( id int ) error { // SeekId is identical to Seek except the song is identified by it's id func ( c * Client ) SeekId ( id , time int ) error { // DeleteId deletes the song identified by id. func ( c * Client ) DeleteId ( id int ) error { // MoveId moves songid to position on the plyalist. func ( c * Client ) MoveId ( songid , position int ) error { // AddId adds the file/directory uri to playlist and returns the identity func ( c * Client ) AddId ( uri string , pos int ) ( int , error ) { // The returned jobId identifies the update job, enqueued by MPD.", "commit_type": "fix"}
{"commit_tokens": ["Allow", "configuration", "of", "endpoint", "via", "env", "var"], "add_tokens": "// * ROLLBAR_ENDPOINT - The Rollbar endpoint: https://api.rollbar.com/api/1/item/ if os . Getenv ( \" \" ) != \" \" && os . Getenv ( \" \" ) != \" \" { rollbar . ConfigureFromEnvironment ( )", "del_tokens": "rbToken := os . Getenv ( \" \" ) rbEnv := os . Getenv ( \" \" ) if rbToken != \" \" && rbEnv != \" \" { rollbar . ConfigureReporter ( rbToken , rbEnv )", "commit_type": "allow"}
{"commit_tokens": ["add", "support", "for", "wildcard", "cors", "origin"], "add_tokens": "if origin != \" \" && ! strings . HasPrefix ( origin , \" \" ) && ! strings . HasPrefix ( origin , \" \" ) { return errors . New ( \" \" )", "del_tokens": "if ! strings . HasPrefix ( origin , \" \" ) && ! strings . HasPrefix ( origin , \" \" ) { return errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["remove", "unused", "conversionError", "error", "string", "case"], "add_tokens": "val = userData . Value", "del_tokens": "if reflectValue , ok := userData . Value . ( reflect . Value ) ; ok { val = reflectValue . Interface ( ) } else { val = userData . Value }", "commit_type": "remove"}
{"commit_tokens": ["Added", "error", "checking", "in", "encrypter", "/", "decrypter", "to", "avoid", "nil", "pointer", "panic"], "add_tokens": "var ErrRequiredAttributeMissing string func ( e ErrRequiredAttributeMissing ) Error ( ) string { return fmt . Sprintf ( \" \" , e ) } if db . Headers == nil { return nil , ErrRequiredAttributeMissing ( \" \" ) } if db . Headers . EncryptionIV == nil { return nil , ErrRequiredAttributeMissing ( \" \" ) } if db . Credentials == nil { return nil , ErrRequiredAttributeMissing ( \" \" ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "Links", "in", "Exploration"], "add_tokens": "href := fmt . Sprintf ( \" \" , uID , e . ID ) href := fmt . Sprintf ( \" \" , uID , eID ) href := fmt . Sprintf ( \" \" , e . UserID , e . ID )", "del_tokens": "href := fmt . Sprintf ( \" \" , uID , e . ID ) href := fmt . Sprintf ( \" \" , uID , eID ) href := fmt . Sprintf ( \" \" , e . UserID , e . ID )", "commit_type": "fix"}
{"commit_tokens": ["Change", "order", "of", "fields", "in", "filterModel"], "add_tokens": "// resampling is done by convolution with a (scaled) kernel kernel func ( float32 ) float32 // for optimized access to image points converter kernel , factor , kernel , factor , kernel , factor , kernel , factor , kernel , factor , kernel , factor ,", "del_tokens": "// for optimized access to image points converter // resampling is done by convolution with a (scaled) kernel kernel func ( float32 ) float32 factor , kernel , factor , kernel , factor , kernel , factor , kernel , factor , kernel , factor , kernel ,", "commit_type": "change"}
{"commit_tokens": ["Add", "escaping", "support", "and", "overhaul", "things", "a", "lot"], "add_tokens": "Logger . Infof ( \" \" , string ( b ) , glob . String ( ) )", "del_tokens": "Logger . Tracef ( \" \" , string ( b ) , glob . String ( ) )", "commit_type": "add"}
{"commit_tokens": ["Use", "atomic", ".", "LoadPointer", "()", "to", "read", "pointers", "stored", "atomically"], "add_tokens": "ptr := atomic . LoadPointer ( & cb . _lastFailure ) return * ( * time . Time ) ( ptr )", "del_tokens": "return * ( * time . Time ) ( cb . _lastFailure )", "commit_type": "use"}
{"commit_tokens": ["Updated", "regexps", "to", "support", "right", "aligned", "negative", "values", "."], "add_tokens": "decimal = regexp . MustCompile ( `^-*\\d*\\.?\\d*$` ) percent = regexp . MustCompile ( `^-*\\d*\\.?\\d*$%$` )", "del_tokens": "decimal = regexp . MustCompile ( `^\\d*\\.?\\d*$` ) percent = regexp . MustCompile ( `^\\d*\\.?\\d*$%$` )", "commit_type": "update"}
{"commit_tokens": ["Add", "/", "basic", "-", "auth", "/", ":", "user", "/", ":", "pass", "handler"], "add_tokens": "type authResponse struct { Authorized bool `json:\"authorized\"` User string `json:\"user\"` } mux . HandleFunc ( \" \" , h . BasicAuth ) mux . HandleFunc ( \" \" , http . NotFound ) mux . HandleFunc ( \" \" , http . NotFound ) mux . HandleFunc ( \" \" , http . NotFound )", "del_tokens": "mux . HandleFunc ( \" \" , http . NotFound ) mux . HandleFunc ( \" \" , http . NotFound )", "commit_type": "add"}
{"commit_tokens": ["Make", "subprotocol", "negotiation", "more", "flexible", "."], "add_tokens": "// NegotiateSubprotocol specifies the function to negotiate a subprotocol // based on a request. If NegotiateSubprotocol is nil, then no subprotocol // will be used. NegotiateSubprotocol func ( r * http . Request ) ( string , error ) if u . NegotiateSubprotocol != nil { c . subprotocol , err = u . NegotiateSubprotocol ( r ) if err != nil { netConn . Close ( ) return nil , err", "del_tokens": "// Subprotocols specifies the server's supported protocols. If Subprotocols // is nil, then Upgrade does not negotiate a subprotocol. Subprotocols [ ] string // Check if the passed subprotocol is supported by the server func ( u * Upgrader ) hasSubprotocol ( subprotocol string ) bool { if u . Subprotocols == nil { return false } for _ , s := range u . Subprotocols { if s == subprotocol { return true } } return false } if u . Subprotocols != nil { for _ , proto := range Subprotocols ( r ) { if u . hasSubprotocol ( proto ) { c . subprotocol = proto break }", "commit_type": "make"}
{"commit_tokens": ["Fix", "a", "slight", "race", "in", "a", "ticker", "test", "."], "add_tokens": "case <- time . After ( time . Millisecond ) : case <- time . After ( time . Millisecond ) :", "del_tokens": "default : default :", "commit_type": "fix"}
{"commit_tokens": ["add", "type", "Request", "struct", "instead", "of", "Args"], "add_tokens": "// req := request.NewRequest(c) // resp, err := req.Get(\"http://httpbin.org/get\") // req.Data = map[string]string{ // resp, err := req.Post(\"http://httpbin.org/post\") // req.Cookies = map[string]string{ // resp, err := req.Get(\"http://httpbin.org/cookies\") // req.Headers = map[string]string{ // resp, err := req.Get(\"http://httpbin.org/get\") // req.Files = []request.FileField{ // resp, err := req.Post(\"http://httpbin.org/post\") // req.Json = map[string]string{ // resp, err := req.Post(\"http://httpbin.org/post\") // req.Json = []int{1, 2, 3} // resp, err = req.Post(\"http://httpbin.org/post\") // req.Proxy = \"http://127.0.0.1:8080\" // // req.Proxy = \"https://127.0.0.1:8080\" // // req.Proxy = \"socks5://127.0.0.1:57341\" // resp, err := req.Get(\"http://httpbin.org/get\") // req.BasicAuth = request.BasicAuth{\"user\", \"passwd\"} // resp, err := req.Get(\"http://httpbin.org/basic-auth/user/passwd\")", "del_tokens": "// a := request.NewArgs(c) // resp, err := request.Get(\"http://httpbin.org/get\", a) // a.Data = map[string]string{ // resp, err := request.Post(\"http://httpbin.org/post\", a) // a.Cookies = map[string]string{ // resp, err := request.Get(\"http://httpbin.org/cookies\", a) // a.Headers = map[string]string{ // resp, err := request.Get(\"http://httpbin.org/get\", a) // a.Files = []request.FileField{ // resp, err := request.Post(\"http://httpbin.org/post\", a) // a.Json = map[string]string{ // resp, err := request.Post(\"http://httpbin.org/post\", a) // a.Json = []int{1, 2, 3} // resp, err = request.Post(\"http://httpbin.org/post\", a) // a.Proxy = \"http://127.0.0.1:8080\" // // a.Proxy = \"https://127.0.0.1:8080\" // // a.Proxy = \"socks5://127.0.0.1:57341\" // resp, err := request.Get(\"http://httpbin.org/get\", a) // a.BasicAuth = request.BasicAuth{\"user\", \"passwd\"} // resp, err := request.Get(\"http://httpbin.org/basic-auth/user/passwd\", a)", "commit_type": "add"}
{"commit_tokens": ["add", "option", "to", "disable", "hash", "id"], "add_tokens": "DisableRenew bool // disable auto renew session DisableHashID bool // disable hash session id when save to store", "del_tokens": "DisableRenew bool // disable auto renew session", "commit_type": "add"}
{"commit_tokens": ["add", "note", "about", "building", "gorp"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", ".", "fi", "tld"], "add_tokens": "r := regexp . MustCompile ( `(?i)\\[?domain(\\s*\\_?name)?\\]?[\\s\\.]*\\:?\\s*([a-z0-9\\-\\.]+)\\.([a-z]{2,})` )", "del_tokens": "r := regexp . MustCompile ( `(?i)\\[?domain(\\s*\\_?name)?\\]?\\s*\\:?\\s*([a-z0-9\\-\\.]+)\\.([a-z]{2,})` )", "commit_type": "add"}
{"commit_tokens": ["Fix", "target", "IP", "address", "in", "serialized", "ARP", "message"], "add_tokens": "buf . Write ( m . targetProtocolAddress )", "del_tokens": "buf . Write ( m . targetHardwareAddress )", "commit_type": "fix"}
{"commit_tokens": ["Move", "Instruction", "below", "Config", "declaration"], "add_tokens": "// Instruction is the representation of an input template, output location, and // optional command to execute when rendered type Instruction struct { Source string `mapstructure:\"source\"` Destination string `mapstructure:\"destination\"` Command string `mapstructure:\"command\"` }", "del_tokens": "// Instruction is the representation of an input template, output location, and // optional command to execute when rendered type Instruction struct { Source string `mapstructure:\"source\"` Destination string `mapstructure:\"destination\"` Command string `mapstructure:\"command\"` }", "commit_type": "move"}
{"commit_tokens": ["Add", "ability", "to", "skip", "vendor", "directories", "during", "copy"], "add_tokens": "if err := shutil . CopyTree ( projectRootDir , projectDestDir , vendorCopyOptions ( currPkg . OmitVendorDirs ) ) ; err != nil { if err := shutil . CopyTree ( fmtSrcDir , fmtDstDir , vendorCopyOptions ( currPkg . OmitVendorDirs ) ) ; err != nil { func vendorCopyOptions ( skipVendorDirs bool ) * shutil . CopyTreeOptions { isHidden := strings . HasPrefix ( currInfo . Name ( ) , \" \" ) isVendorDir := currInfo . IsDir ( ) && currInfo . Name ( ) == \" \" if isHidden || isTestDataDir || notGoFile || goTestFile || ( skipVendorDirs && isVendorDir ) {", "del_tokens": "if err := shutil . CopyTree ( projectRootDir , projectDestDir , nil ) ; err != nil { if err := shutil . CopyTree ( fmtSrcDir , fmtDstDir , vendorCopyOptions ( ) ) ; err != nil { func vendorCopyOptions ( ) * shutil . CopyTreeOptions { if isTestDataDir || notGoFile || goTestFile {", "commit_type": "add"}
{"commit_tokens": ["Added", "infield", "-", "brackets", "option", "(", "as", "functional", "option", "InfieldBrackets", "()", ")", "to", "GetArg", "*", "functions"], "add_tokens": "TEST_BRACKETS = `some stuff in \"quotes\" and {\"brackets\":[1, 'help', (2+3)]} {{\"a\":1,\"b\":2},{\"c\":3}} x={\"value\":\"with brakets\", a=[1, \"2\", 3.14, {\"another\": \"field\"}]}` func TestScannerInfieldBrackets ( test * testing . T ) { scanner := NewScannerString ( TEST_BRACKETS ) scanner . InfieldBrackets = true for { token , delim , err := scanner . NextToken ( ) if err != nil { test . Log ( err ) break } test . Logf ( \" \" , delim , token ) } } func TestBracketsInfield ( test * testing . T ) { for i , a := range GetArgs ( TEST_BRACKETS , InfieldBrackets ( ) ) { fmt . Println ( i , a ) } }", "del_tokens": "TEST_BRACKETS = `some stuff in \"quotes\" and {\"brackets\":[1, 'help', (2+3)]} {{\"a\":1,\"b\":2},{\"c\":3}}`", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "in", "pool", "documentation", "."], "add_tokens": "// conn := pool.Get()", "del_tokens": "// conn, err := pool.Get()", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "on", "use", "pipeline", "after", "splitArray", "result"], "add_tokens": "\" \" : func ( sep string , s string ) [ ] interface { } { var r [ ] interface { }", "del_tokens": "\" \" : func ( sep string , s string ) [ ] string { var r [ ] string", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "Kill", "is", "idempotent"], "add_tokens": "// If there is no process, there is nothing to kill. defer func ( ) { // Make sure there is no reference to the old process after it has been // killed. c . l . Lock ( ) defer c . l . Unlock ( ) c . process = nil } ( ) // FIXME: this is never reached under normal circumstances, because // the plugin process is never signaled to exit. We can reach this // if the child process exited abnormally before the Kill call. c . logger . Warn ( \" \" ) // ensure the context is cancelled when we're done defer ctxCancel ( ) // ensure the context is cancelled when we're done defer ctxCancel ( )", "del_tokens": "// If there is no process, we never started anything. Nothing to kill. // Cancel the context ctxCancel ( ) // Cancel the context, marking that we exited ctxCancel ( )", "commit_type": "make"}
{"commit_tokens": ["Remove", "error", "returns", "which", "are", "always", "nil"], "add_tokens": "func ( t * Table ) Append ( row [ ] string ) { func ( t * Table ) AppendBulk ( rows [ ] [ ] string ) { t . Append ( row )", "del_tokens": "func ( t * Table ) Append ( row [ ] string ) error { return nil func ( t * Table ) AppendBulk ( rows [ ] [ ] string ) ( err error ) { err = t . Append ( row ) if err != nil { return err } return nil", "commit_type": "remove"}
{"commit_tokens": ["Make", "gunit", "test", "deal", "with", "keys", "with", "capitalization", "correctly"], "add_tokens": "tags = append ( tags , strings . ToLower ( tag ) ) m , err := TagsMatcher ( tags , cfg ) if err != nil { panic ( err ) }", "del_tokens": "tags = append ( tags , tag ) m , _ := TagsMatcher ( tags , cfg )", "commit_type": "make"}
{"commit_tokens": ["Fix", "formatting", "&", "go", "vet", "issues"], "add_tokens": "// LogFormatterParams is the structure any formatter will be handed when time to log comes", "del_tokens": "// FormatterParams is the structure any formatter will be handed when time to log comes", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "ListOneTimeAsync", "Task", ".", "Result", "()", "comment"], "add_tokens": "// Task.Result() returns []*projections.ProjectionDetails // Task.Result() returns []*projections.ProjectionDetails", "del_tokens": "// Task.Result() returns []projections.ProjectionDetails // Task.Result() returns []projections.ProjectionDetails", "commit_type": "fix"}
{"commit_tokens": ["Changing", "the", "place", "where", "escaped", "quotes", "are", "added", ".", "This", "helps", "the", "callee", "to", "be", "really", "simple"], "add_tokens": "getView ( \" \" , t )", "del_tokens": "getView ( \" \\\" \\\" \" , t )", "commit_type": "change"}
{"commit_tokens": ["fix", "error", "in", "code", "example"], "add_tokens": "err := EnvEx . View ( func ( txn * lmdb . Txn ) ( err error ) {", "del_tokens": "err = EnvEx . View ( func ( txn * lmdb . Txn ) ( err error ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "example", "code", "for", "new", "response", "format"], "add_tokens": "log . Println ( \" \" , err ) log . Println ( \" \" , res . ApnsId )", "del_tokens": "log . Println ( \" \" , err ) log . Println ( \" \" , res . NotificationID )", "commit_type": "update"}
{"commit_tokens": ["Add", "armor62", "encoding", "to", "sign", "/", "verify"], "add_tokens": "if err = CheckArmor62Frame ( frame , EncryptionArmorHeader , EncryptionArmorFooter ) ; err != nil { func CheckArmor62Frame ( frame Frame , header , footer string ) error { } else if hdr != header { return ErrBadArmorHeader { header , hdr } } else if ftr != footer { return ErrBadArmorFooter { footer , ftr }", "del_tokens": "if err = CheckArmor62Frame ( frame ) ; err != nil { func CheckArmor62Frame ( frame Frame ) error { } else if hdr != EncryptionArmorHeader { return ErrBadArmorHeader { EncryptionArmorHeader , hdr } } else if ftr != EncryptionArmorFooter { return ErrBadArmorFooter { EncryptionArmorFooter , ftr }", "commit_type": "add"}
{"commit_tokens": ["Fix", "code", "on", "google", "appengine"], "add_tokens": "if configuredLogger , ok := config . Logger . ( * log . Logger ) ; ok { config . Logger = log . New ( appengineWriter { c } , configuredLogger . Prefix ( ) , configuredLogger . Flags ( ) ) } else { config . Logger = log . New ( appengineWriter { c } , log . Prefix ( ) , log . Flags ( ) ) }", "del_tokens": "config . Logger = log . New ( appengineWriter { c } , config . Logger . Prefix ( ) , config . Logger . Flags ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "rudimentary", "logging", "control", "via", "--", "debug", "flag"], "add_tokens": "\" \" logrus . SetLevel ( logrus . WarnLevel ) // clear existing hooks: logrus . StandardLogger ( ) . Hooks = make ( logrus . LevelHooks ) // ... and disable stderr: } // Configures the logger to dump everything to stderr func InitLoggerDebug ( ) { // clear existing hooks: logrus . StandardLogger ( ) . Hooks = make ( logrus . LevelHooks ) logrus . SetOutput ( os . Stderr ) fmt . Fprintln ( os . Stderr , \" \" + unwrap ( err ) . Error ( ) ) // ConsoleMessage prints the same message to a 'ui console' (if defined) and also to // the logger with INFO priority func ConsoleMessage ( w io . Writer , msg string , params ... interface { } ) { msg = fmt . Sprintf ( msg , params ... ) if w != nil { fmt . Fprintln ( w , msg ) } logrus . Info ( msg ) }", "del_tokens": "// ... and disable its own output: fmt . Fprintln ( os . Stderr , unwrap ( err ) )", "commit_type": "add"}
{"commit_tokens": ["Allow", "uses", "to", "shutdown", "the", "pprof"], "add_tokens": "_ \" \" stores = make ( map [ string ] kv . Driver ) Debug = false PprofAddr = \" \" // start pprof handlers if Debug { go http . ListenAndServe ( PprofAddr , nil ) }", "del_tokens": "// For pprof _ \" \" stores = make ( map [ string ] kv . Driver ) go http . ListenAndServe ( \" \" , nil )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "for", "data", "race", "in", "generating", "request", "ids"], "add_tokens": "var reqMutex sync . Mutex reqMutex . Lock ( ) val := int ( random . Int31 ( ) ) reqMutex . Unlock ( ) return val", "del_tokens": "return int ( random . Int31 ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "the", "way", "commands", "and", "options", "work"], "add_tokens": "\" \" sample . Run ( )", "del_tokens": "// sample.Run()", "commit_type": "update"}
{"commit_tokens": ["Fix", "compile", "of", "tests", "."], "add_tokens": "t . Errorf ( \" \" , expectedUid , header . Uid ) t . Errorf ( \" \" , expectedGid , header . Gid ) t . Errorf ( \" \" , expectedMode , header . Mode )", "del_tokens": "t . Errorf ( \" \" , expectedUid , header . Uid ) t . Errorf ( \" \" , expectedGid , header . Gid ) t . Errorf ( \" \" , expectedMode , header . Mode )", "commit_type": "fix"}
{"commit_tokens": ["Make", "docs", "say", "what", "SetPath", "actually", "does", "."], "add_tokens": "// SetPath updates or adds a URIPath attribute on this message.", "del_tokens": "// SetPath updates or adds a LocationPath attribute on this message.", "commit_type": "make"}
{"commit_tokens": ["Remove", "quarantine", "in", "apply", "(", "OS", "X", ")"], "add_tokens": "zipPath := filepath . Join ( os . Getenv ( \" \" ) , \" \" ) options := updater . UpdateOptions { DestinationPath : filepath . Join ( os . TempDir ( ) , \" \" ) }", "del_tokens": "zipPath := filepath . Join ( os . Getenv ( \" \" ) , \" \" ) localPath := filepath . Join ( tmpDir , \" \" ) err = util . CopyFile ( zipPath , localPath , testLog ) require . NoError ( t , err ) options := updater . UpdateOptions { DestinationPath : filepath . Join ( os . TempDir ( ) , \" \" ) }", "commit_type": "remove"}
{"commit_tokens": ["removes", "unused", "header", "regarding", "Mobile", "-", "Detect", "/", "229"], "add_tokens": "if md . VersionFloat ( \" \" ) >= 4.3 || md . VersionFloat ( \" \" ) >= 3.1 || md . VersionFloat ( \" \" ) >= 3.1 ||", "del_tokens": "\" \" , if md . VersionFloat ( \" \" ) >= 4.3 || md . VersionFloat ( \" \" ) >= 4.0 || md . VersionFloat ( \" \" ) >= 4.0 ||", "commit_type": "remove"}
{"commit_tokens": ["change", "definition", "of", "PluginWithPrefix", "interface"], "add_tokens": "MetricKeyPrefix ( ) string prefix = p . MetricKeyPrefix ( ) metricNames = append ( metricNames , p . MetricKeyPrefix ( ) ) prefix := p . MetricKeyPrefix ( )", "del_tokens": "GetMetricKeyPrefix ( ) string prefix = p . GetMetricKeyPrefix ( ) metricNames = append ( metricNames , p . GetMetricKeyPrefix ( ) ) prefix := p . GetMetricKeyPrefix ( )", "commit_type": "change"}
{"commit_tokens": ["remove", "sync", ".", "Once", "from", "Promise"], "add_tokens": "f := & Promise {", "del_tokens": "\" \" onceEnd * sync . Once f := & Promise { new ( sync . Once ) ,", "commit_type": "remove"}
{"commit_tokens": ["Make", "New", "()", "thread", "-", "safe", "."], "add_tokens": "l . DisableColor ( ) DisableColor ( )", "del_tokens": "// l.DisableColor() // DisableColor()", "commit_type": "make"}
{"commit_tokens": ["use", "io", ".", "ReadAtLeast", "instead", "of", "ReadFull"], "add_tokens": "n , err := io . ReadAtLeast ( f , readBuf , 1 )", "del_tokens": "n , err := io . ReadFull ( f , readBuf )", "commit_type": "use"}
{"commit_tokens": ["Fix", "bugs", "in", "bigquery", "storage", "driver", "."], "add_tokens": "Name : colPodName , row [ colTimestamp ] = stat . Timestamp // Container name row [ colContainerName ] = containerName // Hostname row [ colHostName ] = hostname", "del_tokens": "Name : colPodStatus , fields = append ( fields , & bigquery . TableFieldSchema { Type : typeInteger , Name : colCpuInstantUsage , } ) row [ colTimestamp ] = stat . Timestamp . Unix ( ) // Hostname row [ colHostName ] = hostname // Container name row [ colContainerName ] = containerName", "commit_type": "fix"}
{"commit_tokens": ["fix", "import", "for", "command", "line", "tool"], "add_tokens": "d \" \"", "del_tokens": "d \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "expiration", "to", "redis", "cache"], "add_tokens": "\" \" \" \" \" \" Expire time . Duration params := [ ] interface { } { key , data } if redis . Expire != 0 { params = append ( params , \" \" , strconv . Itoa ( int ( redis . Expire . Seconds ( ) ) ) ) } _ , err = conn . Do ( \" \" , params ... )", "del_tokens": "if err != nil { image = nil return } _ , err = conn . Do ( \" \" , key , data ) if err != nil { return }", "commit_type": "add"}
{"commit_tokens": ["Add", "glide", "to", "travis", "build"], "add_tokens": "func ExampleTimeRFC1123 ( ) {", "del_tokens": "func ExampleParseTimeRFC1123 ( ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "HTTP", "status", "code", "conversion", "type", "safe", "opt", "out", "to", "RPC", "on", "error"], "add_tokens": "parentSpan . SetTag ( string ( ext . HTTPStatusCode ) , uint16 ( 200 ) )", "del_tokens": "parentSpan . SetTag ( string ( ext . HTTPStatusCode ) , 200 )", "commit_type": "make"}
{"commit_tokens": ["Add", "APIEndpoints", "in", "example", "application"], "add_tokens": "func APIEndpoints ( c * gin . Context ) {", "del_tokens": "func APIIndex ( c * gin . Context ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "%s", "into", "%v", "in", "parse_test", ".", "go"], "add_tokens": "t . Errorf ( \" \" , m . Entries [ \" \" ] . Int ) t . Errorf ( \" \" , m . Entries [ \" \" ] . Bool )", "del_tokens": "t . Errorf ( \" \" , m . Entries [ \" \" ] . Int ) t . Errorf ( \" \" , m . Entries [ \" \" ] . Bool )", "commit_type": "fix"}
{"commit_tokens": ["Add", "stored", "age", "in", "debug", "output"], "add_tokens": "ttl , _ := res . MaxAge ( h . Shared ) log . Printf ( \" \" , ttl . String ( ) )", "del_tokens": "log . Println ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "and", "update", "readme"], "add_tokens": "err := s . backend . UpdateCount ( \" \" , time . Second , 1 ) counter , err := s . backend . GetCount ( \" \" , time . Second )", "del_tokens": "err := s . backend . UpdateCount ( \" \" , time . Second ) counter , err := s . backend . GetCount ( \" \" , time . Second , 2 )", "commit_type": "fix"}
{"commit_tokens": ["move", "creation", "of", "bufio", ".", "Reader", "out", "of", "newFileBlockReader", "()"], "add_tokens": "func newFileBlockReader ( br * bufio . Reader , pass string ) ( fileBlockReader , error ) {", "del_tokens": "func newFileBlockReader ( r io . Reader , pass string ) ( fileBlockReader , error ) { br , ok := r . ( * bufio . Reader ) if ! ok { br = bufio . NewReader ( r ) }", "commit_type": "move"}
{"commit_tokens": ["Create", "a", "new", "*", "template", ".", "Template", "instance", "for", "each", "loading", "."], "add_tokens": "leftDelim string rightDelim string funcMap template . FuncMap l := & Loader { funcMap : make ( template . FuncMap , len ( DefaultFuncMap ) ) , l . Funcs ( DefaultFuncMap ) return l } func ( l * Loader ) newTemplate ( ) * template . Template { tmpl := template . New ( \" \" ) . Funcs ( l . funcMap ) if l . leftDelim != \" \" && l . rightDelim != \" \" { tmpl . Delims ( l . leftDelim , l . rightDelim ) } return tmpl t , err := l . newTemplate ( ) . Parse ( string ( data ) ) l . leftDelim = left l . rightDelim = right for name , fn := range funcMap { l . funcMap [ name ] = fn }", "del_tokens": "tmpl * template . Template return & Loader { tmpl : template . New ( \" \" ) . Funcs ( DefaultFuncMap ) , t , err := l . tmpl . Parse ( string ( data ) ) l . tmpl . Delims ( left , right ) l . tmpl . Funcs ( funcMap )", "commit_type": "create"}
{"commit_tokens": ["Implement", "exit", "code", "handling", "and", "use", "--", "key", "instead", "of", "--", "token"], "add_tokens": "var tokenFlag = app . Flag ( \" \" , \" \" ) . String ( ) var moreThanOneError = false moreThanOneError = strings . Contains ( err . Error ( ) , \" \" ) // Ugh, there has to be a better way // We're done, print output and figure out correct exit code var exitStatus = 0 switch { case moreThanOneError : exitStatus = 6 case resp . StatusCode == 401 : exitStatus = 1 case resp . StatusCode == 403 : exitStatus = 3 case resp . StatusCode == 404 : exitStatus = 4 case resp . StatusCode > 399 && resp . StatusCode < 500 : exitStatus = 2 case resp . StatusCode > 499 : exitStatus = 5 } os . Exit ( exitStatus )", "del_tokens": "var tokenFlag = app . Flag ( \" \" , \" \" ) . Short ( 't' ) . String ( ) // We're done", "commit_type": "implement"}
{"commit_tokens": ["Use", "libkermit", "for", "integration", "test"], "add_tokens": "docker \" \" project * docker . Project project , err := docker . NewProjectFromEnv ( ) c . Assert ( err , checker . IsNil , check . Commentf ( \" \" ) ) s . project = project err = s . composeProject . Start ( ) consul , err := s . project . Inspect ( \" \" ) nginx , err := s . project . Inspect ( \" \" )", "del_tokens": "\" \" \" \" \" \" \" \" dockerClient * docker . Client } func ( s * ConsulCatalogSuite ) GetContainer ( name string ) ( * docker . Container , error ) { return s . dockerClient . InspectContainer ( name ) dockerHost := os . Getenv ( \" \" ) if dockerHost == \" \" { // FIXME Handle windows -- see if dockerClient already handle that or not dockerHost = fmt . Sprintf ( \" \" , opts . DefaultUnixSocket ) } // Make sure we can speak to docker dockerClient , err := docker . NewClient ( dockerHost ) c . Assert ( err , checker . IsNil , check . Commentf ( \" \" ) ) s . dockerClient = dockerClient err = s . composeProject . Up ( ) consul , err := s . GetContainer ( \" \" ) nginx , err := s . GetContainer ( \" \" )", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "!bangs", "by", "adding", "&no_redirect", "=", "1", "to", "the", "baseUrl", "if", "the", "query", "starts", "with", "!", ".", "This", "allows", "use", "of"], "add_tokens": "var baseUrl = \" \" return fmt . Sprintf ( baseUrl , queryEnc , \" \" ) return fmt . Sprintf ( baseUrl , queryEnc , \" \" )", "del_tokens": "var baseUrl = \" \" var bangUrl = \" \" return fmt . Sprintf ( bangUrl , queryEnc ) } else { return fmt . Sprintf ( baseUrl , queryEnc )", "commit_type": "add"}
{"commit_tokens": ["Add", "of", "Pow_C128", "-", "128", "bit", "Pow", "calc", "using", "standard", "C", "instructions", "for", "64", "bit", "processors", "."], "add_tokens": "powOrderPreference := [ ] string { \" \" , \" \" , \" \" , \" \" } return \" \" , PowGo // default return PowGo if no others", "del_tokens": "powOrderPreference := [ ] string { \" \" , \" \" , \" \" } return \" \" , PowGo // defualt return PowGo if no others", "commit_type": "add"}
{"commit_tokens": ["move", "protocol", "methods", "down", "into", "peerstream"], "add_tokens": "handler ( ( * Stream ) ( s ) ) return ( * Stream ) ( st ) , err n . not . OpenedStream ( n . net , ( * Stream ) ( s ) ) n . not . ClosedStream ( n . net , ( * Stream ) ( s ) )", "del_tokens": "handler ( wrapStream ( s ) ) return wrapStream ( st ) , err } // StreamsWithPeer returns all the live Streams to p func ( s * Swarm ) StreamsWithPeer ( p peer . ID ) [ ] * Stream { return wrapStreams ( ps . StreamsWithGroup ( p , s . swarm . Streams ( ) ) ) n . not . OpenedStream ( n . net , & Stream { stream : s } ) n . not . ClosedStream ( n . net , & Stream { stream : s } )", "commit_type": "move"}
{"commit_tokens": ["Added", "Remember", "Me", "cookie", "to", "the", "example"], "add_tokens": "func ( c * BasicAuth ) Check ( r * http . Request ) ( user string , err error ) { err = core . ErrorAuthenticationFailure return err = core . ErrorAuthenticationFailure return err = core . ErrorAuthenticationFailure return", "del_tokens": "func ( c * BasicAuth ) Check ( r * http . Request ) error { return core . ErrorAuthenticationFailure fmt . Println ( user ) return core . ErrorAuthenticationFailure return core . ErrorAuthenticationFailure return nil", "commit_type": "add"}
{"commit_tokens": ["added", "components", "for", "zookeper", "client", "support", "."], "add_tokens": "Detect ( ) ( * mesos . MasterInfo , error ) // DetectChange ( func ( * mesos . MasterInfo ) ) error", "del_tokens": "Detect ( receiver chan * mesos . MasterInfo )", "commit_type": "add"}
{"commit_tokens": ["Update", "README", ".", "md", "and", "godoc"], "add_tokens": "Please make sure Golang , GCC is installed correctly before installing RobotGo ; version string = \" \"", "del_tokens": "Please make sure Golang , GCC , zlib and libpng is installed correctly before installing RobotGo ; version string = \" \"", "commit_type": "update"}
{"commit_tokens": ["update", "ringcentral", "/", "examples", "/", "get_account"], "add_tokens": "err := config . LoadDotEnvSkipEmpty ( os . Getenv ( \" \" ) , \" \" )", "del_tokens": "err := config . LoadDotEnv ( )", "commit_type": "update"}
{"commit_tokens": ["Add", "Windows", "Credential", "Manager", "support"], "add_tokens": "import \" \" const errNotFound = \" \" // Get gets a secret from the keyring given a service name and a user. cred , err := wincred . GetGenericCredential ( k . credName ( service , username ) ) if err != nil { if err . Error ( ) == errNotFound { return \" \" , ErrNotFound } return \" \" , err } return string ( cred . CredentialBlob ) , nil // name. cred := wincred . NewGenericCredential ( k . credName ( service , username ) ) cred . CredentialBlob = [ ] byte ( password ) return cred . Write ( ) func ( k windowsKeychain ) Delete ( service , username string ) error { cred , err := wincred . GetGenericCredential ( k . credName ( service , username ) ) if err != nil { if err . Error ( ) == errNotFound { return ErrNotFound } return err } return cred . Delete ( ) } // credName combines service and username to a single string. func ( k windowsKeychain ) credName ( service , username string ) string { return service + \" \" + username", "del_tokens": "// Get gets a secret from the keyring given a service name and a user. This // method is currently a NO-OP on windows. return nil , ErrNotFound // name. This method is currently a NO-OP on windows. return nil // This method is currently a NO-OP on windows. func ( k MacOSXKeychain ) Delete ( service , username string ) error { return nil", "commit_type": "add"}
{"commit_tokens": ["Adding", "FetchValueCommand", "and", "refactoring", "along", "the", "way", "."], "add_tokens": "var data [ ] byte data , err = cmd . rpbData ( ) if err != nil { return } if err = c . write ( data ) ; err != nil { data , err = c . read ( )", "del_tokens": "if err = c . write ( cmd . rpbData ( ) ) ; err != nil { data , err := c . read ( )", "commit_type": "add"}
{"commit_tokens": ["changed", "to", "only", "one", "worker", "to", "fetch", "plugin", "details", "nessus", "was", "dying", "under", "the", "load", "..."], "add_tokens": "// AllPlugin wil hammer nessus asking for details of every plugins available and feeding them in // the returned channel. // Gettign all the plugins is slow (usually takes a few minutes on a decent machine). // Launch our worker getting individual plugin details. go func ( ) { } ( )", "del_tokens": "// AllPlugin wil hammer nessus with 20 workers asking for details of every plugins available and // feeding them in the returned channel. Gettign all the plugins is slow (usually takes a few // minutes on a decent machine. pluginFetcher := func ( ) { } // Launch our workers getting individual plugin details. for i := 0 ; i < 10 ; i ++ { go pluginFetcher ( ) }", "commit_type": "change"}
{"commit_tokens": ["Make", "it", "compatible", "with", "sentry"], "add_tokens": "pc , file , line , _ := runtime . Caller ( 2 ) PC : pc ,", "del_tokens": "_ , file , line , _ := runtime . Caller ( 2 )", "commit_type": "make"}
{"commit_tokens": ["change", "int", "size", "and", "add", "float", "support"], "add_tokens": "\" \" type SexpInt int type SexpUint uint type SexpFloat float64 var SexpIntSize = reflect . TypeOf ( SexpInt ( 0 ) ) . Bits ( ) var SexpFloatSize = reflect . TypeOf ( SexpFloat ( 0.0 ) ) . Bits ( ) func ( f SexpFloat ) SexpString ( ) string { return strconv . FormatFloat ( float64 ( f ) , 'g' , 5 , SexpFloatSize ) } i , err := strconv . ParseInt ( tok . str , 10 , SexpIntSize ) i , err := strconv . ParseUint ( tok . str , 16 , SexpIntSize ) i , err := strconv . ParseUint ( tok . str , 2 , SexpIntSize ) case TokenFloat : f , err := strconv . ParseFloat ( tok . str , SexpFloatSize ) if err != nil { return SexpNull , err } return SexpFloat ( f ) , nil", "del_tokens": "type SexpInt int8 type SexpUint uint8 i , err := strconv . ParseInt ( tok . str , 10 , 8 ) i , err := strconv . ParseUint ( tok . str , 16 , 8 ) i , err := strconv . ParseUint ( tok . str , 2 , 8 )", "commit_type": "change"}
{"commit_tokens": ["Fix", "error", "when", "printing", "usage", "for", "multi", "-", "value", "arguments"], "add_tokens": "if v . Type ( ) . Comparable ( ) && z . Type ( ) . Comparable ( ) && v . Interface ( ) != z . Interface ( ) {", "del_tokens": "if v . Interface ( ) != z . Interface ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "usage", "of", "PAC", "files"], "add_tokens": "return & url . URL { Host : conf . Automatic . FindProxyForURL ( req . URL . String ( ) ) } , nil", "del_tokens": "return url . Parse ( conf . Automatic . FindProxyForURL ( req . URL . String ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "json", "tag", "on", "model", "to", "skip", "Parent", "and", "avoid", "circular", "referencing", "in", "a", "json", ".", "Marshal"], "add_tokens": "Parent interface { } `json:\"-\"`", "del_tokens": "Parent interface { }", "commit_type": "add"}
{"commit_tokens": ["add", "fields", "to", "MarketSummary", "data"], "add_tokens": "MarketName string `json:\"MarketName\"` High float64 `json:\"High\"` Low float64 `json:\"Low\"` Ask float64 `json:\"Ask\"` Bid float64 `json:\"Bid\"` OpenBuyOrders int `json:\"OpenBuyOrders\"` OpenSellOrders int `json:\"OpenSellOrders\"` Volume float64 `json:\"Volume\"` Last float64 `json:\"Last\"` BaseVolume float64 `json:\"BaseVolume\"` TimeStamp string `json:\"TimeStamp\"`", "del_tokens": "MarketName string `json:\"MarketName\"` High float64 `json:\"High\"` Low float64 `json:\"Low\"` Volume float64 `json:\"Volume\"` Last float64 `json:\"Last\"` BaseVolume float64 `json:\"BaseVolume\"` TimeStamp string `json:\"TimeStamp\"`", "commit_type": "add"}
{"commit_tokens": ["using", "async", "processing", "to", "simplify", "response", "parsing"], "add_tokens": "ch := make ( chan tokenStruct , 5 ) go processResponse ( conn , ch ) loop : for tok := range ch { switch token := tok . data . ( type ) { case doneStruct : break loop case [ ] columnStruct : conn . columns = token case [ ] interface { } : conn . lastRow = token default : fmt . Println ( \" \" , tok ) }", "del_tokens": "err = processResponse ( conn ) if err != nil { t . Error ( \" \" , err . Error ( ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "wrong", "import", "and", "remaining", "references", "to", "apps", "/", "v1beta1"], "add_tokens": "apps_v1b2inf \" \" apps_v1b2 . SchemeGroupVersion . WithKind ( \" \" ) : apps_v1b2inf . NewDeploymentInformer ( mainClient , namespace , resyncPeriod , cache . Indexers { } ) ,", "del_tokens": "apps_v1b1inf \" \" apps_v1b2 . SchemeGroupVersion . WithKind ( \" \" ) : apps_v1b1inf . NewDeploymentInformer ( mainClient , namespace , resyncPeriod , cache . Indexers { } ) ,", "commit_type": "fix"}
{"commit_tokens": ["added", "readme", "and", "better", "documentation"], "add_tokens": "/ * Example usage : opts := map [ string ] string { \" \" : \" \" , \" \" : \" * \" \" \" : \" \" , \" \" : \" \" } s . Use ( helmet . ContentSecurityPolicy ( opts , true ) ) keys := [ ] string { \" \" , \" \" } r := gin . New ( ) r . Use ( SetHPKP ( keys , 5184000 , true , \" \" ) )", "del_tokens": "/ * Example usage : `` `golang opts := map [ string ] string { \" \" : \" \" , \" \" : \" * \" \" \" : \" \" , \" \" : \" \" } s . Use ( helmet . ContentSecurityPolicy ( opts , true ) ) `` ` `` `golang opts := map [ string ] string { \" \" : \" \" , \" \" : \" \" , \" \" : \" \" , } s . Use ( helmet . SetHPKP ( opts ) ) `` `", "commit_type": "add"}
{"commit_tokens": ["fix", "SetQuery", "panic", "(", "caused", "by", "uninitialized", "map", ")"], "add_tokens": "return & Resource { Url : \" \" , Api : apiInstance }", "del_tokens": "return & Resource { Url : \" \" , Api : apiInstance , QueryValues : make ( url . Values ) }", "commit_type": "fix"}
{"commit_tokens": ["use", "types", "from", "same", "namespace"], "add_tokens": "Host string Raw string var index = & Index { req := & Request {", "del_tokens": "\" \" var index = es . Index { req := & es . Request {", "commit_type": "use"}
{"commit_tokens": ["Add", "rate", "limiting", "and", "http", "caching", "to", "the", "github", "client", "."], "add_tokens": "\" \" \" \" type RateLimitRoundTripper struct { delegate http . RoundTripper throttle util . RateLimiter } func ( r * RateLimitRoundTripper ) RoundTrip ( req * http . Request ) ( resp * http . Response , err error ) { r . throttle . Accept ( ) return r . delegate . RoundTrip ( req ) } var client * http . Client cacheTransport := httpcache . NewMemoryCacheTransport ( ) rateLimitTransport := & RateLimitRoundTripper { delegate : cacheTransport , // Global limit is 5000 Q/Hour, try to only use 1800 to make room for other apps throttle : util . NewTokenBucketRateLimiter ( 0.5 , 10 ) , } client = & http . Client { Transport : & oauth2 . Transport { Base : rateLimitTransport , Source : oauth2 . ReuseTokenSource ( nil , ts ) , } , } } else { rateLimitTransport := & RateLimitRoundTripper { delegate : cacheTransport , throttle : util . NewTokenBucketRateLimiter ( 0.01 , 10 ) , } client = & http . Client { Transport : rateLimitTransport , } return github . NewClient ( client )", "del_tokens": "tc := oauth2 . NewClient ( oauth2 . NoContext , ts ) return github . NewClient ( tc ) return github . NewClient ( nil )", "commit_type": "add"}
{"commit_tokens": ["added", "postgres", "support", "for", "db", "migrations"], "add_tokens": "import \" \"", "del_tokens": "import ( \" \" \" \" ) func ( db * Mysql ) ToDBTypeSql ( columnType ColumnType , length int ) string { switch columnType { case DB_TYPE_STRING : return fmt . Sprintf ( \" \" , length ) } panic ( \" \" ) }", "commit_type": "add"}
{"commit_tokens": ["Removed", "support", "for", "multiple", "encryption", "keys", "for", "speed", "reasons", "."], "add_tokens": "ConnectionString string Database string var EncryptionKey = [ ] byte { }", "del_tokens": "ConnectionString string Database string EncryptionKey [ ] byte EncryptionKeyPerCollection map [ string ] [ ] byte DisableEncryption bool func ( m * Connection ) GetEncryptionKey ( collection string ) [ ] byte { key , has := m . Config . EncryptionKeyPerCollection [ collection ] if has { return key } else { return m . Config . EncryptionKey } }", "commit_type": "remove"}
{"commit_tokens": ["Change", "the", "name", "of", "the", "new", "api", "key", "methods", "and", "expose", "the", "custom", "batch", "method"], "add_tokens": "return c . AddKeyWithParam ( body ) func ( c * Client ) AddKeyWithParam ( params interface { } ) ( interface { } , error ) { return c . UpdateKeyWithParam ( key , body ) func ( c * Client ) UpdateKeyWithParam ( key string , params interface { } ) ( interface { } , error ) {", "del_tokens": "return c . AddAPIKey ( body ) func ( c * Client ) AddAPIKey ( params interface { } ) ( interface { } , error ) { return c . UpdateAPIKey ( key , body ) func ( c * Client ) UpdateAPIKey ( key string , params interface { } ) ( interface { } , error ) {", "commit_type": "change"}
{"commit_tokens": ["Fixed", "the", "spatial", "match", "issue", ".", "Added", "more", "test"], "add_tokens": "ADJACENCY_GRAPHS = append ( ADJACENCY_GRAPHS , adjacency . AdjacencyGph [ \" \" ] ) //l33tFilePath, _ := filepath.Abs(\"adjacency/L33t.json\") //L33T_TABLE = adjacency.GetAdjancencyGraphFromFile(l33tFilePath, \"l33t\") MATCHERS = append ( MATCHERS , SpatialMatch ) MATCHERS = append ( MATCHERS , RepeatMatch ) //TODO: This is not working. //It appears that the Adjacency graph data is incorrect. Need to get a new copy from python-zxcvbn. func SpatialMatch ( password string ) ( matches [ ] match . Match ) { if graph . Graph != nil { matches = append ( matches , spatialMatchHelper ( password , graph ) ... ) } lastDirection := - 99 //an int that it should never be! //My graphs seem to be wrong. . . and where the hell is qwerty //Consider growing pattern by one character if j hasn't gone over the edge //index 1 in the adjacency means the key is shifted, 0 means unshifted: A vs a, % vs 5, etc. //for example, 'q' is adjacent to the entry '2@'. @ is shifted w/ index 1, 2 is unshifted. //adding a turn is correct even in the initial case when last_direction is null: //every spatial pattern starts with a turn. //if the current pattern continued, extend j and try to grow again //otherwise push the pattern discovered so far, if any... //don't consider length 1 or 2 chains. //. . . and then start a new search from the rest of the password func RepeatMatch ( password string ) [ ] match . Match { if strings . ToLower ( current ) == strings . ToLower ( prev ) {", "del_tokens": "ADJACENCY_GRAPHS = append ( ADJACENCY_GRAPHS , adjacency . AdjacencyGph [ \" \" ] ) // // l33tFilePath, _ := filepath.Abs(\"adjacency/L33t.json\") // L33T_TABLE = adjacency.GetAdjancencyGraphFromFile(l33tFilePath, \"l33t\") MATCHERS = append ( MATCHERS , spatialMatch ) MATCHERS = append ( MATCHERS , repeatMatch ) func spatialMatch ( password string ) ( matches [ ] match . Match ) { matches = append ( matches , spatialMatchHelper ( password , graph ) ... ) lastDirection := - 99 //and int that it should never be! // Consider growing pattern by one character if j hasn't gone over the edge // index 1 in the adjacency means the key is shifted, 0 means unshifted: A vs a, % vs 5, etc. // for example, 'q' is adjacent to the entry '2@'. @ is shifted w/ index 1, 2 is unshifted. // adding a turn is correct even in the initial case when last_direction is null: // every spatial pattern starts with a turn. // if the current pattern continued, extend j and try to grow again // otherwise push the pattern discovered so far, if any... // don't consider length 1 or 2 chains. // . . . and then start a new search from the rest of the password func repeatMatch ( password string ) [ ] match . Match { if current == prev {", "commit_type": "fix"}
{"commit_tokens": ["Added", "links", "to", "Wiki", "to", "documentation", ".", "Also", "replaced", "screenshot", "with", "GIF", "screencast", "."], "add_tokens": "// Checkbox implements a simple box for boolean values which can be checked and // unchecked. // // See https://github.com/rivo/tview/wiki/Checkbox for an example.", "del_tokens": "// Checkbox is a one-line box (three lines if there is a title) where the // user can enter text.", "commit_type": "add"}
{"commit_tokens": ["Move", "metric", "flush", "invocations", "to", "s", ".", "Flush"], "add_tokens": "wm := w . Flush ( ) assert . Len ( t , wm . counters , 1 , \" \" ) nometrics := w . Flush ( ) assert . Len ( t , nometrics . counters , 0 , \" \" )", "del_tokens": "\" \" ddmetrics := w . Flush ( 10 * time . Second ) assert . Len ( t , ddmetrics , 1 , \" \" ) nometrics := w . Flush ( 10 * time . Second ) assert . Len ( t , nometrics , 0 , \" \" )", "commit_type": "move"}
{"commit_tokens": ["remove", "RETENTION", "POLICY", "from", "CREATE", "DATABASE"], "add_tokens": "s : `CREATE DATABASE testdb` ,", "del_tokens": "s : `CREATE DATABASE testdb WITH RETENTION POLICY policy1` , Policies : [ ] string { \" \" } , } , } , // CREATE DATABASE statement with multiple retention policies { s : `CREATE DATABASE testdb WITH DEFAULT RETENTION POLICY policy1 WITH RETENTION POLICY policy2` , stmt : & influxql . CreateDatabaseStatement { Name : \" \" , Policies : [ ] string { \" \" , \" \" } , DefaultPolicy : \" \" ,", "commit_type": "remove"}
{"commit_tokens": ["Added", "separate", "method", "to", "read", "bytes", "to", "prevent", "copying", "when", "converting", "string", "<", "-", ">", "[]", "byte"], "add_tokens": "return u . ReadBytes ( data ) return u . ReadBytes ( data [ 1 : len ( data ) - 1 ] )", "del_tokens": "return u . SetString ( string ( data ) ) return u . SetString ( string ( data [ 1 : len ( data ) - 1 ] ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "golint", "-", "compliant", "comments", "in", "generated", "code"], "add_tokens": "g . p ( \" \" , mockType , intf . Name ) g . p ( \" \" , mockType ) g . p ( \" \" ) g . p ( \" \" , m . Name )", "del_tokens": "g . p ( \" \" , intf . Name )", "commit_type": "add"}
{"commit_tokens": ["Fix", "wrong", "stdout", "and", "stderr", "redirection"], "add_tokens": "$ exec >> $ stdoutlog 2 >> $ stderrlog &", "del_tokens": "$ exec >> $ stderrlog 2 >> $ stdoutlog &", "commit_type": "fix"}
{"commit_tokens": ["fixed", "imports", "with", "empty", "alias"], "add_tokens": "if alias . Alias == nil || * alias . Alias != \" \" { if _ , err := fmt . Fprintf ( w , \" \\n \" , alias , path ) ; err != nil { return err }", "del_tokens": "if _ , err := fmt . Fprintf ( w , \" \\n \" , alias , path ) ; err != nil { return err", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "duckduckgo", "query", "package", "."], "add_tokens": "\" \" _ \" \" channel := flag . String ( \" \" , \" \" , \" \" ) channels := strings . Split ( * channel , \" \" ) for _ , c := range channels { c = strings . TrimSpace ( c ) if len ( c ) == 0 { continue } err = conn . Join ( c ) if err != nil { log . Printf ( \" \" , err . Error ( ) ) os . Exit ( 1 ) }", "del_tokens": "channel := flag . String ( \" \" , \" \" , \" \" ) err = conn . Join ( * channel ) if err != nil { log . Printf ( \" \" , err . Error ( ) ) os . Exit ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "trailing", "comment", "lexer", "loop"], "add_tokens": "case '\\n' , eof :", "del_tokens": "case '\\n' :", "commit_type": "fix"}
{"commit_tokens": ["Fix", "using", "only", "a", "single", "receive", "window", "."], "add_tokens": "// TODO: implement receive window 1 / 2 switch. Based on duty cycle status of gateway? // txPacket.TXInfo.Timestamp = rxPacket.RXInfo.Timestamp + uint32(band.ReceiveDelay2/time.Microsecond) // txPacket.TXInfo.Frequency = band.RX2Frequency // txPacket.TXInfo.DataRate = band.DataRateConfiguration[band.RX2DataRate] // if err := ctx.Gateway.Send(txPacket); err != nil { // return fmt.Errorf(\"send tx packet (rx window 2) to gateway error: %s\", err) // } // TODO: implement receive window 1 / 2 switch. Based on duty cycle status of gateway? // txPacket.TXInfo.Timestamp = rxPacket.RXInfo.Timestamp + uint32(band.JoinAcceptDelay2/time.Microsecond) // txPacket.TXInfo.Frequency = band.RX2Frequency // txPacket.TXInfo.DataRate = band.DataRateConfiguration[band.RX2DataRate] // if err = ctx.Gateway.Send(txPacket); err != nil { // return fmt.Errorf(\"send tx packet (rx window 2) to gateway error: %s\", err) // }", "del_tokens": "txPacket . TXInfo . Timestamp = rxPacket . RXInfo . Timestamp + uint32 ( band . ReceiveDelay2 / time . Microsecond ) txPacket . TXInfo . Frequency = band . RX2Frequency txPacket . TXInfo . DataRate = band . DataRateConfiguration [ band . RX2DataRate ] if err := ctx . Gateway . Send ( txPacket ) ; err != nil { return fmt . Errorf ( \" \" , err ) } txPacket . TXInfo . Timestamp = rxPacket . RXInfo . Timestamp + uint32 ( band . JoinAcceptDelay2 / time . Microsecond ) txPacket . TXInfo . Frequency = band . RX2Frequency txPacket . TXInfo . DataRate = band . DataRateConfiguration [ band . RX2DataRate ] if err = ctx . Gateway . Send ( txPacket ) ; err != nil { return fmt . Errorf ( \" \" , err ) }", "commit_type": "fix"}
{"commit_tokens": ["Allow", "generating", "marshalers", "for", "renamed", "structs", "."], "add_tokens": "name string explicit bool func ( p * Parser ) needType ( comments string ) bool { v . explicit = v . needType ( n . Doc . Text ( ) ) if ! v . explicit && ! v . AllStructs { // Allow to specify non-structs explicitly independent of '-all' flag. if v . explicit { v . StructNames = append ( v . StructNames , v . name ) return nil }", "del_tokens": "name string func ( p * Parser ) needStruct ( comments string ) bool { if p . AllStructs { return true } if ! v . needStruct ( n . Doc . Text ( ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "White", "990", "BR30", "and", "Color", "1000", "BR30"], "add_tokens": "case device . ProductLifxOriginal1000 , device . ProductLifxColor650 , device . ProductLifxWhite800LowVoltage , device . ProductLifxWhite800HighVoltage , device . ProductLifxWhite900BR30 , device . ProductLifxColor1000BR30 , device . ProductLifxColor1000 :", "del_tokens": "case device . ProductLifxOriginal1000 , device . ProductLifxColor650 , device . ProductLifxWhite800LowVoltage , device . ProductLifxWhite800HighVoltage , device . ProductLifxColor1000 :", "commit_type": "add"}
{"commit_tokens": ["Add", "filtering", "options", "to", "select", "plugin", "at", "startup"], "add_tokens": "var fPLuginsFilter = flag . String ( \" \" , \" \" , \" \" ) plugins , err := ag . LoadPlugins ( * fPLuginsFilter )", "del_tokens": "plugins , err := ag . LoadPlugins ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "TestValidateRootKey", "validates", "presence", "of", "x509", "cert", "in", "root", ".", "json"], "add_tokens": "cert , err := LoadCertFromPEM ( pemBytes )", "del_tokens": "cert , err := loadCertFromPEM ( pemBytes )", "commit_type": "add"}
{"commit_tokens": ["updated", "to", "have", "a", "main", "for", "migrations", "to", "call", "to", "make", "the", "boilerplate", "easier"], "add_tokens": "\" \" \" \" func ( m * postgresMigrator ) DumpHistory ( writer io . Writer ) error { rows , err := m . db . Query ( m . historyQuery ( ) ) if err != nil { return err } for rows . Next ( ) { var n int var t time . Time err := rows . Scan ( & n , & t ) if err != nil { return err } fmt . Fprintf ( writer , \" \\n \" , n , t ) } if rows . Err ( ) != nil { return rows . Err ( ) } return nil } return fmt . Sprintf ( \" \" , //make it easier to port to other DB func ( m * postgresMigrator ) historyQuery ( ) string { return fmt . Sprintf ( \" \" , MIGRATION_TABLE ) }", "del_tokens": "return fmt . Sprintf ( \" \" ,", "commit_type": "update"}
{"commit_tokens": ["Use", "new", "for", "more", "concise", "code"], "add_tokens": "user := new ( User ) err := resp . Data ( user )", "del_tokens": "var user User err := resp . Data ( & user )", "commit_type": "use"}
{"commit_tokens": ["Improve", "short", "names", "for", "logs"], "add_tokens": "{ Include : [ ] string { \" \" , \" \" , \" \" , \" \" } } , expected := [ ] string { \" \" , \" \" , \" \" } got := c . WatchPaths ( ) if ! reflect . DeepEqual ( got , expected ) { t . Errorf ( \" \" , expected , got )", "del_tokens": "{ Include : [ ] string { \" \" , \" \" , \" \" , \" \" } } , if ! reflect . DeepEqual ( c . WatchPaths ( ) , [ ] string { \" \" , \" \" , \" \" } ) { t . Fail ( )", "commit_type": "improve"}
{"commit_tokens": ["Make", "logging", "of", "collector", "executions", "less", "verbose", "."], "add_tokens": "log . Errorf ( \" \" , name , duration . Seconds ( ) , err ) log . Debugf ( \" \" , name , duration . Seconds ( ) )", "del_tokens": "log . Infof ( \" \" , name , duration . Seconds ( ) , err ) log . Infof ( \" \" , name , duration . Seconds ( ) )", "commit_type": "make"}
{"commit_tokens": ["fix", "hard", "coded", "cache", "limit"], "add_tokens": "cache = lru . New ( SelectorCacheMaxEntries )", "del_tokens": "cache = lru . New ( 50 )", "commit_type": "fix"}
{"commit_tokens": ["fix", "Readdir", "behaviour", "for", "n", ">", "0", "fix", "RemoveAll"], "add_tokens": "\" \" sort . Sort ( filesSorter ( files ) ) type filesSorter [ ] File // implement sort.Interface for []File func ( s filesSorter ) Len ( ) int { return len ( s ) } func ( s filesSorter ) Swap ( i , j int ) { s [ i ] , s [ j ] = s [ j ] , s [ i ] } func ( s filesSorter ) Less ( i , j int ) bool { return s [ i ] . Name ( ) < s [ j ] . Name ( ) } if parent == nil { log . Fatal ( \" \" , f . Name ( ) , \" \" ) } err := m . lockfreeMkdir ( pdir , 0777 ) m . lock ( ) m . unRegisterWithParent ( path ) m . unlock ( )", "del_tokens": "var err error err = m . lockfreeMkdir ( pdir , 0777 ) m . unRegisterWithParent ( p )", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "coded", "related", "code", ";", "fix", "compile", "errors"], "add_tokens": "// The file is consistent. return nil , NewIndexFormatTooNewError ( genInput . DataInput , version , FORMAT_SEGMENTS_GEN_CURRENT , FORMAT_SEGMENTS_GEN_CURRENT ) if format == CODEC_MAGIC { CheckHeaderNoMagic ( input . DataInput , \" \" , VERSION_40 , VERSION_40 ) method := CodecForName ( input . ReadString ( ) )", "del_tokens": "return nil , & CorruptIndexError { fmt . Sprintf ( \" \" , genInput , version , FORMAT_SEGMENTS_GEN_CURRENT , FORMAT_SEGMENTS_GEN_CURRENT ) } if format == codec . CODEC_MAGIC { codec . CheckHeaderNoMagic ( input , \" \" , VERSION_40 , VERSION_40 ) method := codec . ForName ( input . ReadString ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", ":", "committ", "-", ">", "commit"], "add_tokens": "return fmt . Errorf ( \" \" , err )", "del_tokens": "return fmt . Errorf ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["add", "helper", "for", "sparse", "to", "normal", "conversion"], "add_tokens": "h . toNormalIfSparseTooBig ( ) h . toNormalIfSparseTooBig ( ) func ( h * HyperLogLogPlus ) toNormalIfSparseTooBig ( ) { if uint32 ( len ( h . tmpSet ) ) * 100 > h . m { h . mergeSparse ( ) if uint32 ( h . sparseList . Len ( ) ) > h . m { h . toNormal ( ) } } }", "del_tokens": "if uint32 ( len ( h . tmpSet ) ) * 100 > h . m { h . mergeSparse ( ) if uint32 ( h . sparseList . Len ( ) ) > h . m { h . toNormal ( ) } } if uint32 ( len ( h . tmpSet ) ) * 100 > h . m { h . mergeSparse ( ) if uint32 ( h . sparseList . Len ( ) ) > h . m { h . toNormal ( ) } }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "notifications"], "add_tokens": "\" \" listenerCallbacks map [ string ] func ( ... string )", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "new", "New", "method", "to", "the", "Interface"], "add_tokens": "\" \" \" \" // New creates and initalizes a new Set interface. It accepts a variable // number of arguments to populate the initial set. If nothing is passed a // zero size Set based on the struct is created. func ( s * set ) New ( items ... interface { } ) Interface { return NewNonTS ( items ... ) }", "del_tokens": "\" \" \" \"", "commit_type": "add"}
{"commit_tokens": ["made", "Exactly", "not", "panic", "on", "nils"], "add_tokens": "return Fail ( t , \" \" , \" \" , aType , bType )", "del_tokens": "return Fail ( t , \" \" , \" \" , aType . Name ( ) , bType . Name ( ) )", "commit_type": "make"}
{"commit_tokens": ["Allow", "relative", "paths", "to", "any", "path", "inside", "the", "main", "log", "dir"], "add_tokens": "// Change how the link name is generated based on where the // target location is. if the location is directly underneath // the main filename's parent directory, then we create a // symlink with a relative path linkDir := filepath . Dir ( rl . linkName ) baseDir := filepath . Dir ( filename ) if strings . Contains ( rl . linkName , baseDir ) { tmp , err := filepath . Rel ( linkDir , filename ) if err != nil { return errors . Wrapf ( err , `failed to evaluate relative path from %#v to %#v` , baseDir , rl . linkName ) } linkDest = tmp // the directory where rl.linkName should be created must exist _ , err := os . Stat ( linkDir ) if err != nil { // Assume err != nil means the directory doesn't exist if err := os . MkdirAll ( linkDir , 0755 ) ; err != nil { return errors . Wrapf ( err , `failed to create directory %s` , linkDir ) } }", "del_tokens": "if filepath . Dir ( rl . linkName ) == filepath . Dir ( filename ) { linkDest = filepath . Base ( filename )", "commit_type": "allow"}
{"commit_tokens": ["move", "validation", "to", "httpkit", "/", "validate"], "add_tokens": "\" \" if err := validate . FormatOf ( f . Path , f . In , f . Format , val . ( string ) , f . KnownFormats ) ; err != nil {", "del_tokens": "\" \" if err := validation . FormatOf ( f . Path , f . In , f . Format , val . ( string ) , f . KnownFormats ) ; err != nil {", "commit_type": "move"}
{"commit_tokens": ["use", "tagged", "literals", "for", "struct", "initializations", "."], "add_tokens": "record := make ( map [ string ] interface { } ) record [ \" \" ] = uuidString record [ \" \" ] = now record [ \" \" ] = l LogID : \" \" , InsertID : uuidString , Time : now , Record : record ,", "del_tokens": "\" \" , uuidString , now , map [ string ] interface { } { \" \" : uuidString , \" \" : now , \" \" : l , } ,", "commit_type": "use"}
{"commit_tokens": ["removed", "pop", "as", "a", "dependency"], "add_tokens": "type interfacer interface { Interface ( ) interface { } } if dv , ok := i . ( interfacer ) ; ok { return dv . Interface ( )", "del_tokens": "\" \" if dv , ok := i . ( nulls . String ) ; ok { return dv . String", "commit_type": "remove"}
{"commit_tokens": ["Remove", "usage", "of", "BufferStorage", "for", "private", "responses", ".", "Content", "is", "sent", "now", "directly", "to", "http", ".", "ResponseWriter"], "add_tokens": "func getCacheableStatus ( req * http . Request , response * Response , config * Config ) ( bool , time . Time ) { // err means there was an error parsing headers // Just ignore them and make response not cacheable return false , time . Time { } isPublic := len ( reasonsNotToCache ) == 0 if expiration . Before ( time . Now ( ) ) { expiration = time . Now ( ) . Add ( time . Duration ( 5 ) * time . Minute ) } if ! isPublic { return false , expiration return false , expiration return true , expiration", "del_tokens": "func getCacheableStatus ( req * http . Request , response * Response , config * Config ) ( bool , time . Time , error ) { return false , time . Now ( ) , err canBeStored := len ( reasonsNotToCache ) == 0 if ! canBeStored { return false , time . Now ( ) , nil return false , time . Now ( ) , nil return expiration . After ( time . Now ( ) . UTC ( ) ) , expiration , nil", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "bucket", ".", "addObject", "."], "add_tokens": "\" \" // A storage.Object representing metadata for this object. Never changes. metadata * storage . Object // A slice of objects compared by name. type objectSlice [ ] object func ( s objectSlice ) Len ( ) int func ( s objectSlice ) Less ( i , j int ) bool func ( s objectSlice ) Swap ( i , j int ) // INVARIANT: Strictly increasing. objects objectSlice // GUARDED_BY(mu) // Create an object struct for the given attributes and contents. // // EXCLUSIVE_LOCKS_REQUIRED(b.mu) func ( b * bucket ) mintObject ( attrs * storage . ObjectAttrs , contents [ ] byte ) object func ( b * bucket ) addObject ( attrs * storage . ObjectAttrs , contents [ ] byte ) * storage . Object { b . mu . Lock ( ) defer b . mu . Unlock ( ) // Create an object record from the given attributes. var o object = b . mintObject ( attrs , contents ) // Add it to our list of object. b . objects = append ( b . objects , o ) sort . Sort ( b . objects ) return o . metadata", "del_tokens": "// The attributes with which this object was created. These never change. attrs * storage . ObjectAttrs // INVARIANT: Strictly increasing by object.attrs.Name. objects [ ] object // GUARDED_BY(mu) func ( b * bucket ) addObject ( attrs * storage . ObjectAttrs , contents [ ] byte ) * storage . Object { panic ( \" \" ) return nil", "commit_type": "implement"}
{"commit_tokens": ["Fix", "NATSRequester", "to", "connect", "to", "right", "URL"], "add_tokens": "conn , err := nats . Connect ( n . URL )", "del_tokens": "conn , err := nats . Connect ( nats . DefaultURL )", "commit_type": "fix"}
{"commit_tokens": ["use", "golang", ".", "org", "/", "x", "/", "sys", "/", "unix", "for", "dup2"], "add_tokens": "\" \" if err := unix . Dup2 ( int ( f . file . Fd ( ) ) , fd ) ; err != nil {", "del_tokens": "if err := syscall . Dup2 ( int ( f . file . Fd ( ) ) , fd ) ; err != nil {", "commit_type": "use"}
{"commit_tokens": ["Add", "some", "testing", "to", "mux"], "add_tokens": "w . WriteHeader ( http . StatusInternalServerError )", "del_tokens": "w . WriteHeader ( http . StatusInternalServerError )", "commit_type": "add"}
{"commit_tokens": ["add", "delete", "-", "repo", "and", "test"], "add_tokens": "if r . Method != \" \" { t . Fatalf ( \" \\n \" , r . Method ) }", "del_tokens": "\" \" fmt . Printf ( \" \\n \" , r . URL . Path )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "go", "1", "and", "avoid", "exporting", "constants"], "add_tokens": "\" \" \" \" \" \" fmt . Printf ( \" \\n \" , err . Error ( ) )", "del_tokens": "\" \" \" \" fmt . Printf ( \" \\n \" , err . String ( ) )", "commit_type": "update"}
{"commit_tokens": ["fix", "whine", "from", "go", ".", "tip"], "add_tokens": "t . Errorf ( \" \" , i , res , tc . Want . Response ) t . Errorf ( \" \\n \\n \" , i , res , tc . Want . Response )", "del_tokens": "t . Errorf ( \" \" , i , res , tc . Want . Response ) t . Errorf ( \" \\n \\n \" , i , res , tc . Want . Response )", "commit_type": "fix"}
{"commit_tokens": ["update", "messages", "and", "add", "some", "new", "code", "around", "handling", "/", "creating", "messages"], "add_tokens": "\" \" routes RoutingTable network * swarm . Swarm listeners map [ uint64 ] chan swarm . Message listenLock sync . RWMutex // Read in all messages from swarm and handle them appropriately // NOTE: this function is just a quick sketch for { select { case mes := <- dht . network . Chan . Incoming : // Unmarshal message dht . listenLock . RLock ( ) ch , ok := dht . listeners [ id ] dht . listenLock . RUnlock ( ) if ok { // Send message to waiting goroutine ch <- mes } //case closeChan: or something } } // Register a handler for a specific message ID, used for getting replies // to certain messages (i.e. response to a GET_VALUE message) func ( dht * IpfsDHT ) ListenFor ( mesid uint64 ) <- chan swarm . Message { lchan := make ( chan swarm . Message ) dht . listenLock . Lock ( ) dht . listeners [ mesid ] = lchan dht . listenLock . Unlock ( ) return lchan }", "del_tokens": "routes RoutingTable network * swarm . Swarm", "commit_type": "update"}
{"commit_tokens": ["Add", "nullable", "types", "and", "fix", "Query", "/", "EC2", "serialization", "."], "add_tokens": "case StringValue : if casted != nil { v . Set ( name , * casted ) case BooleanValue : if casted != nil { if * casted { v . Set ( name , \" \" ) } else { v . Set ( name , \" \" ) }", "del_tokens": "case string : if casted != \" \" { v . Set ( name , casted ) case bool : if casted { v . Set ( name , \" \" )", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "of", "another", "comma", "added"], "add_tokens": "if isNotFirst { stream . WriteMore ( ) } }", "del_tokens": "if isNotFirst { stream . WriteMore ( ) } }", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "helpful", "data", "in", "the", "error", "message"], "add_tokens": "\" \" return errors . New ( \" \" + strconv . Itoa ( sc . maxLength ) ) return errors . New ( \" \" + strconv . Itoa ( sc . minLength ) ) switch sc . format {", "del_tokens": "return errors . New ( \" \" ) return errors . New ( \" \" ) switch sc . format {", "commit_type": "add"}
{"commit_tokens": ["Added", "bypass", "writer", "which", "allows", "data", "to", "be", "written", "to", "the", "underlying", "output", "."], "add_tokens": "for _ , f := range [ ] string { \" \" , \" \" } { for i := 0 ; i <= 50 ; i ++ { fmt . Fprintf ( writer , \" \\n \" , f , i , 50 ) time . Sleep ( time . Millisecond * 25 ) } fmt . Fprintf ( writer . Bypass ( ) , \" \\n \" , f )", "del_tokens": "for i := 0 ; i <= 100 ; i ++ { fmt . Fprintf ( writer , \" \\n \" , i , 100 ) time . Sleep ( time . Millisecond * 5 )", "commit_type": "add"}
{"commit_tokens": ["add", "IP", "list", "support", "for", "TCP", "transport"], "add_tokens": "\" \" count uint64 if len ( opts . IPs ) > 0 { count := atomic . AddUint64 ( & tr . count , 1 ) _ , sport , err := net . SplitHostPort ( addr ) if err != nil { return nil , err } n := uint64 ( len ( opts . IPs ) ) addr = opts . IPs [ int ( count % n ) ] + \" \" + sport }", "del_tokens": "// count uint32 } func ( o * DialOptions ) getIP ( ) string { n := len ( o . IPs ) if n == 0 { return \" \" } return o . IPs [ int ( time . Now ( ) . Nanosecond ( ) ) % n ] // count := atomic.AddUint32(&o.count, 1) //return o.IPs[int(count)%n]", "commit_type": "add"}
{"commit_tokens": ["Allow", "custom", "http", ".", "RoundTripper"], "add_tokens": "// Transport allows the use of a custom round tripper. // If Transport is not of type `*http.Transport`, the `TLSConfig` property is not used. // Otherwise a `TLSConfig` property other than `nil` will overwrite the `TLSClientConfig` // property of `Transport`. Transport http . RoundTripper var httpTransport * http . Transport if config . Transport != nil { httpTransport , _ = config . Transport . ( * http . Transport ) } else { httpTransport = & http . Transport { } config . Transport = httpTransport } if config . TLSConfig != nil && httpTransport != nil { httpTransport . TLSClientConfig = config . TLSConfig Transport : config . Transport ,", "del_tokens": "transport := & http . Transport { } if config . TLSConfig != nil { transport . TLSClientConfig = config . TLSConfig Transport : transport ,", "commit_type": "allow"}
{"commit_tokens": ["Made", "client", ".", "Do", "public", "."], "add_tokens": "// Execute a function on a memcached connection to the node owning key \"k\" // // Note that this automatically handles transient errors by replaying // your function on a \"not-my-vbucket\" error, so don't assume // your command will only be executed only once. func ( b * Bucket ) Do ( k string , f func ( mc * memcached . Client , vb uint16 ) error ) error { return b . Do ( k , func ( mc * memcached . Client , vb uint16 ) error { return b . Do ( k , func ( mc * memcached . Client , vb uint16 ) error { return b . Do ( k , func ( mc * memcached . Client , vb uint16 ) error {", "del_tokens": "func ( b * Bucket ) do ( k string , f func ( mc * memcached . Client , vb uint16 ) error ) error { return b . do ( k , func ( mc * memcached . Client , vb uint16 ) error { return b . do ( k , func ( mc * memcached . Client , vb uint16 ) error { return b . do ( k , func ( mc * memcached . Client , vb uint16 ) error {", "commit_type": "make"}
{"commit_tokens": ["Add", "WithInversionCache", "and", "use", "pointer", "methods"], "add_tokens": "inversionCache bool maxGoroutines : 384 , minSplitSize : - 1 , fastOneParity : false , inversionCache : true , // WithInversionCache allows to control the inversion cache. // This will cache reconstruction matrices so they can be reused. // Enabled by default. func WithInversionCache ( enabled bool ) Option { return func ( o * options ) { o . inversionCache = enabled } }", "del_tokens": "maxGoroutines : 384 , minSplitSize : - 1 , fastOneParity : false ,", "commit_type": "add"}
{"commit_tokens": ["Add", "NoSuchPostError", "for", "Update", "function"], "add_tokens": "if reqErr , ok := err . ( * pc . RequestError ) ; ok { switch reqErr . Resp . StatusCode { case 404 : return & result , NoSuchPostError { uid } case 409 : return & result , ConflictError { uid } } type NoSuchPostError struct { UID string } func ( e NoSuchPostError ) Error ( ) string { return fmt . Sprintf ( \" \" , e . UID ) } UID string return fmt . Sprintf ( \" \" , e . UID )", "del_tokens": "if reqErr , ok := err . ( * pc . RequestError ) ; ok && reqErr . Resp . StatusCode == 409 { return & result , ConflictError { uid } uid string return fmt . Sprintf ( \" \" , e . uid )", "commit_type": "add"}
{"commit_tokens": ["Fix", "example", "local", "-", "up", "-", "cluster", ".", "sh"], "add_tokens": "glog . Fatalf ( \" \" , err )", "del_tokens": "glog . Errorf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["fix", "erroneous", "member", "assignment", "bug", "from", "d5bbf59"], "add_tokens": "func ( s * reader ) nextMsgLen ( ) ( int , error ) { n , err := ReadLen ( s . R , s . lbuf ) if err != nil { return 0 , err } s . next = n return s . next , nil", "del_tokens": "func ( s * reader ) nextMsgLen ( ) ( n int , err error ) { s . next , err = ReadLen ( s . R , s . lbuf ) return s . next , err", "commit_type": "fix"}
{"commit_tokens": ["Add", "application", "/", "javascript", "as", "text", "mime", "type"], "add_tokens": "case \" \" , \" \" , \" \" , \" \" :", "del_tokens": "case \" \" : return true case \" \" : return true case \" \" :", "commit_type": "add"}
{"commit_tokens": ["Use", "tags", "for", "key", "names"], "add_tokens": "// []string with kv[0] = \"key\" and > kv[1] = value\". func getFieldByTagName ( structValue reflect . Value , name string ) reflect . Value { field := reflect . Value { } structType := structValue . Type ( ) for i := 0 ; i < structValue . NumField ( ) ; i ++ { if n , ok := nameFromTags ( structType . Field ( i ) ) ; ok { stracer . Traceln ( \" \" , n , name ) if n == name { field = structValue . Field ( i ) } } } return field } // putInStruct does not return error for field not found. stracer . Traceln ( \" \" , kv ) // Field not found, try to get it by tags. if ! fieldValue . IsValid ( ) { fieldValue = getFieldByTagName ( structValue , kv [ 0 ] ) }", "del_tokens": "// []string with \"key\" > kv[0] and \"value\" > kv[1]. stracer . Traceln ( \" \" , kv )", "commit_type": "use"}
{"commit_tokens": ["added", "Remove", "()", "its", "still", "stop", "-", "the", "-", "world", "though", "..."], "add_tokens": "f . grp . Add ( 1 ) // Remove will delete the specified stream after waiting for all // activity on it to stop (writer/readers closed). // Note that Remove also blocks calls to Get to prevent // the key from being requested while awaiting deletion. func ( c * Cache ) Remove ( key string ) error { c . mu . Lock ( ) defer c . mu . Unlock ( ) f , ok := c . files [ key ] delete ( c . files , key ) if ok { f . grp . Wait ( ) return os . Remove ( f . name ) } return nil } if err != nil { return nil , err } name : f . Name ( ) , } , nil defer f . grp . Done ( )", "del_tokens": "name : key , } , err", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "valid", "statements", "for", "SHOW"], "add_tokens": "return nil , newParseError ( tokstr ( tok , lit ) , [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , pos )", "del_tokens": "return nil , newParseError ( tokstr ( tok , lit ) , [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } , pos )", "commit_type": "add"}
{"commit_tokens": ["Use", "requirements", "in", "delete", "command"], "add_tokens": "func ( f Factory ) NewDelete ( ) * Delete {", "del_tokens": "func ( f Factory ) NewDelete ( ) Delete {", "commit_type": "use"}
{"commit_tokens": ["Fix", "crashes", "when", "resizing", "sub", "images"], "add_tokens": "raw := image . NewYCbCr ( image . Rect ( 0 , 0 , w * 2 , h * 2 ) , image . YCbCrSubsampleRatio420 ) dst := raw . SubImage ( image . Rect ( 7 , 7 , 7 + w , 7 + h ) ) ydst := image . NewYCbCr ( image . Rect ( 0 , 0 , w * 2 , h * 2 ) , image . YCbCrSubsampleRatio444 ) dst := ydst . SubImage ( image . Rect ( 7 , 7 , 7 + w , 7 + h ) )", "del_tokens": "dst := image . Image ( image . NewYCbCr ( image . Rect ( 0 , 0 , w , h ) , image . YCbCrSubsampleRatio420 ) ) dst := image . Image ( image . NewYCbCr ( image . Rect ( 0 , 0 , w , h ) , image . YCbCrSubsampleRatio444 ) )", "commit_type": "fix"}
{"commit_tokens": ["fix", "wrong", "type", "for", "formatting"], "add_tokens": "t . Fatalf ( \" \" , out . Boss . HiredAt . IsZero ( ) )", "del_tokens": "t . Fatalf ( \" \" , out . Boss . HiredAt )", "commit_type": "fix"}
{"commit_tokens": ["add", "glip_bot_webhooks_list", "recreate", "by", "URL"], "add_tokens": "if opts . Recreate == subscription . Id || opts . Recreate == subscription . DeliveryMode . Address {", "del_tokens": "if subscription . Id == opts . Recreate {", "commit_type": "add"}
{"commit_tokens": ["Use", "html", "/", "template", "instead", "of", "printf", "for", "auth", "page"], "add_tokens": "\" \" tmpl * template . Template tmpl : template . Must ( template . New ( \" \" ) . Parse ( string ( MustAsset ( \" \" ) ) ) ) , if err := ga . tmpl . Execute ( rw , struct { ClientId string } { ClientId : ga . config . ClientId } ) ; err != nil { http . Error ( rw , fmt . Sprintf ( \" \" , err ) , http . StatusInternalServerError ) }", "del_tokens": "fmt . Fprintf ( rw , string ( MustAsset ( \" \" ) ) , ga . config . ClientId )", "commit_type": "use"}
{"commit_tokens": ["Add", "import", "and", "fix", "return", "type"], "add_tokens": "\" \" func LevelFromString ( levelStr string ) Level {", "del_tokens": "func LevelFromString ( levelStr string ) int {", "commit_type": "add"}
{"commit_tokens": ["Add", "table", ".", "SetAutoFormatHeaders", "(", "bool", ")", "to", "make", "header", "formatting", "optional", "."], "add_tokens": "autoFmt bool autoFmt : true , // Turn header autoformatting on/off. Default is on (true). func ( t * Table ) SetAutoFormatHeaders ( auto bool ) { t . autoFmt = auto } h := t . headers [ i ] if t . autoFmt { h = Title ( h ) } Pad ( h , SPACE , v ) , f := t . footers [ i ] if t . autoFmt { f = Title ( f ) } Pad ( f , SPACE , v ) ,", "del_tokens": "Pad ( Title ( t . headers [ i ] ) , SPACE , v ) , Pad ( Title ( t . footers [ i ] ) , SPACE , v ) ,", "commit_type": "add"}
{"commit_tokens": ["Created", "Export", "and", "Import", "functions"], "add_tokens": "// TODO: Download in best quality HasBestiesMedia int `json:\"has_besties_media\"`", "del_tokens": "HasBestiesMedia bool `json:\"has_besties_media\"`", "commit_type": "create"}
{"commit_tokens": ["Fixing", "minor", "logic", "issue", "with", "certificate", "caching"], "add_tokens": "if err := m . load ( ) ; err == nil { if b == nil { break } if len ( der ) == 0 { return ErrInvalidCertificate }", "del_tokens": "err := m . load ( ) if err == nil {", "commit_type": "fix"}
{"commit_tokens": ["Upgrade", "to", "redis", ".", "v5"], "add_tokens": "redis \" \"", "del_tokens": "redis \" \"", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "sortorder", "package", "-", "doc", "snafu", "."], "add_tokens": "// Currently, it only implements so-called \"natural order\", where integers // embedded in strings are compared by value.", "del_tokens": "// Currently, it only implements so-called \"natural order\", where strings // embedded in integers are compared by value.", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "default", "values", "in", "struct", "tags"], "add_tokens": "defaultVal string // default value for this option, only if provided as a struct tag defaultVal , hasDefault := field . Tag . Lookup ( \" \" ) if hasDefault { spec . defaultVal = defaultVal } if hasDefault { errs = append ( errs , fmt . Sprintf ( \" \" , t . Name ( ) , field . Name ) ) return false } if spec . multiple && hasDefault { errs = append ( errs , fmt . Sprintf ( \" \" , t . Name ( ) , field . Name ) ) return false } // fill in defaults and check that all the required args were provided if wasPresent [ spec ] { continue } name := spec . long if ! spec . positional { name = \" \" + spec . long } if spec . required { if spec . defaultVal != \" \" { err := scalar . ParseValue ( p . val ( spec . dest ) , spec . defaultVal ) if err != nil { return fmt . Errorf ( \" \" , name , err ) } }", "del_tokens": "// finally check that all the required args were provided if spec . required && ! wasPresent [ spec ] { name := spec . long if ! spec . positional { name = \" \" + spec . long }", "commit_type": "add"}
{"commit_tokens": ["Use", "https", "for", "badge", "."], "add_tokens": "\" \" : \" \" , // append db to avoid stemming to 'red' \" \" : \" \" ,", "del_tokens": "\" \" : \" \" ,", "commit_type": "use"}
{"commit_tokens": ["change", "Channels", ".", "Find", "to", "return", "root", "when", "no", "arguments", "passed"], "add_tokens": "return root", "del_tokens": "return nil", "commit_type": "change"}
{"commit_tokens": ["Added", "stub", "clock", "implementations", "."], "add_tokens": "import ( \" \" \" \" ) type realClock struct { } func ( c realClock ) Now ( ) time . Time { return time . Now ( ) } func RealClock ( ) Clock { return realClock { } } func ( sc * SimulatedClock ) Now ( ) time . Time { log . Fatal ( \" \" ) return time . Time { } } func ( sc * SimulatedClock ) AdvanceTime ( d time . Duration ) { log . Fatal ( \" \" ) }", "del_tokens": "import \" \" func RealClock ( ) Clock func ( sc * SimulatedClock ) AdvanceTime ( d time . Duration )", "commit_type": "add"}
{"commit_tokens": ["Added", "another", "convenience", "function", ":", "AllocAndCopy"], "add_tokens": "import ( \" \" \" \" ) // AllocAndCopy abstracts away the common pattern of allocating and then copying a Go slice to the GPU func AllocAndCopy ( p unsafe . Pointer , bytesize int64 ) ( DevicePtr , error ) { if bytesize == 0 { return 0 , errors . Wrapf ( InvalidValue , \" \" ) } var d C . CUdeviceptr if err := result ( C . cuAllocAndCopy ( & d , p , C . size_t ( bytesize ) ) ) ; err != nil { return 0 , errors . Wrapf ( err , \" \" ) } return DevicePtr ( d ) , nil }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["added", "option", "for", "encoding", "payload", "as", "base64"], "add_tokens": "\" \" \" \" URL string Connection * http . Client Headers map [ string ] string EncodingBase64 bool msg := c . processEvent ( line ) msg := c . processEvent ( line ) func ( c * Client ) processEvent ( msg [ ] byte ) * Event { if len ( e . Data ) > 0 && c . EncodingBase64 { var buf [ ] byte _ , err := base64 . StdEncoding . Decode ( buf , e . Data ) if err != nil { log . Println ( err ) } e . Data = buf }", "del_tokens": "URL string Connection * http . Client Headers map [ string ] string msg := processEvent ( line ) msg := processEvent ( line ) func processEvent ( msg [ ] byte ) * Event {", "commit_type": "add"}
{"commit_tokens": ["Add", "decoding", "tests", "make", "conn", "tests", "compile"], "add_tokens": "\" \" return nil , fmt . Errorf ( \" \" , err . Error ( ) ) return nil , fmt . Errorf ( \" \" , err . Error ( ) ) err = bmux . AllBasesMux ( ) . Decoder ( in ) . Decode ( out [ : ] )", "del_tokens": "return nil , err return nil , err err = bmux . AllBasesMux ( ) . Decoder ( in ) . Decode ( out )", "commit_type": "add"}
{"commit_tokens": ["fixed", "oauth", "login", "redirect", "when", "using", "app", "sub", "url"], "add_tokens": "ctx . Redirect ( setting . AppSubUrl + \" \" )", "del_tokens": "ctx . Redirect ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "merge", "of", "existing", "array", "to", "empty", "array", "(", "was", "resulting", "in", "null", "now", "results", "in", "empty", "array", ")", "."], "add_tokens": "newAry := [ ] * lazyNode { }", "del_tokens": "var newAry [ ] * lazyNode", "commit_type": "fix"}
{"commit_tokens": ["Improve", "panic", "messages", "a", "bit"], "add_tokens": "log . Panicf ( \" \" , len ( P ) ) log . Panicf ( \" \" , 16 * 8 , m )", "del_tokens": "log . Panicf ( \" \" , len ( P ) ) log . Panicf ( \" \" , 16 * 8 )", "commit_type": "improve"}
{"commit_tokens": ["changed", "the", "filename", "which", "is", "send", "to", "the", "server", "."], "add_tokens": "\" \" fileField := request . FileField { FieldName : key , FileName : filepath . Base ( filename ) , File : file }", "del_tokens": "fileField := request . FileField { key , filename , file }", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "with", "new", "changes", "loading", "models"], "add_tokens": "if err1 := model . convertOldFormat ( filename ) ; err1 != nil { return model , err1 return model , nil", "del_tokens": "if err = model . convertOldFormat ( filename ) ; err != nil { return model , err return nil , err", "commit_type": "fix"}
{"commit_tokens": ["fix", "int", "-", ">", "int64"], "add_tokens": "func LastCommitGeneration ( files [ ] string ) int64 { return int64 ( - 1 ) max := int64 ( - 1 ) func GenerationFromSegmentsFileName ( fileName string ) int64 { return int64 ( 0 )", "del_tokens": "func LastCommitGeneration ( files [ ] string ) int { return - 1 max := - 1 func GenerationFromSegmentsFileName ( fileName string ) int { return 0", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "genericExec", "function", "and", "renamed", "buildSQL", "to", "buildSelectSQL"], "add_tokens": "return genericExec ( store , stmt ) } func genericExec ( store Store , stmt string ) error {", "del_tokens": "if err != nil { Log ( fmt . Sprintf ( \" \" , err ) ) }", "commit_type": "add"}
{"commit_tokens": ["improve", "request", "logging", "(", "closer", "to", "Apache", "Common", "Log", ")"], "add_tokens": "flagSet . Bool ( \" \" , true , \" \" ) server := & http . Server { Handler : LoggingHandler ( os . Stdout , oauthproxy , opts . RequestLogging ) }", "del_tokens": "server := & http . Server { Handler : oauthproxy }", "commit_type": "improve"}
{"commit_tokens": ["Changed", "logrus", "import", "to", "lower", "-", "case"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "change"}
{"commit_tokens": ["Change", "how", "node", "ids", "are", "chosen"], "add_tokens": "if mask == math . MaxUint64 { id = ( uint64 ( idSource . Int63 ( ) ) << 63 ) | uint64 ( idSource . Int63 ( ) ) } else { id = uint64 ( idSource . Int63 ( ) ) & mask } if id == 0 { id = 1 } sid := id L : for _ , n := range others { if n . id == id { id ++ if id == sid { // This shouldn't happen because the top of the func should've // caught that the ID space was used up; but, just in case. return nil , fmt . Errorf ( \" \" , b . idBits , len ( others ) ) } if id > mask { id = 1 goto L", "del_tokens": "for id == 0 { if mask == math . MaxUint64 { id = ( uint64 ( idSource . Int63 ( ) ) << 63 ) | uint64 ( idSource . Int63 ( ) ) } else { id = uint64 ( idSource . Int63 ( ) ) & mask } for _ , n := range others { if n . id == id { id = 0 break", "commit_type": "change"}
{"commit_tokens": ["Make", "patch", "a", "type", "with", "two", "values", ":", "none", "and", "bsdiff"], "add_tokens": "type PatchKind string const ( PatchRaw PatchKind = \" \" PatchBSDIFF PatchKind = \" \" ) Available bool `json:\"available\"` DownloadURL string `json:\"download_url\"` Checksum string `json:\"checksum\"` Signature string `json:\"signature\"` Patch PatchKind `json:\"patch_type\"` Version string `json:\"version\"` Release Release `json:\"release\"`", "del_tokens": "Available bool `json:\"available\"` DownloadURL string `json:\"download_url\"` Checksum string `json:\"checksum\"` Signature string `json:\"signature\"` PatchType string `json:\"patch_type\"` Version string `json:\"version\"` Release Release `json:\"release\"`", "commit_type": "make"}
{"commit_tokens": ["Fix", "consumer", "receiving", "no", "complete", "messages", "."], "add_tokens": "var fetchSize int32 = 1024 request . MaxWaitTime = 1000 request . AddBlock ( c . topic , c . partition , c . offset , fetchSize ) // We got no messages. If we got a trailing one then we need to ask for more data. // Otherwise we just poll again and wait for one to be produced... if block . MsgSet . PartialTrailingMessage { fetchSize *= 2 } select { case <- c . stopper : close ( c . messages ) close ( c . errors ) close ( c . done ) return default : continue }", "del_tokens": "request . MaxWaitTime = 10000 request . AddBlock ( c . topic , c . partition , c . offset , 1024 ) panic ( \" \" ) / * If we timed out waiting for a new message we should just poll again . However , if we got part of a message but our maxBytes was too small ( hard - coded 1024 at the moment ) we should increase that and ask again . If we just poll with the same size immediately we 'l l end up in an infinite loop DOSing the broker . . . * /", "commit_type": "fix"}
{"commit_tokens": ["improve", "test", "coverage", "for", "agentPoller"], "add_tokens": "Role string `json:\"role\"` CPUsTotal float64 `json:\"system/cpus_total\"` // if a . AgentIP == \" \" { // allows us to mock this during testing if a . AgentIP , err = a . getIP ( ) ; err != nil { log . Error ( err ) } func getLabelsByContainerID ( containerID string , frameworks [ ] frameworkInfo ) map [ string ] string { labels := map [ string ] string { } return labels return labels", "del_tokens": "CPUTotal float64 `json:\"system/cpu_total\"` if a . AgentIP , err = a . getIP ( ) ; err != nil { log . Error ( err ) func getLabelsByContainerID ( containerID string , frameworks [ ] frameworkInfo ) ( labels map [ string ] string ) { return return", "commit_type": "improve"}
{"commit_tokens": ["Allow", "comments", "in", "rules", "for", "easier", "debugging"], "add_tokens": "// // TODO - Review this... why is this even necessary? // case matchedRule.AppUrlScheme != \"\": // renderInline = false // if !matchedRule.NoAppStoreRedirect { // destination = matchedRule.AppStoreUrl // } else { // destination = matchedRule.Destination // } glog . Infoln ( \" \" , matchedRule , destination )", "del_tokens": "// TODO - Review this... why is this even necessary? case matchedRule . AppUrlScheme != \" \" : renderInline = false if ! matchedRule . NoAppStoreRedirect { destination = matchedRule . AppStoreUrl } else { destination = matchedRule . Destination }", "commit_type": "allow"}
{"commit_tokens": ["Use", "client", ".", "SystemAPIClient", "instead", "of", "APIClient"], "add_tokens": "func Monitor ( ctx context . Context , cli client . SystemAPIClient , options types . EventsOptions , fun func ( m eventtypes . Message ) ) chan error { func MonitorWithHandler ( ctx context . Context , cli client . SystemAPIClient , options types . EventsOptions , handler * Handler ) chan error { func monitorEvents ( ctx context . Context , cli client . SystemAPIClient , options types . EventsOptions , started chan struct { } , eventChan chan eventtypes . Message , errChan chan error ) {", "del_tokens": "func Monitor ( ctx context . Context , cli client . APIClient , options types . EventsOptions , fun func ( m eventtypes . Message ) ) chan error { func MonitorWithHandler ( ctx context . Context , cli client . APIClient , options types . EventsOptions , handler * Handler ) chan error { func monitorEvents ( ctx context . Context , cli client . APIClient , options types . EventsOptions , started chan struct { } , eventChan chan eventtypes . Message , errChan chan error ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "alias", "docs", "+", "notes"], "add_tokens": "// to structs. NOTE: when returning an error the tag returned in FieldError will be // the alias tag unless the dive tag is part of the alias; everything after the // dive tag is not reported as the alias tag. Also the ActualTag in the before case // will be the actual tag within the alias that failed.", "del_tokens": "// to structs.", "commit_type": "add"}
{"commit_tokens": ["Implement", "YaRPC", "connector", "part", "1"], "add_tokens": "// Bytes gets the bytes from a UUID func ( u UUID ) Bytes ( ) ( [ ] byte , error ) { // BytesToUUID creates a UUID from a byte slice func BytesToUUID ( bs [ ] byte ) ( UUID , error ) {", "del_tokens": "func ( u UUID ) bytes ( ) ( [ ] byte , error ) { func bytesToUUID ( bs [ ] byte ) ( UUID , error ) {", "commit_type": "implement"}
{"commit_tokens": ["adding", "ExecuteSystemCommand", "|", "refactored", "prepareCommand", "|", "Fixed", "tests"], "add_tokens": "cmd := prepareCommand ( [ ] string { command , \" \" , \" \" } , workingDirectory , logger1 , logger2 ) cmd := prepareCommand ( [ ] string { command , \" \" , \" \" } , workingDirectory , logger1 , logger2 )", "del_tokens": "cmd , err := prepareCommand ( [ ] string { command , \" \" , \" \" } , workingDirectory , logger1 , logger2 ) c . Assert ( err , Equals , nil ) cmd , err := prepareCommand ( [ ] string { command , \" \" , \" \" } , workingDirectory , logger1 , logger2 ) c . Assert ( err , Equals , nil )", "commit_type": "add"}
{"commit_tokens": ["Remove", "zkstart", "from", "Makefile", ";", "support", "task", "in", "ExecOnly", "mode"], "add_tokens": "Id string `json:\"id\"` Cmd * Cmd `json:\"cmd,omitempty\"` // If this is set to true then we only require id and command to be set ExecOnly bool `json:\"exec_only\"` Runs int `json:\"runs,omitempty\"`", "del_tokens": "Id string `json:\"id\"` Cmd * Cmd `json:\"cmd,omitempty\"` Runs int `json:\"runs,omitempty\"`", "commit_type": "remove"}
{"commit_tokens": ["remove", "host", "-", "local", "-", "ptp", "plugin"], "add_tokens": "ipConf , err := allocator . Get ( args . ContainerID )", "del_tokens": "\" \" var ipConf * types . IPConfig switch ipamConf . Type { case \" \" : ipConf , err = allocator . Get ( args . ContainerID ) case \" \" : ipConf , err = allocator . GetPtP ( args . ContainerID ) default : return errors . New ( \" \" ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "a", "double", "sha256", "hash", "method", "for", "supporting", "bitcoin"], "add_tokens": "DBL_SHA2_256 = 0x56 \" \" : SHA1 , \" \" : SHA2_256 , \" \" : SHA2_512 , \" \" : SHA3 , \" \" : BLAKE2B , \" \" : BLAKE2S , \" \" : DBL_SHA2_256 , SHA1 : \" \" , SHA2_256 : \" \" , SHA2_512 : \" \" , SHA3 : \" \" , BLAKE2B : \" \" , BLAKE2S : \" \" , DBL_SHA2_256 : \" \" , SHA1 : 20 , SHA2_256 : 32 , SHA2_512 : 64 , SHA3 : 64 , BLAKE2B : 64 , BLAKE2S : 32 , DBL_SHA2_256 : 32 ,", "del_tokens": "\" \" : SHA1 , \" \" : SHA2_256 , \" \" : SHA2_512 , \" \" : SHA3 , \" \" : BLAKE2B , \" \" : BLAKE2S , SHA1 : \" \" , SHA2_256 : \" \" , SHA2_512 : \" \" , SHA3 : \" \" , BLAKE2B : \" \" , BLAKE2S : \" \" , SHA1 : 20 , SHA2_256 : 32 , SHA2_512 : 64 , SHA3 : 64 , BLAKE2B : 64 , BLAKE2S : 32 ,", "commit_type": "add"}
{"commit_tokens": ["add", "date_format", "config", "option", "for", "file", "/", "multifile", "providers"], "add_tokens": "DateFormat string `json:\"date_format\"` // date format string(default: %04d%02d%02d) if opts . DateFormat == \" \" { opts . DateFormat = \" \" DateFormat : p . config . DateFormat ,", "del_tokens": "\" \" if opts . Filename == \" \" { _ , appName := filepath . Split ( os . Args [ 0 ] ) opts . Filename = appName + \" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "mutex", "as", "channels", "are", "*", "not", "*", "faster", ".", "Was", "I", "mad?"], "add_tokens": "\" \" mutex * sync . Mutex mutex : & sync . Mutex { } , c . mutex . Lock ( ) defer c . mutex . Unlock ( ) c . mutex . Lock ( ) defer c . mutex . Unlock ( ) return c . value", "del_tokens": "lock chan int lock : make ( chan int , 1 ) , c . lock <- 1 <- c . lock c . lock <- 1 val := c . value <- c . lock return val", "commit_type": "use"}
{"commit_tokens": ["Allow", "changing", "the", "tag", "name", "used", "for", "field", "aliases"], "add_tokens": "tag : \" \" , tag string alias := fieldAlias ( field , c . tag ) func fieldAlias ( field reflect . StructField , tagName string ) string { if tag := field . Tag . Get ( tagName ) ; tag != \" \" {", "del_tokens": "alias := fieldAlias ( field ) func fieldAlias ( field reflect . StructField ) string { if tag := field . Tag . Get ( \" \" ) ; tag != \" \" {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "reading", "the", "expiry", "time", "in", "seconds"], "add_tokens": "var tmp uint32 expiryTime = int64 ( int64 ( tmp ) * 1000 ) // If the byte was a expiry time flag, we need to reread a byte", "del_tokens": "// TODO use the expiry time var tmp int32 expiryTime = int64 ( tmp ) // TODO use the expiry time", "commit_type": "fix"}
{"commit_tokens": ["Improve", "idempotence", "check", "for", "consul", "service", "registration"], "add_tokens": "ID : \" \" , if found && addr == member . Addr . String ( ) { // Check if the associated service is available if service != nil { match := false services := state . NodeServices ( member . Name ) for id , _ := range services . Services { if id == service . ID { match = true } } if ! match { goto AFTER_CHECK } } AFTER_CHECK :", "del_tokens": "if found && addr == member . Addr . String ( ) && service == nil {", "commit_type": "improve"}
{"commit_tokens": ["make", "ugens", "/", "baseNode", "private"], "add_tokens": "if _ , isBase := s . ( * baseNode ) ; ! isBase { t . Fatalf ( \" \" )", "del_tokens": "if _ , isBase := s . ( * BaseNode ) ; ! isBase { t . Fatalf ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Add", "complex", "test", "and", "test", "name"], "add_tokens": "name string name : \" \" , name : \" \" , name : \" \" , name : \" \" , name : \" \" , name : \" \" , name : \" \" , { name : \" \" , data : `{\"tags\": [{\"list\": [{\"one\":\"pizza\"}]}]}` , get : \" \" , output : \" \" , } , name : \" \" , assert . Equal ( t , fixture . output , newO . Obj , \" \" , index + 1 , fixture . name , fixture )", "del_tokens": "assert . Equal ( t , fixture . output , newO . Obj , \" \" , index + 1 , fixture )", "commit_type": "add"}
{"commit_tokens": ["added", "ipv6", "link", "-", "local", "loopback"], "add_tokens": "\" \" // IP6LinkLocalLoopback is the ip6 link-local loopback multiaddr IP6LinkLocalLoopback = ma . StringCast ( \" \" ) b := m . Bytes ( ) // /ip4/127 prefix (_entire_ /8 is loopback...) if bytes . HasPrefix ( b , [ ] byte { 4 , 127 } ) { return true } // /ip6/::1 if IP6Loopback . Equal ( m ) || IP6LinkLocalLoopback . Equal ( m ) { return true } return false", "del_tokens": "return m . Equal ( IP4Loopback ) || m . Equal ( IP6Loopback )", "commit_type": "add"}
{"commit_tokens": ["Use", "lookup", "table", "in", "go", "-", "multibase", "now", "that", "it", "is", "supported", "."], "add_tokens": "baseStr , ok := mb . EncodingToStr [ base ] if ! ok { return baseStr", "del_tokens": "// FIXME: Use lookup tables when they are added to go-multibase switch base { case mb . Base58BTC : return \" \" default :", "commit_type": "use"}
{"commit_tokens": ["Add", "level", "option", "to", "scalar", "mercator", "projection"], "add_tokens": "Project func ( lat , lng float64 , level ... uint64 ) ( x , y uint64 ) Inverse func ( x , y uint64 , level ... uint64 ) ( lat , lng float64 ) func scalarMercatorProject ( lng , lat float64 , level ... uint64 ) ( x , y uint64 ) { l := ScalarMercator . Level if len ( level ) != 0 { l = level [ 0 ] } factor = 1 << l func scalarMercatorInverse ( x , y uint64 , level ... uint64 ) ( lng , lat float64 ) { l := ScalarMercator . Level if len ( level ) != 0 { l = level [ 0 ] } factor = 1 << l", "del_tokens": "Project func ( lat , lng float64 ) ( x , y uint64 ) Inverse func ( x , y uint64 ) ( lat , lng float64 ) func scalarMercatorProject ( lat , lng float64 ) ( x , y uint64 ) { factor = 1 << ScalarMercator . Level func scalarMercatorInverse ( x , y uint64 ) ( lat , lng float64 ) { factor = 1 << ScalarMercator . Level", "commit_type": "add"}
{"commit_tokens": ["Added", "page#Fill", "()", "function", "to", "clear", "and", "set", "text", "on", "fields"], "add_tokens": "Step ( \" \" , func ( ) { page . Find ( \" \" ) . Fill ( \" \" ) } ) Expect ( page . Find ( \" \" ) ) . To ( HaveAttribute ( \" \" , \" \" ) )", "del_tokens": "Expect ( page . Find ( \" \" ) ) . To ( HaveAttribute ( \" \" , \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["remove", "dependency", "on", "interface", "-", "conn"], "add_tokens": "ic \" \" // ConnSecurity is the interface that one can mix into a connection interface to // give it the security methods. type ConnSecurity interface { // LocalPeer returns our peer ID LocalPeer ( ) peer . ID // LocalPrivateKey returns our private key LocalPrivateKey ( ) ic . PrivKey // RemotePeer returns the peer ID of the remote peer. RemotePeer ( ) peer . ID // RemotePublicKey returns the public key of the remote peer. RemotePublicKey ( ) ic . PubKey } // ConnMultiaddrs is an interface mixin for connection types that provide multiaddr // addresses for the endpoints. type ConnMultiaddrs interface { // LocalMultiaddr returns the local Multiaddr associated // with this connection LocalMultiaddr ( ) ma . Multiaddr // RemoteMultiaddr returns the remote Multiaddr associated // with this connection RemoteMultiaddr ( ) ma . Multiaddr } io . Closer ConnSecurity ConnMultiaddrs", "del_tokens": "iconn \" \" iconn . PeerConn", "commit_type": "remove"}
{"commit_tokens": ["add", "function", "to", "override", "default", "percentiles", "and", "their", "labels"], "add_tokens": "// percentiles is a mapping from labels to desired percentiles to be // calculated by the MetricSystem percentiles map [ string ] float64 percentiles : map [ string ] float64 { \" \" : 0 , \" \" : .5 , \" \" : .75 , \" \" : .9 , \" \" : .95 , \" \" : .99 , \" \" : .999 , \" \" : .9999 , \" \" : 1 , } , // SpecifyPercentiles allows users to override the default collected // and reported percentiles. func ( ms * MetricSystem ) SpecifyPercentiles ( percentiles map [ string ] float64 ) { ms . percentiles = percentiles } totalSum := float64 ( 0 ) for label , p := range ms . percentiles {", "del_tokens": "labelToPercentile := map [ string ] float64 { \" \" : 0 , \" \" : .5 , \" \" : .75 , \" \" : .9 , \" \" : .95 , \" \" : .99 , \" \" : .999 , \" \" : .9999 , \" \" : 1 , } totalSum := float64 ( 0 ) for label , p := range labelToPercentile {", "commit_type": "add"}
{"commit_tokens": ["Create", "new", "file", "error", "level", "Debug"], "add_tokens": "logrus . Debugf ( \" \" ,", "del_tokens": "logrus . Infof ( \" \" ,", "commit_type": "create"}
{"commit_tokens": ["Use", "variant", "method", "args", "instead", "of", "struct", "fields"], "add_tokens": "obj := Container { nil } sampleWithHTMLEscape := [ ] byte ( `{ exp := string ( sample ) res := string ( val . EncodeJSON ( EncodeOptIndent ( \" \" , \" \\t \" ) ) ) if exp != res { t . Errorf ( \" \" , res , exp ) exp = string ( sampleWithHtmlEscape ) res = string ( val . EncodeJSON ( EncodeOptHTMLEscape ( true ) , EncodeOptIndent ( \" \" , \" \\t \" ) ) ) if exp != res { t . Errorf ( \" \" , exp , res )", "del_tokens": "obj := Container { nil , true } sampleWithHtmlEscape := [ ] byte ( `{ obj := Container { val . Data ( ) , false } if string ( obj . BytesIndent ( \" \" , \" \\t \" ) ) != string ( sample ) { t . Errorf ( \" \" , obj . BytesIndent ( \" \" , \" \\t \" ) , sample ) objWithHtmlEscape := Container { val . Data ( ) , true } if string ( objWithHtmlEscape . BytesIndent ( \" \" , \" \\t \" ) ) != string ( sampleWithHtmlEscape ) { t . Errorf ( \" \" , objWithHtmlEscape . BytesIndent ( \" \" , \" \\t \" ) , sampleWithHtmlEscape )", "commit_type": "use"}
{"commit_tokens": ["add", "size", "to", "list", "containers"], "add_tokens": "func ( client * DockerClient ) ListContainers ( all bool , size bool ) ( [ ] Container , error ) { showSize := 0 if size == true { showSize = 1 } uri := fmt . Sprintf ( \" \" , APIVersion , argAll , showSize )", "del_tokens": "func ( client * DockerClient ) ListContainers ( all bool ) ( [ ] Container , error ) { uri := fmt . Sprintf ( \" \" , APIVersion , argAll )", "commit_type": "add"}
{"commit_tokens": ["Update", "sweet", "entry", "point", "."], "add_tokens": "junit \" \" func TestMain ( m * testing . M ) { RegisterFailHandler ( sweet . GomegaFail ) sweet . Run ( m , func ( s * sweet . S ) { s . RegisterPlugin ( junit . NewPlugin ( ) ) s . AddSuite ( & WatcherSuite { } ) s . AddSuite ( & ConvenienceSuite { } )", "del_tokens": "func Test ( t * testing . T ) { sweet . T ( func ( s * sweet . S ) { RegisterFailHandler ( sweet . GomegaFail ) s . RunSuite ( t , & WatcherSuite { } ) s . RunSuite ( t , & ConvenienceSuite { } )", "commit_type": "update"}
{"commit_tokens": ["move", "internal", "struct", "to", "its", "methods"], "add_tokens": "type authHandler struct { identityEndpoint string handler http . Handler client * http . Client userAgent string tokenCache Cache } //Handler returns a new keystone http middleware.", "del_tokens": "type authHandler struct { identityEndpoint string handler http . Handler client * http . Client userAgent string tokenCache Cache } //Handler returns a new keystone http middleware.", "commit_type": "move"}
{"commit_tokens": ["Add", "extra", "flags", "from", "go", "-", "micro"], "add_tokens": "app . Flags = cmd . Flags app . Before = cmd . Setup app . RunAndExitOnError ( )", "del_tokens": "\" \" cmd . Init ( ) app . Run ( os . Args )", "commit_type": "add"}
{"commit_tokens": ["Fix", "panic", "when", "key", "starts", "at", "-", "sign"], "add_tokens": "var npath string npath , rjson , ok = execModifier ( json , path ) path = npath", "del_tokens": "path , rjson , ok = execModifier ( json , path )", "commit_type": "fix"}
{"commit_tokens": ["use", "upstream", "go", "-", "isatty", "pkg"], "add_tokens": "isatty \" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "channels", ".", "info", "test"], "add_tokens": "\" \" var reLooksLikeChannelID = regexp . MustCompile ( `^C[A-Z0-9]+` ) func looksLikeChannelID ( s string ) bool { return reLooksLikeChannelID . MatchString ( s ) } if ! assert . True ( t , looksLikeChannelID ( channel . ID ) , \" \" ) { return false } res , err := cl . Channels ( ) . History ( mockserver . ChannelJedis . ID ) . t . Run ( \" \" , func ( t * testing . T ) { res , err := cl . Channels ( ) . Info ( mockserver . ChannelJedis . ID ) . IncludeLocale ( true ) . Do ( ctx ) if ! assert . NoError ( t , err , \" \" ) { return } if ! checkChannel ( t , res ) { return } } )", "del_tokens": "res , err := cl . Channels ( ) . History ( \" \" ) .", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "Panics ( Error ( HasSubstr ( \" \" ) ) ) ) Panics ( Error ( HasSubstr ( \" \" ) ) ) )", "del_tokens": "Panics ( Error ( HasSubstr ( \" \" ) ) ) ) Panics ( Error ( HasSubstr ( \" \" ) ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "reflection", "on", "Uint", "types"], "add_tokens": "case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 : case reflect . Uint , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 , reflect . Uint8 : return strconv . FormatUint ( v . getResolvedValue ( ) . Uint ( ) , 10 )", "del_tokens": "case reflect . Int , reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 , reflect . Uint , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 , reflect . Uint8 :", "commit_type": "fix"}
{"commit_tokens": ["make", "region", "resource", "-", "specific", ";", "create", "new", "client", "for", "each", "crud", "operation"], "add_tokens": "\" \" \" \" \" \" : & schema . Schema { Type : schema . TypeString , Required : true , ForceNew : true , DefaultFunc : envDefaultFunc ( \" \" ) , } , computeClient , err := openstack . NewComputeV2 ( config . osClient , gophercloud . EndpointOpts { Region : d . Get ( \" \" ) . ( string ) , } ) if err != nil { return fmt . Errorf ( \" \" , err ) } sgr , err := secgroups . CreateRule ( computeClient , createOpts ) . Extract ( ) computeClient , err := openstack . NewComputeV2 ( config . osClient , gophercloud . EndpointOpts { Region : d . Get ( \" \" ) . ( string ) , } ) if err != nil { return fmt . Errorf ( \" \" , err ) } err = secgroups . DeleteRule ( computeClient , d . Id ( ) ) . ExtractErr ( )", "del_tokens": "osClient := config . computeV2Client sgr , err := secgroups . CreateRule ( osClient , createOpts ) . Extract ( ) osClient := config . computeV2Client err := secgroups . DeleteRule ( osClient , d . Id ( ) ) . ExtractErr ( )", "commit_type": "make"}
{"commit_tokens": ["add", "Children", "()", "and", "ChildrenFiltered", "()", "with", "tests"], "add_tokens": "\" \" // - Contains() (static function?) // - Contents() (similar to Children(), but includes text and comment nodes, so Children() should filter them out) // - Each() should pass a Selection object over a single node, so that Attr() and such can be called // - End() // - Eq() var allChildren bool var sel cascadia . Selector var e error selector = strings . TrimSpace ( selector ) if selector == \" \" || selector == \" \" { // Get all children allChildren = true } else { if sel , e = cascadia . Compile ( selector ) ; e != nil { // Selector doesn't compile, empty selection return nil } if allChildren || sel ( nchild ) { matches = append ( matches , nchild ) }", "del_tokens": "// - Fix ChildrenFiltered, by forking Cascadia and adding a MatchSingle() method? //var allChildren bool //var sel *cascadia.Selector / * if selector == \" \" || selector == \" \" { // Get all children allChildren = true } else { if sel , e := cascadia . Compile ( selector ) ; e != nil { // Selector doesn't compile, empty selection return nil } * / // TODO : At the moment, given Cascadia's API, cannot call Children with a selector string //if allChildren /*|| sel(nchild)*/ { matches = append ( matches , nchild ) //}", "commit_type": "add"}
{"commit_tokens": ["Use", "expvar", "to", "count", "fetches", "."], "add_tokens": "\" \" icons , e := fetchIcons ( url ) icon , e := fetchBestIcon ( url ) icons , e := fetchIcons ( url ) func fetchIcons ( url string ) ( [ ] besticon . Icon , error ) { fetchCount . Add ( 1 ) icons , err := besticon . FetchIcons ( url ) if err != nil { fetchErrors . Add ( 1 ) } return icons , err } func fetchBestIcon ( url string ) ( * besticon . Icon , error ) { fetchCount . Add ( 1 ) icon , err := besticon . FetchBestIcon ( url ) if err != nil { fetchErrors . Add ( 1 ) } return icon , err } var ( fetchCount = expvar . NewInt ( \" \" ) fetchErrors = expvar . NewInt ( \" \" ) )", "del_tokens": "icons , e := besticon . FetchIcons ( url ) icon , e := besticon . FetchBestIcon ( url ) icons , e := besticon . FetchIcons ( url )", "commit_type": "use"}
{"commit_tokens": ["fix", "scrollwheel", "with", "multiple", "windows"], "add_tokens": "in := win . Input ( )", "del_tokens": "in := & win . ctx . Input", "commit_type": "fix"}
{"commit_tokens": ["allow", "github", ".", "com", "/", "user", "/", "project", "/"], "add_tokens": "// must be /{user}/{project}/? pathComponents := strings . Split ( strings . TrimRight ( repo . url . Path , \" \" ) , \" \" ) if len ( pathComponents ) != 3 {", "del_tokens": "// must be /{user}/{project} if len ( strings . Split ( repo . url . Path , \" \" ) ) != 3 {", "commit_type": "allow"}
{"commit_tokens": ["Allow", "multi", "volume", "files", "to", "not", "have", "end", "blocks", "."], "add_tokens": "var atEOF bool switch err { case errArchiveContinues : case io . EOF : // Read all of volume without finding an end block. The only way // to tell if the archive continues is to try to open the next volume. atEOF = true default : if atEOF && os . IsNotExist ( err ) { // volume not found so assume that the archive has ended return nil , io . EOF }", "del_tokens": "if err != errArchiveContinues {", "commit_type": "allow"}
{"commit_tokens": ["Add", "option", "to", "override", "buckets", "used", "in", "handing", "time", "histograms", "."], "add_tokens": "serverHandledHistogramOpts = prom . HistogramOpts { Namespace : \" \" , Subsystem : \" \" , Name : \" \" , Help : \" \" , Buckets : prom . DefBuckets , } serverHandledHistogram * prom . HistogramVec type HistogramOption func ( * prom . HistogramOpts ) func WithHistogramBuckets ( buckets [ ] float64 ) HistogramOption { return func ( o * prom . HistogramOpts ) { o . Buckets = buckets } } func EnableHandlingTimeHistogram ( opts ... HistogramOption ) { for _ , o := range opts { o ( & serverHandledHistogramOpts ) } serverHandledHistogram = prom . NewHistogramVec ( serverHandledHistogramOpts , [ ] string { \" \" , \" \" , \" \" } , )", "del_tokens": "serverHandledHistogram = prom . NewHistogramVec ( prom . HistogramOpts { Namespace : \" \" , Subsystem : \" \" , Name : \" \" , Help : \" \" , Buckets : prom . DefBuckets , } , [ ] string { \" \" , \" \" , \" \" } ) func EnableHandlingTimeHistogram ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "wrong", "timestamp", "format", "."], "add_tokens": "\" \" ,", "del_tokens": "\" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "locks", "and", "ping", "to", "pm", ".", "CheckExistence", "()"], "add_tokens": "// // Note that this may perform read-ish operations on the cache repo, and it // takes a lock accordingly. Deadlock may result from calling it during a // segment where the cache repo mutex is already write-locked. pm . crepo . mut . RLock ( ) pm . crepo . mut . RUnlock ( ) pm . crepo . mut . RLock ( ) pm . ex . s |= ExistsUpstream if pm . crepo . r . Ping ( ) { pm . ex . f |= ExistsUpstream } pm . crepo . mut . RUnlock ( )", "del_tokens": "//pm.ex.s |= ExistsUpstream // TODO maybe need a method to do this as cheaply as possible, // per-repo type", "commit_type": "add"}
{"commit_tokens": ["change", "WritePES", "()", "to", "write", "zero", "packet_length", "in", "order", "to", "fit", "big", "frame", "size", ">", "64K"], "add_tokens": "var pts_dts_flags , header_length uint // packet_length(16) if zero then variable length if err = WriteUInt ( w , 0 , 2 ) ; err != nil {", "del_tokens": "var pts_dts_flags , header_length , packet_length uint dataLen := getSeekerLength ( data ) packet_length = 3 + header_length + uint ( dataLen ) if DebugWriter { fmt . Printf ( \" \\n \" , packet_length ) } // packet_length(16) if err = WriteUInt ( w , packet_length , 2 ) ; err != nil {", "commit_type": "change"}
{"commit_tokens": ["changes", "Box", ".", "Dir", "to", "Box", ".", "AbsolutePath", "(", "also", "internally", ")"], "add_tokens": "\" \" \" \" log . Printf ( \" \" , box . AbsolutePath ( ) ) // find/create a rice.Box templateBox , err := rice . FindBox ( \" \" ) if err != nil { log . Fatal ( err ) } // get file contents as string templateString , err := templateBox . String ( \" \" ) if err != nil { log . Fatal ( err ) } // parse and execute the template tmplMessage , err := template . New ( \" \" ) . Parse ( templateString ) if err != nil { log . Fatal ( err ) } tmplMessage . Execute ( os . Stdout , map [ string ] string { \" \" : \" \" } ) go http . ListenAndServe ( \" \" , nil )", "del_tokens": "log . Printf ( \" \" , box . Dir ( ) ) go http . ListenAndServe ( \" \" , nil )", "commit_type": "change"}
{"commit_tokens": ["Add", "UserData", "to", "server", "API"], "add_tokens": "StartedAt * time . Time `json:\"started_at\"` UserData string `json:\"user_data\"` ServerConsole ServerType ServerType `json:\"server_type\"` Zone Zone Snapshots [ ] Image", "del_tokens": "ServerType ServerType `json:\"server_type\"` Zone Zone Snapshots [ ] Image ServerConsole", "commit_type": "add"}
{"commit_tokens": ["Update", "clone", "docs", "to", "disuade", "concurrent", "Clone", "."], "add_tokens": "// Clone clones the btree, lazily. Clone should not be called concurrently, // but the original tree (b) and the new tree (b2) can be used concurrently // once the Clone call completes.", "del_tokens": "// Clone clones the btree, lazily. b2 can be used concurrently with // with the original tree, including concurrent writes to b and b2.", "commit_type": "update"}
{"commit_tokens": ["fix", "params", "with", "custom", "type", "should", "be", "converted", "to", "requested", "type"], "add_tokens": "func ( json * JSON ) Get ( name string ) interface { } { // handle type alias if typ . PkgPath ( ) != \" \" && typ . Kind ( ) != reflect . Struct && typ . Kind ( ) != reflect . Slice && typ . Kind ( ) != reflect . Array { rv := reflect . ValueOf ( value . Value ( ) ) if ! rv . Type ( ) . ConvertibleTo ( typ ) { return nil , false } return rv . Convert ( typ ) . Interface ( ) , true }", "del_tokens": "func ( json JSON ) Get ( name string ) interface { } {", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "in", "meter", "traversal", "logic"], "add_tokens": "sw . meters [ i ] = nil // compress and trim the meter list var newLen int for _ , m := range sw . meters { if m != nil { sw . meters [ newLen ] = m newLen ++ }", "del_tokens": "newLen := len ( sw . meters ) newLen -- sw . meters [ i ] = sw . meters [ newLen ] // trim the meter list for i := newLen ; i < len ( sw . meters ) ; i ++ { sw . meters [ i ] = nil", "commit_type": "fix"}
{"commit_tokens": ["Add", "pending", "tests", ".", "Modify", "report", "to", "print", "them", "in", "cyan", "color"], "add_tokens": "func ( g * G ) It ( name string , h ... func ( ) ) { var it Runnable if len ( h ) > 0 { it = & It { name : name , h : h [ 0 ] , parent : g . parent } g . parent . children = append ( g . parent . children , Runnable ( it ) ) } else { g . reporter . itIsPending ( name ) }", "del_tokens": "func ( g * G ) It ( name string , h func ( ) ) { it := & It { name : name , h : h , parent : g . parent } g . parent . children = append ( g . parent . children , Runnable ( it ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "copy", "callback", "functionality", "for", "now"], "add_tokens": "return & Parser {", "del_tokens": "//CopyFunc(func()) p := & Parser { //z.CopyFunc(p.copy) return p // copy copies bytes to the same position and is called whenever the tokenizer overwrites its internal buffer. // This is required because the referenced slices from the tokenizer still point to the tokenizer's internal buffer. // func (p *Parser) copy() { // fmt.Print(\"copy \", string(p.buf[0].Data)) // for _, n := range p.buf[p.pos:] { // tmp := make([]byte, len(n.Data)) // copy(tmp, n.Data) // n.Data = tmp // } // fmt.Println(\" \", string(p.buf[0].Data)) // }", "commit_type": "remove"}
{"commit_tokens": ["fix", "Size_", "usage", "in", "tests"], "add_tokens": "Disks : [ ] * pb . Disk { & pb . Disk { Path : \" \" , Size : 10000000000 } } , if nodesbyaddr [ 0 ] . Capacity ( ) != uint32 ( okHwProfile . Disks [ 0 ] . Size / 1024 / 1024 / 1024 ) || nodesbyaddr [ 0 ] . Active ( ) == false { if nodesbyaddr [ 0 ] . Capacity ( ) != uint32 ( okHwProfile . Disks [ 0 ] . Size / 1024 / 1024 / 1024 ) || nodesbyaddr [ 0 ] . Active ( ) != false {", "del_tokens": "Disks : [ ] * pb . Disk { & pb . Disk { Path : \" \" , Size_ : 10000000000 } } , if nodesbyaddr [ 0 ] . Capacity ( ) != uint32 ( okHwProfile . Disks [ 0 ] . Size_ / 1024 / 1024 / 1024 ) || nodesbyaddr [ 0 ] . Active ( ) == false { if nodesbyaddr [ 0 ] . Capacity ( ) != uint32 ( okHwProfile . Disks [ 0 ] . Size_ / 1024 / 1024 / 1024 ) || nodesbyaddr [ 0 ] . Active ( ) != false {", "commit_type": "fix"}
{"commit_tokens": ["add", "SliceDecoder", "for", "custom", "map", "or", "slice"], "add_tokens": "isSliceDecoder := fl . value . Type ( ) . Implements ( reflect . TypeOf ( ( * SliceDecoder ) ( nil ) ) . Elem ( ) ) if ! isSliceDecoder && fl . value . CanAddr ( ) { isSliceDecoder = fl . value . Addr ( ) . Type ( ) . Implements ( reflect . TypeOf ( ( * SliceDecoder ) ( nil ) ) . Elem ( ) ) } ( fl . field . Type . Kind ( ) != reflect . Slice && fl . field . Type . Kind ( ) != reflect . Map && ! isSliceDecoder )", "del_tokens": "( fl . field . Type . Kind ( ) != reflect . Slice && fl . field . Type . Kind ( ) != reflect . Map )", "commit_type": "add"}
{"commit_tokens": ["added", "a", "couple", "more", "baseAcronyms"], "add_tokens": "const baseAcronyms = `JSON,JWT,ID,UUID,SQL,ACK,ACL,ADSL,AES,ANSI,API,ARP,ATM,BGP,BSS,CAT,CCITT,CHAP,CIDR,CIR,CLI,CPE,CPU,CRC,CRT,CSMA,CMOS,DCE,DEC,DES,DHCP,DNS,DRAM,DSL,DSLAM,DTE,DMI,EHA,EIA,EIGRP,EOF,ESS,FCC,FCS,FDDI,FTP,GBIC,gbps,GEPOF,HDLC,HTTP,HTTPS,IANA,ICMP,IDF,IDS,IEEE,IETF,IMAP,IP,IPS,ISDN,ISP,kbps,LACP,LAN,LAPB,LAPF,LLC,MAC,MAN,Mbps,MC,MDF,MIB,MoCA,MPLS,MTU,NAC,NAT,NBMA,NIC,NRZ,NRZI,NVRAM,OSI,OSPF,OUI,PAP,PAT,PC,PIM,PIM,PCM,PDU,POP3,POP,POST,POTS,PPP,PPTP,PTT,PVST,RADIUS,RAM,RARP,RFC,RIP,RLL,ROM,RSTP,RTP,RCP,SDLC,SFD,SFP,SLARP,SLIP,SMTP,SNA,SNAP,SNMP,SOF,SRAM,SSH,SSID,STP,SYN,TDM,TFTP,TIA,TOFU,UDP,URL,URI,USB,UTP,VC,VLAN,VLSM,VPN,W3C,WAN,WEP,WiFi,WPA,WWW`", "del_tokens": "const baseAcronyms = `ID,UUID,SQL,ACK,ACL,ADSL,AES,ANSI,API,ARP,ATM,BGP,BSS,CAT,CCITT,CHAP,CIDR,CIR,CLI,CPE,CPU,CRC,CRT,CSMA,CMOS,DCE,DEC,DES,DHCP,DNS,DRAM,DSL,DSLAM,DTE,DMI,EHA,EIA,EIGRP,EOF,ESS,FCC,FCS,FDDI,FTP,GBIC,gbps,GEPOF,HDLC,HTTP,HTTPS,IANA,ICMP,IDF,IDS,IEEE,IETF,IMAP,IP,IPS,ISDN,ISP,kbps,LACP,LAN,LAPB,LAPF,LLC,MAC,MAN,Mbps,MC,MDF,MIB,MoCA,MPLS,MTU,NAC,NAT,NBMA,NIC,NRZ,NRZI,NVRAM,OSI,OSPF,OUI,PAP,PAT,PC,PIM,PIM,PCM,PDU,POP3,POP,POST,POTS,PPP,PPTP,PTT,PVST,RADIUS,RAM,RARP,RFC,RIP,RLL,ROM,RSTP,RTP,RCP,SDLC,SFD,SFP,SLARP,SLIP,SMTP,SNA,SNAP,SNMP,SOF,SRAM,SSH,SSID,STP,SYN,TDM,TFTP,TIA,TOFU,UDP,URL,URI,USB,UTP,VC,VLAN,VLSM,VPN,W3C,WAN,WEP,WiFi,WPA,WWW`", "commit_type": "add"}
{"commit_tokens": ["fixed", "flashing", "powershell", "window", "when", "build", "with", "-", "H", "=", "windowsgui", "flag"], "add_tokens": "\" \" cmd . SysProcAttr = & syscall . SysProcAttr { HideWindow : true } cmd := exec . Command ( \" \" , \" \" ) cmd . SysProcAttr = & syscall . SysProcAttr { HideWindow : true } out , err := cmd . Output ( )", "del_tokens": "out , err := exec . Command ( \" \" , \" \" ) . Output ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "set", "configuration", "from", "the", "cli"], "add_tokens": "\" \" return vars , errors . New ( \" \" )", "del_tokens": "return vars , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "memory", "value", "in", "stats", "api"], "add_tokens": "Memory : uint64 ( m . Memory ) ,", "del_tokens": "Memory : uint64 ( m . Cpus ) ,", "commit_type": "fix"}
{"commit_tokens": ["Made", "the", "integration", "test", "use", "the", "local", "version", "."], "add_tokens": "// HACK(jacobsa): The gotest command reads the GCFLAGS environment variable, // which allows us to give a -I flag to 6g to let it find the locally built // package. However 6l cannot find it, and there is no linker flags // environment variable. So we actually install the package here, instead of // just building it locally. // // TODO(jacobsa): When the new 'go' tool comes out, check whether this still // replies to its 'test' command. If so, file an issue to get a linker flags // environment variable added. cmd := exec . Command ( \" \" , \" \" )", "del_tokens": "cmd := exec . Command ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Adding", "empty", "import", "for", "xoutil", "so", "that", "the", "repo", "will", "be", "automatically", "available"], "add_tokens": "_ \" \" _ \" \"", "del_tokens": "_ \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "trimmed", "signature", "unit", "test", "message"], "add_tokens": "if ! assert . NoError ( t , err , \" \" ) {", "del_tokens": "if ! assert . NoError ( t , err , \" \" ) {", "commit_type": "fix"}
{"commit_tokens": ["Move", "underscore", "into", "otto", "/", "underscore"], "add_tokens": "package underscore func Source ( ) string { return string ( underscore ( ) ) } func underscore ( ) [ ] byte { }", "del_tokens": "package otto // underscore_js returns the raw file data data. func underscore_js ( ) [ ] byte { }", "commit_type": "move"}
{"commit_tokens": ["add", "string", "interface", "for", "multi", "catcher"], "add_tokens": "func ( self * MultiCatcher ) String ( ) string { return strings . Join ( self . errs , \" \" ) } err = errors . New ( self . String ( ) )", "del_tokens": "err = errors . New ( strings . Join ( self . errs , \" \" ) )", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "cookbook", "test", "cases", "also", "."], "add_tokens": "mux . HandleFunc ( \" \" , func ( w http . ResponseWriter , r * http . Request ) { mux . HandleFunc ( \" \" , func ( w http . ResponseWriter , r * http . Request ) {", "del_tokens": "mux . HandleFunc ( \" \" , func ( w http . ResponseWriter , r * http . Request ) { mux . HandleFunc ( \" \" , func ( w http . ResponseWriter , r * http . Request ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "percentile", "when", "only", "one", "element"], "add_tokens": "length := input . Len ( ) if length == 0 { if length == 1 { return input [ 0 ] , nil }", "del_tokens": "if input . Len ( ) == 0 {", "commit_type": "fix"}
{"commit_tokens": ["Use", "constants", "for", "status", "codes", "HTTP", "methods", "and", "JSON", "API", "media", "types", "in", "comments", "and", "readme"], "add_tokens": "// w.Header().Set(\"Content-Type\", jsonapi.MediaType)", "del_tokens": "// w.Header().Set(\"Content-Type\", \"application/vnd.api+json\")", "commit_type": "use"}
{"commit_tokens": ["fix", "bootstrap", "related", "flags", "and", "paths"], "add_tokens": "// Exclude the following files \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "del_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , } var bootstrapFlex = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "commit_type": "fix"}
{"commit_tokens": ["use", "atomic", "to", "get", "/", "set", "the", "result"], "add_tokens": "\" \" //r *PromiseResult r unsafe . Pointer r := atomic . LoadPointer ( & this . r ) return ( * PromiseResult ) ( r ) //this.lock.Lock() //defer this.lock.Unlock() //this.r = r atomic . StorePointer ( & this . r , unsafe . Pointer ( r ) ) r := this . result ( ) if r == nil { execWithLock ( this . lock , func ( ) { } ) fun = nil } else { fun = func ( ) { finalAction ( r ) } }", "del_tokens": "//\"unsafe\" r * PromiseResult return this . r this . lock . Lock ( ) defer this . lock . Unlock ( ) this . r = r execWithLock ( this . lock , func ( ) { r := this . result ( ) if r == nil { fun = nil } else { fun = func ( ) { finalAction ( r ) } } } )", "commit_type": "use"}
{"commit_tokens": ["move", "local", "step", "to", ".", "bitrise", "work", "dir"], "add_tokens": "stepDir := bitrise . BitriseWorkStepsDirPath stepYMLPth := bitrise . BitriseWorkDirPath + \" \" bitrise . RunCopyDir ( stepIDData . ID , stepDir ) bitrise . RunCopyFile ( stepIDData . ID + \" \" , stepYMLPth )", "del_tokens": "stepDir := \" \" stepYMLPth := \" \" stepDir = stepIDData . ID stepYMLPth = stepDir + \" \" stepDir = bitrise . BitriseWorkStepsDirPath stepYMLPth = bitrise . BitriseWorkDirPath + \" \"", "commit_type": "move"}
{"commit_tokens": ["Added", "scanning", "of", "one", "column", "results", "into", "slices", "of", "native", "types"], "add_tokens": "case reflect . Slice : return fmt . Errorf ( \" \" ) if len ( columns ) != 1 { return fmt . Errorf ( \" \" , elem . Kind ( ) , ) } // Single column results can be scanned into native types if len ( columns ) != 1 { return fmt . Errorf ( \" \" , elem . Kind ( ) , ) } for r . rows . Next ( ) { newElem := reflect . New ( elem ) . Elem ( ) if err := r . rows . Scan ( newElem . Addr ( ) . Interface ( ) ) ; err != nil { return err } argElem . Set ( reflect . Append ( argElem , newElem ) ) }", "del_tokens": "return fmt . Errorf ( \" \" , elem . Kind ( ) , ) return fmt . Errorf ( \" \" , elem . Kind ( ) , ) // // Is the slice element a struct? // if elem.Kind() == reflect.Struct { // // Iterate through the struct fields to build the receiver // return nil // } else { // // Create a single interface for receiving // for r.rows.Next() { // // Create a new slice element // newElem := reflect.New(elem).Elem() // if err := r.rows.Scan(newElem.Addr().Interface()); err != nil { // return err // } // argElem.Set(reflect.Append(argElem, newElem)) // } // }", "commit_type": "add"}
{"commit_tokens": ["create", "temp", "file", "for", "repo", "release", "test"], "add_tokens": "file , dir , err := openTestFile ( \" \" , \" \\n \" ) t . Fatalf ( \" \" , err ) defer os . RemoveAll ( dir ) opt := & UploadOptions { Name : \" \" }", "del_tokens": "opt := & UploadOptions { Name : \" \" } file , err := os . Open ( \" \" ) t . Errorf ( \" \" )", "commit_type": "create"}
{"commit_tokens": ["Add", "NTEXT", "type", "for", "supporting", "mssql"], "add_tokens": "NText = \" \" NText : TEXT_TYPE , case Char , Varchar , NVarchar , TinyText , Text , NText , MediumText , LongText , Enum , Set , Uuid , Clob , SysName :", "del_tokens": "case Char , Varchar , NVarchar , TinyText , Text , MediumText , LongText , Enum , Set , Uuid , Clob , SysName :", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "pattern", "check", "."], "add_tokens": "return [ ] string { } case map [ string ] interface { } : // nested configuration continue", "del_tokens": "break", "commit_type": "add"}
{"commit_tokens": ["Use", "v3", "in", "tests", "to", "prevent", "indirect", "dependencies"], "add_tokens": "import paypal \" \"", "del_tokens": "import paypal \" \"", "commit_type": "use"}
{"commit_tokens": ["Add", "client", "session", "caching", "to", "BBS", "/", "ETCD", "TLS", "transports"], "add_tokens": "\" \" \" \" var tr * http . Transport if etcdOptions . CertFile == \" \" || etcdOptions . KeyFile == \" \" { logger . Fatal ( \" \" , errors . New ( \" \" ) ) } var err error tlsCert , err := tls . LoadX509KeyPair ( etcdOptions . CertFile , etcdOptions . KeyFile ) if err != nil { logger . Fatal ( \" \" , err ) } tlsConfig := & tls . Config { Certificates : [ ] tls . Certificate { tlsCert } , InsecureSkipVerify : true , ClientSessionCache : tls . NewLRUClientSessionCache ( 128 ) , } tr = & http . Transport { TLSClientConfig : tlsConfig , Dial : etcdClient . DefaultDial , } etcdClient . SetTransport ( tr )", "del_tokens": "var err error", "commit_type": "add"}
{"commit_tokens": ["Remove", "empty", "line", "of", "no", "context", "case"], "add_tokens": "if len ( example . SubDescriptions ) > 0 { differenceIsFound := false for i , subscription := range example . SubDescriptions { if ! differenceIsFound && i <= len ( example . PreviousSubDescriptions ) - 1 { if subscription == example . PreviousSubDescriptions [ i ] { continue } fullMessage += strings . Repeat ( \" \\t \" , i + 1 ) + subscription differenceIsFound = true fmt . Println ( fullMessage )", "del_tokens": "differenceIsFound := false for i , subscription := range example . SubDescriptions { if ! differenceIsFound && i <= len ( example . PreviousSubDescriptions ) - 1 { if subscription == example . PreviousSubDescriptions [ i ] { continue fullMessage += strings . Repeat ( \" \\t \" , i + 1 ) + subscription differenceIsFound = true fmt . Println ( fullMessage )", "commit_type": "remove"}
{"commit_tokens": ["add", "missing", "fields", "to", "the", "Parameter", "object"], "add_tokens": "Type string `json:\",omitempty\"` Default string `json:\",omitempty\"` NoEcho * BoolExpr `json:\",omitempty\"` AllowedValues [ ] string `json:\",omitempty\"` AllowedPattern string `json:\",omitempty\"` MinLength * IntegerExpr `json:\",omitempty\"` MaxLength * IntegerExpr `json:\",omitempty\"` MinValue * IntegerExpr `json:\",omitempty\"` MaxValue * IntegerExpr `json:\",omitempty\"` Description string `json:\",omitempty\"` ConstraintDescription string `json:\",omitempty\"`", "del_tokens": "Type string `json:\",omitempty\"` Description string `json:\",omitempty\"` Default string `json:\",omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["fix", "version", "check", "against", "devel"], "add_tokens": "goVersion , err := strconv . ParseFloat ( runtime . Version ( ) [ 2 : 5 ] , 64 ) // runtime.Version() may return commit hash, we assume it is above 1.5 if goVersion < 1.5 && err == nil {", "del_tokens": "goVersion , _ := strconv . ParseFloat ( runtime . Version ( ) [ 2 : 5 ] , 64 ) if goVersion < 1.5 {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "importpath", "from", "go_binary", "go_test"], "add_tokens": "fixedFile = migrateGrpcCompilers ( c , fixedFile ) return removeBinaryImportPath ( c , fixedFile ) // removeBinaryImportPath removes \"importpath\" attributes from \"go_binary\" // and \"go_test\" rules. These are now deprecated. func removeBinaryImportPath ( c * config . Config , oldFile * bf . File ) * bf . File { fixed := false fixedFile := * oldFile for i , stmt := range fixedFile . Stmt { call , ok := stmt . ( * bf . CallExpr ) if ! ok { continue } rule := bf . Rule { Call : call } if rule . Kind ( ) != \" \" && rule . Kind ( ) != \" \" || rule . Attr ( \" \" ) == nil { continue } fixedCall := * call fixedCall . List = make ( [ ] bf . Expr , len ( call . List ) ) copy ( fixedCall . List , call . List ) rule . Call = & fixedCall rule . DelAttr ( \" \" ) fixedFile . Stmt [ i ] = & fixedCall fixed = true } if ! fixed { return oldFile } return & fixedFile }", "del_tokens": "return migrateGrpcCompilers ( c , fixedFile )", "commit_type": "remove"}
{"commit_tokens": ["make", "BuildAll", "()", "return", "error"], "add_tokens": "\" \" totalWaitTime = 180 //second dialTimeOut = 5 //second func BuildAll ( ) error { return servicebuilder . BuildAll ( ) case <- serviceUpChan : return true //Service is up. case <- time . After ( totalWaitTime * time . Second ) : close ( timeOutChan ) //Timeout is reached. Stop waiting. return false } case <- timeOutChan : timeOut := time . Duration ( dialTimeOut ) * time . Second if err != nil { //TODO handle the error more specifically return false } else { conn . Close ( ) return true } }", "del_tokens": "\" \" totalWaitTime = 180 //second dialTimeOut = 5 //second func BuildAll ( ) { servicebuilder . BuildAll ( ) case <- serviceUpChan : return true //Service is up. case <- time . After ( totalWaitTime * time . Second ) : close ( timeOutChan ) //Timeout is reached. Stop waiting. return false } case <- timeOutChan : timeOut := time . Duration ( dialTimeOut ) * time . Second if err != nil { //TODO handle the error more specifically return false } else { conn . Close ( ) return true } }", "commit_type": "make"}
{"commit_tokens": ["Use", "parseJSON", "as", "the", "API", "method"], "add_tokens": "\" \" : c . groupByTag , \" \" : c . decodeJSON , \" \" : c . toLower , \" \" : c . toTitle , \" \" : c . toUpper , \" \" : t . noop , \" \" : t . noop , \" \" : t . noop , \" \" : t . noop , \" \" : t . noop ,", "del_tokens": "\" \" : c . groupByTag , \" \" : c . decodeJSON , \" \" : c . toLower , \" \" : c . toTitle , \" \" : c . toUpper , \" \" : t . noop , \" \" : t . noop , \" \" : t . noop , \" \" : t . noop , \" \" : t . noop ,", "commit_type": "use"}
{"commit_tokens": ["fix", "edge", "case", "in", "comparison"], "add_tokens": "additionalItems : NilConstraint , lv := rv . Len ( ) if lv <= i { break } if pdebug . Enabled { pdebug . Printf ( \" \" , i ) } if lp > 0 && l > lp { // we got more than positional schemas", "del_tokens": "if l >= lp { // we got more than positional schemas", "commit_type": "fix"}
{"commit_tokens": ["added", "utility", "to", "format", "the", "first", "ask", "of", "a", "prompt"], "add_tokens": "fmt . Print ( FormatAsk ( fmt . Sprintf ( \" \" , input . Question ) ) )", "del_tokens": "fmt . Print ( fmt . Sprintf ( \" \" , input . Question ) )", "commit_type": "add"}
{"commit_tokens": ["move", "Append", "to", "a", "member", "function", "to", "match", "the", "design", "of", "the", "standard", "time", "and", "math", "/", "big", "packages"], "add_tokens": "func ( i KSUID ) Append ( b [ ] byte ) [ ] byte { return string ( i . Append ( make ( [ ] byte , 0 , stringEncodedLength ) ) )", "del_tokens": "func Append ( b [ ] byte , i KSUID ) [ ] byte { return string ( Append ( make ( [ ] byte , 0 , stringEncodedLength ) , i ) )", "commit_type": "move"}
{"commit_tokens": ["Add", "pure", "in", "-", "memory", "operations", "."], "add_tokens": "// Note that the configuration is written to the system // temporary folder, so your file should not contain // sensitive information. if err = os . MkdirAll ( path . Dir ( tmpName ) , os . ModePerm ) ; err != nil { return nil , err } // LoadFromReader accepts raw data directly from a reader // and returns a new configuration representation. // You must use ReloadData to reload. // You cannot append files a configfile read this way. func LoadFromReader ( in io . Reader ) ( c * ConfigFile , err error ) { c = newConfigFile ( [ ] string { \" \" } ) err = c . read ( in ) return c , err } if c . fileNames [ 0 ] == \" \" { return fmt . Errorf ( \" \" ) } // ReloadData reloads configuration file from memory func ( c * ConfigFile ) ReloadData ( in io . Reader ) ( err error ) { var cfg * ConfigFile if len ( c . fileNames ) != 1 { return fmt . Errorf ( \" \" ) } cfg , err = LoadFromReader ( in ) if err == nil { * c = * cfg } return err } if len ( c . fileNames ) == 1 && c . fileNames [ 0 ] == \" \" { return fmt . Errorf ( \" \" ) }", "del_tokens": "os . MkdirAll ( path . Dir ( tmpName ) , os . ModePerm )", "commit_type": "add"}
{"commit_tokens": ["add", "tab", ".", "WaitFor", "method", "to", "wait", "for", "a", "condition", "to", "become", "true"], "add_tokens": "t . Subscribe ( \" \" , func ( target * gcd . ChromeTarget , payload [ ] byte ) {", "del_tokens": "t . Subscribe ( \" \" , func ( target * gcd . ChromeTarget , payload [ ] byte ) { func ( t * Tab ) subscribeFrameNavigationEvent ( ) { t . Subscribe ( \" \" , func ( target * gcd . ChromeTarget , payload [ ] byte ) { if t . isNavigating { return } } ) }", "commit_type": "add"}
{"commit_tokens": ["added", "ipv6", "link", "-", "local", "loopback"], "add_tokens": "\" \" // IP6LinkLocalLoopback is the ip6 link-local loopback multiaddr IP6LinkLocalLoopback = ma . StringCast ( \" \" ) b := m . Bytes ( ) // /ip4/127 prefix (_entire_ /8 is loopback...) if bytes . HasPrefix ( b , [ ] byte { 4 , 127 } ) { return true } // /ip6/::1 if IP6Loopback . Equal ( m ) || IP6LinkLocalLoopback . Equal ( m ) { return true } return false", "del_tokens": "return m . Equal ( IP4Loopback ) || m . Equal ( IP6Loopback )", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "imagebuilder", "to", "be", "more", "consistent", "with", "docker", "build"], "add_tokens": "\" \" //Executor Executor func NewBuilderForReader ( r io . Reader , args map [ string ] string ) ( * Builder , * parser . Node , error ) { b := NewBuilder ( ) b . Args = args node , err := ParseDockerfile ( r ) if err != nil { return nil , nil , err } return b , node , err } func NewBuilderForFile ( path string , args map [ string ] string ) ( * Builder , * parser . Node , error ) { f , err := os . Open ( path ) if err != nil { return nil , nil , err } defer f . Close ( ) return NewBuilderForReader ( f , args ) }", "del_tokens": "Executor Executor", "commit_type": "upgrade"}
{"commit_tokens": ["Changed", "typeclassSet", "back", "to", "what", "it", "was", "originally"], "add_tokens": "constraints TypeClassSet func WithConstraints ( constraints ... TypeClass ) TypeVarConsOpt { tv . constraints = TypeClassSet ( constraints ) return t == nil || ( t . name == \" \" && t . instance == nil && ( t . constraints == nil || len ( t . constraints ) == 0 ) )", "del_tokens": "constraints * TypeClassSet func WithConstraints ( cs ... TypeClass ) TypeVarConsOpt { constraints := NewTypeClassSet ( cs ... ) tv . constraints = constraints return t == nil || ( t . name == \" \" && t . instance == nil && ( t . constraints == nil || len ( t . constraints . s ) == 0 ) )", "commit_type": "change"}
{"commit_tokens": ["Allowed", "one", "LEI", "identifier", "to", "be", "assocaited", "with", "more", "than", "one", "Organisation"], "add_tokens": "DELETE hc , soo , iden `, MERGE ( i : Identifier { value : { value } , authority : { authority } } )", "del_tokens": "DELETE hc , soo , iden , i `, CREATE ( i : Identifier { value : { value } , authority : { authority } } )", "commit_type": "allow"}
{"commit_tokens": ["Move", "stdin", "reader", "to", "helpers"], "add_tokens": "id , err := assertClient ( registryUrl ) . RegisterNewSchema ( args [ 0 ] , stdinToString ( ) )", "del_tokens": "\" \" \" \" \" \" bs , err := ioutil . ReadAll ( bufio . NewReader ( os . Stdin ) ) if err != nil { log . Fatal ( err ) } log . Printf ( \" \\n \" , string ( bs ) ) id , err := assertClient ( registryUrl ) . RegisterNewSchema ( args [ 0 ] , string ( bs ) )", "commit_type": "move"}
{"commit_tokens": ["Update", "the", "readme", "and", "do", "some", "tests", "for", "softhsm"], "add_tokens": "case [ ] byte : // just copy a . Value = x . ( [ ] byte )", "del_tokens": "break // TODO(miek): 64 bit", "commit_type": "update"}
{"commit_tokens": ["fix", "benign", "race", "and", "clean", "up", "handshake", "logic"], "add_tokens": "lzc := & lazyServerConn { con : rwc , started := make ( chan struct { } ) go lzc . waitForHandshake . Do ( func ( ) { close ( started ) } ) <- started rwc . Close ( ) rwc . Close ( ) rwc . Close ( )", "del_tokens": "lzc := & lazyConn { con : rwc , rhandshake : true , rhsync : true , // take lock here to prevent a race condition where the reads below from // finishing and taking the write lock before this goroutine can lzc . whlock . Lock ( ) go func ( ) { defer lzc . whlock . Unlock ( ) lzc . whsync = true lzc . whandshake = true } ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "variable", "name", "."], "add_tokens": "httpResp , err := c . Client . Do ( httpReq ) if err != nil { return err", "del_tokens": "httpResp , e := c . Client . Do ( httpReq ) if e != nil { return e", "commit_type": "fix"}
{"commit_tokens": ["Fix", "digits", "generation", "to", "avoid", "overflows", "."], "add_tokens": "remaining := numDigits for remaining > 10 { ret += fmt . Sprintf ( \" \" , pow ( 10 , 9 ) + randInt ( pow ( 10 , 10 ) - pow ( 10 , 9 ) ) ) remaining -= 10 } ret += fmt . Sprintf ( \" \" , pow ( 10 , remaining - 1 ) + randInt ( pow ( 10 , remaining ) - pow ( 10 , remaining - 1 ) ) )", "del_tokens": "ret += fmt . Sprintf ( \" \" , pow ( 10 , numDigits - 1 ) + randInt ( pow ( 10 , numDigits ) - pow ( 10 , numDigits - 1 ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "notify", "for", "unhealthy", "container"], "add_tokens": "NotifyPodMissing = \" \" NotifyPodDown = \" \" NotifyLetPodGo = \" \" NotifyPodIPLost = \" \" NotifyPodUnHealthy = \" \"", "del_tokens": "NotifyPodMissing = \" \" NotifyPodDown = \" \" NotifyLetPodGo = \" \" NotifyPodIPLost = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "deadlock", "in", "another", "way", "."], "add_tokens": "go func ( ) { err := mapreduce . Materialize ( dataRepo , branchParam ( r ) , commitParam ( r ) , compRepo , jobDir , shard , modulos ) if err != nil { log . Print ( err ) } } ( )", "del_tokens": "err := mapreduce . Materialize ( dataRepo , branchParam ( r ) , commitParam ( r ) , compRepo , jobDir , shard , modulos ) if err != nil { http . Error ( w , err . Error ( ) , 500 ) log . Print ( err ) return }", "commit_type": "fix"}
{"commit_tokens": ["updated", "chain", "-", "head", "api", "call"], "add_tokens": "ChainHead string", "del_tokens": "EntryBlockKeyMR string", "commit_type": "update"}
{"commit_tokens": ["Add", "new", "field", "GetName", "on", "serializer", "interface"], "add_tokens": "hbdEncode ( heartbeatTime , packetEncoder , messageEncoder . IsCompressionEnabled ( ) , serializer . GetName ( ) )", "del_tokens": "\" \" \" \" var serializerName string switch serializer . ( type ) { case * json . Serializer : serializerName = \" \" case * protobuf . Serializer : serializerName = \" \" default : serializerName = \" \" } hbdEncode ( heartbeatTime , packetEncoder , messageEncoder . IsCompressionEnabled ( ) , serializerName )", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "option", "to", "change", "the", "text", "to", "lower"], "add_tokens": "if msg . Text != nil { if bot . DefaultOptions . CleanInitialUsername { if bot . DefaultOptions . AllowWithoutSlashInMention && ! strings . HasSuffix ( text , \" \" ) { if bot . DefaultOptions . LowerText { text := strings . ToLower ( * msg . Text ) msg . Text = & text }", "del_tokens": "if bot . DefaultOptions . CleanInitialUsername { if msg . Text != nil { if bot . DefaultOptions . AllowWithoutSlashInMention && ! strings . HasSuffix ( text , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "ISO88595", "Code", "page", "support"], "add_tokens": "// DefaultType DataCoding = 0x00 // SMSC Default Alphabet // IA5Type DataCoding = 0x01 // IA5 (CCITT T.50)/ASCII (ANSI X3.4) // BinaryType DataCoding = 0x02 // Octet unspecified (8-bit binary) Latin1Type DataCoding = 0x03 // Latin 1 (ISO-8859-1) // Binary2Type DataCoding = 0x04 // Octet unspecified (8-bit binary) // JISType DataCoding = 0x05 // JIS (X 0208-1990) ISO88595Type DataCoding = 0x06 // Cyrillic (ISO-8859-5) // ISO88598Type DataCoding = 0x07 // Latin/Hebrew (ISO-8859-8) UCS2Type DataCoding = 0x08 // UCS2 (ISO/IEC-10646) // PictogramType DataCoding = 0x09 // Pictogram Encoding // ISO2022JPType DataCoding = 0x0A // ISO-2022-JP (Music Codes) // EXTJISType DataCoding = 0x0D // Extended Kanji JIS (X 0212-1990) // KSC5601Type DataCoding = 0x0E // KS C 5601 case ISO88595Type : return ISO88595 ( text ) . Encode ( ) case ISO88595Type : return ISO88595 ( text ) . Decode ( )", "del_tokens": "Latin1Type DataCoding = 0x03 UCS2Type DataCoding = 0x08", "commit_type": "add"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// Version returns current version // Get returns an entry from the HostPool", "del_tokens": "// Returns current version // return an entry from the HostPool", "commit_type": "fix"}
{"commit_tokens": ["Added", "capability", "for", "Anonymous", "/", "Guest", "access", "to", "otherwise", "restricted", "pages"], "add_tokens": "// SecureHandlerFunc type is an adapter that extends the standard type SecureHandlerFunc func ( w http . ResponseWriter , r * http . Request , u User ) func SecureUserFunc ( handler SecureHandlerFunc ) http . HandlerFunc { // SecureGuestFunc will attempt to retireve authenticated User details from // the current session when invoking the auth.SecureHandlerFunc function. If no // User details are found the handler will allow the user to proceed as a guest, // which means the User details will be nil. func SecureGuestFunc ( handler SecureHandlerFunc ) http . HandlerFunc {", "del_tokens": "// UserHandlerFunc type is an adapter that extends the standard type UserHandlerFunc func ( w http . ResponseWriter , r * http . Request , u User ) func SecureUserFunc ( handler UserHandlerFunc ) http . HandlerFunc { // SecureUserOptFunc will attempt to verify a user session exists prior to // executing the auth.SecureHandlerFunc function. If no valid sessions exists, // the user will be allowed to continue, however, the auth.User value will // be nil. func SecureUserOptFunc ( handler UserHandlerFunc ) http . HandlerFunc {", "commit_type": "add"}
{"commit_tokens": ["Adding", "OuterHTML", "and", "InnerHTML", "actions"], "add_tokens": "/ * func ( s * Selector ) selAsInt ( ) int { } * /", "del_tokens": "func ( s * Selector ) selAsInt ( ) int { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "timing", "side", "-", "channel", "attack", "in", "hmac", "comparison"], "add_tokens": "if ! hmac . Equal ( sig , hasher . Sum ( nil ) ) {", "del_tokens": "\" \" if ! bytes . Equal ( sig , hasher . Sum ( nil ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "doc", "line", "."], "add_tokens": "// The uuid package generates and inspects UUIDs. // // UUIDs are based on RFC 4122 and DCE 1.1: Authentication and Security Services.", "del_tokens": "// The uuid package generates and inspects UUIDs based on RFC 4122 and // DCE 1.1: Authentication and Security Services.", "commit_type": "update"}
{"commit_tokens": ["Add", "cmd", "option", "to", "show", "sup", "version"], "add_tokens": "supfile = flag . String ( \" \" , \" \" , \" \" ) showVersionShort = flag . Bool ( \" \" , false , \" \" ) showVersionLong = flag . Bool ( \" \" , false , \" \" ) if * showVersionShort || * showVersionLong { fmt . Println ( \" \" ) return }", "del_tokens": "supfile = flag . String ( \" \" , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "multiple", "calls", "to", "UpgradeRequests", "and", "add", "a", "TODO", "to", "the", "Readme", "about", "allowing", "for", "different", "websocket", "listeners", "to", "use", "different", "options"], "add_tokens": "upgrader := websocket . Upgrader { wsConn , err := upgrader . Upgrade ( w , r , nil ) if err != nil { _checkAndGenerateEvent ( eventHandler , Error , nil , nil , err ) } else { newConn ( r , wsConn , eventHandler ) }", "del_tokens": "if called { panic ( \" \" ) } called = true upgrader = websocket . Upgrader { upgradeWebsocket ( eventHandler , w , r ) // Internal /////////// var upgrader websocket . Upgrader var called = false // Hack func upgradeWebsocket ( eventHandler EventHandler , w http . ResponseWriter , r * http . Request ) { wsConn , err := upgrader . Upgrade ( w , r , nil ) if err != nil { _checkAndGenerateEvent ( eventHandler , Error , nil , nil , err ) return } newConn ( r , wsConn , eventHandler ) }", "commit_type": "allow"}
{"commit_tokens": ["change", "name", "of", "logfile", "var", "from", "l", "to", "f"], "add_tokens": "f := openLog ( ) defer f . Close ( ) logger . SetOutput ( f ) logger . Println ( a ... )", "del_tokens": "return values", "commit_type": "change"}
{"commit_tokens": ["add", "MSet", "and", "test", "case"], "add_tokens": "defer func ( ) { SHARD_COUNT = 32 } ( ) func TestMInsert ( t * testing . T ) { animals := map [ string ] interface { } { \" \" : Animal { \" \" } , \" \" : Animal { \" \" } , } m := New ( ) m . MSet ( animals ) if m . Count ( ) != 2 { t . Error ( \" \" ) } }", "del_tokens": "defer func ( ) { SHARD_COUNT = 32 } ( )", "commit_type": "add"}
{"commit_tokens": ["Added", "validation", "for", "dots", "."], "add_tokens": "// As per RFC 5332 secion 3.2.3: https://tools.ietf.org/html/rfc5322#section-3.2.3 // Dots are not allowed in the beginning, end or in occurances of more than 1 in the email address userDotRegexp = regexp . MustCompile ( \" \" ) if userDotRegexp . MatchString ( user ) || ! userRegexp . MatchString ( user ) || ! hostRegexp . MatchString ( host ) {", "del_tokens": "if ! userRegexp . MatchString ( user ) || ! hostRegexp . MatchString ( host ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "apply", "logging", "and", "output"], "add_tokens": "return errors . New ( \" \" ) logger . Info ( \" \" , cluster . Name ) logger . Info ( \" \" ) logger . Info ( \" \" ) logger . Info ( \" \" )", "del_tokens": "return errors . New ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "tpage", ".", "write", "()", "test", "."], "add_tokens": "type allocator func ( size int ) ( * page , error ) lnode . pos = uint32 ( uintptr ( unsafe . Pointer ( & b [ 0 ] ) ) - uintptr ( unsafe . Pointer ( lnode ) ) ) copy ( b [ 0 : ] , node . key ) copy ( b [ 0 : ] , node . value )", "del_tokens": "type allocator func ( count int ) ( * page , error ) lnode . pos = uint32 ( uintptr ( unsafe . Pointer ( & b [ 0 ] ) ) - uintptr ( unsafe . Pointer ( & lnode ) ) ) copy ( b [ : ] , node . key ) copy ( b [ : ] , node . value )", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "so", "there", "are", "less", "allocations", "per", "run"], "add_tokens": "maxLength int hid := & HashID { } // Calculate the maximum possible string length by hashing the maximum possible id encoded , err := hid . EncodeInt64 ( [ ] int64 { math . MaxInt64 } ) if err != nil { return nil , fmt . Errorf ( \" \" , err ) } hid . maxLength = len ( encoded ) if hid . minLength > hid . maxLength { hid . maxLength = hid . minLength } return hid , nil result := make ( [ ] rune , 0 , h . maxLength )", "del_tokens": "return & HashID { } , nil result := make ( [ ] rune , 0 , h . minLength )", "commit_type": "make"}
{"commit_tokens": ["Added", "border", "-", "width", "collapse"], "add_tokens": "if prop == css . Margin || prop == css . Padding || prop == css . Border_Width {", "del_tokens": "if prop == css . Margin || prop == css . Padding {", "commit_type": "add"}
{"commit_tokens": ["Add", "json", "-", "schema", "keywords", "in", "generator"], "add_tokens": "Name string `json:\"name\" jsonschema:\"required,minLength=1,maxLength=20\"` Age int `json:\"age\" jsonschema:\"minimum=18,maximum=120,exclusiveMaximum=true,exclusiveMinimum=true\"` Email string `json:\"email\" jsonschema:\"format=email\"`", "del_tokens": "Name string `json:\"name\" jsonschema:\"required\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "native", "[]", "byte", "parsers", "for", "Parsing", "ints", "removing", "allocations", "and", "gaining", "another", "~4%", "on", "goser"], "add_tokens": "ic . OutputImports [ `ffjson_pills \"github.com/pquerna/ffjson/pills\"` ] = true // TODO: make native byte verions of ParseFloat ic . OutputImports [ `\"strconv\"` ] = true out += fmt . Sprintf ( \" \\n \" ,", "del_tokens": "ic . OutputImports [ `\"strconv\"` ] = true // TODO: make native byte verions of ParseInt/ParseUint out += fmt . Sprintf ( \" \\n \" ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "race", "in", "Test", "{", "Gracefulness", "Shutdown", "}"], "add_tokens": "statechanged := make ( chan http . ConnState ) listener , exitchan := startServer ( t , server , statechanged ) // avoid a race between the client connection and the server accept if state := <- statechanged ; state != http . StateNew { t . Fatal ( \" \" , state ) } statechanged := make ( chan http . ConnState ) listener , exitchan := startServer ( t , server , statechanged ) // avoid a race between the client connection and the server accept if state := <- statechanged ; state != http . StateNew { t . Fatal ( \" \" , state ) }", "del_tokens": "listener , exitchan := startServer ( t , server , nil ) listener , exitchan := startServer ( t , server , nil )", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "error", "handling", "check", "for", "topic", "and", "queue", "exits", "and", "dups"], "add_tokens": "func TestListTopicshandler_NoTopics ( t * testing . T ) {", "del_tokens": "func TestHealthCheckHandler_NoTopics ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["Create", "potentialNationalNumber", "from", "the", "copy", "of", "normalizedNationalNumber"], "add_tokens": "bufferCopy := make ( [ ] byte , normalizedNationalNumber . Len ( ) ) copy ( bufferCopy , normalizedNationalNumber . Bytes ( ) ) potentialNationalNumber := builder . NewBuilder ( bufferCopy )", "del_tokens": "potentialNationalNumber := builder . NewBuilder ( [ ] byte ( normalizedNationalNumber . String ( ) ) )", "commit_type": "create"}
{"commit_tokens": ["Fix", "panic", "when", "resources", "root", "path", "is", "not", "the", "working", "directory"], "add_tokens": "\" \" iconpath := filepath . Join ( walk . Resources . RootDirPath ( ) , filename ) err := ioutil . WriteFile ( iconpath , iconBytes , 0644 ) defer os . Remove ( iconpath ) iconpath := filepath . Join ( walk . Resources . RootDirPath ( ) , filename ) err := ioutil . WriteFile ( iconpath , iconBytes , 0644 ) defer os . Remove ( iconpath )", "del_tokens": "err := ioutil . WriteFile ( filename , iconBytes , 0644 ) defer os . Remove ( filename ) err := ioutil . WriteFile ( filename , iconBytes , 0644 ) defer os . Remove ( filename )", "commit_type": "fix"}
{"commit_tokens": ["Add", "-", "b", "flag", "to", "beep", "if", "any", "command", "exited", "with", "an", "error"], "add_tokens": "\" \" beep := kingpin . Flag ( \" \" , \" \" ) . Short ( 'b' ) . Bool ( ) if * beep { fmt . Print ( \" \\a \" ) } if * beep { fmt . Print ( \" \\a \" ) }", "del_tokens": "PlaceHolder ( \" \" ) .", "commit_type": "add"}
{"commit_tokens": ["adding", "tests", "and", "ToElementMatch", "func"], "add_tokens": "tests := map [ string ] struct { regexs [ ] * regexp . Regexp in string \" \" : { in : `<div><my-element-demo-one /><my-element-demo-two /><not-my-element-demo-one /></div>` , expected : `<div><my-element-demo-one/><my-element-demo-two/></div>` , } , \" \" : { in : `<div><my-element-demo-one data-test='test'></my-element-demo-one ><my-element-demo-two></my-element-demo-two><not-my-element-demo-one></not-my-element-demo-one></div>` , expected : `<div><my-element-demo-one></my-element-demo-one ><my-element-demo-two></my-element-demo-two></div>` , for _ , regex := range test . regexs {", "del_tokens": "tests := map [ string ] struct { regexs [ ] * regexp . Regexp in string \" \" : { in : `<div><my-element-demo-one /><my-element-demo-two /><not-my-element-demo-one /></div>` , expected : `<div><my-element-demo-one/><my-element-demo-two/></div>` , } , \" \" : { in : `<div><my-element-demo-one data-test='test'></my-element-demo-one ><my-element-demo-two></my-element-demo-two><not-my-element-demo-one></not-my-element-demo-one></div>` , expected : `<div><my-element-demo-one></my-element-demo-one ><my-element-demo-two></my-element-demo-two></div>` , for _ , regex := range test . regexs {", "commit_type": "add"}
{"commit_tokens": ["Make", "TestCanHandleRECONNECTMessage", "thread", "-", "safe"], "add_tokens": "\" \" var connCount int32 atomic . AddInt32 ( & connCount , 1 ) assertInt32sEqual ( t , 1 , atomic . LoadInt32 ( & connCount ) ) assertInt32sEqual ( t , 2 , atomic . LoadInt32 ( & connCount ) )", "del_tokens": "connCount := 0 connCount ++ assertIntsEqual ( t , 1 , connCount ) assertIntsEqual ( t , 2 , connCount )", "commit_type": "make"}
{"commit_tokens": ["Fix", "t", ".", "Error", "when", "t", ".", "Errorf", "was", "intended"], "add_tokens": "t . Errorf ( \" \" , i )", "del_tokens": "t . Error ( \" \" , i )", "commit_type": "fix"}
{"commit_tokens": ["Move", "credit", "cards", "to", "the", "right", "message", "set"], "add_tokens": "URL string Version string // OFX version string, overwritten in Client.Request() Signon SignonRequest //<SIGNONMSGSETV1> Signup [ ] Message //<SIGNUPMSGSETV1> Banking [ ] Message //<BANKMSGSETV1> CreditCards [ ] Message //<CREDITCARDMSGSETV1> if err := marshalMessageSet ( encoder , oq . CreditCards , \" \" ) ; err != nil { return nil , err }", "del_tokens": "URL string Version string // OFX version string, overwritten in Client.Request() Signon SignonRequest //<SIGNONMSGSETV1> Signup [ ] Message //<SIGNUPMSGSETV1> Banking [ ] Message //<BANKMSGSETV1> //<CREDITCARDMSGSETV1>", "commit_type": "move"}
{"commit_tokens": ["fix", "expr", "value", "of", "default"], "add_tokens": "dft = fmt . Sprintf ( \" \" , v . Int ( ) ) dft = fmt . Sprintf ( \" \" , v . Float ( ) )", "del_tokens": "dft = fmt . Sprintf ( \" \" , int64 ( v ) ) dft = fmt . Sprintf ( \" \" , float64 ( v ) )", "commit_type": "fix"}
{"commit_tokens": ["move", "parseFormat", "to", "formater", ".", "go"], "add_tokens": "import ( \" \" \" \" \" \" ) // parseFormat checks the legality of format and parses it to format and fargs func ( logger * Logger ) parseFormat ( format string ) error { fts := strings . Split ( format , \" \\n \" ) if len ( fts ) != 2 { return errors . New ( \" \" ) } logger . format = fts [ 0 ] logger . fargs = strings . Split ( fts [ 1 ] , \" \" ) for k , v := range logger . fargs { tv := strings . TrimSpace ( v ) _ , ok := fields [ tv ] if ok == false { return errors . New ( \" \" ) } logger . fargs [ k ] = tv } return nil }", "del_tokens": "import \" \"", "commit_type": "move"}
{"commit_tokens": ["removed", "Nullable", "from", "ColumnMap", "as", "it", "s", "not", "useful", ".", "Updated", "README", "hook", "docs"], "add_tokens": "// Unique and MaxSize only inform the if col . isPK {", "del_tokens": "// Nullable, Unique, and MaxSize only inform the // If false, \" not null\" is added to create table statements. // Not used elsewhere Nullable bool // If true \" not null\" will be added to create table statements for this // column func ( c * ColumnMap ) SetNullable ( b bool ) * ColumnMap { c . Nullable = b return c } Nullable : true , if ! col . Nullable || col . isPK {", "commit_type": "remove"}
{"commit_tokens": ["Allow", "users", "to", "specify", "file", "types", "was", "well", "as", "process", "types"], "add_tokens": "\" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , return \" \" , \" \" , fmt . Errorf ( \" \\n \" , opt ) return \" \" , \" \" , fmt . Errorf ( \" \" , con [ 0 ] ) if con [ 0 ] == \" \" { mcon [ \" \" ] = con [ 1 ] }", "del_tokens": "\" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , return \" \" , \" \" , fmt . Errorf ( \" \\n \" , opt ) return \" \" , \" \" , fmt . Errorf ( \" \" , con [ 0 ] )", "commit_type": "allow"}
{"commit_tokens": ["Added", "handling", "for", "connection", "errors", "in", "connection", "pool"], "add_tokens": "reclaim ( * boltConn ) error func ( d * boltDriverPool ) reclaim ( conn * boltConn ) error { var newConn * boltConn var err error if conn . connErr != nil || conn . closed { newConn , err = newPooledBoltConn ( d . connStr , d ) if err != nil { return err } } else { // sneakily swap out connection so a reference to // it isn't held on to newConn = & boltConn { } * newConn = * conn } return nil", "del_tokens": "reclaim ( * boltConn ) func ( d * boltDriverPool ) reclaim ( conn * boltConn ) { // sneakily swap out connection so a reference to // it isn't held on to newConn := & boltConn { } * newConn = * conn", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "submitting", "a", "reason", "would", "panic"], "add_tokens": "// Swappable impl for testing serviceClientFn func ( ) ( svc . AmazonEC2ContainerServiceV20141113 , error ) func NewECSClient ( credentialProvider credentials . AWSCredentialProvider , config * config . Config , insecureSkipVerify bool ) ECSClient { client := & ApiECSClient { credentialProvider : credentialProvider , config : config , insecureSkipVerify : insecureSkipVerify , } client . serviceClientFn = func ( ) ( svc . AmazonEC2ContainerServiceV20141113 , error ) { return client . serviceClientImpl ( ) } return client } // serviceClient provides a client for interacting with the ECS service apis func ( client * ApiECSClient ) serviceClient ( ) ( svc . AmazonEC2ContainerServiceV20141113 , error ) { return client . serviceClientFn ( ) } // serviceClientImpl is the default serviceClient provider. func ( client * ApiECSClient ) serviceClientImpl ( ) ( svc . AmazonEC2ContainerServiceV20141113 , error ) { reason := change . Reason if len ( reason ) > EcsMaxReasonLength { reason = reason [ : EcsMaxReasonLength ] }", "del_tokens": "// serviceClient recreates a new service clent and signer with each request. // This is because there is some question of whether the connection pool used by // the client is valid. func ( client * ApiECSClient ) serviceClient ( ) ( * svc . AmazonEC2ContainerServiceV20141113Client , error ) { func NewECSClient ( credentialProvider credentials . AWSCredentialProvider , config * config . Config , insecureSkipVerify bool ) ECSClient { return & ApiECSClient { credentialProvider : credentialProvider , config : config , insecureSkipVerify : insecureSkipVerify } } reason := change . Reason [ : EcsMaxReasonLength ]", "commit_type": "fix"}
{"commit_tokens": ["update", "example", "test", "case", "names", "so", "they", "render"], "add_tokens": "func ExampleCharge_post ( ) { func ExampleCharge_get ( ) { func ExampleInvoice_update ( ) { func ExampleCustomer_delete ( ) { func ExampleInvoiceItem_list ( ) {", "del_tokens": "func ExampleClient_post ( ) { func ExampleClient_get ( ) { func ExampleClient_update ( ) { func ExampleClient_delete ( ) { func ExampleClient_list ( ) {", "commit_type": "update"}
{"commit_tokens": ["change", "var", "name", "from", "skip", "to", "callDepth"], "add_tokens": "var callDepth int callDepth = 2 // user is calling qq.Log() callDepth = 1 // user is calling myCustomQQLogger.Log() pc , filename , line , ok := runtime . Caller ( callDepth )", "del_tokens": "var skip int // num levels up the call stack skip = 2 // user is calling qq.Log() skip = 1 // user is calling myCustomQQLogger.Log() pc , filename , line , ok := runtime . Caller ( skip )", "commit_type": "change"}
{"commit_tokens": ["use", "package", "-", "config", "to", "get", "LDFLAGS"], "add_tokens": "VideoCodecLongName string // Readable/long name of the video Codec AudioCodecLongName string // readable/long name of the audio codec", "del_tokens": "VideoCodecName string // Readable/long name of the video Codec AudioCodecName string // readable/long name of the audio codec", "commit_type": "use"}
{"commit_tokens": ["Use", "configured", "signal", "to", "restart", "daemons", "."], "add_tokens": "d . cmd . Process . Signal ( d . conf . RestartSignal )", "del_tokens": "\" \" d . cmd . Process . Signal ( syscall . SIGHUP )", "commit_type": "use"}
{"commit_tokens": ["removed", "top", "var", "from", "allocator"], "add_tokens": "fptrs : make ( [ ] float64 , 0 , size ) , if cap ( al . fptrs ) == len ( al . fptrs ) { al . fptrs = make ( [ ] float64 , 0 , al . size ) al . fptrs = append ( al . fptrs , float64 ( v ) ) fptr := ( * float64 ) ( unsafe . Pointer ( al . fheader . Data + uintptr ( len ( al . fptrs ) - 1 ) * unsafe . Sizeof ( _fv ) ) )", "del_tokens": "top int top : 0 , fptrs : make ( [ ] float64 , size ) , if al . top == len ( al . fptrs ) - 1 { al . top = 0 al . fptrs = make ( [ ] float64 , al . size ) fptr := ( * float64 ) ( unsafe . Pointer ( al . fheader . Data + uintptr ( al . top ) * unsafe . Sizeof ( _fv ) ) ) al . top ++ * fptr = float64 ( v )", "commit_type": "remove"}
{"commit_tokens": ["fix", "Sprintf", "utf8", "verb", "(", "tests", "failed", ")"], "add_tokens": "const utf8Verb = \" / verb that fit more then 1 byte got = fmt . Sprintf ( utf8Verb , v ) want = \" \\033 \" + fmt . Sprintf ( utf8Verb , 3.14 ) + got = fmt . Sprintf ( utf8Verb , v ) want = fmt . Sprintf ( utf8Verb , 3.14 )", "del_tokens": "got = fmt . Sprintf ( \" v want = \" \\033 \" + fmt . Sprintf ( \" 3 14) + got = fmt . Sprintf ( \" v want = fmt . Sprintf ( \" 3 14)", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "GOPATH", "workspace", "format"], "add_tokens": "import ( \" \" \" \" ) fmt . Printf ( \" \\n \" , os . Args )", "del_tokens": "import \" \"", "commit_type": "use"}
{"commit_tokens": ["added", "stochastic", "gradient", "descent", "for", "optimization"], "add_tokens": "// OptimizationMethod defines a type enum which // (using constants declared below) lets a user // pass in a optimization method to use when // creating a new model type OptimizationMethod string const ( BatchGA OptimizationMethod = \" \" StochasticGA = \" \" ) // with batch gradient descent where the parameter // vector theta is in one dimension only (so // softmax regression would need it's own model, // for example) // StochasticAscendable is an interface that can be used // with stochastic gradient descent where the parameter // vector theta is in one dimension only (so // softmax regression would need it's own model, // for example) type StochasticAscendable interface { // LearningRate returns the learning rate α // to be used in Gradient Descent as the // modifier term LearningRate ( ) float64 // Examples returns the number of examples in the // training set the model is using Examples ( ) int // Dj returns the derivative of the cost function // J(θ) with respect to the j-th parameter of // the hypothesis, θ[j], for the training example // x[i]. Called as Dij(i,j) Dij ( int , int ) ( float64 , error ) // Theta returns a pointer to the parameter vector // theta, which is 1D vector of floats Theta ( ) [ ] float64 // MaxIterations returns the maximum number of // iterations to try using gradient ascent. Might // return after less if strong convergance is // detected, but it'll let the user set a cap. MaxIterations ( ) int }", "del_tokens": "// with stochastic and/or batch gradient descent.", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "count", "on", "the", "number", "of", "elements", "recovered", "from", "memeory"], "add_tokens": "obj , err := store . ReadByKey ( \" \" ) actualObj := obj [ 0 ] . ( * TestObjBy1 )", "del_tokens": "obj , err := store . ReadOneByKey ( \" \" ) actualObj := obj . ( * TestObjBy1 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "so", "that", "p3", "runs", "as", "expected", "&", "added", "p3", "to", "gitignore"], "add_tokens": "package main", "del_tokens": "package cmd", "commit_type": "fix"}
{"commit_tokens": ["Allow", "customization", "of", "progress", "reporting", "interval"], "add_tokens": "client * http . Client jsonEncOpts * jsonEncOpts xmlEncOpts * xmlEncOpts flag int progressInterval time . Duration // default progress reporting interval is 200 milliseconds return & Req { flag : LstdFlags , progressInterval : 200 * time . Millisecond } form : formParam . Values , uploads : uploads , uploadProgress : up , progressInterval : resp . r . progressInterval , form url . Values uploads [ ] FileUpload dump [ ] byte uploadProgress UploadProgress progressInterval time . Duration if now := time . Now ( ) ; now . Sub ( lastTime ) > m . progressInterval {", "del_tokens": "client * http . Client jsonEncOpts * jsonEncOpts xmlEncOpts * xmlEncOpts flag int return & Req { flag : LstdFlags } form : formParam . Values , uploads : uploads , uploadProgress : up , form url . Values uploads [ ] FileUpload dump [ ] byte uploadProgress UploadProgress if now := time . Now ( ) ; now . Sub ( lastTime ) > 200 * time . Millisecond {", "commit_type": "allow"}
{"commit_tokens": ["Add", "example", "to", "the", "service", "prototype", "s", "documentation"], "add_tokens": "RequiredParam ( \" \" , \" \" , `Label for the service to target (e.g., \"{app: 'MyApp'}\").` , Object ) , to 't argetLabelSelector ', at 't argetPort '. Since 't argetLabelSelector ' is an object literal that specifies which labels the service is meant to target , this will typically look something like : ksonnet prototype use service -- targetLabelSelector \" \" [ ... ] `,", "del_tokens": "RequiredParam ( \" \" , \" \" , \" \" , Object ) , to 't argetLabelSelector ', at 't argetPort '.`,", "commit_type": "add"}
{"commit_tokens": ["make", "test", "a", "little", "more", "clear"], "add_tokens": "if ! exp . Equals ( & actual2 ) {", "del_tokens": "if ! ( * exp ) . Equals ( & actual2 ) {", "commit_type": "make"}
{"commit_tokens": ["add", "a", "wrapper", "Response", "struct", "that", "exposes", "the", "MediaType"], "add_tokens": "res := client . Get ( user , apierr , \" \" ) if res . IsError ( ) { t . Fatalf ( \" \" , res . Error ( ) ) res := client . Get ( user , apierr , \" \" ) if res . IsError ( ) { t . Fatalf ( \" \" , res . Error ( ) )", "del_tokens": "res , err := client . Get ( user , apierr , \" \" ) if err != nil { t . Fatalf ( \" \" , err ) res , err := client . Get ( user , apierr , \" \" ) if err != nil { t . Fatalf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Use", "finished", "upload", "for", "testing", "replay"], "add_tokens": "assemblyId = info . AssemblyId assemblyUrl = info . AssemblyUrl", "del_tokens": "assemblyId = info . AssemblyId assemblyUrl = info . AssemblyUrl", "commit_type": "use"}
{"commit_tokens": ["move", "container", "image", "logic", "to", "nomock", "server"], "add_tokens": "noReleaseServiceID string = \" \" //userId, err := nomockutil.GetSubjectInToken(p.token) // if err != nil { // return newService, err // } _ , err := servicesResource . Post ( serviceConfig )", "del_tokens": "\" \" noReleaseServiceID string = \" \" containerImagePrefix string = \" \" // IP:5000/nomock/ userId , err := nomockutil . GetSubjectInToken ( p . token ) if err != nil { return newService , err } if serviceConfig . IsSourceProject ( ) { serviceConfig . ContainerImage = containerImagePrefix + userId + \" \" + serviceConfig . ServiceName + \" \" } _ , err = servicesResource . Post ( serviceConfig )", "commit_type": "move"}
{"commit_tokens": ["remove", "step", ".", "yml", "befor", "copy", "new", "one"], "add_tokens": "if err := bitrise . RemoveFile ( stepYMLPth ) ; err != nil { log . Fatal ( \" \" , err ) }", "del_tokens": "if err := bitrise . RemoveFile ( stepYMLPth ) ; err != nil { log . Fatal ( \" \" , err ) }", "commit_type": "remove"}
{"commit_tokens": ["move", "watcher", "related", "code", "to", "watcher", ".", "go"], "add_tokens": "type BackgroundCallback func ( client CuratorFramework , event CuratorEvent ) error", "del_tokens": "type Watcher interface { Process ( event * zk . Event ) error } type BackgroundCallback interface { ProcessResult ( client CuratorFramework , event CuratorEvent ) error }", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "test", "bug", "."], "add_tokens": "ExpectThat ( err , Equals ( nil ) )", "del_tokens": "ExpectThat ( err , Equals ( \" \" ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "example", "of", "firehose", "filtering", "by", "envelope", "type"], "add_tokens": "\" \" \" \" filterType := flag . String ( \" \" , \" \" , \" \" ) flag . Parse ( ) cnsmr := consumer . New ( dopplerAddress , & tls . Config { InsecureSkipVerify : true } , nil ) cnsmr . SetDebugPrinter ( ConsoleDebugPrinter { } ) var ( msgChan <- chan * events . Envelope errorChan <- chan error ) switch * filterType { case \" \" : msgChan , errorChan = cnsmr . FilteredFirehose ( firehoseSubscriptionId , authToken , consumer . LogMessages ) case \" \" : msgChan , errorChan = cnsmr . FilteredFirehose ( firehoseSubscriptionId , authToken , consumer . Metrics ) default : msgChan , errorChan = cnsmr . Firehose ( firehoseSubscriptionId , authToken ) }", "del_tokens": "consumer := consumer . New ( dopplerAddress , & tls . Config { InsecureSkipVerify : true } , nil ) consumer . SetDebugPrinter ( ConsoleDebugPrinter { } ) msgChan , errorChan := consumer . Firehose ( firehoseSubscriptionId , authToken )", "commit_type": "add"}
{"commit_tokens": ["Add", "grid", "license", "unit", "test", "cases"], "add_tokens": "// GetGridInfo returns the details for grid", "del_tokens": "// GetLicense returns the details for grid", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "grammar", "handling", "of", "alter", "table", "add"], "add_tokens": "\" \" : COLUMN , \" \" : CONSTRAINT , \" \" : FOREIGN , \" \" : FULLTEXT , \" \" : SPATIAL ,", "del_tokens": "\" \" : UNUSED , \" \" : UNUSED , \" \" : UNUSED , \" \" : UNUSED , \" \" : UNUSED ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "status", "check", "for", "Document", "SaveAs", "function"], "add_tokens": "if status != 1 {", "del_tokens": "if status != 0 {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "generate", "doutput", "code", ".", "os", ".", "Error", "-", ">", "error", ".", "Remove", "calling", "of", "go", "fmt", "from", "code", ".", "This", "should", "really", "be", "done", "manually", "."], "add_tokens": "APP_VERSION = \" \" var err error", "del_tokens": "APP_VERSION = \" \" var err error // If gofmt exists on the system, use it to format the generated source file. if err = gofmt ( * out ) ; err != nil { fmt . Fprintf ( os . Stderr , \" \\n \" , err ) return }", "commit_type": "fix"}
{"commit_tokens": ["Removed", "functionality", "/", "code", "for", "comparing", "(", "during", "dev", ")", "to", "reference", "code"], "add_tokens": "func New512 ( ) hash . Hash { compress ( d , d . x [ : ] ) compress ( d , p [ : n ] ) compress ( d , d . x [ : ] )", "del_tokens": "sseOptimized bool // temp bool to indicate use of SSE (during dev only) func New512 ( enableSSE bool ) hash . Hash { if enableSSE { d . EnableSSE ( ) } // Enable SSE func ( d * digest ) EnableSSE ( ) { d . sseOptimized = true } if d . sseOptimized { compress ( d , d . x [ : ] ) } else { blocks ( d , d . x [ : ] ) } if d . sseOptimized { compress ( d , p [ : n ] ) } else { blocks ( d , p [ : n ] ) } if d . sseOptimized { compress ( d , d . x [ : ] ) } else { blocks ( d , d . x [ : ] ) }", "commit_type": "remove"}
{"commit_tokens": ["changed", "input", "parameter", "of", "encrypt", "function", "to", "byte", "slice"], "add_tokens": "// This method accepts the message as byte slice, then encrypts it using a symmetric key func ( engine * CryptoEngine ) NewMessage ( message [ ] byte ) ( Message , error ) { encryptedData := secretbox . Seal ( nil , message , & m . nonce , & engine . secretKey ) // This method accepts the message as byte slice and the public key of the receiver of the messae, func ( engine * CryptoEngine ) NewMessageToPubKey ( message [ ] byte , peerPublicKey [ ] byte ) ( Message , error ) {", "del_tokens": "// This method accepts the message as string, then encrypts it using a symmetric key func ( engine * CryptoEngine ) NewMessage ( message string ) ( Message , error ) { messageBytes := [ ] byte ( message ) encryptedData := secretbox . Seal ( nil , messageBytes , & m . nonce , & engine . secretKey ) // This method accepts the message as string and the public key of the receiver of the messae, func ( engine * CryptoEngine ) NewMessageToPubKey ( message string , peerPublicKey [ ] byte ) ( Message , error ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "spelling", "mistake", "in", "comment"], "add_tokens": "// get back to 0 or trim the leading separator", "del_tokens": "// get back to 0 or trim the leading seperator", "commit_type": "fix"}
{"commit_tokens": ["added", "Close", "method", "to", "speaker"], "add_tokens": "// Close closes the playback and the driver. In most cases, there is certainly no need to call Close // even when the program doesn't play anymore, because in properly set systems, the default mixer // handles multiple concurrent processes. It's only when the default device is not a virtual but hardware // device, that you'll probably want to manually manage the device from your application.", "del_tokens": "// Close closes playback and driver. In most cases, there is certainly no need to call Close // even when program doesn't play anymore and it won't exist, because in properly set systems, // the default mixer handles multiple processes. It's only when the default device is not virtual // but hardware device that you'll probably want to manually manage the device from your application.", "commit_type": "add"}
{"commit_tokens": ["Added", "basic", "if", "/", "else", "handling"], "add_tokens": "return l mkModule ( newBlockNode ( newNameExpr ( \" \" ) , mkModule ( newTextNode ( \" \" , 0 ) ) , 0 ) ) , } , { \" \" , \" \" , mkModule ( newIfNode ( newNameExpr ( \" \" ) , mkModule ( newTextNode ( \" \" , 0 ) ) , mkModule ( newTextNode ( \" \" , 0 ) ) , 0 ) ) ,", "del_tokens": "return node ( l ) mkModule ( newTagNode ( \" \" , mkModule ( newTextNode ( \" \" , 0 ) ) , map [ string ] expr { \" \" : newNameExpr ( \" \" ) } , 0 ) ) ,", "commit_type": "add"}
{"commit_tokens": ["move", "reply", "convert", "method", "from", "Redis", "struct", "to", "Reply", "struct"], "add_tokens": "l , err := rp . ListValue ( ) if err := rp . OKStatusValue ( ) ; err != nil { n , err := rp . IntegerValue ( ) if s , err := rp . Multi [ 2 ] . Multi [ 1 ] . StringBulkValue ( ) ; err != nil || s != \" \" {", "del_tokens": "l , err := r . ListReturnValue ( rp ) if err := r . OKStatusReturnValue ( rp ) ; err != nil { n , err := r . IntegerReturnValue ( rp ) if s , err := r . StringBulkReturnValue ( rp . Multi [ 2 ] . Multi [ 1 ] ) ; err != nil || s != \" \" {", "commit_type": "move"}
{"commit_tokens": ["Creating", "constants", "to", "JSON", "and", "Plain", "Text"], "add_tokens": "// ContentTypeJSON define json content type ContentTypeJSON string = \" \" // ContentTypePlain define plain text content type ContentTypePlain string = \" \" Payload interface { } m . ContentType = ContentTypeJson", "del_tokens": "Payload [ ] byte m . ContentType = \" \"", "commit_type": "create"}
{"commit_tokens": ["Use", "a", "map", "instead", "of", "slice", "for", "arguments"], "add_tokens": "AllowedContent map [ string ] bool if _ , ok := opts [ 0 ] . AllowedContent [ c . Type ( ) ] ; ok {", "del_tokens": "\" \" AllowedContent [ ] string // Sort and search opts.AllowedContent types sort . Strings ( opts [ 0 ] . AllowedContent ) i := sort . SearchStrings ( opts [ 0 ] . AllowedContent , c . Type ( ) ) if c . Request ( ) . ContentLength == 0 { if c . Request ( ) . ContentLength >= 1 { if i < len ( opts [ 0 ] . AllowedContent ) { return h ( c ) } }", "commit_type": "use"}
{"commit_tokens": ["Added", "quotes", "to", "names", "in", "address", "headers"], "add_tokens": "n := msg . encodeHeader ( name ) if n == name { n = quote ( name ) } return n + \" \" + address + \" \" func quote ( text string ) string { buf := bytes . NewBufferString ( `\"` ) for i := 0 ; i < len ( text ) ; i ++ { if text [ i ] == '\\\\' || text [ i ] == '\"' { buf . WriteByte ( '\\\\' ) } buf . WriteByte ( text [ i ] ) } buf . WriteByte ( '\"' ) return buf . String ( ) }", "del_tokens": "return msg . encodeHeader ( name ) + \" \" + address + \" \"", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", "in", "function", "name"], "add_tokens": "// computePatternStr computes the pattern string required for generating the route's regex. func ( r * Route ) computePatternStr ( patternString string , hasWildcard bool , key string ) string { patternString = r . computePatternStr ( patternString , hasWildcard , key ) patternString = r . computePatternStr ( patternString , hasWildcard , key )", "del_tokens": "// computerPatternStr computes the pattern string required for the route's regex. func ( r * Route ) computerPatternStr ( patternString string , hasWildcard bool , key string ) string { patternString = r . computerPatternStr ( patternString , hasWildcard , key ) patternString = r . computerPatternStr ( patternString , hasWildcard , key )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "router", "for", "trie", "-", "mux"], "add_tokens": "const Version = \" \"", "del_tokens": "const Version = \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "dev", "flag", "for", "skipping", "challenge", "pre", "-", "checks"], "add_tokens": "devMode bool // caURL - The root url to the boulder instance you want certificates from // usr - A filled in user struct // optPort - The alternative port to listen on for challenges. // devMode - If set to true, all CanSolve() checks are skipped. func NewClient ( caURL string , usr User , keyBits int , optPort string , devMode bool ) * Client { return & Client { directory : dir , user : usr , jws : jws , keyBits : keyBits , devMode : devMode , solvers : solvers } if solver , ok := c . solvers [ auth . Challenges [ idx ] . Type ] ; ok && ( c . devMode || solver . CanSolve ( domain ) ) {", "del_tokens": "func NewClient ( caURL string , usr User , keyBits int , optPort string ) * Client { return & Client { directory : dir , user : usr , jws : jws , keyBits : keyBits , solvers : solvers } if solver , ok := c . solvers [ auth . Challenges [ idx ] . Type ] ; ok && solver . CanSolve ( domain ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "ErrorId", ".", "cant", "get", "a", "pointer", "uint", "from", "a", "value", "object", "only", "a", "pointer", "/", "chan", "/", "map", "/", "etc"], "add_tokens": "expected := \" \"", "del_tokens": "expected := fmt . Sprintf ( \" \" , ErrorId ( err ) )", "commit_type": "remove"}
{"commit_tokens": ["Use", "Path", "insetad", "of", "Directory"], "add_tokens": "Path string `mapstructure:\"path\"` Path string `form:\"path,omitempty\"` Path string `form:\"path,omitempty\"`", "del_tokens": "Directory string `mapstructure:\"directory\"` Directory string `form:\"directory,omitempty\"` Directory string `form:\"directory,omitempty\"`", "commit_type": "use"}
{"commit_tokens": ["Add", "load", "balancing", "support", "to", "services", "."], "add_tokens": "if svc . ( * api . Service ) . CreateExternalLoadBalancer {", "del_tokens": "if svc . ( api . Service ) . CreateExternalLoadBalancer {", "commit_type": "add"}
{"commit_tokens": ["Added", "interface", "for", "custom", "loggers"], "add_tokens": "// Logger interface allows to use other loggers than // standard log.Logger. type Logger interface { Printf ( string , ... interface { } ) } type RequestLogHook func ( Logger , * http . Request , int ) type ResponseLogHook func ( Logger , * http . Response ) Logger Logger // Customer logger instance.", "del_tokens": "type RequestLogHook func ( * log . Logger , * http . Request , int ) type ResponseLogHook func ( * log . Logger , * http . Response ) Logger * log . Logger // Customer logger instance.", "commit_type": "add"}
{"commit_tokens": ["Fix", "tests", "(", "lowercase", "error", ")"], "add_tokens": "// error: User with mail: user1@mail.go already exists // error: User with mail: user1@mail.go already exists t . Fatalf ( \" \\n \\n \" , method , expectingMsg , formattedErr . Error ( ) ) Prefix = \" \" Prefix = \" \" Prefix = \" \"", "del_tokens": "// Error: User with mail: user1@mail.go already exists // Error: User with mail: user1@mail.go already exists t . Fatalf ( \" \\n \\n \" , method , expectingMsg , formattedErr . Error ( ) ) Prefix = \" \" Prefix = \" \" Prefix = \" \"", "commit_type": "fix"}
{"commit_tokens": ["fix", "v3", "when", "grpcConn", "is", "nil"], "add_tokens": "image , err := registry . ParseImage ( repo + \" \" + tag ) } ) . Errorf ( \" \" , repo , tag , err ) // Get the vulnerability report. result , err := rc . cl . VulnerabilitiesV3 ( rc . reg , image . Path , image . Reference ( ) ) if err != nil { // Fallback to Clair v2 API. result , err = rc . cl . Vulnerabilities ( rc . reg , image . Path , image . Reference ( ) ) if err != nil { logrus . WithFields ( logrus . Fields { \" \" : \" \" , \" \" : r . URL , \" \" : r . Method , } ) . Errorf ( \" \" , repo , tag , err ) w . WriteHeader ( http . StatusInternalServerError ) return } }", "del_tokens": "result , err := rc . cl . Vulnerabilities ( rc . reg , repo , tag ) } ) . Errorf ( \" \" , repo , tag , err )", "commit_type": "fix"}
{"commit_tokens": ["added", "loggercontext", "and", "Logger", ".", "LogWithCtx", "support"], "add_tokens": "import \" \" Log ( keyVals ... interface { } ) error // LogWithCtx is the same as Log but additionally taking a context which may // contain additional key-value pairs that are added to the log issuance, if // any. LogWithCtx ( ctx context . Context , keyVals ... interface { } ) error // With returns a new contextual logger with keyVals appended to those // created by With, keyVals is appended to the existing context. With ( keyVals ... interface { } ) Logger", "del_tokens": "Log ( v ... interface { } ) error // With returns a new contextual logger with keyvals appended to those // created by With, keyvals is appended to the existing context. With ( keyvals ... interface { } ) Logger", "commit_type": "add"}
{"commit_tokens": ["Update", "for", "weekly", "of", "2011", "-", "07", "-", "16", ";", "changes", "to", "string", ".", "Split", "()", "."], "add_tokens": "t := strings . SplitN ( line . Args [ 1 ] [ 1 : len ( line . Args [ 1 ] ) - 1 ] , \" \" , 2 ) a := strings . SplitN ( line . Args [ len ( line . Args ) - 1 ] , \" \" , 2 ) nicks := strings . Split ( line . Args [ len ( line . Args ) - 1 ] , \" \" )", "del_tokens": "t := strings . Split ( line . Args [ 1 ] [ 1 : len ( line . Args [ 1 ] ) - 1 ] , \" \" , 2 ) a := strings . Split ( line . Args [ len ( line . Args ) - 1 ] , \" \" , 2 ) nicks := strings . Split ( line . Args [ len ( line . Args ) - 1 ] , \" \" , - 1 )", "commit_type": "update"}
{"commit_tokens": ["Fix", "invalid", "rollback", "in", "asm", "vertical", "routines"], "add_tokens": "a . Movq ( AX , DX ) a . Orq ( AX , AX ) a . Subq ( DX , Constant ( xwidth * 2 ) ) a . Subq ( DX , Constant ( xwidth ) ) a . Neg ( DX ) a . Movq ( v . backroll , DX )", "del_tokens": "a . Movq ( AX , DX ) if v . xtaps == 2 { a . Andq ( AX , Constant ( xwidth - 1 ) ) } else { a . Andq ( AX , Constant ( xwidth >> 1 - 1 ) ) } a . Subq ( AX , Constant ( xwidth * 2 ) ) a . Subq ( AX , Constant ( xwidth ) ) a . Neg ( AX ) a . Movq ( v . backroll , AX ) a . Subq ( CX , Constant ( 1 ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "unavailable", "reason", "to", "all", "report"], "add_tokens": "UnavailableReason string `json:\"unavailable_reason,omitempty\"` r := Report { if status != nil { r . UnavailableReason = status . Error ( ) } return r", "del_tokens": "return Report {", "commit_type": "add"}
{"commit_tokens": ["remove", "lxc", "config", "set", "<remote", ">", "password", "foo"], "add_tokens": "if len ( args ) != 3 { return errArgs password := args [ 2 ] c , _ , err := lxd . NewClient ( config , \" \" )", "del_tokens": "if len ( args ) != 4 && len ( args ) != 3 { return errArgs } if len ( args ) == 4 { action = args [ 2 ] } server := \" \" password := args [ 2 ] if len ( args ) == 4 { servername := fmt . Sprintf ( \" \" , args [ 1 ] ) r , ok := config . Remotes [ servername ] if ! ok { return fmt . Errorf ( \" \" , servername ) } server = r . Addr fmt . Printf ( \" \" , servername ) password = args [ 3 ] c , _ , err := lxd . NewClient ( config , server )", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "couple", "Println", "/", "f", "cases"], "add_tokens": "fmt . Printf ( \" \\n \" , rerr ) fmt . Printf ( \" \\n \" , rerr )", "del_tokens": "fmt . Println ( \" \" , rerr ) fmt . Println ( \" \" , rerr )", "commit_type": "fix"}
{"commit_tokens": ["remove", "http", "method", "constants", "from", "tests"], "add_tokens": "if r . Method == \" \" { if r . Method == \" \" { if r . Method == \" \" { if r . Method == \" \" { if r . Method == \" \" { if r . Method == \" \" { if r . Method == \" \" { if r . Method == \" \" {", "del_tokens": "if r . Method == http . MethodPost { if r . Method == http . MethodGet { if r . Method == http . MethodGet { if r . Method == http . MethodPut { if r . Method == http . MethodDelete { if r . Method == http . MethodGet { if r . Method == http . MethodPut { if r . Method == http . MethodDelete {", "commit_type": "remove"}
{"commit_tokens": ["Upgrade", "to", "new", "RegisterViewPath", "API"], "add_tokens": "meta . GetBaseResource ( ) . ( * admin . Resource ) . GetAdmin ( ) . RegisterViewPath ( \" \" )", "del_tokens": "admin . RegisterViewPath ( \" \" )", "commit_type": "upgrade"}
{"commit_tokens": ["Fix", "the", "registration", "order", "of", "health", "path"], "add_tokens": "r . HandleFunc ( \" \" , health ) . Methods ( \" \" )", "del_tokens": "r . HandleFunc ( \" \" , health ) . Methods ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["removed", "the", "dep", "on", "markbates", "/", "going"], "add_tokens": "wg := & sync . WaitGroup { } for i , _ := range validators { wg . Add ( 1 ) go func ( wg * sync . WaitGroup , i int ) { defer wg . Done ( ) validator := validators [ i ] validator . IsValid ( errors ) } ( wg , i ) } wg . Wait ( )", "del_tokens": "\" \" wait . Wait ( len ( validators ) , func ( index int ) { validator := validators [ index ] validator . IsValid ( errors ) } )", "commit_type": "remove"}
{"commit_tokens": ["use", "time", ".", "Time", "for", "startTime"], "add_tokens": "return logger . startTime . UnixNano ( ) return logger . startTime . Nanosecond ( ) return l . time . Sub ( logger . startTime ) . Nanoseconds ( )", "del_tokens": "return logger . startTime return logger . startTime % 1000 return l . time . UnixNano ( ) - logger . startTime", "commit_type": "use"}
{"commit_tokens": ["implement", "fetch", "metrics", "using", "prometheus", "common", "/", "expfmt"], "add_tokens": "\" \" // every pushIntervalSeconds. Metrics are fetched from func ( p * Prometheus ) SetPushGateway ( pushGatewayURL string , pushIntervalSeconds time . Duration ) { out := & bytes . Buffer { } metricFamilies , _ := prometheus . DefaultGatherer . Gather ( ) for i := range metricFamilies { expfmt . MetricFamilyToText ( out , metricFamilies [ i ] ) } return out . Bytes ( )", "del_tokens": "\" \" // Local metrics URL where metrics are fetched from, this could be ommited in the future // if implemented using prometheus common/expfmt instead MetricsURL string // every pushIntervalSeconds. Metrics are fetched from metricsURL func ( p * Prometheus ) SetPushGateway ( pushGatewayURL , metricsURL string , pushIntervalSeconds time . Duration ) { p . Ppg . MetricsURL = metricsURL response , err := http . Get ( p . Ppg . MetricsURL ) if err != nil { log . Errorf ( \" \" , err ) } defer response . Body . Close ( ) body , _ := ioutil . ReadAll ( response . Body ) return body", "commit_type": "implement"}
{"commit_tokens": ["Add", "support", "for", "adding", "routes", "in", "handler", "add", "route", ".", "Route", "method"], "add_tokens": "r := Render { res , nil , nil , RenderOptions { } , \" \" , time . Now ( ) } r := Render { res , nil , nil , RenderOptions { } , \" \" , time . Now ( ) } r := Render { res , nil , nil , RenderOptions { } , \" \" , time . Now ( ) } r := Render { res , & req , nil , RenderOptions { } , \" \" , time . Now ( ) } r := Render { res , & req , nil , RenderOptions { } , \" \" , time . Now ( ) }", "del_tokens": "r := Render { res , nil , nil , RenderOptions { } , \" \" , nil , time . Now ( ) } r := Render { res , nil , nil , RenderOptions { } , \" \" , nil , time . Now ( ) } r := Render { res , nil , nil , RenderOptions { } , \" \" , nil , time . Now ( ) } r := Render { res , & req , nil , RenderOptions { } , \" \" , nil , time . Now ( ) } r := Render { res , & req , nil , RenderOptions { } , \" \" , nil , time . Now ( ) }", "commit_type": "add"}
{"commit_tokens": ["Use", "program", "counters", "instead", "of", "stacks", "to", "track", "ref", "count", "usage"], "add_tokens": "\" \" finalizer unsafe . Pointer finalizerPtr := ( * Finalizer ) ( atomic . LoadPointer ( & c . finalizer ) ) if finalizerPtr != nil { finalizer := * finalizerPtr finalizer . Finalize ( ) finalizerPtr := ( * Finalizer ) ( atomic . LoadPointer ( & c . finalizer ) ) if finalizerPtr == nil { return nil } return * finalizerPtr atomic . StorePointer ( & c . finalizer , unsafe . Pointer ( & f ) )", "del_tokens": "finalizer Finalizer if c . finalizer != nil { c . finalizer . Finalize ( ) return c . finalizer c . finalizer = f", "commit_type": "use"}
{"commit_tokens": ["Remove", "unmarshalmap", ".", "Generator", "interface"], "add_tokens": "gen * Generator g * Generator", "del_tokens": "gen * generator g * generator", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "separate", "file", "for", "errors"], "add_tokens": "actual := buffer . String ( ) [ 20 : len ( buffer . String ( ) ) - 1 ] }", "del_tokens": "actual := buffer . String ( ) [ 20 : len ( buffer . String ( ) ) - 1 ] }", "commit_type": "add"}
{"commit_tokens": ["Add", "integration", "for", "build", "-", "info"], "add_tokens": "status \" \" log . Printf ( \" \" , serviceName ) m . HandleFunc ( status . PingPath , status . PingHandler ) m . HandleFunc ( status . PingPathDW , status . PingHandler ) m . HandleFunc ( status . BuildInfoPath , status . BuildInfoHandler ) m . HandleFunc ( status . BuildInfoPathDW , status . BuildInfoHandler )", "del_tokens": "log . Printf ( \" \" , serviceName ) m . HandleFunc ( \" \" , pingHandler ) m . HandleFunc ( \" \" , pingHandler ) m . HandleFunc ( \" \" , buildInfoHandler ) m . HandleFunc ( \" \" , buildInfoHandler )", "commit_type": "add"}
{"commit_tokens": ["Add", "RDM", "name", "to", "digital_magazine", "clip"], "add_tokens": "src . layout = redLayout { name } type redLayout struct { rdmName string } func ( red redLayout ) clipName ( path string ) ( clip string , ok bool ) { if * includeRedMagazine && isDigitalMagazineName ( parts [ 0 ] ) { return red . rdmName + \" \" , true func isDigitalMagazineName ( name string ) bool { return name == \" \" || name == \" \" }", "del_tokens": "src . layout = redLayout { } type redLayout struct { } func ( redLayout ) clipName ( path string ) ( clip string , ok bool ) { if * includeRedMagazine && ( parts [ 0 ] == \" \" || parts [ 0 ] == \" \" ) { // TODO(light): differentiate based on RDMs return \" \" , true", "commit_type": "add"}
{"commit_tokens": ["Remove", "outdated", "file", "name", "list", "."], "add_tokens": "func ( d * indexData ) fileName ( i uint32 ) string { return string ( d . fileNameContent [ d . fileNameIndex [ i ] : d . fileNameIndex [ i + 1 ] ] ) }", "del_tokens": "// TODO - delme fileNames [ ] string toc . names . readIndex ( r ) fnIndex := toc . names . relativeIndex ( ) fnBlob := r . readSectionBlob ( toc . names . data ) for i , n := range fnIndex { if i == 0 { continue } d . fileNames = append ( d . fileNames , string ( fnBlob [ fnIndex [ i - 1 ] : n ] ) ) }", "commit_type": "remove"}
{"commit_tokens": ["Move", "default", "MaxSize", "setup", "into", "compareReader", "()"], "add_tokens": "if c . Opt . MaxSize == 0 { c . Opt . MaxSize = defaultMaxSize }", "del_tokens": "if c . Opt . MaxSize == 0 { c . Opt . MaxSize = defaultMaxSize }", "commit_type": "move"}
{"commit_tokens": ["Added", "check", "for", "language", "existence"], "add_tokens": "func NewFaker ( config Config ) ( Faker , error ) { if config . Lang == \" \" { config . Lang = \" \" } err := checkLang ( config ) if err != nil { return nil , err } } , nil } func checkLang ( config Config ) error { availLangs := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } found := false for _ , lang := range availLangs { if config . Lang == lang { found = true break } } if ! found { return fmt . Errorf ( \" \" , config . Lang ) return nil", "del_tokens": "func NewFaker ( config * Config ) Faker { fmt . Println ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "code", "generator", "initialisation"], "add_tokens": "cl := hello . NewSayClient ( \" \" , client . DefaultClient )", "del_tokens": "cl := hello . NewSayClient ( client . DefaultClient )", "commit_type": "update"}
{"commit_tokens": ["Use", "bytes", ".", "Equal", "to", "compare", "two", "byte", "arrays", "."], "add_tokens": "\" \" } else if bytes . Equal ( actualHeader , perfHeader ) {", "del_tokens": "} else if string ( actualHeader ) == string ( perfHeader ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "custom", "log", "levels"], "add_tokens": "levels = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } Print ( int , ... interface { } ) Printf ( int , string , ... interface { } ) if l >= 0 && l <= len ( levels ) - 1 { func Print ( lvl int , v ... interface { } ) { stdLog . output ( & Message { lvl , fmt . Sprint ( v ... ) , time . Now ( ) } ) } func Printf ( lvl int , format string , v ... interface { } ) { stdLog . output ( & Message { lvl , fmt . Sprintf ( format , v ... ) , time . Now ( ) } ) }", "del_tokens": "LOG levels = [ ... ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" } if l >= TRACE && l <= FATAL {", "commit_type": "add"}
{"commit_tokens": ["Use", "hex", ".", "Encode", "instead", "of", "fmt", ".", "Sprintf"], "add_tokens": "// ipmitool needs every byte to be a separate argument buf = append ( buf , \" \" + hex . EncodeToString ( data [ i : i + 1 ] ) )", "del_tokens": "// ipmitool raw wasn't happy with hex.Encode buf = append ( buf , fmt . Sprintf ( \" \" , data [ i : i + 1 ] ) )", "commit_type": "use"}
{"commit_tokens": ["Using", "new", "base", "-", "rw", "to", "disable", "access", "logs"], "add_tokens": "\" \" healthHandler := v1a . Handler ( \" \" , \" \" , checks ... ) baseftrwapp . RunServerWithConf ( baseftrwapp . RWConf { Engs : engs , HealthHandler : healthHandler , Port : * port , ServiceName : \" \" , Env : * env , EnableReqLog : false , } ) Checker : func ( ) ( string , error ) { return \" \" , service . Check ( ) } ,", "del_tokens": "\" \" log . SetLevel ( log . InfoLevel ) log . Println ( \" \" , os . Args ) baseftrwapp . RunServer ( engs , v1a . Handler ( \" \" , \" \" , checks ... ) , * port , \" \" , * env ) Checker : func ( ) ( string , error ) { return \" \" , service . Check ( ) } ,", "commit_type": "use"}
{"commit_tokens": ["fix", "off", "by", "one", "."], "add_tokens": "randIndex -- randIndex --", "del_tokens": "randIndex -- randIndex --", "commit_type": "fix"}
{"commit_tokens": ["Make", "Client", "an", "interface", "instead", "of", "a", "struct"], "add_tokens": "var client = ofxgo . GetClient ( serverURL , & ofxgo . BasicClient { AppID : appID , AppVer : appVer , SpecVersion : ver , NoIndent : noindent , } )", "del_tokens": "var client = ofxgo . BasicClient { AppID : appID , AppVer : appVer , SpecVersion : ver , NoIndent : noindent , }", "commit_type": "make"}
{"commit_tokens": ["Add", "smoke", "test", "for", "Handler", "."], "add_tokens": "func TestHandlerCallsHandler ( t * testing . T ) { mockHandler := & MockedHandler { } mockHandler . On ( \" \" ) . Return ( ) handler := Handler ( mockHandler ) req , _ := http . NewRequest ( \" \" , \" \" , nil ) w := httptest . NewRecorder ( ) handler . ServeHTTP ( w , req ) mockHandler . AssertCalled ( t , \" \" ) } mockHandler := & MockedHandler { } mockHandler . On ( \" \" ) . Return ( ) metricsHandler := MetricsHandler ( mockHandler ) mockHandler . AssertCalled ( t , \" \" )", "del_tokens": "handler := & MockedHandler { } handler . On ( \" \" ) . Return ( ) metricsHandler := MetricsHandler ( handler ) handler . AssertCalled ( t , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "json", ":", "omitempty", "from", "Sum", "stats", "because", "zero", "is", "valid", "for", "it", "."], "add_tokens": "Sum float64 Min float64 `json:\",omitempty\"` Avg float64 `json:\",omitempty\"` Med float64 `json:\",omitempty\"` // median Pct95 float64 `json:\",omitempty\"` // 95th percentile Max float64 `json:\",omitempty\"` Sum uint64 Min uint64 `json:\",omitempty\"` Avg uint64 `json:\",omitempty\"` Med uint64 `json:\",omitempty\"` // median Pct95 uint64 `json:\",omitempty\"` // 95th percentile Max uint64 `json:\",omitempty\"`", "del_tokens": "Sum float64 `json:\",omitempty\"` Min float64 `json:\",omitempty\"` Avg float64 `json:\",omitempty\"` Med float64 `json:\",omitempty\"` // median Pct95 float64 `json:\",omitempty\"` // 95th percentile Max float64 `json:\",omitempty\"` Sum uint64 `json:\",omitempty\"` Min uint64 `json:\",omitempty\"` Avg uint64 `json:\",omitempty\"` Med uint64 `json:\",omitempty\"` // median Pct95 uint64 `json:\",omitempty\"` // 95th percentile Max uint64 `json:\",omitempty\"`", "commit_type": "remove"}
{"commit_tokens": ["Move", "middlewares", "to", "middleware", "directory"], "add_tokens": "package middleware func wrapResponseWriter ( w http . ResponseWriter ) ResponseWriter {", "del_tokens": "package lion func WrapResponseWriter ( w http . ResponseWriter ) ResponseWriter {", "commit_type": "move"}
{"commit_tokens": ["Fix", "top", "-", "level", "ordering", "+", "additional", "testing"], "add_tokens": "group = func ( ) { } group = func ( ) { } group ( ) n . loc [ 0 ] -- group ( )", "del_tokens": "group = nil if group != nil { group ( ) } n . loc [ 0 ] = - 1 if group != nil { group ( ) }", "commit_type": "fix"}
{"commit_tokens": ["Used", "the", "same", "default", "paths", "for", "cluster", "-", "id", "and", "detect_ip", "on", "Windows", "and", "Linux"], "add_tokens": "return \" \"", "del_tokens": "return \" \"", "commit_type": "use"}
{"commit_tokens": ["Added", "tests", "for", "pipeline", "actions"], "add_tokens": "return r . ResponseBody , resp , nil", "del_tokens": "return r . ResponseBody , nil , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", ":", "pass", "a", "wrong", "bit", "number"], "add_tokens": "v , err := strconv . ParseInt ( value , 0 , 64 )", "del_tokens": "v , err := strconv . ParseInt ( value , 0 , 10 )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "two", "go", "vet", "issues", "in", "the", "tests"], "add_tokens": "t . Errorf ( \" \" , err ) t . Errorf ( \" \" , err )", "del_tokens": "t . Error ( \" \" , err ) t . Error ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Add", "New", "*", "Clients", "functions", "to", "the", "generated", "code", "to", "simplify", "their", "use", "."], "add_tokens": "\" \" // {{$srvIdent}} is a client for UPnP SOAP service with URN \"{{.URN}}\". See // goupnp.ServiceClient, which contains RootDevice and Service attributes which // are provided for informational value. goupnp . ServiceClient } // New{{$srvIdent}}Clients discovers instances of the service on the network, // and returns clients to any that are found. errors will contain an error for // any devices that replied but which could not be queried, and err will be set // if the discovery process failed outright. // // This is a typical entry calling point into this package. func New { { $ srvIdent } } Clients ( ) ( clients [ ] * { { $ srvIdent } } , errors [ ] error , err error ) { var genericClients [ ] goupnp . ServiceClient if genericClients , errors , err = goupnp . NewServiceClients ( { { $ srv . Const } } ) ; err != nil { return } clients = make ( [ ] * { { $ srvIdent } } , len ( genericClients ) ) for i := range genericClients { clients [ i ] = & { { $ srvIdent } } { genericClients [ i ] } } return", "del_tokens": "// {{$srvIdent}} is a client for UPnP SOAP service with URN \"{{.URN}}\". SOAPClient * soap . SOAPClient", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "build", "after", "a", "change", "in", "package", "gcs", "."], "add_tokens": "return gcs . NewConn ( projectId , httpClient )", "del_tokens": "return gcs . OpenConn ( projectId , httpClient )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "uniqueMergeSortedStrings", "when", "both", "lists", "are", "empty"], "add_tokens": "assert ( i < len ( varSet ) )", "del_tokens": "assert ( i < len ( varSet ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "additional", "DEA", "variables", "to", "App"], "add_tokens": "Id string `json:\"instance_id\"` // id of the app Index int `json:\"instance_index\"` // index of the app Name string `json:\"name\"` // name of the app Host string `json:\"host\"` // host of the app Port int `json:\"port\"` // port of the app Version string `json:\"version\"` // version of the app Home string // root folder for the deployed app MemoryLimit string // maximum amount of memory that each instance of the application can consume WorkingDir string // present working directory, where the buildpack that processed the application ran TempDir string // directory location where temporary and staging files are stored User string // user account under which the DEA runs", "del_tokens": "Id string `json:\"instance_id\"` // id of the app Index int `json:\"instance_index\"` // index of the app Name string `json:\"name\"` // name of the app Host string `json:\"host\"` // host of the app Port int `json:\"port\"` // port of the app Version string `json:\"version\"` // version of the app", "commit_type": "add"}
{"commit_tokens": ["allow", "arrays", "of", "children", "in", "view", "construction", "flattening"], "add_tokens": "if v == nil && ok { varr , isArray := obj [ i ] . ( [ ] * ViewImpl ) if isArray { for _ , v := range varr { if v != nil { p . children = append ( p . children , v ) } } continue }", "del_tokens": "if v == nil {", "commit_type": "allow"}
{"commit_tokens": ["fix", "parsing", "of", "comments", "in", "aggregation", ".", "conf"], "add_tokens": "if item . name == \" \" || strings . HasPrefix ( item . name , \" \" ) {", "del_tokens": "if item . name == \" \" {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typos", "in", "PromptTemplates", "documentation"], "add_tokens": "// Prompt is a text/template for the prompt label when the value is invalid due to an error triggered by", "del_tokens": "// Prompt is a text/template for the prompt label when the value is invalid dur to an error triggered from", "commit_type": "fix"}
{"commit_tokens": ["make", "question", "-", "mark", "placeholders", "optional", "and", "not", "enabled", "by", "default"], "add_tokens": "var ( db * sql . DB dsnStruct * DSN ) dsnStruct , err = ParseDSN ( dsn ) if err != nil { panic ( err ) } if ! dsnStruct . enableQMPlaceholders { return }", "del_tokens": "var db * sql . DB", "commit_type": "make"}
{"commit_tokens": ["Using", "mattn", "/", "go", "-", "sqlite3", "for", "integration", "test"], "add_tokens": "_ \" \"", "del_tokens": "_ \" \"", "commit_type": "use"}
{"commit_tokens": ["fix", "a", "test", "not", "compiling"], "add_tokens": "DecisionWorker : & DecisionWorker { StateSerializer : JsonStateSerializer { } , idGenerator : UUIDGenerator { } } ,", "del_tokens": "DecisionWorker : DecisionWorker { StateSerializer : JsonStateSerializer { } , idGenerator : UUIDGenerator { } } ,", "commit_type": "fix"}
{"commit_tokens": ["Remove", "programatic", "focus", "from", "measurement", "suite"], "add_tokens": "var _ = Describe ( \" \" , func ( ) {", "del_tokens": "var _ = FDescribe ( \" \" , func ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Allow", "empty", "interface", "as", "a", "type", "for", "the", "context", "middleware", "parameter"], "add_tokens": "var emptyInterfaceType reflect . Type = reflect . TypeOf ( ( * interface { } ) ( nil ) ) . Elem ( ) if ! isValidHandler ( vfn , ctxType , reflect . TypeOf ( resp ) . Out ( 0 ) , reflect . TypeOf ( req ) , emptyInterfaceType ) { firstArgType := fnType . In ( 0 ) if firstArgType != reflect . PtrTo ( ctxType ) && firstArgType != emptyInterfaceType {", "del_tokens": "var interfaceType func ( ) interface { } // This is weird. I need to get an interface{} reflect.Type; var x interface{}; TypeOf(x) doesn't work, because it returns nil if ! isValidHandler ( vfn , ctxType , reflect . TypeOf ( resp ) . Out ( 0 ) , reflect . TypeOf ( req ) , reflect . TypeOf ( interfaceType ) . Out ( 0 ) ) { if fnType . In ( 0 ) != reflect . PtrTo ( ctxType ) {", "commit_type": "allow"}
{"commit_tokens": ["Add", "Fetch", "with", "Response", "to", "test", "http", "aids"], "add_tokens": "// Simple Fetch Wrapper, given a url it returns bytes and response func FetchResp ( url string ) ( ret [ ] byte , err error , resp * http . Response ) { resp , err = http . Get ( url ) defer func ( ) { if resp != nil && resp . Body != nil { resp . Body . Close ( ) } } ( ) if err != nil { Log ( WARN , err . Error ( ) ) return } ret , err = ioutil . ReadAll ( resp . Body ) if err != nil { return } return } Log ( WARN , url , \" \" , body , \" \" , err . Error ( ) )", "del_tokens": "Debug ( url ) Log ( WARN , url , body , err . Error ( ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "multi", "-", "element", "E"], "add_tokens": "var i int var ss = [ ] int { 5 , 5 , 3 , 0 , 4 , 5 } for _ , c := range \" if ss [ i ] != Stroke ( c ) { t . Errorf ( \" \" , ss [ i ] , Stroke ( c ) ) } i += 1 }", "del_tokens": "//\"fmt\"", "commit_type": "add"}
{"commit_tokens": ["Updated", "example", "to", "reflect", "parameter", "changes", "to", "CreateTrunk", "()"], "add_tokens": "b . CreateTrunk ( \" \" , \" \" , true )", "del_tokens": "interfaces := [ ] string { \" \" , \" \" , \" \" } b . CreateTrunk ( \" \" , interfaces , true )", "commit_type": "update"}
{"commit_tokens": ["remove", "container", "remove", "image", "build", "image"], "add_tokens": "GetContainers ( ids [ ] string ) ( [ ] * types . Container , error ) BuildImage ( repository , version string ) ( chan * types . BuildImageMessage , error ) RemoveContainer ( ids [ ] string ) ( chan * types . RemoveContainerMessage , error ) RemoveImage ( nodename string , images [ ] string ) ( chan * types . RemoveImageMessage , error )", "del_tokens": "BuildImage ( ) error RemoveContainer ( ) error", "commit_type": "remove"}
{"commit_tokens": ["Allow", "bundles", "list", "to", "be", "empty", "for", "GetBundleByNameForProvider"], "add_tokens": "if len ( bundles ) == 0 { return Bundle { } , microerror . Maskf ( bundleNotFoundError , name ) }", "del_tokens": "if len ( bundles ) == 0 { return Bundle { } , microerror . Maskf ( executionFailedError , \" \" ) }", "commit_type": "allow"}
{"commit_tokens": ["Allow", "debug", "mode", "to", "work", "from", "the", "handler"], "add_tokens": "{ { if . Debug } } { { exported \" \" } } = webdav . Dir ( \" \" ) { { else } } { { end } } { { if not . Debug } } var err error { { end } }", "del_tokens": "var err error", "commit_type": "allow"}
{"commit_tokens": ["Allow", "calling", "Template", ".", "Reset", "on", "uninitialized", "Template"], "add_tokens": "t . bytesBufferPool . New = newBytesBuffer", "del_tokens": "t . bytesBufferPool . New = newBytesBuffer", "commit_type": "allow"}
{"commit_tokens": ["Fix", "bugs", "in", "collector", "apps"], "add_tokens": "datapoint . Set ( \" \" , timestampMillis ) log . Println ( \" \\n \" , * ipCommandFlag , ip )", "del_tokens": "datapoint . Set ( \" \" , timestampMillis )", "commit_type": "fix"}
{"commit_tokens": ["Add", "processing", "of", "command", ".", "Commands", "for", "user", "defined", "commands"], "add_tokens": "// create built in commands // take other commands for pattern , cmd := range command . Commands { if c , ok := cmds [ pattern ] ; ok { log . Printf ( \" \\n \" , c . String ( ) , pattern ) continue } // register command cmds [ pattern ] = cmd }", "del_tokens": "// create commands", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "non", "hardcoded", "authendpoint", "."], "add_tokens": "return OAuthConfigForTenant ( env . ActiveDirectoryEndpoint , tenantID ) } // OAuthConfigForTenant returns an OAuthConfig with tenant specific urls for target cloud auth endpoint func OAuthConfigForTenant ( activeDirectoryEndpoint , tenantID string ) ( * OAuthConfig , error ) { u , err := url . Parse ( activeDirectoryEndpoint )", "del_tokens": "u , err := url . Parse ( env . ActiveDirectoryEndpoint )", "commit_type": "add"}
{"commit_tokens": ["Add", "LICENSE", "and", "factor", "out", "documentation"], "add_tokens": "// Copyright 2013 Alvaro J. Genial. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file.", "del_tokens": "// Package form implements encoding and decoding of application/x-www-form-urlencoded data.", "commit_type": "add"}
{"commit_tokens": ["Make", "Some", "Code", "More", "Idiomatic"], "add_tokens": "// Copyright 2013 The GoMPD Authors. All rights reserved. if err := cl . client . readOKLine ( \" \" ) ; err != nil { * ( e . Value . ( * command ) . promise . ( * PromisedId ) ) = ( PromisedId ) ( rid ) // Finalize the command list with the last OK: if cerr := cl . client . readOKLine ( \" \" ) ; cerr != nil {", "del_tokens": "// Copyright 2009 The GoMPD Authors. All rights reserved. err := cl . client . readOKLine ( \" \" ) if err != nil { } else { * ( e . Value . ( * command ) . promise . ( * PromisedId ) ) = ( PromisedId ) ( rid ) cerr := cl . client . readOKLine ( \" \" ) if cerr != nil {", "commit_type": "make"}
{"commit_tokens": ["updated", "for", "new", "version", "of", "ast", "(", "TypeCaseClause", "-", ">", "CaseClause", ")"], "add_tokens": "tcase := stmt . ( * ast . CaseClause ) if len ( tcase . List ) == 1 { return expr , tcase . List [ 0 ]", "del_tokens": "tcase := stmt . ( * ast . TypeCaseClause ) if len ( tcase . Types ) == 1 { return expr , tcase . Types [ 0 ]", "commit_type": "update"}
{"commit_tokens": ["fix", "bug", "in", "IsEmpty", "()"], "add_tokens": "if q . tail == 0 || q . head == q . tail { func ( q * Queue ) Tail ( ) int { return q . tail } func ( q * Queue ) Head ( ) int { return q . head }", "del_tokens": "if q . tail == 0 || q . head > q . tail {", "commit_type": "fix"}
{"commit_tokens": ["Move", "whole", "skip", "first", "line", "logic", "to", "Doc", "."], "add_tokens": "rawLines := strings . Split ( raw , \" \\n \" ) lines := rawLines if skipFirstLine { lines = lines [ 1 : ] } minIndentSize := getMinIndent ( lines ) lines = removeIndentation ( lines , minIndentSize ) return strings . Join ( rawLines , \" \\n \" ) func getMinIndent ( lines [ ] string ) int { func removeIndentation ( lines [ ] string , n int ) [ ] string {", "del_tokens": "lines := strings . Split ( raw , \" \\n \" ) minIndentSize := getMinIndent ( lines , skipFirstLine ) lines = removeIndentation ( lines , minIndentSize , skipFirstLine ) return strings . Join ( lines , \" \\n \" ) func getMinIndent ( lines [ ] string , skipFirstLine bool ) int { if i == 0 && skipFirstLine { continue } // Skips first line if skipFirstLine is true, skips empty lines. func removeIndentation ( lines [ ] string , n int , skipFirstLine bool ) [ ] string { if i == 0 && skipFirstLine { continue }", "commit_type": "move"}
{"commit_tokens": ["move", "decode", "add", "values", "method", "to", "the", "decode_", "{", "type", "}", ".", "go", "file"], "add_tokens": "// DecodeBool reads the next JSON-encoded value from the decoder's input (io.Reader) // and stores it in the boolean pointed to by v. // Add Values functions // AddBool decodes the next key to a *bool. // If next key is neither null nor a JSON boolean, an InvalidUnmarshalError will be returned. // If next key is null, bool will be false. func ( dec * Decoder ) AddBool ( v * bool ) error { return dec . Bool ( v ) } // AddBoolNull decodes the next key to a *bool. // If next key is neither null nor a JSON boolean, an InvalidUnmarshalError will be returned. // If next key is null, bool will be false. // If a `null` is encountered, gojay does not change the value of the pointer. func ( dec * Decoder ) AddBoolNull ( v * * bool ) error { return dec . BoolNull ( v ) } // Bool decodes the next key to a *bool. // If next key is neither null nor a JSON boolean, an InvalidUnmarshalError will be returned. // If next key is null, bool will be false. func ( dec * Decoder ) Bool ( v * bool ) error { err := dec . decodeBool ( v ) if err != nil { return err } dec . called |= 1 return nil } // BoolNull decodes the next key to a *bool. // If next key is neither null nor a JSON boolean, an InvalidUnmarshalError will be returned. // If next key is null, bool will be false. func ( dec * Decoder ) BoolNull ( v * * bool ) error { err := dec . decodeBoolNull ( v ) if err != nil { return err } dec . called |= 1 return nil }", "del_tokens": "// DecodeBool reads the next JSON-encoded value from its input and stores it in the boolean pointed to by v.", "commit_type": "move"}
{"commit_tokens": ["Use", "third", "-", "party", "UDP", "testing", "library", "to", "tighten", "up", "test", "."], "add_tokens": "\" \" \" \" udp . SetAddr ( fmt . Sprintf ( \" \" , port ) ) log := logrus . New ( ) udp . ShouldReceive ( t , \" \" , func ( ) { log . Info ( \" \" ) } )", "del_tokens": "\" \" log := logrus . New ( ) addr := net . UDPAddr { Port : port , IP : net . ParseIP ( \" \" ) , } c , err := net . ListenUDP ( \" \" , & addr ) if err != nil { t . Fatalf ( \" \" , err ) } defer c . Close ( ) log . Info ( \" \" ) var buf = make ( [ ] byte , 1500 ) n , _ , err := c . ReadFromUDP ( buf ) if err != nil { t . Fatalf ( \" \" ) } if n <= 0 { t . Errorf ( \" \" ) }", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "Cassandra", ">", "=", "3", "with", "protocol", "version", "4"], "add_tokens": "\" \" // cassandra://host:port/keyspace?protocol=version // cassandra://localhost/SpaceOfKeys?protocol=4 if len ( u . Query ( ) . Get ( \" \" ) ) > 0 { protoversion , err := strconv . Atoi ( u . Query ( ) . Get ( \" \" ) ) if err != nil { return err } cluster . ProtoVersion = protoversion }", "del_tokens": "// cassandra://host:port/keyspace // cassandra://localhost/SpaceOfKeys", "commit_type": "add"}
{"commit_tokens": ["add", "graceful", "server", "shutdown", "goroutine"], "add_tokens": "slowdown : make ( map [ string ] time . Time ) , kill : make ( chan struct { } ) , reload : make ( chan string ) , recompile : make ( chan string ) , fmt . Fprintf ( os . Stderr , \" \\n \" , a , err ) fmt . Printf ( \" \\n \\n \" ) fmt . Printf ( \" \\n \\n \" )", "del_tokens": "kill : make ( chan struct { } ) , reload : make ( chan string ) , recompile : make ( chan string ) , fmt . Fprintf ( os . Stderr , \" \\n \" , a , err ) fmt . Println ( \" \\n \" ) fmt . Println ( \" \\n \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "interface", "to", "return", "error", "of", "argument", "encoding", ":"], "add_tokens": "data := map [ string ] string { \" \" : \" \" } f . Post ( \" \" , data ) data := map [ string ] string { \" \" : \" \" } f . Post ( \" \" , data ) Name string `msg:\"name\"` func Benchmark_PostWithMapSlice ( b * testing . B ) { b . StopTimer ( ) f , err := New ( Config { } ) if err != nil { panic ( err ) } b . StartTimer ( ) data := map [ string ] [ ] int { \" \" : { 1 , 2 , 3 } , } for i := 0 ; i < b . N ; i ++ { f . Post ( \" \" , data ) } }", "del_tokens": "f . Post ( \" \" , \" \" ) f . Post ( \" \" , \" \" ) Name string `codec:\"name\"`", "commit_type": "fix"}
{"commit_tokens": ["Allow", "multiple", "evaulations", "of", "functions"], "add_tokens": "v = arg . Clone ( ) . Select ( t ) v = arg . Clone ( ) . Select ( t ) v = arg . Clone ( ) . Select ( t )", "del_tokens": "v = arg . Select ( t ) v = arg . Select ( t ) v = arg . Select ( t )", "commit_type": "allow"}
{"commit_tokens": ["Use", "%v", "instead", "of", "%s"], "add_tokens": "return fmt . Errorf ( \" \" , collection )", "del_tokens": "return fmt . Errorf ( \" \" , collection )", "commit_type": "use"}
{"commit_tokens": ["Improve", "README", "godocs", "and", "example", "API", "client"], "add_tokens": "\" \" \" \" \" \" \" \" \" \" // Services // Client to wrap services // Github OAuth2 API flags := flag . NewFlagSet ( \" \" , flag . ExitOnError ) // -access-token=xxx or GITHUB_ACCESS_TOKEN env var accessToken := flags . String ( \" \" , \" \" , \" \" ) flags . Parse ( os . Args [ 1 : ] ) flagutil . SetFlagsFromEnv ( flags , \" \" ) if * accessToken == \" \" { log . Fatal ( \" \" ) token := & oauth2 . Token { AccessToken : * accessToken }", "del_tokens": "\" \" \" \" // Define models // Implement services // (optional) Create a client to wrap services // Github OAuth2 Example - httpClient handles authorization accessToken := os . Getenv ( \" \" ) if accessToken == \" \" { fmt . Println ( \" \" ) os . Exit ( 0 ) token := & oauth2 . Token { AccessToken : accessToken }", "commit_type": "improve"}
{"commit_tokens": ["Fix", "Quo", "and", "add", "license", "again"], "add_tokens": "var _ = fmt . Println z . scale -= int32 ( shift )", "del_tokens": "fmt . Println ( xp , yp )", "commit_type": "fix"}
{"commit_tokens": ["added", "Job", "interface", "(", "again", ")"], "add_tokens": "type Job interface { Do ( ) } //JobFunc wraps a func as Job type JobFunc func ( ) //Do implements Job's Do func ( wf JobFunc ) Do ( ) { wf ( ) } job . Do ( )", "del_tokens": "type Job func ( ) job ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "types", ".", "go"], "add_tokens": "Tasks * TasksInProgress `xml:\"Tasks,omitempty\"`", "del_tokens": "Tasks * TasksInProgress `xml:\"Taks,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["Add", "makefile", "to", "prepare", "for", "codegen"], "add_tokens": "\" \" m . ImplType = strings . ToLower ( p . Name )", "del_tokens": "m . ImplType = p . Name", "commit_type": "add"}
{"commit_tokens": ["Fixed", "two", "test", "bugs", "."], "add_tokens": "expectEqInt ( t , 118 , record . LineNumber ) expectEqInt ( t , 132 , record . LineNumber )", "del_tokens": "expectEqInt ( t , 98 , record . LineNumber ) expectEqInt ( t , 112 , record . LineNumber )", "commit_type": "fix"}
{"commit_tokens": ["adds", "support", "for", "embedded", "struct", "similarly", "to", "encoding", "/", "json"], "add_tokens": "type Embedded struct { B string } // encoding/json takes, if set, the tag as name and doesn't falls back to the // struct field's name. { `d1:X3:foo1:Yi10e1:Z3:bare` , new ( dT ) , dT { \" \" , 10 , \" \" } , false } , // embedded structs { `d1:A3:foo1:B3:bare` , new ( struct { A string Embedded } ) , struct { A string Embedded } { \" \" , Embedded { \" \" } } , false } ,", "del_tokens": "{ `d1:X3:foo1:Yi10e1:Z3:bare` , new ( dT ) , dT { \" \" , 10 , \" \" } , false } ,", "commit_type": "add"}
{"commit_tokens": ["Add", "argo", "submit", "list", "get", "lint", "commands"], "add_tokens": "\" \" \" \" log . Fatal ( err ) // MustHomeDir returns the home directory of the user func MustHomeDir ( ) string { usr , err := user . Current ( ) if err != nil { log . Fatal ( err ) } return usr . HomeDir }", "del_tokens": "fmt . Println ( err ) os . Exit ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "last", "()", "function", "."], "add_tokens": "if len ( arg ) == 0 { return nil , nil } return [ ] tree . Res { arg [ len ( arg ) - 1 ] } , nil", "del_tokens": "return [ ] tree . Res { numlit . NumLit ( len ( arg ) ) } , nil", "commit_type": "fix"}
{"commit_tokens": ["fix", "statement", "count", "tracking", "in", "TestMSSQLStmtAndRows"], "add_tokens": "defer func ( ) { // not checking resources usage here, because these are // unpredictable due to use of goroutines. err := db . Close ( ) if err != nil { t . Fatalf ( \" \" , err ) } } ( ) if db . Driver ( ) . ( * odbc . Driver ) . Stats . StmtCount != sc { t . Fatalf ( \" \" , sc , db . Driver ( ) . ( * odbc . Driver ) . Stats . StmtCount ) } // no reource tracking past this point // NOTE(brainman): this could actually re-prepare since // we are running it simultaneously in multiple goroutines", "del_tokens": "defer closeDB ( t , db , sc , sc + 2 ) // TODO(brainman): talk to brad about why this runs diver.Conn.Prepare again and again", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "Termination", "extension"], "add_tokens": "mux . Del ( \" \" , http . HandlerFunc ( handler . delFile ) ) header . Set ( \" \" , \" \" ) // Terminate an upload permanently. func ( handler * Handler ) delFile ( w http . ResponseWriter , r * http . Request ) { id := r . URL . Query ( ) . Get ( \" \" ) // Ensure file is not locked if _ , ok := handler . locks [ id ] ; ok { handler . sendError ( w , ErrFileLocked ) return } // Lock file for further writes (heads are allowed) handler . locks [ id ] = true // File will be unlocked regardless of an error or success defer func ( ) { delete ( handler . locks , id ) } ( ) err := handler . dataStore . Terminate ( id ) if err != nil { if os . IsNotExist ( err ) { err = ErrNotFound } handler . sendError ( w , err ) return } w . WriteHeader ( http . StatusNoContent ) }", "del_tokens": "header . Set ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Updated", "due", "to", "change", "in", "store"], "add_tokens": "func NewGroupStore ( addr string , streams int , insecureSkipVerify bool , opts ... grpc . DialOption ) ( store . GroupStore , error ) { func ( g * groupStore ) ReadGroup ( parentKeyA , parentKeyB uint64 ) ( [ ] store . ReadGroupItem , error ) { rv := make ( [ ] store . ReadGroupItem , len ( res . Items ) )", "del_tokens": "type GroupStore interface { store . GroupStore ReadGroup ( parentKeyA , parentKeyB uint64 ) ( [ ] ReadGroupItem , error ) } type ReadGroupItem struct { ChildKeyA uint64 ChildKeyB uint64 TimestampMicro int64 Value [ ] byte } func NewGroupStore ( addr string , streams int , insecureSkipVerify bool , opts ... grpc . DialOption ) ( GroupStore , error ) { func ( g * groupStore ) ReadGroup ( parentKeyA , parentKeyB uint64 ) ( [ ] ReadGroupItem , error ) { rv := make ( [ ] ReadGroupItem , len ( res . Items ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "--", "only", "-", "files", "and", "--", "only", "-", "dirs", "."], "add_tokens": "if verbose { fmt . Println ( \" \" , path ) } // TODO: These only match if the file/dir still exists...not sure if there's a better way. if reflex . onlyFiles || reflex . onlyDirs { stat , err := os . Stat ( name ) if err != nil { continue } if ( reflex . onlyFiles && stat . IsDir ( ) ) || ( reflex . onlyDirs && ! stat . IsDir ( ) ) { continue } }", "del_tokens": "fmt . Println ( \" \" , path )", "commit_type": "add"}
{"commit_tokens": ["add", "some", "docs", "and", ".", "travis", ".", "yml"], "add_tokens": ". \" \"", "del_tokens": ". \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "uint", "types", "in", "Metric"], "add_tokens": "e . MetricSint64 = pb . Int64 ( reflect . ValueOf ( event . Metric ) . Int ( ) ) e . MetricD = pb . Float64 ( reflect . ValueOf ( event . Metric ) . Float ( ) ) e . MetricD = pb . Float64 ( reflect . ValueOf ( event . Metric ) . Float ( ) ) case reflect . Uint , reflect . Uint32 , reflect . Uint64 : e . MetricSint64 = pb . Int64 ( int64 ( reflect . ValueOf ( event . Metric ) . Uint ( ) ) )", "del_tokens": "e . MetricSint64 = pb . Int64 ( ( reflect . ValueOf ( event . Metric ) . Int ( ) ) ) e . MetricD = pb . Float64 ( ( reflect . ValueOf ( event . Metric ) . Float ( ) ) ) e . MetricD = pb . Float64 ( ( reflect . ValueOf ( event . Metric ) . Float ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "debug", "information", "from", "tests"], "add_tokens": "if ! db . First ( & User { } , \" \" , \" \" ) . RecordNotFound ( ) {", "del_tokens": "if ! db . Debug ( ) . First ( & User { } , \" \" , \" \" ) . RecordNotFound ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "CompletedAt", "and", "CompletedByID", "fields", "to", "task", "and", "subtask", "."], "add_tokens": "ID uint `json:\"id\"` TaskID uint `json:\"task_id\"` CreatedAt string `json:\"created_at\"` CreatedByID uint `json:\"created_by_id\"` Revision uint `json:\"revision\"` Title string `json:\"title\"` CompletedAt string `json:\"completed_at\"` CompletedByID uint `json:\"completed_by\"`", "del_tokens": "ID uint `json:\"id\"` TaskID uint `json:\"task_id\"` CreatedAt string `json:\"created_at\"` CreatedByID uint `json:\"created_by_id\"` Revision uint `json:\"revision\"` Title string `json:\"title\"`", "commit_type": "add"}
{"commit_tokens": ["Implement", "client", "-", "side", "pinging"], "add_tokens": "import ( \" \" \" \" ) func assertDurationsSameish ( t * testing . T , actual , expected , allowedDeviation time . Duration ) { diff := actual - expected if diff < 0 || diff > allowedDeviation { t . Errorf ( \" \" , diff , allowedDeviation ) } } // formats a ping-signature (i.e. go-twitch-irc) into a full-fledged pong response (i.e. \":tmi.twitch.tv PONG tmi.twitch.tv :go-twitch-irc\") func formatPong ( signature string ) string { return \" \" + signature }", "del_tokens": "import \" \"", "commit_type": "implement"}
{"commit_tokens": ["using", "semver", "for", "versioning", "..", "makes", "sense"], "add_tokens": "const version = \" \"", "del_tokens": "const version = \" \"", "commit_type": "use"}
{"commit_tokens": ["Update", "example", "file", "to", "correctly", "defer", "t", ".", "Done", "()"], "add_tokens": "defer t . Done ( )", "del_tokens": "t . Done ( )", "commit_type": "update"}
{"commit_tokens": ["Update", "doc", "strings", "based", "on", "feedback"], "add_tokens": "// GetPathTemplate returns the template used to build the // route match. // This is useful for building simple REST API documentation and for instrumentation // against third-party services. // An error will be returned if the route does not define a path. // GetHostTemplate returns the template used to build the // route match. // This is useful for building simple REST API documentation and for instrumentation // against third-party services. // An error will be returned if the route does not define a host.", "del_tokens": "// GetPathTemplate and GetHostTemplate returns the template used to match against for the route // This is userful for building simple REST API documentation, // and instrumentation for services like New Relic to ensure consistent reporting // The route must have a path defined.", "commit_type": "update"}
{"commit_tokens": ["fix", "loading", "package", "user", "settings", "bug"], "add_tokens": "pt := filepath . Join ( dir , p . Name ( ) + \" \" )", "del_tokens": "pt := filepath . Join ( dir , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["add", "lag", "type", "to", "trivial", "change", "group"], "add_tokens": "case TYPE_REPLICA , TYPE_RDONLY , TYPE_BATCH , TYPE_SPARE , TYPE_LAG , TYPE_BACKUP , TYPE_EXPERIMENTAL : case TYPE_REPLICA , TYPE_RDONLY , TYPE_BATCH , TYPE_SPARE , TYPE_LAG , TYPE_BACKUP , TYPE_EXPERIMENTAL :", "del_tokens": "case TYPE_REPLICA , TYPE_RDONLY , TYPE_BATCH , TYPE_SPARE , TYPE_BACKUP , TYPE_EXPERIMENTAL : case TYPE_REPLICA , TYPE_RDONLY , TYPE_BATCH , TYPE_SPARE , TYPE_BACKUP , TYPE_EXPERIMENTAL :", "commit_type": "add"}
{"commit_tokens": ["Moved", "the", "interface", "to", "the", "pinterface", "package"], "add_tokens": "\" \" // Check that the userstate qualifies for the IUserState interface var _ pinterface . IUserState = userstate", "del_tokens": "// Check that the userstate qualifies for the UserStateKeeper interface var _ UserStateKeeper = userstate", "commit_type": "move"}
{"commit_tokens": ["add", "multiple", "hasone", "and", "belongsto"], "add_tokens": "codegen . SimpleImport ( \" \" ) ,", "del_tokens": "codegen . SimpleImport ( \" \" ) ,", "commit_type": "add"}
{"commit_tokens": ["Implement", "TerminateNicely", "for", "windows", "process"], "add_tokens": "p . logger . Debug ( execProcessLogTag , \" \" , p . pid ) // Make sure process is being waited on for process state reaping to occur // as to avoid forcibly killing the process if p . waitCh == nil { panic ( \" \" ) } // If the process exits before Wait() can be called the // ProcessState may not be set and Kill() will fail with // an: \"TerminateProcess: Access is denied\" error. // // See: https://github.com/golang/go/issues/5615 if p . cmd . ProcessState != nil && p . cmd . ProcessState . Exited ( ) { p . logger . Debug ( execProcessLogTag , \" \" ) return nil } err := p . cmd . Process . Kill ( ) if err != nil { return bosherr . WrapErrorf ( err , \" \" , err ) }", "del_tokens": "panic ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "pgrep", "check", "before", "starting", "mysqld"], "add_tokens": "mgr . Log ( \" \\n \" )", "del_tokens": "mgr . Log ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["move", "AppFS", "to", "config", "(", "to", "avoid", "circular", "dep", ")"], "add_tokens": "// AppFS is a handle to the filesystem in use var AppFS = afero . NewOsFs ( ) func LoadDBConfig ( appPath string , env string ) * DBConfig { appName := GetAppName ( appPath ) func GetActiveEnv ( appPath string ) string { appName := strmangle . EnvAppName ( GetAppName ( appPath ) ) contents , err := afero . ReadFile ( AppFS , filepath . Join ( appPath , \" \" ) )", "del_tokens": "\" \" func LoadDBConfig ( appPath string , appName string , env string ) * DBConfig { func GetActiveEnv ( appPath string , appName string ) string { appName = strmangle . EnvAppName ( appName ) contents , err := afero . ReadFile ( cmd . AppFS , filepath . Join ( appPath , \" \" ) )", "commit_type": "move"}
{"commit_tokens": ["use", "rune", "instead", "of", "byte"], "add_tokens": "func isDigit ( r rune ) bool { return '0' <= r && r <= '9' func isHex ( r rune ) bool { return isDigit ( r ) || ( 'a' <= r && 'f' >= r ) type RuneMatcherFunc func ( r rune ) bool func ( f RuneMatcherFunc ) Match ( s string ) int { if length == 0 { for i , r := range s { if f ( r ) { if i != 0 { return i } return - 1 var IntMatcher = RuneMatcherFunc ( isDigit ) var HexMatcher = RuneMatcherFunc ( isHex )", "del_tokens": "func isDigit ( c byte ) bool { return '0' <= c && c <= '9' func isHex ( c byte ) bool { return isDigit ( c ) || ( 'a' <= c && 'f' >= c ) type ByteMatcherFunc func ( c byte ) bool func ( f ByteMatcherFunc ) Match ( s string ) int { if length == 0 || ! f ( s [ 0 ] ) { for i := 1 ; i < length ; i ++ { if f ( s [ i ] ) { return i var IntMatcher = ByteMatcherFunc ( isDigit ) var HexMatcher = ByteMatcherFunc ( isHex )", "commit_type": "use"}
{"commit_tokens": ["Add", "more", "tests", "and", "check", "for", "error", "."], "add_tokens": "var err error var socket string socket , err = GetSocket ( dsn . String ( ) ) // Each of below command may fail as result depends on OS. socket , err = GetSocketFromTCPConnection ( dsn . String ( ) ) if err == nil { assert . NotEmpty ( t , socket ) } socket , err = GetSocketFromNetstat ( ) if err == nil { assert . NotEmpty ( t , socket ) } socket , err = GetSocketFromProcessLists ( ) if err == nil { assert . NotEmpty ( t , socket ) }", "del_tokens": "socket , err := GetSocket ( dsn )", "commit_type": "add"}
{"commit_tokens": ["change", "cache", "mutex", "to", "r", "/", "w"], "add_tokens": "l sync . RWMutex c . l . RLock ( ) c . l . RUnlock ( )", "del_tokens": "l sync . Mutex c . l . Lock ( ) c . l . Unlock ( )", "commit_type": "change"}
{"commit_tokens": ["move", "WithOrder", "functions", "to", "WithOptions"], "add_tokens": "func ( f Fields ) Pack ( buf [ ] byte , val reflect . Value , options * Options ) ( int , error ) { if n , err := field . Pack ( buf [ pos : ] , v , length , options ) ; err != nil { func ( f Fields ) Unpack ( r io . Reader , val reflect . Value , options * Options ) error { if err := fields . Unpack ( r , v , options ) ; err != nil { if err := fields . Unpack ( r , v , options ) ; err != nil { err := field . Unpack ( buf [ : size ] , v , length , options )", "del_tokens": "func ( f Fields ) Pack ( buf [ ] byte , val reflect . Value ) ( int , error ) { if n , err := field . Pack ( buf [ pos : ] , v , length ) ; err != nil { func ( f Fields ) Unpack ( r io . Reader , val reflect . Value ) error { if err := fields . Unpack ( r , v ) ; err != nil { if err := fields . Unpack ( r , v ) ; err != nil { err := field . Unpack ( buf [ : size ] , v , length )", "commit_type": "move"}
{"commit_tokens": ["fix", "import", "path", "causing", "travis", "failed", "build"], "add_tokens": "var vt , acct , appsc = messenger . GetTokens ( )", "del_tokens": "msgs \" \" var vt , acct , appsc = msgs . GetTokens ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "SetCellColor", "to", "allow", "for", "colorizing", "individual", "cells", "in", "conjunction", "with", "column", "colors"], "add_tokens": "cellParams [ ] CellColor cellParams : [ ] CellColor { } , if len ( t . columnsParams ) > 0 || len ( t . cellParams ) > 0 { if val := t . getColorForCell ( y , x + rowIdx ) ; val != \" \" { str = format ( str , val ) if len ( t . columnsParams ) > 0 || len ( t . cellParams ) > 0 { if val := t . getColorForCell ( y , x + rowIdx ) ; val != \" \" { str = format ( str , val )", "del_tokens": "cellParams [ ] [ ] string if len ( t . columnsParams ) > 0 { if t . cellParams [ x ] [ y ] != \" \" { str = format ( str , t . cellParams [ x ] [ y ] ) if len ( t . columnsParams ) > 0 { if t . cellParams [ x ] [ y ] != \" \" { str = format ( str , t . cellParams [ x ] [ y ] )", "commit_type": "add"}
{"commit_tokens": ["Add", "pass", "drop", "and", "interval", "to", "the", "plugin", "options"], "add_tokens": "log . Printf ( \" \\n \" , ag . Interval , ag . Debug , ag . Hostname )", "del_tokens": "log . Printf ( \" \" , ag )", "commit_type": "add"}
{"commit_tokens": ["Move", "flag", "parsing", "to", "main", "()", "and", "rename", "arguments", "to", "Listen"], "add_tokens": "func ( server * server ) Listen ( host string , port string ) { \" \" : host , \" \" : port , err := http . ListenAndServe ( net . JoinHostPort ( host , port ) , nil )", "del_tokens": "func ( server * server ) Listen ( apiHost string , apiPort string ) { \" \" : apiHost , \" \" : apiPort , err := http . ListenAndServe ( net . JoinHostPort ( apiHost , apiPort ) , nil )", "commit_type": "move"}
{"commit_tokens": ["Added", "parameter", "binding", "to", "prevent", "AQL", "injection", "."], "add_tokens": "bindVars map [ string ] interface { } // Bind sets the name and value of a bind parameter // Binding parameters prevents AQL injection func ( q * Query ) Bind ( name string , value interface { } ) * Query { if q . bindVars == nil { q . bindVars = make ( map [ string ] interface { } ) } q . bindVars [ name ] = value return q } Query string `json:\"query\"` BindVars map [ string ] interface { } `json:\"bindVars,omitempty\"` Cache * bool `json:\"cache,omitempty\"` BatchSize int `json:\"batchSize,omitempty\"` jsonQuery , _ := json . Marshal ( & QueryFmt { Query : q . aql , BindVars : q . bindVars , Cache : q . cache , BatchSize : q . batchSize } )", "del_tokens": "Query string `json:\"query\"` Cache * bool `json:\"cache,omitempty\"` BatchSize int `json:\"batchSize,omitempty\"` jsonQuery , _ := json . Marshal ( & QueryFmt { Query : q . aql , Cache : q . cache , BatchSize : q . batchSize } )", "commit_type": "add"}
{"commit_tokens": ["Allows", "guest", "users", "to", "access", "ggr"], "add_tokens": "listen string quotaDir string users string timeout time . Duration gracefulPeriod time . Duration guestAccessAllowed bool guestUserName string flag . BoolVar ( & guestAccessAllowed , \" \" , false , \" \" ) flag . StringVar ( & guestUserName , \" \" , \" \" , \" \" )", "del_tokens": "listen string quotaDir string users string timeout time . Duration gracefulPeriod time . Duration", "commit_type": "allow"}
{"commit_tokens": ["add", "Project", ".", "name", "(", "fn", ")", "to", "compute", "nameTemplate"], "add_tokens": "if name , err := p . name ( fn ) ; err == nil { // name returns the computed name for `fn`, using the nameTemplate. func ( p * Project ) name ( fn * function . Function ) ( string , error ) { data := struct { Project * Project Function * function . Function } { Project : p , Function : fn , } name , err := render ( p . nameTemplate , data ) if err != nil { return \" \" , err } return name , nil }", "del_tokens": "data := struct { Project * Project Function * function . Function } { Project : p , Function : fn , } if name , err := render ( p . nameTemplate , data ) ; err == nil {", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "to", "wait", "for", "6", "seconds"], "add_tokens": "if time . Since ( st ) > 6 * time . Second {", "del_tokens": "if time . Since ( st ) > time . Second {", "commit_type": "fix"}
{"commit_tokens": ["Add", "(", "*", "Client", ")", ".", "RunContext", "to", "allow", "for", "cancelation"], "add_tokens": "\" \" return c . RunContext ( context . TODO ( ) ) } // RunContext is the same as Run but a context.Context can be passed in for // cancelation. func ( c * Client ) RunContext ( ctx context . Context ) error { // Wait for an error from any goroutine or for the context to time out, then // signal we're exiting and wait for the goroutines to exit. var err error select { case err = <- c . errChan : case <- ctx . Done ( ) : }", "del_tokens": "// Wait for an error from any goroutine, then signal we're exiting and wait // for the goroutines to exit. err := <- c . errChan", "commit_type": "add"}
{"commit_tokens": ["Added", "default", "value", "for", "Must", "...", "disable", "auto", "-", "remove", "added", "deleteKey", "method"], "add_tokens": "c , err := LoadConfigFile ( \" \" ) t . Fatal ( err ) if value != \" \" { t . Errorf ( \" \\n \\n \\n \" , \" \" , value ) t . Errorf ( \" \\n \\n \\n \" , \" \" , value ) SaveConfigFile ( c , \" \" )", "del_tokens": "c , err := LoadConfigFile ( \" \" ) t . Error ( err ) if value != \" \" { t . Error ( \" \" ) t . Error ( \" \" ) SaveConfigFile ( c , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "struct", "field", "tag", "from", "altname", "to", "field", "."], "add_tokens": "SocketsUsed uint64 `json:\"sockets_used\" field:\"sockets.used\"` TCPInUse uint64 `json:\"tcp_in_use\" field:\"TCP.inuse\"` TCPOrphan uint64 `json:\"tcp_orphan\" field:\"TCP.orphan\"` TCPTimeWait uint64 `json:\"tcp_time_wait\" field:\"TCP.tw\"` TCPAllocated uint64 `json:\"tcp_allocated\" field:\"TCP.alloc\"` TCPMemory uint64 `json:\"tcp_memory\" field:\"TCP.mem\"` UDPInUse uint64 `json:\"udp_in_use\" field:\"UDP.inuse\"` UDPMemory uint64 `json:\"udp_memory\" field:\"UDP.mem\"` UDPLITEInUse uint64 `json:\"udplite_in_use\" field:\"UDPLITE.inuse\"` RAWInUse uint64 `json:\"raw_in_use\" field:\"RAW.inuse\"` FRAGInUse uint64 `json:\"frag_in_use\" field:\"FRAG.inuse\"` FRAGMemory uint64 `json:\"frag_memory\" field:\"FRAG.memory\"` statType := line [ 0 : strings . Index ( line , \" \" ) ] + \" \" val , ok := statMap [ typeOfElem . Field ( i ) . Tag . Get ( \" \" ) ]", "del_tokens": "SocketsUsed uint64 `json:\"sockets_used\" altname:\"sockets:used\"` TCPInUse uint64 `json:\"tcp_in_use\" altname:\"TCP:inuse\"` TCPOrphan uint64 `json:\"tcp_orphan\" altname:\"TCP:orphan\"` TCPTimeWait uint64 `json:\"tcp_time_wait\" altname:\"TCP:tw\"` TCPAllocated uint64 `json:\"tcp_allocated\" altname:\"TCP:alloc\"` TCPMemory uint64 `json:\"tcp_memory\" altname:\"TCP:mem\"` UDPInUse uint64 `json:\"udp_in_use\" altname:\"UDP:inuse\"` UDPMemory uint64 `json:\"udp_memory\" altname:\"UDP:mem\"` UDPLITEInUse uint64 `json:\"udplite_in_use\" altname:\"UDPLITE:inuse\"` RAWInUse uint64 `json:\"raw_in_use\" altname:\"RAW:inuse\"` FRAGInUse uint64 `json:\"frag_in_use\" altname:\"FRAG:inuse\"` FRAGMemory uint64 `json:\"frag_memory\" altname:\"FRAG:memory\"` statType := line [ 0 : strings . Index ( line , \" \" ) + 1 ] val , ok := statMap [ typeOfElem . Field ( i ) . Tag . Get ( \" \" ) ]", "commit_type": "change"}
{"commit_tokens": ["added", "SecurityInsecureTLS", "and", "SecurityInsecureStartTLS", "Security", "types"], "add_tokens": "if _ , err := ( & Config { Server : \" \" , Port : 1 , Security : SecurityInsecureTLS } ) . Connect ( ) ; err == nil { t . Error ( \" \" ) } if _ , err := ( & Config { Server : \" \" , Port : 1 , Security : SecurityInsecureStartTLS } ) . Connect ( ) ; err == nil { t . Error ( \" \" ) } if _ , err := ( & Config { Server : testConfig . Server , Port : testConfig . TLSPort , Security : SecurityInsecureTLS } ) . Connect ( ) ; err != nil { t . Error ( \" \" , err ) } if _ , err := ( & Config { Server : testConfig . Server , Port : testConfig . Port , Security : SecurityInsecureStartTLS } ) . Connect ( ) ; err != nil { t . Error ( \" \" , err ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Remove", "bad", "local", "stream", "reference", "storage"], "add_tokens": "// TODO: hold reference to the newly created stream // for possible cleanup. This stream should not be put // in the streams maps which holds remotely created // streams and will can have reference id conflicts.", "del_tokens": "// TODO: Do not store reference s . streamC . L . Lock ( ) s . streams [ referenceID ] = newStream s . streamC . L . Unlock ( )", "commit_type": "remove"}
{"commit_tokens": ["Move", "examples", "to", "their", "own", "package", "and", "improve", "tests"], "add_tokens": "svcHolding := & holdingservice { id : 98 } svcHolding . Add ( 1 ) supervisor . Add ( svcHolding ) svcHolding2 := & holdingservice { id : 99 } svcHolding2 . Add ( 1 ) childSupervisor . Add ( svcHolding2 ) var wg sync . WaitGroup wg . Add ( 1 ) go func ( ) { supervisor . Serve ( ctx ) wg . Done ( ) } ( ) svcHolding . Wait ( ) svcHolding2 . Wait ( ) wg . Wait ( ) if count := getServiceCount ( & supervisor ) ; count != 4 { t . Errorf ( \" \" , svc1 . count , svc3 . count ) t . Errorf ( \" \" , svc2 . count , svc4 . count )", "del_tokens": "supervisor . Serve ( ctx ) if count := getServiceCount ( & supervisor ) ; count != 3 { t . Errorf ( \" \" , svc1 . count , svc2 . count , svc3 . count , svc4 . count ) t . Errorf ( \" \" , svc1 . count , svc2 . count , svc3 . count , svc4 . count )", "commit_type": "move"}
{"commit_tokens": ["Added", "initiate", "inventory", "job", "."], "add_tokens": "\" \" \" \" \" \" \" \" rawBody , err := json . Marshal ( j ) body := bytes . NewReader ( rawBody ) request , err := http . NewRequest ( \" \" , \" \" + c . Signature . Region . Glacier + \" \" + vault + \" \" , body ) if err != nil { return err } request . Header . Add ( \" \" , \" \" ) err = c . Signature . Sign ( request , body , nil ) if err != nil { return err } response , err := c . Client . Do ( request ) if err != nil { return err } if response . StatusCode != 202 { body , err := ioutil . ReadAll ( response . Body ) if err != nil { return err } err = response . Body . Close ( ) if err != nil { return err } var e aws . Error err = json . Unmarshal ( body , & e ) if err != nil { return err } return e }", "del_tokens": "_ , err := json . Marshal ( j )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "rsa", "public", "keys", "when", "loading", "connections"], "add_tokens": "\" \" \" \" \" \" ID string `json:\"id\"` Round string `json:\"round,omitempty\"` AuthMethod string `json:\"auth\"` // (psk|pubkey) EAP_ID string `json:\"eap_id,omitempty\"` PubKeys [ ] string `json:\"pubkeys,omitempty\"` // PEM encoded public keys // SetPublicKeys is a helper method that converts Public Keys to x509 PKIX PEM format // Supported formats are those implemented by x509.MarshalPKIXPublicKey func ( a * AuthConf ) SetPublicKeys ( keys [ ] crypto . PublicKey ) error { var newKeys [ ] string for _ , key := range keys { asn1Bytes , err := x509 . MarshalPKIXPublicKey ( key ) if err != nil { return fmt . Errorf ( \" \" , err ) } pemKey := pem . Block { Type : \" \" , Bytes : asn1Bytes , } pemBytes := pem . EncodeToMemory ( & pemKey ) newKeys = append ( newKeys , string ( pemBytes ) ) } a . PubKeys = newKeys return nil }", "del_tokens": "ID string `json:\"id\"` Round string `json:\"round,omitempty\"` AuthMethod string `json:\"auth\"` // (psk|pubkey) EAP_ID string `json:\"eap_id,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "hugo", "--", "version", "prints", "the", "version", "and", "does", "*", "nothing", "*", "else", "."], "add_tokens": "if * version { fmt . Println ( \" \" ) return }", "del_tokens": "if * version { fmt . Println ( \" \" ) }", "commit_type": "make"}
{"commit_tokens": ["fix", "large", "integers", "not", "valid"], "add_tokens": "return n == float64 ( int64 ( n ) ) || n == float64 ( uint64 ( n ) ) return fmt . Sprintf ( \" \" , int64 ( n ) )", "del_tokens": "\" \" _ , errInt := strconv . ParseInt ( fmt . Sprintf ( \" \" , n ) , 10 , 64 ) _ , errUint := strconv . ParseUint ( fmt . Sprintf ( \" \" , n ) , 10 , 64 ) return errInt == nil || errUint == nil valInt , errInt := strconv . ParseInt ( fmt . Sprintf ( \" \" , n ) , 10 , 64 ) valUint , errUint := strconv . ParseUint ( fmt . Sprintf ( \" \" , n ) , 10 , 64 ) if errInt == nil { return fmt . Sprintf ( \" \" , valInt ) } else if errUint == nil { return fmt . Sprintf ( \" \" , valUint ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "to", "reporting", "to", "use", "output", "formats"], "add_tokens": "gas . Stats . NumLines += prog . Fset . File ( file . Pos ( ) ) . LineCount ( )", "del_tokens": "count := func ( f * token . File ) bool { gas . Stats . NumLines += f . LineCount ( ) return true } prog . Fset . Iterate ( count )", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "possible", "deadlock", "caused", "by", "keepAlive"], "add_tokens": "defaultKeepAliveInterval = 10 keepAliveInterval int32 sess . chUDPOutput = make ( chan [ ] byte ) atomic . StoreInt32 ( & s . keepAliveInterval , int32 ( interval ) ) interval := time . Duration ( atomic . LoadInt32 ( & s . keepAliveInterval ) ) * time . Second", "del_tokens": "defaultKeepAliveInterval = 10 * time . Second keepAliveInterval time . Duration sess . chUDPOutput = make ( chan [ ] byte , txQueueLimit ) s . mu . Lock ( ) defer s . mu . Unlock ( ) s . keepAliveInterval = time . Duration ( interval ) * time . Second s . mu . Lock ( ) interval := s . keepAliveInterval s . mu . Unlock ( )", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "+", "sure", "up", "logic"], "add_tokens": "switch format { case JSON : // skip non JSON files if filepath . Ext ( info . Name ( ) ) != \" \" { return nil } } return processFn ( path ) // ImportByReader imports the the translations found within the contents read from the supplied reader. // // NOTE: generally used when assets have been embedded into the binary and are already in memory. err = locale . Add ( tl . Key , tl . Translation , tl . OverrideExisting ) if err != nil { return err } continue err = locale . AddCardinal ( tl . Key , tl . Translation , pr , tl . OverrideExisting ) err = locale . AddOrdinal ( tl . Key , tl . Translation , pr , tl . OverrideExisting ) err = locale . AddRange ( tl . Key , tl . Translation , pr , tl . OverrideExisting ) if err != nil { return err }", "del_tokens": "return processFn ( dirnameOrFilename ) // ImportByReader imports a files contexts return locale . Add ( tl . Key , tl . Translation , tl . OverrideExisting ) return locale . AddCardinal ( tl . Key , tl . Translation , pr , tl . OverrideExisting ) return locale . AddOrdinal ( tl . Key , tl . Translation , pr , tl . OverrideExisting ) return locale . AddRange ( tl . Key , tl . Translation , pr , tl . OverrideExisting )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "new", "much", "more", "complete", "implementation", "of", "exc", "-", "c14n"], "add_tokens": "func ( ctx NSContext ) Copy ( ) NSContext { return NSContext { prefixes : prefixes } } func ( ctx NSContext ) declare ( prefix , namespace string ) etree . Attr { ctx . prefixes [ prefix ] = namespace switch prefix { case defaultPrefix : return etree . Attr { Key : xmlnsPrefix , Value : namespace , } default : return etree . Attr { Space : xmlnsPrefix , Key : prefix , Value : namespace , } } } func ( ctx NSContext ) SubContext ( el * etree . Element ) ( NSContext , error ) { // The subcontext should inherit existing declared prefixes newCtx := ctx . Copy ( ) newCtx . declare ( attr . Key , attr . Value ) newCtx . declare ( defaultPrefix , attr . Value ) return newCtx , nil", "del_tokens": "func ( ctx NSContext ) SubContext ( el * etree . Element ) ( NSContext , error ) { // The subcontext should inherit existing declared prefixes prefixes [ attr . Key ] = attr . Value prefixes [ defaultPrefix ] = attr . Value return NSContext { prefixes : prefixes } , nil", "commit_type": "add"}
{"commit_tokens": ["Adding", "retries", "to", "backend", "service", "in", "the", "startup"], "add_tokens": "\" \" attempt := 0 for config . RetryAttempts == - 1 || attempt <= config . RetryAttempts { log . Printf ( \" \" , attempt , config . RetryAttempts ) err = adapter . Ping ( ) if err == nil { break } if err != nil && attempt == config . RetryAttempts { log . Fatalf ( \" \" , uri . Scheme , err ) } time . Sleep ( time . Duration ( config . RetryInterval ) * time . Millisecond ) attempt ++", "del_tokens": "err = adapter . Ping ( ) if err != nil { log . Fatalf ( \" \" , uri . Scheme , err )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "%L", "(", "millisecond", ")", "and", "%N", "(", "nanosecond", ")", "from", "ruby"], "add_tokens": "case 'L' : msec := t . Nanosecond ( ) / 1e6 fmt . Fprintf ( b , \" \" , int ( msec ) ) case 'N' : fmt . Fprintf ( b , \" \" , t . Nanosecond ( ) ) // %f replaced by microsecond as a six digit decimal number, zero-padded on the left (001234) // %L replaced by millisecond as a three digit decimal number, zero-padded on the left (001) // %N replaced by nanosecond as a 9 digit decimal number, zero-padded on the left (001234567)", "del_tokens": "// %f replaced by microsecond as a decimal number, zero-padded on the left (000123)", "commit_type": "add"}
{"commit_tokens": ["Use", "gunzip", "if", "it", "is", "available", "on", "PATH"], "add_tokens": "\" \" gunzipPath , err := exec . LookPath ( \" \" ) if err == nil { return gunzipTarGZToTar ( gunzipPath , source , destination ) } defer dest . Close ( ) err = file . Close ( ) err = os . Remove ( path ) if err != nil { return 0 , err } return n , nil } func gunzipTarGZToTar ( gunzipPath , path , destPath string ) ( int64 , error ) { destFile , err := os . OpenFile ( destPath , os . O_WRONLY , 0666 ) if err != nil { return 0 , err } defer destFile . Close ( ) cmd := exec . Command ( gunzipPath , \" \" , path ) cmd . Stdout = destFile err = cmd . Run ( ) fileInfo , err := os . Stat ( destPath ) if err != nil { return 0 , err } return fileInfo . Size ( ) , nil", "del_tokens": "err = dest . Close ( ) err = file . Close ( ) return n , nil", "commit_type": "use"}
{"commit_tokens": ["Fixed", "up", "package", "name", "for", "gen"], "add_tokens": "package gen", "del_tokens": "package data", "commit_type": "fix"}
{"commit_tokens": ["Remove", "error", "return", "from", "Block", ".", "Sha", "function", "."], "add_tokens": "func ( b * Block ) Sha ( ) * wire . ShaHash { return b . blockSha return & sha", "del_tokens": "func ( b * Block ) Sha ( ) ( * wire . ShaHash , error ) { return b . blockSha , nil return & sha , nil", "commit_type": "remove"}
{"commit_tokens": ["add", "branch", "iterator", "/", "remove", "useless", "repo", "from", "reference", "iterator"], "add_tokens": "ptr * C . git_reference_iterator iter := & ReferenceIterator { ptr : ptr } iter := & ReferenceIterator { ptr : ptr }", "del_tokens": "ptr * C . git_reference_iterator repo * Repository iter := & ReferenceIterator { repo : repo , ptr : ptr } iter := & ReferenceIterator { repo : repo , ptr : ptr }", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "comment", "and", "more", "additions", "to", "README", ".", "md"], "add_tokens": "// Convert num from specified base to a different base.", "del_tokens": "// Convert string", "commit_type": "add"}
{"commit_tokens": ["Fix", "NotEqual", "in", "order", "to", "be", "composable"], "add_tokens": "func ( s * Suite ) NotEqual ( exp , act interface { } ) bool { return s . Status . failWithCustomMsg ( fmt . Sprintf ( \" \" , exp , act ) , s . callerInfo ) return s . Status . pass ( )", "del_tokens": "func ( s * Suite ) NotEqual ( exp , act interface { } ) { s . Status . failWithCustomMsg ( fmt . Sprintf ( \" \" , exp , act ) , s . callerInfo )", "commit_type": "fix"}
{"commit_tokens": ["add", "Width", "and", "Height", "methods", "to", "Texture"], "add_tokens": "enabled bool parent Doer tex uint32 width , height int texture := & Texture { parent : parent , width : width , height : height , } // Width returns the width of a texture in pixels. func ( t * Texture ) Width ( ) int { return t . width } // Height returns the height of a texture in pixels. func ( t * Texture ) Height ( ) int { return t . height }", "del_tokens": "enabled bool parent Doer tex uint32 texture := & Texture { parent : parent }", "commit_type": "add"}
{"commit_tokens": ["Added", "Body", "arg", "to", "update", "overrides", "."], "add_tokens": "type UpdatePositionFunction func ( body * Body , dt vect . Float ) type UpdateVelocityFunction func ( body * Body , gravity vect . Vect , damping , dt vect . Float ) body . UpdatePositionFunc ( body , dt ) body . UpdateVelocityFunc ( body , gravity , damping , dt )", "del_tokens": "type UpdatePositionFunction func ( dt vect . Float ) type UpdateVelocityFunction func ( gravity vect . Vect , damping , dt vect . Float ) body . UpdatePositionFunc ( dt ) body . UpdateVelocityFunc ( gravity , damping , dt )", "commit_type": "add"}
{"commit_tokens": ["Use", "github", ".", "com", "/", "akavel", "/", "rsrc"], "add_tokens": "\" \" if err = rsrc . Embed ( p , arch , \" \" , b . pathIconWindows ) ; err != nil {", "del_tokens": "\" \" if err = rsrc . Run ( \" \" , b . pathIconWindows , p , arch ) ; err != nil {", "commit_type": "use"}
{"commit_tokens": ["added", "response", "writer", "implementation", "to", "get", "status", "of", "response"], "add_tokens": "rw := & responseWriter { w : w } next . ServeHTTP ( rw , r ) log . Printf ( \" \\n \" , r . RemoteAddr , r . Method , r . URL . String ( ) , rw . Size ( ) , rw . Status ( ) , tEnd . Sub ( tIni ) )", "del_tokens": "// TODO: Afegir codi d'estat. Veure https://github.com/gocraft/web/blob/master/response_writer.go // per implementar wrapper sobre http.ResponseWriter y capturar l'estat next . ServeHTTP ( w , r ) log . Printf ( \" \\n \" , r . RemoteAddr , r . Method , r . URL . String ( ) , tEnd . Sub ( tIni ) )", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "parser", ".", "fixed", "parser", "when", "using", "restricted", "method", "list"], "add_tokens": "// Verify signing method is in the required set if p . ValidMethods != nil { var signingMethodValid = false var alg = token . Method . Alg ( ) for _ , m := range p . ValidMethods { if m == alg { signingMethodValid = true break } } if ! signingMethodValid { // signing method is not in the listed set return token , & ValidationError { err : fmt . Sprintf ( \" \" , alg ) , Errors : ValidationErrorSignatureInvalid } } }", "del_tokens": "// Verify signing method is in the required set if p . ValidMethods != nil { var signingMethodValid = false var alg = token . Method . Alg ( ) for _ , m := range p . ValidMethods { if m == alg { signingMethodValid = true break } } if ! signingMethodValid { return nil , & ValidationError { err : fmt . Sprintf ( \" \" , alg ) , Errors : ValidationErrorSignatureInvalid } } }", "commit_type": "add"}
{"commit_tokens": ["Fix", "goroutine", "leak", "on", "events", "error", "."], "add_tokens": "decodeChan := make ( chan decodingResult ) decoder := json . NewDecoder ( stream ) for { decodeResult := decode ( decoder ) decodeChan <- decodeResult if decodeResult . err != nil { close ( decodeChan ) return } } case <- stopChan : stream . Close ( ) for range decodeChan { } case decodeResult := <- decodeChan :", "del_tokens": "decoder := json . NewDecoder ( stream ) stopped := make ( chan struct { } ) <- stopChan stream . Close ( ) stopped <- struct { } { } decodeResult := decode ( decoder ) case <- stopped : default :", "commit_type": "fix"}
{"commit_tokens": ["remove", "Set", "/", "GetState", ";", "add", "client", "inFlightCount", ";", "move", "client", "incr", "/", "decr", "to", "atomic"], "add_tokens": "s := q . getBufferSize ( ) log . Printf ( \" \" , s ) c . consumer . WriteCommand ( c . consumer . Ready ( s ) )", "del_tokens": "c . consumer . WriteCommand ( c . consumer . Ready ( q . getBufferSize ( ) ) )", "commit_type": "remove"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", ".", "json"], "add_tokens": "FrameScheduledNavigationReasonFormSubmissionGet FrameScheduledNavigationReason = \" \" FrameScheduledNavigationReasonFormSubmissionPost FrameScheduledNavigationReason = \" \" case FrameScheduledNavigationReasonFormSubmissionGet : * t = FrameScheduledNavigationReasonFormSubmissionGet case FrameScheduledNavigationReasonFormSubmissionPost : * t = FrameScheduledNavigationReasonFormSubmissionPost", "del_tokens": "FrameScheduledNavigationReasonFormSubmission FrameScheduledNavigationReason = \" \" case FrameScheduledNavigationReasonFormSubmission : * t = FrameScheduledNavigationReasonFormSubmission", "commit_type": "update"}
{"commit_tokens": ["fix", "a", "bug", "decoding", "pointer", "-", "valued", "maps"], "add_tokens": "case reflect . Ptr : elem := reflect . New ( rv . Type ( ) . Elem ( ) ) err := unify ( data , reflect . Indirect ( elem ) ) if err == nil { rv . Set ( elem ) } return err rvval := reflect . Indirect ( reflect . New ( rv . Type ( ) . Elem ( ) ) )", "del_tokens": "rvval := indirect ( reflect . New ( rv . Type ( ) . Elem ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", ".", "keychain", "-", "db", "extension", "on", "macOS", "Sierra"], "add_tokens": "\" \" \" \" \" \" func keychainPath ( name string ) ( string , error ) { usr , err := user . Current ( ) if err != nil { return \" \" , err } // As of macOS Sierra, Keychain files are stored with the `.keychain-db` // extension, rather than `.keychain`. The result of the kern.osrelease // sysctl is the kernel version number in the form \"major.minor.patch\", // and Sierra is the first macOS release to use kernel major version 16 osver , err := syscall . Sysctl ( \" \" ) if err != nil { return \" \" , err } major , err := strconv . Atoi ( strings . Split ( osver , \" \" ) [ 0 ] ) if err != nil { return \" \" , err } if major >= 16 { return usr . HomeDir + \" \" + name + \" \" , nil } else { return usr . HomeDir + \" \" + name + \" \" , nil } } path , err := keychainPath ( name ) return & keychain { Path : path , Service : name } , nil", "del_tokens": "usr , err := user . Current ( ) return & keychain { Path : usr . HomeDir + \" \" + name + \" \" , Service : name } , nil", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "in", "etcd", "backend", "when", "connecting", "to", "etcd2"], "add_tokens": "var err error if r . client != nil { rr := etcd . NewRawRequest ( \" \" , \" \" , nil , nil ) _ , err = r . client . SendRequest ( rr ) } else { rr := etcd2 . NewRawRequest ( \" \" , \" \" , nil , nil ) _ , err = r . client2 . SendRequest ( rr ) }", "del_tokens": "rr := etcd . NewRawRequest ( \" \" , \" \" , nil , nil ) _ , err := r . client . SendRequest ( rr )", "commit_type": "fix"}
{"commit_tokens": ["Using", "batch", "get", "locally", "to", "retrieve", "chunks"], "add_tokens": "func simpleCmdLocal ( rw * bufio . ReadWriter ) error { func getLocal ( rw * bufio . ReadWriter ) ( data [ ] byte , flags uint32 , err error ) {", "del_tokens": "func simpleCmdLocal ( rw * bufio . ReadWriter , cmd [ ] byte ) error { rw . Write ( cmd ) func getLocal ( rw * bufio . ReadWriter , cmd [ ] byte ) ( data [ ] byte , flags uint32 , err error ) { rw . Write ( cmd )", "commit_type": "use"}
{"commit_tokens": ["Fix", "platform", "specific", "stat", "usage", "(", "build", "constraints", ")"], "add_tokens": "const Version = \" \" var usage = fmt . Sprintf ( `[options] [path [...]] Version : % s `, Version) usr , gid := uidGidFromFileInfo ( stat )", "del_tokens": "// \"flag\" \" \" \" \" const usage = `[options] [path [...]] ` stat_t := stat . Sys ( ) . ( * syscall . Stat_t ) usr := strconv . Itoa ( int ( stat_t . Uid ) ) gid := \" \" uObj , err := user . LookupId ( usr ) if err == nil { usr = uObj . Username gid = uObj . Gid }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "validation", "of", "IPv4", "-", "mapped", "IPv6", "addresses"], "add_tokens": "return ip != nil && strings . Contains ( str , \" \" ) return ip != nil && strings . Contains ( str , \" \" )", "del_tokens": "return ip != nil && ip . To4 ( ) != nil return ip != nil && ip . To4 ( ) == nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "default", "time", "format"], "add_tokens": "\" \" ,", "del_tokens": "\" \" ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "DefaultHost", "mutable", "for", "testing", "purposes"], "add_tokens": "// DefaultHost is a mutable var for testing purposes var DefaultHost = HostDevelopment Host : DefaultHost ,", "del_tokens": "Host : HostDevelopment ,", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "-", "script", "{", "scriptfile", "}", "so", "that", "you", "can", "run", "scripts", "with", "shebang", ":"], "add_tokens": "case 3 : if os . Args [ 1 ] == \" \" || os . Args [ 1 ] == \" \" { cmd := \" \" + os . Args [ 2 ] commander . OneCmd ( cmd ) } else { fmt . Println ( \" \" , os . Args [ 0 ] , \" \" ) } return fmt . Println ( \" \" , os . Args [ 0 ] , \" \" )", "del_tokens": "fmt . Println ( \" \" , os . Args [ 0 ] , \" \" )", "commit_type": "add"}
{"commit_tokens": ["move", "docs", "to", "the", "public", "interface"], "add_tokens": "// Error asynchronously sends an error to Rollbar with the given severity level. // ErrorWithExtras asynchronously sends an error to Rollbar with the // given severity level with extra custom data. // ErrorWithStackSkip asynchronously sends an error to Rollbar with the // given severity level and a given number of stack trace frames skipped. // ErrorWithStackSkipWithExtras asynchronously sends an error to Rollbar // with the given severity level and a given number of stack trace // frames skipped with extra custom data. // RequestError asynchronously sends an error to Rollbar with the given // severity level and request-specific information. // RequestErrorWithExtras asynchronously sends an error to Rollbar with // the given severity level and request-specific information with extra // custom data. // RequestErrorWithStackSkip asynchronously sends an error to Rollbar // with the given severity level and a given number of stack trace // frames skipped, in addition to extra request-specific information. // RequestErrorWithStackSkipWithExtras asynchronously sends an error to // Rollbar with the given severity level and a given number of stack // trace frames skipped, in addition to extra request-specific // information and extra custom data. // Message asynchronously sends a message to Rollbar with the given // severity level. Rollbar request is asynchronous. // MessageWithExtras asynchronously sends a message to Rollbar with the // given severity level with extra custom data. Rollbar request is // asynchronous. // Wait will block until the queue of errors / messages is empty.", "del_tokens": "// Error asynchronously sends an error to Rollbar with the given severity level. // ErrorWithExtras asynchronously sends an error to Rollbar with the given severity level with extra custom data. // RequestError asynchronously sends an error to Rollbar with the given // severity level and request-specific information. // RequestErrorWithExtras asynchronously sends an error to Rollbar with the given // severity level and request-specific information with extra custom data. // ErrorWithStackSkip asynchronously sends an error to Rollbar with the given // severity level and a given number of stack trace frames skipped. // ErrorWithStackSkipWithExtras asynchronously sends an error to Rollbar with the given // severity level and a given number of stack trace frames skipped with extra custom data. // RequestErrorWithStackSkip asynchronously sends an error to Rollbar with the // given severity level and a given number of stack trace frames skipped, in // addition to extra request-specific information. // RequestErrorWithStackSkip asynchronously sends an error to Rollbar with the // given severity level and a given number of stack trace frames skipped, in // addition to extra request-specific information and extra custom data. // Message asynchronously sends a message to Rollbar with the given severity // level. Rollbar request is asynchronous. // Message asynchronously sends a message to Rollbar with the given severity // level with extra custom data. Rollbar request is asynchronous. // Wait will block until the queue of errors / messages is empty.", "commit_type": "move"}
{"commit_tokens": ["use", "new", "location", "of", "pq", "library"], "add_tokens": "_ \" \"", "del_tokens": "_ \" \"", "commit_type": "use"}
{"commit_tokens": ["Fix", "issue", "of", "WARNING", ":", "--", "size", "ignored", "for", "volume", "for", "docker", "inspect"], "add_tokens": "{ \" \" , false , inspectImages ( ctx , dockerCli ) } , if getSize && ! inspectData . IsSizeSupported {", "del_tokens": "{ \" \" , true , inspectImages ( ctx , dockerCli ) } , if ! inspectData . IsSizeSupported {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "asmCmpOp", "(", "signed", "vs", "unsigned", "ops", ")", "and", "add", "if", "statement", "support"], "add_tokens": "size = f . sizeof ( instr . X ) if size != f . sizeof ( instr . Y ) { panic ( \" \" ) } asm += asmCmpOp ( f . Indent , instr . Op , xIsSigned , regX , regY , & regVal , size ) case types . Bool : return false", "del_tokens": "asm += asmCmpOp ( f . Indent , instr . Op , regX , regY , & regVal )", "commit_type": "fix"}
{"commit_tokens": ["Add", "bold", "and", "underline", "attributes", "to", "Style"], "add_tokens": "Reverse ( style . Reverse ) . Bold ( style . Bold ) . Underline ( style . Underline )", "del_tokens": "Reverse ( style . Reverse )", "commit_type": "add"}
{"commit_tokens": ["Fix", "redundant", "decimal", "when", "fraction", "is", "0"], "add_tokens": "if f . Fraction > 0 { sa = sa [ : len ( sa ) - f . Fraction ] + f . Decimal + sa [ len ( sa ) - f . Fraction : ] }", "del_tokens": "sa = sa [ : len ( sa ) - f . Fraction ] + f . Decimal + sa [ len ( sa ) - f . Fraction : ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "hex", "/", "base64", "/", "btc", "(", "b58", ")", "encoding", "of", "binary", "data"], "add_tokens": "data \" \" \" \" RootCmd . PersistentFlags ( ) . StringP ( \" \" , \" \" , \" \" , \" \" ) RootCmd . PersistentFlags ( ) . StringP ( \" \" , \" \" , \" \" , \" \" ) // validate and set encoding enc := viper . GetString ( \" \" ) switch enc { case \" \" : data . Encoder = data . HexEncoder case \" \" : data . Encoder = data . B64Encoder case \" \" : data . Encoder = base58 . BTCEncoder default : return errors . Errorf ( \" \" , enc ) }", "del_tokens": "RootCmd . PersistentFlags ( ) . StringP ( \" \" , \" \" , \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "gauges", "with", "custom", "labels", "."], "add_tokens": "g3 := termui . NewGauge ( ) g3 . Percent = 50 g3 . Width = 50 g3 . Height = 3 g3 . Y = 11 g3 . Border . Label = \" \" g3 . Label = \" \" termui . Render ( g0 , g1 , g2 , g3 )", "del_tokens": "termui . Render ( g0 , g1 , g2 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "obsolete", "field", "name", "in", "comments"], "add_tokens": "// Assigned uids for nodes which were created would be returned in the assigned.Uids map.", "del_tokens": "// Assigned uids for nodes which were created would be returned in the resp.AssignedUids map.", "commit_type": "fix"}
{"commit_tokens": ["Update", "README", "and", "user", "-", "visible", "strings", "to", "point", "to", "v2"], "add_tokens": "goPkgsErrFmt = \" \"", "del_tokens": "goPkgsErrFmt = \" \"", "commit_type": "update"}
{"commit_tokens": ["Makes", "Report", "Label", "use", "the", "actual", "node", "count"], "add_tokens": "nodeCount := len ( g . Nodes )", "del_tokens": "nodeCount := rpt . options . NodeCount", "commit_type": "make"}
{"commit_tokens": ["add", "some", "more", "error", "checks"], "add_tokens": "if length > MaxBlockSize { return nil , errors . New ( fmt . Sprintf ( \" \" , length , MaxBlockSize ) )", "del_tokens": "if length > 65536 { return nil , errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "blake2b", "and", "blake2s", "as", "options", "for", "go", "-", "multihash"], "add_tokens": "blake2b \" \" blake2s \" \" if length < 0 { var ok bool length , ok = DefaultLengths [ code ] if ! ok { return m , fmt . Errorf ( \" \" , code ) } } case BLAKE2B : switch length { case 32 : out := blake2b . Sum256 ( data ) d = out [ : ] case 48 : out := blake2b . Sum384 ( data ) d = out [ : ] case 64 : out := blake2b . Sum512 ( data ) d = out [ : ] default : return nil , fmt . Errorf ( \" \" ) } case BLAKE2S : out := blake2s . Sum256 ( data ) d = out [ : ]", "del_tokens": "if length < 0 { var ok bool length , ok = DefaultLengths [ code ] if ! ok { return m , fmt . Errorf ( \" \" , code ) } }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "issues", "adding", "back", "newer", "error", "handling"], "add_tokens": "_ \" \" sqliteErr , isErr := err . ( sqlite3 . Error ) if isErr { // The sqlite3 library only provides error codes, not position information. Output what we do know. pipe <- fmt . Errorf ( \" \\n \" , sqliteErr . Code . Error ( ) , sqliteErr . ExtendedCode . Error ( ) , sqliteErr . Error ( ) ) ) } else { pipe <- fmt . Errorf ( \" \" , query , err ) }", "del_tokens": "\" \" pipe <- fmt . Errorf ( \" \" , query , err )", "commit_type": "fix"}
{"commit_tokens": ["Made", "the", "length", "of", "the", "user", "confirmation", "string", "customizable"], "add_tokens": "defaultRedisServer = \" \" ) var ( minConfirmationCodeLength = 20 // minimum length of the confirmation code // Set the minimum length of the user confirmation code. The default is 20. func ( state * UserState ) SetMinimumConfirmationCodeLength ( length int ) { minConfirmationCodeLength = length }", "del_tokens": "minConfirmationCodeLength = 20 // minimum length of the confirmation code saltword = \" \" // used together with username and password when hashing defaultRedisServer = \" \" // The confirmation code must be a minimum of 8 letters long", "commit_type": "make"}
{"commit_tokens": ["fix", "a", "panic", "when", "tokens", "do", "not", "have", "a", "kid", "in", "the", "header"], "add_tokens": "kid , ok := jt . Header [ keyIDJwtHeaderName ] . ( string ) if ! ok { return nil , & ValidationError { Code : ValidationErrorKidNotFound , Message : \" \" , HTTPStatus : http . StatusUnauthorized , } } if key , err = tv . keyGetter . getSigningKey ( r , iss , kid ) ; err == nil {", "del_tokens": "if key , err = tv . keyGetter . getSigningKey ( r , iss , jt . Header [ keyIDJwtHeaderName ] . ( string ) ) ; err == nil {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "superfluous", "space", "in", "DisableJavascript", "option"], "add_tokens": "DisableJavascript : boolOption { option : \" \" } ,", "del_tokens": "DisableJavascript : boolOption { option : \" \" } ,", "commit_type": "remove"}
{"commit_tokens": ["Move", "jsonschema", "code", "into", "separate", "package", "."], "add_tokens": "\" \" base_schema := jsonschema . NewSchemaFromFile ( \" \" ) base_schema . ResolveRefs ( ) base_schema . ResolveAllOfs ( ) openapi_schema := jsonschema . NewSchemaFromFile ( \" \" ) openapi_schema . ResolveRefs ( ) openapi_schema . ResolveAllOfs ( )", "del_tokens": "base_schema := NewSchemaFromFile ( \" \" ) base_schema . resolveRefs ( ) base_schema . resolveAllOfs ( ) openapi_schema := NewSchemaFromFile ( \" \" ) openapi_schema . resolveRefs ( ) openapi_schema . resolveAllOfs ( )", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "string", "arrays", ".", "Reorganised", "SEXP", "parsing"], "add_tokens": "import ( \" \" \" \" ) return sexp . Parse ( p . content [ 4 : len ( p . content ) ] , 0 )", "del_tokens": "import \" \" return parseSEXP ( p . content [ 4 : len ( p . content ) ] , 0 )", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "the", "last", "API", "update", "^^", "(", "https", ":", "//", "core", ".", "telegram", ".", "org", "/", "bots", "/", "api", "-", "changelog", ")"], "add_tokens": "Caption * string `json:\"caption,omitempty\"` FileID string `json:\"file_id\"` Thumb * PhotoSize `json:\"thumb,omitempty\"` FileName * string `json:\"file_name,omitempty\"` MimeType * string `json:\"mime_type,omitempty\"` FileSize * int `json:\"file_size,omitempty\"` FileID string `json:\"file_id\"` Width int `json:\"width\"` Height int `json:\"height\"` Thumb * PhotoSize `json:\"thumb,omitempty\"` // .webp or .jpg format FileSize * int `json:\"file_size,omitempty\"` FileID string `json:\"file_id\"` Width int `json:\"width\"` Height int `json:\"height\"` Duration int `json:\"duration\"` Thumb * PhotoSize `json:\"thumb,omitempty\"` MimeType * string `json:\"mime_type,omitempty\"` FileSize * int `json:\"file_size,omitempty\"` UserID * int `json:\"user_id,omitempty\"` Duration * int `json:\"duration,omitempty\"` Caption * string `json:\"caption,omitempty\"` Duration * int `json:\"duration,omitempty\"` Caption * string `json:\"caption,omitempty\"`", "del_tokens": "FileID string `json:\"file_id\"` Thumb PhotoSize `json:\"thumb\"` FileName * string `json:\"file_name,omitempty\"` MimeType * string `json:\"mime_type,omitempty\"` FileSize * int `json:\"file_size,omitempty\"` FileID string `json:\"file_id\"` Width int `json:\"width\"` Height int `json:\"height\"` Thumb PhotoSize `json:\"thumb\"` // .webp or .jpg format FileSize * int `json:\"file_size,omitempty\"` FileID string `json:\"file_id\"` Width int `json:\"width\"` Height int `json:\"height\"` Duration int `json:\"duration\"` Thumb PhotoSize `json:\"thumb\"` MimeType * string `json:\"mime_type,omitempty\"` FileSize * int `json:\"file_size,omitempty\"` Caption * string `json:\"caption,omitempty\"` UserID * string `json:\"user_id,omitempty\"` Caption * string `json:\"caption,omitempty\"` Caption * string `json:\"caption,omitempty\"`", "commit_type": "update"}
{"commit_tokens": ["Remove", "V4", "address", "family", "in", "cmux_test", ".", "go", "."], "add_tokens": "l , err := net . Listen ( \" \" , \" \" )", "del_tokens": "l , err := net . Listen ( \" \" , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["fix", "race", "by", "returning", "new", "copies", "of", "maps"], "add_tokens": "assert . Equal ( t , s . ResponseCounts , map [ string ] int { \" \" : 1 } )", "del_tokens": "assert . Equal ( t , s . ResponseCounts ( ) , map [ string ] int { \" \" : 1 } )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unnecessary", "/", "redundant", "function", "calls", "in", "Sorter", ".", "Swap"], "add_tokens": "x := s . Slice . Index ( i ) y := s . Slice . Index ( j ) tmp . Set ( x ) x . Set ( y ) y . Set ( tmp )", "del_tokens": "tmp . Set ( s . Slice . Index ( i ) ) s . Slice . Index ( i ) . Set ( s . Slice . Index ( j ) ) s . Slice . Index ( j ) . Set ( tmp )", "commit_type": "remove"}
{"commit_tokens": ["added", "some", "extra", "standard", "error", "messages"], "add_tokens": "ErrValueAvailableActionIsNil = errors . New ( \" \" ) MaximumLookbackPeriod int = 100000", "del_tokens": "MaximumLookbackPeriod int = 200", "commit_type": "add"}
{"commit_tokens": ["Removing", "required", "subject", "from", "gserviceaccount", ".", "TokenSource"], "add_tokens": "// using the provided context and scopes. // If context is empty, then then context.Background() will be used instead. // If additional claims need to be added to the TokenSource (ie, subject or the // \"sub\" field), use jwt/bearer.Claim to add them prior to wrapping the // TokenSource with oauth2.ReusableTokenSource. func ( gsa * GServiceAccount ) TokenSource ( ctxt context . Context , scopes ... string ) ( * bearer . Bearer , error ) { // bearer grant options opts := [ ] bearer . Option { } // create token source b , err := bearer . NewTokenSource ( signer , gsa . TokenURI , ctxt , opts . . . ,", "del_tokens": "// using the provided subject, context, and scopes. // If subject is empty, then GServiceAccount.ClientEmail will be used. // Similarly, if the passed context is nil, then context.Background() will be // used instead. // If additional claims need to be added to the TokenSource, use // jwt/bearer.Claim to add them prior to wrapping the TokenSource with // oauth2.ReusableTokenSource. func ( gsa * GServiceAccount ) TokenSource ( subject string , ctxt context . Context , scopes ... string ) ( * bearer . Bearer , error ) { if subject == \" \" { subject = gsa . ClientEmail } // create token source b , err := bearer . NewTokenSource ( signer , gsa . TokenURI , ctxt , bearer . Claim ( \" \" , subject ) ,", "commit_type": "remove"}
{"commit_tokens": ["Adds", "bearer", "token", "base", "authentication", "."], "add_tokens": "token string func newPBRestClientbyToken ( token , apiURL , depth string , pretty bool ) * client { client := new ( client ) client . token = token client . agentHeader = \" \" if apiURL == \" \" { client . apiURL = \" \" } else { client . apiURL = apiURL } if depth == \" \" { client . depth = \" \" } else { client . depth = depth } return client } if c . token != \" \" { r . Header . Add ( \" \" , \" \" + c . token ) } else { r . SetBasicAuth ( c . username , c . password ) }", "del_tokens": "r . SetBasicAuth ( c . username , c . password )", "commit_type": "add"}
{"commit_tokens": ["Added", "root", "key", "creation", "if", "non", "-", "existing", "to", "notary"], "add_tokens": "return \" \" , fmt . Errorf ( \" \" , err )", "del_tokens": "return \" \" , fmt . Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["update", "libp2p", "with", "go", "-", "multiaddr", "and", "go", "-", "stream", "-", "muxer", "updates"], "add_tokens": "peer \" \" ma \" \"", "del_tokens": "peer \" \" ma \" \"", "commit_type": "update"}
{"commit_tokens": ["Remove", "out", "of", "style", "error", "message", "prefix", "."], "add_tokens": "lua . Errorf ( l , fmt . Sprintf ( \" \" , val ) )", "del_tokens": "lua . Errorf ( l , fmt . Sprintf ( \" \" , val ) )", "commit_type": "remove"}
{"commit_tokens": ["Implement", "methods", "for", "indexer", "acknowledgement"], "add_tokens": "Text string `json:\"text\"` Code int `json:\"code\"` AckID * int `json:\"ackId\"` // Use a pointer so we can differentiate between a 0 and an ack ID not being specified Acks map [ string ] bool `json:\"acks\"` // Splunk returns ack IDs as strings rather than ints", "del_tokens": "Text string `json:\"text\"` Code int `json:\"code\"` AckID string `json:\"ackID,omitempty\"`", "commit_type": "implement"}
{"commit_tokens": ["Add", "pagination", "to", "IAMRoles", "resources", "."], "add_tokens": "// REMOVE: Baesd on https://github.com/rebuy-de/aws-nuke/blob/master/resources/ecr-repository.go params := & iam . ListRolesInput { } resources := make ( [ ] Resource , 0 ) for { resp , err := svc . ListRoles ( params ) if err != nil { return nil , err } for _ , out := range resp . Roles { resources = append ( resources , & IAMRole { svc : svc , name : * out . RoleName , path : * out . Path , } ) } if * resp . IsTruncated == false { break } params . Marker = resp . Marker", "del_tokens": "resp , err := svc . ListRoles ( nil ) if err != nil { return nil , err } resources := make ( [ ] Resource , 0 ) for _ , out := range resp . Roles { resources = append ( resources , & IAMRole { svc : svc , name : * out . RoleName , path : * out . Path , } )", "commit_type": "add"}
{"commit_tokens": ["Move", "compiled", "assets", "into", "subpackage"], "add_tokens": "\" \" writeHTML ( w , assets . MustAsset ( \" \" ) , http . StatusOK ) writeHTML ( w , assets . MustAsset ( \" \" ) , http . StatusOK ) writeHTML ( w , assets . MustAsset ( \" \" ) , http . StatusOK ) writeHTML ( w , assets . MustAsset ( \" \" ) , http . StatusOK ) img , err := assets . Asset ( \" \" + kind ) writeResponse ( w , http . StatusOK , \" \" , assets . MustAsset ( \" \" ) ) // DigestAuth handles a simple implementation of HTTP Digest Authentication, // which supports the \"auth\" QOP and the MD5 and SHA-256 crypto algorithms.", "del_tokens": "writeHTML ( w , MustAsset ( \" \" ) , http . StatusOK ) writeHTML ( w , MustAsset ( \" \" ) , http . StatusOK ) writeHTML ( w , MustAsset ( \" \" ) , http . StatusOK ) writeHTML ( w , MustAsset ( \" \" ) , http . StatusOK ) img , err := Asset ( \" \" + kind ) writeResponse ( w , http . StatusOK , \" \" , MustAsset ( \" \" ) ) // DigestAuth blah", "commit_type": "move"}
{"commit_tokens": ["Use", "WagnerFischer", "to", "detect", "mangled", "passwords"], "add_tokens": "{ \" \" , ErrMangledDictionary } , // dictionary with mangling { \" \" , ErrMangledDictionary } , // dictionary with mangling { \" \" , ErrMangledDictionary } , // reversed dictionary { \" \" , ErrMangledDictionary } , // reversed dictionary with mangling", "del_tokens": "{ \" \" , ErrDictionary } , // reversed dictionary { \" \" , ErrDictionary } , // dictionary with mangling { \" \" , ErrDictionary } , // reversed dictionary with mangling", "commit_type": "use"}
{"commit_tokens": ["add", "golangci", "badge", "and", "fix", "some", "lint", "issues", "found", "by", "the", "tool"], "add_tokens": "_ = parse ( \" \" , args ) _ = parse ( \" \" , & args )", "del_tokens": "parse ( \" \" , args ) parse ( \" \" , & args )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "build", "errors", "."], "add_tokens": "var _ bucketTestSetUpInterface = & bucketTest { } func ( t * bucketTest ) SetUpBucketTest ( b gcs . Bucket ) { t . bucket = b", "del_tokens": "var _ bucketSetter = & bucketTest { } var _ SetUpInterface = & bucketTest { } func ( t * bucketTest ) SetUp ( ti * TestInfo ) { // Create a context and bucket. t . bucket = t . getBucket ( )", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "pull", "-", "request", "look", "for", "title", "argument"], "add_tokens": "var title , body string if len ( args ) == 1 { title = args [ 0 ] } if title == \" \" { messageFile , err := git . PullReqMsgFile ( ) utils . Check ( err ) err = writePullRequestChanges ( repo , messageFile ) utils . Check ( err ) editorPath , err := git . EditorPath ( ) utils . Check ( err ) err = editTitleAndBody ( editorPath , messageFile ) utils . Check ( err ) title , body , err = readTitleAndBody ( messageFile ) utils . Check ( err ) }", "del_tokens": "messageFile , err := git . PullReqMsgFile ( ) utils . Check ( err ) err = writePullRequestChanges ( repo , messageFile ) utils . Check ( err ) editorPath , err := git . EditorPath ( ) utils . Check ( err ) err = editTitleAndBody ( editorPath , messageFile ) utils . Check ( err ) title , body , err := readTitleAndBody ( messageFile ) utils . Check ( err )", "commit_type": "make"}
{"commit_tokens": ["Added", "checking", "of", "golden", "files", "."], "add_tokens": "// checkGolden file checks the supplied actual output for the named test case // against the golden file for that case. If requested by the user, it rewrites // the golden file on failure. func checkAgainstGoldenFile ( caseName string , output [ ] byte ) bool { goldenFile := \" \" + caseName goldenContents := readFileOrDie ( path . Join ( \" \" , goldenFile ) ) return string ( output ) == string ( goldenContents ) } output , exitCode , err := runTestCase ( caseName ) // Check the output against the golden file. if ! checkAgainstGoldenFile ( caseName , output ) { t . Errorf ( \" \" , caseName ) }", "del_tokens": "_ , exitCode , err := runTestCase ( caseName )", "commit_type": "add"}
{"commit_tokens": ["fixed", "panic", "when", "parsing", ".", "edu", "domain"], "add_tokens": "\" \" , \" \" , if found != - 1 { index = found if tokens [ token ] [ index ] != \" \" { index += 1 }", "del_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , if found == - 1 { token = \" \" index = 0 continue index = found index += 1", "commit_type": "fix"}
{"commit_tokens": ["Use", "special", "name", "_destroy", "to", "mark", "a", "record", "as", "delete"], "add_tokens": "primaryKey := values [ 0 ] context . DB . First ( result , primaryKey ) if destroyValues , ok := request . Form [ prefix + \" \" ] ; ok { if destroyValues [ 0 ] != \" \" { context . DB . Delete ( result , primaryKey ) return } }", "del_tokens": "context . DB . First ( result , values [ 0 ] )", "commit_type": "use"}
{"commit_tokens": ["Fix", "import", "from", "garyburd", "to", "gomodule"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["adds", "ability", "to", "configure", "remote", "stemcell", "in", "concourse", "plugin"], "add_tokens": "StemcellURL string StemcellSHA string d . manifest . AddRemoteStemcell ( stemcellName , d . StemcellAlias , stemcellVer , d . StemcellURL , d . StemcellSHA )", "del_tokens": "d . manifest . AddRemoteStemcell ( stemcellName , d . StemcellAlias , stemcellVer , stemcellURL , stemcellSHA )", "commit_type": "add"}
{"commit_tokens": ["added", "some", "timeouts", "to", "cyand"], "add_tokens": "\" \" const timeout = 30 * time . Second func uploadInner ( w http . ResponseWriter , r * http . Request , kill chan bool ) { select { case <- kill : return default : } select { case <- kill : return default : } select { case <- kill : return default : } select { case <- kill : return default : } close ( kill ) } func upload ( w http . ResponseWriter , r * http . Request ) { kill := make ( chan bool ) go uploadInner ( w , r , kill ) select { case <- time . After ( timeout ) : close ( kill ) http . Error ( w , \" \" , http . StatusInternalServerError ) log . Print ( \" \" ) case <- kill : }", "del_tokens": "func upload ( w http . ResponseWriter , r * http . Request ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "tests", "for", "Error", "handling"], "add_tokens": "func ( s * Do ) hasError ( ) bool { return len ( s . Errors ) > 0 } var err error s . TableName , err = s . model . TableName ( ) s . err ( err ) if s . hasError ( ) { return } if err != nil { return } defer rows . Close ( ) if s . hasError ( ) { return s } var sqls [ ] string for _ , field := range s . model . Fields ( \" \" ) { sqls = append ( sqls , field . DbName + \" \" + field . SqlType ) } s . Sql = fmt . Sprintf ( \" \\\" \\\" \" , s . TableName , strings . Join ( sqls , \" \" ) , )", "del_tokens": "s . TableName = s . model . TableName ( ) defer rows . Close ( ) s . Sql = s . model . CreateTable ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "on", "read", "timeout"], "add_tokens": "ReadTimeout : s . options . ReadTimeout , WriteTimeout : s . options . WriteTimeout , ReadTimeout : s . options . ReadTimeout , WriteTimeout : s . options . WriteTimeout ,", "del_tokens": "\" \" ReadTimeout : 10 * time . Second , WriteTimeout : 10 * time . Second , ReadTimeout : 10 * time . Second , WriteTimeout : 10 * time . Second ,", "commit_type": "fix"}
{"commit_tokens": ["add", "way", "to", "query", "subscribed", "topics"], "add_tokens": "// getTopics chan * topicReq getTopics : make ( chan * topicReq ) , case treq := <- p . getTopics : var out [ ] string for t := range p . myTopics { out = append ( out , t ) } treq . resp <- out func ( p * PubSub ) Subscribe ( ctx context . Context , topic string ) ( <- chan * Message , error ) { type topicReq struct { resp chan [ ] string } func ( p * PubSub ) GetTopics ( ) [ ] string { out := make ( chan [ ] string , 1 ) p . getTopics <- & topicReq { resp : out } return <- out }", "del_tokens": "func ( p * PubSub ) Subscribe ( topic string ) ( <- chan * Message , error ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "larger", "buffer", "for", "receiving", "netlink", "messages"], "add_tokens": "buf [ ] byte nladdr , ok := localaddr . ( * syscall . SockaddrNetlink ) if ! ok { success = true return & NetlinkSocket { fd : fd , addr : nladdr , // netlink messages can be bigger than this, but it // seems unlikely in practice, and this is similar to // the limit that the OVS userspace imposes. buf : make ( [ ] byte , 65536 ) , } , nil nr , from , err := syscall . Recvfrom ( s . fd , s . buf , 0 ) buf := MakeAlignedByteSlice ( nr ) copy ( buf , s . buf ) return & NlMsgParser { data : buf , pos : 0 } , nil", "del_tokens": "switch nladdr := localaddr . ( type ) { case * syscall . SockaddrNetlink : success = true return & NetlinkSocket { fd : fd , addr : nladdr } , nil default : buf := MakeAlignedByteSlice ( syscall . Getpagesize ( ) ) nr , from , err := syscall . Recvfrom ( s . fd , buf , 0 ) return & NlMsgParser { data : buf [ : nr ] , pos : 0 } , nil", "commit_type": "use"}
{"commit_tokens": ["add", "context", ".", "WithTimeout", "(", "to", "force", "termination", "of", "goroutine", ")"], "add_tokens": "ctx , cancel := context . WithTimeout ( context . Background ( ) , d * time . Second ) defer cancel ( ) go func ( context . Context ) { } ( ctx ) // httpClient is overwritten in tests var httpClient = func ( ctx context . Context ) ( * http . Client , error ) { const scope = \" \" return google . DefaultClient ( ctx , scope ) } client , err := httpClient ( ctx )", "del_tokens": "go func ( ) { } ( ) scope := \" \" client , err := google . DefaultClient ( ctx , scope )", "commit_type": "add"}
{"commit_tokens": ["Adding", "doc", "for", "public", "interface"], "add_tokens": "// Inteface of Premailer // Transform process and inlining css // It start to collect the rules in the document style tags // Calculate specificity and sort the rules based on that // It then collects the affected elements // And applies the rules on those // The leftover rules will put back into a style element", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "test", "case", "for", "watchers"], "add_tokens": "log . Printf ( \" \" , event , s . parentWatchers . Len ( ) )", "del_tokens": "log . Printf ( \" \" , event )", "commit_type": "add"}
{"commit_tokens": ["make", "it", "compatibly", "with", "Ubuntu", "saucy"], "add_tokens": "/ * # include < SDL2 / SDL . h > # include < SDL2 / SDL_syswm . h > # if ! ( SDL_VERSION_ATLEAST ( 2 , 0 , 2 ) ) # define SDL_SYSWM_WAYLAND SDL_SYSWM_UNKNOWN # define SDL_SYSWM_MIR SDL_SYSWM_UNKNOWN # endif * /", "del_tokens": "// #include <SDL2/SDL.h> // #include <SDL2/SDL_syswm.h>", "commit_type": "make"}
{"commit_tokens": ["Add", "interface", "to", "Seeder", "and", "don", "t", "export", "struct"], "add_tokens": "//go:generate counterfeiter . Seeder type Seeder interface { CreateDBIfNeeded ( ) error IsExistingUser ( ) ( bool , error ) CreateUser ( ) error GrantUserAllPrivileges ( ) error } type seeder struct { func NewSeeder ( db * sql . DB , config config . PreseededDatabase , logger lager . Logger ) Seeder { return & seeder { func ( s seeder ) CreateDBIfNeeded ( ) error { func ( s seeder ) IsExistingUser ( ) ( bool , error ) { func ( s seeder ) CreateUser ( ) error { func ( s seeder ) GrantUserAllPrivileges ( ) error {", "del_tokens": "type Seeder struct { func NewSeeder ( db * sql . DB , config config . PreseededDatabase , logger lager . Logger ) * Seeder { return & Seeder { func ( s Seeder ) CreateDBIfNeeded ( ) error { func ( s Seeder ) IsExistingUser ( ) ( bool , error ) { func ( s Seeder ) CreateUser ( ) error { func ( s Seeder ) GrantUserAllPrivileges ( ) error {", "commit_type": "add"}
{"commit_tokens": ["Use", "go", "-", "colorable", "for", "Print", "function", "s", "out"], "add_tokens": "\" \" var out io . Writer func init ( ) { out = colorable . NewColorableStdout ( ) } return fmt . Fprint ( out , formatAll ( a ) ... ) return fmt . Fprintf ( out , format , formatAll ( a ) ... ) return fmt . Fprintln ( out , formatAll ( a ) ... )", "del_tokens": "return fmt . Print ( formatAll ( a ) ... ) return fmt . Printf ( format , formatAll ( a ) ... ) return fmt . Println ( formatAll ( a ) ... )", "commit_type": "use"}
{"commit_tokens": ["Added", "EnableMQTTDebugLog", "()", "removed", "redundant", "debug", "print", "."], "add_tokens": "\" \" Info . Printf ( \" \" ) Debug . Printf ( \" \" , topic ) func EnableMQTTDebugLog ( ) { MQTT . ERROR = log . New ( os . Stdout , \" \" , 0 ) MQTT . CRITICAL = log . New ( os . Stdout , \" \" , 0 ) MQTT . WARN = log . New ( os . Stdout , \" \" , 0 ) MQTT . DEBUG = log . New ( os . Stdout , \" \" , 0 ) }", "del_tokens": "Info . Printf ( \" \" , client ) Info . Printf ( \" \" ) Info . Printf ( \" \" ) Info . Printf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "capture", "logs"], "add_tokens": "LogHook LogHook // PrintErrStrategy is used to log attempts as they happen. // You know, more visible type LogHook func ( e ErrEntry ) res += c . FormatError ( e ) // Format the Error to human readable string func ( c * Client ) FormatError ( e ErrEntry ) string { return fmt . Sprintf ( \" \\n \" , e . Time . Unix ( ) , e . Method , e . Verb , e . URL , e . Request , e . Retry , e . Err ) } defer c . Unlock ( ) } else if c . LogHook != nil { // NOTE: There is a possibility that Log Printing hook slows it down. // but the consumer can always do the Job in a go-routine. c . LogHook ( e )", "del_tokens": "res += fmt . Sprintf ( \" \\n \" , e . Time . Unix ( ) , e . Method , e . Verb , e . URL , e . Request , e . Retry , e . Err ) c . Unlock ( )", "commit_type": "add"}
{"commit_tokens": ["Improve", "specitivity", "of", "error", "message", "for", "GenDecl"], "add_tokens": "return gas . NewIssue ( ctx , valueSpec , r . What , r . Severity , r . Confidence ) , nil", "del_tokens": "return gas . NewIssue ( ctx , decl , r . What , r . Severity , r . Confidence ) , nil", "commit_type": "improve"}
{"commit_tokens": ["Moved", "the", "factory", "function", "."], "add_tokens": "// Create a file system that stores data and metadata in memory. func NewMemFS ( clock timeutil . Clock ) fuse . FileSystem", "del_tokens": "// Create a file system that stores data and metadata in memory. func NewMemFS ( clock timeutil . Clock ) fuse . FileSystem", "commit_type": "move"}
{"commit_tokens": ["Fix", "NewJWT", "to", "return", "JWT", "rather", "than", "mrfusion", ".", "Authenticator"], "add_tokens": "func NewJWT ( secret string ) JWT { return JWT {", "del_tokens": "func NewJWT ( secret string ) mrfusion . Authenticator { return & JWT {", "commit_type": "fix"}
{"commit_tokens": ["Adds", "SUBSCRIBE", "UNSUBSCRIBE", "and", "LSUB", "support"], "add_tokens": "// If Subscribed is set to true, LSUB will be used instead. Subscribed bool name := imap . List if c . Subscribed { name = imap . Lsub } Name : name ,", "del_tokens": "Name : imap . List ,", "commit_type": "add"}
{"commit_tokens": ["Added", "event", "validation", ".", "Enabled", "by", "configuration", "parameter", "Validatecheck"], "add_tokens": "Validatecheck bool )", "del_tokens": ")", "commit_type": "add"}
{"commit_tokens": ["Added", "IF", "EXISTS", "toggle", "to", "DROP", "TABLE", "statement"], "add_tokens": "table * TableElem ifExists bool func ( stmt DropStmt ) IfExists ( ) DropStmt { stmt . ifExists = true return stmt } // String outputs a parameter-less and dialect neutral DROP TABLE statement. if stmt . ifExists { return fmt . Sprintf ( `DROP TABLE IF EXISTS \"%s\"` , stmt . table . Name ) , nil }", "del_tokens": "table * TableElem", "commit_type": "add"}
{"commit_tokens": ["Changed", "URL", "pattern", "for", "servers"], "add_tokens": "c . url = fmt . Sprintf ( \" \" , laddr , serverName )", "del_tokens": "c . url = fmt . Sprintf ( \" \" , laddr , serverName )", "commit_type": "change"}
{"commit_tokens": ["Added", "comments", "/", "license", "."], "add_tokens": "\" \" \" \" \" \" \" \" : template . HTML ( diff ) ,", "del_tokens": "\" \" \" \" \" \" \" \" : template . HTML ( diff ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "rate", "limiting", "to", "readme"], "add_tokens": "// limiters that may be used to limit download transfer speeds.", "del_tokens": "// limiters that may used to limit download transfer speeds.", "commit_type": "add"}
{"commit_tokens": ["Remove", "oid", "as", "id", "name"], "add_tokens": "func ( v * RevWalk ) Next ( id * Oid ) ( err error ) { ret := C . git_revwalk_next ( id . toC ( ) , v . ptr )", "del_tokens": "func ( v * RevWalk ) Next ( oid * Oid ) ( err error ) { ret := C . git_revwalk_next ( oid . toC ( ) , v . ptr )", "commit_type": "remove"}
{"commit_tokens": ["Use", "best", "PNG", "compression", "we", "can", "afford", "it", ":", ")"], "add_tokens": "assertIntegerEquals ( t , 1734 , w . Body . Len ( ) )", "del_tokens": "assertIntegerEquals ( t , 2001 , w . Body . Len ( ) )", "commit_type": "use"}
{"commit_tokens": ["remove", "Array", "trickery", "in", "main", ".", "go"], "add_tokens": "connections [ ] * FTPConn ftpServer . connections = append ( ftpServer . connections , ftpConn ) ftpServer . removeConnection ( ftpConn ) func ( ftpServer * FTPServer ) removeConnection ( ftpConn * FTPConn ) { i := ftpServer . indexOfConnection ( ftpConn ) ftpServer . connections [ i ] = ftpServer . connections [ len ( ftpServer . connections ) - 1 ] ftpServer . connections = ftpServer . connections [ 0 : len ( ftpServer . connections ) - 1 ] return } func ( ftpServer * FTPServer ) indexOfConnection ( ftpConn * FTPConn ) int { for p , v := range ftpServer . connections { if ( v == ftpConn ) { return p } } return - 1 }", "del_tokens": "connections * Array s . connections = new ( Array ) ftpServer . connections . Append ( ftpConn ) ftpServer . connections . Remove ( ftpConn )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "typo", "in", "proxy", "error", "response", "method"], "add_tokens": "httputils . Errorf ( w , http . StatusBadRequest , errMissingFunctionName ) httputils . Errorf ( w , http . StatusNotFound , \" \" , functionName ) httputils . Errorf ( w , http . StatusInternalServerError , \" \" , functionName ) httputils . Errorf ( w , http . StatusInternalServerError , \" \" , functionName )", "del_tokens": "httputils . ErrorF ( w , http . StatusBadRequest , errMissingFunctionName ) httputils . ErrorF ( w , http . StatusNotFound , \" \" , functionName ) httputils . ErrorF ( w , http . StatusInternalServerError , \" \" , functionName ) httputils . ErrorF ( w , http . StatusInternalServerError , \" \" , functionName )", "commit_type": "fix"}
{"commit_tokens": ["Make", "that", "206", "of", "Vintageous", "tests", "passing", ";", ")"], "add_tokens": "if op != py . EQ && op != py . NE { return nil , fmt . Errorf ( \" \" ) var o2 primitives . Region o2 = t . data o2 = primitives . Region { a2 . Int ( ) , b2 . Int ( ) } if op == py . EQ { return toPython ( o . data == o2 ) } else { return toPython ( o . data != o2 ) }", "del_tokens": "if op != py . EQ { return nil , fmt . Errorf ( \" \" ) return toPython ( o . data == t . data ) r2 := primitives . Region { a2 . Int ( ) , b2 . Int ( ) } return toPython ( o . data == r2 )", "commit_type": "make"}
{"commit_tokens": ["adding", "template", "extension", "allowance", "for", "binary", "rebuilding"], "add_tokens": "if filepath . Ext ( addPath ) == config . Static . TemplateExtension { return true }", "del_tokens": "// if filepath.Ext(addPath) == \".js\" { // return true // }", "commit_type": "add"}
{"commit_tokens": ["add", "stmt", "cache", "Scanner", "for", "multiple", "rows"], "add_tokens": "tmplfile string flag . StringVar ( & tmplfile , \" \" , \" \" , \" \" ) if tmplfile == \" \" { tmplfile = TmplName if ! sys . IsExist ( tmplfile ) { tmplfile = defTmplPath } } if t , err = template . ParseFiles ( tmplfile ) ; err == nil {", "del_tokens": "tmpl string flag . StringVar ( & tmpl , \" \" , \" \" , \" \" ) if tmpl == \" \" { tmpl = defTmplPath } if t , err = template . ParseFiles ( tmpl ) ; err == nil {", "commit_type": "add"}
{"commit_tokens": ["Make", "LoadFromString", "not", "panic", "but", "return", "an", "error", "instead", "."], "add_tokens": "func ( f * Fingerprint ) LoadFromString ( s string ) error { return err return nil } // MustLoadFromString works like LoadFromString but panics in case of an error. func ( f * Fingerprint ) MustLoadFromString ( s string ) { if err := f . LoadFromString ( s ) ; err != nil { panic ( err ) }", "del_tokens": "func ( f * Fingerprint ) LoadFromString ( s string ) { panic ( err )", "commit_type": "make"}
{"commit_tokens": ["add", ":", "before", "text", "this", "allow", "space", "in", "the", "text"], "add_tokens": "msg . Args = append ( msg . Args , \" \" + text )", "del_tokens": "msg . Args = append ( msg . Args , text )", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "specifiy", "source", "IP", "address"], "add_tokens": "// Source is the source IP address Source string if conn = p . listen ( ipv4Proto [ p . network ] ) ; conn == nil { if conn = p . listen ( ipv6Proto [ p . network ] ) ; conn == nil { func ( p * Pinger ) listen ( netProto string ) * icmp . PacketConn { conn , err := icmp . ListenPacket ( netProto , p . Source )", "del_tokens": "source string if conn = p . listen ( ipv4Proto [ p . network ] , p . source ) ; conn == nil { if conn = p . listen ( ipv6Proto [ p . network ] , p . source ) ; conn == nil { func ( p * Pinger ) listen ( netProto string , source string ) * icmp . PacketConn { conn , err := icmp . ListenPacket ( netProto , source )", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "print", "the", "stack", "when", "failing", "to", "create", "the", "default", "connection", "."], "add_tokens": "\" \" \" \" func stackFatalf ( t tLogger , f string , args ... interface { } ) { lines := make ( [ ] string , 0 , 32 ) msg := fmt . Sprintf ( f , args ... ) lines = append ( lines , msg ) // Generate the Stack of callers: for i := 2 ; true ; i ++ { _ , file , line , ok := runtime . Caller ( i ) if ok == false { break } msg := fmt . Sprintf ( \" \" , i , file , line ) lines = append ( lines , msg ) } t . Fatalf ( \" \" , strings . Join ( lines , \" \\n \" ) ) } stackFatalf ( t , \" \" , err )", "del_tokens": "t . Fatalf ( \" \\n \" , err )", "commit_type": "change"}
{"commit_tokens": ["add", "imagestore", "storagepool", "storageprovider", "apis"], "add_tokens": "if cmd . Name == \" \" { respBody , ok = respMap [ \" \" ] } else { respBody , ok = respMap [ strings . ToLower ( cmd . Name ) + \" \" ] if ! ok { // some API's response are not ended with \"response\" respBody , ok = respMap [ strings . ToLower ( cmd . Name ) ] }", "del_tokens": "respBody , ok = respMap [ strings . ToLower ( cmd . Name ) + \" \" ] if ! ok { // some API's response are not ended with \"response\" respBody , ok = respMap [ strings . ToLower ( cmd . Name ) ]", "commit_type": "add"}
{"commit_tokens": ["Use", "!file", ":", "var", "||", "!var", ":", "file", "syntax"], "add_tokens": "r , _ := regexp . Compile ( \" \" ) case \" \" : case \" \" : case \" \" :", "del_tokens": "r , _ := regexp . Compile ( \" \" ) case \" \" : case \" \" : case \" \" :", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "nested", "spans"], "add_tokens": "\" \" \" \" _ , err = w . Write ( [ ] byte ( `{\"id\":\"123\"}` ) ) Expect ( err ) . To ( BeNil ( ) )", "del_tokens": "\" \" \" \" w . Write ( [ ] byte ( `{\"id\":\"123\"}` ) )", "commit_type": "add"}
{"commit_tokens": ["Making", "it", "easier", "to", "configure", "websocket", ".", "Upgrader"], "add_tokens": "Upgrader * websocket . Upgrader s . Upgrader = & websocket . Upgrader { } s . Upgrader . Subprotocols = append ( s . Upgrader . Subprotocols , proto ) conn , err := s . Upgrader . Upgrade ( w , r , nil )", "del_tokens": "upgrader * websocket . Upgrader s . upgrader = & websocket . Upgrader { } s . upgrader . Subprotocols = append ( s . upgrader . Subprotocols , proto ) conn , err := s . upgrader . Upgrade ( w , r , nil )", "commit_type": "make"}
{"commit_tokens": ["implement", "core", "event", "for", "unloadplugin"], "add_tokens": ". \" \" \" \" eventManager * EventController c . eventManager = new ( EventController )", "del_tokens": "\" \"", "commit_type": "implement"}
{"commit_tokens": ["Add", "experimental", "target", "parsing", "for", "Elasticsearch", "datasources"], "add_tokens": "RefID string `json:\"refId\"` Datasource string `json:\"datasource\"` // For Prometheus // For Elasticsearch DsType * string `json:\"dsType,omitempty\"` Metrics [ ] struct { ID int `json:\"id\"` Field string `json:\"field\"` Type string `json:\"type\"` } `json:\"metrics,omitempty\"` Query string `json:\"query,omitempty\"` TimeField string `json:\"timeField,omitempty\"` BucketAggs [ ] struct { ID int `json:\"id\"` Field string `json:\"field\"` Type string `json:\"type\"` Settings struct { Interval string `json:\"interval\"` MinDocCount int `json:\"min_doc_count\"` } `json:\"settings\"` } `json:\"bucketAggs,omitempty\"`", "del_tokens": "RefID string `json:\"refId\"` Datasource string `json:\"datasource\"`", "commit_type": "add"}
{"commit_tokens": ["Added", "functions", "to", "parse", "or", "get", "and", "priority", "to", "an", "string"], "add_tokens": "defroot = Logger ( \" \" ) defseperator = \" \" DefaultPriority = Notice Priority : DefaultPriority , // Parses and returns the given priority. func ParsePriority ( pr string ) Priority { for k , v := range priorities { if v == pr { return k } } e := errors . New ( \" \" + pr + \" \" ) ErrorM ( \" \" , e ) return DefaultPriority } // Returns the name of an priority. func NamePriority ( pr Priority ) string { return priorities [ pr ] }", "del_tokens": "defroot = Logger ( \" \" ) defseperator = \" \" defpriority = Notice Priority : defpriority ,", "commit_type": "add"}
{"commit_tokens": ["Using", "anon", "functions", "and", "calling", "run", "altogether"], "add_tokens": "App { Action : func ( name string ) { println ( \" \" , 2 + 2 ) } , Action : func ( name string ) { println ( \" \" , 2 - 2 ) } , Action : func ( name string ) { println ( \" \" , 2 * 2 ) } , Action : func ( name string ) { println ( \" \" , 2 / 2 ) } , } . Run ( os . Args [ 1 ] )", "del_tokens": "app := App { Action : DoAdd , Action : DoSubtract , Action : DoMultiply , Action : DoDivide , } app . Run ( os . Args [ 1 ] ) } func DoAdd ( name string ) { println ( \" \" , 2 + 2 ) } func DoSubtract ( name string ) { println ( \" \" , 2 - 2 ) } func DoMultiply ( name string ) { println ( \" \" , 2 * 2 ) } func DoDivide ( name string ) { println ( \" \" , 2 / 2 )", "commit_type": "use"}
{"commit_tokens": ["Added", ":", "server", "to", "tags"], "add_tokens": "err := p . accRow ( rows , acc , serv . Address ) err := p . accRow ( row , acc , serv . Address ) func ( p * Postgresql ) accRow ( row scanner , acc plugins . Accumulator , server string ) error { tags := map [ string ] string { \" \" : server , \" \" : name }", "del_tokens": "err := p . accRow ( rows , acc ) err := p . accRow ( row , acc ) func ( p * Postgresql ) accRow ( row scanner , acc plugins . Accumulator ) error { tags := map [ string ] string { \" \" : name }", "commit_type": "add"}
{"commit_tokens": ["use", "a", "timeout", "client", "for", "requests"], "add_tokens": "return Hubbub { db : db , config : c , client : NewTimeoutClient ( c . Timeout . Converted . Connect , c . Timeout . Converted . ReadWrite ) }", "del_tokens": "return Hubbub { db : db , config : c , client : & http . Client { } }", "commit_type": "use"}
{"commit_tokens": ["Updated", "text", "decoding", "to", "fallback", "to", "ISO", "-", "8859", "-", "1", "."], "add_tokens": "default : // Fallback to ISO-8859-1 return decodeISO8859 ( b ) , nil", "del_tokens": "default : return \" \" , fmt . Errorf ( \" \" , enc )", "commit_type": "update"}
{"commit_tokens": ["improved", "TestComposer_AddExpr_nil", "and", "nil", "sql", ".", "Null", "types", "handling"], "add_tokens": "if v != nil && v . Valid { if v != nil && v . Valid { if v != nil && v . Valid { if v != nil && v . Valid {", "del_tokens": "if v . Valid { if v . Valid { if v . Valid { if v . Valid {", "commit_type": "improve"}
{"commit_tokens": ["Changing", "the", "signature", "so", "that", "forgetting", "setting", "the", "number", "of", "units", "is", "made", "less", "easy", "."], "add_tokens": "func NewOptions ( max int , options ... Option ) * ProgressBar { max : max , return NewOptions ( max )", "del_tokens": "// OptionSetMax sets the maximum value to progress to func OptionSetMax ( max int ) Option { return func ( p * ProgressBar ) { p . config . max = max } } func NewOptions ( options ... Option ) * ProgressBar { return NewOptions ( OptionSetMax ( max ) )", "commit_type": "change"}
{"commit_tokens": ["removed", "commitTime", "from", "VoteSet", "."], "add_tokens": "mtx sync . Mutex vset * state . ValidatorSet votes map [ uint64 ] * Vote votesBitArray BitArray votesByBlockHash map [ string ] uint64 totalVotes uint64 twoThirdsMajority [ ] byte twoThirdsExists bool vs . twoThirdsExists = true return vs . twoThirdsExists func ( vs * VoteSet ) TwoThirdsMajority ( ) ( hash [ ] byte , ok bool ) { if vs . twoThirdsExists { return vs . twoThirdsMajority , true } else { return nil , false if ! vs . twoThirdsExists {", "del_tokens": "\" \" mtx sync . Mutex vset * state . ValidatorSet votes map [ uint64 ] * Vote votesBitArray BitArray votesByBlockHash map [ string ] uint64 totalVotes uint64 twoThirdsMajority [ ] byte twoThirdsCommitTime time . Time vs . twoThirdsCommitTime = time . Now ( ) return ! vs . twoThirdsCommitTime . IsZero ( ) func ( vs * VoteSet ) TwoThirdsMajority ( ) ( hash [ ] byte , commitTime time . Time , ok bool ) { if vs . twoThirdsCommitTime . IsZero ( ) { return nil , time . Time { } , false return vs . twoThirdsMajority , vs . twoThirdsCommitTime , true if vs . twoThirdsCommitTime . IsZero ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "50", "and", "75", "move", "rules", "."], "add_tokens": "// move clock being one hundred or greater when a player requested a draw. // when the half move clock was one hundred and fifty or greater. if g . pos . halfMoveClock < 100 { return fmt . Errorf ( \" \" , g . pos . halfMoveClock ) if g . pos . halfMoveClock >= 100 { if ! g . ignoreAutomaticDraws && g . pos . halfMoveClock >= 150 && g . method != Checkmate {", "del_tokens": "// move clock being fifty or greater when a player requested a draw. // when the half move clock was seventy five or greater. if g . pos . halfMoveClock < 50 { return fmt . Errorf ( \" \" , g . pos . halfMoveClock ) if g . pos . halfMoveClock >= 50 { if ! g . ignoreAutomaticDraws && g . pos . halfMoveClock >= 75 && g . method != Checkmate {", "commit_type": "fix"}
{"commit_tokens": ["Make", "resumption", "follow", "the", "-", "13", "rules", "."], "add_tokens": "Context [ ] byte Key : c . context . resumptionPSK , Context : c . context . resumptionContext , pskContext := c . config . ClientPSKs [ c . config . ServerName ] . Context ctx . updateWithClientHello ( chm , pskContext ) var pskSecret , pskContext , dhSecret [ ] byte pskContext = c . config . ClientPSKs [ c . config . ServerName ] . Context err = ctx . updateWithClientHello ( chm , pskContext ) var pskContext [ ] byte pskContext = make ( [ ] byte , len ( key . Context ) ) copy ( pskContext , key . Context ) // XXX: We init different contexts for early vs. main handshakes, that // means that in principle, we could end up with different ciphersuites for // early data vs. the main record flow. Probably not ideal. ctx . updateWithClientHello ( chm , pskContext ) err = ctx . updateWithClientHello ( chm , pskContext ) Key : ctx . resumptionPSK , Context : ctx . resumptionContext ,", "del_tokens": "Key : c . context . resumptionSecret , ctx . updateWithClientHello ( chm , nil ) var pskSecret , dhSecret [ ] byte err = ctx . updateWithClientHello ( chm , nil ) ctx . updateWithClientHello ( chm , nil ) err = ctx . updateWithClientHello ( chm , nil ) Key : ctx . resumptionSecret ,", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "parsing", "a", "column", "defintion", "with", "the", "special", "default", "value", "of", "CURRENT_TIMESTAMP", "."], "add_tokens": "\" \\n \" + \" \\n \" +", "del_tokens": "\" \\n \" +", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "on", "domains", "url", "."], "add_tokens": "requestUrl := \" \" + query . Encode ( )", "del_tokens": "requestUrl := \" \" + query . Encode ( )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "NL", "value", "termination", "for", "arrays"], "add_tokens": "case isWhitespace ( r ) : case r == arrayValTerm || isNL ( r ) :", "del_tokens": "case isWhitespace ( r ) || isNL ( r ) : case r == arrayValTerm :", "commit_type": "allow"}
{"commit_tokens": ["Add", "matching", "of", "empty", "label"], "add_tokens": "if s . head . stats . SampleCount / ( uint64 ( s . head . stats . ChunkCount ) + 1 ) > 24000 {", "del_tokens": "if s . head . stats . SampleCount / ( uint64 ( s . head . stats . ChunkCount ) + 1 ) > 400 {", "commit_type": "add"}
{"commit_tokens": ["Added", "filtering", "in", "docker", "watch", "so", "that", "multiple", "events", "don", "t", "fire"], "add_tokens": "Die \" \" : Die , return c . WatchContainerMatching ( func ( c * Container ) bool { return true } , notify ) } func ( c * Docker ) WatchContainerMatching ( accept func ( * Container ) bool , notify func ( Action , * Container ) ) ( chan <- bool , error ) { if watch != nil && accept ( container ) {", "del_tokens": "if watch != nil {", "commit_type": "add"}
{"commit_tokens": ["Add", "to", "check", "JCS_EXT_RGBA", "support", "."], "add_tokens": "cinfo . in_color_space = C . getJCS_EXT_RGBA ( ) if cinfo . in_color_space == C . JCS_UNKNOWN { return nil , errors . New ( \" \" ) }", "del_tokens": "cinfo . in_color_space = C . JCS_EXT_RGBA", "commit_type": "add"}
{"commit_tokens": ["Remove", "unrelated", "change", "to", "clientTimeout"], "add_tokens": "clientTimeout = 5 * time . Second", "del_tokens": "clientTimeout = 2 * time . Second", "commit_type": "remove"}
{"commit_tokens": ["added", "caller", "to", "panic", "handlers"], "add_tokens": "\" \" _ , file , line , _ := runtime . Caller ( 1 ) log . Printf ( \" \" , file , line , r ) _ , file , line , _ := runtime . Caller ( 1 ) log . Printf ( \" \" , file , line , r )", "del_tokens": "log . Print ( \" \" , r ) log . Print ( \" \" , r )", "commit_type": "add"}
{"commit_tokens": ["remove", "single", "quotes", "of", "service", "-", "discovery", "exec"], "add_tokens": "command = append ( command , \" \" )", "del_tokens": "command = append ( command , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "for", "Attachment", "Filtering", "on", "Unavailable", "Vols"], "add_tokens": "( ( s == types . VolumeAvailable && ! attachments . Unattached ( ) ) || s == types . VolumeUnavailable ) { //!attachments.Unattached() {", "del_tokens": "( s == types . VolumeAvailable || s == types . VolumeUnavailable ) && ! attachments . Unattached ( ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "small", "bug", ":", "changed", "Seek", "skipping", "fixed", "size", "header", "(", "44bytes", ")", "to", "skipping", "variable", "size", "."], "add_tokens": "d . hsz = 4 + 4 + 4 // add size of (RiffMark + FileSize + WaveMark) d . hsz += 4 + 4 + d . h . FormatSize // add size of (FmtMark + FormatSize + its trailing size) d . hsz += 4 + 4 //add size of (DataMark + DataSize) d . hsz += 4 + fs //add size of (Unknown formtype + formsize) RiffMark [ 4 ] byte FileSize int32 WaveMark [ 4 ] byte FmtMark [ 4 ] byte FormatSize int32 FormatType int16 DataMark [ 4 ] byte DataSize int32 hsz int32 _ , err := seeker . Seek ( int64 ( pos + d . hsz ) , io . SeekStart ) // hsz is the size of the header", "del_tokens": "RiffMark [ 4 ] byte FileSize int32 WaveMark [ 4 ] byte FmtMark [ 4 ] byte FormatSize int32 FormatType int16 DataMark [ 4 ] byte DataSize int32 _ , err := seeker . Seek ( int64 ( pos ) + 44 , io . SeekStart ) // 44 is the size of the header", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "office", "hours"], "add_tokens": "func TestSlovakHolidays ( t * testing . T ) {", "del_tokens": "func TestCzechHolidays ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["add", "return", "code", "evaluation", "and", "fixed", "test"], "add_tokens": "if resp . StatusCode >= 400 { return nil , errors . New ( string ( resBody [ : ] ) )", "del_tokens": "\" \" resBodyAsString := string ( resBody [ : len ( resBody ) ] ) if strings . HasPrefix ( resBodyAsString , \" \" ) { return nil , errors . New ( resBodyAsString )", "commit_type": "add"}
{"commit_tokens": ["add", "backlog", "and", "Config", ".", "BacklogSize", "to", "configure"], "add_tokens": "StreamName : \" \" , BacklogSize : 2000 , Client : client , for i := 0 ; i < 5000 ; i ++ {", "del_tokens": "StreamName : \" \" , Client : client , for i := 0 ; i < 10000 ; i ++ {", "commit_type": "add"}
{"commit_tokens": ["Fix", "errors", "occured", "by", "update", "of", "aws", "-", "sdk", "-", "go", "."], "add_tokens": "HasMoreShards : aws . Bool ( true ) , HasMoreShards : aws . Bool ( true ) , HasMoreStreams : aws . Bool ( true ) , HasMoreStreams : aws . Bool ( false ) ,", "del_tokens": "HasMoreShards : aws . Boolean ( true ) , HasMoreShards : aws . Boolean ( true ) , HasMoreStreams : aws . Boolean ( true ) , HasMoreStreams : aws . Boolean ( false ) ,", "commit_type": "fix"}
{"commit_tokens": ["make", "Apply", "a", "method", "on", "Response"], "add_tokens": "func ( r Response ) Apply ( ) error {", "del_tokens": "func Apply ( r Response ) error {", "commit_type": "make"}
{"commit_tokens": ["Adding", "Text", "()", "for", "style", "rule"], "add_tokens": "import ( \" \" \" \" \" \" ) func ( sr * CSSStyleRule ) Text ( ) string { decls := make ( [ ] string , 0 , len ( sr . Styles ) ) keys := make ( [ ] string , 0 , len ( sr . Styles ) ) for key , _ := range sr . Styles { keys = append ( keys , key ) } sort . Strings ( keys ) for _ , key := range keys { decls = append ( decls , sr . Styles [ key ] . Text ( ) ) } return fmt . Sprintf ( \" \\n \\n \\n \" , sr . SelectorText , strings . Join ( decls , \" \\n \" ) ) }", "del_tokens": "import ( )", "commit_type": "add"}
{"commit_tokens": ["Remove", "Unknown", "log", "level", ".", "Add", "utility", "function", "for", "converting", "string", "to", "a", "LogLevel"], "add_tokens": "Level : LevelDebug ,", "del_tokens": "Level : LevelUnknown ,", "commit_type": "remove"}
{"commit_tokens": ["Changing", "the", "registerEntries", "to", "use", "chan", "bools", "rather", "than", "ints"], "add_tokens": "type registerEntry struct { ch chan bool func ( lc * registerEntry ) init ( ) { func ( lc * registerEntry ) Ch ( ) chan bool { func ( lc * registerEntry ) SetCh ( ch chan bool ) { type register [ ] registerEntry", "del_tokens": "type lockableChanInt struct { ch chan int func ( lc * lockableChanInt ) init ( ) { func ( lc * lockableChanInt ) Ch ( ) chan int { func ( lc * lockableChanInt ) SetCh ( ch chan int ) { type register [ ] lockableChanInt", "commit_type": "change"}
{"commit_tokens": ["Add", "documentation", "on", "the", "grouping", "feature"], "add_tokens": "// Group connects a list of commands with a descriptive string. // // The Name is used in the help output to group related commands together. // AddGroup adds a new empty, named group. // // Pass the returned group name to Command's Group member // to make the command part of the group.", "del_tokens": "// Group is smth // AddGroup adds a group.", "commit_type": "add"}
{"commit_tokens": ["Added", "selector", "closing", "on", "producer", "closing"], "add_tokens": "ra . batches [ record . Topic ] [ record . partition ] = partitionBatch ra . batches [ record . Topic ] [ record . partition ] = make ( [ ] * ProducerRecord , 0 , ra . batchSize ) ra . networkClient . close ( )", "del_tokens": "ra . batches [ record . Topic ] [ record . partition ] = partitionBatch ra . batches [ record . Topic ] [ record . partition ] = make ( [ ] * ProducerRecord , 0 , ra . batchSize )", "commit_type": "add"}
{"commit_tokens": ["added", "AudiCodec", "AudioCodecName", "and", "renamed", "CodecName", "to", "VideoCodec"], "add_tokens": "VideoCodecName string // Readable/long name of the video Codec AudioCodec string // Name of the audio codec AudioCodecName string // readable/long name of the audio codec aStreamIndex int Bitrate int aStreamIndex := - 1 } else if streams [ i ] . codec . codec_type == C . AVMEDIA_TYPE_AUDIO { aStreamIndex = i vCodecHuman := C . GoString ( vCodec . long_name ) if aStreamIndex == - 1 { return nil , errors . New ( \" \" ) } aacCtx := streams [ aStreamIndex ] . codec aCodec := C . avcodec_find_decoder ( aacCtx . codec_id ) if aCodec == nil { return nil , errors . New ( \" \" ) } aCodecName := strings . ToUpper ( C . GoString ( aCodec . name ) ) aCodecHuman := C . GoString ( aCodec . long_name ) VideoCodecName : vCodecHuman , AudioCodec : aCodecName , AudioCodecName : aCodecHuman , aStreamIndex : aStreamIndex , Bitrate : bitrate ,", "del_tokens": "CodecName string // Readable/long name of the video Codec bitrate int break vCodecHuman := strings . ToUpper ( C . GoString ( vCodec . long_name ) ) CodecName : vCodecHuman , bitrate : bitrate ,", "commit_type": "add"}
{"commit_tokens": ["Update", "example", "to", "reflect", "change", "to", "input", "of", "md5", "calculation", "."], "add_tokens": "// 2014/12/31,100.0,Payment,\"\",bead7c34cf0828efb8a240e262e7afea // 2014/12/31,100.0,Payment,1,cc8ab528163236eb1aa4004202ee1935 // 2014/12/31,85.0,Payment,\"\",8f4d3a8a05031256a4fa4cf1fadd757b", "del_tokens": "// 2014/12/31,100.0,Payment,\"\",d97e17fc4b32aa405da3598c82be4052 // 2014/12/31,100.0,Payment,1,6c21a286811d8f7c90c19a68de4091c4 // 2014/12/31,85.0,Payment,\"\",c2f3e05f25610fb52c8e543ea95393c0", "commit_type": "update"}
{"commit_tokens": ["Add", "call", "and", "publish", "options"], "add_tokens": "func ( l * logWrapper ) Call ( ctx context . Context , req client . Request , rsp interface { } , opts ... client . CallOption ) error { func ( t * traceWrapper ) Call ( ctx context . Context , req client . Request , rsp interface { } , opts ... client . CallOption ) error {", "del_tokens": "func ( l * logWrapper ) Call ( ctx context . Context , req client . Request , rsp interface { } ) error { func ( t * traceWrapper ) Call ( ctx context . Context , req client . Request , rsp interface { } ) error {", "commit_type": "add"}
{"commit_tokens": ["Use", "valueOf", "to", "fix", "issue", "with", "[]", "byte"], "add_tokens": "if actualType . ConvertibleTo ( reflect . TypeOf ( expected ) ) { actualValue := reflect . ValueOf ( actual ) if actualValue == expectedValue . Convert ( actualType ) . Interface ( ) {", "del_tokens": "if reflect . TypeOf ( actual ) . ConvertibleTo ( reflect . TypeOf ( expected ) ) { if actual == expectedValue . Convert ( actualType ) . Interface ( ) {", "commit_type": "use"}
{"commit_tokens": ["add", "a", "way", "to", "connect", "to", "instance"], "add_tokens": "\" \" if auto . settings . connectToInstance { auto . debugger . ConnectToInstance ( auto . settings . chromeHost , auto . settings . chromePort ) } else { auto . debugger . StartProcess ( auto . settings . chromePath , auto . settings . userDir , auto . settings . chromePort ) }", "del_tokens": "\" \" auto . debugger . StartProcess ( auto . settings . chromePath , auto . settings . userDir , auto . settings . chromePort )", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "cors", ".", "go"], "add_tokens": "// origin. Returning arbitrary origin headers in an access control allow", "del_tokens": "// origin. Returning arbitrary origin headers an an access control allow", "commit_type": "fix"}
{"commit_tokens": ["Add", "basic", "call", "and", "field", "parsing"], "add_tokens": "\" \" const exampleQuery = `node(42){id,answer,{towel,planet}}` result , err := parser . Parse ( \" \" , [ ] byte ( exampleQuery ) ) if err != nil { fmt . Println ( \" \" , err ) } asjson , _ := json . MarshalIndent ( result , \" \" , \" \" ) fmt . Println ( string ( asjson ) ) // { // \"Name\": \"node\", // \"Arguments\": [ // \"42\" // ], // \"Fields\": [ // { // \"Name\": \"id\" // }, // { // \"Name\": \"answer\" // }, // { // \"Fields\": [ // { // \"Name\": \"towel\" // }, // { // \"Name\": \"planet\" // } // ] // } // ] // }", "del_tokens": "const exampleQuery = `node(42){answer}` result , err := parser . Parse ( \" \" , [ ] byte ( \" \" ) ) fmt . Println ( result , err ) // foobar <nil>", "commit_type": "add"}
{"commit_tokens": ["Added", "formatting", "for", "when", "multiple", "certs", "are", "in", "a", "single", "file", ".", "Each"], "add_tokens": "for i , cert := range certs { fmt . Println ( \" \" , i + 1 )", "del_tokens": "for _ , cert := range certs {", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "DoesNotExist", "conditional", "instead", "of", "the", "Generation", "for", "gcs", "locks"], "add_tokens": "obj = obj . If ( storage . Conditions { DoesNotExist : true } )", "del_tokens": "// https://cloud.google.com/storage/docs/json_api/v1/objects/insert // See ifGenerationMatch \"Setting to 0 makes the operation succeed only if there are no live versions of the object\" obj = obj . Generation ( 0 )", "commit_type": "use"}
{"commit_tokens": ["Adding", "a", "channel", "mode", "to", "the", "client"], "add_tokens": "\" \" : 9 , \" \" : 1 , \" \" : 1 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 ,", "del_tokens": "\" \" : 9 , \" \" : 1 , \" \" : 1 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 , \" \" : 0 ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "user", "to", "override", "no", "-", "op", "checkpoint", "with", "Option"], "add_tokens": "// Counter interface is used for exposing basic metrics from the scanner // Checkpoint interface used track consumer progress in the stream type Checkpoint interface { Get ( shardID string ) ( string , error ) Set ( shardID string , sequenceNumber string ) error } type noopCheckpoint struct { } func ( n noopCheckpoint ) Set ( string , string ) error { return nil } func ( n noopCheckpoint ) Get ( string ) ( string , error ) { return \" \" , nil } func WithCheckpoint ( checkpoint Checkpoint ) Option { func New ( app , stream string , opts ... Option ) ( * Consumer , error ) { checkpoint : & noopCheckpoint { } , counter : & noopCounter { } , checkpoint Checkpoint", "del_tokens": "\" \" // Counter is used for exposing basic metrics from the scanner func WithCheckpoint ( checkpoint checkpoint . Checkpoint ) Option { func New ( checkpoint checkpoint . Checkpoint , app , stream string , opts ... Option ) ( * Consumer , error ) { if checkpoint == nil { return nil , fmt . Errorf ( \" \" ) } checkpoint : checkpoint , // provide default no-op counter if c . counter == nil { c . counter = & noopCounter { } } checkpoint checkpoint . Checkpoint", "commit_type": "allow"}
{"commit_tokens": ["added", "!", "before", "error", "reporter"], "add_tokens": "fmt . Println ( format . Error , \" \" , msg , invalid . Error ( ) , format . ResetFormat )", "del_tokens": "fmt . Println ( format . Error , \" \" , msg , invalid . Error ( ) , format . ResetFormat )", "commit_type": "add"}
{"commit_tokens": ["removed", "global", "state", "from", "test"], "add_tokens": "\" \" name := \" \" name := \" \" parts := strings . Split ( r . RequestURI , \" \" ) name := parts [ len ( parts ) - 1 ]", "del_tokens": "var name = \" \"", "commit_type": "remove"}
{"commit_tokens": ["Use", "the", "DATABASE", "environment", "variables", "in", "test"], "add_tokens": "database := os . Getenv ( \" \" ) \" \\\\ \" , addr , instance , user , password , database )", "del_tokens": "\" \\\\ \" , addr , instance , user , password )", "commit_type": "use"}
{"commit_tokens": ["Adding", "tests", "for", "bucketOperations", "and", "URLEncoding"], "add_tokens": "defer resp . Body . Close ( ) if resp != nil { if resp . StatusCode != http . StatusOK { // Head has no response body, handle it return fmt . Errorf ( \" \" , resp . Status ) } } return nil", "del_tokens": "return resp . Body . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Adds", "full", "FETCH", "support", "to", "server"], "add_tokens": "id := uint32 ( i + 1 ) if ! seqset . Contains ( id ) { m := msg . Metadata ( items ) m . Id = id msgs = append ( msgs , m )", "del_tokens": "if ! seqset . Contains ( uint32 ( i + 1 ) ) { msgs = append ( msgs , msg . Metadata ( items ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "noop", "chaincode", "argument", "handling"], "add_tokens": "if len ( args ) != 0 || function == \" \" {", "del_tokens": "if len ( args ) != 1 {", "commit_type": "fix"}
{"commit_tokens": ["add", "sender", "and", "constructors", "for", "stack", "-", "trace", "collecting", "message", "types"], "add_tokens": "func ( f * formatMessenger ) Loggable ( ) bool { return f . base != \" \" }", "del_tokens": "func ( f * formatMessenger ) Loggable ( ) bool { return f . base != \" \" }", "commit_type": "add"}
{"commit_tokens": ["Fix", "spec", "that", "leaves", "phantom", "process", "around", "if", "it", "fails"], "add_tokens": "defer service . Stop ( )", "del_tokens": "service . Stop ( )", "commit_type": "fix"}
{"commit_tokens": ["allow", "passing", "required", "scopes", "to", "Authorizer"], "add_tokens": "func ( a * Authenticator ) Authorizer ( scopes ... string ) Callback { // add mandatory scope if missing if ! stringInList ( scopes , a . provider . MandatoryScope ) { scopes = append ( scopes , a . provider . MandatoryScope ) } _ , err := a . provider . ValidateRequestAuthorization ( authCtx , ctx . GinContext . Request , session , scopes ... )", "del_tokens": "func ( a * Authenticator ) Authorizer ( ) Callback { // TODO: Add scopes. _ , err := a . provider . ValidateRequestAuthorization ( authCtx , ctx . GinContext . Request , session , \" \" )", "commit_type": "allow"}
{"commit_tokens": ["fix", "data", "race", "with", "grpc", "go", "routines", "and", "logging"], "add_tokens": "func init ( ) { // We check this here to avoid data race with GRPC go routines writing to the logger if os . Getenv ( \" \" ) != \" \" { etcd . SetLogger ( grpclog . NewLoggerV2WithVerbosity ( os . Stderr , os . Stderr , os . Stderr , 4 ) ) } }", "del_tokens": "if os . Getenv ( \" \" ) != \" \" { etcd . SetLogger ( grpclog . NewLoggerV2WithVerbosity ( os . Stderr , os . Stderr , os . Stderr , 4 ) ) }", "commit_type": "fix"}
{"commit_tokens": ["Add", "Config", ".", "Compare", "()", "and", "default", "CompareConfig"], "add_tokens": "// DefaultConfig is the default configuration used for all exported non-method functions except Compare. // ConmpareConfig is the default configuration used for Compare. var CompareConfig = & Config { Diffable : true , IncludeUnexported : true , } // values in got and want, using the default config. return CompareConfig . Compare ( got , want ) // Compare returns a string containing a line-by-line unified diff of the // values in got and want according to the cfg. func ( cfg * Config ) Compare ( got , want interface { } ) string { cfg . Diffable = true return diff . Diff ( cfg . Sprint ( got ) , cfg . Sprint ( want ) )", "del_tokens": "// values in got and want. Compare includes unexported fields. diffOpt := & Config { Diffable : true , IncludeUnexported : true , } return diff . Diff ( diffOpt . Sprint ( got ) , diffOpt . Sprint ( want ) ) // CompareWithoutZeroFields returns a diff like Compare but omits struct fields // that have a zero value. func CompareWithoutZeroFields ( got , want interface { } ) string { diffOpt := & Config { Diffable : true , IncludeUnexported : true , SkipZeroFields : true , } return diff . Diff ( diffOpt . Sprint ( got ) , diffOpt . Sprint ( want ) )", "commit_type": "add"}
{"commit_tokens": ["update", "libp2p", "dep", "to", "fix", "hanging", "listeners", "problem"], "add_tokens": "ci \" \" peer \" \"", "del_tokens": "ci \" \" peer \" \"", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "serialization", "/", "deserialization", "of", "_sort", "parameter"], "add_tokens": "q := Query { \" \" , \" \" } c . Assert ( func ( ) { m . MongoSearcher . CreateQuery ( q ) } , Panics , createUnsupportedSearchError ( \" \" , \" \\\" \\\" \" ) )", "del_tokens": "q := Query { \" \" , \" \" } c . Assert ( func ( ) { m . MongoSearcher . CreateQuery ( q ) } , Panics , createUnsupportedSearchError ( \" \" , \" \\\" \\\" \" ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "message", "when", "a", "new", "snapshot", "is", "created"], "add_tokens": "if err . Error ( ) != \" \" { t . Fatalf ( \" \" ) } if err . Error ( ) != \" \" { t . Fatalf ( \" \" , err ) }", "del_tokens": "\" \" fmt . Println ( err )", "commit_type": "fix"}
{"commit_tokens": ["move", "batch", "and", "multi", "-", "ops", "to", "seperate", "file"], "add_tokens": "StartNodes : [ ] string { \" \" , \" \" , \" \" } , func redisTest ( cluster * redis . Cluster , begin , end int , done chan int ) { time . Sleep ( 50 * time . Millisecond )", "del_tokens": "StartNodes : [ ] string { \" \" , \" \" , \" \" } , func redisTest ( cluster redis . Cluster , begin , end int , done chan int ) { time . Sleep ( 10 * time . Millisecond )", "commit_type": "move"}
{"commit_tokens": ["Added", "Select", "to", "process", "rows", "as", "they", "come", "over", "the", "wire"], "add_tokens": "func ( c * Connection ) Select ( sql string , onDataRow func ( * messageReader , [ ] fieldDescription ) error ) ( err error ) { err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow ) err = c . Select ( sql , onDataRow )", "del_tokens": "func ( c * Connection ) query ( sql string , onDataRow func ( * messageReader , [ ] fieldDescription ) error ) ( err error ) { err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow ) err = c . query ( sql , onDataRow )", "commit_type": "add"}
{"commit_tokens": ["Remove", "leftover", "reference", "to", "old", "const"], "add_tokens": "stream , error := odb . NewWriteStream ( len ( str ) , ObjectBlob )", "del_tokens": "stream , error := odb . NewWriteStream ( len ( str ) , OBJ_BLOB )", "commit_type": "remove"}
{"commit_tokens": ["Use", "io", ".", "ReadFull", "for", "reading", "a", "known", "amount", "of", "bytes"], "add_tokens": "var data [ 1 ] byte n , err := r . r . Read ( data [ : ] ) // readBytes fully reads bytes into a slice, or returns an error. func ( r * Decoder ) readBytes ( data [ ] byte ) error { _ , err := io . ReadFull ( r . r , data ) // readBytesUntil will read a slice of data until 'delim' is found func ( r * Decoder ) readBytesUntil ( delim byte ) ( data [ ] byte , err error ) { collected , err = r . readBytesUntil ( CHR_TERM ) err = r . readBytes ( data ) collected , err = r . readBytesUntil ( ':' ) err = r . readBytes ( data )", "del_tokens": "data := [ ] byte { 0 } n , err := r . r . Read ( data ) // readByteSlice takes a []byte to fill it and check errors appropriately func ( r * Decoder ) readByteSlice ( data [ ] byte ) error { n , err := r . r . Read ( data ) if n == len ( data ) { return nil } // readByteSliceUntil will read a slice of data until 'delim' is found func ( r * Decoder ) readByteSliceUntil ( delim byte ) ( data [ ] byte , err error ) { collected , err = r . readByteSliceUntil ( CHR_TERM ) err = r . readByteSlice ( data ) collected , err = r . readByteSliceUntil ( ':' ) err = r . readByteSlice ( data )", "commit_type": "use"}
{"commit_tokens": ["Fixed", "dateWithOutSepMatch", "for", "dates", "with", "8", "digits", "."], "add_tokens": "runTest ( t , \" \" , float64 ( 2 ) ) // I think this is wrong. . . runTest ( t , \" \" , float64 ( 2 ) ) // I think this is wrong. . .", "del_tokens": "runTest ( t , \" \" , float64 ( 2 ) ) runTest ( t , \" \" , float64 ( 2 ) )", "commit_type": "fix"}
{"commit_tokens": ["Use", "default", "capabilities", "from", "docker"], "add_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "del_tokens": "\" \" , \" \" , \" \" , \" \" ,", "commit_type": "use"}
{"commit_tokens": ["add", "GetAllocated", "Height", "/", "Width"], "add_tokens": "\" \" \" \" pbptr := ( * C . GdkPixbuf ) ( unsafe . Pointer ( pixbuf . Native ( ) ) ) // GetAllocatedWidth() is a wrapper around gtk_widget_get_allocated_width(). func ( v * Widget ) GetAllocatedWidth ( ) int { return int ( C . gtk_widget_get_allocated_width ( v . native ( ) ) ) } // GetAllocatedHeight() is a wrapper around gtk_widget_get_allocated_height(). func ( v * Widget ) GetAllocatedHeight ( ) int { return int ( C . gtk_widget_get_allocated_height ( v . native ( ) ) ) }", "del_tokens": "\" \" \" \" pbptr := ( * C . GdkPixbuf ) ( unsafe . Pointer ( pixbuf . Native ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "exposed", "interfaces", "from", "resource", "and", "module", "files"], "add_tokens": "// moduleRequirements specify that the module requires specific named middlewares. type moduleRequirements interface { if req , ok := m . ( moduleRequirements ) ; ok {", "del_tokens": "// ModuleRequirements specify that the module requires specific named middlewares. type ModuleRequirements interface { if req , ok := m . ( ModuleRequirements ) ; ok {", "commit_type": "remove"}
{"commit_tokens": ["allow", "for", "context", "on", "client"], "add_tokens": "fmt . Fprintln ( os . Stderr , string ( b ) ) var hasTimeout bool pctx := operation . Context if pctx == nil { pctx = r . Context } else { hasTimeout = true } var ctx context . Context var cancel context . CancelFunc if hasTimeout { ctx , cancel = context . WithCancel ( pctx ) } else { ctx , cancel = context . WithTimeout ( pctx , request . timeout ) } fmt . Fprintln ( os . Stderr , string ( b ) )", "del_tokens": "fmt . Println ( string ( b ) ) pctx := r . Context ctx , cancel := context . WithTimeout ( pctx , request . timeout ) fmt . Println ( string ( b ) )", "commit_type": "allow"}
{"commit_tokens": ["remove", "hex", "encoding", "from", "flatfs"], "add_tokens": "// length of the dir splay prefix prefixLen int path : path , prefixLen : prefixLen , sync : sync , var padding = strings . Repeat ( \" \" , maxPrefixLen ) prefix := ( key . String ( ) + padding ) [ : fs . prefixLen ] file = path . Join ( dir , key . String ( ) + extension ) return datastore . NewKey ( name ) , true", "del_tokens": "\" \" // length of the dir splay prefix, in bytes of hex digits hexPrefixLen int path : path , // convert from binary bytes to bytes of hex encoding hexPrefixLen : prefixLen * hex . EncodedLen ( 1 ) , sync : sync , var padding = strings . Repeat ( \" \" , maxPrefixLen * hex . EncodedLen ( 1 ) ) safe := hex . EncodeToString ( key . Bytes ( ) [ 1 : ] ) prefix := ( safe + padding ) [ : fs . hexPrefixLen ] file = path . Join ( dir , safe + extension ) k , err := hex . DecodeString ( name ) if err != nil { return datastore . Key { } , false } return datastore . NewKey ( string ( k ) ) , true", "commit_type": "remove"}
{"commit_tokens": ["make", "small", "readability", "improvement", "to", "formatArgs", "()"], "add_tokens": "if names [ i ] == noName { continue name := colorize ( names [ i ] , bold ) formatted [ i ] = fmt . Sprintf ( \" \" , name , val )", "del_tokens": "if names [ i ] == \" \" { } else { name := colorize ( names [ i ] , bold ) formatted [ i ] = fmt . Sprintf ( \" \" , name , val )", "commit_type": "make"}
{"commit_tokens": ["Fix", "readBits", "losing", "the", "top", "few", "bits", "for", "unaligned", "reads", "."], "add_tokens": "var val uint64 val += ( uint64 ( m ) << uint32 ( i * 8 ) ) return uint32 ( val )", "del_tokens": "var val uint32 val += ( uint32 ( m ) << uint32 ( i * 8 ) ) return val", "commit_type": "fix"}
{"commit_tokens": ["fix", "cmd", "text", "for", "root", "container", "-", "diff", "command"], "add_tokens": "Use : \" \" , Short : \" \" , Long : `container-diff is a CLI tool for analyzing and comparing container images.` ,", "del_tokens": "Use : \" \" , Short : \" \" , Long : `Analyzes a single image or compares two images using the specifed analyzers/differs as indicated via flags (see documentation for available ones).` ,", "commit_type": "fix"}
{"commit_tokens": ["Added", "notice", "command", "(", "and", "let", "gofmt", "do", "its", "job", ")"], "add_tokens": "\" \" \" \" : UMAway , \" \" : UMInvisibility , \" \" : UMWallops , \" \" : UMRestricted , \" \" : UMOperator , \" \" : UMLocalOp , \" \" : UMRecNotices , Name string con * IrcCon Perms uint32 fi , err := os . Open ( finame ) fi , err := os . Create ( finame ) // Notice performs an action in the channel func ( c * IrcChannel ) Notice ( text string ) { msg := fmt . Sprintf ( \" \\u0001 \\u0001 \" , text ) c . Say ( msg ) } // Returns a channel that will contain messages sent to", "del_tokens": "\" \" \" \" : UMAway , \" \" : UMInvisibility , \" \" : UMWallops , \" \" : UMRestricted , \" \" : UMOperator , \" \" : UMLocalOp , \" \" : UMRecNotices , Name string con * IrcCon Perms uint32 fi , err := os . Open ( finame ) fi , err := os . Create ( finame ) // Returns a channel that will contain messages sent to", "commit_type": "add"}
{"commit_tokens": ["Use", "github", ".", "com", "/", "coreos", "/", "bbolt"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Moved", "construction", "of", "command", "dependencies", "to", "the", "factory"], "add_tokens": "fakeuuid \" \" fakews \" \" factory Factory config bmconfig . Config configService * fakeconfig . FakeService filesystem boshsys . FileSystem ui bmui . UI extractor bmtar . Extractor logger boshlog . Logger workspace := fakews . NewFakeWorkspace ( ) uuidGenerator := & fakeuuid . FakeGenerator { } workspace , uuidGenerator , releaseValidator := fakebmrel . NewFakeValidator ( ) releaseCompiler := fakebmcomp . NewFakeReleaseCompiler ( ) Expect ( cmd ) . To ( BeAssignableToTypeOf ( NewDeployCmd (", "del_tokens": "factory Factory config bmconfig . Config configService * fakeconfig . FakeService filesystem boshsys . FileSystem ui bmui . UI extractor bmtar . Extractor releaseValidator * fakebmrel . FakeValidator releaseCompiler * fakebmcomp . FakeReleaseCompiler logger boshlog . Logger runner := fakesys . NewFakeCmdRunner ( ) extractor = bmtar . NewCmdExtractor ( runner , logger ) releaseValidator = fakebmrel . NewFakeValidator ( ) releaseCompiler = fakebmcomp . NewFakeReleaseCompiler ( ) extractor , releaseValidator , releaseCompiler , Expect ( cmd ) . To ( Equal ( NewDeployCmd (", "commit_type": "move"}
{"commit_tokens": ["Move", "partition", "code", "into", "separate", "package", "."], "add_tokens": "\" \" p , err := partition . NewPartition ( f )", "del_tokens": "\" \" p , err := word2vec . NewPartition ( f )", "commit_type": "move"}
{"commit_tokens": ["add", "a", "connect", "+", "wait", "header", "time", "out"], "add_tokens": "timeout string flag . StringVar ( & timeout , \" \" , \" \" , \" \" ) certBytes [ ] byte err error connectTimeout time . Duration connectTimeout , err = time . ParseDuration ( timeout ) check ( err ) endpoint := winrm . NewEndpointWithTimeout ( hostname , port , https , insecure , & certBytes , connectTimeout )", "del_tokens": "certBytes [ ] byte err error endpoint := winrm . NewEndpoint ( hostname , port , https , insecure , & certBytes )", "commit_type": "add"}
{"commit_tokens": ["use", "uintptr", "instand", "of", "uint"], "add_tokens": "func ioctl ( fd uintptr , request uintptr , argp uintptr ) error {", "del_tokens": "func ioctl ( fd uintptr , request uint , argp uintptr ) error {", "commit_type": "use"}
{"commit_tokens": ["use", "new", "insecure", "transport", "constructor"], "add_tokens": "\" \" \" \" ia := makeInsecureTransport ( t ) ib := makeInsecureTransport ( t ) Secure : ia , Secure : ib , ttransport . SubtestTransport ( t , ta , tb , zero , ia . LocalPeer ( ) ) Secure : makeInsecureTransport ( t ) , func makeInsecureTransport ( t * testing . T ) * insecure . Transport { priv , pub , err := crypto . GenerateKeyPair ( crypto . Ed25519 , 256 ) if err != nil { t . Fatal ( err ) } id , err := peer . IDFromPublicKey ( pub ) if err != nil { t . Fatal ( err ) } return insecure . NewWithIdentity ( id , priv ) }", "del_tokens": "Secure : insecure . New ( \" \" ) , Secure : insecure . New ( \" \" ) , ttransport . SubtestTransport ( t , ta , tb , zero , \" \" ) Secure : insecure . New ( \" \" ) ,", "commit_type": "use"}
{"commit_tokens": ["Use", "static", "nat", "by", "default", "to", "SSH", "the", "machine"], "add_tokens": "UsePortForward bool mcnflag . BoolFlag { Name : \" \" , Usage : \" \" , } , d . UsePortForward = flags . Bool ( \" \" ) if d . UsePortForward { if err := d . configurePortForwardingRules ( ) ; err != nil { return err } } else { if err := d . enableStaticNat ( ) ; err != nil { return err } log . Info ( \" \" ) if _ , err := cs . VirtualMachine . DestroyVirtualMachine ( p ) ; err != nil { return err } func ( d * Driver ) enableStaticNat ( ) error { cs := d . getClient ( ) log . Infof ( \" \" ) p := cs . NAT . NewEnableStaticNatParams ( d . PublicIPID , d . Id ) if _ , err := cs . NAT . EnableStaticNat ( p ) ; err != nil { return err } return nil }", "del_tokens": "if err := d . configurePortForwardingRules ( ) ; err != nil { return err log . Info ( \" \" ) if _ , err := cs . VirtualMachine . DestroyVirtualMachine ( p ) ; err != nil { return err }", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "generating", "//", "See", "<url", ">", "comments", "(", "they", "had", "gone", "missing", ")"], "add_tokens": "if err == nil && u . Scheme != \" \" {", "del_tokens": "if err != nil && u . Scheme != \" \" {", "commit_type": "fix"}
{"commit_tokens": ["add", "function", "to", "set", "priority", "by", "name"], "add_tokens": "\" \" \" \" \" \" // SetPriorityString sets the output priority by the name of a debug level func SetPriorityString ( s string ) error { s = strings . ToUpper ( s ) for i , name := range priorityName { if name == s { SetPriority ( i ) return nil } } return fmt . Errorf ( \" \" , s ) }", "del_tokens": "\" \"", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "second", "round", "test1", "bug"], "add_tokens": "exHostIP := host . IP ( ) logger . Debugf ( \" \" , host . TransportAddr ( ) ) logger . Debugf ( \" \" , changedAddr ) logger . Debugf ( \" \" , identical ) logger . Debugf ( \" \" , packet == nil ) packet , _ , _ , host , err = test1 ( conn , changedAddr , softwareName ) logger . Debugf ( \" \" , packet == nil ) logger . Debugf ( \" \" , host . TransportAddr ( ) ) logger . Debugf ( \" \" , identical ) if exHostIP == host . IP ( ) { logger . Debugf ( \" \" , packet == nil )", "del_tokens": "logger . Debugf ( \" \" , changedAddr , identical , host . ip , host . port ) logger . Debugf ( \" \" , packet == nil ) otherConn , err := net . ListenUDP ( \" \" , nil ) if err != nil { return NAT_ERROR , nil , err } defer otherConn . Close ( ) packet , _ , identical , _ , err = test1 ( otherConn , changedAddr , softwareName ) logger . Debugf ( \" \" , packet == nil ) logger . Debugf ( \" \" , identical ) if identical { logger . Debug ( \" \" , packet == nil )", "commit_type": "fix"}
{"commit_tokens": ["Add", "ability", "to", "specify", "SLS", "info", "to", "docker", "image"], "add_tokens": "for depProduct , depTypes := range dockerDepsToMap ( curImage . Dependencies ( ) ) {", "del_tokens": "for depProduct , depTypes := range curImage . Deps . ToMap ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "with", "Stop", "()", "not", "waiting", "for", "the", "ack", "before", "returning"], "add_tokens": "close ( h . stop ) return if h . stop == nil { return } h . stop <- struct { } { } <- h . stop", "del_tokens": "break close ( h . stop )", "commit_type": "fix"}
{"commit_tokens": ["add", "__call", "for", "map", "types", "(", "creates", "an", "iterator", "over", "the", "map", ")"], "add_tokens": "// Map types have a meta table with __len, __index, __newindex, and __call // defined. The first three meta methods allow map values to be fetched and // stored, while the last creates an iterator over the map.", "del_tokens": "// Map types have a meta table with __len, __index, and __newindex defined. // This allows map values to be fetched and stored. // TODO: implement __call for creating an iterator //", "commit_type": "add"}
{"commit_tokens": ["Added", "check", "for", "invalid", "email", "address"], "add_tokens": "addr , err := mail . ParseAddress ( to [ i ] ) if err != nil { return err }", "del_tokens": "addr , _ := mail . ParseAddress ( to [ i ] )", "commit_type": "add"}
{"commit_tokens": ["Fix", "potential", "deadlock", "on", "Close", "()"], "add_tokens": "closerLock sync . Mutex // Acquire closer lock to ensure only one thread can close the stop channel c . closerLock . Lock ( ) defer c . closerLock . Unlock ( ) // Notify all other threads that they should stop // Wait for the threads to stop // Finally flush any remaining metrics that may have come in at the last moment c . Lock ( ) defer c . Unlock ( )", "del_tokens": "c . Lock ( ) defer c . Unlock ( )", "commit_type": "fix"}
{"commit_tokens": ["added", "scheduler", "cache", "for", "offers", "and", "slavePiDs", "better", "validation", "of", "tasks", "before", "launch", "framework", "msg", "directly", "to", "cache", "slave", "etc", "."], "add_tokens": "LaunchTasks ( offerIDs [ ] * mesos . OfferID , tasks [ ] * mesos . TaskInfo , filters * mesos . Filters ) mesos . Status", "del_tokens": "LaunchTasks ( offerID * mesos . OfferID , tasks [ ] * mesos . TaskInfo , filters * mesos . Filters ) mesos . Status", "commit_type": "add"}
{"commit_tokens": ["Implement", "processing", "of", "urls", "to", "support", "displaying", ".", "gifv"], "add_tokens": "}", "del_tokens": "} else { return true }", "commit_type": "implement"}
{"commit_tokens": ["Allow", "setting", "of", "absolute", "path", "to", "override", "current", "working", "dir"], "add_tokens": "// AbsPath is used to make an absolute path of an issue's filename to be // relative in order to match patch file. If not set, current working // directory is used. AbsPath string absPath := c . AbsPath if absPath == \" \" { absPath , err = os . Getwd ( ) if err != nil { returnErr = fmt . Errorf ( \" \" , err ) } if rel , err := filepath . Rel ( absPath , path ) ; err == nil {", "del_tokens": "cwd , err := os . Getwd ( ) if err != nil { returnErr = fmt . Errorf ( \" \" , err ) if rel , err := filepath . Rel ( cwd , path ) ; err == nil {", "commit_type": "allow"}
{"commit_tokens": ["Implement", "ActiveLen", "()", "native", "NACK"], "add_tokens": "if _ , err := sess . Do ( \" \" , job . ID ) ; err != nil { // Wait blocks until the given job is ACKed. // Native WAITJOB discussed upstream at https://github.com/antirez/disque/issues/168. time . Sleep ( 50 * time . Millisecond ) // ActiveLen returns length of active jobs taken from a given queue. func ( pool * Pool ) ActiveLen ( queue string ) ( int , error ) { sess := pool . redis . Get ( ) defer sess . Close ( ) reply , err := sess . Do ( \" \" , \" \" , queue , \" \" , \" \" ) if err != nil { return 0 , err } replyArr , ok := reply . ( [ ] interface { } ) if ! ok || len ( replyArr ) != 2 { return 0 , errors . New ( \" \" ) } jobs , ok := replyArr [ 1 ] . ( [ ] interface { } ) if ! ok { return 0 , errors . New ( \" \" ) } return len ( jobs ) , nil }", "del_tokens": "// Native NACKJOB discussed upstream at https://github.com/antirez/disque/issues/43. if _ , err := sess . Do ( \" \" , job . ID ) ; err != nil { // Wait waits for a job to finish (blocks until it's ACKed). // Native WAITJOB discussed upstream at https://github.com/antirez/disque/issues/43. time . Sleep ( 10 * time . Millisecond )", "commit_type": "implement"}
{"commit_tokens": ["Fixing", "output", "from", "cobra", "when", "error", "occured", "."], "add_tokens": "if err != nil { os . Exit ( 1 ) }", "del_tokens": "checkErr ( err )", "commit_type": "fix"}
{"commit_tokens": ["use", "the", "new", "screen", "shortcut"], "add_tokens": "xu . Conn ( ) . CreatePixmap ( xu . Screen ( ) . RootDepth , pix , xu . RootWin ( ) ,", "del_tokens": "screen := xu . Conn ( ) . DefaultScreen ( ) xu . Conn ( ) . CreatePixmap ( screen . RootDepth , pix , xu . RootWin ( ) ,", "commit_type": "use"}
{"commit_tokens": ["allow", "querying", "_all_docs", "using", "View", "functions"], "add_tokens": "if ddoc == \" \" && name == \" \" { u . Path = fmt . Sprintf ( \" \" , b . Name ) } else { u . Path = fmt . Sprintf ( \" \" , b . Name , ddoc , name ) }", "del_tokens": "u . Path = fmt . Sprintf ( \" \" , b . Name , ddoc , name )", "commit_type": "allow"}
{"commit_tokens": ["add", "newlines", "to", "listing", "types"], "add_tokens": "fmt . Printf ( \" \\n \" ) fmt . Printf ( \" \\n \" , t . Name , t . Version ) fmt . Printf ( \" \\t \\n \" , downloadURL )", "del_tokens": "fmt . Printf ( \" \" ) fmt . Printf ( \" \" , t . Name , t . Version ) fmt . Printf ( \" \\t \" , downloadURL )", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "fast", "generic", "action", "handlers"], "add_tokens": "if req . route . Handler . Generic { req . route . Handler . GenericHandler ( rw , req ) } else { req . route . Handler . DynamicHandler . Call ( [ ] reflect . Value { closure . Contexts [ len ( closure . Contexts ) - 1 ] , reflect . ValueOf ( rw ) , reflect . ValueOf ( req ) } ) }", "del_tokens": "invoke ( req . route . Handler , closure . Contexts [ len ( closure . Contexts ) - 1 ] , [ ] reflect . Value { reflect . ValueOf ( rw ) , reflect . ValueOf ( req ) } )", "commit_type": "allow"}
{"commit_tokens": ["Allow", "gratuitous", "ARP", "over", "IPoIB"], "add_tokens": "\" \" if ! bytes . Equal ( ethernet . Broadcast , dstHW ) && len ( srcHW ) != len ( dstHW ) {", "del_tokens": "if len ( srcHW ) != len ( dstHW ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "output", "of", "expected", "results", "from", "TestPassKeyringKeysWhenNotEmpty", "test"], "add_tokens": "t . Fatalf ( \" \" , len ( keys ) )", "del_tokens": "t . Fatalf ( \" \" , len ( keys ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "leaf", "elements", "with", "numbers"], "add_tokens": "// # sed -rn 's/^<!ELEMENT\\s+([A-Z0-9]+)\\s+-\\s+o\\s+%.*TYPE>.*$/\\t\"\\1\",/p' *.dtd | sort \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ,", "del_tokens": "// # sed -rn 's/^<!ELEMENT\\s+([A-Z]+)\\s+-\\s+o\\s+%.*TYPE>.*$/\\t\"\\1\",/p' *.dtd | sort", "commit_type": "add"}
{"commit_tokens": ["add", "a", "test", "for", "the", "clearScreen", "function"], "add_tokens": "clearScreen ( sb ) func clearScreen ( sb * screenbuf . ScreenBuf ) { sb . Reset ( ) sb . Clear ( ) sb . Flush ( ) }", "del_tokens": "sb . Reset ( ) sb . Clear ( ) sb . Flush ( )", "commit_type": "add"}
{"commit_tokens": ["allow", "requeueing", "of", "failed", "subs", "and", "unsubs"], "add_tokens": "s . Subscribe ( \" \" , 0 , false ) . Wait ( )", "del_tokens": "s . Subscribe ( \" \" , 0 ) . Wait ( )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "inconsistency", "in", "enum", "type", "name"], "add_tokens": "OpenglApi int = C . GLFW_OPENGL_API OpenglEsApi int = C . GLFW_OPENGL_ES_API NoRobustness int = C . GLFW_NO_ROBUSTNESS NoResetNotification int = C . GLFW_NO_RESET_NOTIFICATION LoseContextOnReset int = C . GLFW_LOSE_CONTEXT_ON_RESET OpenglAnyProfile int = C . GLFW_OPENGL_ANY_PROFILE OpenglCoreProfile int = C . GLFW_OPENGL_CORE_PROFILE OpenglCompatProfile int = C . GLFW_OPENGL_COMPAT_PROFILE True int = C . GL_TRUE False int = C . GL_FALSE func WindowHint ( target Hint , hint int ) { func ( w * Window ) GetAttribute ( attrib Hint ) int { return int ( C . glfwGetWindowAttrib ( w . data , C . int ( attrib ) ) )", "del_tokens": "//HintValue corresponds to a hint value. type HintValue int OpenglApi HintValue = C . GLFW_OPENGL_API OpenglEsApi HintValue = C . GLFW_OPENGL_ES_API NoRobustness HintValue = C . GLFW_NO_ROBUSTNESS NoResetNotification HintValue = C . GLFW_NO_RESET_NOTIFICATION LoseContextOnReset HintValue = C . GLFW_LOSE_CONTEXT_ON_RESET OpenglAnyProfile HintValue = C . GLFW_OPENGL_ANY_PROFILE OpenglCoreProfile HintValue = C . GLFW_OPENGL_CORE_PROFILE OpenglCompatProfile HintValue = C . GLFW_OPENGL_COMPAT_PROFILE True HintValue = C . GL_TRUE False HintValue = C . GL_FALSE func WindowHint ( target Hint , hint HintValue ) { func ( w * Window ) GetAttribute ( attrib Hint ) HintValue { return HintValue ( C . glfwGetWindowAttrib ( w . data , C . int ( attrib ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Allow", "creation", "update", "and", "retrieval", "of", "SSL", "certificate", "options"], "add_tokens": "\" \" : 2300 , \" \" : true , \" \" : 10 assert . True ( t , ck . VerifyCertificate ) assert . Equal ( t , 10 , ck . SSLDownDaysBefore )", "del_tokens": "\" \" : 2300", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "clock", "dependency", "."], "add_tokens": "\" \" func NewConn ( key aws . AccessKey , httpConn HttpConn , signer Signer , clock time . Clock ) ( Conn , error ) {", "del_tokens": "func NewConn ( key aws . AccessKey , httpConn HttpConn , signer Signer ) ( Conn , error ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "segfault", "when", "bucket", "doesn", "t", "exist"], "add_tokens": "if err != io . EOF { // catastrophic error", "del_tokens": "if err != io . EOF && err != io . ErrUnexpectedEOF { // catastrophic error", "commit_type": "fix"}
{"commit_tokens": ["add", "database", "commond", "for", "generate", "model", "functions", "add", "LEVEL_OFF", "for"], "add_tokens": "\" \" out := os . Stdout if log . Level >= LEVEL_ERROR { out = os . Stderr } _ , err := fmt . Fprint ( out , clw . termColor [ log . Level ] . Render ( log . String ( ) ) )", "del_tokens": "_ , err := fmt . Print ( clw . termColor [ log . Level ] . Render ( log . String ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["Add", "force", "flag", "to", "server", "delete"], "add_tokens": "ServerDelete ( name string , force bool ) error", "del_tokens": "ServerDelete ( name string ) error", "commit_type": "add"}
{"commit_tokens": ["fix", "plz", "compilation", ";", "remove", "state", "exporter"], "add_tokens": "countlog . LogPanic ( recover ( ) ) countlog . LogPanic ( recover ( ) )", "del_tokens": "recovered := recover ( ) if recovered != nil { countlog . Fatal ( \" \" , \" \" , recovered , \" \" , countlog . ProvideStacktrace ) } recovered := recover ( ) if recovered != nil { countlog . Fatal ( \" \" , \" \" , recovered , \" \" , countlog . ProvideStacktrace ) }", "commit_type": "fix"}
{"commit_tokens": ["Allow", "specifying", "a", "datafetch", "function"], "add_tokens": "type DataFetchFunction func ( [ ] byte , string ) ( [ ] byte , error ) DataFetch DataFetchFunction go readOps ( patchWire , ops , errc , actx . DataFetch ) func readOps ( rc * wire . ReadContext , ops chan sync . Operation , errc chan error , dataFetch DataFetchFunction ) { var buf [ ] byte case SyncOp_REMOTE_DATA : if dataFetch == nil { errc <- fmt . Errorf ( \" \" ) return } buf , err = dataFetch ( buf [ : 0 ] , rop . RemotePath ) if err != nil { errc <- err return } if int64 ( len ( buf ) ) != rop . RemoteSize { errc <- fmt . Errorf ( \" \" , rop . RemoteSize , len ( buf ) ) return } ops <- sync . Operation { Type : sync . OpData , Data : buf , }", "del_tokens": "go readOps ( patchWire , ops , errc ) func readOps ( rc * wire . ReadContext , ops chan sync . Operation , errc chan error ) {", "commit_type": "allow"}
{"commit_tokens": ["fix", "digest", "-", "md5", "with", "some", "ejabberd", "server"], "add_tokens": "message := \" \\\" \" + user + \" \\\" \\\" \" + realm + \" \\\" \\\" \" + nonce + \" \\\" \\\" \" + cnonceStr + \" \\\" \" + nonceCount + \" \" + qop + \" \\\" \" + digestUri + \" \\\" \" + digest + \" \" + charset", "del_tokens": "message := \" \" + user + \" \" + realm + \" \" + nonce + \" \" + cnonceStr + \" \" + nonceCount + \" \" + qop + \" \" + digestUri + \" \" + digest + \" \" + charset", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "Add", "bug", "added", "Modf", "etc"], "add_tokens": "return 0 , false return 0 , false", "del_tokens": "return c . BadScale , false return c . Inflated , false", "commit_type": "fix"}
{"commit_tokens": ["adding", "hit", "-", "record", "tracking"], "add_tokens": "\" \" \" \" type HitRecord struct { Verb string Path string Query url . Values Body [ ] byte } server * httptest . Server hits int paths map [ string ] * Path pathsHit chan string hitRecords [ ] HitRecord bodyBytes , _ := ioutil . ReadAll ( r . Body ) r . Body . Close ( ) b . hitRecords = append ( b . hitRecords , HitRecord { r . Method , r . URL . Path , r . URL . Query ( ) , bodyBytes } ) func ( b * Bogus ) HitRecords ( ) [ ] HitRecord { return b . hitRecords }", "del_tokens": "server * httptest . Server hits int paths map [ string ] * Path pathsHit chan string", "commit_type": "add"}
{"commit_tokens": ["added", "check", "to", "avoid", "attempt", "at", "referencing", "type", "and", "ID", "from", "URL", "if", "url", "is", "not", "present", "or", "incorrect"], "add_tokens": "if len ( splitURL ) == 3 { ref . ReferencedID = splitURL [ len ( splitURL ) - 1 ] ref . Type = splitURL [ len ( splitURL ) - 2 ] }", "del_tokens": "ref . ReferencedID = splitURL [ len ( splitURL ) - 1 ] ref . Type = splitURL [ len ( splitURL ) - 2 ]", "commit_type": "add"}
{"commit_tokens": ["use", "primary", "preferred", "mode", "for", "master", "mgo", "session", "and", "fixes", "from", "jackluo2012"], "add_tokens": "n := f . Size ( ) b := make ( [ ] byte , n ) //starting with primary preferred, but individual query can change mode per copied session session . SetMode ( mgo . Strong , true )", "del_tokens": "n := file . ByteLength b := make ( [ ] byte , file . ByteLength ) session . SetMode ( mgo . Monotonic , true )", "commit_type": "use"}
{"commit_tokens": ["Make", "PubControl", ".", "clients", "threadsafe", ".", "Don", "t", "fail", "fast", "when", "a", "single", "client", "fails", "to", "publish", "."], "add_tokens": "import ( \" \" \" \" \" \" ) clients [ ] * PubControlClient clientsRWLock sync . RWMutex pc . clientsRWLock . Lock ( ) defer pc . clientsRWLock . Unlock ( ) pc . clientsRWLock . Lock ( ) defer pc . clientsRWLock . Unlock ( ) pc . clientsRWLock . Lock ( ) defer pc . clientsRWLock . Unlock ( ) pc . clientsRWLock . RLock ( ) defer pc . clientsRWLock . RUnlock ( ) errs := make ( [ ] string , 0 ) errs = append ( errs , err . Error ( ) ) if len ( errs ) > 0 { return fmt . Errorf ( \" \" , len ( errs ) , len ( pc . clients ) , channel , strings . Join ( errs , \" \" ) ) }", "del_tokens": "clients [ ] * PubControlClient return err", "commit_type": "make"}
{"commit_tokens": ["added", "file", "based", "logging", "to", "service", ";", "new", "config", "file", "entry", "log_path"], "add_tokens": "log . Println ( \" \" ) log . Println ( spew . Sdump ( r . Form ) err = encoder . Encode ( \" \" )", "del_tokens": "log . Println ( \" \" ) err = encoder . Encode ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "topicID", "on", "receiver", "construction"], "add_tokens": "func NewReceiver ( projectID , subscriptionID string , opts ... option . ClientOption ) ( * Receiver , error ) {", "del_tokens": "func NewReceiver ( projectID , topicID , subscriptionID string , opts ... option . ClientOption ) ( * Receiver , error ) {", "commit_type": "remove"}
{"commit_tokens": ["Move", "JS", "function", "into", ".", "inc", ".", "js"], "add_tokens": "return js . Global . Get ( \" \" ) . Call ( \" \" , value ) . String ( )", "del_tokens": "var typeOfFunc * js . Object func initTypeOf ( ) { typeOfFunc = js . Global . Call ( \" \" , `(function() { return function ( x ) { return typeof x } } ) ( ) `) } if typeOfFunc == nil { initTypeOf ( ) } return typeOfFunc . Invoke ( value ) . String ( )", "commit_type": "move"}
{"commit_tokens": ["make", "sure", "Id", "because", "ID", "at", "the", "end", "of", "a", "Camelize"], "add_tokens": "c := Camelize ( string ( n ) ) if strings . HasSuffix ( c , \" \" ) { c = strings . TrimSuffix ( c , \" \" ) c += \" \" } return c", "del_tokens": "return Camelize ( string ( n ) )", "commit_type": "make"}
{"commit_tokens": ["Add", "limitation", "to", "buffers", "(", "JavaScript", ")"], "add_tokens": "m := getDefaultBufferSize ( p . sampleRate , p . channelNum , p . bytesPerSample ) n := min ( len ( data ) , m - len ( p . bufferedData ) ) if n < 0 { n = 0 } p . bufferedData = append ( p . bufferedData , data [ : n ] ... ) return n , nil", "del_tokens": "p . bufferedData = append ( p . bufferedData , data ... ) return len ( data ) , nil", "commit_type": "add"}
{"commit_tokens": ["Use", "only", "valid", "object", "names", "in", "ListingTest", ".", "Prefix", "."], "add_tokens": "AssertEq ( nil , t . createObject ( \" \\x01 \" , \" \" ) ) AssertEq ( nil , t . createObject ( \" \" ) ExpectEq ( \" \\x01 \" , objects . Results [ 2 ] . Name ) ExpectEq ( \" b j cts.Res u lts[3]. N a m e )", "del_tokens": "AssertEq ( nil , t . createObject ( \" \" , \" \" ) ) AssertEq ( nil , t . createObject ( \" \\xff \" , \" \" ) ) ExpectEq ( \" \" , objects . Results [ 2 ] . Name ) ExpectEq ( \" \\xff \" , objects . Results [ 3 ] . Name )", "commit_type": "use"}
{"commit_tokens": ["Add", "points", "of", "error", "handling"], "add_tokens": "if err != nil { return nil , err } if err != nil { return nil , err } if err != nil { return nil , err } fieldMap = append ( fieldMap , nestFieldMap ) if err != nil { return nil , err }", "del_tokens": "} fieldMap = append ( fieldMap , nestFieldMap ) if err != nil { return nil , err if err != nil { return nil , err }", "commit_type": "add"}
{"commit_tokens": ["Fix", "formatting", "of", "an", "error", "message", "."], "add_tokens": "return TimeOfDay { } , fmt . Errorf ( \" \" , s )", "del_tokens": "return TimeOfDay { } , fmt . Errorf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Use", "ServerOption", "style", "to", "pass", "http", "client"], "add_tokens": "httpClient * http . Client bot adapter . BotAdapter // WithHttpClient sets custom http client for server. func WithHttpClient ( client * http . Client ) ServerOption { return func ( s * Server ) { s . httpClient = client } } mux : NewDefaultMux ( ) , httpClient : http . DefaultClient , tbot , err := createBot ( token , server . httpClient ) if err != nil { return nil , err } server . bot = tbot", "del_tokens": "bot adapter . BotAdapter return NewServerWithClient ( token , http . DefaultClient , options ... ) } // NewServerWithClient creates new Server with Telegram API Token // and default /help handler func NewServerWithClient ( token string , httpClient * http . Client , options ... ServerOption ) ( * Server , error ) { tbot , err := createBot ( token , httpClient ) if err != nil { return nil , err } bot : tbot , mux : NewDefaultMux ( ) ,", "commit_type": "use"}
{"commit_tokens": ["Add", "config", "to", "use", "derive", "on", "value", "method", "in", "addition", "to", "derive", "on", "error"], "add_tokens": "type DeriveMethodType int const ( DeriveOnErr DeriveMethodType = iota DeriveOnValue ) prevSetpoint float64 // last setpoint prevValue float64 // last process value deriveOn DeriveMethodType // What do we derive on? // SetDeriveMethod changes the derivation method. func ( c * PIDController ) SetDeriveMethod ( dm DeriveMethodType ) { c . deriveOn = dm } // GetDeriveMethod returns the derivation method. func ( c * PIDController ) GetDeriveMethod ( ) DeriveMethodType { return c . deriveOn } if c . deriveOn == DeriveOnErr { d = ( err - c . prevErr ) / dt } else { d = ( ( c . setpoint - c . prevSetpoint ) / dt ) - ( ( value - c . prevValue ) / dt ) } c . prevValue = value c . prevSetpoint = c . setpoint", "del_tokens": "d = ( err - c . prevErr ) / dt", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "of", "custom", "mapstructure", "decoder", "hook"], "add_tokens": "errors \" \" type StrInt int func ( s StrInt ) UnmarshalMap ( v interface { } ) ( interface { } , error ) { if reflect . ValueOf ( v ) . Kind ( ) == reflect . String { if v . ( string ) == \" \" { return 1 , nil } return nil , errors . New ( \" \" ) } return v , nil } func ( s StrInt ) MarshalJSON ( ) ( [ ] byte , error ) { if s == 1 { return [ ] byte ( `\"one\"` ) , nil } return nil , errors . New ( \" \" ) } Foo string Bar int StrInt StrInt Foo : \" \" , Bar : 321 , StrInt : 1 , Foo : \" \" , Bar : 456 , StrInt : 1 ,", "del_tokens": "Foo string Bar int Foo : \" \" , Bar : 321 , Foo : \" \" , Bar : 456 ,", "commit_type": "add"}
{"commit_tokens": ["Adding", "headers", "to", "request", "and", "fixing", "case", "on", "URI", "name"], "add_tokens": "URI string // quoted URI : \" \" , url , err := url . Parse ( dr . URI ) ah . URI = url . RequestURI ( ) return fmt . Sprintf ( \" \" , dr . Method , ah . URI , ah . hash ( dr . Body ) ) return fmt . Sprintf ( \" \" , dr . Method , ah . URI ) if ah . URI != \" \" { buffer . WriteString ( fmt . Sprintf ( \" \\\" \\\" \" , ah . URI ) )", "del_tokens": "Uri string // quoted Uri : \" \" , url , err := url . Parse ( dr . Uri ) ah . Uri = url . RequestURI ( ) return fmt . Sprintf ( \" \" , dr . Method , ah . Uri , ah . hash ( dr . Body ) ) return fmt . Sprintf ( \" \" , dr . Method , ah . Uri ) if ah . Uri != \" \" { buffer . WriteString ( fmt . Sprintf ( \" \\\" \\\" \" , ah . Uri ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "gexec", ".", "Build", "work", "on", "windows"], "add_tokens": "\" \" \" \" executable := filepath . Join ( tmpDir , path . Base ( packagePath ) ) if runtime . GOOS == \" \" { executable = executable + \" \" }", "del_tokens": "executable := filepath . Join ( tmpDir , filepath . Base ( packagePath ) )", "commit_type": "make"}
{"commit_tokens": ["using", "expectedError", "instead", "of", "magic", "string", "and", "changing", "pre", "to", "post", "in", "failing", "assertion", "message", "."], "add_tokens": "if rollbackErr := tx . Rollback ( ) ; rollbackErr != nil {", "del_tokens": "if rollbackErr := tx . Rollback ( ) ; rollbackErr != nil {", "commit_type": "use"}
{"commit_tokens": ["Adding", "comment", "to", "clarify", "usage"], "add_tokens": "// NewConsumerFromClient initializes a new consumer from an existing client. // // Please note that clients cannot be shared between consumers (due to Kafka internals), // they can only be re-used which requires the user to call Close() on the first consumer // before using this method again to initialize another one. Attempts to use a client with // more than one consumer at a time will return errors.", "del_tokens": "// NewConsumerFromClient initializes a new consumer from an existing client", "commit_type": "add"}
{"commit_tokens": ["Made", "Object", "map", "into", "method"], "add_tokens": "// The underlying golang map can be accessed with Map(). m map [ string ] * Value // The formatted map with typed values // Returns the golang map. // Needed when iterating through the values of the object. func ( j * Object ) Map ( ) map [ string ] * Value { return j . m } child , ok := obj . Map ( ) [ key ] obj . m = m", "del_tokens": "// The underlying golang map can be accessed with Map. // It is needed when iterating through the values of the object. Map map [ string ] * Value // The formatted map with typed values child , ok := obj . Map [ key ] obj . Map = m", "commit_type": "make"}
{"commit_tokens": ["Add", "possibility", "to", "negate", "a", "validator", "for", "a", "struct"], "add_tokens": "negate := false //Check wether the tag looks like '!something' or 'something' if len ( tagOpt ) > 0 && tagOpt [ 0 ] == '!' { tagOpt = string ( tagOpt [ 1 : ] ) negate = true } if result := validatefunc ( field ) ; ! result && ! negate || result && negate { var err error if ! negate { err = fmt . Errorf ( \" \" , t . Name , field , tagOpt ) } else { err = fmt . Errorf ( \" \" , t . Name , field , tagOpt ) }", "del_tokens": "if result := validatefunc ( field ) ; ! result { err := fmt . Errorf ( \" \" , t . Name , field , tagOpt )", "commit_type": "add"}
{"commit_tokens": ["Add", "CreatedAt", "and", "UpdatedAt", "fields", "to", "secret"], "add_tokens": "CreatedAt string `\"json: created_at\"` Value string `\"json: value\"` UpdatedAt string `\"json: updated_at\"` Uuid string `\"json: uuid\"`", "del_tokens": "Value string `\"json: value\"` Uuid string `\"json: uuid\"`", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "datacenter_policy", "type", "."], "add_tokens": "DatacenterPolicy [ ] DatacenterPolicy `json:\"datacenter_policy,omitempty\"`", "del_tokens": "DatacenterPolicy string `json:\"datacenter_policy,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["use", "rowID", "instead", "of", "id", "in", "proxy", ".", "Now", "works", "with", "default", "label"], "add_tokens": "id , err := p . m . GetID ( call . Args [ \" \" ] . ( string ) , call . Args [ \" \" ] ) call . Args [ \" \" ] = id", "del_tokens": "id , err := p . m . GetID ( call . Args [ \" \" ] . ( string ) , call . Args [ \" \" ] ) call . Args [ \" \" ] = id", "commit_type": "use"}
{"commit_tokens": ["fix", "incompatable", "modules", "attribute", "on", "packet"], "add_tokens": "Modules map [ string ] string `json:\"modules,omitempty\"`", "del_tokens": "Modules [ ] map [ string ] string `json:\"modules,omitempty\"`", "commit_type": "fix"}
{"commit_tokens": ["Remove", "more", "test", "non", "-", "determinism"], "add_tokens": "// map[string]interface {}{\"bob\":map[string]interface {}{\"emails\":[]string{\"a\", \"b\"}}}", "del_tokens": "\" \" : map [ string ] interface { } { \" \" : \" \" , } , // map[string]interface {}{\"bob\":map[string]interface {}{\"emails\":[]string{\"a\", \"b\"}}, \"jane\":map[string]interface {}{\"name\":\"jane\"}}", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "Complex64", "generator", "to", "correctly", "specify", "Complex64Shrinker", "(", "instead", "of", "the", "128", "version", ")", "."], "add_tokens": "} ) . WithShrinker ( Complex64Shrinker )", "del_tokens": "} ) . WithShrinker ( Complex128Shrinker )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "tx", "class", "of", "select", "/", "commit", "/", "rollback"], "add_tokens": "func ( me * Channel ) TxSelect ( ) ( err error ) { if err = me . send ( & txSelect { } ) ; err != nil { return } switch ( <- me . rpc ) . ( type ) { case * txSelectOk : return case nil : return me . Close ( ) } return ErrBadProtocol } func ( me * Channel ) TxCommit ( ) ( err error ) { if err = me . send ( & txCommit { } ) ; err != nil { return } switch ( <- me . rpc ) . ( type ) { case * txCommitOk : return case nil : return me . Close ( ) } return ErrBadProtocol } func ( me * Channel ) TxRollback ( ) ( err error ) { if err = me . send ( & txRollback { } ) ; err != nil { return } switch ( <- me . rpc ) . ( type ) { case * txRollbackOk : return case nil : return me . Close ( ) } return ErrBadProtocol }", "del_tokens": "//TODO func (me *Channel) TxSelect() error { return nil } //TODO func (me *Channel) TxCommit() error { return nil } //TODO func (me *Channel) TxRollback() error { return nil }", "commit_type": "implement"}
{"commit_tokens": ["moved", "post", "processing", "pkg", "into", "base", "repo", "dir"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "move"}
{"commit_tokens": ["implemented", "removal", "of", "events", "that", "exceed", "TTL", "setting"], "add_tokens": "// TODO: move deprecated functions to their own file called longpoll_deprecated.go // TODO: log warning whenever deprecated func used // TODO: if TTL is zero, default to FOREVER? timeToEpochMilliseconds ( time . Now ( ) ) , sm . checkExpiredEvents ( buf ) sm . deleteBufferIfEmpty ( buf , newEvent . Category ) if sm . EventTimeToLiveSeconds == FOREVER { // Events can never expire. bail out early instead of wasting time. return nil } // determine what time is considered the threshold for expiration now_ms := timeToEpochMilliseconds ( time . Now ( ) ) expiration_time := now_ms - int64 ( sm . EventTimeToLiveSeconds * 1000 ) return buf . DeleteEventsOlderThan ( expiration_time )", "del_tokens": "sm . checkExpiredEvents ( buf ) // TODO: make sure this call is trivial when TTL option == FOREVER sm . deleteBufferIfEmpty ( buf , newEvent . Category ) // TODO: Make sure trivial if buffer nonempty (I believe this is the case) // TODO: implement // TODO: make this func also work when doing periodic check against all // buffers. Will this involve another data struct with timestamps? // if so, can we just do a timestamp check on that data struct and skip // having to check event timestamps one by one? // TODO: on the other hand, would it be just as fast to check timestamp of oldest event in buffer? // TODO: if error ever possible have calling code check value return nil", "commit_type": "implement"}
{"commit_tokens": ["Make", "a", "simple", "adjustment", "for", "new", "rule", "for", "now", "."], "add_tokens": "if numPlayed [ player ] >= 10 {", "del_tokens": "if numPlayed [ player ] >= 8 {", "commit_type": "make"}
{"commit_tokens": ["Add", "WithData", "function", "on", "loggers"], "add_tokens": "WithData ( Data ) Logger data : l . baseData ( data ... ) , } } func ( l * logger ) WithData ( data Data ) Logger { return & logger { component : l . component , task : l . task , sinks : l . sinks , sessionID : l . sessionID , Data : l . baseData ( data ... ) , Data : l . baseData ( data ... ) , logData := l . baseData ( data ... ) logData := l . baseData ( data ... ) func ( l * logger ) baseData ( givenData ... Data ) Data {", "del_tokens": "Data : l . baseData ( data ) , Data : l . baseData ( data ) , logData := l . baseData ( data ) logData := l . baseData ( data ) func ( l * logger ) baseData ( givenData [ ] Data ) Data {", "commit_type": "add"}
{"commit_tokens": ["fixed", "active", "page", "caching", "."], "add_tokens": "w . Header ( ) . Set ( \" \" , \" \" ) w . Header ( ) . Set ( \" \" , \" \" )", "del_tokens": "w . Header ( ) . Set ( \" \" , \" \" ) w . Header ( ) . Set ( \" \" , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "VolumesRW", "type", "bug"], "add_tokens": "VolumesRW map [ string ] bool", "del_tokens": "VolumesRW map [ string ] string", "commit_type": "fix"}
{"commit_tokens": ["use", "facebookgo", "/", "clock", "fork"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "use"}
{"commit_tokens": ["Create", "TLS", "config", "with", "existing", "CaCertPool"], "add_tokens": "caCertPool := x509 . NewCertPool ( ) return NewTLSConfigWithCertPool ( certFile , keyFile , caCertFile , caCertPool ) } func NewTLSConfigWithCertPool ( certFile , keyFile , caCertFile string , caCertPool * x509 . CertPool ) ( * tls . Config , error ) {", "del_tokens": "caCertPool := x509 . NewCertPool ( )", "commit_type": "create"}
{"commit_tokens": ["fix", "endpoint", "/", "v1", "/", "import", "not", "/", "v1", "/", "batch"], "add_tokens": "import \" \" url := c . Endpoint + \" \" if res . StatusCode >= 500 { body , _ := ioutil . ReadAll ( res . Body ) c . log ( \" \" , string ( body ) ) }", "del_tokens": "url := c . Endpoint + \" \"", "commit_type": "fix"}
{"commit_tokens": ["create", "low", "level", "objects", "API", "which", "doesn", "t", "require", "a", "http", ".", "Response", "to", "work"], "add_tokens": "// LOW LEVEL API: Repersentation of possible request directives in a `Cache-Control` header: http://tools.ietf.org/html/rfc7234#section-5.2.1 // LOW LEVEL API: Parses a Cache Control Header from a Request into a set of directives. // LOW LEVEL API: Repersentation of possible response directives in a `Cache-Control` header: http://tools.ietf.org/html/rfc7234#section-5.2.2 // LOW LEVEL API: Parses a Cache Control Header from a Response into a set of directives.", "del_tokens": "// Low level repersentation of possible request directives in a `Cache-Control` header: http://tools.ietf.org/html/rfc7234#section-5.2.1 // Low level repersentation of possible response directives in a `Cache-Control` header: http://tools.ietf.org/html/rfc7234#section-5.2.2", "commit_type": "create"}
{"commit_tokens": ["Allow", "disabling", "timestamp", "in", "non", "-", "tty", "output", "."], "add_tokens": "ForceColors bool DisableColors bool DisableTimestamp bool if ! f . DisableTimestamp { f . appendKeyValue ( b , \" \" , entry . Time . Format ( time . RFC3339 ) ) }", "del_tokens": "ForceColors bool DisableColors bool f . appendKeyValue ( b , \" \" , entry . Time . Format ( time . RFC3339 ) )", "commit_type": "allow"}
{"commit_tokens": ["added", "in", "request", "body", "for", "multi", "get", "command"], "add_tokens": "body , err := api . DoCommand ( \" \" , url , args , mgetRequest )", "del_tokens": "body , err := api . DoCommand ( \" \" , url , args , nil )", "commit_type": "add"}
{"commit_tokens": ["Move", "diffcmd", "to", "run", "package"], "add_tokens": "d := run . NewDiffCmd ( pull . Release { CacheDir : cacheDir } , c . Args ( ) [ 0 ] , c . Args ( ) [ 1 ] ) d := run . NewDiffCmd ( pull . Release { CacheDir : cacheDir } , c . Args ( ) [ 1 ] , c . Args ( ) [ 2 ] )", "del_tokens": "d := & diffCmd { releaseRepo : pull . Release { CacheDir : cacheDir } , release1 : c . Args ( ) [ 0 ] , release2 : c . Args ( ) [ 1 ] , } d := & diffCmd { releaseRepo : pull . Release { CacheDir : cacheDir } , release1 : c . Args ( ) [ 1 ] , release2 : c . Args ( ) [ 2 ] , }", "commit_type": "move"}
{"commit_tokens": ["Adding", "more", "tests", "to", "the", "configurationprovider"], "add_tokens": "value * configuration if config , ok := value . ( * configuration ) ; ok { if dr . value != nil { config . Issuer = dr . value . Issuer config . JwksUri = dr . value . JwksUri } } else { c . t . Fatalf ( \" \" , value ) }", "del_tokens": "value interface { } value = dr . value", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \"", "del_tokens": "expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \" expectedDesc := \" \"", "commit_type": "fix"}
{"commit_tokens": ["using", "fmt", ".", "Fprintln", "instead", "of", "fmt", ".", "Fprintf"], "add_tokens": "\" \" fmt . Fprintln ( writer , msg ) fmt . Fprintln ( writer , \" \\n \" ) fmt . Fprintln ( writer , msg ) fmt . Fprintln ( writer , \" \\n \" )", "del_tokens": "\" \\n \" fmt . Fprintf ( writer , msg ) fmt . Fprint ( writer , \" \\n \\n \" ) fmt . Fprintf ( writer , msg ) fmt . Fprint ( writer , \" \\n \\n \" )", "commit_type": "use"}
{"commit_tokens": ["add", "sup", "application", "/", "x", "-", "www", "-", "form", "-", "urlencoded"], "add_tokens": "\" \" , comment := `/@Accept json,xml,plain,html,mpfd,x-www-form-urlencoded,json-api,json-stream` \" \" , comment := `/@Produce json,xml,plain,html,mpfd,x-www-form-urlencoded,json-api,json-stream`", "del_tokens": "comment := `/@Accept json,xml,plain,html,mpfd,json-api,json-stream` comment := `/@Produce json,xml,plain,html,mpfd,json-api,json-stream`", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "metric", "mem_bytes", "that", "reports", "the", "number", "of", "bytes", "used", "by", "TCP", "/", "UDP", "memory"], "add_tokens": "// Used for calculating the total memory bytes on TCP and UDP. Factories [ sockStatSubsystem ] = NewSockStatCollector // NewSockStatCollector returns a new Collector exposing socket stats. // Remove trailing :. / * The mem metrics is the count of pages used . Multiply the mem metrics by the page size from the kernal to get the number of bytes used . Update the TCP mem from page count to bytes . * / sockStat [ \" \" ] [ \" \" ] = strconv . Itoa ( pageCount * pageSize ) // Update the UDP mem from page count to bytes. sockStat [ \" \" ] [ \" \" ] = strconv . Itoa ( pageCount * pageSize )", "del_tokens": "// Used for calculating the total memory bytes on TCP and UDP Factories [ \" \" ] = NewSockStatCollector // NewSockStatCollector returns a new Collector exposing socket stats // Remove trailing : // The mem options are reported in pages // Multiply them by the pagesize to get bytes // Update TCP Mem sockStat [ \" \" ] [ \" \" ] = strconv . Itoa ( pageCount * pageSize ) // Update UDP Mem sockStat [ \" \" ] [ \" \" ] = strconv . Itoa ( pageCount * pageSize )", "commit_type": "add"}
{"commit_tokens": ["Remove", "extra", "unnecessary", "version", "check"], "add_tokens": "gk := spec . GroupVersionKind ( ) . GroupKind ( )", "del_tokens": "gvk := spec . GroupVersionKind ( ) gk := gvk . GroupKind ( ) if gk . Kind == \" \" || gvk . Version == \" \" { // Group can be empty e.g. built-in objects like ConfigMap return nil , errors . Errorf ( \" \" , gvk ) }", "commit_type": "remove"}
{"commit_tokens": ["makes", "the", "parser", "close", "all", "of", "its", "channels", "properly"], "add_tokens": "close ( chunks ) case chunk , ok := <- chunks : if ! ok { close ( pages ) return } case rawPage , ok := <- rawPages : if ! ok { close ( nonRedirectPages ) return } case rawPage , ok := <- rawPages : if ! ok { close ( pages ) return } case page , ok := <- pages : if ! ok { close ( linkedPages ) return } case page , ok := <- pages : if ! ok { close ( categorizedPages ) return }", "del_tokens": "case chunk := <- chunks : case rawPage := <- rawPages : case rawPage := <- rawPages : case page := <- pages : case page := <- pages :", "commit_type": "make"}
{"commit_tokens": ["Fix", "value", "handling", "for", "arrays"], "add_tokens": "if f . value . Type ( ) == reflect . TypeOf ( new ( [ ] bool ) ) . Elem ( ) || f . value . Type ( ) == reflect . TypeOf ( new ( bool ) ) . Elem ( ) {", "del_tokens": "if f . value . Type ( ) == reflect . TypeOf ( new ( bool ) ) . Elem ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "the", "remaining", "enum", "validations", "work", "with", "deep", "nesting"], "add_tokens": "// allow aliases in nested enums within nested messages (howsoever deep) only if option allow_alias is specified for _ , msg := range pf . Messages { if err := validateEnumConstantTagAliasesInMessage ( msg ) ; err != nil { return err } func validateEnumConstantTagAliasesInMessage ( msg MessageElement ) error { if err := validateEnumConstantTagAliases ( msg . Enums ) ; err != nil { return err } for _ , nestedmsg := range msg . Messages { if err := validateEnumConstantTagAliasesInMessage ( nestedmsg ) ; err != nil {", "del_tokens": "// allow aliases in nested enums only if option allow_alias is specified if err := validateEnumConstantTagAliasesInMessage ( pf ) ; err != nil { return err func validateEnumConstantTagAliasesInMessage ( pf * ProtoFile ) error { for _ , msg := range pf . Messages { if err := validateEnumConstantTagAliases ( msg . Enums ) ; err != nil {", "commit_type": "make"}
{"commit_tokens": ["Fix", "Example_get", "-", "resp", ".", "ReceivedAt", "should", "be", "called"], "add_tokens": "fmt . Printf ( \" \\n \" , resp . ReceivedAt ( ) )", "del_tokens": "fmt . Printf ( \" \\n \" , resp . ReceivedAt )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "bigint", ".", "go"], "add_tokens": "// EqualBigInt returns true if both *big.Ints are equal", "del_tokens": "// EqualBigInt returns true if both *bit.Ints are equal", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "missed", "returns", "in", "a", "couple", "of", "functions"], "add_tokens": "return trc . request . Post ( requestUrl , options , [ ] string { } ) return trc . request . Post ( requestUrl , options , [ ] string { } ) return trc . request . Post ( requestUrl , options , [ ] string { } ) return trc . request . Post ( requestUrl , params , [ ] string { } )", "del_tokens": "trc . request . Post ( requestUrl , options , [ ] string { } ) trc . request . Post ( requestUrl , options , [ ] string { } ) trc . request . Post ( requestUrl , options , [ ] string { } ) trc . request . Post ( requestUrl , params , [ ] string { } )", "commit_type": "add"}
{"commit_tokens": ["Moving", "ticker", "log", "entry", "to", "debug"], "add_tokens": "u . log . Debug ( \" \" )", "del_tokens": "u . log . Info ( \" \" )", "commit_type": "move"}
{"commit_tokens": ["add", "license", "notice", "to", "*", ".", "go", "files"], "add_tokens": "/ * * This Source Code Form is subject to the terms of the Mozilla Public * License , v . 2.0 . If a copy of the MPL was not distributed with this * file , You can obtain one at http : //mozilla.org/MPL/2.0/. * /", "del_tokens": "Licensed under Mozilla Public License Version 2.", "commit_type": "add"}
{"commit_tokens": ["Add", "[]", "byte", "and", "[]", "uint8", "to", "Body", "types", "page", "::", "intercept", "will", "accept"], "add_tokens": "const Version = `0.9.34`", "del_tokens": "const Version = `0.9.33`", "commit_type": "add"}
{"commit_tokens": ["add", "test", "cleanup", "back", "in"], "add_tokens": "defer os . RemoveAll ( link )", "del_tokens": "//defer os.RemoveAll(link)", "commit_type": "add"}
{"commit_tokens": ["Improve", "the", "binder", "godoc", "formatting"], "add_tokens": "// // Request: // url?id=123&ol[0]=1&ol[1]=2&ul[]=str&ul[]=array&user.name=rob // Action: // Example.Action(id int, ol []int, ul []string, user User) // Binder(int, keyValue[]{ {\"id\", \"123\"} }) // Binder([]int, keyValue[]{ {\"ol[0]\", \"1\"}, {\"ol[1]\", \"2\"} }) // Binder([]string, keyValue[]{ {\"ul[]\", \"str\"}, {\"ul[]\", \"array\"} }) // Binder(User, keyValue[]{ {\"user.Name\", \"rob\"} })", "del_tokens": "// Request: url?id=123&ol[0]=1&ol[1]=2&ul[]=str&ul[]=array&user.name=rob // Action: Example.Action(id int, ol []int, ul []string, user User) // - Binder(int, keyValue[]{ {\"id\", \"123\"} }) // - Binder([]int, keyValue[]{ {\"ol[0]\", \"1\"}, {\"ol[1]\", \"2\"} }) // - Binder([]string, keyValue[]{ {\"ul[]\", \"str\"}, {\"ul[]\", \"array\"} }) // - Binder(User, keyValue[]{ {\"user.Name\", \"rob\"} })", "commit_type": "improve"}
{"commit_tokens": ["added", "comment", "to", "explain", "-", "in", "api", "call", "means", "current", "user", "."], "add_tokens": "endpointProfile string = \" \" // '-' for logged in user", "del_tokens": "endpointProfile string = \" \"", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "field", "name", "(", "Tasteometer", ".", "User", "-", ">", "Tasteometer", ".", "Users", ")"], "add_tokens": "Users [ ] string `xml:\"input>user>name\"`", "del_tokens": "User [ ] string `xml:\"input>user>name\"`", "commit_type": "fix"}
{"commit_tokens": ["Add", "generation", "of", "vendors", "/", "products", "and", "features", "from", "upstream", "JSON"], "add_tokens": "product * Product if d . CachedHardwareVendor ( ) != 0 { if d . CachedHardwareVersion ( ) != 0 { if vendor , ok := Vendors [ v . Vendor ] ; ok { if product , ok := vendor . Products [ v . Product ] ; ok { d . product = product } } func ( d * Device ) GetProduct ( ) ( * Product , error ) { if d . CachedProduct ( ) != nil { return d . CachedProduct ( ) , nil } _ , err := d . GetHardwareVersion ( ) if err != nil { return nil , err } return d . CachedProduct ( ) , nil } func ( d * Device ) CachedProduct ( ) * Product { d . RLock ( ) defer d . RUnlock ( ) return d . product }", "del_tokens": "VendorLifx = 1 ProductLifxOriginal1000 uint32 = 1 ProductLifxColor650 uint32 = 3 ProductLifxWhite800LowVoltage uint32 = 10 ProductLifxWhite800HighVoltage uint32 = 11 ProductLifxWhite900BR30 uint32 = 18 ProductLifxColor1000BR30 uint32 = 20 ProductLifxColor1000 uint32 = 22 if d . CachedHardwareProduct ( ) != 0 { if d . CachedHardwareProduct ( ) != 0 {", "commit_type": "add"}
{"commit_tokens": ["fix", "crashing", "bug", "in", "pick_among_best"], "add_tokens": "winners := firstRoundScores . FilterErrors ( ) . Shuffle ( ) . Sort ( ) max := 5 if len ( winners ) < max { max = len ( winners ) } top5Winners := winners [ : max ]", "del_tokens": "top5Winners := firstRoundScores . FilterErrors ( ) . Shuffle ( ) . Sort ( ) [ : 5 ]", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "special", "use", "case", "for", "CreateServiceOffering"], "add_tokens": "if n == \" \" || n == \" \" || n == \" \" || n == \" \" {", "del_tokens": "if n == \" \" || n == \" \" || n == \" \" {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "infinite", "loop", "in", "remote_enforcer", "Makefile", "changes", "to", "get", "the", "right", "binary", "name", "removed", "stack", "print"], "add_tokens": "\" \" ipcProtocol = \" \" defaultPath = \" \" statsContextID = \" \" defaulttimeInterval = 2 var statsInterval time . Duration EnvstatsInterval , err := strconv . Atoi ( os . Getenv ( \" \" ) ) if err == nil && EnvstatsInterval != 0 { statsInterval = time . Duration ( EnvstatsInterval ) * time . Second } else { statsInterval = defaulttimeInterval * time . Second } for ! ( s . collector . Flowentries . Len ( ) > 0 ) { time . Sleep ( statsInterval ) s . collector . Lock ( ) if time . Since ( starttime ) > statsInterval {", "del_tokens": "ipcProtocol = \" \" defaultPath = \" \" statsContextID = \" \" if ! ( s . collector . Flowentries . Len ( ) > 0 ) { //starttime = time.Now() if time . Since ( starttime ) > 2 * time . Second {", "commit_type": "fix"}
{"commit_tokens": ["Add", "covermode", "=", "count", "+", "-", "race", "warning"], "add_tokens": "example : - project = github . com / go - playground / overalls", "del_tokens": "example : - project = github . com / bluesuncorp / overalls", "commit_type": "add"}
{"commit_tokens": ["Add", "buildpack", "integration", "test", "framework", "and", "packager"], "add_tokens": "\" \" \" \" source := filepath . Join ( m . manifestRootDir , \" \" , fmt . Sprintf ( \" \" , md5 . Sum ( [ ] byte ( entry . URI ) ) ) , path . Base ( entry . URI ) ) exists , err := FileExists ( source ) if err != nil { m . log . Warning ( \" \" , err . Error ( ) ) } if ! exists { r := strings . NewReplacer ( \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ) source = filepath . Join ( m . manifestRootDir , \" \" , r . Replace ( filteredURI ) ) }", "del_tokens": "r := strings . NewReplacer ( \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" ) source := filepath . Join ( m . manifestRootDir , \" \" , r . Replace ( filteredURI ) )", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "R", "flag", "to", "set", "the", "projecroot"], "add_tokens": "arg , err = filepath . Rel ( ctx . Srcdirs ( ) [ 0 ] , projectroot )", "del_tokens": "arg , err = filepath . Rel ( ctx . Srcdirs ( ) [ 0 ] , mustGetwd ( ) )", "commit_type": "add"}
{"commit_tokens": ["Update", "conf", "without", "full", "reinstall"], "add_tokens": "rootCmd . AddCommand ( buildCmd , cleanCmd , pushCmd , installCmd , testCmd , versionCmd , initCmd , updateCmd ) func discoverAndRunUpdateType ( path string , args builder . BuildArgs ) { if cnt , err := builder . NewAci ( path , args ) ; err == nil { cnt . UpdateConf ( ) } else if _ , err := builder . OpenPod ( path , args ) ; err == nil { log . Get ( ) . Panic ( \" \" ) } else { log . Get ( ) . Panic ( \" \" ) } }", "del_tokens": "rootCmd . AddCommand ( buildCmd , cleanCmd , pushCmd , installCmd , testCmd , versionCmd , initCmd )", "commit_type": "update"}
{"commit_tokens": ["Add", "godoc", "package", "documentation", "and", "examples"], "add_tokens": "import \" \"", "del_tokens": "import ( \" \" \" \" ) func TestCommandf_Redirect ( t * testing . T ) { var stdout , stderr bytes . Buffer cmd := Commandf ( \" \" , \" \" , \" \" ) cmd . Stdout = & stdout cmd . Stderr = & stderr err := cmd . Run ( ) if err != nil { t . Fatal ( err ) } if stdout . String ( ) != \" \\n \" { t . Errorf ( \" \" , stdout . String ( ) ) } if stderr . String ( ) != \" \\n \" { t . Errorf ( \" \" , stderr . String ( ) ) } }", "commit_type": "add"}
{"commit_tokens": ["added", "channel", "for", "health", "checks", "to", "availablePlugin"], "add_tokens": "healthChan chan error ap . healthChan = make ( chan error , 1 ) // Emits event and disables the plugin if the default limit is exceeded // Ping the client resetting the failedHealthCheks on success. // On failure healthCheckFailed() is called. ap . healthChan <- ap . client . Ping ( ) case err := <- ap . healthChan :", "del_tokens": "hc := make ( chan error , 1 ) hc <- ap . client . Ping ( ) case err := <- hc :", "commit_type": "add"}
{"commit_tokens": ["Implement", "(", "*", "Wallet", ")", ".", "Lock", "()", "and", "reply", "with", "correct", "JSON"], "add_tokens": "\" \" key struct { sync . Mutex secret [ ] byte } if err := wallet . keyGenerator . unlock ( key ) ; err != nil { return err } else { wallet . key . Lock ( ) wallet . key . secret = key wallet . key . Unlock ( ) return nil } func ( wallet * Wallet ) Lock ( ) ( err error ) { wallet . key . Lock ( ) if wallet . key . secret != nil { for i , _ := range wallet . key . secret { wallet . key . secret [ i ] = 0 } wallet . key . secret = nil } else { err = fmt . Errorf ( \" \" ) } wallet . key . Unlock ( ) return err", "del_tokens": "return wallet . keyGenerator . unlock ( key ) func ( wallet * Wallet ) Lock ( ) {", "commit_type": "implement"}
{"commit_tokens": ["Use", "multiple", "value", "arguments", "for", "Encoder", ".", "Encode", "()"], "add_tokens": "func ( r * Encoder ) encodeSingle ( data interface { } ) error {", "del_tokens": "// Encode is the generic encoder method that will encode any of the following supported types: // * big.Int // * List // * Dictionary // * bool // * float32, float34 // * []byte, string (all strings are stored as byte slices anyway) // * int8, int16, int32, int64, int // * uint8, uint16, uint32, uint64, uint func ( r * Encoder ) Encode ( data interface { } ) error {", "commit_type": "use"}
{"commit_tokens": ["Fix", "pkgDecls", "incorrectly", "matching", "privates"], "add_tokens": "dotIndex := strings . IndexRune ( rid , '.' ) if dotIndex < 0 { pid , pfunc := rid [ : dotIndex ] , rid [ dotIndex + 1 : ]", "del_tokens": "// len(type)+1 to account for dot separator if len ( rid ) <= len ( id ) + 1 { pid , pfunc := rid [ : len ( id ) ] , rid [ len ( id ) + 1 : ]", "commit_type": "fix"}
{"commit_tokens": ["Fix", "test", "$", "should", "not", "be", "escaped"], "add_tokens": "writeAndCompare ( `foo=\"\\n\\r\\\\r!\"` , `foo=\"\\n\\r\\\\r\\!\"` )", "del_tokens": "writeAndCompare ( `foo=\"$ba\\n\\r\\\\r!\"` , `foo=\"\\$ba\\n\\r\\\\r\\!\"` )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "the", "test", "so", "it", "compiled"], "add_tokens": "\" \" func task ( ) { fmt . Println ( \" \" ) func taskWithParams ( a int , b string ) { fmt . Println ( a , b ) defaultScheduler . Every ( 1 ) . Second ( ) . Do ( task ) defaultScheduler . Every ( 1 ) . Second ( ) . Do ( taskWithParams , 1 , \" \" ) defaultScheduler . Start ( ) time . Sleep ( 10 * time . Second )", "del_tokens": "\" \" func task ( ) string { return \" \" func taskWithParams ( a int , b string ) ( a_ int , b_ string ) { return a , b now := time . Now ( ) default_scheduler . Every ( 1 ) . Second ( ) . Do ( task ) default_scheduler . Every ( 1 ) . Second ( ) . Do ( taskWithParams , 1 , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "documentation", "to", "http2", "code"], "add_tokens": "// StreamSession is a session manager on top of a network // connection using spdy. // NewStreamSession creates a new stream session from the // provided network connection. The network connection is // expected to already provide a tls session. // NewSender returns a new Sender from the session. Each // call to NewSender will result in a sender with a new // underlying spdy stream. // Close closes the underlying network connection, causing // each stream created by this session to closed. // StreamReceiver is a receiver object with an underlying spdystream. // Receive returns a new message from the underlying stream. When // the mode is set to return a pipe, the receiver will wait for a // substream to be created. If the mode is 0, then the receiver // will wait for a message on the underlying stream. // StreamSender is a sender object with an underlying spdy stream. // Send sends a messages either on the underlying stream or // creating substream. A substream is created when a file // is attached or return pipe is requested, otherwise the // message will just be sent on the underlying spdy stream. // Close closes the underlying spdy stream", "del_tokens": "// Only allows sending, no parent stream //ret = &libchan.NopReceiver{}", "commit_type": "add"}
{"commit_tokens": ["Implement", "http", ".", "Handler", "in", "media", ".", "server"], "add_tokens": "matches , _ := regexp . MatchString ( \" \" , s . cmds [ 0 ] ) matches , _ = regexp . MatchString ( \" \" , s . cmds [ 1 ] )", "del_tokens": "matches , _ := regexp . MatchString ( \" \" , s . cmds [ 0 ] ) matches , _ = regexp . MatchString ( \" \" , s . cmds [ 1 ] )", "commit_type": "implement"}
{"commit_tokens": ["Add", "consts", "for", "common", "category", "codes", ".", "Fix", "golint", "complaints"], "add_tokens": "// CPUCategoryCode Category code for cpus const CPUCategoryCode = \" \" // MemoryCategoryCode Category code for Memory const MemoryCategoryCode = \" \" // NICSpeedCategoryCode Category code for NIC speed const NICSpeedCategoryCode = \" \" // GetProductPrices Get a list of product item prices for a specific product // package type and a specific set of price category code / product item // capacity combinations.", "del_tokens": "// Get a list of product item prices for a specific product package type and // a specific set of price category code / product item capacity combinations.", "commit_type": "add"}
{"commit_tokens": ["Improve", "godoc", "for", "request", "function", "add", "info", "about", "form", "argument"], "add_tokens": "// request makes a request to Asana API, using method, at path, sending data or form with opt filter. // Only data or form could be sent at the same time. If both provided form will be omitted. // Also it's possible to do request with nil data and form.", "del_tokens": "// request makes a request to Asana API, using method, at path, sending data with opt filter.", "commit_type": "improve"}
{"commit_tokens": ["Add", "simple", "comments", "to", "exported", "methods"], "add_tokens": "// Parse the php5 parser entrypoint positionBuilder = position . Builder { Positions : & positions } // ListGetFirstNodeComments returns comments of a first node in the list", "del_tokens": "positionBuilder = position . Builder { & positions }", "commit_type": "add"}
{"commit_tokens": ["adding", "cleaner", "template", "as", "well", "as", "better", "job", "name", "de", "-", "linter"], "add_tokens": "/ * * File Generated by enaml generator * / type { { . JobName } } struct { { { range $ key , $ value := . Elements } } { { $ value . ElementName } } { { $ value . ElementType } } ` + \"` \" + `yaml:\"{{$value.ElementYamlName}},omitempty\"` + \" \" + ` { { end } } } `", "del_tokens": "type { { . JobName } } struct { { { range $ key , $ value := . Elements } } { { $ value . ElementName } } { { $ value . ElementType } } ` + \"` \" + `yaml:\"{{$value.ElementYamlName}},omitempty\"` + \" \" + ` { { end } } } `", "commit_type": "add"}
{"commit_tokens": ["Add", "trace", "with", "filename", "and", "line", "num"], "add_tokens": "return resource . appendPrimaryKey ( resource . getMetas ( resource . attrs . editAttrs ) ) return resource . appendPrimaryKey ( resource . getMetas ( ) ) func ( resource * Resource ) appendPrimaryKey ( metas [ ] Meta ) [ ] Meta { primaryKeyMeta := Meta { base : resource , Name : \" \" , Type : \" \" , Value : func ( value interface { } , context * qor . Context ) interface { } {", "del_tokens": "return appendPrimaryKey ( resource . getMetas ( resource . attrs . editAttrs ) ) return appendPrimaryKey ( resource . getMetas ( ) ) func appendPrimaryKey ( metas [ ] Meta ) [ ] Meta { primaryKeyMeta := Meta { Name : \" \" , Type : \" \" , Value : func ( value interface { } , context * qor . Context ) interface { } {", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "path", "on", "bucket", ".", "GetHeader"], "add_tokens": "body , err := bucket . GetReader ( s . Path ( filepath ) )", "del_tokens": "func ( f * S3StorageFile ) Close ( ) error { return f . Close ( ) } body , err := bucket . GetReader ( filepath )", "commit_type": "add"}
{"commit_tokens": ["add", "docs", "remove", "extra", "new", "-", "line", "regenerate", "example", "READMEs"], "add_tokens": "\" \" : \" \", out = \" \\n \" + strings . Join ( lines , \" \\n \" )", "del_tokens": "\" \" : \" \\n \" , out = \" \\n \" + strings . Join ( lines , \" \\n \" ) + \" \\n \"", "commit_type": "add"}
{"commit_tokens": ["Add", "regex", "support", "on", "hosts"], "add_tokens": "if s [ i ] == c && ( len ( sep ) == 1 || s [ i : i + len ( sep ) ] == sep ) && ( i == 0 || s [ i - 1 ] != '\\\\' ) {", "del_tokens": "if s [ i ] == c && ( len ( sep ) == 1 || s [ i : i + len ( sep ) ] == sep ) {", "commit_type": "add"}
{"commit_tokens": ["change", "chan", "bool", "to", "chan", "struct", "{}", "for", "notification", "remove", "unused", "functions", "change", "functions", "names", "to", "match", "conventions", "."], "add_tokens": "stop chan struct { } defer c . RUnlock ( ) c . stop = make ( chan struct { } )", "del_tokens": "stop chan bool defer c . RUnlock ( ) c . stop = make ( chan bool )", "commit_type": "change"}
{"commit_tokens": ["Add", "ActiveEnv", "global", "and", "remove", "exported", "funcs"], "add_tokens": "// ActiveEnv is the environment mode currently set by \"default_env\" in config.toml // or APPNAME_ENV environment variable. This mode indicates what section of // config variables to to load into the config structs. var ActiveEnv string AppPath = getAppPath ( ) ActiveEnv = getActiveEnv ( AppPath ) // getActiveEnv attempts to get the config.toml and database.toml environment func getActiveEnv ( appPath string ) string { return \" \" return \" \" // getAppPath executes the git cmd \"git rev-parse --show-toplevel\" to obtain func getAppPath ( ) string {", "del_tokens": "AppPath = GetAppPath ( ) // GetActiveEnv attempts to get the config.toml and database.toml environment func GetActiveEnv ( appPath string ) string { log . Fatal ( \" \" , err ) log . Fatal ( \" \" , err ) // GetAppPath executes the git cmd \"git rev-parse --show-toplevel\" to obtain func GetAppPath ( ) string { if len ( AppPath ) > 0 { return AppPath }", "commit_type": "add"}
{"commit_tokens": ["fix", "debug", "and", "default", "loggers"], "add_tokens": "case priority == \" \" :", "del_tokens": "case priority == \" \" :", "commit_type": "fix"}
{"commit_tokens": ["add", "error", "check", "to", "fmt", ".", "Fprintf"], "add_tokens": "if _ , err := fmt . Fprintf ( p . w , format , a ... ) ; err != nil { panic ( err ) }", "del_tokens": "fmt . Fprintf ( p . w , format , a ... )", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "for", "RSA", "public", "key"], "add_tokens": "pubKeyBytes , err := x509 . MarshalPKIXPublicKey ( publicKey ( rsaKey ) ) return fmt . Errorf ( \" \" , err ) sshPubKey , err := ssh . NewPublicKey ( publicKey ( rsaKey ) )", "del_tokens": "fmt . Printf ( \" \" , keyPemBlock . Type ) fmt . Printf ( \" \" ) pubKeyBytes , err := x509 . MarshalPKIXPublicKey ( rsaKey . PublicKey ) return fmt . Errorf ( \" \\n \\n \\n \\n \\n \" , rsaKey . PublicKey , rsaKey . PublicKey , rsaKey . PublicKey , err , keyPemBlock . Type ) sshPubKey , err := ssh . NewPublicKey ( rsaKey . PublicKey )", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "new", "release", "when", "updating", "the", "config"], "add_tokens": "r . Handle ( \" \" , \" \" , & PatchConfigs { e . AppsService , e . ReleasesService , e . ConfigsService } ) // Update an app config AppsService AppsService ReleasesService ReleasesService ConfigsService ConfigsService // Find app // Update the config // Find current release r , err := h . ReleasesService . Head ( a ) if err != nil { return http . StatusInternalServerError , nil , err } // If there is an existing release, create a new one if r != nil { // Create new release based on new config and old slug _ , err = h . ReleasesService . Create ( a , c , r . Slug ) if err != nil { return http . StatusInternalServerError , nil , err } } if r == nil { return http . StatusNotFound , nil , nil }", "del_tokens": "r . Handle ( \" \" , \" \" , & PatchConfigs { e . AppsService , e . ConfigsService } ) // Update an app config AppsService AppsService ConfigsService ConfigsService", "commit_type": "create"}
{"commit_tokens": ["Add", "benchmark", "and", "test", "for", "limited", "reader"], "add_tokens": "\" \" limit bool limit : false , header : headerHG00096_1000 , lines : 1000 , } , { in : bamHG00096_1000 , limit : true , br , err := NewReader ( bytes . NewBuffer ( t . in ) , t . limit ) if err == egzip . NewBlock { continue } func BenchmarkRoundTrip ( b * testing . B ) { for i := 0 ; i < b . N ; i ++ { br , _ := NewReader ( bytes . NewBuffer ( bamHG00096_1000 ) , false ) var buf bytes . Buffer bw , _ := NewWriter ( & buf , br . Header ( ) . Clone ( ) ) for { r , err := br . Read ( ) if err != nil { break } bw . Write ( r ) } } }", "del_tokens": "br , err := NewReader ( bytes . NewBuffer ( t . in ) , false )", "commit_type": "add"}
{"commit_tokens": ["add", "license", "info", "to", "files"], "add_tokens": "// Copyright 2016 Joel Scoble and The JoeFriday authors. // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. var iData net . Interface var inf = & net . Info { Interfaces : make ( [ ] net . Interface , 0 , 4 ) } bldr . Reset ( ) data := inf . SerializeFlatBuilder ( bldr )", "del_tokens": "var iData net . Iface var inf = & net . Info { Interfaces : make ( [ ] net . Iface , 0 , 4 ) } data := net . Serialize ( inf , bldr )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "which", "handling", "of", "new", "Export", "s", "naming", "convention", "is", "not", "called"], "add_tokens": "err = ReceiveOCN ( c , obj , queueName , path )", "del_tokens": "err = receiveOCN ( c , obj , queueName , path )", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "couple", "more", "report", "card", "issues"], "add_tokens": "// Package commandeer sets up command line flags based on the fields and field // tags of a struct. It helps ease common pains of CLI app development by // allowing you to unobtrusively define flags in a library package while having // a tiny main package which calls commandeer.Run* or commandeer.Flags. 'h' : { } , // \"h\" is always used for help, so we can't set it.", "del_tokens": "// commandeer sets up command line flags based on the fields and field tags of a // struct. It helps ease common pains of CLI app development by allowing you to // unobtrusively define flags in a library package while having a tiny main // package which calls commandeer.Run* or commandeer.Flags. 'h' : struct { } { } , // \"h\" is always used for help, so we can't set it.", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "bugs", "in", "LGTM", "detection", "by", "searching", "more", "events"], "add_tokens": "github_util \" \" events , err := github_util . GetAllEventsForPR ( client , opts . Org , opts . Project , * pr . Number )", "del_tokens": "events , _ , err := client . Issues . ListIssueEvents ( opts . Org , opts . Project , * pr . Number , & github . ListOptions { } )", "commit_type": "fix"}
{"commit_tokens": ["fix", "key", "order", "in", "place"], "add_tokens": "coloptKey", "del_tokens": "coloptKey", "commit_type": "fix"}
{"commit_tokens": ["add", "customize", "file", "extension", "to", "goathtml"], "add_tokens": "extension string func NewProvider ( fs filesystem . Filespace , layoutPath , viewPath , extension string , funcs template . FuncMap ) * Provider { extension : extension , return strings . HasSuffix ( subPath , provider . extension )", "del_tokens": "func NewProvider ( fs filesystem . Filespace , layoutPath , viewPath string , funcs template . FuncMap ) * Provider { return strings . HasSuffix ( subPath , goathtml . FileExtension )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "GUID", "ToString", "."], "add_tokens": "return fmt . Sprintf ( \" \" , g [ 3 ] , g [ 2 ] , g [ 1 ] , g [ 0 ] , g [ 5 ] , g [ 4 ] , g [ 7 ] , g [ 6 ] , g [ 8 : 10 ] , g [ 10 : ] )", "del_tokens": "return fmt . Sprintf ( \" \" , g [ 3 ] , g [ 2 ] , g [ 1 ] , g [ 0 ] , g [ 5 ] , g [ 4 ] , g [ 7 ] , g [ 6 ] , g [ 8 : 10 ] , g [ 10 : ] )", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "func", "of", "getting", "system", "and", "metrics", "snapshot", "by", "pid"], "add_tokens": "\" \" Leader * Pid State * State System * System MetricsSnapshot * MetricsSnapshot Http * http . Client Http : httpClient ,", "del_tokens": "\" \" Leader * Pid State * State Http * http . Client Http : httpClient ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "PrimitiveItemTypes", "and", "ItemTypes", "returned", "from", "value", "()", "in", "polymorphic", "properties"], "add_tokens": "if r . StringArray != nil { return r . StringArray if r . IAMPolicyDocumentArray != nil { return r . IAMPolicyDocumentArray", "del_tokens": "if r . String != nil { return r . String if r . IAMPolicyDocument != nil { return r . IAMPolicyDocument", "commit_type": "fix"}
{"commit_tokens": ["Move", "callback", "data", "pool", "back", "into", "main", "package"], "add_tokens": "package yara pool := makecbPool ( 32 )", "del_tokens": "package callbackdata pool := MakePool ( 32 )", "commit_type": "move"}
{"commit_tokens": ["add", "format", "support", "for", "termlog"], "add_tokens": "func xmlToConsoleLogWriter ( filename string , props [ ] xmlProperty , enabled bool ) ( * ConsoleLogWriter , bool ) {", "del_tokens": "func xmlToConsoleLogWriter ( filename string , props [ ] xmlProperty , enabled bool ) ( ConsoleLogWriter , bool ) {", "commit_type": "add"}
{"commit_tokens": ["use", "Go", "MPD", "server", "for", "tests"], "add_tokens": "package mpd func serve ( network , addr string , listening chan bool ) { ln , err := net . Listen ( network , addr ) listening <- true", "del_tokens": "package main type Attrs map [ string ] string func main ( ) { ln , err := net . Listen ( \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["change", "Sqlite3", "dialect", "to", "unexported", "."], "add_tokens": "type sqlite3 struct { d := & sqlite3 { } func ( d * sqlite3 ) SqlType ( f interface { } , size int ) string { func ( d * sqlite3 ) SetModelValue ( value reflect . Value , field reflect . Value ) error { func ( d * sqlite3 ) IndexExists ( mg * Migration , tableName string , indexName string ) bool { func ( d * sqlite3 ) ColumnsInTable ( mg * Migration , table interface { } ) map [ string ] bool { func ( d * sqlite3 ) PrimaryKeySql ( isString bool , size int ) string {", "del_tokens": "type Sqlite3 struct { d := & Sqlite3 { } func ( d * Sqlite3 ) SqlType ( f interface { } , size int ) string { func ( d * Sqlite3 ) SetModelValue ( value reflect . Value , field reflect . Value ) error { func ( d * Sqlite3 ) IndexExists ( mg * Migration , tableName string , indexName string ) bool { func ( d * Sqlite3 ) ColumnsInTable ( mg * Migration , table interface { } ) map [ string ] bool { func ( d * Sqlite3 ) PrimaryKeySql ( isString bool , size int ) string {", "commit_type": "change"}
{"commit_tokens": ["Fix", "a", "couple", "of", "typos", "."], "add_tokens": "// Map creates a shrink by applying a converter to each element of a shrink", "del_tokens": "// Map creates a shrink by a appling a converter to each element of a shrink", "commit_type": "fix"}
{"commit_tokens": ["add", "stats", "and", "events", "collection"], "add_tokens": "_ \" \" \" \" _ \" \" \" \" _ \" \" \" \" \" \" \" \" Dogstatsd string `conf:\"dogstatsd\" help:\"address of a dogstatsd agent to send metrics to\"` if len ( config . Dogstatsd ) != 0 { dd := datadog . NewClient ( datadog . ClientConfig { Address : config . Dogstatsd , } ) defer dd . Close ( ) } errchan <- http . ListenAndServe ( addr , httpstats . NewHandler ( nil , httpevents . NewHandler ( nil , nsqlookup . HTTPHandler { } ) ) ) errchan <- netx . ListenAndServe ( addr , netstats . NewHandler ( nil , netevents . NewHandler ( nil , nsqlookup . TCPHandler { } ) ) )", "del_tokens": "errchan <- http . ListenAndServe ( addr , nsqlookup . HTTPHandler { } ) errchan <- netx . ListenAndServe ( addr , nsqlookup . TCPHandler { } )", "commit_type": "add"}
{"commit_tokens": ["make", "application", "name", "and", "path", "exportable"], "add_tokens": "fmt . Println ( AppName + \" \" ) fmt . Println ( AppName + \" \" ) fmt . Println ( AppName + \" \" ) fmt . Printf ( AppName + \" \\n \" , process . Pid ) fmt . Println ( \" \" + AppName + \" \" ) fmt . Print ( \" \" + AppName + \" \" ) fmt . Print ( \" \" + AppName + \" \" )", "del_tokens": "fmt . Println ( Name + \" \" ) fmt . Println ( Name + \" \" ) fmt . Println ( Name + \" \" ) fmt . Printf ( Name + \" \\n \" , process . Pid ) fmt . Println ( \" \" + Name + \" \" ) fmt . Print ( \" \" + Name + \" \" ) fmt . Print ( \" \" + Name + \" \" )", "commit_type": "make"}
{"commit_tokens": ["Remove", "challenge", "pre", "-", "checks", "."], "add_tokens": "if solver , ok := c . solvers [ auth . Challenges [ idx ] . Type ] ; ok {", "del_tokens": "CanSolve ( domain string ) bool if solver , ok := c . solvers [ auth . Challenges [ idx ] . Type ] ; ok && ( c . devMode || solver . CanSolve ( domain ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "stopping", "MQTT", "RPC", "."], "add_tokens": "\" \" sync . Mutex active bool quit chan struct { } active : false , mqttRpc . Lock ( ) defer mqttRpc . Unlock ( ) if mqttRpc . active { return } mqttRpc . active = true mqttRpc . quit = make ( chan struct { } ) } , mqttRpc . subscriptionTopic ( ) ) func ( mqttRpc * MQTTRPCServer ) Stop ( ) { mqttRpc . Lock ( ) defer mqttRpc . Unlock ( ) if ! mqttRpc . active { return } close ( mqttRpc . quit ) } func ( mqttRpc * MQTTRPCServer ) subscriptionTopic ( ) string { return mqttRpc . prefix + \" \" } select { case <- mqttRpc . quit : mqttRpc . client . Unsubscribe ( mqttRpc . subscriptionTopic ( ) ) return case msg := <- mqttRpc . messageCh : mqttRpc . handleMessage ( msg ) }", "del_tokens": "} , mqttRpc . prefix + \" \" ) mqttRpc . handleMessage ( <- mqttRpc . messageCh )", "commit_type": "implement"}
{"commit_tokens": ["remove", "the", "temporary", "source", "file", "if", "we", "copied", "byte", "by", "byte", "."], "add_tokens": "// Try to rename generated source. // If the rename failed (might do so due to temporary file residing on a // different device), try to copy byte by byte. defer func ( ) { rc . Close ( ) os . Remove ( src ) // ignore the error, source is in tmp. } ( ) os . Remove ( dest )", "del_tokens": "// Try to rename generated source ... // ... if the rename failed (might do so due to temporary file residing on a // different device) try to copy byte by byte. defer rc . Close ( ) _ = os . Remove ( dest )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "golint", "and", "go", "tool", "vet", "errors"], "add_tokens": "// Parse parses the string representation of path template func Parse ( tmpl string ) ( Compiler , error ) {", "del_tokens": "func Parse ( tmpl string ) ( template , error ) { return strings . Join ( components , \" \" ) , nil", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "Centralized", "Logging", "logic"], "add_tokens": "// --------- // |----------> | console | // Addding this check for when you are doing centralized logging | --------- // i.e. ----------------- ----------------- ------------- -------- // | app log handler | -- json --> | central log app | -- unmarshal json to Entry -> | log handler | --> | syslog | // ----------------- ----------------- ------------- -------- // | --------- // |----------> | DataDog | // --------- if e . WG == nil { e . WG = new ( sync . WaitGroup ) }", "del_tokens": "// need to dereference as e is put back into the pool // and could be reused before the log has been written // entry := *e", "commit_type": "add"}
{"commit_tokens": ["Use", "type", "int", "for", "Config", "Timeout"], "add_tokens": "Timeout int Timeout : time . Duration ( cfg . Timeout ) * time . Second ,", "del_tokens": "Timeout time . Duration Timeout : cfg . Timeout * time . Second ,", "commit_type": "use"}
{"commit_tokens": ["Update", "the", "crufty", "kubernetes", "code", "because", "they", "keep", "breaking", "the", "interface", "...."], "add_tokens": "api \" \" lb := api . LabelSelector { selector } fd := api . FieldSelector { fields . Everything ( ) } services , err := c . client . Services ( c . namespace ) . List ( api . ListOptions { LabelSelector : lb , FieldSelector : fd } ) lb := api . LabelSelector { labels . Everything ( ) } fd := api . FieldSelector { fields . Everything ( ) } rsp , err := c . client . Services ( c . namespace ) . List ( api . ListOptions { LabelSelector : lb , FieldSelector : fd } )", "del_tokens": "services , err := c . client . Services ( c . namespace ) . List ( selector , fields . Everything ( ) ) rsp , err := c . client . Services ( c . namespace ) . List ( labels . Everything ( ) , fields . Everything ( ) )", "commit_type": "update"}
{"commit_tokens": ["Add", "EnvironMap", "()", "that", "converts", "os", ".", "Environ", "()", "output", "to", "a", "map"], "add_tokens": "import ( \" \" \" \" ) // EnvironMap returns the current environment variables as a map. func EnvironMap ( ) map [ string ] string { return environToMap ( os . Environ ( ) ) } func environToMap ( environ [ ] string ) map [ string ] string { ret := make ( map [ string ] string ) for _ , v := range environ { parts := strings . SplitN ( v , \" \" , 2 ) ret [ parts [ 0 ] ] = parts [ 1 ] } return ret }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Make", "file", "and", "folder", "permissions", "configurable"], "add_tokens": "// FilePerms is used to set the permissions on the golden fixture files. FilePerms os . FileMode = 0644 // DirPerms is used to set the permissions on the golden fixture folder. DirPerms os . FileMode = 0755 err := ioutil . WriteFile ( goldenFileName ( name ) , actualData , FilePerms ) err = os . Mkdir ( FixtureDir , DirPerms )", "del_tokens": "err := ioutil . WriteFile ( goldenFileName ( name ) , actualData , 0644 ) err = os . Mkdir ( FixtureDir , 0755 )", "commit_type": "make"}
{"commit_tokens": ["Remove", "leading", "/", "in", "mux", "path", "binding"], "add_tokens": "for pattern != \" \" && pattern [ 0 ] == '/' { pattern = pattern [ 1 : ] }", "del_tokens": "\" \" // Return the canonical path for p, eliminating . and .. elements. func cleanPath ( p string ) string { if p == \" \" { return \" \" } if p [ 0 ] != '/' { p = \" \" + p } np := path . Clean ( p ) // path.Clean removes trailing slash except for root; // put the trailing slash back if necessary. if p [ len ( p ) - 1 ] == '/' && np != \" \" { np += \" \" } return np }", "commit_type": "remove"}
{"commit_tokens": ["fixed", "wrong", "json", "tag", "for", "RespUserInteractive", "Session", "param"], "add_tokens": "Session string `json:\"session\"`", "del_tokens": "Session string `json:\"string\"`", "commit_type": "fix"}
{"commit_tokens": ["Fix", "exchange", "not", "being", "created", "when", "producing", "message"], "add_tokens": "Payload [ ] byte // ContentType the message content-type. ContentType string if err := r . ch . ExchangeDeclare ( m . Exchange , m . Kind , r . config . Durable , false , false , false , nil ) ; err != nil { if m . ContentType == \" \" { m . ContentType = \" \" } ContentType : m . ContentType , Body : m . Payload ,", "del_tokens": "\" \" Payload interface { } body , err := json . Marshal ( m . Payload ) if err != nil { ContentType : \" \" , Body : body ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "default", "notify", "implementation", "stub", "-", "demux"], "add_tokens": "global . Watch ( name , c , events ... ) global . Stop ( c ) var global = demux { tree : make ( map [ string ] interface { } ) ,", "del_tokens": "impl . Watch ( name , c , events ... ) impl . Stop ( c ) var impl interface { Watch ( string , chan <- EventInfo , ... Event ) Stop ( chan <- EventInfo )", "commit_type": "add"}
{"commit_tokens": ["Making", "a", "lot", "of", "headway", ".", "Fixed", "a", "bug", "in", "tinyint", "decoding", ".", "Added", "more", "tests", ".", "Better", "function", "docs"], "add_tokens": "// Here we have to get the marker as an int to check and see // if it's a TINYINT var markerInt int8 binary . Read ( bytes . NewBuffer ( [ ] byte { marker } ) , binary . BigEndian , & markerInt ) case markerInt >= - 16 && markerInt <= 127 :", "del_tokens": "case int ( marker ) >= - 16 && int ( marker ) <= 127 :", "commit_type": "make"}
{"commit_tokens": ["Fix", "PubSubClient", "connection", "pool", "management", "."], "add_tokens": "numReplies , err := strconv . ParseInt ( string ( line [ 1 : ] ) , 10 , 64 ) if err != nil { return nil , err } for i := int64 ( 0 ) ; i < numReplies ; i ++ {", "del_tokens": "\" \" for { if err == io . EOF { break }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "examples", "web", ">", "website"], "add_tokens": "e . Index ( \" \" ) e . Favicon ( \" \" ) e . Static ( \" \" , \" \" )", "del_tokens": "e . Index ( \" \" ) e . Favicon ( \" \" ) e . Static ( \" \" , \" \" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "0", "indexed", "captures", "."], "add_tokens": "i64 , err := strconv . ParseInt ( string ( data [ 2 : len ( data ) - 1 ] ) , 16 , 64 )", "del_tokens": "i64 , err := strconv . ParseInt ( string ( data [ 2 : len ( data ) - 1 ] ) , 16 , 32 )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "unmarshaling", "on", "ReturnOld", "/", "New", "for", "multidocument", "operations"], "add_tokens": "if doc . Kind ( ) != reflect . Ptr { if update . Kind ( ) != reflect . Ptr { if doc . Kind ( ) != reflect . Ptr {", "del_tokens": "if ! doc . Kind ( ) != reflect . Ptr { if ! update . Kind ( ) != reflect . Ptr { if ! doc . Kind ( ) != reflect . Ptr {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "readme", "and", "example", "tests", "."], "add_tokens": "defer profile . Start ( ) . Stop ( ) } func ExampleMemProfile ( ) { defer profile . Start ( profile . MemProfile ) . Stop ( ) } func ExampleNoShutdownHook ( ) { // start a CPU profileri with a custom path. defer profile . Start ( profile . CPUProfile , profile . ProfilePath ( \" \" ) , profile . NoShutdownHook ) . Stop ( )", "del_tokens": "defer profile . Start ( profile . CPUProfile ) . Stop ( )", "commit_type": "update"}
{"commit_tokens": ["Add", "several", "negative", "tests", "for", "encoding", "."], "add_tokens": "// opaqueStruct is used to test handling of uint8 slices and arrays. type opaqueStruct struct { Slice [ ] uint8 `xdropaque:\"false\"` Array [ 1 ] uint8 `xdropaque:\"false\"` }", "del_tokens": "// opaqueStruct is used to test handling of uint8 slices and arrays. type opaqueStruct struct { Slice [ ] uint8 `xdropaque:\"false\"` Array [ 1 ] uint8 `xdropaque:\"false\"` }", "commit_type": "add"}
{"commit_tokens": ["Remove", "basic", "auth", "since", "we", "now", "have", "proper", "security", "examples", "."], "add_tokens": "service . LogInfo ( \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" )", "del_tokens": "h = handleSecurity ( \" \" , h ) service . LogInfo ( \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" )", "commit_type": "remove"}
{"commit_tokens": ["implement", "directory", "changing", "in", "swift", "driver"], "add_tokens": "path = scoped_path ( driver . user , path ) if path == ( \" \" + driver . user ) { return true } object , _ , err := driver . connection . Object ( driver . container , path ) if err != nil { return false } return object . ContentType == \" \" path = scoped_path ( driver . user , path ) path = scoped_path ( driver . user , path )", "del_tokens": "return false path = scoped_path_with_trailing_slash ( driver . user , path ) path = scoped_path_with_trailing_slash ( driver . user , path )", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "pre", "defined", "func"], "add_tokens": "bf . WriteString ( e . opts . DelimLeft ) bf . WriteString ( preDefinedFuncNameHTML ) bf . WriteString ( space ) bf . WriteString ( doubleQuote ) bf . WriteString ( doubleQuote ) bf . WriteString ( e . opts . DelimRight )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Move", "files", "view", "templates", "to", "media", "library"], "add_tokens": "if meta . GetFormattedValuer ( ) == nil { meta . SetFormattedValuer ( func ( value interface { } , context * qor . Context ) interface { } { return utils . Stringify ( meta . GetValuer ( ) ( value , context ) ) } ) } for _ , gopath := range strings . Split ( os . Getenv ( \" \" ) , \" \" ) { admin . RegisterViewPath ( path . Join ( gopath , \" \" ) ) }", "del_tokens": "if meta , ok := meta . ( * admin . Meta ) ; ok { meta . SetFormattedValuer ( func ( value interface { } , context * qor . Context ) interface { } { return utils . Stringify ( meta . GetValuer ( ) ( value , context ) ) } ) } } func ( Base ) ConfigureQorMeta ( meta resource . Metaor ) {", "commit_type": "move"}
{"commit_tokens": ["Add", "trailing", "newline", "elision", "{{", "...", "}}", "\\"], "add_tokens": "itemField // alphanumeric identifier starting with '.' itemIdentifier // alphanumeric identifier not starting with '.' itemLeftDelim // left action delimiter itemLeftParen // '(' inside action itemNumber // simple number, including imaginary itemPipe // pipe symbol itemRawString // raw quoted string (includes quotes) itemRightDelim // right action delimiter itemElideNewline // elide newline after right delim itemRightParen // ')' inside action itemSpace // run of spaces separating arguments itemString // quoted string (includes quotes) itemText // plain text itemVariable // variable starting with '$', such as '$' or '$1' or '$hello' if l . peek ( ) == '\\\\' { l . pos ++ l . emit ( itemElideNewline ) } if strings . HasPrefix ( l . input [ l . pos : ] , l . rightDelim + \" \\\\ \" ) || strings . HasPrefix ( l . input [ l . pos : ] , l . rightDelim ) {", "del_tokens": "itemField // alphanumeric identifier starting with '.' itemIdentifier // alphanumeric identifier not starting with '.' itemLeftDelim // left action delimiter itemLeftParen // '(' inside action itemNumber // simple number, including imaginary itemPipe // pipe symbol itemRawString // raw quoted string (includes quotes) itemRightDelim // right action delimiter itemRightParen // ')' inside action itemSpace // run of spaces separating arguments itemString // quoted string (includes quotes) itemText // plain text itemVariable // variable starting with '$', such as '$' or '$1' or '$hello' if strings . HasPrefix ( l . input [ l . pos : ] , l . rightDelim ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "broken", "import", "path", "making", "go", "test", "work", "with", "the", "sample", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "same", "MultiError", "version", "from", "the", "App", "Engine", "SDK", "."], "add_tokens": "s , n := \" \" , 0 for _ , e := range m { if e != nil { if n == 0 { s = e . Error ( ) } n ++ switch n { return fmt . Sprintf ( \" \" , s , n - 1 )", "del_tokens": "s := \" \" for k , v := range m { if v != nil && k == 0 { s = v . Error ( ) switch len ( m ) { return fmt . Sprintf ( \" \" , s , len ( m ) - 1 )", "commit_type": "use"}
{"commit_tokens": ["fix", "tests", "for", "Go", "tip"], "add_tokens": "// Looks like Go tip @ 2016-07-20 support map[int]int! // { // \"\", map[int]int{1: 2}, // ``, NewError(-32603, \"json: unsupported type: map[int]int\"), // }, // Looks like Go tip @ 2016-07-20 support map[int]int! // { // \"\", new(map[int]int), // ``, NewError(-32603, \"json: unsupported type: map[int]int\"), // },", "del_tokens": "{ \" \" , map [ int ] int { 1 : 2 } , `` , NewError ( - 32603 , \" \" ) , } , { \" \" , new ( map [ int ] int ) , `` , NewError ( - 32603 , \" \" ) , } ,", "commit_type": "fix"}
{"commit_tokens": ["Make", "a", "copy", "in", "Histogram", "export"], "add_tokens": "Counts : append ( [ ] int64 ( nil ) , h . counts ... ) , // copy // Import returns a new Histogram populated from the Snapshot data (which the // caller must stop accessing).", "del_tokens": "Counts : h . counts , // Import returns a new Histogram populated from the Snapshot data.", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "for", "import", "values"], "add_tokens": "const sliceWidth = 1048576", "del_tokens": "const sliceWidth = 1048576 const sliceWidth = 1048576", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "condition", "in", "client"], "add_tokens": "RepliesCh : make ( chan [ ] byte , 10 ) , return status . Err ( )", "del_tokens": "done := make ( chan error , 1 ) Done : done , Writer : c . c . Writer ( ) , } else if err := status . Err ( ) ; err != nil { return err return <- done", "commit_type": "fix"}
{"commit_tokens": ["add", "test", "cases", "for", "GetDataBuilder"], "add_tokens": "if b . decompress { if payload , err := b . client . compressionProvider . Decompress ( path , data ) ; err != nil { return nil , err } else { data = payload } }", "del_tokens": "} else if b . decompress { if data , err := b . client . compressionProvider . Decompress ( givenPath , payload ) ; err != nil { return nil , err } else { return data , nil }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "race", "issues", "on", "nodes"], "add_tokens": "n . RLock ( ) defer n . RUnlock ( ) var i int n . Parent . RLock ( ) n . Parent . RUnlock ( ) p = n . Parent . xpath ( stopAtDocument , stopAtID )", "del_tokens": "i := 0 p = n . Parent . xpath ( stopAtDocument , stopAtID )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "andCardinality", "orCardinality", "and", "Intersects", "."], "add_tokens": "func ( bc * bitmapContainer ) intersects ( a container ) bool { switch a . ( type ) { case * arrayContainer : return bc . intersectsArray ( a . ( * arrayContainer ) ) case * bitmapContainer : return bc . intersectsBitmap ( a . ( * bitmapContainer ) ) } return nil } func ( bc * bitmapContainer ) intersectsArray ( value2 * arrayContainer ) bool { c := value2 . getCardinality ( ) for k := 0 ; k < c ; k ++ { v := value2 . content [ k ] if bc . contains ( v ) { return true } } return false } func ( bc * bitmapContainer ) intersectsBitmap ( value2 * bitmapContainer ) bool { for k := 0 ; k < len ( bc . bitmap ) ; k ++ { if ( bc . bitmap [ k ] & value2 . bitmap [ k ] ) != 0 { return true } } return false }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "parsing", "of", "FEN", "tag", "to", "decodePGN", "function"], "add_tokens": "gameFuncs := [ ] func ( * Game ) { } for _ , tp := range tagPairs { if strings . ToLower ( tp . Key ) == \" \" { fenFunc , err := FEN ( tp . Value ) if err != nil { return nil , fmt . Errorf ( \" \" , err . Error ( ) , tp . Key ) } gameFuncs = append ( gameFuncs , fenFunc ) break } } gameFuncs = append ( gameFuncs , TagPairs ( tagPairs ) ) g := NewGame ( gameFuncs ... )", "del_tokens": "g := NewGame ( TagPairs ( tagPairs ) )", "commit_type": "add"}
{"commit_tokens": ["fix", "up", "tests", "that", "started", "failing", "after", "changing", "identify", "code"], "add_tokens": "if plist == nil || len ( plist ) == 0 { continue", "del_tokens": "if len ( plist ) == 0 {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "reflect", "clearer", "understanding", "of", "spec"], "add_tokens": "func TestSpecNotCachedWithoutValidatorOrExpiration ( t * testing . T ) { assert . Equal ( t , \" \" , client . get ( \" \" ) . cacheStatus ) assert . Equal ( t , 2 , upstream . requests ) assert . Equal ( t , \" \" , client . get ( \" \" ) . cacheStatus )", "del_tokens": "func TestSpecNoCachingByDefault ( t * testing . T ) { upstream . LastModified = upstream . Now . AddDate ( - 1 , 0 , 0 ) assert . Equal ( t , \" \" , client . get ( \" \" ) . cacheStatus )", "commit_type": "update"}
{"commit_tokens": ["Moved", "parser", "away", "from", "types", "and", "filesystem", "functions"], "add_tokens": "// TaskList is an array of Tasks type TaskList [ ] Task", "del_tokens": "\" \" type taskList [ ] Task // LoadDogFile finds a Dogfile in disk, parses YAML and returns a map func LoadDogFile ( ) ( tm map [ string ] Task , err error ) { var dat [ ] byte var tl taskList dat , err = ioutil . ReadFile ( \" \" ) if err != nil { return } err = yaml . Unmarshal ( dat , & tl ) if err != nil { return } // TODO create the map while reading the Dogfile tm = make ( map [ string ] Task ) for _ , t := range tl { tm [ t . Name ] = t } return }", "commit_type": "move"}
{"commit_tokens": ["Allow", "NewPackageLogger", "to", "specify", "it", "s", "own", "io", ".", "Writer", "interface"], "add_tokens": "func NewPackageLogger ( out io . Writer , pkg string ) * Logger { Logger : log . New ( out , \" \" + pkg + \" \" , 0 ) ,", "del_tokens": "func NewPackageLogger ( pkg string ) * Logger { Logger : log . New ( os . Stdout , \" \" + pkg + \" \" , 0 ) ,", "commit_type": "allow"}
{"commit_tokens": ["add", "api", "to", "get", "status", "and", "enable", "/", "disable"], "add_tokens": "\" \" \" \" LogLevel string IPv6 bool ApiUrl string Services [ ] * Service apiListener net . Listener fields data . Fields if n . ApiUrl == \" \" { n . ApiUrl = \" \" } n . startApi ( ) n . stopApi ( )", "del_tokens": "LogLevel string IPv6 bool Services [ ] * Service", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "hashing", "option", "for", "backwards", "compatibility"], "add_tokens": "passwordAlgo string // The hashing algorithm to utilize default: \"any\" allowed: (\"sha256\", \"bcrypt\", \"any\") // Default password algorithm is \"bcrypt\". // These are possible values: \"sha256\", \"bcrypt\", \"any\" // If algo is \"any\", bcrypt will be used when hashing and both // valid bcrypt and sha256 hashes will be allowed when comparing. case \" \" , \" \" , \" \" : case \" \" , \" \" : // Check if a given password(+username) is correct func ( state * UserState ) correct_sha256 ( hash , username , password string ) bool { // prevents timing attack return subtle . ConstantTimeCompare ( [ ] byte ( hash ) , [ ] byte ( state . HashPassword ( username , password ) ) ) == 1 } // Check if a given password is correct func correct_bcrypt ( hash , password string ) bool { // prevents timing attack return bcrypt . CompareHashAndPassword ( [ ] byte ( hash ) , [ ] byte ( password ) ) == nil } return state . correct_sha256 ( hash , username , password ) return correct_bcrypt ( hash , password ) case \" \" : // only use for backwards compatibility return state . correct_sha256 ( hash , username , password ) || correct_bcrypt ( hash , password )", "del_tokens": "passwordAlgo string // The hashing algorithm to utilize default: \"bcrypt\" allowed: (\"sha256\", \"bcrypt\") // Default password algorithm is \"bcrypt\" options (\"sha256\", \"bcrypt\") case \" \" : state . passwordAlgo = algo case \" \" : case \" \" : // prevent timing attacks return subtle . ConstantTimeCompare ( [ ] byte ( hash ) , [ ] byte ( state . HashPassword ( username , password ) ) ) == 1 // prevents timing attack return bcrypt . CompareHashAndPassword ( [ ] byte ( hash ) , [ ] byte ( password ) ) == nil", "commit_type": "add"}
{"commit_tokens": ["Remove", "chula", "-", "tnc", "-", "2017", "because", "cannot", "find", "the", "license", "of", "it"], "add_tokens": "return LoadDict ( path . Join ( path . Dir ( filename ) , \" \" ) )", "del_tokens": "return LoadDict ( path . Join ( path . Dir ( filename ) , \" \" ) )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "miscellaneous", "spelling", "and", "grammar", "issues"], "add_tokens": "if _ , err := Connect ( \" \" , \" \" ) ; err != nats . ErrNoServers { if _ , err := Connect ( \" \" , \" \" , ConnectWait ( connectTime ) ) ; err != ErrConnectReqTimeout { if _ , err := Connect ( \" \" , \" \" , ConnectWait ( connectTime ) ) ; err != ErrConnectReqTimeout { // Check that durables cannot be subscribed to again by same client. // published on its subject.", "del_tokens": "if _ , err := Connect ( \" \" , \" \" ) ; err != nats . ErrNoServers { if _ , err := Connect ( \" \" , \" \" , ConnectWait ( connectTime ) ) ; err != ErrConnectReqTimeout { if _ , err := Connect ( \" \" , \" \" , ConnectWait ( connectTime ) ) ; err != ErrConnectReqTimeout { // Check that durables can not be subscribed to again by same client. // published on it's subject.", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "for", "router", "groups", "add", "Path", "method", "for", "router", "groups", "and", "add", "an", "event", "handler", "for", "debuging", "router"], "add_tokens": "import ( \" \" \" \" ) func ( r * routerGroup ) Path ( ) string { return filepath . Clean ( r . router . Path ( ) + r . prefix ) }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "fields", "to", "User"], "add_tokens": "Login string `json:\"login,omitempty\"` ID int `json:\"id,omitempty\"` AvatarURL string `json:\"avatar_url,omitempty\"` GravatarID string `json:\"gravatar_id,omitempty\"` URL string `json:\"url,omitempty\"` Name string `json:\"name,omitempty\"` Company string `json:\"company,omitempty\"` Blog string `json:\"blog,omitempty\"` Location string `json:\"location,omitempty\"` Email string `json:\"email,omitempty\"` Hireable bool `json:\"hireable,omitempty\"` Bio string `json:\"bio,omitempty\"` PublicRepos int `json:\"public_repos,omitempty\"` PublicGists int `json:\"public_gists,omitempty\"` Followers int `json:\"followers,omitempty\"` Following int `json:\"following,omitempty\"` HTMLURL string `json:\"html_url,omitempty\"` CreatedAt time . Time `json:\"created_at,omitempty\"` UpdatedAt time . Time `json:\"updated_at,omitempty\"` Type string `json:\"type,omitempty\"` // hypermedia relations FollowingURL string `json:\"following_url,omitempty\"` FollowersURL string `json:\"followers_url,omitempty\"` GistsURL string `json:\"gists_url,omitempty\"` StarredURL string `json:\"starred_url,omitempty\"` SubscriptionsURL string `json:\"subscriptions_url,omitempty\"` OrganizationsURL string `json:\"organizations_url,omitempty\"` ReposURL string `json:\"repos_url,omitempty\"` EventsURL string `json:\"events_url,omitempty\"` ReceivedEventsURL string `json:\"received_events_url,omitempty\"`", "del_tokens": "Login string `json:\"login,omitempty\"` ID int `json:\"id,omitempty\"` AvatarURL string `json:\"avatar_url,omitempty\"` GravatarID string `json:\"gravatar_id,omitempty\"` URL string `json:\"url,omitempty\"` Name string `json:\"name,omitempty\"` Company string `json:\"company,omitempty\"` Blog string `json:\"blog,omitempty\"` Location string `json:\"location,omitempty\"` Email string `json:\"email,omitempty\"` Hireable bool `json:\"hireable,omitempty\"` Bio string `json:\"bio,omitempty\"` PublicRepos int `json:\"public_repos,omitempty\"` PublicGists int `json:\"jsonpublic_gists,omitempty\"` Followers int `json:\"followers,omitempty\"` Following int `json:\"following,omitempty\"` HTMLURL string `json:\"html_url,omitempty\"` CreatedAt time . Time `json:\"created_at,omitempty\"` Type string `json:\"type,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "GetRouteMap", "()"], "add_tokens": "pResults := getNodeRoutes ( pn , pPrefix , 1 ) wResults := getNodeRoutes ( pn . wild , pPrefix + \" \" , 2 ) pResults = parseTree ( pn , pPrefix + \" \" , 2 ) wResults := getNodeRoutes ( cn . wild , wPrefix , 1 )", "del_tokens": "pResults := getNodeRoutes ( pn , pPrefix , 0 ) wResults := getNodeRoutes ( pn . wild , pPrefix + \" \" , 0 ) pResults = parseTree ( pn , pPrefix + \" \" , 1 ) wResults := getNodeRoutes ( cn . wild , wPrefix , 0 )", "commit_type": "add"}
{"commit_tokens": ["Added", "note", "about", "calling", "save", "before", "writing", "to", "response", "."], "add_tokens": "Also : Call Save before writing to the response , otherwise the session cookie will not be sent to the client . // Use the flash values.", "del_tokens": "// Just print the flash values. fmt . Fprint ( w , \" \" , flashes ) fmt . Fprint ( w , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "package", "comment"], "add_tokens": "flagPkgCmt = flag . String ( \" \" , \" \" , \" \\n \" ) var comment string if * flagPkgCmt != \" \" { comment = \" \\n \" + commentLines ( * flagPkgCmt ) } % s % s data := \" // comment lines prefixes each line in lines with \"// \". func commentLines ( lines string ) string { lines = \" \" + strings . Replace ( lines , \" \\n \" , \" \\n \" , - 1 ) return lines }", "del_tokens": "% s data := \"", "commit_type": "add"}
{"commit_tokens": ["Remove", "number", "format", "cache", "codes"], "add_tokens": "if ! includeDecimalDigits { return format", "del_tokens": "// numberFormats keeps a copy of all numberFormat instances that have been // loaded before, to prevent parsing a single number format string multiple // times. There is vey little danger of this list consuming too much memory, // since the data for each of these is pretty small in size, and the same // formats are used by multiple locales. numberFormats = map [ string ] * numberFormat { } numberFormatsNoDecimals = map [ string ] * numberFormat { } // processed := false // if includeDecimalDigits { // _, processed = numberFormats[pattern] // } else { // _, processed = numberFormatsNoDecimals[pattern] // } // if !processed { if includeDecimalDigits { numberFormats [ pattern ] = format } else { numberFormatsNoDecimals [ pattern ] = format } // } if includeDecimalDigits { return numberFormats [ pattern ] return numberFormatsNoDecimals [ pattern ]", "commit_type": "remove"}
{"commit_tokens": ["Added", "RR", "eviction", "and", "size", "bounds", "to", "cache"], "add_tokens": "cmax int // defaultCacheMax is used to bound limit the frontend cache const defaultCacheMax = 1024 // New will create a default sublist cmax : defaultCacheMax , // Common byte variables for wildcards and token separator. return r . ( [ ] interface { } ) // We use random eviction to bound the size of the cache. // RR is used for speed purposes here. if int ( s . cache . Count ( ) ) >= s . cmax { s . cache . RemoveRandom ( ) } break", "del_tokens": "return r . ( [ ] interface { } ) // FIXME: This can overwhelm memory, but can't find a fast enough solution. // LRU is too slow, LFU and time.Now() is also too slow. Can try PLRU or // possible 2-way, although 2-way also uses time. We could have a go routine // for getting time, then on a fetch we just &timeNow in an atomic way. break ;", "commit_type": "add"}
{"commit_tokens": ["Make", "deschedule", "safe", "to", "call", "multiple", "times"], "add_tokens": "if m . ticker != nil { m . ticker . Stop ( ) m . ticker = nil } select { case m . stopTick <- struct { } { } : default : }", "del_tokens": "m . ticker . Stop ( ) m . ticker = nil m . stopTick <- struct { } { }", "commit_type": "make"}
{"commit_tokens": ["Added", "resources", ".", "GetAll<ResourceName", ">", "(", "name", ")", "and", "resources", ".", "GetWithName<ResourceName", ">", "(", "name", "template", ")", "methods", "that", "make", "up", "for", "the", "lack", "of", "generics", "in", "Go", "and", "keep", "all", "casting", "within", "the", "Goformation", "library"], "add_tokens": "t1 := & resources . Template { t2 := & resources . Template { } functions := resources . GetAllAWSLambdaFunction ( t2 ) It ( \" \" , func ( ) { Expect ( functions ) . To ( HaveLen ( 1 ) ) } ) function , err := resources . GetWithNameAWSLambdaFunction ( \" \" , t2 ) It ( \" \" , func ( ) { Expect ( err ) . To ( BeNil ( ) ) Expect ( function ) . To ( BeAssignableToTypeOf ( & resources . AWSLambdaFunction { } ) ) } ) It ( \" \" , func ( ) { Expect ( function . Handler ) . To ( Equal ( \" \" ) ) } )", "del_tokens": ". \" \" t1 := & Template { t2 := & Template { }", "commit_type": "add"}
{"commit_tokens": ["Fix", "timeout", "on", "uploading", "big", "files"], "add_tokens": "timer := time . NewTimer ( c . ConnectTimeout ) reader := p . Body if reader != nil { reader = newWatchdogReader ( reader , c . Timeout , timer ) } req , err = http . NewRequest ( p . Operation , url . String ( ) , reader )", "del_tokens": "req , err = http . NewRequest ( p . Operation , url . String ( ) , p . Body ) timer := time . NewTimer ( c . ConnectTimeout ) reader := p . Body if reader != nil { reader = newWatchdogReader ( reader , c . Timeout , timer ) }", "commit_type": "fix"}
{"commit_tokens": ["add", "echo", "test", ";", "make", "echo", "example", "more", "compliant"], "add_tokens": "\" \" b := bufio . NewReader ( conn ) for { line , e := b . ReadBytes ( '\\n' ) if e != nil { break } conn . Write ( line ) }", "del_tokens": "\" \" io . Copy ( conn , conn )", "commit_type": "add"}
{"commit_tokens": ["Adding", "race", "flag", "to", "gexec", ".", "Build"], "add_tokens": "launcherPath , err := gexec . Build ( \" \" , \" \" )", "del_tokens": "launcherPath , err := gexec . Build ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Use", "1024", "-", "bit", "RSA", "keys"], "add_tokens": "p . PrivKey , p . PubKey , err = RandTestKeyPair ( 1024 )", "del_tokens": "p . PrivKey , p . PubKey , err = RandTestKeyPair ( 512 )", "commit_type": "use"}
{"commit_tokens": ["Fix", "unquoting", "of", "single", "quoted", "strings", "."], "add_tokens": "value , err := unquote ( t . Value ) func unquote ( s string ) ( string , error ) { quote := s [ 0 ] s = s [ 1 : len ( s ) - 1 ] out := \" \" for s != \" \" { value , _ , tail , err := strconv . UnquoteChar ( s , quote ) if err != nil { return \" \" , err } s = tail out += string ( value ) } return out , nil }", "del_tokens": "value , err := strconv . Unquote ( t . Value )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "evaluation", "of", "or", "operator", "in", "exec", ".", "go"], "add_tokens": "return CoerceBool ( left ) || CoerceBool ( right ) , nil", "del_tokens": "return CoerceBool ( left ) && CoerceBool ( right ) , nil", "commit_type": "fix"}
{"commit_tokens": ["Remove", "gratuitous", "and", "dangerous", "global", "variable"], "add_tokens": "var bufBack [ 4 ] byte", "del_tokens": "var bufBack [ 4 ] byte", "commit_type": "remove"}
{"commit_tokens": ["Moved", "regex", "to", "global", "scope", "to", "prevent", "re", "-", "evaluation", "on", "subsequent", "call", "modified", "test", "to", "ensure", "that", "we", "are", "testing", "solely", "the", "data", "URI", "functionality", "and", "that", "the", "helper", "isn", "t", "relying", "on", "other", "parts", "of", "the", "UGCPolicy", "."], "add_tokens": "// dataURIImagePrefix is used by AllowDataURIImages to define the acceptable // prefix of data URIs that contain common web image formats. // // This is not exported as it's not useful by itself, and only has value // within the AllowDataURIImages func dataURIImagePrefix = regexp . MustCompile ( `^image/(gif|jpeg|png|webp);base64,` , )", "del_tokens": "// !url.IsAbs() is permitted p . AllowRelativeURLs ( true ) dataURIImagePrefix := regexp . MustCompile ( `^image/(gif|jpeg|png|webp);base64,` , )", "commit_type": "move"}
{"commit_tokens": ["added", "parse", "-", "parameters", "-", "as", "-", "json", "property", "to", "hooks", "fixed", "some", "bugs", "in", "old", "code"], "add_tokens": "{ \" \" , map [ string ] interface { } { \" \" : map [ string ] interface { } { \" \" : [ ] interface { } { \" \" , \" \" , \" \" } } } , \" \" , true } , value , ok := ExtractParameterAsString ( tt . s , tt . params )", "del_tokens": "value , ok := ExtractParameter ( tt . s , tt . params )", "commit_type": "add"}
{"commit_tokens": ["Allow", "build", "configurations", "to", "specify", "metadata"], "add_tokens": "// bcWrapper is the API wrapper since the server wraps the resulting object. type bcWrapper struct { BuildConfig * BuildConfig `json:\"build_configuration\"` } func ( c * Client ) UploadBuildConfigVersion ( v * BuildConfigVersion , metadata map [ string ] interface { } , data io . Reader , size int64 ) error { log . Printf ( \" \" , v . Slug ( ) , size , metadata ) bodyData . Version . Metadata = metadata var bv bcCreate if err := decodeJSON ( response , & bv ) ; err != nil { if err := c . putFile ( bv . UploadPath , data , size ) ; err != nil { Metadata map [ string ] interface { } `json:\"metadata,omitempty\"` Builds [ ] BuildConfigBuild `json:\"builds\"`", "del_tokens": "func ( c * Client ) UploadBuildConfigVersion ( v * BuildConfigVersion , tpl io . Reader , size int64 ) error { log . Printf ( \" \" , v . Slug ( ) , size ) var data bcCreate if err := decodeJSON ( response , & data ) ; err != nil { if err := c . putFile ( data . UploadPath , tpl , size ) ; err != nil { // bcWrapper is the API wrapper since the server wraps the resulting object. type bcWrapper struct { BuildConfig * BuildConfig `json:\"build_configuration\"` } Builds [ ] BuildConfigBuild `json:\"builds\"`", "commit_type": "allow"}
{"commit_tokens": ["added", "support", "for", "frame", "compression"], "add_tokens": "db , err := sql . Open ( \" \" , \" \" )", "del_tokens": "db , err := sql . Open ( \" \" , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Improve", "panic", "msg", "for", "not", "registering", "render", "middleware"], "add_tokens": "return \" \"", "del_tokens": "return \" \"", "commit_type": "improve"}
{"commit_tokens": ["Fix", "possible", "panic", "in", "test", "waitgroup"], "add_tokens": "if wg != nil { wg . Add ( 2 ) }", "del_tokens": "wg . Add ( 1 ) wg . Add ( 1 )", "commit_type": "fix"}
{"commit_tokens": ["Add", "hclog", ".", "Fmt", "to", "make", "it", "easier", "when", "doing", "string", "formatting"], "add_tokens": "case Format : val = fmt . Sprintf ( st [ 0 ] . ( string ) , st [ 1 : ] ... ) switch sv := val . ( type ) { case error : // Check if val is of type error. If error type doesn't // implement json.Marshaler or encoding.TextMarshaler // then set val to err.Error() so that it gets marshaled switch sv . ( type ) { val = sv . Error ( ) case Format : val = fmt . Sprintf ( sv [ 0 ] . ( string ) , sv [ 1 : ] ... )", "del_tokens": "// Check if val is of type error. If error type doesn't // implement json.Marshaler or encoding.TextMarshaler // then set val to err.Error() so that it gets marshaled if err , ok := val . ( error ) ; ok { switch err . ( type ) { val = err . Error ( )", "commit_type": "add"}
{"commit_tokens": ["make", "widget", "basic", "support", "front", "-", "end", "edit"], "add_tokens": "return template . HTML ( fmt . Sprintf ( \" \\\" \\\" \\n \\n \" , w . nameForClass ( ) , result . String ( ) ) )", "del_tokens": "return template . HTML ( result . String ( ) )", "commit_type": "make"}
{"commit_tokens": ["Changed", "test", "to", "code", "compatible", "to", "original", "protobuf"], "add_tokens": "A , B * int32 M map [ uint32 ] * CipherArr } type CipherArr struct { V [ ] * CipherText ct := [ ] * CipherText { { } , { } } ca := & CipherArr { V : ct } M : map [ uint32 ] * CipherArr { 1 : ca } , //fmt.Println(hex.Dump(buf)) assert . Equal ( t , len ( msg . M [ 1 ] . V ) , len ( msg2 . M [ 1 ] . V ) ) }", "del_tokens": "A , B int M map [ uint32 ] [ ] CipherText cv := [ ] CipherText { { } , { } } M : map [ uint32 ] [ ] CipherText { 1 : cv } , assert . Equal ( t , len ( msg . M [ 1 ] ) , len ( msg2 . M [ 1 ] ) ) }", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "reflect", ".", "Type", "/", "Value", "to", "RemovePtr", "methods"], "add_tokens": "var v reflect . Type if rt , isType := t . ( reflect . Type ) ; isType { v = rt } else { v = reflect . TypeOf ( t ) } var v reflect . Value if rv , isValue := t . ( reflect . Value ) ; isValue { v = rv } else { v = reflect . ValueOf ( t ) }", "del_tokens": "v := reflect . TypeOf ( t ) v := reflect . ValueOf ( t )", "commit_type": "add"}
{"commit_tokens": ["Fix", "comments", "of", "callflow", "CRUD", "functions"], "add_tokens": "// Create creates the callflow remotely. // Update updates the call flow by overwriting it. // Delete deletes the CallFlow.", "del_tokens": "// CreateCallFlow creates the callflow remotely. // UpdateCallFlow updates the call flow by overwriting it. // DeleteCallFlow deletes the CallFlow.", "commit_type": "fix"}
{"commit_tokens": ["change", "the", "output", "a", "little", "bit"], "add_tokens": "fmt . Fprintf ( w , \" \\n \" , msg ) fmt . Fprintf ( w , \" \\n \" , msg )", "del_tokens": "fmt . Fprintf ( w , \" \\n \" , msg ) fmt . Fprintf ( w , \" \" , k , msg . Content )", "commit_type": "change"}
{"commit_tokens": ["Allow", "for", "custom", "HTTP", "client", "to", "be", "used"], "add_tokens": "\" \" client * http . Client func NewMetrics ( metricsURL , metricsPrefix string , client * http . Client , interval time . Duration , registry metrics . Registry , logger * log . Logger ) * SquareMetrics { client : client , if err != nil && err != io . EOF { resp , err := mb . client . Post ( mb . url , \" \" , bytes . NewReader ( raw ) ) if resp != nil {", "del_tokens": "func NewMetrics ( metricsURL , metricsPrefix string , interval time . Duration , registry metrics . Registry , logger * log . Logger ) * SquareMetrics { if err != nil { resp , err := http . Post ( mb . url , \" \" , bytes . NewReader ( raw ) ) if err == nil {", "commit_type": "allow"}
{"commit_tokens": ["add", "sleep", "and", "update", "README", ".", "md"], "add_tokens": "\" \" version string = \" \" // Sleep time.Sleep func Sleep ( tm float64 ) { time . Sleep ( time . Duration ( tm ) * time . Second ) }", "del_tokens": "version string = \" \"", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "slice", "param", "for", "HasSubtitles"], "add_tokens": "func ( c * Client ) HasSubtitles ( subs [ ] Subtitle ) ( bool , error ) { // Convert subs param to map[string]Subtitle, because OSDb. subMap := map [ string ] Subtitle { } for i , s := range subs { key := \" \" + strconv . Itoa ( i + 1 ) // keys are cd1, cd2, ... subMap [ key ] = s } args := [ ] interface { } { c . Token , & subMap }", "del_tokens": "func ( c * Client ) HasSubtitles ( subs map [ string ] Subtitle ) ( bool , error ) { args := [ ] interface { } { c . Token , & subs }", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "new", "generated", "walk", "the", "doc", "tree", "functionality"], "add_tokens": "for _ , f := range me . Fields { if bag . walkerTypes [ strings . Replace ( f . finalTypeName , \" \" , \" \" , - 1 ) ] { fc ++ ; walkBody += sfmt ( \" \\t \\n \" , f . Name ) } else if strings . HasPrefix ( f . finalTypeName , \" \" ) && bag . walkerTypes [ ustr . Replace ( f . finalTypeName , typeRenderRepls ) ] { walkBody += sfmt ( \" \\t \\n \" , f . Name ) } }", "del_tokens": "for _ , f := range me . Fields { if bag . walkerTypes [ f . finalTypeName ] { fc ++ ; walkBody += sfmt ( \" \\t \\n \" , f . finalTypeName ) } }", "commit_type": "fix"}
{"commit_tokens": ["use", "the", "same", "function", "signature", "as", "Set", ";", "Kind", "data", "is", "probably", "not", "used", "when", "deleting"], "add_tokens": "func ( p * JsonPointer ) Delete ( document interface { } ) ( interface { } , error ) { return document , is . outError", "del_tokens": "func ( p * JsonPointer ) Delete ( document interface { } ) ( interface { } , reflect . Kind , error ) { return is . getOutNode , is . getOutKind , is . outError", "commit_type": "use"}
{"commit_tokens": ["Allow", "reverse", "searches", "in", "IterateRange"], "add_tokens": "func ( t * IAVLTree ) IterateRange ( start , end [ ] byte , ascending bool , fn func ( key [ ] byte , value [ ] byte ) bool ) ( stopped bool ) { return t . root . traverseInRange ( t , start , end , ascending , func ( node * IAVLNode ) bool {", "del_tokens": "func ( t * IAVLTree ) IterateRange ( start , end [ ] byte , fn func ( key [ ] byte , value [ ] byte ) bool ) ( stopped bool ) { return t . root . traverseInRange ( t , start , end , func ( node * IAVLNode ) bool {", "commit_type": "allow"}
{"commit_tokens": ["Added", "AllowInsecure", "method", "to", "accept", "insecure", "HTTPS", "connections", "(", "i", ".", "e", ".", "to", "servers", "with", "self", "-", "signed", "or", "expired", "certificates", ")", ".", "You", "shouldn", "t", "use", "it", "but", "when", "you", "need", "it", "it", "s", "there", "."], "add_tokens": "\" \" var ( DefaultClient = & http . Client { } // we use our own default client, so we can change the TLS configuration ) // // Allow connections via HTTPS even if something is wrong with the certificate // (self-signed or expired) // func AllowInsecure ( insecure bool ) { if insecure { tr := & http . Transport { TLSClientConfig : & tls . Config { InsecureSkipVerify : true } , } DefaultClient . Transport = tr } else { DefaultClient . Transport = nil } } resp , err := DefaultClient . Get ( URLWithParams ( urlStr , params ) . String ( ) ) resp , err := DefaultClient . PostForm ( urlStr , URLWithParams ( urlStr , params ) . Query ( ) ) // // Allow connections via HTTPS even if something is wrong with the certificate // (self-signed or expired) // func ( self * HttpClient ) AllowInsecure ( insecure bool ) { if insecure { tr := & http . Transport { TLSClientConfig : & tls . Config { InsecureSkipVerify : true } , } self . client . Transport = tr } else { self . client . Transport = nil } }", "del_tokens": "resp , err := http . Get ( URLWithParams ( urlStr , params ) . String ( ) ) resp , err := http . PostForm ( urlStr , URLWithParams ( urlStr , params ) . Query ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "swapped", "case", "-", "sensitivity", "defaults"], "add_tokens": "SystemCase = func ( w * Wildmatch ) { }", "del_tokens": "SystemCase = CaseFold", "commit_type": "fix"}
{"commit_tokens": ["remove", "panic", "()", "in", "consumeResponse", "()"], "add_tokens": "return 0 , nil , err defer response . Body . Close ( ) return 0 , nil , err", "del_tokens": "\" \" defer func ( ) { if response != nil && response . Body != nil { response . Body . Close ( ) } if e := recover ( ) ; e != nil { trace := make ( [ ] byte , 10 * 1024 ) _ = runtime . Stack ( trace , false ) log . Printf ( \" \" , trace ) err = fmt . Errorf ( \" \" , e ) } } ( ) panic ( err ) panic ( err )", "commit_type": "remove"}
{"commit_tokens": ["updating", "mist", "publish", "command", "to", "satisfy", "the", "logtap", "publisher", "interface"], "add_tokens": "func ( mist * Mist ) Publish ( tags [ ] string , data string ) error { return nil", "del_tokens": "func ( mist * Mist ) Publish ( tags [ ] string , data string ) {", "commit_type": "update"}
{"commit_tokens": ["Remove", "simplejson", "dependency", "in", "exec", "plugin"], "add_tokens": "var jsonOut interface { } err = json . Unmarshal ( out , & jsonOut ) return processResponse ( acc , c . Name , map [ string ] string { } , jsonOut ) case float64 : acc . Add ( prefix , v , tags )", "del_tokens": "\" \" jsonOut , err := simplejson . NewJson ( out ) return processResponse ( acc , c . Name , map [ string ] string { } , jsonOut . Interface ( ) ) case json . Number : value , err := v . ( json . Number ) . Float64 ( ) if err != nil { return err } acc . Add ( prefix , value , tags )", "commit_type": "remove"}
{"commit_tokens": ["Make", "verb", "field", "of", "type", "string"], "add_tokens": "verbFlag * Flag if fieldValue . Type ( ) . Name ( ) == \" \" { r . verbFlag = flag break } // Process verb fs . verbFlag . value . Set ( reflect . ValueOf ( Verbs ( args [ 0 ] ) ) )", "del_tokens": "if fieldValue . Type ( ) . Name ( ) == \" \" { break } // Process verbs", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "IE", "compatibility", "Trident", "tokens", "."], "add_tokens": "{ \" \" , \" \" } , { \" \" , \" \" } , \" \" , \" \" , \" \" ,", "del_tokens": "\" \" ,", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "to", "reset", "to", "default", "positioning", "prior", "to", "building", "text", "data", "."], "add_tokens": "t . X1 = Point { 0 , 0 } t . X2 = Point { 0 , 0 } if t . IsDebug { fmt . Printf ( \" \\n \\n \" , lowerLeft )", "del_tokens": "if t . font . IsDebug {", "commit_type": "make"}
{"commit_tokens": ["Add", "test", "and", "small", "debugging", "tool"], "add_tokens": "\" \" \" \" \" \" // AppendFunc is an utility type to allow users to create a type dumper interface { dump ( io . Writer ) } func ( l appenderList ) dump ( out io . Writer ) { var buf bytes . Buffer ll := len ( l ) for i , a := range l { if dumper , ok := a . ( dumper ) ; ok { dumper . dump ( & buf ) } else { fmt . Fprintf ( & buf , \" \" , a ) } if i < ll - 1 { fmt . Fprintf ( & buf , \" \\n \" ) } } buf . WriteTo ( out ) } func ( v stdlibFormat ) dump ( out io . Writer ) { fmt . Fprintf ( out , \" \" , v . s ) } func ( v verbatimw ) dump ( out io . Writer ) { fmt . Fprintf ( out , \" \" , v . s ) }", "del_tokens": "// AppendFunc is an utility type to allow users to create a", "commit_type": "add"}
{"commit_tokens": ["Allowing", "ScanStructs", "to", "take", "a", "struct", "with", "an", "embedded", "pointer", "to", "a", "struck", "."], "add_tokens": "case reflect . Struct : case reflect . Slice : initEmbeddedPtr ( row ) func initEmbeddedPtr ( value reflect . Value ) { for i := 0 ; i < value . NumField ( ) ; i ++ { v := value . Field ( i ) kind := v . Kind ( ) t := value . Type ( ) . Field ( i ) if t . Anonymous && kind == reflect . Ptr { z := reflect . New ( t . Type . Elem ( ) ) v . Set ( z ) } } } if f . Anonymous && ( f . Type . Kind ( ) == reflect . Struct || f . Type . Kind ( ) == reflect . Ptr ) { if f . Type . Kind ( ) == reflect . Ptr { subColMaps = append ( subColMaps , createColumnMap ( f . Type . Elem ( ) ) ) } else { subColMaps = append ( subColMaps , createColumnMap ( f . Type ) ) }", "del_tokens": "case reflect . Struct : case reflect . Slice : if f . Anonymous && f . Type . Kind ( ) == reflect . Struct { subColMaps = append ( subColMaps , createColumnMap ( f . Type ) )", "commit_type": "allow"}
{"commit_tokens": ["Removed", "405", "handling", "for", "now"], "add_tokens": "// e := New() // e.Get(\"/\", func(c *Context) error { // return c.String(http.StatusOK, \"Echo!\") // }) // r, _ := http.NewRequest(POST, \"/\", nil) // w := httptest.NewRecorder() // e.ServeHTTP(w, r) // assert.Equal(t, http.StatusMethodNotAllowed, w.Code)", "del_tokens": "e := New ( ) e . Get ( \" \" , func ( c * Context ) error { return c . String ( http . StatusOK , \" \" ) } ) r , _ := http . NewRequest ( POST , \" \" , nil ) w := httptest . NewRecorder ( ) e . ServeHTTP ( w , r ) assert . Equal ( t , http . StatusMethodNotAllowed , w . Code )", "commit_type": "remove"}
{"commit_tokens": ["Adding", "safeguards", "around", "Shutdown", "and", "AddTarget"], "add_tokens": "if t == nil { return } if c . r != nil { return c . r . Shutdown ( ctxt , opts ... ) } return nil", "del_tokens": "return c . r . Shutdown ( ctxt , opts ... )", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "use", "local", "packages"], "add_tokens": "\" \" \" \" \" \" \" \" \" \" \" \" archiveLength , err := binary . ReadVarint ( bReader )", "del_tokens": "\" \" \" \" \" \" \" \" \" \" \" \" archiveLength , err := binary . ReadVarint ( bReader )", "commit_type": "update"}
{"commit_tokens": ["Fixing", "decoding", "behavior", "for", "mislabeled", "RSA", "private", "key", "blocks"], "add_tokens": "// io.Reader, or a string (strings are assumed to be a filename). // Standard crypto primitives (ie, rsa.PrivateKey/PublicKey, // ecdsa.PrivateKey/PublicKey, etc) can then be loaded into a Store via a call // to Load. // Store is a store containing crypto primitives (ie, rsa.PrivateKey,, etc). // EncodePrimitive encodes the crypto primitive obj into PEM-encoded data. default : return nil , errors . New ( \" \" ) // try pkcs1 and pkcs8 decoding if err == nil { // rsa decoding was successful store [ RSAPrivateKey ] = key } else { // otherwise just use the raw bytes (ie, the decoded b64 value) store [ PrivateKey ] = block . Bytes", "del_tokens": "// io.Reader, or a string (assumed to be a filename). // Standard crypto primitives (ie, rsa.PrivateKey, etc) can then be loaded into // a Store via a call to Load. // Store is a store for decoded crypto primitives (ie, rsa.PrivateKey, etc). // EncodePrimitive is a utility func to quickly encode a crypto primitive obj // into PEM-encoded data. // try pkcs1 and pkcs8 decoding first if err != nil { // use the raw b64 decoded bytes key = block . Bytes store [ PrivateKey ] = key", "commit_type": "fix"}
{"commit_tokens": ["remove", "the", "existence", "check", "of", "resources", "when", "create", "them"], "add_tokens": "node := & Node { Jenkins : j , Raw : new ( NodeResponse ) , Base : \" \" + name }", "del_tokens": "node , _ := j . GetNode ( name ) if node != nil { return node , nil } node = & Node { Jenkins : j , Raw : new ( NodeResponse ) , Base : \" \" + name } exists , err := j . GetView ( name ) if err != nil { return nil , err } if exists . Raw . Name != \" \" { return exists , errors . New ( \" \" ) }", "commit_type": "remove"}
{"commit_tokens": ["Added", "attributes", "for", "hello", "."], "add_tokens": "// TODO(jacobsa): Why do we get premission denied errors when this is // 0500? Mode : 0555 | os . ModeDir , // hello helloInode : inodeInfo { attributes : fuse . InodeAttributes { Mode : 0400 , } , } ,", "del_tokens": "Mode : 0700 | os . ModeDir ,", "commit_type": "add"}
{"commit_tokens": ["Make", "headers", "more", "generic", "and", "a", "function", "of", "the", "Package", "struct", "."], "add_tokens": "name string files map [ string ] * File func NewPackage ( name string ) * Package { return & Package { name : name , files : make ( map [ string ] * File ) } err := f . WriteFile ( p . name , filepath . Join ( targetDir , f . name ) ) func ( p * Package ) AddHeader ( file , header string ) { f , ok := p . files [ file ] if ! ok { f = NewFile ( file ) p . files [ file ] = f } f . headers = append ( f . headers , header ) }", "del_tokens": "name string files map [ string ] * File sources [ ] string func NewPackage ( name string , sources [ ] string ) * Package { return & Package { name : name , files : make ( map [ string ] * File ) , sources : sources } err := f . WriteFile ( p . name , filepath . Join ( targetDir , f . name ) , p . sources )", "commit_type": "make"}
{"commit_tokens": ["fix", "resourceType", "definition", "and", "samples"], "add_tokens": "ResourceTypes map [ string ] ResourceType `yaml:\"resourceTypes\"`", "del_tokens": "// TODO: Auto-fill the resourcePath and resourcePathName parameters // Remove mediaTypeExtension. // TODO: In resource type definitions, there are two reserved parameter // names: resourcePath and resourcePathName. The processing application // MUST set the values of these reserved parameters to the inheriting // resource's path (for example, \"/users\") and the part of the path // following the rightmost \"/\" (for example, \"users\"), respectively. // Processing applications MUST also omit the value of any // mediaTypeExtension found in the resource's URI when setting // resourcePath and resourcePathName. // TODO: Fill this during the post-processing phase // []map[ResourceTypeName]ResourceType ResourceTypes [ ] map [ string ] ResourceType `yaml:\"resourceTypes\"` // TODO: Flatten the arrays of maps here.", "commit_type": "fix"}
{"commit_tokens": ["added", "repeat", "--", "echo", "so", "I", "know", "what", "s", "going", "on"], "add_tokens": "cmd . Add ( Command { \" \" , `repeat [--count=n] [--wait=ms] [--echo] command args` , cmd . Repeat } ) echo := false if arg == \" \" { echo = true } else if strings . HasPrefix ( arg , \" \" ) { if echo { fmt . Println ( cmd . Prompt , command ) }", "del_tokens": "cmd . Add ( Command { \" \" , `repeat [--count=n] [--wait=ms] line` , cmd . Repeat } ) if strings . HasPrefix ( arg , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "an", "io", ".", "TeeReader", "and", "a", "bytes", ".", "Buffer", "for", "a", "copy", "of", "the", "source", "rencode", "data"], "add_tokens": "\" \" \" \" buf := deluge . DebugIncoming [ count - 1 ] fmt . Println ( \" \" , buf . Len ( ) , \" \" ) src , err := zlib . NewReader ( buf ) if err != nil { fmt . Fprintf ( os . Stderr , \" \\n \" , err ) os . Exit ( 5 ) } defer src . Close ( ) f , err := os . Create ( \" \" ) if err != nil { fmt . Fprintf ( os . Stderr , \" \\n \" , err ) os . Exit ( 5 ) } defer f . Close ( ) _ , err = io . Copy ( f , src )", "del_tokens": "\" \" b := deluge . DebugIncoming [ count - 1 ] fmt . Println ( \" \" , len ( b ) ) err := ioutil . WriteFile ( \" \" , b , 0664 )", "commit_type": "use"}
{"commit_tokens": ["use", "same", "size", "tests", "on", "levenstein", "and", "fuzzy"], "add_tokens": "{ \" \" , \" ft := fuzzyTests [ 0 ] Match ( ft . source , ft . target ) ft := fuzzyTests [ 0 ] RankMatch ( ft . source , ft . target )", "del_tokens": "Match ( \" \" , \" \" ) RankMatch ( \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["make", "sure", "tests", "have", "plugins"], "add_tokens": "c := NewClient ( & ClientConfig { Cmd : process , HandshakeConfig : testHandshake , Plugins : testPluginMap , } ) Plugins : testPluginMap , Plugins : testPluginMap , Plugins : testPluginMap , Plugins : testPluginMap , Plugins : testPluginMap , c := NewClient ( & ClientConfig { Cmd : process , HandshakeConfig : testHandshake , Plugins : testPluginMap , } )", "del_tokens": "c := NewClient ( & ClientConfig { Cmd : process , HandshakeConfig : testHandshake } ) c := NewClient ( & ClientConfig { Cmd : process , HandshakeConfig : testHandshake } )", "commit_type": "make"}
{"commit_tokens": ["Implemented", "bitcasts", ".", "Can", "print", "floats", "now", "."], "add_tokens": "typeName := c . typeName ( t ) c . Printf ( \" \" , nt . Obj ( ) . Name ( ) , typeName ) c . Printf ( \" \" , typeName , nt . Obj ( ) . Name ( ) ) return ! is64Bit ( t ) && t . Kind ( ) != types . UntypedNil", "del_tokens": "case * types . Slice : c . Printf ( \" \" , nt . Obj ( ) . Name ( ) ) c . Printf ( \" \" , nt . Obj ( ) . Name ( ) ) case * types . Map : c . Printf ( \" \" , nt . Obj ( ) . Name ( ) ) panic ( fmt . Sprintf ( \" \\n \" , t ) ) if t . Kind ( ) == types . UntypedNil { return false } return true", "commit_type": "implement"}
{"commit_tokens": ["Remove", "now", "-", "duplicated", "response", "-", "trimming", "code", "from", "Consumer"], "add_tokens": "var err error c . msgbuf , err = c . fetch ( )", "del_tokens": "messages , err := c . fetch ( ) // check first messages if any of them has index lower than requested, // this can happen because of kafka optimizations toSkip := 0 for toSkip < len ( messages ) { if messages [ toSkip ] . Offset >= c . offset { break } toSkip ++ } // messages crc is checked by underlying connection so no need to check // those again if len ( messages ) == toSkip && toSkip != 0 { c . conf . Logger . Debug ( \" \" , \" \" , toSkip ) } // ignore all messages that are of index lower than requested c . msgbuf = messages [ toSkip : ]", "commit_type": "remove"}
{"commit_tokens": ["Adding", "correct", "canonical", "link", "to", "alias", "pages"], "add_tokens": "alias := \" \\n \\n \\n \\\" \\\" \\\" \\\" \\n \\\" \\\" \\\" \\\" \\n \\\" \\\" \\\" \\\" \\n \\n \"", "del_tokens": "alias := \" \\n \\n \\n \\\" \\\" \\\" \\\" \\n \\\" \\\" \\\" \\\" \\n \\\" \\\" \\\" \\\" \\n \\n \"", "commit_type": "add"}
{"commit_tokens": ["use", "bitmaps", "for", "unions", "/", "or", "operations"], "add_tokens": "bc1 := newBitmapContainerFromRun ( rc ) bc2 := ac . toBitmapContainer ( ) return bc1 . orBitmap ( bc2 ) / * out := ac . clone ( ) for _ , p := range rc . iv { for i := p . start ; i <= p . last ; i ++ { out . iadd ( i ) } return out * /", "del_tokens": "out := ac . clone ( ) for _ , p := range rc . iv { for i := p . start ; i <= p . last ; i ++ { out . iadd ( i ) } return out", "commit_type": "use"}
{"commit_tokens": ["Use", "existing", "function", "for", "used", "pattern"], "add_tokens": "panic ( fmt . Errorf ( \" \" , minAlphabetLength ) )", "del_tokens": "panic ( errors . New ( fmt . Sprintf ( \" \" , minAlphabetLength ) ) )", "commit_type": "use"}
{"commit_tokens": ["changed", "a", "bufer", "to", "be", "allocated", "globally"], "add_tokens": "var bufBack [ 4 ] byte", "del_tokens": "var bufBack [ 4 ] byte", "commit_type": "change"}
{"commit_tokens": ["Add", "checks", "for", "value", "and", "pointer", "receivers"], "add_tokens": "case * ast . Ident : recv = e . Name", "del_tokens": "case * ast . UnaryExpr : recv = e . X . ( * ast . Ident ) . Name", "commit_type": "add"}
{"commit_tokens": ["update", "godoc", "and", "make", "fieldsError", ".", "Error", "a", "multe", "-", "line", "string"], "add_tokens": "return errs", "del_tokens": "return & errs", "commit_type": "update"}
{"commit_tokens": ["Update", "example", "to", "use", "new", "AWS", "Session"], "add_tokens": "alog \" \" \" \" sess , err := session . NewSession ( aws . NewConfig ( ) ) if err != nil { log . Log ( \" \" , err ) } // New Kinesis and DynamoDB clients (if you need custom config) myKsis := kinesis . New ( sess ) myDdbClient := dynamodb . New ( sess ) ck , err := checkpoint . New ( * app , * table , checkpoint . WithDynamoClient ( myDdbClient ) , checkpoint . WithRetryer ( & MyRetryer { } ) ) // expvar counter consumer . WithClient ( myKsis ) ,", "del_tokens": "alog \" \" \" \" // Following will overwrite the default dynamodb client // Older versions of aws sdk does not picking up aws config properly. // You probably need to update aws sdk verison. Tested the following with 1.13.59 myDynamoDbClient := dynamodb . New ( session . New ( aws . NewConfig ( ) ) , & aws . Config { Region : aws . String ( \" \" ) , } , ) ck , err := checkpoint . New ( * app , * table , checkpoint . WithDynamoClient ( myDynamoDbClient ) , checkpoint . WithRetryer ( & MyRetryer { } ) ) // The following 2 lines will overwrite the default kinesis client ksis := kinesis . New ( session . New ( aws . NewConfig ( ) ) , & aws . Config { Region : aws . String ( \" \" ) , } , ) consumer . WithClient ( ksis ) ,", "commit_type": "update"}
{"commit_tokens": ["use", "https", "when", "tls", ".", "Config", "is", "provided"], "add_tokens": "if tlsConfig == nil { u . Scheme = \" \" } else { u . Scheme = \" \" }", "del_tokens": "u . Scheme = \" \"", "commit_type": "use"}
{"commit_tokens": ["Create", "ProtoVersioner", "as", "proto", ".", "Message", "and", "Versioner"], "add_tokens": "\" \" protoModel , ok := model . ( ProtoVersioner ) if ! ok { return errors . New ( \" \" ) } err = UnmarshalProto ( logger , unencodedPayload [ EnvelopeOffset : ] , protoModel ) err = fmt . Errorf ( \" \" , envelopeFormat ) protoModel , ok := model . ( ProtoVersioner ) if ! ok { return nil , errors . New ( \" \" ) } payload , err = MarshalProto ( protoModel ) err = fmt . Errorf ( \" \" , format ) func UnmarshalProto ( logger lager . Logger , marshaledPayload [ ] byte , model ProtoVersioner ) error { func MarshalProto ( v ProtoVersioner ) ( [ ] byte , error ) {", "del_tokens": "err = UnmarshalProto ( logger , unencodedPayload [ EnvelopeOffset : ] , model ) err = fmt . Errorf ( \" \" , envelopeFormat ) payload , err = MarshalProto ( model ) err = fmt . Errorf ( \" \" , format ) func UnmarshalProto ( logger lager . Logger , marshaledPayload [ ] byte , model Versioner ) error { func MarshalProto ( v Versioner ) ( [ ] byte , error ) {", "commit_type": "create"}
{"commit_tokens": ["Remove", "old", "AddFile", "+", "add", "fixme"], "add_tokens": "// TODO: FIXME: We could check if the io.Reader supports io.Seek, so we can do a size scan, and then seek to the beginning for the read", "del_tokens": "// AddFile add file from dir in archive func ( z * ZipFile ) AddFile ( filepath string ) error { file , err := os . Open ( filepath ) if err != nil { return err } info , err := file . Stat ( ) if err != nil { return err } header , err := zip . FileInfoHeader ( info ) if err != nil { return err } zipWriter , err := z . Writer . CreateHeader ( header ) if err != nil { return err } _ , err = io . Copy ( zipWriter , file ) return err }", "commit_type": "remove"}
{"commit_tokens": ["fixed", "tests", "wrt", "Max", "/", "Min"], "add_tokens": "b = [ ] float64 { 2 } b = [ ] float64 { 2 }", "del_tokens": "a = [ ] float64 { 2 } a = [ ] float64 { 2 }", "commit_type": "fix"}
{"commit_tokens": ["Add", "IndexBuilder", ".", "ContentSize", "rearrange", "a", "function", "."], "add_tokens": "// ContentSize returns the number of content bytes so far ingested. func ( b * IndexBuilder ) ContentSize ( ) uint32 { // Add the name too so we don't skip building index if we have // lots of empty files. return b . contentEnd + b . nameEnd", "del_tokens": "\" \" func ( m * candidateMatch ) String ( ) string { return fmt . Sprintf ( \" \" , m . file , m . offset )", "commit_type": "add"}
{"commit_tokens": ["Add", "Restructured", "Text", "lexer", "."], "add_tokens": "{ \" \\\\ \\\\ \\\\ \\\\ \" , EmitterFunc ( markdownCodeBlock ) , nil } , func markdownCodeBlock ( groups [ ] string , lexer Lexer ) Iterator { { String , groups [ 1 ] } , { String , groups [ 2 ] } , { Text , groups [ 3 ] } ,", "del_tokens": "{ \" \\\\ \\\\ \\\\ \\\\ \" , EmitterFunc ( handleCodeblock ) , nil } , func handleCodeblock ( groups [ ] string , lexer Lexer ) Iterator { & Token { String , groups [ 1 ] } , & Token { String , groups [ 2 ] } , & Token { Text , groups [ 3 ] } ,", "commit_type": "add"}
{"commit_tokens": ["add", "kern", "value", "to", "map"], "add_tokens": "import ( \" \" \" \" ) Version uint64 //for debug NTables uint64 //for debug Kerning KernMap } func ( k KernTable ) debug ( ) string { var buff bytes . Buffer for left , kval := range k . Kerning { buff . WriteString ( fmt . Sprintf ( \" \\n \\n \" , left ) ) for right , val := range kval { buff . WriteString ( fmt . Sprintf ( \" \\t \\n \" , right , val ) ) } } return buff . String ( ) / * } * / //KernMap kerning map map[left]KernValue type KernMap map [ uint64 ] KernValue //KernValue kerning values map[right]value type KernValue map [ uint64 ] int64", "del_tokens": "Version uint64 NTables uint64 Subtables [ ] KernSubTable }", "commit_type": "add"}
{"commit_tokens": ["adding", "template", "message", "sending", "test", "refactored", "model", "to", "use", "Var"], "add_tokens": "func ( a * MandrillAPI ) MessageSendTemplate ( templateName string , templateContent [ ] Var , message Message , async bool ) ( [ ] SendResponse , error ) { Html string `json:\"html,omitempty\"` Text string `json:\"text,omitempty\"`", "del_tokens": "func ( a * MandrillAPI ) MessageSendTemplate ( templateName string , templateContent [ ] TemplateContent , message Message , async bool ) ( [ ] SendResponse , error ) { type TemplateContent struct { Name string `json:\"name\"` Content string `json:\"content\"` } Html string `json:\"html\"` Text string `json:\"text\"`", "commit_type": "add"}
{"commit_tokens": ["Update", "so", "plurals", "and", "resources", "generated", "from", "the", "same", "file", "."], "add_tokens": "\" \" translators map [ string ] * Translator translatorsLowercase map [ string ] * Translator fallback * Translator // fallback translator; the lowercase bool specifies whether to lookup // the locale by proper or lowercase name, why because the http // Accept-Language header passed by some browsers has the locale lowercased // and others proper name so this just makes it easier to lowercase, pass in // the lowecased array and lookup by lowercase name. func FindTranslator ( locales [ ] string , lowercase bool ) * Translator { if lowercase { for _ , locale := range locales { if t , ok := utrans . translatorsLowercase [ locale ] ; ok { return t } } } else { for _ , locale := range locales { if t , ok := utrans . translators [ locale ] ; ok { return t } utrans . translatorsLowercase [ strings . ToLower ( loc . Locale ) ] = t", "del_tokens": "translators map [ string ] * Translator fallback * Translator // fallback translator func FindTranslator ( locales [ ] string ) * Translator { for _ , locale := range locales { if t , ok := utrans . translators [ locale ] ; ok { return t", "commit_type": "update"}
{"commit_tokens": ["Added", "automatic", "number", "type", "conversions"], "add_tokens": "expect . Equal ( int64 ( 10 ) , t1 ) expect . Equal ( uint64 ( 10 ) , t2 ) expect . Equal ( float64 ( 10 ) , t3 ) expect . Equal ( float64 ( 10 ) , t3a ) expect . Equal ( \" \" , t4 ) expect . Equal ( time . Second , t5 ) expect . Equal ( time . Minute , t6 ) expect . Equal ( time . Hour , t7 )", "del_tokens": "expect . Equal ( t1 , int64 ( 10 ) ) expect . Equal ( t2 , uint64 ( 10 ) ) expect . Equal ( t3 , float64 ( 10 ) ) expect . Equal ( t3a , float64 ( 10 ) ) expect . Equal ( t4 , \" \" ) expect . Equal ( t5 , time . Second ) expect . Equal ( t6 , time . Minute ) expect . Equal ( t7 , time . Hour )", "commit_type": "add"}
{"commit_tokens": ["Made", "root", "permission", "check", "work", "for", "setuid", "bit", "(", "EUID", ")"], "add_tokens": "\" \" if syscall . Getuid ( ) != 0 && syscall . Geteuid ( ) != 0 {", "del_tokens": "\" \" u , err := user . Current ( ) if err != nil { return err } if u . Uid != \" \" {", "commit_type": "make"}
{"commit_tokens": ["Make", "this", "example", "code", "to", "make", "more", "sense"], "add_tokens": "LOOP : time . Sleep ( time . Second ) // this is work to be done by worker. select { case <- stop : break LOOP default :", "del_tokens": "time . Sleep ( time . Second ) if _ , ok := <- stop ; ok { break", "commit_type": "make"}
{"commit_tokens": ["added", "integration", "tests", "for", "SLVGBDTG"], "add_tokens": "Context ( \" \" , func ( ) { It ( \" \" , func ( ) { It ( \" \" , func ( ) { groups , err := accountService . GetBlockDeviceTemplateGroups ( ) Expect ( err ) . ToNot ( HaveOccurred ( ) ) Expect ( len ( groups ) ) . To ( BeNumerically ( \" \" , 0 ) ) } ) Context ( \" \" , func ( ) {", "del_tokens": "\" \" Context ( \" \" , func ( ) { It ( \" \" , func ( ) { FContext ( \" \" , func ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "json", "field", "name", "case", "for", "comments"], "add_tokens": "UUID uuid . UUID `json:\"uuid\"` Created time . Time `json:\"created\"` Player uuid . UUID `json:\"player\"` Content string `json:\"content\"`", "del_tokens": "UUID uuid . UUID `json:uuid` Created time . Time `json:created` Player uuid . UUID `json:player` Content string `json:content`", "commit_type": "fix"}
{"commit_tokens": ["adds", "helper", "func", "to", "write", "png"], "add_tokens": "\" \" func WriteImageToPng ( img * image . Image , name string ) { fso , err := os . Create ( name ) if err != nil { panic ( err ) } defer fso . Close ( ) png . Encode ( fso , ( * img ) ) }", "del_tokens": "_ \" \"", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "-", "case", "for", "slice", "marshalling"], "add_tokens": "{ & IntsValue , IntsString } , Value string }", "del_tokens": "Value string }", "commit_type": "add"}
{"commit_tokens": ["Add", "backoff", "retry", "db", "migration"], "add_tokens": "\" \" \" \" m . Logger . Error ( \" \" , err ) err = backoff . RetryNotify ( b . Migrate , m . backoff , func ( err error , duration time . Duration ) { m . Logger . Warningf ( \" \" , err , duration ) } ) m . Logger . Error ( \" \" , err ) m . Logger . Error ( \" \" , err ) m . Logger . Error ( \" \" , err ) m . Logger . Error ( \" \" , err )", "del_tokens": "\" \" log . Println ( \" \" , err ) err = b . Migrate ( ) log . Println ( \" \" , err ) log . Println ( \" \" , err ) log . Println ( \" \" , err ) log . Println ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Added", "service", "tests", "deal", "with", "missing", "provenances"], "add_tokens": "\" \" func TestUnMarshallingAnnotation ( t * testing . T ) { assert := assert . New ( t ) annotations := Annotations { } jason , err := ioutil . ReadFile ( \" \" ) assert . NoError ( err , \" \" ) err = json . Unmarshal ( [ ] byte ( jason ) , & annotations ) assert . NoError ( err , \" \" )", "del_tokens": "func TestUnMashallingAnnotation ( t * testing . T ) { annotation := Annotation { } jason := `{ \" \" : { \" \" : \" \" } } ` err := json . Unmarshal ( [ ] byte ( jason ) , & annotation ) if err != nil { panic ( err ) } assertion := assert . New ( t ) assertion . Nil ( err )", "commit_type": "add"}
{"commit_tokens": ["Fix", "resetting", "display", "attributes", "on", "VT100", "output"], "add_tokens": "w . SetDisplayAttributes ( fg , bg , DisplayDefaultFont , DisplayReset )", "del_tokens": "w . SetDisplayAttributes ( fg , bg , DisplayDefaultFont )", "commit_type": "fix"}
{"commit_tokens": ["Upgrade", "maptime", "--", ">", "badtime"], "add_tokens": "if startTime == nullStopWatchStart { // nolint: badtime", "del_tokens": "if startTime == nullStopWatchStart {", "commit_type": "upgrade"}
{"commit_tokens": ["Updated", "FindAlbums", "to", "behave", "like", "FindTracks", "(", "return", "a", "slice", "of", "pointers", ")"], "add_tokens": "// IDs in a single call. Albums are returned in the order // requested. If an album is not found, that position in the // result slice will be nil. func ( c * Client ) FindAlbums ( ids ... ID ) ( [ ] * FullAlbum , error ) { if resp . StatusCode != http . StatusOK { var e struct { E Error `json:\"error\"` } err = json . NewDecoder ( resp . Body ) . Decode ( & e ) if err != nil { return nil , errors . New ( \" \" ) } return nil , e . E } var a struct { Albums [ ] * FullAlbum `json:\"albums\"` } err = json . NewDecoder ( resp . Body ) . Decode ( & a ) return a . Albums , nil", "del_tokens": "func ( a * SimpleAlbum ) String ( ) string { return \" \" + a . Name } func ( a * FullAlbum ) String ( ) string { return \" \" + a . Name } // IDs in a single call. func ( c * Client ) FindAlbums ( ids ... ID ) ( * AlbumResult , error ) { var result AlbumResult err = json . NewDecoder ( resp . Body ) . Decode ( & result ) return & result , nil", "commit_type": "update"}
{"commit_tokens": ["Add", "notification", "channel", "for", "finished", "work"], "add_tokens": "FinishedWork ( ) chan bool queue string ready chan bool finishedwork chan bool messages chan * Msg stop chan bool exit chan bool closed chan bool make ( chan bool ) , func ( f * fetch ) FinishedWork ( ) chan bool { return f . finishedwork }", "del_tokens": "queue string ready chan bool messages chan * Msg stop chan bool exit chan bool closed chan bool", "commit_type": "add"}
{"commit_tokens": ["implement", "plz", ".", "Close", "and", "plz", ".", "CloseAll"], "add_tokens": "if len ( event . Properties ) % 2 == 1 { msg = append ( msg , \" \\n \" ... ) return msg } beforePropMsgLen := len ( msg ) if event . Level <= LevelInfo && ( k == \" \" || k == \" \" ) { noProp := len ( msg ) == beforePropMsgLen if noProp && event . Level <= LevelTrace { return nil }", "del_tokens": "if event . Level <= LevelInfo && k == \" \" {", "commit_type": "implement"}
{"commit_tokens": ["Remove", "randomization", "of", "filename", "."], "add_tokens": "repo = \" \" + os . Args [ 1 ]", "del_tokens": "repo = \" \" + os . Args [ 1 ] + btrfs . RandSeq ( 4 )", "commit_type": "remove"}
{"commit_tokens": ["Add", "note", "about", "concurrency", "to", "error", "messages", "."], "add_tokens": "type protocolError string func ( pe protocolError ) Error ( ) string { return fmt . Sprintf ( \" \" , string ( pe ) ) } return nil , protocolError ( \" \" ) return nil , protocolError ( \" \" ) return - 1 , protocolError ( \" \" ) return - 1 , protocolError ( \" \" ) return 0 , protocolError ( \" \" ) return 0 , protocolError ( \" \" ) return 0 , protocolError ( \" \" ) return nil , protocolError ( \" \" ) return nil , protocolError ( \" \" ) return nil , protocolError ( \" \" )", "del_tokens": "return nil , errors . New ( \" \" ) return nil , errors . New ( \" \" ) return - 1 , errors . New ( \" \" ) return - 1 , errors . New ( \" \" ) return 0 , errors . New ( \" \" ) return 0 , errors . New ( \" \" ) return 0 , errors . New ( \" \" ) return nil , errors . New ( \" \" ) return nil , errors . New ( \" \" ) return nil , errors . New ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "comment", "styles", "."], "add_tokens": "// maxOffset limits how far copy back-references can go, the same as the C++ // code.", "del_tokens": "// We limit how far copy back-references can go, the same as the C++ code.", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "timestamp", "in", "RFC3339", "format"], "add_tokens": "time . Stamp , time . RFC3339 , } // if timestamps starts with numeric try formats with different order // it is more likely that timestamp is in RFC3339 format then if c := p . buff [ p . cursor ] ; c > '0' && c < '9' { tsFmts = [ ] string { time . RFC3339 , time . Stamp , } p . cursor = len ( time . Stamp )", "del_tokens": "\" \" , \" \" , p . cursor = tsFmtLen", "commit_type": "add"}
{"commit_tokens": ["Use", "mattn", "/", "go", "-", "isatty", "instead", "of", "ssh", "/", "terminal"], "add_tokens": "\" \" return isatty . IsTerminal ( f . Fd ( ) )", "del_tokens": "\" \" return terminal . IsTerminal ( int ( f . Fd ( ) ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "container", "ports", "to", "test", "endpoint", "structures"], "add_tokens": "dummyEndpoint := routing_table . Endpoint { InstanceGuid : \" \" , Host : \" \" , Port : 11 , ContainerPort : 1111 } dummyEndpoint = routing_table . Endpoint { InstanceGuid : \" \" , Host : \" \" , Port : 22 , ContainerPort : 2222 } Ω( r outes) . S hould( H aveLen( 1 ) ) Ω( e ndpoints) . S hould( H aveLen( 1 ) )", "del_tokens": "dummyEndpoint := routing_table . Endpoint { InstanceGuid : \" \" , Host : \" \" , Port : 11 } dummyEndpoint = routing_table . Endpoint { InstanceGuid : \" \" , Host : \" \" , Port : 22 }", "commit_type": "add"}
{"commit_tokens": ["Fix", "UTC", "time", "parsing", "when", "an", "offset", "is", "specified", "."], "add_tokens": "\" \" tzOffsetRegex = `(Z|z|\\+|-)(\\d+:\\d+)*\"*$` if m , _ := regexp . Match ( tzOffsetRegex , data ) ; m { t . Time , err = ParseTime ( timeFormat , string ( data ) ) if m , _ := regexp . Match ( tzOffsetRegex , data ) ; m { t . Time , err = ParseTime ( timeFormat , string ( data ) )", "del_tokens": "\" \" stringData := string ( data ) if strings . IndexAny ( stringData , \" \" ) > - 1 { t . Time , err = ParseTime ( timeFormat , stringData ) stringData := string ( data ) if strings . IndexAny ( stringData , \" \" ) > - 1 { t . Time , err = ParseTime ( timeFormat , stringData )", "commit_type": "fix"}
{"commit_tokens": ["Use", "golang", "context", "pkg", "instead", "of", "gorilla", "/", "context", "to", "fix", "memory", "leaks"], "add_tokens": "\" \" var ctx = r . Context ( ) registry := ctx . Value ( registryKey ) * r = * r . WithContext ( context . WithValue ( ctx , registryKey , newRegistry ) )", "del_tokens": "\" \" registry := context . Get ( r , registryKey ) context . Set ( r , registryKey , newRegistry )", "commit_type": "use"}
{"commit_tokens": ["Fix", "tests", "on", "Windows", "."], "add_tokens": "mode = 0666", "del_tokens": "mode = 0700", "commit_type": "fix"}
{"commit_tokens": ["fix", "error", "message", "for", "negative", "number"], "add_tokens": "return nil , fmt . Errorf ( \" \" , n )", "del_tokens": "return nil , fmt . Errorf ( \" \" , n )", "commit_type": "fix"}
{"commit_tokens": ["fix", "PlayId", "--", "was", "sending", "the", "wrong", "command"], "add_tokens": "// PlayId plays the song identified by id. If id is negative, start playing // at the currect position in playlist. func ( c * Client ) PlayId ( id int ) os . Error { if id < 0 { c . writeLine ( \" \" ) } else { c . writeLine ( fmt . Sprintf ( \" \" , id ) ) } return c . readErr ( ) ; }", "del_tokens": "// PlayId plays the song identified by id. func ( c * Client ) PlayId ( id int ) os . Error { return c . Play ( id ) }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "some", "old", "assumptions", "about", "memcached", "response", "errors", "."], "add_tokens": "switch res , err := memcached . UnwrapMemcachedError ( mc . Add ( vb , k , 0 , exp , v ) ) ; {", "del_tokens": "if res . Status != gomemcached . SUCCESS { return res } switch res , err := mc . Add ( vb , k , 0 , exp , v ) ; { if res . Status != gomemcached . SUCCESS { return res } if res . Status != gomemcached . SUCCESS { return res }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "short", "flag", "parsing", "add", "some", "tests", "."], "add_tokens": "if len ( arg ) > 2 { p . args = append ( [ ] string { \" \" + arg [ 2 : ] } , p . args ... ) }", "del_tokens": "p . args = append ( [ ] string { \" \" + arg [ 2 : ] } , p . args ... )", "commit_type": "fix"}
{"commit_tokens": ["Allows", "netdev", "devices", "to", "be", "ignored"], "add_tokens": "\" \" \" \" fieldSep = regexp . MustCompile ( \" \" ) netdevIgnoredDevices = flag . String ( \" \" , \" \" , \" \" ) ignoredDevicesPattern * regexp . Regexp ignoredDevicesPattern : regexp . MustCompile ( * netdevIgnoredDevices ) , metrics : map [ string ] * prometheus . GaugeVec { } , netDev , err := getNetDevStats ( c . ignoredDevicesPattern ) func getNetDevStats ( ignore * regexp . Regexp ) ( map [ string ] map [ string ] map [ string ] string , error ) { return parseNetDevStats ( file , ignore ) func parseNetDevStats ( r io . Reader , ignore * regexp . Regexp ) ( map [ string ] map [ string ] map [ string ] string , error ) { if ignore . MatchString ( dev ) { log . Debugf ( \" \" , dev ) continue }", "del_tokens": "fieldSep = regexp . MustCompile ( \" \" ) metrics : map [ string ] * prometheus . GaugeVec { } , netDev , err := getNetDevStats ( ) func getNetDevStats ( ) ( map [ string ] map [ string ] map [ string ] string , error ) { return parseNetDevStats ( file ) func parseNetDevStats ( r io . Reader ) ( map [ string ] map [ string ] map [ string ] string , error ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "failure", "record", "struct", "."], "add_tokens": "// FailureRecord represents a single failed expectation for a test. type FailureRecord struct { // The file name within which the expectation failed, e.g. \"foo_test.go\". FileName string // The line number at which the expectation failed, or zero if unknown. LineNumber uint // The error generated by the testing framework. For example: // // Expected: 17 // Actual: \"taco\", which is not numeric // GeneratedError string // A user-specified string to print out with the error, if any. UserError string } // A set of failure records that the test has produced. FailureRecords [ ] FailureRecord", "del_tokens": "// A set of failure messages that the test has produced. FailureMessages [ ] string", "commit_type": "add"}
{"commit_tokens": ["Allow", "registering", "converters", "for", "slice", "types", "."], "add_tokens": "func ( d * Decoder ) decode ( v reflect . Value , path string , parts [ ] pathPart , values [ ] string ) error { // Get the converter early in case there is one for a slice type. conv := d . cache . converter ( t ) if conv == nil && t . Kind ( ) == reflect . Slice { // Try to get a converter for the element type. } else if conv != nil {", "del_tokens": "func ( d * Decoder ) decode ( v reflect . Value , path string , parts [ ] pathPart , values [ ] string ) error { // Simple case. if t . Kind ( ) == reflect . Slice { } else if conv := d . cache . converter ( t ) ; conv != nil {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "public", "parent", "key", "to", "public", "child", "key", "derivation"], "add_tokens": "// As described at https://crypto.stackexchange.com/a/8916 ySquared := big . NewInt ( 0 ) ySquared . Exp ( X , big . NewInt ( 3 ) , nil ) Y . ModSqrt ( ySquared , curveParams . P ) Ymod2 := big . NewInt ( 0 ) Ymod2 . Mod ( Y , big . NewInt ( 2 ) ) signY := uint64 ( key [ 0 ] ) - 2 if signY != Ymod2 . Uint64 ( ) {", "del_tokens": "// As described at https://bitcointa.lk/threads/compressed-keys-y-from-x.95735/ qPlus1Div4 := big . NewInt ( 0 ) ySquared := X . Exp ( X , big . NewInt ( 3 ) , nil ) qPlus1Div4 . Add ( curveParams . P , big . NewInt ( 1 ) ) qPlus1Div4 . Div ( qPlus1Div4 , big . NewInt ( 4 ) ) // sqrt(n) = n^((q+1)/4) if q = 3 mod 4 Y . Exp ( ySquared , qPlus1Div4 , curveParams . P ) if uint32 ( key [ 0 ] ) % 2 == 0 {", "commit_type": "fix"}
{"commit_tokens": ["fix", "new", "line", "w", "/", "o", "border"], "add_tokens": "//GetBorder - get current border func ( t Table ) GetBorder ( ) Border { return t . border } olddataout := dataout delim = Borders [ t . border ] [ BKRighttop ] //+ \"\\n\" if olddataout != dataout { delim += \" \\n \" } panic ( err )", "del_tokens": "delim = Borders [ t . border ] [ BKRighttop ] + \" \\n \" return \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "default", "scope", "for", "Twitch", "if", "no", "scope", "is", "provided"], "add_tokens": "if len ( scopes ) > 0 { for _ , scope := range scopes { c . Scopes = append ( c . Scopes , scope ) } } else { c . Scopes = [ ] string { ScopeUserRead }", "del_tokens": "for _ , scope := range scopes { c . Scopes = append ( c . Scopes , scope )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "XfrmState", "Encapsulation"], "add_tokens": "// EncapType is an enum representing an ipsec template direction. type EncapType uint8 const ( _ = iota XFRM_ENCAP_ESPINUDP_NONIKE EncapType = iota XFRM_ENCAP_ESPINUDP EncapType = iota ) func ( e EncapType ) String ( ) string { switch e { case XFRM_ENCAP_ESPINUDP_NONIKE : return \" \" case XFRM_ENCAP_ESPINUDP : return \" \" } return \" \" } // XfrmEncap represents the encapsulation to use for the ipsec encryption. type XfrmStateEncap struct { Type EncapType SrcPort int DstPort int OriginalAddress net . IP } Dst net . IP Src net . IP Proto Proto Mode Mode Spi int Reqid int Auth * XfrmStateAlgo Crypt * XfrmStateAlgo Encap * XfrmStateEncap", "del_tokens": "Dst net . IP Src net . IP Proto Proto Mode Mode Spi int Reqid int Auth * XfrmStateAlgo Crypt * XfrmStateAlgo", "commit_type": "add"}
{"commit_tokens": ["Allow", "import", "of", "other", "packages", "when", "using", "protoc", "-", "gen"], "add_tokens": "log . Printf ( \" \" , * file . Name ) log . Printf ( \" \" , * file . Name ) continue", "del_tokens": "log . Fatalf ( \" \" , * file . Name ) log . Fatalf ( \" \" , * file . Name )", "commit_type": "allow"}
{"commit_tokens": ["Add", "test", "for", "sort", "exproute", "before", "compile"], "add_tokens": "func ( s * RouteSuite ) TestTrieMatchLongestPath ( c * C ) { func ( s * RouteSuite ) TestRegexpMatchLongestPath ( c * C ) { r := NewExpRouter ( ) l1 := makeLoc ( \" \" ) c . Assert ( r . AddLocation ( `RegexpRoute(\"/r\")` , l1 ) , IsNil ) l2 := makeLoc ( \" \" ) c . Assert ( r . AddLocation ( `RegexpRoute(\"/r/hello\")` , l2 ) , IsNil ) req := makeReq ( \" \" ) out , err := r . Route ( req ) c . Assert ( err , IsNil ) c . Assert ( out , Equals , l2 ) }", "del_tokens": "func ( s * RouteSuite ) TestMatchLongestPath ( c * C ) {", "commit_type": "add"}
{"commit_tokens": ["change", "ledis", "-", "load", "refer", "mysql", "load", "dump"], "add_tokens": "\" \" //master enable binlog, here output this like mysql if head . LogFileIndex != 0 && head . LogPos != 0 { format := \" \\n \" fmt . Printf ( format , head . LogFileIndex , head . LogPos ) } return nil", "del_tokens": "\" \" \" \" var masterAddr = flag . String ( \" \" , \" \" , \" \" ) info := new ( server . MasterInfo ) info . Addr = * masterAddr info . LogFileIndex = head . LogFileIndex info . LogPos = head . LogPos infoFile := path . Join ( cfg . DataDir , \" \" ) return info . Save ( infoFile )", "commit_type": "change"}
{"commit_tokens": ["add", "sender_actions", "audio", "/", "video", "/", "file", "payloads", "to", "send", "api"], "add_tokens": "URL string `json:\"url,omitempty\"` Coords InputCoords `json:\"coordinates,omitempty\"` } type InputCoords struct { Lat float64 `json:\"lat\"` Long float64 `json:\"long\"`", "del_tokens": "URL string `json:\"url,omitempty\"` Lat float64 `json:\"coordinates.lat,omitempty\"` Long float64 `json:\"coordinates.long,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["fix", "linting", "issue", ":", "return", "value", "is", "not", "checked"], "add_tokens": "_ = lgr . Output ( depth , fmt . Sprintf ( logger . message ( lv , message ) , args ... ) )", "del_tokens": "lgr . Output ( depth , fmt . Sprintf ( logger . message ( lv , message ) , args ... ) )", "commit_type": "fix"}
{"commit_tokens": ["Remove", "log", "prefix", "from", "usage", "errors"], "add_tokens": "ErrUsage = errors . New ( \" \\n \" ) fmt . Fprintln ( os . Stderr , sup . VERSION ) fmt . Fprintln ( os . Stderr , err ) os . Exit ( 1 ) fmt . Fprintln ( os . Stderr , err ) os . Exit ( 1 ) fmt . Fprintln ( os . Stderr , err ) os . Exit ( 1 ) fmt . Fprintln ( os . Stderr , fmt . Errorf ( \" \" , * onlyHosts ) ) os . Exit ( 1 ) fmt . Fprintln ( os . Stderr , err ) os . Exit ( 1 ) fmt . Fprintln ( os . Stderr , err ) os . Exit ( 1 )", "del_tokens": "\" \" ErrUsage = errors . New ( \" \" ) fmt . Println ( sup . VERSION ) log . Fatal ( err ) log . Fatal ( err ) log . Fatal ( err ) log . Fatal ( fmt . Errorf ( \" \" , * onlyHosts ) ) log . Fatal ( err ) log . Fatal ( err )", "commit_type": "remove"}
{"commit_tokens": ["use", "alias", "field", "to", "correctly", "read", "container", "IDs"], "add_tokens": "statPoint := convertCadvisorStatToAggregatedStat ( id , stat . Aliases , stat . Name , containerIds , resourceType , memLimit , stat . Stats [ i ] ) func convertCadvisorStatToAggregatedStat ( id string , aliases [ ] string , name string , containerIds map [ string ] string , resourceType string , memLimit uint64 , stat * info . ContainerStats ) AggregatedStat { found := false for _ , alias := range aliases { if idVal , ok := containerIds [ alias ] ; ok { id = idVal found = true break } } if ! found { return AggregatedStat { } }", "del_tokens": "statPoint := convertCadvisorStatToAggregatedStat ( id , stat . Name , containerIds , resourceType , memLimit , stat . Stats [ i ] ) func convertCadvisorStatToAggregatedStat ( id string , name string , containerIds map [ string ] string , resourceType string , memLimit uint64 , stat * info . ContainerStats ) AggregatedStat { return AggregatedStat { }", "commit_type": "use"}
{"commit_tokens": ["Implement", "an", "untested", "version", "of", "monitor", "s", "collector"], "add_tokens": "JobID * string `reform:\"job\"`", "del_tokens": "JobID string `reform:\"job\"`", "commit_type": "implement"}
{"commit_tokens": ["Add", "support", "for", "the", "login", "command"], "add_tokens": "\" \" jar , _ := cookiejar . New ( nil ) Jar : jar , if ! cs . HTTPGETOnly && ( api == \" \" || api == \" \" || api == \" \" ) {", "del_tokens": "if ! cs . HTTPGETOnly && ( api == \" \" || api == \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "scheduled", "job", "cancel", "button"], "add_tokens": "// JobStatusCancelled job status cancelled JobStatusCancelled = \" \" if qorJob . GetStatus ( ) != JobStatusNew && qorJob . GetStatus ( ) != JobStatusScheduled {", "del_tokens": "if qorJob . GetStatus ( ) != JobStatusNew {", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", ":", "slienced", "is", "a", "misspelling", "of", "silenced"], "add_tokens": "// header was sent yet. The panic is not silenced tho and is propagated to the", "del_tokens": "// header was sent yet. The panic is not slienced tho and is propagated to the", "commit_type": "fix"}
{"commit_tokens": ["Fix", "attachment", "of", "Print", "example"], "add_tokens": "func ExamplePrint ( ) {", "del_tokens": "func ExampleConfig_Print ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "mutex", "to", "synchronize", "access", "to", "struct", "fields"], "add_tokens": "type hkServer struct { mutex * sync . Mutex container * container . Container port string listener * net . TCPListener // os gives us a free Port when Port is \"\" ln , err := net . Listen ( \" \" , \" \" ) if err != nil { log . Fatal ( err ) } port := ExtractPort ( ln . Addr ( ) ) listener : ln . ( * net . TCPListener ) , port : port , listener := netio . NewTCPHAPListener ( s . listener , context )", "del_tokens": "type hkServer struct { port string container * container . Container mutex * sync . Mutex // os gives us a free Port when Port is \"\" ln , err := net . Listen ( \" \" , \" \" ) if err != nil { return err } s . port = ExtractPort ( ln . Addr ( ) ) listener := netio . NewTCPHAPListener ( ln . ( * net . TCPListener ) , context )", "commit_type": "use"}
{"commit_tokens": ["Fix", "int", "overflow", "on", "32", "bits", "systems"], "add_tokens": "got := [ ] int64 { r . Int63 ( ) , r . Int63 ( ) , r . Int63 ( ) , r . Int63 ( ) , r . Int63 ( ) } want := [ ] int64 {", "del_tokens": "got := [ ] int { r . Int ( ) , r . Int ( ) , r . Int ( ) , r . Int ( ) , r . Int ( ) } want := [ ] int {", "commit_type": "fix"}
{"commit_tokens": ["Added", "TODO", "list", "and", "changed", "method", "name", "SortedURLs", "=", ">", "SortedSanitizedURLs"], "add_tokens": "func ( schemaSet * SchemaSet ) SortedSanitizedURLs ( ) [ ] string {", "del_tokens": "func ( schemaSet * SchemaSet ) SortedURLs ( ) [ ] string {", "commit_type": "add"}
{"commit_tokens": ["added", "a", "GetContext", "function", "to", "get", "webgo", "context", "from", "HTTP", "request", "context"], "add_tokens": "const ( urlchars = `([^/]+)` urlwildcard = `(.+)` errMultiHeaderWrite = `http: multiple response.WriteHeader calls` errMultiWrite = `http: multiple response.Write calls` wgoCtxKey = \" \" ) reqwc := req . WithContext ( context . WithValue ( req . Context ( ) , wgoCtxKey , wc ) ) //GetContext returns the WebgoContext saved inside the HTTP request context func GetContext ( r * http . Request ) * WC { return r . Context ( ) . Value ( wgoCtxKey ) . ( * WC ) }", "del_tokens": "const urlchars = `([^/]+)` const urlwildcard = `(.+)` const errMultiHeaderWrite = `http: multiple response.WriteHeader calls` const errMultiWrite = `http: multiple response.Write calls` reqwc := req . WithContext ( context . WithValue ( req . Context ( ) , \" \" , wc ) )", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "html", "escaper", "properly", "escapes", "non", "-", "ASCII", "chars"], "add_tokens": "testHTMLEscapeWriter ( t , \" z\" , & l ;", "del_tokens": "testHTMLEscapeWriter ( t , \" \" , \" \" )", "commit_type": "make"}
{"commit_tokens": ["make", "methods", "of", "usbTransfer", "private"], "add_tokens": "defer t . free ( ) if err := t . submit ( timeout ) ; err != nil { n , err := t . wait ( buf )", "del_tokens": "defer t . Close ( ) if err := t . Submit ( timeout ) ; err != nil { n , err := t . Wait ( buf )", "commit_type": "make"}
{"commit_tokens": ["Added", "time", "quantum", "support", "for", "Databases", "and", "Frames", ";", "removed", "Exists", "suffix", "from", "Ensure", "functions", ";", "added", "setters", "for", "DatabaseOptions", "and", "FrameOptions", ";", "removed", "ColumnLabelDatabaseOption", "and", "RowLabelDatabaseOption"], "add_tokens": "options := DefaultDatabaseOptions ( ) err := options . SetColumnLabel ( \" \" ) t . Fatalf ( \" \" ) options := DefaultFrameOptions ( ) err := options . SetRowLabel ( \" \" ) options = DefaultDatabaseOptions ( ) err = options . SetColumnLabel ( columnLabel ) options = DefaultFrameOptions ( ) err = options . SetRowLabel ( rowLabel )", "del_tokens": "_ , err := ColumnLabelDatabaseOption ( \" \" ) t . Fatalf ( \" \" ) _ , err := RowLabelFrameOption ( \" \" ) options , err = ColumnLabelDatabaseOption ( columnLabel ) options , err = RowLabelFrameOption ( rowLabel )", "commit_type": "add"}
{"commit_tokens": ["Use", "S3", "region", "from", "AWS_REGION", "if", "provided"], "add_tokens": "config := aws . DefaultConfig . Copy ( ) if config . Region == \" \" { config . Region = \" \" } svc := s3 . New ( & config )", "del_tokens": "svc := s3 . New ( & aws . Config { Region : \" \" , } )", "commit_type": "use"}
{"commit_tokens": ["remove", "session", "data", "store", "from", "connection", "type"], "add_tokens": "ID string // Randomly generated unique connection ID // NewConn creates a new neptulon.Conn object which wraps the given tls.Conn object.", "del_tokens": "\" \" ID string // Randomly generated unique connection ID Data * cmap . CMap // Thread-safe data store for storing arbitrary data for this connection session // NewConn creates a new neptulon.Conn object which wraps a given tls.Conn object. Data : cmap . New ( ) ,", "commit_type": "remove"}
{"commit_tokens": ["fix", "typo", "in", "struct", "field", "name"], "add_tokens": "OverflowPages uint64 // Number of overflow pages OverflowPages : uint64 ( _stat . ms_overflow_pages ) ,", "del_tokens": "OwerflowPages uint64 // Number of overflow pages OwerflowPages : uint64 ( _stat . ms_overflow_pages ) ,", "commit_type": "fix"}
{"commit_tokens": ["use", "cache", "print", "can", "print", "normal", "text"], "add_tokens": "//fmt.Printf(\"%s\\n\", c.listCache.debug()) buff , err := c . listCache . toStream ( ) if err != nil { return err } fmt . Printf ( \" \\n \" , buff . String ( ) ) //c.stream.WriteTo(buff) buff . WriteTo ( & c . stream ) var err error c . getRoot ( ) . Curr . X , c . getRoot ( ) . Curr . Y , err = c . listCache . appendTextToCache ( cache , text )", "del_tokens": "fmt . Printf ( \" \\n \" , c . listCache . debug ( ) ) err := c . listCache . appendTextToCache ( cache , text )", "commit_type": "use"}
{"commit_tokens": ["Implemented", "replay", "rate", "based", "on", "timing", "."], "add_tokens": "\" \" speed := flag . Float64 ( \" \" , 1 , \" \" ) logStartTime := - 1 replayStartTime := time . Now ( ) eventTime := int ( ( op [ \" \" ] . ( bson . MongoTimestamp ) ) >> 32 ) if logStartTime == - 1 { logStartTime = eventTime } for time . Now ( ) . Sub ( replayStartTime ) . Seconds ( ) * * speed < float64 ( eventTime - logStartTime ) { time . Sleep ( time . Duration ( 10 ) * time . Millisecond ) }", "del_tokens": "// speed := flag.Float64(\"speed\", 1, \"Sets multiplier for playback speed.\")", "commit_type": "implement"}
{"commit_tokens": ["Make", "Sequence", "mutator", "take", "an", "xdr", ".", "SequenceNumber"], "add_tokens": "import ( \" \" \" \" ) Sequence xdr . SequenceNumber", "del_tokens": "import \" \" Sequence int64", "commit_type": "make"}
{"commit_tokens": ["Adds", "subexpression", "support", "with", "tests"], "add_tokens": "return node . Expression . Accept ( v )", "del_tokens": "// @todo return nil", "commit_type": "add"}
{"commit_tokens": ["add", "voice", "target", "packet", "support"], "add_tokens": "// types implement this interface: AudioBuffer, AccessTokens, BanList, // RegisteredUsers, TextMessage, and VoiceTarget.", "del_tokens": "// public types implement this interface: AudioBuffer, AccessTokens, BanList, // RegisteredUsers, and TextMessage.", "commit_type": "add"}
{"commit_tokens": ["Use", "NewMemoryStoreWithOptions", "in", "tests", "."], "add_tokens": "// TestLimiterMemory tests Limiter with memory store. store := NewMemoryStoreWithOptions ( StoreOptions { Prefix : \" \" , CleanUpInterval : 30 * time . Second , } ) // TestLimiterRedis tests Limiter with Redis store.", "del_tokens": "store := NewMemoryStore ( \" \" , 30 * time . Second ) // TestLimiterRedis tests ratelimit.Limiter with Redis store.", "commit_type": "use"}
{"commit_tokens": ["change", "https", "bool", "to", "scheme", "string"], "add_tokens": "t . scheme = \" \" t . scheme = \" \"", "del_tokens": "t . https = false t . https = true", "commit_type": "change"}
{"commit_tokens": ["Add", "support", "for", "slices", "of", "other", "uint", "and", "int", "types"], "add_tokens": "case reflect . Uint8 , reflect . Uint16 , reflect . Uint32 , reflect . Uint64 , reflect . Uint : case reflect . Int8 , reflect . Int16 , reflect . Int32 , reflect . Int64 , reflect . Int : safeArray := prop . ToArray ( ) if safeArray != nil { arr := safeArray . ToValueArray ( ) fArr := reflect . MakeSlice ( f . Type ( ) , len ( arr ) , len ( arr ) ) for i , v := range arr { s := fArr . Index ( i ) s . SetInt ( reflect . ValueOf ( v ) . Int ( ) ) } f . Set ( fArr ) }", "del_tokens": "case reflect . Uint8 :", "commit_type": "add"}
{"commit_tokens": ["Fix", "broken", "css", "rules", "output"], "add_tokens": "lineNumbersStyle := \" \" // all rules begin with default rules followed by user provided rules classes [ chroma . LineNumbers ] = lineNumbersStyle + classes [ chroma . LineNumbers ] classes [ chroma . LineNumbersTable ] = lineNumbersStyle + \" \" + classes [ chroma . LineNumbersTable ] classes [ chroma . LineHighlight ] = \" \" + classes [ chroma . LineHighlight ] classes [ chroma . LineTable ] = \" \" + classes [ chroma . LineTable ] classes [ chroma . LineTableTD ] = \" \" + classes [ chroma . LineTableTD ]", "del_tokens": "lineNumbersStyle := \" \" classes [ chroma . LineNumbers ] += lineNumbersStyle classes [ chroma . LineNumbersTable ] += lineNumbersStyle + \" \" classes [ chroma . LineHighlight ] += \" \" classes [ chroma . LineTable ] += \" \" classes [ chroma . LineTableTD ] += \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "gomol", "config", "with", "options", "to", "add", "filename", "and", "line", "number", "attrs", "when", "logging", "messages"], "add_tokens": "import \" \" config * Config config : NewConfig ( ) , // SetConfig will set the configuration for the Base to the given Config func ( b * Base ) SetConfig ( config * Config ) { b . config = config } if len ( b . config . FilenameAttr ) > 0 || len ( b . config . LineNumberAttr ) > 0 { file , line := getCallerInfo ( ) if m == nil { m = make ( map [ string ] interface { } ) } if len ( b . config . FilenameAttr ) > 0 { m [ b . config . FilenameAttr ] = file } if len ( b . config . LineNumberAttr ) > 0 { m [ b . config . LineNumberAttr ] = line } }", "del_tokens": "import ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fixing", "for", "100", "-", "character", "line", "limit", "."], "add_tokens": "// Every function for writing into the MockLogFile should acquire the lock via either Write() // or writeWithHeader(). func ( mlf * MockLogFile ) writeWithHeader ( contents [ ] byte , logEventType mysql_proto . LogEventType_Type ) {", "del_tokens": "// Every function for writing into the MockLogFile should acquire the lock via either Write() or writeWithHeader(). func ( mlf * MockLogFile ) writeWithHeader ( contents [ ] byte , logEventType mysql_proto . LogEventType_Type ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// ClearSentData: newrelic_platform_go.IComponent interface implementation", "del_tokens": "// newrelic_platform_go.IComponent interface implementation", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "8", "bytes", "of", "message", "length", "to", "the", "total", "size", "of", "the", "slice"], "add_tokens": "m . length = uint64 ( len ( m . data ) + len ( m . nonce ) + 8 ) encryptedMessage . length = uint64 ( len ( encryptedMessage . data ) + len ( encryptedMessage . nonce ) + 8 )", "del_tokens": "m . length = uint64 ( len ( m . data ) + len ( m . nonce ) ) encryptedMessage . length = uint64 ( len ( encryptedMessage . data ) + len ( encryptedMessage . nonce ) )", "commit_type": "add"}
{"commit_tokens": ["make", "Decode", "(", "[]", "byte", ")", "canonicalize", "the", "CBOR", "."], "add_tokens": "// Decode a CBOR object into an IPLD Node. // // If passed a non-canonical CBOR node, this function will canonicalize it. // Therefore, `bytes.Equal(b, Decode(b).RawData())` may not hold. If you already // have a CID for this data and want to ensure that it doesn't change, you // should use `DecodeBlock`. // // Note: This function does not hold onto `b`. You may reuse it. func Decode ( b [ ] byte ) ( * Node , error ) { m , err := decodeCBOR ( b ) // We throw away `b` here to ensure that we canonicalize the encoded // CBOR object. return WrapObject ( m ) } // Decode a CBOR encoded Block into an IPLD Node. // // This method *does not* canonicalize and *will* preserve the CID. As a matter // of fact, it will assume that `block.Cid()` returns the correct CID and will // make no effort to validate this assumption. // // In general, you should not be calling this method directly. Instead, you // should be calling the `Decode` method from the `go-ipld-format` package. That // method will pick the right decoder based on the Block's CID. // // Note: This function keeps a reference to `block` and assumes that it is // immutable.", "del_tokens": "func Decode ( b [ ] byte ) ( n * Node , err error ) { hash , err := mh . Sum ( b , mh . SHA2_256 , - 1 ) if err != nil { return nil , err } c := cid . NewCidV1 ( cid . DagCBOR , hash ) block , err := blocks . NewBlockWithCid ( b , c ) return DecodeBlock ( block ) }", "commit_type": "make"}
{"commit_tokens": ["Updated", "how", "echoResp", "is", "created", "for", "type", "handlers", "."], "add_tokens": "echoResp := NewEchoResponse ( )", "del_tokens": "var echoResp * EchoResponse", "commit_type": "update"}
{"commit_tokens": ["make", "collector", "exit", "on", "close", "request"], "add_tokens": "return", "del_tokens": "break", "commit_type": "make"}
{"commit_tokens": ["Added", "support", "for", "annotated", "tags"], "add_tokens": "\" \" type SuiteRepository struct { repos map [ string ] * Repository } func ( s * SuiteRepository ) SetUpTest ( c * C ) { s . repos = unpackFixtures ( c , tagFixtures ) } func ( s * SuiteRepository ) TestTag ( c * C ) { for i , t := range tagTests { r , ok := s . repos [ t . repo ] c . Assert ( ok , Equals , true ) k := 0 for hash , expected := range t . tags { tag , err := r . Tag ( core . NewHash ( hash ) ) c . Assert ( err , IsNil ) testTagExpected ( c , tag , expected , fmt . Sprintf ( \" \" , i , k ) ) k ++ } } } func ( s * SuiteRepository ) TestTags ( c * C ) { for i , t := range tagTests { r , ok := s . repos [ t . repo ] c . Assert ( ok , Equals , true ) testTagIter ( c , r . Tags ( ) , t . tags , fmt . Sprintf ( \" \" , i ) ) } }", "del_tokens": "type SuiteRepository struct { }", "commit_type": "add"}
{"commit_tokens": ["add", "a", "test", "for", "node", "removal"], "add_tokens": "}", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Change", "output", "format", "of", "values", "to", "be", "the", "same", "as", "patterns"], "add_tokens": "case resource . Values : if r . Result { return fmt . Sprintf ( \" \" , r . ResourceType , r . Title , r . Property , strings . Join ( r . Expected , \" \" ) ) } else { return fmt . Sprintf ( \" \" , r . ResourceType , r . Title , r . Property , strings . Join ( r . Expected , \" \" ) ) }", "del_tokens": "case resource . Values : if r . Result { return fmt . Sprintf ( \" \" , r . ResourceType , r . Title , r . Property ) } else { return fmt . Sprintf ( \" \" , r . ResourceType , r . Title , r . Property , strings . Join ( r . Expected , \" \" ) , strings . Join ( r . Found , \" \" ) ) }", "commit_type": "change"}
{"commit_tokens": ["Fix", "error", "handling", "and", "reporting"], "add_tokens": "\" \" return nil , & errors . HttpError { errors . StatusTooManyRequests , fmt . Sprintf ( \" \" , cl . maxConnections , connections ) , }", "del_tokens": "return nil , fmt . Errorf ( \" \" , cl . maxConnections , connections )", "commit_type": "fix"}
{"commit_tokens": ["Use", "io", ".", "ReadCloser", "+", "json", ".", "NewDecoder"], "add_tokens": "func ( c * Client ) executeRaw ( method string , urlStr string , text string ) ( io . ReadCloser , error ) { resBody , err := c . doRawRequest ( req , emptyResponse ) defer resBody . Close ( ) if err := json . NewDecoder ( resBody ) . Decode ( & result ) ; err != nil { return resBody , err func ( c * Client ) doRawRequest ( req * http . Request , emptyResponse bool ) ( io . ReadCloser , error ) { resp . Body . Close ( ) resp . Body . Close ( ) resp . Body . Close ( ) return resp . Body , nil", "del_tokens": "\" \" func ( c * Client ) executeRaw ( method string , urlStr string , text string ) ( [ ] byte , error ) { resBodyBytes , err := c . doRawRequest ( req , emptyResponse ) err = json . Unmarshal ( resBodyBytes , & result ) if err != nil { return resBodyBytes , err func ( c * Client ) doRawRequest ( req * http . Request , emptyResponse bool ) ( [ ] byte , error ) { if resp . Body != nil { defer resp . Body . Close ( ) } return ioutil . ReadAll ( resp . Body )", "commit_type": "use"}
{"commit_tokens": ["Adding", "create", "stash", "but", "with", "failing", "tests", "..."], "add_tokens": "return nil , fmt . Errorf ( \" \" , err , err ) // CreateStashPath create a stash at path func ( s * Sensu ) CreateStashPath ( path string , payload map [ string ] interface { } ) ( map [ string ] interface { } , error ) { // return s.Post(fmt.Sprintf(\"stashes/create\"), payload) payloadstr , err := json . Marshal ( payload ) if err != nil { return nil , fmt . Errorf ( \" \" , err , err ) } return s . PostPayload ( fmt . Sprintf ( \" \" , path ) , string ( payloadstr [ : ] ) ) }", "del_tokens": "return nil , fmt . Errorf ( \" \" , err , err )", "commit_type": "add"}
{"commit_tokens": ["add", "limit", "test", "and", "fix", "limit", "bug"], "add_tokens": "ps [ \" \" ] = fmt . Sprintf ( \" \" , o . Limit . Int64 ) ps [ \" \" ] = fmt . Sprintf ( \" \" , o . Offset . Int64 ) ps [ \" \" ] = fmt . Sprintf ( \" \" , o . Sort . Int64 )", "del_tokens": "ps [ \" \" ] = string ( o . Limit . Int64 ) ps [ \" \" ] = string ( o . Offset . Int64 ) ps [ \" \" ] = string ( o . Sort . Int64 )", "commit_type": "add"}
{"commit_tokens": ["Add", "fun", "GetByStatus", "to", "ArticleService"], "add_tokens": "gomock \" \" func ( _m * MockIArticleService ) FindByStatus ( status string ) [ ] models . Article { ret := _m . ctrl . Call ( _m , \" \" , status ) ret0 , _ := ret [ 0 ] . ( [ ] models . Article ) return ret0 } func ( _mr * _MockIArticleServiceRecorder ) FindByStatus ( arg0 interface { } ) * gomock . Call { return _mr . mock . ctrl . RecordCall ( _mr . mock , \" \" , arg0 ) }", "del_tokens": "gomock \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "github", "and", "gitlab", "integration", "in", "readme"], "add_tokens": "// Init will initialize database to create tables automatically. database := \" \" // The datasource looks like \"root:root@/archci?charset=utf8\". // Main is the entry to start beego application.", "del_tokens": "database := \" \" // \"root:root@/archci?charset=utf8\"", "commit_type": "add"}
{"commit_tokens": ["Fix", "function", "comments", "based", "on", "best", "practices", "from", "Effective", "Go"], "add_tokens": "// SetStore: if external kvstore exists, set store to context", "del_tokens": "// if external kvstore exists, set store to context", "commit_type": "fix"}
{"commit_tokens": ["adding", "handling", "for", "leading", "or", "trailing", "whitespace", "in", "header", "columns"], "add_tokens": "// fieldInfo is a struct field that should be mapped to a CSV column, or vice-versa if key == k || strings . TrimSpace ( key ) == k {", "del_tokens": "// fieldInfo is a struct field that should be mapped to a CSV column, or vica-versa if key == k {", "commit_type": "add"}
{"commit_tokens": ["improve", "the", "error", "messages", "when", "we", "re", "unable", "to", "parse", "something"], "add_tokens": "require . Equal ( t , `envconfig: unable to parse value \"foobar\" for possible keys [SHARDS shards]. err=struct token has 1 fields but struct has 2` , err . Error ( ) ) require . Equal ( t , `envconfig: unable to parse value \"{foobar,barbaz}\" for possible keys [SHARDS shards]. err=envconfig: unable to parse value \"barbaz\" for possible keys [SHARDS shards]. err=strconv.ParseInt: parsing \"barbaz\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `envconfig: unable to parse value \"foobar\" for possible keys [OK ok]. err=strconv.ParseBool: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `envconfig: unable to parse value \"foobar\" for possible keys [PORT port]. err=strconv.ParseInt: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `envconfig: unable to parse value \"foobar\" for possible keys [PORT port]. err=strconv.ParseUint: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `envconfig: unable to parse value \"foobar\" for possible keys [PORT port]. err=strconv.ParseFloat: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `envconfig: unable to parse value \"foobar\" as bytes for possible keys [DATA data]. err=illegal base64 data at input byte 4` , err . Error ( ) )", "del_tokens": "require . Equal ( t , \" \" , err . Error ( ) ) require . Equal ( t , `strconv.ParseInt: parsing \"barbaz\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `strconv.ParseBool: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `strconv.ParseInt: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `strconv.ParseUint: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , `strconv.ParseFloat: parsing \"foobar\": invalid syntax` , err . Error ( ) ) require . Equal ( t , \" \" , err . Error ( ) )", "commit_type": "improve"}
{"commit_tokens": ["add", "Config", "struct", "allow", "specifying", "Lua", "name", "generator", "functions", "for", "struct", "fields", "and", "methods"], "add_tokens": "// By default, the name of a struct field is determined by its tag:", "del_tokens": "// The name of a struct field is determined by its tag:", "commit_type": "add"}
{"commit_tokens": ["Add", "functions", "to", "return", "rejected", "deliveries"], "add_tokens": "returned , err := queue . ReturnAllUnackedDeliveries ( )", "del_tokens": "returned , err := queue . ReturnUnackedDeliveries ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "TODO", "for", "response", "error", "handling"], "add_tokens": "respErr := handleErrors ( body ) // TODO distinguish parsing error vs response error", "del_tokens": "respErr := handleErrors ( body )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "anonymous", "structs"], "add_tokens": "case * ast . StructType : // anonymous struct atype := aspec . Type . ( * ast . StructType ) return compareStructType ( btype , atype ) return compareStructType ( btype , atype ) func compareStructType ( before , after * ast . StructType ) ( changeType , string ) { // structs don't care if fields were added added , removed , changed := diffFields ( before . Fields . List , after . Fields . List ) if len ( removed ) > 0 { // Fields were removed return changeBreaking , \" \" } else if len ( changed ) > 0 { // Fields changed types return changeBreaking , \" \" } else if len ( added ) > 0 { return changeNonBreaking , \" \" } return changeNone , \" \" }", "del_tokens": "// structs don't care if fields were added added , removed , changed := diffFields ( btype . Fields . List , atype . Fields . List ) if len ( removed ) > 0 { // Fields were removed return changeBreaking , \" \" } else if len ( changed ) > 0 { // Fields changed types return changeBreaking , \" \" } else if len ( added ) > 0 { return changeNonBreaking , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Improve", "code", "coverage", "for", "config", "."], "add_tokens": "want : \" \" , conf : DefaultConfig ( ) , // url scheme { want : \" \" , conf : DefaultConfig ( ) , req : & http . Request { Header : http . Header { } , URL : & url . URL { Scheme : \" \" , } , } , } , // X-Host headers { want : \" \" , conf : Config { \" \" , \" \" , \" \" } , req : & http . Request { Header : http . Header { \" \" : { \" \" } , } , URL : & url . URL { } , } , } , // URL Host { want : \" \" , conf : Config { \" \" , \" \" , \" \" } , req : & http . Request { Header : http . Header { } , URL : & url . URL { Host : \" \" , } , } , } ,", "del_tokens": "want : \" \" , conf : Config { \" \" , \" \" , \" \" } ,", "commit_type": "improve"}
{"commit_tokens": ["Use", "hmac", ".", "New", "instead", "of", "hmac", ".", "NewSHA256", "."], "add_tokens": "\" \" m := hmac . New ( sha256 . New , secret ) keym := hmac . New ( sha256 . New , secret ) m := hmac . New ( sha256 . New , keym . Sum ( nil ) )", "del_tokens": "m := hmac . NewSHA256 ( secret ) keym := hmac . NewSHA256 ( secret ) m := hmac . NewSHA256 ( keym . Sum ( nil ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "lint", "issues", "and", "add", "package", "comment"], "add_tokens": "_ , exprs , gotComma , err := p . parseCommaList ( tokenParenR , elementKind ) return ids , gotComma , nil gotComma := false if ! first && ! gotComma { gotComma = true return p . pop ( ) , exprs , gotComma , nil if ! first && ! gotComma { gotComma = false params , gotComma , err := p . parseIdentifierList ( \" \" ) trailingComma : gotComma , return nil , makeStaticError ( fmt . Sprintf ( \" \" , next ) , next . loc )", "del_tokens": "_ , exprs , got_comma , err := p . parseCommaList ( tokenParenR , elementKind ) return ids , got_comma , nil got_comma := false if ! first && ! got_comma { got_comma = true return p . pop ( ) , exprs , got_comma , nil if ! first && ! got_comma { got_comma = false params , got_comma , err := p . parseIdentifierList ( \" \" ) trailingComma : got_comma , } else { return nil , makeStaticError ( fmt . Sprintf ( \" \" , next ) , next . loc )", "commit_type": "fix"}
{"commit_tokens": ["Add", "http", ".", "Handler", "helpers", "(", "adapted", "from", "xlog", ")"], "add_tokens": "if lp , ok := ctx . Value ( ctxKey { } ) . ( * Logger ) ; ok { // Update existing pointer. * lp = l return ctx } return context . WithValue ( ctx , ctxKey { } , & l ) if l , ok := ctx . Value ( ctxKey { } ) . ( * Logger ) ; ok { return * l", "del_tokens": "return context . WithValue ( ctx , ctxKey { } , l ) if l , ok := ctx . Value ( ctxKey { } ) . ( Logger ) ; ok { return l", "commit_type": "add"}
{"commit_tokens": ["Fix", "set", "value", "on", "nested", "field"], "add_tokens": "value := & f . value // value must be settable so we need to make sure it holds the address of the // variable and not a copy, so we can pass the pointer to strctVal instead of a // copy (which is not assigned to any variable, hence not settable). // see \"https://blog.golang.org/laws-of-reflection#TOC_8.\" if f . value . Kind ( ) != reflect . Ptr { a := f . value . Addr ( ) value = & a } v := strctVal ( value . Interface ( ) )", "del_tokens": "v := strctVal ( f . value . Interface ( ) )", "commit_type": "fix"}
{"commit_tokens": ["move", "importer", "into", "pdk", "lib"], "add_tokens": "client pdk . PilosaImporter frames := [ ] string { netSrcFrame , netDstFrame , tranSrcFrame , tranDstFrame , netProtoFrame , transProtoFrame , appProtoFrame , hostnameFrame , methodFrame , contentTypeFrame , userAgentFrame , packetSizeFrame , TCPFlagsFrame } m . client = pdk . NewImportClient ( m . PilosaHost , m . Database , frames )", "del_tokens": "client SetBit m . client = NewImportClient ( m . PilosaHost , m . Database )", "commit_type": "move"}
{"commit_tokens": ["Add", "a", "missing", "unit", "test"], "add_tokens": "n := make ( EventsList , 0 ) fmt . Fprint ( w , `{\"uuid\": \"x\", \"events\": [{\"type\": \"CREATE\", \"entityType\": \"fake\", \"updateMechanism\": \"DEFAULT\", \"entities\": [{\"ID\": \"x\"}]}]}` ) fmt . Fprint ( w , `{\"uuid\": \"y\", \"events\": [{\"type\": \"CREATE\", \"entityType\": \"notfake\", \"updateMechanism\": \"DEFAULT\", \"entities\": [{\"ID\": \"y\"}]}]}` ) fmt . Fprint ( w , `{\"uuid\": \"z\", \"events\": [{\"type\": \"CREATE\", \"entityType\": \"fake\", \"updateMechanism\": \"DEFAULT\", \"entities\": [{\"ID\": \"z\"}]}]}` ) h1 := func ( e * Event ) { n = append ( n , e ) } h2 := func ( e * Event ) { n = append ( n , e ) } So ( len ( n ) , ShouldEqual , 3 ) } ) Convey ( \" \" , func ( ) { So ( string ( n [ 0 ] . Data ) , ShouldEqual , `{\"ID\":\"x\"}` ) So ( string ( n [ 1 ] . Data ) , ShouldEqual , `{\"ID\":\"x\"}` ) So ( string ( n [ 2 ] . Data ) , ShouldEqual , `{\"ID\":\"y\"}` )", "del_tokens": "n := 0 fmt . Fprint ( w , `{\"uuid\": \"x\", \"events\": [{\"type\": \"CREATE\", \"entityType\": \"fake\", \"updateMechanism\": \"DEFAULT\", \"entities\": [{}]}]}` ) fmt . Fprint ( w , `{\"uuid\": \"y\", \"events\": [{\"type\": \"CREATE\", \"entityType\": \"notfake\", \"updateMechanism\": \"DEFAULT\", \"entities\": [{}]}]}` ) fmt . Fprint ( w , `{\"uuid\": \"z\", \"events\": [{\"type\": \"CREATE\", \"entityType\": \"fake\", \"updateMechanism\": \"DEFAULT\", \"entities\": [{}]}]}` ) h1 := func ( * Event ) { n ++ } h2 := func ( * Event ) { n ++ } So ( n , ShouldEqual , 3 )", "commit_type": "add"}
{"commit_tokens": ["Change", "standard", "time", "outout", "to", "RFC3339"], "add_tokens": "\" \" : now , \" \" : now , func now ( help plush . HelperContext ) string { return time . Now ( ) . Format ( time . RFC3339 ) }", "del_tokens": "\" \" : time . Now , \" \" : time . Now ,", "commit_type": "change"}
{"commit_tokens": ["Implement", "nullsafe", "navigation", ".", "TestDataRefs", "works", "."], "add_tokens": "// TODO: If all params are optional, then initialize opt_data = opt_data || {}; var expr string expr = \" \" expr = genVarName expr = \" \" + node . Key // Nullsafe access makes this complicated. // FOO.BAR?.BAZ => (FOO.BAR == null ? null : FOO.BAR.BAZ) if node . NullSafe { s . js ( \" \" , expr , \" \" ) } expr += \" \" + strconv . Itoa ( node . Index ) + \" \" if node . NullSafe { s . js ( \" \" , expr , \" \" ) } expr += \" \" + node . Key if node . NullSafe { s . js ( \" \" , expr , \" \" ) } var buf bytes . Buffer ( & state { wr : & buf , scope : s . scope } ) . walk ( node . Arg ) expr += \" \" + buf . String ( ) + \" \" s . js ( expr )", "del_tokens": "s . js ( \" \" ) s . js ( genVarName ) s . js ( \" \" , node . Key ) s . js ( \" \" , strconv . Itoa ( node . Index ) , \" \" ) s . js ( \" \" , node . Key ) s . js ( \" \" ) s . walk ( node . Arg ) s . js ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["Add", "a", "RelationNotFoundError", "and", "test", "that", "it", "is", "thrown", "when", "appropriate"], "add_tokens": "return nil , NewRelationNotFoundError ( relationName )", "del_tokens": "// TODO: return some type of error here? return nil , nil", "commit_type": "add"}
{"commit_tokens": ["Fix", "support", "for", "AnythingOfTypeArgument", "."], "add_tokens": "var args Arguments = [ ] interface { } { \" \" , AnythingOfType ( \" \" ) , true } _ , count = args . Diff ( [ ] interface { } { \" \" , 123 , true } ) var args Arguments = [ ] interface { } { \" \" , AnythingOfType ( \" \" ) , true } diff , count = args . Diff ( [ ] interface { } { \" \" , 123 , true } )", "del_tokens": "var args Arguments = [ ] interface { } { \" \" , 123 , true } _ , count = args . Diff ( [ ] interface { } { \" \" , AnythingOfType ( \" \" ) , true } ) var args Arguments = [ ] interface { } { \" \" , 123 , true } diff , count = args . Diff ( [ ] interface { } { \" \" , AnythingOfType ( \" \" ) , true } )", "commit_type": "fix"}
{"commit_tokens": ["added", "executor", "tests", "for", "Abort", "()"], "add_tokens": "driver . status = mesosproto . Status_DRIVER_NOT_STARTED driver . stopped = true log . Errorf ( \" \\n \" , err ) return driver . status , err return driver . status , err if driver . status != mesosproto . Status_DRIVER_RUNNING { if driver . status != mesosproto . Status_DRIVER_RUNNING { return driver . status }", "del_tokens": "msg := fmt . Sprintf ( \" \\n \" , err ) log . Errorf ( msg ) return mesosproto . Status_DRIVER_NOT_STARTED , err return mesosproto . Status_DRIVER_NOT_STARTED , err if driver . status != mesosproto . Status_DRIVER_RUNNING && driver . status != mesosproto . Status_DRIVER_ABORTED {", "commit_type": "add"}
{"commit_tokens": ["Add", "stub", "for", "Runtime", "test"], "add_tokens": "import ( \" \" \" \" ) spy , c , cas := & Spy { } , make ( chan EventInfo , 1 ) , fixture . Cases ( t ) r , p := newRuntime ( spy ) , cas . path ( \" \" ) calls := & Spy { { T : TypeFanin } , { T : TypeWatch , P : p , E : Delete } , } if err := r . Watch ( p , c , Delete ) ; err != nil { t . Fatalf ( \" \" , err ) } if ! reflect . DeepEqual ( spy , calls ) { t . Errorf ( \" \" , calls , spy ) }", "del_tokens": "import \" \" t . Skip ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Use", "and", "parse", "/", "proc", "cmdline", "to", "report", "process", "name", "/", "args"], "add_tokens": "d := & Discovery { PID : os . Getpid ( ) } d . Name , d . Args = getCommandLine ( )", "del_tokens": "d := & Discovery { PID : os . Getpid ( ) , Name : os . Args [ 0 ] , Args : os . Args [ 1 : ] }", "commit_type": "use"}
{"commit_tokens": ["Add", "some", "delay", "to", "livetestprog"], "add_tokens": "time . Sleep ( 1 * time . Second )", "del_tokens": "time . Sleep ( 3 * time . Millisecond )", "commit_type": "add"}
{"commit_tokens": ["Fix", "local", "bind", "body", "not", "being", "desugared"], "add_tokens": "for i := range ast . binds { err = desugar ( & ast . binds [ i ] . body , objLevel )", "del_tokens": "for _ , bind := range ast . binds { err = desugar ( & bind . body , objLevel )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "regex", "matching", "when", "running", "tests"], "add_tokens": "\" \" func TestRegex ( t * testing . T ) { fakeTest := testing . T { } os . Args = append ( os . Args , \" \" ) parseFlags ( ) g := Goblin ( & fakeTest ) g . Describe ( \" \" , func ( ) { g . It ( \" \" , func ( ) { g . Fail ( \" \" ) } ) g . It ( \" \" , func ( ) { } ) g . It ( \" \" , func ( ) { } ) } ) if fakeTest . Failed ( ) { t . Fatal ( \" \" ) } // Reset the regex so other tests can run runRegex = nil } os . Args = append ( os . Args , \" \" , \" \" ) parseFlags ( ) g := Goblin ( & fakeTest )", "del_tokens": "g := Goblin ( & fakeTest , \" \" )", "commit_type": "add"}
{"commit_tokens": ["allow", "exported", "TableSchema", "to", "set", "tmpschema", "allowing", "multiple", "concurrent", "jobs"], "add_tokens": "tables map [ string ] postgres . TableSchema , schema , tmpschema , s3prefix , awsRegion string , delim rune ) error { if _ , err := r . logAndExec ( fmt . Sprintf ( `CREATE SCHEMA \"%s\"` , tmpschema ) , false ) ; err != nil { if err := r . refreshTable ( schema , name , tmpschema , postgres . S3Filename ( s3prefix , name ) , awsRegion , ts , delim ) ; err != nil { if _ , err := r . logAndExec ( fmt . Sprintf ( `DROP SCHEMA \"%s\" CASCADE` , tmpschema ) , false ) ; err != nil {", "del_tokens": "tmpschema = flag . String ( \" \" , \" \" , \" \" ) tables map [ string ] postgres . TableSchema , schema , s3prefix , awsRegion string , delim rune ) error { if _ , err := r . logAndExec ( fmt . Sprintf ( `CREATE SCHEMA \"%s\"` , * tmpschema ) , false ) ; err != nil { if err := r . refreshTable ( schema , name , * tmpschema , postgres . S3Filename ( s3prefix , name ) , awsRegion , ts , delim ) ; err != nil { if _ , err := r . logAndExec ( fmt . Sprintf ( `DROP SCHEMA \"%s\" CASCADE` , * tmpschema ) , false ) ; err != nil {", "commit_type": "allow"}
{"commit_tokens": ["Adding", "OCI", "column", "indicator", "and", "handling", "NULLS"], "add_tokens": "unsafe . Pointer ( & oci8cols [ i ] . ind ) , ind int switch { case rc . cols [ i ] . ind == - 1 : //Null dest [ i ] = nil case rc . cols [ i ] . ind == 0 || //Normal rc . cols [ i ] . ind == - 2 || //Field longer than type (truncated) rc . cols [ i ] . ind > 0 : //Field longer than type (truncated). Value is original length. dest [ i ] = string ( rc . cols [ i ] . pbuf ) default : return errors . New ( fmt . Sprintf ( \" \" , rc . cols [ i ] . ind ) ) }", "del_tokens": "nil , dest [ i ] = string ( rc . cols [ i ] . pbuf )", "commit_type": "add"}
{"commit_tokens": ["Added", "echo", ".", "HandlerFunc", "to", "handlers"], "add_tokens": "case HandlerFunc : return h case func ( * Context ) error : return h", "del_tokens": "case func ( * Context ) error : return h", "commit_type": "add"}
{"commit_tokens": ["updated", "readme", "and", "simplify", "encode", "stream"], "add_tokens": "MarshalStream ( enc * StreamEncoder ) func ( s * StreamEncoder ) AddObject ( v MarshalerObject ) { return m . MarshalStream ( s ) if s . Encoder . err != nil { init . Cancel ( s . Encoder . err )", "del_tokens": "MarshalStream ( enc * StreamEncoder ) error func ( s * StreamEncoder ) AddObject ( v MarshalerObject ) error { return nil return nil err := m . MarshalStream ( s ) if err != nil { init . Cancel ( err )", "commit_type": "update"}
{"commit_tokens": ["add", "Client", "-", "Side", "monitoring", "."], "add_tokens": "// EnableHandlingTimeHistogram turns on recording of handling time of RPCs for server-side interceptors.", "del_tokens": "// EnableHandlingTimeHistogram turns on recording of handling time of RPCs.", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "expressions", "tests", "and", "fixed", "an", "expression", "parsing", "bug", "."], "add_tokens": "location_token * Token negate bool negative_sign bool term1 IEvaluator term2 IEvaluator op_token * Token } else { return nil , ctx . Error ( \" \" , expr . location_token ) factor2 , err := p . parseTerm ( ) power2 , err := p . parsePower ( ) expr . location_token = p . Current ( ) term2 , err := p . parseSimpleExpression ( )", "del_tokens": "negate bool negative_sign bool term1 IEvaluator term2 IEvaluator op_token * Token factor2 , err := p . parsePower ( ) power2 , err := p . parseFactor ( ) term2 , err := p . parseTerm ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "equality", "check", "for", "different", "use", "cases", "of", "empty", "respectively", "missing", "Principal", "trees", "which", "all", "have", "the", "same", "effect", "."], "add_tokens": "ourPrincipalMap , oursOk := ours . ( map [ string ] interface { } ) theirPrincipalMap , theirsOk := theirs . ( map [ string ] interface { } ) if oursOk { for key , val := range ourPrincipalMap { var tmp = newAWSStringSet ( val ) if len ( tmp ) > 0 { oursNormalized [ key ] = tmp } } if theirsOk { for key , val := range theirPrincipalMap { var tmp = newAWSStringSet ( val ) if len ( tmp ) > 0 { theirsNormalized [ key ] = newAWSStringSet ( val ) } } if len ( multiple ) == 0 { return awsStringSet { } }", "del_tokens": "ourPrincipalMap , ok := ours . ( map [ string ] interface { } ) if ! ok { return false } theirPrincipalMap , ok := theirs . ( map [ string ] interface { } ) if ! ok { return false } for key , val := range ourPrincipalMap { oursNormalized [ key ] = newAWSStringSet ( val ) for key , val := range theirPrincipalMap { theirsNormalized [ key ] = newAWSStringSet ( val )", "commit_type": "fix"}
{"commit_tokens": ["Add", "request", "context", "to", "panic", "message"], "add_tokens": "prefix := requestPrefix ( reqID , r ) printPanic ( prefix , reqID , err ) func printPanic ( prefix , reqID string , err interface { } ) { log . Print ( prefix + buf . String ( ) )", "del_tokens": "printPanic ( reqID , err ) func printPanic ( reqID string , err interface { } ) { if reqID != \" \" { cW ( & buf , nYellow , \" \" , reqID ) } log . Print ( buf . String ( ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "when", "no", "handler", "was", "defined"], "add_tokens": "if h != nil && ! h ( id , uri ) {", "del_tokens": "if ! h ( id , uri ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "comments", "for", "all", "test", "messages"], "add_tokens": "{ // Empty message should error { // Make sure we've got a command { // Need data after tags { // Need data after prefix Expect : \" \" , Err : ErrMissingDataAfterPrefix , } , { // Basic prefix test { // Trailing argument test { // Full prefix test { // Test : in the middle of a param { // Test FromChannel on a different channel prefix { // Test FromChannel on a single user { // Simple message Expect : \" \\n \" , { // Simple message with tags { // Simple message with prefix Prefix : \" \" , Name : \" \" , Expect : \" \\n \" , { // Message with prefix and multiple params { // Message with empty trailing { // Test basic tag parsing { // Escaped \\n in tag { // Escaped \\ in tag { // Escaped ; in tag { // Empty tag { // Escaped & in tag { // Multiple simple tags { // Complicated escaped tag", "del_tokens": "{ { { Expect : \" \" , Err : ErrMissingDataAfterPrefix , } , { { { { { { { { Prefix : \" \" , Name : \" \" , Expect : \" \\n \" , { { Expect : \" \\n \" , { { { { { { { { { {", "commit_type": "add"}
{"commit_tokens": ["Allowing", "for", "a", "custom", "logger", "to", "be", "assigned", "to", "workers", ".", "Logger"], "add_tokens": "var Logger WorkersLogger = log . New ( os . Stdout , \" \" , log . Ldate | log . Lmicroseconds )", "del_tokens": "var Logger = log . New ( os . Stdout , \" \" , log . Ldate | log . Lmicroseconds )", "commit_type": "allow"}
{"commit_tokens": ["improve", "CdUpDir", "()", "to", "only", "stop", "at", "directories", "not", "files"], "add_tokens": "if filepath . Base ( dir ) == dirName && DirExists ( dir ) {", "del_tokens": "if filepath . Base ( dir ) == dirName {", "commit_type": "improve"}
{"commit_tokens": ["Add", "fuzzing", "for", "time", ".", "Time"], "add_tokens": "fuzzFuncs fuzzFuncMap defaultFuzzFuncs fuzzFuncMap r * rand . Rand nilChance float64 minElements int maxElements int defaultFuzzFuncs : fuzzFuncMap { reflect . TypeOf ( & time . Time { } ) : reflect . ValueOf ( fuzzTime ) , } , doCustom , ok = f . defaultFuzzFuncs [ v . Type ( ) ] if ! ok { return false } func fuzzTime ( t * time . Time , c Continue ) { var sec , nsec int64 c . Fuzz ( & sec ) c . Fuzz ( & nsec ) * t = time . Unix ( sec , nsec ) }", "del_tokens": "fuzzFuncs fuzzFuncMap r * rand . Rand nilChance float64 minElements int maxElements int return false", "commit_type": "add"}
{"commit_tokens": ["use", "req", ".", "URL", ".", "EscapedPath", "()", "instead", "of", "getPath", "(", "req", ")"], "add_tokens": "path = req . URL . EscapedPath ( )", "del_tokens": "\" \" path = getPath ( req ) // getPath returns the escaped path if possible; doing what URL.EscapedPath() // which was added in go1.5 does func getPath ( req * http . Request ) string { if req . RequestURI != \" \" { // Extract the path from RequestURI (which is escaped unlike URL.Path) // as detailed here as detailed in https://golang.org/pkg/net/url/#URL // for < 1.5 server side workaround // http://localhost/path/here?v=1 -> /path/here path := req . RequestURI path = strings . TrimPrefix ( path , req . URL . Scheme + `://` ) path = strings . TrimPrefix ( path , req . URL . Host ) if i := strings . LastIndex ( path , \" \" ) ; i > - 1 { path = path [ : i ] } if i := strings . LastIndex ( path , \" \" ) ; i > - 1 { path = path [ : i ] } return path } return req . URL . Path }", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "nested", "beforeEach", "calls"], "add_tokens": "parent * D //TODO: should handle errors for beforeEach it . parent . runBeforeEach ( ) parent * D beforeEach [ ] func ( ) describe := & D { name : name , parent : d } func ( d * D ) runBeforeEach ( ) { if d . parent != nil { d . parent . runBeforeEach ( ) } for _ , b := range d . beforeEach { b ( ) } } d . beforeEach = append ( d . beforeEach , h ) it := It { name : name , h : h , t : & T { } , parent : d }", "del_tokens": "befores [ ] func ( ) describe := & D { name : name } d . befores = append ( d . befores , h ) it := It { name : name , h : h , t : & T { } } //TODO: handle errors for _ , b := range d . befores { b ( ) }", "commit_type": "add"}
{"commit_tokens": ["Use", "error", "type", "for", "signaling", "errors", "."], "add_tokens": "var err error if err != nil {", "del_tokens": "var err string if err != \" \" {", "commit_type": "use"}
{"commit_tokens": ["Fix", "data", "race", "found", "with", "go", "build", "-", "race"], "add_tokens": "func ( c * Connection ) doTimeoutRequest ( timer * time . Timer , req * http . Request ) ( * http . Response , error ) { type result struct { resp * http . Response err error } done := make ( chan result , 1 ) resp , err := c . client . Do ( req ) done <- result { resp , err } case r := <- done : return r . resp , r . err panic ( \" \" ) // For Go 1.0", "del_tokens": "func ( c * Connection ) doTimeoutRequest ( timer * time . Timer , req * http . Request ) ( resp * http . Response , err error ) { done := make ( chan bool , 1 ) resp , err = c . client . Do ( req ) done <- true case <- done : return return // For Go 1.0", "commit_type": "fix"}
{"commit_tokens": ["change", "keyword", "from", "/", "machines", "to", "/", "_etcd", "/", "machines"], "add_tokens": "key := path . Join ( \" \" , nodeName )", "del_tokens": "key := path . Join ( \" \" , nodeName )", "commit_type": "change"}
{"commit_tokens": ["Add", "response", "body", "size", "to", "writer", "interface"], "add_tokens": "Size ( ) int size int n , err = w . ResponseWriter . Write ( data ) w . size = n return func ( w * responseWriter ) Size ( ) int { return w . size }", "del_tokens": "return w . ResponseWriter . Write ( data )", "commit_type": "add"}
{"commit_tokens": ["Changed", "expiration", "scheme", "to", "use", "time", ".", "*", "goodies", "instead"], "add_tokens": "var ttl int64 if err = c . Conn . Query ( `SELECT objectname, updated, nodetag, num_chunks, chunk_size, object_size, TTL(num_chunks) FROM objects WHERE objectname = ? ORDER BY updated DESC LIMIT 1` , * objectname ) . Consistency ( cons ) . Scan ( & o . Objectname , & o . Updated , & o . Nodetag , & o . NumChunks , & o . ChunkSize , & o . ObjectSize , & ttl ) ; err != nil { FYI . Printf ( \" \" , ttl ) if ttl != 0 { o . Expiration = time . Unix ( time . Now ( ) . Unix ( ) + ttl , 0 ) }", "del_tokens": "if err = c . Conn . Query ( `SELECT objectname, updated, nodetag, num_chunks, chunk_size, object_size FROM objects WHERE objectname = ? ORDER BY updated DESC LIMIT 1` , * objectname ) . Consistency ( cons ) . Scan ( & o . Objectname , & o . Updated , & o . Nodetag , & o . NumChunks , & o . ChunkSize , & o . ObjectSize ) ; err != nil { func ( o * Object ) FullName ( ) string { if o == nil { return \" \" } return o . id }", "commit_type": "change"}
{"commit_tokens": ["Added", "function", ":", "ColorLogS", "ColorLog"], "add_tokens": "\" \\033 \\033 \" , \" \\033 \\033 \" , Red , EndColor , Red , \" \" , EndColor ) \" \\033 \\033 \" , Magenta , EndColor , Gray , \" \" , EndColor ) Green , EndColor )", "del_tokens": "\" \\033 \\033 \" , \" \\033 \\033 \" , Blue , EndColor , Red , \" \" , EndColor ) \" \\033 \\033 \" , Blue , EndColor , Gray , \" \" , EndColor ) Blue , EndColor , Green )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "because", "of", "leveldb", "s", "change"], "add_tokens": "db , err = leveldb . OpenFile ( dbDir , nil )", "del_tokens": "db , err = leveldb . OpenFile ( dbDir , & opt . Options { Flag : opt . OFCreateIfMissing } )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "test", "writer"], "add_tokens": "if cfg . before || cfg . after || cfg . out != nil {", "del_tokens": "if cfg . before || cfg . after {", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "buffer", "instead", "of", "naive", "concatenation", "in", "SubstituteRune"], "add_tokens": "\" \" func SubstituteRune ( s string , sub map [ rune ] string ) ( result string ) { var buf bytes . Buffer buf . WriteString ( d ) buf . WriteRune ( c ) return buf . String ( )", "del_tokens": "func SubstituteRune ( s string , sub map [ rune ] string ) ( buf string ) { buf += d buf += string ( c ) return", "commit_type": "use"}
{"commit_tokens": ["Add", "documentation", "to", "the", "Renderer"], "add_tokens": "// Renderer is a struct responsible for determining if a Template is renderable // and performing the actual rendering steps. // dependencies is the slice of Dependencies this Renderer knows how to // render. // dry is the mode in which Templates are \"rendered\" to a stream (default is // stdout). This stream can be set using the SetDryStream() function. dry bool dryStream io . Writer // dependencyDataMap is a map of each dependency to the data received from a // poll. // NewRenderer accepts a slice of Dependencies and a \"dry\" flag. The slice of // Dependencies corresponds to all the Dependencies this Renderer cares about. // The \"dry\" flag triggers a special mode in the Renderer where output files are // written to an IO stream instead of being written to disk. This mode is useful // for debugging or testing changes before actually applying them. This IO // stream defaults to os.Stdout but can be changed used the SetDryStream() // function. // This function returns a pointer to the new Renderer and any error(s) that // occurred during creation. // SetDryStream accepts an io.Writer and sets the internal dryStream for this // Renderer. // Receive accepts a Dependency and data for that Dependency. This data is // cached on the Renderer. This data is then used to determine if a Template // is \"renderable\" (i.e. all its Dependencies have been downloaded at least // once). // MaybeRender accepts a Template and slice of ConfigTemplates that created that // Template. If the template is \"renderable\" (i.e. all its Dependencies have // been downlaoded at least once), the most recent version of the data from the // Template's Dependencies is added to a TemplateContext and Executed. If there // is a failure, an error is returned. // init() creates the Renderer's underlying data structures and returns an error // if any problems occur. // canRender accepts a Template and returns true if and only if all of the // Dependencies of that template have data in the Renderer. // templateContextFor creates and returns a new TemplateContext for the given // Template, iterating through all the Template's Dependencies and appending // them where appropriate in the TemplateContext. // // If an unknown Dependency.(type) is encountered, an error is returned.", "del_tokens": "// dry bool dryStream io . Writer // // // // // canRender accepts a Template and returns true iff all the Dependencies of // that template have data in the Renderer. // templateContextFor creates a TemplateContext for the given Template, // iterating through all the Template's Dependencies and appending them where // appropriate in the TemplateContext. If an unknown Dependency is encountered, // an error will be returned.", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "duplication", "between", "expireable", "map", "and", "non", "-", "expireable", "map", ".", "Also", "shorten", "1", "of", "the", "public", "API", "method", "."], "add_tokens": "// LimitByKeysWithTokenBucketTTL functions just like LimitByKeys. // But user can define a TTL for the token bucket to expire. // This is to ensure that the middleware won't leak memory. func LimitByKeysWithTokenBucketTTL ( limiter * limiter . Limiter , keys [ ] string , bucketExpireTTL time . Duration ) * errors . HTTPError { if limiter . LimitReachedWithTokenBucketTTL ( strings . Join ( keys , \" \" ) , bucketExpireTTL ) {", "del_tokens": "// LimitByKeysWithCustomTokenBucketTTL keeps track number of request made by keys separated by pipe. // User can define a TTL for the key to expire func LimitByKeysWithCustomTokenBucketTTL ( limiter * limiter . Limiter , keys [ ] string , bucketExpireTTL time . Duration ) * errors . HTTPError { if limiter . LimitReachedWithCustomTokenBucketTTL ( strings . Join ( keys , \" \" ) , bucketExpireTTL ) {", "commit_type": "remove"}
{"commit_tokens": ["fixing", "service", "binding", "name", "in", "main"], "add_tokens": "\" \" lo . G . Debug ( \" \" , cloudControllerInfo ) service , _ := appEnv . Services . WithName ( \" \" )", "del_tokens": "service , _ := appEnv . Services . WithName ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "allowing", "invalid", "moves"], "add_tokens": "valid := moveSlice ( g . ValidMoves ( ) ) . find ( m ) if valid == nil { g . moves = append ( g . moves , valid ) g . pos = g . pos . Update ( valid )", "del_tokens": "// TODO there is a bug here. The move pointer shouldn't // be used directly. It could be later set to nil or // it might have incomplete tag information from // encodings. if ! moveSlice ( g . ValidMoves ( ) ) . contains ( m ) { g . moves = append ( g . moves , m ) g . pos = g . pos . Update ( m )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "issue", "installing", "on", "32", "bit", "machines"], "add_tokens": "return errors . New ( \" \" , val , int64 ( math . MaxInt64 ) ) case uint16 ( length ) > math . MaxUint16 && uint32 ( length ) <= math . MaxUint32 : case uint16 ( length ) >= math . MaxUint16 && uint32 ( length ) <= math . MaxUint32 : case uint16 ( length ) >= math . MaxUint16 && uint32 ( length ) <= math . MaxUint32 :", "del_tokens": "return errors . New ( \" \" , val , math . MaxInt64 ) case length > math . MaxUint16 && length <= math . MaxUint32 : case length >= math . MaxUint16 && length <= math . MaxUint32 : case length >= math . MaxUint16 && length <= math . MaxUint32 :", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "streamLock", "is", "non", "-", "blocking", "due", "to", "receiveBytes"], "add_tokens": "stream := s . streams [ sid ] if stream != nil { written , err := stream . receiveBytes ( s . conn , int64 ( hdr . Length ( ) ) ) atomic . AddInt32 ( & s . bucket , - int32 ( written ) ) stream . notifyReadEvent ( ) if err != nil { s . Close ( ) return }", "del_tokens": "var written int64 var err error if stream , ok := s . streams [ sid ] ; ok { written , err = stream . receiveBytes ( s . conn , int64 ( hdr . Length ( ) ) ) atomic . AddInt32 ( & s . bucket , - int32 ( written ) ) stream . notifyReadEvent ( ) } // read data error if err != nil { s . Close ( ) return", "commit_type": "make"}
{"commit_tokens": ["Fix", "QingStor", "signer", "&", "Add", "more", "params", "to", "sign"], "add_tokens": "\" \" paramsParts = append ( paramsParts , key + \" \" + url . QueryEscape ( value ) )", "del_tokens": "paramsParts = append ( paramsParts , key + \" \" + value )", "commit_type": "fix"}
{"commit_tokens": ["Implement", "binary", "marshal", "/", "unmarshal", "for", "PullACKPacket", "."], "add_tokens": "} // MarshalBinary marshals the object in binary form. func ( p PullACKPacket ) MarshalBinary ( ) ( [ ] byte , error ) { out := make ( [ ] byte , 4 ) out [ 0 ] = p . ProtocolVersion binary . LittleEndian . PutUint16 ( out [ 1 : 3 ] , p . RandomToken ) out [ 3 ] = byte ( PullACK ) return out , nil } // UnmarshalBinary decodes the object from binary form. func ( p * PullACKPacket ) UnmarshalBinary ( data [ ] byte ) error { if len ( data ) != 4 { return errors . New ( \" \" ) } if data [ 3 ] != byte ( PullACK ) { return errors . New ( \" \" ) } p . ProtocolVersion = data [ 0 ] p . RandomToken = binary . LittleEndian . Uint16 ( data [ 1 : 3 ] ) return nil", "del_tokens": "Identifier uint8", "commit_type": "implement"}
{"commit_tokens": ["Update", "first", "line", "of", "package", "doc", "to", "be", "more", "descriptive", "."], "add_tokens": "// Package btree implements in-memory B-Trees of arbitrary degree.", "del_tokens": "// Package btree implements B-Trees of arbitrary degree.", "commit_type": "update"}
{"commit_tokens": ["added", "middlewares", "for", "resetexpiry", "/", "responsewriter"], "add_tokens": "resetExpiryMiddleware o := & CookieOverseer { o . resetExpiryMiddleware . resetter = o return o", "del_tokens": "return & CookieOverseer {", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "inline", "comments"], "add_tokens": "lexer . state = LexerNormal", "del_tokens": "lexer . state = LexerComment", "commit_type": "fix"}
{"commit_tokens": ["Implement", "OptionLocalAddress", "option", "for", "tcp", "transport"], "add_tokens": "\" \" localAddr net . Addr t . localAddr = a . listener . Addr ( ) func ( t * tcpTran ) GetOption ( name string ) ( interface { } , error ) { switch name { case mangos . OptionLocalAddress : if t . localAddr == nil { return nil , mangos . ErrBadOption } return t . localAddr . String ( ) , nil default : return nil , mangos . ErrBadOption }", "del_tokens": "\" \" func ( * tcpTran ) GetOption ( string ) ( interface { } , error ) { return nil , mangos . ErrBadOption", "commit_type": "implement"}
{"commit_tokens": ["Add", "test", "for", "other", "group"], "add_tokens": "Expect ( trace . groups [ \" \" ] ) . To ( BeNumerically ( \" \" , 2 * time . Millisecond ) ) Expect ( trace . groups [ \" \" ] ) . To ( BeNumerically ( \" \" , 3 * time . Millisecond ) ) Expect ( trace . groups [ \" \" ] ) . To ( BeNumerically ( \" \" , 0 ) )", "del_tokens": "Expect ( trace . groups [ \" \" ] ) . To ( BeNumerically ( \" \" , 2 * time . Millisecond ) ) Expect ( trace . groups [ \" \" ] ) . To ( BeNumerically ( \" \" , 3 * time . Millisecond ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "potential", "NPE", "when", "printing", "error", "cause", "chains", "."], "add_tokens": "if err != nil { buffer . WriteString ( err . Error ( ) ) } else { buffer . WriteString ( \" \" ) }", "del_tokens": "buffer . WriteString ( err . Error ( ) )", "commit_type": "fix"}
{"commit_tokens": ["added", "min", "/", "max", "length", "validators"], "add_tokens": "import ( \" \" \" \" ) const letterBytes = \" \" func randString ( n int ) string { b := make ( [ ] byte , n ) for i := range b { b [ i ] = letterBytes [ rand . Int63 ( ) % int64 ( len ( letterBytes ) ) ] } return string ( b ) } func TestMaxLength ( t * testing . T ) { // the string to test testStr := randString ( 150 ) // validate the string if err := MaxLength ( 140 ) ( testStr ) ; err == nil { t . Error ( \" \" ) } } func TestMinLength ( t * testing . T ) { // the string to test testStr := randString ( 10 ) // validate the string if err := MinLength ( 12 ) ( testStr ) ; err == nil { t . Error ( \" \" ) } }", "del_tokens": "import \" \"", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "parsing", "nfs", "client", "stats", "."], "add_tokens": "stats . ServerRPC , err = parseServerRPC ( values ) stats . ServerV4Stats , err = parseServerV4Stats ( values )", "del_tokens": "stats . RPC , err = parseRPC ( values ) stats . V4Stats , err = parseV4Stats ( values )", "commit_type": "add"}
{"commit_tokens": ["Add", "ErrNoGamesOwned", "use", "it", "."], "add_tokens": "var ErrNoGamesOwned = errors . New ( \" \" ) if err == ErrNoGamesOwned { return 0 , nil } steamApiKey + \" \" + steamid + \" \" count , _ := response . Get ( \" \" ) . Get ( \" \" ) . Int ( ) if err != nil && count == 0 { return nil , ErrNoGamesOwned", "del_tokens": "steamApiKey + \" \" + steamid + \" \" if err != nil { return nil , err", "commit_type": "add"}
{"commit_tokens": ["Add", "errore", "message", "when", "a", "non", "existing", "field", "is", "requested", ".", "Fix", "numeration"], "add_tokens": "} else { return nil , errors . New ( field + \" \" ) ret [ strconv . Itoa ( i ) ] = m return nil , errors . New ( e . Error ( ) + \" \" + strconv . Itoa ( i ) )", "del_tokens": "ret [ string ( i ) ] = m return nil , errors . New ( e . Error ( ) + \" \" + string ( i ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "avoid", "a", "compile", "error", "due", "to", "float", "to", "int", "truncation", "with", "GCCGO"], "add_tokens": "assertEquals ( t , \" \" , HumanSize ( int64 ( float64 ( 3.42 * GB ) ) ) ) assertEquals ( t , \" \" , HumanSize ( int64 ( float64 ( 5.372 * TB ) ) ) ) assertEquals ( t , \" \" , HumanSize ( int64 ( float64 ( 2.22 * PB ) ) ) )", "del_tokens": "assertEquals ( t , \" \" , HumanSize ( 3.42 * GB ) ) assertEquals ( t , \" \" , HumanSize ( 5.372 * TB ) ) assertEquals ( t , \" \" , HumanSize ( 2.22 * PB ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "debugging", "timeout", "debug", "printing"], "add_tokens": "\" \" // TESTING \" \" c . debugf ( \" \\n \" , msg . Id , msg . Data ) c . debugf ( \" \\n \" , err ) c . debugf ( \" \" ) c . debugf ( \" \\n \" , err ) c . debugf ( \" \\n \" , f . Id ) fmt . Printf ( format , args ... )", "del_tokens": "\" \" // log.Printf(\"error in ws read: %s\\n\", err) log . Printf ( format , args ... )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "current", "go", "/", "types", "version", "."], "add_tokens": "case * types . PkgName : return c . pkgVars [ o . Pkg ( ) . Path ( ) ]", "del_tokens": "case * types . Package : return c . pkgVars [ o . Path ( ) ]", "commit_type": "fix"}
{"commit_tokens": ["Remove", "update", "fields", "because", "this", "is", "more", "like", "edit", "issue", "and", "this", "method", "was", "not", "fully", "complete"], "add_tokens": "func ( s * IssueService ) AddComment ( issueID string , comment string ) ( * Issue , * http . Response , error ) {", "del_tokens": "func ( s * IssueService ) UpdateFields ( issueID string , fields map [ string ] string ) ( * Issue , * http . Response , error ) { apiEndpoint := fmt . Sprintf ( \" \" , issueID ) type FieldsParams struct { Fields map [ string ] string `json:\"fields\"` } params := FieldsParams { Fields : fields , } req , err := s . client . NewRequest ( \" \" , apiEndpoint , params ) if err != nil { return nil , nil , err } responseIssue := new ( Issue ) resp , _ := s . client . Do ( req , responseIssue ) return responseIssue , resp , nil } func ( s * IssueService ) AddComment ( issueID string , comment string ) ( * Issue , * http . Response , error ) {", "commit_type": "remove"}
{"commit_tokens": ["Change", "Lift", "to", "C", "and", "DoneChan", "to", "C"], "add_tokens": "func TestC ( t * testing . T ) { case <- C ( ch ) . Done ( ) : Defer ( C ( ch ) , func ( ) { close ( chT ) } ) case <- Link ( C ( ch ) , C ( nil ) ) : d := Join ( C ( ch ) , c )", "del_tokens": "func TestDoneChan ( t * testing . T ) { case <- DoneChan ( ch ) . Done ( ) : Defer ( Lift ( ch ) , func ( ) { close ( chT ) } ) case <- Link ( Lift ( ch ) , Lift ( nil ) ) : d := Join ( Lift ( ch ) , c )", "commit_type": "change"}
{"commit_tokens": ["Change", "import", "redigo", "from", "garyburd", "to", "gomodule", "in", "redis", "/", "redis", ".", "go"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "change"}
{"commit_tokens": ["Add", "flag", "to", "allow", "upgrade", "/", "change", "for", "all"], "add_tokens": "result := s . Solve ( p , false , latest )", "del_tokens": "for _ , ds := range fix . ds [ 1 : ] { latest = append ( latest , ds . name . Name ) } for _ , ds := range fix . ds [ 1 : ] { var has bool for _ , lp := range fix . l { if ds . name . Name == lp . n { has = true break } } if ! has { latest = append ( latest , ds . name . Name ) } } result := s . Solve ( p , latest )", "commit_type": "add"}
{"commit_tokens": ["Use", "Tag", ".", "parseFramesCoordsWithID", "in", "GetFrames"], "add_tokens": "if _ , exists := t . framesCoords [ id ] ; exists { t . parseFramesCoordsWithID ( id )", "del_tokens": "if fcs , exists := t . framesCoords [ id ] ; exists { parseFunc := t . findParseFunc ( id ) if parseFunc != nil { for _ , fc := range fcs { fr := readFrame ( parseFunc , t . file , fc ) t . AddFrame ( id , fr ) } } // Delete frames with id from t.framesCoords, // because they are just being parsed delete ( t . framesCoords , id )", "commit_type": "use"}
{"commit_tokens": ["Use", "ConstStore", "instead", "of", "custom", "one"], "add_tokens": "store := tokens . ConstStore ( otherToken )", "del_tokens": "\" \" type constStore struct { } func ( s * constStore ) Get ( parent string , scope string ) ( string , error ) { return otherToken , nil } func ( s * constStore ) Set ( parent string , scope [ ] string , token string , ttl time . Duration ) error { return nil } store := & constStore { }", "commit_type": "use"}
{"commit_tokens": ["add", "-", "p", "PORT", "as", "a", "valid", "format", "specification"], "add_tokens": "PortSpecTemplateFormat = \" \"", "del_tokens": "PortSpecTemplateFormat = \" \"", "commit_type": "add"}
{"commit_tokens": ["make", "finding", "home", "dir", "cross", "compile", "friendly"], "add_tokens": "home , err := homeDir ( ) fmt . Println ( \" \" , err ) path := filepath . Join ( home , \" \" )", "del_tokens": "\" \" u , err := user . Current ( ) fmt . Println ( \" \" , err ) // fmt.Println(\"Homedir:\", u.HomeDir) path := filepath . Join ( u . HomeDir , \" \" )", "commit_type": "make"}
{"commit_tokens": ["Add", "initial", "implementation", "of", "MessageError", "type", "."], "add_tokens": "This is currently undergoing change to return errors of type MessageError for issues which are not io related so the caller can differentiate between general io errors and malformed messages .", "del_tokens": "This will change soon as the package should return errors that can be programatically tested .", "commit_type": "add"}
{"commit_tokens": ["Fixed", "tests", "another", "wrong", "err", "check"], "add_tokens": "if err := conn . Authenticate ( ndv . cluster . user , ndv . cluster . password ) ; err != nil {", "del_tokens": "// need to authenticate if conn . Authenticate ( ndv . cluster . user , ndv . cluster . password ) ; err != nil {", "commit_type": "fix"}
{"commit_tokens": ["Use", "single", "byte", "to", "store", "INT3"], "add_tokens": "int3 = [ ] byte { 0xCC } orginalData = make ( [ ] byte , 1 )", "del_tokens": "int3 = [ ] byte { '0' , 'x' , 'C' , 'C' } orginalData = make ( [ ] byte , 4 )", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", "in", "pushgateway", "url"], "add_tokens": "return p . Ppg . PushGatewayURL + \" \" + p . Ppg . Job + \" \" + h", "del_tokens": "return p . Ppg . PushGatewayURL + \" \" + p . Ppg . Job + \" \" + h", "commit_type": "fix"}
{"commit_tokens": ["Use", "chan", "struct", "{}", "instead", "of", "chan", "bool"], "add_tokens": "\" \" sem chan struct { } LogFile : logfile , LinkName : \" \" , RotationTime : 86400 * time . Second , MaxAge : 0 , Offset : 0 , curFn : \" \" , outFh : nil , logfilePattern : \" \" , sem : make ( chan struct { } , 1 ) , rl . sem <- struct { } { }", "del_tokens": "\" \" sem chan bool logfile , \" \" , 86400 * time . Second , 0 , 0 , \" \" , nil , \" \" , make ( chan bool , 1 ) , rl . sem <- true", "commit_type": "use"}
{"commit_tokens": ["add", "custom", "number", "format", "func", "to", "mbarchart"], "add_tokens": "NumFmt func ( int ) string bc . NumFmt = func ( n int ) string { return fmt . Sprint ( n ) } s := bc . NumFmt ( n ) s := bc . NumFmt ( bc . max )", "del_tokens": "s := fmt . Sprint ( n ) s := fmt . Sprintf ( \" \" , bc . max )", "commit_type": "add"}
{"commit_tokens": ["Move", "ffmpeg", "initialization", "to", "the", "init", "function"], "add_tokens": "func init ( ) { C . av_log_set_level ( C . AV_LOG_QUIET ) C . avcodec_register_all ( ) C . av_register_all ( ) }", "del_tokens": "C . av_log_set_level ( C . AV_LOG_QUIET ) C . avcodec_register_all ( ) C . av_register_all ( )", "commit_type": "move"}
{"commit_tokens": ["Fix", "frame", "line", "for", "BuildStackWithCallers", "test"], "add_tokens": "if frame . Line != 25 {", "del_tokens": "if frame . Line != 22 {", "commit_type": "fix"}
{"commit_tokens": ["Change", "EmptyCid", "to", "just", "Nil", "."], "add_tokens": "return Nil , err return Nil , err", "del_tokens": "return EmptyCid , err return EmptyCid , err", "commit_type": "change"}
{"commit_tokens": ["Add", "LedgerKey", "()", "to", "LedgerEntryChange"], "add_tokens": "return change . LedgerKey ( ) . Type } // LedgerKey returns the key for the ledger entry that was changed // in `change`. func ( change * LedgerEntryChange ) LedgerKey ( ) LedgerKey { change := change . MustCreated ( ) return change . LedgerKey ( ) return change . MustRemoved ( ) change := change . MustUpdated ( ) return change . LedgerKey ( ) change := change . MustState ( ) return change . LedgerKey ( )", "del_tokens": "return change . MustCreated ( ) . Data . Type return change . MustRemoved ( ) . Type return change . MustUpdated ( ) . Data . Type return change . MustState ( ) . Data . Type", "commit_type": "add"}
{"commit_tokens": ["Add", "client", "method", "DeleteReminder", "."], "add_tokens": "showCompletedTasks := true completedTasks , err = client . CompletedTasksForListID ( list . ID , showCompletedTasks ) // Update (and complete) task completedTasks , err = client . CompletedTasksForListID ( list . ID , showCompletedTasks ) // Note // Subtask // Reminder var reminder * wundergo . Reminder reminderDate := \" \" createdByDeviceUdid := \" \" Eventually ( func ( ) error { reminder , err = client . CreateReminder ( reminderDate , task . ID , createdByDeviceUdid ) return err } ) . Should ( Succeed ( ) ) reminder . Date = \" \" Eventually ( func ( ) error { reminder , err = client . UpdateReminder ( * reminder ) return err } ) . Should ( Succeed ( ) ) Eventually ( func ( ) error { return client . DeleteReminder ( * reminder ) } ) . Should ( Succeed ( ) ) // Delete task", "del_tokens": "completed := true completedTasks , err = client . CompletedTasksForListID ( list . ID , completed ) completed := true completedTasks , err = client . CompletedTasksForListID ( list . ID , completed )", "commit_type": "add"}
{"commit_tokens": ["Add", "errlevel", "flag", "to", "cmdline", "utility", "."], "add_tokens": "// if errors package changes, this must change var priorityMap = map [ string ] errors . Priority { \" \" : errors . Debug , \" \" : errors . Info , \" \" : errors . Notice , \" \" : errors . Warning , \" \" : errors . Error , \" \" : errors . Critical , \" \" : errors . Alert , \" \" : errors . Emergency , } var flagErr = flag . String ( \" \" , \" \" , \" \" ) errlevel := strings . ToLower ( * flagErr ) // Sanity-check for flagErr if _ , included := priorityMap [ errlevel ] ; ! included { fmt . Println ( \" \" ) os . Exit ( 1 ) } if result . Errors . Priority ( ) >= priorityMap [ errlevel ] {", "del_tokens": "if result . Errors . Priority ( ) > errors . Warning {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "error", "messaging", "when", "upstream", "flag", "library", "is", "inconsistent", "."], "add_tokens": "//always return nil because upstream library is inconsistent & we always check the error buffer anyway", "del_tokens": "if err != nil { return err }", "commit_type": "fix"}
{"commit_tokens": ["added", "errormessage", "to", "Field", "and", "if", "populated", "returns", "this", "in", "required", "validation", "func", "instead"], "add_tokens": "errorMsg := \" \" if len ( fieldSpec . ErrorMessage ) > 0 { errorMsg = fieldSpec . ErrorMessage } errs . Add ( [ ] string { fieldName } , RequiredError , errorMsg ) //A custom error message ErrorMessage string", "del_tokens": "errs . Add ( [ ] string { fieldName } , RequiredError , \" \" )", "commit_type": "add"}
{"commit_tokens": ["Remove", "extraneous", "variable", "in", "print", "statement", "."], "add_tokens": "prometheusHost , interval , prometheusPort , trustBaseURL , window )", "del_tokens": "prometheusHost , interval , prometheusPort , runBookURL , trustBaseURL , window )", "commit_type": "remove"}
{"commit_tokens": ["updated", "dictionary", "object", "to", "match", "what", "is", "returned", "from", "fastly", "api"], "add_tokens": "// CreatedAt is the Time-stamp (GMT) when the dictionary was created. CreatedAt string `mapstructure:\"created_at\"` // DeletedAt is the Time-stamp (GMT) when the dictionary was deleted. DeletedAt string `mapstructure:\"deleted_at\"` // ID is the alphanumeric string identifying a dictionary. ID string `mapstructure:\"id\"` // Name is the name for the Dictionary. Name string `mapstructure:\"name\"` // ServiceID is the alphanumeric string identifying a service. // UpdatedAt is the Time-stamp (GMT) when the dictionary was updated. UpdatedAt string `mapstructure:\"updated_at\"` // Version is the current version of the service. Version int `mapstructure:\"version\"` // WriteOnly Determines if items in the dictionary are readable or not. WriteOnly bool `mapstructure:\"write_only\"`", "del_tokens": "Version int `mapstructure:\"version\"` ID string `mapstructure:\"id\"` Name string `mapstructure:\"name\"` Address string `mapstructure:\"address\"`", "commit_type": "update"}
{"commit_tokens": ["move", "to", "map", "for", "pks"], "add_tokens": "func pkWhere ( pks map [ string ] PrimaryKey ) string { func pkWhereFields ( pks map [ string ] PrimaryKey ) string { func pkUpdateFields ( pks map [ string ] PrimaryKey ) string {", "del_tokens": "func pkWhere ( pks [ ] PrimaryKey ) string { func pkWhereFields ( pks [ ] PrimaryKey ) string { func pkUpdateFields ( pks [ ] PrimaryKey ) string {", "commit_type": "move"}
{"commit_tokens": ["added", "debug", "to", "create", "/", "drop"], "add_tokens": "deets := c . Dialect . Details ( ) if deets . Database != \" \" { if Debug { fmt . Printf ( \" \\n \" , deets . Database , c . URL ( ) ) } deets := c . Dialect . Details ( ) if deets . Database != \" \" { if Debug { fmt . Printf ( \" \\n \" , deets . Database , c . URL ( ) ) }", "del_tokens": "if c . Dialect . Details ( ) . Database != \" \" { if c . Dialect . Details ( ) . Database != \" \" {", "commit_type": "add"}
{"commit_tokens": ["change", "to", "allow", "for", "test", "apiurl"], "add_tokens": "func APIURL ( uuid string , labels [ ] string , env string ) string { if env == \" \" { base = \" \" }", "del_tokens": "func APIURL ( uuid string , labels [ ] string ) string {", "commit_type": "change"}
{"commit_tokens": ["remove", "readAndOut", "()", ".", "use", "io", ".", "Copy"], "add_tokens": "go func ( ) { defer stdoutPipe . Close ( ) io . Copy ( os . Stdout , stdoutPipe ) go func ( ) { defer stderrPipe . Close ( ) io . Copy ( os . Stderr , stderrPipe ) } ( )", "del_tokens": "\" \" defer func ( ) { stdoutPipe . Close ( ) stderrPipe . Close ( ) go readAndOut ( stdoutPipe , os . Stdout ) go readAndOut ( stderrPipe , os . Stderr ) func readAndOut ( r io . Reader , f * os . File ) { s := bufio . NewScanner ( r ) for s . Scan ( ) { fmt . Fprintln ( f , s . Text ( ) ) } }", "commit_type": "remove"}
{"commit_tokens": ["Adds", "CanonicalPath", "to", "allow", "canonical", "import", "path", "annotation", "to", "follow", "package", "clause"], "add_tokens": "f . CanonicalPath = \" \" // package c // import \"d.e/f\"", "del_tokens": "// package c", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "function", "for", "setting", "the", "cookie", "timeout"], "add_tokens": "// Cookies lasts for 24 hours by default. Specified in seconds. state . cookieTime = defaultCookieTime // Get how long a login cookie should last, in seconds // Set how long a login cookie should last, in seconds func ( state * UserState ) SetCookieTimeout ( cookieTime int64 ) { state . cookieTime = cookieTime } // Set how long a loogin cookie should last", "del_tokens": "state . cookieTime = 3600 * 24 // Login cookies should last for 24 hours // Get how long a login cookie should last", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "godoc", "strings", "(", "golint", ")"], "add_tokens": "// A CounterOption lets you add options to Counter metrics using With* funcs. type CounterOption func ( * prom . CounterOpts ) // WithConstLabels allows you to add ConstLabels to Counter metrics. // A HistogramOption lets you add options to Histogram metrics using With* // funcs. // WithHistogramConstLabels allows you to add custom ConstLabels to // histograms metrics.", "del_tokens": "type CounterOption func ( opts * prom . CounterOpts )", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "Regexp", "split", "and", "searches", "with", "a", "user", "-", "specified", "index", "start"], "add_tokens": "re . muRun . Lock ( ) re . muRun . Unlock ( ) re . muRun . Unlock ( ) re . muRun . Lock ( ) re . muRun . Unlock ( )", "del_tokens": "re . mu . Lock ( ) re . mu . Unlock ( ) re . mu . Unlock ( ) re . mu . Lock ( ) re . mu . Unlock ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "checks", "in", "tests"], "add_tokens": "require . Error ( t , err , \" \" ) require . Error ( t , err , \" \" ) require . NoError ( t , err , \" \" ) require . Error ( t , err , \" \" ) require . Error ( t , err , \" \" ) require . Error ( t , err , \" \" )", "del_tokens": "assert . Error ( t , err ) assert . NoError ( t , err )", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "TRUNCATE", "as", "DDL", "statement"], "add_tokens": "// DDL represents a CREATE, ALTER, DROP, RENAME or TRUNCATE statement. // Table is set for AlterStr, DropStr, RenameStr, TruncateStr CreateStr = \" \" AlterStr = \" \" DropStr = \" \" RenameStr = \" \" TruncateStr = \" \"", "del_tokens": "// DDL represents a CREATE, ALTER, DROP or RENAME statement. // Table is set for AlterStr, DropStr, RenameStr CreateStr = \" \" AlterStr = \" \" DropStr = \" \" RenameStr = \" \"", "commit_type": "add"}
{"commit_tokens": ["fix", "some", "sprintf", "conversion", "issues"], "add_tokens": "return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , updateCount , len ( keys ) ) } ) return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , documentCount , len ( keys ) ) } )", "del_tokens": "return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , updateCount , len ( keys ) ) } ) return nil , nil , WithStack ( InvalidArgumentError { Message : fmt . Sprintf ( \" \" , documentCount , len ( keys ) ) } )", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "test", ".", "Made", "paths", "relative", ".", "Ported", "more", "python", "over"], "add_tokens": "type listWrapper struct { var tempList listWrapper ; err = json . Unmarshal ( data , & tempList ) return tempList . List", "del_tokens": "type TempList struct { type FrequencyLists struct { MaleNames [ ] string FemaleNames [ ] string Surnames [ ] string Passwords [ ] string English [ ] string } var FreqLists FrequencyLists func init ( ) { maleNames := GetStringListFromFile ( \" \" ) femaleNames := GetStringListFromFile ( \" \" ) surnames := GetStringListFromFile ( \" \" ) passwords := GetStringListFromFile ( \" \" ) english := GetStringListFromFile ( \" \" ) FreqLists = FrequencyLists { MaleNames : maleNames , FemaleNames : femaleNames , Surnames : surnames , Passwords : passwords , English : english } } var templist TempList ; err = json . Unmarshal ( data , & templist ) return templist . List", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "way", "close", "()", "works"], "add_tokens": "// Pool allows you to use a pool of net.Conn connections. // storage for our net.Conn connections conns chan net . Conn // net.Conn generator // to prevent access to closed channels isDestroyed bool if p . isDestroyed { return nil , errors . New ( \" \" ) } case conn := <- p . conns : func ( p * Pool ) Put ( conn net . Conn ) error { if p . isDestroyed { return errors . New ( \" \" ) } return nil return errors . New ( \" \" ) // Destroy destroys the pool and close all connections. After Destroy() the // pool is no longer usable. func ( p * Pool ) Destroy ( ) { if p . isDestroyed { return } close ( p . conns ) p . conns = nil p . factory = nil p . isDestroyed = true }", "del_tokens": "\" \" // Pool allows you to use a pool of resources. conns chan net . Conn case conn , ok := <- p . conns : if ! ok { return nil , errors . New ( \" \" ) } func ( p * Pool ) Put ( conn net . Conn ) { log . Println ( \" \" ) // Close closes all the pools connections func ( p * Pool ) Close ( ) { close ( p . conns ) }", "commit_type": "change"}
{"commit_tokens": ["Add", "ScanLogStream", "and", "ScanErrorLogStream", "to", "log_sender"], "add_tokens": "\" \" Initialize ( log_sender . NewLogSender ( autowire . AutowiredEmitter ( ) , gosteno . NewLogger ( \" \" ) ) )", "del_tokens": "Initialize ( log_sender . NewLogSender ( autowire . AutowiredEmitter ( ) ) )", "commit_type": "add"}
{"commit_tokens": ["Remove", "flags", "from", "server", "package", ".", "Create", "cmd", "package", "to", "parse", "flags", "and", "cli", "usage"], "add_tokens": "Address string DefaultServer = NewRpcServer ( Address )", "del_tokens": "\" \" \" \" flagRegistry string flagBindAddress string func init ( ) { flag . StringVar ( & flagRegistry , \" \" , \" \" , \" \" ) flag . StringVar ( & flagBindAddress , \" \" , \" \" , \" \" ) } flag . Parse ( ) switch flagRegistry { case \" \" : registry . DefaultRegistry = registry . NewKubernetesRegistry ( ) store . DefaultStore = store . NewMemcacheStore ( ) } DefaultServer = NewRpcServer ( flagBindAddress )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "off", "-", "by", "-", "one", "error", "in", "sequence", "length", "check"], "add_tokens": "seq := make ( nybblePairs , ( lSeq + 1 ) >> 1 )", "del_tokens": "seq := make ( nybblePairs , lSeq >> 1 )", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "case", "with", "argument", "parsing", "."], "add_tokens": "\" \" return fmt . Sprintf ( \" \\n \" , args ) , nil { \" \" , \" \\n \" , false } , { \" \" , \" \\n \" , false } ,", "del_tokens": "\" \" return \" \\n \" , nil { \" \" , \" \\n \" , false } ,", "commit_type": "add"}
{"commit_tokens": ["Allowing", "POST", "request", "obj", "id", "to", "be", "empty", "proper", "input", "errors", "otherwise"], "add_tokens": "ID string `json:\"id\"` var status int", "del_tokens": "ID string `json:\"id\" valid:\"required\"` var status int", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "[]", "int", "on", "the", "decoding", "part"], "add_tokens": "if val . Kind ( ) == reflect . Int && val . Type ( ) . Size ( ) < 8 { return errors . New ( \" \" ) } case reflect . Uint , reflect . Uint32 , reflect . Uint64 : if val . Kind ( ) == reflect . Uint && val . Type ( ) . Size ( ) < 8 { return errors . New ( \" \" ) } case reflect . Bool , reflect . Int32 , reflect . Int64 , reflect . Int , reflect . Uint32 , reflect . Uint64 , reflect . Uint : if ( eltype . Kind ( ) == reflect . Int || eltype . Kind ( ) == reflect . Uint ) && eltype . Size ( ) < 8 { return errors . New ( \" \" ) }", "del_tokens": "case reflect . Uint32 , reflect . Uint64 : case reflect . Bool , reflect . Int32 , reflect . Int64 , reflect . Uint32 , reflect . Uint64 :", "commit_type": "add"}
{"commit_tokens": ["Implement", "the", "StateDriver", "for", "a", "Consul", "datastore"], "add_tokens": "eventStr := \" \" if etcdRsp . Node . Value != \" \" { eventStr = \" \" } else { eventStr = \" \" } log . Infof ( \" \" , eventStr , etcdRsp . Node . Key ) log . Errorf ( \" \" , err ) // ChannelStateEvents watches for updates(created, modify, delete) to a state of // specified type and unmarshals (given a function) all changes and puts then on // channel of core.WatchState objects. // XXX: move this to some common file func ChannelStateEvents ( d core . StateDriver , sType core . State , go ChannelStateEvents ( d , sType , unmarshal , byteRsps , rsps , recvErr )", "del_tokens": "node := etcdRsp . Node log . Printf ( \" \" , node . Key ) log . Printf ( \" \" , err ) func ( d * EtcdStateDriver ) channelStateEvents ( sType core . State , go d . channelStateEvents ( sType , unmarshal , byteRsps , rsps , recvErr )", "commit_type": "implement"}
{"commit_tokens": ["Add", "c", ":", "/", "go", "/", "src", "as", "a", "predefined", "GOROOT", "."], "add_tokens": "// Include c:/go/src since it's frequent on Windows. This simplifies our life // when processing a trace generated on another VM. goroots = [ ] string { runtime . GOROOT ( ) , \" \" } for _ , goroot := range goroots { if strings . HasPrefix ( c . SourcePath , goroot ) { return true }", "del_tokens": "goroot = runtime . GOROOT ( ) if strings . HasPrefix ( c . SourcePath , goroot ) { return true", "commit_type": "add"}
{"commit_tokens": ["Remove", "dependency", "on", "github", ".", "com", "/", "cznic", "/", "mathutil"], "add_tokens": "switch { case x < min : return min case x > max : return max default : return x } latMMin := int ( math . Abs ( 60000 * coord [ 1 ] ) ) if latMMin > 90 * 60000 { latMMin = 90 * 60000 } lngMMin := int ( math . Abs ( 60000 * coord [ 0 ] ) ) if lngMMin > 180 * 60000 { lngMMin = 180 * 60000 }", "del_tokens": "\" \" return mathutil . Min ( mathutil . Max ( x , min ) , max ) latMMin := mathutil . Min ( int ( math . Abs ( 60000 * coord [ 1 ] ) ) , 90 * 60000 ) lngMMin := mathutil . Min ( int ( math . Abs ( 60000 * coord [ 0 ] ) ) , 180 * 60000 )", "commit_type": "remove"}
{"commit_tokens": ["Add", "necessary", "plugins", "for", "tests"], "add_tokens": "assert . Equal ( t , 4 , plugins . Count ( ) )", "del_tokens": "assert . Equal ( t , 19 , plugins . Count ( ) )", "commit_type": "add"}
{"commit_tokens": ["use", "gopkg", ".", "in", "/", "check", ".", "v1"], "add_tokens": "check \" \" func Test ( t * testing . T ) { check . TestingT ( t ) } type S struct { } var _ = check . Suite ( & S { } ) func ( s * S ) TestV ( c * check . C ) { c . Assert ( err , check . IsNil ) c . Assert ( v . Major ( ) , check . Equals , int64 ( 1 ) ) c . Assert ( v . Minor ( ) , check . Equals , int64 ( 2 ) ) c . Assert ( v . Patch ( ) , check . Equals , int64 ( 3 ) ) c . Assert ( v . Metadata ( ) , check . Equals , \" \" ) v2 , err := v . SetMetadata ( \" \" ) c . Assert ( err , check . IsNil ) c . Assert ( v2 . Metadata ( ) , check . Equals , \" \" )", "del_tokens": "func TestV ( t * testing . T ) { if err != nil { t . Error ( err ) return } v2 , _ := v . SetMetadata ( \" \" ) t . Logf ( \" \" , v ) t . Logf ( \" \" , v2 )", "commit_type": "use"}
{"commit_tokens": ["Updating", "to", "latest", "protocol", ".", "json"], "add_tokens": "if in . BackendNodeID != 0 { if ! first { out . RawByte ( ',' ) } first = false out . RawString ( \" \\\" \\\" \" ) out . Int64 ( int64 ( in . BackendNodeID ) ) case \" \" : ( out . Type ) . UnmarshalEasyJSON ( in ) if in . Source != nil { if ! first { out . RawByte ( ',' ) } first = false out . RawString ( \" \\\" \\\" \" ) if in . Source == nil { out . RawString ( \" \" ) } else { ( * in . Source ) . MarshalEasyJSON ( out ) } }", "del_tokens": "if ! first { out . RawByte ( ',' ) first = false out . RawString ( \" \\\" \\\" \" ) out . Int64 ( int64 ( in . BackendNodeID ) ) case \" \" : ( out . Type ) . UnmarshalEasyJSON ( in ) out . RawString ( \" \\\" \\\" \" ) if in . Source == nil { out . RawString ( \" \" ) } else { ( * in . Source ) . MarshalEasyJSON ( out ) } if ! first { out . RawByte ( ',' ) } first = false", "commit_type": "update"}
{"commit_tokens": ["Use", "default", "transport", "with", "additional", "TLS", "config"], "add_tokens": "tr := http . DefaultTransport . ( * http . Transport ) tr . TLSClientConfig = & tls . Config { InsecureSkipVerify : config . SkipSslValidation } ctx = context . WithValue ( ctx , oauth2 . HTTPClient , & http . Client { Transport : tr } )", "del_tokens": "if config . SkipSslValidation == false { ctx = context . WithValue ( ctx , oauth2 . HTTPClient , defConfig . HttpClient ) } else { tr := & http . Transport { TLSClientConfig : & tls . Config { InsecureSkipVerify : true } , } ctx = context . WithValue ( ctx , oauth2 . HTTPClient , & http . Client { Transport : tr } ) }", "commit_type": "use"}
{"commit_tokens": ["add", "random", "factor", "and", "make", "use", "of", "s"], "add_tokens": "package main func RandomString ( s int ) string { // s number of character randomFactor , _ := RandomBytes ( 1 ) mathrand . Seed ( time . Now ( ) . UnixNano ( ) * int64 ( randomFactor [ 0 ] ) ) b := make ( [ ] rune , s )", "del_tokens": "package randstr ) import ( func RandomString ( s int ) string { // generate random string mathrand . Seed ( time . Now ( ) . UnixNano ( ) ) b := make ( [ ] rune , 32 )", "commit_type": "add"}
{"commit_tokens": ["Added", "attributes", "for", "the", "root", "inode", "."], "add_tokens": "attributes fuse . InodeAttributes attributes : fuse . InodeAttributes { } , dir : true ,", "del_tokens": "dir : true ,", "commit_type": "add"}
{"commit_tokens": ["use", "start", "/", "die", "like", "old", "version", "not", "create", "/", "destroy", ".", "not", "sure", "how", "this", "was", "changed", "and", "missed", ".", "maybe", "it", "was", "racey", "."], "add_tokens": "p . pumpLogs ( & docker . APIEvents { Status : \" \" , case \" \" , \" \" : go p . pumpLogs ( event , true ) case \" \" : func ( p * LogsPump ) pumpLogs ( event * docker . APIEvents , backlog bool ) { debug ( \" \" , id , \" \" ) debug ( \" \" , id , \" \" ) debug ( \" \" , id , \" \" ) debug ( \" \" , id , \" \" , err ) case \" \" , \" \" : case \" \" : // we can stop routing when it dies.", "del_tokens": "p . monitorLogs ( & docker . APIEvents { Status : \" \" , case \" \" : go p . monitorLogs ( event , true ) case \" \" : func ( p * LogsPump ) monitorLogs ( event * docker . APIEvents , backlog bool ) { debug ( \" \" , id , err ) case \" \" : case \" \" : // we can stop routing when it is destroyed.", "commit_type": "use"}
{"commit_tokens": ["Fix", "code", "to", "pass", "tests"], "add_tokens": "// Didn't find it, but we didn't want to.. so we mark it as found // Empty pattern should match even if input to scanner is empty if pat . Inverse ( ) || pat . Pattern ( ) == \" \" { if len ( expectedValues ) != len ( found ) {", "del_tokens": "// Didn't find it, but we didn't want to.. so we mark it as found if pat . Inverse ( ) { if ! reflect . DeepEqual ( sliceToPatterns ( expectedValues ) , found ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "match", "latest", "sarama", "."], "add_tokens": "config . SaramaConfig . ClientID = name saramaClient , err := sarama . NewClient ( brokerList , config . SaramaConfig )", "del_tokens": "saramaClient , err := sarama . NewClient ( name , brokerList , config . KafkaClientConfig )", "commit_type": "update"}
{"commit_tokens": ["Add", "watcher", "implementation", "backed", "by", "fsnotify"], "add_tokens": "// It is guaranteed the ch is non-nil. All unexpected events are ignored.", "del_tokens": "// It is guaranteed the ch is non-nil.", "commit_type": "add"}
{"commit_tokens": ["Add", "elipses", "for", "options", "arguments"], "add_tokens": "func NestedProcessStart ( msg string , level int , v ... interface { } ) string {", "del_tokens": "func NestedProcessStart ( msg string , level int ) string {", "commit_type": "add"}
{"commit_tokens": ["Add", "auth", "support", "in", "kvdb", ".", "Currently", "auth", "is", "supported", "only", "in", "etcd", "while", "consul", "returns", "an", "error", ".", "PWX", "-", "1663"], "add_tokens": "\" \" // the maximum amount of time a dial will wait for a connection to setup. // 30s is long enough for most of the network conditions. defaultDialTimeout = 30 * time . Second var username , password , caFile string // options provided. Probably auth options if options != nil || len ( options ) > 0 { var ok bool // Check if username provided username , ok = options [ kvdb . UsernameKey ] if ok { // Check if password provided password , ok = options [ kvdb . PasswordKey ] if ! ok { return nil , kvdb . ErrNoPassword } // Check if certificate provided caFile , ok = options [ kvdb . CAFileKey ] if ! ok { return nil , kvdb . ErrNoCertificate } } } tls := transport . TLSInfo { CAFile : caFile , } tr , err := transport . NewTransport ( tls , defaultDialTimeout ) if err != nil { return nil , err } Transport : tr , Username : username , Password : password ,", "del_tokens": "Transport : e . DefaultTransport ,", "commit_type": "add"}
{"commit_tokens": ["Fix", "duplicate", "key", "error", "when", "normalizing", "tables"], "add_tokens": "switch { case ! isNil ( old ) && isNil ( val ) : return nil case isNil ( old ) : return p . SetValue ( cfg , opts , val ) case isSub ( old ) && isSub ( val ) : cfgOld , _ := old . toConfig ( opts ) cfgVal , _ := val . toConfig ( opts ) return mergeConfig ( opts , cfgOld , cfgVal ) default :", "del_tokens": "if ! isNil ( old ) { if isNil ( val ) { return nil } return p . SetValue ( cfg , opts , val )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "type", "test", "for", "set"], "add_tokens": "assert . Equal ( t , \" \" , m1 . MetricType , \" \" )", "del_tokens": "assert . Equal ( t , \" \" , m1 . MetricType , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Added", "docs", "on", "ACLs", "."], "add_tokens": "// version. The object is created with the default ACL of \"private\".", "del_tokens": "// version.", "commit_type": "add"}
{"commit_tokens": ["Allow", "ledger", "selection", "to", "be", "done", "at", "runtime", "for", "solo", "."], "add_tokens": "\" \" \" \" \" \" \" \" // Stand in until real config ledgerType := os . Getenv ( \" \" ) var rawledger rawledger . ReadWriter switch ledgerType { case \" \" : name , err := ioutil . TempDir ( \" \" , \" \" ) // TODO, config if err != nil { panic ( fmt . Errorf ( \" \" , err ) ) } rawledger = fileledger . New ( name ) case \" \" : fallthrough default : historySize := 10 // TODO, config rawledger = ramledger . New ( historySize ) } queueSize := 100 // TODO configure batchSize := 10 batchTimeout := 10 * time . Second solo . New ( queueSize , batchSize , batchTimeout , rawledger , grpcServer )", "del_tokens": "solo . New ( 100 , 10 , 10 , 10 * time . Second , grpcServer )", "commit_type": "allow"}
{"commit_tokens": ["fix", "up", "some", "indexing", "in", "ParseSignature", "."], "add_tokens": "// must be positive, must be able to fit in another 0x2, <len> // hence the -3. We assume that the length must be at least one byte. index ++ if rLen <= 0 || rLen > len ( sigStr ) - index - 3 { // 0x02. length already checked in previous if. index ++ // S should be the rest of the string. if sLen <= 0 || sLen > len ( sigStr ) - index {", "del_tokens": "if rLen < 0 || rLen > len ( sigStr ) - index { index ++ // 0x02 if sLen < 0 || sLen > len ( sigStr ) - index { index ++", "commit_type": "fix"}
{"commit_tokens": ["Removing", "unused", "parameter", "in", "VerifyContent", ";", "expected", "root", "should", "be", "compared", "against", "trees", "root", "value", "."], "add_tokens": "func ( m * MerkleTree ) VerifyContent ( content Content ) ( bool , error ) {", "del_tokens": "func ( m * MerkleTree ) VerifyContent ( expectedMerkleRoot [ ] byte , content Content ) ( bool , error ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "to", "avoid", "a", "compilation", "error", "of", "size_test", ".", "go", "with", "GCCGO", "due", "to", "float", "to", "int", "truncation"], "add_tokens": "func HumanSize ( size float64 ) string {", "del_tokens": "func HumanSize ( size int64 ) string {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "in", "concatenation", "coalescing", "(", "wrong", "length", "cached", ")", "and", "add", "some", "tests", "."], "add_tokens": "return conc ( cc . Left , conc ( cc . Right , rhs , ccrlen , rhsLength ) , cc . Split , ccrlen + rhsLength ) return conc ( conc ( lhs , cc . Left , lhsLength , cc . Split ) , cc . Right , lhsLength + cc . Split , cc . rLength ( ) )", "del_tokens": "return conc ( cc . Left , conc ( cc . Right , rhs , ccrlen , rhsLength ) , cc . Split , ccrlen + rhsLength ) return conc ( conc ( lhs , cc . Left , lhsLength , cc . Split ) , cc . Right , cc . Split , cc . rLength ( ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "enum", "for", "verification", "type"], "add_tokens": "type Verification string Pass Verification = \" \" Fail Verification = \" \" Unchecked Verification = \" \" Id string `json:\"id\"` Name string `json:\"name\"` Type CardType `json:\"type\"` Month uint8 `json:\"exp_month\"` Year uint16 `json:\"exp_year\"` LastFour string `json:\"last4\"` Fingerprint string `json:\"fingerprint\"` CardCountry string `json:\"country\"` Customer string `json:\"customer\"` Recipient string `json:\"recipient\"` Address1 string `json:\"address_line1\"` Address2 string `json:\"address_line2\"` Country string `json:\"address_country\"` State string `json:\"address_state\"` Zip string `json:\"address_zip\"` City string `json:\"address_city\"` Line1Check Verification `json:\"address_line1_check\"` ZipCheck Verification `json:\"address_zip_check\"` CVCCheck Verification `json:\"cvc_check\"`", "del_tokens": "Id string `json:\"id\"` Name string `json:\"name\"` Type CardType `json:\"type\"` Month uint8 `json:\"exp_month\"` Year uint16 `json:\"exp_year\"` LastFour string `json:\"last4\"` Fingerprint string `json:\"fingerprint\"` CardCountry string `json:\"country\"` Customer string `json:\"customer\"` Recipient string `json:\"recipient\"` Address1 string `json:\"address_line1\"` Address2 string `json:\"address_line2\"` Country string `json:\"address_country\"` State string `json:\"address_state\"` Zip string `json:\"address_zip\"` City string `json:\"address_city\"` Line1Check string `json:\"address_line1_check\"` ZipCheck string `json:\"address_zip_check\"` CVCCheck string `json:\"cvc_check\"`", "commit_type": "add"}
{"commit_tokens": ["add", "query", "options", "and", "tests"], "add_tokens": "Url string // Deal url Image_url string // Deal image url Purchase_url string // Deal option url for purchase Url string // Gift certificate landing page url Image_url string // Gift certificate image url Rating_image_url string // URL to star rating image for this business (size = 84x17) Rating_image_small_url string // URL to small version of rating image for this business (size = 50x10) Rating_image_large_url string // URL to large version of rating image for this business (size = 166x30) Id string // User identifier Image_url string // User profile image url Name string // User name", "del_tokens": "import \" \" Url url . URL // Deal url Image_url url . URL // Deal image url Purchase_url url . URL // Deal option url for purchase Url url . URL // Gift certificate landing page url Image_url url . URL // Gift certificate image url Rating_image_url url . URL // URL to star rating image for this business (size = 84x17) Rating_image_small_url url . URL // URL to small version of rating image for this business (size = 50x10) Rating_image_large_url url . URL // URL to large version of rating image for this business (size = 166x30) Id string // User identifier Image_url url . URL // User profile image url Name string // User name", "commit_type": "add"}
{"commit_tokens": ["Use", "interface", "to", "abstract", "memcache", "clients"], "add_tokens": "func TestMainGomemcache ( t * testing . T ) { sessionStore := NewGomemcacheStore ( memcacheClient , \" \" , [ ] byte ( \" \" ) ) func TestMainMc ( t * testing . T ) { sessionStore := NewMemcacheStore ( memcacheClient , \" \" , [ ] byte ( \" \" ) ) sessionStore := NewMemcacheStoreWithValueStorer ( NewGoMemcacher ( memcacheClient ) , headerStorer , \" \" , [ ] byte ( \" \" ) )", "del_tokens": "func TestMain ( t * testing . T ) { sessionStore := NewMemcacheStore ( memcacheClient , \" \" , [ ] byte ( \" \" ) ) func TestMainBinary ( t * testing . T ) { sessionStore := NewBinaryMemcacheStore ( memcacheClient , \" \" , [ ] byte ( \" \" ) ) sessionStore := NewMemcacheStoreWithValueStorer ( memcacheClient , headerStorer , \" \" , [ ] byte ( \" \" ) )", "commit_type": "use"}
{"commit_tokens": ["add", "skip", "option", "for", "bulk", "key", "retrieval", "functions"], "add_tokens": "GetAll ( count int , skip int , resource string ) ( [ ] [ ] [ ] byte , error ) GetAllAfter ( key [ ] byte , count int , skip int , resource string ) ( [ ] [ ] [ ] byte , error ) //Get all items after a key GetAllBefore ( key [ ] byte , count int , skip int , resource string ) ( [ ] [ ] [ ] byte , error ) //Get all items before a key Filter ( prefix [ ] byte , count int , skip int , resource string ) ( [ ] [ ] [ ] byte , error )", "del_tokens": "GetAll ( count int , resource string ) ( [ ] [ ] [ ] byte , [ ] [ ] byte , error ) GetAllAfter ( key [ ] byte , count int , resource string ) ( [ ] [ ] [ ] byte , [ ] [ ] byte , error ) //Get all items after a key GetAllBefore ( key [ ] byte , count int , resource string ) ( [ ] [ ] [ ] byte , [ ] [ ] byte , error ) //Get all items before a key Filter ( prefix [ ] byte , count int , resource string ) ( [ ] [ ] [ ] byte , [ ] [ ] byte , error )", "commit_type": "add"}
{"commit_tokens": ["moved", "//", "go", ":", "generate", "under", "package", "declaration", "to", "make", "go", "linter", "happy"], "add_tokens": "//go:generate qtc -dir=testdata/templates", "del_tokens": "//go:generate qtc -dir=testdata/templates", "commit_type": "move"}
{"commit_tokens": ["Fix", "use", "of", "close", "in", "mount", ".", "Query"], "add_tokens": "if res == nil { dst := dses [ i ] rest := rests [ i ] r , err := dst . Query ( q2 ) err := res . Close ( ) if err != nil { return query . Result { Error : err } , false } res = nil if len ( mounts ) > i && res != nil {", "del_tokens": "var ds datastore . Datastore var rest datastore . Key if ds == nil { ds = dses [ i ] rest = rests [ i ] r , err := ds . Query ( q2 ) ds = nil if len ( mounts ) > i {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "a", "new", "logger", "to", "be", "injected"], "add_tokens": "log Logger // Logger is an interface compatible with log.Logger. type Logger interface { Println ( v ... interface { } ) Fatal ( v ... interface { } ) Printf ( format string , v ... interface { } ) } func SetLogger ( l Logger ) { log = l }", "del_tokens": "log * glog . Logger", "commit_type": "allow"}
{"commit_tokens": ["Adds", "some", "test", "coverage", "for", "server", "clients", "delete", "endpoint"], "add_tokens": "token := req . Header . Get ( \" \" ) token = strings . TrimPrefix ( token , \" \" ) token = strings . TrimPrefix ( token , \" \" ) h . clients . Delete ( id ) // TODO: should return a 404 if the client does not exist", "del_tokens": "token := strings . TrimPrefix ( req . Header . Get ( \" \" ) , \" \" ) if ok := h . clients . Delete ( id ) ; ! ok { panic ( \" \" ) } w . WriteHeader ( http . StatusOK )", "commit_type": "add"}
{"commit_tokens": ["Made", "resolve", "structure", "exported", "outside", "the", "package"], "add_tokens": "type Resolver struct { func NewResolver ( iface * net . Interface ) ( * Resolver , error ) { return & Resolver { c , c . closedCh } , nil func ( r * Resolver ) Browse ( service , domain string , entries chan <- * ServiceEntry ) error { func ( r * Resolver ) Lookup ( instance , service , domain string , entries chan <- * ServiceEntry ) error {", "del_tokens": "type resolver struct { func NewResolver ( iface * net . Interface ) ( * resolver , error ) { return & resolver { c , c . closedCh } , nil func ( r * resolver ) Browse ( service , domain string , entries chan <- * ServiceEntry ) error { func ( r * resolver ) Lookup ( instance , service , domain string , entries chan <- * ServiceEntry ) error {", "commit_type": "make"}
{"commit_tokens": ["Update", "unsafe", "rule", "to", "match", "package", "explicitly"], "add_tokens": "path := strings . Trim ( imported . Path . Value , `\"` ) // unsafe is not included in Package.Imports() if path == \" \" { gas . context . Imports . Imported [ path ] = path }", "del_tokens": "path := strings . Trim ( imported . Path . Value , `\"` )", "commit_type": "update"}
{"commit_tokens": ["Added", "pointer", "support", "for", "columns"], "add_tokens": "type foo struct { FirstName string `db:\"first_name\"` LastName string Email string `db:\"email_address\"` Unwanted string `db:\"-\"` } func Test_ColumnsForStruct ( t * testing . T ) { func Test_ColumnsForStruct_WithPointer ( t * testing . T ) { assert := assert . New ( t ) f := & foo { } columns := ColumnsForStruct ( f ) assert . Equal ( columns . Names , [ ] string { \" \" , \" \" , \" \" } ) assert . Equal ( columns . SymbolizedNames , [ ] string { \" \" , \" \" , \" \" } ) }", "del_tokens": "func TestColumnsForStruct ( t * testing . T ) { type foo struct { FirstName string `db:\"first_name\"` LastName string Email string `db:\"email_address\"` Unwanted string `db:\"-\"` }", "commit_type": "add"}
{"commit_tokens": ["update", "doc", "of", "Get", "()"], "add_tokens": "//Duplicated close of a connection is endurable as the second close is ignored.", "del_tokens": "//Duplicated close is endurable as the second close is ignored.", "commit_type": "update"}
{"commit_tokens": ["Use", "session", ".", "log", "()", "instead", "of", "println"], "add_tokens": "s . log ( LogDebug , \" \" + err . Error ( ) ) s . log ( LogDebug , \" \" ) s . log ( LogDebug , \" \" ) s . log ( LogDebug , \" \" ) s . log ( LogDebug , \" \" ) s . log ( LogDebug , \" \" ) s . log ( LogDebug , \" \" ) pc . session . log ( LogDebug , \" \" ) ( * PlaylistContainer ) ( userdata ) . session . log ( LogDebug , \" \" ) ( * PlaylistContainer ) ( userdata ) . session . log ( LogDebug , \" \" ) t . session . log ( LogDebug , \" \" ) t . session . log ( LogDebug , \" \" )", "del_tokens": "println ( \" \" , err ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" ) println ( \" \" , t ) println ( \" \" , t )", "commit_type": "use"}
{"commit_tokens": ["add", "message", "to", "loading", "spinner"], "add_tokens": "message string chars [ ] string delay time . Duration writer io . Writer func NewSpinner ( message string , chars [ ] string , delay time . Duration , writer io . Writer ) Spinner { message : message , chars : chars , delay : delay , writer : writer , func NewDefaultSpinner ( message string ) Spinner { return NewSpinner ( message , chars , delay , writer ) out := fmt . Sprintf ( \" \" , s . message , s . chars [ i ] )", "del_tokens": "chars [ ] string delay time . Duration writer io . Writer func NewSpinner ( chars [ ] string , delay time . Duration , writer io . Writer ) Spinner { chars : chars , delay : delay , writer : writer , func NewDefaultSpinner ( ) Spinner { return NewSpinner ( chars , delay , writer ) out := s . chars [ i ]", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "messed", "space", "after", "Config", "in", "doc"], "add_tokens": "// Config is used to defined", "del_tokens": "// Config is used to defined", "commit_type": "fix"}
{"commit_tokens": ["Fix", "code", "broken", "by", "the", "new", "Go", "SSA", "enabled", "compiler", "optimizations", "."], "add_tokens": "// findSigpanic intentionally executes faulting code to generate a stack trace var p * int // intentional nil pointer dereference to trigger sigpanic return * p", "del_tokens": "// findSigpanic intentially executes faulting code to generate a stack trace // intentional division by zero fault a , b := 1 , 0 return a / b", "commit_type": "fix"}
{"commit_tokens": ["Use", "defined", "MaxVarintLen64", "from", "stdlib"], "add_tokens": "buf := make ( [ ] byte , 2 * binary . MaxVarintLen64 + len ( c . hash ) )", "del_tokens": "buf := make ( [ ] byte , 2 * 8 + len ( c . hash ) )", "commit_type": "use"}
{"commit_tokens": ["Add", "missing", "deployment", "VM", "information", "from", "the", "bosh", "v261", "director", "API"], "add_tokens": "VMCID string `json:\"vm_cid\"` IPs [ ] string `json:\"ips\"` DNS [ ] string `json:\"dns\"` AgentID string `json:\"agent_id\"` JobName string `json:\"job_name\"` Index int `json:\"index\"` JobState string `json:\"job_state\"` State string `json:\"state\"` ResourcePool string `json:\"resource_pool\"` VMType string `json:\"vm_type\"` Vitals Vitals `json:\"vitals\"` Processes [ ] Process `json:\"processes\"` ResurectionPaused bool `json:\"resurrection_paused\"` AZ string `json:\"az\"` ID string `json:\"id\"` Bootstrap bool `json:\"bootstrap\"` Ignore bool `json:\"ignore\"` // Disk struct Ephemeral DiskStats `json:\"ephemeral\"` System DiskStats `json:\"system\"` Persistent DiskStats `json:\"persistent\"` // CPU struct // DiskStats struct // VM Process struct type Process struct { Name string `json:\"name\"` State string `json:\"state\"` Uptime Uptime `json:\"uptime\"` Mem ProcessMemory `json:\"mem\"` CPU ProcessCPU `json:\"cpu\"` } // Uptime struct type Uptime struct { Secs int `json:\"secs\"` } // Process CPU struct type ProcessCPU struct { Total float64 `json:\"total\"` } // Memory struct type ProcessMemory struct { Percent float64 `json:\"percent\"` KB int `json:\"KB\"` }", "del_tokens": "AgentID string `json:\"agent_id\"` VMCID string `json:\"vm_cid\"` CID string `json:\"cid\"` JobName string `json:\"job_name\"` Index int `json:\"index\"` IPs [ ] string `json:\"ips\"` DNS [ ] string `json:\"dns\"` ResurectionPaused bool `json:\"resurrection_paused\"` Vitals Vitals `json:\"vitals\"` ID string `json:\"id\"` Ephemeral DiskStats `json:\"ephemeral\"` System DiskStats `json:\"system\"` // Disk struct", "commit_type": "add"}
{"commit_tokens": ["Adding", "/", "uuid", "support", "and", "checks", "for", "ListenAndServe", "errors"], "add_tokens": "var listenErr error logger . Fatal ( \" \" , err ) listenErr = server . ListenAndServeTLS ( \" \" , \" \" ) listenErr = server . ListenAndServe ( ) } if listenErr != nil { logger . Fatalf ( \" \" , listenErr )", "del_tokens": "log . Fatal ( \" \" , err ) server . ListenAndServeTLS ( \" \" , \" \" ) server . ListenAndServe ( )", "commit_type": "add"}
{"commit_tokens": ["Add", "helper", "to", "get", "a", "new", "StdEncoding"], "add_tokens": "// NewStdEncoding returns an Encoding preconfigured with the standard base62 alphabet func NewStdEncoding ( ) * Encoding { return NewEncoding ( encodeStd ) } var StdEncoding = NewStdEncoding ( )", "del_tokens": "var StdEncoding = NewEncoding ( encodeStd )", "commit_type": "add"}
{"commit_tokens": ["Adds", "test", "to", "the", "cotacao", "command"], "add_tokens": "var ( url = \" \" type retorno struct { data := & retorno { } err = web . GetJSON ( url , data )", "del_tokens": "const ( URL = \" \" type Cotacao struct { data := & Cotacao { } err = web . GetJSON ( URL , data )", "commit_type": "add"}
{"commit_tokens": ["add", "Perm", "function", "in", "math", "/", "random", "pkg"], "add_tokens": "// using jsonx to support c-style comments and extra comma at last element of object or array err = jsonx . NewDecoder ( reader , jsonx . WithComment ( ) , jsonx . WithExtraComma ( ) ) . Decode ( conf )", "del_tokens": "// json format which supports comments and extra comma at last element of object or array var node jsonx . Node node , err = jsonx . Read ( reader , jsonx . WithComment ( ) , jsonx . WithExtraComma ( ) ) if err == nil { var buf bytes . Buffer if err = jsonx . Write ( & buf , node ) ; err == nil { err = json . NewDecoder ( & buf ) . Decode ( conf ) } }", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "search", "command", "to", "the", "registry", "package", "."], "add_tokens": "registry . NewSearchCommand ( dockerCli ) ,", "del_tokens": "hide ( image . NewSearchCommand ( dockerCli ) ) ,", "commit_type": "move"}
{"commit_tokens": ["fixed", "a", "small", "bug", "where", "info", "could", "be", "nil"], "add_tokens": "if info == nil || info . IsDir ( ) {", "del_tokens": "if info . IsDir ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Improve", "coverage", "and", "fix", "identifier", "string", "gen"], "add_tokens": "return string ( append ( append ( result , first ) , tail ... ) )", "del_tokens": "return append ( append ( result , first ) , tail ... )", "commit_type": "improve"}
{"commit_tokens": ["add", "warning", "note", "to", "server", "upgrade", "-", "plan", "change", "command"], "add_tokens": "cmd . Command ( \" \" , \" \" , serversChangePlan )", "del_tokens": "cmd . Command ( \" \" , \" \" , serversChangePlan )", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "configured", "job", "base", "labels", "."], "add_tokens": "baseLabels := model . LabelSet { \" \" : model . LabelValue ( t . Address ( ) ) } for baseK , baseV := range t . BaseLabels { baseLabels [ baseK ] = baseV } m [ baseK ] = baseV m [ baseK ] = baseV", "del_tokens": "baseLabels := map [ string ] string { \" \" : t . Address ( ) } m [ model . LabelName ( baseK ) ] = model . LabelValue ( baseV ) m [ model . LabelName ( baseK ) ] = model . LabelValue ( baseV )", "commit_type": "add"}
{"commit_tokens": ["add", "re", "-", "use", "for", "client", "connection", "on", "import"], "add_tokens": "slice_clients map [ string ] * Client slice_clients : make ( map [ string ] * Client ) , func ( c * Client ) getDirectClient ( indexName string , slice uint64 , host string ) ( * Client , error ) { key := fmt . Sprintf ( \" \" , indexName , slice , host ) cacheClient , ok := c . slice_clients [ key ] if ok { return cacheClient , nil } uri , err := NewURIFromAddress ( host ) if err != nil { return nil , err } newClient := NewClientWithURI ( uri ) c . slice_clients [ key ] = newClient return newClient , nil } client , err := c . getDirectClient ( indexName , slice , node . Host )", "del_tokens": "uri , err := NewURIFromAddress ( node . Host ) client := NewClientWithURI ( uri )", "commit_type": "add"}
{"commit_tokens": ["Add", "permission", "for", "state", "change", "log", "remove", "State", "StateChangeLog", "from", "create", "/", "edit", "page"], "add_tokens": "res . Meta ( & admin . Meta { Name : \" \" , Permission : roles . Deny ( roles . Update , roles . Anyone ) . Deny ( roles . Create , roles . Anyone ) } ) res . NewAttrs ( res . NewAttrs ( ) , \" \" , \" \" ) res . EditAttrs ( res . EditAttrs ( ) , \" \" , \" \" )", "del_tokens": "res . Meta ( & admin . Meta { Name : \" \" , Permission : roles . Deny ( roles . Update , roles . Anyone ) } )", "commit_type": "add"}
{"commit_tokens": ["Update", "repository", "links", "to", "ipfs", "org", "and", "remove", "broken", "gobuilder", ".", "me", "link"], "add_tokens": "dnslink \" \"", "del_tokens": "dnslink \" \"", "commit_type": "update"}
{"commit_tokens": ["fixed", "initialization", "problem", "with", "test"], "add_tokens": "V1 := make ( map [ int ] bool ) V2 := make ( map [ int ] bool ) V1 := make ( map [ int ] bool ) V2 := make ( map [ int ] bool )", "del_tokens": "a := true if a { return } var V1 map [ int ] bool var V2 map [ int ] bool var V1 map [ int ] bool var V2 map [ int ] bool", "commit_type": "fix"}
{"commit_tokens": ["Use", "xml", ".", "Marshal", "instead", "of", "StringXML", "in", "tests"], "add_tokens": "\" \" if got := b . Bytes ( ) ; string ( got ) != tc . want { func ( tc testCase ) testMarshal ( t * testing . T ) { got , err := xml . Marshal ( tc . e ) if string ( got ) != tc . want { t . Errorf ( \" \\n \\n \" , tc . e , string ( got ) , tc . want ) tc . testMarshal ( t ) tc . testMarshal ( t ) tc . testMarshal ( t )", "del_tokens": "if got := b . String ( ) ; got != tc . want { func ( tc testCase ) testStringXML ( t * testing . T ) { got , err := tc . e . StringXML ( ) if got != tc . want { t . Errorf ( \" \\n \\n \" , tc . e , got , tc . want ) tc . testStringXML ( t ) tc . testStringXML ( t ) tc . testStringXML ( t )", "commit_type": "use"}
{"commit_tokens": ["add", "stats", ".", "Tags", ".", "Format"], "add_tokens": "\" \" c . Histogram ( stats . Opts { Name : \" \" , Unit : \" \" } ) . Observe ( time . Second )", "del_tokens": "c . Histogram ( stats . Opts { Name : \" \" , Unit : \" \" } ) . Observe ( 1 )", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "unit", "tests", "for", "topic", "and", "partitions", "."], "add_tokens": "return pl [ i ] . topic . Name < pl [ j ] . topic . Name || ( pl [ i ] . topic . Name == pl [ j ] . topic . Name && pl [ i ] . ID < pl [ j ] . ID )", "del_tokens": "return pl [ i ] . ID < pl [ j ] . ID", "commit_type": "add"}
{"commit_tokens": ["Fix", "close", "logic", "in", "the", "sender"], "add_tokens": "s . flush ( ) return s . transport . Close ( )", "del_tokens": "s . flush ( ) err := s . transport . Close ( ) return err", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "encryption", "issue", "for", "negative", "md5sum"], "add_tokens": "table := make ( [ ] uint64 , 256 ) var a uint64 var i uint64 for i = 0 ; i < 256 ; i ++ { for i = 1 ; i < 1024 ; i ++ { table = Sort ( table , func ( x , y uint64 ) int64 { return int64 ( a % uint64 ( x + i ) - a % uint64 ( y + i ) ) for i = 0 ; i < 256 ; i ++ { for i = 0 ; i < 256 ; i ++ {", "del_tokens": "table := make ( [ ] int , 256 ) var a int64 for i := 0 ; i < 256 ; i ++ { for i := 1 ; i < 1024 ; i ++ { table = Sort ( table , func ( x , y int ) int { return int ( a % int64 ( x + i ) - a % int64 ( y + i ) ) for i := 0 ; i < 256 ; i ++ { for i := 0 ; i < 256 ; i ++ {", "commit_type": "fix"}
{"commit_tokens": ["Add", "timeouts", "when", "waiting", "on", "the", "PR", "building", "bot"], "add_tokens": "err := sq . githubConfig . WaitForPending ( pr ) if err != nil { s := fmt . Sprintf ( \" \" , err ) sq . SetPRStatus ( pr , s ) return } err = sq . githubConfig . WaitForNotPending ( pr ) if err != nil { s := fmt . Sprintf ( \" \" , err ) sq . SetPRStatus ( pr , s ) return }", "del_tokens": "_ = sq . githubConfig . WaitForPending ( pr ) _ = sq . githubConfig . WaitForNotPending ( pr )", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "for", "HttpOnly", "and", "Secure", "cookies"], "add_tokens": "HttpOnly : Config . CookieHttpOnly , Secure : Config . CookieSecure ,", "del_tokens": "HttpOnly : true ,", "commit_type": "add"}
{"commit_tokens": ["fix", "goroot", "build", "and", "use", "goreleaser"], "add_tokens": "if ! inv . Keep { // remove this file before we run the compiled version, in case the // compiled file screws things up. Yes this doubles up with the above // defer, that's ok. os . Remove ( main ) } // we explicitly set GOROOT on the command because go build will fail // without it. goroot := os . Getenv ( \" \" ) if goroot == \" \" { c := exec . Command ( \" \" , \" \" , \" \" ) c . Stderr = stderr b , err := c . Output ( ) if err != nil { return fmt . Errorf ( \" \" , err ) } goroot = strings . TrimSpace ( string ( b ) ) if goroot == \" \" { return errors . New ( \" \" ) } } c . Env = append ( os . Environ ( ) , \" \" + goroot )", "del_tokens": "c . Env = os . Environ ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "compilation", "with", "Go", "weekly", ".", "2011", "-", "10", "-", "18"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "typo", "in", "the", "readme", "and", "moving", "todos", "in", "a", "separate", "file", "."], "add_tokens": "// +build amd64,!appengine", "del_tokens": "// +build amd64", "commit_type": "fix"}
{"commit_tokens": ["updated", "tests", "and", "had", "a", "bit", "of", "fun", "while", "at", "it", "."], "add_tokens": "electron muon higgs case muon : return \" \" case higgs : return \" \"", "del_tokens": "electron", "commit_type": "update"}
{"commit_tokens": ["Add", "errors", "to", "Matcher", ".", "Get", "*", "and", "handle", "automatic", "405", "method", "not", "allowed"], "add_tokens": "value , _ := hm . matcher . GetWithContext ( c , reversedHost , nil )", "del_tokens": "value := hm . matcher . GetWithContext ( c , reversedHost , nil )", "commit_type": "add"}
{"commit_tokens": ["adds", "parsing", "of", "response", "structs"], "add_tokens": "Responses [ ] * ast . File var op , md , mt , pm , rs bool // only add a particular file once case \" \" : if ! rs { cp . Responses = append ( cp . Responses , file ) rs = true }", "del_tokens": "var op , md , mt , pm bool // only add a particular file once", "commit_type": "add"}
{"commit_tokens": ["Added", "callback", "metrics", "e", ".", "g", ".", "GaugeFunc", "."], "add_tokens": "// TODO: Come up with a better example. // Note that this example is pretty much academic as the prometheus package // already provides an UntypedFunc type.", "del_tokens": "// Note that this is a pretty low-level approach. A more high-level approach is // to implement a Collector directly and not an individual Metric, see the // Collector examples.", "commit_type": "add"}
{"commit_tokens": ["Use", "TimeFieldFormat", "for", "Timestamp", "field"], "add_tokens": "if TimeFieldFormat == \" \" { return appendInt64 ( dst , key , t . Unix ( ) ) } return appendTime ( dst , TimestampFieldName , now ( ) )", "del_tokens": "return appendInt64 ( dst , TimestampFieldName , now ( ) . Unix ( ) )", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "change", "that", "broke", "backwards", "compatability", "prove", "it", "still", "works", "with", "a", "test", "."], "add_tokens": "TemplateVariables [ ] TemplateVariable `json:\"template_variables,omitempty\"`", "del_tokens": "TemplateVariables [ ] TemplateVariable `json:\"template_variables\"`", "commit_type": "fix"}
{"commit_tokens": ["Remove", "ts", "from", "read", "requests", "and", "update", "deps"], "add_tokens": "_ , err := client . Read ( ctx , r )", "del_tokens": "r . Tsm = brimtime . TimeToUnixMicro ( time . Now ( ) ) res , err := client . Read ( ctx , r ) if res . Tsm != r . Tsm { log . Printf ( \" \" , id , i , brimtime . UnixMicroToTime ( res . Tsm ) , brimtime . UnixMicroToTime ( r . Tsm ) ) }", "commit_type": "remove"}
{"commit_tokens": ["Use", "client", "-", "go", "for", "ListerWatcher", "etc", "."], "add_tokens": "claimController * cache . Controller volumeController * cache . Controller controller . claims , controller . claimController = cache . NewInformer ( cache . ResourceEventHandlerFuncs { controller . volumes , controller . volumeController = cache . NewInformer ( cache . ResourceEventHandlerFuncs { controller . classes = cache . NewStore ( cache . DeletionHandlingMetaNamespaceKeyFunc )", "del_tokens": "// TODO get rid of this and use https://github.com/kubernetes/kubernetes/pull/32718 \" \" claimController * framework . Controller volumeController * framework . Controller controller . claims , controller . claimController = framework . NewInformer ( framework . ResourceEventHandlerFuncs { controller . volumes , controller . volumeController = framework . NewInformer ( framework . ResourceEventHandlerFuncs { controller . classes = cache . NewStore ( framework . DeletionHandlingMetaNamespaceKeyFunc )", "commit_type": "use"}
{"commit_tokens": ["remove", "embedded", "fields", "in", "event", "types"], "add_tokens": "User * User Actor * User Client * Client Type ChannelChangeType Channel * Channel Client * Client UserList RegisteredUsers Acl * Acl Client * Client BanList BanList Client * Client Type ContextActionChangeType ContextAction * ContextAction", "del_tokens": "* User Actor * User Client * Client Type ChannelChangeType * Channel Client * Client RegisteredUsers Acl Client * Client BanList Client * Client Type ContextActionChangeType * ContextAction", "commit_type": "remove"}
{"commit_tokens": ["added", "some", "mutex", "locking", "in", "mist", "to", "avoid", "concurrent", "subscriptions"], "add_tokens": "\" \" mutex = & sync . Mutex { } // publish publishes to both subscribers, and to replicators mutex . Lock ( ) mutex . Unlock ( ) // unsubscribe removes a proxy from the list of mist subscribers; we need this // so that we can lock this process incase multiple proxies are closing at the // same time func unsubscribe ( pid uint32 ) { mutex . Lock ( ) delete ( subscribers , pid ) mutex . Unlock ( ) }", "del_tokens": "// \"sort\" // Publish publishes to both subscribers, and to replicators", "commit_type": "add"}
{"commit_tokens": ["added", "old", "-", "style", "with", "-", "tag", "which", "is", "still", "supported", "by", "django", "(", "see", "https", ":", "//", "docs", ".", "djangoproject", ".", "com", "/", "en", "/", "dev", "/", "ref", "/", "templates", "/", "builtins", "/", "#with", ")", "."], "add_tokens": "tokenKeywords = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "del_tokens": "tokenKeywords = [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" }", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "Tags", "type", "."], "add_tokens": "type Tags [ ] Tag func ( tags * Tags ) UnmarshalJSON ( data [ ] byte ) error { var tagsArray [ ] Tag switch data [ 0 ] { case '[' : // Attempt to unmarshal into []Tag err := json . Unmarshal ( data , & tagsArray ) if err != nil { return err } case '{' : // Unmarshal into map[string]string tagsMap := make ( map [ string ] string ) err := json . Unmarshal ( data , & tagsMap ) if err != nil { return err } // convert to []Tag for k , v := range tagsMap { tagsArray = append ( tagsArray , Tag { k , v } ) } default : return errors . New ( \" \" ) } * tags = tagsArray return nil } Tags Tags `json:\"tags,omitempty\"`", "del_tokens": "Tags [ ] Tag `json:\"tags,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "a", ".", "MarshalJSONBuf", "interface", "to", "the", "generated", "code", "so", "for", "structs", "containing", "other", "ffjson", "structs", "we", "can", "avoid", "having", "to", "allocate", "multiple", "bytes", ".", "Buffers"], "add_tokens": "if typ . Implements ( marshalerBufType ) || typeInInception ( ic , typ ) { out += \" \" + name + \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" return out } if typ . Implements ( marshalerType ) { out += \" \" + \" \\n \" out += \" \" + name + \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" // TOOD(pquerna): automatically calc a good size! out += `err := mj.MarshalJSONBuf(&buf)` + \" \\n \" out += `if err != nil {` + \" \\n \" out += \" \" + \" \\n \" out += `}` + \" \\n \" out += `return buf.Bytes(), nil` + \" \\n \" out += `}` + \" \\n \" out += `func (mj *` + si . Name + `) MarshalJSONBuf(buf *bytes.Buffer) (error) {` + \" \\n \" out += `return nil` + \" \\n \"", "del_tokens": "if typ . Implements ( marshalerType ) || typeInInception ( ic , typ ) { out += \" \" + \" \\n \" out += \" \" + name + \" \" + \" \\n \" out += \" \" + \" \\n \" out += \" \" + \" \\n \" // TOOD(pquerna): automatically calc a good size! // out += \"println(string(buf.Bytes()))\" + \"\\n\" out += `return buf.Bytes(), nil` + \" \\n \"", "commit_type": "add"}
{"commit_tokens": ["Add", "http", "todo", ";", "Simplify", "servecontent", "func"], "add_tokens": "http . ServeContent ( w , r , p , s . modtime , bytes . NewReader ( bs ) )", "del_tokens": "rdskr := bytes . NewReader ( bs ) http . ServeContent ( w , r , p , s . modtime , rdskr )", "commit_type": "add"}
{"commit_tokens": ["added", "a", "raw", "helper", "that", "converts", "a", "string", "to", "template", ".", "HTML"], "add_tokens": "input := `<%= escapedHTML() %>|<%= unescapedHTML() %>|<%= raw(\"<b>unsafe</b>\") %>` \" \" : func ( ) string { \" \" : func ( ) template . HTML { r . Equal ( \" \" , s )", "del_tokens": "input := `<%= safe() %>|<%= unsafe() %>` \" \" : func ( ) string { \" \" : func ( ) template . HTML { r . Equal ( \" \" , s )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "dispatching", "to", "post", "methods", "with", "bodies", ";", "improve", "default", "user", "selection"], "add_tokens": "curr += n", "del_tokens": "curr += n", "commit_type": "fix"}
{"commit_tokens": ["Remove", "ktrie", "param", "from", "delimcase", "func", "."], "add_tokens": "return delimitedCase ( s , kebabDelim , false ) return delimitedCase ( s , kebabDelim , true ) return delimitedCase ( s , snakeDelim , false ) return delimitedCase ( s , snakeDelim , true ) return delimitedCase ( s , snakeDelim , false ) return delimitedCase ( s , snakeDelim , true ) return delimitedCase ( s , kebabDelim , false ) return delimitedCase ( s , kebabDelim , true ) func delimitedCase ( s string , delim rune , upper bool ) string {", "del_tokens": "return delimitedCase ( ciTrie , s , kebabDelim , false ) return delimitedCase ( ciTrie , s , kebabDelim , true ) return delimitedCase ( ciTrie , s , snakeDelim , false ) return delimitedCase ( ciTrie , s , snakeDelim , true ) return delimitedCase ( k . t , s , snakeDelim , false ) return delimitedCase ( k . t , s , snakeDelim , true ) return delimitedCase ( k . t , s , kebabDelim , false ) return delimitedCase ( k . t , s , kebabDelim , true ) func delimitedCase ( t * ktrie . KTrie , s string , delim rune , upper bool ) string {", "commit_type": "remove"}
{"commit_tokens": ["created", "onionv3", "and", "garlic", "multiaddrs"], "add_tokens": "\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , t . Error ( \" \" , s , err ) t . Error ( err , \" \" , len ( b2 ) ) testString ( \" \" , \" \" ) testString ( \" \" , \" \" ) testString ( \" \" , \" \" ) testString ( \" \" , \" \" ) testString ( \" \" , \" \" ) testString ( \" \" , \" \" ) testString ( \" \" , \" \" )", "del_tokens": "t . Error ( \" \" , s ) t . Error ( err )", "commit_type": "create"}
{"commit_tokens": ["Added", "support", "for", "running", "generators", "in", "parallel", "."], "add_tokens": "var rng = util . NewRand ( 42 ) // Create everything here to save allocations in the loop. args := & GeneratorArgs { rng , 0 , NewSerialExecutor ( ) } func BenchmarkSerialGeneration ( b * testing . B ) { args := & GeneratorArgs { Rng : rng , Executor : NewSerialExecutor ( ) , } generator , err := NewGenerator ( BigFancyRegexp , args ) if err != nil { panic ( err ) } b . ResetTimer ( ) for i := 0 ; i < b . N ; i ++ { generator . Generate ( ) } } func BenchmarkParallelGeneration ( b * testing . B ) { args := & GeneratorArgs { Rng : rng , Executor : NewForkJoinExecutor ( ) , }", "del_tokens": "var args = & GeneratorArgs { Rng : util . NewRand ( 42 ) , } func BenchmarkGeneration ( b * testing . B ) { //fmt.Printf(\"generated message:\\n%s\\n\\n\", generator(r))", "commit_type": "add"}
{"commit_tokens": ["Fix", "code", ".", "google", ".", "com", "/", "p", "/", "go", ".", "net", "import", "to", "use", "golang", ".", "org", "/", "x", "/", "net", "instead", "."], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "fix"}
{"commit_tokens": ["Fix", "publish", "discard", "when", "no", "worker", "configured"], "add_tokens": "db . Publish . Publish ( records ... ) db . Publish . Discard ( records ... )", "del_tokens": "Publish { DB : draftDB } . Publish ( records ... ) Publish { DB : draftDB } . Discard ( records ... )", "commit_type": "fix"}
{"commit_tokens": ["implemented", "eventBuffer", "purges", "via", "priority", "queue"], "add_tokens": "manager , err := golongpoll . StartLongpoll ( golongpoll . Options { LoggingEnabled : true , MaxLongpollTimeoutSeconds : 120 , MaxEventBufferSize : 100 , EventTimeToLiveSeconds : 60 * 5 , // 5 minutes } )", "del_tokens": "manager , err := golongpoll . CreateCustomManager ( 120 , 100 , true )", "commit_type": "implement"}
{"commit_tokens": ["Remove", "logging", "of", "unused", "keys", "for", "now"], "add_tokens": "// TODO: log unused keys", "del_tokens": "// TODO: use logging if len ( data . Unused ) > 0 { fmt . Printf ( \" \" , data . Unused ) }", "commit_type": "remove"}
{"commit_tokens": ["add", "async", "close", "with", "timeout"], "add_tokens": "\" \" Convey ( \" \" , t , func ( ) { death := NewDeath ( syscall . SIGHUP ) death . setTimeout ( 10 * time . Millisecond ) neverClose := & neverClose { } syscall . Kill ( os . Getpid ( ) , syscall . SIGHUP ) death . WaitForDeath ( neverClose ) } ) } type neverClose struct { } func ( n * neverClose ) Close ( ) { time . Sleep ( 2 * time . Minute )", "del_tokens": "defer death . Close ( ) defer death . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "bool_test", ".", "go"], "add_tokens": "// The type of the flag as required by the pflag.Value interface", "del_tokens": "// The type of the flag as requred by the pflag.Value interface", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "not", "detecting", "a", "change", "in", "return", "parameters"], "add_tokens": "// Adding return parameters to a function, when it didn't have any before is // ok, so only check if for breaking changes if there was parameters before if len ( before . Results . List ) > 0 { added , removed , changed := diffFields ( bresults , aresults ) if len ( added ) > 0 || len ( removed ) > 0 || len ( changed ) > 0 { return changeBreaking , \" \" }", "del_tokens": "_ , removed , changed := diffFields ( bresults , aresults ) // Only check if we're changing/removing return parameters if len ( removed ) > 0 || len ( changed ) > 0 { return changeBreaking , \" \"", "commit_type": "fix"}
{"commit_tokens": ["Add", "ListSSL", "test", "fix", "bugs", "in", "ZoneCustomSSL", "struct"], "add_tokens": "Signature string `json:\"signature\"` Status string `json:\"status\"` Priority int `json:\"priority\"`", "del_tokens": "Priority int `json:\"priority\"` Status string `json:\"success\"` Permissions [ ] string `json:\"permissions\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "changing", "root", "widget"], "add_tokens": "painter * Painter root Widget painter : p , root : root , func ( ui * tcellUI ) SetWidget ( w Widget ) { ui . root = w } ui . painter . Theme = p ui . root . OnKeyEvent ( e ) ui . painter . Repaint ( ui . root ) ui . painter . Repaint ( ui . root )", "del_tokens": "Painter * Painter Root Widget Painter : p , Root : root , ui . Painter . Theme = p ui . Root . OnKeyEvent ( e ) ui . Painter . Repaint ( ui . Root ) ui . Painter . Repaint ( ui . Root )", "commit_type": "add"}
{"commit_tokens": ["use", "LongestPrefix", "as", "a", "way", "easier", "way", "to", "find", "the", "subcommand"], "add_tokens": "k , _ , ok := c . commandTree . LongestPrefix ( strings . Join ( c . Args [ i : ] , \" \" ) ) if ok { c . subcommand = k i += strings . Count ( k , \" \" )", "del_tokens": "// TODO: LongestPrefix newI := i for _ , arg := range c . Args [ i + 1 : ] { if arg == \" \" || arg [ 0 ] == '-' { break } subcommand := c . subcommand + \" \" + arg if _ , ok := c . commandTree . Get ( subcommand ) ; ok { c . subcommand = subcommand } newI ++ } // If we found a subcommand, then move i so that we // get the proper arg list below if strings . ContainsRune ( c . subcommand , ' ' ) { i = newI", "commit_type": "use"}
{"commit_tokens": ["Using", "value", "instead", "of", "pointer", "in", "test"], "add_tokens": "u := UUID { }", "del_tokens": "u := new ( UUID )", "commit_type": "use"}
{"commit_tokens": ["Fix", "file", "in", "use", "issue", "when", "renewing", "token", "in", "devicetoken", "flow"], "add_tokens": "\" \" defer f . Close ( ) // test that LoadToken closes the file properly err = SaveToken ( f . Name ( ) , 0600 , * actualToken ) if err != nil { t . Fatalf ( \" \" , err ) } f . Close ( ) if runtime . GOOS != \" \" { // permissions don't work on Windows if perm := fi . Mode ( ) . Perm ( ) ; perm != mode { t . Fatalf ( \" \" , perm , mode , f . Name ( ) ) } pathWhereWeShouldntHavePermission := \" \" if runtime . GOOS == \" \" { pathWhereWeShouldntHavePermission = \" \\\\ \\\\ \\\\ \\\\ \" } err := SaveToken ( pathWhereWeShouldntHavePermission , 0644 , * token ( ) ) t . Fatalf ( \" \" , expectedSubstring , err ) t . Fatalf ( \" \" , expectedSubstring , err )", "del_tokens": "if perm := fi . Mode ( ) . Perm ( ) ; perm != mode { t . Fatalf ( \" \" , perm , mode , f . Name ( ) ) err := SaveToken ( \" \" , 0644 , * token ( ) ) t . Fatalf ( \" \" , expectedSubstring , err . Error ( ) ) t . Fatalf ( \" \" , expectedSubstring , err . Error ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "test", "bugs", "."], "add_tokens": "testCase { - 1125899906842624.0 , MATCH_TRUE , \" \" } , testCase { - 1125899906842624.0 + 0i , MATCH_TRUE , \" \" } , testCase { float32 ( kExpected ) , MATCH_FALSE , \" \" } , testCase { complex64 ( kExpected ) , MATCH_FALSE , \" \" } , testCase { 1125899906842624.0 , MATCH_TRUE , \" \" } , testCase { 1125899906842624.0 + 0i , MATCH_TRUE , \" \" } , testCase { float32 ( kExpected ) , MATCH_FALSE , \" \" } , testCase { complex64 ( kExpected ) , MATCH_FALSE , \" \" } ,", "del_tokens": "testCase { - 1125899906842620.0 , MATCH_TRUE , \" \" } , testCase { - 1125899906842620.0 + 0i , MATCH_TRUE , \" \" } , testCase { float32 ( kExpected ) , MATCH_TRUE , \" \" } , testCase { complex64 ( kExpected ) , MATCH_TRUE , \" \" } , testCase { 1125899906842620.0 , MATCH_TRUE , \" \" } , testCase { 1125899906842620.0 + 0i , MATCH_TRUE , \" \" } , testCase { float32 ( kExpected ) , MATCH_TRUE , \" \" } , testCase { complex64 ( kExpected ) , MATCH_TRUE , \" \" } ,", "commit_type": "fix"}
{"commit_tokens": ["updated", "godep", "bosh", "-", "agent", "and", "softlayer", "-", "go", "dependencies"], "add_tokens": "import ( boshcmd \" \" ) DecompressFileToDirOptions [ ] boshcmd . CompressorOptions func ( fc * FakeCompressor ) DecompressFileToDir ( tarballPath string , dir string , options boshcmd . CompressorOptions ) ( err error ) { fc . DecompressFileToDirOptions = append ( fc . DecompressFileToDirOptions , options )", "del_tokens": "func ( fc * FakeCompressor ) DecompressFileToDir ( tarballPath string , dir string ) ( err error ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "error", "message", "in", "VariableToInterface"], "add_tokens": "return nil , fmt . Errorf ( \" \" , input . Type )", "del_tokens": "return nil , fmt . Errorf ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "data", "corruption", "in", "Kafka", "add", "hexdump", "to", "collector", "/", "consumers"], "add_tokens": "log . Println ( \" \" , conn . RemoteAddr ( ) )", "del_tokens": "log . Println ( \" \" , conn . RemoteAddr ( ) )", "commit_type": "fix"}
{"commit_tokens": ["Move", "change", "debug", "to", "stinger", "method"], "add_tokens": "fmt . Println ( change )", "del_tokens": "\" \" \" \" fset := token . NewFileSet ( ) // only require non-nil fset pcfg := printer . Config { Mode : printer . RawFormat , Indent : 1 } if change . op == opChange { fmt . Printf ( \" \\n \" , change . op , change . changeType , change . summary ) } else { fmt . Println ( change . op ) } if change . before != nil { pcfg . Fprint ( os . Stdout , fset , change . before ) fmt . Println ( ) } if change . after != nil { pcfg . Fprint ( os . Stdout , fset , change . after ) fmt . Println ( ) } fmt . Println ( )", "commit_type": "move"}
{"commit_tokens": ["Add", "extensions", "to", "the", "generator", "."], "add_tokens": "// TODO: (needed for repeated extensions)", "del_tokens": "// TODO(: (needed for repeated extensions)", "commit_type": "add"}
{"commit_tokens": ["Fix", "region", "comparator", "and", "add", "some", "basic", "unit", "tests", "."], "add_tokens": "return int ( ai ) - int ( bi ) return int ( ai ) - int ( bi ) return int ( ai ) - int ( bi )", "del_tokens": "return int ( ai - bi ) return int ( ai - bi ) return int ( ai - bi )", "commit_type": "fix"}
{"commit_tokens": ["Make", "role", ".", "newPermission", "()", "public"], "add_tokens": "return role . NewPermission ( )", "del_tokens": "return role . newPermission ( )", "commit_type": "make"}
{"commit_tokens": ["remove", "LDFLAGS", "-", "mavx", "and", "fix", "build", "constraints"], "add_tokens": "// +build linux amd64 // #cgo LDFLAGS: tr := trytes . Trits ( ) copy ( c . state , tr [ transactionTrinarySize - HashSize : ] )", "del_tokens": "// +build linux,amd64 // #cgo LDFLAGS: -mavx tr := trytes . Trits ( ) copy ( c . state , tr [ transactionTrinarySize - HashSize : ] )", "commit_type": "remove"}
{"commit_tokens": ["fixed", "router", "issue", "for", "/"], "add_tokens": "mode : debugLevel ,", "del_tokens": "mode : off ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "variable", "references", "in", "tests", "."], "add_tokens": "var dispid [ ] int32 var err error dispid , err = dispatch . GetIDsOfName ( [ ] string { method } )", "del_tokens": "var dispid [ ] int32 dispid , err := dispatch . GetIDsOfName ( [ ] string { method } )", "commit_type": "fix"}
{"commit_tokens": ["Created", "entry", "point", "for", "an", "API", "handler", ";", "Simple", "tests", "for", "API", "handler"], "add_tokens": "if lenData := len ( mapData [ \" \" ] . ( map [ string ] interface { } ) ) ; lenData == numPosts {", "del_tokens": "if lenData := len ( mapData [ \" \" ] . ( map [ string ] interface { } ) ) ; lenData > numPosts {", "commit_type": "create"}
{"commit_tokens": ["implement", "some", "more", "of", "the", "graval", "-", "swift", "example"], "add_tokens": "path = scoped_path ( driver . user , path ) object , _ , err := driver . connection . Object ( driver . container , path ) if err != nil { return - 1 } return int ( object . Bytes ) path = scoped_path ( driver . user , path ) object , _ , err := driver . connection . Object ( driver . container , path ) if err != nil { return time . Now ( ) , err } return object . LastModified , nil path = scoped_path ( driver . user , path ) log . Printf ( \" \" , path ) data , err = driver . connection . ObjectGetString ( driver . container , path ) if err != nil { return \" \" , errors . New ( \" \" ) } return", "del_tokens": "bytes = - 1 return return time . Now ( ) , nil log . Printf ( \" \" , len ( data ) ) return \" \" , errors . New ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["fixed", "sockets", ".", "Close", "()"], "add_tokens": "defer s . Close ( ) time . Sleep ( 100 * time . Millisecond )", "del_tokens": "time . Sleep ( 1 * time . Second ) s . Close ( )", "commit_type": "fix"}
{"commit_tokens": ["Added", "language", "/", "printer", "/", "schema_printer_test", ".", "go"], "add_tokens": "fields := getMapValue ( node , \" \" ) fields := getMapValue ( node , \" \" ) values := getMapValue ( node , \" \" ) fields := getMapValue ( node , \" \" ) definition := getMapValueString ( node , \" \" )", "del_tokens": "fields := toSliceString ( getMapValue ( node , \" \" ) ) fields := toSliceString ( getMapValue ( node , \" \" ) ) values := toSliceString ( getMapValue ( node , \" \" ) ) fields := toSliceString ( getMapValue ( node , \" \" ) ) definition := getMapValueString ( node , \" \" )", "commit_type": "add"}
{"commit_tokens": ["add", "documentation", "on", "event", "&", "handler"], "add_tokens": "var levelNames = [ 8 ] string { // LevelName converts a level into its textual representation. return levelNames [ level ] // NewEvent creates a new Event object. // The time is set to current time, and the fields are deep-copied. func NewEvent ( id uint64 , level Level , message string , fields interface { } ) * Event { fieldsCopy , _ , flatFields := deStruct ( fields ) Fields : fieldsCopy , // LevelName returns the textual representation of the level name for the event.", "del_tokens": "var LevelNames = [ 8 ] string { return LevelNames [ level ] func NewEvent ( id uint64 , level Level , message string , data interface { } ) * Event { dataCopy , _ , flatFields := deStruct ( data ) Fields : dataCopy ,", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "Wait", "()", "call", "instead", "of", "channel"], "add_tokens": "looper . Wait ( ) looper . Wait ( ) err := looper . Wait ( )", "del_tokens": "<- looper . DoneChan <- looper . DoneChan err := <- looper . DoneChan", "commit_type": "use"}
{"commit_tokens": ["fix", "a", "bug", "found", "in", "c2", "-", "docker", "-", "15"], "add_tokens": "type ByMemCap [ ] NodeInfo func ( a ByMemCap ) Len ( ) int { return len ( a ) } func ( a ByMemCap ) Swap ( i , j int ) { a [ i ] , a [ j ] = a [ j ] , a [ i ] } func ( a ByMemCap ) Less ( i , j int ) bool { return a [ i ] . Memory < a [ j ] . Memory } nodeInfoList := ByMemCap { } sort . Sort ( nodeInfoList ) log . Debugf ( \" \" , nodeInfoList )", "del_tokens": "nodeInfoList := [ ] NodeInfo { }", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "stringer", "call", "to", "generate", "enum"], "add_tokens": "fmt . Fprintf ( buf , \" \\n \\n \\n \\n \" , enumMappings [ e . Name ] , enumMappings [ e . Name ] )", "del_tokens": "fmt . Fprintf ( buf , \" \\n \\n \" , enumMappings [ e . Name ] )", "commit_type": "add"}
{"commit_tokens": ["updated", "tests", "and", "added", "client"], "add_tokens": "So ( s . getStream ( \" \" ) , ShouldNotBeNil ) So ( s . getStream ( \" \" ) , ShouldBeNil )", "del_tokens": "So ( s . streams [ \" \" ] , ShouldNotBeNil ) So ( s . streams [ \" \" ] , ShouldBeNil )", "commit_type": "update"}
{"commit_tokens": ["Fix", "funky", "conditionals", "in", "REST", "header", "parsing", "."], "add_tokens": "var t time . Time t , err = time . Parse ( time . RFC1123 , s ) if err != nil { return } var n int n , err = strconv . Atoi ( s ) if err != nil { return } var v bool v , err = strconv . ParseBool ( s ) if err != nil { return }", "del_tokens": "if t , e := time . Parse ( time . RFC1123 , s ) ; e != nil { err = e return } else { } if n , e := strconv . Atoi ( s ) ; e != nil { err = e return } else { } if v , e := strconv . ParseBool ( s ) ; e != nil { err = e return } else { }", "commit_type": "fix"}
{"commit_tokens": ["Use", "memcache", "binary", "protocol", "rather", "than", "text"], "add_tokens": "if err != ErrBadIncrDec { t . Fatalf ( \" \" , ErrBadIncrDec , err )", "del_tokens": "\" \" if err == nil || ! strings . Contains ( err . Error ( ) , \" \" ) { t . Fatalf ( \" \" , err )", "commit_type": "use"}
{"commit_tokens": ["Add", "argo", "-", "cd", "client", "wrapper"], "add_tokens": "\" \" \" \" func NewInstallCommand ( ) * cobra . Command { clientConfig clientcmd . ClientConfig conf , err := clientConfig . ClientConfig ( ) clientConfig = addKubectlFlagsToCmd ( command ) func addKubectlFlagsToCmd ( cmd * cobra . Command ) clientcmd . ClientConfig { // The \"usual\" clientcmd/kubectl flags loadingRules := clientcmd . NewDefaultClientConfigLoadingRules ( ) loadingRules . DefaultClientConfig = & clientcmd . DefaultClientConfig overrides := clientcmd . ConfigOverrides { } kflags := clientcmd . RecommendedConfigOverrideFlags ( \" \" ) cmd . PersistentFlags ( ) . StringVar ( & loadingRules . ExplicitPath , \" \" , \" \" , \" \" ) clientcmd . BindOverrideFlags ( & overrides , cmd . PersistentFlags ( ) , kflags ) return clientcmd . NewInteractiveDeferredLoadingClientConfig ( loadingRules , & overrides , os . Stdin ) }", "del_tokens": "func NewInstallCommand ( globalArgs * globalFlags ) * cobra . Command { conf , err := globalArgs . clientConfig . ClientConfig ( ) addKubectlFlagsToCmd ( command , globalArgs )", "commit_type": "add"}
{"commit_tokens": ["Use", "existing", "PAX", "headers", "for", "time"], "add_tokens": "\" \" \" \" name , size , bi2 , err := FileInfoFromHeader ( hdr ) if err != nil { t . Fatal ( err ) } if name != filepath . ToSlash ( f . Name ( ) ) { t . Errorf ( \" \" , name , filepath . ToSlash ( f . Name ( ) ) ) } if size != fi . Size ( ) { t . Errorf ( \" \" , size , fi . Size ( ) ) } if ! reflect . DeepEqual ( * bi , * bi2 ) { t . Errorf ( \" \" , * bi , * bi2 ) } ensurePresent ( t , hdr . Winheaders , \" \" , \" \" )", "del_tokens": "ensurePresent ( t , hdr . Winheaders , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" )", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "multiline", "passwords", "on", "all", "platforms"], "add_tokens": "\" \" // if the added secret has multiple lines, osx will hex encode it trimStr := strings . TrimSpace ( string ( out [ : ] ) ) dec , err := hex . DecodeString ( trimStr ) // if there was an error hex decoding the string, assume it's not encoded if err != nil { return fmt . Sprintf ( \" \" , trimStr ) , nil } return fmt . Sprintf ( \" \" , dec ) , err", "del_tokens": "return strings . TrimSpace ( fmt . Sprintf ( \" \" , out ) ) , nil", "commit_type": "add"}
{"commit_tokens": ["move", "mock", "to", "it", "s", "own", "pkg"], "add_tokens": "package mockclient \" \" mock . On ( \" \" ) . Return ( & dockerclient . Version { Version : \" \" } , nil ) . Once ( ) iface := reflect . TypeOf ( ( * dockerclient . Client ) ( nil ) ) . Elem ( )", "del_tokens": "package dockerclient mock . On ( \" \" ) . Return ( & Version { Version : \" \" } , nil ) . Once ( ) iface := reflect . TypeOf ( ( * Client ) ( nil ) ) . Elem ( )", "commit_type": "move"}
{"commit_tokens": ["Fix", "error", "message", "for", "repeated", "short", "-", "form", "options"], "add_tokens": "// Short-form options are aggregated. TODO: Cleanup // Rewrite current arg as -<name> and append remaining aggregate opts as a new arg after the current one newargs [ optidx ] = \" \" + name", "del_tokens": "// Insert remaining short-form opts as a new arg after the current one", "commit_type": "fix"}
{"commit_tokens": ["Add", "new", "tokens", "to", "support", "insert", "and", "delete", "ops", "on", "the", "grammar", "."], "add_tokens": "OrDeR AsC DeSc NoT AnD Or Id TyPe At DiStInCt InSeRt DeLeTe DaTa InTo `, { Type : ItemInsert , Text : \" \" } , { Type : ItemDelete , Text : \" \" } , { Type : ItemData , Text : \" \" } , { Type : ItemInto , Text : \" \" } ,", "del_tokens": "OrDeR AsC DeSc NoT AnD Or Id TyPe At DiStInCt `,", "commit_type": "add"}
{"commit_tokens": ["adding", "tests", "for", "HasChangeTime", "()", "and", "HasBirthTime", "()"], "add_tokens": "if c . HasChangeTime ( ) { c . ChangeTime ( ) } if b . HasBirthTime ( ) { b . BirthTime ( ) } if ! nc . HasChangeTime ( ) { defer func ( ) { recover ( ) } ( ) } if ! nb . HasBirthTime ( ) { defer func ( ) { recover ( ) } ( ) }", "del_tokens": "c . ChangeTime ( ) b . BirthTime ( ) defer func ( ) { recover ( ) } ( ) defer func ( ) { recover ( ) } ( )", "commit_type": "add"}
{"commit_tokens": ["add", "gunzipping", "of", "CloudWatch", "Log", "payload"], "add_tokens": "\" \" \" \" \" \" // Event represents a Kinesis event with one or more records. Records [ ] * Record `json:\"Records\"` } // Record represents a single Kinesis record. type Record struct { kinesis . Record Logs struct { Owner string `json:\"owner\"` LogGroup string `json:\"logGroup\"` LogStream string `json:\"logStream\"` SubscriptionFilters [ ] string `json:\"subscriptionFilters\"` MessageType string `json:\"messageType\"` LogEvents [ ] * LogEvent `json:\"logEvents\"` } for _ , record := range event . Records { r , err := gzip . NewReader ( bytes . NewReader ( record . Data ( ) ) ) if err != nil { return nil , err } err = json . NewDecoder ( r ) . Decode ( & record . Logs ) if err != nil { return nil , err } r . Close ( ) }", "del_tokens": "// Event represents a Logs event with one or more records. Owner string `json:\"owner\"` LogGroup string `json:\"logGroup\"` LogStream string `json:\"logStream\"` SubscriptionFilters [ ] string `json:\"subscriptionFilters\"` MessageType string `json:\"messageType\"` LogEvents [ ] * LogEvent `json:\"logEvents\"`", "commit_type": "add"}
{"commit_tokens": ["Added", "Chmod", "as", "alias", "for", "os", ".", "Chmod", "on", "non", "-", "Windows"], "add_tokens": "package acl import \" \" // Chmod is os.Chmod. var Chmod = os . Chmod", "del_tokens": "package acl", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "can", "use", "head", "error"], "add_tokens": "reply . Error = errors . New ( string ( head ) )", "del_tokens": "reply . Error = errors . New ( string ( data [ 1 : len ( data ) - 2 ] ) )", "commit_type": "fix"}
{"commit_tokens": ["Removes", "logrus", "dependency", ".", "Resolves", "https", ":", "//", "github", ".", "com", "/", "adlio", "/", "trello", "/", "issues", "/", "1", "."], "add_tokens": "Logger logger type logger interface { Debugf ( string , ... interface { } ) } func NewClient ( key , token string ) * Client { c . log ( \" \" , path , params . Encode ( ) ) c . log ( \" \" , path , params . Encode ( ) ) func ( c * Client ) log ( format string , args ... interface { } ) { if c . Logger != nil { c . Logger . Debugf ( format , args ) } }", "del_tokens": "\" \" Logger * logrus . Logger func NewClient ( key , token string ) * Client { logger := logrus . New ( ) logger . Level = logrus . WarnLevel Logger : logger , c . Logger . Debugf ( \" \" , path , params . Encode ( ) ) c . Logger . Debugf ( \" \" , path , params . Encode ( ) )", "commit_type": "remove"}
{"commit_tokens": ["add", "custom", "matchers", "to", "ensure", "order", "agnosticism"], "add_tokens": ". \" \" Eventually ( registeredRoutes ) . Should ( Receive ( MatchRegistryMessage ( gibson . RegistryMessage { Eventually ( registeredRoutes ) . Should ( Receive ( MatchRegistryMessage ( gibson . RegistryMessage { Ω( m sg2) . S hould( M atchRegistryMessage( m sg1) ) Eventually ( registeredRoutes ) . Should ( Receive ( MatchRegistryMessage ( gibson . RegistryMessage { Eventually ( registeredRoutes ) . Should ( Receive ( MatchRegistryMessage ( gibson . RegistryMessage { Eventually ( unregisteredRoutes ) . Should ( Receive ( MatchRegistryMessage ( gibson . RegistryMessage {", "del_tokens": "Eventually ( registeredRoutes ) . Should ( Receive ( Equal ( gibson . RegistryMessage { Eventually ( registeredRoutes ) . Should ( Receive ( Equal ( gibson . RegistryMessage { Ω( m sg2) . S hould( E qual( m sg1) ) Eventually ( registeredRoutes ) . Should ( Receive ( Equal ( gibson . RegistryMessage { Eventually ( registeredRoutes ) . Should ( Receive ( Equal ( gibson . RegistryMessage { Eventually ( unregisteredRoutes ) . Should ( Receive ( Equal ( gibson . RegistryMessage {", "commit_type": "add"}
{"commit_tokens": ["use", "jsfiddle", "endpoint", "for", "testing", "notification", "replay"], "add_tokens": "res , err := client . ReplayNotification ( notificationAssemblyId , \" \" )", "del_tokens": "res , err := client . ReplayNotification ( notificationAssemblyId , \" \" )", "commit_type": "use"}
{"commit_tokens": ["Fix", "short", "read", "and", "report", "unexpected", "EOFs", "decoding", "peer", "protocol"], "add_tokens": "MaxLength Integer // TODO: Should this include the length header or not? defer func ( ) { written , _ := io . Copy ( ioutil . Discard , r ) if written != 0 && err == nil { err = fmt . Errorf ( \" \" , msg . Type , written ) } else if err == io . EOF { err = io . ErrUnexpectedEOF } } ( )", "del_tokens": "MaxLength Integer defer func ( ) { written , _ := io . Copy ( ioutil . Discard , r ) if written != 0 && err != nil { err = fmt . Errorf ( \" \" , msg . Type , written ) } } ( ) if err != nil { err = fmt . Errorf ( \" \" , msg . Type , err ) }", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "setter", "for", "the", "timeout"], "add_tokens": "timeout : DefaultTimeout , timeout time . Duration // Timeout returns the socket read/write timeout. By default, it's // DefaultTimeout. func ( c * Client ) Timeout ( ) time . Duration { return c . timeout } // SetTimeout specifies the socket read/write timeout. // If zero, DefaultTimeout is used. func ( c * Client ) SetTimeout ( timeout time . Duration ) { if timeout == time . Duration ( 0 ) { timeout = DefaultTimeout } c . timeout = timeout } cn . nc . SetDeadline ( time . Now ( ) . Add ( cn . c . timeout ) ) case <- time . After ( c . timeout ) :", "del_tokens": "// Timeout specifies the socket read/write timeout. // If zero, DefaultTimeout is used. Timeout time . Duration cn . nc . SetDeadline ( time . Now ( ) . Add ( cn . c . netTimeout ( ) ) ) func ( c * Client ) netTimeout ( ) time . Duration { if c . Timeout != 0 { return c . Timeout } return DefaultTimeout } case <- time . After ( c . netTimeout ( ) ) :", "commit_type": "use"}
{"commit_tokens": ["Fix", "cross", "compile", "for", "make", "cross"], "add_tokens": "\" \" type DefaultCommandFactory struct { Root string } // get our binary name from arg0 so we can always reexec ourself command := exec . Command ( os . Args [ 0 ] , append ( [ ] string { \" \" , c . Root , system . SetCloneFlags ( command , uintptr ( GetNamespaceFlags ( container . Namespaces ) ) ) // GetNamespaceFlags parses the container's Namespaces options to set the correct // flags on clone, unshare, and setns func GetNamespaceFlags ( namespaces libcontainer . Namespaces ) ( flag int ) { for _ , ns := range namespaces { flag |= ns . Value } return flag }", "del_tokens": "\" \" type DefaultCommandFactory struct { } // get our binary name so we can always reexec ourself name := os . Args [ 0 ] command := exec . Command ( name , append ( [ ] string { command . SysProcAttr = & syscall . SysProcAttr { Cloneflags : uintptr ( GetNamespaceFlags ( container . Namespaces ) ) , }", "commit_type": "fix"}
{"commit_tokens": ["change", "output", "to", "base64", "json"], "add_tokens": "\" \" \" \" mdnsServer := utility . BroadcastServer ( ) defer mdnsServer . Shutdown ( ) buf . WriteString ( \" \\\" \" ) buf . WriteString ( \" \\\" \" ) encodedImage := base64 . StdEncoding . EncodeToString ( buf . Bytes ( ) ) c . JSON ( 200 , gin . H { \" \" : encodedImage , } ) //c.Data(200, \"image/jpeg\", buf.Bytes())", "del_tokens": "c . Data ( 200 , \" \" , buf . Bytes ( ) )", "commit_type": "change"}
{"commit_tokens": ["fix", "tabs", "in", "templates", ".", "go"], "add_tokens": ". \" \" . \" \" \" \" RegisterFailHandler ( Fail ) RunSpecs ( t , \" \" )", "del_tokens": ". \" \" . \" \" \" \" RegisterFailHandler ( Fail ) RunSpecs ( t , \" \" )", "commit_type": "fix"}
{"commit_tokens": ["fix", "naming", "and", "remove", "print"], "add_tokens": "decodingResultChan , closeChan := client . readJSONStream ( resp . Body , decode ) eventOrErrorChan := make ( chan EventOrError ) for decodingResult := range decodingResultChan { event , _ := decodingResult . result . ( Event ) eventOrErrorChan <- EventOrError { Error : decodingResult . err , close ( eventOrErrorChan ) return eventOrErrorChan , closeChan , nil", "del_tokens": "fmt . Printf ( \" \\n \" , event , err ) resultChan , closeChan := client . readJSONStream ( resp . Body , decode ) eventInfoChan := make ( chan EventOrError ) for res := range resultChan { event , _ := res . result . ( Event ) eventInfoChan <- EventOrError { Error : res . err , close ( eventInfoChan ) return eventInfoChan , closeChan , nil", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "shorthand", "type", "syntax", "detected", "as", "a", "breaking", "change"], "add_tokens": "// Expand multiple names for a type and remove unexported from structs switch t := s . Type . ( type ) { case * ast . StructType : expandFieldList ( t . Fields , true ) case * ast . InterfaceType : for _ , m := range t . Methods . List { expandFieldList ( m . Type . ( * ast . FuncType ) . Params , false ) expandFieldList ( m . Type . ( * ast . FuncType ) . Results , false ) } // Expand the shorthand type notation expandFieldList ( d . Type . Params , false ) expandFieldList ( d . Type . Results , false )", "del_tokens": "// If struct, expand multiple names for a type and remove unexported if stype , ok := s . Type . ( * ast . StructType ) ; ok { expandFieldList ( stype . Fields , true )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "by", "fixing", "import", "paths"], "add_tokens": "httptransport \" \" \" \"", "del_tokens": "//swagclient \"github.com/go-swagger/go-swagger/client\" httptransport \" \" \" \"", "commit_type": "fix"}
{"commit_tokens": ["Use", "interface", "to", "create", "logger"], "add_tokens": "func Logger ( logger logrus . FieldLogger ) gin . HandlerFunc { entry := logger . WithFields ( logrus . Fields {", "del_tokens": "func Logger ( log * logrus . Logger ) gin . HandlerFunc { entry := logrus . NewEntry ( log ) . WithFields ( logrus . Fields {", "commit_type": "use"}
{"commit_tokens": ["add", "color", ".", "FromXxx", "functions"], "add_tokens": "func hslToRgb ( h , s , l float64 ) ( r , g , b float64 ) { func rgbToHsl ( r , g , b float64 ) ( h , s , l float64 ) {", "del_tokens": "func HslToRgb ( h , s , l float64 ) ( r , g , b float64 ) { func RgbToHsl ( r , g , b float64 ) ( h , s , l float64 ) {", "commit_type": "add"}
{"commit_tokens": ["Updating", "functions", "to", "make", "more", "sense"], "add_tokens": "// Given a filepath, get it's permission bits func Stat ( filepath string ) ( PermissionBits , error ) { fi , err := os . Stat ( filepath ) if err != nil { return 0 , err } return FileMode ( fi . Mode ( ) ) , nil } // Given a FileMode from the os package, get it's permission bits func FileMode ( fm os . FileMode ) PermissionBits { perm := PermissionBits ( fm . Perm ( ) ) func UpdateFileMode ( fm * os . FileMode , b PermissionBits ) {", "del_tokens": "// Given a FileInfo from the os package, get it's permission bits func FilePerms ( fi os . FileInfo ) PermissionBits { perm := PermissionBits ( fi . Mode ( ) . Perm ( ) ) fm := fi . Mode ( ) // Given a filepath, get it's permission bits func StatPerms ( filepath string ) ( PermissionBits , error ) { fi , err := os . Stat ( filepath ) if err != nil { return 0 , err } return FilePerms ( fi ) , nil } func ( b PermissionBits ) UpdateFileModePermissions ( fm * os . FileMode ) { func ( b PermissionBits ) Chmod ( file * os . File ) error { var fm os . FileMode b . UpdateFileModePermissions ( & fm ) return file . Chmod ( fm ) }", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "to", "GetOrInsert", "()", "for", "[]", "byte", "keys"], "add_tokens": "if element . keyHash == h { switch key . ( type ) { case [ ] byte : if bytes . Compare ( element . key . ( [ ] byte ) , key . ( [ ] byte ) ) == 0 { return element . Value ( ) , true } default : if element . key == key { actual = element . Value ( ) return actual , true } }", "del_tokens": "if element . keyHash == h && element . key == key { actual = element . Value ( ) return actual , true", "commit_type": "add"}
{"commit_tokens": ["Moved", "primary", "key", "to", "constraints", "and", "added", "a", "Unique", "constraint"], "add_tokens": "// Primary Key // ----------- // Implements the `TableModifier` interface. // Unique // ----------- // A UNIQUE constraint that implements the `TableModifier` interface. type UniqueConstraint [ ] string func ( uc UniqueConstraint ) Create ( d Dialect ) ( string , error ) { cs := make ( [ ] string , len ( uc ) ) for i , c := range uc { cs [ i ] = fmt . Sprintf ( `\"%s\"` , c ) } return fmt . Sprintf ( \" \" , strings . Join ( cs , \" \" ) ) , nil } // To implement the `TableModifier` interface, the struct must // have method Modify(). It does not need to modify its parent table. func ( uc UniqueConstraint ) Modify ( table * TableElem ) error { // Confirm that all columns in the primary key exists for _ , name := range uc { // TODO Aggregate errors _ , exists := table . C [ name ] if ! exists { return fmt . Errorf ( \" \" , name , table . Name ) } // TODO Set the attributes of the column type? } // TODO Add the unique clause to the table return nil } // Constructor function for UniqueConstraint func Unique ( names ... string ) UniqueConstraint { return UniqueConstraint ( names ) }", "del_tokens": "/ * Primary Key - - - - - - - - - - - Implements the `TableModifier` interface . * /", "commit_type": "move"}
{"commit_tokens": ["add", "metabase", ".", "NewClientPasswordWithSessionId", "()"], "add_tokens": "\" \" RelPathApiDatabase = \" \" EnvBaseURL = \" \" EnvSessionId = \" \" EnvUsername = \" \" EnvPassword = \" \" return NewClientSessionId ( res . Id , tlsSkipVerify ) , res , nil } // NewClientPasswordWithSessionId returns a *http.Client first attempting to use // the supplied `sessionId` with a fallback to `username` and `password`. func NewClientPasswordWithSessionId ( baseUrl , username , password , sessionId string , tlsSkipVerify bool ) ( * http . Client , * AuthResponse , error ) { sessionId = strings . TrimSpace ( sessionId ) if len ( sessionId ) > 0 { httpClient := NewClientSessionId ( sessionId , tlsSkipVerify ) userUrl := urlutil . JoinAbsolute ( baseUrl , RelPathApiUserCurrent ) resp , err := httpClient . Get ( userUrl ) if err == nil && resp . StatusCode == 200 { return httpClient , nil , nil } } return NewClientPassword ( baseUrl , username , password , tlsSkipVerify ) func NewClientSessionId ( sessionId string , tlsSkipVerify bool ) * http . Client { header . Add ( MetabaseSessionHeader , sessionId ) httpClient = NewClientSessionId ( os . Getenv ( cfg . EnvMetabaseSessionId ) , true )", "del_tokens": "return NewClientId ( res . Id , tlsSkipVerify ) , res , nil func NewClientId ( id string , tlsSkipVerify bool ) * http . Client { header . Add ( MetabaseSessionHeader , id ) httpClient = NewClientId ( os . Getenv ( cfg . EnvMetabaseSessionId ) , true )", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "rest", "of", "the", "report", "tests"], "add_tokens": "if len ( data ) < 2 { return nil , fmt . Errorf ( \" \" , len ( data ) ) } sml . Size = ( data [ 1 ] & 0x07 ) // Size (3 bits) sml . Scale = ( data [ 1 ] & 0x18 ) >> 0x03 // Scale (2 bits) sml . Precision = ( data [ 1 ] & 0xE0 ) >> 0x05 // Precision (3 bits) if len ( data ) < 2 + int ( sml . Size ) { return nil , fmt . Errorf ( \" \" , ( 2 + sml . Size ) , len ( data ) ) } return fmt . Sprintf ( \" \" , sml . Value , sml . TypeString , sml . Unit )", "del_tokens": "sml . Size = ( data [ 1 ] & 0x07 ) // Size sml . Scale = ( data [ 1 ] & 0x18 ) >> 0x03 // Scale sml . Precision = ( data [ 1 ] & 0xE0 ) >> 0x05 // Precision case 8 : val := int64 ( 0 ) err = binary . Read ( buf , binary . BigEndian , & val ) sml . Value = float64 ( val ) return fmt . Sprintf ( \" \" , sml . Value , sml . TypeString )", "commit_type": "add"}
{"commit_tokens": ["added", "full", "check", "support", "for", "consul", "including", "check", "-", "http", "and", "check", "-", "cmd", "support", "when", "using", "progrium", "/", "consul"], "add_tokens": "Container * dockerapi . Container pp PublishedPort func NewService ( port PublishedPort , isgroup bool ) * Service { container := port . Container service . pp = port log . Println ( \" \" , containerId [ : 12 ] , err ) Container : container , log . Println ( \" \" , container . ID [ : 12 ] , \" \" ) service := NewService ( port , len ( ports ) > 1 ) log . Println ( \" \" , container . ID [ : 12 ] , \" \" , port . ExposedPort )", "del_tokens": "func NewService ( container * dockerapi . Container , port PublishedPort , isgroup bool ) * Service { log . Println ( \" \" , containerId , err ) log . Println ( \" \" , containerId , \" \" ) service := NewService ( container , port , len ( ports ) > 1 ) log . Println ( \" \" , containerId , \" \" , port . ExposedPort )", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "etcdtest", "package", "and", "tests", "for", "etcd_client", ".", "go"], "add_tokens": "type EtcdClient interface { Get ( key string ) ( [ ] * etcd . Response , error ) } func getValues ( c EtcdClient , prefix string , keys [ ] string ) ( map [ string ] interface { } , error ) { func etcdWalk ( c EtcdClient , key string , prefix string , vars map [ string ] interface { } ) error {", "del_tokens": "func getValues ( c * etcd . Client , prefix string , keys [ ] string ) ( map [ string ] interface { } , error ) { func etcdWalk ( c * etcd . Client , key string , prefix string , vars map [ string ] interface { } ) error {", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "coveralls", "endpoint", "to", ".", "circle", ".", "yml"], "add_tokens": "Body : `{ \" \" : \" \" , \" \" : \" \" } `, Body : `{ \" \" : \" \" , \" \" : \" \" } `, Body : `{ \" \" : \" \" , \" \" : \" \" } `, Body : `{ \" \" : \" \" , \" \" : \" \" } `, Body : `{ \" \" : \" \" , \" \" : \" \" } `,", "del_tokens": "Body : routes . AccountsCreateRequest { Username : username , AltEmail : email , } , Body : routes . AccountsCreateRequest { Username : username , AltEmail : email , } , Body : routes . AccountsCreateRequest { Username : uniuri . New ( ) , AltEmail : email , } , Body : routes . AccountsCreateRequest { Username : uniuri . New ( ) , InviteCode : uniuri . New ( ) , } , Body : routes . AccountsCreateRequest { Username : account . Name , InviteCode : uniuri . New ( ) , } ,", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "Delete", "()"], "add_tokens": "p := NewPerson ( \" \" , 25 ) c . Assert ( p . Name , Equals , \" \" ) p1 := NewPerson ( \" \" , 25 ) func ( s * MainSuite ) TestDelete ( c * C ) { // Create and save a new model p1 := NewPerson ( \" \" , 25 ) zoom . Save ( p1 ) // Make sure it was saved key := \" \" + p1 . Id exists , err := zoom . KeyExists ( key ) if err != nil { c . Error ( err ) } c . Assert ( exists , Equals , true ) // delete it zoom . Delete ( p1 ) // Make sure it's gone exists , err = zoom . KeyExists ( key ) if err != nil { c . Error ( err ) } c . Assert ( exists , Equals , false ) } p1 := NewPerson ( \" \" , 25 )", "del_tokens": "p := NewPerson ( \" \" , 25 ) c . Assert ( p . Name , Equals , \" \" ) p1 := NewPerson ( \" \" , 26 ) p1 := NewPerson ( \" \" , 26 )", "commit_type": "add"}
{"commit_tokens": ["Add", "generic", "command", "to", "ignore", "commands", "arguments"], "add_tokens": "commands = map [ string ] * Cmd { } Command ( \" \" , \" \" , \" \" , \" \" ) if len ( commands ) != 1 { t . Fatalf ( \" \" , len ( commands ) ) } cmd , exists := commands [ \" \" ] if ! exists { t . Fatal ( \" \" ) } if cmd . Response != nil { t . Error ( \" \" ) } if cmd . Error != nil { t . Error ( \" \" ) } } func TestGenericCommand ( t * testing . T ) { commands = map [ string ] * Cmd { } GenericCommand ( \" \" ) t . Fatalf ( \" \" , len ( commands ) ) commands = map [ string ] * Cmd { } commands = map [ string ] * Cmd { } commands = map [ string ] * Cmd { } commands = map [ string ] * Cmd { }", "del_tokens": "Command ( \" \" ) t . Fatal ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Fix", "double", "-", "free", "and", "pointer", "ownership", "issues"], "add_tokens": "func coordSeqFromPtr ( ptr * C . GEOSCoordSequence ) * coordSeq { cs := & coordSeq { c : ptr } runtime . SetFinalizer ( cs , func ( * coordSeq ) { cGEOSCoordSeq_destroy ( ptr ) } ) ptr := cGEOSCoordSeq_create ( C . uint ( len ( coords ) ) , C . uint ( 2 ) ) if ptr == nil { return nil , Error ( ) } cs := & coordSeq { c : ptr }", "del_tokens": "func coordSeqFromPtr ( c * C . GEOSCoordSequence ) * coordSeq { cs := & coordSeq { c } runtime . SetFinalizer ( cs , ( * coordSeq ) . destroy ) cs := newCoordSeq ( len ( coords ) , 2 ) func ( c * coordSeq ) destroy ( ) { // XXX: mutex cGEOSCoordSeq_destroy ( c . c ) c . c = nil }", "commit_type": "fix"}
{"commit_tokens": ["Improve", "naming", "of", "log", "sanitizer", "method"], "add_tokens": "SanitizeLogMessage ( raw string ) string", "del_tokens": "SanitizeLogLine ( raw string ) string", "commit_type": "improve"}
{"commit_tokens": ["Remove", "unneeded", "global", "color", "variables", "that", "were", "only", "used", "in", "one", "spot", "each"], "add_tokens": "return color . GreenString ( format , args ... ) return color . RedString ( format , args ... )", "del_tokens": "var ( _okColor = color . GreenString _failColor = color . RedString ) return _okColor ( format , args ... ) return _failColor ( format , args ... )", "commit_type": "remove"}
{"commit_tokens": ["Change", "default", "port", "for", "etc2", "backend", "to", "default", "2379"], "add_tokens": "urls = append ( urls , \" \" )", "del_tokens": "urls = append ( urls , \" \" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "stellar", "-", "sign", "for", "new", "GetPasswdMasked", "iface"], "add_tokens": "str , err := gopass . GetPasswdMasked ( ) if err != nil { return \" \" , err } line = string ( str )", "del_tokens": "line = string ( gopass . GetPasswdMasked ( ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "ability", "to", "pipe", "outout", "to", "a", "logging", "function"], "add_tokens": "// message, log everything written to stdout to this application's log, and // timeout after 30 seconds. Errors : deputy . FromStderr , StdoutLog : log . Printf , Timeout : time . Second * 30 , log . Log ( err )", "del_tokens": "// and timeout after 30 seconds. Errors : deputy . FromStderr , Timeout : time . Second * 30 , log . Println ( err )", "commit_type": "add"}
{"commit_tokens": ["added", "set", "test", "for", "deep", "maps"], "add_tokens": "func TestSetInDeepMap ( t * testing . T ) { m := map [ string ] interface { } { \" \" : map [ string ] interface { } { \" \" : map [ string ] interface { } { \" \" : 3 } } } o := New ( m ) assert . Equal ( t , o , o . Set ( \" \" , \" \" ) , \" \" ) assert . Equal ( t , \" \" , m [ \" \" ] . ( map [ string ] interface { } ) [ \" \" ] . ( map [ string ] interface { } ) [ \" \" ] ) }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["removed", "fmt", ".", "Println", "statements", "exponential", "back", "off", "while", "retrying", "to", "connect"], "add_tokens": "var ( err error waitPeriod = time . Millisecond ) if connectionErr := logger . openConnection ( ) ; connectionErr != nil { return connectionErr waitPeriod *= 2 time . Sleep ( waitPeriod ) continue logger . mu . Lock ( )", "del_tokens": "var err error fmt . Printf ( \" \\n \\t \" , err ) if err := logger . openConnection ( ) ; err != nil { fmt . Printf ( \" \\n \" , err ) return err } else { fmt . Printf ( \" \\n \" ) continue logger . mu . Lock ( )", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "parsing", ".", "SRCINFO", "files", "directly"], "add_tokens": "var r rune switch r = l . next ( ) ; { case r == '#' : return lexComment l . errorf ( \" \" , r ) } } } func lexComment ( l * lexer ) stateFn { for { switch l . next ( ) { case '\\n' : l . ignore ( ) return lexEnv case eof : l . emit ( itemEOF ) return nil", "del_tokens": "switch r := l . next ( ) ; { // TODO error if we hit this // maybe use it to handle comments in .SRCINFO return l . errorf ( \" \" )", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "missing", "tc", "act", "flags", "and", "structs"], "add_tokens": "const ( TCA_ACT_UNSPEC = iota TCA_ACT_KIND TCA_ACT_OPTIONS TCA_ACT_INDEX TCA_ACT_STATS TCA_ACT_MAX ) SizeofTcActBpf = 0x14 TC_ACT_REDIRECT = 7 type TcGen struct { Index uint32 Capab uint32 Action int32 Refcnt int32 Bindcnt int32 } type TcActBpf struct { TcGen } func ( msg * TcActBpf ) Len ( ) int { return SizeofTcActBpf } func DeserializeTcActBpf ( b [ ] byte ) * TcActBpf { return ( * TcActBpf ) ( unsafe . Pointer ( & b [ 0 : SizeofTcActBpf ] [ 0 ] ) ) } func ( x * TcActBpf ) Serialize ( ) [ ] byte { return ( * ( * [ SizeofTcActBpf ] byte ) ( unsafe . Pointer ( x ) ) ) [ : ] } TcGen const ( TCA_BPF_FLAG_ACT_DIRECT uint32 = 1 << iota ) const ( TCA_BPF_UNSPEC = iota TCA_BPF_ACT TCA_BPF_POLICE TCA_BPF_CLASSID TCA_BPF_OPS_LEN TCA_BPF_OPS TCA_BPF_FD TCA_BPF_NAME TCA_BPF_FLAGS TCA_BPF_MAX = TCA_BPF_FLAGS ) const ( TCA_ACT_BPF_UNSPEC = iota TCA_ACT_BPF_TM TCA_ACT_BPF_PARMS TCA_ACT_BPF_OPS_LEN TCA_ACT_BPF_OPS TCA_ACT_BPF_FD TCA_ACT_BPF_NAME TCA_ACT_BPF_MAX = TCA_ACT_BPF_NAME )", "del_tokens": "Index uint32 Capab uint32 Action int32 Refcnt int32 Bindcnt int32", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "requirements", "for", "Join", "."], "add_tokens": "// Block until a mounted file system has been unmounted. The return value will // be non-nil if anything unexpected happened while serving. May be called // multiple times. Must not be called unless WaitForReady has returned nil.", "del_tokens": "// Block until the file system has been unmounted. The return value will be // non-nil if anything unexpected happened while mounting or serving. May be // called multiple times.", "commit_type": "change"}
{"commit_tokens": ["changing", "imports", "to", "gopkg", ".", "in"], "add_tokens": "\" \" \" \"", "del_tokens": "\" \" \" \"", "commit_type": "change"}
{"commit_tokens": ["Fix", "off", "by", "one", "error", "when", "marking", "offset"], "add_tokens": "if info := s . offsets [ key ] ; offset >= info . Offset {", "del_tokens": "if info := s . offsets [ key ] ; offset > info . Offset {", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "api", "in", "store", "package", "github", ".", "com", "/", "armon", "/", "consul", "-", "api", "is", "deprecated"], "add_tokens": "consul \" \" client , _ := consul . NewClient ( consul . DefaultConfig ( ) )", "del_tokens": "consul \" \" client , _ := consul . NewClient ( & consul . Config { } )", "commit_type": "update"}
{"commit_tokens": ["Add", "json", "keys", "for", "persistent", "disks"], "add_tokens": "ID string `json:\"id\"` VolumeID string `json:\"volume_id\"` Path string `json:\"path\"`", "del_tokens": "ID string VolumeID string Path string", "commit_type": "add"}
{"commit_tokens": ["updated", "assets", ":", "switched", "to", "touch"], "add_tokens": "// if runtime.GOOS == \"windows\" { // command = append(command, fmt.Sprintf(\"copy /b %s +,,\", absFile)) // command = append(command, fmt.Sprintf(\"powershell (ls %s).LastWriteTime = Get-Date\", absFile)) // } else { command = append ( command , fmt . Sprintf ( \" \" , absFile ) ) // }", "del_tokens": "\" \" if runtime . GOOS == \" \" { // command = append(command, fmt.Sprintf(\"copy /b %s +,,\", absFile)) command = append ( command , fmt . Sprintf ( \" \" , absFile ) ) } else { command = append ( command , fmt . Sprintf ( \" \" , absFile ) ) }", "commit_type": "update"}
{"commit_tokens": ["fix", "race", "conditions", "in", "tests"], "add_tokens": ". \" \" Ω( \" a ) . S hould( E xit( ) )", "del_tokens": ". \" \" Ω( c ommand) . S hould( E xit( ) )", "commit_type": "fix"}
{"commit_tokens": ["add", "--", "wait", "to", "IPTables", ".", "List"], "add_tokens": "Args : [ ] string { ipt . path , \" \" , \" \" , table , \" \" , chain } ,", "del_tokens": "Args : [ ] string { ipt . path , \" \" , table , \" \" , chain } ,", "commit_type": "add"}
{"commit_tokens": ["Moving", "XMLNS", "to", "a", "solid", "type", "since", "it", "s", "limited", "in", "functionality", "."], "add_tokens": "GetNS ( ) map [ xml . Name ] NS } //NSStruct is a helper implementation of NSElem. type NSStruct struct { NS map [ xml . Name ] NS } //GetNS returns all namespaces of the element func ( x NSStruct ) GetNS ( ) map [ xml . Name ] NS { ret := make ( map [ xml . Name ] NS ) for k , v := range x . NS { ret [ k ] = v } return ret } //NS is a namespace node. type NS struct { xml . Attr Parent Elem NodePos } //GetToken returns the xml.Token representation of the namespace. func ( ns NS ) GetToken ( ) xml . Token { return ns . Attr } //GetParent returns the parent node of the namespace. func ( ns NS ) GetParent ( ) Elem { return ns . Parent } //String returns the string value of the namespace func ( ns NS ) String ( ) string { return ns . Attr . Value", "del_tokens": "GetNS ( ) map [ xml . Name ] Node", "commit_type": "move"}
{"commit_tokens": ["Added", "username", "site", "and", "password", "for", "influxdb", "datasources"], "add_tokens": "sess := x . Limit ( 100 , 0 ) . Where ( \" \" , query . AccountId ) . Asc ( \" \" ) User : cmd . User , Password : cmd . Password , Database : cmd . Database , User : cmd . User , Password : cmd . Password , Database : cmd . Database ,", "del_tokens": "sess := x . Limit ( 100 , 0 ) . Where ( \" \" , query . AccountId )", "commit_type": "add"}
{"commit_tokens": ["Add", "space", "id", "and", "space", "name"], "add_tokens": "`VCAP_APPLICATION={\"instance_id\":\"451f045fd16427bb99c895a2649b7b2a\",\"instance_index\":0,\"host\":\"0.0.0.0\",\"port\":61857,\"started_at\":\"2013-08-12 00:05:29 +0000\",\"started_at_timestamp\":1376265929,\"start\":\"2013-08-12 00:05:29 +0000\",\"state_timestamp\":1376265929,\"limits\":{\"mem\":512,\"disk\":1024,\"fds\":16384},\"application_version\":\"c1063c1c-40b9-434e-a797-db240b587d32\",\"application_name\":\"styx-james\",\"application_uris\":[\"styx-james.a1-app.cf-app.com\"],\"version\":\"c1063c1c-40b9-434e-a797-db240b587d32\",\"name\":\"styx-james\",\"space_id\":\"3e0c28c5-6d9c-436b-b9ee-1f4326e54d05\",\"space_name\":\"jdk\",\"uris\":[\"styx-james.a1-app.cf-app.com\"],\"users\":null}` , Ω( c fenv. S paceName) . S hould( B eEquivalentTo( \" j ) ) Ω( c fenv. S paceID) . S hould( B eEquivalentTo( \" 3 ) )", "del_tokens": "`VCAP_APPLICATION={\"instance_id\":\"451f045fd16427bb99c895a2649b7b2a\",\"instance_index\":0,\"host\":\"0.0.0.0\",\"port\":61857,\"started_at\":\"2013-08-12 00:05:29 +0000\",\"started_at_timestamp\":1376265929,\"start\":\"2013-08-12 00:05:29 +0000\",\"state_timestamp\":1376265929,\"limits\":{\"mem\":512,\"disk\":1024,\"fds\":16384},\"application_version\":\"c1063c1c-40b9-434e-a797-db240b587d32\",\"application_name\":\"styx-james\",\"application_uris\":[\"styx-james.a1-app.cf-app.com\"],\"version\":\"c1063c1c-40b9-434e-a797-db240b587d32\",\"name\":\"styx-james\",\"uris\":[\"styx-james.a1-app.cf-app.com\"],\"users\":null}` ,", "commit_type": "add"}
{"commit_tokens": ["add", "privacy", "add", "private", "homepage", "and", "default_branch", "attrs", "to", "repository"], "add_tokens": "ID * int `json:\"id,omitempty\"` Owner * User `json:\"owner,omitempty\"` Name * string `json:\"name,omitempty\"` Description * string `json:\"description,omitempty\"` Homepage * string `json:\"homepage,omitempty\"` DefaultBranch * string `json:\"default_branch,omitempty\"` CreatedAt * Timestamp `json:\"created_at,omitempty\"` PushedAt * Timestamp `json:\"pushed_at,omitempty\"` UpdatedAt * Timestamp `json:\"updated_at,omitempty\"` Private * bool `json:\"private\"`", "del_tokens": "ID * int `json:\"id,omitempty\"` Owner * User `json:\"owner,omitempty\"` Name * string `json:\"name,omitempty\"` Description * string `json:\"description,omitempty\"` CreatedAt * Timestamp `json:\"created_at,omitempty\"` PushedAt * Timestamp `json:\"pushed_at,omitempty\"` UpdatedAt * Timestamp `json:\"updated_at,omitempty\"`", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "and", "fix", "lint", "error"], "add_tokens": "// MkdirNone is used to create no intermediate directories.", "del_tokens": "// MkdirAll is used to create no intermediate directories.", "commit_type": "add"}
{"commit_tokens": ["Allow", "setting", "envs", "for", "a", "command"], "add_tokens": "cmd . AddEnvs ( \" \" + opts . Committer . Name , \" \" + opts . Committer . Email )", "del_tokens": "cmd . AddArguments ( \" \" , \" \" + opts . Committer . Name , \" \" , \" \" + opts . Committer . Email )", "commit_type": "allow"}
{"commit_tokens": ["Add", "comment", "about", "FOpts", "."], "add_tokens": "FOpts : [ ] MACCommand { } , // you can leave this out when there is no MAC command to send", "del_tokens": "FOpts : [ ] MACCommand { } ,", "commit_type": "add"}
{"commit_tokens": ["Add", "unit", "test", "for", "enhanced", "error", "reporting"], "add_tokens": "func TestCorruptDbErrors ( t * testing . T ) { func TestSqlLogicErrors ( t * testing . T ) { dirName , err := ioutil . TempDir ( \" \" , \" \" ) if err != nil { t . Fatal ( err ) } defer os . RemoveAll ( dirName ) dbFileName := path . Join ( dirName , \" \" ) db , err := sql . Open ( \" \" , dbFileName ) if err != nil { t . Error ( err ) } _ , err = db . Exec ( \" \" ) if err != nil { t . Error ( err ) } const expectedErr = \" \" _ , err = db . Exec ( \" \" ) if err . Error ( ) != expectedErr { t . Errorf ( \" \" , err . Error ( ) , expectedErr ) } }", "del_tokens": "func TestFailures ( t * testing . T ) {", "commit_type": "add"}
{"commit_tokens": ["change", "BinaryMessages", "to", "ByteSliceMessages", "to", "address", "the", "data", "type", "for", "sending", "and", "recieving"], "add_tokens": "// Message Connection connects a websocket message connection to a []byte type ByteSliceConnection struct { // Sender is the []byte channel used for sending out bytes data to the client. // Receiver is the []byte channel used for receiving bytes data from the client. // ByteSliceMessages returns a websocket handling middleware. It can only be used // - A receiving []byte channel (<-chan []byte) on which you will // receive all incoming bytes data from the client // - A sending []byte channel (chan<- []byte) on which you will be // able to send bytes data to the client. func ByteSliceMessages ( options ... * Options ) martini . Handler { // Close the ByteSlice connection. Closes the send goroutine and all channels used func ( c * ByteSliceConnection ) Close ( closeCode int ) error { // Write the bytes to the websocket, also keeping the connection alive func ( c * ByteSliceConnection ) write ( mt int , payload [ ] byte ) error { // Send handler for the ByteSlice connection. Starts a goroutine func ( c * ByteSliceConnection ) send ( ) { func ( c * ByteSliceConnection ) recv ( ) { func ( c * ByteSliceConnection ) mapChannels ( context martini . Context ) { return & ByteSliceConnection {", "del_tokens": "// Binary Connection connects a websocket message connection to a []byte type BinaryConnection struct { // Sender is the []byte channel used for sending out binary data to the client. // Receiver is the []byte channel used for receiving binary data from the client. // Messages returns a websocket handling middleware. It can only be used // - A receiving string channel (<-chan string) on which you will // receive all incoming strings from the client // - A sending string channel (chan<- string) on which you will be // able to send strings to the client. func BinaryMessages ( options ... * Options ) martini . Handler { // Close the binary connection. Closes the send goroutine and all channels used func ( c * BinaryConnection ) Close ( closeCode int ) error { // Write the binary to the websocket, also keeping the connection alive func ( c * BinaryConnection ) write ( mt int , payload [ ] byte ) error { // Send handler for the binary connection. Starts a goroutine func ( c * BinaryConnection ) send ( ) { func ( c * BinaryConnection ) recv ( ) { func ( c * BinaryConnection ) mapChannels ( context martini . Context ) { //fmt.Sprintln(typ.Kind().String()) return & BinaryConnection {", "commit_type": "change"}
{"commit_tokens": ["use", "channel", "and", "capture", "handlers", "in", "top", "-", "level", "package", "tests"], "add_tokens": "\" \" handler := channel . NewHandler ( ) handler := channel . NewHandler ( ) handler := channel . NewHandler ( ) handler := channel . NewHandler ( ) // send a second event, just so we have one that's not sitting on the channel.Handler channel handler1 := channel . NewHandler ( ) handler2 := channel . NewHandler ( ) channelHandler := channel . NewHandler ( ) handler := channel . NewHandler ( ) handler := channel . NewHandler ( ) handler := channel . NewHandler ( ) // goroutine is because the channel.Handler is unbuffered, meaning the handler := channel . NewHandler ( ) handler := channel . NewHandler ( )", "del_tokens": "handler := NewChannelHandler ( ) handler := NewChannelHandler ( ) handler := NewChannelHandler ( ) handler := NewChannelHandler ( ) // send a second event, just so we have one that's not sitting on the channelHandler channel handler1 := NewChannelHandler ( ) handler2 := NewChannelHandler ( ) channelHandler := NewChannelHandler ( ) handler := NewChannelHandler ( ) handler := NewChannelHandler ( ) handler := NewChannelHandler ( ) // goroutine is because the channelHandler is unbuffered, meaning the handler := NewChannelHandler ( ) handler := NewChannelHandler ( )", "commit_type": "use"}
{"commit_tokens": ["Updated", "test", "name", "since", "we", "test", "both"], "add_tokens": "func RemoveIpvXDomain ( t * testing . T ) {", "del_tokens": "func RemoveIpv4Domain ( t * testing . T ) {", "commit_type": "update"}
{"commit_tokens": ["Changed", "path", "to", "Mesosphere", "GH"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "change"}
{"commit_tokens": ["Use", "BuildWithCtx", "so", "that", "JSON", "references", "work"], "add_tokens": "\" \" buf := bytes . Buffer { } io . Copy ( & buf , r . Body ) sc , err := schema . Read ( bytes . NewReader ( buf . Bytes ( ) ) ) var m map [ string ] interface { } if err := json . NewDecoder ( bytes . NewReader ( buf . Bytes ( ) ) ) . Decode ( & m ) ; err != nil { resp [ \" \" ] = false resp [ \" \" ] = err . Error ( ) json . NewEncoder ( w ) . Encode ( resp ) return } v , err := b . BuildWithCtx ( sc , m ) buf . Reset ( )", "del_tokens": "sc , err := schema . Read ( r . Body ) v , err := b . Build ( sc ) buf := bytes . Buffer { }", "commit_type": "use"}
{"commit_tokens": ["remove", "NAME", "constant", "since", "will", "clash", "with", "others"], "add_tokens": "return \" \"", "del_tokens": "const NAME = \" \" return NAME", "commit_type": "remove"}
{"commit_tokens": ["Make", "constant", "tuning", "more", "stable", "by", "putting", "I", "into", "the", "intergral", "sum"], "add_tokens": "// SetPID changes the P, I, and D constants func ( c * PIDController ) SetPID ( p , i , d float64 ) { c . p = p c . i = i c . d = d } // SetPID returns the P, I, and D constants func ( c * PIDController ) GetPID ( ) ( p , i , d float64 ) { return c . p , c . i , c . d } c . integral += err * dt * c . i return ( c . p * err ) + c . integral + ( c . d * d )", "del_tokens": "c . integral += err * dt return ( c . p * err ) + ( c . i * c . integral ) + ( c . d * d )", "commit_type": "make"}
{"commit_tokens": ["Add", "relaxed", "init", "settings", "."], "add_tokens": "// Whether an active connection is required on initialization. Defaults to true. // If false, the Init function will return a nil error on connection failure, but // retry to connect in the background. RequireConnectionOnInit bool RequireConnectionOnInit : true , // Healthy will return true if the logger is connected to the remote host func ( l * JSONLogger ) Healthy ( ) bool { return l . isConnected } if err := l . connect ( ) ; err != nil { if l . config . RequireConnectionOnInit { return err } // Reconnect in background l . performReconnect ( )", "del_tokens": "err = l . connect ( ) if err != nil { return err", "commit_type": "add"}
{"commit_tokens": ["Implement", "API", "Title", "Expansion", "(", "3", ")"], "add_tokens": "// ListOptions specifies the optional parameters to various List methods that // ExpandOptions specifies which Hipchat collections to automatically expand. // This functionality is primarily used to reduce the total time to receive the data. // It also reduces the sheer number of API calls from 1+N, to 1. // // cf: https://developer.atlassian.com/hipchat/guide/hipchat-rest-api/api-title-expansion type ExpandOptions struct { Expand string `url:\"expand,omitempty\"` }", "del_tokens": "// ListOptions specifies the optional parameters to various List methods that", "commit_type": "implement"}
{"commit_tokens": ["Adds", "usage", "info", "for", "env", "var", "flags"], "add_tokens": "var longShortEnv string longShortEnv += fmt . Sprintf ( \" \" , long ) if longShortEnv != \" \" { longShortEnv += \" \" longShortEnv += fmt . Sprintf ( \" \" , short ) env , ok := field . Tag . Lookup ( \" \" ) if ok { if longShortEnv != \" \" { longShortEnv += \" \" } longShortEnv += fmt . Sprintf ( \" \" , env ) } if len ( longShortEnv ) > length { length = len ( longShortEnv ) usage = append ( usage , longShortEnv )", "del_tokens": "var longShort string longShort += fmt . Sprintf ( \" \" , long ) if longShort != \" \" { longShort += \" \" longShort += fmt . Sprintf ( \" \" , short ) if len ( longShort ) > length { length = len ( longShort ) usage = append ( usage , longShort )", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "function", "signature", "for", "cached", "downloader"], "add_tokens": "\" \" downloader : cacheddownloader . NewDownloader ( DOWNLOAD_TIMEOUT , 1 , skipSSLVerification , systemcerts . SystemRootsPool ( ) ) ,", "del_tokens": "downloader : cacheddownloader . NewDownloader ( DOWNLOAD_TIMEOUT , 1 , skipSSLVerification ) ,", "commit_type": "use"}
{"commit_tokens": ["Implement", "improved", "support", "for", "animated", "gifs", "via", "google"], "add_tokens": "\" \" Route { \" \" , \" \" , \" \" , handlers . HandleGoogleImage , } ,", "del_tokens": "\" \"", "commit_type": "implement"}
{"commit_tokens": ["Add", "constructor", "with", "custom", "fetcher", "and", "document", "the", "whole", "thing"], "add_tokens": "// Cepko implements easy-to-use communication with CloudSigma's VMs through a // virtual serial port without bothering with formatting the messages properly // nor parsing the output with the specific and sometimes confusing shell tools // for that purpose. // // Having the server definition accessible by the VM can ve useful in various // ways. For example it is possible to easily determine from within the VM, // which network interfaces are connected to public and which to private // network. Another use is to pass some data to initial VM setup scripts, like // setting the hostname to the VM name or passing ssh public keys through // server meta. // // Example usage: // // package main // // import ( // \"fmt\" // // \"github.com/cloudsigma/cepgo\" // ) // // func main() { // c := cepgo.NewCepgo() // result, err := c.Meta() // if err != nil { // panic(err) // } // fmt.Printf(\"%#v\", result) // } // // Output: // // map[string]interface {}{ // \"optimize_for\":\"custom\", // \"ssh_public_key\":\"ssh-rsa AAA...\", // \"description\":\"[...]\", // } // // For more information take a look at the Server Context section API Docs: // http://cloudsigma-docs.readthedocs.org/en/latest/server_context.html // /dev/ttyS1. // returns it. // Queries to the serial port can be executed only from instance of this type. // The result from each of them can be either a map[string]interface or a // single in case of single value is returned. // Creates a Cepgo instance with the default serial port fetcher // Creates a Cepgo instance with custom fetcher fetcher func NewCepgoFetcher ( fetcher func ( string ) ( interface { } , error ) ) * Cepgo { cepgo := new ( Cepgo ) cepgo . fetcher = fetcher return cepgo } // Fetches a single key // Fetches all the server context. Equivalent of c.Key(\"\") // Fetches only the object meta field. Equivalent of c.Key(\"/meta/\") // Fetches only the global context. Equivalent of c.Key(\"/global_context/\")", "del_tokens": "// /dev/ttyS1 // returns it", "commit_type": "add"}
{"commit_tokens": ["Fix", "errors", "with", "gofmt", "compliance"], "add_tokens": "", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "path", "is", "not", "incorrectly", "modified", "via", "ref"], "add_tokens": "// Output: false modified: [0].FirstChild.NextSibling.Data = \" baz\"", "del_tokens": "// Output: false modified: [0].FirstChild.NextSibling.Attr = \" baz\"", "commit_type": "make"}
{"commit_tokens": ["added", "comment", "to", "choice", ".", "Prompt"], "add_tokens": "// Choice is a prompt that presents a list of various options to the user // for them to select using the arrow keys and enter. // Prompt shows the list, and listens for input from the user using /dev/tty.", "del_tokens": "// Choice is a prompt that presents a", "commit_type": "add"}
{"commit_tokens": ["add", "encoding", "speed", "test", "and", "gofmt"], "add_tokens": "// the previous stop is no buffer leader may get blocked // when heartbeat returns at line 132", "del_tokens": "// the previous stop is no buffer leader may get blocked // when heartbeat returns at line 132", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "logging", "initializer", ".", "If", "Log", "instance", "not", "explicitly", "set", "by"], "add_tokens": "// ensure logging is initialized func ( m * CirconusMetrics ) initializeLogging ( ) { if m . Log == nil { // was not explicitly set by user // note: this is only done once. // after a Start or Flush call - changing Debug will // NOT toggle logging if m . Debug { m . Log = log . New ( os . Stderr , \" \" , log . LstdFlags ) } else { m . Log = log . New ( ioutil . Discard , \" \" , log . LstdFlags ) } } } m . initializeLogging ( ) m . initializeLogging ( )", "del_tokens": "Log : log . New ( ioutil . Discard , \" \" , log . LstdFlags ) , if m . Debug { m . Log = log . New ( os . Stderr , \" \" , log . LstdFlags ) }", "commit_type": "add"}
{"commit_tokens": ["Remove", "extra", "arg", "from", "sprintf"], "add_tokens": "warnings = append ( warnings , red . SprintfFunc ( ) ( \" \" ) )", "del_tokens": "warnings = append ( warnings , red . SprintfFunc ( ) ( \" \" , cert . Version + 1 ) )", "commit_type": "remove"}
{"commit_tokens": ["Add", "isFinal", "flag", "for", "encryption", "V2", "packets"], "add_tokens": "// encryptionBlockV1 contains a block of encrypted data. It contains type encryptionBlockV1 struct { } // encryptionBlockV2 is encryptionBlockV1, but with a flag signifying // whether or not this is the final packet. type encryptionBlockV2 struct { encryptionBlockV1 IsFinal bool `codec:\"final\"`", "del_tokens": "// encryptionBlock contains a block of encrypted data. It contains type encryptionBlock struct { seqno packetSeqno", "commit_type": "add"}
{"commit_tokens": ["add", "[]", "byte", "specialized", "float", "handler", "add", "test", "with", "Everything", "being", "deserialized"], "add_tokens": "\" \" , out += fmt . Sprintf ( \" \\n \" ,", "del_tokens": "// TODO: make native byte verions of ParseFloat ic . OutputImports [ `\"strconv\"` ] = true out += fmt . Sprintf ( \" \\n \" ,", "commit_type": "add"}
{"commit_tokens": ["Updated", "jsonschema", "and", "tests", "to", "allow", "for", "matchers", "with", "just", "boolean", "values"], "add_tokens": "rule - five : matchers : foo . bar : [ true ] baz : [ false ] output : type : \" \" series : \" \" dimensions : [ ] stat_type : \" \" Rule { Name : \" \" , Matchers : RuleMatchers { \" \" : [ ] string { \" \" } , \" \" : [ ] string { \" \" } , } , Output : RuleOutput { \" \" : \" \" , \" \" : \" \" , \" \" : [ ] interface { } { } , \" \" : \" \" , \" \" : \" \" , } , } ,", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Fixing", "issue", "from", "last", "commit"], "add_tokens": "once sync . Once ec . once . Do ( func ( ) {", "del_tokens": "var once sync . Once once . Do ( func ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "interface", "of", "the", "Round", "func", "so", "it", "accepts", "a", "factor", "as", "a", "pow", "of", "10", "with", "a", "default", "value", "."], "add_tokens": "// Factor defaults to 1.0e5 func ( p * Point ) Round ( factor ... int ) * Point { f := 1.0e5 if len ( factor ) != 0 { f = float64 ( factor [ 0 ] ) } x := val * f res [ idx ] = x / f", "del_tokens": "func ( p * Point ) Round ( decimalPlaces int ) * Point { exp := math . Pow ( 10 , float64 ( decimalPlaces ) ) x := val * exp res [ idx ] = x / exp", "commit_type": "change"}
{"commit_tokens": ["Add", "nested", "e", "-", "mail", "test"], "add_tokens": "const mailString = \" \\r \\n \" + \" \\r \\n \" + const nestedMailString = \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + \" \\r \\n \" + mailString + \" \\r \\n \"", "del_tokens": "const mailString = \" \\r \\n \" +", "commit_type": "add"}
{"commit_tokens": ["Implement", "--", "only", "regexp", "cmd", "option", "to", "filter", "hosts"], "add_tokens": "\" \" onlyHosts = flag . String ( \" \" , \" \" , \" \" ) ErrCmd = errors . New ( \" \" ) // --only option to filter hosts if * onlyHosts != \" \" { expr , err := regexp . CompilePOSIX ( * onlyHosts ) if err != nil { log . Fatal ( err ) } var hosts [ ] string for _ , host := range network . Hosts { if expr . MatchString ( host ) { hosts = append ( hosts , host ) } } if len ( hosts ) == 0 { log . Fatal ( fmt . Errorf ( \" \" , * onlyHosts ) ) } network . Hosts = hosts }", "del_tokens": "ErrCmd = errors . New ( \" \" )", "commit_type": "implement"}
{"commit_tokens": ["added", "broadcast", "function", "to", "test", "recevers"], "add_tokens": "s . BroadcastMessage ( p ) func TestReceiver_Broadcast ( t * testing . T ) { }", "del_tokens": "r . conn . Lock ( ) r . conn . Write ( p ) r . conn . Unlock ( )", "commit_type": "add"}
{"commit_tokens": ["Remove", "runtime", "-", "schema", "/", "tasks"], "add_tokens": "err := models . FromJSON ( [ ] byte ( node . Value ) , task )", "del_tokens": "err := task . UnmarshalJSON ( [ ] byte ( node . Value ) )", "commit_type": "remove"}
{"commit_tokens": ["add", "client", ".", "Rels", "()"], "add_tokens": "// see sawyer_test.go for definitions of structs and SetupServer", "del_tokens": "\" \" type TestUser struct { Id int `json:\"id\"` Login string `json:\"login\"` Url hypermedia . Hyperlink `json:\"url\"` FooUrl hypermedia . Hyperlink `json:\"foo_url\" rel:\"foo\"` Whatever hypermedia . Hyperlink `json:\"whatever\" rel:\"whatevs\"` HomepageUrl string `json:\"homepage_url\"` * hypermedia . HALResource } func ( u * TestUser ) HyperfieldRels ( ) { } type TestError struct { Message string `json:\"message\"` } type SetupServer struct { Client * Client Server * httptest . Server Mux * http . ServeMux } func Setup ( t * testing . T ) * SetupServer { mux := http . NewServeMux ( ) srv := httptest . NewServer ( mux ) client , err := NewFromString ( srv . URL + \" \" , nil ) assert . Equalf ( t , nil , err , \" \" , srv . URL ) return & SetupServer { client , srv , mux } } func ( s * SetupServer ) Teardown ( ) { s . Server . Close ( ) }", "commit_type": "add"}
{"commit_tokens": ["fixes", "Granular", "example", "test", "name", "."], "add_tokens": "func ExampleGranular ( ) {", "del_tokens": "func ExampleGranularStrings ( ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "lua", "strings", "to", "be", "bulk"], "add_tokens": "c . WriteBulk ( lua . LVAsString ( value ) )", "del_tokens": "c . WriteInline ( lua . LVAsString ( value ) )", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "a", "new", "function", "to", "check", "quorum", "on", "a", "node", "periodically", "and", "update", "its", "status", "."], "add_tokens": "// This cluster size is updated from an external source // such as a kv database. This is an extra measure to find the // number of nodes in the cluster other than just relying on // memberlist and the length of nodeMap. It is used in // determining the cluster quorum clusterSize int // Ts at which we lost quorum lostQuorumTs time . Time // UpdateClusterSize is called from an external source indicating the cluster size func ( s * GossipStoreImpl ) UpdateClusterSize ( clusterSize int ) { s . Lock ( ) defer s . Unlock ( ) s . clusterSize = clusterSize } func ( s * GossipStoreImpl ) GetClusterSize ( ) int { return s . clusterSize } func ( s * GossipStoreImpl ) UpdateLostQuorumTs ( ) { s . Lock ( ) defer s . Unlock ( ) s . lostQuorumTs = time . Now ( ) } func ( s * GossipStoreImpl ) GetLostQuorumTs ( ) time . Time { return s . lostQuorumTs } Status : types . NODE_STATUS_WAITING_FOR_QUORUM , func ( s * GossipStoreImpl ) GetSelfStatus ( ) types . NodeStatus { s . Lock ( ) defer s . Unlock ( ) nodeInfo , _ := s . nodeMap [ s . id ] return nodeInfo . Status }", "del_tokens": "Status : types . NODE_STATUS_UP ,", "commit_type": "implement"}
{"commit_tokens": ["Move", "method", "up", "so", "it", "follows", "the", "order", "of", "rest", "declarations", "."], "add_tokens": "func ( r * usersResource ) getAllUsers ( request * restful . Request , response * restful . Response , user schema . User ) ( error , interface { } ) { users , err := r . users . GetAll ( ) return err , users }", "del_tokens": "func ( r * usersResource ) getAllUsers ( request * restful . Request , response * restful . Response , user schema . User ) ( error , interface { } ) { users , err := r . users . GetAll ( ) return err , users }", "commit_type": "move"}
{"commit_tokens": ["Improve", "libbuildpack", "s", "version", "parsing", "to", "account", "for", "non", "-", "semver"], "add_tokens": "matchVersion := func ( versionLine , depVersion string ) bool { return versionLine == depVersion } if err == nil { matchVersion = func ( versionLine , depVersion string ) bool { constraint , err := semver . NewConstraint ( versionLine ) if err != nil { return false } return constraint . Check ( v ) } if ! matchVersion ( deprecation . VersionLine , dep . Version ) { continue if eolTime . Sub ( m . currentTime ) < thirtyDays {", "del_tokens": "if err != nil { return nil versionLine , err := semver . NewConstraint ( deprecation . VersionLine ) if err != nil { return err if versionLine . Check ( v ) && eolTime . Sub ( m . currentTime ) < thirtyDays {", "commit_type": "improve"}
{"commit_tokens": ["Fix", "Windows", "code", "to", "allow", "multiple", "GET", "parameters"], "add_tokens": "import ( \" \" ) r := strings . NewReplacer ( \" \" , \" \" ) return runCmd ( \" \" , \" \" , \" \" , r . Replace ( url ) )", "del_tokens": "return runCmd ( \" \" , \" \" , \" \" , url )", "commit_type": "fix"}
{"commit_tokens": ["Move", "to", ".", "snapshots", "and", "don", "t", "spew", "collection", "capacities"], "add_tokens": "subDirName = \" \"", "del_tokens": "subDirName = \" \"", "commit_type": "move"}
{"commit_tokens": ["Added", "a", "JSON", "encoder", "/", "decoder", "to", "securecookie", "."], "add_tokens": "func TestGobSerialization ( t * testing . T ) { enc GobEncoder if serialized , err = enc . serialize ( value ) ; err != nil { if err = enc . deserialize ( serialized , & deserialized ) ; err != nil { t . Error ( err ) } if fmt . Sprintf ( \" \" , deserialized ) != fmt . Sprintf ( \" \" , value ) { t . Errorf ( \" \" , value , deserialized ) } } } } func TestJSONSerialization ( t * testing . T ) { var ( enc JSONEncoder serialized [ ] byte deserialized map [ string ] string err error ) for _ , value := range testCookies { if serialized , err = enc . serialize ( value ) ; err != nil { t . Error ( err ) } else { deserialized = make ( map [ string ] string ) if err = enc . deserialize ( serialized , & deserialized ) ; err != nil {", "del_tokens": "func TestSerialization ( t * testing . T ) { if serialized , err = serialize ( value ) ; err != nil { if err = deserialize ( serialized , & deserialized ) ; err != nil {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "parsing", "the", "dependencies", "and", "public", "dependencies", "as", "well", "to", "the", "parser"], "add_tokens": "// parse the main proto file... pf , err := parseFile ( filePath ) if err != nil { return pf , err } // verify via extra checks... if err := verify ( filePath , & pf ) ; err != nil { return pf , err } return pf , nil } // ParseFile This method is to be called with the path // of the proto file to be parsed. func parseFile ( filePath string ) ( ProtoFile , error ) { // read the file contents... // create buffered reader with file contents... // initialize parser... // parse the file contents... err = parser . parse ( & pf ) if err != nil { return pf , err } func ( p * parser ) parse ( pf * ProtoFile ) error { if err != nil { return err } if err != nil { return err } return nil", "del_tokens": "\" \" parser . parser ( & pf ) func ( p * parser ) parser ( pf * ProtoFile ) { finishIfNecessary ( err ) finishIfNecessary ( err ) func finishIfNecessary ( err error ) { if err != nil { fmt . Printf ( \" \" + err . Error ( ) + \" \\n \" ) os . Exit ( - 1 ) } }", "commit_type": "add"}
{"commit_tokens": ["Fix", "plugin", "-", "go", "-", "grpc", "example"], "add_tokens": "\" \" func ( p * KVPlugin ) GRPCServer ( broker * plugin . GRPCBroker , s * grpc . Server ) error { func ( p * KVPlugin ) GRPCClient ( ctx context . Context , broker * plugin . GRPCBroker , c * grpc . ClientConn ) ( interface { } , error ) {", "del_tokens": "func ( p * KVPlugin ) GRPCServer ( s * grpc . Server ) error { func ( p * KVPlugin ) GRPCClient ( c * grpc . ClientConn ) ( interface { } , error ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "node", "removal", "when", "at", "root", "of", "tree"], "add_tokens": "// If at the root of the trie, reset if parent == nil { node . reset ( ) } else { parent . children . remove ( node ) } root . reset ( ) func ( trie * Trie ) reset ( ) { trie . prefix = nil trie . children = newSparseChildList ( trie . maxPrefixPerNode ) }", "del_tokens": "parent . children . remove ( node ) root . prefix = nil root . children = newSparseChildList ( trie . maxPrefixPerNode )", "commit_type": "fix"}
{"commit_tokens": ["Use", "copy", "for", "zeroing", "offsetFreq", "."], "add_tokens": "copy ( w . literalFreq , zeroLits [ : ] ) copy ( w . offsetFreq , zeroLits [ : maxNumDist ] ) copy ( w . offsetFreq , zeroLits [ : maxNumDist ] )", "del_tokens": "copy ( w . literalFreq , zeroLits [ : ] ) for i := range w . offsetFreq { w . offsetFreq [ i ] = 0 } for i := range w . offsetFreq { w . offsetFreq [ i ] = 0 }", "commit_type": "use"}
{"commit_tokens": ["Add", "RFC", "2822", "string", "method"], "add_tokens": "RFC2822Format = \" \" return c . Format ( time . RFC1123Z ) // Rfc2822String returns the current time in RFC 2822 format func ( c * Carbon ) Rfc2822String ( ) string { return c . Format ( RFC2822Format )", "del_tokens": "RFC1123Format = \" \" return c . Format ( RFC1123Format ) // Format the instance as RFC2822 func ToRfc2822String ( ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "data", "race", "in", "closing", "TrapServer", "and", "packetTransport"], "add_tokens": "\" \" servingMu sync . RWMutex s . servingMu . Lock ( ) s . servingMu . Unlock ( ) s . servingMu . RLock ( ) serving := s . serving s . servingMu . RUnlock ( ) if ! serving { s . servingMu . RLock ( ) serving := s . serving s . servingMu . RUnlock ( ) if serving { s . servingMu . Lock ( ) s . servingMu . Unlock ( )", "del_tokens": "if ! s . serving { if s . serving {", "commit_type": "fix"}
{"commit_tokens": ["add", "deeply", "sub", "command", "test"], "add_tokens": "sub1 := app . Register ( & Command { sub1 . Register ( & Command { Name : \" \" , Fn : func ( ctx * Context ) error { if ctx . Path ( ) != \" \" { t . Errorf ( \" \" , ctx . Path ( ) , \" \" ) } argv := ctx . Argv ( ) . ( * arg_t ) if argv . Help != false || argv . Version != \" \" { t . Errorf ( \" \" , * argv ) } return nil } , ArgvFn : func ( ) interface { } { return new ( arg_t ) } , } ) if err := app . Run ( [ ] string { } ) ; err != nil { t . Errorf ( \" \" , err ) } if err := app . Run ( [ ] string { \" \" , \" \" , \" \" , } ) ; err != nil { t . Errorf ( \" \" , err )", "del_tokens": "app . Register ( & Command { err := app . Run ( [ ] string { } ) if err != nil { t . Errorf ( \" \" , err )", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "decode", "hook", "for", "headers"], "add_tokens": "mapToHTTPHeaderHookFunc ( ) ,", "del_tokens": "\" \" \" \" // stringToTimeHookFunc returns a function that converts strings to a time.Time // value. func stringToTimeHookFunc ( ) mapstructure . DecodeHookFunc { return func ( f reflect . Type , t reflect . Type , data interface { } ) ( interface { } , error ) { if f . Kind ( ) != reflect . String { return data , nil } if t != reflect . TypeOf ( time . Now ( ) ) { return data , nil } // Convert it by parsing return time . Parse ( time . RFC3339 , data . ( string ) ) } }", "commit_type": "add"}
{"commit_tokens": ["use", "POSIX", "regexp", "to", "allow", "$", "and", "^"], "add_tokens": "re , err := regexp . CompilePOSIX ( s [ 1 : len ( s ) - 1 ] )", "del_tokens": "re , err := regexp . Compile ( s [ 1 : len ( s ) - 1 ] )", "commit_type": "use"}
{"commit_tokens": ["fix", "wrong", "content", "-", "type", "on", "response"], "add_tokens": "c . Writer . WriteHeader ( status ) c . Writer . WriteHeader ( status ) c . Writer . WriteHeader ( status )", "del_tokens": "c . Writer . WriteHeader ( status ) c . Writer . WriteHeader ( status ) c . Writer . WriteHeader ( status )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "Fail", "to", "return", "error"], "add_tokens": "// error will be reported as the failure. Returns the original error for // convenient chaining. Fail ( err error ) error func ( o * op ) Fail ( err error ) error { return err", "del_tokens": "// error will be reported as the failure. Fail ( err error ) Op func ( o * op ) Fail ( err error ) Op { return o", "commit_type": "change"}
{"commit_tokens": ["Use", "square", "golang", "JWT", "package", "instead", "of", "SermoDigital"], "add_tokens": "\" \" configuration := NewConfiguration ( [ ] byte ( \" \" ) , \" \" , \" \" , jose . HS256 ) configuration := NewConfiguration ( [ ] byte ( \" \" ) , \" \" , \" \" , jose . HS256 ) configuration := NewConfiguration ( [ ] byte ( \" \" ) , \" \" , \" \" , jose . HS256 )", "del_tokens": "\" \" configuration := NewConfiguration ( [ ] byte ( \" \" ) , \" \" , \" \" , crypto . SigningMethodHS256 ) configuration := NewConfiguration ( [ ] byte ( \" \" ) , \" \" , \" \" , crypto . SigningMethodHS256 ) configuration := NewConfiguration ( [ ] byte ( \" \" ) , \" \" , \" \" , crypto . SigningMethodHS256 )", "commit_type": "use"}
{"commit_tokens": ["Fix", "override", "service", "during", "compose", "reload"], "add_tokens": "p . reload = append ( p . reload , name ) for _ , name := range p . reload { wrappers [ name ] = NewServiceWrapper ( name , p ) p . reload = [ ] string { }", "del_tokens": "for name , _ := range p . Services { wrappers [ name ] = NewServiceWrapper ( name , p ) } for name , _ := range p . Services { if _ , ok := wrappers [ name ] ; ! ok { wrappers [ name ] = NewServiceWrapper ( name , p ) }", "commit_type": "fix"}
{"commit_tokens": ["Remove", "extra", "tab", "for", "gofmt"], "add_tokens": "\" \"", "del_tokens": "\" \"", "commit_type": "remove"}
{"commit_tokens": ["Add", "NotifyUrl", "for", "Create", "-", "and", "ReplayAssembly"], "add_tokens": "options := map [ string ] interface { } { } if assembly . NotifyUrl != \" \" { options [ \" \" ] = assembly . NotifyUrl } params , signature , err := assembly . client . sign ( options ) if assembly . NotifyUrl != \" \" { options [ \" \" ] = assembly . NotifyUrl }", "del_tokens": "params , signature , err := assembly . client . sign ( map [ string ] interface { } { } )", "commit_type": "add"}
{"commit_tokens": ["add", "a", "few", "comments", "to", "consts"], "add_tokens": "// DoNotScale means 'never change size of the object when its parent resizes' // AutoSize is used only in constructors. It means that the constructor // should either calculate the size of an object, e.g. for Label it is its text // length, or use default intial values // DoNotChange is used as a placeholder when you want to change only one // value and keep other ones untouched. Used in SetSize and SetConstraints // methods only // Example: control.SetConstraint(10, DoNotChange) changes only minimal width // of the control and do not change the current minimal control height // BorderStyle is a kind of frame: none, single, and double BorderStyle int // ViewButton is a set of buttons displayed in a view title ViewButton int // HitResult is a type of a view area that is under mouse cursor. // Used in mouse click events HitResult int // Align is text align: left, right and center Align int // EventType is a type of event fired by an object EventType int // Direction indicates the direction in which a control must draw its // content. At that moment it can be applied to Label (text output // direction and to ProgressBar (direction of bar filling) Direction int // PackType sets how to pack controls inside its parent. Can be Vertical or // Horizontal PackType int // SelectDialogType sets the way of choosing an item from a list for // SelectionDialog control: a list-based selections, or radio group one // Event is structure used by Views and controls to communicate with Composer // and vice versa // Used for Label text output direction and for Radio items distribution, // and for container controls // EventType is event that window or control may process", "del_tokens": "// scale coefficient means never change of the object when its parent resizes // Used as a placeholder when width or height is not important, e.g, creating a control manually to use in packer later // Used as a placeholder when you want to change only one value keeping others untouched. Example: ctrl.SetConstraint(10, DoNotChange) // NullWindow View = nil type Box struct { X , Y int W , H int } BorderStyle int ViewButton int HitResult int Align int EventType int Direction int PackType int // Internal event structure. Used by Windows and controls to communicate with Composer // InternalEvent types const ( // asks Composer to redraw the screen ActionRedraw = iota // asks application to close ActionQuit ) // Used for Label text output direction and for Radio items distribution // EventType // Event that window or control may process", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "older", "versions", "of", "go"], "add_tokens": "if req . Method == \" \" { if req . Method == \" \" {", "del_tokens": "if req . Method == http . MethodPost { if req . Method == http . MethodGet {", "commit_type": "fix"}
{"commit_tokens": ["Add", "database", "connection", "check", "loop", "on", "startup"], "add_tokens": "\" \" const ( // DBMaxRetryAttempts is the number of times alm server will attempt to open a connection to the database before it gives up DBMaxRetryAttempts int = 50 ) var db * gorm . DB var err error for i := 1 ; i <= DBMaxRetryAttempts ; i ++ { fmt . Printf ( \" \\n \" , i , DBMaxRetryAttempts ) db , err = gorm . Open ( \" \" , fmt . Sprintf ( \" \" , dbHost ) ) if err != nil { time . Sleep ( time . Second ) } else { defer db . Close ( ) break } } panic ( \" \" )", "del_tokens": "db , err := gorm . Open ( \" \" , fmt . Sprintf ( \" \" , dbHost ) ) panic ( \" \" + err . Error ( ) ) defer db . Close ( )", "commit_type": "add"}
{"commit_tokens": ["Adds", "session", "due", "to", "breaking", "change", "in", "AWS", "API"], "add_tokens": "\" \" sess := session . New ( ) client := s3 . New ( sess , config ) sess := session . New ( ) client := s3 . New ( sess , config ) sess := session . New ( ) client := s3 . New ( sess , config )", "del_tokens": "client := s3 . New ( config ) client := s3 . New ( config ) client := s3 . New ( config )", "commit_type": "add"}
{"commit_tokens": ["Remove", "unused", "resp", "values", "."], "add_tokens": "_ , err = tp . RoundTrip ( r ) _ , err = tp . RoundTrip ( r )", "del_tokens": "resp , err = tp . RoundTrip ( r ) resp , err = tp . RoundTrip ( r )", "commit_type": "remove"}
{"commit_tokens": ["use", "golang", "time", "datatype", "instead", "of", "time", "units", "in", "name"], "add_tokens": "updateState = 2 * time . Second pingTimeout = 40 * time . Second flushThrottle = 100 * time . Millisecond defaultSendTimeout = 10 * time . Second c . flushTimer = cmn . NewThrottleTimer ( \" \" , flushThrottle ) c . pingTimer = cmn . NewRepeatTimer ( \" \" , pingTimeout ) c . chStatsTimer = cmn . NewRepeatTimer ( \" \" , updateState ) // Times out (and returns false) after defaultSendTimeout timeout := time . NewTimer ( defaultSendTimeout )", "del_tokens": "updateStatsSeconds = 2 pingTimeoutSeconds = 40 flushThrottleMS = 100 defaultSendTimeoutSeconds = 10 c . flushTimer = cmn . NewThrottleTimer ( \" \" , flushThrottleMS * time . Millisecond ) c . pingTimer = cmn . NewRepeatTimer ( \" \" , pingTimeoutSeconds * time . Second ) c . chStatsTimer = cmn . NewRepeatTimer ( \" \" , updateStatsSeconds * time . Second ) // Times out (and returns false) after defaultSendTimeoutSeconds timeout := time . NewTimer ( defaultSendTimeoutSeconds * time . Second )", "commit_type": "use"}
{"commit_tokens": ["Allow", "retrieving", "of", "correct", "request", "URL"], "add_tokens": "url := req . URL ( ) . Path", "del_tokens": "url := req . URL . Path", "commit_type": "allow"}
{"commit_tokens": ["Adding", "a", "few", "tests", "to", "improve", "coverage", "."], "add_tokens": "answer = answer . lazyOR ( bm )", "del_tokens": "type rblist [ ] * Bitmap func ( p rblist ) Swap ( i , j int ) { p [ i ] , p [ j ] = p [ j ] , p [ i ] } func ( p rblist ) Len ( ) int { return len ( p ) } func ( p rblist ) Less ( i , j int ) bool { return p [ i ] . GetSizeInBytes ( ) > p [ j ] . GetSizeInBytes ( ) } answer . lazyOR ( bm )", "commit_type": "add"}
{"commit_tokens": ["Allow", "null", "values", "in", "GPRMC", "speed", "&", "course", "fields"], "add_tokens": "if s . Fields [ 6 ] != \" \" { s . Speed , err = strconv . ParseFloat ( s . Fields [ 6 ] , 64 ) if err != nil { return fmt . Errorf ( \" \" , s . Fields [ 6 ] ) } if s . Fields [ 7 ] != \" \" { s . Course , err = strconv . ParseFloat ( s . Fields [ 7 ] , 64 ) if err != nil { return fmt . Errorf ( \" \" , s . Fields [ 7 ] ) }", "del_tokens": "s . Speed , err = strconv . ParseFloat ( s . Fields [ 6 ] , 64 ) if err != nil { return fmt . Errorf ( \" \" , s . Fields [ 6 ] ) s . Course , err = strconv . ParseFloat ( s . Fields [ 7 ] , 64 ) if err != nil { return fmt . Errorf ( \" \" , s . Fields [ 7 ] )", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "insecure", "SSL"], "add_tokens": "\" \" \" \" ApiAddress string LoginAddress string Username string Password string SkipSslValidation bool HttpClient * http . Client Token string ApiAddress : \" \" , LoginAddress : \" \" , Username : \" \" , Password : \" \" , Token : \" \" , SkipSslValidation : false , HttpClient : http . DefaultClient , if config . SkipSslValidation == false { config . HttpClient = defConfig . HttpClient } else { tr := & http . Transport { TLSClientConfig : & tls . Config { InsecureSkipVerify : true } , } config . HttpClient = & http . Client { Transport : tr } } if err != nil { log . Printf ( \" \\n \" , err ) os . Exit ( 1 ) }", "del_tokens": "ApiAddress string LoginAddress string Username string Password string HttpClient * http . Client Token string ApiAddress : \" \" , LoginAddress : \" \" , Username : \" \" , Password : \" \" , Token : \" \" , HttpClient : http . DefaultClient , config . HttpClient = defConfig . HttpClient", "commit_type": "add"}
{"commit_tokens": ["implemented", "pre", "-", "counters", "that", "are", "incremented", "before", "calling", "the", "mocked", "method"], "add_tokens": "{ { $ methodName } } PreCounter uint64 atomic . AddUint64 ( & m . { { $ methodName } } PreCounter , 1 ) //{{$methodName}}MinimockCounter returns a count of {{$structName}}.{{$methodName}}Func invocations //{{$methodName}}MinimockPreCounter returns the value of {{$structName}}.{{$methodName}} invocations func ( m * { { $ structName } } ) { { $ methodName } } MinimockPreCounter ( ) uint64 { return atomic . LoadUint64 ( & m . { { $ methodName } } PreCounter ) }", "del_tokens": "//{{$methodName}}MinimockCounter returns a count of {{$interfaceName}}.{{$methodName}} invocations", "commit_type": "implement"}
{"commit_tokens": ["fix", "some", "issues", "in", "generating", "gast", "path", "code", "for", "slices", "and", "maps", "via", "gen", "-", "fast", "-", "path", ".", "go", "."], "add_tokens": "case \" \" , \" \" , \" \" , \" \" , \" \" : case \" \" , \" \" , \" \" , \" \" , \" \" : // keep as slice, so it is in specific iteration order. // Initial order was uint64, string, interface{}, int, int64 mapvaltypes := [ ] string { \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , } mapvaltypes2 := make ( map [ string ] bool ) for _ , s := range mapvaltypes { mapvaltypes2 [ s ] = true if ! mapvaltypes2 [ s ] { for _ , ms := range mapvaltypes {", "del_tokens": "case \" \" , \" \" , \" \" , \" \" , \" \" : case \" \" , \" \" , \" \" , \" \" , \" \" : mapvaltypes := map [ string ] bool { \" \" : true , \" \" : true , \" \" : true , \" \" : true , \" \" : true , if ! mapvaltypes [ s ] { for ms , _ := range mapvaltypes {", "commit_type": "fix"}
{"commit_tokens": ["fix", "Title", "to", "keep", "dot", "in", "floating", "number"], "add_tokens": "func isNumOrSpace ( r rune ) bool { return ( '0' <= r && r <= '9' ) || r == ' ' } rs := [ ] rune ( name ) for i , r := range rs { switch r { case '_' : rs [ i ] = ' ' case '.' : // ignore floating number 0.0 if ( i != 0 && ! isNumOrSpace ( rs [ i - 1 ] ) ) || ( i != len ( rs ) - 1 && ! isNumOrSpace ( rs [ i + 1 ] ) ) { rs [ i ] = ' ' } } } name = string ( rs )", "del_tokens": "name = strings . Replace ( name , \" \" , \" \" , - 1 ) name = strings . Replace ( name , \" \" , \" \" , - 1 )", "commit_type": "fix"}
{"commit_tokens": ["fix", "bugs", "pointed", "out", "by", "go", "vet"], "add_tokens": "log . Fatalf ( \" \" , err ) log . Fatalf ( \" \" , err )", "del_tokens": "log . Fatal ( \" \" , err ) log . Fatal ( \" \" , err )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "which", "panic", "when", "r", ".", "Bytes", "()", "is", "empty", "."], "add_tokens": "if len ( r . Bytes ( ) ) == 0 || r . Bytes ( ) [ 0 ] != '[' {", "del_tokens": "if r . Bytes ( ) [ 0 ] != '[' {", "commit_type": "fix"}
{"commit_tokens": ["use", "fresh", "/", "dev", "/", "tty", "fd", "for", "stdin", "in", "input", "parser"], "add_tokens": "n , err := syscall . Read ( t . fd , buf ) in , err := syscall . Open ( \" \" , syscall . O_RDONLY , 0 ) if err != nil { panic ( err ) } fd : in ,", "del_tokens": "n , err := syscall . Read ( syscall . Stdin , buf ) fd : syscall . Stdin ,", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "for", "remove", "and", "find"], "add_tokens": "if index < 0 || index >= array . Len ( ) {", "del_tokens": "if index < 0 || index > array . Len ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "to", "Register", "and", "HandleCmd", "functions"], "add_tokens": "availableCommands = \" \" noCommandsAvailable = \" \" cmds := \" \" cmds += k + \" \" } if cmds != \" \" { Msg ( channel , fmt . Sprintf ( \" \" , availableCommands , cmds [ : len ( cmds ) - 2 ] ) ) } else { Msg ( channel , noCommandsAvailable )", "del_tokens": "availableCommands := \" \" availableCommands += k + \" \" Msg ( channel , availableCommands [ : len ( availableCommands ) - 2 ] )", "commit_type": "add"}
{"commit_tokens": ["remove", "default", "extension", "from", "path", ".", "Join", "call"], "add_tokens": "filename = path . Join ( \" \" , \" \" ) + defaultFileExtension", "del_tokens": "filename = path . Join ( \" \" , \" \" , defaultFileExtension )", "commit_type": "remove"}
{"commit_tokens": ["Use", "formatting", "functions", "where", "intended"], "add_tokens": "t . Errorf ( \" \" , err ) t . Logf ( \" \" , err ) t . Fatalf ( \" \" , err )", "del_tokens": "t . Error ( \" \" , err ) t . Log ( \" \" , err ) t . Fatal ( \" \" , err )", "commit_type": "use"}
{"commit_tokens": ["Make", "failing", "case", "minimal", "and", "provide", "support"], "add_tokens": "pi := Partition ( list , rand . Intn ( list . Len ( ) ) ) for i := 0 ; i < pi ; i ++ { c . Check ( list [ i ] <= list [ pi ] , check . Equals , true ) } for i := pi + 1 ; i < len ( list ) ; i ++ { c . Check ( list [ i ] > list [ pi ] , check . Equals , true ) } } } func ( s * S ) TestPartitionCollision ( c * check . C ) { for p := 0 ; p < 10 ; p ++ { list := make ( Ints , 10 ) for i := range list { list [ i ] = rand . Intn ( 5 ) } c . Check ( list [ i ] <= list [ pi ] , check . Equals , true ) list [ i ] = rand . Intn ( 1000 )", "del_tokens": "c . Check ( list [ i ] < list [ pi ] , check . Equals , true ) list [ i ] = rand . Int ( ) % 1000", "commit_type": "make"}
{"commit_tokens": ["fix", "race", "in", "case", "of", "concurrent", "access", "to", "(", "*", "Context", ")", ".", "Get"], "add_tokens": "lock * sync . RWMutex lock : & sync . RWMutex { } , c . lock . RLock ( ) c . lock . RUnlock ( )", "del_tokens": "lock * sync . Mutex lock : & sync . Mutex { } ,", "commit_type": "fix"}
{"commit_tokens": ["Updated", "tests", "to", "work", "with", "new", "API", "definitions"], "add_tokens": "td := & queue . TaskDefinitionRequest { Priority : \" \" , if provisionerId := cs . HttpRequestObject . ( * queue . TaskDefinitionRequest ) . ProvisionerId ; provisionerId != \" \" {", "del_tokens": "td := & queue . TaskDefinition { Priority : json . RawMessage ( `\"high\"` ) , if provisionerId := cs . HttpRequestObject . ( * queue . TaskDefinition ) . ProvisionerId ; provisionerId != \" \" {", "commit_type": "update"}
{"commit_tokens": ["Fixed", "TestReadRowsFromSheet", "following", "pulls", "of", "two", "succesive", "patches", "that", "broke", "it", "."], "add_tokens": "rows , maxCols , maxRows := readRowsFromSheet ( worksheet , reftable ) if maxRows != 2 { t . Error ( \" \" ) } if maxCols != 22 { t . Error ( \" \" ) rows , _ , _ := readRowsFromSheet ( worksheet , reftable ) rows , maxCol , maxRow := readRowsFromSheet ( worksheet , reftable ) if maxCol != 22 { t . Error ( \" \" , strconv . Itoa ( maxCol ) ) } if maxRow != 8 { t . Error ( \" \" , strconv . Itoa ( maxRow ) ) }", "del_tokens": "rows := readRowsFromSheet ( worksheet , reftable ) if len ( rows ) != 2 { t . Error ( \" \" ) rows := readRowsFromSheet ( worksheet , reftable ) rows := readRowsFromSheet ( worksheet , reftable )", "commit_type": "fix"}
{"commit_tokens": ["Add", "Any", "+", "Match", "Tests"], "add_tokens": "g . Connect ( path , h ... ) g . Delete ( path , h ... ) g . Get ( path , h ... ) g . Head ( path , h ... ) g . Options ( path , h ... ) g . Patch ( path , h ... ) g . Post ( path , h ... ) g . Put ( path , h ... ) g . Trace ( path , h ... )", "del_tokens": "g . Connect ( path , h ) g . Delete ( path , h ) g . Get ( path , h ) g . Head ( path , h ) g . Options ( path , h ) g . Patch ( path , h ) g . Post ( path , h ) g . Put ( path , h ) g . Trace ( path , h )", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "issue", "that", "doesn", "t", "check", "the", "nil", "when", "get", "all", "errors", "for", "WhenAll", "function"], "add_tokens": "if err := getError ( recover ( ) ) ; err != nil { e = err //fmt.Println(\"error in end\", e) //buf := bytes.NewBufferString(\"\") //pcs := make([]uintptr, 50) //num := runtime.Callers(2, pcs) //for _, v := range pcs[0:num] { // fun := runtime.FuncForPC(v) // file, line := fun.FileLine(v) // name := fun.Name() // //fmt.Println(name, file + \":\", line) // writeStrings(buf, []string{name, \" \", file, \":\", strconv.Itoa(line), \"\\n\"}) //} //fmt.Println(buf.String()) //fmt.Println(\"send future result\", r) //fmt.Println(\"begin callback \", r) //fmt.Println(\"after callback\", r) //fmt.Println(\"reject2\", newErrorWithStacks(e)) //fmt.Println(\"reject1===\", err, \"\\n\") //fmt.Println(\"whenall reject\", errs) e := newAggregateError ( \" \" , errs ) //fmt.Println(\"whenall reject2\", e.Error()) f . Reject ( e ) if ie == nil { continue } //fmt.Println(\"newAggregateError\", innerErrors) //fmt.Println(\"newAggregateError, newErrorWithStacks\", newErrorWithStacks(s).Error())", "del_tokens": "if e = getError ( recover ( ) ) ; e != nil { fmt . Println ( \" \" , e ) buf := bytes . NewBufferString ( \" \" ) pcs := make ( [ ] uintptr , 50 ) num := runtime . Callers ( 2 , pcs ) for _ , v := range pcs [ 0 : num ] { fun := runtime . FuncForPC ( v ) file , line := fun . FileLine ( v ) name := fun . Name ( ) //fmt.Println(name, file + \":\", line) writeStrings ( buf , [ ] string { name , \" \" , file , \" \" , strconv . Itoa ( line ) , \" \\n \" } ) } fmt . Println ( buf . String ( ) ) f . Reject ( newAggregateError ( \" \" , errs ) )", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "to", "use", "SIMD", "Alignment", "with", "32"], "add_tokens": "K = 10 M = 3 ALIGN = 32 var alignment int = ALIGN var remainder = block_len % alignment var chunk_size int chunk_size = block_len if remainder > 0 { chunk_size = block_len + ( alignment - remainder ) return chunk_size / e . p . k", "del_tokens": "DEFAULT_K = 10 DEFAULT_M = 3 var alignment int = e . p . k * e . p . w var padding = block_len % alignment var padded_len int if padding > 0 { padded_len = block_len + ( alignment - padding ) } else { padded_len = block_len return padded_len / e . p . k", "commit_type": "make"}
{"commit_tokens": ["Allow", "call", "Publish", "with", "nil", "values"], "add_tokens": "sync . Mutex // lock for an event handler - useful for running async callbacks serially passedArguments := bus . setUpPublish ( handler , args ... ) func ( bus * EventBus ) setUpPublish ( callback * eventHandler , args ... interface { } ) [ ] reflect . Value { funcType := callback . callBack . Type ( ) passedArguments := make ( [ ] reflect . Value , len ( args ) ) for i , v := range args { if v == nil { passedArguments [ i ] = reflect . New ( funcType . In ( i ) ) . Elem ( ) } else { passedArguments [ i ] = reflect . ValueOf ( v ) }", "del_tokens": "sync . Mutex // lock for an event handler - useful for running async callbacks serially passedArguments := bus . setUpPublish ( topic , args ... ) func ( bus * EventBus ) setUpPublish ( topic string , args ... interface { } ) [ ] reflect . Value { passedArguments := make ( [ ] reflect . Value , 0 ) for _ , arg := range args { passedArguments = append ( passedArguments , reflect . ValueOf ( arg ) )", "commit_type": "allow"}
{"commit_tokens": ["Use", "UnixNano", "int64s", "instead", "of", "Time"], "add_tokens": "Expiration int64 func ( item Item ) expired ( now int64 ) bool { if item . Expiration == 0 { return now > item . Expiration if item . Expiration == 0 { return time . Now ( ) . UnixNano ( ) > item . Expiration var e int64 e = time . Now ( ) . Add ( d ) . UnixNano ( ) now := time . Now ( ) . UnixNano ( )", "del_tokens": "Expiration time . Time func ( item Item ) expired ( now time . Time ) bool { if item . Expiration == emptyTime { return item . Expiration . Before ( now ) if item . Expiration == emptyTime { return item . Expiration . Before ( time . Now ( ) ) e := emptyTime e = time . Now ( ) . Add ( d ) now := time . Now ( )", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "returned", "job", "IDs", "are", "as", "per", "Disque", "spec"], "add_tokens": "\" \" if len ( id ) != 40 && strings . HasPrefix ( id , \" \" ) { t . Errorf ( \" \" , id ) if len ( ids [ 0 ] ) != 40 && strings . HasPrefix ( ids [ 0 ] , \" \" ) { t . Errorf ( \" \" , ids [ 0 ] )", "del_tokens": "if id == \" \" { t . Errorf ( \" \" ) if ids [ 0 ] == \" \" { t . Errorf ( \" \" )", "commit_type": "make"}
{"commit_tokens": ["Use", "fatalf", "for", "formatted", "output"], "add_tokens": "log . Fatalf ( \" \" , fn , err ) log . Fatalf ( \" \" , fn , err ) log . Fatalf ( \" \" , fn , err )", "del_tokens": "log . Fatal ( \" \" , fn , err ) log . Fatal ( \" \" , fn , err ) log . Fatal ( \" \" , fn , err )", "commit_type": "use"}
{"commit_tokens": ["Use", "strings", ".", "Replacer", "instead", "of", "hand", "-", "rolled", "escapeString"], "add_tokens": "var ( escape = strings . NewReplacer ( \" \\\\ \" , `\\\\` , \" \\n \" , `\\n` ) escapeWithDoubleQuote = strings . NewReplacer ( \" \\\\ \" , `\\\\` , \" \\n \" , `\\n` , \" \\\" \" , `\\\"` ) ) if includeDoubleQuote { return escapeWithDoubleQuote . Replace ( v ) return escape . Replace ( v )", "del_tokens": "\" \" result := bytes . NewBuffer ( make ( [ ] byte , 0 , len ( v ) ) ) for _ , c := range v { switch { case c == '\\\\' : result . WriteString ( `\\\\` ) case includeDoubleQuote && c == '\"' : result . WriteString ( `\\\"` ) case c == '\\n' : result . WriteString ( `\\n` ) default : result . WriteRune ( c ) } return result . String ( )", "commit_type": "use"}
{"commit_tokens": ["Add", "tests", "to", "verify", "404", "still", "return", "a", "redirect", "."], "add_tokens": "if ! strings . HasPrefix ( URL , \" \" ) && ! strings . HasPrefix ( URL , \" \" ) {", "del_tokens": "if ! strings . HasPrefix ( URL , \" \" ) {", "commit_type": "add"}
{"commit_tokens": ["Change", "from", "vars", "to", "funcs", "."], "add_tokens": "switch 1 { return fmt . Errorf ( \" \" , err ) //b := buf.Bytes() fmt . Fprintf ( w , \" \\n \" , dashSepToMixedCaps ( name ) , name ) fmt . Fprintf ( w , \" \\n \" , dashSepToMixedCaps ( name ) ) fmt . Fprint ( w , \" \" ) goon . Fdump ( w , svg ) fmt . Fprintln ( w , \" \" )", "del_tokens": "switch 0 { var ( fmt . Fprint ( & buf , \" \\n \" ) return err fmt . Fprintf ( w , \" \\n \" , dashSepToMixedCaps ( name ) , name ) fmt . Fprintf ( w , \" \" , dashSepToMixedCaps ( name ) ) goon . Fdump ( w , svg )", "commit_type": "change"}
{"commit_tokens": ["Fix", "example", "for", "altered", "Logging", "interface", "."], "add_tokens": "var log service . Logger log = s s . Error ( err . Error ( ) ) log . Info ( \" \" ) log . Info ( \" \" )", "del_tokens": "var localLog service . Logger localLog = s s . LogError ( err . Error ( ) ) localLog . LogInfo ( \" \" ) localLog . LogInfo ( \" \" )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "improper", "wait", "group", "usage", "in", "test"], "add_tokens": "wg . Add ( 1 ) go func ( t * testing . T , i int ) { } ( t , i )", "del_tokens": "go func ( wg * sync . WaitGroup , t * testing . T , i int ) { wg . Add ( 1 ) } ( & wg , t , i )", "commit_type": "fix"}
{"commit_tokens": ["Add", "testHarnessShiftLoad", "delete", "toml", "files"], "add_tokens": "var testHarnessShiftLoad = shift . Load err := testHarnessShiftLoad ( cfg , configPath , strmangle . EnvAppName ( appName ) , env )", "del_tokens": "err := shift . Load ( cfg , configPath , strmangle . EnvAppName ( appName ) , env )", "commit_type": "add"}
{"commit_tokens": ["add", "struct", "tags", "for", "compat"], "add_tokens": "Comparator string `json:\"comparator\"` Path string `json:\"path\"` Value interface { } `json:\"value\"`", "del_tokens": "Comparator string Path string Value interface { }", "commit_type": "add"}
