{"commit_tokens": ["Remove", "lombok", "from", "client", "."], "add_tokens": "public BatchRunnable ( Batch batch ) { this . batch = batch ; }", "del_tokens": "import lombok . RequiredArgsConstructor ; @ RequiredArgsConstructor", "commit_type": "remove"}
{"commit_tokens": ["add", "request", "and", "response", "to", "DvalinRSContext"], "add_tokens": "import javax . servlet . http . HttpServletResponse ; HttpServletRequest request = this . getHttpServletRequest ( ) ; @ Override public HttpServletRequest getHttpServletRequest ( ) { return this . getMessageContext ( ) . getHttpServletRequest ( ) ; } @ Override public HttpServletResponse getHttpServletResponse ( ) { return this . getMessageContext ( ) . getHttpServletResponse ( ) ; }", "del_tokens": "HttpServletRequest request = this . getMessageContext ( ) . getHttpServletRequest ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "MODE_MULTI_PROCESS", "as", "default", "mode", "for", "preferences", "."], "add_tokens": "this ( context , postfix , Context . MODE_MULTI_PROCESS ) ;", "del_tokens": "this ( context , postfix , Context . MODE_PRIVATE ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "demo", "app", "to", "use", "subclassing", "and", "added", "constructors", "to", "the", "MessagingMBean", "sample"], "add_tokens": "import javax . management . MalformedObjectNameException ; import org . softee . management . annotation . Description ; import org . softee . management . annotation . MBean ; / * * * Subclass create purely to redefine the objectname and description * / @ MBean ( objectName = \"org.softee:type=Demo,application=ESB,name=MessageMonitor\" ) @ Description ( \"An MBean created to show the ease of use of the pojo-mbean\" ) private class DemoMessagingMBean extends MessagingMBean { public DemoMessagingMBean ( ) throws MalformedObjectNameException { } } monitor = new DemoMessagingMBean ( ) ;", "del_tokens": "monitor = new MessagingMBean ( \"Demonstration\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "google", "-", "code", "-", "format", "as", "a", "maven", "plugin"], "add_tokens": "cl = ClassLoader . getSystemClassLoader ( ) ; // needed if nailgun classes are loaded in the boot // classpath.", "del_tokens": "cl = ClassLoader . getSystemClassLoader ( ) ; // needed if nailgun classes are loaded in the boot // classpath.", "commit_type": "add"}
{"commit_tokens": ["improve", "test", "/", "spec", "isolation"], "add_tokens": "Logger . warn ( \"starting ApplicationTest...\" ) ;", "del_tokens": "public ApplicationTest ( ) { Logger . warn ( \"starting ApplicationTest...\" ) ; }", "commit_type": "improve"}
{"commit_tokens": ["use", "dir", "mode", "instead", "of", "file", "mode"], "add_tokens": "super . zipDir ( null , zOut , dir + \"/\" , ZipFileSet . DEFAULT_DIR_MODE , JAR_MARKER ) ;", "del_tokens": "super . zipDir ( null , zOut , dir + \"/\" , ZipFileSet . DEFAULT_FILE_MODE , JAR_MARKER ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "basic", "stress", "test", "with", "JMeter", "and", "fixed", "leaked", "optionsBuilder"], "add_tokens": "ClientManager . configureWorker ( ) ;", "del_tokens": "ClientManager . configureWorker ( optionBuilder ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "documentation", "for", "property", "handler", "."], "add_tokens": ". volumes ( extractFromPropertiesAsList ( prefix + \".volumesFrom\" , properties ) )", "del_tokens": ". volumes ( extractFromPropertiesAsList ( prefix + \".volumes\" , properties ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "fail", "fast", "response", "configurable", "."], "add_tokens": "private MockResponse failFastResponse ; @ Override public MockResponse dispatch ( RecordedRequest request ) throws InterruptedException { if ( failFastResponse != null && responseQueue . peek ( ) == null ) { return failFastResponse ; @ Override public SocketPolicy peekSocketPolicy ( ) { MockResponse peek = responseQueue . peek ( ) ; if ( peek == null ) { return failFastResponse != null ? failFastResponse . getSocketPolicy ( ) : SocketPolicy . KEEP_OPEN ; } MockResponse failFastResponse = failFast ? new MockResponse ( ) . setResponseCode ( HttpURLConnection . HTTP_NOT_FOUND ) : null ; setFailFast ( failFastResponse ) ; } public void setFailFast ( MockResponse failFastResponse ) { this . failFastResponse = failFastResponse ;", "del_tokens": "private boolean failFast ; public MockResponse dispatch ( RecordedRequest request ) throws InterruptedException { if ( failFast && responseQueue . peek ( ) == null ) { return new MockResponse ( ) . setResponseCode ( 404 ) ; @ Override public SocketPolicy peekSocketPolicy ( ) { final MockResponse peek = responseQueue . peek ( ) ; if ( peek == null ) return SocketPolicy . KEEP_OPEN ; this . failFast = failFast ;", "commit_type": "make"}
{"commit_tokens": ["Removed", "a", "call", "to", "a", "deprecated", "method"], "add_tokens": "import org . dasein . cloud . network . RawAddress ; nic . setIpAddresses ( new RawAddress ( child . getFirstChild ( ) . getNodeValue ( ) . trim ( ) ) ) ;", "del_tokens": "nic . setIpAddress ( child . getFirstChild ( ) . getNodeValue ( ) . trim ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "exposing", "the", "tcp", "port", "-", "which", "allows", "us", "to", "use", "the", "TransportClient", "instead", "of", "the", "REST", "client", "on", "port", "9200"], "add_tokens": "* Represents an elasticsearch docker instance which exposes by default port 9200 and 9300 ( transport . tcp . port ) private static final int ELASTICSEARCH_DEFAULT_TCP_PORT = 9300 ; addExposedPort ( ELASTICSEARCH_DEFAULT_TCP_PORT ) ;", "del_tokens": "* Represents an elasticsearch docker instance which exposes by default port 9200.", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "layout", "information", "wasn", "t", "getting", "copied", "when", "internal", "element", "IDs", "changed", "."], "add_tokens": "if ( ! getDestination ( ) . equals ( that . getDestination ( ) ) ) return false ; if ( ! getSource ( ) . equals ( that . getSource ( ) ) ) return false ;", "del_tokens": "if ( ! getDestinationId ( ) . equals ( that . getDestinationId ( ) ) ) return false ; if ( ! getSourceId ( ) . equals ( that . getSourceId ( ) ) ) return false ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "ShellImpl", "from", "a", "plexus", "component", "to", "a", "POJO", "moved", "lookup", "of", "executor", "to", "the", "builder", ".", "ShellImpl", "s", "IO", "and", "Variables", "are", "now", "immutable"], "add_tokens": "import org . apache . maven . shell . command . CommandExecutor ; CommandExecutor executor = container . lookup ( CommandExecutor . class ) ; ShellImpl shell = new ShellImpl ( executor , io , variables ) ;", "del_tokens": "ShellImpl shell = ( ShellImpl ) getContainer ( ) . lookup ( Shell . class ) ; shell . setIo ( io != null ? io : new IO ( ) ) ; shell . setVariables ( variables != null ? variables : new Variables ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Changed", "Korean", "Proxy", "(", "not", "existing", "anymore", ")"], "add_tokens": "\"http://spectator.kr.\" + Constants . BASE_PATH ) ,", "del_tokens": "\"QFKR1PROXY.kassad.in:8088\" ) ,", "commit_type": "change"}
{"commit_tokens": ["move", "shell", "thread", "from", "Bootstrap", "to", "JLineShellComponent"], "add_tokens": "private Thread shellThread ; public void start ( ) { shellThread = new Thread ( this , \"Spring Shell\" ) ; shellThread . start ( ) ; running = true ; public void stop ( ) { running = false ; / * * * wait the shell command to complete by typing \"quit\" or \"exit\" * * / public void waitForComplete ( ) { try { shellThread . join ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } }", "del_tokens": "public void start ( ) { running = true ; public void stop ( ) { running = false ;", "commit_type": "move"}
{"commit_tokens": ["removed", "dtoClass", "and", "destClass", "options", "since", "they", "cause", "problems", "with", "Eclipse", "APT", "where", "each", "class", "match", "is", "handled", "separately"], "add_tokens": "@ Id long id ; } @ DTO public static class FooDTO { String bar ; @ Id int id ; @ CollectionOfElements List < String > names ; java . util . Date startDate ; public FooDTO ( ) { } public FooDTO ( long l ) { } public FooDTO ( long l , long r ) { }", "del_tokens": "@ DTO public Foo ( ) { } public Foo ( long l ) { } public Foo ( long l , long r ) { }", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "a", "crash", "with", "GroupLayerView", "position", "setting", "with", "a", "transform", "applied"], "add_tokens": "position = shapeTransform . getPosition ( ) . getObservable ( ) ;", "del_tokens": "position . setValue ( shapeTransform . getPosition ( ) . getInitialPoint ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "EvernoteApi", "to", "use", "GET"], "add_tokens": "import org . scribe . model . Verb ; @ Override protected Verb getRequestTokenVerb ( ) { return Verb . GET ; } @ Override protected Verb getAccessTokenVerb ( ) { return Verb . GET ; } {", "del_tokens": "{", "commit_type": "fix"}
{"commit_tokens": ["created", "privatewrapper", "factory", "2", "which", "calls", "createCustom", "View"], "add_tokens": "// @Override // @TargetApi(Build.VERSION_CODES.HONEYCOMB) // public View onCreateView(View parent, String name, @NonNull Context context, @NonNull AttributeSet attrs) { // return CalligraphyContextWrapper.onActivityCreateView(this, parent, super.onCreateView(parent, name, context, attrs), name, context, attrs); // }", "del_tokens": "import android . annotation . TargetApi ; import android . os . Build ; import android . support . annotation . NonNull ; import android . util . AttributeSet ; import android . view . View ; @ Override @ TargetApi ( Build . VERSION_CODES . HONEYCOMB ) public View onCreateView ( View parent , String name , @ NonNull Context context , @ NonNull AttributeSet attrs ) { return CalligraphyContextWrapper . onActivityCreateView ( this , parent , super . onCreateView ( parent , name , context , attrs ) , name , context , attrs ) ; }", "commit_type": "create"}
{"commit_tokens": ["added", "metadata", "and", "currency", "attributes", "to", "card", "charges", "request"], "add_tokens": "import java . util . Map ; import mx . openpay . client . enums . Currency ; * The amount to charge to the card . Required . * / / * * * A currency to give to the charge . Optional . < br > * Default value is MXN < br > * < br > * * See @ * * @ param currency * @ return * / public CreateCardChargeParams currency ( final Currency currency ) { return this . with ( \"currency\" , currency . name ( ) ) ; } / * * * * @ param metadata * @ return * / public CreateCardChargeParams metadata ( final Map < String , String > metadata ) { return this . with ( \"metadata\" , metadata ) ; }", "del_tokens": "* The amount to charge to the card , in MXN . Required . * /", "commit_type": "add"}
{"commit_tokens": ["added", "small", "docu", "for", "multi", "argumetn", "functions"], "add_tokens": "* @ param values * the values to which the function should be applied . public abstract double applyFunction ( double [ ] values ) ; @ Override", "del_tokens": "* @ param value * the value the function should be applied to public abstract double applyFunction ( double ... value ) ; @ Override", "commit_type": "add"}
{"commit_tokens": ["adding", "support", "for", "jackson", "date", "formatting"], "add_tokens": "import com . fasterxml . jackson . databind . SerializerProvider ; import org . junit . runner . RunWith ; import org . powermock . api . mockito . PowerMockito ; import org . powermock . core . classloader . annotations . PrepareForTest ; import org . powermock . modules . junit4 . PowerMockRunner ; @ RunWith ( PowerMockRunner . class ) @ PrepareForTest ( SerializerProvider . class ) SerializerProvider serializerProvider ; // has to be mocked with powermock due to final methods serializerProvider = PowerMockito . mock ( SerializerProvider . class ) ; sut = new JsonWriter ( serializerProvider , jgen , result , 10000 ) ; verify ( serializerProvider , times ( 1 ) ) . defaultSerializeDateValue ( dt , jgen ) ;", "del_tokens": "sut = new JsonWriter ( jgen , result , 10000 ) ; verify ( jgen , times ( 1 ) ) . writeNumber ( dt . getTime ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "memory", "leak", "caused", "by", "ShutdownThread", "retaining", "Server", "instances", "."], "add_tokens": "// Jetty Server instances are held by the ShutdownThread, and may not be GCed // Normally this isn't too big of a problem, but in test cases many Server instances may // start and stop. Deregister it manually, and release the Handler (which holds all our stuff) // so it can GC even if someone else holds a Server reference server . setHandler ( null ) ; server . setStopAtShutdown ( false ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Adding", "methods", "getSolution", "()", "to", "XReal", "and", "XInt"], "add_tokens": "x = randSphere ( 2 , 100 , 500 ) ;", "del_tokens": "import jmetal . core . Solution ; x = randSphere ( 2 , 0.0 , 1.0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Collections", ".", "isNullOrEmpty", "()", "."], "add_tokens": "import org . fest . assertions . internal . * ; private Collections collections = Collections . instance ( ) ; collections . assertNullOrEmpty ( info , actual ) ; @ VisibleForTesting final void updateCollections ( Collections newCollections ) { collections = newCollections ; }", "del_tokens": "import org . fest . assertions . internal . Objects ; // TODO Auto-generated method stub", "commit_type": "implement"}
{"commit_tokens": ["Added", "resource", "loadable", "getActualUrl", "()", "to", "be", "used", "outside", "of", "UrlUtilities", "to", "allow", "loading", "of", "local", "resources", "."], "add_tokens": "import java . net . MalformedURLException ; URL u = getActualUrl ( url ) ; URL u = getActualUrl ( url ) ; public static URL getActualUrl ( String url ) throws MalformedURLException { Matcher m = resPattern . matcher ( url ) ; return m . find ( ) ? UrlUtilities . class . getClassLoader ( ) . getResource ( url . substring ( m . end ( ) ) ) : new URL ( url ) ; }", "del_tokens": "Matcher m = resPattern . matcher ( url ) ; URL u = m . find ( ) ? UrlUtilities . class . getClassLoader ( ) . getResource ( url . substring ( m . end ( ) ) ) : new URL ( url ) ; Matcher m = resPattern . matcher ( url ) ; URL u = m . find ( ) ? UrlUtilities . class . getClassLoader ( ) . getResource ( url . substring ( m . end ( ) ) ) : new URL ( url ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "BETWEEN", "BEGINS_WITH", "CONTAINS", "scan", "filters", "(", "with", "tests", ")", "."], "add_tokens": "v1Filter . put ( key , v1Condition ) ;", "del_tokens": "v2Filter . put ( key , v2Condition ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "flaky", "tests", "in", "GitRepositoryTest"], "add_tokens": "repo . commit ( Revision . HEAD , Author . UNKNOWN , TEST_MESSAGE_SUMMARY , change ) . join ( ) ; repo . commit ( Revision . HEAD , Author . UNKNOWN , TEST_MESSAGE_SUMMARY , jsonUpserts [ 0 ] ) . join ( ) ; repo . commit ( Revision . HEAD , Author . UNKNOWN , TEST_MESSAGE_SUMMARY , jsonUpserts [ 0 ] ) . join ( ) ;", "del_tokens": "repo . commit ( Revision . HEAD , Author . UNKNOWN , TEST_MESSAGE_SUMMARY , change ) ; repo . commit ( Revision . HEAD , Author . UNKNOWN , TEST_MESSAGE_SUMMARY , jsonUpserts [ 0 ] ) ; repo . commit ( Revision . HEAD , Author . UNKNOWN , TEST_MESSAGE_SUMMARY , jsonUpserts [ 0 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "embedded", "collection", "recursion", "."], "add_tokens": "Class < ? > componentType = field . getType ( ) . getComponentType ( ) ; TypeUtils . checkForNoArgConstructor ( componentType ) ; visitor . visitClass ( componentType ) ; Class < ? > componentType = TypeUtils . getComponentType ( field . getType ( ) , field . getGenericType ( ) ) ; TypeUtils . checkForNoArgConstructor ( componentType ) ; EmbeddedCollectionSetter setter = new EmbeddedCollectionSetter ( field ) ; Visitor visitor = new Visitor ( this . setterChain . extend ( setter ) , this . prefix + field . getName ( ) , unindexed ) ; visitor . visitClass ( componentType ) ; else // not embedded, so we're at a leaf object (including arrays and collections of basic types)", "del_tokens": "TypeUtils . checkForNoArgConstructor ( field . getType ( ) . getComponentType ( ) ) ; visitor . visitClass ( field . getType ( ) ) ; throw new UnsupportedOperationException ( \"@Embedded arrays not supported yet\" ) ; else // not embedded, so we're at a leaf object (including arrays of basic types)", "commit_type": "fix"}
{"commit_tokens": ["move", "all", "hash", "computation", "to", "Prefix", ".", "hashCode"], "add_tokens": "int h ; h = data . length == 0 ? 0 : data [ 0 ] + data [ data . length - 1 ] << 8 ; h ^= ( h >>> 20 ) ^ ( h >>> 12 ) ; return h ^ ( h >>> 7 ) ^ ( h >>> 4 ) ;", "del_tokens": "return data . length == 0 ? 0 : data [ 0 ] + data [ data . length - 1 ] << 8 ;", "commit_type": "move"}
{"commit_tokens": ["add", "example", "of", "integrating", "with", "Jersey", "JAX", "-", "RS"], "add_tokens": "* @ param cipherText the encrypted content of the token // FIXME not thread safe", "del_tokens": "* @ param cipherText the encrypted content of the token // FIXME not thead safe", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "hasAvp", "with", "Vendor", "-", "Id", "."], "add_tokens": "return hasAvp ( code , 0L ) ; } protected boolean hasAvp ( int code , long vendorId ) { return avpSet . getAvp ( code , vendorId ) != null ;", "del_tokens": "Avp rawAvp = avpSet . getAvp ( code ) ; if ( rawAvp != null ) { return true ; } return false ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "with", "extra", "comma", "in", "json", "object"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; values = filterNullValues ( values ) ; out . write ( values [ i ] . toString ( ) ) ; private Object [ ] filterNullValues ( Object [ ] values ) { List < Object > list = new ArrayList < > ( values . length ) ; for ( Object value : values ) { if ( value != null ) { list . add ( value ) ; } } return list . toArray ( ) ; }", "del_tokens": "if ( values [ i ] == null ) { continue ; } out . write ( values [ i ] . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "ES7", "distribution", "files"], "add_tokens": "final String classifier , super ( ELASTICSEARCH_GROUPID , artifactId , version , classifier , type ) ; return type ;", "del_tokens": "public static final String ELASTICSEARCH_TYPE = \"zip\" ; public ElasticsearchArtifact ( final String artifactId , final String version ) { this ( ELASTICSEARCH_GROUPID , artifactId , version , ELASTICSEARCH_TYPE ) ; } final String groupId , super ( groupId , artifactId , version , null , type ) ; return ELASTICSEARCH_TYPE ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "all", "107", "deps", "to", "107", "module", "and", "cleaned", "up", "API", "to", "be", "107", "free"], "add_tokens": "import org . ehcache . config . CacheConfiguration ; public interface CacheManager { < K , V > Cache < K , V > createCache ( final String alias , final CacheConfiguration < K , V > config ) ; < K , V > Cache < K , V > getCache ( final String s ) ; void close ( ) ;", "del_tokens": "public interface CacheManager extends javax . cache . CacheManager {", "commit_type": "move"}
{"commit_tokens": ["Added", "new", "copyright", "text", "message", "for", "description", "removal", "."], "add_tokens": "\"+++ Due to legal reasons the video is only available in Germany.+++\" , \"+++ Aus rechtlichen Gründen kann das Video nur in Deutschland abgerufen werden. +++\"", "del_tokens": "\"+++ Due to legal reasons the video is only available in Germany.+++\"", "commit_type": "add"}
{"commit_tokens": ["Use", "execSQL", "for", "executable", "queries", "."], "add_tokens": "Ollie . execSQL ( getSql ( ) , getArgs ( ) ) ;", "del_tokens": "Ollie . rawQuery ( mTable , getSql ( ) , getArgs ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "to", "follow", "symlink", "at", "/", "opt", "/", "netbeans"], "add_tokens": "\"/opt/netbeans/bin/netbeans\" ,", "del_tokens": "\"/opt/netbeans-8.0.2/bin/netbeans\" ,", "commit_type": "change"}
{"commit_tokens": ["removed", "exception", "test", "from", "DialogFeedback"], "add_tokens": "startActivity ( Intent . createChooser ( sendMailtoGmail , \"\" ) ) ;", "del_tokens": "startActivity ( Intent . createChooser ( sendMailtoGmail , \"\" ) ) ; if ( 2 + 2 == 4 ) { throw new ActivityNotFoundException ( \"excepcion de prueba\" ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Move", "SPI", "target", "to", "macro"], "add_tokens": "AntClassLoader loader = new AntClassLoader ( parent , getProject ( ) , classpath , false ) ; return loader ;", "del_tokens": "return new AntClassLoader ( parent , getProject ( ) , classpath , false ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "avatar", "exceptions", "on", "302", "redirect", "responses"], "add_tokens": "if ( response . getCode ( ) == 301 || response . getCode ( ) == 302 ) {", "del_tokens": "if ( response . getCode ( ) == 301 ) {", "commit_type": "fix"}
{"commit_tokens": ["Created", "more", "ClusterChain", "tests", "fixed", "ClusterChain", "off", "-", "by", "-", "one", "error", "in", "writing", "."], "add_tokens": "( int ) ( clusterSize - ( offset % clusterSize ) ) ) ;", "del_tokens": "( int ) ( clusterSize - ( offset % clusterSize ) - 1 ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Made", "service", "broker", "more", "generic", "so", "that", "we", "build", "a", "REST", "endpoint", "using", "Spring", "MVC", "."], "add_tokens": "* Service providers must implement this interface . * void delete ( String instanceId ) throws ResourceNotFoundException ; ServiceBinding bind ( BindRequest request ) throws ResourceNotFoundException ; void unbind ( String instanceId , String bindingId ) throws ResourceNotFoundException ;", "del_tokens": "void delete ( String instanceId ) ; ServiceBinding bind ( BindRequest request ) ; void unbind ( String instanceId , String bindingId ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "tests", "for", "time", "support"], "add_tokens": "* Thread - safe date converter for heavily reused date formats . java . lang . ThreadLocal < DateFormat > ( ) { protected DateFormat initialValue ( ) { java . lang . ThreadLocal < DateFormat > ( ) { protected DateFormat initialValue ( ) { java . lang . ThreadLocal < DateFormat > ( ) { protected DateFormat initialValue ( ) {", "del_tokens": "* Threadsafe date converter . java . lang . ThreadLocal ( ) { protected Object initialValue ( ) { java . lang . ThreadLocal ( ) { protected Object initialValue ( ) { java . lang . ThreadLocal ( ) { protected Object initialValue ( ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "push", "operation", "to", "use", "the", "asynchronous", "endpoints", "and", "removed", "old", "workarounds", "that", "are", "no", "longer", "necessary", "."], "add_tokens": "this ( null , username , apiKey , clientApiVersion ) ; this ( base , username , apiKey , clientApiVersion , false ) ; this ( base , username , apiKey , clientApiVersion , logHttp , false ) ; public ZanataProxyFactory ( URI base , String username , String apiKey , VersionInfo clientApiVersion , boolean logHttp , boolean disableSSLCert ) { super ( base , username , apiKey , clientApiVersion , logHttp , disableSSLCert ) ;", "del_tokens": "import org . jboss . resteasy . client . ClientExecutor ; super ( null , username , apiKey , clientApiVersion ) ; super ( base , username , apiKey , null , clientApiVersion , false ) ; super ( base , username , apiKey , null , clientApiVersion , logHttp ) ; public ZanataProxyFactory ( URI base , String username , String apiKey , ClientExecutor executor , VersionInfo clientApiVersion , boolean logHttp ) { super ( base , username , apiKey , executor , clientApiVersion , logHttp ) ; } public IFixedSourceDocResource getFixedSourceDocResources ( String projectSlug , String versionSlug ) { return createProxy ( IFixedSourceDocResource . class , getFixedSourceDocResourcesURI ( projectSlug , versionSlug ) ) ; } public URI getFixedSourceDocResourcesURI ( String projectSlug , String versionSlug ) { return super . getResourceURI ( projectSlug , versionSlug ) ; } public IFixedCopyTransResource getFixedCopyTransResource ( ) { return createProxy ( IFixedCopyTransResource . class ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "more", "license", "excludes", "(", "intellij", "git", "md", ")"], "add_tokens": "* Goal that generates the services files", "del_tokens": "* Goal that generates the servces files", "commit_type": "add"}
{"commit_tokens": ["Use", "more", "lightweight", "dependencies", "."], "add_tokens": "results = _GLOSSARY . search ( \"latest\" , search . paramMap ( ) , EnumSet . of ( Glossary . Category . SOLID_TUMOR ) ) ; results = _GLOSSARY . search ( \"latest\" , search . paramMap ( ) , EnumSet . of ( Glossary . Category . SOLID_TUMOR , Glossary . Category . HEMATO ) ) ;", "del_tokens": "search . setCategory ( EnumSet . of ( Glossary . Category . SOLID_TUMOR ) ) ; results = _GLOSSARY . search ( \"latest\" , search . paramMap ( ) ) ; search . setCategory ( EnumSet . of ( Glossary . Category . SOLID_TUMOR , Glossary . Category . HEMATO ) ) ; results = _GLOSSARY . search ( \"latest\" , search . paramMap ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "missing", "licenses", "and", "javadoc", "requirements"], "add_tokens": "/ * * * Copyright 2013 - 2014 Linagora , Universit é oseph ourier * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / * Bean used to inject an data into a { @ link Import } template . * @ author gcrosmarie - Linagora", "del_tokens": "* Bean used to inject an data into a { @ link Import } template * @ author gcrosmarie", "commit_type": "add"}
{"commit_tokens": ["Remove", "hashCode", "()", "and", "equals", "()", "from", "TraceImpl"], "add_tokens": "/* for testing purpose only */ protected ShallowTrace getShallowTrace ( ) { return _shallowTrace ; }", "del_tokens": "@ Override public boolean equals ( final Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; final TraceImpl trace = ( TraceImpl ) o ; return _shallowTrace . equals ( trace . _shallowTrace ) && _related . equals ( trace . _related ) ; } @ Override public int hashCode ( ) { int result = _shallowTrace . hashCode ( ) ; result = 31 * result + _related . hashCode ( ) ; return result ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "withdrawal", "fees", "to", "fees", "endpoint"], "add_tokens": "HashMap < String , BitsoFee . Fee > fees = bitsoFee . getTradeFees ( ) ; HashMap < String , String > withdrawalFees = bitsoFee . getWithdrawalFees ( ) ; assertEquals ( ( withdrawalFees != null ) , true ) ; // @Test totalExpectedOpenOrders = ( book . getBook ( ) . equals ( \"btc_mxn\" ) || book . getBook ( ) . equals ( \"eth_btc\" ) ) ? totalOpenOrders : 0 ;", "del_tokens": "HashMap < String , BitsoFee . Fee > fees = bitsoFee . getFees ( ) ; //@Test totalExpectedOpenOrders = ( book . getBook ( ) . equals ( \"btc_mxn\" ) || book . getBook ( ) . equals ( \"eth_btc\" ) ) ? totalOpenOrders : 0 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "ability", "to", "set", "the", "timeout"], "add_tokens": "private int httpSocketTimeoutMS = 30000 ; private int httpConnectTimeoutMS = 3000 ; / * * * Allow to set the timeout * @ param connectTimeout connection timeout in MS * @ param readTimeout socket timeout in MS * / public void setTimeout ( int connectTimeout , int readTimeout ) { httpSocketTimeoutMS = readTimeout ; httpConnectTimeoutMS = connectTimeout ; } . setSocketTimeout ( httpSocketTimeoutMS ) . setConnectTimeout ( httpConnectTimeoutMS ) . setConnectionRequestTimeout ( httpConnectTimeoutMS )", "del_tokens": "private final static int HTTP_TIMEOUT_MS = 30000 ; . setSocketTimeout ( HTTP_TIMEOUT_MS ) . setConnectTimeout ( HTTP_TIMEOUT_MS ) . setConnectionRequestTimeout ( HTTP_TIMEOUT_MS )", "commit_type": "add"}
{"commit_tokens": ["Change", "access", "modifiers", "in", "ValidationMessage"], "add_tokens": "public String [ ] getArguments ( ) { void setArguments ( String [ ] arguments ) {", "del_tokens": "String [ ] getArguments ( ) { public void setArguments ( String [ ] arguments ) {", "commit_type": "change"}
{"commit_tokens": ["removing", "from", "logic", ";", "unused", "."], "add_tokens": "* @ deprecated Unused , use { @ link Archiver # setDuplicateBehavior ( String ) } instead .", "del_tokens": "* @ deprecated Use { @ link Archiver # setDuplicateBehavior ( String ) } instead . setDuplicateBehavior ( duplicate ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "catch", "and", "throw", "where", "inner", "exception", "where", "not", "attached"], "add_tokens": "throw new Sql2oException ( \"An error occurred while executing StatementRunnableWithResult. Transaction rolled back.\" , throwable ) ;", "del_tokens": "throw new Sql2oException ( \"An error occurred while executing StatementRunnableWithResult. Transaction rolled back.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "the", "delete", "test", "(", "made", "deleted", "repository", "name", "matching", "more", "strict", ")"], "add_tokens": "assertFalse ( curl ( LIST_PATH ) . contains ( \"\\\"\" + NEW_LOCAL + \"\\\"\" ) ) ;", "del_tokens": "assertFalse ( curl ( LIST_PATH ) . contains ( NEW_LOCAL ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "sql2o", "so", "that", "is", "can", "set", "private", "fields", "and", "methods", "."], "add_tokens": "for ( Field f : clazz . getDeclaredFields ( ) ) { for ( Method m : clazz . getDeclaredMethods ( ) ) {", "del_tokens": "for ( Field f : clazz . getFields ( ) ) { for ( Method m : clazz . getMethods ( ) ) {", "commit_type": "change"}
{"commit_tokens": ["Allow", "more", "characters", "in", "the", "path", "of", "a", "url", "."], "add_tokens": "private static final String pct_encoded = \"(%\\\\p{XDigit}{2})\" ; private static final String pchar = \"[\\\\w~!$&'*+,;=:@\\\\(\\\\)\\\\.\\\\-]|\" + pct_encoded ; \"(/(\" + pchar + \")+)*/?\" \"#(\" + pchar + \"|[/?])*\"", "del_tokens": "\"(/([\\\\w\\\\(\\\\)\\\\.\\\\-]|(%\\\\p{XDigit}{2}))+)*/?\" \"#([\\\\w&\\\\-=]|(%\\\\p{XDigit}{2}))*\"", "commit_type": "allow"}
{"commit_tokens": ["Fix", "potential", "NPE", "and", "support", "for", "new", "Windows"], "add_tokens": "Properties pr = getEnvironmentVariables ( ) ; String systemRoot = pr . getProperty ( \"SystemRoot\" ) ; String fileSeperator = System . getProperty ( \"file.separator\" ) ; FontFactory . registerDirectory ( systemRoot + fileSeperator + \"fonts\" ) ; // Ignore if ( operatingSystem . startsWith ( \"windows 95\" ) || operatingSystem . startsWith ( \"windows 98\" ) || operatingSystem . startsWith ( \"me\" ) ) { } else if ( operatingSystem . startsWith ( \"windows\" ) ) { // Modern windows", "del_tokens": "Properties pr = null ; pr = getEnvironmentVariables ( ) ; String systemRoot = pr . getProperty ( \"SystemRoot\" ) ; String fileSeperator = System . getProperty ( \"file.separator\" ) ; FontFactory . registerDirectory ( systemRoot + fileSeperator + \"fonts\" ) ; if ( operatingSystem . indexOf ( \"windows 95\" ) > - 1 || operatingSystem . indexOf ( \"windows 98\" ) > - 1 || operatingSystem . indexOf ( \"me\" ) > - 1 ) { } else if ( ( operatingSystem . indexOf ( \"nt\" ) > - 1 ) || ( operatingSystem . indexOf ( \"windows 2000\" ) > - 1 ) || ( operatingSystem . indexOf ( \"windows xp\" ) > - 1 ) || ( operatingSystem . indexOf ( \"windows 2003\" ) > - 1 ) || ( operatingSystem . indexOf ( \"windows vista\" ) > - 1 ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "to", "the", "current", "ReactFX", "snapshot", "."], "add_tokens": ". filter ( ( p , f ) -> p != null ) . subscribe ( ( p , f ) -> positionPopup ( p , f ) ) ) ;", "del_tokens": "import static org . reactfx . util . Tuples . * ; . by ( ( popup , adjustment ) -> t ( popup , adjustment ) ) . filter ( t -> t . _1 != null ) . subscribe ( t -> positionPopup ( t . _1 , t . _2 ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "(", "ugly", ")", "turn", "around", "for", "broken", "pipe", "..."], "add_tokens": "for ( int i = 0 ; i < 8 ; i ++ ) { int size = ( int ) Math . pow ( 10.0 , ( double ) i ) ; sfile . delete ( ) ;", "del_tokens": "for ( int i = 0 ; i < 20 ; i ++ ) { int size = i * 100000 ;", "commit_type": "add"}
{"commit_tokens": ["make", "unlink", "/", "link", "methods", "return", "the", "updated", "UserProfile"], "add_tokens": "import com . auth0 . android . auth0 . lib . result . UserProfile ; public Request < UserProfile , ManagementException > link ( String primaryUserId , String primaryToken , String secondaryToken ) { return factory . POST ( url , client , gson , UserProfile . class , mgmtErrorBuilder ) public Request < UserProfile , ManagementException > unlink ( String primaryUserId , String primaryToken , String secondaryUserId , String secondaryProvider ) { return factory . DELETE ( url , client , gson , UserProfile . class , mgmtErrorBuilder )", "del_tokens": "public Request < Void , ManagementException > link ( String primaryUserId , String primaryToken , String secondaryToken ) { return factory . POST ( url , client , gson , mgmtErrorBuilder ) public Request < Void , ManagementException > unlink ( String primaryUserId , String primaryToken , String secondaryUserId , String secondaryProvider ) { return factory . DELETE ( url , client , gson , mgmtErrorBuilder )", "commit_type": "make"}
{"commit_tokens": ["Fix", "to", "find", "maven", "wrapper", "timing"], "add_tokens": "Executors . newSingleThreadExecutor ( ) . submit ( ( ) -> MavenUtils . findAndInstall ( pomFile . getParentFile ( ) . toPath ( ) ) ) ;", "del_tokens": "Executors . newSingleThreadExecutor ( ) . submit ( ( ) -> MavenUtils . findAndInstall ( projectDir . toPath ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "performance", "test", "for", "ImVectorImpl", "to", "be", "sure", "that", "future", "changes", "don", "t", "decrease", "performance", "."], "add_tokens": "public static final < T > ImVectorImpl < T > empty ( ) { return ( ImVectorImpl < T > ) EMPTY ; }", "del_tokens": "public static final < T > ImList < T > empty ( ) { return ( ImVectorImpl < T > ) EMPTY ; }", "commit_type": "add"}
{"commit_tokens": ["Removed", "overloaded", "constructor", "to", "prevent", "breaking", "API", "change"], "add_tokens": "public void testConstructor ( ) throws Exception { request . setActionUrlWithString ( \"http://test.com\" ) ; request . setActionUrlWithString ( \"http://test.com\" ) ;", "del_tokens": "public void testConstructor_Integer_URL ( ) throws Exception { @ Test public void testConstructor_Integer_String ( ) throws Exception { request = new PiwikRequest ( 3 , \"test\" ) ; assertEquals ( new Integer ( 3 ) , request . getSiteId ( ) ) ; assertTrue ( request . getRequired ( ) ) ; assertEquals ( \"test\" , request . getActionUrlAsString ( ) ) ; assertNotNull ( request . getVisitorId ( ) ) ; assertNotNull ( request . getRandomValue ( ) ) ; assertEquals ( \"1\" , request . getApiVersion ( ) ) ; assertFalse ( request . getResponseAsImage ( ) ) ; } request = new PiwikRequest ( 3 , \"http://test.com\" ) ; request = new PiwikRequest ( 3 , \"http://test.com\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "method", "that", "returns", "supported", "file", "types"], "add_tokens": "import java . util . * ; private static final Set < String > SUPPORTED_TYPE = new HashSet < > ( Arrays . asList ( \"**/*.graphml\" ) ) ; @ Override public Set < String > getSupportedFileTypes ( ) { return SUPPORTED_TYPE ; }", "del_tokens": "import java . util . ArrayList ; import java . util . HashMap ; import java . util . List ; import java . util . Map ;", "commit_type": "add"}
{"commit_tokens": ["Add", "back", "support", "for", "building", "RDF", "response", "."], "add_tokens": "import org . carewebframework . cal . api . domain . IPatient ; public static boolean validateRequest ( Map < String , String > params ) { IPatient patient = PatientContext . getActivePatient ( ) ; public SmartAPI ( String pattern , String capability , String ztyp ) { super ( pattern , ContentType . RDF , capability ) ; this . ztyp = ztyp ; }", "del_tokens": "import org . carewebframework . vista . api . domain . Patient ; public SmartAPI ( String pattern , String capability , String ztyp ) { super ( pattern , ContentType . RDF , capability ) ; this . ztyp = ztyp ; } public boolean validateRequest ( Map < String , String > params ) { Patient patient = PatientContext . getCurrentPatient ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "reserved", "words"], "add_tokens": "public OrderSpecifier < D > desc ( ) { return Grammar . desc ( this ) ; } public ExprBoolean after ( Expr < D > right ) { return Grammar . after ( this , right ) ; } public ExprBoolean after ( D right ) { return Grammar . after ( this , right ) ; } public ExprBoolean between ( D first , D second ) { return Grammar . between ( this , first , second ) ; } private final Class < D > type ; this . type = type ; public ExprEntity < D > get ( int index ) { return new PathEntity < D > ( type , path + \"[\" + index + \"]\" ) ; }", "del_tokens": "public ExprBoolean after ( Expr < D > right ) { return Grammar . after ( this , right ) ; } public ExprBoolean after ( D right ) { return Grammar . after ( this , right ) ; } public ExprBoolean between ( D first , D second ) { return Grammar . between ( this , first , second ) ; } public OrderSpecifier < D > desc ( ) { return Grammar . desc ( this ) ; }", "commit_type": "add"}
{"commit_tokens": ["Updated", "thread", "sleep", "time", "for", "reading", "thread", "in", "mgcp", "client"], "add_tokens": "Thread . currentThread ( ) . sleep ( latency ) ;", "del_tokens": "Thread . currentThread ( ) . sleep ( delay ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "tracking", "of", "the", "statement", "type", "all", "the", "way", "to", "the", "compiled", "statement", "."], "add_tokens": "import com . j256 . ormlite . stmt . StatementBuilder . StatementType ; private final StatementType type ; public AndroidCompiledStatement ( String sql , SQLiteDatabase db , StatementType type ) { this . type = type ; if ( type != StatementType . SELECT ) { throw new IllegalArgumentException ( \"Cannot call executeQuery on a \" + type + \" statement\" ) ; } if ( type == StatementType . SELECT ) { throw new IllegalArgumentException ( \"Cannot call executeUpdate on a \" + type + \" statement\" ) ; }", "del_tokens": "public AndroidCompiledStatement ( String sql , SQLiteDatabase db ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "when", "adding", "child", "to", "tab", "menu", "pane", "."], "add_tokens": "setInnerComponent ( div ) ;", "del_tokens": "associateComponent ( div ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "direct", "upload", "option", "and", "expose", "it", "as", "a", "config", "option", "."], "add_tokens": "insert . getMediaHttpUploader ( ) . setDirectUploadEnabled ( isDirectUploadEnabled ( ) ) ;", "del_tokens": "* @ throws IOException on IO error * @ throws IOException on IO error", "commit_type": "implement"}
{"commit_tokens": ["Added", "HTTP", "503", "error", "and", "message"], "add_tokens": "AUTHORISATION_FAILURE , / * * Service Unavailable , usually temporary * / HTTP_503_ERROR ;", "del_tokens": "AUTHORISATION_FAILURE ;", "commit_type": "add"}
{"commit_tokens": ["removed", "an", "unused", "import", "and", "fixed", "up", "overview", "javadoc"], "add_tokens": "* MyCommandLineRunner ( String [ ] args ) throws CmdLineException { * super ( args ) ; * } * try { * ( new MyCommandLineRunner ( args ) ) . run ( ) ; * } catch ( CmdLineException e ) { * System . exit ( - 1 ) ; * }", "del_tokens": "import com . google . javascript . jscomp . AbstractCommandLineRunner . CommandLineConfig ; * MyCommandLineRunner ( String [ ] args ) { super ( args ) ; } * ( new MyCommandLineRunner ( args ) ) . run ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "up", "the", "use", "of", "local", "variables", "-", "in", "particular", "inside", "for", "loops"], "add_tokens": "private boolean definingParameters ; int iteratorIdx = this . defineVariable ( createIteratorName ( ) , \"java.util.Iterator\" ) . getIndex ( ) ; int iIdx = this . defineVariable ( loop . getVariable ( ) , \"java.lang.Object\" ) . getIndex ( ) ; cv . visitVarInsn ( ASTORE , iteratorIdx ) ; cv . visitVarInsn ( ALOAD , iteratorIdx ) ; cv . visitVarInsn ( ASTORE , iIdx ) ; cv . visitVarInsn ( ALOAD , iteratorIdx ) ; definingParameters = true ; definingParameters = false ; if ( ! definingParameters && ! leftHandExpression ) { // using new variable inside a comparison expression // so lets initialize it too cv . visitInsn ( ACONST_NULL ) ; cv . visitVarInsn ( ASTORE , idx ) ; } protected String createIteratorName ( ) { return \"__iterator\" + idx ;", "del_tokens": "cv . visitVarInsn ( ASTORE , ++ idx ) ; cv . visitVarInsn ( ALOAD , idx ) ; cv . visitVarInsn ( ASTORE , ++ idx ) ; cv . visitVarInsn ( ALOAD , -- idx ) ; / * * * @ return looks up the given variable name * / protected Variable lookupVariable ( String name ) { Variable answer = ( Variable ) variableStack . get ( name ) ; if ( answer == null ) { throw new ClassGeneratorException ( \"Undefined variable: \" + name ) ; } return answer ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "one", "more", "ClusterChain", "test", "."], "add_tokens": "private final boolean readOnly ; return getChainLength ( ) * clusterSize ; / * * * Determines the length of this { @ code ClusterChain } in clusters . * * @ return the length of this chain * / public final int getChainLength ( ) { if ( getStartCluster ( ) == 0 ) return 0 ; final long [ ] chain = getFat ( ) . getChain ( getStartCluster ( ) ) ; return chain . length ; } public final void setChainLength ( int nrClusters ) throws IOException {", "del_tokens": "private final boolean readOnly ; final long [ ] chain = getFat ( ) . getChain ( getStartCluster ( ) ) ; return ( ( long ) chain . length ) * clusterSize ; public void setChainLength ( int nrClusters ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["changed", "fileinput", "/", "fileoutput", "streams", "to", "more", "general", "input", "/", "output", "streams"], "add_tokens": "import java . io . OutputStream ; private OutputStream outputStream ; * @ param outputStream OutputStream - will be closed by this class public BioPAXMarshallerImp ( BioPAXLevel bpLevel , OutputStream outputStream , int numEntries ) { this . outputStream = outputStream ; simpleExporter . convertToOWL ( completeModel , outputStream ) ; outputStream . close ( ) ;", "del_tokens": "import java . io . FileOutputStream ; private FileOutputStream fileOutputStream ; * @ param fileOutputStream FileOutputStream - will be closed by this class public BioPAXMarshallerImp ( BioPAXLevel bpLevel , FileOutputStream fileOutputStream , int numEntries ) { this . fileOutputStream = fileOutputStream ; simpleExporter . convertToOWL ( completeModel , fileOutputStream ) ; fileOutputStream . close ( ) ;", "commit_type": "change"}
{"commit_tokens": ["creates", "WaspResponse", "and", "pass", "it", "to", "callBack", "in", "MockFactory", "."], "add_tokens": "import java . util . Collections ; WaspResponse waspResponse = new WaspResponse ( waspRequest . getUrl ( ) , statusCode , Collections . EMPTY_MAP , responseString , responseString . length ( ) , 0 ) ; callBack . onSuccess ( ( T ) waspResponse ) ;", "del_tokens": "callBack . onSuccess ( ( T ) responseString ) ;", "commit_type": "create"}
{"commit_tokens": ["Changed", "client_secrets", "auth", "to", "use", "accessToken", "works", "remotely"], "add_tokens": "import com . google . api . client . googleapis . auth . oauth2 . GoogleCredential ; genomics = factory . fromCredential ( new GoogleCredential ( ) . setAccessToken ( options . getAccessToken ( ) ) ) ; options . getAccessToken ( ) , VARIANT_FIELDS ) ) )", "del_tokens": "genomics = factory . fromClientSecretsFile ( options . getClientSecretsFile ( ) ) ; options . getClientSecretsFile ( ) , VARIANT_FIELDS ) ) )", "commit_type": "change"}
{"commit_tokens": ["Changed", "fields", "to", "protected", "."], "add_tokens": "protected ServiceRegistry serviceRegistry ; protected RequestContextBuilder requestContextBuilder = new DefaultRequestContextBuilder ( ) ; protected EndpointAuthorizationChecker endpointAuthorizationChecker = new EmptyAuthorizationChecker ( ) ; protected EndpointMarshaller endpointMarshaller = new EndpointMarshaller ( ) ; protected EndpointExceptionHandler endpointExceptionHandler = new DefaultEndpointExceptionHandler ( ) ;", "del_tokens": "private ServiceRegistry serviceRegistry ; private RequestContextBuilder requestContextBuilder = new DefaultRequestContextBuilder ( ) ; private EndpointAuthorizationChecker endpointAuthorizationChecker = new EmptyAuthorizationChecker ( ) ; private EndpointMarshaller endpointMarshaller = new EndpointMarshaller ( ) ; private EndpointExceptionHandler endpointExceptionHandler = new DefaultEndpointExceptionHandler ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "NPE", "when", "wrapping", "http", "status", "code", "for", "protobuffer", "serialisation", "."], "add_tokens": "// Response entity might be null ( null == response . getEntity ( ) || ! response . getEntity ( ) . getClass ( ) . isAnnotationPresent ( SkipProtoWrapper . class ) ) ) {", "del_tokens": "! response . getEntity ( ) . getClass ( ) . isAnnotationPresent ( SkipProtoWrapper . class ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "loading", "of", "quick", "-", "modelinfo", ".", "xml", "from", "classpath"], "add_tokens": "return JAXB . unmarshal ( QuickModelHelper . class . getResourceAsStream ( \"/org/hl7/fhir/quick-modelinfo.xml\" ) ,", "del_tokens": "return JAXB . unmarshal ( QuickModelHelper . class . getResourceAsStream ( \"resources/org/hl7/fhir/quick-modelinfo.xml\" ) ,", "commit_type": "fix"}
{"commit_tokens": ["Improved", "the", "converted", ".", "Less", "double", "code", "."], "add_tokens": "public class Iconomy6 extends Converter {", "del_tokens": "public class Iconomy6 implements Converter { private List < String > dbTypes = new ArrayList < String > ( ) ; private String selectedDbType ; private List < String > dbInfo = new ArrayList < String > ( ) ; private HashMap < String , String > dbConnectInfo = new HashMap < String , String > ( ) ; @ Override public List < String > getDbTypes ( ) { return dbTypes ; } @ Override public boolean setDbType ( String dbType ) { boolean result = false ; if ( dbTypes . contains ( dbType ) ) { selectedDbType = dbType ; result = true ; } return result ; } @ Override public boolean setDbInfo ( String field , String value ) { boolean result = false ; if ( dbInfo . contains ( field ) ) { dbConnectInfo . put ( field , value ) ; result = true ; } return result ; } @ Override public boolean allSet ( ) { return dbInfo . size ( ) == dbConnectInfo . size ( ) ; }", "commit_type": "improve"}
{"commit_tokens": ["Improve", "SimpleNumberTest", "to", "also", "include", "tests", "for", "primitives"], "add_tokens": "private Points . Point pointFromColumn ( Column < Long > column , Granularity gran , AbstractSerializer serializer ) {", "del_tokens": "private Points . Point pointFromColumn ( Column < Long > column , Granularity gran , AbstractSerializer serializer ) {", "commit_type": "improve"}
{"commit_tokens": ["Adds", "a", "genRepoInfoFile", "goal", "."], "add_tokens": "// verify debugger required file generation verifier . assertFilePresent ( \"target/flexible-project-1.0-SNAPSHOT/WEB-INF/classes/\" + \"source-context.json\" ) ;", "del_tokens": "import com . google . cloud . tools . appengine . cloudsdk . CloudSdk ; import com . google . cloud . tools . appengine . cloudsdk . process . NonZeroExceptionExitListener ; import java . util . Arrays ; private void deleteService ( String service ) throws ProcessRunnerException { CloudSdk cloudSdk = new CloudSdk . Builder ( ) . exitListener ( new NonZeroExceptionExitListener ( ) ) . build ( ) ; cloudSdk . runAppCommand ( Arrays . asList ( \"services\" , \"delete\" , service ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "reflection", "issues", "in", "BaseOperation", "."], "add_tokens": "protected HasMetadataOperation ( K client , String resourceT , String namespace , String name , Boolean cascading , T item , Class < K > clientType , Class < T > type , Class < L > listType , Class < D > doneableType ) {", "del_tokens": "protected HasMetadataOperation ( K client , String resourceT , String namespace , String name , Boolean cascading , T item , Class < T > clientType , Class < T > type , Class < L > listType , Class < D > doneableType ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "some", "comments", "on", "null", "/", "min", "/", "max", "values", "from", "SBE", "spec", ".", "Added", "constant", "presence", "handling"], "add_tokens": "/** value of constant if used */ private final int constValue ; // TODO: handle constant presence by grabbing child node and parsing it's CDATA based on primitive (save it) if ( this . getPresence ( ) == Presence . CONSTANT ) { if ( node . getFirstChild ( ) == null ) throw new IllegalArgumentException ( \"type has declared presence \\\"constant\\\" but XML node has no data\" ) ; this . constValue = Primitive . parseConstValue2Int ( this . primitive , node . getFirstChild ( ) . getNodeValue ( ) ) ; } else { this . constValue = 0 ; } * Construct a new EncodedDataType with direct values . Does not handle constant values . super ( name , presence , description , fixUsage ) ; this . constValue = 0 ; / * * * The constant value of the type ( if ) * * @ return value of the constant for this type * / public int getConstantValue ( ) throws IllegalArgumentException { if ( getPresence ( ) != Presence . CONSTANT ) throw new IllegalArgumentException ( \"type is not of constant presence\" ) ; return constValue ; }", "del_tokens": "* Construct a new EncodedDataType with direct values super ( name , presence , description , fixUsage ) ; // TODO: use similar constructor for super so setting all specifics", "commit_type": "add"}
{"commit_tokens": ["Fixing", "When", "two", "select", "commands", "are", "together", "in", "the", "srec", "xml", "the", "second", "select", "fails", "."], "add_tokens": "assertEquals ( tc . getExecutionContext ( ) . getCommands ( ) . size ( ) , 38 ) ;", "del_tokens": "assertEquals ( tc . getExecutionContext ( ) . getCommands ( ) . size ( ) , 37 ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "HEAD", "on", "_temporary", "object"], "add_tokens": "String objName = path . toString ( ) ; if ( path . toString ( ) . startsWith ( hostName ) ) { objName = path . toString ( ) . substring ( hostName . length ( ) ) ; } if ( objName . contains ( HADOOP_ATTEMPT ) ) { LOG . debug ( \"Exists on temp object {}. Return false\" , objName ) ; return false ; } . getObject ( objName ) ;", "del_tokens": ". getObject ( path . toString ( ) . substring ( hostName . length ( ) ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "problem", "with", "change", "event", "generation", "when", "return", "fields", "are", "provided", "."], "add_tokens": "C apiInstance = apiVersionPlugin . getTranslator ( ) . convertPersistent ( entity , context ) ;", "del_tokens": "import com . dottydingo . hyperion . service . pipeline . auth . AuthorizationContext ; private final AuthorizationContext historyAuthContext = new NoOpAuthContext ( ) ; PersistenceContext ctx = ( PersistenceContext ) context . clone ( ) ; ctx . setRequestedFields ( null ) ; ctx . setAuthorizationContext ( historyAuthContext ) ; C apiInstance = apiVersionPlugin . getTranslator ( ) . convertPersistent ( entity , ctx ) ; private class NoOpAuthContext implements AuthorizationContext { @ Override public boolean isAuthorized ( ) { return true ; } @ Override public boolean isReadable ( String propertyName ) { return true ; } @ Override public boolean isWritable ( String propertyName ) { return true ; } }", "commit_type": "fix"}
{"commit_tokens": ["Using", "WorkbookFactory", ".", "create", "(", "File", ")", "to", "improve", "reader", "memory", "efficiency"], "add_tokens": "return WorkbookFactory . create ( file ) ;", "del_tokens": "import java . io . FileInputStream ; is = new FileInputStream ( file ) ; return WorkbookFactory . create ( is ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "handlers", "execute", "on", "a", "separate", "thread"], "add_tokens": "import java . util . concurrent . ExecutorService ; import java . util . concurrent . ForkJoinPool ; private ExecutorService exectorService ; private final int maxQueuedRequests ; this . exectorService = builder . executorService ; this . maxQueuedRequests = builder . maxQueuedRequests ; private ExecutorService executorService = new ForkJoinPool ( ) ; private int maxQueuedRequests = Runtime . getRuntime ( ) . availableProcessors ( ) * 5 ; public Builder setExecutorService ( ExecutorService executorService ) { this . executorService = executorService ; return this ; } public Builder setMaxQueuedRequests ( int maxQueuedRequests ) { this . maxQueuedRequests = maxQueuedRequests ; return this ; } ch . pipeline ( ) . addLast ( \"RequestRouter\" , new RequestRouter ( requestHandlers , executorService , maxQueuedRequests ) ) ;", "del_tokens": "ch . pipeline ( ) . addLast ( \"RequestRouter\" , new RequestRouter ( requestHandlers ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Improve", "templateSend", "method", "to", "check", "the", "response", "code", "to", "see", "if", "it", "s", "successful", "or", "not", "."], "add_tokens": "final JsonObject jsonObject = tmpJsonElement . getAsJsonObject ( ) ; if ( jsonObject . get ( \"errcode\" ) . getAsInt ( ) == 0 ) return jsonObject . get ( \"msgid\" ) . getAsString ( ) ; throw new WxErrorException ( WxError . fromJson ( responseContent ) ) ;", "del_tokens": "return tmpJsonElement . getAsJsonObject ( ) . get ( \"msgid\" ) . getAsString ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["remove", "unused", "method", "from", "interface"], "add_tokens": "private List < String > getValues ( final List < String > options )", "del_tokens": "/ * * * { @ inheritDoc } * / public List < String > getValues ( final List < String > options )", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "couple", "of", "methods", "a", "concrete", "and", "an", "abstract", "one", "in", "the", "same", "class"], "add_tokens": "/ * * * @ hidden * @ opt operations * / class UMLOptions { } abstract class AbstractNode { public abstract void abstractMethod ( ) ; public int concreteMethod ( ) { return 1 ; } }", "del_tokens": "abstract class AbstractNode { }", "commit_type": "add"}
{"commit_tokens": ["removing", "duplicate", "couch", "app", "from", "api", "/", "adding", "version", "converter", "to", "couch", "-", "db", "to", "accommodate", "shift", "to", "couch", "doc", "wrapper", "around", "core", "api", "objects", "and", "fix", "group", "constituent", "recursion", "and", "fix", "NPE", "for", "uninitialized", "key", "in", "store", "models"], "add_tokens": "public synchronized StoreKey getKey ( ) if ( key == null ) { this . key = new StoreKey ( doctype , name ) ; }", "del_tokens": "this . key = new StoreKey ( doctype , name ) ; public StoreKey getKey ( )", "commit_type": "remove"}
{"commit_tokens": ["fix", "TimeBoundaryQuery", "to", "properly", "handle", "timestamps", "prior", "to", "1970"], "add_tokens": "public static final Interval MY_Y2K_INTERVAL = new Interval ( new DateTime ( Long . MIN_VALUE ) , new DateTime ( Long . MAX_VALUE ) ) ;", "del_tokens": "public static final Interval MY_Y2K_INTERVAL = new Interval ( new DateTime ( 0 ) , new DateTime ( \"3000-01-01\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "generated", "constructors", "to", "be", "public"], "add_tokens": "overrideMethod ( c , constructor , Modifier . PUBLIC ) ;", "del_tokens": "overrideMethod ( c , constructor , constructor . getModifiers ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["moved", "FloatingActionMenu", "construction", "to", "layouting", "phase"], "add_tokens": "invalidateMenu ( ) ; } public void invalidateMenu ( ) { if ( floatingActionMenu != null ) floatingActionMenu . build ( ) ; floatingActionMenu . setAnchor ( this ) ; floatingActionMenu . show ( ) ; floatingActionMenu . setAnchor ( this ) ; floatingActionMenu . show ( ) ;", "del_tokens": "floatingActionMenu . show ( FloatingActionButton . this ) ; floatingActionMenu . show ( FloatingActionButton . this ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "checker", "for", "empty", "if", "statement"], "add_tokens": "import com . google . errorprone . checkers . EmptyIfStatementChecker ; emptyStatementCheckers = Arrays . asList ( //new EmptyStatementChecker(), new EmptyIfStatementChecker ( ) ) ;", "del_tokens": "emptyStatementCheckers = Arrays . asList ( new EmptyStatementChecker ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "obsolete", "gdn", "-", "vendors", "metadata"], "add_tokens": "import org . junit . Test ;", "del_tokens": "import org . junit . Test ; assertThat ( DoubleClickMetadata . toString ( metadata . gdnVendors ( ) , 1 ) ) . isEqualTo ( \"1: GDNVendor1\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "to", "stub", "static", "method", "via", "doReturn"], "add_tokens": "import java . lang . reflect . InvocationTargetException ; Throwable loadJvmtiException = null ; try { / * * TODO ( moltmann @ google . com ) : Replace with regular method call once the API becomes * public * / Class . forName ( \"android.os.Debug\" ) . getMethod ( \"attachJvmtiAgent\" , String . class , String . class , ClassLoader . class ) . invoke ( null , AGENT_LIB_NAME , null , cl ) ; } catch ( InvocationTargetException e ) { loadJvmtiException = e . getCause ( ) ; } catch ( IllegalAccessException | ClassNotFoundException | NoSuchMethodException e ) { loadJvmtiException = e ; } if ( loadJvmtiException != null ) { if ( loadJvmtiException instanceof IOException ) { throw ( IOException ) loadJvmtiException ; } else { throw new IOException ( \"Could not load jvmti plugin\" , loadJvmtiException ) ; } }", "del_tokens": "import android . os . Debug ; Debug . attachJvmtiAgent ( AGENT_LIB_NAME , null , cl ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "ability", "to", "remove", "parameters", "by", "setting", "them", "to", "null"], "add_tokens": "* Returns true if this object contains no custom key - value pairs . * @ return true if this object contains no custom key - value pairs * / public boolean isEmpty ( ) { return size ( ) == 0 ; } / * * * Puts a custom value at this custom key . / * * * Returns the number of custom key - value pairs . * @ return the number of custom key - value pairs * / public int size ( ) { return map . size ( ) ; }", "del_tokens": "* Puts a custom variable at this custom key .", "commit_type": "add"}
{"commit_tokens": ["Changed", "default", "startup", "timeout", "to", "5", "minutes"], "add_tokens": "public static final int DEFAULT_STARTUP_TIMEOUT = 5 * 60 ; return startupTimeout != 0 ? startupTimeout : DEFAULT_STARTUP_TIMEOUT ;", "del_tokens": "return startupTimeout != 0 ? startupTimeout : 30 ;", "commit_type": "change"}
{"commit_tokens": ["fix", "limited", "number", "/", "range", "matcher"], "add_tokens": "if ( Double . compare ( item . getMinimum ( ) , Double . NaN ) == 0 ) return false ; if ( Double . compare ( item . getMaximum ( ) , Double . NaN ) == 0 ) return false ; if ( Double . compare ( item . getProperties ( ) . optValue ( \"min\" ) . getMinimum ( ) , Double . NaN ) == 0 ) return false ; if ( Double . compare ( item . getProperties ( ) . optValue ( \"max\" ) . getMaximum ( ) , Double . NaN ) == 0 ) return false ;", "del_tokens": "if ( Double . compare ( item . getMinimum ( ) , Double . NaN ) != 0 ) return false ; if ( Double . compare ( item . getMaximum ( ) , Double . NaN ) != 0 ) return false ; if ( Double . compare ( item . getProperties ( ) . optValue ( \"min\" ) . getMinimum ( ) , Double . NaN ) != 0 ) return false ; if ( Double . compare ( item . getProperties ( ) . optValue ( \"max\" ) . getMaximum ( ) , Double . NaN ) != 0 ) return false ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "RequestDispatcher", "to", "make", "sure", "it", "maps", "exceptions", "to", "ErrorResponse", "properly"], "add_tokens": "import io . katharsis . response . HttpStatus ; //Reused in RequestDispatcherTest public static ExceptionMapperRegistry exceptionMapperRegistry = new ExceptionMapperRegistry ( exceptionMapperTypeSet ( ) ) ; return ErrorResponse . builder ( ) . setStatus ( HttpStatus . BAD_REQUEST_400 ) . build ( ) ;", "del_tokens": "ExceptionMapperRegistry exceptionMapperRegistry = new ExceptionMapperRegistry ( exceptionMapperTypeSet ( ) ) ; return ErrorResponse . builder ( ) . setStatus ( 400 ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "executable", "main", "class", "and", "assembly", "config", "for", "runnable", "jar"], "add_tokens": "import com . google . common . collect . Lists ; import org . apache . http . impl . client . BasicAuthCache ; import org . apache . http . impl . client . BasicCredentialsProvider ; import org . apache . http . impl . client . HttpClientBuilder ;", "del_tokens": "import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStreamReader ; import java . net . URL ; import java . util . Base64 ; import javax . net . ssl . HttpsURLConnection ; import javax . net . ssl . SSLSocketFactory ; import com . google . common . collect . Lists ; import org . apache . http . HttpResponse ; import org . apache . http . auth . UsernamePasswordCredentials ; import org . apache . http . impl . client . * ;", "commit_type": "add"}
{"commit_tokens": ["Add", "includeDays", "option", "(", "default", "true", ")", "to", "toEncodedString", "on", "Timecode"], "add_tokens": "* timecode including days @ rate < / code > return toEncodedString ( true ) ; } / * * * Returns the timecode in the Encoded Timecode format for this library . The format of this timecode is < code > smpte * timecode optionally including days @ rate < / code > * where * rate is < code > denominator : [ numerator ] < / code > ( where numerator , if omitted , * is 1 ) . See { @ link Timebase } for further information on the encoding of the timebase * * @ param includeDays true if the days component should be emitted too ( if non - zero ) * * @ return * / public String toEncodedString ( boolean includeDays ) { return toSMPTEString ( includeDays ) + \"@\" + getTimebase ( ) . toEncodedString ( ) ;", "del_tokens": "* timecode @ rate < / code > return toSMPTEString ( ) + \"@\" + getTimebase ( ) . toEncodedString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "kind", "of", "anti", "-", "aliasing", "to", "the", "radial", "image", "method"], "add_tokens": "final BigDecimal STEP = new BigDecimal ( Double . MIN_VALUE ) ; stops . add ( new Stop ( Double . MIN_VALUE , stop . getColor ( ) ) ) ; double radiusMinus05 = radius - 0.5d ; double radiusMinus10 = radius - 1d ; double radiusMinus15 = radius - 1.5d ; double radiusMinus20 = radius - 2d ; if ( distance > radiusMinus05 ) { color = Color . color ( color . getRed ( ) , color . getGreen ( ) , color . getBlue ( ) , 0.15 ) ; } else if ( distance > radiusMinus10 ) { color = Color . color ( color . getRed ( ) , color . getGreen ( ) , color . getBlue ( ) , 0.35 ) ; } else if ( distance > radiusMinus15 ) { color = Color . color ( color . getRed ( ) , color . getGreen ( ) , color . getBlue ( ) , 0.55 ) ; } else if ( distance > radiusMinus20 ) { color = Color . color ( color . getRed ( ) , color . getGreen ( ) , color . getBlue ( ) , 0.75 ) ; }", "del_tokens": "final BigDecimal STEP = new BigDecimal ( 0.000001 ) ; stops . add ( new Stop ( 0.000001 , stop . getColor ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "and", "remove", "marker", "APIs"], "add_tokens": "import com . moagrius . tileview . io . StreamProviderAssets ; . setStreamProvider ( new StreamProviderAssets ( ) ) // TODO: DEBUG MOVING MARKERS, REMOVE BEFORE MERGING x = coordinatePlugin . longitudeToX ( sites . get ( 0 ) [ 1 ] ) ; y = coordinatePlugin . latitudeToY ( sites . get ( 0 ) [ 0 ] ) ; markerPlugin . moveMarker ( view , x , y ) ; // TODO: DEBUG REMOVING MARKERS, REMOVE BEFORE MERGING, UNCOMMENT TO DEMONSTRAT //markerPlugin.removeMarker(view);", "del_tokens": "import android . content . Context ; import com . moagrius . tileview . io . StreamProvider ; import java . io . IOException ; import java . io . InputStream ; private static class SlowStreamProviderAssets implements StreamProvider { @ Override public InputStream getStream ( int column , int row , Context context , Object data ) throws IOException { String file = String . format ( Locale . US , ( String ) data , column , row ) ; try { Thread . sleep ( 500 ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } return context . getAssets ( ) . open ( file ) ; } } . setStreamProvider ( new SlowStreamProviderAssets ( ) )", "commit_type": "move"}
{"commit_tokens": ["make", "username", "and", "password", "required"], "add_tokens": "public String username ; public String password ;", "del_tokens": "public String user ; public String password ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "extra", "test", "for", "logger", "utils", "small", "refactoring"], "add_tokens": "import static org . junit . Assert . fail ; import static org . mockito . Mockito . reset ; public final class LapseLoggerAspectTest { @ Resource TimeSource timeSource ; reset ( mockCalcService ) ; assertTrue ( logContent . contains ( \"@metric op=CalcService.plus, tDelta=200\\n\" ) ) ; } @ Test public void shouldLogFailedOperation ( ) { // Given: when ( timeSource . currentTime ( ) ) . thenReturn ( 1000L ) // 1st time . thenReturn ( 1001L ) ; // 2nd time when ( mockCalcService . add ( 1 , 2 ) ) . thenThrow ( new IllegalArgumentException ( ) ) ; // When: try { realCalcService . add ( 1 , 2 ) ; fail ( \"Calc service should throw an exception\" ) ; } catch ( IllegalArgumentException ignored ) { // OK } // Then: final String logContent = loggerProvider . getRawLogContents ( ) ; assertTrue ( logContent . contains ( \"@metric op=CalcService.plus, tDelta=1, failed=true\\n\" ) ) ;", "del_tokens": "public class LapseLoggerAspectTest { @ Resource TimeSource timeSource ; assertTrue ( logContent . contains ( \"@metric op=CalcService.plus, tDelta=200\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["implemented", "assign", "()", "flows", "also", "working", "with", "toNobody", "()"], "add_tokens": "import pl . project13 . janbanery . core . flow . * ; // task assignment ------------------ TaskAssignmentFlow assign ( Task task ) ; TaskFlow assign ( Task task , User user ) throws IOException ;", "del_tokens": "import pl . project13 . janbanery . core . flow . TaskFlow ; import pl . project13 . janbanery . core . flow . TaskMarkFlow ; import pl . project13 . janbanery . core . flow . TaskMoveFlow ; import pl . project13 . janbanery . core . flow . TaskUpdateFlow ;", "commit_type": "implement"}
{"commit_tokens": ["Added", "support", "for", "Alarm", "Sensors", "."], "add_tokens": "} else if ( ( ccb [ startIndex + 2 ] & 0xFF ) == 0xFF || ccb [ startIndex + 2 ] == 0x63 ) {", "del_tokens": "} else if ( ccb [ startIndex + 2 ] == 0xFF || ccb [ startIndex + 2 ] == 0x63 ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Target", ".", "Type", ".", "Default"], "add_tokens": "import org . arquillian . container . chameleon . spi . model . Target . Type ; private String defaultType ; Type definedType = target . getType ( ) ; if ( target . getType ( ) == Type . Default ) { if ( defaultType != null ) { definedType = Type . from ( defaultType ) ; } } if ( adapter . isType ( definedType ) ) { definedType ,", "del_tokens": "if ( adapter . isType ( target . getType ( ) ) ) { target . getType ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Improve", "namespaces", "for", "nanopublication", "output"], "add_tokens": "import java . util . Map ; private Map < String , String > ns ; public HashAdder ( URI baseURI , String hash , RDFHandler handler , Map < String , String > ns ) { this . ns = ns ; if ( ns . get ( \"this\" ) != null ) handler . handleNamespace ( \"this\" , ns . get ( \"this\" ) ) ; if ( ns . get ( \"sub\" ) != null ) handler . handleNamespace ( \"sub\" , ns . get ( \"sub\" ) ) ; if ( ns . get ( \"blank\" ) != null ) handler . handleNamespace ( \"blank\" , ns . get ( \"blank\" ) ) ;", "del_tokens": "public HashAdder ( URI baseURI , String hash , RDFHandler handler ) { if ( baseURI != null ) { handler . handleNamespace ( \"this\" , RdfUtils . getHashURIString ( baseURI , hash ) ) ; handler . handleNamespace ( \"sub\" , RdfUtils . getHashURIString ( baseURI , hash , \"\" ) ) ; handler . handleNamespace ( \"blank\" , RdfUtils . getHashURIString ( baseURI , hash , \"\" ) + \".\" ) ; }", "commit_type": "improve"}
{"commit_tokens": ["Fix", "to", "postfix", "with", "leading", "zero", "hack"], "add_tokens": "private static final Pattern numericHasLeadingZeroes = Pattern . compile ( ( \"\\\\b0+\" ) ) ; while ( m . find ( ) ) { postfix = m . replaceAll ( \"\" ) ;", "del_tokens": "private static final Pattern numericHasLeadingZeroes = Pattern . compile ( ( \"^0+([0-9]*)$\" ) ) ; if ( m . find ( ) ) { postfix = m . group ( 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "proper", "support", "for", "padding", "values", "."], "add_tokens": "import org . apache . commons . lang3 . StringUtils ; // handle the padding if ( value != null && ! value . isEmpty ( ) && itemDef . getLength ( ) != null && itemDef . getPadding ( ) != null && value . length ( ) < itemDef . getLength ( ) ) { if ( NaaccrXmlDictionaryUtils . NAACCR_PADDING_LEFT_BLANK . equals ( itemDef . getPadding ( ) ) ) value = StringUtils . leftPad ( value , itemDef . getLength ( ) , ' ' ) ; else if ( NaaccrXmlDictionaryUtils . NAACCR_PADDING_RIGHT_BLANK . equals ( itemDef . getPadding ( ) ) ) value = StringUtils . rightPad ( value , itemDef . getLength ( ) , ' ' ) ; else if ( NaaccrXmlDictionaryUtils . NAACCR_PADDING_LEFT_ZERO . equals ( itemDef . getPadding ( ) ) ) value = StringUtils . leftPad ( value , itemDef . getLength ( ) , '0' ) ; else if ( NaaccrXmlDictionaryUtils . NAACCR_PADDING_RIGHT_ZERO . equals ( itemDef . getPadding ( ) ) ) value = StringUtils . rightPad ( value , itemDef . getLength ( ) , '0' ) ; else throw new RuntimeException ( \"Unknown padding option: \" + itemDef . getPadding ( ) ) ; }", "del_tokens": "// TODO this code doesn't handle padding yet...", "commit_type": "add"}
{"commit_tokens": ["Fix", "OGCCollection#reduceFromMulti", "and", "add", "test"], "add_tokens": "return new OGCPolygon ( new Polygon ( polygon . getDescription ( ) ) , 0 , esriSR ) ;", "del_tokens": "return new OGCLineString ( new Polygon ( polygon . getDescription ( ) ) , 0 , esriSR ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "predicates", "to", "throw", "checked", "exceptions"], "add_tokens": "static < T > Condition < T > match ( Callable < T > item , CheckedPredicate < ? super T > predicate ) { static < T > Condition < T > match ( T item , CheckedPredicate < ? super T > predicate ) {", "del_tokens": "import java . util . function . Predicate ; static < T > Condition < T > match ( Callable < T > item , Predicate < ? super T > predicate ) { static < T > Condition < T > match ( T item , Predicate < ? super T > predicate ) {", "commit_type": "allow"}
{"commit_tokens": ["Remove", "reference", "to", "google", "common", "."], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import java . util . Map ; private List < UserGroup > userGroups = new ArrayList < > ( ) ;", "del_tokens": "import com . google . common . collect . Lists ; import java . util . * ; private List < UserGroup > userGroups = Lists . newArrayList ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "an", "eclipse", "warning", "about", "a", "package", "and", "a", "class", "having", "the", "same", "name"], "add_tokens": ". classpathResourcesAt ( \"/org/httpobjects/util/ClasspathResourcesObjectTest_resources\" ) . classpathResourcesAt ( \"/org/httpobjects/util/ClasspathResourcesObjectTest_resources\" ) Response response = object . get ( new MockRequest ( object , \"/bar/util/ClasspathResourcesObjectTest_resources/a.txt\" ) ) ;", "del_tokens": ". classpathResourcesAt ( \"/org/httpobjects/util/ClasspathResourcesObjectTest\" ) . classpathResourcesAt ( \"/org/httpobjects/util/ClasspathResourcesObjectTest\" ) Response response = object . get ( new MockRequest ( object , \"/bar/util/ClasspathResourcesObjectTest/a.txt\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "binary", "data", "page", "in", "showcase", "."], "add_tokens": "import io . reinert . requestor . examples . showcase . place . BinaryDataPlace ; BINARY_DATA ( \"Binary Data\" , Tokens . BINARY_DATA_TOKEN , BinaryDataPlace . INSTANCE ) , public static final String BINARY_DATA_TOKEN = \"binary-data\" ; } else if ( token . equals ( Tokens . BINARY_DATA_TOKEN ) ) { return BINARY_DATA ;", "del_tokens": "// STREAM(\"Stream\", Tokens.STREAM_TOKEN, null), public static final String STREAM_TOKEN = \"stream\" ; // } else if (token.equals(Tokens.STREAM_TOKEN)) { // return STREAM;", "commit_type": "add"}
{"commit_tokens": ["fixed", "broken", "tests", "due", "to", "change", "to", "OrcWriter"], "add_tokens": "writer . addRow ( ( Object ) struct ) ; writer . addRow ( ( Object ) null ) ; writer . addRow ( ( Object ) struct1 ) ; writer . addRow ( ( Object ) struct2 ) ; writer . addRow ( ( Object ) struct3 ) ;", "del_tokens": "writer . addRow ( struct ) ; writer . addRow ( ( List < Object > ) null ) ; writer . addRow ( struct1 ) ; writer . addRow ( struct2 ) ; writer . addRow ( struct3 ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "assertion", "more", "verbose", "to", "allow", "failure", "troubleshooting"], "add_tokens": "Assert . assertTrue ( \"More tests expected: \" + copy . toString ( ) , copy . isEmpty ( ) ) ; if ( ! build . getResult ( ) . isBetterOrEqualTo ( Result . UNSTABLE ) ) { // avoid expensive build.getLog() until condition is met Assert . fail ( \"Build status: \" + build . getResult ( ) + \", log follows:\\n\" + build . getLog ( ) ) ; }", "del_tokens": "Assert . assertTrue ( copy . toString ( ) , copy . isEmpty ( ) ) ; Assert . assertTrue ( \"Build status: \" + build . getResult ( ) , build . getResult ( ) . isBetterOrEqualTo ( Result . UNSTABLE ) ) ;", "commit_type": "make"}
{"commit_tokens": ["improve", "README", "and", "javadoc", "documentation"], "add_tokens": "/ * * * An implementation of the Password - Based Key Derivation Function as specified * in RFC 2898. * * @ author Will Glozer * @ version 1.0 * /", "del_tokens": "* @ return The derived key . *", "commit_type": "improve"}
{"commit_tokens": ["Added", "pressure", "-", "humidity", "-", "and", "speedunit", "to", "Unit", "in", "DarkSky"], "add_tokens": "US ( \"us\" , \"\\u00B0F\" , \"mb\" , \"\\u0025\" , \"mph\" ) , // imperial units SI ( \"si\" , \"\\u00B0C\" , \"mb\" , \"\\u0025\" , \"m/s\" ) , // SI units CA ( \"ca\" , \"\\u00B0C\" , \"mb\" , \"\\u0025\" , \"kph\" ) , // same as SI except wind speed is in kph UK ( \"uk\" , \"\\u00B0C\" , \"mb\" , \"\\u0025\" , \"mph\" ) , UK2 ( \"uk2\" , \"\\u00B0C\" , \"mb\" , \"\\u0025\" , \"mph\" ) , // same as SI except that nearest storm distance and visibility are in miles and wind speed is in mph AUTO ( \"auto\" , \"\\u00B0C\" , \"mb\" , \"\\u0025\" , \"mph\" ) ; // units based on geographic location public final String pressureUnitString ; public final String humidityUnitString ; public final String speedUnitString ; Unit ( final String VALUE , final String TEMPERATURE_UNIT_STRING , final String PRESSURE_UNIT_STRING , final String HUMIDITY_UNIT_STRING , final String SPEED_UNIT_STRING ) { pressureUnitString = PRESSURE_UNIT_STRING ; humidityUnitString = HUMIDITY_UNIT_STRING ; speedUnitString = SPEED_UNIT_STRING ;", "del_tokens": "US ( \"us\" , \"\\u00B0F\" ) , // imperial units SI ( \"si\" , \"\\u00B0C\" ) , // SI units CA ( \"ca\" , \"\\u00B0C\" ) , // same as SI except wind speed is in kph UK ( \"uk\" , \"\\u00B0C\" ) , UK2 ( \"uk2\" , \"\\u00B0C\" ) , // same as SI except that nearest storm distance and visibility are in miles and wind speed is in mph AUTO ( \"auto\" , \"\\u00B0C\" ) ; // units based on geographic location Unit ( final String VALUE , final String TEMPERATURE_UNIT_STRING ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "spec", "to", "DEFAULT_TEST_FILES", "and", "DEFAULT_TEST_CLASS_NAMES"], "add_tokens": "protected static final String DEFAULT_TEST_FILES = \".*(Spec|Test|Tests|TestCase)\\\\.groovy\" ; protected static final String DEFAULT_TEST_CLASS_NAMES = \"*Spec,*Test,*Tests,*TestCase\" ;", "del_tokens": "protected static final String DEFAULT_TEST_FILES = \".*(Test|Tests|TestCase)\\\\.groovy\" ; protected static final String DEFAULT_TEST_CLASS_NAMES = \"*Test,*Tests,*TestCase\" ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "integration", "tests", "regarding", "the", "identification", "heuristics", ".", "KSIJAVAAPI", "-", "280", "."], "add_tokens": "! testData . getExpectException ( ) && testData . getExpectedFailureCode ( ) . equals ( \" \" ) ) ) {", "del_tokens": "! testData . getExpectException ( ) ) ) {", "commit_type": "update"}
{"commit_tokens": ["Remove", "unnecessary", "class", "references", "on", "static", "method", "calls"], "add_tokens": "Object testObj = installHooks ( proxy . call ( ) ) ; INSTANCE_TO_CLASS . put ( testObj , invoke ( runner , \"getTestClass\" ) ) ; applyTimeout ( testObj ) ;", "del_tokens": "Object testObj = LifecycleHooks . installHooks ( proxy . call ( ) ) ; INSTANCE_TO_CLASS . put ( testObj , LifecycleHooks . invoke ( runner , \"getTestClass\" ) ) ; LifecycleHooks . applyTimeout ( testObj ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "optional", "String", "value", "to", "NotImplementedYet", "annotation"], "add_tokens": "/ * * * Optional description to describe when the implementation will be done * / String value ( ) default \"\" ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "work", "around", "for", "NPE", "in", "Request", ".", "getContextPath"], "add_tokens": "ret . put ( \"ContextPath\" , ServletHelper . getRequestContextPath ( aHttpRequest ) ) ;", "del_tokens": "ret . put ( \"ContextPath\" , aHttpRequest . getContextPath ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "source", "view", "not", "being", "included", "in", "the", "new", "adapter", "."], "add_tokens": "import java . util . ArrayList ; import java . util . Arrays ; * Adapter to provide views for the fields equal annotation . Ensures that source view gets passed along * with other views specified in the annotation . ArrayList < View > viewSet = new ArrayList < > ( Arrays . asList ( views ) ) ; viewSet . add ( sourceView ) ; return viewSet . toArray ( new View [ viewSet . size ( ) ] ) ;", "del_tokens": "* View [ ] newViewSet = new View [ views . length + 1 ] ; newViewSet [ newViewSet . length - 1 ] = sourceView ; return newViewSet ;", "commit_type": "fix"}
{"commit_tokens": ["add", "simple", "Id", "generation", "method"], "add_tokens": "final SelectResult selectResult = sdb . select ( new SelectRequest ( new QueryBuilder ( entityInformation ) . with ( QueryBuilder . Count . ON ) . toString ( ) ) ) ;", "del_tokens": "Assert . notNull ( entity . getItemName ( ) , \"Item name should not be null\" ) ; UpdateCondition condition = new UpdateCondition ( ) ; final SelectResult selectResult = sdb . select ( new SelectRequest ( new QueryBuilder < > ( entityInformation ) . with ( QueryBuilder . Count . ON ) . toString ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "safe", "factiry"], "add_tokens": "return self . createConstantMatrix ( rows , columns , value ) . safe ( ) ; return self . createConstantVector ( length , value ) . safe ( ) ;", "del_tokens": "return self . createConstantMatrix ( rows , columns , value ) ; return self . createConstantVector ( length , value ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "map", "/", "convert", "to", "String", "type"], "add_tokens": "return ! type . isEnum ( ) && ! type . isAssignableFrom ( String . class ) && ! Primitives . isPrimitiveWrapper ( type ) ;", "del_tokens": "return ! type . isEnum ( ) && ! Primitives . isPrimitiveWrapper ( type ) ;", "commit_type": "fix"}
{"commit_tokens": ["update", "tests", "behaviour", ":", "remove", "#", "at", "the", "end", "of", "the", "url"], "add_tokens": "int pos = url . indexOf ( \"?\" ) ; if ( pos >= 0 ) { pos = url . indexOf ( \"#\" ) ; if ( pos >= 0 ) { url = url . substring ( 0 , pos ) ; } final Map < String , String > parameters = new HashMap < String , String > ( ) ;", "del_tokens": "final Map < String , String > parameters = new HashMap < String , String > ( ) ; final int pos = url . indexOf ( \"?\" ) ; if ( pos > 0 ) {", "commit_type": "update"}
{"commit_tokens": ["Updated", "5305", "code", "list", "to", "version", "D16B"], "add_tokens": "* Source : https : //www.unece.org/trade/untdid/d16b/tred/tred5305.htm public enum ETaxCategoryUN5305 implements IHasID < String > , IHasDisplayText D ( \"D\" , ETaxCategoryUN5305Name . D ) , I ( \"I\" , ETaxCategoryUN5305Name . I ) , J ( \"J\" , ETaxCategoryUN5305Name . J ) , K ( \"K\" , ETaxCategoryUN5305Name . K ) , L ( \"L\" , ETaxCategoryUN5305Name . L ) , M ( \"M\" , ETaxCategoryUN5305Name . M ) ,", "del_tokens": "* Source : http : //www.unece.org/trade/untdid/d08b/tred/tred5305.htm public enum ETaxCategoryUN5305 implements IHasID < String > , IHasDisplayText", "commit_type": "update"}
{"commit_tokens": ["moved", "definitions", "Schema", "implementation", "to", "SchemaExtension"], "add_tokens": "logger . info ( \"Content file {} processed\" , contentPath ) ; logger . warn ( \"Failed to read content file {} > {}\" , contentPath , e . getMessage ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( \"Failed to read content file {}\" , contentPath ) ; logger . info ( \"Content URI {} processed\" , contentUri ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( \"Failed to read content URI {} > {}\" , contentUri , e . getMessage ( ) ) ;", "del_tokens": "logger . info ( \"Content file processed: {}\" , contentPath ) ; logger . warn ( String . format ( \"Failed to read content file: %s\" , contentPath ) , e ) ; if ( logger . isWarnEnabled ( ) ) { logger . warn ( \"Content file is not readable: {}\" , contentPath ) ; logger . info ( \"Content URI processed {}\" , contentUri ) ; if ( logger . isWarnEnabled ( ) ) { logger . warn ( \"Failed to read URI content {} > {}\" , contentUri , e . getMessage ( ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "initialization", "ordering", "problems", "in", "MetaMediaManager", "-", ">"], "add_tokens": "* Provides this media manager with its host and region manager . public void init ( MediaHost host , RegionManager remgr ) _remgr = remgr ;", "del_tokens": "* Default constructor . public AbstractMediaManager ( MediaHost host ) _remgr = host . getRegionManager ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "AbstractMultiNodeActionBuilder", "for", "multi", "-", "node", "actions", ".", "Implemented", "NodesShutdown", "action", "."], "add_tokens": "import io . searchbox . AbstractMultiINodeActionBuilder ; StringBuilder sb = new StringBuilder ( super . buildURI ( ) ) ; sb . append ( \"/_cluster/nodes\" ) . append ( \"/\" ) . append ( nodes ) ; public static class Builder extends AbstractMultiINodeActionBuilder < NodesInfo , Builder > {", "del_tokens": "import org . apache . commons . lang . StringUtils ; import java . util . Collection ; import java . util . LinkedList ; private Collection < String > nodes ; this . nodes = builder . nodes ; StringBuilder sb = new StringBuilder ( ) ; sb . append ( super . buildURI ( ) ) . append ( \"/_cluster/nodes\" ) ; if ( this . nodes . size ( ) > 0 ) { sb . append ( \"/\" ) . append ( StringUtils . join ( this . nodes , \",\" ) ) ; } public static class Builder extends AbstractAction . Builder < NodesInfo , Builder > { private Collection < String > nodes = new LinkedList < String > ( ) ; public Builder addNode ( String node ) { nodes . add ( node ) ; return this ; } public Builder addNode ( Collection < ? extends String > nodes ) { this . nodes . addAll ( nodes ) ; return this ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "the", "GET", "e", "-", "money", "endpoint", "for", "a", "user", "without", "specifying", "currency", "created", "a", "test", "to", "mock", "the", "call", "."], "add_tokens": "protected MangoPayApi getRoot ( ) { return root ; } put ( \"users_emoney\" , new String [ ] { \"/users/%s/emoney\" , RequestType . GET . toString ( ) } ) ; put ( \"disputes_repudiation_create_settlement\" , new String [ ] { \"/repudiations/%s/settlementtransfer\" , RequestType . POST . toString ( ) } ) ; // These are temporary functions and WILL be removed in the future.", "del_tokens": "put ( \"disputes_repudiation_create_settlement\" , new String [ ] { \"/repudiations/%s/settlementtransfer\" , RequestType . POST . toString ( ) } ) ; // These are temporary functions and WILL be removed in the future.", "commit_type": "add"}
{"commit_tokens": ["added", "basic", "AJAX", "upload", "window", "for", "uploading", "system", "updates"], "add_tokens": "import org . ijsberg . iglu . util . execution . Executable ; new Executable ( ) { @ Override protected Object execute ( ) throws Throwable { server . stop ( ) ; server . destroy ( ) ; System . out . println ( \"server stopped\" ) ; return null ; } } . executeAsync ( ) ; //server.setAttribute(\"org.mortbay.jetty.Request.maxFormContentSize\", -1); //server.setAttribute(\"org.eclipse.jetty.server.Request.maxFormContentSize\", -1); ctx . setMaxFormContentSize ( 10000000 ) ;", "del_tokens": "import org . ijsberg . iglu . util . collection . ArraySupport ; import org . mortbay . jetty . Connector ; import org . mortbay . jetty . nio . SelectChannelConnector ; server . stop ( ) ; server . destroy ( ) ; System . out . println ( \"server stopped\" ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "rate", "limiting", "logic", "to", "puller", "logs"], "add_tokens": "import com . swrve . ratelimitedlogger . RateLimitedLog ; import org . joda . time . Duration ; private static final int MAX_LOG_RATE = 3 ; private static final Duration MAX_LOG_DURATION = Duration . millis ( 2000 ) ; private static final Logger logger = LoggerFactory . getLogger ( Puller . class ) ; private static final Logger LOG = RateLimitedLog . withRateLimit ( logger ) . maxRate ( MAX_LOG_RATE ) . every ( MAX_LOG_DURATION ) . build ( ) ; LOG . error ( \"Pull failed\" , ex ) ; LOG . error ( \"Message handler threw exception\" , e ) ; LOG . error ( \"Message handler returned null\" ) ; LOG . error ( \"Acking pubsub threw exception\" , throwable ) ;", "del_tokens": "import java . util . concurrent . atomic . AtomicBoolean ; private static final Logger log = LoggerFactory . getLogger ( Puller . class ) ; log . error ( \"Pull failed\" , ex ) ; log . error ( \"Message handler threw exception\" , e ) ; log . error ( \"Message handler returned null\" ) ; log . error ( \"Acking pubsub threw exception\" , throwable ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "nextMarker", "instead", "of", "calculating", "based", "on", "last", "observed", "element", "."], "add_tokens": "private boolean exhausted = false ; private List < T > curValues ; private String nextMarker = paginationOptions . getMarker ( ) ; nextMarker = container . getNextMarker ( ) ;", "del_tokens": "boolean exhausted = false ; List < T > curValues ; String nextMarker = paginationOptions . getMarker ( ) ; boolean first = true ; if ( ! this . first && values . size ( ) > 0 ) { values . remove ( 0 ) ; } nextMarker = values . get ( values . size ( ) - 1 ) . getId ( ) ; this . first = false ;", "commit_type": "use"}
{"commit_tokens": ["removed", "debugging", "info", "and", "fixed", "unit", "test", "."], "add_tokens": "// System.out.println(\"sub-ranges for: \" + this); // System.out.println(\"\\tNum ranges: \" + numParts); // System.out.println(\"\\tsize: \" + size()); // System.out.println(\"\\tviewSize: \" + viewSize); // System.out.println(); // System.out.println(\"\\t\\tstartIdx: \" + startIdx); // System.out.println(\"\\t\\tendIdx: \" + endIdx); // System.out.println(\"\\t\\tnext startIdx: \" + startIdx); // System.out.println(\"\\t\\tpartitionEnd: \" + partitionEnd);", "del_tokens": "System . out . println ( \"sub-ranges for: \" + this ) ; System . out . println ( \"\\tNum ranges: \" + numParts ) ; System . out . println ( \"\\tsize: \" + size ( ) ) ; System . out . println ( \"\\tviewSize: \" + viewSize ) ; System . out . println ( ) ; System . out . println ( \"\\t\\tstartIdx: \" + startIdx ) ; System . out . println ( \"\\t\\tendIdx: \" + endIdx ) ; System . out . println ( \"\\t\\tnext startIdx: \" + startIdx ) ; System . out . println ( \"\\t\\tpartitionEnd: \" + partitionEnd ) ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "folder", "for", "results", "for", "TestKoPeMeKiekerPremain", "to", "test", "-", "classes"], "add_tokens": "import java . io . File ; import kieker . monitoring . writer . filesystem . ChangeableFolderSyncFsWriter ; import de . dagere . kopeme . TestUtils ; import de . dagere . kopeme . datastorage . FolderProvider ; ProcessBuilder pb = new ProcessBuilder ( \"java\" , //\"-Xdebug\", \"-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=1044\", \"-cp\" , System . getProperty ( \"java.class.path\" ) , public static void main ( String [ ] args ) throws Exception { TestUtils . cleanAndSetKoPeMeOutputFolder ( ) ; File folder = new File ( FolderProvider . getInstance ( ) . getFolderFor ( TestKiekerMeasureUtil . class . getName ( ) ) ) ; System . out . println ( folder ) ; ChangeableFolderSyncFsWriter inst = ChangeableFolderSyncFsWriter . getInstance ( KiekerMeasureUtil . CTRLINST ) ; inst . setFolder ( folder ) ;", "del_tokens": "import java . io . IOException ; ProcessBuilder pb = new ProcessBuilder ( \"java\" , \"-cp\" , System . getProperty ( \"java.class.path\" ) , public static void main ( String [ ] args ) throws IOException , ClassNotFoundException {", "commit_type": "change"}
{"commit_tokens": ["added", "attributes", "for", "Bean", "descriptor"], "add_tokens": "bg . addProperty ( name , String . class , Collections . singletonMap ( \"name\" , \"value\" ) ) ; assertEquals ( name + \" attribute \" , descriptor . getValue ( \"name\" ) , \"value\" ) ; final String value = name + \"value\" ; descriptor . getWriteMethod ( ) . invoke ( bean , new Object [ ] { value } ) ; assertEquals ( name + \" value\" , value , descriptor . getReadMethod ( ) . invoke ( bean , null ) ) ;", "del_tokens": "bg . addProperty ( name , String . class , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "many", "logs", "in", "test"], "add_tokens": "return requestOne ( request ) . flatMap ( message -> Mono . empty ( ) ) . log ( \"flatMap(message ->\" ) . cast ( Void . class ) ;", "del_tokens": "return requestOne ( request ) . transform ( mono -> Mono . empty ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "test", "pass", "whatever", "the", "default", "Locale", "is"], "add_tokens": "import java . util . Locale ; . getInstance ( Locale . US ) ) , new IdentityConverter ( ) ) ; assertEquals ( \"112,312\" , myBean2AsMap . get ( \"myLong\" ) ) ;", "del_tokens": "import net . entropysoft . transmorph . DefaultConverters ; . getInstance ( ) ) , new IdentityConverter ( ) ) ; assertEquals ( \"112 312\", yBean2AsMap. g et( \" myLong\") ) ;", "commit_type": "make"}
{"commit_tokens": ["Improved", "the", "evaluation", "of", "empty", "Target", "elements"], "add_tokens": "if ( values . isEmpty ( ) ) { return null ; } // End if return value . getDefaultValue ( ) ; continue ; if ( result . isEmpty ( ) ) { return null ; }", "del_tokens": "Double result = value . getDefaultValue ( ) ; if ( result == null ) { throw new InvalidFeatureException ( value ) ; } return result ; throw new InvalidFeatureException ( value ) ;", "commit_type": "improve"}
{"commit_tokens": ["Updated", "the", "GraphService", "configurator", "and", "removed", "the", "need", "for", "an", "extra"], "add_tokens": "import com . thinkaurelius . titan . core . TitanGraph ; private static final String DEFAULT_IMPL_CLASS = TitanGraph . class . getName ( ) ; private static final String CONFIG_PATH = \"application.properties\" ;", "del_tokens": "private static final String DEFAULT_IMPL_CLASS = \"no.default.graph.class\" ; private static final String CONFIG_PATH = \"metadata.graph.properties\" ;", "commit_type": "update"}
{"commit_tokens": ["Added", "information", "to", "the", "Readme"], "add_tokens": "String brokerURL = \"tcp://localhost:21616\" ; String username = \"your_username\" ; Client client = new Client ( brokerURL , username ) ;", "del_tokens": "Client client = new Client ( \"tcp://localhost:21616\" , \"your_user\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "handling", "of", "positive", "decimal", "values", "in", "ImmoXML"], "add_tokens": "// ImmoXML specifies positive decimal values including 0 if ( value == null || value . compareTo ( BigDecimal . ZERO ) < 0 ) // ImmoXML specifies positive integer values excluding 0", "del_tokens": "if ( value == null || value . compareTo ( BigDecimal . ZERO ) < 1 )", "commit_type": "fix"}
{"commit_tokens": ["update", "javadocs", "for", "distance", "calculations"], "add_tokens": "* This class estimates the distance between the mobile device and a BLE beacon based on the measured * RSSI and a txPower calibration value that represents the expected RSSI for an iPhone 5 receiving * the signal when it is 1 meter away . * * This class uses a best - fit curve equation with configurable coefficients . The coefficients must * be supplied by the caller and are specific to the Android device being used . See the * < code > ModelSpecificDistanceCalculator < / code > for more information on the coefficients . * / * * * Construct a calculator with coefficients specific for the device 's signal vs. distance * * @ param coefficient1 * @ param coefficient2 * @ param coefficient3 * / * distance = ( mCoefficient1 ) * Math . pow ( ratio , mCoefficient2 ) + mCoefficient3 ;", "del_tokens": "distance = ( 0.42093 ) * Math . pow ( ratio , 6.9476 ) + 0.54992 ;", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "option", "to", "provide", "custom", "initializer", "annotations", "."], "add_tokens": "import java . util . LinkedHashSet ; import java . util . Set ; static final String FL_INITIALIZER_ANNOT = EP_FL_NAMESPACE + \":CustomInitializerAnnotations\" ; static final ImmutableSet < String > DEFAULT_KNOWN_INITIALIZERS = ImmutableSet . of ( \"android.view.View.onFinishInflate\" , \"android.app.Service.onCreate\" , \"android.app.Activity.onCreate\" , \"android.app.Fragment.onCreate\" , \"android.app.Application.onCreate\" , \"javax.annotation.processing.Processor.init\" ) ; static final ImmutableSet < String > DEFAULT_INITIALIZER_ANNOT = ImmutableSet . of ( \"org.junit.Before\" , \"org.junit.BeforeClass\" ) ; // + Anything with @Initializer as its \"simple name\" knownInitializers = getKnownInitializers ( getFlagStringSet ( flags , FL_KNOWN_INITIALIZERS , DEFAULT_KNOWN_INITIALIZERS ) ) ; initializerAnnotations = getFlagStringSet ( flags , FL_INITIALIZER_ANNOT , DEFAULT_INITIALIZER_ANNOT ) ; private static ImmutableSet < String > getFlagStringSet ( ErrorProneFlags flags , String flagName , ImmutableSet < String > defaults ) { Set < String > combined = new LinkedHashSet < String > ( defaults ) ; Optional < String > flagValue = flags . get ( flagName ) ; if ( flagValue . isPresent ( ) ) { for ( String s : flagValue . get ( ) . split ( DELIMITER ) ) { combined . add ( s ) ; } } return ImmutableSet . copyOf ( combined ) ; }", "del_tokens": "knownInitializers = getKnownInitializers ( getFlagStringSet ( flags , FL_KNOWN_INITIALIZERS ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "Support", "for", "headers", "matching", "in", "request"], "add_tokens": "private final static Logger LOGGER = Logger . getLogger ( HttpMockServer . class . getName ( ) ) ; public static boolean DEBUG = true ; public final List < Map . Entry < RequestParams , ResponseParams > > responses ; ConfigResult ( int port , List < Map . Entry < RequestParams , ResponseParams >> responses ) {", "del_tokens": "public static final int MOCK_SERVER_PORT = 8099 ; public static final String SEPARATOR = \"\" ; public static boolean DEBUG = true ; private final static Logger LOGGER = Logger . getLogger ( HttpMockServer . class . getName ( ) ) ; public final List < Map . Entry < ResponsePath , ResponseParams > > responses ; ConfigResult ( int port , List < Map . Entry < ResponsePath , ResponseParams >> responses ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "the", "version", "number", "reporting", "."], "add_tokens": "// $Id: CDDB.java,v 1.3 2000/10/23 07:37:43 mdb Exp $ import java . util . StringTokenizer ; * The client name reported to the CDDB server . public static final String CLIENT_NAME = \"TSP/CDDB_client\" ; / * * * The client version reported to the CDDB server . * / public static String CLIENT_VERSION ; // assigned during static init req . append ( CLIENT_NAME ) . append ( \" \" ) ; req . append ( CLIENT_VERSION ) ; / * * * The client version number is extracted from the version control * revision of this file from a string that is managed by the version * control system . * / static { StringTokenizer tok = new StringTokenizer ( \"$Revision: 1.3 $\" ) ; tok . nextToken ( ) ; CLIENT_VERSION = tok . nextToken ( ) ; }", "del_tokens": "// $Id: CDDB.java,v 1.2 2000/10/23 07:32:12 mdb Exp $ * The client name and version reported to the CDDB server . public static final String CLIENT_NAME_AND_VERSION = \"TSP/CDDB_client $Revision: 1.2 $\" ; req . append ( CLIENT_NAME_AND_VERSION ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "for", "file", "system", "URI", "handling", "."], "add_tokens": "* { @ link FileSystem } implementation for JIMFS . Mostly a thin wrapper around a * { @ link FileSystemService } that implements the required public file system methods . * / * * * Returns the URI for this file system . * / public URI uri ( ) { return uri ; } return service . newWatchService ( ) ; try { service . resourceManager ( ) . close ( ) ; } finally { provider . fileSystemClosed ( this ) ; }", "del_tokens": "return new PollingWatchService ( service ) ; service . resourceManager ( ) . close ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "bugs", "in", "JDBCStateRepository", "and", "updated", "integration", "test"], "add_tokens": "if ( updater . isSchemaVersion1 ( ) ) { updater . migrateToVersion2 ( ) ; } return state ; updateStatement . setString ( 4 , featureState . getFeature ( ) . name ( ) ) ; insertStatement . setString ( 3 , Strings . trimToNull ( featureState . getStrategyId ( ) ) ) ; insertStatement . setString ( 4 , Strings . trimToNull ( paramsAsString ) ) ;", "del_tokens": "updateStatement . setString ( 3 , Strings . trimToNull ( featureState . getStrategyId ( ) ) ) ; updateStatement . setString ( 4 , Strings . trimToNull ( paramsAsString ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "mapping", "existing", "references", "minor", "refactoring", ".", "Contributed", "by", "Venkatesh", "Seetharam"], "add_tokens": "static final String GUID_PROPERTY_KEY = \"guid\" ; static final String ENTITY_TYPE_PROPERTY_KEY = \"type\" ; static final String BACKING_INDEX = \"search\" ; static final String INDEX_NAME = \"metadata\" ;", "del_tokens": "static final String GUID_PROPERTY_KEY = \"GUID\" ; static final String ENTITY_TYPE_PROPERTY_KEY = \"typeName\" ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "filename", "to", "path", "to", "better", "represent", "the", "fact", "it", "is", "the", "full", "path", "."], "add_tokens": "getattrOut . println ( path ) ;", "del_tokens": "getattrOut . println ( filename ) ;", "commit_type": "change"}
{"commit_tokens": ["moved", "trigger", "of", "lightbox", "when", "image", "is", "displayed"], "add_tokens": "String imageId = UUID . nameUUIDFromBytes ( mimeEncodedImage . getBytes ( ) ) . toString ( ) ; links = links + String . format ( \"<a onclick=\\\"img=document.getElementById('%s'); \" + \"img.style.display = (img.style.display == 'none' ? 'block' : 'none');return false\\\">\" + \"Screenshot %s</a><a href=\\\"%s\\\" data-lightbox=\\\"image-1\\\" data-title=\\\"%s\\\">\" + \"<img id=\\\"%s\\\"src=\\\"%s\\\" style='max-width: 250px;display:none;' alt=\\\"This is the title\\\"/></a></br>\" , imageId , index ++ , mimeEncodedImage , StringEscapeUtils . escapeHtml ( name ) , imageId , mimeEncodedImage ) ;", "del_tokens": "links = links + String . format ( \"<a href=\\\"%s\\\" data-lightbox=\\\"image-1\\\" data-title=\\\"%s\\\">\" + \"<img src=\\\"%s\\\" style='max-width: 250px;' alt=\\\"This is the title\\\"/>Screenshot %s</a></br>\" , mimeEncodedImage , StringEscapeUtils . escapeHtml ( name ) , mimeEncodedImage , index ++ ) ;", "commit_type": "move"}
{"commit_tokens": ["added", "way", "to", "fire", "callback", "publicly"], "add_tokens": "notifyOnDateListener ( ) ; public void notifyOnDateListener ( ) { if ( mCallBack != null ) { mCallBack . onDateSet ( DatePickerDialog . this , mCalendar . get ( Calendar . YEAR ) , mCalendar . get ( Calendar . MONTH ) , mCalendar . get ( Calendar . DAY_OF_MONTH ) ) ; } }", "del_tokens": "if ( mCallBack != null ) { mCallBack . onDateSet ( DatePickerDialog . this , mCalendar . get ( Calendar . YEAR ) , mCalendar . get ( Calendar . MONTH ) , mCalendar . get ( Calendar . DAY_OF_MONTH ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Removed", "spaces", "from", "blank", "line", "."], "add_tokens": "", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Add", "some", "empty", "presentation", "models", "DragonBallAdapter", "and", "fill", "MainActivity", "with", "sample", "code"], "add_tokens": "public abstract class HeaderRecyclerViewAdapter < VH extends RecyclerView . ViewHolder , H , T >", "del_tokens": "public abstract class HeaderRecyclerView < VH extends RecyclerView . ViewHolder , H , T >", "commit_type": "add"}
{"commit_tokens": ["Fix", "zip", "file", "generating", ":", "ZipOutputStream", "should", "be", "closed", "to", "finish", "zip", "creating", "correctly"], "add_tokens": "return byteArrayOutputStreamForZippedPass . toByteArray ( ) ;", "del_tokens": "return byteArrayOutputStreamForZippedPass . toByteArray ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "a", "race", "condition", "in", "the", "BasicAuthSpec", "."], "add_tokens": "} , authorization { @ Override public boolean isMatch ( Request a , Request b ) { return a . getHeader ( \"Authorization\" ) . equals ( b . getHeader ( \"Authorization\" ) ) ; }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Removed", "get", "and", "setter", "method", "name", "restrictions", "for", "ParcelProperty", "annotated", "methods", "."], "add_tokens": "( ignoreModifier || astMethod . getAccessModifier ( ) . equals ( ASTAccessModifier . PUBLIC ) ) ; return astMethod . getParameters ( ) . size ( ) == 1 && ( ignoreModifier || ( astMethod . getName ( ) . startsWith ( SET ) && astMethod . getAccessModifier ( ) . equals ( ASTAccessModifier . PUBLIC ) ) ) ;", "del_tokens": "( ignoreModifier || astMethod . getAccessModifier ( ) . equals ( ASTAccessModifier . PUBLIC ) ) ; return astMethod . getParameters ( ) . size ( ) == 1 && astMethod . getName ( ) . startsWith ( SET ) && ( ignoreModifier || astMethod . getAccessModifier ( ) . equals ( ASTAccessModifier . PUBLIC ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "method", "to", "copy", "metadata"], "add_tokens": "public void copyFactor ( DDF ddf ) throws DDFException ; public void copyMetaData ( DDF ddf ) throws DDFException ;", "del_tokens": "public void copyFactor ( DDF oldDDF ) throws DDFException ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "ImmutableArray", "interface", "and", "makes", "Array", "implement", "it"], "add_tokens": "public class Array < T > implements Iterable < T > , ImmutableArray < T > { @ Override public int getSize ( ) { return size ; }", "del_tokens": "public class Array < T > implements Iterable < T > {", "commit_type": "add"}
{"commit_tokens": ["Removed", "logging", "and", "all", "other", "dependencies"], "add_tokens": "throw new IllegalArgumentException ( \"wizard can't be null\" ) ; // Next page is null. Updating buttons and ignoring request. // Previous page is null. Updating buttons and ignoring request. throw new IllegalArgumentException ( \"startPage can't be null\" ) ;", "del_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static final Logger logger = LoggerFactory . getLogger ( WizardController . class ) ; RuntimeException e = new IllegalArgumentException ( \"wizard can't be null\" ) ; logger . error ( \"wizard is null.\" , e ) ; throw e ; logger . error ( \"Next page is null. Updating buttons and ignoring request.\" ) ; logger . error ( \"Previous page is null. Updating buttons and ignoring request.\" ) ; RuntimeException e = new IllegalArgumentException ( \"startPage can't be null\" ) ; logger . error ( \"startPage is null.\" , e ) ; throw e ;", "commit_type": "remove"}
{"commit_tokens": ["Made", "API", "methods", "use", "AssetPair"], "add_tokens": "public static final String WAVES = \"WAVES\" ; static String normalize ( String assetId ) { return assetId == null || assetId . isEmpty ( ) ? Asset . WAVES : assetId ; } static boolean isWaves ( String assetId ) { return WAVES . equals ( normalize ( assetId ) ) ; } static String toJsonObject ( String assetId ) { return isWaves ( assetId ) ? null : assetId ; }", "del_tokens": "public static final String WAVES = \"\" ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "setRefreshing", "()", "method", "for", "allowing", "direction", "when", "refreshing", "programmatically"], "add_tokens": "switch ( mDirection ) { case BOTTOM : endTarget = getMeasuredHeight ( ) - ( int ) ( mSpinnerFinalOffset ) ; break ; case TOP : default : endTarget = ( int ) ( mSpinnerFinalOffset - Math . abs ( mOriginalOffsetTop ) ) ; break ; } switch ( mDirection ) { case BOTTOM : mCurrentTargetOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; break ; case TOP : default : mCurrentTargetOffsetTop = mCircleView . getTop ( ) ; break ; } // mCurrentTargetOffsetTop = mCircleView.getTop(); mCurrentTargetOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; mCurrentTargetOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ;", "del_tokens": "endTarget = ( int ) ( mSpinnerFinalOffset + mOriginalOffsetTop ) ; mCurrentTargetOffsetTop = mCircleView . getTop ( ) ; mCurrentTargetOffsetTop = mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ; mCurrentTargetOffsetTop = mOriginalOffsetTop = getMeasuredHeight ( ) - mCircleView . getMeasuredHeight ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Implemented", "interactive", "mode", "for", "center", "button", "with", "canvas"], "add_tokens": "_knobColor = Color . rgb ( 204 , 204 , 204 ) ;", "del_tokens": "_knobColor = Color . rgb ( 133 , 133 , 133 ) ;", "commit_type": "implement"}
{"commit_tokens": ["Changed", "access", "of", "BaseParser", ".", "toRule", "(", "s", ")", "from", "private", "to", "protected"], "add_tokens": "/ * * * Converts the given object array to an array of rules . * * @ param objects the objects to convert * @ return the rules corresponding to the given objects * / protected Rule [ ] toRules ( @ NotNull Object [ ] objects ) { / * * * Converts the given object to a rule . * * @ param obj the object to convert * @ return the rule corresponding to the given object * / protected Rule toRule ( Object obj ) {", "del_tokens": "private Rule [ ] toRules ( @ NotNull Object [ ] objects ) { private Rule toRule ( Object obj ) {", "commit_type": "change"}
{"commit_tokens": ["moving", "to", "latest", "GH", "and", "increase", "maxSearchMultiplier"], "add_tokens": "throw new RuntimeException ( \"Cannot find matching path! Wrong vehicle \" + encoder + \" or missing OpenStreetMap data? Try to increase maxSearchMultiplier (\" + maxSearchMultiplier + \"). Current gpx sublist:\" + gpxList . size ( ) + \", start list:\" + startQRList + \", end list:\" + endQRList + \", bounds: \" + graph . getBounds ( ) ) ;", "del_tokens": "throw new RuntimeException ( \"Cannot find matching path! Missing or old OpenStreetMap data? \" + gpxList . size ( ) + \", \" + startQRList + \", \" + endQRList ) ;", "commit_type": "move"}
{"commit_tokens": ["adds", "inverse", "()", "method", "to", "ColorSpaceTranformation", "wich", "returns", "the", "corresponding", "inverse", "transform"], "add_tokens": "Math . round ( 0.7720f * y - 0.4030f * cb + 1.4020f * cr ) , Math . round ( 1.0000f * y + 1.7720f * cb - 0.0001f * cr ) ) ; ; static { pairTransforms ( RGB_2_HSV , HSV_2_RGB ) ; pairTransforms ( RGB_2_LAB , LAB_2_RGB ) ; pairTransforms ( RGB_2_YCbCr , YCbCr_2_RGB ) ; } private static final void pairTransforms ( ColorSpaceTransformation t1 , ColorSpaceTransformation t2 ) { t1 . inverse = t2 ; t2 . inverse = t1 ; } private ColorSpaceTransformation inverse ; public ColorSpaceTransformation inverse ( ) { return inverse ; }", "del_tokens": "Math . round ( 0.7720f * y - 0.4030f * cb + 1.4020f * cr ) , Math . round ( 1.0000f * y + 1.7720f * cb - 0.0001f * cr ) ) ; ;", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "computeSolutionHVContribution", "()", "to", "class", "FastHypervolume"], "add_tokens": "* This method forces to compute the contribution of each solution", "del_tokens": "* This method forces to compute the contribution of each solution ( required for PAEShv )", "commit_type": "add"}
{"commit_tokens": ["Add", "concept", "of", "a", "LifecycleInjectorBuilderSuite"], "add_tokens": "return withModuleClass ( ( Class < Module > ) rootModule ) ;", "del_tokens": "return withModuleClass ( ( Class < ? extends Module > ) rootModule ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "how", "a", "tarball", "is", "generated", "when", "sending", "a", "build", "request", ".", "Instead", "of", "creating", "a", "temporary", "folder", "and", "copying", "all", "the", "files", "in", "a", "flat", "structure", "read", "the", "files", "directly", "and", "preserve", "their", "path", "details", "."], "add_tokens": "import java . util . ArrayList ; List < File > filesToAdd = new ArrayList < File > ( ) ; filesToAdd . add ( dockerFile ) ; throw new DockerException ( String . format ( \"Source file %s doesn't exist\" , src ) ) ; filesToAdd . addAll ( FileUtils . listFiles ( src , null , true ) ) ; filesToAdd . add ( src ) ; dockerFolderTar = CompressArchiveUtil . archiveTARFiles ( dockerFolder , filesToAdd , archiveNameWithOutExtension ) ;", "del_tokens": "File tmpDockerContextFolder = null ; //Create tmp docker context folder tmpDockerContextFolder = new File ( FileUtils . getTempDirectoryPath ( ) , \"docker-java-build\" + archiveNameWithOutExtension ) ; FileUtils . copyFileToDirectory ( dockerFile , tmpDockerContextFolder ) ; throw new DockerException ( String . format ( \"Source file %s doesnt' exist\" , src ) ) ; FileUtils . copyDirectoryToDirectory ( src , tmpDockerContextFolder ) ; FileUtils . copyFileToDirectory ( src , tmpDockerContextFolder ) ; dockerFolderTar = CompressArchiveUtil . archiveTARFiles ( tmpDockerContextFolder , archiveNameWithOutExtension ) ; FileUtils . deleteQuietly ( tmpDockerContextFolder ) ; FileUtils . deleteQuietly ( tmpDockerContextFolder ) ;", "commit_type": "change"}
{"commit_tokens": ["Update", "message", "framing", "IDs", "to", "adhere", "to", "gRPC", "spec"], "add_tokens": "public static final byte CALL_HEADER_FRAME = 0x2 ; public static final byte STATUS_FRAME = 0x3 ;", "del_tokens": "public static final byte STATUS_FRAME = 0x2 ; public static final byte RESERVED_FRAME = 0x3 ;", "commit_type": "update"}
{"commit_tokens": ["Fixing", "an", "user", "-", "reported", "problem"], "add_tokens": "if ( user != null ) { // this shouldn't happen, but let's be defensive FavoriteUserProperty fup = user . getProperty ( FavoriteUserProperty . class ) ; return fup . isJobFavorite ( project . getFullName ( ) ) ; } return false ;", "del_tokens": "FavoriteUserProperty fup = user . getProperty ( FavoriteUserProperty . class ) ; return fup . isJobFavorite ( project . getFullName ( ) ) ; } else { return false ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "clone", "method", "(", "use", "datastructhelper", "instead", ")"], "add_tokens": "//DataStruct<K> cloneStruct();", "del_tokens": "DataStruct < K > cloneStruct ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "the", "unqualified", "id", "parse", "bug"], "add_tokens": "template_id , IDENTIFIER", "del_tokens": "IDENTIFIER , template_id", "commit_type": "fix"}
{"commit_tokens": ["Use", "objects", "not", "indexes", "for", "getLeader"], "add_tokens": "import com . google . common . base . Optional ; getLeader ( ) . get ( ) . commit ( bytes ) ; private Optional < SimpleCounterMachine > getLeader ( ) { for ( SimpleCounterMachine counter : counters ) { return Optional . of ( counter ) ; return Optional . absent ( ) ;", "del_tokens": "int leader = getLeader ( ) ; counters . get ( leader ) . commit ( bytes ) ; private int getLeader ( ) { for ( int i = 0 ; i < counters . size ( ) ; i ++ ) { SimpleCounterMachine counter = counters . get ( i ) ; return i ; throw new IllegalStateException ( \"Unable to find leader\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "errors", "in", "handling", "header", "long", "click", "."], "add_tokens": "mTouchMode = TOUCH_MODE_REST ; if ( mTouchMode == TOUCH_MODE_DOWN || mTouchMode == TOUCH_MODE_TAP ) { mTouchModeReset = null ;", "del_tokens": "Log . d ( TAG , ev . toString ( ) ) ; if ( mTouchMode != TOUCH_MODE_DOWN || mTouchMode != TOUCH_MODE_TAP ) {", "commit_type": "fix"}
{"commit_tokens": ["allow", "developer", "to", "add", "attributes", "to", "a", "CliContext"], "add_tokens": "import java . net . SocketException ; } catch ( SocketException e ) { logger . error ( e . getMessage ( ) ) ; IO . close ( socket ) ;", "del_tokens": "try { socket . close ( ) ; } catch ( IOException e ) { logger . warn ( e , \"Failed to close the socket\" ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Added", "two", "helper", "methods", "to", "EmojiManager", "to", "look", "up", "Emoji", "by", "unicode"], "add_tokens": "* @ param sequence Sequence of char that may contain emoji in full or partially . * @ return * < li > Matches . EXACTLY if char sequence in its entirety is an emoji < / li > * < li > Matches . POSSIBLY if char sequence matches prefix of an emoji < / li > * < li > Matches . IMPOSSIBLE if char sequence matches no emoji or prefix of an emoji < / li > public Matches isEmoji ( char [ ] sequence ) { if ( sequence == null ) return Matches . POSSIBLY ; for ( char c : sequence ) {", "del_tokens": "* @ param emojiSequence Sequence of char that may contain emoji in full or partially . * @ return Returns * Matches . EXACTLY if char sequence in its entirety is an emoji * Matches . POSSIBLY if char sequence matches prefix of an emoji * Matches . IMPOSSIBLE if char sequence matches no emoji or prefix of an emoji public Matches isEmoji ( char [ ] emojiSequence ) { for ( char c : emojiSequence ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "canonical", "name", "method", "which", "can", "be", "used", "to", "lookup", "elements", "(", "e", ".", "g", ".", "when", "merging", "models", ")", "."], "add_tokens": "softwareSystem . setId ( idGenerator . generateId ( softwareSystem ) ) ; person . setId ( idGenerator . generateId ( person ) ) ; container . setId ( idGenerator . generateId ( container ) ) ; component . setId ( idGenerator . generateId ( component ) ) ; component . setId ( idGenerator . generateId ( component ) ) ;", "del_tokens": "softwareSystem . setId ( idGenerator . generateId ( softwareSystem ) ) ; person . setId ( idGenerator . generateId ( person ) ) ; container . setId ( idGenerator . generateId ( container ) ) ; component . setId ( idGenerator . generateId ( component ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "bugs", "in", "network", "interface", "management"], "add_tokens": "static public final String VERSION = \"2012-06-01\" ;", "del_tokens": "static public final String VERSION = \"2011-07-15\" ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "default", "trace", "retention", "to", "4096", "."], "add_tokens": "private static final int DEFUALT_MAX_RELATIONSHIPS_PER_TRACE = 4096 ;", "del_tokens": "private static final int DEFUALT_MAX_RELATIONSHIPS_PER_TRACE = 1024 ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "an", "incorrect", "method", "name", "."], "add_tokens": "return RESTCSNodeRelationshipModeV1 . getRelationshipModeId ( getProxyEntity ( ) . getRelationshipMode ( ) ) ; getEntity ( ) . setRelationshipMode ( RESTCSNodeRelationshipModeV1 . getRelationshipMode ( mode ) ) ;", "del_tokens": "return RESTCSNodeRelationshipModeV1 . getRelationshipTypeId ( getProxyEntity ( ) . getRelationshipMode ( ) ) ; getEntity ( ) . setRelationshipMode ( RESTCSNodeRelationshipModeV1 . getRelationshipType ( mode ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "Query", "/", "Form", "parameter", "support", "group", "them", "for", "now"], "add_tokens": "import io . swagger . models . parameters . QueryParameter ; // QUERY & FORM QueryParameter queryParameter = new QueryParameter ( ) ; queryParameter . setName ( methodParameterName ) ; queryParameter . setDescription ( getDescription ( methodParameter ) ) ; setPropertyType ( queryParameter , method ) ; operation . addParameter ( queryParameter ) ;", "del_tokens": "// TODO Query Parameter?", "commit_type": "add"}
{"commit_tokens": ["Change", "the", "logging", "collector", "precondition", "to", "logging", "-", "it", "causes", "too", "many", "issues", "in", "downstream", "tests"], "add_tokens": "import org . slf4j . Logger ; private static final Logger LOGGER = MetricsLoggerFactory . getLogger ( LoggingCollector . class ) ; if ( originalListener . getClass ( ) . getName ( ) . startsWith ( \"nebula.plugin.metrics.collector.LoggingCollector\" ) ) { LOGGER . error ( \"Output event listener is already wrapped. A previous build against this daemon did not clean reset the logging collection. Please report this bug\" ) ; return ; }", "del_tokens": "import static com . google . common . base . Preconditions . checkState ; checkState ( ! originalListener . getClass ( ) . getName ( ) . startsWith ( \"nebula.plugin.metrics.collector.LoggingCollector\" ) , \"Output event listener is already wrapped. A previous build against this daemon did not clean reset the logging collection\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "back", "Scroll", "&", "Stitch", "strategy"], "add_tokens": "VIEWPORT_ONLY , WHOLE_PAGE , WHOLE_PAGE_SCROLL_AND_STITCH", "del_tokens": "VIEWPORT_ONLY , WHOLE_PAGE", "commit_type": "add"}
{"commit_tokens": ["Changed", "visibility", "of", "constructors", "to", "package", "private"], "add_tokens": "CircuitBreakerState ( CircuitBreakerStateMachine stateMachine ) { CircuitBreakerState ( CircuitBreakerStateMachine stateMachine , CircuitBreakerState currentState ) {", "del_tokens": "public CircuitBreakerState ( CircuitBreakerStateMachine stateMachine ) { public CircuitBreakerState ( CircuitBreakerStateMachine stateMachine , CircuitBreakerState currentState ) {", "commit_type": "change"}
{"commit_tokens": ["Adds", "support", "for", "the", "&", "operator", "in", "sub", "-", "sections"], "add_tokens": "private boolean keepCommas = false ; * * @ param keepCommas determines if commas are kept in the output or not public ValueList ( boolean keepCommas ) { this . keepCommas = keepCommas ; sb . append ( keepCommas ? \",\" : \" \" ) ; ValueList result = new ValueList ( keepCommas ) ;", "del_tokens": "public ValueList ( ) { sb . append ( \" \" ) ; ValueList result = new ValueList ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "m2e", "mapping", "for", "license", "-", "maven", "-", "plugin", ".", "Added", "some", "serialVersionUIDs", "."], "add_tokens": "private static final long serialVersionUID = 2958878066896490587L ; * @ return the detail message string of this < tt > Throwable < / tt > instance ( which may be < tt > null < / tt > ) .", "del_tokens": "* @ return the detail message string of this < tt > Throwable < / tt > instance * ( which may be < tt > null < / tt > ) .", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "with", "generic", "data", "types"], "add_tokens": "// Update wildcard and typename to include wildcards and generics wildcardTypeName = TypeName . get ( type ) ; typeName = TypeName . get ( type ) ;", "del_tokens": "if ( type instanceof WildcardType ) { wildcardTypeName = TypeName . get ( type ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "using", "DateFormat", "on", "background", "thread"], "add_tokens": "private String fileName ; fileName = SCREENSHOT_FILE_FORMAT . format ( new Date ( ) ) ; File file = new File ( screenshotFolder , fileName ) ;", "del_tokens": "File file = new File ( screenshotFolder , SCREENSHOT_FILE_FORMAT . format ( new Date ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "JavaDocs", ".", "More", "to", "follow", "."], "add_tokens": "/ * * * A family represents a group of components . It is used to describe what entities a system * should process . * * Example : Family . getFamilyFor ( PositionComponent . class , VelocityComponent . class ) * * Families can 't be instantiate directly but must be accessed via Family.getFamilyFor(), this is * to avoid duplicate families that describe the same components . * * @ author Stefan Bachmann * / /** The hashmap holding all families */ /** A bitset used for quick comparison between families & entities */ /** Each family has a unique index, used for bitmasking */ /** Private constructor, use static method Family.getFamilyFor() */ / * * * Returns this family 's unique index * / / * * * Checks if the passed entity matches this family 's requirements. * @ param entity The entity to check for matching * @ return Whether the entity matches or not * / public boolean matches ( Entity entity ) { BitSet entityComponentBits = entity . getComponentBits ( ) ; / * * * Returns a family with the passed componentTypes as a descriptor . Each set of component types will * always return the same Family instance . * @ param componentTypes The components to describe the family * @ return The family * /", "del_tokens": "public boolean matches ( Entity e ) { BitSet entityComponentBits = e . getComponentBits ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "another", "test", "for", "Serialized", "utility", "class"], "add_tokens": "public void testSerializeAndDeserializeOfNonEmptyStream ( ) { File file = new File ( \"target/temp1\" ) ; @ Test public void testSerializeAndDeserializeOfEmptyStream ( ) { File file = new File ( \"target/temp2\" ) ; file . delete ( ) ; Observable < Integer > source = Observable . empty ( ) ; Serialized . write ( source , file , false ) . subscribe ( ) ; assertTrue ( file . exists ( ) ) ; List < Integer > list = Serialized . < Integer > read ( file ) . toList ( ) . toBlocking ( ) . single ( ) ; assertTrue ( list . isEmpty ( ) ) ; }", "del_tokens": "public void testSerializeAndDeserialize ( ) { File file = new File ( \"target/temp123\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixing", "the", "inner", "/", "outer", "loops", "logic"], "add_tokens": "if ( bestDelta < 0 ) {", "del_tokens": "if ( null == bestRule ) { break ; } if ( 0.0 == bestDelta ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "the", "super", "call", "to", "the", "xhtml", "parser", "because", "that", "one", "will", "call", "doxia", "for", "every", "node", "which", "will", "cut", "out", "most", "of", "the", "attributes", "of", "different", "tags", "and", "will", "result", "in", "corrupt", "html", ".", "Instead", "we", "call", "sink", ".", "rawText", "()", "which", "will", "pass", "the", "already", "generated", "html"], "add_tokens": "import org . asciidoctor . OptionsBuilder ; import java . io . IOException ; import java . io . Reader ; OptionsBuilder . options ( ) . headerFooter ( false ) . safe ( SafeMode . UNSAFE ) . backend ( \"xhtml\" ) . attributes ( AttributesBuilder . attributes ( ) . unsetStyleSheet ( ) . attribute ( \"idprefix\" , \"a_\" ) . asMap ( ) ) . asMap ( ) ) ; sink . rawText ( result ) ;", "del_tokens": "import java . io . IOException ; import java . io . Reader ; import java . io . StringReader ; import org . asciidoctor . OptionsBuilder ; OptionsBuilder . options ( ) . headerFooter ( true ) . safe ( SafeMode . UNSAFE ) . backend ( \"xhtml\" ) . attributes ( AttributesBuilder . attributes ( ) . unsetStyleSheet ( ) . attribute ( \"idprefix\" , \"a_\" ) . asMap ( ) ) . asMap ( ) ) ; // prevent site plugin from breaking font-based icon syntax result = result . replaceAll ( \"<i class=\\\"fa icon-([^\\\"]+)\\\"([^>]*)></i>\" , \"<span class=\\\"fa icon-$1\\\"$2></span>\" ) ; super . parse ( new StringReader ( result ) , sink ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "loading", "multiple", "root", "hierarchies", "in", "TABLoader", ".", "It", "now", "adds", "artifical", "Top", "node"], "add_tokens": "* Expects a single - rooted hierarchy , otherwise adds an artificial \"Top\" node . //TODO the loader could be made static, but this requires a change in the ILoader interface * @ throws IOException IOException int artificialLevel = 0 ; //flags that we added Top and need an increment in level int_depth = int_depth + artificialLevel ; if ( 0 == int_depth ) { //looks like we got multiple roots in the input artificialLevel = 1 ; fatherId = result . newNode ( \"Top\" , null ) ; rootPath . add ( 0 , fatherId ) ; int_depth = 1 ; }", "del_tokens": "/ * * refactored , deleted class level variables and changed rootPath from array [ ] * to allay list * / //TODO the loader could be made static, but this requires a change in the ILoader interface * @ throws IOException", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "unit", "test", "."], "add_tokens": ". setFilter ( \"scale='trunc(ow/a/2)*2:320'\" ) assertThat ( args , is ( Arrays . asList ( \"-y\" , \"-v\" , \"error\" , \"-i\" , \"input\" , \"-s\" , \"320x240\" , \"-vf\" , \"scale='trunc(ow/a/2)*2:320'\" , \"output\" ) ) ) ;", "del_tokens": ". disableSubtitle ( ) . disableVideo ( ) . setFilter ( \"scale='trunc(ow/a/2)*2:320'\" ) assertThat ( args , is ( Arrays . asList ( \"-y\" , \"-v\" , \"error\" , \"-i\" , \"input\" , \"-vn\" , \"-an\" , \"-sn\" , \"-vf\" , \"scale='trunc(ow/a/2)*2:320'\" , \"output\" ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "where", "managed", "Map", "has", "a", "key", "removed", "then", "re", "-", "added", "."], "add_tokens": "import java . util . Collections ; if ( removedKeys . size ( ) > 0 ) { removedKeys . remove ( stringKey ) ; } if ( addedOrUpdatedKeys . size ( ) > 0 ) { addedOrUpdatedKeys . remove ( stringKey ) ; } // TODO: allow key set to be modified return Collections . unmodifiableSet ( delegate . keySet ( ) ) ; // TODO: allow values to be modified return Collections . unmodifiableCollection ( delegate . values ( ) ) ;", "del_tokens": "// TODO: handle case when set is modified return delegate . keySet ( ) ; // TODO: convert items to a DirtyableDBObject... // TODO: handle case when set is modified return delegate . values ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "the", "Flexy", "Pool", "to", "work", "even", "if", "there", "is", "no", "strategy", "configured"], "add_tokens": "import com . vladmihalcea . flexypool . adaptor . PoolAdapter ; private final PoolAdapter < T > poolAdapter ; this . poolAdapter = configuration . getPoolAdapter ( ) ; this . targetDataSource = poolAdapter . getTargetDataSource ( ) ; LOGGER . info ( \"The flexy pool is not using any strategy!\" ) ; if ( ! connectionAcquiringStrategies . isEmpty ( ) ) { for ( ConnectionAcquiringStrategy strategy : connectionAcquiringStrategies ) { try { connection = strategy . getConnection ( context ) ; break ; } catch ( AcquireTimeoutException e ) { LOGGER . warn ( \"Couldn't retrieve connection from strategy {} with context {}\" , strategy , context ) ; } } else { connection = poolAdapter . getConnection ( context ) ;", "del_tokens": "this . targetDataSource = configuration . getPoolAdapter ( ) . getTargetDataSource ( ) ; throw new IllegalArgumentException ( \"The flexy pool pool must use at least one strategy!\" ) ; for ( ConnectionAcquiringStrategy strategy : connectionAcquiringStrategies ) { try { connection = strategy . getConnection ( context ) ; break ; } catch ( AcquireTimeoutException e ) { LOGGER . warn ( \"Couldn't retrieve connection from strategy {} with context {}\" , strategy , context ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "variant", "of", "sendSimpleErrorResponse", "w", "/", "o", "extra"], "add_tokens": "\"Not Found\" ) ; \"MethodNotAllowed\" , \"Method Not Allowed\" ) ; \"InvalidBucketName\" , \"Bad Request\" ) ; \"Bad Request\" ) ; \"Not Found\" ) ; \"Bad Request\" ) ; \"MissingContentLength\" , \"Length Required\" ) ; \"Invalid Argument\" ) ; \"Not Found\" ) ; \"Bad Request\" ) ; private static void sendSimpleErrorResponse ( HttpServletResponse response , int status , String code , String message ) { sendSimpleErrorResponse ( response , status , code , message , Optional . < String > absent ( ) ) ; }", "del_tokens": "\"Not Found\" , Optional . < String > absent ( ) ) ; \"MethodNotAllowed\" , \"Method Not Allowed\" , Optional . < String > absent ( ) ) ; \"InvalidBucketName\" , \"Bad Request\" , Optional . < String > absent ( ) ) ; \"Bad Request\" , Optional . < String > absent ( ) ) ; \"Not Found\" , Optional . < String > absent ( ) ) ; \"Bad Request\" , Optional . < String > absent ( ) ) ; \"MissingContentLength\" , \"Length Required\" , Optional . < String > absent ( ) ) ; \"Invalid Argument\" , Optional . < String > absent ( ) ) ; \"Not Found\" , Optional . < String > absent ( ) ) ; \"Bad Request\" , Optional . < String > absent ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "the", "right", "interface", "for", "Log4jServiceImpl", "and", "changed", "the", "build", ".", "properties", "to", "include", "Import", "-", "Package", "statements", "that", "work", "."], "add_tokens": "// ls.log( LogService.LOG_DEBUG, \"*******TESTING*********\" ); // ls.log( LogService.LOG_ERROR, \"*******TESTING*********\", new Exception() ); // ls.log( LogService.LOG_INFO, \"*******TESTING*********\" ); // ls.log( LogService.LOG_WARNING, \"*******TESTING*********\" ); // ls.log( null, LogService.LOG_INFO, \"*******TESTING*********\" );", "del_tokens": "ls . log ( LogService . LOG_DEBUG , \"*******TESTING*********\" ) ; ls . log ( LogService . LOG_ERROR , \"*******TESTING*********\" , new Exception ( ) ) ; ls . log ( LogService . LOG_INFO , \"*******TESTING*********\" ) ; ls . log ( LogService . LOG_WARNING , \"*******TESTING*********\" ) ; ls . log ( null , LogService . LOG_INFO , \"*******TESTING*********\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["updated", "POM", ".", "xml", "a", "little", "bit", "and", "fixed", "address", "test"], "add_tokens": "assertEquals ( \"More than one error is present\" , 4 , errors . size ( ) ) ; assertEquals ( \"Error message does not match expected\" , error2 . getMessage ( ) , \"House number is invalid\" ) ;", "del_tokens": "assertEquals ( \"More than one error is present\" , errors . size ( ) , 2 ) ; assertEquals ( \"Error message does not match expected\" , error2 . getMessage ( ) , \"House number is missing\" ) ; ;", "commit_type": "update"}
{"commit_tokens": ["Updated", ":", "Modified", "Login", "Screen"], "add_tokens": "* @ version $ Revision : 1.5 $ $ Date : 2000 / 01 / 26 16 : 16 : 45 $", "del_tokens": "* @ version $ Revision : 1.4 $ $ Date : 2000 / 01 / 21 10 : 35 : 27 $", "commit_type": "update"}
{"commit_tokens": ["Added", "methods", "to", "get", "access", "to", "the", "TransactionManager"], "add_tokens": "import org . simpleds . tx . TransactionManager ; / * * * @ return the currently configured { @ link TransactionManager } instance * / public TransactionManager getTransactionManager ( ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "rect", "join", "type"], "add_tokens": "strokeLayer . setLineJoinType ( stroke . getJoinType ( ) ) ; if ( rectCornerRadius == 0 ) { canvas . drawRect ( fillRect , paint ) ; } else { canvas . drawRoundRect ( fillRect , rectCornerRadius , rectCornerRadius , paint ) ; }", "del_tokens": "canvas . drawRoundRect ( fillRect , rectCornerRadius , rectCornerRadius , paint ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "keygenerator", "to", "use", "a", "config", "object", "rather", "than", "multiple"], "add_tokens": "* name changed from XX - unencrypted to XX - encrypted and the value being encoded . < br > public SecureProperties ( Properties defaults ) throws KeyStoreException , NoSuchAlgorithmException , CertificateException , FileNotFoundException , UnrecoverableEntryException , IOException { * specified key . NOTE : If you specify key - path its important to have * FIRST specified entry - name and keystore - password or an error will * occur . * Method will load the KeyStore from file using the key path , entry name , * and keystore password from the properties file . String keyEntryName = this . getProperty ( \"entry-name\" ) ; String keyStorePassword = this . getProperty ( \"keystore-password\" ) ; key = KeystoreUtils . getAESSecretKey ( new File ( keypath ) , keyEntryName , keyStorePassword ) ;", "del_tokens": "* name changed from XXX - unencrypted to XXX - encrypted and the value being * encoded . < br > public SecureProperties ( Properties defaults ) throws KeyStoreException , NoSuchAlgorithmException , CertificateException , FileNotFoundException , UnrecoverableEntryException , IOException { * specified key . * Method will get the key - path from this properties object and attempt to * load the keystore from file . key = KeystoreUtils . getAESSecretKey ( new File ( keypath ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "battery", "profile", ".", "Change", "disconnection", "logic", "to", "close", "the", "client", "connection", ".", "Remove", "reconnection", "semantics", ".", "If", "reconnects", "are", "needed", "do", "it", "from", "the", "app", ".", "This", "ensures", "the", "connect", "/", "disconnect", "life", "cycle", "is", "always", "the", "same", "."], "add_tokens": "import nl . littlerobots . bean . internal . battery . BatteryProfile . BatteryLevelCallback ; mGattClient . close ( ) ; mGattClient . close ( ) ; / * * * Read the battery level * * @ param callback the callback for the result , the battery level in the range of 0 - 100 % * / public void readBatteryLevel ( final Callback < Integer > callback ) { mGattClient . getBatteryProfile ( ) . getBatteryLevel ( new BatteryLevelCallback ( ) { @ Override public void onBatteryLevel ( int percentage ) { callback . onResult ( percentage ) ; } } ) ; }", "del_tokens": "mGattClient . disconnect ( ) ; mGattClient . close ( ) ; mGattClient . close ( ) ; Log . w ( TAG , \"onSerialMessageReceived after disconnect from device \" + getDevice ( ) . getAddress ( ) ) ; mGattClient . disconnect ( ) ; //mTransport = new GattSerialTransport(mTransportListener, device); //mTransport.connect(context); mGattClient . disconnect ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "LongKeyMapRepository", "constructor", "that", "would", "fail", "when", "passing", "an", "empty", "map"], "add_tokens": "idGenerator = ( ! registry . isEmpty ( ) ) ? new AtomicLong ( Collections . max ( registry . keySet ( ) ) ) : new AtomicLong ( ) ;", "del_tokens": "idGenerator = new AtomicLong ( Collections . max ( registry . keySet ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "the", "endless", "loop", "when", "you", "feed", "the", "parser", "a", ".", "new", "()"], "add_tokens": "Characters c = Characters . NONE ; for ( char a = 'a' ; a <= 'z' ; a ++ ) c = c . add ( a ) ; for ( char a = 'A' ; a <= 'Z' ; a ++ ) c = c . add ( a ) ; if ( ! start ) for ( char a = '0' ; a <= '9' ; a ++ ) c = c . add ( a ) ; return c ;", "del_tokens": "return Characters . ALL_EXCEPT_EMPTY ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "link", "previews", "to", "configuration", "sync", "."], "add_tokens": "private final Optional < Boolean > linkPreviews ; Optional < Boolean > typingIndicators , Optional < Boolean > linkPreviews ) this . linkPreviews = linkPreviews ; public Optional < Boolean > getLinkPreviews ( ) { return linkPreviews ; }", "del_tokens": "Optional < Boolean > typingIndicators )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "where", "java", ".", "sql", ".", "Date", "type", "environment", "variables", "changed", "into", "Strings", "after", "a", "state", "save", "and", "reload", "from", "database", "."], "add_tokens": "Date now = new Date ( ) ; test ( now ) ; test ( new java . sql . Date ( now . getTime ( ) ) ) ; test ( new java . sql . Time ( now . getTime ( ) ) ) ; test ( new java . sql . Timestamp ( now . getTime ( ) ) ) ; test ( new Date ( 0 ) ) ; test ( new java . sql . Date ( 0 ) ) ; test ( new java . sql . Time ( 0 ) ) ; test ( new java . sql . Timestamp ( 0 ) ) ;", "del_tokens": "test ( new Date ( 0 ) ) ; test ( new Date ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "getFirstHeader", "rather", "than", "getHeaders"], "add_tokens": "private static String headerValue ( HttpResponse response , String name ) { Header header = response . getFirstHeader ( name ) ; return header == null ? null : header . getValue ( ) ;", "del_tokens": "private static String headerValue ( HttpResponse response , String header ) { Header [ ] headers = response . getHeaders ( header ) ; return headers . length == 0 ? null : headers [ 0 ] . getValue ( ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "DownloadButton", ".", "java", "and", "SelectFiles", ".", "java"], "add_tokens": "import com . sdl . selenium . web . button . SelectFiles ; public class DownloadFile extends SelectFiles {", "del_tokens": "import org . openqa . selenium . interactions . Actions ; public class DownloadFile extends WebLocator { / * * * Download file with AutoIT . Work only on FireFox . * Use only this : button . download ( new String [ ] { \"C:\\\\download.exe\" , \"TestSet.tmx\" } ) ; * * @ param filePath * / public boolean download ( String [ ] filePath ) { driver . switchTo ( ) . window ( driver . getWindowHandle ( ) ) ; focus ( ) ; Actions builder = new Actions ( driver ) ; builder . moveToElement ( currentElement ) . build ( ) . perform ( ) ; builder . click ( ) . build ( ) . perform ( ) ; driver . switchTo ( ) . defaultContent ( ) ; return RunExe . getInstance ( ) . download ( filePath ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "<hostname", ">", "setting", "to", "a", "container", "configuration", "."], "add_tokens": ". withEnv ( configuration . getEnv ( ) ) . withHostname ( configuration . getHostname ( ) ) ;", "del_tokens": ". withEnv ( configuration . getEnv ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "integration", "test", "abstract", "so", "that", "integration", "tests", "can", "pass", "."], "add_tokens": "public abstract class SimpleLdapTemplateITest extends AbstractLdapTemplateIntegrationTest {", "del_tokens": "public class SimpleLdapTemplateITest extends AbstractLdapTemplateIntegrationTest {", "commit_type": "make"}
{"commit_tokens": ["Added", "test", "case", "for", "entry", "translator", "."], "add_tokens": "* @ param claimStrategyOption threading strategy for producers claiming { @ link Entry } s in the ring .", "del_tokens": "* @ param claimStrategyOption threading strategy for producers claiming { @ link Entry } in the ring .", "commit_type": "add"}
{"commit_tokens": ["added", "iban", "structures", "to", "properties", "file"], "add_tokens": "n , // owner account number (\"1\", \"2\" etc) i ; // identification number", "del_tokens": "n ; // owner account number (\"1\", \"2\" etc)", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "bug", "in", "DefaultRoleManager", ".", "createRole", "()"], "add_tokens": "if ( hasRole ( name ) ) { return allRoles . get ( name ) ; } else { Role role = new Role ( name ) ; allRoles . put ( name , role ) ; return role ; }", "del_tokens": "return allRoles . getOrDefault ( name , new Role ( name ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "text", "gravity", "and", "position", "priority", "supported"], "add_tokens": "progressThree . setProgress ( progressThree . getProgress ( ) + 10 ) ; progressThree . setProgress ( progressThree . getProgress ( ) - 10 ) ;", "del_tokens": "progressThree . setProgress ( progressThree . getProgress ( ) + 1 ) ; progressThree . setProgress ( progressThree . getProgress ( ) - 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "JSON", "Patch", "payload", "validation", "API", "+", "refactoring"], "add_tokens": "public static Operation fromRfcName ( String rfcName ) throws InvalidJsonPatchException { if ( rfcName == null ) throw new InvalidJsonPatchException ( \"rfcName cannot be null\" ) ; Operation op = OPS . get ( rfcName . toLowerCase ( ) ) ; if ( op == null ) throw new InvalidJsonPatchException ( \"unknown / unsupported operation \" + rfcName ) ; return op ;", "del_tokens": "import static com . google . common . base . Preconditions . checkNotNull ; public static Operation fromRfcName ( String rfcName ) { checkNotNull ( rfcName , \"rfcName cannot be null\" ) ; return checkNotNull ( OPS . get ( rfcName . toLowerCase ( ) ) , \"unknown / unsupported operation %s\" , rfcName ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "related", "to", "changePrefix", "pre", "-", "processor"], "add_tokens": "String tail = e . getKey ( ) . substring ( prefix . length ( ) ) . replaceFirst ( \"^[\\\\.]?\" + Pattern . quote ( from ) , to ) String newKey = isEmptyStr ( tail ) ? prefix : ( prefix + \".\" + tail ) . replaceFirst ( \"^\\\\.\" , \"\" ) ; return ( errors ) -> { return errors . stream ( ) logger . debug ( \"converting errors list to errors tree\" ) ;", "del_tokens": "String toBeReplaced = e . getKey ( ) . substring ( prefix . length ( ) ) ; String newKey = ( prefix + toBeReplaced . replaceFirst ( \"^\" + Pattern . quote ( from ) , to ) ) return ( errs ) -> { return errs . stream ( ) logger . debug ( \"converting errors list to errors tree\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", ".", "enl", "to", "help"], "add_tokens": "description = \"input bibliography FILE (*.bib, *.enl, *.json)\" ,", "del_tokens": "description = \"input bibliography FILE (*.bib, *.json)\" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "copyright", "info", "and", "JavaDoc", "."], "add_tokens": "/ * Copyright 2008 Alin Dreghiciu . * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or * implied . * * See the License for the specific language governing permissions and * limitations under the License . * / * Hello World Activator . * * @ author Alin Dreghiciu * @ since 0.2 . 4 , January 02 , 2007 / * * * HttpService reference . * /", "del_tokens": "* Extension of the default OSGi bundle activator", "commit_type": "add"}
{"commit_tokens": ["add", "fix", "for", "encoding", "problems"], "add_tokens": "byte [ ] clearBytes = clearText . getBytes ( STRING_ENCODING ) ;", "del_tokens": "byte [ ] clearBytes = clearText . getBytes ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "waitpid", "()", "call", "on", "launch", "failure", "(", "mostly", "for", "Linux", ")", "to", "reap", "zombie", "processes", "."], "add_tokens": "if ( rc != 0 && pid != 0 ) { IntByReference exit = new IntByReference ( ) ; LibC . waitpid ( pid , exit , LibC . WNOHANG ) ; } checkReturnCode ( rc , \"Invocation of posix_spawn() failed\" ) ;", "del_tokens": "checkReturnCode ( rc , \"Invocation of posix_spawn() failed\" ) ; exitPending . countDown ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "test", "for", "TimeStamp", "."], "add_tokens": "TimeStamp time = TimeStamp . time ( 0 , 0 ) ; TimeStamp newTime = time . plus ( TimeDuration . ofMillis ( 100 ) ) ; assertThat ( newTime , equalTo ( TimeStamp . time ( 0 , 100000000 ) ) ) ; } @ Test public void plus2 ( ) { TimeStamp time = TimeStamp . time ( 100 , 100000000 ) ; TimeStamp newTime = time . plus ( TimeDuration . ofNanos ( 999000000 ) ) ; assertThat ( newTime , equalTo ( TimeStamp . time ( 101 , 99000000 ) ) ) ; } @ Test public void plus3 ( ) { TimeStamp time = TimeStamp . time ( 100 , 750000000 ) ; TimeStamp newTime = time . plus ( TimeDuration . ofSeconds ( 5.750 ) ) ; assertThat ( newTime , equalTo ( TimeStamp . time ( 106 , 500000000 ) ) ) ;", "del_tokens": "TimeStamp time = TimeStamp . time ( 0 , 0 ) . plus ( TimeDuration . ofMillis ( 100 ) ) ; assertThat ( time . getSec ( ) , equalTo ( 0L ) ) ; assertThat ( time . getNanoSec ( ) , equalTo ( 100000000 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "retrieving", "view", "definitions", "and", "creating", "them", "in", "the", "generateChangeLog", "command", "."], "add_tokens": "assertEquals ( 0 , finalDiffResult . getMissingViews ( ) . size ( ) ) ;", "del_tokens": "// assertEquals(0, finalDiffResult.getMissingViews().size()); //disabled for now because we can't diff views", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "method", "name", ":", "Vebatim", "-", ">", "Verbatim", "."], "add_tokens": "w . fieldVerbatim ( \"children\" , children . toString ( ) ) ;", "del_tokens": "w . fieldVebatim ( \"children\" , children . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "generics", "to", "avoid", "suppress", "warnings"], "add_tokens": "Map < String , Object > model = new HashMap < String , Object > ( ) ;", "del_tokens": "@ SuppressWarnings ( { \"rawtypes\" , \"unchecked\" } ) Map model = new HashMap ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "wrong", "greater", "/", "less", "than", "operator"], "add_tokens": "if ( Math . random ( ) < 0.1 ) {", "del_tokens": "if ( Math . random ( ) > 0.1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Made", "Asciidoctor", "options", "customisable", "."], "add_tokens": "import org . asciidoctor . Attributes ; import org . asciidoctor . AttributesBuilder ; import org . asciidoctor . Options ; import org . asciidoctor . OptionsBuilder ; // Map<String, Object> options = new HashMap<String, Object>(); // Map<String, Object> attributes = new HashMap<String, Object>(); // attributes.put(\"source-highlighter\", config.getString(\"asciidoctor.highlighter\")); // options.put(\"attributes\", attributes); Attributes attributes = AttributesBuilder . attributes ( config . getString ( \"asciidoctor.options\" ) ) . get ( ) ; Options options = OptionsBuilder . options ( ) . attributes ( attributes ) . get ( ) ;", "del_tokens": "Map < String , Object > options = new HashMap < String , Object > ( ) ; Map < String , Object > attributes = new HashMap < String , Object > ( ) ; attributes . put ( \"source-highlighter\" , config . getString ( \"asciidoctor.highlighter\" ) ) ; options . put ( \"attributes\" , attributes ) ;", "commit_type": "make"}
{"commit_tokens": ["Made", "rescrolling", "more", "accurate", "and", "added", "test", "for", "it", "."], "add_tokens": "private Point2D preparedCenter = null ; preparedCenter = new Point2D . Double ( viewRect . getCenterX ( ) , viewRect . getCenterY ( ) ) ; Dimension viewSize = viewport . getExtentSize ( ) ; Rectangle view = new Rectangle ( ( int ) Math . round ( preparedCenter . getX ( ) - viewSize . width / 2.0 ) , ( int ) Math . round ( preparedCenter . getY ( ) - viewSize . height / 2.0 ) , viewSize . width , viewSize . height ) ;", "del_tokens": "private Point preparedCenter = null ; preparedCenter = new Point ( viewRect . x + viewRect . width / 2 , viewRect . y + viewRect . height / 2 ) ; Dimension viewSize = ( viewport ) . getExtentSize ( ) ; Rectangle view = new Rectangle ( preparedCenter . x - viewSize . width / 2 , preparedCenter . y - viewSize . height / 2 , viewSize . width , viewSize . height ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "method", "getActions", "on", "Card"], "add_tokens": "Member fetchMember ( Argument ... args ) { Member fetchMemberCreator ( Argument ... args ) { Organization fetchOrganization ( Argument ... args ) { private TList listAfter ; private TList listBefore ; private Date dateLastEdited ; public Date getDateLastEdited ( ) { return dateLastEdited ; } public void setDateLastEdited ( Date dateLastEdited ) { this . dateLastEdited = dateLastEdited ; } public TList getListAfter ( ) { return listAfter ; } public void setListAfter ( TList listAfter ) { this . listAfter = listAfter ; } public TList getListBefore ( ) { return listBefore ; } public void setListBefore ( TList listBefore ) { this . listBefore = listBefore ; } private String idList ; public String getIdList ( ) { return idList ; } public void setIdList ( String idList ) { this . idList = idList ; }", "del_tokens": "Member fetchMember ( Argument ... args ) { Member fetchMemberCreator ( Argument ... args ) { Organization fetchOrganization ( Argument ... args ) {", "commit_type": "add"}
{"commit_tokens": ["Removed", "test", "until", "we", "could", "find", "a", "self", "-", "signed", "certificate", "."], "add_tokens": "//private static final String httpsGoogleUrl = \"https://www.google.com\"; Constructor < UrlUtilities > con = UrlUtilities . class . getDeclaredConstructor ( ) ; //TODO - add in when we find self-signing site. // assertNull(UrlUtilities.getContentFromUrl(httpsGoogleUrl, Proxy.NO_PROXY, null, null)); // assertNull(UrlUtilities.getContentFromUrl(httpsGoogleUrl, null, null, Proxy.NO_PROXY, null, null)); // assertNull(UrlUtilities.getContentFromUrl(httpsGoogleUrl, null, 0, null, null, false));", "del_tokens": "private static final String httpsGoogleUrl = \"https://www.google.com\" ; Constructor < UrlUtilities > con = c . getDeclaredConstructor ( ) ; assertNull ( UrlUtilities . getContentFromUrl ( httpsGoogleUrl , Proxy . NO_PROXY , null , null ) ) ; assertNull ( UrlUtilities . getContentFromUrl ( httpsGoogleUrl , null , null , Proxy . NO_PROXY , null , null ) ) ; assertNull ( UrlUtilities . getContentFromUrl ( httpsGoogleUrl , null , 0 , null , null , false ) ) ; assertEquals ( new String ( content8 ) , new String ( content1 ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "expected", "geonameID", "for", "LONDON_UK", "from", "2643743", "to", "2643741", "existing", "test", "was", "breaking", "the", "build"], "add_tokens": "int LONDON_UK = 2643741 ;", "del_tokens": "int LONDON_UK = 2643743 ;", "commit_type": "update"}
{"commit_tokens": ["Fixing", "Issue", "207", ":", "Concurrent", "modification", "exception", "on", "redeploy", "of", "Diameter", "BASE", "ra", "alpha"], "add_tokens": "import java . util . Iterator ; try { Iterator < ApplicationId > appIdsIt = stack . getMetaData ( ) . getLocalPeer ( ) . getCommonApplications ( ) . iterator ( ) ; while ( appIdsIt . hasNext ( ) ) { network . removeNetworkReqListener ( appIdsIt . next ( ) ) ; // Update the iterator (avoid ConcurrentModificationException) appIdsIt = stack . getMetaData ( ) . getLocalPeer ( ) . getCommonApplications ( ) . iterator ( ) ; } catch ( InternalException e ) { logger . error ( \"\" , e ) ;", "del_tokens": "try { for ( ApplicationId appId : stack . getMetaData ( ) . getLocalPeer ( ) . getCommonApplications ( ) ) { network . removeNetworkReqListener ( appId ) ; } catch ( InternalException e ) { logger . error ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "integration", "test", "for", "new", "field", "annotation", "feature"], "add_tokens": "} catch ( final NoSuchFieldException e )", "del_tokens": "} catch ( NoSuchFieldException e )", "commit_type": "add"}
{"commit_tokens": ["use", "OutputStream", "instead", "of", "List<String", ">", "for", "stdout", "and", "stderr"], "add_tokens": "import java . io . IOException ; import java . io . OutputStream ; public int exec ( String command , OutputStream stdout , OutputStream stderr ) throws WinRmException , IOException { ( \"stderr\" . equals ( s . getName ( ) ) ? stderr : stdout ) . write ( value ) ;", "del_tokens": "import java . nio . charset . StandardCharsets ; import java . util . List ; public int exec ( String command , List < String > stdout , List < String > stderr ) throws WinRmException { ( \"stderr\" . equals ( s . getName ( ) ) ? stderr : stdout ) . add ( new String ( value , StandardCharsets . ISO_8859_1 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "JPMML", "-", "Evaluator", "dependency"], "add_tokens": "import org . jpmml . evaluator . Batch ; import org . jpmml . evaluator . IntegrationTest ; import org . jpmml . evaluator . IntegrationTestBatch ; public class EstimatorTest extends IntegrationTest { protected Batch createBatch ( String name , String dataset ) { Batch result = new IntegrationTestBatch ( name , dataset ) { public IntegrationTest getIntegrationTest ( ) { return EstimatorTest . this ;", "del_tokens": "import java . io . ObjectOutputStream ; import com . google . common . io . ByteStreams ; import org . jpmml . evaluator . ArchiveBatch ; import org . jpmml . evaluator . ArchiveBatchTest ; public class EstimatorTest extends ArchiveBatchTest { protected ArchiveBatch createBatch ( String name , String dataset ) { ArchiveBatch result = new ArchiveBatch ( name , dataset ) { public InputStream open ( String path ) { Class < ? extends EstimatorTest > clazz = EstimatorTest . this . getClass ( ) ; return clazz . getResourceAsStream ( path ) ; ensureSerializability ( pmml ) ; static private void ensureSerializability ( Object object ) throws IOException { try ( ObjectOutputStream oos = new ObjectOutputStream ( ByteStreams . nullOutputStream ( ) ) ) { oos . writeObject ( object ) ; } }", "commit_type": "update"}
{"commit_tokens": ["Added", "code", "to", "shut", "down", "our", "application", "objects", "when", "the", "servlet", "is", "shut"], "add_tokens": "// $Id: DispatcherServlet.java,v 1.4 2001/03/01 21:09:54 mdb Exp $ public void stop ( ) { // shutdown our applications for ( int i = 0 ; i < _apps . size ( ) ; i ++ ) { Application app = ( Application ) _apps . get ( i ) ; app . shutdown ( ) ; } }", "del_tokens": "// $Id: DispatcherServlet.java,v 1.3 2001/03/01 21:06:22 mdb Exp $", "commit_type": "add"}
{"commit_tokens": ["Fix", "indentation", "and", "remove", "commented", "code"], "add_tokens": "if ( connectTimeout != null ) { connection . setConnectTimeout ( connectTimeout . intValue ( ) ) ; if ( readTimeout != null ) { connection . setReadTimeout ( readTimeout . intValue ( ) ) ;", "del_tokens": "if ( connectTimeout != null ) { connection . setConnectTimeout ( connectTimeout . intValue ( ) ) ; if ( readTimeout != null ) { connection . setReadTimeout ( readTimeout . intValue ( ) ) ; //this.connection.setConnectTimeout((int) unit.toMillis(duration)); //this.connection.setReadTimeout((int) unit.toMillis(duration));", "commit_type": "fix"}
{"commit_tokens": ["Improve", "sample", "+", "small", "API", "changes"], "add_tokens": "void onWheelItemSelected ( WheelView parent , int position ) ; public WheelAdapter getAdapter ( ) { //TODO use the relativePosition for both transform callbacks - perhaps just provide an interpolator? float relativePosition = Math . abs ( angleFromSelection ) / mWheelView . mItemAngle * 2f ; int alpha = ( int ) ( ( 1f - Math . pow ( relativePosition , 2.5f ) ) * 255f ) ; //clamp to between 0 and 255 drawable . setAlpha ( alpha ) ; mOnItemSelectListener . onWheelItemSelected ( this , getSelectedPosition ( ) ) ; * A simple circle with some helper methods used in { @ link com . lukedeighton . wheelview . WheelView }", "del_tokens": "void onWheelItemSelected ( WheelAdapter adapter , int position ) ; public WheelAdapter getWheelAdapter ( ) { int alpha = ( int ) ( Math . abs ( angleFromSelection ) / mWheelView . mItemAngle * 255f * 2f ) - 80 ; drawable . setAlpha ( 255 - alpha ) ; mOnItemSelectListener . onWheelItemSelected ( mAdapter , getSelectedPosition ( ) ) ; * A simple circle class with some helper methods used in { @ link com . lukedeighton . wheelview . WheelView }", "commit_type": "improve"}
{"commit_tokens": ["Updated", "the", "error", "code", "to", "403", "from", "401", ".", "Removed", "whitespace", "from", "MainActivity", ".", "java"], "add_tokens": "static final int INITIALISATION_ERROR = 403 ;", "del_tokens": "static final int INITIALISATION_ERROR = 400 ;", "commit_type": "update"}
{"commit_tokens": ["Improving", "performance", "of", "an", "indicator", "and", "a", "strategy"], "add_tokens": "private final TADecimal multiplier ; multiplier = TADecimal . TWO . dividedBy ( TADecimal . valueOf ( timeFrame + 1 ) ) ; return indicator . getValue ( index ) . minus ( emaPrev ) . multipliedBy ( multiplier ) . plus ( emaPrev ) ;", "del_tokens": "private TADecimal multiplier ( ) { return TADecimal . TWO . dividedBy ( TADecimal . valueOf ( timeFrame + 1 ) ) ; } return indicator . getValue ( index ) . minus ( emaPrev ) . multipliedBy ( multiplier ( ) ) . plus ( emaPrev ) ;", "commit_type": "improve"}
{"commit_tokens": ["Improve", "check", "for", "escaped", "left", "-", "paren"], "add_tokens": "// Count the backslashes preceding this position. If it's // even, there is no escape and the slashes are just literals. // If it's odd, one of the slashes (the last one) is escaping // the parenthesis at the given position. int numSlashes = 0 ; while ( pos > 0 && ( s . charAt ( pos - 1 ) == '\\\\' ) ) { pos -- ; numSlashes ++ ; } return numSlashes % 2 != 0 ;", "del_tokens": "return ( pos > 0 && pos < s . length ( ) ) && ( s . charAt ( pos - 1 ) == '\\\\' ) && ! ( ( pos >= 2 ) && ( s . charAt ( pos - 2 ) == '\\\\' ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["fix", "buffer", "handling", "when", "we", "have", "unclosed", "quotes"], "add_tokens": "multiLineBuffer = Arrays . copyOf ( multiLineBuffer , originalSize + size ) ; System . arraycopy ( line , 0 , multiLineBuffer , originalSize , size ) ; return ( size > 0 && line [ size - 1 ] == '\\\\' ) ;", "del_tokens": "LOGGER . info ( \"updating multiline..\" ) ; multiLineBuffer = Arrays . copyOf ( multiLineBuffer , size ) ; System . arraycopy ( line , 0 , multiLineBuffer , size , originalSize ) ; return ( size > 1 && line [ size - 1 ] == '\\\\' && line [ size - 2 ] == ' ' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "WebAppRewriter", "to", "framework", "package"], "add_tokens": "import org . jboss . wsf . framework . deployment . WebAppDesciptorModifier ;", "del_tokens": "import org . jboss . wsf . spi . deployment . WebAppDesciptorModifier ;", "commit_type": "move"}
{"commit_tokens": ["allow", "shipment_id", "to", "be", "null", "for", "rates", "(", "for", "batches", ")", ";", "bump", "version"], "add_tokens": "public static final String VERSION = \"2.2.5\" ;", "del_tokens": "public static final String VERSION = \"2.2.4\" ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "some", "discussion", "to", "the", "javadoc", "overview", "about", "input", "path", "expr", "construction", "."], "add_tokens": "* path expression used to retrieve data from the server . Only * used if using MarkLogic Server for input in < code > basic < / code > mode . * { @ link # SUBDOCUMENT_EXPRESSION input . subDocumentExpr } . If * this property is not set , < code > fn : collection ( ) < / code > is used . * The config property name ( < code > { @ value } < / code > ) * sub - document records from the server . Used only if using MarkLogic * Server for input in < code > basic < / code > mode . If not set , * the document nodes selected by the { @ link # DOCUMENT_SELECTOR * document selector } are used .", "del_tokens": "* path expression used to retrieve data from the server . Required * if using MarkLogic Server for input in < code > basic < / code > mode . * { @ link # SUBDOCUMENT_EXPRESSION input . subDocumentExpr } . * The config property name * ( < code > { @ value } < / code > ) * sub - document records from the server . Required if using MarkLogic * Server for input in < code > basic < / code > mode and retrieving * non - document items .", "commit_type": "add"}
{"commit_tokens": ["Change", "how", "LynxView", "uses", "LynxConfiguration", "validating", "the", "lynxConfig", "instance", "if", "is", "configured", "programmatically", "and", "updating", "lynxPresenter", "config"], "add_tokens": "initializeConfiguration ( attrs ) ; validateLynxConfig ( lynxConfig ) ; presenter . setLynxConfig ( lynxConfig ) ; } private void validateLynxConfig ( LynxConfig lynxConfig ) { if ( lynxConfig == null ) { throw new IllegalArgumentException ( \"You can't configure Lynx with a null LynxConfig instance.\" ) ; } if ( attrs != null ) { //Initialize lynx config here }", "del_tokens": "if ( attrs != null ) { initializeConfiguration ( attrs ) ; } lynxConfig = new LynxConfig ( ) ; //Obtain Lynx configuration from attrs", "commit_type": "change"}
{"commit_tokens": ["Remove", "unintentional", "extending", "of", "JUnit", "class", "..."], "add_tokens": "public class EmbeddedPostgreSQLController", "del_tokens": "import org . junit . rules . ExternalResource ; import com . nesscomputing . testing . lessio . AllowAll ; @ AllowAll public class EmbeddedPostgreSQLController extends ExternalResource", "commit_type": "remove"}
{"commit_tokens": ["Changed", "to", "match", "multi", "-", "line", "patterns"], "add_tokens": "import java . util . regex . Pattern ; String rslt = Pattern . compile ( x , Pattern . DOTALL ) . matcher ( s ) . replaceAll ( r ) ; res . setAttribute ( Attributes . STRING , rslt ) ;", "del_tokens": "res . setAttribute ( Attributes . STRING , s . replaceAll ( x , r ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "unused", "dot", "from", "Logger", "names", "."], "add_tokens": "protected static Logger logger = Logger . getInstance ( Logger . INTERNAL_PREFIX + \"analytics\" ) ;", "del_tokens": "protected static Logger logger = Logger . getInstance ( Logger . INTERNAL_PREFIX + \".analytics\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "some", "javadoc", "+", "readme"], "add_tokens": "api . setStatus ( copyStatus ) ;", "del_tokens": "api . setStatus ( copyStatus ) ;", "commit_type": "update"}
{"commit_tokens": ["Made", "Scroll", "Bars", "optional", "and", "moved", "factory", "methods", "from", "VirtualFlow", "to", "VirtualFlowContent"], "add_tokens": "import org . fxmisc . flowless . VirtualFlowContent . Gravity ;", "del_tokens": "import org . fxmisc . flowless . VirtualFlow . Gravity ;", "commit_type": "make"}
{"commit_tokens": ["allow", "user", "to", "select", "JRE", "to", "run", "elasticsearch", "in"], "add_tokens": "private JavaHomeOption javaHome ; ElasticServer ( String esJavaOpts , File installationDirectory , File executableFile , long startTimeoutInMs , boolean cleanInstallationDirectoryOnStop , JavaHomeOption javaHome ) { this . javaHome = javaHome ; javaHome . ifNeedBeSet ( javaHomeValue -> builder . environment ( ) . put ( \"JAVA_HOME\" , javaHomeValue ) ) ;", "del_tokens": "ElasticServer ( String esJavaOpts , File installationDirectory , File executableFile , long startTimeoutInMs , boolean cleanInstallationDirectoryOnStop ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "some", "class", "-", "level", "jdoc"], "add_tokens": "* This is useful only when deploying into the Hawkular Bus with Hawkular Metrics . The expected message payload should * be JSON representation of { @ link AvailDataMessage } .", "del_tokens": "* This is useful only when deploying into the Hawkular Bus with Hawkular Metrics . The expected format of the * data is JSON like : * < / p > * < code > * { tenantId , List < org . rhq . metrics . client . common . SingleMetric > } * < / code > * < / p > * TODO : Add filtering of relevant Metric Ids . This means fetching the active triggers , running through the conditions , * and collecting the dataIds . Then using thise to filter the metricIds converted and forwarded to the engine . Note * that we will need a way to update that Id set as changes occur to the Trigger population . Changes are * rare so we don 't want it to be too cumbersome.", "commit_type": "fix"}
{"commit_tokens": ["added", "unit", "test", "for", "HttpClientAdaptor#deleteTable", "(", "..", ")"], "add_tokens": "DeleteDatabaseRequest request = new DeleteDatabaseRequest ( new Database ( databaseName ) ) ; DeleteDatabaseResult result = clientAdaptor . deleteDatabase ( request ) ; String dstName = result . getDatabaseName ( ) ; assertEquals ( databaseName , dstName ) ;", "del_tokens": "import com . treasure_data . model . CreateDatabaseRequest ; import com . treasure_data . model . CreateDatabaseResult ; Database database = null ; { // create CreateDatabaseRequest request = new CreateDatabaseRequest ( databaseName ) ; CreateDatabaseResult result = clientAdaptor . createDatabase ( request ) ; database = result . getDatabase ( ) ; assertEquals ( databaseName , database . getName ( ) ) ; } { // delete DeleteDatabaseRequest request = new DeleteDatabaseRequest ( database ) ; DeleteDatabaseResult result = clientAdaptor . deleteDatabase ( request ) ; String dstName = result . getDatabaseName ( ) ; assertEquals ( databaseName , dstName ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "model", "and", "methods", "for", "Google", "Drive", "revisions", "comments", "and", "replies"], "add_tokens": "import org . springframework . social . google . api . query . ApiPage ; * { @ link ApiPage } of { @ link FileComment } public class FileCommentsPage extends ApiPage < FileComment > {", "del_tokens": "import org . springframework . social . google . api . query . ApiList ; * { @ link ApiList } of { @ link UserPermission } public class UserPermissionsList extends ApiList < UserPermission > {", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "client", "depend", "on", "the", "application", "for", "the", "integration", "tests", "so", "we", "can", "launch", "the", "server", "in", "as", "a", "@ClassRule", "to", "validate", "that", "the", "client", "works", "against", "a", "running", "server", "."], "add_tokens": "import io . dropwizard . testing . junit . DropwizardAppRule ; import java . io . File ; import org . junit . ClassRule ; import com . ge . snowizard . application . SnowizardApplication ; import com . ge . snowizard . application . SnowizardConfiguration ; import com . google . common . io . Resources ; @ ClassRule public static final DropwizardAppRule < SnowizardConfiguration > RULE = new DropwizardAppRule < SnowizardConfiguration > ( SnowizardApplication . class , resourceFilePath ( \"test-snowizard.yml\" ) ) ; final List < String > urls = ImmutableList . of ( \"localhost:\" + RULE . getLocalPort ( ) ) ; public static String resourceFilePath ( final String resourceClassPathLocation ) { try { return new File ( Resources . getResource ( resourceClassPathLocation ) . toURI ( ) ) . getAbsolutePath ( ) ; } catch ( final Exception e ) { throw new RuntimeException ( e ) ; } }", "del_tokens": "final List < String > urls = ImmutableList . of ( \"127.0.0.1:8080\" ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "empty", "next", "client", "samples"], "add_tokens": "import com . mcxiaoke . next . samples . http . NextClientSamples ; mSampleListData . add ( new SampleInfo ( NextClientSamples . TAG , NextClientSamples . class ) ) ;", "del_tokens": "import com . mcxiaoke . next . samples . core . LicenseSamples ; mSampleListData . add ( new SampleInfo ( LicenseSamples . TAG , LicenseSamples . class ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "syncronous", "Redis", "Sliding", "Window", "test"], "add_tokens": "import org . assertj . core . api . AssertionsForClassTypes ; import java . util . stream . IntStream ; public void shouldLimitSingleWindowAsync ( ) throws Exception { // TODO latch shouldn't be necessary if I can block on completableFuture @ Test public void shouldLimitSingleWindowSync ( ) throws Exception { ImmutableSet < Window > rules = ImmutableSet . of ( Window . of ( 10 , TimeUnit . SECONDS , 5 ) ) ; RedisRateLimit rateLimiter = new RedisRateLimit ( client , rules ) ; IntStream . rangeClosed ( 1 , 5 ) . forEach ( value -> { boolean result = rateLimiter . overLimit ( \"ip:127.0.0.5\" ) ; AssertionsForClassTypes . assertThat ( result ) . isEqualTo ( false ) ; } ) ; assertThat ( rateLimiter . overLimit ( \"ip:127.0.0.5\" ) ) . isEqualTo ( true ) ; } }", "del_tokens": "public void shouldConnect ( ) throws Exception { ImmutableSet < Window > rules = ImmutableSet . of ( Window . of ( 10 , TimeUnit . SECONDS , 1 ) ) ; RedisRateLimit rateLimiter = new RedisRateLimit ( client , rules ) ; assertThat ( rateLimiter . overLimitAsync ( \"ip:127.0.0.1\" ) . toCompletableFuture ( ) . get ( ) ) . isEqualTo ( false ) ; } @ Test public void shouldLimitSingleWindow ( ) throws Exception { // TODO close connection }", "commit_type": "add"}
{"commit_tokens": ["Allow", "any", "level", "of", "subclassing", "of", "AnnotationLiteral", "and", "TypeLiteral"], "add_tokens": "private abstract class NamedAnnotationLiteral extends AnnotationLiteral < Named > implements Named { } annotations . put ( Named . class , new NamedAnnotationLiteral ( ) { public String value ( ) { return \"\" ; } } ) ; annotations . put ( Named . class , new NamedAnnotationLiteral ( ) { public String value ( ) { return \"aTrout\" ; } } ) ; orderXmlAnnotations . put ( Named . class , new NamedAnnotationLiteral ( ) { public String value ( ) { return \"currentSynchronousOrder\" ; } } ) ;", "del_tokens": "private class NamedAnnotationLiteral extends AnnotationLiteral < Named > implements Named { private String value ; public NamedAnnotationLiteral ( String value ) { this . value = value ; } public String value ( ) { return value ; } } annotations . put ( Named . class , new NamedAnnotationLiteral ( \"\" ) ) ; annotations . put ( Named . class , new NamedAnnotationLiteral ( \"aTrout\" ) ) ; orderXmlAnnotations . put ( Named . class , new NamedAnnotationLiteral ( \"currentSynchronousOrder\" ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "proposal", "for", "new", "Encoder", "interface"], "add_tokens": "import com . floreysoft . jmte . encoder . Encoder ; final String prefixedRenderedResult = ( prefix != null ? prefix : \"\" ) + renderedResult + ( suffix != null ? suffix : \"\" ) ; Encoder encoder = context . getEncoder ( ) ; if ( encoder != null ) { final String encodedPrefixedRenderedResult = encoder . encode ( prefixedRenderedResult ) ; return encodedPrefixedRenderedResult ; } else { return prefixedRenderedResult ; }", "del_tokens": "return ( prefix != null ? prefix : \"\" ) + renderedResult + ( suffix != null ? suffix : \"\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "default", "datasource", "timeout", "to", "500ms"], "add_tokens": "private Duration maxConnectionWait = new Duration ( 500 , TimeUnit . MILLISECONDS ) ;", "del_tokens": "private Duration maxConnectionWait = new Duration ( 30 , TimeUnit . MILLISECONDS ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "basic", "implementation", "to", "TraceRenderer", "based", "on", "trace_row", ".", "xml"], "add_tokens": "import android . widget . TextView ; import com . github . pedrovgs . lynx . R ; private TextView tv_trace ; return inflater . inflate ( R . layout . trace_row , parent , true ) ; tv_trace = ( TextView ) rootView . findViewById ( R . id . tv_trace ) ; Trace trace = getContent ( ) ; tv_trace . setText ( trace . getMessage ( ) ) ;", "del_tokens": "return null ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "minor", "datatype", "handling", "bugs"], "add_tokens": "String sVal = val . toString ( cbuffer , 0 ) ; ATTRIBUTE_TYPE , sVal ) ;", "del_tokens": "ATTRIBUTE_TYPE , val . toString ( cbuffer , 0 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moving", "Sets", "to", "a", "new", "package"], "add_tokens": "package edu . jhu . util . collections ;", "del_tokens": "package edu . jhu . util ;", "commit_type": "move"}
{"commit_tokens": ["Added", "timeout", "on", "futures", "for", "the", "testcommands", "+", "added", "the", "transactionalmaptest"], "add_tokens": "private final static Object NO_RESULT = new Object ( ) { public String toString ( ) { long remainingTimeoutMs = unit . toMillis ( timeout ) ; synchronized ( this ) { for ( ; ; ) { if ( result != NO_RESULT ) { if ( result instanceof Throwable ) { throw new ExecutionException ( ( Throwable ) result ) ; } return ( E ) result ; } if ( remainingTimeoutMs <= 0 ) { throw new TimeoutException ( ) ; } long startMs = System . currentTimeMillis ( ) ; wait ( remainingTimeoutMs ) ; remainingTimeoutMs -= System . currentTimeMillis ( ) - startMs ; } }", "del_tokens": "private final static Object NO_RESULT = new Object ( ) { public String toString ( ) { throw new UnsupportedOperationException ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "API", "tracing", "consistent", "with", "other", "clouds"], "add_tokens": "APITrace . begin ( provider , \"KVDB.addKeyValuePairs\" ) ; APITrace . begin ( provider , \"KVDB.createDatabase\" ) ; APITrace . begin ( provider , \"KVDB.getDatabase\" ) ; APITrace . begin ( provider , \"KVDB.getKeyValuePairs\" ) ; APITrace . begin ( provider , \"KVDB.isSubscribed\" ) ; APITrace . begin ( provider , \"KVDB.list\" ) ; APITrace . begin ( provider , \"KVDB.listKeyValueDatabaseStatus\" ) ; APITrace . begin ( provider , \"KVDB.query\" ) ; APITrace . begin ( provider , \"KVDB.removeDatabase\" ) ; APITrace . begin ( provider , \"KVDB.removeKeyValuePairs\" ) ; APITrace . begin ( provider , \"KVDB.removeKeyValuePairStrings\" ) ; APITrace . begin ( provider , \"KVDB.replaceKeyValuePairs\" ) ;", "del_tokens": "APITrace . begin ( provider , \"addKeyValuePairs\" ) ; APITrace . begin ( provider , \"createKVDatabase\" ) ; APITrace . begin ( provider , \"getDatabase\" ) ; APITrace . begin ( provider , \"getKeyValuePairs\" ) ; APITrace . begin ( provider , \"isSubscribedKVDB\" ) ; APITrace . begin ( provider , \"listKVDBs\" ) ; APITrace . begin ( provider , \"listKVDBStatus\" ) ; APITrace . begin ( provider , \"queryKVDB\" ) ; APITrace . begin ( provider , \"removeKVDB\" ) ; APITrace . begin ( provider , \"removeKeyValuePairs\" ) ; APITrace . begin ( provider , \"removeKeyValuePairStrings\" ) ; APITrace . begin ( provider , \"replaceKeyValuePairs\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "paragraph", "generation", "on", "Lorem"], "add_tokens": "private int positiveRandom ; positiveRandom = new Random ( ) . nextInt ( 31 ) + 1 ; @ Test public void testParagraph ( ) throws Exception { String paragraph = lorem . paragraph ( ) ; String [ ] numberOfSentences = paragraph . split ( \"\\\\. \" ) ; assertTrue ( numberOfSentences . length >= 3 ) ; } @ Test public void testParagraphs ( ) throws Exception { String paragraphs = lorem . paragraphs ( ) ; assertTrue ( paragraphs . contains ( \"\\n\" ) ) ; } @ Test public void testParagraphsWithArguments ( ) throws Exception { String paragraphs = lorem . paragraphs ( positiveRandom ) ; int numberOfWhiteLines = paragraphs . split ( \"\\n\" ) . length ; assertTrue ( numberOfWhiteLines == positiveRandom ) ; } @ Test public void testParagraphsWithInvalidArguments ( ) throws Exception { try { lorem . paragraphs ( 0 ) ; assertTrue ( false ) ; } catch ( IllegalArgumentException e ) { assertTrue ( true ) ; } }", "del_tokens": "private int positiveRandom = new Random ( ) . nextInt ( 31 ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "DDF", ".", "getGlobalObjectType", "to", "return", "bdt"], "add_tokens": "return \"bdt\" ;", "del_tokens": "return \"bdf\" ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "more", "tests", "and", "avoid", "one", "possible", "IndexOutOfBoundsException"], "add_tokens": "if ( line . length ( ) >= 4 && line . substring ( 0 , 4 ) . contains ( \"C\" ) ) {", "del_tokens": "if ( line . substring ( 0 , 4 ) . contains ( \"C\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["make", "data", "members", "final", "#codereview"], "add_tokens": "private final Field field ; private final WeakReference < Object > objectRef ; private final Method method ; private final WeakReference < Object > objectRef ; private final WeakReference < Object > valueRef ; private final Variable parent ;", "del_tokens": "private Field field ; private WeakReference < Object > objectRef ; private Method method ; private WeakReference < Object > objectRef ; private WeakReference < Object > valueRef ; private Variable parent ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "new", "line", "char", "detection"], "add_tokens": "if ( - 1 == newText . indexOf ( \"\\\\n\" ) ) { wel . get ( 0 ) . sendKeys ( newText . substring ( 0 , newText . indexOf ( \"\\\\n\" ) ) ) ; newText = newText . substring ( newText . indexOf ( \"\\\\n\" ) + 2 ) ;", "del_tokens": "if ( - 1 == newText . indexOf ( \"\\n\" ) ) { wel . get ( 0 ) . sendKeys ( newText . substring ( 0 , newText . indexOf ( \"\\n\" ) ) ) ; newText = newText . substring ( newText . indexOf ( \"\\n\" ) + 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["upgrade", "to", "JAX", "-", "RS", "/", "Jersey", "2", ".", "x", "API"], "add_tokens": "import javax . ws . rs . core . Response ; import javax . ws . rs . core . Response . StatusType ; public GitLabApiException ( Response response ) { ErrorMessage errorMessage = response . readEntity ( ErrorMessage . class ) ;", "del_tokens": "import javax . ws . rs . core . Response . StatusType ; import com . sun . jersey . api . client . ClientResponse ; public GitLabApiException ( ClientResponse response ) { ErrorMessage errorMessage = response . getEntity ( ErrorMessage . class ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Implement", "read", "-", "only", "mode"], "add_tokens": "import com . fasterxml . jackson . databind . JsonMappingException ; try { return Jackson . treeToValue ( node , JsonPatch . class ) ; } catch ( JsonMappingException e ) { throw new JsonPatchException ( \"invalid JSON patch\" , e ) ; }", "del_tokens": "return Jackson . treeToValue ( node , JsonPatch . class ) ;", "commit_type": "implement"}
{"commit_tokens": ["fixed", "resource", "leak", "in", "sequence", "querying", "when", "a", "ResultSet", "is", "not", "properly", "closed", "Oracle", "throws", "ORA", "-", "01000", ":", "maximum", "open", "cursors", "exceeded"], "add_tokens": "try ( PreparedStatement statement = transaction . prepareStatement ( dialect . nextFromSequence ( sequenceName ) ) ; ResultSet resultSet = statement . executeQuery ( ) ) { transaction . registerCursor ( resultSet ) ; resultSet . next ( ) ; return resultSet . getLong ( 1 ) ; }", "del_tokens": "PreparedStatement statement = transaction . prepareStatement ( dialect . nextFromSequence ( sequenceName ) ) ; ResultSet resultSet = statement . executeQuery ( ) ; transaction . registerCursor ( resultSet ) ; resultSet . next ( ) ; return resultSet . getLong ( 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "spi", ".", "BinaryService", ".", "MultipartUpload"], "add_tokens": "import org . trellisldp . http . impl . HttpSession ; final BinaryService . MultipartUpload upload = new BinaryService . MultipartUpload ( ) ; upload . binary = mockBinary ; upload . session = new HttpSession ( ) ; upload . baseUrl = BASE_URL ; upload . path = BINARY_PATH ; when ( mockBinaryResolver . completeUpload ( eq ( UPLOAD_SESSION_ID ) , any ( ) ) ) . thenReturn ( upload ) ;", "del_tokens": "when ( mockBinaryResolver . completeUpload ( eq ( UPLOAD_SESSION_ID ) , any ( ) ) ) . thenReturn ( new SimpleEntry < > ( binaryIdentifier , mockBinary ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "input", "and", "output", "session", "buffers", ".", "Printed", "status", "type", "and", "headers", "of", "response", "from", "socket", ".", "Added", "constants", "and", "helper", "methods", "from", "ApacheHttpClient4Handler", "."], "add_tokens": "restEndpointUrl = \"/v1.3\" ; //schemeRegistry.register(new Scheme(\"http\", 4243, PlainSocketFactory.getSocketFactory())); //HttpClient httpClient = new DefaultHttpClient(cm); //client = new ApacheHttpClient4(new ApacheHttpClient4Handler(httpClient, null, false), clientConfig); //client.addFilter(new JsonClientFilter());", "del_tokens": "restEndpointUrl = serverUrl + \"/v1.3\" ; schemeRegistry . register ( new Scheme ( \"http\" , 4243 , PlainSocketFactory . getSocketFactory ( ) ) ) ; // HttpClient httpClient = new DefaultHttpClient(cm); // client = new ApacheHttpClient4(new ApacheHttpClient4Handler(httpClient, null, false), clientConfig); client . addFilter ( new JsonClientFilter ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "access", "to", "field", "providers", "in", "Soy", "s", "AugmentedParamStore", "(", "What", "is", "used", "for", "passing", "data", "=", "$foo", "in", "calls", ")", "access", "the", "underlying", "providers", "instead", "of", "the", "non", "-", "lazy", "value", "."], "add_tokens": "return ( val != null ) ? val : backingStore . getFieldProvider ( name ) ;", "del_tokens": "return ( val != null ) ? val : backingStore . getField ( name ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "bug", "stripping", "quotes", "from", "URL", "()", "arguments"], "add_tokens": "css = \"/* importing file */\\n\\r@import url(\\\"././imported.css\\\")\" ; css = \"/* importing file */\\n\\r@import url('foo/../imported.css')\" ; css = \"/* importing file */\\n\\r@import url( \\\"./foo/bar/.././../imported.css\\\" )\" ;", "del_tokens": "css = \"/* importing file */\\n\\r@import \\\"././imported.css\\\"\" ; css = \"/* importing file */\\n\\r@import \\\"foo/../imported.css\\\"\" ; css = \"/* importing file */\\n\\r@import \\\"./foo/bar/.././../imported.css\\\"\" ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "quadtree", "tests", "to", "QuadTree<Long", ">"], "add_tokens": "import de . jetsli . graph . trees . QuadTree ; import de . jetsli . graph . trees . QuadTreeTester ; // protected QuadTree<Long> createQuadTree(long items) { // return new SpatialKeyHashtable().init(items);", "del_tokens": "// protected QuadTree<Integer> createQuadTree(long items) { // try { // return new SpatialKeyTree().init(items); // } catch (Exception ex) { // throw new RuntimeException(ex); // }", "commit_type": "move"}
{"commit_tokens": ["use", "the", "faster", "indexOf", "(", "char", ")", "method"], "add_tokens": "int endPrimaryKeyIndex = res . indexOf ( ')' , primaryKeyIndex ) ;", "del_tokens": "int endPrimaryKeyIndex = res . indexOf ( \")\" , primaryKeyIndex ) ;", "commit_type": "use"}
{"commit_tokens": ["Adds", "license", "copyright", "headers", "etc", "."], "add_tokens": "/ * * Copyright ( C ) 2016 Airbnb , Inc . * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / import rx . functions . Actions ; return create ( observable , Actions . empty ( ) ) ;", "del_tokens": "return create ( observable , DummyAction . instance ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "static", "factories", "for", "regular", "expressions", "over", "simple", "sequences", "and", "made", "static", "constructors", "for", "RegularExpression", "."], "add_tokens": "protected LogicExpression ( String input , Function < String , Tok . Arg < E > > factory ) public static < E > LogicExpression < E > compile ( String input , Function < String , Tok . Arg < E > > factory ) { return new LogicExpression ( input , factory ) ; }", "del_tokens": "public LogicExpression ( String input , Function < String , Tok . Arg < E > > factory )", "commit_type": "add"}
{"commit_tokens": ["Added", "deltaTime", "to", "processEntity", "."], "add_tokens": "processEntity ( entities . get ( i ) , deltaTime ) ; * @ param deltaTime The delta time between the last and current frame public abstract void processEntity ( Entity entity , float deltaTime ) ;", "del_tokens": "processEntity ( entities . get ( i ) ) ; public abstract void processEntity ( Entity entity ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "tests", "for", "CompilationUnitContext", ".", "solveSymbolAsUsage"], "add_tokens": "SymbolReference < ? extends ValueDeclaration > ref = solveSymbol ( name , typeSolver ) ; if ( ref . isSolved ( ) ) { Value value = Value . from ( ref . getCorrespondingDeclaration ( ) , typeSolver ) ; return Optional . of ( value ) ; } else { return Optional . empty ( ) ; }", "del_tokens": "throw new UnsupportedOperationException ( this . getClass ( ) . getCanonicalName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "links", "and", "buttons", "at", "dictionary", "pages"], "add_tokens": "/** The key of the message: Edit */ public static final String LABELS_suggest_elevate_word_link_edit = \"{labels.suggest_elevate_word_link_edit}\" ; /** The key of the message: Delete */ public static final String LABELS_suggest_elevate_word_link_delete = \"{labels.suggest_elevate_word_link_delete}\" ; /** The key of the message: Details */ public static final String LABELS_suggest_elevate_word_link_details = \"{labels.suggest_elevate_word_link_details}\" ; /** The key of the message: Edit */ public static final String LABELS_suggest_bad_word_link_edit = \"{labels.suggest_bad_word_link_edit}\" ; /** The key of the message: Delete */ public static final String LABELS_suggest_bad_word_link_delete = \"{labels.suggest_bad_word_link_delete}\" ; /** The key of the message: Details */ public static final String LABELS_suggest_bad_word_link_details = \"{labels.suggest_bad_word_link_details}\" ;", "del_tokens": "/** The key of the message: Create New */ public static final String LABELS_web_crawling_link_create_new = \"{labels.web_crawling_link_create_new}\" ; public static final String LABELS_suggest_elevate_word_link_create_new = \"{labels.suggest_elevate_word_link_create_new}\" ; /** The key of the message: Create */ public static final String LABELS_suggest_bad_word_link_create_new = \"{labels.suggest_bad_word_link_create_new}\" ; /** The key of the message: Create */", "commit_type": "fix"}
{"commit_tokens": ["Add", "message", "to", "exception", "thrown", "when", "Parser", "can", "t", "find", "closing", "}", "."], "add_tokens": "throw new EdnException ( \"Expected '}', but found end of input.\\n\" + String . valueOf ( b . build ( ) ) ) ;", "del_tokens": "throw new EdnException ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Create", "the", "itest", "user", "during", "the", "build", "with", "a", "random", "password"], "add_tokens": "protected static final String testPasword = System . getProperty ( \"hawkular.itest.rest.password\" ) ; protected static final String testUser = System . getProperty ( \"hawkular.itest.rest.user\" ) ; // System.out.println(\"testPasword = \"+ testPasword);", "del_tokens": "protected static final String testPasword = \"password\" ; protected static final String testUser = \"jdoe\" ;", "commit_type": "create"}
{"commit_tokens": ["Added", "support", "for", "injecting", "private", "constructors", "and", "fields", "."], "add_tokens": "import java . lang . reflect . Modifier ; public < T > ConstructionProxy < T > get ( final Constructor < T > constructor ) { // We can't use FastConstructor if the constructor is private. if ( Modifier . isPrivate ( constructor . getModifiers ( ) ) ) { constructor . setAccessible ( true ) ; return new ConstructionProxy < T > ( ) { public T newInstance ( Object ... arguments ) throws InvocationTargetException { try { return constructor . newInstance ( arguments ) ; } catch ( InstantiationException e ) { throw new RuntimeException ( e ) ; } catch ( IllegalAccessException e ) { throw new AssertionError ( e ) ; } } } ; }", "del_tokens": "public < T > ConstructionProxy < T > get ( Constructor < T > constructor ) {", "commit_type": "add"}
{"commit_tokens": ["update", "getting", "port", "system", "property"], "add_tokens": "int port = SYSCONFIG . getIntProperty ( WebServiceCommunication . SYSPROP_PORT + \".\" + name ) ; if ( port == Integer . MIN_VALUE ) {", "del_tokens": "int port = SYSCONFIG . getIntProperty ( WebServiceCommunication . SYSPROP_PORT + \".\" + name , 0 ) ; if ( port == 0 ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "shiro", "style", "priority", "filter", "and", "add", "the", "Stormpath", "filter", "under", "that"], "add_tokens": "import com . stormpath . shiro . servlet . filter . StormpathShiroFilterChainResolverFactory ; import org . apache . shiro . util . Factory ; import org . apache . shiro . web . filter . mgt . FilterChainResolver ; defaults . put ( \"shiro.loginUrl\" , \"/login\" ) ; // TODO: this duplicates stormpath config, but we do NOT have the config object yet, think about this a bit more this . objects . clear ( ) ; WebSecurityManager securityManager = createWebSecurityManager ( ) ; setWebSecurityManager ( securityManager ) ; FilterChainResolver resolver = createFilterChainResolver ( ) ; if ( resolver != null ) { setFilterChainResolver ( resolver ) ; } protected ConfigLoader ensureConfigLoader ( ) { @ Override protected FilterChainResolver createFilterChainResolver ( ) { FilterChainResolver originalFilterChainResolver = super . createFilterChainResolver ( ) ; if ( originalFilterChainResolver == null ) { return null ; } return getFilterChainResolverFactory ( originalFilterChainResolver ) . getInstance ( ) ; } protected Factory < ? extends FilterChainResolver > getFilterChainResolverFactory ( FilterChainResolver originalFilterChainResolver ) { return new StormpathShiroFilterChainResolverFactory ( originalFilterChainResolver , getServletContext ( ) ) ; } // TODO think about putting these in Shiro proper", "del_tokens": "super . configure ( ) ; private ConfigLoader ensureConfigLoader ( ) { // TODO think about putting these in Shiro proper", "commit_type": "add"}
{"commit_tokens": ["Fix", "froyo", "bug", ":", "no", "more", "descendingIterator"], "add_tokens": "for ( ListIterator < Connection > i = connections . listIterator ( connections . size ( ) ) ; i . hasPrevious ( ) ; ) { Connection connection = i . previous ( ) ;", "del_tokens": "import java . util . Iterator ; for ( Iterator < Connection > i = connections . descendingIterator ( ) ; i . hasNext ( ) ; ) { Connection connection = i . next ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "self", "-", "documenting", "flag"], "add_tokens": "ApplicationInfo ai = pm . getApplicationInfo ( context . getPackageName ( ) , PackageManager . GET_META_DATA ) ; ApplicationInfo ai = pm . getApplicationInfo ( context . getPackageName ( ) , PackageManager . GET_META_DATA ) ; ApplicationInfo ai = pm . getApplicationInfo ( context . getPackageName ( ) , PackageManager . GET_META_DATA ) ;", "del_tokens": "/ * * * TODO document the meaning of this 128 flag . * / private final static int FLAG = 128 ; ApplicationInfo ai = pm . getApplicationInfo ( context . getPackageName ( ) , FLAG ) ; ApplicationInfo ai = pm . getApplicationInfo ( context . getPackageName ( ) , FLAG ) ; ApplicationInfo ai = pm . getApplicationInfo ( context . getPackageName ( ) , FLAG ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "way", "to", "set", "the", "-", "progress", "flag", "."], "add_tokens": "URI progress ; this . pass_prefix = checkNotNull ( prefix ) ; public FFmpegBuilder addProgress ( URI uri ) { this . progress = checkNotNull ( uri ) ; return this ; } if ( progress != null ) { args . add ( \"-progress\" ) . add ( progress . toString ( ) ) ; }", "del_tokens": "this . pass_prefix = prefix ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "do", "a", "reverse", "row", "key", "lookup"], "add_tokens": "import com . bazaarvoice . emodb . sor . api . UnknownTableException ; import com . bazaarvoice . emodb . table . db . DroppedTableException ; * Converts EmoDB coordinates \"table/key\" to a Cassandra row key and vice versa . * * $ curl - s - XPOST http : //localhost:8081/tasks/sor-row-key?rowkey=564c0c4f54555e41e664656d6f31 * 564 c0c4f54555e41e664656d6f31 : review : testcustomer / demo1 for ( String rowkeyString : parameters . get ( \"rowkey\" ) ) { String coord ; try { ByteBuffer rowkey = ByteBufferUtil . hexToBytes ( rowkeyString ) ; long tableUuid = AstyanaxStorage . getTableUuid ( rowkey ) ; Table table = _tableDao . getByUuid ( tableUuid ) ; coord = table . getName ( ) + \"/\" + AstyanaxStorage . getContentKey ( rowkey ) ; } catch ( NumberFormatException e ) { coord = \"invalid hex\" ; } catch ( UnknownTableException | DroppedTableException e ) { coord = \"unknown table UUID\" ; } catch ( Exception e ) { out . println ( e ) ; coord = \"error\" ; } out . printf ( \"%s: %s%n\" , rowkeyString , coord ) ; }", "del_tokens": "* Converts EmoDB coordinates \"table/key\" to a Cassandra row key .", "commit_type": "add"}
{"commit_tokens": ["Updated", "default", "port", "to", "80"], "add_tokens": "private String port = \"80\" ;", "del_tokens": "private String port = \"1148\" ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "locator", "strategies", "added", "setValue", "()"], "add_tokens": ". put ( SET_VALUE , postC ( \"/session/:sessionId/appium/element/:id/value\" ) ) public Response execute ( String driverCommand , Map < String , ? > parameters ) {", "del_tokens": "protected Response execute ( String driverCommand , Map < String , ? > parameters ) {", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "the", "build", "methods", "in", "UriBuilder"], "add_tokens": "cur = cur . replaceAll ( \"\\\\{\\\\s*\" + Pattern . quote ( pathParam ) + \"\\\\s*(:[^}]*)?\\\\s*}\" , replacement ) ;", "del_tokens": "cur = cur . replaceAll ( \"\\\\{\\\\s*\" + Pattern . quote ( pathParam ) + \"\\\\s*(:[^}])*}\" , replacement ) ;", "commit_type": "implement"}
{"commit_tokens": ["Allow", "appcache", "to", "cache", "directories", "e", ".", "g", ".", "the", "root", "URI", "/"], "add_tokens": "\".webm\" , \".css\" , \".json\" , \".flv\" , \".swf\" , \"/\" , } ;", "del_tokens": "\".webm\" , \".css\" , \".json\" , \".flv\" , \".swf\" , } ;", "commit_type": "allow"}
{"commit_tokens": ["making", "access", "assertion", "package", "private"], "add_tokens": "static interface AccessAssertion { static class SingleThreadAssertion static class MainThreadAssertion / * * * http : //www.apache.org/licenses/LICENSE-2.0 * * Modified code from AOSP", "del_tokens": "public static interface AccessAssertion { public static class SingleThreadAssertion public static class MainThreadAssertion / * * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * * if ( isInPool ( instance ) ) { throw new IllegalStateException ( \"Already in the pool!\" ) ; } private boolean isInPool ( T instance ) { for ( int i = 0 ; i < mPoolSize ; i ++ ) { if ( mPool [ i ] == instance ) { return true ; } } return false ; }", "commit_type": "make"}
{"commit_tokens": ["Fix", "dataDirectory", "creation", "when", "it", "s", "nested", "more", "than", "by", "1", "level"], "add_tokens": "mkdirs ( dataDirectory ) ;", "del_tokens": "Verify . verify ( this . dataDirectory . exists ( ) || this . dataDirectory . mkdir ( ) , \"Failed to mkdir %s\" , this . dataDirectory ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "CachingAuthenticator", "which", "caches", "the", "Principal"], "add_tokens": "* @ param allowedTimestampSlop the length of time for which the timestamp on a request can differ * from the server time when the request is received * @ param timeUnit the unit { @ code allowedTimestampSlop } is expressed in protected AbstractAuthenticator ( long allowedTimestampSlop , TimeUnit timeUnit ) { this . allowedTimestampRange = timeUnit . toMillis ( allowedTimestampSlop ) ;", "del_tokens": "* @ param duration the length of time for which the timestamp on a request can differ from the server * time when the request is received * @ param timeUnit the unit { @ code duration } is expressed in protected AbstractAuthenticator ( long duration , TimeUnit timeUnit ) { this . allowedTimestampRange = timeUnit . toMillis ( duration ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "list", "of", "expected", "domains", "to", "avoid", "searching", "for", "dynamically", "registered", "domains"], "add_tokens": "public Domain setExpectedRecordCount ( int expectedRecordCount ) { return this ;", "del_tokens": "public void setExpectedRecordCount ( int expectedRecordCount ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "embedded", "-", "jmxtrans", "threads", "daemon"], "add_tokens": "collectScheduledExecutor = Executors . newScheduledThreadPool ( getNumQueryThreads ( ) , new NamedThreadFactory ( \"jmxtrans-collect-\" , true ) ) ; exportScheduledExecutor = Executors . newScheduledThreadPool ( getNumExportThreads ( ) , new NamedThreadFactory ( \"jmxtrans-export-\" , true ) ) ;", "del_tokens": "collectScheduledExecutor = Executors . newScheduledThreadPool ( getNumQueryThreads ( ) , new NamedThreadFactory ( \"jmxtrans-collect-\" ) ) ; exportScheduledExecutor = Executors . newScheduledThreadPool ( getNumExportThreads ( ) , new NamedThreadFactory ( \"jmxtrans-export-\" ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Changing", "from", "private", "to", "protected", "to", "make", "the", "class", "more", "extensible", ".", "Extracting", "CacheEntry", "into", "its", "own", "class", "for", "reusability", "."], "add_tokens": "if ( ce != null && ce . getExpires ( ) > System . currentTimeMillis ( ) ) { ChannelFuture f = e . getChannel ( ) . write ( ce . getContent ( ) ) ;", "del_tokens": "if ( ce != null && ce . expires > System . currentTimeMillis ( ) ) { ChannelFuture f = e . getChannel ( ) . write ( ce . content ) ; private static class CacheEntry { public HttpMessage content ; public long expires ; private CacheEntry ( HttpMessage content , long expires ) { this . content = content ; this . expires = expires ; } }", "commit_type": "change"}
{"commit_tokens": ["adding", "wrapper", "interface", "to", "js", "http", "request"], "add_tokens": "import org . mozilla . javascript . * ; public class JsHttpRequest extends ScriptableObject implements HttpProtocol , Wrapper { @ Override public Object unwrap ( ) { return req ; }", "del_tokens": "import org . mozilla . javascript . Context ; import org . mozilla . javascript . RhinoHelper ; import org . mozilla . javascript . Scriptable ; import org . mozilla . javascript . ScriptableObject ; public class JsHttpRequest extends ScriptableObject implements HttpProtocol {", "commit_type": "add"}
{"commit_tokens": ["update", "druid", "encrypt", "and", "decrypt", "password", "logic"], "add_tokens": "private static final String PASSWORD_PKEY_TEMPLATE = \"db.%s.password.pkey\" ; String password = this . getProperty ( String . format ( PASSWORD_TEMPLATE , ds ) ) ; password = DruidEncryptPlugin . decryptedPassword ( this . getProperty ( String . format ( PASSWORD_PKEY_TEMPLATE , ds ) ) , password ) ; String user = this . getProperty ( String . format ( USER_TEMPLATE , ds ) ) ; DruidEncryptPlugin dp = new DruidEncryptPlugin ( url , user , password ) ;", "del_tokens": "DruidEncryptPlugin dp = new DruidEncryptPlugin ( url , this . getProperty ( String . format ( USER_TEMPLATE , ds ) ) , this . getProperty ( String . format ( PASSWORD_TEMPLATE , ds ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "api", "to", "prevent", "an", "item", "to", "be", "dragged", "above", "the", "top", "item"], "add_tokens": "private boolean mCanNotDragAboveTop ; public void setCanNotDragAboveTopItem ( boolean canNotDragAboveTop ) { mCanNotDragAboveTop = canNotDragAboveTop ; } // If we are not allowed to drag above top and new pos is 0 then don't do anything if ( ! ( mCanNotDragAboveTop && newPos == 0 ) ) { mAdapter . changeItemPosition ( mDragItemPosition , newPos ) ; mDragItemPosition = newPos ; }", "del_tokens": "mAdapter . changeItemPosition ( mDragItemPosition , newPos ) ; mDragItemPosition = newPos ;", "commit_type": "add"}
{"commit_tokens": ["Add", ":", "requestHandlers", "in", "ImageProgressClient"], "add_tokens": "import com . qingstor . sdk . utils . Base64 ; public void imageProgressAsync ( ResponseCallBack < ImageProcessOutput > callback ) throws QSException { bucket . imageProcessAsync ( objectName , input , callback ) ; } public RequestHandler imageProgressRequest ( ) throws QSException { return bucket . imageProcessRequest ( objectName , input ) ; } public RequestHandler getImageProgressExpiredUrlRequest ( long expires ) throws QSException { return bucket . imageProcessExpiredUrlRequest ( this . objectName , this . input , expires ) ; } sb . append ( Base64 . encode ( text . getBytes ( ) ) . replace ( \"=\" , \"\" ) ) ; sb . append ( \",c_\" ) ; String encode = Base64 . encode ( color . getBytes ( ) ) ; sb . append ( encode . replace ( \"=\" , \"\" ) ) ; sb . append ( Base64 . encode ( url . getBytes ( ) ) . replace ( \"=\" , \"\" ) ) ;", "del_tokens": "sb . append ( this . text ) ; sb . append ( \",c_\" ) ; sb . append ( this . color ) ; sb . append ( this . url ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "Ebean", "and", "other", "dependencies"], "add_tokens": "import io . ebeaninternal . dbmigration . model . CurrentModel ;", "del_tokens": "import io . ebean . dbmigration . model . CurrentModel ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "bug", "if", "deque", "is", "too", "small"], "add_tokens": "* push to end , pop from beginning // ensure that there are at least 10 entries int [ ] newArr = new int [ endIndexPlusOne + 10 ] ; if ( i > frontIndex ) }", "del_tokens": "* push to end , from from beginning int [ ] newArr = new int [ endIndexPlusOne ] ; if ( i > frontIndex ) }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "parsing", "photo_info", "in", "file", "metadata", "."], "add_tokens": "time_taken = JsonDateReader . Dropbox . readOptional ( parser ) ;", "del_tokens": "time_taken = JsonDateReader . Dropbox . readOptional ( parser ) ; break ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "constructor", "to", "set", "name", "and", "base", "URL", "of", "a", "custom", "server", "."], "add_tokens": "this ( \"OpenStreetMap\" , \"http://tile.openstreetmap.org\" ) ; } public OSMTileFactoryInfo ( String name , String baseURL ) { super ( name , baseURL ,", "del_tokens": "super ( \"OpenStreetMap\" , \"http://tile.openstreetmap.org\" ,", "commit_type": "add"}
{"commit_tokens": ["Add", "insertArchive", "with", "deployment", "specs", "to", "ArchiveRepository"], "add_tokens": "* Insert a Jar into the repository / * * * Insert a Jar into the repository * @ param jarScriptArchive script archive which describes the jar and * the ModuleSpec which should be inserted * @ param initialDeploySpecs a set of initial deployment specs . * @ throws UnsupportedOperationException if this repository does not support * adding deploy specs to a module . * / public void insertArchive ( JarScriptArchive jarScriptArchive , Map < String , Object > initialDeploySpecs ) throws IOException ;", "del_tokens": "* insert a Jar into the repository", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "BetamaxFilters", "to", "deal", "with", "aggregated", "requests", "."], "add_tokens": "if ( httpObject instanceof HttpContent ) { if ( httpObject instanceof LastHttpContent ) { response = onRequestIntercepted ( ) . orNull ( ) ; if ( httpObject instanceof HttpRequest ) { setViaHeader ( ( HttpMessage ) httpObject ) ; return null ; private Optional < ? extends FullHttpResponse > onRequestIntercepted ( ) throws IOException {", "del_tokens": "if ( httpObject instanceof HttpContent ) { if ( httpObject instanceof LastHttpContent ) { response = onRequestIntercepted ( ( HttpRequest ) httpObject ) . orNull ( ) ; try { if ( httpObject instanceof HttpContent ) { request . append ( ( HttpContent ) httpObject ) ; } if ( httpObject instanceof HttpRequest ) { setViaHeader ( ( HttpMessage ) httpObject ) ; } return null ; } catch ( IOException e ) { return createErrorResponse ( e ) ; private Optional < ? extends FullHttpResponse > onRequestIntercepted ( HttpRequest httpObject ) throws IOException {", "commit_type": "fix"}
{"commit_tokens": ["move", "PushAppId", "and", "masterSecret", "to", "Sender", "level"], "add_tokens": "@ Test public void testClientBuilderPushAppIdAndMasterSecret ( ) { SenderClient client = SenderClient . withRootServerURL ( \"https://aerogear.example.com/ag-push\" ) . pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET ) . build ( ) ; assertEquals ( \"https://aerogear.example.com/ag-push/\" , client . getServerURL ( ) ) ; assertEquals ( PUSH_APPLICATION_ID , client . getPushApplicationId ( ) ) ; assertEquals ( MASTER_SECRET , client . getMasterSecret ( ) ) ; }", "del_tokens": ". pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET ) . pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET ) . pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET ) . pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET ) . pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET ) . pushApplicationId ( PUSH_APPLICATION_ID ) . masterSecret ( MASTER_SECRET )", "commit_type": "move"}
{"commit_tokens": ["Fix", "for", "retrieving", "the", "action", "bean", "from", "the", "request", "attribute"], "add_tokens": "ActionBean actionBean = ( ActionBean ) pageContext . getRequest ( ) . getAttribute ( bean ) ;", "del_tokens": "ActionBean actionBean = ( ActionBean ) pageContext . getAttribute ( bean ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "the", "ability", "for", "property", "value", "checking", "to", "assert", "that", "a", "null", "property", "(", "doesnt", "exist", ")", "means", "wildcard", "."], "add_tokens": "import com . thinkaurelius . faunus . mapreduce . derivations . EdgePropertyValueFilter ; import com . thinkaurelius . faunus . mapreduce . derivations . VertexPropertyValueFilter ; return this . propertyValueFilter ( klass , key , compare , value , false ) ; } public FaunusGraph propertyValueFilter ( final Class < ? extends Element > klass , final String key , final Query . Compare compare , final Object value , final Boolean nullIsWildcard ) throws IOException { this . mapSequenceConfiguration . setBoolean ( VertexPropertyValueFilter . NULL_WILDCARD , nullIsWildcard ) ; this . mapSequenceConfiguration . setBoolean ( EdgePropertyValueFilter . NULL_WILDCARD , nullIsWildcard ) ;", "del_tokens": "import com . thinkaurelius . faunus . mapreduce . derivations . EdgePropertyValueFilter ; import com . thinkaurelius . faunus . mapreduce . derivations . VertexPropertyValueFilter ; / * private static Map < String , String > configurationToMap ( final Configuration configuration ) { final Map < String , String > map = new HashMap < String , String > ( ) ; for ( Map . Entry < String , String > entry : configuration ) { map . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } return map ; } * / //logger.info(\"\\tJob configuration: \" + FaunusGraph.configurationToMap(job.getConfiguration()));", "commit_type": "add"}
{"commit_tokens": ["allow", "round", "robin", "pool", "manipulation", "by", "A", "or", "AAAA", "naming", "convention"], "add_tokens": "roundRobinPoolApi . remove ( name , guid ) ;", "del_tokens": "roundRobinPoolApi . remove ( name , type , guid ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "tests", "for", "ModelProxy", "and", "fit", "it"], "add_tokens": "/ * * * Return the path to the resource inside the jar , e . g . ` / file . txt ` * / public String getResourcePath ( ) ;", "del_tokens": "public String getResourceName ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "sorting", "log", "line", "and", "no", "down", "sample"], "add_tokens": "final int ringBufferSize = 16 * 8192 ; System . getProperty ( \"rx.ring-buffer.size\" , ringBufferSize + \"\" ) ; long downSampleIntervalMs = TimeUnit . MINUTES . toMillis ( 0 ) ;", "del_tokens": "final int ringBufferSize = 16 * 8192 ; System . getProperty ( \"rx.ring-buffer.size\" , ringBufferSize + \"\" ) ; long downSampleIntervalMs = TimeUnit . MINUTES . toMillis ( 5 ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "date", "format", "handling", "so", "that", "Dates", "in", "collections", "will", "be", "formatted", "using", "the", "default", "date", "formatter", ".", "As", "a", "result", "set", "(", "variableName", "value", "formatter", ")", "has", "been", "removed", "."], "add_tokens": "protected DateFormat defaultDateFormat = new SimpleDateFormat ( \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\" ) ; //String date = defaultDateFormat.format(value); values . put ( variableName , value ) ;", "del_tokens": "private DateFormat defaultDateFormat = new SimpleDateFormat ( \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\" ) ; String date = defaultDateFormat . format ( value ) ; values . put ( variableName , date ) ; / * * * Sets a Date value into the list of variable substitutions using a user * defined { @ link DateFormat } . * * @ param variableName * @ param value * @ param format * @ return * @ since 1.0 * / public UriTemplate set ( String variableName , Date value , DateFormat format ) { values . put ( variableName , format . format ( value ) ) ; return this ; }", "commit_type": "change"}
{"commit_tokens": ["make", "sure", "that", "when", "debug", "is", "on", "old", "events", "are", "sent", "even", "if", "flag", "of", "NO", "events", "is", "on", "..."], "add_tokens": "if ( ! eventsOff || isDebuggerMode ( execution . getSystemContext ( ) ) ) { //consider flag events and debugger before sending events", "del_tokens": "if ( ! eventsOff ) {", "commit_type": "make"}
{"commit_tokens": ["fixing", "working", "directory", "support", "for", "Hadoop", ".", "Improve", "init", "method"], "add_tokens": "private SwiftConnectionManager swiftConnectionManager ; LOG . debug ( \"SwiftAPIClient constructor for {}\" , pFilesystemURI . toString ( ) ) ; } @ Override public void initiate ( String scheme ) throws IOException , ConfigurationParseException { cachedSparkOriginated = new HashMap < String , Boolean > ( ) ; cachedSparkJobsStatus = new HashMap < String , Boolean > ( ) ; schemaProvided = scheme ; Properties props = ConfigurationHandler . initialize ( filesystemURI , conf ) ; LOG . trace ( \"{} set connection manager\" , filesystemURI . toString ( ) ) ; // Hadoop eco system depends on working directory value // Although it's not needed by Spark, it still in use when native Hadoop uses Stocator // Current approach is similar to the hadoop-openstack logic that generates working folder // We should re-consider another approach String username = System . getProperty ( \"user.name\" ) ; Path path = new Path ( \"/user\" , username ) . makeQualified ( filesystemURI , new Path ( username ) ) ; LOG . debug ( \"Initializing SwiftNativeFileSystem against URI {} and working dir {}\" , filesystemURI , path . toString ( ) ) ; return path ;", "del_tokens": "private final SwiftConnectionManager swiftConnectionManager ; } @ Override public void initiate ( String scheme ) throws IOException , ConfigurationParseException { cachedSparkOriginated = new HashMap < String , Boolean > ( ) ; cachedSparkJobsStatus = new HashMap < String , Boolean > ( ) ; schemaProvided = scheme ; Properties props = ConfigurationHandler . initialize ( filesystemURI , conf ) ; return null ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "default", "timeout", "public", "so", "it", "can", "be", "set", "globally"], "add_tokens": "public static final int DEFAULT_TIMEOUT = 10000 ;", "del_tokens": "private static final int DEFAULT_TIMEOUT = 10000 ;", "commit_type": "make"}
{"commit_tokens": ["Use", "architecture", "-", "appropriate", "webdriver", "if", "possible"], "add_tokens": "private URL getDriverRsrc ( Platform platform , String browser , String bits ) throws RuntimeException { rsrcDriver = getClass ( ) . getResource ( \"/drivers/\" + browser + \"driver-linux-\" + bits + \"bit\" ) ; rsrcDriver = getClass ( ) . getResource ( \"/drivers/\" + browser + \"driver-mac-\" + bits + \"bit\" ) ; rsrcDriver = getClass ( ) . getResource ( \"/drivers/\" + browser + \"driver-windows-\" + bits + \"bit.exe\" ) ; // If searching for system-appropriate version did not work, fall back on 32-bit version if ( rsrcDriver == null && ! bits . equals ( \"32\" ) ) { rsrcDriver = getDriverRsrc ( platform , browser , \"32\" ) ; } return rsrcDriver ; } private String extractDriver ( Platform platform , String browser ) throws IOException , RuntimeException { // Determine system architecture and load an appropriate driver if possible String bits = System . getProperty ( \"os.arch\" ) . endsWith ( \"64\" ) ? \"64\" : \"32\" ; URL rsrcDriver = getDriverRsrc ( platform , browser , bits ) ; // Extract the executable to a temp file", "del_tokens": "private String extractDriver ( Platform platform , String browser ) throws IOException , RuntimeException { rsrcDriver = getClass ( ) . getResource ( \"/drivers/\" + browser + \"driver-linux-32bit\" ) ; rsrcDriver = getClass ( ) . getResource ( \"/drivers/\" + browser + \"driver-mac-32bit\" ) ; rsrcDriver = getClass ( ) . getResource ( \"/drivers/\" + browser + \"driver-windows-32bit.exe\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "utility", "method", "inline", "now", "it", "is", "used", "in", "one", "place"], "add_tokens": "import javax . xml . transform . OutputKeys ; import javax . xml . transform . Result ; import javax . xml . transform . Source ; import javax . xml . transform . Transformer ; import javax . xml . transform . TransformerFactory ; import javax . xml . transform . TransformerFactoryConfigurationError ; Transformer transformer = TransformerFactory . newInstance ( ) . newTransformer ( ) ; transformer . setOutputProperty ( OutputKeys . INDENT , \"yes\" ) ; transformer . setOutputProperty ( \"{http://xml.apache.org/xslt}indent-amount\" , \"4\" ) ; transformer . transform ( domSource , streamResult ) ;", "del_tokens": "StarterUtil . identityTransform ( domSource , streamResult ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "getAllPaths", "()", "to", "credentials", "operations", "."], "add_tokens": "return \"CredentialSummaryData{\"", "del_tokens": "return \"CredentialSummaryResponse{\"", "commit_type": "add"}
{"commit_tokens": ["updating", "methods", "names", "in", "samples", "to", "increase", "consistency"], "add_tokens": "public void onEvent ( ConnectivityChanged event ) { public void onEvent ( WifiSignalStrengthChanged event ) {", "del_tokens": "/ * * * Exemplary activity showing how to use NetworkEvents library with Dagger and ButterKnife . * Take a closer look on onConnectivityChanged and onWifiSignalStrengthChanged methods * as well as @ Subscribe annotations , initialization of Bus and NetworkEvents classes . * / public void onConnectivityChanged ( ConnectivityChanged event ) { public void onWifiSignalStrengthChanged ( WifiSignalStrengthChanged event ) {", "commit_type": "update"}
{"commit_tokens": ["Remove", "JSuncaughtExceptionLine", "use", "an", "error", "reporter", "to", "report", "line", "number", "info", "instead", "."], "add_tokens": "// Use the interpreter for interactive input cx . setOptimizationLevel ( - 1 ) ; String msg = ToolErrorReporter . getMessage ( \"msg.uncaughtJSException\" , ee . toString ( ) ) ; if ( ee . getSourceName ( ) != null ) { Context . reportError ( msg , ee . getSourceName ( ) , ee . getLineNumber ( ) , null , 0 ) ; } else { Context . reportError ( msg ) ; } String msg = ToolErrorReporter . getMessage ( \"msg.uncaughtJSException\" , ee . toString ( ) ) ; Context . reportError ( msg , ee . getSourceName ( ) , ee . getLineNumber ( ) , null , 0 ) ; Context . reportError ( msg ) ;", "del_tokens": "Context . reportError ( ToolErrorReporter . getMessage ( \"msg.uncaughtJSException\" , ee . toString ( ) ) ) ; Object [ ] args = { ee . getSourceName ( ) , new Integer ( ee . getLineNumber ( ) ) , ee . toString ( ) } ; Context . reportError ( ToolErrorReporter . getMessage ( \"msg.uncaughtJSExceptionLine\" , args ) ) ; Context . reportError ( ToolErrorReporter . getMessage ( \"msg.uncaughtJSException\" , ee . toString ( ) ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "the", "dead", "man", "switch", "connection", "feature"], "add_tokens": "/ * * * The dead man switch * / private boolean deadManSwitch = false ; public BitfinexApiBroker ( final String apiKey , final String apiSecret , final boolean deadManSwitch ) { this ( apiKey , apiSecret ) ; this . deadManSwitch = deadManSwitch ; } / * * * Is the dead man feature enabled * @ return * / public boolean isDeadManFeatureEnabled ( ) { return deadManSwitch ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Implementing", "multitouch", "support", "on", "Android", "devices", ".", "In", "addition", "this", "adds", "pressure", "and", "size", "values", "to", "Touch", ".", "TouchEvent", "and", "new", "constructors", "and", "methods", "to", "set", "and", "access", "these", "."], "add_tokens": "ForPlay . setPlatform ( new AndroidPlatform ( activity ) ) ; private AndroidTouch touch ; private AndroidTouchEventHandler touchHandler ; instance = this ; touch = new AndroidTouch ( ) ; touchHandler = new AndroidTouchEventHandler ( ) ; return touch ; } public AndroidTouchEventHandler touchEventHandler ( ) { return touchHandler ; //Run the game's custom painting code. //Separate from layers painting themselves.", "del_tokens": "ForPlay . setPlatform ( instance = new AndroidPlatform ( activity ) ) ; // TODO(pdr): need to implement this. return null ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "::", "inspect"], "add_tokens": "public String toS ( ) { return list . toString ( ) ; }", "del_tokens": "public String toS ( ) { return list . toString ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Changed", "callable", "and", "failure", "to", "be", "an", "instance", "of", "FusionTask", "."], "add_tokens": "return FusionTask . create ( name , Promises . value ( null ) , ( src , dst ) -> { dst . fail ( failure ) ; } ) ; return FusionTask . create ( name , Promises . value ( null ) , ( src , dst ) -> { try { dst . done ( callable . call ( ) ) ; } catch ( Throwable t ) { dst . fail ( t ) ; } } ) ;", "del_tokens": "return async ( name , ( ) -> Promises . error ( failure ) , false ) ; return async ( name , ( ) -> Promises . value ( callable . call ( ) ) , false ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "ObjectBuffer", "resizing", "and", "added", "a", "test", "for", "it", "."], "add_tokens": "ByteArrayOutputStream byteStream = new ByteArrayOutputStream ( 256 ) ;", "del_tokens": "ByteArrayOutputStream byteStream = new ByteArrayOutputStream ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "serializable", "domain", "objects", "."], "add_tokens": "import java . io . Serializable ; public static class Head implements Serializable { public static class Remote implements Serializable {", "del_tokens": "public static class Head { public static class Remote {", "commit_type": "use"}
{"commit_tokens": ["Make", "unit", "test", "parameters", "more", "conservative"], "add_tokens": "int concurrency = 10 ; final int reqNum = 6000 ;", "del_tokens": "int concurrency = 20 ; final int reqNum = 4000 ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "use", "of", "deprecated", "apis"], "add_tokens": "import java . time . Duration ; final Duration timeoutDuration = Duration . ofMillis ( dnsLookupTimeoutMillis ) ; resolver . setTimeout ( timeoutDuration ) ;", "del_tokens": "import static java . lang . Math . toIntExact ; import static java . util . concurrent . TimeUnit . MILLISECONDS ; int timeoutSecs = toIntExact ( MILLISECONDS . toSeconds ( dnsLookupTimeoutMillis ) ) ; int millisRemainder = toIntExact ( dnsLookupTimeoutMillis - SECONDS . toMillis ( timeoutSecs ) ) ; resolver . setTimeout ( timeoutSecs , millisRemainder ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "cache", "REST", "response", "."], "add_tokens": "// if (!authorize(request.getHeader(\"Authorization\"))) { // request.setReasonCode(HttpReasonCode.Unauthorized); // return; // } String requestedPath = request . getRequestedUri ( ) . getPath ( ) ; if ( requestedPath . equals ( \"/pools/default/bucketsStreaming/default\" ) ) { } else if ( requestedPath . equals ( \"/pools/default/buckets/default\" ) ) { } else if ( requestedPath . equals ( \"/pools\" ) ) { try { // Success request . setReasonCode ( HttpReasonCode . OK ) ; OutputStream os = request . getOutputStream ( ) ; os . write ( getPoolsJSON ( ) ) ; } catch ( IOException ex ) { Logger . getLogger ( JMembase . class . getName ( ) ) . log ( Level . SEVERE , null , ex ) ; request . resetResponse ( ) ; request . setReasonCode ( HttpReasonCode . Internal_Server_Error ) ; }", "del_tokens": "if ( ! authorize ( request . getHeader ( \"Authorization\" ) ) ) { request . setReasonCode ( HttpReasonCode . Unauthorized ) ; return ; } if ( request . getRequestedUri ( ) . getPath ( ) . equals ( \"/pools/default/bucketsStreaming/default\" ) ) { } else if ( request . getRequestedUri ( ) . getPath ( ) . equals ( \"/pools/default/buckets/default\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "it", "possible", "to", "run", "tests", "with", "firefox", "driver", "without", "having", "to", "change", "code"], "add_tokens": "if ( System . getProperty ( \"ghostdriver.test.driver\" , \"\" ) . equals ( \"firefox\" ) ) { mDriver = new FirefoxDriver ( capabilities ) ; } else { mDriver = new RemoteWebDriver ( new URL ( GHOSTDRIVER_URL ) , capabilities ) ; }", "del_tokens": "mDriver = new RemoteWebDriver ( new URL ( GHOSTDRIVER_URL ) , capabilities ) ; // mDriver = new FirefoxDriver(capabilities);", "commit_type": "make"}
{"commit_tokens": ["Add", "ability", "to", "read", "SqlArgs", "and", "Schema", "from", "a", "query", "result"], "add_tokens": "throw new DatabaseException ( \"Batch did not return the expected result: \" + Arrays . toString ( result ) ) ;", "del_tokens": "throw new DatabaseException ( \"Batch did not return the expected result: \" + Arrays . asList ( result ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "argument", "type", "form", "int", "to", "long", "."], "add_tokens": "public ActivityQueryParams minId ( long minId ) { public ActivityQueryParams maxId ( long maxId ) {", "del_tokens": "public ActivityQueryParams minId ( int minId ) { public ActivityQueryParams maxId ( int maxId ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "missing", "type", "for", "linked", "style", "sheets"], "add_tokens": "&& ( e . getAttribute ( \"type\" ) . isEmpty ( ) || \"text/css\" . equalsIgnoreCase ( e . getAttribute ( \"type\" ) ) )", "del_tokens": "&& \"text/css\" . equalsIgnoreCase ( e . getAttribute ( \"type\" ) )", "commit_type": "allow"}
{"commit_tokens": ["Added", "test", "for", "preflight", "with", "any", "origin", "and", "withCredentials", "disabled", "."], "add_tokens": ". getFilterConfigAnyOriginAndSupportsCredentialsDisabled ( ) ) ; Assert . assertTrue ( response . getHeader ( CORSFilter . RESPONSE_HEADER_ACCESS_CONTROL_ALLOW_ORIGIN ) . equals ( \"*\" ) ) ; Assert . assertNull ( response . getHeader ( CORSFilter . RESPONSE_HEADER_ACCESS_CONTROL_ALLOW_CREDENTIALS ) ) ;", "del_tokens": ". getDefaultFilterConfig ( ) ) ; Assert . assertEquals ( HttpServletResponse . SC_FORBIDDEN , response . getStatus ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "Lazy", "interface", "for", "Widgets", "plugin", ".", "Fixing", "a", "test"], "add_tokens": "public boolean f ( Event ev ) { done = 0 ; $ ( \"table > tbody > tr > td > input:checked\" , e ) . each ( new Function ( ) { assertEquals ( 1 , done ) ;", "del_tokens": "public boolean f ( Event e ) { $ ( \"table > tbody > tr > td > input:checked\" ) . each ( new Function ( ) { done = 0 ; assertEquals ( 1 , done ) ;", "commit_type": "add"}
{"commit_tokens": ["made", "scaling", "better", "regarding", "current", "mouse", "position"], "add_tokens": "double oldScaleX = scaleX ; double oldScaleY = scaleY ; // respect mouse x,y when scaling // TODO minor bug: compute difference of lat,lon position for mouse before and after scaling if ( e . getWheelRotation ( ) < 0 ) { offsetX -= ( offsetX + e . getX ( ) ) * scaleX ; offsetY -= ( offsetY + e . getY ( ) ) * scaleY ; } else { offsetX += e . getX ( ) * oldScaleX ; offsetY += e . getY ( ) * oldScaleY ; } logger . info ( \"mouse wheel moved => repaint \" + e . getWheelRotation ( ) + \" \" + offsetX + \",\" + offsetY + \" \" + scaleX + \",\" + scaleY ) ;", "del_tokens": "// TODO respect mouse x,y when scaling offsetX -= offsetX * scaleX - currentPosX ; offsetY -= offsetY * scaleY - currentPosY ; logger . info ( \"mouse wheel moved => repaint\" ) ;", "commit_type": "make"}
{"commit_tokens": ["remove", "container", "commit", "changes", "from", "this", "branch"], "add_tokens": "imagesService . pullImage ( imageId ) ;", "del_tokens": "import net . wouterdanes . docker . provider . model . ContainerCommitConfiguration ; @ Override public String commitContainer ( final ContainerCommitConfiguration configuration ) { return miscService . commitContainer ( configuration . getId ( ) , Optional . fromNullable ( configuration . getRepo ( ) ) , Optional . fromNullable ( configuration . getTag ( ) ) , Optional . fromNullable ( configuration . getComment ( ) ) , Optional . fromNullable ( configuration . getAuthor ( ) ) ) ; } String result = imagesService . pullImage ( imageId ) ; System . out . println ( result ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "trans", "index", "for", "UAO", "and", "HKSCS"], "add_tokens": "super ( \"Big5-HKSCS\" , Big5HKSCSEncLen , 2 ) ;", "del_tokens": "super ( \"Big5-HKSCS\" , Big5HKSCSEncLen , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Dependencies", "and", "Build", "Tools"], "add_tokens": "IProxyBasedMockInterceptor interceptor = new JavaMockInterceptor ( configuration , specification , mockMetaClass ) ; configuration . getConstructorArgs ( ) , interceptor , specification . getClass ( ) . getClassLoader ( ) ) ;", "del_tokens": "IProxyBasedMockInterceptor interceptor = new JavaMockInterceptor ( configuration , specification , mockMetaClass ) ; configuration . getConstructorArgs ( ) , interceptor , specification . getClass ( ) . getClassLoader ( ) , configuration . isUseObjenesis ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Changed", "visibility", "of", "OntologyBuilder", "build", "method", "."], "add_tokens": "protected Ontology build ( ) throws URISyntaxException {", "del_tokens": "Ontology build ( ) throws URISyntaxException {", "commit_type": "change"}
{"commit_tokens": ["Make", "it", "safe", "to", "pass", "a", "parallel", "stream", "to", "saveAll"], "add_tokens": "entities . forEach ( entity -> this . saveEntity ( bw , entity ) ) ; } } private void saveEntity ( PgBinaryWriter bw , TEntity entity ) throws SaveEntityFailedException { synchronized ( bw ) { // Start a New Row: bw . startRow ( columns . size ( ) ) ; // Iterate over each column mapping: columns . forEach ( column -> { try { column . getWrite ( ) . invoke ( bw , entity ) ; } catch ( Exception e ) { throw new SaveEntityFailedException ( e ) ; } } ) ;", "del_tokens": "int columnCount = columns . size ( ) ; entities . forEach ( entity -> { // Start a New Row: bw . startRow ( columnCount ) ; // Iterate over each column mapping: columns . forEach ( column -> { try { column . getWrite ( ) . invoke ( bw , entity ) ; } catch ( Exception e ) { throw new SaveEntityFailedException ( e ) ; } } ) ; } ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "uploader", "field", "back", "to", "PatchsetCreated", "."], "add_tokens": "import java . io . IOException ; /* To allow old builds to deserialize without warnings. */ private Account uploader ; private void readObject ( java . io . ObjectInputStream in ) throws IOException , ClassNotFoundException { in . defaultReadObject ( ) ; / * If we 're loading an old build with only one of these parameters, set * the other to it . * / if ( uploader == null && account != null ) { uploader = account ; } if ( account == null && uploader != null ) { account = uploader ; } }", "del_tokens": "@ Override public int hashCode ( ) { //CS IGNORE MagicNumber FOR NEXT 5 LINES. REASON: Autogenerated Code. //CS IGNORE AvoidInlineConditionals FOR NEXT 5 LINES. REASON: Autogenerated Code. int hash = 5 ; hash = 83 * hash + ( this . change != null ? this . change . hashCode ( ) : 0 ) ; hash = 83 * hash + ( this . patchSet != null ? this . patchSet . hashCode ( ) : 0 ) ; return hash ; } / * * * Implementation specific equals . * @ param obj the object to compare . * @ see # equals ( java . lang . Object ) * @ return true if equals * / public boolean equals ( PatchsetCreated obj ) { return change . equals ( obj . change ) && patchSet . equals ( obj . patchSet ) ; }", "commit_type": "add"}
{"commit_tokens": ["Removing", "detection", "point", "from", "response", "object", "-", "no", "need", "to", "store", "this", ".", "A"], "add_tokens": "if ( userMatch && detectionSystemMatch && earliestMatch ) {", "del_tokens": "import org . owasp . appsensor . DetectionPoint ; DetectionPoint detectionPoint = criteria . getDetectionPoint ( ) ; //check detection point match if detection point specified boolean detectionPointMatch = ( detectionPoint != null ) ? detectionPoint . getId ( ) . equals ( response . getDetectionPoint ( ) . getId ( ) ) : true ; if ( userMatch && detectionSystemMatch && detectionPointMatch && earliestMatch ) {", "commit_type": "remove"}
{"commit_tokens": ["fixed", "crash", "if", "ApiDemos", "app", "is", "installed", "on", "device"], "add_tokens": "import android . content . pm . PackageManager ; private List < ActivityInfo > getActivitiesList ( ) { String packageName = getApplicationInfo ( ) . packageName ; if ( packageName . equals ( info . activityInfo . packageName ) ) list . add ( info . activityInfo ) ; return new SampleAdapter ( this , getActivitiesList ( ) ) ; private PackageManager mPackageManager ; mPackageManager = context . getPackageManager ( ) ; ( ( TextView ) convertView ) . setText ( item . loadLabel ( mPackageManager ) ) ;", "del_tokens": "import android . text . TextUtils ; private List < ActivityInfo > getInfosList ( ) { list . add ( info . activityInfo ) ; return new SampleAdapter ( this , getInfosList ( ) ) ; TextView tv = ( TextView ) convertView ; if ( TextUtils . isEmpty ( item . nonLocalizedLabel ) ) { tv . setText ( item . labelRes ) ; } else { tv . setText ( item . nonLocalizedLabel ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Update", "exception", "message", "for", "unknown", "error"], "add_tokens": "throw new ViSearchException ( \"An unknown error occurred in ViSearch: \" + json , json ) ;", "del_tokens": "throw new ViSearchException ( \"An unknown error occurred in ViSearch.\" , json ) ;", "commit_type": "update"}
{"commit_tokens": ["Allow", "client", "ids", "to", "match", "if", "they", "are", "both", "empty"], "add_tokens": "import org . springframework . util . StringUtils ; if ( clientMatches ( value ) ) { private boolean clientMatches ( OAuth2RestOperations value ) { String clientIdForTemplate = value . getResource ( ) . getClientId ( ) ; boolean clientsEqual = clientIdForTemplate != null && clientIdForTemplate . equals ( clientId ) ; boolean clientsBothEmpty = ! StringUtils . hasText ( clientIdForTemplate ) && ! StringUtils . hasText ( clientId ) ; return clientsEqual || clientsBothEmpty ; }", "del_tokens": "String clientIdForTemplate = value . getResource ( ) . getClientId ( ) ; if ( clientIdForTemplate != null && clientIdForTemplate . equals ( clientId ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", ":", "for", "consistency", "require", "always", "InputStream", "in", "ConfigReader", "."], "add_tokens": "InputStream getResponseFile ( String relativeFilePath ) throws IOException ;", "del_tokens": "import java . io . File ; public File getResponseFile ( String relativeFilePath ) throws IOException ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "binding", "issue", "."], "add_tokens": "URI uri = sipFactory . createAddress ( \"sip:receiver@127.0.0.1:5059\" ) . getURI ( ) ;", "del_tokens": "URI uri = sipFactory . createAddress ( \"sip:receiver@10.32.4.95:5059\" ) . getURI ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "LIKE", "clause", "ignore", "the", "case"], "add_tokens": "criteriaBuilder . like ( criteriaBuilder . lower ( expression ) , \"%\" + filterValue . toLowerCase ( ) + \"%\" ) ) ; criteriaBuilder . like ( criteriaBuilder . lower ( expression ) , \"%\" + globalFilterValue . toLowerCase ( ) + \"%\" ) ) ;", "del_tokens": "criteriaBuilder . like ( expression , \"%\" + filterValue + \"%\" ) ) ; criteriaBuilder . like ( expression , \"%\" + globalFilterValue + \"%\" ) ) ;", "commit_type": "make"}
{"commit_tokens": ["make", "TYPE", "filter", "work", "on", "multi", "-", "level", "path"], "add_tokens": "final Class < ? > exp = ( Class < ? > ) expectedVal ; return objectOrAnyCollectionItemMatches ( actualVal , new Predicate < Object > ( ) { @ Override public boolean accept ( Object value ) { Class < ? > act = value == null ? null : value . getClass ( ) ; if ( act == null ) { return false ; } else { return act . equals ( exp ) ; } } } ) ;", "del_tokens": "Class < ? > exp = ( Class < ? > ) expectedVal ; Class < ? > act = actualVal == null ? null : actualVal . getClass ( ) ; if ( act == null ) { return false ; } else { return act . equals ( exp ) ; }", "commit_type": "make"}
{"commit_tokens": ["Added", "integration", "test", "and", "license", "information", "where", "it", "was", "missing", "."], "add_tokens": "/ * * Copyright 2002 - 2007 the original author or authors . * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / return new String [ ] { \"conf/ldapAndJdbcTransactionTestContext.xml\" } ;", "del_tokens": "return new String [ ] { \"conf/ldapTemplateTransactionTestContext.xml\" } ;", "commit_type": "add"}
{"commit_tokens": ["Change", "Javadoc", "to", "mention", "SyncSubscription", "instead", "of", "AsyncSubscription", "."], "add_tokens": "* Creates a { @ link SyncSubscription } with interest in a given subject . In order to receive * messages , call one of the available { @ link SyncSubscription # nextMessage ( ) } . * @ return the { @ link SyncSubscription }", "del_tokens": "* Creates a { @ code AsyncSubscription } with interest in a given subject . In order to receive * messages , a { @ code MessageHandler } must be registered , and { @ link AsyncSubscription # start ( ) } * must be called . * @ return the { @ code AsyncSubscription }", "commit_type": "change"}
{"commit_tokens": ["added", "classes", "SetOfMolecules", "ChemModel", "ChemSequence", "ChemFile"], "add_tokens": "growArraySize = bonds . length ; growArraySize = atoms . length ;", "del_tokens": "/ * * * Gets the ConnectionTable attribute of the AtomContainer object * * @ return The ConnectionTable value * / public int [ ] [ ] getConnectionTable ( ) { Atom [ ] bondatoms ; int [ ] [ ] ct = new int [ atoms . length ] [ atoms . length ] ; for ( int f = 0 ; f < bonds . length ; f ++ ) { bondatoms = bonds [ f ] . getAtoms ( ) ; wireAtoms ( ct , atoms , 0 , 1 ) ; } return ct ; } / * * * Description of the Method * * @ param ct Description of Parameter * @ param atoms Description of Parameter * @ param pos1 Description of Parameter * @ param pos2 Description of Parameter * / protected void wireAtoms ( int [ ] [ ] ct , Atom [ ] atoms , int pos1 , int pos2 ) { if ( pos1 < atoms . length ) { if ( pos2 < atoms . length ) { } } }", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "visitor", "for", "ConnectionSpecs", "and", "a", "method", "to", "get", "the", "DataSourceConnectionSpec", "s", "DataSource", "object", "."], "add_tokens": "public DriverManagerConnectionSpec ( String url , String user , String password ) { / * * * Performs some processing on this connection spec . * * @ param connectionSpecVisitor a { @ link ConnectionSpecVisitor } . * / @ Override public void accept ( ConnectionSpecVisitor connectionSpecVisitor ) { connectionSpecVisitor . visit ( this ) ; }", "del_tokens": "public DriverManagerConnectionSpec ( String url , String user , String password ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "overloaded", "methods", "to", "make", "the", "initialization", "easier", "in", "default"], "add_tokens": "public void createCachingXmlDataStore_fallback1_null ( ) throws IOException { public void createCachingXmlDataStore_fallback2_null ( ) throws IOException { CachingXmlDataStore . createCachingXmlDataStore ( DATA_URL , VERSION_URL , CHARSET , null ) ; } @ Test ( expected = IllegalArgumentException . class ) public void createCachingXmlDataStore_fallback3_null ( ) throws IOException { CachingXmlDataStore . createCachingXmlDataStore ( new File ( \"test\" ) , null ) ; } @ Test ( expected = IllegalArgumentException . class ) public void createCachingXmlDataStore_file1_null ( ) throws IOException { CachingXmlDataStore . createCachingXmlDataStore ( null , DATA_URL , VERSION_URL , CHARSET ) ; } @ Test ( expected = IllegalArgumentException . class ) public void createCachingXmlDataStore_file2_null ( ) throws IOException { @ Test ( expected = IllegalArgumentException . class ) public void createCachingXmlDataStore_file3_null ( ) throws IOException { CachingXmlDataStore . createCachingXmlDataStore ( null , Data . EMPTY ) ; }", "del_tokens": "public void createCachingXmlDataStore_fallback_null ( ) throws IOException { public void createCachingXmlDataStore_file_null ( ) throws IOException { @ Test ( expected = IllegalArgumentException . class ) public void createCachingXmlDataStore_withoutSpecificCacheFile_fallback_null ( ) throws IOException { CachingXmlDataStore . createCachingXmlDataStore ( DATA_URL , VERSION_URL , CHARSET , null ) ; }", "commit_type": "add"}
{"commit_tokens": ["fix", "decimal", "separator", "when", "convert", "percentage", "elements"], "add_tokens": "* < p > * < p > * < p > * < p > import java . text . DecimalFormatSymbols ; * The pattern to output percentage values in the CSV format . This pattern is used private static final String ZERO_PRECISION_PATTERN = \"0%\" ; * @ param locale the locale for parsing date and percent elements . valueToPrint = convertPercentElementToString ( entry , column . getFormat ( ) , locale ) ; * @ param locale the locale for parsing value . private static String convertPercentElementToString ( Object value , ColumnFormat columnFormat , Locale locale ) { DecimalFormatSymbols dfs = new DecimalFormatSymbols ( locale ) ; DecimalFormat df = new DecimalFormat ( ZERO_PRECISION_PATTERN , dfs ) ; df = new DecimalFormat ( pattern , dfs ) ;", "del_tokens": "* * * * The format to output percentage values in the CSV format . This format is used private static final DecimalFormat ZERO_PRECISION_FORMAT = new DecimalFormat ( \"0%\" ) ; * @ param locale the locale for parsing date elements . valueToPrint = convertPercentElementToString ( entry , column . getFormat ( ) ) ; private static String convertPercentElementToString ( Object value , ColumnFormat columnFormat ) { DecimalFormat df = ZERO_PRECISION_FORMAT ; df = new DecimalFormat ( pattern ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "getItem", "method", "to", "FileItemAdapter"], "add_tokens": "protected final LogicHandler < T > mLogic ; protected SortedList < T > mList = null ; / * * * Get the item at the designated position in the adapter . * * @ param position of item in adapter * @ return null if position is zero ( that means it 's the \"..\" header), the item otherwise. * / protected @ Nullable T getItem ( int position ) { if ( position == 0 ) { return null ; } return mList . get ( position - 1 ) ; }", "del_tokens": "private final LogicHandler < T > mLogic ; private SortedList < T > mList = null ;", "commit_type": "add"}
{"commit_tokens": ["Add", "style", "and", "fix", "bug", "for", "EditText", "."], "add_tokens": "if ( ! mInEditMode && mAnimEnable && mEnable ) {", "del_tokens": "if ( ! mInEditMode && mAnimEnable ) {", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "mapping", "MySQL", "TIME", "data", "type", "to", "java", ".", "time", ".", "LocalTime"], "add_tokens": "import io . vertx . mysqlclient . impl . datatype . DataType ; import io . vertx . mysqlclient . impl . protocol . ColumnDefinition ; int pos = getColumnIndex ( name ) ; return pos == - 1 ? null : getLocalTime ( pos ) ; @ Override public LocalTime getLocalTime ( int pos ) { ColumnDefinition columnDefinition = rowDesc . columnDefinitions ( ) [ pos ] ; Object val = getValue ( pos ) ; if ( columnDefinition . getType ( ) == DataType . TIME && val instanceof Duration ) { // map MySQL TIME data type to java.time.LocalTime Duration duration = ( Duration ) val ; return LocalTime . ofNanoOfDay ( duration . toNanos ( ) ) ; } else { return super . getLocalTime ( pos ) ; } }", "del_tokens": "throw new UnsupportedOperationException ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "OS", "arch", "condition", "for", "amd64", "arch", "type", "to", "work"], "add_tokens": "return \"amd64\" . equalsIgnoreCase ( OS_ARCH ) ? \"linux_x86_64\" : \"linux_\" + OS_ARCH ; }", "del_tokens": "return \"linux_\" + OS_ARCH ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "the", "bytecode", "parser"], "add_tokens": "c . dup ( ) ;", "del_tokens": "c . iconst ( 0 ) ; //just to make the stacks match c . swap ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "get", "()", "and", "getValue", "()", "on", "AbstractConfigObject", "return", "a", "more", "specific", "type"], "add_tokens": "public AbstractConfigValue get ( Object key ) { public AbstractConfigValue getValue ( String path ) {", "del_tokens": "public ConfigValue get ( Object key ) { public ConfigValue getValue ( String path ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "example", "for", "ExcelFileOutputFormat", "-", "Convert", "CSV", "to", "EXcel"], "add_tokens": "Writable [ ] currentRowTextArray = currentRow . get ( ) ; for ( Writable currentColumn : currentRowTextArray ) { // for each column in the row String formattedValue = ( String ) currentColumn . get ( ) . toString ( ) ;", "del_tokens": "Text [ ] currentRowTextArray = ( Text [ ] ) currentRow . get ( ) ; for ( Text currentColumn : currentRowTextArray ) { // for each column in the row String formattedValue = currentColumn . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "self", "-", "bound", "singletons"], "add_tokens": "conf . boundImpls . put ( cn , d ) ;", "del_tokens": "if ( c != d ) { // Note: d is *NOT* necessarily a singleton. conf . boundImpls . put ( cn , d ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "quarter", "calculation", "in", "intervals"], "add_tokens": ". put ( \"quarter\" , start . get ( Calendar . MONTH ) / 3 + 1 ) ; ObjectNode to = mapper . createObjectNode ( ) . put ( \"year\" , end . get ( Calendar . YEAR ) ) . put ( \"quarter\" , end . get ( Calendar . MONTH ) / 3 + 1 ) ;", "del_tokens": ". put ( \"quarter\" , start . get ( Calendar . MONTH ) / 3 ) ; ObjectNode to = mapper . createObjectNode ( ) . put ( \"year\" , end . get ( Calendar . YEAR ) ) . put ( \"quarter\" , end . get ( Calendar . MONTH ) / 3 ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "jmockit", "to", "do", "unit", "testing"], "add_tokens": "import com . baidu . disconf . client . test . fetcher . FetcherMgrMgrTestCase ; FetcherMgrMgrTestCase . class , DisconfCoreMgrTestCase . class ,", "del_tokens": "import com . baidu . disconf . client . test . fetcher . RestfulMgrTestCase ; RestfulMgrTestCase . class , DisconfCoreMgrTestCase . class ,", "commit_type": "add"}
{"commit_tokens": ["Adds", "toString", "to", "Targets", ".", "Normalizes", "equals", "/", "hashCode", "."], "add_tokens": "} else if ( \"hashCode\" . equals ( method . getName ( ) ) ) { } else if ( \"toString\" . equals ( method . getName ( ) ) ) { return toString ( ) ; @ Override public boolean equals ( Object obj ) { if ( obj instanceof FeignInvocationHandler ) { FeignInvocationHandler other = ( FeignInvocationHandler ) obj ; return target . equals ( other . target ) ; @ Override public int hashCode ( ) { return target . hashCode ( ) ; } return target . toString ( ) ;", "del_tokens": "} if ( \"hashCode\" . equals ( method . getName ( ) ) ) { @ Override public int hashCode ( ) { return target . hashCode ( ) ; } @ Override public boolean equals ( Object other ) { if ( other instanceof FeignInvocationHandler ) { FeignInvocationHandler that = ( FeignInvocationHandler ) other ; return this . target . equals ( that . target ) ; return \"target(\" + target + \")\" ;", "commit_type": "add"}
{"commit_tokens": ["Making", "channel", "future", "handler", "run", "in", "separate", "thread", ".", "Workaround", "for", "https", ":", "//", "github", ".", "com", "/", "netty", "/", "netty", "/", "issues", "/", "1840"], "add_tokens": "boolean shouldRetry = retryOkayOnOperation && numRetries > 0 && isRetriableException ( e ) ;", "del_tokens": "boolean shouldRetry = retryOkayOnOperation && numRetries >= 0 && isRetriableException ( e ) ;", "commit_type": "make"}
{"commit_tokens": ["Updating", "line", "number", "info", "for", "element", "types", "in", "FeatureFileParser"], "add_tokens": "public Step ( final String theLine , final boolean isSubStep , final File source , final int lineNumber ) { this . log . debug ( \"annot of step is null: \" + this . getClass ( ) . getSimpleName ( ) ) ; return this . substitutedInlineTable != null ? this . substitutedInlineTable : this . inlineTable ; public void setSubstitutedInlineTable ( final List < Map < String , String > > substitutedInlineTable ) { public int getSourceLineNumber ( ) {", "del_tokens": "public Step ( final String theLine , final boolean isSubStep , final File source , final int lineNumber ) { this . log . debug ( \"annot of step is null: \" + this . getClass ( ) . getSimpleName ( ) ) ; return this . substitutedInlineTable != null ? this . substitutedInlineTable : this . inlineTable ; public void setSubstitutedInlineTable ( final List < Map < String , String > > substitutedInlineTable ) { protected int getSourceLineNumber ( ) {", "commit_type": "update"}
{"commit_tokens": ["added", "codes", "for", "exception", "handling", "within", "HttpClient", ".", "java"], "add_tokens": "} else if ( typeName . equals ( \"?\" ) ) { } else { return Table . Type . UNDEFINED ; // TODO #MN private Type type ; public Table ( String name , Type type , String schema , long count ) { public Table ( Client client , String databaseName , String name , Type type , String schema , long count ) {", "del_tokens": "} else { private Table . Type type ; public Table ( String name , Table . Type type , String schema , long count ) { public Table ( Client client , String databaseName , String name , Table . Type type , String schema , long count ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "true", "and", "fail", "test", "cases", "."], "add_tokens": "import com . thesett . aima . logic . fol . TrueAndFailResolverUnitTestBase ; import com . thesett . aima . logic . fol . wam . compiler . WAMCompiler ; LogicCompiler < Clause , WAMCompiledPredicate , WAMCompiledQuery > compiler = new WAMCompiler ( symbolTable , machine ) ; // Add all tests defined in the TrueAndFailResolverUnitTestBase class. suite . addTest ( new TrueAndFailResolverUnitTestBase < Clause , WAMCompiledPredicate , WAMCompiledQuery > ( \"testTrueSucceeds\" , engine ) ) ; suite . addTest ( new TrueAndFailResolverUnitTestBase < Clause , WAMCompiledPredicate , WAMCompiledQuery > ( \"testFailFails\" , engine ) ) ; suite . addTest ( new TrueAndFailResolverUnitTestBase < Clause , WAMCompiledPredicate , WAMCompiledQuery > ( \"testDisjunctionOfTrueAndFailSucceeds\" , engine ) ) ; suite . addTest ( new TrueAndFailResolverUnitTestBase < Clause , WAMCompiledPredicate , WAMCompiledQuery > ( \"testConjunctionOfTrueAndFailFails\" , engine ) ) ; suite . addTest ( new TrueAndFailResolverUnitTestBase < Clause , WAMCompiledPredicate , WAMCompiledQuery > ( \"testConjunctionOfTruesSucceeds\" , engine ) ) ;", "del_tokens": "import com . thesett . aima . logic . fol . wam . compiler . WAMCompiler ; LogicCompiler < Clause , WAMCompiledPredicate , WAMCompiledQuery > compiler = new WAMCompiler ( symbolTable , machine ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "a", "flag", "to", "allow", "the", "processing", "of", "the", "directive", "multiple", "times", "allowing", "to", "add", "rulesets", "in", "the", "future", "(", "use", "case", ":", "a", "library", "provide", "a", "set", "up", "processor", "the", "final", "developper", "want", "to", "add", "other", "rules", ")", ".", "By", "default", "the", "parsing", "of", "directives", "occurs", "only", "once", "."], "add_tokens": "/ * * * Internal flag , < code > true < / code > when the parsing of directives occurred once , prevent the parsing of new directives unless # isAllowingOverride is < code > true < / code > . * / private boolean myAllowedOverrideRequired = false ; / * * * Manually set to < code > true < / code > to allow several parsing of the directive , thus allowing adding rulesets . * / private boolean myAllowingOverride = false ; public boolean isAllowingOverride ( ) { return myAllowingOverride ; } public void setAllowingOverride ( boolean allowingOverride ) { myAllowingOverride = allowingOverride ; } boolean _canProceed = ! isAllowedOverrideRequired ( ) || isAllowingOverride ( ) ; if ( _canProceed && ! _directives . isEmpty ( ) ) setAllowedOverrideRequired ( true ) ; private boolean isAllowedOverrideRequired ( ) { return myAllowedOverrideRequired ; } private void setAllowedOverrideRequired ( boolean allowedOverrideRequired ) { myAllowedOverrideRequired = allowedOverrideRequired ; }", "del_tokens": "if ( ! _directives . isEmpty ( ) ) throw new Exception ( \"not implemented yet !\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "auto", "-", "start", "to", "class", "finder"], "add_tokens": "* Find this class 's class access service in the current workspace. { // This bundle was never started, that's okay. Use this bundle context try { // Note: this does not start the service, but it does registers it as a service. // Wait a 30 seconds for the ClassService to come up while the activator starts this service thread . wait ( 30000 ) ;", "del_tokens": "* Find this class 's class access registered class access service in the current workspace. { // This bundle was never started, so start it! try { String dependentBaseBundleClassName = ClassFinderActivator . class . getName ( ) ; bundleContext . addServiceListener ( new BundleServiceDependentListener ( null , bundleContext ) , /*\"(&\" +*/ \"(objectClass=\" + dependentBaseBundleClassName + \")\" ) ; // This will call startupThisService once the service is up new BundleStarter ( null , bundleContext , dependentBaseBundleClassName ) . start ( ) ; } catch ( InvalidSyntaxException e ) { e . printStackTrace ( ) ; } try { // Note: this does not start the service, it only registers it as a service. // Wait a minute for the ClassService to come up while the activator starts this service thread . wait ( 60000 ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "corporate", "user", "departments"], "add_tokens": "private static final ClientCorporationAssociations clientCorporationAssociations = ClientCorporationAssociations . getInstance ( ) ; private static final CorporateUserAssociations corporateUserAssociations = CorporateUserAssociations . getInstance ( ) ; if ( type == CorporateUser . class ) { return ( EntityAssociations < T > ) corporateUserAssociations ; } / * * * Returns the associations for CorporateUser * * @ return * / public static CorporateUserAssociations corporateUserAssociations ( ) { return corporateUserAssociations ; }", "del_tokens": "private static final ClientCorporationAssociations clientCorporationAssociations = ClientCorporationAssociations . getInstance ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Integration", "Test", "for", "@QueueListener", "methods"], "add_tokens": "messageReceivedCount . await ( ) ;", "del_tokens": "messageReceivedCount . countDown ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "only", "output", "the", "unprocessed", "fields", "when", "some", "are", "found", ".", "Outputting", "the", "schema", "name", "as", "well", "."], "add_tokens": "if ( ! difference . isEmpty ( ) ) { log . trace ( \"parseJsonNode() - Unprocessed fields for {}:\\n{}\" , schema . name ( ) , Joiner . on ( '\\n' ) . join ( difference ) ) ; }", "del_tokens": "log . trace ( \"parseJsonNode() - Unprocessed fields:\\n{}\" , Joiner . on ( '\\n' ) . join ( difference ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Create", "UnicodeMatcher", "UnicodeRangeMatcher", ";", "extend", "MatcherVisitor"], "add_tokens": "extends UnicodeMatcher", "del_tokens": "import org . parboiled . matchers . AbstractMatcher ; extends AbstractMatcher public abstract boolean matchesSingleCharOnly ( ) ; public abstract boolean canStartWithChar ( final char c ) ;", "commit_type": "create"}
{"commit_tokens": ["Allow", "final", "fields", ";", "cleaned", "up", "some", "comments", "."], "add_tokens": "//TODO: see about batching deletes with remove({_id : {$in: [ids]}}) //loops over mappedClasses and call ensureIndex for each @Entity object (for now) return new QueryImpl < T > ( clazz , mongo . getDB ( dbName ) . getCollection ( kind ) , this ) ;", "del_tokens": "//TODO: see about batching deletes //TODO loop over mappedClasses and call ensureIndex for each one on non-embedded objects (for now) return new QueryImpl < T > ( clazz , mongo . getDB ( dbName ) . getCollection ( kind ) , this ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "a", "couple", "of", "bugs"], "add_tokens": "if ( fm != null ) { return ( FraggleFragment ) fm . findFragmentByTag ( tag ) ; } return new EmptyFragment ( ) ;", "del_tokens": "return ( FraggleFragment ) fm . findFragmentByTag ( tag ) ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "code", "from", "NanoWebSocketServer", "to", "WebSocketResponseHandler", "so", "that", "requests", "can", "be", "handled", "without", "the", "presence", "of", "NanoHTTPD"], "add_tokens": "handshakeResponse . addHeader ( WebSocketResponseHandler . HEADER_UPGRADE , WebSocketResponseHandler . HEADER_UPGRADE_VALUE ) ; handshakeResponse . addHeader ( WebSocketResponseHandler . HEADER_CONNECTION , WebSocketResponseHandler . HEADER_CONNECTION_VALUE ) ;", "del_tokens": "handshakeResponse . addHeader ( NanoWebSocketServer . HEADER_UPGRADE , NanoWebSocketServer . HEADER_UPGRADE_VALUE ) ; handshakeResponse . addHeader ( NanoWebSocketServer . HEADER_CONNECTION , NanoWebSocketServer . HEADER_CONNECTION_VALUE ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "ContractVerifierMessaging", "independent", "of", "the", "builder", "interface"], "add_tokens": "send ( builder . create ( payload , headers ) , destination ) ;", "del_tokens": "send ( create ( payload , headers ) , destination ) ; @ Override public < T > Message < ? > create ( T t , Map < String , Object > headers ) { return builder . create ( t , headers ) ; }", "commit_type": "make"}
{"commit_tokens": ["Fix", "edge", "cases", "in", "Duplicate", "class", "found", "..."], "add_tokens": "verify ( getClassStatement ( ) , ! name . equals ( strInnerClass ) && ! name . contains ( dotInner + \".\" ) && ! name . endsWith ( dotInner ) && ! name . startsWith ( strInnerClass + \".\" ) , Res . MSG_DUPLICATE_CLASS_FOUND , name + dotInner ) ;", "del_tokens": "verify ( getClassStatement ( ) , ! name . equals ( strInnerClass ) && ! name . endsWith ( dotInner ) , Res . MSG_DUPLICATE_CLASS_FOUND , name + dotInner ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "additional", "fields", ".", "Added", "update", "for", "managed", "user"], "add_tokens": "@ Size ( max = 255 ) @ Pattern ( regexp = \"[\\\\P{Cc}]+\" , message = \"The confirm password must not contain control characters\" ) @ JsonIgnore private transient String confirmPassword ; // not persisted @ Column ( name = \"FULLNAME\" ) @ Size ( max = 255 ) @ Pattern ( regexp = \"[\\\\P{Cc}]+\" , message = \"The full name must not contain control characters\" ) private String fullname ; @ Persistent @ Column ( name = \"EMAIL\" ) @ Size ( max = 255 ) public String getConfirmPassword ( ) { return confirmPassword ; } public void setConfirmPassword ( String confirmPassword ) { this . confirmPassword = confirmPassword ; } public String getFullname ( ) { return fullname ; } public void setFullname ( String fullname ) { this . fullname = fullname ; }", "del_tokens": "@ Column ( name = \"EMAIL\" , allowsNull = \"false\" ) @ NotNull @ Size ( min = 1 , max = 255 )", "commit_type": "add"}
{"commit_tokens": ["use", "additional", "config", "file", "called", "client", ".", "yaml", "-", "this", "is", "mainly", "for", "reading", "config", "specific", "to", "cli"], "add_tokens": "public static String clientFile ( ) { return ConfigDefaults . get ( \"CLIENT_YAML\" ) ; }", "del_tokens": "public static String systemConfigFile ( ) { return ConfigDefaults . get ( \"SYSTEM_YAML\" ) ; }", "commit_type": "use"}
{"commit_tokens": ["Change", "docs", "to", "give", "the", "proper", "class", "name", "for", "VoldemortJsvcDaemon"], "add_tokens": "* jsvc - pidfile . / voldemort . pid voldemort . server . VoldemortJsvcDaemon * voldemort . server . VoldemortJsvcDaemon / etc / voldemort", "del_tokens": "* jsvc - pidfile . / voldemort . pid voldemort . server . VoldemortDaemon * voldemort . server . VoldemortDaemon / etc / voldemort", "commit_type": "change"}
{"commit_tokens": ["Change", "implementation", "to", "avoid", "calculating", "dependencies", "twice", "when", "checking", "policies"], "add_tokens": "whitesourceAgent . sendRequest ( ) ;", "del_tokens": "import org . whitesource . agent . api . dispatch . RequestType ; boolean checkPolcies = false ; String checkPoliciesValue = configProps . getProperty ( CHECK_POLICIES_PROPERTY_KEY ) ; if ( StringUtils . isNotBlank ( checkPoliciesValue ) ) { checkPolcies = Boolean . valueOf ( checkPoliciesValue ) ; } if ( checkPolcies ) { boolean success = whitesourceAgent . sendRequest ( RequestType . CHECK_POLICIES ) ; if ( success ) { whitesourceAgent . sendRequest ( RequestType . UPDATE ) ; } } else { whitesourceAgent . sendRequest ( RequestType . UPDATE ) ; }", "commit_type": "change"}
{"commit_tokens": ["Updated", "test", "cases", "improved", "documentation", "on", "exception", "classes"], "add_tokens": "* This { @ link RuntimeException } is raised when the the template process * encounters an issue parsing the URI template expression . It indicates * the expression is malformed .", "del_tokens": "*", "commit_type": "update"}
{"commit_tokens": ["Add", "config", "initial", "config", "path", ".", "and", "add", "test", "utiligy"], "add_tokens": "import acromusashi . stream . util . ResourceResolver ; Config actual = StormConfigGenerator . loadStormConfig ( ResourceResolver . resolve ( \"StormConfigGeneratorTest_testLoadStormConfig_ReadSuccess.yaml\" ) ) ; StormConfigGenerator . loadStormConfig ( \"StormConfigGeneratorTest_testLoadStormConfig_NotFound.yaml\" ) ;", "del_tokens": "import org . apache . commons . lang . StringUtils ; /** 試験用データファイル配置ディレクトリ*/ private static final String DATA_DIR = \"src/test/resources/\" + StringUtils . replaceChars ( StormConfigGeneratorTest . class . getPackage ( ) . getName ( ) , '.' , '/' ) + '/' ; Config actual = StormConfigGenerator . loadStormConfig ( DATA_DIR + \"StormConfigGeneratorTest_testLoadStormConfig_ReadSuccess.yaml\" ) ; StormConfigGenerator . loadStormConfig ( DATA_DIR + \"StormConfigGeneratorTest_testLoadStormConfig_NotFound.yaml\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "parameters", "error", "form", "currency", "withdrawal"], "add_tokens": "parameters . put ( \"destination_tag\" , extraParameters . get ( \"tag\" ) ) ;", "del_tokens": "parameters . put ( \"destination_tag\" , parameters . get ( \"tag\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "documentation", ".", "Added", "Filter", "to", "MavenLogHandler", "to", "ensure", "that", "only", "relevant", "log", "records", "are", "emitted", "onto", "the", "Maven", "Log", "."], "add_tokens": "import java . util . Arrays ; rootLogger . addHandler ( new MavenLogHandler ( getLog ( ) , \"XJC\" , getEncoding ( false ) , new String [ ] { \"com.sun\" , \"javax.xml\" } ) ) ;", "del_tokens": "rootLogger . addHandler ( new MavenLogHandler ( getLog ( ) , \"XJC\" , getEncoding ( false ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "few", "methods", "from", "the", "CSP", "Client", "and", "Builder", "."], "add_tokens": "public static String addXMLBoilerplate ( final String xml , final String entityFileName , final String rootElementName ) \"<!DOCTYPE \" + ( rootElementName == null ? \"chapter\" : rootElementName ) + \" PUBLIC \\\"-//OASIS//DTD DocBook XML V4.5//EN\\\" \\\"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd\\\" [\\n\" + \"<!ENTITY % BOOK_ENTITIES SYSTEM \\\"\" + entityFileName + \"\\\">\\n\" + public static String addXMLBoilerplate ( final String xml ) { return addXMLBoilerplate ( xml , \"Book.ent\" , \"chapter\" ) ; }", "del_tokens": "public static String addXMLBoilerplate ( final String xml ) \"<!DOCTYPE chapter PUBLIC \\\"-//OASIS//DTD DocBook XML V4.5//EN\\\" \\\"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd\\\" [\\n\" + \"<!ENTITY % BOOK_ENTITIES SYSTEM \\\"Book.ent\\\">\\n\" +", "commit_type": "add"}
{"commit_tokens": ["Removed", "InputFile#getFileHash", "()", "and", "changed", "InputFile#getId", "()", "to", "return", "a", "String", "rather", "than", "an", "int", "."], "add_tokens": "String getId ( ) ;", "del_tokens": "int getId ( ) ; byte [ ] getFileHash ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "problem", "with", "unit", "test"], "add_tokens": "import iot . jcypher . query . result . JcError ; import iot . jcypher . query . result . JcResultException ; import java . util . List ; List < JcError > errors = dbAccess . clearDatabase ( ) ; if ( errors . size ( ) > 0 ) { printErrors ( errors ) ; throw new JcResultException ( errors ) ; } assertQuery ( testId , resultString , tdr . getTestData ( testId ) ) ;", "del_tokens": "// assertQuery(testId, resultString, tdr.getTestData(testId));", "commit_type": "fix"}
{"commit_tokens": ["Fix", "selection", "between", "Adapter", "or", "Bw"], "add_tokens": "if ( parent . getClass ( ) . equals ( Bw . class ) ) { } else if ( parent . getClass ( ) . equals ( Adapter . class ) ) {", "del_tokens": "if ( \"bw\" . equals ( ( ( ServiceType ) parent ) . getName ( ) ) ) { } else if ( \"adapter\" . equals ( ( ( ServiceType ) parent ) . getName ( ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Adds", "addValidation", "method", "in", "TrackingByNegativeColorFilter"], "add_tokens": "import br . com . etyllica . motion . core . strategy . ComponentValidationStrategy ; public void addValidation ( ComponentValidationStrategy validation ) { searchStrategy . addComponentStrategy ( validation ) ; }", "del_tokens": "import br . com . etyllica . motion . filter . validation . CountComponentPoints ; searchStrategy . addComponentStrategy ( new CountComponentPoints ( 40 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "failing", "test", "+", "minor", "clean", "up", "."], "add_tokens": "// TODO: Implement ImageIO meta data interface // Compute pixel (not array) offsets based on raster (banded/interleaved)? throw new IIOException ( \"Unknown PSD bit depth: \" + mHeader . mBits ) ; if ( mImageResources == null ) { } for ( PSDImageResource resource : mImageResources ) { if ( resource instanceof PSDThumbnail ) { if ( thumbnails == null ) { thumbnails = new ArrayList < PSDThumbnail > ( ) ; thumbnails . add ( ( PSDThumbnail ) resource ) ;", "del_tokens": "// TODO: Implement meta data reading throw new IIOException ( \"Unknown bit depth: \" + mHeader . mBits ) ; // int offset = (y - pSource.y) / pYSub * pDest.width * channels + (channels - 1 - c); if ( mImageResources != null ) { for ( PSDImageResource resource : mImageResources ) { if ( resource instanceof PSDThumbnail ) { if ( thumbnails == null ) { thumbnails = new ArrayList < PSDThumbnail > ( ) ; } thumbnails . add ( ( PSDThumbnail ) resource ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "possibility", "to", "pass", "custom", "variable", "names", "at", "runtime", "as", "an", "alternative", "to", "having", "them", "hard", "coded", "in", "the", "corresponding", "COBOL", "type", "."], "add_tokens": "// ----------------------------------------------------------------------------- // Constructors // ----------------------------------------------------------------------------- this ( cobolContext , hostData , start , customChoiceStrategy , null ) ; } public Cob2ObjectConverter ( CobolContext cobolContext , byte [ ] hostData , int start , FromCobolChoiceStrategy customChoiceStrategy , List < String > customVariables ) { super ( cobolContext , hostData , start , customChoiceStrategy , customVariables ) ; // ----------------------------------------------------------------------------- // Visit methods // ----------------------------------------------------------------------------- // ----------------------------------------------------------------------------- // Handlers // ----------------------------------------------------------------------------- // ----------------------------------------------------------------------------- // Getters // -----------------------------------------------------------------------------", "del_tokens": "super ( cobolContext , hostData , start , customChoiceStrategy ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "UTF", "-", "8", "for", "encoding"], "add_tokens": "import java . nio . charset . Charset ; content . append ( EntityUtils . toString ( entity , Charset . forName ( ENCODING_UTF8 ) ) ) ;", "del_tokens": "content . append ( EntityUtils . toString ( entity ) ) ;", "commit_type": "use"}
{"commit_tokens": ["updated", "demo", "app", "to", "use", "the", "original", "file", "name", "on", "both", "multipart", "and", "binary"], "add_tokens": "import java . io . File ; . addFileToUpload ( fileToUploadPath , paramNameString ) . addHeader ( \"file-name\" , new File ( fileToUploadPath ) . getName ( ) )", "del_tokens": "import com . alexbbb . uploadservice . ContentType ; . addFileToUpload ( fileToUploadPath , paramNameString , \"test\" , ContentType . APPLICATION_OCTET_STREAM ) final String paramNameString = parameterName . getText ( ) . toString ( ) ; . addHeader ( \"file-name\" , paramNameString )", "commit_type": "update"}
{"commit_tokens": ["Improve", "the", "Java", "CloudI", "API", "function", "info_key_value_new", "types", "."], "add_tokens": "import java . util . List ; private byte [ ] text_pairs_new ( Map < String , List < String > > info ) for ( Map . Entry < String , List < String > > pair : info . entrySet ( ) ) public byte [ ] info_key_value_new ( Map < String , List < String > > info )", "del_tokens": "private byte [ ] text_pairs_new ( HashMap < String , ArrayList < String > > info ) for ( Map . Entry < String , ArrayList < String > > pair : info . entrySet ( ) ) public byte [ ] info_key_value_new ( HashMap < String , ArrayList < String > > info )", "commit_type": "improve"}
{"commit_tokens": ["Updated", "code", "to", "handle", "fileref", "loop", "in", "Java", "."], "add_tokens": "//getLog().info(\"HREF IS = \" + getOption(_href, \"something\")); //getLog().info(\"############################################################################################################\"); //getLog().info(\"############################################# MAKE PDF: \" + makePdf + \"####################################################\"); //getLog().error(\"DocBook File: '\" +inputFileName+ \"' - File: '\" +uri.getPath()+ \"' - Problem: File already processed.\"); //throw new XProcException(step.getNode(), \"File already processed: \" + file.getAbsolutePath());", "del_tokens": "// getLog().info(\"HREF IS = \" + getOption(_href, \"something\")); // getLog().info(\"############################################################################################################\"); // getLog().info(\"############################################# MAKE PDF: \" + makePdf + \"####################################################\"); // getLog().error(\"DocBook File: '\" +inputFileName+ \"' - File: '\" +uri.getPath()+ \"' - Problem: File already processed.\"); // throw new XProcException(step.getNode(), \"File already processed: \" + file.getAbsolutePath());", "commit_type": "update"}
{"commit_tokens": ["Fix", "bug", "in", "simplefs", "concerning", "simultaneous", "downloads", "."], "add_tokens": "if ( register . isModified ( fileName ) ) { register . onStartDownload ( fileName ) ; register . onEndDownload ( fileName ) ; register . onEndDownload ( fileName ) ;", "del_tokens": "if ( register . isRegistered ( fileName ) ) { register . remove ( fileName ) ; register . remove ( fileName ) ;", "commit_type": "fix"}
{"commit_tokens": ["making", "changes", "to", "flush", "trying", "to", "fix", "undertow", "problem"], "add_tokens": "private static final String ASSERTING_TEXT = \"asserting that the time lapse with hold [%s] is >= than regular request [%s]\" ; assertTrue ( String . format ( ASSERTING_TEXT , timeLapseRequestWithHold , regularRequestWithHoldTime ) , timeLapseRequestWithHold >= regularRequestWithHoldTime ) ;", "del_tokens": "private static final String ASSERTING_TEXT = \"asserting that the time lapse with hold is >= than regular request\" ; assertTrue ( ASSERTING_TEXT , timeLapseRequestWithHold >= regularRequestWithHoldTime ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "better", "HTTP", "connection", "timeouts", "handling"], "add_tokens": "private static final int CONNECTION_READ_TIMEOUT = 60000 ; try { conn = uploadTestRun ( testRun ) ; catch ( SocketTimeoutException ste ) { LOGGER . log ( Level . SEVERE , \"Unable to send the results to the server due to a timeout exception\" , ste ) ; throw ste ; } try { if ( conn . getResponseCode ( ) == 202 ) { LOGGER . info ( \"The test run was successfully sent to Probe Dock.\" ) ; return true ; } else { LOGGER . severe ( \"Unable to send the test run to Probe Dock. Return code: \" + conn . getResponseCode ( ) + \", content: \" + readInputStream ( conn . getInputStream ( ) ) ) ; } } catch ( SocketTimeoutException ste ) { LOGGER . log ( Level . SEVERE , \"Unable to read the response from the server du to a timeout exception\" , ste ) ; throw ste ; } } catch ( IOException ioe ) { conn . setReadTimeout ( CONNECTION_READ_TIMEOUT ) ;", "del_tokens": "conn = uploadTestRun ( testRun ) ; if ( conn . getResponseCode ( ) == 202 ) { LOGGER . info ( \"The test run was successfully sent to Probe Dock.\" ) ; return true ; } else { LOGGER . severe ( \"Unable to send the test run to Probe Dock. Return code: \" + conn . getResponseCode ( ) + \", content: \" + readInputStream ( conn . getInputStream ( ) ) ) ; } catch ( IOException ioe ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "second", "metric", "to", "track", "cas", "exhaustion"], "add_tokens": "import com . yammer . metrics . core . Counter ; import java . util . Arrays ; import java . util . List ; import java . util . Map ; import java . util . Set ; private final Counter casRetriesExhausted ; casRetriesExhausted = Metrics . newCounter ( HBaseDbHarness . class , \"casRetriesExhausted\" , metricsScope ) ; casRetriesExhausted . inc ( ) ;", "del_tokens": "import java . util . * ;", "commit_type": "add"}
{"commit_tokens": ["Add", "better", "logging", "for", "when", "code", "snippets", "don", "t", "compile", "."], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static Logger logger = LoggerFactory . getLogger ( TemplateHelper . class ) ; CtField field ; try { field = CtField . make ( code , thisClass ) ; } catch ( CannotCompileException e ) { logger . error ( \"Unable to compile this code:\\n\" + code ) ; throw e ; } CtConstructor constructor ; try { constructor = CtNewConstructor . make ( code , thisClass ) ; } catch ( CannotCompileException e ) { logger . error ( \"Unable to compile this code:\\n\" + code ) ; throw e ; } CtMethod m ; try { m = CtNewMethod . make ( code , thisClass ) ; } catch ( CannotCompileException e ) { logger . error ( \"Unable to compile this code:\\n\" + code ) ; throw e ; }", "del_tokens": "CtField field = CtField . make ( code , thisClass ) ; CtConstructor constructor = CtNewConstructor . make ( code , thisClass ) ; CtMethod m = CtNewMethod . make ( code , thisClass ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "use", "of", "status", "constants"], "add_tokens": "import static org . apache . http . HttpStatus . SC_NOT_FOUND ; import static org . apache . http . HttpStatus . SC_UNAUTHORIZED ; case SC_UNAUTHORIZED : case SC_NOT_FOUND :", "del_tokens": "import org . apache . http . HttpStatus ; case HttpStatus . SC_UNAUTHORIZED : case HttpStatus . SC_NOT_FOUND :", "commit_type": "make"}
{"commit_tokens": ["added", "support", "for", "faceted", "NRQL", "queries"], "add_tokens": "private List < Map < String , Object > > facets ; private Map < String , Object > totalResult ; / * * * Returns the list of facets . * @ return The list of facets * / public List < Map < String , Object > > getFacets ( ) { return facets ; } public Map < String , Object > getTotalResult ( ) { return totalResult ; } + \", facets=\" + facets + \", totalResult=\" + totalResult + \", performanceStats=\" + performanceStats", "del_tokens": "+ \", performanceStats=\" + performanceStats", "commit_type": "add"}
{"commit_tokens": ["fix", "counter", "initalization", "when", "no", "server"], "add_tokens": "if ( ! hasServer ( ) ) this . setCounter ( INITIAL_REF_ID ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["make", "service", "indicator", "available", "."], "add_tokens": "public final static int _SI_SERVICE_SCCP = 3 ; public final static int _SI_SERVICE_ISUP = 5 ; case _SI_SERVICE_SCCP : case _SI_SERVICE_ISUP :", "del_tokens": "private final static int SERVICE_SCCP = 3 ; private final static int SERVICE_ISUP = 5 ; case SERVICE_SCCP : case SERVICE_ISUP :", "commit_type": "make"}
{"commit_tokens": ["Add", "getSelectedItem", "()", "method", "to", "Spinner", "class", "."], "add_tokens": "public void onPositionChanged ( Slider view , boolean fromUser , float oldPos , float newPos , int oldValue , int newValue ) { public void onPositionChanged ( Slider view , boolean fromUser , float oldPos , float newPos , int oldValue , int newValue ) {", "del_tokens": "import android . transition . Slide ; import android . widget . CompoundButton ; import com . rey . material . widget . RadioButton ; public void onPositionChanged ( Slider view , float oldPos , float newPos , int oldValue , int newValue ) { public void onPositionChanged ( Slider view , float oldPos , float newPos , int oldValue , int newValue ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "MetadataList", "Endpoint", "and", "DistributionPoints", "."], "add_tokens": "protected EndpointImpl ( String namespaceURI , String elementLocalName , String namespacePrefix ) {", "del_tokens": "public EndpointImpl ( String namespaceURI , String elementLocalName , String namespacePrefix ) {", "commit_type": "add"}
{"commit_tokens": ["added", "BOOL", "and", "VARIANT_BOOL", "support", "."], "add_tokens": "* Gets the interface GUID associated with the given interface . / * * * Loads a type library from a given file and returns its IUnknown . * / / * * * GUID of IUnknown . * / public static final GUID IID_IUnknown = new GUID ( \"{00000000-0000-0000-C000-000000000046}\" ) ;", "del_tokens": "* Gets the interface VTID associated with the given interface .", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "NAACCR", "15", "."], "add_tokens": "userDictionary = NaaccrDictionaryUtils . getDefaultUserDictionaryByVersion ( baseDictionary . getNaaccrVersion ( ) ) ; if ( item . getRecordTypes ( ) == null || Arrays . asList ( item . getRecordTypes ( ) . split ( \",\" ) ) . contains ( recordType ) ) if ( item . getRecordTypes ( ) == null || Arrays . asList ( item . getRecordTypes ( ) . split ( \",\" ) ) . contains ( recordType ) )", "del_tokens": "userDictionary = NaaccrDictionaryUtils . getDefaultUserDictionary ( baseDictionary . getNaaccrVersion ( ) ) ; if ( Arrays . asList ( item . getRecordTypes ( ) . split ( \",\" ) ) . contains ( recordType ) ) if ( Arrays . asList ( item . getRecordTypes ( ) . split ( \",\" ) ) . contains ( recordType ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "encoding", "the", "colorprofile", "of", "images", "."], "add_tokens": "import java . awt . color . ColorSpace ; if ( ( ( ICC_ColorSpace ) bi . getColorModel ( ) . getColorSpace ( ) ) . getProfile ( ) != ICC_Profile . getInstance ( ColorSpace . CS_sRGB ) ) { pdProfile . getPDStream ( ) . getCOSObject ( ) . setInt ( COSName . N , profile . getNumComponents ( ) ) ;", "del_tokens": "if ( bi . getColorModel ( ) . getColorSpace ( ) != ICC_ColorSpace . getInstance ( ICC_ColorSpace . CS_sRGB ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Adding", "the", "ability", "to", "just", "auto", "-", "convert", "to", "a", "newer", "algorithm", ".", "This", "may", "produce", "different", "passwords", "though", "than", "their", "buggy", "javascript", "versions", ".", "See", "https", ":", "//", "github", ".", "com", "/", "tasermonkey", "/", "android", "-", "passwordmaker", "/", "issues", "/", "5", "for", "more", "details", "."], "add_tokens": "* @ throws IncompatibleException upon invalid algorithm string . public static AlgorithmType fromRdfString ( String str , boolean convert ) throws IncompatibleException { // TODO: full support for all invalid types should be present as well as allowing the account to exist and be modified. if ( convert ) { if ( str . compareTo ( \"hmac-sha256\" ) == 0 ) return AlgorithmType . SHA256 ; if ( str . compareTo ( \"md5-v0.6\" ) == 0 || str . compareTo ( \"hmac-md5-v0.6\" ) == 0 ) return AlgorithmType . MD5 ; } throw new IncompatibleException ( \"Original hmac-sha256-v1.5.1 implementation has been detected, \" + \"this is not compatible with PasswordMakerJE due to a bug in the original \" + \"this is not compatible with PasswordMakerJE due to a bug in the original \" + \"this is not compatible with PasswordMakerJE due to a bug in the original \" + throw new IncompatibleException ( String . format ( \"Invalid algorithm type '%1s'\" , str ) ) ;", "del_tokens": "* @ throws Exception upon invalid algorithm string . public static AlgorithmType fromRdfString ( String str ) throws Exception { // TODO: full support for all invalid types should be present as well as allowing the account to exist and be modified. throw new IncompatibleException ( \"Original hmac-sha1 implementation has been detected, \" + \"this is not compatibile with PasswordMakerJE due to a bug in the original \" + \"this is not compatibile with PasswordMakerJE due to a bug in the original \" + \"this is not compatibile with PasswordMakerJE due to a bug in the original \" + throw new Exception ( String . format ( \"Invalid algorithm type '%1s'\" , str ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "batch", "updates"], "add_tokens": "return true ;", "del_tokens": "System . err . println ( \" ********************* not implemented @ \" + DebugPrinter . getFileName ( ) + \" line \" + DebugPrinter . getLineNumber ( ) ) ; return false ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "broken", "screenshot", "in", "the", "reporting", "and", "added", "an", "explenation", "on", "how", "logging", "works", "in", "senbot"], "add_tokens": "TestPage1 viewRepresentation = seleniumManager . getViewRepresentation ( TestPage1 . class ) ;", "del_tokens": "TestPage1 viewRepresentation = seleniumManager . getViewRepresentation ( TestPage1 . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "all", "geo", "conversion", "in", "an", "unique", "entry", "point", "to", "avoid", "code", "redundancies"], "add_tokens": "import org . apache . commons . beanutils . Converter ; import com . terradue . jcatalogue . client . geo . Box ; import com . terradue . jcatalogue . client . geo . Line ; import com . terradue . jcatalogue . client . geo . Polygon ; import com . terradue . jcatalogue . client . internal . converters . GeoConverter ; Converter geoConverter = new GeoConverter ( ) ; register ( geoConverter , Box . class ) ; register ( geoConverter , Line . class ) ; register ( geoConverter , Point . class ) ; register ( geoConverter , Polygon . class ) ;", "del_tokens": "import com . terradue . jcatalogue . client . internal . converters . PointConverter ; register ( new PointConverter ( ) , Point . class ) ;", "commit_type": "move"}
{"commit_tokens": ["Improve", "mappings", "adomain", "multisize", "Video"], "add_tokens": "if ( request . getImpCount ( ) == 0 ) {", "del_tokens": "if ( size == TestData . NO_SLOT || ( size > 1 && impVideo ) ) { assertEquals ( 0 , request . getImpCount ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "multi", "-", "module", "report", "aggregation", "when", "the", "sub", "-", "modules", "are", "not", "ordered"], "add_tokens": "* @ phase package", "del_tokens": "* @ phase install", "commit_type": "fix"}
{"commit_tokens": ["fix", "typo", "in", "the", "log"], "add_tokens": "LOGGER . info ( \"Starting Stream against partitions {} with no end.\" , Arrays . toString ( vbids ) ) ;", "del_tokens": "LOGGER . info ( \"Starting Stream against partitions {} with no end.\" , partitions ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "ClassCast", "exception", "when", "MentionsEditText", "is", "used", "directly"], "add_tokens": "if ( ! ( widget instanceof MentionsEditText ) ) { return ; } // Get reference to the MentionsEditText MentionsEditText editText = ( MentionsEditText ) widget ; if ( text == null ) { editText . deselectAllSpans ( ) ; editText . updateSpan ( this ) ;", "del_tokens": "import com . linkedin . android . spyglass . ui . RichEditorView ; // Get reference to the RichEditor EditText editText = ( EditText ) widget ; RichEditorView richEditor = ( RichEditorView ) widget . getParent ( ) ; if ( richEditor == null || text == null ) { richEditor . deselectAllSpans ( ) ; richEditor . updateSpan ( this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "logging", "information", "when", "loading", "previously", "processed", "traces", "."], "add_tokens": "System . err . printf ( \"Loaded cas for %s @ %s\\n\" , sequenceId , trace . getTrace ( ) ) ;", "del_tokens": "System . err . printf ( \"Loaded cas for %s @ %s\" , sequenceId , trace . getTrace ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", ".", "class", "on", "array", "types"], "add_tokens": "/ * throw new EvalError ( \"Attemp to .class on non class...\" , this ) ; * / if ( operation == CLASS ) if ( obj instanceof BSHType ) { NameSpace namespace = callstack . top ( ) ; return ( ( BSHType ) obj ) . getType ( namespace ) ; } else throw new EvalError ( \"Attemp to invoke .class on non class.\" , this ) ;", "del_tokens": "throw new EvalError ( \"Trying to call .class on something inappropriate...\" , this ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "broken", "/", "useless", "latency", "tracking", "for", "put", "RPCs", "."], "add_tokens": "// TODO(tsuna): The following timing is rather useless. First of all, // the histogram never resets, so it tends to converge to a certain // distribution and never changes. What we really want is a moving // histogram so we can see how the latency distribution varies over time. // The other problem is that the Histogram class isn't thread-safe and // here we access it from a callback that runs in an unknown thread, so // we might miss some increments. So let's comment this out until we // have a proper thread-safe moving histogram. //final long start_put = System.nanoTime(); //final Callback<Object, Object> cb = new Callback<Object, Object>() { // public Object call(final Object arg) { // putlatency.add((int) ((System.nanoTime() - start_put) / 1000000)); // return arg; // } // public String toString() { // return \"time put request\"; // } //}; return tsdb . client . put ( point ) /*.addBoth(cb)*/ ;", "del_tokens": "final long start_put = System . nanoTime ( ) ; final Callback < Object , Object > cb = new Callback < Object , Object > ( ) { public Object call ( final Object arg ) { putlatency . add ( ( int ) ( ( System . nanoTime ( ) - start_put ) / 1000000 ) ) ; return arg ; } public String toString ( ) { return \"time put request\" ; } } ; return tsdb . client . put ( point ) . addBoth ( cb ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "volatile", "flag", "to", "ZRTP", "state"], "add_tokens": "private volatile int state = ZRTP_STATE_INACTIVE ;", "del_tokens": "private int state = ZRTP_STATE_INACTIVE ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "work", "for", "OSX", "correctly"], "add_tokens": "else if ( isLinux ( ) ) else if ( isMac ( ) ) { String output = null ; try { //Nix, use /proc/cpuinfo Process pr = Runtime . getRuntime ( ) . exec ( \"sysctl -a hw\" ) ; BufferedReader br = new BufferedReader ( new InputStreamReader ( pr . getInputStream ( ) ) ) ; String line = null ; // StringBuilder sb = new StringBuilder(); while ( ( line = br . readLine ( ) ) != null ) { if ( line . contains ( \"l1icachesize\" ) && output == null ) //We just need one line that says \"cache size\" output = line ; } } catch ( IOException ex ) { Logger . getLogger ( SystemInfo . class . getName ( ) ) . log ( Level . SEVERE , null , ex ) ; } String [ ] vals = output . split ( \"\\\\s+\" ) ; L2CacheSize = Integer . parseInt ( vals [ 1 ] ) ; }", "del_tokens": "else if ( isMac ( ) || isLinux ( ) )", "commit_type": "update"}
{"commit_tokens": ["Added", "calculation", "of", "open", "/", "closed", "minutes"], "add_tokens": "/ * * * Returns the number of minutes the instance is 'open' . * * @ return Minutes ( 1 - 1440 ) * / public final int getOpenMinutes ( ) { return to . toMinutes ( ) - from . toMinutes ( ) ; } / * * * Returns the number of minutes the instance is 'closed' . * * @ return Minutes ( 0 - 1439 ) * / public final int getClosedMinutes ( ) { return 1440 - getOpenMinutes ( ) ; } final int thisClosedMinutes = getClosedMinutes ( ) ; final int otherOpenMinutes = other . getOpenMinutes ( ) ; if ( otherOpenMinutes > thisClosedMinutes ) {", "del_tokens": "final int restMinutes = 1440 - ( this . to . toMinutes ( ) - this . from . toMinutes ( ) ) ; final int otherMinutes = other . to . toMinutes ( ) - other . from . toMinutes ( ) ; if ( otherMinutes > restMinutes ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "OpenLDAP", "password", "policy", "overlay"], "add_tokens": "import java . util . Properties ; final ChaiConfiguration chaiConfig = new ChaiConfiguration ( ) ; Properties settings = ChaiConfiguration . getDefaultSettings ( ) ; settings . putAll ( System . getProperties ( ) ) ; chaiConfig . setSettings ( settings ) ; chaiConfig . setSetting ( ChaiSetting . BIND_URLS , ldapURL ) ; chaiConfig . setSetting ( ChaiSetting . BIND_DN , bindDN ) ; chaiConfig . setSetting ( ChaiSetting . BIND_PASSWORD , password ) ; final boolean enableFailover = \"true\" . equalsIgnoreCase ( chaiConfiguration . getSetting ( ChaiSetting . FAILOVER_ENABLE ) ) ; LOGGER . debug ( \"unable to create connection: \" + e . getClass ( ) . getName ( ) + \":\" + e . getMessage ( ) , e ) ;", "del_tokens": "final ChaiConfiguration chaiConfig = new ChaiConfiguration ( ldapURL , bindDN , password ) ; final boolean enableFailover = chaiConfiguration . getSetting ( ChaiSetting . FAILOVER_ENABLE ) . equalsIgnoreCase ( \"true\" ) ; LOGGER . debug ( \"unable to create connection: \" + e . getClass ( ) . getName ( ) + \":\" + e . getMessage ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "polling", "impl", "of", "waitUntilEmpty", "()"], "add_tokens": "// $Id: Queue.java,v 1.4 2003/09/22 22:25:30 belaban Exp $ long time_to_wait = timeout ; if ( timeout == 0 ) { while ( size > 0 && closed == false ) { try { add_mutex . wait ( 1 ) ; } catch ( InterruptedException e ) { ; } } } else { long start_time = System . currentTimeMillis ( ) ; while ( time_to_wait > 0 && size > 0 && closed == false ) { try { add_mutex . wait ( time_to_wait ) ; } catch ( InterruptedException ex ) { } time_to_wait -= ( System . currentTimeMillis ( ) - start_time ) ; if ( size > 0 ) throw new TimeoutException ( \"queue has \" + size + \" elements\" ) ; if ( closed ) throw new QueueClosedException ( ) ;", "del_tokens": "// $Id: Queue.java,v 1.3 2003/09/20 01:32:45 belaban Exp $ //System.out.println(\"SIZE: \" + size); while ( size > 0 ) { try { add_mutex . wait ( 1 ) ; catch ( InterruptedException e ) { } // synchronized(remove_mutex) { // if(closed) // throw new QueueClosedException(); // if(size == 0) // return; // try { // remove_mutex.wait(timeout); // } // catch(InterruptedException e) { // } // if(closed) // throw new QueueClosedException(); // if(size > 0) // throw new TimeoutException(\"queue has \" + size + \" elements\"); // } //", "commit_type": "add"}
{"commit_tokens": ["Allow", "mocking", "of", "package", "private", "classes"], "add_tokens": ". onlyMethods ( getMethodsToProxy ( settings ) ) . withSharedClassLoader ( ) . buildProxyClass ( ) ;", "del_tokens": "// Allow to mock package private classes System . setProperty ( \"dexmaker.share_classloader\" , \"true\" ) ; . onlyMethods ( getMethodsToProxy ( settings ) ) . buildProxyClass ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "skip", "feature", "to", "start", "run", "and", "load", "data", "goals", "defaults", "to", "false"], "add_tokens": "if ( getNode ( ) != null ) { getNode ( ) . stop ( ) ; }", "del_tokens": "getNode ( ) . stop ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "windows", "32", "bit", "binary", "name", "Thanks", "to", "WavyPeng"], "add_tokens": "LOG . debug ( \"Os name is <\" + os + \"> isWindows: \" + isWindows + \" isMac: \" + isMac ) ; LOG . debug ( \"Creating jave temp folder to place executables in <\" + dirFolder . getAbsolutePath ( ) + \">\" ) ; else { LOG . debug ( \"Jave temp folder exists in <\" + dirFolder . getAbsolutePath ( ) + \">\" ) ; } LOG . debug ( \"Executable exists in <\" + ffmpegFile . getAbsolutePath ( ) + \">\" ) ; LOG . debug ( \"Need to copy executable to <\" + ffmpegFile . getAbsolutePath ( ) + \">\" ) ; LOG . debug ( \"Copy from resource <\" + resourceName + \"> to target <\" + dest . getAbsolutePath ( ) + \">\" ) ; if ( copy ( getClass ( ) . getResourceAsStream ( resourceName ) , dest . getAbsolutePath ( ) ) ) { if ( dest . exists ( ) ) { LOG . debug ( \"Target <\" + dest . getAbsolutePath ( ) + \"> exists\" ) ; } else { LOG . fatal ( \"Target <\" + dest . getAbsolutePath ( ) + \"> does not exist\" ) ; } } else { LOG . fatal ( \"Copy resource to target <\" + dest . getAbsolutePath ( ) + \"> failed\" ) ; } LOG . fatal ( \"Cannot write file \" + destination , ex ) ;", "del_tokens": "copy ( getClass ( ) . getResourceAsStream ( resourceName ) , dest . getAbsolutePath ( ) ) ; LOG . warn ( \"Cannot write file \" + destination , ex ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "assertThat", "helpers", "for", "activity"], "add_tokens": "assertThatSelection ( \"TextView#hello_world\" , activity ) . hasSize ( 1 ) ;", "del_tokens": "assertThatSelection ( \"TextView#hello_world\" , activity . findViewById ( android . R . id . content ) ) . hasSize ( 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "JavaGeneratingProcessor", ".", "Starts", "refactoring", "builder", "template", "rendering", "."], "add_tokens": "JavaType fluent = typeGenericOf ( SHALLOW_FLUENT . apply ( item ) , builder ) ; . withClassName ( item . getClassName ( ) + \"Builder\" ) . withGenericTypes ( new JavaType [ ] { } ) . withInterfaces ( new HashSet ( Arrays . asList ( typeGenericOf ( BUILDER_INTERFACE , item ) ) ) ) ARRAY_AS_LIST { public JavaType apply ( JavaType item ) { return LIST_OF . apply ( UNWRAP_ARRAY_OF . apply ( item ) ) ; } } ,", "del_tokens": "JavaType generic = typeExtends ( T , builder ) ; JavaType fluent = SHALLOW_FLUENT . apply ( item ) ; . withClassName ( item . getClassName ( ) + \"Fluent\" ) . withGenericTypes ( new JavaType [ ] { generic } ) . withInterfaces ( new HashSet ( Arrays . asList ( BUILDER_INTERFACE ) ) ) . withGenericTypes ( new JavaType [ ] { T } )", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "-", "check", "to", "toString", "()", "."], "add_tokens": "if ( mode != null ) { sb . append ( \", mode=\" ) ; sb . append ( this . mode . name ( ) ) ; }", "del_tokens": "sb . append ( \", mode=\" ) ; sb . append ( this . mode . name ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "BigDecimalTest", "and", "added", "UnsupportedOperationExceptions", "in", "a", "lot", "of", "BigDecimal", "builtin", "functions", "and", "operators"], "add_tokens": "throw new UnsupportedOperationException ( \"builtin power operator is not available for BigDecimal\" ) ;", "del_tokens": "throw new RuntimeException ( \"No support for big decimals\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "unit", "tests", "copyrights", "dependencies", "and", "plugins"], "add_tokens": "* Copyright 2012 Brian Matthews * The abstract base classes and concrete implementations for the Mojos * that implement the goals of the plugin are defined in this package . package com . btmatthews . maven . plugins . ldap . apache ;", "del_tokens": "* Copyright 2008 - 2011 Brian Thomas Matthews package com . btmatthews . maven . plugins . ldap . mojos ; import org . apache . maven . plugin . AbstractMojo ; import org . apache . maven . plugin . MojoFailureException ; * This Mojo implements the stop - server goal which terminates an embedded LDAP * server . * * @ goal stop - server * @ author < a href = \"mailto:brian.matthews@btmatthews.com\" > Brian Matthews < / a > * @ version 1.0 public class StopServerMojo extends AbstractMojo { public void execute ( ) throws MojoFailureException { } }", "commit_type": "update"}
{"commit_tokens": ["Fix", "typo", "when", "no", "docker", "URL", "is", "specified"], "add_tokens": "throw new IllegalArgumentException ( \"No url given and no DOCKER_HOST environment variable set\" ) ;", "del_tokens": "throw new IllegalArgumentException ( \"No url given and now DOCKER_HOST environment variable set\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "method", "for", "easily", "being", "able", "to", "filter", "the", "list"], "add_tokens": "if ( isItemVisible ( f ) ) { / * * * Used by the list to determine whether a file should be displayed or not . * Default behavior is to always display folders . If files can be selected , * then files are also displayed . Override this method to enable other * filtering behaviour , like only displaying files with specific extensions ( . zip , . txt , etc ) . * * @ param file to maybe add . Can be either a directory or file . * @ return True if item should be added to the list , false otherwise * / protected boolean isItemVisible ( final File file ) { return isDir ( file ) || ( mode == MODE_FILE || mode == MODE_FILE_AND_DIR ) ; }", "del_tokens": "if ( ( mode == MODE_FILE || mode == MODE_FILE_AND_DIR ) || f . isDirectory ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "typos", "and", "improved", "code", "layout", "(", "the", "things", "that", "really", "matter", ")"], "add_tokens": "// JUnit requires rules to be public public void testUtf8IsDefaultEncoding ( ) throws IOException { opener . setReceiver ( buffer ) ;", "del_tokens": "// Junit expects rules to be public. public void testUtf8Encoding ( ) throws IOException { opener . setReceiver ( buffer ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "worker", "s", "working", "directory", "to", "a", "relative", "path", "."], "add_tokens": "strategy = new FileCachingJobServiceClassLoaderStrategy ( service , jobId , \"./worker\" ) ; }", "del_tokens": "// TODO replace hard coded class loader strategy. strategy = new FileCachingJobServiceClassLoaderStrategy ( service , jobId , \"/Users/brad/jmist/worker\" ) ; } // new FileCachingJobServiceClassLoaderStrategy(service, jobId, \"C:/test/worker\");", "commit_type": "change"}
{"commit_tokens": ["Added", ":", "if", "folder", "is", "requested", "return", "index", ".", "html", ".", "(", "Changes", "ConfigReader", ")", "."], "add_tokens": "* @ param relativePath relative path ( usually only file name ) of file that was in main config . InputStream getResponseConfigFromFile ( String relativePath ) throws IOException ; * @ param relativePath relative path ( usually only file name ) of file that was requested . InputStream getStaticFile ( String relativePath ) throws IOException ; / * * * Informs if given path points to a folder . * @ param relativePath relative path to check * @ return true if there is folder under pointed path , false otherwise . * / boolean isFolder ( String relativePath ) ;", "del_tokens": "* @ param fileName name of file that was in main config . InputStream getResponseConfigFromFile ( String fileName ) throws IOException ; * @ param fileName name of file that was requested . InputStream getStaticFile ( String fileName ) throws IOException ;", "commit_type": "add"}
{"commit_tokens": ["Move", "default", "currency", "provider", "to", "top", "level"], "add_tokens": "* < p > * The set of loaded currencies is provided by an instance of { @ link CurrencyUnitDataProvider } . * The provider used is determined by the system property { @ code org . joda . money . CurrencyUnitDataProvider } * which should be the fully qualified class name of the provider . The default provider loads the first * resource named { @ code / org / joda / money / MoneyData . csv } on the classpath . // load one data provider by system property try { String clsName = System . getProperty ( \"org.joda.money.CurrencyUnitDataProvider\" , \"org.joda.money.DefaultCurrencyUnitDataProvider\" ) ; Class < ? extends CurrencyUnitDataProvider > cls = CurrencyUnit . class . getClassLoader ( ) . loadClass ( clsName ) . asSubclass ( CurrencyUnitDataProvider . class ) ; cls . newInstance ( ) . registerCurrencies ( ) ; } catch ( SecurityException ex ) { new DefaultCurrencyUnitDataProvider ( ) . registerCurrencies ( ) ; }", "del_tokens": "String clsName = System . getProperty ( \"org.joda.money.CurrencyUnitDataProvider\" , \"org.joda.money.CurrencyUnitDataProvider$DefaultProvider\" ) ; Class < ? extends CurrencyUnitDataProvider > cls = CurrencyUnit . class . getClassLoader ( ) . loadClass ( clsName ) . asSubclass ( CurrencyUnitDataProvider . class ) ; cls . newInstance ( ) . registerCurrencies ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "32kb", "block", "size", "according", "to", "suggestion", "by", "Alec", "Wysoker"], "add_tokens": "* The input data is blocked into 32 kb size ( in default ) , and each block is static final int DEFAULT_BLOCK_SIZE = 32 * 1024 ; // Use 32kb for the default block size", "del_tokens": "* The input data is blocked into 8 kb size ( in default ) , and each block is static final int DEFAULT_BLOCK_SIZE = 8 * 1024 ; // Use 8kb for the default block size", "commit_type": "use"}
{"commit_tokens": ["Fix", "build", "on", "a", "JVM", "."], "add_tokens": "ClassLoader classLoaderA = newPathClassLoader ( ) ; ClassLoader classLoaderB = newPathClassLoader ( ) ; private ClassLoader newPathClassLoader ( ) throws Exception { return ( ClassLoader ) Class . forName ( \"dalvik.system.PathClassLoader\" ) . getConstructor ( String . class , ClassLoader . class ) . newInstance ( \"\" , getClass ( ) . getClassLoader ( ) ) ; }", "del_tokens": "import dalvik . system . PathClassLoader ; ClassLoader classLoaderA = new PathClassLoader ( \"\" , getClass ( ) . getClassLoader ( ) ) ; ClassLoader classLoaderB = new PathClassLoader ( \"\" , getClass ( ) . getClassLoader ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "team", "alert", "action", "client", "implementations"], "add_tokens": "* Rest api uri of add recipient operation .", "del_tokens": "* Rest api uri of assign ownership operation .", "commit_type": "add"}
{"commit_tokens": ["add", "in", "adapter", "for", "viewpager"], "add_tokens": "import android . support . v4 . app . FragmentActivity ; import com . prolific . parallaxview . ParallaxUtil ; public class ParallaxActivity extends FragmentActivity { ParallaxUtil . attachFragmentManager ( getSupportFragmentManager ( ) ) ;", "del_tokens": "import android . app . Activity ; public class ParallaxActivity extends Activity {", "commit_type": "add"}
{"commit_tokens": ["Fix", "pom", "so", "package", "can", "be", "deployed", "again", "."], "add_tokens": "private static final String GC_ACTION = \"action=gc\" ; public EngineResult postEngineRequest ( String url , String action ) { return postEngineRequest ( baseUrl , RESCAN_ACTION ) ; return postEngineRequest ( baseUrl , GC_ACTION ) ;", "del_tokens": "private final static String GC_ACTION = \"action=gc\" ; public EngineResult doPost ( String url , String action ) { return doPost ( baseUrl , RESCAN_ACTION ) ; return doPost ( baseUrl , GC_ACTION ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "method", "for", "automatically", "calculation", "of", "Y", "axis", "."], "add_tokens": "import java . util . ArrayList ; // Automatically calculates Y axis values. private Axis calculateYAxis ( int numberOfSteps ) { if ( numberOfSteps < 2 ) { throw new IllegalArgumentException ( \"Number or steps have to be grater or equal 2\" ) ; } List < Float > values = new ArrayList < Float > ( ) ; final float range = mData . getMaxYValue ( ) - mData . getMinYValue ( ) ; final float tickRange = range / ( numberOfSteps - 1 ) ; final float x = ( float ) Math . ceil ( Math . log10 ( tickRange ) - 1 ) ; final float pow10x = ( float ) Math . pow ( 10 , x ) ; final float roundedTickRange = ( float ) Math . ceil ( tickRange / pow10x ) * pow10x ; float value = mData . getMinYValue ( ) ; while ( value <= mData . getMaxYValue ( ) ) { values . add ( value ) ; value += roundedTickRange ; } Axis yAxis = new Axis ( ) ; yAxis . setValues ( values ) ; return yAxis ; } drawYAxis ( canvas ) ; // Shift values to prevent recalculation of values that have been already calculated.", "del_tokens": "drawYAxis ( canvas ) ; // Shift values to prevent recalculation of values that where already calculated.", "commit_type": "add"}
{"commit_tokens": ["Improve", "API", "and", "use", "array", "for", "backtrace"], "add_tokens": "public final NoticeStackRecord [ ] backtrace ; this ( e . getClass ( ) . getCanonicalName ( ) , e . getMessage ( ) , e . getStackTrace ( ) ) ; public NoticeError ( String type , String message , StackTraceElement [ ] stackTrace ) { this . backtrace = new NoticeStackRecord [ stackTrace . length ] ; for ( int i = 0 ; i < stackTrace . length ; i ++ ) { this . backtrace [ i ] = new NoticeStackRecord ( stackTrace [ i ] ) ; }", "del_tokens": "public final List < NoticeStackRecord > backtrace ; this . type = e . getClass ( ) . getCanonicalName ( ) ; this . message = e . getMessage ( ) ; this . backtrace = new ArrayList < > ( ) ; for ( StackTraceElement el : e . getStackTrace ( ) ) { this . backtrace . add ( new NoticeStackRecord ( el ) ) ; } public NoticeError ( String type , String message , List < NoticeStackRecord > backtrace ) { this . backtrace = backtrace ;", "commit_type": "improve"}
{"commit_tokens": ["Made", "get", "signature", "the", "last", "call"], "add_tokens": "/ * * * OAuth 1.0 a implementation of { @ link OAuthService } * * @ author Pablo Fernandez * / / * * * Default constructor * * @ param signatureService OAuth 1.0 a signature service * @ param timestampService OAuth 1.0 a timestamp service * @ param baseStringExtractor OAuth 1.0 a base string extractor * @ param headerExtractor OAuth 1.0 a http header extractor * @ param rtExtractor OAuth 1.0 a request token extractor * @ param atExtractor OAuth 1.0 a access token extractor * @ param config OAuth 1.0 a configuration param object * / / * * * { @ inheritDoc } * / if ( scope != NO_SCOPE ) request . addOAuthParameter ( OAuthConstants . SCOPE , scope ) ; / * * * { @ inheritDoc } * / / * * * { @ inheritDoc } * / / * * * { @ inheritDoc } * / / * * * { @ inheritDoc } * /", "del_tokens": "if ( scope != NO_SCOPE ) { request . addOAuthParameter ( OAuthConstants . SCOPE , scope ) ; }", "commit_type": "make"}
{"commit_tokens": ["Add", "PROCESS_OUTGOING_CALLS", "to", "phone", "group", "."], "add_tokens": "Permission . USE_SIP , Permission . PROCESS_OUTGOING_CALLS } ;", "del_tokens": "Permission . USE_SIP } ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "res", "as", "shortcut", "for", "resource", "according", "to", "apache", ".", "commons", ".", "vfs"], "add_tokens": "/ * * * * / private static final String [ ] RESOURCE_PROTO_NAMES = new String [ ] { \"resource://\" , \"res://\" } ; for ( String resProto : RESOURCE_PROTO_NAMES ) { if ( url . startsWith ( resProto ) ) { InputStream is = resourceAwareClass . getResourceAsStream ( url . substring ( resProto . length ( ) ) ) ; InputSource source = new InputSource ( is ) ; // source.setEncoding(\"MacRoman\"); return documentBuilder . parse ( source ) ; } return item . hasAttribute ( selector . substring ( 1 ) ) ; }", "del_tokens": "if ( url . startsWith ( \"resource://\" ) ) { InputStream is = resourceAwareClass . getResourceAsStream ( url . substring ( \"resource://\" . length ( ) ) ) ; InputSource source = new InputSource ( is ) ; // source.setEncoding(\"MacRoman\"); return documentBuilder . parse ( source ) ; return item . hasAttribute ( selector . substring ( 1 ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Allow", "caching", "multiple", "sizes", "of", "image", "files"], "add_tokens": "byte [ ] bytes = box . mCache . get ( cacheKey ( ) ) ; protected String cacheKey ( ) { return streamId ( ) ; } cacheStream = box . mCache . beginStream ( cacheKey ( ) ) ;", "del_tokens": "byte [ ] bytes = box . mCache . get ( streamId ( ) ) ; cacheStream = box . mCache . beginStream ( streamId ( ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["updated", "SubsetProblem", "accordingly", "after", "renaming", "AbstractProblem"], "add_tokens": "public class SubsetProblem < DataType extends SubsetData > extends ProblemWithData < SubsetSolution , DataType > { // call constructor of ProblemWithData (already checks that objective is not null)", "del_tokens": "public class SubsetProblem < DataType extends SubsetData > extends AbstractProblem < SubsetSolution , DataType > { // call constructor of AbstractProblem (already checks that objective is not null)", "commit_type": "update"}
{"commit_tokens": ["Update", "maven", "central", "repo", "to", "https", ":", "//", "repo", ".", "maven", ".", "apache", ".", "org", "/", "maven2", "/"], "add_tokens": "String releaseUrlStr = \"https://repo.maven.apache.org/maven2/\" ;", "del_tokens": "String releaseUrlStr = \"http://central.maven.org/maven2/\" ;", "commit_type": "update"}
{"commit_tokens": ["added", "editor", "driver", "which", "automaticaly", "validats", "the", "input", "data", "on", "the"], "add_tokens": "* * * getter for the decorator . * * @ return the decorator * / public final AbstractDecorator < T > getDecorator ( ) { return this . decorator ; } / * * * getter for the widget which takes the values . * * @ return the takesValues public final TakesValue < T > getTakesValues ( ) { return this . takesValues ;", "del_tokens": "* * import org . apache . commons . lang3 . ObjectUtils ; private T originalData ; this . originalData = pvalue ; * check if entry has changed since it was set with setValue ( ) . * * @ return true if entry has changed . public boolean entryHasChanged ( ) { return ObjectUtils . equals ( this . originalData , this . getValue ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "auto", "close", "instead", "of", "release"], "add_tokens": "try ( final FileLock lock = out . lock ( tryLockMax , tryWaitMillis ) ) {", "del_tokens": "final FileLock lock = out . lock ( tryLockMax , tryWaitMillis ) ; try { } finally { lock . release ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "::", "insert"], "add_tokens": "public RubyArray < E > replace ( List < E > other ) { list . clear ( ) ; list . addAll ( other ) ; return this ; }", "del_tokens": "public RubyArray < E > replace ( List < E > other ) { list . clear ( ) ; list . addAll ( other ) ; return this ; }", "commit_type": "add"}
{"commit_tokens": ["add", "furious", "pool", "for", "benchmark"], "add_tokens": "import java . util . concurrent . atomic . AtomicLong ; final AtomicLong created = new AtomicLong ( 0 ) ; System . out . println ( \"Objects created:\" + created . get ( ) ) ; testFurious ( 50 , 1000 ) ; System . out . println ( \"-----------stormpot object pool------------\" ) ; System . out . println ( \"-----------furious object pool------------\" ) ; testFurious ( 50 , 50000 ) ; testFurious ( 100 , 50000 ) ; testFurious ( 150 , 50000 ) ; testFurious ( 200 , 30000 ) ; testFurious ( 250 , 30000 ) ; testFurious ( 300 , 30000 ) ; testFurious ( 350 , 20000 ) ; testFurious ( 400 , 20000 ) ; testFurious ( 450 , 20000 ) ; testFurious ( 500 , 10000 ) ; testFurious ( 550 , 10000 ) ; testFurious ( 600 , 10000 ) ; private static void testFurious ( int workerCount , int loop ) throws InterruptedException { new BenchmarkFurious ( workerCount , loop ) ; cleanup ( ) ; }", "del_tokens": "System . out . println ( \"-----------storm pot object pool------------\" ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "interface", "test", "(", "issue", "35", ")"], "add_tokens": "* @ deprecated This functionality is going to be dropped .", "del_tokens": "* @ deprecated Use annotations ( ) . matching ( Matcher < Annotation > ) instead .", "commit_type": "add"}
{"commit_tokens": ["Added", "additional", "tests", "for", "Parity", "client", "responses", "."], "add_tokens": "if ( ! ( o instanceof AccountsInfo ) ) return false ;", "del_tokens": "if ( o == null || getClass ( ) != o . getClass ( ) ) return false ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "bug", "if", "value", "-", "list", "has", "length", "of", "0", "(", "zero", ")"], "add_tokens": "if ( values . length > 0 ) { // fill array int caIndex = 0 ; for ( int i = 0 ; i < ( values . length - 1 ) ; i ++ ) { char [ ] itemValue = values [ i ] . toCharacters ( ) ; System . arraycopy ( itemValue , 0 , characters , caIndex , itemValue . length ) ; caIndex += itemValue . length ; characters [ caIndex ++ ] = Constants . XSD_LIST_DELIM_CHAR ; } char [ ] lastItemValue = values [ values . length - 1 ] . toCharacters ( ) ; System . arraycopy ( lastItemValue , 0 , characters , caIndex , lastItemValue . length ) ;", "del_tokens": "// fill array int caIndex = 0 ; for ( int i = 0 ; i < ( values . length - 1 ) ; i ++ ) { char [ ] itemValue = values [ i ] . toCharacters ( ) ; System . arraycopy ( itemValue , 0 , characters , caIndex , itemValue . length ) ; caIndex += itemValue . length ; characters [ caIndex ++ ] = Constants . XSD_LIST_DELIM_CHAR ; char [ ] lastItemValue = values [ values . length - 1 ] . toCharacters ( ) ; System . arraycopy ( lastItemValue , 0 , characters , caIndex , lastItemValue . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "strategy", "runs", "on", "whole", "series"], "add_tokens": "super ( null , null , 0 , null , null , null ) ;", "del_tokens": "import eu . verdelhan . ta4j . analysis . Runner ; super ( null , null , 0 , null , null , new Runner ( null , null ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "specify", "T0", "and", "gamma"], "add_tokens": "public SimulatedAnnealingTest ( double t0 , double gamma ) { super ( new SANeighborGenerator < double [ ] > ( t0 , gamma ) ) ;", "del_tokens": "public SimulatedAnnealingTest ( ) { super ( new SANeighborGenerator < double [ ] > ( 20000 , 0.992 ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Update", "example", ".", "Isolate", "program", "log", "and", "checkpoint", "log"], "add_tokens": "LOG . info ( \"Writing data...\" ) ; LOG . info ( \"Reading data...\" ) ; try {", "del_tokens": "LOG . info ( \"Done write buf init: \" + buf ) ; LOG . info ( \"Done write buf\" ) ; LOG . info ( \"Done write buf close partition\" ) ; try { LOG . info ( \"Trying to read data...\" ) ; LOG . info ( \"Read data: \" + buf ) ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "the", "use", "of", "environmental", "variables", "on", "both", "the", "DCs", ";", "now", "all", "the", "configuration", "are", "retrieved", "from", "the", ".", "properties", "file", ".", "README", ".", "md", "updated", "."], "add_tokens": "public void init ( Properties dcProperties ) { dcAgent = new DCAgent ( new ManagerAPI ( this . dcProperties . get ( DCProperties . MANAGER_IP ) . toString ( ) , Integer . parseInt ( this . dcProperties . get ( DCProperties . MANAGER_PORT ) . toString ( ) ) ) ) ; public static void initialize ( Properties dcProperties ) { _INSTANCE . init ( dcProperties ) ;", "del_tokens": "public void init ( String managerIP , int managerPort , Properties dcProperties ) { dcAgent = new DCAgent ( new ManagerAPI ( managerIP , managerPort ) ) ; public static void initialize ( String managerIP , int managerPort , Properties dcProperties ) { _INSTANCE . init ( managerIP , managerPort , dcProperties ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "fix", "for", "Java", "7"], "add_tokens": "throw new IllegalArgumentException ( \"Parameter type (\" + clazz . getName ( ) + \") cannot be handled! Only primitive types and Strings can be\" +", "del_tokens": "throw new IllegalArgumentException ( \"Parameter type (\" + clazz . getTypeName ( ) + \") cannot be handled! Only primitive types and Strings can be\" +", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "tests", "related", "with", "renderer", "creation", "and", "renderer", "recycle", "process", "in", "RendererBuilderTest"], "add_tokens": "private View view ; return view ; public void setView ( View view ) { this . view = view ; }", "del_tokens": "return null ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "errors", "with", "dsl", "completion"], "add_tokens": "List dslConsequences = adapter . listConsequenceItems ( ) ; Iterator iterator = dslConsequences . iterator ( ) ; while ( iterator . hasNext ( ) ) { String consequence = ( String ) iterator . next ( ) ; list . add ( new RuleCompletionProposal ( prefix . length ( ) , consequence ) ) ; // TODO prefix should be from beginning of line, not just last word ? filterProposalsOnPrefix ( prefix , list ) ; } List dslConditions = adapter . listConditionItems ( ) ; Iterator iterator = dslConditions . iterator ( ) ; while ( iterator . hasNext ( ) ) { String condition = ( String ) iterator . next ( ) ; list . add ( new RuleCompletionProposal ( prefix . length ( ) , condition ) ) ; // TODO prefix should be from beginning of line, not just last word ? filterProposalsOnPrefix ( prefix , list ) ; } iterator = imports . iterator ( ) ;", "del_tokens": "list . addAll ( adapter . listConsequenceItems ( ) ) ; list . addAll ( adapter . listConditionItems ( ) ) ; Iterator iterator = imports . iterator ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Created", "an", "S2OAuth", "-", "based", "signer", "to", "potentially", "replace", "the", "Scribe", "-", "based", "signer", "."], "add_tokens": "private final Token tokenAndSecret ; tokenAndSecret = new Token ( accessToken , accessTokenSecret ) ; OAuthRequest request = new OAuthRequest ( Verb . valueOf ( method . name ( ) ) , decode ( url ) . replace ( \"#\" , \"%23\" ) ) ; service . signRequest ( tokenAndSecret , request ) ;", "del_tokens": "private final String accessToken ; private final String accessTokenSecret ; this . accessToken = accessToken ; this . accessTokenSecret = accessTokenSecret ; String adjustedUrl = decode ( url ) . replace ( \"#\" , \"%23\" ) ; OAuthRequest request = new OAuthRequest ( Verb . valueOf ( method . name ( ) ) , adjustedUrl ) ; Token token = new Token ( accessToken , accessTokenSecret ) ; service . signRequest ( token , request ) ;", "commit_type": "create"}
{"commit_tokens": ["Use", "exceptions", "properly", "instead", "of", "booleans"], "add_tokens": "import java . io . IOException ; try { Notification notif = new Notification ( config , new Error ( e , metaData , config ) ) ; notif . deliver ( ) ; } catch ( IOException ex ) { config . getLogger ( ) . warn ( \"Error notifying Bugsnag\" , ex ) ; }", "del_tokens": "Notification notif = new Notification ( config , new Error ( e , metaData , config ) ) ; notif . deliver ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Improved", "multi", "-", "threaded", "support", ";", "still", "doesn", "t", "work!", "Added", "documentation", "and", "other", "considirations"], "add_tokens": "import net . jcip . annotations . GuardedBy ; return drainTo ( c , Integer . MAX_VALUE ) ; public synchronized int drainTo ( Collection < ? super Runnable > c , int maxRunnablelements ) { int counter = 0 ; for ( Runnable object : this ) { counter ++ ; if ( counter < maxRunnablelements ) { c . add ( object ) ; } else { break ; } } for ( Object object : c ) { this . remove ( object ) ; } return counter ; @ GuardedBy ( \"this\" ) public synchronized Runnable element ( ) { @ GuardedBy ( \"this\" ) public synchronized Runnable remove ( ) {", "del_tokens": "// Is never used, TODO Stefan a implementation whould be nice return 0 ; public int drainTo ( Collection < ? super Runnable > c , int maxRunnablelements ) { // Is never used, TODO Stefan a implementation whould be nice return 0 ; public Runnable element ( ) { public Runnable remove ( ) {", "commit_type": "improve"}
{"commit_tokens": ["Add", "documentation", "for", "using", "AsyncItemProcessor", "and", "Filtering"], "add_tokens": "* are removed from the item cache as well and will never be reprocessed . When using the AsyncItemProcessor there * is no filtering possible at all , because a Future - Object is always returned from the ItemProcessor .", "del_tokens": "* are removed from the item cache as well and will never be reprocessed .", "commit_type": "add"}
{"commit_tokens": ["allow", "configuring", "component", "style", "during", "build", "via", "a", "consumer"], "add_tokens": "private Style . @ MonotonicNonNull Builder styleBuilder ; @ Override @ SuppressWarnings ( \"unchecked\" ) public @ NonNull B style ( final @ NonNull Consumer < Style . Builder > consumer ) { consumer . accept ( this . styleBuilder ( ) ) ; return ( B ) this ; } this . styleBuilder = null ; if ( this . styleBuilder == null ) { this . styleBuilder = this . style . toBuilder ( ) ; this . styleBuilder = Style . builder ( ) ; return this . styleBuilder ; return this . styleBuilder != null || this . style != null ; if ( this . styleBuilder != null ) { return this . styleBuilder . build ( ) ;", "del_tokens": "private Style . @ MonotonicNonNull Builder styleB ; this . styleB = null ; if ( this . styleB == null ) { this . styleB = this . style . toBuilder ( ) ; this . styleB = Style . builder ( ) ; return this . styleB ; return this . styleB != null || this . style != null ; if ( this . styleB != null ) { return this . styleB . build ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Change", "the", "order", "where", "the", "NS", "is", "written", "."], "add_tokens": "for ( Attr attr : attrs ) { _writer . writeAttribute ( attr . name , attr . value ) ; }", "del_tokens": "for ( Attr attr : attrs ) { _writer . writeAttribute ( attr . name , attr . value ) ; }", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "font", "size", "not", "reverting", "on", "clear_request"], "add_tokens": "viewEdit = new ViewEdit ( path , mutator , prop . accessor , context ) ;", "del_tokens": "viewEdit = new ViewEdit ( path , mutator , prop . accessor ) ;", "commit_type": "fix"}
{"commit_tokens": ["Create", "test", "that", "verifies", "parsing", "fails", "on", "incorrect", "queries"], "add_tokens": "static void parseLegacyWithListeners ( String query , ANTLRErrorListener lexerListener , ANTLRErrorListener parserListener ) { System . setProperty ( INCLUDE_LEGACY . name ( ) , \"true\" ) ; initLegacyGrammar ( \"/cypher.xml\" ) ; parseWithListeners ( legacyGrammar , query , lexerListener , parserListener ) ; } { parseWithListeners ( grammar , query , new FailingErrorListener ( query ) , new FailingErrorListener ( query ) ) ; } private static void parseWithListeners ( Grammar grammar , String query , ANTLRErrorListener lexerListener , ANTLRErrorListener parserListener ) lexer . addErrorListener ( lexerListener ) ; parser . addErrorListener ( parserListener ) ;", "del_tokens": "lexer . addErrorListener ( new FailingErrorListener ( query ) ) ; parser . addErrorListener ( new FailingErrorListener ( query ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "FilteringHostSupplier", "to", "return", "the", "source", "list", "if", "the", "filter", "result", "is", "empty", "for", "any", "reason"], "add_tokens": "if ( filterList . isEmpty ( ) ) return sourceList ; List < Host > result = Lists . newArrayList ( Collections2 . filter ( sourceList , new Predicate < Host > ( ) { if ( result . isEmpty ( ) ) return sourceList ; return result ;", "del_tokens": "return Lists . newArrayList ( Collections2 . filter ( sourceList , new Predicate < Host > ( ) {", "commit_type": "fix"}
{"commit_tokens": ["updating", "wire", "mock", "reps", "support", "for", "generic", "velocity", "tools"], "add_tokens": "import org . apache . velocity . app . VelocityEngine ; import org . apache . velocity . context . Context ; import org . apache . velocity . tools . ToolManager ; private Context context ; VelocityEngine velocityEngine = new VelocityEngine ( ) ; velocityEngine . init ( ) ; final ToolManager toolManager = new ToolManager ( ) ; toolManager . setVelocityEngine ( velocityEngine ) ; context = toolManager . createContext ( ) ;", "del_tokens": "import org . apache . velocity . VelocityContext ; private VelocityContext context ; context = new VelocityContext ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "Issue", "54", "to", "enable", "serialization", "of", "fields", "that", "are", "declared", "of", "type"], "add_tokens": "/ * * * Tests that a class field with type Object can be serialized properly . * See issue 54 * / public void testClassWithObjectFieldSerialization ( ) { ClassWithObjectField obj = new ClassWithObjectField ( ) ; obj . member = \"abc\" ; String json = gson . toJson ( obj ) ; assertTrue ( json . contains ( \"abc\" ) ) ; } private static class ClassWithObjectField { Object member ; } Gson gson = new GsonBuilder ( ) . registerTypeAdapter ( Parent . Child . class , new InstanceCreator < Parent . Child > ( ) {", "del_tokens": "Gson gson = new GsonBuilder ( ) . registerTypeAdapter ( Parent . Child . class , new InstanceCreator < Parent . Child > ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "leading", "EsClusterHealthCheck#check", "to", "hang"], "add_tokens": "final ClusterHealthStatus status = client . admin ( ) . cluster ( ) . prepareHealth ( ) . get ( ) . getStatus ( ) ; return Result . unhealthy ( \"Last status: %s\" , status . name ( ) ) ; return Result . healthy ( \"Last status: %s\" , status . name ( ) ) ;", "del_tokens": "import org . elasticsearch . action . admin . cluster . health . ClusterHealthResponse ; final ClusterHealthResponse healthResponse = client . admin ( ) . cluster ( ) . prepareHealth ( ) . setWaitForYellowStatus ( ) . execute ( ) . actionGet ( ) ; final ClusterHealthStatus status = healthResponse . getStatus ( ) ; return Result . unhealthy ( \"Last status: %s\" , healthResponse . getStatus ( ) . name ( ) ) ; return Result . healthy ( \"Last status: %s\" , healthResponse . getStatus ( ) . name ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["moving", "Short", "/", "Long", "LBA", "parameters", "into", "mode", "page", "sub", "-", "package"], "add_tokens": "package org . jscsi . scsi . protocol . mode . parameter ; import org . jscsi . scsi . protocol . mode . ModePage ;", "del_tokens": "package org . jscsi . scsi . protocol . mode ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "systematic", "UTF", "-", "8", "encoding", "for", "ouput", "files", ".", "This", "has", "either", "to", "be", "an", "external", "parameter", "or", "use", "the", "platform", "default", "encoding", "."], "add_tokens": "FileUtils . writeStringToFile ( targetFile , source ) ;", "del_tokens": "import java . nio . charset . Charset ; import org . apache . commons . compress . utils . Charsets ; /** All output files are in UTF-8. Might want to externalize as a parameter.*/ private static final Charset TARGET_FILES_ENCODING = Charsets . UTF_8 ; FileUtils . writeStringToFile ( targetFile , source , TARGET_FILES_ENCODING ) ; compiler . setOutputCharacterEncoding ( TARGET_FILES_ENCODING . name ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "cache", "for", "address", "country", "locale"], "add_tokens": "// Status vars private Locale m_aCountry ; Locale ret = m_aCountry ; if ( ret == null && m_sCountry != null ) { m_aCountry = ret = CountryCache . getInstance ( ) . getCountry ( m_sCountry ) ; } return ret ; m_aCountry = null ;", "del_tokens": "return CountryCache . getInstance ( ) . getCountry ( m_sCountry ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "Pages", "using", "mvn", "site", "."], "add_tokens": "* @ param username username or email address of the principal passed . A valid email address would be in the format of } }", "del_tokens": "* @ param username username or email address of the principal passed . A valid email address would in the format of } }", "commit_type": "update"}
{"commit_tokens": ["Creates", "output", "folder", "if", "doesn", "t", "exist", "&", "fixes", "licence", "header", "on", "resources"], "add_tokens": "urls . put ( \"url_\" + id , requestUrlBase + uri . getPath ( ) ) ; File outputFolder = new File ( configuration . getOutputFolder ( ) ) ; if ( ! outputFolder . exists ( ) ) if ( ! outputFolder . mkdir ( ) ) logger . error ( \"Can't create output folder directory...\" ) ; File dir = new File ( outputFolder , ResultType . FORMAT . format ( startDate ) + \"_\" + GATLING_REQUEST_BODIES_DIRECTORY_NAME ) ; File outputFolder = new File ( configuration . getOutputFolder ( ) ) ; if ( ! outputFolder . exists ( ) ) if ( ! outputFolder . mkdir ( ) ) logger . error ( \"Can't create output folder directory...\" ) ; fileWriter = new FileWriter ( new File ( outputFolder , resultType . getScenarioFileName ( startDate ) ) ) ;", "del_tokens": "urls . put ( \"url_\" + id , requestUrlBase + uri . getPath ( ) ) ; // Dump request body File dir = new File ( configuration . getOutputFolder ( ) , ResultType . FORMAT . format ( startDate ) + \"_\" + GATLING_REQUEST_BODIES_DIRECTORY_NAME ) ; fileWriter = new FileWriter ( new File ( configuration . getOutputFolder ( ) , resultType . getScenarioFileName ( startDate ) ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Add", "withService", "(", "String", "Scoped", ")", "per", "review"], "add_tokens": "* method . if ( service instanceof Scoped ) { throw new IllegalArgumentException ( String . format ( \"For service %s, %s must not be an instance of %s, use \\\"withScopedService\\\" instead.\" , serviceName , service , Scoped . class . getSimpleName ( ) ) ) ; return doWithService ( serviceName , service ) ; } / * * * Makes this service available via the new scope 's {@link MortarScope#findService} * method , and { @ link MortarScope # register ( Scoped ) registers } it with the new scope . * Allows set up and tear down . * / public Builder withService ( String serviceName , Scoped service ) { return doWithService ( serviceName , service ) ; private Builder doWithService ( String serviceName , Object service ) { Object existing = serviceProviders . put ( serviceName , service ) ; if ( existing != null ) { throw new IllegalArgumentException ( format ( \"New scope \\\"%s\\\" already bound to service %s, cannot be rebound to %s\" , name , existing , service ) ) ; } return this ; }", "del_tokens": "* method . If the service implements { @ link Scoped } it will be registered with * the new scope . Object existing = serviceProviders . put ( serviceName , service ) ; if ( existing != null ) { throw new IllegalArgumentException ( format ( \"New scope \\\"%s\\\" already bound to service %s, cannot be rebound to %s\" , name , existing , service ) ) ; return this ;", "commit_type": "add"}
{"commit_tokens": ["added", "constructor", "param", "to", "set", "suggestion", "body", "size"], "add_tokens": "mSuggestionsAdapter = new SearchSuggestionsAdapter ( getContext ( ) , mSuggestionsTextSizePx , new SearchSuggestionsAdapter . Listener ( ) {", "del_tokens": "mSuggestionsAdapter = new SearchSuggestionsAdapter ( getContext ( ) , new SearchSuggestionsAdapter . Listener ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "an", "issue", "with", "RequestMapping", "string", "[]"], "add_tokens": "if ( isArray || Collection . class . isAssignableFrom ( cls ) || cls . isArray ( ) ) {", "del_tokens": "if ( isArray || cls . isArray ( ) || cls . isAssignableFrom ( Collection . class ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "separators", "were", "being", "missed", "and", "no", "error", "was"], "add_tokens": "final String relationshipTitle = matcher . group ( \"TopicTitle\" ) . trim ( ) ; // Check that a separator wasn't missed. if ( StringUtilities . lastIndexOf ( s , startDelim ) != StringUtilities . indexOf ( s , startDelim ) ) { throw new ParsingException ( String . format ( ProcessorConstants . ERROR_MISSING_SEPARATOR_MSG , initialCount , separator ) ) ; } else { variables . add ( s . trim ( ) ) ; }", "del_tokens": "final String relationshipTitle = matcher . group ( \"TopicTitle\" ) ; variables . add ( s . trim ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "unused", "code", "and", "comments"], "add_tokens": "return createEntity ( res , AdminLogEntity . class ) ; return createEntity ( res , StatisticsEntity . class ) ; return createEntity ( res , StatisticsDescriptionEntity . class ) ; * @ see < a href = * \"http://www.arangodb.com/manuals/current/HttpMisc.html#HttpMiscVersion\" > * HttpMiscVersion documentation < / a >", "del_tokens": "// 実行 // 結果変換 try { AdminLogEntity entity = createEntity ( res , AdminLogEntity . class ) ; return entity ; } catch ( ArangoException e ) { throw e ; // return null; } try { return createEntity ( res , StatisticsEntity . class ) ; } catch ( ArangoException e ) { throw e ; } try { return createEntity ( res , StatisticsDescriptionEntity . class ) ; } catch ( ArangoException e ) { throw e ; } * @ see < a * href = \"http://www.arangodb.com/manuals/current/HttpMisc.html#HttpMiscVersion\" > HttpMiscVersion * documentation < / a >", "commit_type": "remove"}
{"commit_tokens": ["Changed", "end", "point", "for", "get", "sheet", "as", "file", "."], "add_tokens": "String path = \"sheets/\" + id ;", "del_tokens": "String path = \"sheet/\" + id ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "HyperExpress", "plugin", "for", "latest", "HyperExpress", "refactorings", "."], "add_tokens": "HyperExpress . registerResourceFactoryStrategy ( hal , ContentType . JSON ) ; HyperExpress . registerResourceFactoryStrategy ( hal , ContentType . HAL_JSON ) ; HyperExpress . registerResourceFactoryStrategy ( factoryStrategy , contentType ) ;", "del_tokens": "HyperExpress . registerResourceFactory ( hal , ContentType . JSON ) ; HyperExpress . registerResourceFactory ( hal , ContentType . HAL_JSON ) ; HyperExpress . registerResourceFactory ( factoryStrategy , contentType ) ;", "commit_type": "update"}
{"commit_tokens": ["Move", "main", "classes", "to", "async", "-", "annotations", "module"], "add_tokens": "import com . stanfy . enroscar . async . Async ; if ( returnType . startsWith ( Async . class . getName ( ) . concat ( \"<\" ) ) ) {", "del_tokens": "if ( returnType . startsWith ( TypeSupport . ASYNC_CLASS . concat ( \"<\" ) ) ) {", "commit_type": "move"}
{"commit_tokens": ["make", "the", "test", "more", "robust"], "add_tokens": "final Socket socket = client . create ( client . newOptionsBuilder ( ) . build ( ) ) ; if ( Arrays . equals ( message , binaryEcho ) && ! hasEchoReplied . get ( ) ) { socket . close ( ) ; latch . countDown ( ) ;", "del_tokens": "Socket socket = client . create ( client . newOptionsBuilder ( ) . build ( ) ) ; if ( Arrays . equals ( message , binaryEcho ) ) { latch . countDown ( ) ; socket . close ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "objectKey", "in", "the", "callbacks", "of", "the", "UploadManager"], "add_tokens": "import com . qingstor . sdk . model . OutputModel ; public abstract class UploadManagerCallback < O extends OutputModel > { public abstract void onAPIResponse ( String objectKey , O outputModel ) ;", "del_tokens": "import com . qingstor . sdk . request . ResponseCallBack ; public abstract class UploadManagerCallback implements ResponseCallBack {", "commit_type": "add"}
{"commit_tokens": ["added", "invalid", "move", "count", "constant"], "add_tokens": "/ * * * Indicates an invalid number of moves . * / public static final long INVALID_MOVE_COUNT = - 1 ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "bean", "constructor", "for", "ExpressionParser"], "add_tokens": "public void test1 ( ) @ Test public void test2 ( ) { ExpressionParser ep = new ExpressionParser ( \"abc\" ) ; assertEquals ( \"12345\" , ep . replace ( \"12${length}45\" ) ) ; }", "del_tokens": "public void test ( )", "commit_type": "add"}
{"commit_tokens": ["Remove", "Deframer", "and", "InputStreamDeframer", "since", "we", "are", "not", "using", "them", "anymore", "."], "add_tokens": "* { @ link GrpcDeframer } or { @ link MessageDeframer2 } ( V2 protocol ) .", "del_tokens": "* { @ link com . google . net . stubby . newtransport . Deframer } .", "commit_type": "remove"}
{"commit_tokens": ["Add", "capability", "to", "use", "a", "shared", "jre", "between", "multiple", "applications", "by", "setting", "jreFullPath", "in", "configuration"], "add_tokens": "/ * * * The full path to the installation directory of the jre on the user 's machine. * * @ parameter default - value = \"\" * / private String jreFullPath ; } else if ( jreFullPath != null ) { getLog ( ) . info ( \"JRE Full path is used [\" + jreFullPath + \"]\" ) ; embeddJre = true ; if ( embeddJre && jrePath != null ) { velocityContext . put ( \"jreFullPath\" , \"\" ) ; } else if ( embeddJre && jreFullPath != null ) { velocityContext . put ( \"jrePath\" , \"\" ) ; velocityContext . put ( \"jreFullPath\" , jreFullPath ) ; velocityContext . put ( \"jreFullPath\" , \"\" ) ;", "del_tokens": "if ( embeddJre ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "implement", "an", "OnClickListener", "on", "the", "calling", "Activity", "to", "receive", "the", "Button", "clicks", "."], "add_tokens": "import android . util . Log ; private OnClickListener mOnClickListener ; / * * mDividerView = mToastView try { mOnClickListener = ( OnClickListener ) mContext ; } catch ( ClassCastException e ) { Log . d ( TAG , e . toString ( ) ) ; } if ( mOnClickListener != null ) { mToastButton . setOnClickListener ( new OnClickListener ( ) { @ Override public void onClick ( View v ) { mOnClickListener . onClick ( v ) ; } } ) ; }", "del_tokens": "/ * * mDividerView = ( View ) mToastView //XXX: Setter methods // XXX: Button Type methods // XXX: Progress Type methods // XXX: Getter methods. // XXX: Static methods. // XXX: Private methods.", "commit_type": "add"}
{"commit_tokens": ["add", "new", "user", "messages", "/", "combat", "log", "message", "from", "techies", "update"], "add_tokens": "/ * * * < code > ACT_DOTA_MINI_TAUNT = 602 ; < / code > * / ACT_DOTA_MINI_TAUNT ( 601 , 602 ) , / * * * < code > ACT_DOTA_MINI_TAUNT = 602 ; < / code > * / public static final int ACT_DOTA_MINI_TAUNT_VALUE = 602 ; case 602 : return ACT_DOTA_MINI_TAUNT ; \"\\n\\021ai_activity.proto*\\220\\203\\001\\n\\010Activity\\022\\030\\n\\013ACT\" + \"_DOTA_STATIC_STORM\\020\\331\\004\\022\\030\\n\\023ACT_DOTA_MINI_T\" , \"AUNT\\020\\332\\004B\\021\\n\\017com.dota2.proto\"", "del_tokens": "\"\\n\\021ai_activity.proto*\\366\\202\\001\\n\\010Activity\\022\\030\\n\\013ACT\" + \"_DOTA_STATIC_STORM\\020\\331\\004B\\021\\n\\017com.dota2.proto\"", "commit_type": "add"}
{"commit_tokens": ["adds", "a", "localhost", "request", "filter", ";", "refactors", "filtering", "to", "be", "more", "fluent"], "add_tokens": "if ( resource != null ) { return readVersionFromManifest ( resource . openStream ( ) ) ; }", "del_tokens": "return readVersionFromManifest ( resource . openStream ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "activity_main", ".", "xml", "to", "show", "a", "new", "button", "and", "a", "LynxView", "when", "this", "button", "is", "pressed"], "add_tokens": "Button bt_show_lynx_activity = ( Button ) findViewById ( R . id . bt_show_lynx_activity ) ; bt_show_lynx_activity . setOnClickListener ( new View . OnClickListener ( ) { final Button bt_show_lynx_view = ( Button ) findViewById ( R . id . bt_show_lynx_view ) ; bt_show_lynx_view . setOnClickListener ( new View . OnClickListener ( ) { @ Override public void onClick ( View v ) { View lynxView = findViewById ( R . id . lynx_view ) ; lynxView . setVisibility ( View . VISIBLE ) ; } } ) ;", "del_tokens": "Button bt_show_logcat_view = ( Button ) findViewById ( R . id . bt_show_lynx_view ) ; bt_show_logcat_view . setOnClickListener ( new View . OnClickListener ( ) {", "commit_type": "update"}
{"commit_tokens": ["Updated", "remaining", "methods", "to", "use", "limit", "code"], "add_tokens": "import com . fasterxml . jackson . annotation . JsonProperty ; import com . omertron . rottentomatoesapi . wrapper . IWrapperError ; import org . apache . commons . lang3 . StringUtils ; * Abstract base class for the RT objects * * Handles any unknown properties by outputting a log message < br / > * Handles error messages public abstract class AbstractJsonMapping implements Serializable , IWrapperError { @ JsonProperty ( \"error\" ) private String error = \"\" ; @ Override public String getError ( ) { return error ; } @ Override public void setError ( String error ) { this . error = error ; } / * * * Check to see if the returned values are valid * * @ return * / @ Override public boolean isValid ( ) { return StringUtils . isBlank ( error ) ; }", "del_tokens": "* Abstract class to handle any unknown properties by outputting a log message public abstract class AbstractJsonMapping implements Serializable {", "commit_type": "update"}
{"commit_tokens": ["Fixed", "recursive", "constructor", "in", "CommBAltitudeReply"], "add_tokens": "this ( new ModeSReply ( raw_message ) ) ;", "del_tokens": "this ( new CommBAltitudeReply ( raw_message ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "method", "parameter", "type", "changed", "check", "...", "fixed", "method", "parameter", "ordering", "and", "equality", "issues", "."], "add_tokens": "METHOD_NUMBER_OF_PARAMETERS_CHANGED ( \"java.method.numberOfParametersChanged\" , BREAKING , BREAKING , null ) , METHOD_PARAMETER_TYPE_CHANGED ( \"java.method.parameterTypeChanged\" , POTENTIALLY_BREAKING , BREAKING , null ) ;", "del_tokens": "METHOD_NUMBER_OF_PARAMETERS_CHANGED ( \"java.method.numberOfParametersChanged\" , BREAKING , BREAKING , null ) ;", "commit_type": "implement"}
{"commit_tokens": ["Implemented", "UriBuilder", ".", "toTemplate", "()"], "add_tokens": "return render ( null , true , false , true ) ; public String render ( Map < String , ? > values , boolean encodePath , boolean encodeValues , boolean encodeSlashInPath ) { if ( encodePath && ! encodeValues ) { String pathBit = encodePath ? urlEncode ( cur ) : cur ;", "del_tokens": "return render ( null , false , true ) ; public String render ( Map < String , ? > values , boolean encodeValues , boolean encodeSlashInPath ) { if ( ! encodeValues ) { String pathBit = urlEncode ( cur ) ;", "commit_type": "implement"}
{"commit_tokens": ["fixed", "NPE", "when", "detecting", "filters", "with", "no", "filters"], "add_tokens": "import java . util . Arrays ; if ( hasNoFilters ( ) ) { return ; } return filterMatch ( Arrays . asList ( sexp ) ) ; if ( filterMethod . getClass ( ) == TagFilterMethod . class ) { return false ; } return true ;", "del_tokens": "// TODO Auto-generated method stub return false ; // TODO Auto-generated method stub return false ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "IBS", "for", "local", "computation", "."], "add_tokens": "int numberOfVariants = 0 ; ++ numberOfVariants ; LOG . info ( \"Read \" + numberOfVariants + \" variants at: \" + request . getReferenceName ( ) + \"-\" + \"[\" + request . getStart ( ) + \", \" + request . getEnd ( ) + \"]\" ) ;", "del_tokens": "LOG . info ( \"Finished variants at: \" + request . getReferenceName ( ) + \"-\" + request . getStart ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["remove", "background", "data", "checks", "from", "the", "service", "request", "performer"], "add_tokens": "bind ( ) ; registerListener ( ) ; super . performRequest ( description ) ;", "del_tokens": "import android . net . ConnectivityManager ; /** Connectivity manager. */ private final ConnectivityManager connectivityManager ; connectivityManager = ( ConnectivityManager ) a . getSystemService ( Context . CONNECTIVITY_SERVICE ) ; if ( connectivityManager . getBackgroundDataSetting ( ) ) { bind ( ) ; registerListener ( ) ; super . performRequest ( description ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "active", "style", "if", "value", "is", "set", "to", "MaterialTextBox"], "add_tokens": "if ( ! text . isEmpty ( ) ) { customLabel . addStyleName ( \"active\" ) ; } if ( ! Character . isDigit ( event . getCharCode ( ) ) && event . getNativeEvent ( ) . getKeyCode ( ) != KeyCodes . KEY_TAB setValue ( value , false ) ; if ( ! value . isEmpty ( ) ) { customLabel . addStyleName ( \"active\" ) ; }", "del_tokens": "customLabel . addStyleName ( \"active\" ) ; if ( ! Character . isDigit ( event . getCharCode ( ) ) && event . getNativeEvent ( ) . getKeyCode ( ) != KeyCodes . KEY_TAB txtBox . setValue ( value ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "type", "signatures", "in", "sample", "application"], "add_tokens": "public HasText getFake ( Class < ? > type ) {", "del_tokens": "public HasText getFake ( Class < ? extends HasText > type ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "documentation", "that", "was", "saying", "about", "imfAuthentication", "realm", ".", "In", "BM", "we", "don", "t", "check", "for", "this", "realm", "and", "the", "docs", "should", "not", "mention", "it", "."], "add_tokens": "* 2. The value of the \"WWW-Authenticate\" header contains 'Bearer' * @ return true if status is 401 or 403 and The value of the header contains 'Bearer'", "del_tokens": "private static final String REALM_IMF_AUTHENTICATION = \"realm=\\\"imfAuthentication\\\"\" ; * 2. The value of the \"WWW-Authenticate\" header contains 'Bearer' AND 'realm=\"imfAuthentication\"' * @ return true if status is 401 or 403 and The value of the header contains 'Bearer' AND 'realm=\"imfAuthentication\"'", "commit_type": "fix"}
{"commit_tokens": ["Moves", "new", "SCXML", "code", "to", "dg", "-", "core", "corrects", "coding", "style"], "add_tokens": "import org . finra . datagenerator . engine . scxml . SCXMLEngine ; dist . setMaxNumberOfLines ( 20 ) ; dist . setThreadCount ( 1 ) ;", "del_tokens": "dist . setMaxNumberOfLines ( 45000 ) ; dist . setThreadCount ( 10 ) ;", "commit_type": "move"}
{"commit_tokens": ["update", "generic", "web", "service", "and", "handler"], "add_tokens": "LOG . debug ( \"uri {}\" , uri ) ; ResponseUpdater ru = this . findResponseUpdater ( request ) ; LOG . debug ( \"request updater {}\" , ru ) ; ru . update ( response ) ; . filter ( e -> uri . contains ( e . getKey ( ) ) )", "del_tokens": "this . findResponseUpdater ( request ) . update ( response ) ; . filter ( e -> uri . matches ( e . getKey ( ) ) )", "commit_type": "update"}
{"commit_tokens": ["Fixed", "MonitoringManager", ".", "deregister", "()", "method", "."], "add_tokens": "engine . deregister ( collector . target ( ) ) ;", "del_tokens": "engine . deregister ( collector ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "methods", "to", "add", "all", "new", "provider", "types", "added", "custom", "provider"], "add_tokens": "static int providersWithoutNames = 0 ; public String getName ( ) { return name == null ? \"recommendations-\" + ( ++ providersWithoutNames ) : name ; }", "del_tokens": "public String getName ( ) { return name ; }", "commit_type": "add"}
{"commit_tokens": ["Adds", "total", "count", "to", "the", "SnapshotResource", ".", "getContent", "()", "method", "."], "add_tokens": "result . setTotalCount ( snapshotContentItemRepo . countBySnapshotName ( snapshotId ) ) ;", "del_tokens": "import org . duracloud . common . notification . NotificationManager ; import org . duracloud . snapshot . service . BridgeConfiguration ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "empty", "batch", "request", "task"], "add_tokens": "private static final int TIMEOUT = 60000 ; Assert . assertTrue ( pool . shutdownNow ( ) . isEmpty ( ) ) ; Assert . assertTrue ( pool . shutdownNow ( ) . isEmpty ( ) ) ; Assert . assertTrue ( pool . shutdownNow ( ) . isEmpty ( ) ) ;", "del_tokens": "private static final int TIMEOUT = 180000 ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "deep", "nested", "bullet", "lists", "for", "Nougat"], "add_tokens": "// @since 2.0.2 // There is a bug in Android Nougat, when this span receives an `x` that // doesn't correspond to what it should be (text is placed correctly though). // Let's make this a general rule -> manually calculate difference between expected/actual // and add this difference to resulting left/right values. If everything goes well // we do not encounter a bug -> this `diff` value will be 0 final int diff ; if ( dir < 0 ) { // rtl diff = x - ( layout . getWidth ( ) - ( width * level ) ) ; } else { diff = ( width * level ) - x ; } l = Math . min ( left , right ) + ( dir * diff ) ; r = Math . max ( left , right ) + ( dir * diff ) ;", "del_tokens": "l = Math . min ( left , right ) ; r = Math . max ( left , right ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "java", "doc", "in", "BootstapProgressBar"], "add_tokens": "* Its possible to group multiple together in an { @ link com . beardedhen . androidbootstrap . BootstrapProgressBarGroup BootstrapProgressBarGroup } to give the appearance of a < a href = \"http://getbootstrap.com/components/#progress-stacked\" > stacked < / a > progressbar .", "del_tokens": "* Its possible to group multiple together in an { @ link BootstrapProgressBarGroup } to give the appearance of a < a href = \"http://getbootstrap.com/components/#progress-stacked\" > stacked < / a > progressbar .", "commit_type": "fix"}
{"commit_tokens": ["Updated", "for", "content", "type", "issue", "."], "add_tokens": "import java . util . Arrays ; System . out . println ( \"base \" + data ) ; System . out . println ( attachmentData . size ( ) ) ; System . out . println ( Arrays . toString ( attachmentAndType . getAttachment ( ) ) ) ;", "del_tokens": "System . out . println ( \"base \" + Attachment . generateSha2 ( attachmentAndType . getAttachment ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", "unrouteable", "address", "for", "testConnectTimeout"], "add_tokens": "// Attempt to connect to reserved IP -> should timeout . uri ( \"http://240.0.0.1:2375\" )", "del_tokens": "// Attempt to connect to an unroutable ip address -> connect will time out. . uri ( \"http://172.31.255.1:2375\" )", "commit_type": "change"}
{"commit_tokens": ["Fix", "client", "runtime", "tests", "after", "switching", "to", "jackson"], "add_tokens": "Assert . assertEquals ( ServiceException . class , exception . getClass ( ) ) ; Assert . assertTrue ( exception . getMessage ( ) . contains ( \"JsonMappingException\" ) ) ; public void failure ( ServiceException exception ) { Assert . assertEquals ( ServiceException . class , exception . getClass ( ) ) ; Assert . assertTrue ( exception . getMessage ( ) . contains ( \"JsonMappingException\" ) ) ; lock . countDown ( ) ; } Assert . assertTrue ( exception . getMessage ( ) . contains ( \"JsonParseException\" ) ) ;", "del_tokens": "Assert . assertEquals ( NullPointerException . class , exception . getClass ( ) ) ; public void failure ( ServiceException exception ) { } Assert . assertEquals ( 200 , response . getResponse ( ) . getStatus ( ) ) ; Assert . assertNull ( response . getBody ( ) ) ; lock . countDown ( ) ; Assert . assertTrue ( exception . getMessage ( ) . contains ( \"Expected an int but was STRING\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "rouge", "formatting", "."], "add_tokens": "repo . createCommitStatus ( head , GHCommitState . PENDING , null , message , id ) ;", "del_tokens": "repo . createCommitStatus ( head , GHCommitState . PENDING , null , message , id ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "multiple", "occurences", "of", "task", "name", "in", "fusion", "task", "trace", "name", "."], "add_tokens": "private final String _description ; _description = desc ; return super . map ( _description + FUSION_TRACE_SYMBOL + desc , f ) ; return super . andThen ( _description + FUSION_TRACE_SYMBOL + desc , consumer ) ; return super . recover ( _description + FUSION_TRACE_SYMBOL + desc , f ) ; return super . onFailure ( _description + FUSION_TRACE_SYMBOL + desc , consumer ) ; return super . withTry ( _description + FUSION_TRACE_SYMBOL + desc ) ;", "del_tokens": "return super . map ( getName ( ) + FUSION_TRACE_SYMBOL + desc , f ) ; return super . andThen ( getName ( ) + FUSION_TRACE_SYMBOL + desc , consumer ) ; return super . recover ( getName ( ) + FUSION_TRACE_SYMBOL + desc , f ) ; return super . onFailure ( getName ( ) + FUSION_TRACE_SYMBOL + desc , consumer ) ; return super . withTry ( getName ( ) + FUSION_TRACE_SYMBOL + desc ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "abstract", "class", "instead", "of", "interface", "to", "define", "DownloadCallback"], "add_tokens": "import com . coolerfall . download . DownloadCallback ; . setDownloadCallback ( new Callback ( ) ) private class Callback extends DownloadCallback {", "del_tokens": "import android . os . Environment ; import com . coolerfall . download . DownloadListener ; import com . coolerfall . download . SimpleDownloadListener ; . setDownloadListener ( new Listener ( ) ) private class Listener implements DownloadListener { private class SimpleListener implements SimpleDownloadListener { @ Override public void onSuccess ( int downloadId , String filePath ) { Log . d ( TAG , \"simple download listener sucess\" ) ; } @ Override public void onFailure ( int downloadId , int statusCode , String errMsg ) { Log . d ( TAG , \"simple download listener failt\" ) ; } }", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "searching", "artifacts", "created", "in", "date", "range"], "add_tokens": "import static org . testng . Assert . * ; * @ author rnaegele @ Test public void testArtifactsCreatedSinceSearch ( ) throws IOException { long aWeekAgo = System . currentTimeMillis ( ) - 86400000L * 7 ; List < RepoPath > results = artifactory . searches ( ) . artifactsCreatedSince ( aWeekAgo ) . doSearch ( ) ; assertFalse ( results . isEmpty ( ) ) ; } @ Test public void testArtifactsCreatedInDateRangeSearch ( ) throws IOException { long aWeekAgo = System . currentTimeMillis ( ) - 86400000L * 7 ; long now = System . currentTimeMillis ( ) ; List < RepoPath > results = artifactory . searches ( ) . artifactsCreatedInDateRange ( aWeekAgo , now ) . doSearch ( ) ; assertFalse ( results . isEmpty ( ) ) ; }", "del_tokens": "import static org . testng . Assert . assertEquals ; import static org . testng . Assert . assertTrue ;", "commit_type": "add"}
{"commit_tokens": ["moved", "ReflectionUtil", "and", "made", "it", "package", "protected"], "add_tokens": "package javascalautils . concurrent ; import javascalautils . Failure ; import javascalautils . Success ; import javascalautils . Try ; * Class with utilities for reflective operations . < br > * This class is not intended for public usage , it 's a library internal helper. <br> final class ReflectionUtil { static < T > Try < T > newInstance ( String className ) {", "del_tokens": "package javascalautils ; * Class with utilities for reflective operations . public final class ReflectionUtil { public static < T > Try < T > newInstance ( String className ) {", "commit_type": "move"}
{"commit_tokens": ["adding", "the", "feature", "to", "find", "Android", "avds", "add", "them", "to", "the", "registry", "."], "add_tokens": "import io . selendroid . exceptions . AndroidDeviceException ; import java . io . File ; import org . openqa . selendroid . device . DeviceTargetPlatform ; public String createEmulator ( ) throws AndroidDeviceException ; public boolean isEmulatorAlreadyExistent ( ) throws AndroidDeviceException ; public boolean isEmulatorStarted ( ) throws AndroidDeviceException ; public Abi getAbi ( ) ; public String getAvdName ( ) ; public File getAvdRootFolder ( ) ; public String getScreenSize ( ) ; public DeviceTargetPlatform getTargetPlatform ( ) ;", "del_tokens": "public String createEmulator ( ) ; public boolean isEmulatorAlreadyExistent ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", "and", "code", "indentation", "."], "add_tokens": "static final String [ ] LAUNCHER_RESOURCES = { LAUNCHER_WINDOWS_FILE_NAME , LAUNCHER_WINDOWSCMD_FILE_NAME , LCP_WINDOWS_FILE_NAME , LAUNCHER_UNIX_FILE_NAME } ;", "del_tokens": "static final String [ ] LAUNCHER_RESOURCES = { LAUNCHER_WINDOWS_FILE_NAME , LAUNCHER_WINDOWSCMD_FILE_NAME , LCP_WINDOWS_FILE_NAME , LAUNCHER_UNIX_FILE_NAME } ;", "commit_type": "update"}
{"commit_tokens": ["added", "recording", "call", "state", "switching"], "add_tokens": "public void recordingOn ( ) throws IOException { Map < String , Object > params = new HashMap < String , Object > ( ) ; params . put ( \"recordingEnabled\" , \"true\" ) ; client . getRestDriver ( ) . updateCall ( id , params ) ; JSONObject jsonObject = client . getRestDriver ( ) . requestCallById ( id ) ; updateProperties ( jsonObject , this ) ; } public void recordingOff ( ) throws IOException { Map < String , Object > params = new HashMap < String , Object > ( ) ; params . put ( \"recordingEnabled\" , \"false\" ) ; client . getRestDriver ( ) . updateCall ( id , params ) ; JSONObject jsonObject = client . getRestDriver ( ) . requestCallById ( id ) ; updateProperties ( jsonObject , this ) ; }", "del_tokens": "import com . bandwidth . sdk . bridges . BandwidthBridge ;", "commit_type": "add"}
{"commit_tokens": ["Added", "helper", "class", "to", "handle", "expansion", "functionality", "and", "removing", "this", "burden", "from", "the", "user", ".", "Removed", "ChildObject", "interface", "because", "no", "longer", "needed", "and", "removed", "set", "/", "getStableId", "s", "and", "set", "/", "getIsExpanded", "from", "ParentObject", "interface", ".", "ParentWrapper", "now", "handles", "this", "logic", "along", "with", "stableIds", ".", "Rotation", "now", "handled", "by", "default", "."], "add_tokens": "public class CustomChildObject {", "del_tokens": "import com . ryanbrooks . expandablerecyclerview . Model . ChildObject ; public class CustomChildObject implements ChildObject { @ Override public Object getParentObject ( ) { return mParentObject ; } @ Override public void setParentObject ( Object parentObject ) { mParentObject = parentObject ; }", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "GetGlueCheckIn", "as", "response", "class", "for", "checkins", "."], "add_tokens": "import com . uwetrottmann . getglue . entities . GetGlueCheckIn ; GetGlueCheckIn checkinObject ( GetGlueCheckIn checkinObject (", "del_tokens": "GetGlueObjectResource checkinObject ( GetGlueObjectResource checkinObject (", "commit_type": "use"}
{"commit_tokens": ["use", "system", "properties", "for", "configuration", "if", "no", "other", "properties", "are", "available", "(", "either", "passed", "in", "or", "from", "el", ".", "properties", ")", "and", "System", ".", "getProperty", "(", "javax", ".", "el", ".", "ExpressionFactory", ")", "selects", "JUEL", "s", "factory", "."], "add_tokens": "if ( getClass ( ) . getName ( ) . equals ( properties . getProperty ( \"javax.el.ExpressionFactory\" ) ) ) { if ( getClass ( ) . getName ( ) . equals ( System . getProperty ( \"javax.el.ExpressionFactory\" ) ) ) { return System . getProperties ( ) ; }", "del_tokens": "String clazz = properties . getProperty ( \"javax.el.ExpressionFactory\" ) ; if ( getClass ( ) . getName ( ) . equals ( clazz ) ) {", "commit_type": "use"}
{"commit_tokens": ["Made", "the", "swagger", "resource", "prefix", "configurable", "."], "add_tokens": "import java . nio . ByteBuffer ; if ( cls . isAssignableFrom ( ServerResponse . class ) || cls . isAssignableFrom ( CompletableFuture . class ) || cls . isAssignableFrom ( ByteBuffer . class ) )", "del_tokens": "if ( cls . isAssignableFrom ( ServerResponse . class ) || cls . isAssignableFrom ( CompletableFuture . class ) )", "commit_type": "make"}
{"commit_tokens": ["Made", "public", "the", "means", "to", "acquire", "the", "current", "InetAddress", "."], "add_tokens": "return \"(\" + inetAddress . getHostAddress ( ) + ( port > 0 ? ( \":\" + port + \")\" ) : \"\" ) ;", "del_tokens": "return \"(\" + inetAddress . getHostAddress ( ) + \":\" + port + \")\" ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "bug", "parsing", "array", "query", "params", "when", "only", "one", "item", "present"], "add_tokens": "config . setTypeLoose ( ( typeLooseNode == null ) ? false : typeLooseNode . asBoolean ( ) ) ;", "del_tokens": "config . setTypeLoose ( ( typeLooseNode == null ) ? true : typeLooseNode . asBoolean ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "interface", "name", "to", "snapshot"], "add_tokens": "snapshot . setInterfaceName ( getClass ( ) . getSimpleName ( ) ) ; return snapshot ;", "del_tokens": "return snapshot ;", "commit_type": "add"}
{"commit_tokens": ["Added", "convenience", "factory", "methods", "."], "add_tokens": "import org . jgrapes . io . util . ManagedByteBuffer ; private Write ( DataConnection connection , T buffer , boolean flip ) { super ( connection ) ; this . buffer = buffer ; if ( flip ) { buffer . flip ( ) ; } } this ( connection , buffer , true ) ; return new Write < > ( connection , new ManagedCharBuffer ( data ) , false ) ; } / * * * Convenience method that wraps a byte array in a * { @ code Write < ManagedByteBuffer } event . * * @ param connection the connection to write the data to * @ param data the array to wrap * @ return the event * / public static Write < ManagedByteBuffer > wrap ( DataConnection connection , byte [ ] data ) { return new Write < > ( connection , new ManagedByteBuffer ( data ) , false ) ;", "del_tokens": "super ( connection ) ; this . buffer = buffer ; buffer . flip ( ) ; return new Write < > ( connection , new ManagedCharBuffer ( data ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "order", "by", "in", "columns"], "add_tokens": "final String fileName = httpRequest . getParameter ( \"fileName\" ) ; printResource ( httpResponse . getOutputStream ( ) , \"/css/\" + fileName + \".css\" ) ;", "del_tokens": "printResource ( httpResponse . getOutputStream ( ) , \"/css/bootstrap.css\" ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "missing", "getter", "for", "groupId"], "add_tokens": "private long groupId ; String clientType , LikedBy likedBy , long groupId ) { public long getGroupId ( ) { return groupId ; }", "del_tokens": "String clientType , LikedBy likedBy ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "JUnit", "test", "that", "fails", "with", "Maven", "but", "passes", "in", "my", "IDE", ".", "Strange", "UTF", "-", "8", "issue", "."], "add_tokens": "import java . io . UnsupportedEncodingException ; try { Reader reader = new InputStreamReader ( FixJava . class . getResourceAsStream ( filePath ) , \"UTF-8\" ) ; return readReader ( reader ) ; } catch ( UnsupportedEncodingException e ) { throw new RuntimeException ( e ) ; }", "del_tokens": "Reader reader = new InputStreamReader ( FixJava . class . getResourceAsStream ( filePath ) ) ; return readReader ( reader ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "results", "within", "the", "try", "finally", "."], "add_tokens": "AndroidResults results = new AndroidResults ( cursor , dateAdapter ) ;", "del_tokens": "AndroidResults results = new AndroidResults ( cursor , dateAdapter ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "disabled", "/", "disabled", "ripple", "view"], "add_tokens": "if ( this . isEnabled ( ) && ! animationRunning ) {", "del_tokens": "if ( ! animationRunning ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "ignoring", "numbers", "in", "the", "sql", "names"], "add_tokens": "if ( isFirstChar || Character . isLowerCase ( c ) || Character . isDigit ( c ) ) {", "del_tokens": "if ( isFirstChar || Character . isLowerCase ( c ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "azure", "-", "spring", "-", "boot", "-", "starter"], "add_tokens": "import java . util . concurrent . ExecutionException ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . TimeoutException ;", "del_tokens": "import java . util . concurrent . * ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "Unbounded", "Cache", "to", "Concurrent?HashMap"], "add_tokens": "import java . util . concurrent . ConcurrentHashMap ; public abstract class UnboundedCache < K , V > extends ConcurrentHashMap < K , V > {", "del_tokens": "public abstract class UnboundedCache < K , V > extends HashMap < K , V > {", "commit_type": "change"}
{"commit_tokens": ["Allowed", "filter", "to", "be", "followed", "by", "relative", "path"], "add_tokens": "// Generated from JsonPath.g4 by ANTLR 4.7.2", "del_tokens": "// Generated from JsonPath.g4 by ANTLR 4.7.1", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "the", "nullability", "annotation", "of", "Database", "."], "add_tokens": "@ NotNull", "del_tokens": "@ Nullable", "commit_type": "fix"}
{"commit_tokens": ["Add", "in", "the", "cvec", "dept", "."], "add_tokens": "cm = new ColorMap ( this ) ; private void next ( ) { / * * * Return a cvec big enough . In this implementation , CVecs grow as needed , * so they are always big enough . * @ param nchrs * @ param nranges * @ param nmcess * @ return * / Cvec getcvec ( int nchrs , int nranges , int nmcess ) { if ( cv != null ) { return cv . clearcvec ( ) ; } cv = new Cvec ( nchrs , nranges , nmcess ) ; return cv ;", "del_tokens": "private boolean colored ( Arc a ) { return a . type == PLAIN || a . type == AHEAD || a . type == BEHIND ; private void next ( ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "to", "pass", "directory", "to", "ExecuteBash", ".", "java"], "add_tokens": "import java . io . File ; public static ExecutionResult exec ( File directory , String ... params ) throws IOException , InterruptedException { return exec ( Integer . MAX_VALUE , directory , params ) ; } return exec ( timeout , null , params ) ; } public static ExecutionResult exec ( int timeout , File directory , String ... params ) throws IOException , InterruptedException { ProcessBuilder processBuilder = new ProcessBuilder ( params ) ; if ( directory != null ) { processBuilder . directory ( directory ) ; } return exec ( timeout , processBuilder ) ;", "del_tokens": "return exec ( timeout , new ProcessBuilder ( params ) ) ;", "commit_type": "add"}
{"commit_tokens": ["improved", "test", "with", "a", "meaningful", "example"], "add_tokens": "Integer minimumAge ( ) ; setProperty ( \"minimumAge\" , \"18\" ) ; assertEquals ( Integer . valueOf ( 18 ) , cfg . minimumAge ( ) ) ; setProperty ( \"minimumAge\" , \"21\" ) ; assertEquals ( Integer . valueOf ( 21 ) , cfg . minimumAge ( ) ) ; p . store ( new FileWriter ( target ) , \"reloadable config example\" ) ;", "del_tokens": "Integer someValue ( ) ; setProperty ( \"someValue\" , \"10\" ) ; assertEquals ( Integer . valueOf ( 10 ) , cfg . someValue ( ) ) ; setProperty ( \"someValue\" , \"20\" ) ; assertEquals ( Integer . valueOf ( 20 ) , cfg . someValue ( ) ) ; p . store ( new FileWriter ( target ) , \"foobar\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "debug", "prints", "for", "the", "graphite", "client", "write", "errors"], "add_tokens": "if ( log . isDebugEnabled ( ) ) { log . debug ( \"Failed to write to {}: {}\" , host , future . cause ( ) . toString ( ) ) ; }", "del_tokens": "// Under high load this is spam. Maybe add later... // log.error(\"Failed to write to {}: {}\", host, future.cause().toString());", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "Xbootclasspath", "option", "to", "translator", "and", "changed", "j2objc", ".", "sh", "to", "use", "it"], "add_tokens": "String bootclasspath = Options . getBootClasspath ( ) ; for ( String path : bootclasspath . split ( \":\" ) ) {", "del_tokens": "for ( String path : System . getProperty ( \"sun.boot.class.path\" ) . split ( \":\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["adds", "connection", "pool", "in", "quarkus", "example"], "add_tokens": "private static final Logger log = LoggerFactory . getLogger ( JTAConnectionHolder . class . getName ( ) ) ; protected Connection connection ; if ( connection != null ) { return ; }", "del_tokens": "private static final Logger log = LoggerFactory . getLogger ( DataSetProcessor . class . getName ( ) ) ; Connection connection ;", "commit_type": "add"}
{"commit_tokens": ["Use", "tabs", "from", "design", "library"], "add_tokens": "import android . support . design . widget . TabLayout ; private TabLayout mTabs ; //noinspection ConstantConditions ViewPager viewPager = ( ViewPager ) view . findViewById ( R . id . pager ) ; viewPager . setAdapter ( mViewPagerAdapter ) ; mTabs = ( TabLayout ) view . findViewById ( R . id . tabs ) ; mTabs . post ( new Runnable ( ) { public void run ( ) { mTabs . setTabsFromPagerAdapter ( mViewPagerAdapter ) ; viewPager . addOnPageChangeListener ( new TabLayout . TabLayoutOnPageChangeListener ( mTabs ) ) ; mTabs . setOnTabSelectedListener ( new TabLayout . ViewPagerOnTabSelectedListener ( viewPager ) ) ;", "del_tokens": "import com . evernote . android . demo . view . SlidingTabLayout ; private SlidingTabLayout mTabs ; private ViewPager mViewPager ; mViewPager = ( ViewPager ) view . findViewById ( R . id . pager ) ; mViewPager . setAdapter ( mViewPagerAdapter ) ; mTabs = ( SlidingTabLayout ) view . findViewById ( R . id . tabs ) ; mTabs . setDistributeEvenly ( true ) ; final int toolbarTextColor = getResources ( ) . getColor ( R . color . tb_text ) ; mTabs . setCustomTabColorizer ( new SlidingTabLayout . TabColorizer ( ) { public int getIndicatorColor ( int position ) { return toolbarTextColor ; mTabs . setViewPager ( mViewPager ) ;", "commit_type": "use"}
{"commit_tokens": ["moved", "sql", "API", "to", "sql", "folder"], "add_tokens": "engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/sql/DataFrame.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/sql/DataFrameReader.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/sql/SQLContext.js\" ) + \"');\" ) ;", "del_tokens": "engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/DataFrame.js\" ) + \"');\" ) ; engine . eval ( \"load('\" + getResourceAsURLStirng ( \"/SQLContext.js\" ) + \"');\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Use", "a", "BitSet", "instead", "of", "a", "nested", "arrays"], "add_tokens": "collisionRaster . setPixelIsNotTransparent ( padPoint . x , padPoint . y ) ;", "del_tokens": "// TODO as CollisionRaster changes to use boolean states rgb is not really needed or makes sense for padding // it used to actually changed the buffered image that the word's text is written into. private static final Color PAD_COLOR = Color . BLACK ; collisionRaster . setRGB ( padPoint . x , padPoint . y , PAD_COLOR . getRGB ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "custom", "accent", "to", "the", "sample", "and", "update", "the", "Android", "SDK", "and", "the", "support", "libraries", "."], "add_tokens": "import android . graphics . Color ; import android . support . v7 . app . AppCompatActivity ; public class MainActivity extends AppCompatActivity implements private CheckBox modeCustomAccentTime ; private CheckBox modeCustomAccentDate ; modeCustomAccentTime = ( CheckBox ) findViewById ( R . id . mode_custom_accent_time ) ; modeCustomAccentDate = ( CheckBox ) findViewById ( R . id . mode_custom_accent_date ) ; if ( modeCustomAccentTime . isChecked ( ) ) { tpd . setAccentColor ( Color . parseColor ( \"#9C27B0\" ) ) ; } if ( modeCustomAccentDate . isChecked ( ) ) { dpd . setAccentColor ( Color . parseColor ( \"#9C27B0\" ) ) ; }", "del_tokens": "import android . support . v7 . app . ActionBarActivity ; public class MainActivity extends ActionBarActivity implements @ Override public boolean onCreateOptionsMenu ( Menu menu ) { // Inflate the menu; this adds items to the action bar if it is present. getMenuInflater ( ) . inflate ( R . menu . menu_main , menu ) ; return true ; } @ Override public boolean onOptionsItemSelected ( MenuItem item ) { // Handle action bar item clicks here. The action bar will // automatically handle clicks on the Home/Up button, so long // as you specify a parent activity in AndroidManifest.xml. int id = item . getItemId ( ) ; //noinspection SimplifiableIfStatement if ( id == R . id . action_settings ) { return true ; } return super . onOptionsItemSelected ( item ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "int", "override", "for", "StubBuilder", ".", "willReturn", "()"], "add_tokens": "mockMarket . method ( \"getPrice\" ) . passed ( \"IBM\" ) . willReturn ( 10 ) mockMarket . method ( \"getPrice\" ) . passed ( \"ORCL\" ) . willReturn ( 25 )", "del_tokens": "mockMarket . method ( \"getPrice\" ) . passed ( \"IBM\" ) . willReturn ( new Integer ( 10 ) ) mockMarket . method ( \"getPrice\" ) . passed ( \"ORCL\" ) . willReturn ( new Integer ( 25 ) )", "commit_type": "add"}
{"commit_tokens": ["Moved", "ports", "to", "try", "to", "resolve", "conflicts", "."], "add_tokens": "private static final int DEFAULT_PORT = 5260 ;", "del_tokens": "private static final int DEFAULT_PORT = 5256 ;", "commit_type": "move"}
{"commit_tokens": ["Move", "debug", "logs", "behind", "debug", "check", "so", "it", "saves", "some", "formatting", "and", "variable", "read", "work", "on", "non", "debug", "runs", "."], "add_tokens": "if ( logger . isDebugEnabled ( ) ) { logger . debug ( String . format ( \"Retry %s to send command\" , state . retryCount ) ) ; }", "del_tokens": "logger . debug ( String . format ( \"Retry %s to send command\" , state . retryCount ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "additional", "fields", "to", "the", "error", "response", "."], "add_tokens": "@ JsonPropertyOrder ( { \"requestId\" , \"statusCode\" , \"type\" , \"errorTime\" , \"message\" , \"errorDetail\" , \"stackTrace\" } ) private String requestId ; private String errorTime ; public String getRequestId ( ) { return requestId ; } public void setRequestId ( String requestId ) { this . requestId = requestId ; } public String getErrorTime ( ) { return errorTime ; } public void setErrorTime ( String errorTime ) { this . errorTime = errorTime ; }", "del_tokens": "@ JsonPropertyOrder ( { \"statusCode\" , \"type\" , \"message\" , \"errorDetail\" } )", "commit_type": "add"}
{"commit_tokens": ["Implement", "wrapping", "for", "Objects", "to", "be", "marshalled", "into", "JSON", "."], "add_tokens": "@ Test public void marshal_should_marshal_Object ( ) throws IOException { // Prepare User newUser = new User ( ) ; newUser . setName ( new User . Name ( ) ) ; newUser . getName ( ) . setFirst ( \"Joe\" ) ; newUser . getName ( ) . setLast ( \"Sixpack\" ) ; Object object = newUser ; // Exercise String marshalledUser = cut . marshal ( object ) ; User returnedUser = ( User ) cut . unmarshal ( marshalledUser ) ; // Verify assertNotNull ( returnedUser ) ; assertEquals ( newUser . getName ( ) . getFirst ( ) , returnedUser . getName ( ) . getFirst ( ) ) ; assertEquals ( newUser . getName ( ) . getLast ( ) , returnedUser . getName ( ) . getLast ( ) ) ; } public enum Gender { MALE } private String _first ; private String _last ;", "del_tokens": "public enum Gender { MALE , FEMALE } private String _first , _last ; public boolean isVerified ( ) { return _isVerified ; } public void setVerified ( boolean b ) { _isVerified = b ; } public void setGender ( Gender g ) { _gender = g ; } public void setUserImage ( byte [ ] b ) { _userImage = b ; }", "commit_type": "implement"}
{"commit_tokens": ["Add", "test", "case", "for", "textarea", "getText", "()"], "add_tokens": "import static org . hamcrest . CoreMatchers . equalTo ; import static org . hamcrest . CoreMatchers . is ; import static org . hamcrest . CoreMatchers . nullValue ; import static org . hamcrest . CoreMatchers . sameInstance ; import static org . junit . Assert . assertThat ; import org . openqa . selenium . By ; import org . openqa . selenium . Dimension ; import org . openqa . selenium . ElementNotVisibleException ; import org . openqa . selenium . Keys ; import org . openqa . selenium . OutputType ; import org . openqa . selenium . Point ; import org . openqa . selenium . Rectangle ; import org . openqa . selenium . WebDriver ; import org . openqa . selenium . WebElement ; @ Test @ Ignore public void newline ( ) { driver . get ( testServer . page ( \"htmlunit/newline.html\" ) ) ; assertThat ( driver . findElement ( By . id ( \"textArea1\" ) ) . getText ( ) , equalTo ( \" foo \\n bar\\n test\\n a <p>html snippet</p>\" ) ) ; }", "del_tokens": "import org . openqa . selenium . * ; import static org . hamcrest . CoreMatchers . * ; import static org . junit . Assert . assertThat ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "problem", "displaying", "spaces", "with", "counts", "exceeding", "the", "limits"], "add_tokens": "String countStr = space . getMetadata ( ) . getCount ( ) ; if ( countStr . endsWith ( \"+\" ) ) { } else { space . setItemCount ( Long . valueOf ( space . getMetadata ( ) . getCount ( ) ) ) ;", "del_tokens": "long itemCount = Long . valueOf ( space . getMetadata ( ) . getCount ( ) ) ; if ( itemCount < 1000 ) { space . setItemCount ( itemCount ) ; } else {", "commit_type": "fix"}
{"commit_tokens": ["added", "support", "for", "json", "resource", "bundles"], "add_tokens": "import javax . swing . * ; import java . beans . PropertyChangeEvent ; import java . beans . PropertyChangeListener ; import java . util . * ; import java . util . concurrent . ExecutionException ; \"dataeditor.maximumRowsExceededException.notice\" , \"dataeditor.maximumRowsExceededException.notice\" ,", "del_tokens": "\"MaximumRowsExceededException.notice\" , \"MaximumRowsExceededException.notice\" ,", "commit_type": "add"}
{"commit_tokens": ["Implemented", "all", "status", "list", "methods", "and", "added", "all", "api", "tracing"], "add_tokens": "APITrace . begin ( provider , \"startVM\" ) ; APITrace . begin ( provider , \"calculateVMAnalytics\" ) ; APITrace . begin ( provider , \"enableVMAnalytics\" ) ; APITrace . begin ( provider , \"listFirewallsForVM\" ) ; APITrace . begin ( provider , \"isSubscribedVirtualMachine\" ) ; APITrace . begin ( provider , \"launchVM\" ) ; APITrace . begin ( provider , \"stopVM\" ) ; APITrace . begin ( provider , \"rebootVM\" ) ; APITrace . begin ( provider , \"terminateVM\" ) ; APITrace . begin ( provider , \"disableVMAnalytics\" ) ;", "del_tokens": "APITrace . begin ( provider , \"start\" ) ; APITrace . begin ( provider , \"calculate\" ) ; APITrace . begin ( provider , \"enableAnalytics\" ) ; APITrace . begin ( provider , \"listFirewalls\" ) ; APITrace . begin ( provider , \"isSubscribed\" ) ; APITrace . begin ( provider , \"launch\" ) ; APITrace . begin ( provider , \"stop\" ) ; APITrace . begin ( provider , \"reboot\" ) ; APITrace . begin ( provider , \"terminate\" ) ; APITrace . begin ( provider , \"disableAnalytics\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Move", "application", "of", "IndirectedDelayedExecutor", "to", "Engine", "build", "time"], "add_tokens": "_timerScheduler = timerScheduler ; new IndirectDelayedExecutor ( _timerScheduler ) ,", "del_tokens": "_timerScheduler = new IndirectDelayedExecutor ( timerScheduler ) ; _timerScheduler ,", "commit_type": "move"}
{"commit_tokens": ["Add", "UnicodeChar", "()", "to", "BaseParser", ";", "improve", "documentation"], "add_tokens": "import org . parboiled . BaseParser ; * < p > A { @ code char } in Java being a UTF - 16 code unit , Java needs two { @ code * char } s to represent such a code point ; therefore a simple { @ link * CharMatcher } cannot do the job . < / p > * / * * * Constructor * * < p > Note that at this point , the validity of the code point is already * checked ! < / p > * * @ param codePoint the code point * @ see BaseParser # UnicodeChar ( int ) * / super ( String . format ( \"U+%X\" , codePoint ) ) ;", "del_tokens": "super ( getLabel ( codePoint ) ) ; private static String getLabel ( final int codePoint ) { if ( ! Character . isValidCodePoint ( codePoint ) ) throw new IllegalArgumentException ( \"invalid code point \" + codePoint ) ; return String . format ( \"U+%X\" , codePoint ) ; }", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "clientId", "a", "persistant", "property", "rather", "than", "an", "argument", "to", "verify", "()"], "add_tokens": "public YubicoResponse verify ( String otp ) ; public void setClientId ( Integer id ) ; public Integer getClientId ( ) ;", "del_tokens": "public YubicoResponse verify ( Integer id , String otp ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "some", "unit", "tests", ".", "They", "re", "not", "much", "but", "it", "s", "a", "start", ".", "In", "future", "there", "should", "be", "unit", "tests", "for", "all", "code", "changes", "where", "practical", "."], "add_tokens": "public static Point projectGeoPoint ( final GeoPoint aGeoPoint , final int aZoom , final Point aUseAsReturnValue ) { final Point p = ( aUseAsReturnValue != null ) ? aUseAsReturnValue : new Point ( ) ;", "del_tokens": "public static Point projectGeoPoint ( final GeoPoint aGeoPoint , final int aZoom , Point aUseAsReturnValue ) { Point p = ( aUseAsReturnValue != null ) ? aUseAsReturnValue : new Point ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Joda", "Time", "."], "add_tokens": "InstantiatorRegistry instantiatorRegistry = getInstantiatorRegistry ( ) ; ps . setObject ( i ++ , instantiatorRegistry . valueToDatabase ( arg ) ) ;", "del_tokens": "Dialect provider = getDialect ( ps . getConnection ( ) ) ; ps . setObject ( i ++ , provider . valueToDatabase ( arg ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "license", "and", "copyright", "headers"], "add_tokens": "// Copyright (c) 2013, Facebook, Inc. All rights reserved. / * * * Licensed to the Apache Software Foundation ( ASF ) under one * or more contributor license agreements . See the NOTICE file * distributed with this work for additional information * regarding copyright ownership . The ASF licenses this file * to you under the Apache License , Version 2.0 ( the * \"License\" ) ; you may not use this file except in compliance * with the License . You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / package com . facebook . hive . orc . lazy ;", "del_tokens": "package com . facebook . hive . orc . lazy ;", "commit_type": "add"}
{"commit_tokens": ["adding", "1", "offset", "to", "history", "to", "avoid", "misleading", "data", "to", "be", "shown"], "add_tokens": "out . println ( String . format ( \"[%3d] %s\" , entry . index ( ) + 1 , entry . value ( ) ) ) ;", "del_tokens": "out . println ( String . format ( \"[%3d] %s\" , entry . index ( ) , entry . value ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "JobBundleTest", "merge", "error", "."], "add_tokens": "MetricRegistry registry = SharedMetricRegistries . getOrCreate ( \"dropwizard-jobs\" ) ;", "del_tokens": "MetricRegistry registry = SharedMetricRegistries . getOrCreate ( \"dropwizard-jobs\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "typo", ";", "make", "it", "less", "likely", "to", "happen", "again", "."], "add_tokens": "final OutputStream compressedOut = new BlockCompressedOutputStream ( output ) ; binaryCodec = new BinaryCodec ( compressedOut ) ; recordCodec . setOutputStream ( compressedOut ) ;", "del_tokens": "final OutputStream out = new BlockCompressedOutputStream ( output ) ; binaryCodec = new BinaryCodec ( output ) ; recordCodec . setOutputStream ( out ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "crash", "when", "stopping", "device", "finder", "."], "add_tokens": "final Set < DeviceAnnouncement > lastDevices = currentDevices ( ) ; for ( DeviceAnnouncement announcement : lastDevices ) {", "del_tokens": "for ( DeviceAnnouncement announcement : currentDevices ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "timeout", "and", "javadocs", "."], "add_tokens": "/ * * Calls { @ link # connect ( int , InetAddress , int , int ) connect } with the values last passed to connect . / * * Calls { @ link # connect ( int , InetAddress , int , int ) connect } with the specified timeout and the other values last passed to connect ( timeout , connectHost , connectTcpPort , connectUdpPort ) ;", "del_tokens": "/ * * Calls { @ link # connect ( int , InetAddress , int ) connect } with the values last passed to connect . / * * Calls { @ link # connect ( int , InetAddress , int ) connect } with the specified timeout and the other values last passed to connect ( connectTimeout , connectHost , connectTcpPort , connectUdpPort ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "/", "hystrix", ".", "stream", "has", "the", "correct", "path"], "add_tokens": "import org . springframework . boot . autoconfigure . condition . ConditionalOnWebApplication ; @ Configuration @ ConditionalOnExpression ( \"${hystrix.stream.endpoint.enabled:true}\" ) @ ConditionalOnWebApplication protected static class HystrixWebConfiguration { @ Bean public HystrixStreamEndpoint hystrixStreamEndpoint ( ) { return new HystrixStreamEndpoint ( ) ; } @ Autowired ( required = false ) if ( gauges == null ) { return ; } return poller != null ? poller . isRunning ( ) : false ; * { @ link DisposableBean } that makes sure that Hystrix internal state is cleared when * { @ link ApplicationContext } shuts down .", "del_tokens": "@ Bean @ ConditionalOnExpression ( \"${hystrix.stream.endpoint.enabled:true}\" ) // TODO: make it @ConditionalOnWebApp (need a nested class) public HystrixStreamEndpoint hystrixStreamEndpoint ( ) { return new HystrixStreamEndpoint ( ) ; @ Autowired return poller != null ? poller . isRunning ( ) : false ; * { @ link DisposableBean } that makes sure that Hystrix internal state is cleared * when { @ link ApplicationContext } shuts down .", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "fluent", "builder", "to", "create", "http", "commands"], "add_tokens": "final class AsyncHttpCommand < T > extends HystrixCommand < T > { AsyncHttpCommand ( final Setter setter ,", "del_tokens": "public final class AsyncHttpCommand < T > extends HystrixCommand < T > { public AsyncHttpCommand ( final HystrixCommandGroupKey commandGroup , final AsyncHandler < T > asyncHandler , final AsyncHttpClient . BoundRequestBuilder requestBuilder , final int timeout , final TimeUnit timeUnit ) { this ( Setter . withGroupKey ( commandGroup ) , asyncHandler , requestBuilder , timeout , timeUnit ) ; } public AsyncHttpCommand ( final Setter setter ,", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "failing", "a", "chunk", "or", "keyframe", "would", "crash", "GameUpdateTask"], "add_tokens": "pool . schedule ( ( ) -> task . run ( ) , 0 , TimeUnit . MILLISECONDS ) ;", "del_tokens": "pool . schedule ( ( ) -> task . run ( ) , 10 , TimeUnit . MILLISECONDS ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "additional", "response", "type", "when", "post", "response", "have", "not", "errored", "out"], "add_tokens": "import com . plaid . client . exception . PlaidServersideUnknownResponseException ; import com . plaid . client . response . UnknownResponse ; @ Override @ Override HttpEntity responseEntity = response . getEntity ( ) ; EntityUtils . consume ( responseEntity ) ; T responseBody = jsonMapper . convertValue ( jsonBody , clazz ) ; MfaResponse mfaResponse = jsonMapper . convertValue ( jsonBody , MfaResponse . class ) ; UnknownResponse unknownResponse = jsonMapper . convertValue ( jsonBody , UnknownResponse . class ) ; throw new PlaidServersideUnknownResponseException ( unknownResponse , statusCode ) ; throw new PlaidCommunicationsException ( \"Unable to interpret Plaid response\" , e ) ;", "del_tokens": "HttpEntity responseEntity = response . getEntity ( ) ; EntityUtils . consume ( responseEntity ) ; T responseBody = jsonMapper . convertValue ( jsonBody , clazz ) ; MfaResponse mfaResponse = jsonMapper . convertValue ( jsonBody , MfaResponse . class ) ; throw new PlaidCommunicationsException ( \"Unable to interpret Plaid response\" ) ; throw new PlaidCommunicationsException ( \"Unable to interpret Plaid response\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "support", "for", "Struts", "Convention", "Plugin"], "add_tokens": "package es . cenobit . struts2 . json . osgi ; * < b > Support for OSGi < / b > return actionConfigBuilder . needsReload ( ) ;", "del_tokens": "package es . cenobit . struts2 . osgi . convention ; * < b > Support for OSGi and Convention integration < / b > private PackageProvider packageProviderOSGi ; this . packageProviderOSGi = container . getInstance ( PackageProvider . class , JsonConstants . CONVENTION_PACKAGE_PROVIDER_CLASS ) ; if ( packageProviderOSGi != null ) { packageProviderOSGi . init ( configuration ) ; } boolean isNeedsReload = false ; if ( packageProviderOSGi != null ) { isNeedsReload = isNeedsReload || packageProviderOSGi . needsReload ( ) ; } return isNeedsReload || actionConfigBuilder . needsReload ( ) ; if ( packageProviderOSGi != null ) { packageProviderOSGi . loadPackages ( ) ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "unit", "test", "for", "SimpleNameSubstitutionStrategy", "caching"], "add_tokens": "private long deflateCalls ; private long deflateCacheMisses ; private List < InflateItem > inflateSubstitutionList = new ArrayList < > ( ) ; private long inflateCalls ; private long inflateCacheMisses ; deflateCalls ++ ; inflateCalls ++ ; public long getDeflateCalls ( ) { return deflateCalls ; } public long getDeflateCacheMisses ( ) { return deflateCacheMisses ; } public long getInflateCalls ( ) { return inflateCalls ; } public long getInflateCacheMisses ( ) { return inflateCacheMisses ; } inflateCacheMisses ++ ; deflateCacheMisses ++ ;", "del_tokens": "private List < InflateItem > inflateSubstitutionList = new ArrayList < > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "proper", "dispose", "methods", "in", "all", "skins"], "add_tokens": "titleText . setFill ( tile . getTitleColor ( ) ) ; Helper . enableNode ( titleText , ! tile . getTitle ( ) . isEmpty ( ) ) ; chart . getData ( ) . addAll ( tile . getSeries ( ) ) ; titleText . setText ( tile . getTitle ( ) ) ; titleText . setFill ( tile . getTitleColor ( ) ) ;", "del_tokens": "titleText . setFill ( getSkinnable ( ) . getTitleColor ( ) ) ; Helper . enableNode ( titleText , ! getSkinnable ( ) . getTitle ( ) . isEmpty ( ) ) ; chart . getData ( ) . addAll ( getSkinnable ( ) . getSeries ( ) ) ; titleText . setText ( getSkinnable ( ) . getTitle ( ) ) ; titleText . setFill ( getSkinnable ( ) . getTitleColor ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Make", "some", "internal", "methods", "private"], "add_tokens": "private static IAnnotationBinding getAnnotationBinding ( private static Object getAnnotationValue ( IAnnotationBinding annotation , String varName ) { private static String getEnumAnnotationFieldName ( IAnnotationBinding annotation , String varName ) { private static CaptureStyle getAnnotationCaptureStyleValue ( private static Locale getAnnotationLocaleValue (", "del_tokens": "public static IAnnotationBinding getAnnotationBinding ( public static Object getAnnotationValue ( IAnnotationBinding annotation , String varName ) { public static String getEnumAnnotationFieldName ( IAnnotationBinding annotation , String varName ) { public static CaptureStyle getAnnotationCaptureStyleValue ( public static Locale getAnnotationLocaleValue (", "commit_type": "make"}
{"commit_tokens": ["Allow", "user", "to", "append", "additional", "info", "to", "User", "-", "Agent"], "add_tokens": "context . put ( QSConstant . PARAM_KEY_USER_AGENT , evnContext . getAdditionalUserAgent ( ) ) ; context . put ( QSConstant . PARAM_KEY_USER_AGENT , evnContext . getAdditionalUserAgent ( ) ) ; if ( context . get ( QSConstant . PARAM_KEY_USER_AGENT ) != null ) { paramsHeaders . put ( QSConstant . PARAM_KEY_USER_AGENT , context . get ( QSConstant . PARAM_KEY_USER_AGENT ) ) ; }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["update", "PageHelper", ":", "adding", "useful", "info", "in", "debug", "logs"], "add_tokens": "* @ see WebDriverWait # until ( com . google . common . base . Function ) * @ throws TimeoutException if the timeout expires public static void waitUntil ( ExpectedCondition < ? > expectedCondition , WebDriver driver , long timeOutInSeconds ) { logger . debug ( \"BEGIN Explicit wait (timeout=\" + timeOutInSeconds + \"s). \" + \"Waiting until \" + expectedCondition ) ; String url = ; driver . get ( url ) ; logger . debug ( \"Page at URL \" + url + \" loaded\" ) ;", "del_tokens": "public static void waitUntil ( ExpectedCondition < ? > expectedCondition , WebDriver driver , long timeOutInSeconds ) { logger . debug ( \"BEGIN Explicit wait: waiting until \" + expectedCondition ) ; driver . get ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "transaction", "detail", "(", "Hide", "unknown", "fields", ")"], "add_tokens": "import org . apache . commons . lang3 . StringUtils ; ViewHolder . get ( v , R . id . row_transaction_country ) . setVisibility ( View . VISIBLE ) ; ViewHolder . get ( v , R . id . row_transaction_country ) . setVisibility ( View . GONE ) ; // Transaction cryptogram if ( StringUtils . isNotBlank ( transaction . getCyptogramData ( ) ) ) { ViewHolder . get ( v , R . id . row_transaction_crypto ) . setVisibility ( View . VISIBLE ) ; cryptogram . setText ( transaction . getCyptogramData ( ) ) ; } else { ViewHolder . get ( v , R . id . row_transaction_crypto ) . setVisibility ( View . GONE ) ; } ViewHolder . get ( v , R . id . row_transaction_type ) . setVisibility ( View . VISIBLE ) ; ViewHolder . get ( v , R . id . row_transaction_type ) . setVisibility ( View . GONE ) ;", "del_tokens": "country . setText ( parent . getContext ( ) . getString ( R . string . transaction_unknown ) ) ; cryptogram . setText ( transaction . getCyptogramData ( ) ) ; type . setText ( parent . getContext ( ) . getString ( R . string . transaction_unknown ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "output", "and", "adding", "ability", "to", "set", "min", "cell", "width", "and", "number", "formatter"], "add_tokens": "private DecimalFormat normalNumberFormatter = new DecimalFormat ( \"0.000\" ) ; public void setMinCellWidth ( int cellWidth ) { this . longestCell = cellWidth ; } public void setNumberFormatter ( @ NonNull DecimalFormat decimalFormat ) { this . normalNumberFormatter = decimalFormat ; } return Math . max ( 5 , Math . min ( longNumberFormatter . format ( number ) . length ( ) , normalNumberFormatter . format ( number ) . length ( ) ) ) ;", "del_tokens": "private static final DecimalFormat normalNumberFormatter = new DecimalFormat ( \"0.000#####\" ) ; private double maxNumber ; this . maxNumber = 0 ; return Math . min ( longNumberFormatter . format ( number ) . length ( ) , normalNumberFormatter . format ( number ) . length ( ) ) ; maxNumber = Math . pow ( 10 , longestCell - 2 ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "version", "of", "the", "working", "memory", "logger"], "add_tokens": "if ( memento != null ) { logFileName = memento . getString ( LOG_FILE_NAME ) ; }", "del_tokens": "logFileName = memento . getString ( LOG_FILE_NAME ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "test", "for", "aggregated", "multi", "-", "sample", "gauge", "measurements"], "add_tokens": "import java . util . HashMap ; private Map < String , Object > metricAttributes = new HashMap < String , Object > ( ) ;", "del_tokens": "private Map < String , Object > metricAttributes ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "use", "API", "-", "Common", "component", "for", "HTTPClient", "functionality"], "add_tokens": "import com . moviejukebox . api . common . http . CommonHttpClient ; import com . omertron . thetvdbapi . tools . DOMHelper ; private CommonHttpClient httpClient ; / * * * Create an API object with the passed API Key * * @ param apiKey Must not be null or empty * / this ( apiKey , null ) ; } / * * * Create an API object with the passed API key and using the supplied HttpClient * * @ param apiKey Must not be null or empty * @ param httpClient * / public TheTVDBApi ( String apiKey , CommonHttpClient httpClient ) { if ( StringUtils . isBlank ( apiKey ) ) { this . httpClient = httpClient ; DOMHelper . setHttpClient ( this . httpClient ) ; // should be set in HTTP client already if ( httpClient != null ) { return ; } // should be set in HTTP client already if ( httpClient != null ) { return ; }", "del_tokens": "if ( apiKey == null ) {", "commit_type": "update"}
{"commit_tokens": ["fix", "infinite", "loop", "bug", "with", "resource", "file", "extractor", "when", "files", "with", "same", "name", "generated"], "add_tokens": "while ( writtenFileNames . contains ( usedName ) ) { i ++ ; }", "del_tokens": "while ( writtenFileNames . contains ( usedName ) )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "handling", "creating", "a", "segment", "that", "already", "exists", "."], "add_tokens": "return new SegmentAlreadyExists ( segment ) ;", "del_tokens": "return new NoSuchSegment ( segment ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "ability", "to", "change", "blending"], "add_tokens": "rayHandler . diffuseBlendFunc . apply ( ) ; rayHandler . shadowBlendFunc . apply ( ) ; rayHandler . simpleBlendFunc . apply ( ) ;", "del_tokens": "RayHandler . diffuseBlendFunc . apply ( ) ; Gdx . gl20 . glBlendFunc ( GL20 . GL_ONE , GL20 . GL_ONE_MINUS_SRC_ALPHA ) ; Gdx . gl . glBlendFunc ( GL20 . GL_SRC_ALPHA , GL20 . GL_ONE ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "previously", "deprecated", "and", "now", "unused", "exceptions"], "add_tokens": "final String dashboardDomain = /*@\"dashboard.clevertap.com\"*/ \"6fde0c32.ngrok.io\" ; // TODO put final production dashboard link", "del_tokens": "final String dashboardDomain = /*@\"dashboard.clevertap.com\"*/ \"43764d4a.ngrok.io\" ; // TODO put final production dashboard link", "commit_type": "remove"}
{"commit_tokens": ["Use", "alpha", "to", "show", "/", "hide", "picker", "view", "instead", "of", "visibility", "in", "DatePickerDialog", "class", "."], "add_tokens": "import android . support . v4 . internal . view . SupportMenu ;", "del_tokens": "import com . rey . material . app . Dialog ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "to", "pack", "multiple", "entries"], "add_tokens": "public void testPackEntry ( ) throws Exception { public void testPackEntries ( ) throws Exception { File fileToPack = new File ( getClass ( ) . getResource ( \"TestFile.txt\" ) . getPath ( ) ) ; File fileToPackII = new File ( getClass ( ) . getResource ( \"TestFile-II.txt\" ) . getPath ( ) ) ; File dest = File . createTempFile ( \"temp\" , null ) ; ZipUtil . packEntries ( new File [ ] { fileToPack , fileToPackII } , dest ) ; assertTrue ( dest . exists ( ) ) ; ZipUtil . explode ( dest ) ; assertTrue ( ( new File ( dest , \"TestFile.txt\" ) ) . exists ( ) ) ; assertTrue ( ( new File ( dest , \"TestFile-II.txt\" ) ) . exists ( ) ) ; // if fails then maybe somebody changed the file contents and did not update // the test assertEquals ( 108 , ( new File ( dest , \"TestFile.txt\" ) ) . length ( ) ) ; assertEquals ( 103 , ( new File ( dest , \"TestFile-II.txt\" ) ) . length ( ) ) ; }", "del_tokens": "public void testPackFile ( ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "unique_filename", "and", "added", "a", "test", "for", "use_filename"], "add_tokens": "static final String [ ] BOOLEAN_UPLOAD_OPTIONS = new String [ ] { \"backup\" , \"exif\" , \"faces\" , \"colors\" , \"image_metadata\" , \"use_filename\" , \"unique_filename\" , \"eager_async\" , \"invalidate\" } ;", "del_tokens": "static final String [ ] BOOLEAN_UPLOAD_OPTIONS = new String [ ] { \"backup\" , \"exif\" , \"faces\" , \"colors\" , \"image_metadata\" , \"use_filename\" , \"eager_async\" , \"invalidate\" } ;", "commit_type": "add"}
{"commit_tokens": ["improve", "error", "reporting", "for", "functional", "tests"], "add_tokens": "//execute action", "del_tokens": "//execute controller", "commit_type": "improve"}
{"commit_tokens": ["Allow", "parsing", "and", "generation", "failures", "to", "fail", "the", "build", "."], "add_tokens": "throw new RuntimeException ( \"Failed to create model controller client\" , e ) ; Config config = Config . fromJson ( args [ 0 ] ) ; Generator generator = new Generator ( args [ 1 ] , config ) ; } finally {", "del_tokens": "log . log ( Level . ERROR , \"Failed to create model controller client\" , e ) ; Config config = Config . fromJson ( args [ 0 ] ) ; Generator generator = new Generator ( args [ 1 ] , config ) ; } catch ( Throwable e ) { System . exit ( - 1 ) ; log . log ( Level . ERROR , \"Unexpected error\" , e ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "URL", "-", "encoded", "form", "parameters"], "add_tokens": "import com . github . paweladamski . httpclientmock . condition . UrlEncodedFormCondition ; import com . github . paweladamski . httpclientmock . matchers . MatchersMap ; private final UrlEncodedFormCondition formParametersCondition = new UrlEncodedFormCondition ( ) ; this ( method ) ; addCondition ( formParametersCondition ) ; void addFormParameterCondition ( String name , Matcher < String > matcher ) { formParametersCondition . addExpectedParameter ( name , matcher ) ; } void addFormParameterConditions ( MatchersMap < String , String > parameters ) { formParametersCondition . addExpectedParameters ( parameters ) ; }", "del_tokens": "addCondition ( new HttpMethodCondition ( method ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "maven", "plugin", "for", "Excel", "test", "doc", "generation"], "add_tokens": "public static List < File > getTestFiles ( final String startDir ) { final List < File > files = new ArrayList < File > ( ) ; files . add ( found [ i ] ) ;", "del_tokens": "public static List < String > getTestFiles ( final String startDir ) { final List < String > files = new ArrayList < String > ( ) ; files . add ( file . getPath ( ) . substring ( startDir . length ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["uses", "android", "base64", "for", "auth"], "add_tokens": "import android . util . Base64 ; this . authString = \"Basic \" + Base64 . encodeToString ( ( this . username + \":\" + this . password ) . getBytes ( ) , Base64 . DEFAULT ) ;", "del_tokens": "import java . net . Authenticator ; import java . net . PasswordAuthentication ; import javax . xml . bind . DatatypeConverter ; this . authString = \"Basic \" + DatatypeConverter . printBase64Binary ( ( this . username + \":\" + this . password ) . getBytes ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "new", "event", "and", "fixed", "some", "bugs", "."], "add_tokens": "import de . btobastian . javacord . api . listener . UserChangeNameListener ; private final List < UserChangeNameListener > userChangeNameListeners = new ArrayList < > ( ) ; } else if ( listener instanceof UserChangeNameListener ) { userChangeNameListeners . add ( ( UserChangeNameListener ) listener ) ; response = getRequestUtils ( ) . getFromWebsite ( \"https://discordapp.com/api/users/@me/guilds\" , \"authorization\" , token ) ; //response = getRequestUtils().request(\"https://discordapp.com/api/users/@me/guilds\", \"\", true, \"GET\"); e . printStackTrace ( ) ; protected List < UserChangeNameListener > getUserChangeNameListeners ( ) { return userChangeNameListeners ; }", "del_tokens": "response = getRequestUtils ( ) . request ( \"https://discordapp.com/api/users/@me/guilds\" , \"\" , true , \"GET\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "checks", "to", "add", "and", "remove", "atom"], "add_tokens": "import static com . google . common . base . Preconditions . checkNotNull ; private final List < QueryAtom > atoms = new LinkedList < QueryAtom > ( ) ; atoms . add ( checkNotNull ( atom ) ) ; return atoms . remove ( checkNotNull ( atom ) ) ;", "del_tokens": "private List < QueryAtom > atoms ; atoms = new LinkedList < QueryAtom > ( ) ; atoms . add ( atom ) ; return atoms . remove ( atom ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "maxBy", "()", "minBy", "()", "minmaxBy", "()", "to", "RubyArray"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["remove", "sidecar", "as", "a", "toplevel", "project", "(", "doesn", "t", "make", "sense", "since", "consul", "IS", "a", "sidecar", ")", "."], "add_tokens": "// TODO: fix this set client hack @ SuppressWarnings ( \"unchecked\" ) DynamicServerListLoadBalancer < ConsulServer > dynamic = ( DynamicServerListLoadBalancer < ConsulServer > ) balancer ; ServerList < ConsulServer > list = dynamic . getServerListImpl ( ) ; if ( list instanceof ConsulServerList ) { ConsulServerList csl = ( ConsulServerList ) list ; csl . setClient ( client ) ; }", "del_tokens": "@ SuppressWarnings ( \"unchecked\" ) DynamicServerListLoadBalancer < ConsulServer > dynamic = ( DynamicServerListLoadBalancer < ConsulServer > ) balancer ; ServerList < ConsulServer > list = dynamic . getServerListImpl ( ) ; if ( list instanceof ConsulServerList ) { ConsulServerList csl = ( ConsulServerList ) list ; csl . setClient ( client ) ; }", "commit_type": "remove"}
{"commit_tokens": ["use", "CAS", "error", "page", "and", "add", "confirm", "page"], "add_tokens": "return new ModelAndView ( OAuthConstants . ERROR_VIEW ) ; return new ModelAndView ( OAuthConstants . ERROR_VIEW ) ; return new ModelAndView ( OAuthConstants . ERROR_VIEW ) ; return new ModelAndView ( OAuthConstants . ERROR_VIEW ) ; session . setAttribute ( OAuthConstants . OAUTH20_SERVICE_NAME , service . getTheme ( ) ) ;", "del_tokens": "return OAuthUtils . writeTextError ( response , OAuthConstants . INVALID_REQUEST , 200 ) ; return OAuthUtils . writeTextError ( response , OAuthConstants . INVALID_REQUEST , 200 ) ; return OAuthUtils . writeTextError ( response , OAuthConstants . INVALID_REQUEST , 200 ) ; return OAuthUtils . writeTextError ( response , OAuthConstants . INVALID_REQUEST , 200 ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "original", "filename", "and", "mimetype", "to", "filestore", "ID"], "add_tokens": "import javax . activation . MimeType ; import javax . activation . MimeTypeParseException ; private String originalName ; private MimeType mimeType ; public String getOriginalName ( ) { return this . originalName ; } public void setOriginalName ( String s ) { this . originalName = s ; } public MimeType getMimeType ( ) { return this . mimeType ; } public void setMimeType ( MimeType m ) { this . mimeType = m ; } public void setMimeType ( String s ) throws MimeTypeParseException { this . mimeType = new MimeType ( s ) ; } public String toString ( ) { StringBuilder o = new StringBuilder ( ) ; o . append ( host ) ; o . append ( \":\" ) ; o . append ( name ) ; o . append ( \" (\" ) ; o . append ( originalName ) ; if ( mimeType != null ) o . append ( \":\" ) . append ( mimeType . getBaseType ( ) ) ; o . append ( \")\" ) ; return o . toString ( ) ; }", "del_tokens": "public String toString ( ) { return host + \":\" + name ; }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "implicit", "merge", "conflict", "of", "Light", "re", "-", "factoring", "and", "ChainLight"], "add_tokens": "segments [ size ++ ] = zeroColorBits ; @ Override public void setDistance ( float dist ) { dist *= RayHandler . gammaCorrectionParameter ; this . distance = dist < 0.01f ? 0.01f : dist ; if ( staticLight ) staticUpdate ( ) ; }", "del_tokens": "segments [ size ++ ] = zero ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "the", "IFragmentRequestProcessor", "interface", "such", "that", "such", "processors", "can", "be", "used", "for", "multiple", "requests", "now", "and", "separated", "out", "Jena", "-", "specific", "code", "from", "the", "base", "class", "for", "such", "processors"], "add_tokens": "import org . linkeddatafragments . fragments . LinkedDataFragmentRequest ; * Processes { @ link LinkedDataFragmentRequest } s and returns * the requested { @ link LinkedDataFragment } s . LinkedDataFragment createRequestedFragment ( final LinkedDataFragmentRequest request ) throws IllegalArgumentException ;", "del_tokens": "* Processes a single request sent to a Linked Data Fragments interface . LinkedDataFragment createRequestedFragment ( ) ;", "commit_type": "change"}
{"commit_tokens": ["move", "prober", "utility", "to", "core"], "add_tokens": "package org . robotninjas . barge . utils ;", "del_tokens": "package org . robotninjas . barge ;", "commit_type": "move"}
{"commit_tokens": ["Added", "support", "for", "Web", "Service", "call", "with", "JAX", "-", "WS"], "add_tokens": "/ * * * A Service Agent is a Web Service representation in TIBCO BusinessWorks . * This Service Agent will be started when the BusinessWorks engine starts . * / protected ServiceAgentInEngine2 < ? , ? > serviceAgent2 ; if ( serviceAgent != null ) { return serviceAgent . isStarted ( ) ; } else if ( serviceAgent2 != null ) { return serviceAgent2 . isStarted ( ) ; } else { return false ; } // return (serviceAgent == null) ? false : serviceAgent.isStarted(); } else if ( serviceAgent2 != null ) { serviceAgent2 . stopEngine ( ) ;", "del_tokens": "return ( serviceAgent == null ) ? false : serviceAgent . isStarted ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "allow", "arguments", "to", "constructors"], "add_tokens": "for ( Constructor constructor : parserClass . getConstructors ( ) ) Class [ ] parameterTypes = constructor . getParameterTypes ( ) ; if ( parameterTypes . length == args . length ) { boolean match = true ; int index = 0 ; for ( Class c : parameterTypes ) { if ( ! c . isAssignableFrom ( args [ index ++ ] . getClass ( ) ) ) { match = false ; break ; } } if ( match ) { return constructor . newInstance ( args ) ; } } throw new IllegalArgumentException ( \"no required constructor for \" + cls ) ; catch ( InstantiationException | IllegalAccessException | SecurityException | IllegalArgumentException | InvocationTargetException ex )", "del_tokens": "Class < ? > [ ] types = new Class < ? > [ args . length ] ; int index = 0 ; for ( Object o : args ) types [ index ++ ] = o . getClass ( ) ; Constructor < ? > constructor = parserClass . getConstructor ( types ) ; return constructor . newInstance ( args ) ; catch ( InstantiationException | IllegalAccessException | NoSuchMethodException | SecurityException | IllegalArgumentException | InvocationTargetException ex )", "commit_type": "change"}
{"commit_tokens": ["Add", "T", "getEntry", "(", "long", "sequence", ")", "to", "the", "Barrier", "interface", "."], "add_tokens": "entry = barrier . getEntry ( i ) ;", "del_tokens": "entry = barrier . getRingBuffer ( ) . getEntry ( i ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "storeFence", "for", "solaris", "test"], "add_tokens": "@ SuppressWarnings ( \"restriction\" ) UnsafeAccess . unsafe ( ) . storeFence ( ) ;", "del_tokens": "// UnsafeAccess.unsafe().storeFence();", "commit_type": "use"}
{"commit_tokens": ["Add", "missing", "test", "coverage", "and", "fix", "a", "couple", "segmenting", "and", "serialization"], "add_tokens": "assertDispatchedJson ( payloadJson ( \"{\\\"IngredientWithRepeatableCompoundOptional\\\":{\\\"compoundOptional\\\":[{\\\"param1\\\":5,\\\"param2\\\":false},{\\\"param1\\\":-2,\\\"param2\\\":true}]}}\" ) ) ; assertDispatchedJson ( \"{\\\"recipe\\\":{\\\"Recipe\\\":{\\\"contextIngredient\\\":{\\\"KeyedTestIngredient\\\":{}},\\\"ingredients\\\":[{\\\"EmptyIngredient\\\":{}}]}},\\\"cake\\\":{}}\" ) ;", "del_tokens": "assertDispatchedJson ( payloadJson ( \"{\\\"IngredientWithRepeatableCompoundOptional\\\":{\\\"compoundOptional\\\":{\\\"param1\\\":[5,-2],\\\"param2\\\":[false,true]}}}\" ) ) ; assertDispatchedJson ( \"{\\\"recipe\\\":{\\\"Recipe\\\":{\\\"contextIngredient\\\":{\\\"KeyedTestIngredient\\\":{\\\"key\\\":null}},\\\"ingredients\\\":[{\\\"EmptyIngredient\\\":{}}]}},\\\"cake\\\":{}}\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", "I", "had", "forgotten", "to", "adapt", "(", "DUH", ")"], "add_tokens": "Assert . assertEquals ( pkPersonalization . getRequiredPersonalizationFields ( ) . size ( ) , 2 ) ;", "del_tokens": "Assert . assertEquals ( pkPersonalization . getRequiredPersonalizationFields ( ) . size ( ) , 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "suggest", "from", "searchLog", "."], "add_tokens": "public static void writeJsonResponse ( final int status , final String body , final String errMsg ) { protected static String escapeCallbackName ( final String callbackName ) { protected static String escapeJson ( final Object obj ) { protected static String escapeJsonString ( final String str ) { private static String hex ( final char ch ) {", "del_tokens": "protected void writeJsonResponse ( final int status , final String body , final String errMsg ) { protected String escapeCallbackName ( final String callbackName ) { protected String escapeJson ( final Object obj ) { protected String escapeJsonString ( final String str ) { private String hex ( final char ch ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "export", "_any_", "object", "using", "user", "defined", "attribute", "-", "field", "attribute", "-", "method", "and", "operation", "info", "."], "add_tokens": "import java . util . HashMap ; this ( jmxUrl , null , null ) ; } / * * * Connect the client to a JMX server using the full JMX URL format with username / password credentials . The URL * should look something like : * * < p > * * < pre > * service : jmx : rmi : ///jndi/rmi://hostName:portNumber/jmxrmi * < / pre > * * < / p > * / public JmxClient ( String jmxUrl , String userName , String password ) throws JMException { HashMap < String , Object > map = null ; if ( userName != null || password != null ) { map = new HashMap < String , Object > ( ) ; String [ ] credentials = new String [ ] { userName , password } ; map . put ( \"jmx.remote.credentials\" , credentials ) ; } jmxConnector = JMXConnectorFactory . connect ( serviceUrl , map ) ;", "del_tokens": "jmxConnector = JMXConnectorFactory . connect ( serviceUrl , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "minor", "socket", "monitor", "issues", "."], "add_tokens": "logger . fine ( \"Add channel: \" + channel . toString ( ) + \", mask=\" + debugMask ( selectMask ) ) ; logger . fine ( \"Modify channel: \" + channel . toString ( ) + \", mask=\" + debugMask ( selectMask ) ) ; key . interestOps ( req . mask ) ; if ( selector . keys ( ) . contains ( req . channel ) ) selector . keys ( ) . remove ( req . channel ) ;", "del_tokens": "logger . fine ( \"Add channel: \" + channel . toString ( ) ) ; logger . fine ( \"Modify channel: \" + channel . toString ( ) + \", locked=\" + locked ) ; if ( key != null ) { key . interestOps ( req . mask ) ; } else { try { req . channel . register ( selector , req . mask , req . listener ) ; } catch ( ClosedChannelException e ) { e . printStackTrace ( ) ; } } selector . keys ( ) . remove ( req . channel ) ; / * * /", "commit_type": "fix"}
{"commit_tokens": ["improved", "png", "test", "to", "check", "case", "insensibility", "of", "field", "mapping"], "add_tokens": "@ Bin long hEAder ; @ Bin Chunk [ ] chuNK ; assertEquals ( 0x89504E470D0A1A0AL , png . hEAder ) ; assertEquals ( chunkNames . length , png . chuNK . length ) ; for ( int i = 0 ; i < png . chuNK . length ; i ++ ) { assertChunk ( chunkNames [ i ] , chunkSizes [ i ] , png . chuNK [ i ] . type , png . chuNK [ i ] . length , png . chuNK [ i ] . crc , png . chuNK [ i ] . data ) ;", "del_tokens": "@ Bin long header ; @ Bin Chunk [ ] chunk ; assertEquals ( 0x89504E470D0A1A0AL , png . header ) ; assertEquals ( chunkNames . length , png . chunk . length ) ; for ( int i = 0 ; i < png . chunk . length ; i ++ ) { assertChunk ( chunkNames [ i ] , chunkSizes [ i ] , png . chunk [ i ] . type , png . chunk [ i ] . length , png . chunk [ i ] . crc , png . chunk [ i ] . data ) ;", "commit_type": "improve"}
{"commit_tokens": ["Change", "RC", "rawdatasize", "calculation", "to", "be", "consistent", "to", "ORC"], "add_tokens": "import org . apache . hadoop . hive . common . io . RawDatasizeConst ; setRawDataSize ( RawDatasizeConst . NULL_SIZE ) ; super . write ( obj , RawDatasizeConst . BOOLEAN_SIZE ) ; super . write ( obj , RawDatasizeConst . BYTE_SIZE ) ; rawDataSize = RawDatasizeConst . INT_SIZE ; rawDataSize = RawDatasizeConst . LONG_SIZE ; rawDataSize = RawDatasizeConst . SHORT_SIZE ; super . write ( obj , RawDatasizeConst . FLOAT_SIZE ) ; super . write ( obj , RawDatasizeConst . DOUBLE_SIZE ) ; super . write ( obj , RawDatasizeConst . TIMESTAMP_SIZE ) ; rawDataSize = childrenWriters [ tag ] . getRowRawDataSize ( ) + RawDatasizeConst . UNION_TAG_SIZE ;", "del_tokens": "setRawDataSize ( 1 ) ; super . write ( obj , 1 ) ; super . write ( obj , 1 ) ; rawDataSize = 4 ; rawDataSize = 8 ; rawDataSize = 2 ; super . write ( obj , 4 ) ; super . write ( obj , 8 ) ; super . write ( obj , 12 ) ; rawDataSize = childrenWriters [ tag ] . getRowRawDataSize ( ) + 1 ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "json", "marshalling", "when", "using", "embedded", "solr"], "add_tokens": "import java . io . * ; import org . apache . solr . request . LocalSolrQueryRequest ; import org . apache . solr . response . JSONResponseWriter ; import org . apache . solr . response . SolrQueryResponse ; private final JSONResponseWriter jsonResponseWriter = new JSONResponseWriter ( ) ; return this . serializeResponse ( params , response ) ; private InputStream serializeResponse ( SolrParams params , QueryResponse response ) throws UnsupportedEncodingException , IOException { LocalSolrQueryRequest solrQueryRequest = new LocalSolrQueryRequest ( null , params ) ; SolrQueryResponse solrQueryResponse = new SolrQueryResponse ( ) ; solrQueryResponse . setAllValues ( response . getResponse ( ) ) ; ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; OutputStreamWriter writer = new OutputStreamWriter ( baos , \"UTF-8\" ) ; this . jsonResponseWriter . write ( writer , solrQueryRequest , solrQueryResponse ) ; writer . flush ( ) ; return new ByteArrayInputStream ( baos . toByteArray ( ) ) ; }", "del_tokens": "import java . io . ByteArrayInputStream ; import java . io . IOException ; import java . io . InputStream ; return new ByteArrayInputStream ( response . toString ( ) . getBytes ( \"UTF-8\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "silly", "compiler", "errors", "due", "to", "rushing", "the", "commit", "."], "add_tokens": "public LightBlueEntity getNext ( ) { return null ; public Integer count ( ) { return 0 ; public Boolean isPaged ( ) { return false ; public Boolean hasNextPage ( ) { return false ; public Boolean hasNext ( ) { return false ; public LightBlueEntity getByIndex ( final Integer index ) { return null ;", "del_tokens": "LightBlueEntity getNext ( ) { Integer count ( ) { Boolean isPaged ( ) { Boolean hasNextPage ( ) { Boolean hasNext ( ) { LightBlueEntity getByIndex ( final Integer index ) {", "commit_type": "fix"}
{"commit_tokens": ["Change", "anviltop", "connection", "configuration", "to", "separate", "host", "and", "port"], "add_tokens": "public static final String ANVILTOP_PORT_KEY = \"google.anviltop.endpoint.port\" ; public static final int DEFAULT_ANVILTOP_PORT = 443 ; public static final String ANVILTOP_HOST_KEY = \"google.anviltop.endpoint.host\" ; public static final String PROJECT_ID_KEY = \"google.anviltop.project.id\" ; String host = configuration . get ( ANVILTOP_HOST_KEY ) ; ! Strings . isNullOrEmpty ( host ) , String . format ( \"API endpoint host must be supplied via %s\" , ANVILTOP_HOST_KEY ) ) ; optionsBuilder . setHost ( host ) ; int port = configuration . getInt ( ANVILTOP_PORT_KEY , DEFAULT_ANVILTOP_PORT ) ; optionsBuilder . setPort ( port ) ;", "del_tokens": "public static final String PROJECT_ID_KEY = \"anviltop.project.id\" ; public static final String API_ENDPOINT_KEY = \"anviltop.endpoint.url\" ; String apiEndpoint = configuration . get ( API_ENDPOINT_KEY ) ; ! Strings . isNullOrEmpty ( apiEndpoint ) , String . format ( \"API endpoint URL must be supplied via %s\" , API_ENDPOINT_KEY ) ) ; optionsBuilder . setApiEndpoint ( apiEndpoint ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "ee", "component", "dependency", "resolution"], "add_tokens": "String [ ] implementations ( ) default { } ;", "del_tokens": "String [ ] implementations ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "mock", "class", "android", ".", "util", ".", "Log", "for", "junit", "testing"], "add_tokens": "import java . util . List ; import org . junit . Assert ; import org . mythtv . services . api . channel . ChannelInfo ; // let's run getProgramGuide to get an actual program. DateTime fourHours = now . plus ( Period . hours ( 4 ) ) ; ProgramGuideWrapper guideWrapper = operations . getProgramGuide ( now , fourHours , 0 , 10 , false ) ; List < ChannelInfo > channels = guideWrapper . getProgramGuide ( ) . getChannels ( ) ; Assert . assertNotNull ( channels ) ; Assert . assertFalse ( \"No channels retuned\" , channels . isEmpty ( ) ) ; ChannelInfo chan = channels . get ( 0 ) ; List < Program > programs = chan . getPrograms ( ) ; Assert . assertFalse ( \"No programs retuned\" , programs . isEmpty ( ) ) ; Program p = operations . getProgramDetails ( Integer . parseInt ( chan . getChannelId ( ) ) , programs . get ( 0 ) . getStartTime ( ) ) ; Assert . assertNotNull ( \"Program is null\" , p ) ;", "del_tokens": "Program p = operations . getProgramDetails ( chanid , now ) ; p . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "millisecond", "to", "agent", "log"], "add_tokens": "final String time = new SimpleDateFormat ( \"yyyy-MM-dd HH:mm:ss.SSS\" ) . format ( new Date ( ) ) ; final String time = new SimpleDateFormat ( \"yyyy-MM-dd HH:mm:ss.SSS\" ) . format ( new Date ( ) ) ;", "del_tokens": "final String time = new SimpleDateFormat ( \"yyyy-MM-dd HH:mm:ss\" ) . format ( new Date ( ) ) ; final String time = new SimpleDateFormat ( \"yyyy-MM-dd HH:mm:ss\" ) . format ( new Date ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["implementing", "missing", "bits", "while", "solving", "symbols", "on", "JavaParser"], "add_tokens": "import me . tomassetti . symbolsolver . model . typesolvers . JavaParserTypeSolver ; File src = new File ( \"/home/federico/repos/javaparser/javaparser-core/src/main/java\" ) ; combinedTypeSolver . add ( new JavaParserTypeSolver ( src ) ) ;", "del_tokens": "File src = new File ( \"/home/federico/repos/javaparser/javaparser-core/src/main\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Update", "to", "address", "connection", "leak", "when", "cursor", "creation", "fails", "."], "add_tokens": "Connection con ; try { con = mRepository . getConnection ( ) ; } catch ( FetchException e ) { throw e . toPersistException ( ) ; } //in case of exception, yield connection try { mRepository . yieldConnection ( con ) ; } catch ( FetchException e ) { //ignore and allow triggering exception to propagate }", "del_tokens": "Connection con = mRepository . getConnection ( ) ;", "commit_type": "update"}
{"commit_tokens": ["update", "artifact", "names", "and", "user", "agents"], "add_tokens": "/ * * * { @ link ConnectionFactoryProvider } for proxied access to GCP MySQL instances . * / static { CoreSocketFactory . addArtifactId ( \"cloud-sql-connector-r2dbc-mysql\" ) ; } / * * * MySQL driver option value . * /", "del_tokens": "/** {@link ConnectionFactoryProvider} for proxied access to GCP MySQL instances. */ /** MySQL driver option value. */", "commit_type": "update"}
{"commit_tokens": ["fixes", "to", "the", "test", "cases", "--", "need", "to", "make", "sure", "that", "people", "have", "a", "test", "account", "for", "p6spy"], "add_tokens": "/ * * * * / private static final String P6_TEST_PROPERTIES = \"P6Test.properties\" ; Properties props = loadProperties ( P6_TEST_PROPERTIES ) ; fail ( e . getMessage ( ) + \" check the properties in \" + P6_TEST_PROPERTIES ) ; Properties props = loadProperties ( P6_TEST_PROPERTIES ) ; Properties props2 = loadProperties ( P6_TEST_PROPERTIES ) ;", "del_tokens": "Properties props = loadProperties ( \"P6Test.properties\" ) ; fail ( e . getMessage ( ) ) ; Properties props = loadProperties ( \"P6Test.properties\" ) ; Properties props2 = loadProperties ( \"P6Test.properties\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "documentation", "/", "examples", "for", "expressions", "on", "sequence", "flow"], "add_tokens": "// the tasks are ordered by name (see above)", "del_tokens": "// the tasks are order by name (see above)", "commit_type": "add"}
{"commit_tokens": ["make", "DistributedReference", "constructor", "public", "&", "fix", "bug", "=", "0"], "add_tokens": "public DistributedReference ( long id , T obj ) { this . id = id ;", "del_tokens": "protected DistributedReference ( long id , T obj ) { this . id = 0 ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "parsing", "of", "decimal", "separator", "fomr", "complex", "part"], "add_tokens": "if ( Character . isDigit ( next ) || next == '.' ) {", "del_tokens": "if ( Character . isDigit ( next ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "highlighting", "MathML", "by", "content", "identifier", "hash"], "add_tokens": "import java . util . ArrayList ; @ Test void HighlightMTest ( ) throws IOException , ParserConfigurationException , SAXException { final String sampleMML = getFileContents ( TEST_DIR + \"Emc2.mml\" ) ; final MathDoc mml = new MathDoc ( sampleMML ) ; final int mHash = \"m\" . hashCode ( ) ; final ArrayList < Integer > toHighlight = new ArrayList < > ( ) ; toHighlight . add ( mHash ) ; assertThrows ( NotImplementedException . class , ( ) -> mml . highlightIdentifier ( toHighlight , false ) ) ; } * /", "del_tokens": "import com . formulasearchengine . mathmltools . io . XmlDocumentWriter ; import javax . xml . transform . TransformerException ; import static org . mockito . Mockito . * ; * /", "commit_type": "add"}
{"commit_tokens": ["Added", "example", "for", "custom", "keywords", "in", "tests"], "add_tokens": "public JsonNode getSchemaNode ( ) {", "del_tokens": "protected JsonNode getSchemaNode ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "todo", "example", "app"], "add_tokens": "public static final String ID_KEY = \"_id\" ;", "del_tokens": "public static final String ID_KEY = \"id\" ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "so", "it", "calls", "the", "correct", "report", "()", "method", "."], "add_tokens": "report ( ) ;", "del_tokens": "import java . io . PrintStream ; import java . util . zip . * ; import java . io . * ; report ( System . out ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typo", "executeOnEndpoint", "-", ">", "executeOnEndPoint"], "add_tokens": "return _pool . executeOnEndPoint ( endPoint , callback ) ;", "del_tokens": "return _pool . executeOnEndpoint ( endPoint , callback ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "trailing", "stop", "-", "loss", "indicator"], "add_tokens": "this ( indicator , stopLossDistance , Decimal . NaN ) ; this . stopLossLimit = initialStopLossLimit ; * Simple implementation of the trailing stop - loss concept . if ( stopLossLimit . isNaN ( ) ) { // Case without initial stop-loss limit value stopLossLimit = indicator . getValue ( 0 ) . minus ( stopLossDistance ) ; }", "del_tokens": "super ( indicator ) ; this . indicator = indicator ; this . stopLossLimit = indicator . getValue ( 0 ) . minus ( stopLossDistance ) ; this . stopLossDistance = stopLossDistance ; this . stopLossLimit = initialStopLossLimit ; * Simple implementation of the trailing stop loss concept .", "commit_type": "fix"}
{"commit_tokens": ["added", "more", "tests", "..", "getting", "more", "coverage", "."], "add_tokens": "List < String > firstNames = Reflection . idxList ( Typ . string , list , \"firstName\" ) ; List < String > firstNames = Reflection . idxList ( Typ . string , list , \"firstName\" ) ; List < String > lastNames = Reflection . idxList ( Typ . string , list , \"lastName\" ) ;", "del_tokens": "List < String > firstNames = Reflection . getListOfProps ( Typ . string , list , \"firstName\" ) ; List < String > firstNames = Reflection . getListOfProps ( Typ . string , list , \"firstName\" ) ; List < String > lastNames = Reflection . getListOfProps ( Typ . string , list , \"lastName\" ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "output", "file", "extension", "command", "line", "argument"], "add_tokens": "private String outputFileExtension ; outputFileExtension = \"fa\" ; new SplitFasta ( fastaFile , null , outputFileExtension , outputDirectory ) ; } @ Test ( expected = NullPointerException . class ) public void testConstructorNullOutputFileExtension ( ) { new SplitFasta ( fastaFile , outputFilePrefix , null , outputDirectory ) ; new SplitFasta ( fastaFile , outputFilePrefix , outputFileExtension , null ) ; assertNotNull ( new SplitFasta ( fastaFile , outputFilePrefix , outputFileExtension , outputDirectory ) ) ;", "del_tokens": "new SplitFasta ( fastaFile , null , outputDirectory ) ; new SplitFasta ( fastaFile , outputFilePrefix , null ) ; assertNotNull ( new SplitFasta ( fastaFile , outputFilePrefix , outputDirectory ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "all", "method", "on", "api", "resource"], "add_tokens": "import java . io . IOException ; import java . lang . reflect . Type ; import java . util . List ; import java . util . Map ; import com . google . gson . Gson ; import com . google . gson . reflect . TypeToken ; import com . maestrano . account . MnoBill ; return clazz . getSimpleName ( ) . replaceAll ( \"([a-z])([A-Z])\" , \"$1_$2\" ) . toLowerCase ( ) . replaceFirst ( \"^mno_\" , \"\" ) ; public static < T > List < T > all ( Class < T > clazz , Map < String , String > params , MnoHttpClient httpClient ) throws IOException { Gson gson = new Gson ( ) ; String jsonBody = httpClient . get ( getCollectionUrl ( clazz ) , params ) ; Type parsingType = new TypeToken < MnoApiAccountResponse < List < MnoBill > > > ( ) { } . getType ( ) ; MnoApiAccountResponse < List < T > > resp = gson . fromJson ( jsonBody , parsingType ) ; return resp . getData ( ) ; }", "del_tokens": "return clazz . getSimpleName ( ) . replaceAll ( \"([a-z])([A-Z])\" , \"$1_$2\" ) . toLowerCase ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "additional", "getters", "/", "setters", "."], "add_tokens": "public Drawable getSplitterDrawable ( ) { return mSplitterDrawable ; } public void setSplitterDrawable ( Drawable splitterDrawable ) { mSplitterDrawable = splitterDrawable ; if ( getChildCount ( ) == 2 ) { remeasure ( ) ; } } public Drawable getSplitterDraggingDrawable ( ) { return mSplitterDraggingDrawable ; } public void setSplitterDraggingDrawable ( Drawable splitterDraggingDrawable ) { mSplitterDraggingDrawable = splitterDraggingDrawable ; if ( isDragging ) { invalidate ( ) ; } } / * * * Gets the current orientation of the layout . * * @ return the orientation of the layout * / public int getOrientation ( ) { return mOrientation ; } / * * * Sets the orientation of the layout . * * @ param orientation the desired orientation of the layout * / public void setOrientation ( int orientation ) { if ( mOrientation != orientation ) { mOrientation = orientation ; if ( getChildCount ( ) == 2 ) { remeasure ( ) ; } } } if ( getChildCount ( ) == 2 ) { remeasure ( ) ; }", "del_tokens": "remeasure ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "debug", "all", "requests", "by", "setting", "DEBUG", "=", "true", "in", "DefaultWebResourceFactoryImpl", "."], "add_tokens": "import com . sun . jersey . api . client . filter . LoggingFilter ; private static final boolean DEBUG = false ; com . sun . jersey . api . client . Client client = com . sun . jersey . api . client . Client . create ( clientConfig ) ; if ( DEBUG ) { client . addFilter ( new LoggingFilter ( System . out ) ) ; } return client ;", "del_tokens": "return com . sun . jersey . api . client . Client . create ( clientConfig ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "prioritise", "mappings", "as", "normal", "or", "high"], "add_tokens": "import static com . google . common . collect . Iterables . concat ; import static com . tomakehurst . wiremock . mapping . Priority . HIGH ; private CopyOnWriteArrayList < RequestResponseMapping > normalPriorityMappings = new CopyOnWriteArrayList < RequestResponseMapping > ( ) ; private CopyOnWriteArrayList < RequestResponseMapping > highPriorityMappings = new CopyOnWriteArrayList < RequestResponseMapping > ( ) ; RequestResponseMapping matchingMapping = find ( concat ( highPriorityMappings , normalPriorityMappings ) , mappingMatching ( request ) , RequestResponseMapping . notConfigured ( ) ) ; if ( mapping . priorityIs ( HIGH ) ) { highPriorityMappings . add ( 0 , mapping ) ; } else { normalPriorityMappings . add ( 0 , mapping ) ; } normalPriorityMappings . clear ( ) ;", "del_tokens": "private CopyOnWriteArrayList < RequestResponseMapping > requestResponseMappings = new CopyOnWriteArrayList < RequestResponseMapping > ( ) ; RequestResponseMapping matchingMapping = find ( requestResponseMappings , mappingMatching ( request ) , RequestResponseMapping . notConfigured ( ) ) ; requestResponseMappings . add ( 0 , mapping ) ; requestResponseMappings . clear ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "ScrollView", "from", "Dialog", "."], "add_tokens": "import com . rey . material . app . SimpleDialog ; final SimpleDialog dialog = new SimpleDialog ( getActivity ( ) ) ; dialog . applyStyle ( R . style . SimpleDialog ) ; // dialog.setMessage(\"This is a message\"); dialog . setItems ( new CharSequence [ ] { \"Item 1\" , \"Item 2\" , \"Item 3\" , \"Item 4\" , \"Item 5\" , \"Item 6\" } , 1 ) ; // dialog.setMultiChoiceItems(new CharSequence[]{\"Item 1\", \"Item 2\", \"Item 3\"}, 1, 2);", "del_tokens": "final Dialog dialog = new Dialog ( getActivity ( ) ) ; // dialog.setLayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.WRAP_CONTENT); // dialog.setDimAmount(0.5f); // dialog.setBackgroundColor(0xFFFFFFFF); // dialog.setElevation(ThemeUtil.dpToPx(getActivity(), 4)); // dialog.setMaxElevation(ThemeUtil.dpToPx(getActivity(), 10)); // dialog.setCornerRadius(ThemeUtil.dpToPx(getActivity(), 2)); // dialog.setCanceledOnTouchOutside(true); dialog . applyStyle ( R . style . Dialog ) ; dialog . setMessage ( \"This is a message \\nThis is long message \\nThis is really looooooooooooooooong message.\" ) ; // dialog.setMessageTextColor(0xFF000000); // dialog.setPositiveActionRipple(R.style.FlatWaveColorButtonRippleStyle); // dialog.setNegativeActionRipple(R.style.FlatColorButtonRippleStyle); // dialog.setPositiveActionTextColor(0xFF0099CC); // dialog.setNegativeActionTextColor(0xFF000000); // dialog.setTitleColor(0xFF000000);", "commit_type": "remove"}
{"commit_tokens": ["Made", "clearCache", "()", "public", "so", "that", "the", "cache", "dir", "can", "properly", "be", "cleared"], "add_tokens": "public static void clearCache ( BoxSession session ) { private static void deleteFilesRecursively ( File fileOrDirectory ) {", "del_tokens": "private void clearCache ( BoxSession session ) { private void deleteFilesRecursively ( File fileOrDirectory ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "querymanipulation", "index", "flavor", "."], "add_tokens": "web_cloud , querymanipulation", "del_tokens": "web_cloud", "commit_type": "add"}
{"commit_tokens": ["Move", "endpoints", "servlets", "to", "stack", "integration", "packages"], "add_tokens": "import org . jboss . wsf . spi . invocation . EndpointAssociation ;", "del_tokens": "import org . jboss . wsf . framework . invocation . EndpointAssociation ;", "commit_type": "move"}
{"commit_tokens": ["adds", "an", "api", "to", "search", "a", "specific", "webjar", "instead", "of", "all", "of", "them"], "add_tokens": "return getFullPath ( fullPathIndex , partialPath ) ; } / * * * Returns the full path of an asset within a specific WebJar * * @ param webjar The id of the WebJar to search * @ param partialPath The partial path to look for * @ return a fully qualified path to the resource * / public String getFullPath ( final String webjar , final String partialPath ) { return getFullPath ( filterPathIndexByPrefix ( fullPathIndex , WEBJARS_PATH_PREFIX + \"/\" + webjar ) , partialPath ) ; } private String getFullPath ( SortedMap < String , String > pathIndex , String partialPath ) { final SortedMap < String , String > fullPathTail = pathIndex . tailMap ( reversePartialPath ) ; private SortedMap < String , String > filterPathIndexByPrefix ( SortedMap < String , String > pathIndex , String prefix ) { SortedMap < String , String > filteredPathIndex = new TreeMap < String , String > ( ) ; for ( String key : pathIndex . keySet ( ) ) { String value = pathIndex . get ( key ) ; if ( value . startsWith ( prefix ) ) { filteredPathIndex . put ( key , value ) ; } } return filteredPathIndex ; }", "del_tokens": "final SortedMap < String , String > fullPathTail = fullPathIndex . tailMap ( reversePartialPath ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "an", "example", "for", "pax", "swissbox", "manifest", "based", "extender"], "add_tokens": "// customizer for scanned entries that logs OSGi manifest headers", "del_tokens": "// customized for scanned entries", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "SeekBar", "to", "adjust", "tile", "intensity", "and", "switched", "to", "an", "Orientation", "sensor"], "add_tokens": "import android . widget . SeekBar ; private SeekBar mSeekBar ; mSeekBar = ( SeekBar ) rootView . findViewById ( android . R . id . progress ) ; // Set SeekBar to change parallax intensity mSeekBar . setMax ( 10 ) ; mSeekBar . setOnSeekBarChangeListener ( new SeekBar . OnSeekBarChangeListener ( ) { @ Override public void onProgressChanged ( SeekBar seekBar , int progress , boolean fromUser ) { mBackground . setIntensity ( 1f + ( ( float ) progress ) / 10 ) ; } @ Override public void onStartTrackingTouch ( SeekBar seekBar ) { } @ Override public void onStopTrackingTouch ( SeekBar seekBar ) { } } ) ; mSeekBar . setProgress ( 5 ) ;", "del_tokens": "mBackground . setIntensity ( 1.3f ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "optional", "code", "attribute"], "add_tokens": "* / * * * @ return Optional comment why this element is coding styleguide unaware . * / / * * * @ return Optional code identifying the reason why this element is coding * styleguide unaware . The interpretation of this code is usage * dependent . * / String code ( ) default \"\" ;", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "simple", "TwitterTemplate", "constructor", "to", "set", "error", "handler", "and", "translator", "."], "add_tokens": "import org . scribe . builder . api . LinkedInApi ; // TODO : REMOVE THE SPECIFIC API HERE...FIGURE OUT WHICH ONE WE NEED OR // BUILD UP THE SERVICE PROGRAMMATICALLY this . service = new ServiceBuilder ( ) . provider ( LinkedInApi . class ) . apiKey ( apiKey ) . apiSecret ( apiSecret )", "del_tokens": "import org . scribe . builder . api . TwitterApi ; this . service = new ServiceBuilder ( ) . provider ( TwitterApi . class ) . apiKey ( apiKey ) . apiSecret ( apiSecret )", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "mechanism", "to", "let", "the", "user", "POJO", "render", "the", "HTTP", "response", "."], "add_tokens": "public void doDispatch ( RequestImpl req , ResponseImpl rsp , Object node ) throws IllegalAccessException , InvocationTargetException , ServletException , IOException { Object o = f . bindAndInvoke ( node , req , rsp ) ; if ( o instanceof HttpResponse ) { // let the result render the response HttpResponse response = ( HttpResponse ) o ; response . generateResponse ( req , rsp ) ; }", "del_tokens": "public void doDispatch ( RequestImpl req , ResponseImpl rsp , Object node ) throws IllegalAccessException , InvocationTargetException , ServletException { f . bindAndInvoke ( node , req , rsp ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "wholeArray", "flag", "into", "write", "custom", "field", "method", "definition"], "add_tokens": "this . specialMethods . printJavaDocLinesWithIndent ( \"Writing custom fields\\n@param sourceStruct source structure holding the field, must not be null\\n@param outStream the output stream, must not be null\\n@param fieldValue value to be written\\n@param typeParameterContainer info about field type, must not be null\\n@param nullableNamedFieldInfo info abut field name, it can be null\\n@param extraValue value from extra field part\\n@param wholeArray true if to write whole array\\n@param arraySize if array then it is zero or great\\n@exception IOException if data can't be written\" ) ; this . specialMethods . println ( \"public abstract void writeCustomFieldType(Object sourceStruct, JBBPBitOutputStream outStream, JBBPAbstractField fieldValue, JBBPFieldTypeParameterContainer typeParameterContainer, JBBPNamedFieldInfo nullableNamedFieldInfo, int extraValue, boolean wholeArray, int arraySize) throws IOException;\" ) ; String . format ( \"%s.writeCustomFieldType(this, Out, %s, %s, %s, %s, %b, %s)\" , readWholeStream ,", "del_tokens": "this . specialMethods . printJavaDocLinesWithIndent ( \"Writing custom fields\\n@param sourceStruct source structure holding the field, must not be null\\n@param outStream the output stream, must not be null\\n@param fieldValue value to be written\\n@param typeParameterContainer info about field type, must not be null\\n@param nullableNamedFieldInfo info abut field name, it can be null\\n@param extraValue value from extra field part\\n@param arraySize if array then it is zero or great\\n@exception IOException if data can't be written\" ) ; this . specialMethods . println ( \"public abstract void writeCustomFieldType(Object sourceStruct, JBBPBitOutputStream outStream, JBBPAbstractField fieldValue, JBBPFieldTypeParameterContainer typeParameterContainer, JBBPNamedFieldInfo nullableNamedFieldInfo, int extraValue, int arraySize) throws IOException;\" ) ; String . format ( \"%s.writeCustomFieldType(this, Out, %s, %s, %s, %s, %s)\" ,", "commit_type": "add"}
{"commit_tokens": ["Moving", "UnitOfWork", "annotation", "to", "com", ".", "scottescue", ".", "dropwizard", ".", "entitymanager"], "add_tokens": "package com . scottescue . dropwizard . entitymanager ;", "del_tokens": "package io . dropwizard . hibernate ;", "commit_type": "move"}
{"commit_tokens": ["Use", "loader", "s", "classloader", "for", "resource", "access", "."], "add_tokens": "InputStream resourceInputStream = ApplicationClassLoader . class . getResourceAsStream ( resource ) ; clazz = ApplicationClassLoader . class . getClassLoader ( ) . loadClass ( name ) ;", "del_tokens": "InputStream resourceInputStream = getSystemResourceAsStream ( resource ) ; clazz = getSystemClassLoader ( ) . loadClass ( name ) ;", "commit_type": "use"}
{"commit_tokens": ["use", "separate", "asynchronous", "factory", "bean", "to", "create", "the", "MavenIndexerFacade", "-", "and", "use", "a", "Timer", "to", "avoid", "the", "WAR", "blocking", "on", "startup", "of", "the", "indexer", "as", "the", "indexer", "can", "take", "a", "while", "to", "start"], "add_tokens": "facade . start ( ) ;", "del_tokens": "facade . startAndWait ( ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "flatMap", "rare", "issue", "and", "mono", "repeatUntil", "index"], "add_tokens": "boolean d = done ;", "del_tokens": "boolean d = done ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "showDefaults", "=", "true", "when", "fetching", "schema", "information", "for", "fields", "to", "determine", "if", "a", "field", "is", "multiValued"], "add_tokens": "import org . apache . spark . sql . AnalysisException ; throw new AnalysisException ( \"Query (\" + query + \") does not specify any fields needed to build a schema!\" , null , null ) ; String fieldUrl = solrBaseUrl + collection + \"/schema/fields/\" + field + \"?showDefaults=true\" ; String dynamicFieldsUrl = solrBaseUrl + collection + \"/schema/dynamicfields/\" + dynField + \"?showDefaults=true\" ; String errMsg = \"Can't figure out field type for field: \" + field + \". Check you Solr schema and retry.\" ; log . error ( errMsg ) ; throw new RuntimeException ( errMsg ) ; String errMsg = \"Can't get field type for field \" + field + \" due to: \" + exc ; log . error ( errMsg ) ; if ( exc instanceof RuntimeException ) { throw ( RuntimeException ) exc ; } else { throw new RuntimeException ( errMsg , exc ) ; }", "del_tokens": "throw new IllegalArgumentException ( \"Query (\" + query + \") does not specify any fields needed to build a schema!\" ) ; String fieldUrl = solrBaseUrl + collection + \"/schema/fields/\" + field ; String dynamicFieldsUrl = solrBaseUrl + collection + \"/schema/dynamicfields/\" + dynField ; log . warn ( \"Can't figure out field type for field: \" + field ) ; continue ; log . warn ( \"Can't get field type for field \" + field + \" due to: \" + exc ) ;", "commit_type": "use"}
{"commit_tokens": ["Moved", "resources", "out", "of", "semanticcms", "-", "core", "-", "model", "into", "new", "semanticcms", "-", "core", "-", "resources"], "add_tokens": "import com . semanticcms . core . resources . Resource ; import com . semanticcms . core . resources . ResourceStore ;", "del_tokens": "import com . semanticcms . core . model . Resource ; import com . semanticcms . core . model . ResourceStore ;", "commit_type": "move"}
{"commit_tokens": ["Add", "batch", "test", "(", "now", "failing", ")"], "add_tokens": "import java . util . concurrent . ExecutorService ; public interface StreamConsumer < T > { T accept ( @ NotNull InputStream inputStream ) throws IOException ; public BatchDownloader ( @ NotNull Client client , @ NotNull ExecutorService pool ) { public < T > CompletableFuture < T > download ( @ NotNull final Meta meta , @ NotNull StreamConsumer < T > callback ) {", "del_tokens": "public interface StreamConsumer { void accept ( @ NotNull InputStream inputStream ) throws IOException ; public BatchDownloader ( @ NotNull Client client ) { public CompletableFuture < ? > download ( @ NotNull final Meta meta , @ NotNull StreamConsumer callback ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "javadoc", "at", "line", "142", "."], "add_tokens": "* & # 64 ; Column ( name = \\\"MY_COLUMN_NAME\\\", nullable = false) <i>// annotation and properties</i><br>", "del_tokens": "* & # 64 ; Column ( name = \\\"MY_COLUMN_NAME\\\", nullable = false) <i>// annotation and properties<br>", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "typos", "about", "setFacetFilters", "setNumericFilters", "&", "setTagFilters"], "add_tokens": "protected String facetFilters ; public Query setFacetFilters ( List < String > facets ) { this . facetFilters = obj . toString ( ) ; public Query setTagFilters ( String tags ) { public Query setNumericFilters ( String numerics ) { public Query setNumericFilters ( List < String > numerics ) { stringBuilder . append ( \"tagFilters=\" ) ; stringBuilder . append ( \"numericFilters=\" ) ; if ( facetFilters != null ) { stringBuilder . append ( \"facetFilters\" ) ; stringBuilder . append ( URLEncoder . encode ( facetFilters , \"UTF-8\" ) ) ;", "del_tokens": "protected String facetsFilter ; public Query setFacetsFilter ( List < String > facets ) { this . facetsFilter = obj . toString ( ) ; public Query setTagsFilter ( String tags ) { public Query setNumericsFilter ( String numerics ) { public Query setNumericsFilter ( List < String > numerics ) { stringBuilder . append ( \"tags=\" ) ; stringBuilder . append ( \"numerics=\" ) ; if ( facetsFilter != null ) { stringBuilder . append ( \"facetsFilter\" ) ; stringBuilder . append ( URLEncoder . encode ( facetsFilter , \"UTF-8\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "short", "types", "in", "JSON"], "add_tokens": "private final String shortType ; this . shortType = this . type . replaceAll ( \"^0*([0-9a-fA-F]+)-0000-1000-8000-0026BB765291$\" , \"$1\" ) ; . add ( \"type\" , shortType )", "del_tokens": ". add ( \"type\" , type )", "commit_type": "use"}
{"commit_tokens": ["add", "time", "estimates", "api", "call"], "add_tokens": "import com . victorsima . uber . model . Times ; public void testGetPriceEstimates ( ) { @ Test public void testGetTimeEstimates ( ) { Times times = client . getApiService ( ) . getTimeEstimates ( Double . parseDouble ( startLatitude ) , Double . parseDouble ( startLongitude ) , null , null ) ; assertNotNull ( \"get time estimates response is null\" , times ) ; assertNotNull ( \"time estimates list is null\" , times . getTimes ( ) ) ; }", "del_tokens": "public void testGetTimeEstimates ( ) {", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "static", "variable", "."], "add_tokens": "/ * * * The body element in the current page . * / / * * * The document element in the current page . * / / * * * A static reference to the GQuery class . * / / * * * The window object . * /", "del_tokens": "public static boolean fxOff = false ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "weather", "tile", "that", "uses", "DarkSky"], "add_tokens": "import eu . hansolo . tilesfx . weather . DarkSky ; import eu . hansolo . tilesfx . weather . DarkSky . Language ; import eu . hansolo . tilesfx . weather . DarkSky . Unit ; private Tile weatherTile ; // Weather DarkSky darkSky = new DarkSky ( \"YOUR_DARK_SKY_API_KEY\" , Unit . CA , Language . ENGLISH , 51.911858 , 7.632815 ) ; // Update the weather information by calling weatherTile.updateWeather() weatherTile = TileBuilder . create ( ) . skinType ( SkinType . WEATHER ) . title ( \"YOUR CITY NAME\" ) . darkSky ( darkSky ) . build ( ) ; plusMinusTile , sliderTile , switchTile , worldTile ) ; // , weatherTile);", "del_tokens": "plusMinusTile , sliderTile , switchTile , worldTile ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "with", "blank", "nodes", ";", "improve", "scripts"], "add_tokens": "n = blankNodeMap . size ( ) + 1 ; blankNodeMap . put ( id , n ) ;", "del_tokens": "n = blankNodeMap . size ( ) ; blankNodeMap . put ( id , n + 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "timeouts", "cleaned", "up", "the", "code"], "add_tokens": "private long timeout ; @ Deprecated finder = new OurElementFinder ( getWebDriver ( ) , new OurSearchStrategy ( timeout ) ) ; return elementOrNull ( locator , new OurSearchStrategy ( 1 ) . nullOnFailure ( ) ) ; return customFinder ( new OurSearchStrategy ( timeout ) . nullOnFailure ( ) ) . presentInDomElements ( locator ) ;", "del_tokens": "private Long timeout ; finder = new OurElementFinder ( getWebDriver ( ) , timeout ) ; return elementOrNull ( locator , new OurSearchStrategy ( ) . withTimeout ( 1 ) . nullOnFailure ( ) ) ; return customFinder ( new OurSearchStrategy ( ) . nullOnFailure ( ) ) . presentInDomElements ( locator ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "schema", "html", "safety", "per", "zcorpan"], "add_tokens": "|| schemaUrls . startsWith ( \"http://hsivonen.iki.fi/xhtml-schema/xhtml-transitional-wcag.rng\" ) || schemaUrls . startsWith ( \"http://syntax.whattf.org/relaxng/html5full.rnc\" ) ) ;", "del_tokens": "|| schemaUrls . startsWith ( \"http://hsivonen.iki.fi/xhtml-schema/xhtml-transitional-wcag.rng\" ) || schemaUrls . startsWith ( \"http://syntax.whattf.org/relaxng/xhtml5full-html.rnc\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "user", "agent", ".", "fix", "api", "test"], "add_tokens": "api . deleteResources ( Arrays . asList ( \"api_test\" , \"api_test1\" , \"api_test2\" , \"api_test3\" , \"api_test5\" ) , Cloudinary . emptyMap ( ) ) ;", "del_tokens": "api . deleteResources ( Arrays . asList ( \"api_test\" , \"api_test1\" , \"api_test2\" , \"api_test3\" ) , Cloudinary . emptyMap ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "src", "/", "main", "/", "com", "/", "sailthru", "/", "client", "/", "SailthruClient", ".", "java"], "add_tokens": "public JsonResponse scheduleBlast ( Blast blast ) throws IOException { return apiPost ( blast ) ;", "del_tokens": "public Map < String , Object > scheduleBlast ( Blast blast ) throws IOException { return ( Map < String , Object > ) this . apiPost ( blast ) ;", "commit_type": "update"}
{"commit_tokens": ["Adding", "table", "attributes", "to", "WorkUnit", "."], "add_tokens": "* return WorkingState . valueOf ( getProp ( \"workunit.working.state\" , WorkingState . PENDING . toString ( ) ) ) ; setProp ( \"workunit.working.state\" , state . toString ( ) ) ; return workunit . getHighWaterMark ( ) ; return workunit . getLowWaterMark ( ) ;", "del_tokens": "import org . apache . hadoop . io . Text ; * private WorkingState state = WorkingState . PENDING ; private long lowWaterMark = - 1 ; private long highWaterMark = - 1 ; return state ; this . state = state ; return highWaterMark ; } public void setHighWaterMark ( long highWaterMark ) { this . highWaterMark = highWaterMark ; return this . lowWaterMark ; } public void setLowWaterMark ( long lowWaterMark ) { this . lowWaterMark = lowWaterMark ; Text txt = new Text ( ) ; txt . readFields ( in ) ; state = WorkingState . valueOf ( txt . toString ( ) ) ; this . lowWaterMark = in . readLong ( ) ; highWaterMark = in . readLong ( ) ; Text txt = new Text ( state . toString ( ) ) ; txt . write ( out ) ; out . writeLong ( this . lowWaterMark ) ; out . writeLong ( highWaterMark ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "custom", "exception", "for", "finder", "execution", "fail"], "add_tokens": "final Object [ ] arguments = methodInvocation . getArguments ( ) ; command = buildCommand ( descriptor , arguments ) ; Arrays . toString ( arguments ) ) , ex ) ; final Object result = executeQuery ( descriptor , command , arguments , method ) ; private Object executeQuery ( final FinderDescriptor descriptor , final SqlCommandDesc command , final Object [ ] arguments , final Method method ) throws Throwable { try { return descriptor . executor . executeQuery ( command ) ; } catch ( Throwable th ) { throw new FinderExecutionException ( String . format ( \"Failed to execute query '%s' with parameters %s of finder %s#%s%s\" , command . isFunctionCall ? command . function : command . query , Arrays . toString ( arguments ) , method . getDeclaringClass ( ) , method . getName ( ) , Arrays . toString ( method . getParameterTypes ( ) ) ) , th ) ; } }", "del_tokens": "command = buildCommand ( descriptor , methodInvocation . getArguments ( ) ) ; Arrays . toString ( methodInvocation . getArguments ( ) ) ) , ex ) ; final Object result = descriptor . executor . executeQuery ( command ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "in", "different", "normal", "window", "state", "option"], "add_tokens": "import javax . portlet . WindowState ; public static final String NORMAL_VIEW_NAME_PREFERENCE = \"NotificationController.normalWindowStateViewName\" ; public static final String NORMAL_VIEW_NAME_DEFAULT = \"defaultNorm\" ; String viewName ; if ( WindowState . NORMAL . equals ( req . getWindowState ( ) ) ) { viewName = prefs . getValue ( NORMAL_VIEW_NAME_PREFERENCE , NORMAL_VIEW_NAME_DEFAULT ) ; if ( NORMAL_VIEW_NAME_DEFAULT . equals ( viewName ) ) { viewName = prefs . getValue ( VIEW_NAME_PREFERENCE , VIEW_NAME_DEFAULT ) ; } } else { viewName = prefs . getValue ( VIEW_NAME_PREFERENCE , VIEW_NAME_DEFAULT ) ; }", "del_tokens": "final String viewName = prefs . getValue ( VIEW_NAME_PREFERENCE , VIEW_NAME_DEFAULT ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bad", "null", "check", ".", "Patch", "for", "http", ":", "//", "code", ".", "google", ".", "com", "/", "p", "/", "project", "-", "voldemort", "/", "issues", "/", "detail?id", "=", "40", "."], "add_tokens": "URI [ ] uris = new URI [ urls . length ] ;", "del_tokens": "URI [ ] uris = new URI [ urls . length ] ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "read", "timestamp", "fields"], "add_tokens": "import java . security . Timestamp ; CURRENCY ( ( byte ) 'Y' , 8 , 8 , 8 , false ) , / * * * Timestamp type ( FoxPro ) * / TIMESTAMP ( ( byte ) 'T' , 8 , 8 , 8 , false ) ;", "del_tokens": "CURRENCY ( ( byte ) 'Y' , 8 , 8 , 8 , false ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "priority", "field", "to", "appointment"], "add_tokens": "\"priority\" , \"recurrenceDayBits\" , \"recurrenceFrequency\" , \"recurrenceMax\" , \"recurrenceMonthBits\" , \"recurrenceStyle\" , \"recurrenceType\" , private Integer priority ; @ JsonProperty ( \"priority\" ) public Integer getPriority ( ) { return priority ; } @ JsonProperty ( \"priority\" ) public void setPriority ( Integer priority ) { this . priority = priority ; } if ( priority != null ? ! priority . equals ( that . priority ) : that . priority != null ) return false ; result = 31 * result + ( priority != null ? priority . hashCode ( ) : 0 ) ; \", priority=\" + priority +", "del_tokens": "\"recurrenceDayBits\" , \"recurrenceFrequency\" , \"recurrenceMax\" , \"recurrenceMonthBits\" , \"recurrenceStyle\" , \"recurrenceType\" ,", "commit_type": "add"}
{"commit_tokens": ["Remove", "final", "modifiers", "to", "allow", "mocking"], "add_tokens": "public HystrixCollapserKey getCollapserKey ( ) { public Scope getScope ( ) {", "del_tokens": "public final HystrixCollapserKey getCollapserKey ( ) { public final Scope getScope ( ) {", "commit_type": "remove"}
{"commit_tokens": ["Adding", "detached", "test", "cases", "."], "add_tokens": "getSession ( ) . merge ( entity ) ;", "del_tokens": "getSession ( ) . update ( entity ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "EventAllocationType", "enum", "to", "samoa", "-", "api", "utils"], "add_tokens": "package com . yahoo . labs . samoa . utils ;", "del_tokens": "package com . yahoo . labs . samoa . topology . impl ;", "commit_type": "move"}
{"commit_tokens": ["Improve", "TCK", "test", "method", "names"], "add_tokens": "public void formGetParameterWhenTextControlReturnsInitialValue ( ) throws IOException public void formGetParameterWhenTextControlReturnsSetValue ( ) throws IOException public void formSetParameterWhenTextControlSetsValue ( ) throws IOException public void formSubmitWhenGetSubmitsTextControlSetValue ( ) throws IOException , InterruptedException public void formSubmitWhenPostSubmitsTextControlSetValue ( ) throws IOException , InterruptedException", "del_tokens": "public void formGetParameterWhenTextInputReturnsValue ( ) throws IOException public void formGetParameterWhenTextInputReturnsSetValue ( ) throws IOException public void formSetParameterWhenTextInputSetsValue ( ) throws IOException public void formSubmitWhenGetSubmitsTextControlValue ( ) throws IOException , InterruptedException public void formSubmitWhenPostSubmitsTextControlValue ( ) throws IOException , InterruptedException", "commit_type": "improve"}
{"commit_tokens": ["Using", "Thread", "pool", "from", "Java", "5", "instead", "of", "my", "own", "and", "solved", "a", "NullPointerException", "from", "JTSFeature", ".", "getText", "()"], "add_tokens": "import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . ThreadPoolExecutor ; private ExecutorService executor = Executors . newCachedThreadPool ( ) ; executor . execute ( new Runnable ( ) { } ) ;", "del_tokens": "import es . alrocar . map . vector . provider . filesystem . IVectorFileSystemProvider ; import es . prodevelop . gvsig . mini . utiles . WorkQueue ; WorkQueue . getExclusiveInstance ( ) . execute ( new Runnable ( ) { } , true ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "tests", "and", "fix", "bugs", "found", "by", "tests"], "add_tokens": "final String qualifiedName = StringUtils . isBlank ( javaFile . packageName ) ? className : javaFile . packageName + \".\" + className ; final GeneratedClassInfo generatedClassInfo = new GeneratedClassInfo ( qualifiedName , className , ( String ) literal . getValue ( ) , usedVariables , javaFile . packageName ) ;", "del_tokens": "final GeneratedClassInfo generatedClassInfo = new GeneratedClassInfo ( javaFile . packageName + \".\" + className , className , ( String ) literal . getValue ( ) , usedVariables , javaFile . packageName ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "colors", "for", "cell", "background", "title", "message", "and", "CTAs"], "add_tokens": "String id = inboxMessage . has ( \"_id\" ) ? inboxMessage . getString ( \"_id\" ) : null ;", "del_tokens": "String id = inboxMessage . has ( \"id\" ) ? inboxMessage . getString ( \"id\" ) : null ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "details", "in", "the", "readme", "+", "changing", "the", "version", "number"], "add_tokens": "List < Banana > bananas = generateBananas ( 100 ) ;", "del_tokens": "List < Banana > bananas = generateBananas ( 1000 ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "better", "int", "write", "method"], "add_tokens": "this . pointer . setInt ( index * Pointer . SIZE , integer ) ;", "del_tokens": "this . pointer . write ( index * Pointer . SIZE , new int [ ] { integer } , 0 , 1 ) ;", "commit_type": "use"}
{"commit_tokens": ["removed", "javax", ".", "servlet", "from", "libraries", "and", "added", "tests", "to", "showcases"], "add_tokens": "", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["added", "function", "to", "XOR", "byte", "arrays"], "add_tokens": "byte [ ] b = new byte [ ] { 23 , 57 , 23 , 0 } ; byte [ ] a = new byte [ ] { ( byte ) 0x1111 } ; System . out . println ( a ) ; System . out . println ( b ) ; byte [ ] c = Misc . XOR ( a , b ) ; System . out . println ( c ) ;", "del_tokens": "// TODO Auto-generated method stub Crypto hasher = new Crypto ( ) ; EncryptionResult cypher ; try { cypher = Crypto . getAESEncryption ( \"Hello world\" . getBytes ( ) , \"password\" . getBytes ( ) , 128 ) ; System . out . println ( new String ( Crypto . getAESDecryption ( cypher . getCipherText ( ) , \"password\" . getBytes ( ) , cypher . getSalt ( ) , cypher . getIv ( ) , 256 ) ) ) ; } catch ( InvalidKeyLengthException e ) { // TODO Auto-generated catch block e . printStackTrace ( ) ; } //System.out.println(new String(Crypto.getAESDecryption(cypher.getCipherText(), \"password\".getBytes(), cypher.getSalt(), cypher.getIv(), 256)));", "commit_type": "add"}
{"commit_tokens": ["Changed", "some", "function", "signatures", "and", "names"], "add_tokens": "// static public <T> PersistentTreeSet<T> create(Comparator<? super T> comp, ISeq<T> items) { public static < T > PersistentTreeSet < T > ofComp ( Comparator < ? super T > comp ) { public static < T > PersistentTreeSet < T > ofComp ( Comparator < ? super T > comp , T ... items ) {", "del_tokens": "// static public <T> PersistentTreeSet<T> create(Comparator<T> comp, ISeq<T> items) { public static < T > PersistentTreeSet < T > ofComp ( Comparator < T > comp ) { public static < T > PersistentTreeSet < T > ofComp ( Comparator < T > comp , T ... items ) {", "commit_type": "change"}
{"commit_tokens": ["Fixed", "the", "sphere", "s", "bottom", "cap", "."], "add_tokens": "stackPercentage0 = ( ( float ) ( stack + 1 ) / numStacks ) ; stackPercentage1 = ( ( float ) ( stack ) / numStacks ) ;", "del_tokens": "stackPercentage0 = ( ( float ) ( stack ) / numStacks ) ; stackPercentage1 = ( ( float ) ( stack + 1 ) / numStacks ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unused", "constructor", "parameters", "and", "narrow", "down", "the", "@SuppressWarnings", "to", "the", "method", "where", "it", "s", "actually", "needed"], "add_tokens": "private final StoredProcedureParameter forwardingStoredProcedureParameter ; private final ValueTransformer < ? , ? > valueTransformerForClass ; private final ObjectMapper < ? > globalObjectMapper ; final Method m , final String typeName , final int javaPosition , final boolean sensitive , final ObjectMapper < ? > globalObjectMapper ) throws InstantiationException , IllegalAccessException { @ SuppressWarnings ( \"unchecked\" ) return ( ( ObjectMapper < Object > ) globalObjectMapper ) . marshalToDb ( o ) ; return ( ( ValueTransformer < ? , Object > ) valueTransformerForClass ) . marshalToDb ( o ) ;", "del_tokens": "import java . lang . reflect . Type ; private StoredProcedureParameter forwardingStoredProcedureParameter ; @ SuppressWarnings ( \"rawtypes\" ) private ValueTransformer valueTransformerForClass ; @ SuppressWarnings ( \"rawtypes\" ) private ObjectMapper globalObjectMapper ; final Type genericType , final Method m , final String typeName , final int sqlType , final int javaPosition , final boolean sensitive , final ObjectMapper < ? > globalObjectMapper ) throws InstantiationException , IllegalAccessException { return globalObjectMapper . marshalToDb ( o ) ; return valueTransformerForClass . marshalToDb ( o ) ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "multiple", "IDs", "in", "@OnClick", "annotation", "."], "add_tokens": "int [ ] value ( ) ;", "del_tokens": "int value ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Making", "reconnect", "timeout", "a", "bit", "more", "sensible", "."], "add_tokens": "long retryDelay = this . connectionRetryDelay ; if ( timeout < this . connectionRetryDelay * 2 ) { retryDelay = timeout / 2 ; if ( retryDelay < 100 ) { retryDelay = 100 ; } } Long . valueOf ( retryDelay ) ) ) ; Thread . sleep ( retryDelay ) ;", "del_tokens": "Long . valueOf ( this . connectionRetryDelay ) ) ) ; Thread . sleep ( this . connectionRetryDelay ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "final", "to", "the", "members", "of", "Platform", "."], "add_tokens": "private final InjectorWrapper wrapper ; private final DropwizardModule dropwizardModule = new DropwizardModule ( ) ;", "del_tokens": "private InjectorWrapper wrapper ; private DropwizardModule dropwizardModule = new DropwizardModule ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "DelegatingSerializingTranscoder", "as", "this", "was", "not", "really", "needed", "the", "SessionTranscoder", "can", "be", "used", "directly", "to", "deserialized", "serialized", "sessions", "(", "stored", "with", "old", "format", "in", "memcached", ")"], "add_tokens": "import net . spy . memcached . transcoders . SerializingTranscoder ; private SerializingTranscoder _upgradeSupportTranscoder ; _upgradeSupportTranscoder = getTranscoderFactory ( ) . createSessionTranscoder ( this ) ;", "del_tokens": "private DelegatingSerializingTranscoder _upgradeSupportTranscoder ; final SessionTranscoder sessionTranscoder = getTranscoderFactory ( ) . createSessionTranscoder ( this ) ; _upgradeSupportTranscoder = new DelegatingSerializingTranscoder ( sessionTranscoder ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "a", "Mustache", "compilation", "method"], "add_tokens": "@ Test public void testCompileMustache ( ) { assertNotNull ( compileMustache ( null , \"\" ) ) ; assertNotNull ( compileMustache ( new HashMap < String , Object > ( ) , \"test\" ) ) ; Map < String , Object > map = new HashMap < String , Object > ( ) ; map . put ( \"test\" , \"string\" ) ; assertEquals ( \"<html>string</html>\" , compileMustache ( map , \"<html>{{test}}</html>\" ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "self", "-", "tangency", "test", "typo"], "add_tokens": "else { } boundary = ! is_closed_path && end_point ; boundary = end_point ; // check that this is not the endpoints of a closed path || ( ! vi . end_point && ! vi_prev . end_point ) ) { // this is either NonSimpleResult.CrossOver or // NonSimpleResult.OGCPolylineSelfTangency. if ( ! vi . end_point || ! vi_prev . end_point ) { //one of coincident vertices is not an endpoint m_nonSimpleResult = new NonSimpleResult (", "del_tokens": "else boundary = ! is_closed_path && vi_prev . end_point ; boundary = vi_prev . end_point ; || ( ! vi . end_point && ! vi_prev . end_point ) ) // check // that // this // is // not // the // endpoints // of // a // closed // path { // this is either Non_simple_result::cross_over or // Non_simple_result::ogc_self_tangency. if ( ! vi . end_point || ! vi_prev . end_point ) { // one of // coincident // vertices is // not an // endpoint m_nonSimpleResult = new NonSimpleResult (", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "semicolon", "in", "TransactionLogger", ".", "java"], "add_tokens": "return null ;", "del_tokens": "return null", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", "dependent", "on", "time", "zone"], "add_tokens": "import java . text . SimpleDateFormat ; SimpleDateFormat DATE_FORMAT = new SimpleDateFormat ( \"dd-MM-yyyy:HH:mm:SS\" ) ; String ss = DATE_FORMAT . format ( revisedDate ) ; assertEquals ( \"24-04-2000:00:00:00\" , ss ) ;", "del_tokens": "assertEquals ( \"Mon Apr 24 00:00:00 NZST 2000\" , revisedDate . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "Messages", ".", "add", "()", "method", "add", "constructor", "overload"], "add_tokens": "import java . util . ArrayList ; import java . util . Arrays ; private ArrayList < Message > messages ; messages = new ArrayList < Message > ( Arrays . asList ( msgs ) ) ; } public Messages ( ArrayList < Message > msgs ) { messages = new ArrayList < Message > ( msgs ) ; return messages . get ( i ) ; return messages . toArray ( new Message [ messages . size ( ) ] ) ; return messages . size ( ) ; } public boolean add ( Message m ) { return messages . add ( m ) ;", "del_tokens": "private Message [ ] messages ; messages = msgs ; return messages [ i ] ; return messages ; return messages . length ;", "commit_type": "implement"}
{"commit_tokens": ["adding", "100", "-", "continue", "support", "to", "recreate", "authentication", "token"], "add_tokens": "import org . apache . http . client . config . RequestConfig ; System . out . println ( executionCount ) ; RequestConfig rConfig = RequestConfig . custom ( ) . setExpectContinueEnabled ( true ) . setConnectTimeout ( 5000 ) . setConnectionRequestTimeout ( 5000 ) . setSocketTimeout ( 5000 ) . build ( ) ; . setDefaultRequestConfig ( rConfig )", "del_tokens": "/ * * RequestConfig rConfig = RequestConfig . custom ( ) . setConnectTimeout ( 5000 ) * . setConnectionRequestTimeout ( 5000 ) . setSocketTimeout ( 5000 ) . build ( ) ; * / // .setDefaultRequestConfig(rConfig)", "commit_type": "add"}
{"commit_tokens": ["Add", "driver", "dependency", "range", "and", "fix", "jackson", "deps"], "add_tokens": "assertHasBeenPersistedAs ( jsonify ( \"'pattern' : { '$regex' : '[a-z]'\" ) ) ; //options is not longer generated since 2.8.0", "del_tokens": "assertHasBeenPersistedAs ( jsonify ( \"'pattern' : { '$regex' : '[a-z]' , '$options' : ''}\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "built", "-", "in", "constants", "for", "HTTP", "status", "codes", "."], "add_tokens": "import org . apache . http . HttpStatus ; if ( statusCode == HttpStatus . SC_UNAUTHORIZED ) { if ( statusCode == HttpStatus . SC_BAD_GATEWAY || statusCode == HttpStatus . SC_GATEWAY_TIMEOUT", "del_tokens": "private static final int UNAUTHORIZED = 401 ; private static final int BAD_GATEWAY = 502 ; private static final int GATEWAY_TIMEOUT = 504 ; if ( statusCode == UNAUTHORIZED ) { if ( statusCode == BAD_GATEWAY || statusCode == GATEWAY_TIMEOUT", "commit_type": "use"}
{"commit_tokens": ["add", "validation", "in", "design", "action"], "add_tokens": "validate ( form , messages -> { } , toMainHtml ( ) ) ; validate ( form , messages -> { } , toMainHtml ( ) ) ;", "del_tokens": "validate ( form , messages -> { } , toMainHtml ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "accidental", "calls", "to", "setAdapter", "(", "ListAdapter", ")"], "add_tokens": "if ( ! ( adapter instanceof BaseAdapter ) ) { throw new IllegalArgumentException ( \"DynamicListView needs a BaseAdapter!\" ) ; } super . setAdapter ( adapter ) ;", "del_tokens": "throw new IllegalArgumentException ( \"DynamicListView needs a BaseAdapter!\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "cases", "for", "SNI", "support"], "add_tokens": "baseBootstrap . resolver ( options . addressResolverGroup ( ) . orElseGet ( ( ) -> new DnsAddressResolverGroup ( datagramChannelType ( ) , DnsServerAddresses . defaultAddresses ( ) ) ) ) ;", "del_tokens": "import io . netty . channel . epoll . Epoll ; baseBootstrap . resolver ( new DnsAddressResolverGroup ( datagramChannelType ( ) , DnsServerAddresses . defaultAddresses ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "comments", "for", "example", "usage", "."], "add_tokens": "/ * * Set up our rule ( This does the work . ) * / * Now send a verification to our test case that the rule worked correctly .", "del_tokens": "* Now verify that we actually did what we said we did .", "commit_type": "update"}
{"commit_tokens": ["Added", "the", "QuerySession", "parameter", "to", "all", "relevant", "methods", ".", "This", "change", "is", "in", "preparation", "for", "a", "temporary", "table", "creation", "mechanism", "."], "add_tokens": "QueryResultsHandler resultHandler , QuerySession qs ) doFindStateful ( keys , propIds , dataSourceConstraints , resultHandler , qs ) ; doFindStateless ( keys , propIds , dataSourceConstraints , resultHandler , qs ) ; DataSourceConstraint dataSourceConstraints , QueryResultsHandler resultHandler , QuerySession qs ) objectsToAssert ( keys , propositionIds , dataSourceConstraints , qs , false ) QuerySession qs , dataSourceConstraints , qs ) ; dataSourceConstraints , qs ) , propositionIds , DataSourceConstraint dataSourceConstraints , QueryResultsHandler resultHandler , QuerySession qs ) propositionIds , dataSourceConstraints , qs , true ) ; DataSourceConstraint constraints , QuerySession qs ) return dataSource . getEventsAsc ( keyIds , eventIds , constraints , qs ) ;", "del_tokens": "QueryResultsHandler resultHandler ) doFindStateful ( keys , propIds , dataSourceConstraints , resultHandler ) ; doFindStateless ( keys , propIds , dataSourceConstraints , resultHandler ) ; DataSourceConstraint dataSourceConstraints , QueryResultsHandler resultHandler ) objectsToAssert ( keys , propositionIds , dataSourceConstraints , false ) dataSourceConstraints ) ; dataSourceConstraints ) , propositionIds , DataSourceConstraint dataSourceConstraints , QueryResultsHandler resultHandler ) propositionIds , dataSourceConstraints , true ) ; DataSourceConstraint constraints ) return dataSource . getEventsAsc ( keyIds , eventIds , constraints ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "constructors", "that", "take", "repositories", ".", "json", "Path", "and", "List", "of", "UpdateRepositories", "."], "add_tokens": "import java . nio . file . Path ; import java . nio . file . Paths ; private static Path repositoriesJson ; protected List < UpdateRepository > repositories ; repositoriesJson = Paths . get ( \"repositories.json\" ) ; } public UpdateManager ( PluginManager pluginManager , Path repositoriesJson ) { this ( pluginManager ) ; UpdateManager . repositoriesJson = repositoriesJson ; } public UpdateManager ( PluginManager pluginManager , List < UpdateRepository > repos ) { this ( pluginManager ) ; if ( repos == null ) { throw new RuntimeException ( \"Failed to init UpdateManager, repos cannot be null\" ) ; } else { repositories = repos ; } if ( repositories == null && repositoriesJson != null ) { initRepositoriesFronJson ( ) ; protected synchronized void initRepositoriesFronJson ( ) { log . debug ( \"Read repositories from '{}'\" , repositoriesJson ) ; reader = new FileReader ( repositoriesJson . toFile ( ) ) ;", "del_tokens": "private static final String repositoriesFile = \"repositories.json\" ; private List < UpdateRepository > repositories ; if ( repositories == null ) { initRepositories ( ) ; private synchronized void initRepositories ( ) { log . debug ( \"Read repositories from '{}'\" , repositoriesFile ) ; reader = new FileReader ( repositoriesFile ) ;", "commit_type": "add"}
{"commit_tokens": ["Makes", "BoxRequest", "objects", "serializable", "."], "add_tokens": "import java . io . Serializable ; import java . util . concurrent . locks . ReentrantLock ; public abstract class BoxRequest < T extends BoxObject , R extends BoxRequest < T , R > > implements Serializable { protected transient ProgressListener mListener ; transient BoxRequestHandler mRequestHandler ; / * * * Serialize object . * * @ serialData The capacity ( int ) , followed by elements ( each an { @ code Object } ) in the proper order , followed by a null * @ param s * the stream * / private void writeObject ( java . io . ObjectOutputStream s ) throws java . io . IOException { // Write out capacity and any hidden stuff s . defaultWriteObject ( ) ; } / * * * Deserialize object . * * @ param s * the stream * / private void readObject ( java . io . ObjectInputStream s ) throws java . io . IOException , ClassNotFoundException { s . defaultReadObject ( ) ; mRequestHandler = new BoxRequestHandler ( this ) ; }", "del_tokens": "public abstract class BoxRequest < T extends BoxObject , R extends BoxRequest < T , R > > { protected ProgressListener mListener ; BoxRequestHandler mRequestHandler ;", "commit_type": "make"}
{"commit_tokens": ["Add", "root", "cause", "to", "unsupported", "protocol", "exception", "."], "add_tokens": "* @ throws UnsupportedProtocolException if URL protocol is not supported or arguments are otherwise not valid or null * - in which case root cause has details about erroneous argument .", "del_tokens": "* @ throws UnsupportedProtocolException if URL protocol is not supported .", "commit_type": "add"}
{"commit_tokens": ["Fix", "various", "exceptions", "in", "testing", "."], "add_tokens": "handleMessage ( new JsonMessage ( receive . getValue ( \"id\" ) , receive . getObject ( \"body\" ) , message ) ) ;", "del_tokens": "handleMessage ( new JsonMessage ( receive . getLong ( \"id\" ) , receive . getObject ( \"body\" ) , message ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "that", "occured", "when", "assigning", "instance", "id", "s", "and", "no", "channels", "were", "present", "in", "the", "layout", "."], "add_tokens": "int iHighest = - 1 ; if ( instanceIDs . size ( ) > 0 ) { iHighest = ( ( Integer ) instanceIDs . get ( instanceIDs . size ( ) - 1 ) ) . intValue ( ) ; }", "del_tokens": "int iHighest = ( ( Integer ) instanceIDs . get ( instanceIDs . size ( ) - 1 ) ) . intValue ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "HTTP", "status", "to", "FeignException"], "add_tokens": "private int status ; protected FeignException ( int status , String message ) { super ( message ) ; this . status = status ; } public int status ( ) { return this . status ; } return new FeignException ( response . status ( ) , message ) ;", "del_tokens": "return new FeignException ( message ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "issue", "with", "non", "matching", "property", "shifting", "column", "index"], "add_tokens": "while ( properties . size ( ) < columnIndex ) { properties . add ( null ) ; columns . add ( null ) ; } columns . add ( columnKey ) ; properties . add ( null ) ;", "del_tokens": "while ( properties . size ( ) < columnIndex ) { properties . add ( null ) ; columns . add ( null ) ; } columns . add ( columnKey ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "exceptionCaught", "/", "inbound", "message", "reached", "at", "the", "tail", "of", "the", "pipeline", "warnings"], "add_tokens": "import io . netty . channel . ChannelHandler ; addBeforeSessionHandler ( pipeline , newHttp2ConnectionHandler ( ) ) ; addBeforeSessionHandler ( pipeline , newHttp1Codec ( ) ) ; // NB: We do not call finishSuccessfully() immediately here // because it assumes HttpSessionHandler to be in the pipeline, // which is only true after the connection attempt is successful. pipeline . addLast ( new ChannelInboundHandlerAdapter ( ) { @ Override public void channelActive ( ChannelHandlerContext ctx ) throws Exception { ctx . pipeline ( ) . remove ( this ) ; finishSuccessfully ( pipeline , H1C ) ; ctx . fireChannelActive ( ) ; } } ) ; addBeforeSessionHandler ( pipeline , new HttpObjectAggregator ( options . maxFrameLength ( ) ) ) ; addBeforeSessionHandler ( pipeline , timeoutHandler ) ; void addBeforeSessionHandler ( ChannelPipeline pipeline , ChannelHandler handler ) { // Get the name of the HttpSessionHandler so that we can put our handlers before it. final String sessionHandlerName = pipeline . context ( HttpSessionHandler . class ) . name ( ) ; pipeline . addBefore ( sessionHandlerName , null , handler ) ; }", "del_tokens": "pipeline . addLast ( newHttp2ConnectionHandler ( ) ) ; pipeline . addLast ( newHttp1Codec ( ) ) ; finishSuccessfully ( pipeline , H1C ) ; pipeline . addLast ( new HttpObjectAggregator ( options . maxFrameLength ( ) ) ) ; pipeline . addLast ( timeoutHandler ) ; pipeline . addLast ( new HttpSessionHandler ( protocol ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "StopWatchQueueLength", "JMX", "parameter", "for", "monitoring", "the", "queue"], "add_tokens": "private static final String JMX_QUEUE_LENGTH = \"StopWatchQueueLength\" ; if ( attribute . equals ( JMX_QUEUE_LENGTH ) ) return m_queue . size ( ) ; attributes = new MBeanAttributeInfo [ m_jmxAttributes . length * ATTRS_PER_ITEM + 1 ] ; attributes [ attributes . length - 1 ] = new MBeanAttributeInfo ( JMX_QUEUE_LENGTH , \"int\" , \"Current StopWatch processing queue length (i.e. how many StopWatches are currently unprocessed)\" , true , false , false ) ;", "del_tokens": "attributes = new MBeanAttributeInfo [ m_jmxAttributes . length * ATTRS_PER_ITEM ] ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "repository", "changes", "."], "add_tokens": "import org . springframework . jdbc . core . JdbcTemplate ; final JdbcTemplate template , final String update , checkNotNull ( template , \"Received a null pointer as the JDBC template\" ) ; insertHandler = new SimpleJdbcInsert ( template ) . withTableName ( table ) jdbcTemplate = new NamedParameterJdbcTemplate ( template ) ;", "del_tokens": "import javax . sql . DataSource ; final DataSource dataSource , final String update , checkNotNull ( dataSource , \"Received a null pointer as the data source\" ) ; insertHandler = new SimpleJdbcInsert ( dataSource ) . withTableName ( table ) jdbcTemplate = new NamedParameterJdbcTemplate ( dataSource ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "FluentLoggerFactory", ".", "getLogger", "()", "tag", "param"], "add_tokens": "public FluentLogger getLogger ( String tagPrefix ) { return getLogger ( tagPrefix , \"localhost\" , 24224 ) ; public FluentLogger getLogger ( String tagPrefix , String host , int port ) { return getLogger ( tagPrefix , host , port , 3 * 1000 , 1 * 1024 * 1024 ) ; String tagPrefix , String host , int port , int timeout , int bufferCapacity ) { new Object [ ] { tagPrefix , host , port , timeout , bufferCapacity } ) ; FluentLogger logger = new FluentLogger ( tagPrefix , sender ) ;", "del_tokens": "public FluentLogger getLogger ( String tag ) { return getLogger ( tag , \"localhost\" , 24224 ) ; public FluentLogger getLogger ( String tag , String host , int port ) { return getLogger ( tag , host , port , 3 * 1000 , 1 * 1024 * 1024 ) ; String tag , String host , int port , int timeout , int bufferCapacity ) { new Object [ ] { tag , host , port , timeout , bufferCapacity } ) ; FluentLogger logger = new FluentLogger ( tag , sender ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "an", "issue", "introduced", "when", "adding", "constructor", "scope", "."], "add_tokens": "private static final EnumSet < Scope > METHOD_SCOPES = EnumSet . of ( Scope . NON_ABSTRACT_METHOD , Scope . CONSTRUCTOR , Scope . CONTROL_FLOW , Scope . INITIALIZER ) ; if ( ! METHOD_SCOPES . contains ( scopes . peekFirst ( ) ) ) {", "del_tokens": "Scope scope = scopes . peekFirst ( ) ; if ( scope != Scope . NON_ABSTRACT_METHOD && scope != Scope . CONTROL_FLOW && scope != Scope . INITIALIZER ) {", "commit_type": "fix"}
{"commit_tokens": ["update", "HttpConfig", "cache", "service", "relevant", "API"], "add_tokens": "cs = HttpConfig . sessionCache ( ) ;", "del_tokens": "cs = HttpConfig . cacheService ( ) ;", "commit_type": "update"}
{"commit_tokens": ["using", "filetreetraversal", "to", "read", "dictionaries"], "add_tokens": "import com . google . common . collect . ImmutableList ; List < File > fileList = this . getFilesInDir ( inputPath ) ; private List < File > getFilesInDir ( File inputPath ) { List < File > fileList = new ArrayList < File > ( ) ; for ( File aFile : Files . fileTreeTraverser ( ) . preOrderTraversal ( inputPath ) ) { if ( aFile . isFile ( ) ) { fileList . add ( aFile ) ; } } return fileList ; }", "del_tokens": "if ( inputPath . isDirectory ( ) ) { List < File > fileList = new ArrayList < File > ( ) ; for ( File aFile : Files . fileTreeTraverser ( ) . preOrderTraversal ( inputPath ) ) { fileList . add ( aFile ) ; } }", "commit_type": "use"}
{"commit_tokens": ["Fix", "mbean", "issue", "in", "JMINIX", "page", "of", "OO"], "add_tokens": "put ( WorkersMBean . class , \"com.hp.oo.engine.node.services.WorkersMBean\" ) ;", "del_tokens": "put ( WorkersMBean . class , null ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "minor", "bug", "in", "FileUtilities", "and", "migrated", "a", "helper", "method", "to", "XMLUtilities", "."], "add_tokens": "scanner = new Scanner ( file ) ; if ( scanner . hasNextLine ( ) ) { do { output . append ( scanner . nextLine ( ) ) ; } while ( scanner . hasNextLine ( ) ) ;", "del_tokens": "import java . io . FileReader ; boolean firstLine = true ; scanner = new Scanner ( new FileReader ( file ) ) ; while ( scanner . hasNextLine ( ) ) { // A new line should be skipped at the start of the file if ( ! firstLine ) { } else { firstLine = false ; } output . append ( scanner . nextLine ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "recentSessionsForUser", "so", "contributed", "as", "an", "action", "rather", "than", "as", "a", "collection", "."], "add_tokens": "contributed = Contributed . AS_ACTION @ MemberOrder ( name = \"user\" , sequence = \"1\" )", "del_tokens": "contributed = Contributed . AS_ASSOCIATION @ MemberOrder ( sequence = \"200.100\" )", "commit_type": "change"}
{"commit_tokens": ["Added", "additional", "set", "methods", "with", "latch", "to", "EVCache"], "add_tokens": "private StepCounter getCallsCounter , bulkCallsCounter , bulkHitsCounter , getHitsCounter , setCallsCounter , replaceCallCounter , delCallsCounter ; } else if ( op == Call . REPLACE ) { getReplaceCallCounter ( ) . increment ( ) ; getDeleteCallCounter ( ) . increment ( ) ; private StepCounter getReplaceCallCounter ( ) { if ( this . replaceCallCounter != null ) return this . replaceCallCounter ; this . replaceCallCounter = EVCacheMetricsFactory . getStepCounter ( appName , cacheName , \"ReplaceCall\" ) ; return replaceCallCounter ; } private StepCounter getDeleteCallCounter ( ) { + getHitCounter ( ) + \", bulkHits=\" + getBulkHitCounter ( ) + \", deleteCalls=\" + getDeleteCallCounter ( ) + getBulkCallDuration ( ) + \", replaceCalls=\" + getReplaceCallCounter ( ) + \"]\" ;", "del_tokens": "private StepCounter getCallsCounter , bulkCallsCounter , bulkHitsCounter , getHitsCounter , setCallsCounter , delCallsCounter ; getDelelteCallCounter ( ) . increment ( ) ; private StepCounter getDelelteCallCounter ( ) { + getHitCounter ( ) + \", bulkHits=\" + getBulkHitCounter ( ) + \", deleteCalls=\" + getDelelteCallCounter ( ) + getBulkCallDuration ( ) + \"]\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "2", "new", "events", "for", "improved", "compatability", "with", "SwipeRefreshLayout"], "add_tokens": "/ * * * Called once the user touches the screen and starts swiping in any direction * * @ param listView The originating { @ link ListView } . * @ param position The position to perform the action on , sorted in descending order * for convenience . * @ param direction The type of swipe that triggered the action * / @ Override public void onSwipeStarted ( ListView listView , int position , SwipeDirection direction ) { if ( mSwipeActionListener != null ) mSwipeActionListener . onSwipeStarted ( listView , position , direction ) ; } / * * * Called once the swiping motion ended ( user lifted finger ) * * @ param listView The originating { @ link ListView } . * @ param position The position to perform the action on , sorted in descending order * for convenience . * @ param direction The type of swipe that triggered the action * / @ Override public void onSwipeEnded ( ListView listView , int position , SwipeDirection direction ) { if ( mSwipeActionListener != null ) mSwipeActionListener . onSwipeEnded ( listView , position , direction ) ; } void onSwipeStarted ( ListView listView , int position , SwipeDirection direction ) ; void onSwipeEnded ( ListView listView , int position , SwipeDirection direction ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "basic", "test", "-", "just", "so", "I", "can", "get", "a", "feel", "of", "the", "use", ".", "Also", "Changing", "the", "RepositorySupport", "to", "require", "a", "LuceneAwareCouchDbConnector"], "add_tokens": "protected LuceneAwareCouchDbConnector db ; protected CouchDbRepositorySupportWithLucene ( Class < T > type , LuceneAwareCouchDbConnector db ) { this . db = db ; protected CouchDbRepositorySupportWithLucene ( Class < T > type , LuceneAwareCouchDbConnector db , boolean createIfNotExists ) { this . db = db ; protected CouchDbRepositorySupportWithLucene ( Class < T > type , LuceneAwareCouchDbConnector db , String designDocName ) { this . db = db ;", "del_tokens": "protected CouchDbRepositorySupportWithLucene ( Class < T > type , CouchDbConnector db ) { protected CouchDbRepositorySupportWithLucene ( Class < T > type , CouchDbConnector db , boolean createIfNotExists ) { protected CouchDbRepositorySupportWithLucene ( Class < T > type , CouchDbConnector db , String designDocName ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "formatting", "issues", "and", "small", "changes"], "add_tokens": "}", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "search", "for", "an", "equal", "min", "hash"], "add_tokens": "/ * If the source topic does not have a minhash signature , force the search query to match a non existent topic id so no results are returned . * / return new ArrayList < Integer > ( ) { { add ( - 1 ) ; } } ;", "del_tokens": "return null ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Async", "on", "long", "process"], "add_tokens": "import org . wisdom . api . annotations . scheduler . Async ; rowValues . nodes = new Node [ ] { row . getNode ( ) } ; \"query\" , query , \"language\" , language , \"languages\" , getLanguages ( ) , \"result\" , result , \"rows\" , rows , \"exception\" , exception ) ) ; @ Async", "del_tokens": "rowValues . nodes = new Node [ ] { row . getNode ( ) } ; \"query\" , query , \"language\" , language , \"languages\" , getLanguages ( ) , \"result\" , result , \"rows\" , rows , \"exception\" , exception ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "to", "CC", "Session", "Factory", "."], "add_tokens": "import net . java . slee . resource . diameter . cca . handlers . CCASessionCreationListener ; protected CCASessionCreationListener resourceAdaptor = null ; public CreditControlSessionFactory ( SessionFactory sessionFactory , CCASessionCreationListener resourceAdaptor , long messageTimeout ) public CreditControlSessionFactory ( SessionFactory sessionFactory , CCASessionCreationListener resourceAdaptor , long messageTimeout ,", "del_tokens": "protected CCAResourceAdaptor resourceAdaptor = null ; public CreditControlSessionFactory ( SessionFactory sessionFactory , CCAResourceAdaptor resourceAdaptor , long messageTimeout ) public CreditControlSessionFactory ( SessionFactory sessionFactory , CCAResourceAdaptor resourceAdaptor , long messageTimeout ,", "commit_type": "fix"}
{"commit_tokens": ["Move", "keys", "to", "testing", ".", "properties"], "add_tokens": "public class TheTvDbApiTest extends AbstractTests { tvdb = new TheTVDBApi ( getApiKey ( ) ) ; doConfiguration ( ) ;", "del_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class TheTvDbApiTest { private static final Logger LOG = LoggerFactory . getLogger ( TheTvDbApiTest . class ) ; private static final String API_KEY = \"2805AD2873519EC5\" ; tvdb = new TheTVDBApi ( API_KEY ) ; TestLogger . Configure ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "inverted", "condition", "on", "equals"], "add_tokens": "! additionalPermissions . equals ( that . additionalPermissions ) : that . additionalPermissions == null ) return false ;", "del_tokens": "additionalPermissions . equals ( that . additionalPermissions ) : that . additionalPermissions == null ) return false ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "invalid", "length", "calculation", "."], "add_tokens": "final ByteBuffer buffer = charset . encode ( CharBuffer . wrap ( name ) ) ; int length = buffer . remaining ( ) + 1 ; Util . empty ( channel , buffer ) ;", "del_tokens": "int length = name . length ( ) + 1 ; Util . empty ( channel , charset . encode ( CharBuffer . wrap ( name ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "dropwizard", "-", "db", "depend", "on", "metrics", "-", "jdbi", "."], "add_tokens": "import com . yammer . metrics . jdbi . InstrumentedTimingCollector ; setTimingCollector ( new InstrumentedTimingCollector ( Metrics . defaultRegistry ( ) , Database . class ) ) ;", "del_tokens": "setTimingCollector ( new MetricsTimingCollector ( Metrics . defaultRegistry ( ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "option", "to", "use", "square", "or", "circle", "color", "items"], "add_tokens": "// Find preference and add code to handle showing the ColorPickerDialogFragment once requested. // .setColorShape(ColorPanelView.Shape.RECT)", "del_tokens": "// Find preference and add code to handle showing the ColorPickerDialogFragment // once requested.", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "folder", "name", "modification", "feature"], "add_tokens": "public static final String EXTRA_ALLOW_NEW_DIR_NAME_MODIFICIATION = \"allow_directory_name_modification\" ; final boolean allowNewDirNameModification = getIntent ( ) . getBooleanExtra ( EXTRA_ALLOW_NEW_DIR_NAME_MODIFICIATION , true ) ; final DirectoryChooserFragment fragment = DirectoryChooserFragment . newInstance ( newDirName , initialDir , allowReadOnlyDir , allowNewDirNameModification ) ;", "del_tokens": "final DirectoryChooserFragment fragment = DirectoryChooserFragment . newInstance ( newDirName , initialDir , allowReadOnlyDir ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "servlet", "request", "method", "not", "Pippo", "method", "for", "the", "CSRF", "handler"], "add_tokens": "String httpSerlvetRequestMethod = context . getRequest ( ) . getHttpServletRequest ( ) . getMethod ( ) ; if ( HttpMethod . POST . equals ( httpSerlvetRequestMethod ) ) { } else if ( HttpMethod . GET . equals ( httpSerlvetRequestMethod ) ) { log . debug ( \"Generated '{}' for {} '{}'\" , TOKEN , httpSerlvetRequestMethod , context . getRequestUri ( ) ) ;", "del_tokens": "if ( HttpMethod . POST . equals ( context . getRequestMethod ( ) ) ) { } else if ( HttpMethod . GET . equals ( context . getRequestMethod ( ) ) ) { log . debug ( \"Generated '{}' for {} '{}'\" , TOKEN , context . getRequestMethod ( ) , context . getRequestUri ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Made", "stream", "deserialization", "an", "option"], "add_tokens": "if ( jacksonDBCollection . isEnabled ( JacksonDBCollection . Feature . USE_STREAM_DESERIALIZATION ) ) { this . cursor . setDecoderFactory ( jacksonDBCollection . getDecoderFactory ( ) ) ; }", "del_tokens": "this . cursor . setDecoderFactory ( jacksonDBCollection . getDecoderFactory ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "unnecessary", "line", "breaks", "in", "ConsoleWriter", "and", "Slf4jWriter", "."], "add_tokens": "String msg = result . getName ( ) + \" \" + result . getValue ( ) + \" \" + result . getEpoch ( TimeUnit . SECONDS ) ;", "del_tokens": "String msg = result . getName ( ) + \" \" + result . getValue ( ) + \" \" + result . getEpoch ( TimeUnit . SECONDS ) + \"\\n\" ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "syncAndReturnAll", "rather", "than", "sync"], "add_tokens": "pipe . syncAndReturnAll ( ) ; pipe . syncAndReturnAll ( ) ;", "del_tokens": "pipe . sync ( ) ; pipe . sync ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "typo", "in", "datatype", "-", "mapper"], "add_tokens": "* * @ XmlRootElement ( name = \"datatype-mapper\" )", "del_tokens": "* * @ XmlRootElement ( name = \"destination-mapper\" )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "an", "evil", "typo", "that", "causes", "all", "the", "global", "coordinates", "to", "fail", "to"], "add_tokens": "long longitude = jsonGlobeCoordinate . getLong ( \"longitude\" ) ;", "del_tokens": "long longitude = jsonGlobeCoordinate . getLong ( \"longitiude\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "hadoopclusters", ".", "properties", "from", "resources", "and", "moved", "to", "test"], "add_tokens": "import java . io . InputStream ; import org . apache . commons . logging . Log ; import org . apache . commons . logging . LogFactory ; private static Log LOG = LogFactory . getLog ( Cluster . class ) ; InputStream inp = Cluster . class . getResourceAsStream ( \"/hadoopclusters.properties\" ) ; if ( inp == null ) { LOG . warn ( \"hadoopclusters.properties does not exists\" ) ; } prop . load ( inp ) ;", "del_tokens": "prop . load ( Cluster . class . getResourceAsStream ( \"/hadoopclusters.properties\" ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "EditText", "1dp", "on", "ldpi", "crash", "fixed", "discrete", "SeekBar", "s", "listener", "called", "every", "touch", "fixed", "ViewPropertyAnimator", "breaks", "ImageActionButton", "elevation", "shadow", "fixed", "Borderless", "Ripple", "not", "being", "rendered", "when", "setRippleDrawable", "is", "called", "Multiple", "Times", "fixed", "NPE", "in", "PagerTabStrip"], "add_tokens": "return context . getResources ( ) . getDimensionPixelSize ( R . dimen . carbon_iconSize ) ;", "del_tokens": "return ( int ) ( context . getResources ( ) . getDimension ( R . dimen . carbon_1dip ) * 24 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "problem", "with", "grandparents", "in", "the", "case", "of", "a", "root", "node", "with", "empty", "extent"], "add_tokens": "private static final boolean DEBUG = true ; private static final boolean DDDEBUG = true ; } if ( DDEBUG ) System . err . println ( \"getParentGrandExitNode(\" + v + \", \" + stack + \")\" ) ; if ( parentExitNode == root ) return null ; if ( parentExitNode . parentExtentLength == 0 ) { stack . push ( ( InternalNode < T > ) root ) ; return ( InternalNode < T > ) root ; } if ( a == 0 && ( ( InternalNode < T > ) root ) . extentLength == 0 ) {", "del_tokens": "private static final boolean DEBUG = false ; private static final boolean DDDEBUG = false ; } if ( a == 0 && root . extentLength ( transform ) == 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["removed", "security", "from", "dataeditor", "sample"], "add_tokens": "JXTaskPaneNavigatorApplicationWindowFactory navigatorApplicationWindowFactory = new JXTaskPaneNavigatorApplicationWindowFactory ( ) ; return navigatorApplicationWindowFactory ;", "del_tokens": "import com . jgoodies . looks . plastic . PlasticXPLookAndFeel ; import com . jgoodies . looks . plastic . theme . ExperienceGreen ; import org . pushingpixels . substance . api . skin . SubstanceChallengerDeepLookAndFeel ; import org . valkyriercp . application . support . DefaultApplicationWindowFactory ; import org . valkyriercp . form . binding . swing . editor . LookupBinder ; import org . valkyriercp . taskpane . TaskPaneNavigatorApplicationWindowFactory ; JXTaskPaneNavigatorApplicationWindowFactory jxTaskPaneNavigatorApplicationWindowFactory = new JXTaskPaneNavigatorApplicationWindowFactory ( ) ; return jxTaskPaneNavigatorApplicationWindowFactory ;", "commit_type": "remove"}
{"commit_tokens": ["Changing", "Activator", "as", "ManagedService", "instead", "as", "Andreas", "suggested", "."], "add_tokens": "import java . util . Dictionary ; import org . osgi . service . cm . ConfigurationException ; implements BundleActivator , ManagedService m_RegistrationManagedService = bundleContext . registerService ( Activator . class . getName ( ) , this , properties ) ; public void updated ( Dictionary dictionary ) throws ConfigurationException m_Log4jServiceFactory . updated ( dictionary ) ;", "del_tokens": "import org . osgi . framework . Bundle ; import org . osgi . framework . ServiceFactory ; implements BundleActivator , ServiceFactory String managedServiceName = ManagedService . class . getName ( ) ; m_RegistrationManagedService = bundleContext . registerService ( managedServiceName , this , properties ) ; public Object getService ( Bundle bundle , ServiceRegistration registration ) return m_Log4jServiceFactory ; } public void ungetService ( Bundle bundle , ServiceRegistration registration , Object service ) { // Dont think we need to dispose of it since it will be the same instance returned // the next time getService is called.", "commit_type": "change"}
{"commit_tokens": ["add", "some", "debug", "messages", "."], "add_tokens": "logger . info ( \"Load \" + file ) ; logger . info ( \"Save \" + data + \" into \" + file ) ; if ( data == null ) { throw new NotAvailableException ( \"data\" ) ; } logger . info ( \"Save \" + data + \" into \" + file ) ; logger . info ( \"Create \" + file ) ; if ( data == null ) { throw new NotAvailableException ( \"data\" ) ; }", "del_tokens": "if ( data == null ) { throw new NotAvailableException ( \"data\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Allow", "registration", "of", "currencies", "to", "replace", "existing"], "add_tokens": "CurrencyUnit . registerCurrency ( currencyCode , numericCurrencyCode , decimalPlaces , countryCodes , true ) ;", "del_tokens": "CurrencyUnit . registerCurrency ( currencyCode , numericCurrencyCode , decimalPlaces , countryCodes ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "file", "mapper", "for", "by", "year"], "add_tokens": "long downSampleIntervalMs , Func1 < Fix , String > fileMapper ) {", "del_tokens": "import au . gov . amsa . risky . format . BinaryFixesWriter . ByMonth ; long downSampleIntervalMs ) { ByMonth fileMapper = new BinaryFixesWriter . ByMonth ( output ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "sse", "connect", "with", "last", "event", "id"], "add_tokens": "import io . joshworks . snappy . client . sse . SseClientCallback ; } , null ) ; } public static SSEConnection connect ( String url , Consumer < EventData > callback , String lastEventId ) { return connect ( ClientManager . lookup ( url ) , new SseClientCallback ( ) { @ Override public void onEvent ( EventData data ) { callback . accept ( data ) ; } } , lastEventId ) ; return connect ( url , callback , null ) ; } public static SSEConnection connect ( String url , SseClientCallback callback , String lastEventId ) { SSEConnection connection = new SSEConnection ( ClientManager . lookup ( url ) , lastEventId , callback , ClientManager . getWorker ( ) ) ;", "del_tokens": "import io . joshworks . snappy . client . sse . SseClientCallback ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import static io . joshworks . snappy . SnappyServer . * ; private static final Logger logger = LoggerFactory . getLogger ( LOGGER_NAME ) ; } ) ; SSEConnection connection = new SSEConnection ( ClientManager . lookup ( url ) , callback , ClientManager . getWorker ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "article", "AN", "and", "words", "like", "ANIMAL", "etc", "."], "add_tokens": "private static final String [ ] ARTICLES = new String [ ] { \"THE\" , \"AN \" , \"A \" } ;", "del_tokens": "private static final String [ ] ARTICLES = new String [ ] { \"THE\" , \"AN\" , \"A \" } ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "EmptyImageLoadingListener", "using", "to", "avoid", "null", "checking"], "add_tokens": "private ImageLoaderConfiguration configuration ; private ImageLoadingListener emptyListener ; emptyListener = new EmptyImageLoadingListener ( ) ; if ( listener == null ) { listener = emptyListener ; } if ( options == null ) { options = configuration . defaultDisplayImageOptions ; } listener . onLoadingStarted ( ) ; imageLoadingInfo . listener . onLoadingFailed ( ) ; imageLoadingInfo . listener . onLoadingComplete ( ) ; private class EmptyImageLoadingListener implements ImageLoadingListener { @ Override public void onLoadingStarted ( ) { } @ Override public void onLoadingFailed ( ) { } @ Override public void onLoadingComplete ( ) { } }", "del_tokens": "private ImageLoaderConfiguration configuration = null ; if ( listener != null ) { listener . onLoadingStarted ( ) ; } if ( options == null ) { options = configuration . defaultDisplayImageOptions ; } if ( imageLoadingInfo . listener != null ) { imageLoadingInfo . listener . onLoadingFailed ( ) ; } // Notify listener if ( imageLoadingInfo . listener != null ) { imageLoadingInfo . listener . onLoadingComplete ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["added", "method", "to", "delete", "observer"], "add_tokens": "if ( ! parameter . equals ( this . parameter ) ) {", "del_tokens": "if ( parameter . equals ( this . parameter ) ) {", "commit_type": "add"}
{"commit_tokens": ["Using", "default", "JDK", "6", "dynamic", "compile"], "add_tokens": "throw new RuntimeException ( \"Param 'path' value should be a path directory. path=\" + path ) ;", "del_tokens": "throw new RuntimeException ( \"Param 'path' value should be a path directory.\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "method", "fromRequest", "to", "ImageRequestBuilder"], "add_tokens": "// The resize options are used to determine whether images are going to be downsampled during // decode or not. For the case where the image has to be downsampled and it's a local image it // will be kept as a FileInputStream until decoding instead of reading it in memory. Since // this method returns an encoded image, it should always be read into memory. Therefore, the // resize options are ignored to avoid treating the image as if it was to be downsampled // during decode. imageRequest = ImageRequestBuilder . fromRequest ( imageRequest ) . setResizeOptions ( null )", "del_tokens": "ImageRequestBuilder builder = ImageRequestBuilder . newBuilderWithSource ( imageRequest . getSourceUri ( ) ) ; imageRequest = builder . setAutoRotateEnabled ( imageRequest . getAutoRotateEnabled ( ) ) . setImageDecodeOptions ( imageRequest . getImageDecodeOptions ( ) ) . setImageType ( imageRequest . getImageType ( ) ) . setLocalThumbnailPreviewsEnabled ( imageRequest . getLocalThumbnailPreviewsEnabled ( ) ) . setLowestPermittedRequestLevel ( imageRequest . getLowestPermittedRequestLevel ( ) ) . setPostprocessor ( imageRequest . getPostprocessor ( ) ) . setProgressiveRenderingEnabled ( imageRequest . getProgressiveRenderingEnabled ( ) ) . setRequestPriority ( imageRequest . getPriority ( ) )", "commit_type": "add"}
{"commit_tokens": ["Move", "Mindmaps", ".", "java", "to", "core", "module", "start", "work", "on", "OWL", "reasoning", "tests"], "add_tokens": "public MindmapsGraphFactoryInMemory ( String keyspace , String ignored ) {", "del_tokens": "public MindmapsGraphFactoryInMemory ( String keyspace ) {", "commit_type": "move"}
{"commit_tokens": ["Make", "Quantity", "numeric", "only", "."], "add_tokens": "public abstract class Quantity < T extends Number > { return mValue . doubleValue ( ) ; return mValue . intValue ( ) ;", "del_tokens": "public abstract class Quantity < T > { return 0.0 ; return 0 ;", "commit_type": "make"}
{"commit_tokens": ["Made", "the", "OpenIdService", "compliant", "with", "the", "specs", ".", "Returns", "parameters", "encoded", "with", "Base64", "then", "where", "\\", "r", "are", "removed", "."], "add_tokens": "private static final String CR = \"\\r\\n\" ; return Base64 . encodeBase64String ( sha1 . doFinal ( value . getBytes ( ) ) ) . replaceAll ( CR , \"\" ) ; return Base64 . encodeBase64String ( ENCODER . encode ( value ) . getBytes ( ) ) . replaceAll ( CR , \"\" ) ;", "del_tokens": "private static final String CRLF = \"\\r\\n\" ; return Base64 . encodeBase64String ( sha1 . doFinal ( value . getBytes ( ) ) ) . replaceAll ( CRLF , \"\" ) ; return Base64 . encodeBase64String ( ENCODER . encode ( value ) . getBytes ( ) ) . replaceAll ( CRLF , \"\" ) ;", "commit_type": "make"}
{"commit_tokens": ["fixed", "bug", "with", "query", "dependencies"], "add_tokens": "// subjectsMatch.setPage(0, 5);", "del_tokens": "subjectsMatch . setPage ( 0 , 5 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "hide", "/", "unhide", "for", "a", "submission", ".", "Also", "fixed", "testing", "for", "my", "prev", ".", "work", "."], "add_tokens": "public static JSONObject createSubmission ( String redditObjId , boolean nsfw , boolean saved , boolean hidden ) { return createSubmission ( redditObjId , nsfw , saved , hidden , null , new JSONObject ( ) ) ; public static JSONObject createSubmission ( String redditObjId , boolean nsfw , boolean saved , boolean hidden , JSONObject media , JSONObject mediaEmbed ) { submission . put ( \"hidden\" , hidden ) ; submission . put ( \"saved\" , saved ) ;", "del_tokens": "public static JSONObject createSubmission ( String redditObjId , boolean nsfw ) { return createSubmission ( redditObjId , nsfw , null , new JSONObject ( ) ) ; public static JSONObject createSubmission ( String redditObjId , boolean nsfw , JSONObject media , JSONObject mediaEmbed ) { submission . put ( \"hidden\" , false ) ; submission . put ( \"saved\" , false ) ;", "commit_type": "implement"}
{"commit_tokens": ["Using", "ServerRequestQueue", "in", "Branch", ".", "java"], "add_tokens": "public boolean containsInstallOrOpen ( ) { public void moveInstallOrOpenToFront ( String tag , int networkCount ) { if ( req . getTag ( ) . equals ( BranchRemoteInterface . REQ_TAG_REGISTER_INSTALL ) || req . getTag ( ) . equals ( BranchRemoteInterface . REQ_TAG_REGISTER_OPEN ) ) { iter . remove ( ) ; break ; ServerRequest req = new ServerRequest ( tag ) ; if ( networkCount == 0 ) { insert ( req , 0 ) ; } else { insert ( req , 1 ) ; }", "del_tokens": "private boolean containsInstallOrOpen ( ) { public boolean containsClose ( ) { if ( req . getTag ( ) . equals ( BranchRemoteInterface . REQ_TAG_REGISTER_CLOSE ) ) { return true ; return false ; } public void moveInstallOrOpenToFront ( String tag ) {", "commit_type": "use"}
{"commit_tokens": ["Use", "StringUtils", "from", "already", "imported", "commons", "-", "lang"], "add_tokens": "import org . apache . commons . lang . StringUtils ;", "del_tokens": "import org . primefaces . extensions . util . StringUtils ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "a", "working", "dynamic", "programming", "parser", "from", "Posterior", "Regularization", "toolkit"], "add_tokens": "import edu . jhu . hltcoe . parse . DmvCkyParser ; evalParser = new DmvCkyParser ( ) ; if ( parserName . startsWith ( \"ilp-\" ) ) { if ( parserName . equals ( \"cky\" ) ) { parser = new DmvCkyParser ( ) ; } else if ( parserName . equals ( \"ilp-sentence\" ) ) { parser = new InitializedIlpViterbiParserWithDeltas ( formulation , ilpSolverFactory , deltaGen , ilpSolverFactory ) ;", "del_tokens": "IlpSolverFactory evalIlpSolverFactory = null ; if ( parserName . equals ( \"ilp-sentence\" ) || parserName . equals ( \"ilp-corpus\" ) || parserName . equals ( \"ilp-deltas\" ) || parserName . equals ( \"ilp-deltas-init\" ) ) { if ( ilpSolverId == IlpSolverId . DIP_MILPBLOCK_PC || ilpSolverId == IlpSolverId . DIP_MILPBLOCK_CPM ) { // Don't use this for evaluation evalIlpSolverFactory = new IlpSolverFactory ( IlpSolverId . CPLEX , numThreads , ilpWorkMemMegs ) ; } else { evalIlpSolverFactory = ilpSolverFactory ; } evalParser = new IlpViterbiSentenceParser ( formulation , evalIlpSolverFactory ) ; if ( parserName . equals ( \"ilp-sentence\" ) ) { parser = new InitializedIlpViterbiParserWithDeltas ( formulation , ilpSolverFactory , deltaGen , evalIlpSolverFactory ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "-", "Ddebug", "property", "handling", "removed", "render", "time"], "add_tokens": "if ( System . getProperty ( \"debug\" ) != null ) { System . out . println ( res ) ; }", "del_tokens": "// System.out.println(res);", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "on", "exit", "app"], "add_tokens": "import java . nio . file . Path ; Path sampledir = getSampleDir ( destDir . toPath ( ) ) ; if ( ! sampledir . toFile ( ) . exists ( ) ) { sampledir . toFile ( ) . mkdirs ( ) ; client . start ( getSampleDir ( baseDir . toPath ( ) ) , callback ) ; client . stop ( getSampleDir ( baseDir . toPath ( ) ) , null ) ; client . stop ( getSampleDir ( baseDir . toPath ( ) ) , callback ) ; private Path getSampleDir ( Path baseDir ) { return baseDir . resolve ( baseDir ) ;", "del_tokens": "File sampledir = getSampleDir ( destDir ) ; if ( ! sampledir . exists ( ) ) { sampledir . mkdirs ( ) ; client . start ( getSampleDir ( baseDir ) , callback ) ; client . stop ( getSampleDir ( baseDir ) , null ) ; client . stop ( getSampleDir ( baseDir ) , callback ) ; private File getSampleDir ( File baseDir ) { return new File ( baseDir , \"sample\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "className", "manipulation", "which", "was", "copied", "from", "UIObject", "because", "it", "was", "moved", "into", "Element", "so", "there", "is", "no", "reason", "to", "maintain", "this", "code", "any", "more"], "add_tokens": "// toggleClass() gq . toggleClass ( \"b2\" ) ; assertTrue ( gq . hasClass ( \"b1\" ) ) ; assertFalse ( gq . hasClass ( \"b2\" ) ) ; gq . toggleClass ( \"b2\" ) ; assertTrue ( gq . hasClass ( \"b1\" ) ) ; assertTrue ( gq . hasClass ( \"b2\" ) ) ; gq . toggleClass ( \"b2\" , true ) ; assertTrue ( gq . hasClass ( \"b2\" ) ) ; gq . toggleClass ( \"b2\" , false ) ; assertFalse ( gq . hasClass ( \"b2\" ) ) ;", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["adding", "in", "support", "for", "LocationDerefencingService", ".", "Also", "updating", "the", "README", "to", "asciidoc", "."], "add_tokens": "* Optional SPI service that allows a { @ link Locatable } object to be translated / dereferenced to some other object , typically its owner . The markers on the map then open up the dereferenced object , rather than the < tt > Locatable < / tt > . * For example , the < tt > incode - module - commchannel < / tt > 's <tt>PostalAddress</tt> implements <tt>Locatable</tt>, but this service allows the <i>owner</i> of the", "del_tokens": "* Optional SPI service that allows a { @ link Locatable } object to be mapped to some other object , typically its owner . The markers on the map then open up the mapped object , rather than the < tt > Locatable < / tt > . * For example , the < tt > isis - module - commchannel < / tt > 's <tt>PostalAddress</tt> implements <tt>Locatable</tt>, but this service allows the <i>owner</i> of the", "commit_type": "add"}
{"commit_tokens": ["add", "renderJsonOutputCharset", "configuration", "into", "MvcConfig"], "add_tokens": "setOutputEncoding ( MvcConfig . renderJsonOutputCharset ( ) ) ; super ( jsonStr , H . Format . JSON , MvcConfig . renderJsonOutputCharset ( ) ) ; super ( S . fmt ( jsonFormat , args ) , H . Format . JSON , MvcConfig . renderJsonOutputCharset ( ) ) ; super ( status , jsonStr , H . Format . JSON , MvcConfig . renderJsonOutputCharset ( ) ) ; super ( status , S . fmt ( jsonFormat , args ) , H . Format . JSON , MvcConfig . renderJsonOutputCharset ( ) ) ;", "del_tokens": "setOutputEncoding ( false ) ; / * * By default we don 't output encoding. See http://www.ietf.org/rfc/rfc7159.txt * / super ( jsonStr , H . Format . JSON , false ) ; super ( S . fmt ( jsonFormat , args ) , H . Format . JSON , false ) ; super ( status , jsonStr , H . Format . JSON , false ) ; super ( status , S . fmt ( jsonFormat , args ) , H . Format . JSON , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "salt", "sources", "pluggable", "."], "add_tokens": "import net . sf . acegisecurity . providers . encoding . PasswordEncoder ; import net . sf . acegisecurity . providers . encoding . PlaintextPasswordEncoder ; private SaltSource saltSource ; / * * * The source of salts to use when decoding passwords . < code > null < / code > * is a valid value , meaning the < code > DaoAuthenticationProvider < / code > * will present < code > null < / code > to the relevant * < code > PasswordEncoder < / code > . * * @ param saltSource to use when attempting to decode passwords via the * < code > PasswordEncoder < / code > * / public void setSaltSource ( SaltSource saltSource ) { this . saltSource = saltSource ; } public SaltSource getSaltSource ( ) { return saltSource ; } Object salt = null ; if ( this . saltSource != null ) { salt = this . saltSource . getSalt ( user ) ; } authentication . getCredentials ( ) . toString ( ) , salt ) ) {", "del_tokens": "import net . sf . acegisecurity . providers . encoding . * ; authentication . getCredentials ( ) . toString ( ) , user ) ) {", "commit_type": "make"}
{"commit_tokens": ["add", "ui", "collection", "and", "scrollable"], "add_tokens": "uiObjectStub . useUiObjectSelector ( new UiSelector ( ) . text ( app ) ) ; uiObjectStub . swipeLeft ( 10 ) ; uiObjectStub . swipeRight ( 10 ) ; uiDeviceStub . waitForIdle ( ) ; Thread . sleep ( 5000 ) ; uiObjectStub . useUiObjectSelector ( new UiSelector ( ) . text ( \"Book\" ) ) ;", "del_tokens": "uiDeviceStub . waitForIdle ( ) ; uiObjectStub . useSelector ( new UiSelector ( ) . text ( app ) ) ; uiObjectStub . useSelector ( new UiSelector ( ) . text ( \"Book\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "delta", "for", "float", "comparison", "in", "ResizeSettings"], "add_tokens": "public static float DELTA = 0.000001f ; if ( Math . abs ( quality ) < DELTA ) { } else if ( quality + DELTA > 1.0f ) {", "del_tokens": "if ( quality < 0 ) { } else if ( quality > 1.0f ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "total", "checks", "with", "failures", "information"], "add_tokens": "import java . util . HashSet ; import java . util . Set ; private int passCount = 0 ; private int errorCount = 0 ; private Set < String > suitesWithError = new HashSet < String > ( ) ; private String currentSuite ; errorCount ++ ; suitesWithError . add ( currentSuite ) ; passCount ++ ; currentSuite = suite . getName ( ) ; out . println ( ) ; out . println ( \"========================================\" ) ; out . println ( \"----------------------------------------\" ) ; out . println ( \"========================================\" ) ; if ( suitesWithError . size ( ) > 0 ) { out . println ( \"Failed suites:\" ) ; for ( String name : suitesWithError ) { out . println ( \" \" + name ) ; } out . println ( ) ; } out . print ( \"Status: \" ) ; if ( errorCount > 0 ) { out . println ( \"FAIL\" ) ; out . println ( \"Total failures: \" + errorCount ) ; } else { out . println ( \"PASS\" ) ; } int totalTests = passCount + errorCount ; out . println ( \"Total tests: \" + totalTests ) ;", "del_tokens": "// TODO Output amount of failed specs and list failed tests", "commit_type": "add"}
{"commit_tokens": ["Added", "multiple", "pagination", "strategies", "(", "offset", "pages", "none", ")", ".", "Changed", "default", "implementaiton", "to", "use", "offsets", ".", "Added", "hard", "limit", "offset", "pagination", "to", "all", "resources", "when", "pagination", "parameters", "are", "not", "specified", "."], "add_tokens": "pagination = new Pagination ( Pagination . Strategy . NONE , 0 , 0 ) ; final long begin = pagination . getOffset ( ) ; final long end = begin + pagination . getLimit ( ) ;", "del_tokens": "import java . lang . reflect . InvocationTargetException ; import java . lang . reflect . Method ; pagination = new Pagination ( 0 , 0 ) ; final long begin = ( pagination . getPage ( ) * pagination . getSize ( ) ) - pagination . getSize ( ) ; final long end = begin + pagination . getSize ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "couple", "of", "things", "in", "the", "application"], "add_tokens": "import javax . sip . TransactionAlreadyExistsException ; import javax . sip . TransactionUnavailableException ; import javax . sip . message . Request ; ServerTransaction transaction = requestEvent . getServerTransaction ( ) ; Request request = requestEvent . getRequest ( ) ; logger . info ( \"Got a request event \" + request . getMethod ( ) ) ; if ( transaction == null ) { try { transaction = sp . getNewServerTransaction ( request ) ; } catch ( TransactionUnavailableException tae ) { //TODO Create a 500 Internal server error and return it here. return ; } catch ( TransactionAlreadyExistsException taex ) { // Already processed this request so just return. return ; } } SipSessionImpl session = sessionManager . getRequestSession ( requestEvent , transaction ) ; logger . info ( \"Routing of Subsequent Request -- TODO\" ) ;", "del_tokens": "logger . info ( \"Got a request event\" ) ; SipSessionImpl session = sessionManager . getRequestSession ( requestEvent ) ; SIPRequest request = ( SIPRequest ) requestEvent . getRequest ( ) ; ServerTransaction transaction = ( ServerTransaction ) request . getTransaction ( ) ; //TODO Routing subsequent requests.", "commit_type": "fix"}
{"commit_tokens": ["Added", "work", "around", "for", "Tomcat", "7", "NPE"], "add_tokens": "private static final ICommonsSet < String > s_aUniqueUserAgents = new CommonsHashSet < > ( ) ; try { aHttpRequest . setAttribute ( REQUEST_ATTR , aUserAgent ) ; } catch ( final Throwable t ) { // Happens in certain Tomcat versions (e.g. 7.0.42 with JDK 8): / * * * < pre > java . lang . NullPointerException 1. : org . apache . catalina . connector . Request . notifyAttributeAssigned ( Request . java : 1493 ) 2. : org . apache . catalina . connector . Request . setAttribute ( Request . java : 1483 ) 3. : org . apache . catalina . connector . RequestFacade . setAttribute ( RequestFacade . java : 539 ) * < / pre > * / s_aLogger . warn ( \"Failed to set user agent in request\" , t ) ; }", "del_tokens": "private static final ICommonsSet < String > s_aUniqueUserAgents = new CommonsHashSet < > ( ) ; aHttpRequest . setAttribute ( REQUEST_ATTR , aUserAgent ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "to", "be", "able", "to", "insert", "a", "new", "column", "at", "a", "specific", "index"], "add_tokens": "addColumn ( ) ; addColumn ( ) ; addColumn ( ) ; addColumn ( ) ; addColumn ( ) ; addColumn ( ) ; private void addColumn ( ) { mBoardView . addColumn ( listAdapter , header , header , false ) ;", "del_tokens": "import android . widget . Toast ; addColumnList ( ) ; addColumnList ( ) ; addColumnList ( ) ; addColumnList ( ) ; addColumnList ( ) ; addColumnList ( ) ; private void addColumnList ( ) { mBoardView . addColumnList ( listAdapter , header , header , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "possible", "XSS", "in", "PageHeader"], "add_tokens": "getElement ( ) . setInnerSafeHtml ( builder . toSafeHtml ( ) ) ;", "del_tokens": "getElement ( ) . setInnerHTML ( builder . toSafeHtml ( ) . asString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "constructor", "for", "signed", "functions"], "add_tokens": "import com . martiansoftware . jsap . stringparsers . FileStringParser ; final BitVector bitVector = transform . toBitVector ( ( T ) o ) ; new FlaggedOption ( \"tempDir\" , FileStringParser . getParser ( ) , JSAP . NO_DEFAULT , JSAP . NOT_REQUIRED , 'T' , \"temp-dir\" , \"A directory for temporary files.\" ) , new FlaggedOption ( \"signatureWidth\" , JSAP . INTEGER_PARSER , JSAP . NO_DEFAULT , JSAP . NOT_REQUIRED , 's' , \"signature-width\" , \"If specified, the signature width in bits; if negative, the generated function will be a dictionary.\" ) , final File tempDir = jsapResult . getFile ( \"tempDir\" ) ; final int signatureWidth = jsapResult . getInt ( \"signatureWidth\" , 0 ) ; BinIO . storeObject ( new LcpMonotoneMinimalPerfectHashFunction < CharSequence > ( collection , - 1 , transformationStrategy , signatureWidth , tempDir ) , functionName ) ;", "del_tokens": "final BitVector bitVector = transform . toBitVector ( ( T ) o ) . fast ( ) ; BinIO . storeObject ( new LcpMonotoneMinimalPerfectHashFunction < CharSequence > ( collection , transformationStrategy ) , functionName ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "Mockito", "and", "some", "simple", "test", "cases"], "add_tokens": "return true ;", "del_tokens": "return false ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "make", "internal", "constructor", "package", "access", "only", "."], "add_tokens": "ConstraintType ( String type )", "del_tokens": "public ConstraintType ( String type )", "commit_type": "update"}
{"commit_tokens": ["use", "static", "variable", "to", "save", "some", "memory"], "add_tokens": "private static final Properties properties = new Properties ( ) ;", "del_tokens": "private final Properties properties = new Properties ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "JavaDoc", "Rename", "extract", "binding", "to", "map"], "add_tokens": "public class ObjectBindings_map_Test { public void testMap ( ) { ObjectBinding < String > name = ObjectBindings . map ( selectedPerson , Person :: getName ) ; public void testMapWithDefaultValue ( ) { ObjectBinding < String > name = ObjectBindings . map ( selectedPerson , Person :: getName , \"empty\" ) ;", "del_tokens": "public class ObjectBindings_extract_Test { public void testExtract ( ) { ObjectBinding < String > name = ObjectBindings . extract ( selectedPerson , Person :: getName ) ; public void testExtractWithDefaultValue ( ) { ObjectBinding < String > name = ObjectBindings . extract ( selectedPerson , Person :: getName , \"empty\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "typo", "in", "unit", "tests"], "add_tokens": "isTrue ( ! String . valueOf ( separator ) . matches ( \"[\\\"\\\\s]\" ) , \"Separator contains illegal character(%s)\" , String . valueOf ( separator ) ) ; \"Separator(%s) is already used in brackets\" , String . valueOf ( separator ) ) ;", "del_tokens": "isTrue ( ! Character . toString ( separator ) . matches ( \"[\\\"\\\\s]\" ) , \"Separator contains illegal character(%s)\" , Character . toString ( separator ) ) ; \"Separator(%s) is already used in brackets\" , Character . toString ( separator ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["change", "groupId", "to", "au", ".", "gov", ".", "amsa", ".", "risky", "refactor"], "add_tokens": "Subscriber < String > subscriber = createSubscriber ( socket , socketName , out ) ; . subscribe ( subscriber ) ; // quickly after connecting)", "del_tokens": ". subscribe ( createSubscriber ( socket , socketName , out ) ) ; // quickly after connecting", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "waves", "effect", "."], "add_tokens": "uiObject . removeStyleName ( this . waves . getCssName ( ) ) ; if ( waves != null && ! waves . equals ( WavesType . DEFAULT ) ) {", "del_tokens": "uiObject . removeStyleName ( \"waves-\" + this . waves . getCssName ( ) ) ; if ( waves != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "UnicodeCharMatcher", "implementations", "plus", "first", "tests"], "add_tokens": "REGULAR_MATCHER_CLASSES . add ( UnicodeCharMatcher . class ) ; return doVisit ( matcher , UnicodeCharMatcher . class ) ; return doVisit ( matcher , matcher . getClass ( ) ) ; } private < M extends Matcher > ParserStatistics doVisit ( final M matcher , final Class < ? extends M > c ) {", "del_tokens": "return doVisit ( matcher ) ; final Class < ? extends Matcher > c = matcher . getClass ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "visitor", "class", "for", "performing", "operations", "on", "all", "instances", "of"], "add_tokens": "import com . jmex . effects . particles . ParticleGeometry ; import com . threerings . jme . util . SpatialVisitor ; public void actionPerformed ( ActionEvent e ) { _respawner . traverse ( _spatial ) ; /** Forces all particle systems to respawn. */ protected static SpatialVisitor < ParticleGeometry > _respawner = new SpatialVisitor < ParticleGeometry > ( ParticleGeometry . class ) { protected void visit ( ParticleGeometry geom ) { geom . forceRespawn ( ) ; } } ;", "del_tokens": "import com . jmex . effects . particles . ParticleMesh ; public void actionPerformed ( ActionEvent e ) { forceRespawn ( _spatial ) ; / * * * Recursively forces all particles to respawn . * / protected void forceRespawn ( Spatial spatial ) { if ( spatial instanceof ParticleMesh ) { ( ( ParticleMesh ) spatial ) . forceRespawn ( ) ; } else if ( spatial instanceof Node ) { Node node = ( Node ) spatial ; for ( int ii = 0 , nn = node . getQuantity ( ) ; ii < nn ; ii ++ ) { forceRespawn ( node . getChild ( ii ) ) ; } } }", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "argument", "handling", "."], "add_tokens": "private ApplicationContext context ; this . context = context ; Map < String , ArgumentHandlerRegistryBean > handlers = context . getBeansOfType ( ArgumentHandlerRegistryBean . class ) ;", "del_tokens": "private Map < String , ArgumentHandlerRegistryBean > handlers ; handlers = context . getBeansOfType ( ArgumentHandlerRegistryBean . class ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "readWrite", "boolean", "for", "identifying", "readWrite", "connections", "."], "add_tokens": "private final boolean readWrite ; public AndroidDatabaseConnection ( SQLiteDatabase db , boolean readWrite ) { this . readWrite = readWrite ; public boolean isReadWrite ( ) { return readWrite ; }", "del_tokens": "public AndroidDatabaseConnection ( SQLiteDatabase db ) {", "commit_type": "add"}
{"commit_tokens": ["Removing", "git", "user", "from", "url"], "add_tokens": "static final String JDBC_DRIVER_VERSION_DEFAULT = \"1.2.3\" ;", "del_tokens": "static final String JDBC_DRIVER_VERSION_DEFAULT = \"1.2.2\" ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "tag", "and", "drawable", "functionality"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; private Object tag ; public Object getTag ( ) { return this . tag ; } public void setTag ( Object tag ) { this . tag = tag ; }", "del_tokens": "import java . util . ArrayList ; import java . util . List ;", "commit_type": "add"}
{"commit_tokens": ["Make", "key", "and", "value", "names", "consistent", "with", "RenderingHints", "."], "add_tokens": "* The key for the hint that controls whether images are embedded in the * SVG or referenced externally . public static final SVGHints . Key KEY_IMAGE_HANDLING / * * * Hint value to say that images should be embedded in the SVG output * using PNG data Base64 encoded . * / public static final Object VALUE_IMAGE_HANDLING_EMBED = \"VALUE_IMAGE_HANDLING_EMBED\" ; / * * * Hint value to say that images should be referenced externally . * / public static final Object VALUE_IMAGE_HANDLING_REFERENCE = \"VALUE_IMAGE_HANDLING_REFERENCE\" ; return VALUE_IMAGE_HANDLING_EMBED . equals ( val ) || VALUE_IMAGE_HANDLING_REFERENCE . equals ( val ) ;", "del_tokens": "* The key for the hint that controls how images are supported . public static final SVGHints . Key SVG_IMAGE_HANDLING_KEY public static final Object IMAGE_EMBED_PNG_DATA_VAL = \"IMAGE_EMBED_PNG_DATA_VAL\" ; public static final Object IMAGE_HREF_PNG_FILE_VAL = \"IMAGE_HREF_PNG_FILE_VAL\" ; return IMAGE_EMBED_PNG_DATA_VAL . equals ( val ) || IMAGE_HREF_PNG_FILE_VAL . equals ( val ) ;", "commit_type": "make"}
{"commit_tokens": ["Makes", "comment", "more", "accurate", "."], "add_tokens": "* Unpack archive compressed by tar with xz compression . By default system tar is used ( faster ) . If not found , then the", "del_tokens": "* Unpack archive compressed by tar with bzip2 compression . By default system tar is used ( faster ) . If not found , then the", "commit_type": "make"}
{"commit_tokens": ["Added", "TODO", "in", "RxBleRadio", "."], "add_tokens": "void queue ( RxBleRadioOperation rxBleRadioOperation ) ; // TODO: add dequeueing on unsubscribe?", "del_tokens": "void queue ( RxBleRadioOperation rxBleRadioOperation ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "unused", "exceptions", "from", "RestAssuredEdgeGridFilter"], "add_tokens": "public void signEachRequest ( ) throws URISyntaxException , IOException { public void signWithHostHeader ( ) throws URISyntaxException , IOException { public void dontSignEachRequestWithoutBaseUri ( ) throws URISyntaxException , IOException {", "del_tokens": "import com . akamai . edgegrid . signer . RequestSigningException ; public void signEachRequest ( ) throws URISyntaxException , IOException , RequestSigningException { public void signWithHostHeader ( ) throws URISyntaxException , IOException , RequestSigningException { public void dontSignEachRequestWithoutBaseUri ( ) throws URISyntaxException , IOException , RequestSigningException {", "commit_type": "remove"}
{"commit_tokens": ["use", "Lists", ".", "newArrayList", "for", "clarity"], "add_tokens": "import com . google . common . collect . Lists ; List < String > list = Lists . newArrayList ( getStringProperty ( name ) . split ( \"\\\\s*,\\\\s*\" ) ) ;", "del_tokens": "import java . util . ArrayList ; List < String > list = new ArrayList < String > ( Arrays . asList ( getStringProperty ( name ) . split ( \"\\\\s*,\\\\s*\" ) ) ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "extraAttributes", "option", "and", "test", "for", "lexical", "semantics", "layer"], "add_tokens": "public interface Orthform extends ExtraAttributes {", "del_tokens": "public interface Orthform {", "commit_type": "add"}
{"commit_tokens": ["Fix", "method", "name", "error", "."], "add_tokens": "serviceInstance . setFactoryMethod ( \"newInstance\" ) ;", "del_tokens": "serviceInstance . setFactoryMethod ( \"getInstance\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["adding", "faster", "cluster", "lexicon", "reading"], "add_tokens": "InputStream resourceIn = IOUtils . openFromFile ( resourceFile ) ;", "del_tokens": "InputStream resourceIn = IOUtils . openFromGzipFile ( resourceFile ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "error", "filter", "to", "only", "report", "the", "first", "parse", "error", "at", "a", "specific", "input", "location"], "add_tokens": "* and all \"open\" parent MatcherContexts through the { @ link # getParent ( ) } chain . < / p > * addParserError ( new ParseError ( this , startLocation , currentLocation , matcher , node , errorMessage ) ) ; private void addParserError ( ParseError error ) { // do not add the error if we already have one at the exact same input location for ( ParseError parseError : invariables . parseErrors ) { if ( parseError . getErrorStart ( ) == error . getErrorStart ( ) ) return ; } invariables . parseErrors . add ( error ) ; }", "del_tokens": "* and all \"open\" parent MatcherContexts through the { @ link # getParent ( ) } chain . < / p > invariables . parseErrors . add ( new ParseError ( this , startLocation , currentLocation , matcher , node , errorMessage ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "a", "unit", "test", "for", "deleting", "/", "breaking", "a", "contract"], "add_tokens": "import org . overlord . commons . auth . filters . SamlBearerTokenAuthFilter ; public class DtApiTestAuthFilter extends SamlBearerTokenAuthFilter {", "del_tokens": "import org . overlord . commons . auth . jetty8 . Jetty8SamlBearerTokenAuthFilter ; public class DtApiTestAuthFilter extends Jetty8SamlBearerTokenAuthFilter {", "commit_type": "add"}
{"commit_tokens": ["Added", "clone", "()", "into", "JAXB", "generated", "objects"], "add_tokens": "import com . helger . commons . mock . CommonsTestHelper ; final Genericode04CodeListMarshaller aMarshaller = new Genericode04CodeListMarshaller ( ) ; final CodeListDocument aCLDoc = aMarshaller . read ( aDoc ) ; final Document aDoc2 = aMarshaller . getAsDocument ( aCLDoc ) ; // Read code list again final CodeListDocument aCLDoc2 = aMarshaller . read ( aDoc2 ) ; assertNotNull ( aRes . getPath ( ) , aCLDoc2 ) ; CommonsTestHelper . testDefaultImplementationWithEqualContentObject ( aCLDoc , aCLDoc2 ) ; CommonsTestHelper . testDefaultImplementationWithEqualContentObject ( aCLDoc , aCLDoc . clone ( ) ) ;", "del_tokens": "final CodeListDocument aCLDoc = new Genericode04CodeListMarshaller ( ) . read ( aDoc ) ; final Document aDoc2 = new Genericode04CodeListMarshaller ( ) . getAsDocument ( aCLDoc ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "index", "not", "creating", "enough", "entries"], "add_tokens": "while ( index >= this . processors . size ( ) ) { while ( index >= this . predicates . size ( ) ) {", "del_tokens": "while ( index > this . processors . size ( ) ) { while ( index > this . predicates . size ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Update", "src", "/", "main", "/", "java", "/", "org", "/", "mbassy", "/", "MBassador", ".", "java"], "add_tokens": "public SyncAsyncPostCommand < T > post ( T message ) { return new SyncAsyncPostCommand < T > ( this , message ) ;", "del_tokens": "public SyncAsyncPostCommand post ( T message ) { return new SyncAsyncPostCommand ( this , message ) ;", "commit_type": "update"}
{"commit_tokens": ["Improve", "logging", "output", "when", "MSBuild", "fails", "."], "add_tokens": "public int execute ( ) throws IOException , InterruptedException int exitCode = runMSBuild ( platform . getName ( ) , configuration . getName ( ) ) ; if ( exitCode != 0 ) { return exitCode ; } return 0 ; log . error ( \"Error building \" + platform + \"-\" + configuration ) ;", "del_tokens": "public void execute ( ) throws IOException , InterruptedException runMSBuild ( platform . getName ( ) , configuration . getName ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["adding", "exit", "quit", "refresh", "commands", "to", "ease", "usage", "and", "force", "refreshing", "manually"], "add_tokens": "getLog ( ) . info ( \"Type [exit|quit] to exit and [refresh] to force a manual re-rendering.\" ) ; String line ; final Scanner scanner = new Scanner ( System . in ) ; while ( ( line = scanner . nextLine ( ) ) != null ) { line = line . trim ( ) ; if ( \"exit\" . equalsIgnoreCase ( line ) || \"quit\" . equalsIgnoreCase ( line ) ) { break ; } if ( \"refresh\" . equalsIgnoreCase ( line ) ) { doExecute ( ) ; } else { getLog ( ) . warn ( \"'\" + line + \"' not understood, available commands are [quit, exit, refresh].\" ) ; } }", "del_tokens": "getLog ( ) . info ( \"Type [Enter] to exit\" ) ; new Scanner ( System . in ) . nextLine ( ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "more", "use", "of", "junit", "4"], "add_tokens": "import org . junit . Test ; import static org . junit . Assert . assertEquals ; public class BaseExceptionTest { @ Test public void generatesCorrectDetailedMessageForSingleException ( ) { @ Test public void generatesCorrectDetailedMessageForChainedBaseExceptions ( ) { @ Test public void generatesCorrectDetailedMessageForChainedExceptionsWithOtherExceptionInMix ( ) {", "del_tokens": "import com . mpatric . mp3agic . BaseException ; import com . mpatric . mp3agic . InvalidDataException ; import com . mpatric . mp3agic . NoSuchTagException ; import com . mpatric . mp3agic . NotSupportedException ; import com . mpatric . mp3agic . UnsupportedTagException ; import junit . framework . TestCase ; public class BaseExceptionTest extends TestCase { public void testShouldGenerateCorrectDetailedMessageForSingleException ( ) throws Exception { public void testShouldGenerateCorrectDetailedMessageForChainedBaseExceptions ( ) throws Exception { public void testShouldGenerateCorrectDetailedMessageForChainedExceptionsWithOtherExceptionInMix ( ) throws Exception {", "commit_type": "make"}
{"commit_tokens": ["added", "technology", "selection", "(", "file", "system", "svn", "cmis", ")", "changed", "folder", "to", "camunda", "-", "bpm", "-", "demo", "-", "invoice", "removed", "missing", "user", "pirctures"], "add_tokens": "String directory = System . getProperty ( \"user.home\" ) + \"/camunda-bpm-demo-invoice/\" ; File path = new File ( directory ) ; FileOutputStream fos = new FileOutputStream ( directory + fileName ) ;", "del_tokens": "String home = System . getProperty ( \"user.home\" ) ; File path = new File ( home + \"/fox-invoice/\" ) ; FileOutputStream fos = new FileOutputStream ( home + \"/fox-invoice/\" + fileName ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "introspection", "interface", "as", "a", "provided", "interface", "into", "the", "default", "linker"], "add_tokens": "@ Provides ( specifications = { ImportationLinker . class , ImportationLinkerIntrospection . class } )", "del_tokens": "@ Provides ( specifications = ImportationLinker . class )", "commit_type": "add"}
{"commit_tokens": ["Improve", "selection", "of", "UTF", "-", "8", "character", "set"], "add_tokens": "import java . nio . charset . StandardCharsets ; return sign ( s , clientSecret . getBytes ( StandardCharsets . UTF_8 ) , algorithm ) ; byte [ ] valueBytes = s . getBytes ( StandardCharsets . UTF_8 ) ;", "del_tokens": "import java . io . UnsupportedEncodingException ; private static final String STRING2BYTES_CHARSET = \"UTF-8\" ; try { return sign ( s , clientSecret . getBytes ( STRING2BYTES_CHARSET ) , algorithm ) ; } catch ( UnsupportedEncodingException e ) { throw new RequestSigningException ( \"Failed to sign: invalid string encoding\" , e ) ; } byte [ ] valueBytes = s . getBytes ( STRING2BYTES_CHARSET ) ; } catch ( UnsupportedEncodingException e ) { throw new RequestSigningException ( \"Failed to sign: your JDK does not recognize <\" + STRING2BYTES_CHARSET + \"> encoding\" , e ) ;", "commit_type": "improve"}
{"commit_tokens": ["Changed", "to", "Log4j", "for", "logging"], "add_tokens": "* http : //code.google.com/p/moviejukebox/people/list * * * * For any reuse or distribution , you must make clear to others the * license terms of this work . import org . apache . log4j . Logger ; * private static Logger logger = Logger . getLogger ( DOMHelper . class ) ; * * Document doc ; InputStream in ; String webPage ; logger . warn ( \"Error with API Call for: \" + url ) ;", "del_tokens": "* http : //code.google.com/p/moviejukebox/people/list * * * * For any reuse or distribution , you must make clear to others the * license terms of this work . import java . util . logging . Logger ; import com . moviejukebox . fanarttv . FanartTv ; private static Logger logger = FanartTv . getLogger ( ) ; Document doc = null ; InputStream in = null ; String webPage = null ; logger . fine ( \"Error with API Call for: \" + url ) ;", "commit_type": "change"}
{"commit_tokens": ["Allows", "bus", "jackson", "config", "to", "use", "autowired", "ObjectMapper", "."], "add_tokens": "* Copyright 2013 - 2018 the original author or authors . import org . springframework . beans . factory . annotation . Autowired ; public BusJacksonMessageConverter busJsonConverter ( @ Autowired ( required = false ) ObjectMapper objectMapper ) { return new BusJacksonMessageConverter ( objectMapper ) ; private final ObjectMapper mapper ; public BusJacksonMessageConverter ( ) { this ( null ) ; } public BusJacksonMessageConverter ( ObjectMapper objectMapper ) { super ( MimeTypeUtils . APPLICATION_JSON ) ; if ( objectMapper != null ) { this . mapper = objectMapper ; } else { this . mapper = new ObjectMapper ( ) ; } }", "del_tokens": "* Copyright 2013 - 2017 the original author or authors . public BusJacksonMessageConverter busJsonConverter ( ) { return new BusJacksonMessageConverter ( ) ; private final ObjectMapper mapper = new ObjectMapper ( ) ; public BusJacksonMessageConverter ( ) { super ( MimeTypeUtils . APPLICATION_JSON ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Add", "custom", "handler", "to", "styled", "sample", "."], "add_tokens": "import com . jakewharton . android . actionbarsherlock . handler . Android_ActionBar ; . handleCustom ( Android_ActionBar . Handler . class ) this . rotateLeftFrag ( ) ;", "del_tokens": "rotateLeftFrag ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "App", "Compat", "to", "improve", "android", "sample", "appearence"], "add_tokens": "import android . support . v7 . app . AppCompatActivity ; public final class MainActivity extends AppCompatActivity { View view = findViewById ( R . id . usage_normal ) ; assert view != null ; view . setOnClickListener ( new View . OnClickListener ( ) { view = findViewById ( R . id . usage_low_iteration ) ; assert view != null ; view . setOnClickListener ( new View . OnClickListener ( ) { view = findViewById ( R . id . usage_customized ) ; assert view != null ; view . setOnClickListener ( new View . OnClickListener ( ) { view = findViewById ( R . id . usage_async ) ; assert view != null ; view . setOnClickListener ( new View . OnClickListener ( ) {", "del_tokens": "import android . app . Activity ; public final class MainActivity extends Activity { findViewById ( R . id . usage_normal ) . setOnClickListener ( new View . OnClickListener ( ) { findViewById ( R . id . usage_low_iteration ) . setOnClickListener ( new View . OnClickListener ( ) { findViewById ( R . id . usage_customized ) . setOnClickListener ( new View . OnClickListener ( ) { findViewById ( R . id . usage_async ) . setOnClickListener ( new View . OnClickListener ( ) {", "commit_type": "use"}
{"commit_tokens": ["Fix", "for", "common", "-", "gender", "surnames"], "add_tokens": "if ( p_firstcap . matcher ( originalWord ) . matches ( ) && ( p . getID ( ) == 8 || p . getID ( ) == 10 ) ) { } // Ja ir īpašvārds ar -a -e galotni, tad mēģina arī vīriešu dzimtes variantus uzvārdiem else continue ; // citos gadījumos, ja beigu burti izskatās neadekvāti tam, kas leksikonā pie paradigmas norādīts - tad neminam.", "del_tokens": "continue ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "dependencies", "on", "Transfuse", "specific", "generation", "artifacts"], "add_tokens": "private final Provider < ParcelerPrivateInjectionBuilder > privateProvider ; Provider < ParcelerPrivateInjectionBuilder > privateProvider ) {", "del_tokens": "import org . androidtransfuse . gen . invocationBuilder . PrivateInjectionBuilder ; private final Provider < PrivateInjectionBuilder > privateProvider ; Provider < PrivateInjectionBuilder > privateProvider ) {", "commit_type": "remove"}
{"commit_tokens": ["Removed", "usage", "of", "JavaType", ".", "asClass", "()"], "add_tokens": "import static com . tngtech . archunit . lang . conditions . ArchPredicates . named ; import static java . util . regex . Pattern . quote ; Optional < JavaClass > child = tryFind ( classesToSearchForChild , named ( quote ( childType . getName ( ) ) ) ) ; private static < T > Optional < T > tryFind ( Iterable < T > collection , DescribedPredicate < ? super T > predicate ) {", "del_tokens": "import static com . tngtech . archunit . core . JavaClass . withType ; Optional < JavaClass > child = tryFind ( classesToSearchForChild , withType ( childType . asClass ( ) ) ) ; private static < T > Optional < T > tryFind ( Iterable < T > collection , DescribedPredicate < T > predicate ) {", "commit_type": "remove"}
{"commit_tokens": ["improve", "error", "location", "reporting", "when", "data", "missing", "suppress", "errors", "warnings", "and", "fatal", "errors", "after", "the", "first", "fatal", "error"], "add_tokens": "int col = e . getColumnNumber ( ) ; this . emitter . startElementWithClass ( \"span\" , \"line\" ) ; this . emitter . endElement ( \"span\" ) ; if ( col > - 1 ) { this . emitter . characters ( COLUMN ) ; this . emitter . startElementWithClass ( \"span\" , \"col\" ) ; this . emitter . characters ( \"\" + col ) ; this . emitter . endElement ( \"span\" ) ; } if ( systemId != null ) { this . emitter . characters ( IN_RESOURCE ) ; } } if ( systemId != null ) { this . emitter . startElementWithClass ( \"span\" , \"url\" ) ; this . emitter . characters ( scrub ( systemId ) ) ; this . emitter . endElement ( \"span\" ) ;", "del_tokens": "this . emitter . characters ( COLUMN ) ; this . emitter . characters ( \"\" + e . getColumnNumber ( ) ) ; this . emitter . characters ( IN_RESOURCE ) ; this . emitter . characters ( scrub ( systemId ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "MockMvc", "tests", "to", "rest", "sample"], "add_tokens": "import static org . springframework . security . test . web . servlet . request . SecurityMockMvcRequestPostProcessors . user ; import org . springframework . security . test . context . support . WithMockUser ; . apply ( springSecurity ( ) ) . build ( ) ; . andExpect ( header ( ) . doesNotExist ( \"x-auth-token\" ) ) . andExpect ( status ( ) . isUnauthorized ( ) ) ; } @ WithMockUser @ Test public void autheticatedAnnotation ( ) throws Exception { mvc . perform ( get ( \"/\" ) ) . andExpect ( content ( ) . string ( \"{\\\"username\\\":\\\"user\\\"}\" ) ) ; } @ Test public void autheticatedRequestPostProcessor ( ) throws Exception { mvc . perform ( get ( \"/\" ) . with ( user ( \"user\" ) ) ) . andExpect ( content ( ) . string ( \"{\\\"username\\\":\\\"user\\\"}\" ) ) ;", "del_tokens": ". apply ( springSecurity ( ) ) . build ( ) ; . andExpect ( header ( ) . doesNotExist ( \"x-auth-token\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["removing", "unnecessary", "classes", "using", "dateRangeRandomizer", "for", "fetching", "a", "date"], "add_tokens": "import io . github . benas . jpopulator . randomizers . DateRangeRandomizer ;", "del_tokens": "import io . github . benas . jpopulator . utils . DateUtils ; import io . github . benas . jpopulator . randomizers . DateRangeRandomizer ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "empty", "shares", "check", "."], "add_tokens": "checkArgument ( shares . size ( ) > 0 , \"No shares provided\" ) ;", "del_tokens": "checkArgument ( lengths . length > 0 , \"No shares provided\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["updating", "to", "use", "new", "parent"], "add_tokens": "* Copyright ( C ) 2017 Black Duck Software , Inc .", "del_tokens": "* Copyright ( C ) 2016 Black Duck Software , Inc .", "commit_type": "update"}
{"commit_tokens": ["Fix", "final", "keyword", "usage", "."], "add_tokens": "public Object invoke ( Integer command , String name , String pattern , byte [ ] request_info , byte [ ] request , Integer timeout , Byte priority , byte [ ] trans_id , OtpErlangPid pid )", "del_tokens": "public final Object invoke ( Integer command , String name , String pattern , byte [ ] request_info , byte [ ] request , Integer timeout , Byte priority , byte [ ] trans_id , OtpErlangPid pid )", "commit_type": "fix"}
{"commit_tokens": ["Add", "file", "replacement", "for", "UserDefinedFileAttributes", "."], "add_tokens": "import java . util . Collection ; public class UserDefinedFileAttributes implements UserDefinedAttributes @ Override @ Override public Collection < String > list ( ) throws IOException @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override", "del_tokens": "import org . vesalainen . util . ThreadSafeTemporary ; public class UserDefinedFileAttributes public List < String > list ( ) throws IOException", "commit_type": "add"}
{"commit_tokens": ["Remove", "unnecessary", "fully", "qualified", "name", "."], "add_tokens": "* @ throws IllegalArgumentException If the coordinates are not valid geo coordinates", "del_tokens": "* @ throws java . lang . IllegalArgumentException If the coordinates are not valid geo coordinates", "commit_type": "remove"}
{"commit_tokens": ["add", "the", "first", "live", "test", "case", "for", "validator"], "add_tokens": "exchange . setStatusCode ( StatusCodes . NOT_FOUND ) ; exchange . setStatusCode ( StatusCodes . METHOD_NOT_ALLOWED ) ; if ( exchange . isInIoThread ( ) ) { exchange . dispatch ( this ) ; return ; } exchange . startBlocking ( ) ;", "del_tokens": "exchange . setStatusCode ( StatusCodes . BAD_REQUEST ) ; exchange . setStatusCode ( StatusCodes . BAD_REQUEST ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "Setter", "for", "file", "in", "CSVFileSource"], "add_tokens": "* * if ( this . fileName != null ) { this . init ( ) ; } public void setFileName ( String fileName ) { this . fileName = fileName ; this . init ( ) ;", "del_tokens": "* * this . init ( ) ; public void setFile ( Path file ) { this . file = file ;", "commit_type": "add"}
{"commit_tokens": ["Added", "all", "of", "the", "Message", "Content", "Type", "implementations"], "add_tokens": "import org . telegram . botapi . api . TelegramBot ; int getId ( ) ; String getFirstName ( ) ; String getLastName ( ) ; default String getFullName ( ) { return getFirstName ( ) + \" \" + getLastName ( ) ; } String getUsername ( ) ; UserProfilePhotos getProfilePhotos ( TelegramBot telegramBot ) ; }", "del_tokens": "int getId ( ) ; String getFirstName ( ) ; String getLastName ( ) ; default String getFullName ( ) { return getFirstName ( ) + \" \" + getLastName ( ) ; } String getUsername ( ) ; UserProfilePhotos getProfilePhotos ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["added", "asychronous", "/", "UIEvent", "system"], "add_tokens": "import android . widget . Button ; import org . androidrobotics . annotations . * ; @ Inject private LateReturnListener lateReturnListener ; @ Inject @ View ( R . id . asynchActivity ) private Button button ; @ OnCreate public void registerLateReturnListener ( ) { button . setOnClickListener ( lateReturnListener ) ; }", "del_tokens": "import org . androidrobotics . annotations . Activity ; import org . androidrobotics . annotations . Layout ; import org . androidrobotics . annotations . OnCreate ; import org . androidrobotics . annotations . SystemService ;", "commit_type": "add"}
{"commit_tokens": ["Change", "license", "from", "epl", "to", "apache2"], "add_tokens": "* Licensed under the Apache License , Version 2.0 the \"License\" ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * /", "del_tokens": "* Licensed under the Eclipse Public License 1.0 * /", "commit_type": "change"}
{"commit_tokens": ["Make", "ITS", "independent", "from", "UC"], "add_tokens": "public static final Orchestrator ORCHESTRATOR = Orchestrator . builderEnv ( ) . addPlugin ( \"java\" ) . addPlugin ( FileLocation . of ( \"../../../target/sonar-pmd-plugin.jar\" ) ) . addPlugin ( FileLocation . of ( TestUtils . pluginJar ( \"pmd-extension-plugin\" ) ) ) . restoreProfileAtStartup ( FileLocation . ofClasspath ( \"/com/sonar/it/java/PmdTest/pmd-junit-rules.xml\" ) ) . restoreProfileAtStartup ( FileLocation . ofClasspath ( \"/com/sonar/it/java/PmdTest/pmd-extensions-profile.xml\" ) ) . restoreProfileAtStartup ( FileLocation . ofClasspath ( \"/com/sonar/it/java/PmdTest/pmd-backup.xml\" ) ) . build ( ) ;", "del_tokens": "import com . sonar . orchestrator . OrchestratorBuilder ; public static final Orchestrator ORCHESTRATOR ; static { OrchestratorBuilder orchestratorBuilder = Orchestrator . builderEnv ( ) . addPlugin ( \"java\" ) . addPlugin ( \"pmd\" ) . setMainPluginKey ( \"pmd\" ) . addPlugin ( FileLocation . of ( TestUtils . pluginJar ( \"pmd-extension-plugin\" ) ) ) . restoreProfileAtStartup ( FileLocation . ofClasspath ( \"/com/sonar/it/java/PmdTest/pmd-junit-rules.xml\" ) ) . restoreProfileAtStartup ( FileLocation . ofClasspath ( \"/com/sonar/it/java/PmdTest/pmd-extensions-profile.xml\" ) ) . restoreProfileAtStartup ( FileLocation . ofClasspath ( \"/com/sonar/it/java/PmdTest/pmd-backup.xml\" ) ) ; ORCHESTRATOR = orchestratorBuilder . build ( ) ; }", "commit_type": "make"}
{"commit_tokens": ["Fix", "some", "notifier", "wording", "for", "actions"], "add_tokens": "* REST endpoint for ActionPlugins", "del_tokens": "* REST endpoint for NotifierTypes", "commit_type": "fix"}
{"commit_tokens": ["Make", "it", "easier", "to", "configure", "how", "websocket", "message", "are", "read", "/", "written", ".", "Allow", "customization", "of", "ObjectMapper", "."], "add_tokens": "private final Context context ; this ( new Context ( ) , new MockWebServer ( ) , new HashMap < ServerRequest , Queue < ServerResponse > > ( ) , false ) ; this ( new Context ( ) , new MockWebServer ( ) , new HashMap < ServerRequest , Queue < ServerResponse > > ( ) , useHttps ) ; this ( new Context ( ) , server , responses , useHttps ) ; } public DefaultMockServer ( Context context , MockWebServer server , Map < ServerRequest , Queue < ServerResponse > > responses , boolean useHttps ) { this . context = context ; return new MockServerExpectationImpl ( responses , context ) ;", "del_tokens": "this ( new MockWebServer ( ) , new HashMap < ServerRequest , Queue < ServerResponse > > ( ) , false ) ; this ( new MockWebServer ( ) , new HashMap < ServerRequest , Queue < ServerResponse > > ( ) , useHttps ) ; return new MockServerExpectationImpl ( responses ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "some", "maven", "casting", "issues", "."], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) Dao < Object , Object > dao = ( Dao < Object , Object > ) DaoManager . createDao ( getConnectionSource ( ) , clazz ) ; @ SuppressWarnings ( \"unchecked\" ) D castDao = ( D ) dao ; return castDao ;", "del_tokens": "return DaoManager . createDao ( getConnectionSource ( ) , clazz ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "the", "basic", "entity", "/", "object", "mapping", "."], "add_tokens": "import com . google . appengine . api . datastore . EntityNotFoundException ; < T > T get ( Key key ) throws EntityNotFoundException ;", "del_tokens": "< T > T get ( Key key ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "for", "a", "backup", "versioning", "related", "bug", "."], "add_tokens": "new DefaultPacketProcessor ( false , true , true , false ) { rec . runBackupOps ( ) ; int operation = - 1 ; operation = packet . operation ; @ Override public String toString ( ) { return \"DefaultProcessor operation=\" + operation ; }", "del_tokens": "import com . hazelcast . core . Member ; import static com . hazelcast . impl . Constants . Objects . OBJECT_REDO ; new DefaultPacketProcessor ( false , true , true , true ) { record . version = req . version ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unnecessary", "wrapping", "as", "ArrayList"], "add_tokens": "return sourceClass . getEnumConstants ( ) ;", "del_tokens": "result = Arrays . asList ( sourceClass . getEnumConstants ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixing", "bug", "with", "forall", "simplification"], "add_tokens": "List < Expression > simplifiedRestrictions = Lists . newArrayList ( ) ; simplifiedRestrictions . add ( restrictions . get ( i ) . simplify ( ) ) ; return new ForAllExpression ( boundVariables , simplifiedRestrictions , body . simplify ( ) ) ;", "del_tokens": "List < Expression > simplifiedValues = Lists . newArrayList ( ) ; simplifiedValues . add ( restrictions . get ( i ) . simplify ( ) ) ; return new ForAllExpression ( boundVariables , restrictions , body . simplify ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "all", "CR", "(", "\\", "t", ")", "before", "text", "comparison"], "add_tokens": "String strResponse = resp . getText ( ) . replaceAll ( \"\\r\" , \"\" ) ; String strResource = getResource ( resultResource ) . replaceAll ( \"\\r\" , \"\" ) ; assertEquals ( strResource , strResponse ) ;", "del_tokens": "assertEquals ( getResource ( resultResource ) , resp . getText ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "lot", "of", "documentation", "and", "changed", "visibility", "of", "some", "methods", "to", "have", "a", "consistent", "package", "-", "private", "write", "access", ".", "Moved", "children", "queue", "processing", "to", "ClassNode", "."], "add_tokens": "* Classes that implement this interface represent a class hierarchy based on * ElkClass objects . For each such object , the taxonomy holds a ClassNode object * from which direct sub - and superclasses can be retrieved . * @ author Yevgeny Kazakov", "del_tokens": "* @ author Yevgeny Kazakov", "commit_type": "add"}
{"commit_tokens": ["fixing", "bug", "in", "spatial", "key", "algo"], "add_tokens": "setWorldBounds ( ) ; protected void setWorldBounds ( ) { double midLat = ( maxLatI - minLatI ) / 2 ; double midLon = ( maxLonI - minLonI ) / 2 ; long bits = initialBits ;", "del_tokens": "setInitialBounds ( ) ; protected void setInitialBounds ( ) { double midLat = maxLatI ; double midLon = maxLonI ; long bits = initialBits ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "--", "auto", "-", "metric", "flag", "to", "the", "import", "command", "too", "."], "add_tokens": "CliOptions . addAutoMetricFlag ( argp ) ;", "del_tokens": "argp . addOption ( \"--auto-metric\" , \"Automatically add metrics to tsdb as they\" + \" are inserted. Warning: this may cause unexpected\" + \" metrics to be tracked\" ) ; if ( argp . has ( \"--auto-metric\" ) ) { System . setProperty ( \"tsd.core.auto_create_metrics\" , \"true\" ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "issue", "210", "overwrite", "the", "DLCX", "on", "Endpoint", ".", "Restored", "back"], "add_tokens": "if ( deleteConnection . getConnectionIdentifier ( ) != null ) { processNonCreateConnectionMgcpEvent ( deleteConnection . getConnectionIdentifier ( ) , event . getEndpointIdentifier ( ) , event . getTransactionHandle ( ) , \"net.java.slee.resource.mgcp.DELETE_CONNECTION\" , event ) ; } else { processEndpointMgcpEvent ( deleteConnection . getEndpointIdentifier ( ) , \"net.java.slee.resource.mgcp.DELETE_CONNECTION\" , event ) ; } if ( deleteConnection . getConnectionIdentifier ( ) != null ) { processNonCreateConnectionMgcpEvent ( deleteConnection . getConnectionIdentifier ( ) , deleteConnection . getEndpointIdentifier ( ) , response . getTransactionHandle ( ) , \"net.java.slee.resource.mgcp.DELETE_CONNECTION_RESPONSE\" , response ) ; } else { processEndpointMgcpEvent ( deleteConnection . getEndpointIdentifier ( ) , \"net.java.slee.resource.mgcp.DELETE_CONNECTION_RESPONSE\" , response ) ; } // end activity if delete connection request or response if ( eventObject instanceof DeleteConnection || eventObject instanceof DeleteConnectionResponse ) { try { // send activity end event to the container getSleeEndpoint ( ) . activityEnding ( handle ) ; } catch ( Exception e ) { logger . error ( \"Failed to end activity with handle \" + handle , e ) ; } }", "del_tokens": "processNonCreateConnectionMgcpEvent ( deleteConnection . getConnectionIdentifier ( ) , event . getEndpointIdentifier ( ) , event . getTransactionHandle ( ) , \"net.java.slee.resource.mgcp.DELETE_CONNECTION\" , event ) ; processNonCreateConnectionMgcpEvent ( deleteConnection . getConnectionIdentifier ( ) , deleteConnection . getEndpointIdentifier ( ) , response . getTransactionHandle ( ) , \"net.java.slee.resource.mgcp.DELETE_CONNECTION_RESPONSE\" , response ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "javadoc", "for", "BeanBuilder", ".", "producing", "()"], "add_tokens": "* A shortcut for { @ code produceWith ( ( ) -> existing } where { @ code existing } represents an instance whose lifecycle is not managed by CDI .", "del_tokens": "* A shortcut for < code > produceWith ( ( ) -> existing ) < / code > where < code > existing < / code > represents an instance whose lifecycle is not managed by CDI .", "commit_type": "fix"}
{"commit_tokens": ["improve", "(", "OSGiELResolver", ")", ":", "implement", "invoke", "method", "and", "add", "test"], "add_tokens": "public boolean called = false ; public void toggleCalled ( ) { called = true ; }", "del_tokens": "public boolean called ;", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "whole", "-", "number", "float", "default", "values", "missing", "a", ".", "0", "suffix", "."], "add_tokens": "public float testf2 ( ) { int o = __offset ( 56 ) ; return o != 0 ? bb . getFloat ( o + bb_pos ) : 3.0f ; } public boolean mutateTestf2 ( float testf2 ) { int o = __offset ( 56 ) ; if ( o != 0 ) { bb . putFloat ( o + bb_pos , testf2 ) ; return true ; } else { return false ; } } public static void startMonster ( FlatBufferBuilder builder ) { builder . startObject ( 27 ) ; } public static void addTestf2 ( FlatBufferBuilder builder , float testf2 ) { builder . addFloat ( 26 , testf2 , 3.0f ) ; }", "del_tokens": "public static void startMonster ( FlatBufferBuilder builder ) { builder . startObject ( 26 ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "method", "to", "force", "update", "name", "of", "Friend"], "add_tokens": "return getName ( false ) ; } / * * * Gets the name of this friend . If the name was null then we try to fetch * the name with your Riot API Key if provided . Enable forcedUpdate to * always fetch the latest name of this Friend even when the name is not * null . * * @ param forcedUpdate * True will force to update the name even when it is not null . * @ return The name of this Friend or null if no name is assigned . * / public String getName ( boolean forcedUpdate ) { if ( ( name == null || forcedUpdate ) && api . getRiotApi ( ) != null ) {", "del_tokens": "if ( name == null && api . getRiotApi ( ) != null ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "Java", "6"], "add_tokens": "List < ResourceFilter > filters = new ArrayList < ResourceFilter > ( ) ;", "del_tokens": "List < ResourceFilter > filters = new ArrayList < > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "implementation", "for", "AddStorageGroupDir", "and", "RemoveStorageGroupDir", "."], "add_tokens": "* @ param hostName ResponseEntity < Bool > removeStorageGroupDir ( String groupName , String directoryName , String hostName ) throws MythServiceApiRuntimeException ;", "del_tokens": "* @ param hostname ResponseEntity < Bool > removeStorageGroupDirectory ( String groupName , String directoryName , String hostname ) throws MythServiceApiRuntimeException ;", "commit_type": "add"}
{"commit_tokens": ["making", "dsl", "more", "terse", "(", "no", "callback", "methods", ")"], "add_tokens": "import org . junit . Assert ; import org . junit . Test ; } ; { defineMethod ( \"hello\" , ACC_PUBLIC | ACC_STATIC , sig ( String . class ) , new MethodBody ( ) { { ldc ( \"helloWorld\" ) ; areturn ( ) ; } } ) ;", "del_tokens": "import org . junit . Test ; import org . objectweb . asm . MethodVisitor ; import org . junit . Assert ; * } ; public void executableMethodBody ( ) { defineMethod ( \"hello\" , ACC_PUBLIC | ACC_STATIC , sig ( String . class ) , new MethodBody ( ) { public void executableMethodBody ( ) { ldc ( \"helloWorld\" ) ; areturn ( ) ; } } ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "single", "quotes", "for", "strings", "that", "look", "like", "numbers", "."], "add_tokens": "char style = 0 ; String string = String . valueOf ( object ) ; if ( valueClass == String . class ) { try { Float . parseFloat ( string ) ; style = '\\'' ; } catch ( NumberFormatException ignored ) { } } emitter . emit ( new ScalarEvent ( null , tag , new boolean [ ] { true , true } , string , style ) ) ;", "del_tokens": "emitter . emit ( new ScalarEvent ( null , null , new boolean [ ] { true , true } , String . valueOf ( object ) , ( char ) 0 ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Allowing", "CORS", "invoke", "creating", "GUI", "with", "angular"], "add_tokens": "seteHoldRequestInMilli ( uaiRequest , uaiRequestDTO ) ; private static void seteHoldRequestInMilli ( final UaiRequest uaiRequest , final UaiRequestDTO uaiRequestDTO ) { if ( uaiRequest . holdRequestInMilli != 0 ) { uaiRequestDTO . setHoldRequestInMilli ( uaiRequest . holdRequestInMilli ) ; return ; } uaiRequestDTO . setHoldRequestInMilli ( null ) ; }", "del_tokens": "uaiRequestDTO . setHoldRequestInMilli ( uaiRequest . holdRequestInMilli ) ;", "commit_type": "allow"}
{"commit_tokens": ["Update", "comparison", "of", "expected", "vs", "supplied", "signature", "to", "use", "a", "MessageDigest", "in", "order", "to", "defend", "against", "timing", "based", "attacks"], "add_tokens": "import java . io . UnsupportedEncodingException ; import java . security . MessageDigest ; // verify that the supplied signature matches generated one // use MessageDigest.isEqual as an alternative to String.equals() to defend against timing based attacks try { if ( ! MessageDigest . isEqual ( md5 . getBytes ( \"UTF-8\" ) , suppliedSignature . getBytes ( \"UTF-8\" ) ) ) return false ; } catch ( UnsupportedEncodingException e ) { log . error ( \"This should not occur!!\" , e ) ; }", "del_tokens": "// verify that the secre if ( ! md5 . equals ( suppliedSignature ) )", "commit_type": "update"}
{"commit_tokens": ["Added", "some", "exception", "handlers", "to", "requeue", "bad", "connections", "."], "add_tokens": "private void handleInputQueue ( ) { try { handleOperation ( op , qa . sk , qa ) ; } catch ( IOException e ) { getLogger ( ) . warn ( \"Exception handling %s\" , op , e ) ; queueReconnect ( qa ) ; } // Handle IO for a specific selector. Any IOException will cause a // reconnect private void handleIO ( SelectionKey sk ) { try { int read = qa . channel . read ( b ) ; assert read == - 1 : \"expected to read -1 bytes, read \" + read ; } catch ( IOException e ) { getLogger ( ) . warn ( \"IOException reading while not\" + \" expecting a readable channel\" , e ) ; } private void queueReconnect ( QueueAttachment qa ) { try { qa . channel . socket ( ) . close ( ) ; } catch ( IOException e ) { getLogger ( ) . warn ( \"IOException trying to close a socket\" , e ) ; }", "del_tokens": "private void handleInputQueue ( ) throws IOException { handleOperation ( op , qa . sk , qa ) ; // Handle IO for a specific selector. private void handleIO ( SelectionKey sk ) throws IOException { int read = qa . channel . read ( b ) ; assert read == - 1 : \"expected to read -1 bytes, read \" + read ; private void queueReconnect ( QueueAttachment qa ) throws IOException { qa . channel . socket ( ) . close ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "expressions", "for", "force", "properties", "."], "add_tokens": "* @ parameter default - value = \"true\" expression = \"${deploy.force}\"", "del_tokens": "* @ parameter default - value = \"true\"", "commit_type": "allow"}
{"commit_tokens": ["added", "support", "for", "reading", "and", "writing", "arrays"], "add_tokens": "import java . util . List ; import java . util . StringJoiner ; public static CloudSpannerArray createArray ( CloudSpannerDataType type , List < ? extends Object > elements ) throws SQLException { return new CloudSpannerArray ( type , elements ) ; } private CloudSpannerArray ( CloudSpannerDataType type , List < ? extends Object > elements ) throws SQLException { this . type = type ; this . data = java . lang . reflect . Array . newInstance ( type . getJavaClass ( ) , elements . size ( ) ) ; this . data = elements . toArray ( ( Object [ ] ) data ) ; } this . data = null ; } @ Override public String toString ( ) { StringJoiner joiner = new StringJoiner ( \",\" , \"{\" , \"}\" ) ; for ( Object o : ( Object [ ] ) data ) { joiner . add ( o . toString ( ) ) ; } return joiner . toString ( ) ;", "del_tokens": "this . data = java . lang . reflect . Array . newInstance ( type . getJavaClass ( ) , 10 ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "pom", "for", "deploy", "to", "sonatype", ".", "Fixed", "unit", "test"], "add_tokens": "// get the manager WebSocketScopeManager manager = plugin . getManager ( ) ; manager . addApplication ( new GlobalScope ( ) ) ; // get the manager WebSocketScopeManager manager = plugin . getManager ( ) ; manager . addApplication ( new GlobalScope ( ) ) ; final TyrusWSClient client = new TyrusWSClient ( ) ; new Thread ( new Runnable ( ) { public void run ( ) { client . start ( ) ; } } ) . start ( ) ; ; // send a message //client.sendMessage(\"This is a test\"); // terminate client client . terminate ( ) ; wait4TerminateSignal ( ) ;", "del_tokens": "WebSocketScopeManager manager = plugin . getManager ( ) ; manager . addApplication ( new GlobalScope ( ) ) ; WebSocketScopeManager manager = plugin . getManager ( ) ; manager . addApplication ( new GlobalScope ( ) ) ; TyrusWSClient client = new TyrusWSClient ( ) ; client . start ( ) ; client . sendMessage ( \"This is a test\" ) ; //client.terminate(); //wait4TerminateSignal();", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "S", "/", "MIME", "public", "meta", "data"], "add_tokens": "public void checkSmimeFilename ( ) { if ( this . filename == null && this . mimeTag != null ) { if ( this . mimeTag . contains ( \"multipart/signed\" ) ) { if ( ! this . mimeTag . contains ( \"protocol\" ) || this . mimeTag . contains ( \"protocol=\\\"application/pkcs7-signature\\\"\" ) ) { this . filename = \"smime.p7s\" ; } } } } void setExtension ( final String extension ) { void setFilename ( final String filename ) { void setLongFilename ( final String longFilename ) { void setMimeTag ( final String mimeTag ) { void setData ( final byte [ ] data ) { void setSize ( final long size ) {", "del_tokens": "private void setExtension ( final String extension ) { private void setFilename ( final String filename ) { private void setLongFilename ( final String longFilename ) { private void setMimeTag ( final String mimeTag ) { private void setData ( final byte [ ] data ) { private void setSize ( final long size ) {", "commit_type": "add"}
{"commit_tokens": ["Implement", "new", "XMLOutputFactory", "added", "to", "jelly", "so", "TagScript", ".", "getBodyText", "()"], "add_tokens": "import org . kohsuke . stapler . Stapler ; import org . apache . commons . jelly . XMLOutputFactory ; import java . io . Writer ; public class DefaultScriptInvoker implements ScriptInvoker , XMLOutputFactory { // so TagScript.getBodyText() will use HTMLWriterOutput context . setVariable ( XMLOutputFactory . class . getName ( ) , this ) ; public XMLOutput createXMLOutput ( Writer writer , boolean escapeText ) { StaplerResponse rsp = Stapler . getCurrentResponse ( ) ; String ct = rsp != null ? rsp . getContentType ( ) : \"?\" ; if ( ct != null && ! ct . startsWith ( \"text/html\" ) ) return XMLOutput . createXMLOutput ( writer , escapeText ) ; return HTMLWriterOutput . create ( writer , escapeText ) ; }", "del_tokens": "import org . dom4j . io . HTMLWriter ; import org . dom4j . io . OutputFormat ; import org . dom4j . io . XMLWriter ; public class DefaultScriptInvoker implements ScriptInvoker {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "wrong", "particle", "triangles", "and", "texture", "coordinates"], "add_tokens": "import com . doctoror . particlesdrawable . util . TextureUtils ; private static final int TEXTURE_COORDINATES_PER_VERTEX = 6 ; final int capacity = vertexCount * COORDINATES_PER_VERTEX * TEXTURE_COORDINATES_PER_VERTEX * VERTICES_PER_PARTICLE ; final int step = VERTICES_PER_PARTICLE * TEXTURE_COORDINATES_PER_VERTEX ; for ( int i = 0 ; i < capacity ; i += step ) { particlesTexturesCoordinates . put ( ( byte ) 1 ) ; particlesTexturesCoordinates . put ( ( byte ) 1 ) ; particlesTexturesCoordinates . put ( ( byte ) 0 ) ; particlesTexturesCoordinates . put ( ( byte ) 0 ) ; particlesTexturesCoordinates . put ( ( byte ) 1 ) ; particlesTexturesCoordinates . put ( ( byte ) 1 ) ; particlesTrianglesCoordinates . put ( ( short ) coordX ) ; particlesTrianglesCoordinates . put ( ( short ) ( coordX + particleSize ) ) ;", "del_tokens": "import com . doctoror . particlesdrawable . util . TextureUtils ; final int capacity = vertexCount * COORDINATES_PER_VERTEX * VERTICES_PER_PARTICLE ; for ( int i = 0 ; i < capacity ; i += VERTICES_PER_PARTICLE ) { particlesTrianglesCoordinates . put ( ( short ) ( coordX + particleSize ) ) ; particlesTrianglesCoordinates . put ( ( short ) coordX ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "import", "on", "one", "line", "+", "package", "filtering"], "add_tokens": "bw . newLine ( ) ; if ( qualifiedName == null ) { return true ; } String name = qualifiedName . toString ( ) ; return name . substring ( 0 , name . lastIndexOf ( \".\" ) ) . equals ( daMapperClass . packageName . toString ( ) ) ;", "del_tokens": "bw . newLine ( ) ; return qualifiedName != null && qualifiedName . toString ( ) . equals ( daMapperClass . packageName . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "VOMServerInfo", "test", "which", "broke", "the", "continuuous", "integration"], "add_tokens": "Assert . assertTrue ( store . getVOMSServerInfo ( \"non-existing-vo\" ) . isEmpty ( ) ) ;", "del_tokens": "Assert . assertNull ( store . getVOMSServerInfo ( \"non-existing-vo\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "subscribe", "method", "that", "infers", "types", "and", "updated", "tests", "."], "add_tokens": "/ * * * Subscribes the subscriber to the type that is specified by the parameter * type of the receive method . * * @ param subscriber - The subscriber . * / public void subscribe ( Subscriber < ? > subscriber ) { subscribeStrategy . subscribe ( mapping , subscriber ) ; } return subscribeStrategy . unsubscribeByTypes ( mapping , subscriberType , messageType ) ;", "del_tokens": "return subscribeStrategy . unsubscribeByTypes ( mapping , subscriberType , messageType ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "test", "case", "as", "we", "changed", "regex", "matching", "from", "full", "to", "partial"], "add_tokens": "{ 36 , regex , \"//a/b/c\" , null , \"[0-9]+\" , \"1234234\" , \"aaaaaaaaaa\" } ,", "del_tokens": "{ 36 , regex , \"//a/b/c\" , null , \"[0-9]+\" , \"1234234\" , \"ab13423a\" } ,", "commit_type": "fix"}
{"commit_tokens": ["allow", "unquoted", "names", "in", "errors", "and", "warnings"], "add_tokens": "import org . apache . commons . lang3 . StringUtils ; import static com . fasterxml . jackson . core . JsonParser . Feature . ALLOW_UNQUOTED_FIELD_NAMES ; if ( StringUtils . isBlank ( comments ) ) { mapper . configure ( ALLOW_UNQUOTED_FIELD_NAMES , true ) ;", "del_tokens": "public static final char COMMENT_NEW_LINE = '#' ; if ( comments . length ( ) == 0 ) {", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "UTF", "-", "8", "header", "."], "add_tokens": "* Copyright © 010- 2 011 okia", "del_tokens": "* Copyright 2010 - 2011 Nokia", "commit_type": "fix"}
{"commit_tokens": ["Adding", "additional", "Type", "Injection", "Analyzer", "tests"], "add_tokens": "public void testConstrictorInjection ( ) throws Exception {", "del_tokens": "public void testContructorInjection ( ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "comments", ".", "Remove", "unneeded", "ones", "."], "add_tokens": "//If no extended native handler, just use the default one //Instantiate the appropriate handler //First, assign the activity to which the handler is attached //Set up the layout of the activity //Perform menu inflation, if specified //Set the title, if specified //If the use of the logo is desired, tell the handler //If a drop-down is wanted, pass the adapter and listener for setup //Set whether or not the home button functions as \"up\" //Execute the onCreate callback for any additional setup / * * * Activity to which we are attached . * / / * * * Activity 's action bar instance. * / //Attempt to obtain the logo from the activity's entry in its manifest //If no activity logo was found, try to get the application's logo", "del_tokens": "//Attempt to obtain the logo from the activity's entry in its manifest //If no activity logo was found, try to get the application's logo //For native action bars assigning a layout is all that is required //For native action bars assigning a layout is all that is required", "commit_type": "add"}
{"commit_tokens": ["Improve", "error", "message", "on", "so", "loading", "failure"], "add_tokens": "String cause = error . getMessage ( ) ; if ( cause == null ) { cause = error . toString ( ) ; } message += \" caused by: \" + cause ;", "del_tokens": "message += \" caused by: \" + error . getMessage ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["Remove", "granting", "permission", "from", "library"], "add_tokens": "void start ( ) {", "del_tokens": "boolean start ( ) { // TODO Don't return true and test it in some other way return true ;", "commit_type": "remove"}
{"commit_tokens": ["change", "to", "datatype<arg1", "arg2", ">", "syntax", "instead", "of", "datatype", "arg1", "arg2"], "add_tokens": "assertEquals ( _DataType ( \"Foo\" , list ( \"A\" ) , list ( _Constructor ( \"Foo\" , Util . < Arg > list ( ) ) ) ) , parserImpl ( \"Foo<A>=Foo\" ) . dataType ( ) ) ; assertEquals ( _DataType ( \"Foo\" , list ( \"A\" , \"B\" ) , list ( _Constructor ( \"Foo\" , Util . < Arg > list ( ) ) ) ) , parserImpl ( \"Foo<A, B>=Foo\" ) . dataType ( ) ) ;", "del_tokens": "assertEquals ( _DataType ( \"Foo\" , list ( \"A\" ) , list ( _Constructor ( \"Foo\" , Util . < Arg > list ( ) ) ) ) , parserImpl ( \"Foo A=Foo\" ) . dataType ( ) ) ; assertEquals ( _DataType ( \"Foo\" , list ( \"A\" , \"B\" ) , list ( _Constructor ( \"Foo\" , Util . < Arg > list ( ) ) ) ) , parserImpl ( \"Foo A B=Foo\" ) . dataType ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "implementation", "and", "tests", "for", "Artist", "requests"], "add_tokens": "import se . michaelthelin . spotify . JsonUtil ; import se . michaelthelin . spotify . SpotifyProtos . Artist ; public Artist getArtist ( ) { return JsonUtil . createArtist ( getJson ( ) ) ; }", "del_tokens": "import com . google . common . base . Joiner ;", "commit_type": "add"}
{"commit_tokens": ["removed", "accidental", "Java", "8", "code"], "add_tokens": "for ( int i = 0 ; i < parameterAnnotations . length ; i ++ ) {", "del_tokens": "for ( int i = 0 ; i < method . getParameterCount ( ) ; i ++ ) {", "commit_type": "remove"}
{"commit_tokens": ["Move", "static", "text", "components", "from", "Component", "--", ">", "TextComponent"], "add_tokens": "if ( value == '\\n' ) return newline ( ) ; if ( value == ' ' ) return space ( ) ; / * * * Gets a text component with empty content . * * @ return a text component with empty content * / static @ NonNull TextComponent empty ( ) { return TextComponentImpl . EMPTY ; } / * * * Gets a text component with a new line character as the content . * * @ return a text component with a new line character as the content * / static @ NonNull TextComponent newline ( ) { return TextComponentImpl . NEWLINE ; } / * * * Gets a text immutable component with a single space as the content . * * @ return a text component with a single space as the content * / static @ NonNull TextComponent space ( ) { return TextComponentImpl . SPACE ; }", "del_tokens": "if ( value == '\\n' ) return Component0 . NEWLINE ; if ( value == ' ' ) return Component0 . SPACE ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "locale", "-", "dependent", "unit", "tests", "so", "that", "they", "pass", "under", "a", "different", "locale", "(", "tested", "with", "de_DE", ")", "."], "add_tokens": "* Tests the FmtNumber processor . As FmtNumber uses the default locale , this test must be written in a locale * independent way ( so the test will pass ) . The test can be run in a different local by specifying the * < tt > user . language < / tt > and < tt > user . country < / tt > JVM properties ( i . e . < tt > - Duser . language = de - Duser . country = DE < / tt > ) . // locale-independent private static final String FORMATTED_NUMBER = new DecimalFormat ( DECIMAL_FORMAT ) . format ( 12.34 ) ; final double number = 12.34 ; final double toRoundUp = 12.339 ; final double toRoundDown = 12.341 ; final double number = 12.34 ; final double number = 12.34 ; final double number = 12.34 ;", "del_tokens": "* Tests the FmtNumber processor . private static final String FORMATTED_NUMBER = \"12.34\" ; double number = 12.34 ; double toRoundUp = 12.339 ; double toRoundDown = 12.341 ; double number = 12.34 ; double number = 12.34 ; double number = 12.34 ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "conan", "package", "type", "support", "."], "add_tokens": "pypi , sbt , vagrant , vcs , yum , composer , conan", "del_tokens": "pypi , sbt , vagrant , vcs , yum , composer", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "clearTable", "()", "method", "in", "TableUtils", ".", "It", "will", "do", "a", "TRUNCATE", "if", "possible", "otherwise", "DELETE", "."], "add_tokens": "@ Override public boolean isEntityNamesMustBeUpCase ( ) { return true ; }", "del_tokens": "@ Override public boolean isEntityNamesMustBeUpCase ( ) { return true ; }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "squid", ":", "S1066", "squid", ":", "S1155"], "add_tokens": "if ( children != null && ! children . isEmpty ( ) ) {", "del_tokens": "if ( children != null && children . size ( ) > 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "categories", "false", "for", "opt", "-", "in", "approach", "."], "add_tokens": "private boolean useCategories ;", "del_tokens": "private boolean useCategories = true ;", "commit_type": "make"}
{"commit_tokens": ["Added", "tests", "for", "invalid", "grammar", "."], "add_tokens": "* < p > * This returns dice notation expressions representing only a single dice * group . * Returns the parameters for tests requiring an invalid dice notation * expression . * * @ return arrays with an invalid dice notation expression * @ throws Exception * if any error occurs while loading the parameters * / public static final Iterator < Object [ ] > getDiceNotationInvalid ( ) throws Exception { final CellProcessor [ ] processors ; // Procesors for the CSV file // The CSV has the following columns: // Anything processors = new CellProcessor [ ] { new NotNull ( ) } ; return getParameters ( ParameterCsvPaths . DICE_TEXT_INVALID , processors ) ; } / * * * Returns the parameters for tests requiring a valid dice notation * expression . * @ return arrays with a valid dice notation expression public static final Iterator < Object [ ] > getDiceNotationValid ( ) throws Exception {", "del_tokens": "* Returns the parameters for tests requiring a valid dice string . * @ return arrays with a valid dice string public static final Iterator < Object [ ] > getDiceTextValid ( ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Removed", "a", "duplicate", "line", "of", "code", "."], "add_tokens": "The minimum size for a multi part is 5 MB , hence the buffer size of 5 MB", "del_tokens": "The minimum size for an multi part is 5 MB , hence the buffer size of 5 MB withPartSize ( this . outputStream . size ( ) ) .", "commit_type": "remove"}
{"commit_tokens": ["improved", "clearAll", "methods", "by", "not", "copying", "existing", "collections"], "add_tokens": "* Every listner 's {@link Listener#onUnregister(RegistrationEvent) onUnregister} * method will be called . * Removes all registered listeners from this EventProvider . Every listner 's * { @ link Listener # onUnregister ( RegistrationEvent ) onUnregister } method will be * called . * Closes this EventProvider and removes all registered listeners . Depending on the * actual implementation , the EventProvider might not be able to dispatch further * events after disposing . On some implementations closing might have no additional * effect .", "del_tokens": "* Removes all registered listeners from this EventProvider . * Closes this EventProvider . Depending on its implementation , it might not be * able to dispatch further events after disposing . On some implementations closing * might have no effect .", "commit_type": "improve"}
{"commit_tokens": ["make", "start", "and", "stop", "methods", "public", "too", ";", "if", "this", "object", "gets", "created", "by", "a", "provider", "it", "must", "do", "the", "lifecycle", "manually", "."], "add_tokens": "public JmsEventReceiver ( final JmsEventConfig jmsEventConfig , public void injectTopicFactory ( @ Named ( JMS_EVENT_NAME ) final JmsRunnableFactory topicFactory ) public void start ( ) public void stop ( ) try { final TopicConsumer topicConsumer = topicConsumerHolder . getAndSet ( null ) ; if ( topicConsumer != null ) { topicConsumer . shutdown ( ) ; consumerThread . interrupt ( ) ; consumerThread . join ( 500L ) ; } } catch ( InterruptedException ie ) { Thread . currentThread ( ) . interrupt ( ) ; // Someone else needs to handle that.", "del_tokens": "JmsEventReceiver ( final JmsEventConfig jmsEventConfig , void injectTopicFactory ( @ Named ( JMS_EVENT_NAME ) final JmsRunnableFactory topicFactory ) void start ( ) void stop ( ) throws InterruptedException final TopicConsumer topicConsumer = topicConsumerHolder . getAndSet ( null ) ; if ( topicConsumer != null ) { topicConsumer . shutdown ( ) ; consumerThread . interrupt ( ) ; consumerThread . join ( 500L ) ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "the", "sensor", "strict", "mode", "."], "add_tokens": "import com . yanzhenjie . permission . ApLog ; return mChecker . hasPermission ( context , permission ) ; ApLog . e ( e ) ;", "del_tokens": "import android . hardware . SensorManager ; return checkBodySensors ( context ) ; private static boolean checkBodySensors ( Context context ) throws Throwable { SensorManager sensorManager = ( SensorManager ) context . getSystemService ( Context . SENSOR_SERVICE ) ; PermissionTest test = new SensorTest ( sensorManager ) ; test . test ( ) ; return true ; }", "commit_type": "remove"}
{"commit_tokens": ["add", "support", "for", "open", "graph", "template", "(", "send", "api", ")"], "add_tokens": "LIST , OPEN_GRAPH", "del_tokens": "LIST", "commit_type": "add"}
{"commit_tokens": ["updated", "imports", "after", "changing", "to", "orginal", "objenesis", "library"], "add_tokens": "import org . objenesis . Objenesis ; import org . objenesis . ObjenesisStd ;", "del_tokens": "import org . springframework . objenesis . Objenesis ; import org . springframework . objenesis . ObjenesisStd ;", "commit_type": "update"}
{"commit_tokens": ["added", "validation", "to", "cpe", "component", "parts"], "add_tokens": "public class CpeParsingException extends CpeValidationException { / * * * Constructs a new exception with the specified detail message and cause . * * @ param message the detailed message * @ param cause the cause of the exception * / public CpeParsingException ( String message , Exception cause ) { super ( message , cause ) ; }", "del_tokens": "public class CpeParsingException extends Exception {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "fields", "and", "enum", "constants", "javadoc"], "add_tokens": "public static String fieldsFieldName ( ) { return \"fields\" ; } public static String enumConstantsFieldName ( ) { return \"enumConstants\" ; } public static String elementNameFieldName ( ) { return \"name\" ; public static String elementDocFieldName ( ) {", "del_tokens": "public static String classDocFieldName ( ) { return \"doc\" ; public static String methodDocFieldName ( ) { public static String methodNameFieldName ( ) { return \"name\" ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "wrapping", "step", "error", "message", "in", "div", "."], "add_tokens": "sb . append ( \"<div class=\\\"step-error-message\\\"><pre class=\\\"step-error-message-content\\\">\" ) . append ( formatError ( errorMessage ) ) . append ( \"</pre></div>\" ) ;", "del_tokens": "sb . append ( \"<div class=\\\"step-error-message\\\"><pre>\" ) . append ( formatError ( errorMessage ) ) . append ( \"</pre></div>\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "stream", "stack", "to", "build", "script"], "add_tokens": "public void assertResults ( ) throws CharacterCodingException , ConnectionException {", "del_tokens": "public void assertResults ( ) throws CharacterCodingException , ConnectionException {", "commit_type": "add"}
{"commit_tokens": ["fix", "FileSystem", ".", "get", "in", "HDFSFileSink"], "add_tokens": "import java . net . URI ; import java . net . URISyntaxException ; FileSystem fs = FileSystem . get ( new URI ( path ) , job . getConfiguration ( ) ) ; } catch ( IOException | URISyntaxException e ) { FileSystem fs = FileSystem . get ( new URI ( path ) , job . getConfiguration ( ) ) ;", "del_tokens": "FileSystem fs = FileSystem . get ( job . getConfiguration ( ) ) ; } catch ( IOException e ) { FileSystem fs = FileSystem . get ( job . getConfiguration ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "informative", "log", "messages", "and", "changed", "the", "logger", "name"], "add_tokens": "private static final Logger LOG = LoggerFactory . getLogger ( UserAgentStringParserIntegrationTest . class ) ; for ( final OperatingSystemExample example : OS_EXAMPLES ) { LOG . info ( \"Unknown operating system family found. Please update the enum 'OperatingSystemFamily' for '\" + agent . getOperatingSystem ( ) . getName ( ) + \"'.\" ) ; for ( final UserAgentExample example : UA_EXAMPLES ) { if ( ! example . getName ( ) . equals ( agent . getFamily ( ) ) ) { LOG . info ( \"Unexpected user agent family found. Please check the user agent string '\" + example . getUserAgentString ( ) + \"'.\" ) ; }", "del_tokens": "import net . sf . uadetector . parser . OnlineUserAgentStringParserImpl ; private static final Logger LOG = LoggerFactory . getLogger ( OnlineUserAgentStringParserImpl . class ) ; for ( OperatingSystemExample example : OS_EXAMPLES ) { LOG . info ( \"Unknown operating system family found. Please update the enum 'OperatingSystemFamily'.\" ) ; for ( UserAgentExample example : UA_EXAMPLES ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "in", "JsonWebToken", ".", "Payload", ".", "isValidTime", "()"], "add_tokens": "|| now >= ( issuedAtTimeSeconds - acceptableTimeSkewSeconds ) * 1000 ) ;", "del_tokens": "|| now >= ( issuedAtTimeSeconds + acceptableTimeSkewSeconds ) * 1000 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "method", "to", "Tokenizer", "interface", "to", "determine", "if", "a", "char", "is", "a", "word", "-", "breaking", "char"], "add_tokens": "/ * * * { @ inheritDoc } * / public boolean isWordBreakingChar ( final char c ) { final String wordBreakChars = mConfig . WORD_BREAK_CHARS ; for ( int i = 0 ; i < wordBreakChars . length ( ) ; i ++ ) { char wordBreakChar = wordBreakChars . charAt ( i ) ; if ( c == wordBreakChar ) { return true ; } } return false ; }", "del_tokens": "/ * * * Determines if given character is a word - breaking character according to the current settings * within the { @ link Configuration } . * * @ param c character to test * * @ return true if c is an word - breaking character * / public boolean isWordBreakingChar ( final char c ) { final String wordBreakChars = mConfig . WORD_BREAK_CHARS ; for ( int i = 0 ; i < wordBreakChars . length ( ) ; i ++ ) { char wordBreakChar = wordBreakChars . charAt ( i ) ; if ( c == wordBreakChar ) { return true ; } } return false ; }", "commit_type": "add"}
{"commit_tokens": ["Changed", "Access", "-", "Control", "-", "Allow", "-", "Origin", "response", "header", "to", "be", "space", "-", "delimited", "vs", ".", "comma", "-", "delimited", "."], "add_tokens": "allowOriginHeader = StringUtils . join ( \" \" , ( Object [ ] ) origins ) ;", "del_tokens": "allowOriginHeader = StringUtils . join ( \",\" , ( Object [ ] ) origins ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "the", "bug", "of", "wrong", "output", "if", "ROOT", "value", "shows", "in", "source", "object"], "add_tokens": "if ( source . isObject ( ) || isObjectifiableArray ( ) ) else return javaObj2Json ( flattenedMap . get ( ROOT ) ) ; } private boolean isObjectifiableArray ( ) { return source . isArray ( ) && ! flattenedMap . containsKey ( ROOT ) ;", "del_tokens": "if ( flattenedMap . containsKey ( ROOT ) ) return javaObj2Json ( flattenedMap . get ( ROOT ) ) ; else", "commit_type": "fix"}
{"commit_tokens": ["Add", "config", "files", "and", "classes"], "add_tokens": "import org . apache . commons . io . filefilter . RegexFileFilter ; import ru . yandex . qatools . allure . config . AllureModelConfig ; import ru . yandex . qatools . allure . config . AllureResultsConfig ; String schemaFileName = AllureModelConfig . newInstance ( ) . getSchemaFileName ( ) ; this . schemaFile = new File ( ClassLoader . getSystemResource ( schemaFileName ) . getFile ( ) ) ; AllureResultsConfig resultsConfig = AllureResultsConfig . newInstance ( ) ; File results = new File ( ClassLoader . getSystemResource ( resultsConfig . getDirectoryPath ( ) ) . getFile ( ) ) ; for ( String testSuiteFilePath : results . list ( new RegexFileFilter ( resultsConfig . getTestSuiteFileRegex ( ) ) ) ) {", "del_tokens": "import org . apache . commons . io . filefilter . RegexFileFilter ; private final static ModelProperties modelProperties = new ModelProperties ( ) ; private static final String TEST_SUITE_FILES_REGEXP = \".*-testsuite\\\\.xml\" ; this . schemaFile = new File ( ClassLoader . getSystemResource ( modelProperties . getModelFileName ( ) ) . getFile ( ) ) ; File results = new File ( ClassLoader . getSystemResource ( modelProperties . getResultsPath ( ) ) . getFile ( ) ) ; for ( String testSuiteFilePath : results . list ( new RegexFileFilter ( TEST_SUITE_FILES_REGEXP ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problems", "with", "array", "list", "initialization", "and", "coverage", "tests", "."], "add_tokens": "this . attributeFieldInfos = arrayToList ( attributeFieldInfos ) ; this . attributeMethodInfos = arrayToList ( attributeMethodInfos ) ; this . operationInfos = arrayToList ( operationInfos ) ; private < T > List < T > arrayToList ( T [ ] array ) { List < T > list = new ArrayList < T > ( array . length ) ; for ( T t : array ) { list . add ( t ) ; } return list ; }", "del_tokens": "import java . util . Arrays ; this . attributeFieldInfos = Arrays . asList ( attributeFieldInfos ) ; this . attributeMethodInfos = Arrays . asList ( attributeMethodInfos ) ; this . operationInfos = Arrays . asList ( operationInfos ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "Rlike", "in", "H2", "and", "Postgres", ".", "Throw", "an", "error", "instead", "of", "using", "a", "plain", "like", "if", "rlike", "is", "not", "supported"], "add_tokens": "import org . hibernate . dialect . * ; throw new HibernateException ( \"rlike may only be used with single-column properties\" ) ; if ( dialect instanceof PostgreSQL81Dialect ) { return columns [ 0 ] + \" ~* ?\" ; } if ( dialect instanceof H2Dialect ) { return columns [ 0 ] + \" REGEXP ?\" ; } throw new HibernateException ( \"rlike is not supported with the configured dialect \" + dialect . getClass ( ) . getCanonicalName ( ) ) ;", "del_tokens": "import org . hibernate . dialect . Dialect ; import org . hibernate . dialect . MySQLDialect ; import org . hibernate . dialect . Oracle8iDialect ; throw new HibernateException ( \"ilike may only be used with single-column properties\" ) ; return columns [ 0 ] + \" like ?\" ;", "commit_type": "add"}
{"commit_tokens": ["fix", "tyson", "bug", "immediately", "hit", "new", "bug"], "add_tokens": "String [ ] tok = value . split ( ReflectionUtilities . regexp ) ;", "del_tokens": "String [ ] tok = value . split ( TypeHierarchy . regexp ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "the", "UI", "slightly", "by", "moving", "the", "suggested", "fix", "to", "a", "new", "line", ".", "It", "seems", "that", "the", "javac", "error", "printer", "somehow", "puts", "the", "code", "snippet", "on", "a", "line", "in", "between", ":"], "add_tokens": "import javax . tools . JavaFileObject ; + \"\\ndid you mean to remove this line?\" ) ; + \"\\ndid you mean '\" + fix . getNewCodeSnippet ( ) + \"'?\" ) ;", "del_tokens": "import javax . tools . JavaFileObject ; + \"; did you mean to remove this line?\" ) ; + \"; did you mean '\" + fix . getNewCodeSnippet ( ) + \"'?\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Make", "handleAuthFailureForStream", "have", "parity", "with", "handleAuthFailure"], "add_tokens": "// using a refresh token implies we cannot refresh anything, so clear auth and // notify if ( req . getUseRefreshToken ( ) || ! req . getShouldRefreshOnFailure ( ) ) {", "del_tokens": "if ( ! req . getShouldRefreshOnFailure ( ) ) {", "commit_type": "make"}
{"commit_tokens": ["Removed", "call", "to", "get", "index", "metadata", "in", "JDBC", "repository", "."], "add_tokens": "IndexInfo [ ] indexInfo = new IndexInfo [ 0 ] ; / * Oracle driver has a bug that always causes an analyze to run when requesting index info . Checking indexes is not that important so don 't bother checking. Revisit if Oracle bug ever gets fixed. * /", "del_tokens": "IndexInfo [ ] indexInfo ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "setting", "Limit", ".", "Needed", "to", "bump", "aws", "sdk", "version", "+", "some", "fixes", "to", "get", "it", "going"], "add_tokens": "import com . amazonaws . services . dynamodb . model . AttributeValue ; import com . amazonaws . services . dynamodb . model . Condition ; import com . amazonaws . transform . JsonUnmarshallerContext ; import com . amazonaws . transform . ListUnmarshaller ; import com . amazonaws . transform . SimpleTypeJsonUnmarshallers ; import com . amazonaws . transform . Unmarshaller ; if ( context . testExpression ( \"ComparisonOperator\" , targetDepth ) || context . testExpression ( \"ComparisonOperator\" , targetDepth - 1 ) ) {", "del_tokens": "import com . amazonaws . transform . * ; import com . amazonaws . services . dynamodb . model . * ; if ( context . testExpression ( \"ComparisonOperator\" , originalDepth ) || context . testExpression ( \"ComparisonOperator\" , originalDepth - 1 ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "URLEncode", "on", "deleteIndex", "method"], "add_tokens": "import java . net . URLEncoder ; * { \"name\" : \"notes\" , \"createdAt\" : \"2013-01-18T15:33:13.556Z\" } ] } try { return _deleteRequest ( \"/1/indexes/\" + URLEncoder . encode ( indexName , \"UTF-8\" ) ) ; } catch ( UnsupportedEncodingException e ) { throw new RuntimeException ( e ) ; }", "del_tokens": "* { \"name\" : \"notes\" , \"createdAt\" : \"2013-01-18T15:33:13.556Z\" } ] ��} return _deleteRequest ( \"/1/indexes/\" + indexName ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "for", "only", "one", "child", "id"], "add_tokens": "if ( childIds . length == 1 ) { int id = childIds [ 0 ] ; childIds = new int [ 2 ] ; childIds [ 0 ] = id ; childIds [ 1 ] = id ; }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Implement", "encloseWithParentheses", "()", "using", "recursion", "to", "handle", "any", "size", "of", "complex", "concepts", "."], "add_tokens": "import java . util . ArrayList ; String expected3 = \"[[n1.0], [n2.0, n3.0]]\" ; String expected5 = \"[[n1.0, n2.0], [[n3.0], [n4.0, n5.0]]]\" ; for ( int i = 5 ; i < 10 ; i ++ ) { List < String > vecTest = new ArrayList < String > ( ) ; for ( int j = 0 ; j <= i ; j ++ ) { vecTest . add ( \"n\" + String . valueOf ( j ) + \".0\" ) ; } DefaultContextPreprocessor . encloseWithParentheses ( vecTest ) ; }", "del_tokens": "String expected3 = \"[[n1.0, n2.0], [n3.0]]\" ; String expected5 = \"[[[n1.0, n2.0], [n3.0, n4.0]], [n5.0]]\" ;", "commit_type": "implement"}
{"commit_tokens": ["added", "string", "wrapper", "simple", "string", "responses"], "add_tokens": "import org . mythtv . services . api . StringWrapper ; ResponseEntity < StringWrapper > getHostName ( ) throws MythServiceApiRuntimeException ; ResponseEntity < StringWrapper > profileText ( ) throws MythServiceApiRuntimeException ; ResponseEntity < StringWrapper > profileUrl ( ) throws MythServiceApiRuntimeException ; ResponseEntity < StringWrapper > profileUpdated ( ) throws MythServiceApiRuntimeException ;", "del_tokens": "ResponseEntity < String > getHostName ( ) throws MythServiceApiRuntimeException ; ResponseEntity < String > profileText ( ) throws MythServiceApiRuntimeException ; ResponseEntity < String > profileUrl ( ) throws MythServiceApiRuntimeException ; ResponseEntity < String > profileUpdated ( ) throws MythServiceApiRuntimeException ;", "commit_type": "add"}
{"commit_tokens": ["Added", "override", "sort", "and", "query", "builder", "definitions", "at", "the", "entity", "level"], "add_tokens": "sorts . putAll ( entityPluginBuilder . getDefaultSortBuilders ( ) ) ; sorts . putAll ( entityPluginBuilder . getOverrideSortBuilders ( ) ) ; queries . putAll ( entityPluginBuilder . getDefaultQueryBuilders ( ) ) ; queries . putAll ( entityPluginBuilder . getOverrideQueryBuilders ( ) ) ;", "del_tokens": "sorts . putAll ( entityPluginBuilder . getSortBuilders ( ) ) ; queries . putAll ( entityPluginBuilder . getQueryBuilders ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "last", "details", "before", "the", "PR"], "add_tokens": "\"RendererBuilder has to be created with a non null collection of\" \"RendererBuilder has to be created with a non null collection of\" \"RendererBuilder has to be created with a non null collection of\"", "del_tokens": "\"RendererBuilder have to be created with a non null collection of\" \"RendererBuilder have to be created with a non null collection of\" \"RendererBuilder have to be created with a non null collection of\"", "commit_type": "fix"}
{"commit_tokens": ["Make", "insert", "accept", "varargs", "."], "add_tokens": "public Signature insertArgs ( int index , String [ ] names , Class ... types ) {", "del_tokens": "public Signature insertArgs ( int index , String [ ] names , Class [ ] types ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "declarative", "way", "to", "register", "a", "JMS", "ExceptionListener", "using", "props"], "add_tokens": "import io . nuun . kernel . api . plugin . PluginException ; import javax . jms . ExceptionListener ; private final ConcurrentMap < String , Class < ? extends ExceptionListener > > exceptionListenerClassMap = new ConcurrentHashMap < String , Class < ? extends ExceptionListener > > ( ) ; // Add exceptionListenerClass for current connectionName Class < ? extends ExceptionListener > exceptionListenerClass = getExceptionListenerClass ( connectionConfiguration . getString ( \"exceptionListener\" ) ) ; if ( exceptionListenerClass != null ) { exceptionListenerClassMap . put ( connectionName , exceptionListenerClass ) ; } return new JmsModule ( connectionMap , messageListenerDefinitions , jmsExceptionHandlerClasses , exceptionListenerClassMap ) ; public Class < ? extends ExceptionListener > getExceptionListenerClass ( String className ) { Class < ? extends ExceptionListener > exceptionListenerClass = null ; if ( StringUtils . isNotBlank ( className ) ) { try { exceptionListenerClass = ( Class < ? extends ExceptionListener > ) Class . forName ( className ) ; } catch ( ClassNotFoundException e ) { throw new PluginException ( \"Unable to load default jms exceptionListener class \" + className , e ) ; } } return exceptionListenerClass ; }", "del_tokens": "return new JmsModule ( connectionMap , messageListenerDefinitions , jmsExceptionHandlerClasses ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "HTTP", "Link", "Headers"], "add_tokens": "import com . damnhandy . uri . template . UriTemplate ; import lombok . * ; String relativeUri = childTemplate . set ( \"id\" , getCollectionKey ( entity ) ) . expand ( ) ; return get ( URI . create ( relativeUri ) ) ; } / * * * The URI template used to construct URIs of child elements of this * collection . * / protected UriTemplate childTemplate = UriTemplate . fromTemplate ( \"{id}\" ) ; / * * * The HTTP Link header relation type used by the server to set the * collection child element URI template . * / @ Getter @ Setter private String childTemplateRel = \"child-template\" ; @ Override protected void handleLink ( String href , String rel , String title ) { if ( childTemplateRel . equals ( rel ) ) { childTemplate = UriTemplate . fromTemplate ( href ) ; } super . handleLink ( href , rel , title ) ;", "del_tokens": "import lombok . Getter ; return get ( URI . create ( getCollectionKey ( entity ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Allows", "context", "to", "be", "backwards", "compatible"], "add_tokens": "content . setContext ( Context . valueOf ( par . getValueAsInt ( ) ) ) ;", "del_tokens": "content . setContext ( Context . valueOf ( par . getIntValue ( ) ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["make", "protected", "executeScript", "from", "WebLocator"], "add_tokens": "protected Object executeScript ( String script , Object ... objects ) {", "del_tokens": "public Object executeScript ( String script , Object ... objects ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "CMLWriter", "class", "and", "a", "program", "to", "test", "it", "."], "add_tokens": "ChemFile chemFile ; cw = new CMLWriter ( ( Writer ) new FileWriter ( outFile ) ) ; cw . close ( ) ;", "del_tokens": "cw = new CMLWrite ( new FileWriter ( outFile ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "tar", ".", "bz2", "file", "extraction"], "add_tokens": "import org . codehaus . plexus . archiver . tar . TarBZip2UnArchiver ; public static final List < String > TAR_EXTENSIONS = Arrays . asList ( \"tar.gz\" , \"tar\" , \"tgz\" , \"tar.bz2\" ) ; public static final String BZ_SUFFIX = \".bz2\" ; public static final String TAR_GZ_SUFFIX = TAR_SUFFIX + GZ_SUFFIX ; public static final String TAR_BZ2_SUFFIX = TAR_SUFFIX + BZ_SUFFIX ; unArchiver = new TarUnArchiver ( ) ; } else if ( fileName . endsWith ( TAR_BZ2_SUFFIX ) ) { unArchiver = new TarBZip2UnArchiver ( ) ;", "del_tokens": "public static final List < String > TAR_EXTENSIONS = Arrays . asList ( \"tar.gz\" , \"tar\" , \"tgz\" ) ; public static final String TAR_GZ_SUFFIX = TAR_SUFFIX + GZ_SUFFIX ; unArchiver = new TarGZipUnArchiver ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "<polyline", ">", "."], "add_tokens": "public float [ ] points ;", "del_tokens": "public Length [ ] points ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "test", "on", "adding", "files"], "add_tokens": "return jsonBuilder ( ) . prettyPrint ( ) . startObject ( ) xcb . endObject ( ) logger . info ( \" --> creating river: {}\" , xcb . string ( ) ) ; return xcb ; // We wait up to 10 seconds before considering a failing test / * * * Test case for issue # 60 : https : //github.com/dadoonet/fsriver/issues/60 : new files are not added * / @ Test public void test_add_new_file ( ) throws Exception { String dir = \"test_add_new_file\" ; String fullpath = getUrl ( dir ) ; XContentBuilder river = startRiverDefinition ( dir ) ; startRiver ( \"test_add_new_file\" , endRiverDefinition ( river ) ) ; // We should have two docs first countTestHelper ( \"test_add_new_file\" , null , 1 ) ; logger . info ( \" ---> Adding a copy of roottxtfile.txt\" ) ; // We create a copy of a file File file1 = new File ( fullpath + File . separator + \"roottxtfile.txt\" ) ; File file2 = new File ( fullpath + File . separator + \"new_roottxtfile.txt\" ) ; FileSystemUtils . copyFile ( file1 , file2 ) ; Thread . sleep ( 1000 ) ; // We expect to have two files countTestHelper ( \"test_add_new_file\" , null , 2 ) ; }", "del_tokens": "return jsonBuilder ( ) . startObject ( ) return xcb . endObject ( ) // We wait up to 5 seconds before considering a failing test", "commit_type": "add"}
{"commit_tokens": ["Fix", "imports", "and", "delete", "unused", "parameter"], "add_tokens": "import org . onepf . life2 . oms . appstore . googleUtils . IabException ; import org . onepf . life2 . oms . appstore . googleUtils . IabHelper ; import org . onepf . life2 . oms . appstore . googleUtils . Inventory ; import org . onepf . life2 . oms . appstore . googleUtils . Purchase ;", "del_tokens": "import org . onepf . life2 . google . util . IabException ; import org . onepf . life2 . google . util . IabHelper ; import org . onepf . life2 . google . util . Inventory ; import org . onepf . life2 . google . util . Purchase ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "dnsseed", ".", "bluematt", ".", "me", "to", "the", "DNS", "discovery", "list", "."], "add_tokens": "public static final String [ ] defaultHosts = new String [ ] { \"dnsseed.bluematt.me\" , // Auto generated \"bitseed.xf2.org\" , // Static \"bitseed.bitcoin.org.uk\" // Static } ;", "del_tokens": "private static final String [ ] defaultHosts = new String [ ] { \"bitseed.xf2.org\" , \"bitseed.bitcoin.org.uk\" } ;", "commit_type": "add"}
{"commit_tokens": ["Added", "comment", "to", "test", "."], "add_tokens": "\"doubleValue: 0.0002 # comment\\n\" + //", "del_tokens": "\"doubleValue: 0.0002\\n\" + //", "commit_type": "add"}
{"commit_tokens": ["Added", "cross", "-", "over", "and", "mutation", "checkboxes", "to", "TSP", "applet", "."], "add_tokens": "private final boolean crossover ; private final boolean mutation ; * @ param crossover Whether or not to use a cross - over operator in the evolution . * @ param mutation Whether or not to use a mutation operator in the evolution . int generationCount , boolean crossover , boolean mutation ) if ( ! crossover && ! mutation ) { throw new IllegalArgumentException ( \"At least one of cross-over or mutation must be selected.\" ) ; } this . crossover = crossover ; this . mutation = mutation ; if ( crossover ) { EvolutionaryOperator < List < ? > > crossoverOperator = new ListOrderCrossover ( ) ; operators . add ( crossoverOperator ) ; } if ( mutation ) { EvolutionaryOperator < List < ? > > mutationOperator = new ListOrderMutation ( new PoissonGenerator ( 1.5 , rng ) , new PoissonGenerator ( 1.5 , rng ) ) ; operators . add ( mutationOperator ) ; }", "del_tokens": "int generationCount ) EvolutionaryOperator < List < ? > > crossover = new ListOrderCrossover ( ) ; EvolutionaryOperator < List < ? > > mutation = new ListOrderMutation ( new PoissonGenerator ( 1.5 , rng ) , new PoissonGenerator ( 1.5 , rng ) ) ; operators . add ( crossover ) ; operators . add ( mutation ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "concrete", "map", "set", "and", "list", "types", "from", "handlers", "use", "interfaces", "instead"], "add_tokens": "handlers . put ( Map . class , new MapHandler ( ) ) ; handlers . put ( List . class , new ListHandler ( ) ) ; handlers . put ( Set . class , new SetHandler ( ) ) ;", "del_tokens": "handlers . put ( HashMap . class , new MapHandler ( ) ) ; handlers . put ( LinkedList . class , new ListHandler ( ) ) ; handlers . put ( ArrayList . class , new ArrayHandler ( \"array\" ) ) ; handlers . put ( HashSet . class , new SetHandler ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "partial", "reads", "to", "SimpleDataArray"], "add_tokens": "* 09 / 24 , 2010", "del_tokens": "* Sep 24 , 2010", "commit_type": "add"}
{"commit_tokens": ["Improved", "/", "re", "-", "enabled", "tests"], "add_tokens": "public static final double EPSILON = 0.001 ;", "del_tokens": "public static final double EPSILON = 0.00001 ;", "commit_type": "improve"}
{"commit_tokens": ["Allow", "global", "proxy", "settings", "using", "system", "properties"], "add_tokens": "return fetch ( url , null , DEFAULT_READ_TIMEOUT , DEFAULT_READ_TIMEOUT ) ; if ( proxy == null ) { conn = url . openConnection ( ) ; } else { conn = url . openConnection ( proxy ) ; } return getLatestVersion ( url , null , DEFAULT_READ_TIMEOUT , DEFAULT_READ_TIMEOUT ) ;", "del_tokens": "return fetch ( url , Proxy . NO_PROXY , DEFAULT_READ_TIMEOUT , DEFAULT_READ_TIMEOUT ) ; conn = url . openConnection ( proxy ) ; return getLatestVersion ( url , Proxy . NO_PROXY , DEFAULT_READ_TIMEOUT , DEFAULT_READ_TIMEOUT ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "the", "ability", "to", "search", "for", "an", "equal", "min", "hash"], "add_tokens": "final Integer sourceTopicId = Integer . parseInt ( components [ 0 ] ) ; final Float minimumSimilarity = Float . parseFloat ( components [ 1 ] ) ; final List < Integer > matchingTopics = TopicUtilities . getMatchingMinHash ( getEntityManager ( ) , sourceTopicId , minimumSimilarity ) ;", "del_tokens": "final List < Integer > matchingTopics = TopicUtilities . getMatchingMinHash ( getEntityManager ( ) , Integer . parseInt ( components [ 0 ] ) , Float . parseFloat ( components [ 1 ] ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "384", "bit", "standard", "prime", "test"], "add_tokens": "subtestBigBig ( SecretShare . getPrimeUsedFor192bitSecretPayload ( ) , new BigInteger ( \"12345678998765432100112233445566778899\" ) ) ; subtestBigBig ( SecretShare . getPrimeUsedFor384bitSecretPayload ( ) , new BigInteger ( \"12345678998765432100112233445566778899\" + \"000000000012345678987654321\" ) ) ; public void subtestBigBig ( final BigInteger prime , final BigInteger secret ) * Notice the signature of this method : all this method gets are the ShareInfo objects ,", "del_tokens": "subtestBigBig ( SecretShare . getPrimeUsedFor192bitSecretPayload ( ) ) ; subtestBigBig ( SecretShare . getPrimeUsedFor384bitSecretPayload ( ) ) ; public void subtestBigBig ( final BigInteger prime ) final BigInteger secret = new BigInteger ( \"12345678998765432100112233445566778899\" ) ; * Notice the signatures : all this routine gets are the ShareInfo objects ,", "commit_type": "add"}
{"commit_tokens": ["Added", "code", "to", "mostly", "handle", "combo", "boxes", ".", "The", "current", "problem", "shows", "up", "when", "a", "combo", "box", "popup", "has", "a", "scrollbar", ".", "We", "aren", "t", "correctly", "positioning", "the", "popup", "unless", "the", "scroll", "thumb", "is", "at", "the", "top", "."], "add_tokens": "case FOREGROUND_ENABLED : return \"combo_box_arrows\" ; case FOREGROUND_MOUSEOVER : return \"combo_box_arrows\" ; case FOREGROUND_PRESSED : return \"combo_box_arrows\" ; case FOREGROUND_SELECTED : return \"combo_box_arrows\" ;", "del_tokens": "case FOREGROUND_ENABLED : return \"combo_box_arrow_foreground\" ; case FOREGROUND_MOUSEOVER : return \"combo_box_arrow_foreground\" ; case FOREGROUND_PRESSED : return \"combo_box_arrow_foreground\" ; case FOREGROUND_SELECTED : return \"combo_box_arrow_foreground\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "customizeable", "pass", "/", "fail", "comments", "to", "post", "in", "open", "pull", "requests", "."], "add_tokens": "String msgSuccess = GhprbTrigger . DESCRIPTOR . getMsgSuccess ( ) ; String msgFailure = GhprbTrigger . DESCRIPTOR . getMsgFailure ( ) ; if ( build . getResult ( ) == Result . SUCCESS ) { repo . addComment ( pull , msgSuccess + \"\\nRefer to this link for build results: \" + publishedURL + build . getUrl ( ) ) ; } else { repo . addComment ( pull , msgFailure + \"\\nRefer to this link for build results: \" + publishedURL + build . getUrl ( ) ) ; } //repo.addComment(pull, \"Build results will soon be (or already are) available at: \" + publishedURL + build.getUrl());", "del_tokens": "repo . addComment ( pull , \"Build results will soon be (or already are) available at: \" + publishedURL + build . getUrl ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "longer", "name", "than", "_partitioning", "."], "add_tokens": "String name = inputFile . getName ( ) ; Path partition = new Path ( inputDir , \"_partitioning\" + name ) ; URI partitionURI = new URI ( partition . toString ( ) + \"#_partitioning\" + name ) ;", "del_tokens": "Path partition = new Path ( inputDir , \"_partitioning\" ) ; URI partitionURI = new URI ( partition . toString ( ) + \"#_partitioning\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "with", "(", "Charset", ")", "method", "return", "."], "add_tokens": "public Result with ( Charset charset ) { return this ; String v = headers . remove ( name ) ; if ( v == null && getCookie ( name ) != null ) { // It may be a cookie discard ( name ) ; } return this ; } public Result discard ( String name ) {", "del_tokens": "public void with ( Charset charset ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "remaining", "NonParcels", "with", "accompanying", "converters"], "add_tokens": "package org . parceler . converter ; import org . parceler . ParcelConverter ; public abstract void nullSafeToParcel ( T input , Parcel parcel ) ;", "del_tokens": "package org . parceler ; public abstract void nullSafeToParcel ( T input , Parcel parcel ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "only", "firefox", "for", "test", "."], "add_tokens": "return Arrays . asList ( new String [ ] [ ] { { \"firefox\" } } ) ;", "del_tokens": "return Arrays . asList ( new String [ ] [ ] { { \"firefox\" } , { \"chrome\" } } ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "ManyOptionTest", "for", "-", "del", "vs", "--", "del", "(", "-", "del", "is", "equivalent", "to", "-", "d", "-", "e", "-", "l", ")"], "add_tokens": "// -del is the same as -d -e -l (covered in the test below). rsync . exec ( \"-delete-during\" ) ; rsync . exec ( \"-dirs\" ) ; rsync . exec ( \"-links\" ) ; rsync . exec ( \"-rsh\" ) ; rsync . exec ( \"-no-rsh\" ) ;", "del_tokens": "/ * * * We must get this test to pass * / rsync . exec ( \"-del\" ) ; rsync . exec ( \"-delete-during\" ) ; rsync . exec ( \"-dirs\" ) ; rsync . exec ( \"-links\" ) ; rsync . exec ( \"-rsh\" ) ; / * * * Optional . We don 't have to support stringing short options together * as is allowed in posix . Nice to have . Could easily be done after 1.0 . * * We do have to make the above Illegal , however or we 'll never be able * support it without potentially breaking someone . If we make * \"-del\" illegal we can add posix stringing support any time . * / @ Ignore", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "<polygon", ">", "."], "add_tokens": "} else if ( localName . equalsIgnoreCase ( TAG_POLYGON ) ) { polygon ( attributes ) ; / * * Parse the \"points\" attribute . Used by both < polyline > and < polygon > . * / //========================================================================= // <polygon> element private void polygon ( Attributes attributes ) throws SAXException { /**/ Log . d ( TAG , \"<polygon>\" ) ; if ( currentElement == null ) throw new SAXException ( \"Invalid document. Root element must be <svg>\" ) ; SVG . Polygon obj = new SVG . Polygon ( ) ; obj . parent = currentElement ; obj . style = new Style ( obj . parent . style ) ; parseAttributesCore ( obj , attributes ) ; parseAttributesStyle ( obj , attributes ) ; parseAttributesPolyLine ( obj , attributes ) ; // reuse of polyline \"points\" parser currentElement . addChild ( obj ) ; } /**/ Log . d ( TAG , \"parseAttributesStyle\" ) ;", "del_tokens": "/**/ Log . d ( TAG , \"<polyline> n=\" + n ) ; /**/ Log . d ( TAG , \"<polyline> points[\" + j + \"]=\" + obj . points [ j ] ) ; /**/ Log . d ( TAG , \"parseAttributesStyle \" + obj . style ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "pom", ".", "xml", "and", "first", "test", "-", "without", "specific", "asserts", "yet"], "add_tokens": "import java . util . HashMap ; private Map < Class < ? > , Entity > models = new HashMap < > ( ) ;", "del_tokens": "private Map < Class < ? > , Entity > models ;", "commit_type": "fix"}
{"commit_tokens": ["add", "singleton", "(", "Class", ")", "method", "to", "App"], "add_tokens": "} if ( o instanceof Closeable ) {", "del_tokens": "} else if ( o instanceof Closeable ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "in", "the", "ability", "to", "make", "overlay", "in", "xml"], "add_tokens": "/ * * * Default is set to false because that is how it was written * / private static final boolean DEFAULT_OVERLAY_FLAG = false ; private boolean mPanelIsOverlay = DEFAULT_OVERLAY_FLAG ; mPanelIsOverlay = ta . getBoolean ( R . styleable . SlidingUpPanelLayout_overlay , DEFAULT_OVERLAY_FLAG ) ;", "del_tokens": "private boolean mPanelIsOverlay = false ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "pass", "className", "instead", "of", "OClass", "to", "OSecurityHelper"], "add_tokens": "return requireOClass ( oClass . getName ( ) , permissions ) ; } public static RequiredOrientResource [ ] requireOClass ( final String oClassName , final OrientPermission ... permissions ) { return requireResource ( ODatabaseSecurityResources . CLASS + \".\" + oClassName , permissions ) ;", "del_tokens": "return requireResource ( ODatabaseSecurityResources . CLASS + \".\" + oClass . getName ( ) , permissions ) ;", "commit_type": "allow"}
{"commit_tokens": ["remove", "unnecessary", "syntax", "(", "casts", ")"], "add_tokens": "abc [ k ] += ( b [ j + 0 ] & 0xFF ) + ( b [ j + 1 ] << 8 & 0xFF00 ) + ( b [ j + 2 ] << 16 & 0xFF0000 ) + ( b [ j + 3 ] << 24 ) ; abc [ k ] += b [ j ] << n & m ;", "del_tokens": "abc [ k ] += ( ( int ) b [ j + 0 ] & 0xFF ) + ( ( int ) b [ j + 1 ] << 8 & 0xFF00 ) + ( ( int ) b [ j + 2 ] << 16 & 0xFF0000 ) + ( ( int ) b [ j + 3 ] << 24 ) ; abc [ k ] += ( int ) b [ j ] << n & m ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "all", "necessary", "stuff", ".", "Works", "well", ".", "Needs", "tests", "."], "add_tokens": "import android . provider . BaseColumns ; @ DatabaseTable ( tableName = \"accounts\" ) @ DefaultContentUri ( authority = \"com.tojc.ormlite.android.ormlitecontentprovidersample\" , path = \"accounts\" ) @ DefaultContentMimeTypeVnd ( name = \"com.tojc.ormlite.android.ormlitecontentprovidersample.provider\" , type = \"accounts\" ) public class Account { @ DatabaseField ( columnName = BaseColumns . _ID , generatedId = true ) public Account ( ) { public Account ( String name ) { public int getId ( ) { public String getName ( ) {", "del_tokens": "@ DatabaseTable ( tableName = Contract . Account . TABLENAME ) @ DefaultContentUri ( authority = Contract . AUTHORITY , path = Contract . Account . CONTENT_URI_PATH ) @ DefaultContentMimeTypeVnd ( name = Contract . Account . MIMETYPE_NAME , type = Contract . Account . MIMETYPE_TYPE ) public class Account { @ DatabaseField ( columnName = Contract . Account . _ID , generatedId = true ) public Account ( ) { public Account ( String name ) { public int getId ( ) { public String getName ( ) {", "commit_type": "add"}
{"commit_tokens": ["Improve", "exception", "handling", "for", "NiftyClient", "connections"], "add_tokens": "try { if ( future . isSuccess ( ) ) { Channel nettyChannel = future . getChannel ( ) ; T channel = clientChannelConnector . newThriftClientChannel ( nettyChannel , timer ) ; channel . setReceiveTimeout ( receiveTimeout ) ; channel . setSendTimeout ( sendTimeout ) ; set ( channel ) ; } else if ( future . isCancelled ( ) ) { if ( ! cancel ( true ) ) { setException ( new TTransportException ( \"Unable to cancel client channel connection\" ) ) ; } } else { throw future . getCause ( ) ; } catch ( Throwable t ) { setException ( new TTransportException ( \"Failed to connect client channel\" , t ) ) ;", "del_tokens": "if ( future . isSuccess ( ) ) { Channel nettyChannel = future . getChannel ( ) ; T channel = clientChannelConnector . newThriftClientChannel ( nettyChannel , timer ) ; channel . setReceiveTimeout ( receiveTimeout ) ; channel . setSendTimeout ( sendTimeout ) ; set ( channel ) ; else if ( future . isCancelled ( ) ) { cancel ( true ) ; } else { setException ( future . getCause ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "clashing", "method", "names", "when", "exported", "to", "jmx", "."], "add_tokens": "public void busEnvWithDestination ( String name , String value , @ Selector String destination ) { //TODO: document params public void busEnv ( String name , String value ) { //TODO: document params", "del_tokens": "public void env ( String name , String value , @ Selector String destination ) { //TODO: document params public void env ( String name , String value ) { //TODO: document params", "commit_type": "fix"}
{"commit_tokens": ["Made", "global", "initialization", "logic", "more", "accessible", "and", "avoid", "overriding"], "add_tokens": "import com . helger . photon . uicore . icon . DefaultIcons ; public static void registerDefaultResources ( ) public static void onContextInitialized ( ) registerDefaultResources ( ) ; // Set default icon set if none is defined if ( ! DefaultIcons . areDefined ( ) ) EFamFamIcon . setAsDefault ( ) ; public void contextInitialized ( @ Nonnull final ServletContextEvent aSCE ) { onContextInitialized ( ) ; }", "del_tokens": "private static void _registerDefaultResources ( ) public void contextInitialized ( @ Nonnull final ServletContextEvent aSCE ) _registerDefaultResources ( ) ; // Set default icon set EFamFamIcon . setAsDefault ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Make", "celerio", "SVN", "and", "GIT", "aware", "so", "it", "does", "not", "delete", "or", "overwrite", "any", "file", "under", "source", "control", "."], "add_tokens": "import static com . jaxio . celerio . output . FileUtil . getPathRelativeToBase ; private SCMStatus scmStatus = new SCMStatus ( null ) ; scmStatus = fileTracker . getSCMStatus ( new File ( userSource . getDirectory ( ) ) ) ; if ( scmStatus . isUnderSCM ( pathToFile ) ) { log . info ( \"FILE UNDER SCM: {}\" , pathToFile ) ; return true ; }", "del_tokens": "private String getPathRelativeToBase ( File targetFile , String basePath ) { String absoluteBasePath = new File ( basePath ) . getAbsolutePath ( ) ; String absolutePath = targetFile . getAbsolutePath ( ) ; if ( absolutePath . startsWith ( absoluteBasePath ) ) { String result = absolutePath . substring ( absoluteBasePath . length ( ) ) ; if ( result . charAt ( 0 ) == File . separatorChar ) { result = result . substring ( 1 ) ; } return result ; } throw new IllegalStateException ( \"File is not under absoluteBasePath path!: \" + absolutePath + \" absoluteBasePath: \" + absoluteBasePath ) ; }", "commit_type": "make"}
{"commit_tokens": ["Makes", "it", "possible", "to", "identify", "and", "validate", "input", "streams"], "add_tokens": "import org . daisy . streamline . api . media . FileDetails ; * @ throws ValidatorFactoryException if a validator for the specified identifier cannot be created / * * * Creates a new validator instance . * @ param details the details for the file to validate * @ return a validator * @ throws ValidatorFactoryException if a validator for the specified identifier cannot be created * / public Validator newValidator ( FileDetails details ) throws ValidatorFactoryException ; / * * * Returns true if this factory can create a validator for the supplied details . * @ param details the details * @ return true if a validator can be created , false otherwise * / public boolean supportsDetails ( FileDetails details ) ;", "del_tokens": "* @ throws ValidatorFactoryException if a validator for the specified indentifer cannot be created", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "temporary", "option", "csrfTokenRequiredForThrift"], "add_tokens": "securityConfig != null , null ) ;", "del_tokens": "securityConfig != null ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "tests", "for", "named", "parameters"], "add_tokens": "import org . springframework . web . bind . annotation . RequestParam ; import ch . ralscha . extdirectspring . annotation . ExtDirectMethodType ; @ ExtDirectMethod ( value = ExtDirectMethodType . SIMPLE_NAMED , group = \"itest_simple\" ) public String echo ( String userId , @ RequestParam ( defaultValue = \"10\" ) int logLevel ) { return String . format ( \"UserId: %s LogLevel: %d\" , userId , logLevel ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Adding", "comment", "for", "smoothing", "factor", "+", "cleaning", "up", "imports"], "add_tokens": "/ * * * Default smoothing factor . For now fixed to 1E-20 . * /", "del_tokens": "import com . yahoo . labs . samoa . instances . Attribute ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "method", "logic", "for", "getting", "daily", "weather", "and", "soil", "layer", "to", "avoid", "unreasonable", "error", "report", "in", "the", "main", "process", "of", "DOME"], "add_tokens": "if ( data . containsKey ( \"weather\" ) || ! data . containsKey ( \"dailyWeather\" ) ) {", "del_tokens": "if ( data . containsKey ( \"weather\" ) ) {", "commit_type": "update"}
{"commit_tokens": ["use", "listLocatedStatus", "to", "list", "subdirectories"], "add_tokens": "import java . lang . reflect . Method ; public static List < String > listHDFSDirectory ( String directory ) throws IOException { RemoteIterator < LocatedFileStatus > fileStatusListIterator = fileSystem . listLocatedStatus ( new Path ( directory ) ) ;", "del_tokens": "import java . lang . reflect . Method ; public static List < String > listHDFSDirectorty ( String directory ) throws IOException { RemoteIterator < LocatedFileStatus > fileStatusListIterator = fileSystem . listFiles ( new Path ( directory ) , false ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "username", "and", "password", "validation", "in", "PactGitLoader"], "add_tokens": "if ( isSet ( this . pactGit . username ( ) ) && isSet ( this . pactGit . password ( ) ) ) {", "del_tokens": "if ( isSet ( this . pactGit . username ( ) ) && isSet ( this . pactGit . passphrase ( ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "support", "MS", "Project", "compatible", "MSPDI", "output", "in", "non", "-", "GMT", "timezones", "."], "add_tokens": "int find = m_find [ m_match ] [ m_index ] ; if ( ( m_match > 0 && find == '?' ) || b == find ) \".000+??:??\" . getBytes ( ) ,", "del_tokens": "if ( b == ( int ) m_find [ m_match ] [ m_index ] ) \".000+00:00\" . getBytes ( ) ,", "commit_type": "update"}
{"commit_tokens": ["Fix", "the", "obr", "resolver", "for", "JDBC"], "add_tokens": "strClassName = Utility . getFullClassName ( strClassName ) ; Utility . getLogger ( ) . warning ( \"Error on create class: \" + strClassName ) ; e . printStackTrace ( ) ;", "del_tokens": "// m_datasourceFactory = (DatasourceFactory)Utility.makeObjectFromClassName(Object.class.getName(), strClassName); strClassName = Utility . getFullClassName ( strClassName ) ; Utility . getLogger ( ) . warning ( \"Error on create class: \" + strClassName ) ; e . printStackTrace ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "Javadoc", "and", "Lint", "."], "add_tokens": "* Get whether this drawable is using an intrinsic padding . The default is true . * @ return Whether this drawable is using an intrinsic padding . * Set whether this drawable should use an intrinsic padding . The default is true . * * @ param useIntrinsicPadding Whether this drawable should use its intrinsic padding .", "del_tokens": "* Get whether this { @ code Drawable } is using an intrinsic padding . The default is true . * @ return Whether this { @ code Drawable } is using an intrinsic padding . * Set whether this { @ code Drawable } should use an intrinsic padding . The default is true .", "commit_type": "fix"}
{"commit_tokens": ["Allow", "Timecode", "resampling", "to", "round", "up", "to", "the", "next", "second"], "add_tokens": "if ( resampled < toRate . getSamplesPerSecond ( ) ) { return new Timecode ( negative , days , hours , minutes , seconds , resampled , toRate , dropFrame ) ; } else { return new Timecode ( negative , days , hours , minutes , seconds , 0 , toRate , dropFrame ) . add ( new SampleCount ( resampled , toRate ) ) ; } if ( back . getSampleCount ( ) . getSamples ( ) != this . getSampleCount ( ) . getSamples ( ) )", "del_tokens": "return new Timecode ( negative , days , hours , minutes , seconds , resampled , toRate , dropFrame ) ; if ( back . getFramesPart ( ) != this . getFramesPart ( ) )", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "for", "multiple", "channels", "In", "MediaSearcher", "client"], "add_tokens": "public void search ( String message , String channel ) { try { publisherJedis . publish ( channel , message ) ; } catch ( Exception e ) { logger . error ( e ) ; } } public void delete ( String message , String channel ) { try { publisherJedis . publish ( channel , message ) ; } catch ( Exception e ) { logger . error ( e ) ; } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "cache", "access", "in", "method", "scoring", "related", "to", "initializer", "expressions"], "add_tokens": "scores . add ( scoreMethod ( funcType , Collections . < IInvocableType > emptyList ( ) , argTypes , inferringTypes , funcTypes . size ( ) == 1 , true ) ) ; public MethodScore scoreMethod ( IInvocableType funcType , List < ? extends IInvocableType > listFunctionTypes , List < IType > argTypes , List < IType > inferringTypes , boolean bSkipScoring , boolean bLookInCache ) { IInvocableType cachedFuncType = bLookInCache ? getCachedMethodScore ( funcType , argTypes ) : null ; @ Override public String toString ( ) { String ret = \"_methodName \" + _methodName + \"\\n\" + \"_enclosingType \" + _enclosingType . getName ( ) + \"\\n\" + \"_argTypes \" ; for ( IType a : _argTypes ) { ret += \" \" + a . getName ( ) + \"\\n\" ; } return ret ; }", "del_tokens": "scores . add ( scoreMethod ( funcType , Collections . < IInvocableType > emptyList ( ) , argTypes , inferringTypes , funcTypes . size ( ) == 1 ) ) ; public MethodScore scoreMethod ( IInvocableType funcType , List < ? extends IInvocableType > listFunctionTypes , List < IType > argTypes , List < IType > inferringTypes , boolean bSkipScoring ) { IInvocableType cachedFuncType = getCachedMethodScore ( funcType , argTypes ) ; score . setBest ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "userId", "to", "Long", "to", "accommodate", "values", "larger", "than", "Integer", ".", "MAX_INT", "."], "add_tokens": "private Long userId ; public Long getUserId ( ) { public void setUserId ( Long userId ) {", "del_tokens": "private Integer userId ; public Integer getUserId ( ) { public void setUserId ( Integer userId ) {", "commit_type": "change"}
{"commit_tokens": ["Moved", "composite", "back", "as", "an", "operation", "on", "image"], "add_tokens": "import thirdparty . jhlabs . composite . SubtractComposite ; import java . awt . image . BufferedImage ;", "del_tokens": "import java . awt . image . * ; import thirdparty . jhlabs . composite . * ; * @ param radius the radius of the blur in pixels . * @ min - value 0 * @ max - value 100 + * @ see # getRadius * @ see # setRadius * @ param radius the radius of the blur in pixels . * @ min - value 0 * @ max - value 100 + * @ see # getRadius * @ see # setRadius", "commit_type": "move"}
{"commit_tokens": ["Add", "some", "additional", "debug", "logging", "to", "the", "event", "bus", "."], "add_tokens": "import com . groupon . mesos . util . EventBusExceptionHandler ; this . eventBus = new AsyncEventBus ( eventBusExecutor , new EventBusExceptionHandler ( \"executor-bus\" ) ) ;", "del_tokens": "this . eventBus = new AsyncEventBus ( \"mesos-executor\" , eventBusExecutor ) ;", "commit_type": "add"}
{"commit_tokens": ["CHanged", "MySQL", "to", "use", "DATETIME", "instead", "of", "TIMESTAMP", "."], "add_tokens": "@ Override protected void appendDateType ( StringBuilder sb ) { / * * * TIMESTAMP in MySQL does some funky stuff with the last - modification time . Values are 'not null' by default * with an automatic default of CURRENT_TIMESTAMP . Strange design decision . * / sb . append ( \"DATETIME\" ) ; }", "del_tokens": "import com . j256 . ormlite . field . JdbcType ; @ Override protected void appendCanBeNull ( StringBuilder sb , FieldType fieldType ) { if ( fieldType . getJdbcType ( ) == JdbcType . JAVA_DATE ) { / * * * For some reason with MySQL , timestamp values are 'not null' by default with an automatic default of * CURRENT_TIMESTAMP . Strange design decision . So if the field can be null we must force it to be . * / sb . append ( \"NULL \" ) ; } }", "commit_type": "change"}
{"commit_tokens": ["add", "method", "to", "calculate", "the", "cardinality", "of", "the", "union", "of", "two", "bitmaps", "without", "having", "to", "create", "a", "third", "bitmap", "representing", "the", "union"], "add_tokens": "Iterable < Integer > , BitmapStorage { or ( a , container ) ; return container ; } public int orCardinality ( final EWAHCompressedBitmap a ) { final BitCounter counter = new BitCounter ( ) ; or ( a , counter ) ; return counter . getCount ( ) ; } private void or ( final EWAHCompressedBitmap a , final BitmapStorage container ) { container . setSizeInBits ( sizeInBits ( ) ) ; return ; container . setSizeInBits ( Math . max ( sizeInBits ( ) , a . sizeInBits ( ) ) ) ; final EWAHIterator iterator , final BitmapStorage container ) { public long addStreamOfDirtyWords ( final long [ ] data , final long start , public void setSizeInBits ( final int size ) { this . sizeinbits = size ; }", "del_tokens": "Iterable < Integer > { container . sizeinbits = sizeInBits ( ) ; return container ; container . sizeinbits = Math . max ( sizeInBits ( ) , a . sizeInBits ( ) ) ; return container ; final EWAHIterator iterator , final EWAHCompressedBitmap container ) { private long addStreamOfDirtyWords ( final long [ ] data , final long start ,", "commit_type": "add"}
{"commit_tokens": ["changed", "GAEHttpSender", "class", ":", "the", "change", "allows", "users", "to", "specify", "GAE", "s", "queue", "name"], "add_tokens": "HttpSender sender = new HttpSender ( props , host , port , apiKey ) ;", "del_tokens": "HttpSender sender = new HttpSender ( host , port , apiKey ) ;", "commit_type": "change"}
{"commit_tokens": ["use", "AppCompatActivity", "instead", "of", "Activity"], "add_tokens": "import android . support . v7 . app . AppCompatActivity ; public class DemoActivity extends AppCompatActivity implements AuthenticationCallback {", "del_tokens": "import android . app . Activity ; public class DemoActivity extends Activity implements AuthenticationCallback {", "commit_type": "use"}
{"commit_tokens": ["Fix", "checkstyle", "error", "that", "one", "line", "exceeds", "the", "width", "."], "add_tokens": "* This is not the same as { @ link Serializer } . This interface is only used to convert the intermediate value * into String or vice - versa to be used for { @ link Storage }", "del_tokens": "* This is not the same as { @ link Serializer } . This interface is only used to convert the intermediate value into String , * or vice - versa to be used for { @ link Storage }", "commit_type": "fix"}
{"commit_tokens": ["Add", "constants", "for", "return", "values", "of", "listening", "methods"], "add_tokens": "* which takes a < tt > BiFunction < / tt > returning a boolean as argument . Implementations of * such listening methods should use the defined constants { @ link # CONTINUE } and * { @ link # ABORT } as return values . / * * * Return value for listening methods indicating to continue event delegation with * next listener . * @ since 1.1 . 0 * / public final static boolean CONTINUE = true ; / * * * Return value for listening methods indicating to abort event delegation . * @ since 1.1 . 0 * / public final static boolean ABORT = false ;", "del_tokens": "* which takes a < tt > BiFunction < / tt > returning a boolean as argument .", "commit_type": "add"}
{"commit_tokens": ["Added", "function", "reset", "to", "draft", "so", "draft", "objects", "can", "be", "reused", "."], "add_tokens": "private void releaseAndInitialize ( ) String path ; String part1 = uri . getPath ( ) ; String part2 = uri . getQuery ( ) ; if ( part1 != null ) path = part1 ; else path = \"/\" ; if ( part2 != null ) path += \"?\" + part2 ;", "del_tokens": "public void releaseAndInitialize ( ) String path = uri . getPath ( ) ; if ( path . indexOf ( \"/\" ) != 0 ) { path = \"/\" + path ; } //String origin = \"x\"; // TODO: Make 'origin' configurable", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "configure", "DDL", "config", "file"], "add_tokens": "private void copyDdlConfigurationFile ( ) throws MojoExecutionException , IOException { if ( StringUtils . isBlank ( ddlConfigurationFile ) ) { copyDefaultDdlConfigurationFile ( ) ; } else { try { // copy configuration file to well-known emodb DDL config directory and filename \"config-ddl.yaml\" FileUtils . copyFile ( new File ( ddlConfigurationFile ) , new File ( emoConfigurationDirectory ( ) , \"config-ddl.yaml\" ) ) ; } catch ( Exception e ) { throw new MojoExecutionException ( \"failed to copy configuration file from \" + ddlConfigurationFile , e ) ; } } } private void copyDefaultDdlConfigurationFile ( ) throws MojoExecutionException , IOException { throw new MojoExecutionException ( \"could not find the ddl configuration file\" ) ;", "del_tokens": "private void copyDdlConfigurationFile ( ) throws MojoFailureException , IOException { throw new MojoFailureException ( \"could not find the ddl configuration file\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "mediaDAO", "getIndexedNotClustered", "method"], "add_tokens": "return getDatastore ( ) . find ( clazz ) . disableValidation ( ) . filter ( \"annotations.className in\" , LocalDescriptors . class . getName ( ) ) .", "del_tokens": "return getDatastore ( ) . find ( clazz ) . disableValidation ( ) . filter ( \"annotations.className nin\" , LocalDescriptors . class . getName ( ) ) .", "commit_type": "fix"}
{"commit_tokens": ["Allow", "numeric", "default", "values", "for", "enum", "fields", "in", "structs"], "add_tokens": "buildMethodBuilder . beginControlFlow ( \"if (this.$N == null)\" , fieldName ) ;", "del_tokens": "buildMethodBuilder . beginControlFlow ( \"if (this.$N == null)\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "JavaDoc", "for", "compilation", "with", "Java", "11"], "add_tokens": "* List & lt ; String & gt ; list = new ObjectAccessorList & lt ; & gt ; ( originalList , MyObject :: getStringProperty ( ) ) ;", "del_tokens": "* List & lt ; String > list = new ObjectAccessorList & lt ; > ( originalList , MyObject :: getStringProperty ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "the", "missing", "generics", "checks", ":", "Formal", "type", "parameter", "added", "/", "changed", "/", "removed", "and", "super", "type", "type", "parameters", "changed", "."], "add_tokens": "CLASS_SUPER_TYPE_TYPE_PARAMETERS_CHANGED ( \"java.class.superTypeTypeParametersChanged\" , POTENTIALLY_BREAKING , NON_BREAKING , POTENTIALLY_BREAKING ) , METHOD_PARAMETER_TYPE_CHANGED ( \"java.method.parameterTypeChanged\" , POTENTIALLY_BREAKING , BREAKING , null ) , GENERICS_ELEMENT_NOW_PARAMETERIZED ( \"java.generics.elementNowParameterized\" , NON_BREAKING , NON_BREAKING , POTENTIALLY_BREAKING ) , GENERICS_FORMAL_TYPE_PARAMETER_ADDED ( \"java.generics.formalTypeParameterAdded\" , BREAKING , NON_BREAKING , null ) , GENERICS_FORMAL_TYPE_PARAMETER_REMOVED ( \"java.generics.formalTypeParameterRemoved\" , BREAKING , NON_BREAKING , null ) , GENERICS_FORMAL_TYPE_PARAMETER_CHANGED ( \"java.generics.formalTypeParameterChanged\" , BREAKING , NON_BREAKING , null ) ;", "del_tokens": "METHOD_PARAMETER_TYPE_CHANGED ( \"java.method.parameterTypeChanged\" , POTENTIALLY_BREAKING , BREAKING , null ) ;", "commit_type": "implement"}
{"commit_tokens": ["fix", "typo", "in", "Tutorial", "mode", "constant", "name"], "add_tokens": "public static boolean TUTORIAL_MODE = false ;", "del_tokens": "public static boolean TUTORIAL_MODEx = false ;", "commit_type": "fix"}
{"commit_tokens": ["implement", "case", "sensitive", "pattern", "rules"], "add_tokens": "private boolean caseSensitive = false ; public boolean getCaseSensitive ( ) { return caseSensitive ; } public void setCaseSensitive ( boolean caseSensitive ) { this . caseSensitive = caseSensitive ; } StringElement stringElement = new StringElement ( tokenParts , caseSensitive ) ;", "del_tokens": "StringElement stringElement = new StringElement ( tokenParts , false ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "and", "fix", "AttrsDecorator", "tests", "+", "using", "robolectric", "for", "it"], "add_tokens": "DecorValue decorValue ; decorValue = new DecorValue ( values , attributeIndexes ) ; apply ( ( T ) view , decorValue ) ;", "del_tokens": "apply ( ( T ) view , new DecorValue ( values , attributeIndexes ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "observable", "listeners", "to", "Ellipse", "and", "Shape", "layers"], "add_tokens": "observable . setValue ( new Path ( ) ) ; MiscUtils . getPathFromData ( initialShape , observable . getValue ( ) ) ;", "del_tokens": "private final Path path = new Path ( ) ; observable . setValue ( new Path ( ) ) ; MiscUtils . getPathFromData ( initialShape , observable . getValue ( ) ) ; observable . setValue ( getInitialShape ( ) ) ; observable . setValue ( getInitialShape ( ) ) ; private Path getInitialShape ( ) { MiscUtils . getPathFromData ( initialShape , path ) ; return path ; }", "commit_type": "add"}
{"commit_tokens": ["update", "javadoc", "and", "gradle", "files"], "add_tokens": "* This is the persistent state that is saved by FragmentSwitcher .", "del_tokens": "* This is the persistent state that is saved by ViewPager . Only needed * if you are creating a sublass of ViewPager that must save its own * state , in which case it should implement a subclass of this which * contains that state .", "commit_type": "update"}
{"commit_tokens": ["Update", "CommandLinePluginDescriptor", "interface", "contract", "tighten", "type", "bounds", "update", "javadoc", "."], "add_tokens": "pkg -> classFinder . find ( pkg , pluginDescriptor . getPluginBaseClass ( ) ) ) ; if ( pluginDescriptor . includePluginClass ( c ) ) { final Object plugin = pluginDescriptor . createInstanceForPlugin ( c ) ; pluginDescriptors . entrySet ( ) . forEach ( e -> e . getValue ( ) . validateAndResolvePlugins ( ) ) ; final Set < String > allowedValues = descriptor . getAllowedValuesForDescriptorHelp ( argDef . getLongName ( ) ) ;", "del_tokens": "pkg -> classFinder . find ( pkg , pluginDescriptor . getPluginClass ( ) ) ) ; if ( pluginDescriptor . getClassFilter ( ) . test ( c ) ) { final Object plugin = pluginDescriptor . getInstance ( c ) ; pluginDescriptors . entrySet ( ) . forEach ( e -> e . getValue ( ) . validateArguments ( ) ) ; final Set < String > allowedValues = descriptor . getAllowedValuesForDescriptorArgument ( argDef . getLongName ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "MockitoAnnotations", ".", "initMocks", "instead", "of", "MockitoRule", "for"], "add_tokens": "import org . mockito . MockitoAnnotations ; MockitoAnnotations . initMocks ( this ) ;", "del_tokens": "import org . junit . Rule ; import org . mockito . junit . MockitoJUnit ; import org . mockito . junit . MockitoRule ; @ Rule public MockitoRule mocks = MockitoJUnit . rule ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "we", "send", "the", "correct", "announce", "events"], "add_tokens": "boolean inhibitEvents ) throws AnnounceException { logger . info ( \"Announcing{} to tracker with {}U/{}D/{}L bytes...\" , new Object [ ] { this . formatAnnounceEvent ( event ) , this . torrent . getUploaded ( ) , this . torrent . getDownloaded ( ) , this . torrent . getLeft ( ) } ) ; throw new AnnounceException ( \"Invalid announce URL (\" + mue . getMessage ( ) + \")\" , mue ) ; throw new AnnounceException ( \"Tracker message violates expected \" + \"protocol (\" + mve . getMessage ( ) + \")\" , mve ) ; throw new AnnounceException ( ioe . getMessage ( ) , ioe ) ;", "del_tokens": "boolean inhibitEvents ) { logger . debug ( \"Announcing \" + ( ! AnnounceRequestMessage . RequestEvent . NONE . equals ( event ) ? event . name ( ) + \" \" : \"\" ) + \"to tracker with \" + this . torrent . getUploaded ( ) + \"U/\" + this . torrent . getDownloaded ( ) + \"D/\" + this . torrent . getLeft ( ) + \"L bytes...\" ) ; logger . error ( \"Invalid tracker announce URL: {}!\" , mue . getMessage ( ) , mue ) ; logger . error ( \"Tracker message violates expected protocol: {}!\" , mve . getMessage ( ) , mve ) ; logger . error ( \"Error reading from tracker: {}!\" , ioe . getMessage ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["make", "DTClass", "be", "aware", "of", "it", "s", "superclass"], "add_tokens": "private DTClass superClass ; public DTClass getSuperClass ( ) { return superClass ; } public void setSuperClass ( DTClass superClass ) { this . superClass = superClass ; } public boolean instanceOf ( String dtName ) { DTClass s = this ; while ( s != null ) { if ( s . getDtName ( ) . equals ( dtName ) ) { return true ; } s = s . superClass ; } return false ; }", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["updated", "readme", "+", "fixed", "typo"], "add_tokens": "response . setHeader ( \"Content-Disposition\" , \"attachment; filename=\" + request . getContextPath ( ) . replaceAll ( \"/\" , \"\" ) + \"-jcache-statistics-\" + new SimpleDateFormat ( \"yyyy-MM-dd-HHmmss\" ) . format ( new Date ( ) ) + \".csv\" ) ;", "del_tokens": "response . setHeader ( \"Content-Disposition\" , \"attachment; filename=\" + request . getContextPath ( ) . replaceAll ( \"/\" , \"\" ) + \"-jcache-statistcs-\" + new SimpleDateFormat ( \"yyyy-MM-dd-HHmmss\" ) . format ( new Date ( ) ) + \".csv\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "version", "and", "os", "to", "user", "-", "agent", "string"], "add_tokens": "String path = new URIBuilder ( ) . setPath ( \"current_user\" ) . addParameter ( \"include\" , \"pledges\" ) . toString ( ) ; getDataStream ( path ) , String prefix = \"https://www.patreon.com/api/oauth2/api/\" ; HttpURLConnection connection = ( HttpURLConnection ) url . openConnection ( ) ; connection . setRequestProperty ( \"User-Agent\" , String . format ( \"Patreon-Java, version %s, platform %s %s\" , getVersion ( ) , System . getProperty ( \"os.name\" ) , System . getProperty ( \"os.version\" ) ) ) ; private String getVersion ( ) throws IOException { InputStream resourceAsStream = this . getClass ( ) . getResourceAsStream ( \"/version.properties\" ) ; java . util . Properties prop = new java . util . Properties ( ) ; prop . load ( resourceAsStream ) ; return prop . getProperty ( \"version\" ) ; }", "del_tokens": "getDataStream ( \"current_user\" ) , String prefix = \"https://api.patreon.com/oauth2/api/\" ; HttpURLConnection connection = ( HttpURLConnection ) url . openConnection ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "mutex", "for", "mixed", "scalar", "/", "collection", "arguments", "."], "add_tokens": "if ( c . isEmpty ( ) && mutextArgumentNames . length ( ) == 0 ) { throw new CommandLineException . MissingArgument ( fullName , getOneOfMutexRequiredErrorMessage ( argumentDefinition ) ) ; throw new CommandLineException . MissingArgument ( fullName , getOneOfMutexRequiredErrorMessage ( argumentDefinition ) ) ; // Error message for when mutex args are mutually required (meaning one of them must be specified) but none was private String getOneOfMutexRequiredErrorMessage ( ArgumentDefinition argumentDefinition ) { return \"Argument '\" + argumentDefinition . getLongName ( ) + \"' is required\" + ( argumentDefinition . mutuallyExclusive . isEmpty ( ) ? \".\" : \" unless any of \" + argumentDefinition . mutuallyExclusive ) + \" are specified.\" ; }", "del_tokens": "if ( c . isEmpty ( ) ) { throw new CommandLineException . MissingArgument ( fullName , \"Argument '\" + fullName + \"' must be specified at least once.\" ) ; throw new CommandLineException . MissingArgument ( fullName , \"Argument '\" + fullName + \"' is required\" + ( argumentDefinition . mutuallyExclusive . isEmpty ( ) ? \".\" : \" unless any of \" + argumentDefinition . mutuallyExclusive + \" are specified.\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "local", "copy", "of", "NamesFilter", "names", ";", "modifying", "caller", "s", "List", "is", "buggy"], "add_tokens": "private List < String > names_ ; names_ = new ArrayList < String > ( names ) ; names_ . remove ( column . name ( ) ) ; else if ( values . length == 2 && DatabaseDescriptor . getColumnType ( cfName ) . equals ( \"Super\" ) ) SuperColumn filteredSuperColumn = new SuperColumn ( superColumn . name ( ) ) ; filteredCf . addColumn ( filteredSuperColumn ) ; names_ . remove ( subColumn . name ( ) ) ; else { names_ . remove ( columnName ) ;", "del_tokens": "private List < String > names_ = new ArrayList < String > ( ) ; names_ = names ; names_ . remove ( column . name ( ) ) ; else if ( values . length == 2 && DatabaseDescriptor . getColumnType ( cfName ) . equals ( \"Super\" ) ) SuperColumn filteredSuperColumn = new SuperColumn ( superColumn . name ( ) ) ; filteredCf . addColumn ( filteredSuperColumn ) ; names_ . remove ( subColumn . name ( ) ) ; else { names_ . remove ( columnName ) ;", "commit_type": "make"}
{"commit_tokens": ["Move", "headers", "to", "top", "of", "object"], "add_tokens": "@ JsonPropertyOrder ( { \"headers\" , \"query\" , \"totalItems\" , \"aggs\" , \"bbox\" , \"items\" } )", "del_tokens": "@ JsonPropertyOrder ( { \"query\" , \"totalItems\" , \"aggs\" , \"bbox\" , \"items\" } )", "commit_type": "move"}
{"commit_tokens": ["Use", "new", "Rendering", "Test", "Framework"], "add_tokens": "import org . junit . runner . RunWith ; import org . xwiki . rendering . test . integration . RenderingTestSuite ; * Run all tests found in { @ code * . test } files located in the classpath . These { @ code * . test } files must follow the * conventions described in { @ link org . xwiki . rendering . test . integration . TestDataParser } . * * @ since 3.0 RC1 @ RunWith ( RenderingTestSuite . class ) public class IntegrationTests", "del_tokens": "import junit . framework . Test ; import junit . framework . TestCase ; import org . xwiki . rendering . scaffolding . RenderingTestSuite ; import org . xwiki . test . ComponentManagerTestSetup ; * All Rendering integration tests defined in text files using a special format . * * @ since 1.8 M1 public class RenderingTests extends TestCase public static Test suite ( ) throws Exception { RenderingTestSuite suite = new RenderingTestSuite ( \"Test XWiki1.0 -> XWiki2.0 conversion\" ) ; return new ComponentManagerTestSetup ( suite ) ; }", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "comment", "updated", "formatting", "and", "fixed", "the", "dependencies", "for", "one", "renderer", "."], "add_tokens": "* Gets the GraphVisitor instances from Furnace and provides a sorted copy of that list . @ Inject private Imported < GraphVisitor > visitors ; * Returns a sorted copy of GraphVisitor instances list from Forge . List < GraphVisitor > chain = Lists . newArrayList ( this . visitors ) ; public void disposeVisitors ( List < GraphVisitor > visitorsToDispose ) { for ( GraphVisitor v : visitorsToDispose ) {", "del_tokens": "* Gets the GraphVisitor instances from Forge and provides a sorted copy of that list . //@Inject private WindupContext context; @ Inject private Imported < GraphVisitor > visitors ; * Returns a sorted copy of GraphVisitor instances list from Forge . List < GraphVisitor > chain = Lists . newArrayList ( this . visitors ) ; public void disposeVisitors ( List < GraphVisitor > visitorsToDispose ) { for ( GraphVisitor v : visitorsToDispose ) {", "commit_type": "update"}
{"commit_tokens": ["Allow", "to", "extract", "Data", "to", "types", "and", "back", ".", "Utilizing", "Jackson", "s", "serialization", "/", "deserialization"], "add_tokens": "public static Value createValue ( JsonNode node ) { public static Optional < Value > createOptionalValue ( JsonNode value ) {", "del_tokens": "static Value createValue ( JsonNode node ) { static Optional < Value > createOptionalValue ( JsonNode value ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "a", "way", "to", "set", "the", "-", "progress", "flag", "."], "add_tokens": "URI progress ; this . pass_prefix = checkNotNull ( prefix ) ; public FFmpegBuilder addProgress ( URI uri ) { this . progress = checkNotNull ( uri ) ; return this ; } if ( progress != null ) { args . add ( \"-progress\" ) . add ( progress . toString ( ) ) ; }", "del_tokens": "this . pass_prefix = prefix ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "final", "from", "methods", "because", "class", "is", "final"], "add_tokens": "public void searchAllDocuments ( @ Nonnull final Query aQuery , @ Nonnull final Consumer < StoredDocument > aConsumer ) throws IOException * public List < StoredDocument > getAllDocuments ( @ Nonnull final Query aQuery ) throws IOException public List < StoredDocument > getAllDeletedDocuments ( ) throws IOException public List < StoredDocument > getAllDocumentsOfParticipant ( @ Nonnull final IPeppolParticipantIdentifier aParticipantID ) throws IOException public List < StoredDocument > getAllDocumentsOfCountryCode ( @ Nonnull final String sCountryCode ) throws IOException", "del_tokens": "public final void searchAllDocuments ( @ Nonnull final Query aQuery , @ Nonnull final Consumer < StoredDocument > aConsumer ) throws IOException * public final List < StoredDocument > getAllDocuments ( @ Nonnull final Query aQuery ) throws IOException public final List < StoredDocument > getAllDeletedDocuments ( ) throws IOException public final List < StoredDocument > getAllDocumentsOfParticipant ( @ Nonnull final IPeppolParticipantIdentifier aParticipantID ) throws IOException public final List < StoredDocument > getAllDocumentsOfCountryCode ( @ Nonnull final String sCountryCode ) throws IOException", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "sonar", "branch", "parameter"], "add_tokens": "import org . apache . commons . lang3 . StringUtils ; @ Parameter ( property = \"sonar.branch\" , defaultValue = \"\" ) protected String sonarBranch ; @ Override if ( StringUtils . isEmpty ( sonarKey ) ) { if ( ! StringUtils . isEmpty ( sonarBranch ) ) { sonarKey = String . format ( \"%s:%s\" , sonarKey , sonarBranch ) ; }", "del_tokens": "if ( sonarKey == null || sonarKey . equals ( \"\" ) ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "provisioning", "strategy", "to", "exclude", "delay", "."], "add_tokens": "import hudson . model . Label ; import javax . annotation . Nonnull ; @ Nonnull public static synchronized List < DockerCloud > getDockerClouds ( ) { public static DockerCloud anyCloudForLabel ( Label label ) { return getDockerClouds ( ) . stream ( ) . filter ( cloud -> cloud . canProvision ( label ) ) . findFirst ( ) . orElse ( null ) ; } public static DockerCloud firstDockerCloudByName ( final String serverName ) { return Iterables . find ( getDockerClouds ( ) , input -> serverName . equals ( input . getDisplayName ( ) ) ) ;", "del_tokens": "import java . util . Collection ; public static synchronized Collection < DockerCloud > getServers ( ) { public DockerCloud getServer ( final String serverName ) { return Iterables . find ( getServers ( ) , input -> serverName . equals ( input . getDisplayName ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "case", "to", "match", "Chrome", "expectations"], "add_tokens": "assertThat ( input . getAttribute ( \"value\" ) , equalTo ( \"C:\\\\fakepath\\\\example.txt\" ) ) ;", "del_tokens": "assertThat ( input . getAttribute ( \"value\" ) , equalTo ( \"example.txt\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "for", "class", "not", "yet", "loaded", "when", "rewriting", "invokedynamic"], "add_tokens": "int classId = typeRegistry . getTypeIdFor ( slashedclassname , true ) ; throw new IllegalStateException ( \"Unable to find classId for \" + slashedclassname + \" referenced from invokedynamic in \" + this . methodname + \"()\" ) ;", "del_tokens": "int classId = typeRegistry . getTypeIdFor ( slashedclassname , false ) ; throw new IllegalStateException ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Adding", "extra", "Replace", "Result", "template", "for", "backward", "compatibility"], "add_tokens": "/ * * * A template string for creating ReplaceResult messages . * * Similar to { @ link # replaceResultMessage } , except has support for messageIdentifier * * Use like : * < pre > * String . format ( * ReplaceResultMessageTemplate , * messageId , * sourcedId , * resultScore , * resultDataXml * ) * < / pre > * * * / public static final String ReplaceResultMessageTemplate = / * * * @ deprecated use { @ link # ReplaceResultMessageTemplate } instead . * / @ Deprecated public static final String replaceResultMessage = \"<?xml version = \\\"1.0\\\" encoding = \\\"UTF-8\\\"?>\" + \"<imsx_POXEnvelopeRequest xmlns=\\\"http://www.imsglobal.org/services/ltiv1p1/xsd/imsoms_v1p0\\\">\" + \" <imsx_POXHeader>\" + \" <imsx_POXRequestHeaderInfo>\" + \" <imsx_version>V1.0</imsx_version>\" + \" </imsx_POXRequestHeaderInfo>\" + \" </imsx_POXHeader>\" + \" <imsx_POXBody>\" + \" <replaceResultRequest>\" + \" <resultRecord>\" + \" <sourcedGUID>\" + \" <sourcedId>%s</sourcedId>\" + \" </sourcedGUID>\" + \" <result>\" + \" <resultScore>\" + \" <language>en</language>\" + \" <textString>%s</textString>\" + \" </resultScore>\" + \" %s\" + \" </result>\" + \" </resultRecord>\" + \" </replaceResultRequest>\" + \" </imsx_POXBody>\" + \"</imsx_POXEnvelopeRequest>\" ; String xml = String . format ( ReplaceResultMessageTemplate ,", "del_tokens": "public static final String replaceResultMessage = String xml = String . format ( replaceResultMessage ,", "commit_type": "add"}
{"commit_tokens": ["Added", "basic", "main", ".", "Added", "optional", "explicit", "XSD", "validation", "option"], "add_tokens": "import javax . xml . XMLConstants ; import javax . xml . validation . SchemaFactory ; import java . io . File ; DocumentBuilderFactory factory = DocumentBuilderFactory . newInstance ( ) ; String xsdFilename = System . getProperty ( \"sbe.validate.xsd\" ) ; if ( xsdFilename != null ) { SchemaFactory schemaFactory = SchemaFactory . newInstance ( XMLConstants . W3C_XML_SCHEMA_NS_URI ) ; factory . setSchema ( schemaFactory . newSchema ( new File ( xsdFilename ) ) ) ; } Document document = factory . newDocumentBuilder ( ) . parse ( in ) ;", "del_tokens": "Document document = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) . parse ( in ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", ":", "Executors", "constructor", "to", "CachedFieldImpl", "."], "add_tokens": "import javax . annotation . Nullable ; import java . util . concurrent . Executor ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; this ( sessionProvider , valueGetter , successHandler , errorHandler , Executors . newCachedThreadPool ( ) , null ) ; } public CachedFieldImpl ( @ Nonnull Provider < String > sessionProvider , @ Nonnull Provider < RETURN_TYPE > valueGetter , @ Nonnull SuccessListener < RETURN_TYPE > successHandler , @ Nonnull ErrorListener errorHandler , @ Nonnull ExecutorService valueGetterExecutor , @ Nullable Executor stateListenerExecutor ) { valueGetterWithArg , success , error , valueGetterExecutor , stateListenerExecutor ) ;", "del_tokens": "valueGetterWithArg , success , error ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "Proxy", "Port", "to", "integer"], "add_tokens": "public void setProxy ( String host , int port , String username , String password ) { httpClient . setProxy ( host , port , username , password ) ;", "del_tokens": "public void setProxy ( String host , String port , String username , String password ) { httpClient . setProxy ( host , Integer . parseInt ( port ) , username , password ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "configurer", "for", "the", "SSO", "filter"], "add_tokens": "import org . springframework . security . config . annotation . SecurityConfigurerAdapter ; import org . springframework . security . web . DefaultSecurityFilterChain ; import org . springframework . security . web . authentication . session . SessionAuthenticationStrategy ; public static final class OAuth2ClientAuthenticationConfigurer extends SecurityConfigurerAdapter < DefaultSecurityFilterChain , HttpSecurity > { private OAuth2ClientAuthenticationProcessingFilter filter ; public OAuth2ClientAuthenticationConfigurer ( OAuth2ClientAuthenticationProcessingFilter filter ) { this . filter = filter ; } @ Override public void configure ( HttpSecurity builder ) throws Exception { OAuth2ClientAuthenticationProcessingFilter ssoFilter = filter ; ssoFilter . setSessionAuthenticationStrategy ( builder . getSharedObject ( SessionAuthenticationStrategy . class ) ) ; builder . addFilterAfter ( ssoFilter , AbstractPreAuthenticatedProcessingFilter . class ) ; } } // To get access to the shared state in HttpSecurity you need to register a // callback: http . apply ( new OAuth2ClientAuthenticationConfigurer ( oauth2SsoFilter ( ) ) ) ; if ( configurers . isEmpty ( ) ) { protected OAuth2ClientAuthenticationProcessingFilter oauth2SsoFilter ( ) {", "del_tokens": "http . addFilterAfter ( cloudfoundrySsoFilter ( ) , AbstractPreAuthenticatedProcessingFilter . class ) ; if ( configurers . isEmpty ( ) ) { protected OAuth2ClientAuthenticationProcessingFilter cloudfoundrySsoFilter ( ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "wiring", "of", "modules", "and", "make", "tests", "more", "explicit"], "add_tokens": "import org . robotninjas . barge . state . RaftStateContext ; expose ( RaftStateContext . class ) ;", "del_tokens": "Replica local = config . local ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "the", "unit", "test", "."], "add_tokens": "assertNotNull ( result [ 0 ] . getAffectedDatabaseObjects ( ) ) ; assertTrue ( result [ 0 ] . getAffectedDatabaseObjects ( ) . size ( ) >= 1 , result [ 0 ] assertNotNull ( result [ 1 ] . getAffectedDatabaseObjects ( ) ) ; assertTrue ( result [ 1 ] . getAffectedDatabaseObjects ( ) . size ( ) >= 1 , result [ 0 ]", "del_tokens": "assertNotNull ( result [ 2 ] . getAffectedDatabaseObjects ( ) ) ; assertTrue ( result [ 2 ] . getAffectedDatabaseObjects ( ) . size ( ) > 1 , result [ 0 ] assertNotNull ( result [ 2 ] . getAffectedDatabaseObjects ( ) ) ; assertTrue ( result [ 2 ] . getAffectedDatabaseObjects ( ) . size ( ) > 1 , result [ 0 ]", "commit_type": "fix"}
{"commit_tokens": ["Improve", "torrent", "creator", "and", "fix", "path", "expansion"], "add_tokens": "File actual = new File ( parent , file . file . getPath ( ) ) ; if ( ! actual . getCanonicalPath ( ) . startsWith ( parentPath ) ) { actual . getParentFile ( ) . mkdirs ( ) ; files . add ( new FileStorage ( actual , offset , file . size ) ) ;", "del_tokens": "if ( ! file . file . getCanonicalPath ( ) . startsWith ( parentPath ) ) { file . file . getParentFile ( ) . mkdirs ( ) ; files . add ( new FileStorage ( file . file , offset , file . size ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fixing", "infinite", "loop", "in", "GitRepo"], "add_tokens": "return \"First commit at: \" + firstCommit ( ) . name ( ) + \" Repo: \" + repository ;", "del_tokens": "import static com . google . common . base . Objects . firstNonNull ; String s = \"\" // + \"First commit at: \" + firstCommit ( ) . name ( ) + \"\\n\" // + \"Refs: \\n\" ; Map < String , Ref > allRefs = getAllRefs ( ) ; for ( String k : allRefs . keySet ( ) ) { ObjectId pealed = firstNonNull ( allRefs . get ( k ) . getPeeledObjectId ( ) , pealed = allRefs . get ( k ) . getObjectId ( ) ) ; s += \"Ref: \" + k + \" -> \" + pealed . name ( ) + \"\\n\" ; } return s ;", "commit_type": "fix"}
{"commit_tokens": ["added", "disabled", "test", "that", "shows", "issue", "with", "text", "search", "when", "specifying", "a", "packaging", "/", "classifier", "kind"], "add_tokens": "import org . junit . Ignore ; import java . io . IOException ; indexer . start ( ) ; @ Ignore public void testFindTestSearchAndPackaging ( ) throws Exception { assertSearchAndPackaging ( \"activemq\" , \"xsd\" , null ) ; assertSearchAndPackaging ( \"camel\" , null , \"maven-archetype\" ) ; assertSearchAndPackaging ( \"camel\" , \"xml\" , \"features\" ) ; } protected void assertSearchAndPackaging ( String searchText , String packaging , String classifier ) throws IOException { System . out . println ( \"Searching for text '\" + searchText + \"' packaging \" + packaging + \" classifier \" + classifier ) ; List < ArtifactDTO > resultsNoText = indexer . searchTextAndPackaging ( null , packaging , classifier ) ; List < ArtifactDTO > results = indexer . searchTextAndPackaging ( searchText , packaging , classifier ) ; for ( ArtifactDTO result : results ) { System . out . println ( \"Found \" + result ) ; } assertTrue ( \"Expect that the text '\" + searchText + \"' restricts the results but found \" + results . size ( ) + \" when with no text we found \" + resultsNoText . size ( ) , resultsNoText . size ( ) > results . size ( ) ) ; assertTrue ( \"Should have found at last one result!\" , results . size ( ) > 0 ) ; }", "del_tokens": "indexer . startAndWait ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "classloader", "for", "persistence", "unit", "info"], "add_tokens": "import org . seedstack . seed . core . utils . SeedReflectionUtils ; return SeedReflectionUtils . findMostCompleteClassLoader ( InternalPersistenceUnitInfo . class ) ; throw new UnsupportedOperationException ( \"class transformation is not supported by managed JPA units\" ) ; throw new UnsupportedOperationException ( \"temporary classloader is not supported by managed JPA units\" ) ;", "del_tokens": "// not supported return null ; // does nothing // not supported return null ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "feature", "to", "always", "show", "digit", "dates", "on", "any", "locale"], "add_tokens": "private boolean displayAlwaysDigitNumbers ; displayAlwaysDigitNumbers = a . getBoolean ( R . styleable . CalendarPickerView_tsquare_displayAlwaysDigitNumbers , false ) ; headerTextColor , displayDayNamesHeaderRow , displayAlwaysDigitNumbers , decorators , locale , dayViewAdapter ) ;", "del_tokens": "headerTextColor , displayDayNamesHeaderRow , decorators , locale , dayViewAdapter ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "failing", "test", "on", "invalid", "number"], "add_tokens": "public void should_fail_on_non_existant_date ( ) throws Exception { @ Test ( expected = IllegalStateException . class ) public void should_fail_on_invalid_number ( ) throws Exception { new Toml ( ) . parse ( \"a = 200-\" ) ; }", "del_tokens": "public void should_fail_on_invalid_date ( ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "size", "predicates"], "add_tokens": "import com . uphyca . testing . InstrumentationSupport ; public static final Predicate < Description > SELECT_INSTRUMENTATION_JUNIT3 = public static final Predicate < Description > SELECT_INSTRUMENTATION_JUNIT4 = new JUnit4AssignableFrom ( InstrumentationSupport . class ) ; @ SuppressWarnings ( \"unchecked\" ) public static final Predicate < Description > SELECT_INSTRUMENTATION = Predicates . or ( SELECT_INSTRUMENTATION_JUNIT3 , SELECT_INSTRUMENTATION_JUNIT4 ) ;", "del_tokens": "public static final Predicate < Description > SELECT_INSTRUMENTATION =", "commit_type": "add"}
{"commit_tokens": ["Added", "TestNG", "dataprovider", "tests", "and", "fixed", "a", "ConfigurationTest", "problem", "."], "add_tokens": "@ Test public void testDataProviders ( ) throws IOException { configTestProvider ( ) ; }", "del_tokens": "add ( generateFeatureByName ( \"RuledWordFeature\" , \"COUNTRY_NAME\" , new int [ ] { 15 , 0 , 0 } ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "token", "relay", "between", "resource", "servers"], "add_tokens": "import org . springframework . security . oauth2 . client . OAuth2RestOperations ; import org . springframework . util . Assert ; import org . springframework . web . bind . annotation . RequestMapping ; import org . springframework . web . bind . annotation . RestController ; @ TestPropertySource ( properties = { \"debug:true\" , \"spring.oauth2.resource.userInfoUri=http://start.spring.io\" } ) @ Test public void homePageAccessible ( ) throws Exception { // Random JSON comes back from user info mvc . perform ( get ( \"/\" ) . header ( \"Authorization\" , \"Bearer FOO\" ) ) . andExpect ( status ( ) . isNotFound ( ) ) ; } @ Test public void accessTokenRelay ( ) throws Exception { mvc . perform ( get ( \"/relay\" ) . header ( \"Authorization\" , \"Bearer FOO\" ) ) . andExpect ( status ( ) . isOk ( ) ) ; } @ RestController @ Autowired private OAuth2RestOperations restTemplate ; @ RequestMapping ( \"/relay\" ) public String relay ( ) { Assert . state ( restTemplate . getAccessToken ( ) != null , \"Access token not relayed\" ) ; return \"success!\" ; }", "del_tokens": "@ TestPropertySource ( properties = { \"debug:true\" , \"spring.oauth2.resource.userInfoUri=http://example.com/me\" } )", "commit_type": "add"}
{"commit_tokens": ["Add", "all", "known", "encodings", "for", "dbf"], "add_tokens": "assertEquals ( \"松柏坑溪\",rs.getS t ri n g(\"RIVERN A ME\")); assertEquals ( 1 , rs . getInt ( \"RIVERTYPE\" ) ) ; assertEquals ( \"劍潭湖\",rs.ge t St r ing(\"RIVE R NAME\")); assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( \"RIVERTYPE\" ) ) ; assertEquals ( \"竹篙水溪\",rs.getS t ri n g(\"RIVERN A ME\")); assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( \"RIVERTYPE\" ) ) ; assertEquals ( \"霞苞蓮幹線\",rs.getStr i ng ( \"RIVERNAM E \")); assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( \"RIVERTYPE\" ) ) ; assertEquals ( \"延潭大排水溝\",rs.getStrin g (\" R IVERNAME\" ) ); assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( \"RIVERTYPE\" ) ) ; assertEquals ( \"林內圳幹線\",rs.getStr i ng ( \"RIVERNAM E \"));", "del_tokens": "assertEquals ( \"챁촧\",rs. g et S tring(\"RI V ERNAME\")); assertEquals ( \"퍬쇗댔\",rs.ge t St r ing(\"RIVE R NAME\"));", "commit_type": "add"}
{"commit_tokens": ["Add", "testing", "for", "pvd", "(", "converter", ")", "."], "add_tokens": "Convert ( ) { void run ( String ... args ) { exit ( 1 ) ; } protected void exit ( int i ) { System . exit ( i ) ;", "del_tokens": "private Convert ( ) { private void run ( String ... args ) { System . exit ( 0 ) ; System . exit ( 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "alignment", "ALL", "to", "specs", "horizontally", "and", "vertically"], "add_tokens": "CENTERED , TOP , BOTTOM , LEFT , RIGHT , ALL ; else if ( alignmentText . equals ( \"all\" ) ) { return ALL ; } case ALL : return \"all\" ;", "del_tokens": "CENTERED , TOP , BOTTOM , LEFT , RIGHT ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "handling", "of", "join", "tables", "for", "multi", "-", "tenancy", ".", "Fixes", "https", ":", "//", "github", ".", "com", "/", "grails", "/", "grails", "-", "data", "-", "mapping", "/", "issues", "/", "954"], "add_tokens": "collection . addFilter ( GormProperties . TENANT_IDENTITY , filterCondition , ! isUnidirectionalOneToMany ( property ) , Collections . < String , String > emptyMap ( ) , Collections . < String , String > emptyMap ( ) ) ;", "del_tokens": "collection . addFilter ( GormProperties . TENANT_IDENTITY , filterCondition , true , Collections . < String , String > emptyMap ( ) , Collections . < String , String > emptyMap ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "extend", "model", "controller", "to", "support", "custom", "record", "level", "actions", "which", "would", "be", "automatically", "added", "to", "ModelListView"], "add_tokens": "import com . venky . swf . controller . annotations . Depends ; import com . venky . swf . controller . annotations . SingleRecordAction ; @ SingleRecordAction ( icon = \"/resources/images/show.png\" ) @ SingleRecordAction ( icon = \"/resources/images/edit.png\" ) @ Depends ( \"save\" ) @ SingleRecordAction ( icon = \"/resources/images/clone.png\" ) @ Depends ( \"save\" ) @ Depends ( \"save\" ) @ SingleRecordAction ( icon = \"/resources/images/destroy.png\" )", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "IOException", "to", "some", "Catalog", "parser", "API", "methods", "which", "had", "been", "ignoring", "IOException", "."], "add_tokens": "public CatalogLexer ( File file ) throws FileNotFoundException , IOException { public static List < antlr . Token > tokenize ( File file ) throws FileNotFoundException , IOException { ioReader . close ( ) ;", "del_tokens": "public CatalogLexer ( File file ) throws FileNotFoundException { public static List < antlr . Token > tokenize ( File file ) throws FileNotFoundException { try { ioReader . close ( ) ; } catch ( Throwable ignore ) { }", "commit_type": "add"}
{"commit_tokens": ["changed", "size", "return", "value", "to", "from", "int", "to", "long"], "add_tokens": "long size ( ) ;", "del_tokens": "int size ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "uses", "of", "deprecated", "APIs"], "add_tokens": "return wrapper . getWrapped ( ) ;", "del_tokens": "return wrapper . getWrappedConnection ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "correct", "handling", "of", "OptionGroup", ":", "after", "listOptions", "()", "a", "user", "can", "get", "the"], "add_tokens": "import com . google . common . base . Function ; import com . google . common . base . Preconditions ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . Lists ; import com . google . common . collect . Maps ; * Definitely not thread - safe . If you 're going to use this object from multiple threads, you must do * your own synchronization . Even performing read operations ( like getting an option 's value) must * be synchronized . private final List < OptionGroup > groups = Lists . newArrayList ( ) ; groups . clear ( ) ; void addOptionGroup ( OptionGroup group ) { groups . add ( group ) ; } / * * * Returns the list of option groups for this device . * / public List < OptionGroup > getOptionGroups ( ) throws IOException { listOptions ( ) ; return ImmutableList . copyOf ( groups ) ; }", "del_tokens": "import com . google . common . base . Function ; import com . google . common . base . Preconditions ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . Maps ; * Not thread - safe .", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "bug", "there", "is", "a", "case", "that", "ProxyMetaClass", "doees", "not", "call", "afterInvoke"], "add_tokens": "defaultOptions . put ( \"excludeMethods\" , Arrays . asList ( \"groovyx.gprof.*\" ) ) ;", "del_tokens": "// I believe grabbing phase must be excluded. Is there anyone wants to profile it? defaultOptions . put ( \"excludeMethods\" , Arrays . asList ( \"groovyx.gprof.*\" , \"groovy.grape.*\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["updating", "jpa", "example", "to", "demonstrate", "how", "filter", "with", "Page", "objects"], "add_tokens": "import org . springframework . data . domain . Page ; import org . springframework . data . domain . PageRequest ; import sample . data . jpa . domain . Review ; @ GetMapping ( \"/reviews\" ) @ ResponseBody @ Transactional ( readOnly = true ) public Page < Review > reviews ( ) { return hotelService . getReviews ( hotel ( ) , new PageRequest ( 0 , 10 ) ) ; }", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Add", "log", "levels", ".", "Only", "log", "queries", "for", "FULL", "log", "level", "."], "add_tokens": "import static ollie . Ollie . LogLevel ; Ollie . init ( getContext ( ) , getDatabaseName ( ) , getDatabaseVersion ( ) , getCacheSize ( ) , getLogLevel ( ) ) ; protected LogLevel getLogLevel ( ) { return LogLevel . NONE ; }", "del_tokens": "Ollie . init ( getContext ( ) , getDatabaseName ( ) , getDatabaseVersion ( ) , getCacheSize ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "space", "between", "method", "and", "URL"], "add_tokens": "log . info ( \"> \" + req . getMethod ( ) + \" \" + URLDecoder . decode ( req . getUri ( ) , \"UTF-8\" ) ) ;", "del_tokens": "log . info ( \"> \" + req . getMethod ( ) + URLDecoder . decode ( req . getUri ( ) , \"UTF-8\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "@OnBeanCondition", "to", "prevent", "confusing", "failures"], "add_tokens": "@ ConditionalOnBean ( OAuth2ProtectedResourceDetails . class )", "del_tokens": "@ ConditionalOnBean ( OAuth2ClientContext . class )", "commit_type": "add"}
{"commit_tokens": ["Changed", "method", "name", "getIconByUuid", "in", "domain", "classes"], "add_tokens": "return customIcons . getIconByUuid ( customIconUUID ) . getData ( ) ;", "del_tokens": "return customIcons . getCustomIconByUuid ( customIconUUID ) . getData ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "gv", "prefix", "to", "attributes", "names"], "add_tokens": "mMinTextSize = a . getDimension ( R . styleable . GestureTextView_gvMinTextSize , 0f ) ; mMaxTextSize = a . getDimension ( R . styleable . GestureTextView_gvMaxTextSize , 0f ) ;", "del_tokens": "mMinTextSize = a . getDimension ( R . styleable . GestureTextView_minTextSize , 0f ) ; mMaxTextSize = a . getDimension ( R . styleable . GestureTextView_maxTextSize , 0f ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "bugs", "in", "support", "for", "multiple", "projects", "but", "some", "bugs", "remain", "."], "add_tokens": "String projectName = \"<<untitled project \" + ( ++ projectCount ) + \">>\" ; System . out . println ( \"Adding \" + projectName ) ; Project project = new Project ( projectName ) ; DefaultTreeModel treeModel = ( DefaultTreeModel ) navigatorTree . getModel ( ) ; treeModel . insertNodeInto ( projectNode , rootNode , rootNode . getChildCount ( ) ) ; TreePath projPath = new TreePath ( new Object [ ] { rootNode , projectNode } ) ; navigatorTree . makeVisible ( projPath ) ; navigatorTree . setSelectionPath ( projPath ) ; navigatorTree . setShowsRootHandles ( true ) ; private int projectCount ;", "del_tokens": "/** Filename used for new projects. */ private static final String UNTITLED_PROJECT = \"<<untitled project>>\" ; Project project = new Project ( UNTITLED_PROJECT ) ; rootNode . add ( projectNode ) ; navigatorTree . setSelectionPath ( new TreePath ( new Object [ ] { rootNode , projectNode } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "concerning", "case", "sensitive", "attribute", "IDs", "for", "the", "isAdHoc", "marker", "."], "add_tokens": "if ( attribute . equals ( \"isadhoc\" ) ) {", "del_tokens": "if ( attribute . equals ( \"isAdHoc\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "covariant", "types", "in", "load", "and", "store", "instructions"], "add_tokens": "public < D , V > void iget ( FieldId < D , ? extends V > fieldId , Local < V > target , Local < D > instance ) { public < D , V > void iput ( FieldId < D , V > fieldId , Local < ? extends D > instance , Local < ? extends V > source ) { public < V > void sget ( FieldId < ? , ? extends V > fieldId , Local < V > target ) { public < V > void sput ( FieldId < ? , V > fieldId , Local < ? extends V > source ) {", "del_tokens": "public < D , V > void iget ( FieldId < D , V > fieldId , Local < V > target , Local < D > instance ) { public < D , V > void iput ( FieldId < D , V > fieldId , Local < D > instance , Local < V > source ) { public < V > void sget ( FieldId < ? , V > fieldId , Local < V > target ) { public < V > void sput ( FieldId < ? , V > fieldId , Local < V > source ) {", "commit_type": "allow"}
{"commit_tokens": ["fixing", "minor", "things", "after", "sonar", "scan"], "add_tokens": "throw new TaskAlreadyInLastColumnException ( \"{position: 'task is already in last column'}\" , e ) ; // todo this is a kanbanery bug workaround", "del_tokens": "throw new TaskAlreadyInLastColumnException ( \"{position: 'task is already in last column'}\" ) ; // todo this is a kanbanery bug workaround", "commit_type": "fix"}
{"commit_tokens": ["Adding", "some", "tests", "and", "fixing", "some", "issues", "for", "the", "Factory", "Processor"], "add_tokens": "ParameterizedTypeName . get ( ClassName . get ( Factory . class ) , className ) ; . addAnnotation ( Override . class ) . addModifiers ( Modifier . PUBLIC ) String prefix = \"\" ; String paramName = \"param\" + counter ++ ; createInstanceBuilder . addStatement ( \"$T $L = injector.getInstance($T.class)\" , paramType , returnStatement . append ( prefix ) ; prefix = \", \" ; . addAnnotation ( Override . class ) . addModifiers ( Modifier . PUBLIC ) . addStatement ( \"return $L\" , factoryInjectionTarget . hasSingletonAnnotation ) ; . addAnnotation ( Override . class ) . addModifiers ( Modifier . PUBLIC ) . addStatement ( \"return $L\" , factoryInjectionTarget . hasProducesSingletonAnnotation ) ;", "del_tokens": "ParameterizedTypeName . get ( className , ClassName . get ( Factory . class ) ) ; String paramName = String . format ( \"param$d\" , counter ) ; createInstanceBuilder . addStatement ( \"$T $s = injector.getInstance($T.class)\" , paramType , . addStatement ( \"return $b\" , factoryInjectionTarget . hasSingletonAnnotation ) ; . addStatement ( \"return $b\" , factoryInjectionTarget . hasProducesSingletonAnnotation ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "issue59", "-", "JMX", "configuration", "&", "add", "wroManagerFactory", "parameter", "to", "maven", "plugin"], "add_tokens": "protected final GroupsProcessor newGroupsProcessor ( ) { configureProcessors ( groupsProcessor ) ; return groupsProcessor ; } / * * * Configure the pre and post processors . Override this to specify your own processors . * * @ param groupsProcessor * / protected void configureProcessors ( final GroupsProcessor groupsProcessor ) {", "del_tokens": "protected GroupsProcessor newGroupsProcessor ( ) { return groupsProcessor ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "bug", "in", "the", "set", "preffered", "locale"], "add_tokens": "if ( ! Objects . equals ( this . preferredLocale , preferredLocale ) ) {", "del_tokens": "import java . security . cert . CertificateEncodingException ; if ( Objects . equals ( this . preferredLocale , preferredLocale ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "SimpleAccessControlContext", "for", "case", "where", "we", "want", "to", "use", "a", "DAO", "-", "specified", "role", "."], "add_tokens": "partialDAOClass . getDeclaredConstructor ( Class . class , Map . class , AccessControlContextProvider . class ) ; constructorCode = String . format ( \"public %s(Class entityClass, java.util.Map daoProperties, org.jeppetto.dao.AccessControlContextProvider accessControlContextProvider) { \" + sb . append ( \" queryModel.setAccessControlContext((org.jeppetto.dao.AccessControlContext) argsIterator.next());\\n\\n\" ) ; sb . append ( \" org.jeppetto.dao.SimpleAccessControlContext accessControlContext = new org.jeppetto.dao.SimpleAccessControlContext();\\n\" ) ; sb . append ( \" accessControlContext.setRole(\\\"\" ) . append ( dataAccessMethod . invokeWithRole ( ) ) . append ( \"\\\");\\n\" ) ; if ( interfaceMethod . getName ( ) . endsWith ( \"As\" ) ) { sb . append ( \" queryModel.setAccessControlContext((org.jeppetto.dao.AccessControlContext) argsIterator.next());\\n\\n\" ) ;", "del_tokens": "partialDAOClass . getConstructor ( Class . class , Map . class , boolean . class ) ; constructorCode = String . format ( \"public %s(Class entityClass, java.util.Map daoProperties, AccessControlContextProvider accessControlContextProvider) { \" + sb . append ( \" queryModel.setAccessControlContext(argsIterator.getNext());\\n\\n\" ) ; sb . append ( \" AccessControlContext accessControlContext = new AccessControlContext() {\\n\" ) ; sb . append ( \" public String getAccessId() { return null; }\\n\\n\" ) ; sb . append ( \" public String getRole() {\\n\" ) ; sb . append ( \" return \\\"\" ) . append ( dataAccessMethod . invokeWithRole ( ) ) . append ( \"\\\");\\n\" ) ; sb . append ( \" }\\n\" ) ; sb . append ( \" }\\n\\n\" ) ; if ( ! interfaceMethod . getName ( ) . endsWith ( \"As\" ) ) { sb . append ( \" queryModel.setAccessControlContext(argsIterator.getNext());\\n\\n\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "ordered", "list", "items", "to", "be", "greater", "than", "theme", "block", "margin"], "add_tokens": "// we will use this variable to check if our order number text exceeds block margin, // so we will use it instead of block margin // @since 1.0.3 private int margin ; // @since 1.0.3 return margin > 0 ? margin : theme . getBlockMargin ( ) ; // @since 1.0.3 int width = theme . getBlockMargin ( ) ; if ( numberWidth > width ) { width = numberWidth ; margin = numberWidth ; } else { margin = 0 ; }", "del_tokens": "return theme . getBlockMargin ( ) ; final int width = theme . getBlockMargin ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "authorization", "for", "streaming", "endpoint"], "add_tokens": "Matcher m = Pattern . compile ( \"/pools/\\\\w+/buckets(Streaming)?/(\\\\w+)/?.*\" ) . matcher ( requestPath ) ; bucketName = m . group ( 2 ) ;", "del_tokens": "Matcher m = Pattern . compile ( \"/pools/\\\\w+/buckets/(\\\\w+)/?.*\" ) . matcher ( requestPath ) ; bucketName = m . group ( 1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "problem", "with", "thrownFrom", "enhancing", "failure", "messages", "on", "malformed", "bushwhacker", "rules"], "add_tokens": "import com . github . steveash . bushwhacker . exception . IllegalBushwhackerRulesException ; try { return new RuleExceptionHandler ( makePredicate ( rule ) , makeAction ( rule ) ) ; } catch ( RuntimeException e ) { throw new IllegalBushwhackerRulesException ( \"Cannot build handler for bushwhacker rule \" + rule , e ) ; } builder . add ( PredicateMaker . makeThrownFrom ( matches . getThrownFrom ( ) ) ) ;", "del_tokens": "return new RuleExceptionHandler ( makePredicate ( rule ) , makeAction ( rule ) ) ; builder . add ( PredicateMaker . makeThrownFrom ( matches . getCustom ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "mvn", "test", "work", "."], "add_tokens": "assertTrue ( c . YUBICO_AUTH_SRV_URL . contains ( \"yubico.com\" ) ) ;", "del_tokens": "assertTrue ( c . YUBICO_AUTH_SRV_URL . contains ( \"yubico.org\" ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "Delete", "Group", "and", "change", "deleteUserByUUID"], "add_tokens": "public void deleteUser ( UUID id , AccessToken accessToken ) {", "del_tokens": "public void deleteUserByUUID ( UUID id , AccessToken accessToken ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "custom", "notification", "icon", "."], "add_tokens": "public int getCustomNotificationIcon ( Context context , String resourceName ) { logger . error ( \"Exception while parsing icon file.\" ) ; if ( resourceId == 0 ) { resourceId = context . getResources ( ) . getIdentifier ( \"drawable/\" + resourceName , \"drawable\" , context . getPackageName ( ) ) ;", "del_tokens": "import android . os . Message ; protected static int RES_PUSH_NOTIFICATION_ICON = - 1 ; public int getCustomNotificationIcon ( Context context , String resourceName ) { logger . error ( ( \"Exception while parsing icon file.\" ) ) ; if ( resourceId == - 1 ) { resourceId = context . getResources ( ) . getIdentifier ( resourceName , \"drawable\" , context . getPackageName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "purge", "multi", "threading", "issues", ".", "we", "need", "to", "recheck", "the", "entry", "to", "purge", "."], "add_tokens": "\"purged=\" + res . getEntriesPurged ( ) + \", \" + \"until=\" + now + StorageEntry e2 = storage . get ( _storageEntry . getKey ( ) ) ; if ( _storageEntry . getEntryExpiryTime ( ) == e2 . getEntryExpiryTime ( ) && _storageEntry . getValueExpiryTime ( ) == e2 . getValueExpiryTime ( ) ) { storage . remove ( _storageEntry . getKey ( ) ) ; _purgeCount . incrementAndGet ( ) ; }", "del_tokens": "\"purged=\" + res . getEntriesPurged ( ) + _purgeCount . incrementAndGet ( ) ; storage . remove ( _storageEntry . getKey ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "individual", "process", "listeners", "which", "get", "called", "after", "a", "process", "is", "committed", "."], "add_tokens": "/** List of process listeners */ private final FilterableArrayList < ProcessListener > process_listeners = new FilterableArrayList < ProcessListener > ( ) ; / * * * Register listeners that will be called when the process is updated . * / public void registerListener ( ProcessListener listener ) { process_listeners . add ( listener ) ; } pre_processes , post_processes , keep_completed , process_listeners , locale , implementation_options ) ;", "del_tokens": "pre_processes , post_processes , keep_completed , locale , implementation_options ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "error", "checking", "of", "CF", "names", "for", "people", "migrating", "old", "-", "style", "configurations"], "add_tokens": "if ( cName == null ) { throw new IllegalArgumentException ( \"ColumnFamily element missing Name attribute: \" + columnFamily ) ; } catch ( Exception e ) {", "del_tokens": "catch ( Exception e ) {", "commit_type": "add"}
{"commit_tokens": ["add", "a", "ProtobufWritable", "constructor", "from", "a", "specific", "message", "--", "useful", "for", "testing", "."], "add_tokens": "sb . append ( \"public class Protobuf%sWritable extends ProtobufWritable<%s> {\" , descriptorProto_ . getName ( ) , descriptorProto_ . getName ( ) , descriptorProto_ . getName ( ) ) . endl ( ) ; sb . append ( \" public Protobuf%sWritable(%s m) {\" , descriptorProto_ . getName ( ) , descriptorProto_ . getName ( ) ) . endl ( ) ; sb . append ( \" super(m, new TypeRef<%s>(){});\" , descriptorProto_ . getName ( ) ) . endl ( ) ; sb . append ( \" }\" ) . endl ( ) ;", "del_tokens": "sb . append ( \"public class Protobuf%sWritable extends ProtobufWritable<%s> {\" , descriptorProto_ . getName ( ) , descriptorProto_ . getName ( ) , descriptorProto_ . getName ( ) ) . endl ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "Spinner", "and", "fixing", "some", "bugs", "in", "slider"], "add_tokens": "import javafx . scene . layout . Border ; import javafx . scene . layout . BorderStroke ; import javafx . scene . layout . BorderStrokeStyle ; import javafx . scene . paint . Color ; import com . cctintl . c3dfx . controls . C3DSlider ; c3dSlider . setMinHeight ( 500 ) ; c3dSlider . setBorder ( new Border ( new BorderStroke ( Color . RED , BorderStrokeStyle . SOLID , null , null ) ) ) ; //scene.getStylesheets().add(SliderDemo.class.getResource(\"/resources/css/c3dobjects.css\").toExternalForm()); primaryStage . setHeight ( 900 ) ;", "del_tokens": "import com . cctintl . c3dfx . controls . C3DSlider ; import javafx . geometry . Orientation ; //c3dSlider.setMinHeight(500); scene . getStylesheets ( ) . add ( InputDemo . class . getResource ( \"resources/css/c3dobjects.css\" ) . toExternalForm ( ) ) ; primaryStage . setHeight ( 700 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "child", "builder", "methods", "were", "not", "overridden", "in", "derived", "builder", "class"], "add_tokens": "final JVar addVarargsParam = addVarargsMethod . varParam ( elementType , declaredSuperField . name ( ) ) ; final JVar withVarargsParam = withVarargsMethod . varParam ( elementType , declaredSuperField . name ( ) ) ; final BuilderOutline childBuilderOutline = getBuilderDeclaration ( elementType ) ; addMethod . annotate ( Override . class ) ;", "del_tokens": "final JVar addVarargsParam = addVarargsMethod . varParam ( ( ( JClass ) declaredSuperField . type ( ) ) . getTypeParameters ( ) . get ( 0 ) , declaredSuperField . name ( ) ) ; final JVar withVarargsParam = withVarargsMethod . varParam ( ( ( JClass ) declaredSuperField . type ( ) ) . getTypeParameters ( ) . get ( 0 ) , declaredSuperField . name ( ) ) ; final BuilderOutline childBuilderOutline = getBuilderDeclaration ( declaredSuperField . type ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "score", ".", "mail", "module", ".", "SendMail", "operation", "processInputs", "method", "."], "add_tokens": "sendMailInputs . setSmtpHostname ( hostname ) ;", "del_tokens": "sendMailInputs . setHostname ( hostname ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "exception", "handling", "for", "auditing", "interceptor"], "add_tokens": "private void store ( SecurityEvent auditEvent ) throws Exception {", "del_tokens": "private void store ( SecurityEvent auditEvent ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "waiting", "with", "timeout", "."], "add_tokens": "if ( isExhausted ( ) ) { return true ; wait ( timeout ) ; return isExhausted ( ) ;", "del_tokens": "while ( running > 0 ) { wait ( timeout ) ; return running == 0 ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "classpaths", "with", "spaces", ";", "add", "related", "tests", "."], "add_tokens": "file = new File ( url . getPath ( ) ) ;", "del_tokens": "import java . net . URISyntaxException ; try { file = new File ( url . toURI ( ) ) ; } catch ( URISyntaxException e ) { throw new RuntimeException ( e ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Removed", "some", "redundant", "comments", "."], "add_tokens": "// NOTE: We don't read the body here, it's done later in the read(int, ImageReadParam) method mImageInput . seek ( mBodyStart ) ;", "del_tokens": "// NOTE: We don't read the body here, it's done later in the // read(int, ImageReadParam) method mImageInput . seek ( mBodyStart ) ; // 8 for the header before length in stream", "commit_type": "remove"}
{"commit_tokens": ["fixed", "the", "rectange", "collision", "mode"], "add_tokens": "// are we inside the background? return ! backgroundCollidable . collide ( word ) // is there a collision with the background shape? && wordPlacer . place ( word ) ; // is there a collision with the existing words?", "del_tokens": "return wordPlacer . place ( word ) // is there a collision with the existing words? && ! backgroundCollidable . collide ( word ) ; // is there a collision with the background shape?", "commit_type": "fix"}
{"commit_tokens": ["Move", "hide", "/", "use", "text_tags", "to", "AbstractRequest", "."], "add_tokens": "fields . put ( REQUEST_USE_TEXT_TAGS , isUsingTextTags ( ) ) ; } if ( hasHideTextTags ( ) ) { fields . put ( REQUEST_HIDE_TEXT_TAGS , isHidingTextTags ( ) ) ;", "del_tokens": "public static final String SIGREQ_USE_TEXT_TAGS = \"use_text_tags\" ; public static final String SIGREQ_HIDE_TEXT_TAGS = \"hide_text_tags\" ; fields . put ( SIGREQ_USE_TEXT_TAGS , isUsingTextTags ( ) ) ; public boolean hasUseTextTags ( ) { return has ( SIGREQ_USE_TEXT_TAGS ) ; } public Boolean isUsingTextTags ( ) { return getBoolean ( SIGREQ_USE_TEXT_TAGS ) ; } public void setUseTextTags ( boolean useTextTags ) { set ( SIGREQ_USE_TEXT_TAGS , useTextTags ) ; } public boolean hasHideTextTags ( ) { return has ( SIGREQ_HIDE_TEXT_TAGS ) ; } public Boolean isHidingTextTags ( ) { return getBoolean ( SIGREQ_HIDE_TEXT_TAGS ) ; } public void setHideTextTags ( boolean hideTextTags ) { set ( SIGREQ_HIDE_TEXT_TAGS , hideTextTags ) ; }", "commit_type": "move"}
{"commit_tokens": ["Changing", "the", "way", "to", "create", "SparkStream"], "add_tokens": "import com . clearspring . analytics . util . Lists ; JavaRDD < T > rdd ; } else if ( iterable instanceof List ) { rdd = getSparkContext ( ) . parallelize ( Cast . < List < T > > as ( iterable ) ) ; } else { rdd = getSparkContext ( ) . parallelize ( Lists . < T > newArrayList ( Cast . as ( iterable ) ) ) ; return new SparkStream < > ( rdd ) ;", "del_tokens": "import com . davidbracewell . collection . Collect ; } else if ( iterable instanceof Collection ) { return stream ( Cast . < Collection < T > > as ( iterable ) ) ; return new SparkStream < > ( Collect . stream ( iterable ) . collect ( Collectors . toList ( ) ) ) ;", "commit_type": "change"}
{"commit_tokens": ["updated", "README", ".", "md", "and", "javadoc"], "add_tokens": "* @ param < U > the user - type", "del_tokens": "* @ param < U > the user type", "commit_type": "update"}
{"commit_tokens": ["Remove", "usage", "of", "isBlank", "in", "favour", "of", "isEmpty"], "add_tokens": "if ( usernamePasswordCredentials != null && usernamePasswordCredentials . getUserName ( ) != null && ! usernamePasswordCredentials . getUserName ( ) . isEmpty ( ) ) {", "del_tokens": "if ( usernamePasswordCredentials != null && usernamePasswordCredentials . getUserName ( ) != null && ! usernamePasswordCredentials . getUserName ( ) . isBlank ( ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Remove", "setter", "for", "unmodificable", "fields", "in", "replymarkup"], "add_tokens": "this . hideKeyboard = true ;", "del_tokens": "this . selective = true ; public ReplyKeyboardHide setHideKeyboard ( Boolean hideKeyboard ) { this . hideKeyboard = hideKeyboard ; return this ; }", "commit_type": "remove"}
{"commit_tokens": ["allow", "for", "com", ".", "sun", ".", "proxy", "prefixed", "proxy", "names"], "add_tokens": "if ( slashedName . indexOf ( \"$Proxy\" ) != - 1 || slashedName . indexOf ( \"$$EnhancerBy\" ) != - 1", "del_tokens": "if ( slashedName . startsWith ( \"$Proxy\" ) || slashedName . indexOf ( \"$$EnhancerBy\" ) != - 1", "commit_type": "allow"}
{"commit_tokens": ["fix", "https", ":", "//", "github", ".", "com", "/", "jirkapinkas", "/", "jsitemapgenerator", "/", "issues", "/", "12"], "add_tokens": "out . append ( escapeXmlSpecialCharacters ( image . getLoc ( ) ) ) ; out . append ( escapeXmlSpecialCharacters ( image . getCaption ( ) ) ) ; out . append ( escapeXmlSpecialCharacters ( image . getGeoLocation ( ) ) ) ; out . append ( escapeXmlSpecialCharacters ( image . getTitle ( ) ) ) ; out . append ( escapeXmlSpecialCharacters ( image . getLicense ( ) ) ) ;", "del_tokens": "out . append ( image . getLoc ( ) ) ; out . append ( image . getCaption ( ) ) ; out . append ( image . getGeoLocation ( ) ) ; out . append ( image . getTitle ( ) ) ; out . append ( image . getLicense ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "support", "for", "primary", "date", "attributes", "and", "update", "QUICK", "model", "info", "to", "reflect", "all", "current", "Quality", "FHIR", "Profiles"], "add_tokens": ". withCodeProperty ( \"name\" )", "del_tokens": ". withCodeProperty ( \"code\" )", "commit_type": "remove"}
{"commit_tokens": ["Fix", "Issus", ":", "Move", "mRedirectionCount", "plus", "in", "while", "body", "because", "recursion"], "add_tokens": "while ( mRedirectionCount < MAX_REDIRECTS && shouldAllowRedirects ) { mRedirectionCount ++ ; if ( mRedirectionCount > MAX_REDIRECTS && shouldAllowRedirects ) {", "del_tokens": "while ( mRedirectionCount ++ < MAX_REDIRECTS && shouldAllowRedirects ) { if ( mRedirectionCount > MAX_REDIRECTS ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "incorrect", "loading", "logic", "of", "AutoActive", "in", "FilterChain", "."], "add_tokens": "} if ( autoActive . consumerSide ( ) ) {", "del_tokens": "} else if ( autoActive . consumerSide ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "error", "when", "deserializing", "null", "port", "bindings"], "add_tokens": "import com . google . common . collect . Maps ; import java . util . Collections ; @ JsonProperty ( \"PortBindings\" ) private Map < String , List < PortBinding > > portBindings ; return ( portBindings == null ) ? null : Collections . unmodifiableMap ( portBindings ) ; private Map < String , List < PortBinding > > portBindings ; this . portBindings = ( portBindings == null ) ? null : Maps . newHashMap ( portBindings ) ;", "del_tokens": "@ JsonProperty ( \"PortBindings\" ) private ImmutableMap < String , List < PortBinding > > portBindings ; return portBindings ; private ImmutableMap < String , List < PortBinding > > portBindings ; final ImmutableMap . Builder < String , List < PortBinding > > builder = ImmutableMap . builder ( ) ; for ( Map . Entry < String , List < PortBinding > > entry : portBindings . entrySet ( ) ) { builder . put ( entry . getKey ( ) , ImmutableList . copyOf ( entry . getValue ( ) ) ) ; } this . portBindings = builder . build ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "package", "private", "until", "case", "is", "made", "for", "public", "API", "."], "add_tokens": "final class LinkedQueueNode < E > {", "del_tokens": "public final class LinkedQueueNode < E > {", "commit_type": "make"}
{"commit_tokens": ["Added", "docs", "about", "foreign", "fields", "and", "querying", "."], "add_tokens": "// should find both of the orders that match the account // ORMLite extracts the id from the account for the query automagically statementBuilder . where ( ) . eq ( Order . ACCOUNT_ID_FIELD_NAME , account ) ;", "del_tokens": "// should find both of the orders that match the account id statementBuilder . where ( ) . eq ( Order . ACCOUNT_ID_FIELD_NAME , account . getId ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "cleaner", "issues", "around", "Chunks"], "add_tokens": "touch ( ) ; touch ( ) ;", "del_tokens": "touch ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "race", "condition", "in", "DecisionTree"], "add_tokens": "synchronized ( DecisionTree . class ) { Math . permutate ( variables ) ; }", "del_tokens": "Math . permutate ( variables ) ;", "commit_type": "fix"}
{"commit_tokens": ["created", "state", "machine", "to", "handle", "tasks", "on", "nodes", "in", "analysis", "infrastructure", "added", "log", "download", "logic", "updated", "config", "files", "and", "scripts"], "add_tokens": "System . out . println ( new LogEntry ( \"about to invoke \" + commandLine + \" with parameters \" + ArraySupport . format ( parameters , \",\" ) ) ) ;", "del_tokens": "System . out . println ( new LogEntry ( \"about to invoke \" + commandLine ) + \" with parameters \" + ArraySupport . format ( parameters , \",\" ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "bug", "where", "non", "-", "accessible", "field", "is", "briefly", "published", "causing", "hideous", "random", "exceptions"], "add_tokens": "final Field field = defineClass ( ) . getDeclaredField ( INVOCATION_HANDLER_FIELD ) ; AccessController . doPrivileged ( new SetAccessiblePrivilege ( field ) ) ; invocationHandlerField = field ;", "del_tokens": "invocationHandlerField = defineClass ( ) . getDeclaredField ( INVOCATION_HANDLER_FIELD ) ; AccessController . doPrivileged ( new SetAccessiblePrivilege ( invocationHandlerField ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "prefixes", "to", "simple", "log", "messages"], "add_tokens": "sendToConsole ( \"DEBUG: \" + msg ) ; sendToConsole ( \"DEBUG: \" + msg , e ) ; sendToConsole ( \"ERROR: \" + msg ) ; sendToConsole ( \"ERROR: \" + msg , e ) ; sendToConsole ( \"INFO: \" + msg ) ; @ Override sendToConsole ( \"INFO: \" + msg , e ) ; sendToConsole ( \"WARN: \" + msg ) ; sendToConsole ( \"WARN: \" + msg , e ) ;", "del_tokens": "sendToConsole ( msg ) ; sendToConsole ( msg , e ) ; sendToConsole ( msg ) ; sendToConsole ( msg , e ) ; sendToConsole ( msg ) ; sendToConsole ( msg , e ) ; sendToConsole ( msg ) ; sendToConsole ( msg , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "interfaces", "support", "for", "Peapod", "library", "."], "add_tokens": "while ( aClass != null && ! Object . class . equals ( aClass ) ) {", "del_tokens": "while ( ! Object . class . equals ( aClass ) ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "distinct", "tests", "and", "refactor", "index", "creation"], "add_tokens": "public void ensureIndex ( String index ) { collection . ensureIndex ( toDBObject ( index ) ) ;", "del_tokens": "@ Deprecated // TODO use save or generic method public void index ( String query ) { DBObject dbObject = toDBObject ( query ) ; collection . insert ( dbObject ) ; // TODO don't save id", "commit_type": "move"}
{"commit_tokens": ["Fixed", "starting", "service", "on", "more", "than", "one", "port"], "add_tokens": "import org . apache . zookeeper . KeeperException ; protected Server ( List < String > serverPorts , String locatorEndpoints ) throws Exception { System . out . println ( \"Starting Server on port \" + serverPorts . toString ( ) + \"...\" ) ; for ( String el : serverPorts ) { String address = \"http://192.168.40.15:\" + el + \"/services/Greeter\" ; publishService ( address ) ; } lr . setBus ( bus ) ; String locatorEndpoints = \"192.168.40.15:2181\" ; << << << < HEAD == == == = >>> >>> > b7426aa637fdc826825400be6f19cee767cc1085 new Server ( serverPorts , locatorEndpoints ) ;", "del_tokens": "protected Server ( String serverPort , String locatorEndpoints ) throws Exception { System . out . println ( \"Starting Server on port \" + serverPort + \"...\" ) ; // String address = String.format(\"http://localhost:%1$/services/Greeter\", serverPort); String address = \"http://localhost:\" + serverPort + \"/services/Greeter\" ; publishService ( address ) ; lr . setBus ( bus ) ; String locatorEndpoints = \"localhost:2181\" ; for ( String serverPort : serverPorts ) { new Server ( serverPort , locatorEndpoints ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "from", "mapred", ".", "*", "to", "new", "mapreduce", ".", "*", "API"], "add_tokens": "import org . apache . hadoop . mapreduce . InputSplit ; import org . apache . hadoop . mapreduce . RecordReader ; import org . apache . hadoop . mapreduce . TaskAttemptContext ; public RecordReader < BytesWritable , BitcoinBlock > createRecordReader ( InputSplit split , TaskAttemptContext ctx ) throws IOException { return new BitcoinBlockRecordReader ( ctx . getConfiguration ( ) ) ;", "del_tokens": "import org . apache . hadoop . mapred . FileSplit ; import org . apache . hadoop . mapred . InputSplit ; import org . apache . hadoop . mapred . JobConf ; import org . apache . hadoop . mapred . RecordReader ; import org . apache . hadoop . mapred . Reporter ; public RecordReader < BytesWritable , BitcoinBlock > getRecordReader ( InputSplit split , JobConf job , Reporter reporter ) throws IOException { return new BitcoinBlockRecordReader ( ( FileSplit ) split , job , reporter ) ; } catch ( BitcoinBlockReadException e ) { // log LOG . error ( e ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "AbstractSimpleBeanConverter", "that", "is", "a", "base", "class", "to", "create", "a"], "add_tokens": "MapToBeanTest . class , MapWithClassToBeanMappingTest . class , SimpleBeanConverterTest . class } )", "del_tokens": "MapToBeanTest . class , MapWithClassToBeanMappingTest . class } )", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "service", "mode", "that", "avoids", "usage", "of", "system", "in", "."], "add_tokens": "if ( builder . isServiceMode ( ) ) { System . out . println ( \"The documents4j server is up and running in server mode and will not terminate until interruption.\" ) ; try { Thread . currentThread ( ) . join ( ) ; } catch ( InterruptedException ignored ) { /* do nothing */ } } else { System . out . println ( \"The documents4j server is up and running. Hit the enter key to shut it down...\" ) ; if ( System . in . read ( ) == - 1 ) { logger . warn ( \"Console read terminated without receiving user input\" ) ; } OptionSpec < ? > serviceModeSpec = makeServiceModeSpec ( optionParser ) ; boolean serviceMode = optionSet . has ( serviceModeSpec ) ; return builder . serviceMode ( serviceMode ) ; private static OptionSpec < Void > makeServiceModeSpec ( OptionParser optionParser ) { return optionParser . acceptsAll ( Arrays . asList ( CommandDescription . ARGUMENT_LONG_SERVICE_MODE , CommandDescription . ARGUMENT_SHORT_SERVICE_MODE ) , CommandDescription . DESCRIPTION_CONTEXT_SERVICE_MODE ) ; }", "del_tokens": "System . out . println ( \"The documents4j server is up and running. Hit the enter key to shut it down...\" ) ; if ( System . in . read ( ) == - 1 ) { logger . warn ( \"Console read terminated without receiving user input\" ) ; return builder ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "get", "user", "by", "e", "-", "mail", ".", "yammer", "returns", "user", "inside", "json", "array", "not", "as", "a", "single", "user"], "add_tokens": "import org . springframework . util . CollectionUtils ; YammerProfileList profileList = restTemplate . getForObject ( uri , YammerProfileList . class ) ; //Yammer returns user inside a Json array element if ( CollectionUtils . isEmpty ( profileList ) ) { return null ; } return profileList . get ( 0 ) ;", "del_tokens": "return restTemplate . getForObject ( uri , YammerProfile . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "Taxinvice", "/", "Cashbill", "/", "Statement", "/", "EasyFinBank", "API", "Service", "."], "add_tokens": "EasyFinBankSearchResult result = easyFinBankService . search ( \"1234567890\" , \"020080711000000001\" , TradeType , SearchString , Page , PerPage , Order ) ; System . out . println ( result . getLastScrapDT ( ) ) ;", "del_tokens": "EasyFinBankSearchResult result = easyFinBankService . search ( \"1234567890\" , \"019121811000000004\" , TradeType , SearchString , Page , PerPage , Order ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "support", "for", "plaintext", "message", "type", "."], "add_tokens": "content . getBody ( ) , syncContext , endSession ) ;", "del_tokens": "} else if ( envelope . isPlaintext ( ) ) { paddedMessage = envelope . getMessage ( ) ; boolean secure = envelope . isWhisperMessage ( ) || envelope . isPreKeyWhisperMessage ( ) ; content . getBody ( ) , syncContext , secure , endSession ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "modifier", "final", "to", "static", "fields", "because", "it", "s", "a", "constant"], "add_tokens": "private static final UserAgentStringParser INSTANCE = new UpdatingUserAgentStringParserImpl ( private static final UserAgentStringParser INSTANCE = new UpdatingUserAgentStringParserImpl ( new OnlineXmlDataStore (", "del_tokens": "private static UserAgentStringParser INSTANCE = new UpdatingUserAgentStringParserImpl ( private static UserAgentStringParser INSTANCE = new UpdatingUserAgentStringParserImpl ( new OnlineXmlDataStore (", "commit_type": "add"}
{"commit_tokens": ["make", "dotted", "identifiers", "a", "parser", "problem", "instead", "of", "a", "lexer", "problem"], "add_tokens": "/** \".\" */ DOT ,", "del_tokens": "/** valid java identifier with dots */ DOTTED_IDENTIFIER ,", "commit_type": "make"}
{"commit_tokens": ["Fix", "recursive", "output", "tree", "structure", "+", "add", "some", "unit", "tests"], "add_tokens": "? outputDirectory + \"/\" + file . getParentFile ( ) . getPath ( ) . substring ( inputFile . getPath ( ) . length ( ) ) + \"/\" + file . getName ( ) . replaceAll ( \".md\" , \".html\" )", "del_tokens": "? outputDirectory + \"/\" + file . getParentFile ( ) . getPath ( ) . substring ( 0 , inputFile . getPath ( ) . length ( ) ) + \"/\" + file . getName ( ) . replaceAll ( \".md\" , \".html\" )", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "bug", "with", "class", "hierarchy", "check"], "add_tokens": "//does interface exist in the map? for ( Class iface : cls . getInterfaces ( ) ) { if ( matches . containsKey ( iface ) ) { return matches . get ( iface ) ; } } current = current . getSuperclass ( ) ;", "del_tokens": "current = cls . getSuperclass ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "InMinutes", "from", "duration", "-", "fix", "benchmark"], "add_tokens": "= \"/org/drools/solver/examples/itc2007/examination/benchmark/examinationSolverBenchmarkConfig.xml\" ; // public static final String SOLVER_BENCHMARK_CONFIG // = \"/org/drools/solver/examples/itc2007/examination/benchmark/examinationShortSolverBenchmarkConfig.xml\";", "del_tokens": "// public static final String SOLVER_BENCHMARK_CONFIG // = \"/org/drools/solver/examples/itc2007/examination/benchmark/examinationSolverBenchmarkConfig.xml\"; = \"/org/drools/solver/examples/itc2007/examination/benchmark/examinationShortSolverBenchmarkConfig.xml\" ;", "commit_type": "remove"}
{"commit_tokens": ["add", "fixme", "comments", "and", "inject", "metrics"], "add_tokens": "import io . scalecube . services . metrics . Metrics ; if ( field . isAnnotationPresent ( Inject . class ) ) { if ( field . getType ( ) . equals ( Microservices . class ) ) { setField ( field , service , this . microservices ) ; } else if ( isService ( field . getType ( ) ) ) { setField ( field , service , this . microservices . call ( ) . api ( field . getType ( ) ) ) ; } else if ( Metrics . class . equals ( field . getType ( ) ) ) { setField ( field , service , this . microservices . metrics ( ) ) ; } } else if ( Void . TYPE . equals ( returnType ) ) { // TODO: should we later support 2 parameters? message and the Stream processor?", "del_tokens": "if ( field . isAnnotationPresent ( Inject . class ) && field . getType ( ) . equals ( Microservices . class ) ) { setField ( field , service , this . microservices ) ; } else if ( field . isAnnotationPresent ( Inject . class ) && isService ( field . getType ( ) ) ) { setField ( field , service , this . microservices . call ( ) . api ( field . getType ( ) ) ) ; } else if ( Void . TYPE . equals ( returnType ) ) { //TODO: should we later support 2 parameters? message and the Stream processor?", "commit_type": "add"}
{"commit_tokens": ["add", "unit", "test", "for", "chained", "selects"], "add_tokens": "createDatabase ( con ) ; try { con . close ( ) ; } catch ( SQLException e ) { throw new RuntimeException ( e ) ; } public static Database createDatabase ( ConnectionProvider cp ) { Database db = new Database ( cp ) ; Connection con = cp . get ( ) ; createDatabase ( con ) ; try { con . close ( ) ; } catch ( SQLException e ) { throw new RuntimeException ( e ) ; } return db ; }", "del_tokens": "createDatabase ( con ) ; try { con . close ( ) ; } catch ( SQLException e ) { throw new RuntimeException ( e ) ; }", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "use", "un", "-", "deprecated", "methods", "of", "getting", "headers", "from", "the", "Request", "object", "."], "add_tokens": "if ( request . getHeader ( \"User-Agent\" ) != null ) builder . append ( \" UserAgent=\" + request . getHeader ( \"User-Agent\" ) ) ; if ( request . getHeader ( \"Referer\" ) != null ) builder . append ( \" UrlReferer=\" + request . getHeader ( \"Referer\" ) ) ;", "del_tokens": "if ( request . getRawHeader ( \"User-Agent\" ) != null ) builder . append ( \" UserAgent=\" + request . getRawHeader ( \"User-Agent\" ) ) ; if ( request . getRawHeader ( \"Referer\" ) != null ) builder . append ( \" UrlReferer=\" + request . getRawHeader ( \"Referer\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "minor", "things", "after", "sonar", "scan"], "add_tokens": "TaskFlow asReadyToPull ( ) throws IOException ; TaskFlow asNotReadyToPull ( ) throws IOException ;", "del_tokens": "public TaskFlow asReadyToPull ( ) throws IOException ; public TaskFlow asNotReadyToPull ( ) throws IOException ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "typing", "indicators"], "add_tokens": "/ * @ JsonProperty private boolean online ; public OutgoingPushMessageList ( String destination , long timestamp , List < OutgoingPushMessage > messages , boolean online ) this . online = online ; public boolean isOnline ( ) { return online ; }", "del_tokens": "/ * * @ JsonProperty private String relay ; public OutgoingPushMessageList ( String destination , long timestamp , String relay , List < OutgoingPushMessage > messages ) this . relay = relay ; public String getRelay ( ) { return relay ; }", "commit_type": "add"}
{"commit_tokens": ["Updated", "all", "package", "dependencies", "and", "moved", "tests", "to", "JUnit", "5", ".", "Ready", "for", "JavaFX", "UI", "testing", "to", "start", "."], "add_tokens": "import static org . junit . jupiter . api . Assertions . assertTrue ; assertTrue ( protocol . fromChannel ( bb ) instanceof MenuHeartbeatCommand ) ;", "del_tokens": "import org . hamcrest . Matchers ; import java . util . concurrent . CountDownLatch ; import static org . junit . Assert . assertThat ; assertThat ( ( MenuHeartbeatCommand ) protocol . fromChannel ( bb ) , Matchers . isA ( MenuHeartbeatCommand . class ) ) ;", "commit_type": "update"}
{"commit_tokens": ["allowing", "for", "perceptron", "sequence", "trainer"], "add_tokens": "return loadTrainingParameters ( paramFile , true ) ;", "del_tokens": "return loadTrainingParameters ( paramFile , false ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "additional", "business", "data", "columns"], "add_tokens": "layoutTypePortlet . removePortletId ( themeDisplay . getUserId ( ) , portletId , true ) ;", "del_tokens": "layoutTypePortlet . removePortletId ( themeDisplay . getUserId ( ) , portletId ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "check", "for", "image", "filetype", "added", "check", "for", "key", "-", "existence", "before", "adding", "image", "(", "protocol", "forbids", "images", "without", "keys", ")"], "add_tokens": "import javax . activation . MimetypesFileTypeMap ; // Protocol forbids images for suggestions without keys // TODO: add this piece of information to nokey-Warning if ( suggestionKey != null ) { String image = checkImage ( items , response ) ; if ( image == null ) { response . addNoImageWarning ( CreateStatusCodes . NO_IMAGE ) ; } suggestTreeCreateRequestContainer . setImageBase64 ( image ) ; } // maybe there is a better way for verifying image encoding than MIME? String mimeType = new MimetypesFileTypeMap ( ) . getContentType ( imageFile ) ; if ( ! ( mimeType . equals ( \"image/JPEG\" ) ) ) { try { fileReader . close ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } return null ; } // checks if the suggestion String length matches ASTP requirements", "del_tokens": "// TODO find elegant way to abort(->return) if key is too long // if (suggestionKey == null) { // return response; // } String image = checkImage ( items , response ) ; if ( image == null ) { response . addNoImageWarning ( CreateStatusCodes . NO_IMAGE ) ; // suggestTreeCreateRequestContainer.putHash(suggestionString, // imageName); } suggestTreeCreateRequestContainer . setImageBase64 ( image ) ; // TODO: check length // check if the suggestion String length matches ASTP requirements // TODO: add Strings!", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "offsetting", "the", "ports", "(", "defaults", "to", "0", "offset", ")"], "add_tokens": "new SocketBindingGroup ( \"default-sockets\" , \"public\" , \"${jboss.socket.binding.port-offset:0}\" ) . socketBinding ( \"http\" , \"${jboss.http.port:8080}\" )", "del_tokens": "new SocketBindingGroup ( \"default-sockets\" , \"public\" , \"0\" ) . socketBinding ( \"http\" , 8080 )", "commit_type": "add"}
{"commit_tokens": ["make", "it", "a", "bit", "more", "robust", "."], "add_tokens": "if ( name != null ) { this . holidays . put ( name , holidaysSet ) ; } if ( name != null && holidays . containsKey ( name ) ) {", "del_tokens": "this . holidays . put ( name , holidaysSet ) ; if ( holidays . containsKey ( name ) ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "feature", "to", "set", "the", "color", "for", "zero", "if", "range", "is", "between", "neg", ".", "and", "pos", ".", "values"], "add_tokens": "Color zeroColor = getSkinnable ( ) . getZeroColor ( ) ; boolean isNotZero = true ; CTX . setFill ( tickMarkColor ) ; isNotZero = Double . compare ( 0d , counter ) != 0 ; if ( ! isNotZero ) { CTX . setFill ( zeroColor ) ; CTX . setStroke ( zeroColor ) ; } CTX . setFont ( isNotZero ? tickMarkFont : tickMarkZeroFont ) ; CTX . setFont ( isNotZero ? tickLabelFont : tickLabelZeroFont ) ; if ( isNotZero ) { CTX . setFill ( tickLabelSectionsVisible ? Helper . getColorOfSection ( tickLabelSections , counter , tickLabelColor ) : tickLabelColor ) ; } else { CTX . setFill ( zeroColor ) ; }", "del_tokens": "CTX . setFont ( Double . compare ( 0d , counter ) != 0 ? tickMarkFont : tickMarkZeroFont ) ; CTX . setFont ( Double . compare ( 0d , counter ) != 0 ? tickLabelFont : tickLabelZeroFont ) ; CTX . setFill ( tickLabelSectionsVisible ? Helper . getColorOfSection ( tickLabelSections , counter , tickLabelColor ) : tickLabelColor ) ;", "commit_type": "add"}
{"commit_tokens": ["allow", "to", "cancel", "and", "change", "the", "current", "enterprise", "domain", "/", "email"], "add_tokens": "usernameStyle = options . usernameStyle ( ) ; loginAfterSignUp = options . loginAfterSignUp ( ) ;", "del_tokens": "usernameStyle = options . usernameStyle ( ) ; loginAfterSignUp = options . loginAfterSignUp ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["using", "methods", "instead", "of", "fields"], "add_tokens": "import java . lang . reflect . Member ; import java . lang . reflect . Modifier ; import static org . atatec . trugger . reflection . ReflectionPredicates . declaring ; Predicate < Member > nonStatic = declaring ( Modifier . STATIC ) . negate ( ) ; . filter ( ( getter ( ) . or ( setter ( ) ) ) . and ( nonStatic ) ) List < Field > fields = fields ( ) . filter ( nonStatic ) . in ( type ) ;", "del_tokens": "import static org . atatec . trugger . reflection . ReflectionPredicates . nonStatic ; . filter ( ( getter ( ) . or ( setter ( ) ) ) . and ( nonStatic ( ) ) ) List < Field > fields = fields ( ) . filter ( nonStatic ( ) ) . in ( type ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bugs", "and", "new", "defects", "reported", "by", "SonarCloud"], "add_tokens": "try ( Stream < Path > walkStream = walk ( getSnapshotDirectory ( transactionId ) ) ) { walkStream // . sorted ( Comparator . reverseOrder ( ) ) // . map ( Path :: toFile ) // . forEach ( File :: delete ) ; }", "del_tokens": "walk ( getSnapshotDirectory ( transactionId ) ) // . sorted ( Comparator . reverseOrder ( ) ) // . map ( Path :: toFile ) // . forEach ( File :: delete ) ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "getType", "()", "like", "getTable", "()"], "add_tokens": "public Class < P > getType ( ) { return type ; } }", "del_tokens": "}", "commit_type": "allow"}
{"commit_tokens": ["Adding", "tests", "for", "URI", "configuration"], "add_tokens": "} catch ( MalformedURLException | IllegalArgumentException ex ) { throw new UnleashException ( \"Invalid unleash repository uri [\" + repo . toString ( ) + \"]\" , ex ) ;", "del_tokens": "} catch ( MalformedURLException ex ) { throw new UnleashException ( \"Invalid repo uri\" , ex ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "documentation", "for", "Levenshtein", "automata", "."], "add_tokens": "result = prime * result + ( ( transitions == null ) ? 0 : transitionsHashCode ( ) ) ;", "del_tokens": "result = prime * result + ( ( transitions == null ) ? 0 : transitionsHashCode ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "registering", "callbacks", "when", "propagating", "a", "ServiceInvocationContext", "and", "set", "them", "for", "tracing", "."], "add_tokens": "import java . util . ArrayList ; private List < Runnable > onEnterCallbacks ; private List < Runnable > onExitCallbacks ; resetContext ( propagatedContext ) ; resetContext ( propagatedContext ) ; resetContext ( propagatedContext ) ; resetContext ( propagatedContext ) ; resetContext ( propagatedContext ) ; private static void resetContext ( ServiceInvocationContext ctx ) { removeCurrent ( ) ; if ( ctx . onExitCallbacks != null ) { ctx . onExitCallbacks . forEach ( Runnable :: run ) ; } } if ( propagatedContext . onEnterCallbacks != null ) { propagatedContext . onEnterCallbacks . forEach ( Runnable :: run ) ; } public ServiceInvocationContext onEnter ( Runnable callback ) { if ( onEnterCallbacks == null ) { onEnterCallbacks = new ArrayList < > ( 4 ) ; } onEnterCallbacks . add ( callback ) ; return this ; } public ServiceInvocationContext onExit ( Runnable callback ) { if ( onExitCallbacks == null ) { onExitCallbacks = new ArrayList < > ( 4 ) ; } onExitCallbacks . add ( callback ) ; return this ; }", "del_tokens": "removeCurrent ( ) ; removeCurrent ( ) ; removeCurrent ( ) ; removeCurrent ( ) ; removeCurrent ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Move", "snackbar", "from", "fragment", "layout", "to", "activity", "layout"], "add_tokens": "setupTabs ( ) ; updatePage ( viewpager . getCurrentItem ( ) ) ; updatePage ( i ) ; * Called when the selected page changes . * * @ param selectedPage selected page * / private void updatePage ( int selectedPage ) { updateFab ( selectedPage ) ; updateSnackbar ( selectedPage ) ; } / * * * Updates the FAB based on the selected page * @ param selectedPage selected page private void updateFab ( int selectedPage ) { switch ( selectedPage ) { / * * * Updates the snackbar based on the selected page * * @ param selectedPage selected page * / private void updateSnackbar ( int selectedPage ) { View snackbar = findViewById ( R . id . snackbar ) ; switch ( selectedPage ) { case MainPagerAdapter . SHARED_POS : snackbar . setVisibility ( View . VISIBLE ) ; break ; case MainPagerAdapter . ALL_POS : case MainPagerAdapter . FAVORITES_POS : default : snackbar . setVisibility ( View . GONE ) ; break ; } }", "del_tokens": "setupTabs ( ) ; updateFab ( i ) ; * Updates the FAB based on the selected tab * @ param selectedTab selected tab private void updateFab ( int selectedTab ) { switch ( selectedTab ) {", "commit_type": "move"}
{"commit_tokens": ["adding", "all", "attributes", "to", "the", "request", "dialog", ";", "adding", "accordion", ";", "header", "and", "query", "param"], "add_tokens": "UaiMockServer . start ( \"configForListAllRoutes.config\" ) ;", "del_tokens": "UaiMockServer . start ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "classes", "for", "GP", "optimization", "including", "a", "regression", "class", "and"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixing", "the", "tests", "after", "turning", "off", "PREP_ORG", "."], "add_tokens": "add ( new Result ( \"New Zealand\" , LOCATION , of ( 95.0 , 5.0 , - 10.0 ) , ImmutableMap . of ( \"prep\" , \"in\" ) ) ) ; add ( new Result ( \"Denmark\" , LOCATION , of ( 46.25 , - 5.0 , 15.0 ) , ImmutableMap . of ( \"prep\" , \"in\" ) ) ) ; add ( new Result ( \"UK\" , LOCATION , of ( 10.0 , 0.0 , 0.0 ) , ImmutableMap . of ( \"prep\" , \"in\" ) ) ) ;", "del_tokens": "add ( new Result ( \"New Zealand\" , LOCATION , of ( 95. , 5. , 0. ) , ImmutableMap . of ( \"prep\" , \"in\" ) ) ) ; add ( new Result ( \"Denmark\" , LOCATION , of ( 46.25 , - 5. , 25. ) , ImmutableMap . of ( \"prep\" , \"in\" ) ) ) ; add ( new Result ( \"UK\" , UNKNOWN , of ( 10.0 , 0.0 , 10.0 ) , ImmutableMap . of ( \"prep\" , \"in\" ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "String", ".", "format", "()", "translation", "for", "chars", "autoboxing", "test", "from", "previous", "CL", "."], "add_tokens": "if ( c == 'c' || c == 'C' || c == 'd' || c == 'o' || c == 'x' || c == 'X' || c == 'e' || c == 'f' || c == 'g' || c == 'a' || c == 'A' ) {", "del_tokens": "if ( c == 'c' || c == 'd' || c == 'o' || c == 'x' || c == 'X' || c == 'e' || c == 'f' || c == 'g' || c == 'a' || c == 'A' ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "IllegalArgumentsException", "caused", "by", "zero", "entry", "weight"], "add_tokens": "// ConcurrentLinkedHashMap barfs on size == 0 return entry . size > 0 ? entry . size : 1 ;", "del_tokens": "return entry . size ; //entry.size;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "SeekBar", "default", "color", "and", "changed", "ripple", "logic"], "add_tokens": "* Changed 08 / 05 / 2015 mRipple = new AlmostRippleDrawable ( resources . getColorStateList ( R . color . g_default_seek_bar_ripple ) ) ; mSeekBarDrawable = new SeekBarDrawable ( resources . getColorStateList ( R . color . g_default_seek_bar_track ) , resources . getColorStateList ( R . color . g_default_seek_bar_scrubber ) , resources . getColorStateList ( R . color . g_default_seek_bar_thumb ) ) ; mIndicator . setIndicatorColor ( resources . getColorStateList ( R . color . g_default_seek_bar_indicator ) ) ;", "del_tokens": "* Changed 08 / 04 / 2015 mRipple = new AlmostRippleDrawable ( resources . getColorStateList ( R . color . g_default_ripple_color ) ) ; mSeekBarDrawable = new SeekBarDrawable ( resources . getColorStateList ( R . color . g_default_track_color ) , resources . getColorStateList ( R . color . g_default_progress_color ) , resources . getColorStateList ( R . color . g_default_progress_color ) ) ; mIndicator . setIndicatorColor ( resources . getColorStateList ( R . color . g_progress_color ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "license", "headers", "and", "AUTHORS"], "add_tokens": "/ * * * Copyright ( c ) 2014 - 2016 Marc de Verdelhan & respective authors ( see AUTHORS )", "del_tokens": "/ * * Copyright ( c ) 2014 - 2015 Bastian Engelmann", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "built", "in", "rootname", "to", "empty", "string"], "add_tokens": "public void setRootDissection ( final String type , final String value ) { LOG . debug ( \"Got root dissection: type={}\" , type ) ; // The root name is an empty string final ParsedField parsedfield = new ParsedField ( type , \"\" , value ) ; if ( base . isEmpty ( ) ) { // The root name is an empty string", "del_tokens": "private String rootname = null ; public void setRootDissection ( final String type , final String name , final String value ) { LOG . debug ( \"Got root dissection: type={}; name=\\\"{}\\\"\" , type , name ) ; rootname = name ; final ParsedField parsedfield = new ParsedField ( type , name , value ) ; if ( base . equals ( rootname ) ) {", "commit_type": "change"}
{"commit_tokens": ["fixed", "failure", "to", "copy", "table", "name", "to", "view", "when", "running", "head", "()"], "add_tokens": "View view = new View ( this , Math . min ( nRows , rowCount ( ) ) ) ; view . setName ( name ) ; return view ;", "del_tokens": "return new View ( this , Math . min ( nRows , rowCount ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "concurrency", "model", "of", "ResponseRouter", "that", "results", "in", "NullPointerException"], "add_tokens": "import java . util . concurrent . ConcurrentHashMap ; private final Map < Long , ResponsePromise > messageMap = new ConcurrentHashMap < > ( ) ; ctx . writeAndFlush ( rawRequest ) ;", "del_tokens": "private final Map < Long , ResponsePromise > messageMap = new HashMap < > ( ) ; ctx . writeAndFlush ( rawRequest ) . await ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "JDK", "logging", "test", "case"], "add_tokens": "* Test a CXF endpoint with provided jbossws - cxf . xml public class DescriptorJSETestCase extends JBossWSTest return new JBossWSTestSetup ( DescriptorJSETestCase . class , \"jaxws-cxf-descriptor.war\" ) ;", "del_tokens": "* Test the CXF WS - descriptorMessaging public class DescriptorCXFJSETestCase extends JBossWSTest return new JBossWSTestSetup ( DescriptorCXFJSETestCase . class , \"jaxws-cxf-descriptor.war\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "JavaDocs", "in", "ECKey", "to", "try", "and", "help", "people", "understand", "the", "difference", "between", "pubkeyhashes", "and", "pubkeys", ".", "The", "getting", "started", "guide", "was", "also", "updated", "."], "add_tokens": "/ * * * Gets the raw public key value . This appears in transaction scriptSigs . Note that this is < b > not < / b > the same * as the pubKeyHash / address . * / / * * * Returns the address that corresponds to the public part of this ECKey . Note that an address is derived from * the RIPEMD - 160 hash of the public key and is not the public key itself ( which is too large to be convenient ) . * /", "del_tokens": "/** Gets the raw public key value. */", "commit_type": "improve"}
{"commit_tokens": ["Adding", "Representation", "Conversion", "to", "JacksonDSL"], "add_tokens": "import java . io . ByteArrayInputStream ; import java . io . ByteArrayOutputStream ; import java . io . IOException ; import java . io . OutputStream ; public static class RepresentationConverter { private final Representation representation ; private final ObjectMapper objectMapper ; private final ByteArrayOutputStream byteStream ; private RepresentationConverter ( Representation representation ) { this . representation = representation ; this . objectMapper = new ObjectMapper ( ) ; this . byteStream = new ByteArrayOutputStream ( ) ; } public < T > T to ( Class < T > convertTo ) throws IOException { representation . write ( byteStream ) ; return objectMapper . readValue ( new ByteArrayInputStream ( byteStream . toByteArray ( ) ) , convertTo ) ; } } public static RepresentationConverter convertRepresentation ( Representation representation ) { return new RepresentationConverter ( representation ) ; }", "del_tokens": "import java . io . OutputStream ;", "commit_type": "add"}
{"commit_tokens": ["Add", "flag", "for", "new", "task", "."], "add_tokens": "if ( mContext instanceof Activity ) { mContext . startActivity ( intent ) ; } else { intent . setFlags ( Intent . FLAG_ACTIVITY_NEW_TASK ) ; mContext . startActivity ( intent ) ; }", "del_tokens": "mContext . startActivity ( intent ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "the", "non", "-", "http", "createClientProxy", "to", "respect", "@JsonRpcMethod", "annotation"], "add_tokens": "String methodName = method . getName ( ) ; JsonRpcMethod methodAnnotation = method . getAnnotation ( JsonRpcMethod . class ) ; if ( methodAnnotation != null && methodAnnotation . value ( ) != null ) { methodName = methodAnnotation . value ( ) ; } methodName , arguments , method . getGenericReturnType ( ) , ops , ips ) ;", "del_tokens": "method . getName ( ) , arguments , method . getGenericReturnType ( ) , ops , ips ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "topic", "support", "for", "HproseServlet"], "add_tokens": "* LastModified : Jun 29 , 2016 * param = config . getInitParameter ( \"topic\" ) ; if ( param != null ) { try { String [ ] topics = StrUtil . split ( param , ',' , 0 ) ; for ( int i = 0 , n = topics . length ; i < n ; ++ i ) { String [ ] item = StrUtil . split ( topics [ i ] , '|' , 3 ) ; if ( item . length == 1 ) { service . publish ( item [ 0 ] ) ; } else if ( item . length == 2 ) { service . publish ( item [ 0 ] , Integer . parseInt ( item [ 1 ] , 10 ) ) ; } else if ( item . length == 3 ) { service . publish ( item [ 0 ] , Integer . parseInt ( item [ 1 ] , 10 ) , Integer . parseInt ( item [ 1 ] , 10 ) ) ; } } } catch ( Exception ex ) { throw new ServletException ( ex ) ; } }", "del_tokens": "* LastModified : Jun 28 , 2016 *", "commit_type": "add"}
{"commit_tokens": ["Fix", "character", "encoding", "of", "FormulaDotFileWriter"], "add_tokens": "import java . io . FileOutputStream ; import java . io . OutputStreamWriter ; import java . nio . charset . Charset ; try ( BufferedWriter writer = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( file ) , Charset . forName ( \"UTF-8\" ) ) ) ) {", "del_tokens": "import java . io . FileWriter ; try ( BufferedWriter writer = new BufferedWriter ( new FileWriter ( file ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "for", "Wikipedia", "s", "redirect", "to", "HTTPS"], "add_tokens": "PageRevision revision = new WikiClient ( \"https://en.wikipedia.org\" )", "del_tokens": "PageRevision revision = new WikiClient ( \"http://en.wikipedia.org\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "touch", "interception", "view", "support", "for", "GridView", "and", "add", "GridView", "fragment", "to", "ViewPagerTab2", "example", "."], "add_tokens": "final int pattern = position % 4 ; case 3 : default : f = new ViewPagerTab2GridViewFragment ( ) ; break ;", "del_tokens": "final int pattern = position % 3 ; default :", "commit_type": "add"}
{"commit_tokens": ["Add", "property", "element", "names", "to", "XcalTags", ".", "Change", "value", "type", "names", "."], "add_tokens": "BINARY ( XcalTags . binaryVal ) , BOOLEAN ( XcalTags . booleanVal ) , CUA ( XcalTags . calAddressVal ) , DATE ( XcalTags . dateVal ) , DATE_TIME ( XcalTags . dateTimeVal ) , FLOAT ( XcalTags . floatVal ) , INTEGER ( XcalTags . integerVal ) , PERIOD ( XcalTags . periodVal ) , RECUR ( XcalTags . recurVal ) , TEXT ( XcalTags . textVal ) , TIME ( XcalTags . timeVal ) , URI ( XcalTags . uriVal ) , UTC_OFFSET ( XcalTags . utcOffsetVal ) ,", "del_tokens": "BINARY ( XcalTags . binary ) , BOOLEAN ( XcalTags . _boolean ) , CUA ( XcalTags . calAddress ) , DATE ( XcalTags . date ) , DATE_TIME ( XcalTags . dateTime ) , FLOAT ( XcalTags . _float ) , INTEGER ( XcalTags . integer ) , PERIOD ( XcalTags . period ) , RECUR ( XcalTags . recur ) , TEXT ( XcalTags . text ) , TIME ( XcalTags . time ) , URI ( XcalTags . uri ) , UTC_OFFSET ( XcalTags . utcOffset ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "and", "docs", "for", "Command", "."], "add_tokens": "final String title = cmd . getName ( ) + \": \" + cmd . getDescription ( ) ; return title + '\\n' + getBanner ( title . length ( ) ) ;", "del_tokens": "final String title = cmd . getName ( ) + ( cmd . getDescription ( ) . isPresent ( ) ? \"\" : \": \" + cmd . getDescription ( ) . get ( ) ) ; return title + \"\\n\" + getBanner ( title . length ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "Blend", "class", "for", "image", "and", "pixel", "blending"], "add_tokens": "public static Img crop ( Img img , int x , int y , int width , int height ) { public static BufferedImage crop ( BufferedImage bufferedimg , int x , int y , int width , int height ) {", "del_tokens": "public Img crop ( Img img , int x , int y , int width , int height ) { public BufferedImage crop ( BufferedImage bufferedimg , int x , int y , int width , int height ) {", "commit_type": "add"}
{"commit_tokens": ["add", "an", "ability", "to", "override", "host", "and", "thread", "names", "via", "env"], "add_tokens": "import static io . qameta . allure . ResultsUtils . getHostName ; import static io . qameta . allure . ResultsUtils . getTheadName ; label ( \"host\" , getHostName ( ) ) , label ( \"thread\" , getTheadName ( ) )", "del_tokens": "import java . lang . management . ManagementFactory ; import java . net . InetAddress ; import java . net . UnknownHostException ; private static final String HOST = getHostName ( ) ; label ( \"host\" , HOST ) , label ( \"thread\" , getThreadName ( ) ) private static String getHostName ( ) { try { return InetAddress . getLocalHost ( ) . getHostName ( ) ; } catch ( UnknownHostException e ) { LOGGER . debug ( \"Could not get host name {}\" , e ) ; return \"default\" ; } } private String getThreadName ( ) { return String . format ( \"%s.%s(%s)\" , ManagementFactory . getRuntimeMXBean ( ) . getName ( ) , Thread . currentThread ( ) . getName ( ) , Thread . currentThread ( ) . getId ( ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Make", "Interpolators", "lazy", "singleton", "."], "add_tokens": "ObjectAnimator translateXAnimator = ObjectAnimatorCompat . ofFloat ( target , \"translateX\" , null , PATH_INDETERMINATE_HORIZONTAL_RECT1_TRANSLATE_X ) ; Interpolators . INDETERMINATE_HORIZONTAL_RECT1_TRANSLATE_X . INSTANCE ) ; Interpolators . INDETERMINATE_HORIZONTAL_RECT1_SCALE_X . INSTANCE ) ; ObjectAnimator translateXAnimator = ObjectAnimatorCompat . ofFloat ( target , \"translateX\" , null , PATH_INDETERMINATE_HORIZONTAL_RECT2_TRANSLATE_X ) ; Interpolators . INDETERMINATE_HORIZONTAL_RECT2_TRANSLATE_X . INSTANCE ) ; Interpolators . INDETERMINATE_HORIZONTAL_RECT2_SCALE_X . INSTANCE ) ; trimPathStartAnimator . setInterpolator ( Interpolators . TRIM_PATH_START . INSTANCE ) ; trimPathEndAnimator . setInterpolator ( Interpolators . TRIM_PATH_END . INSTANCE ) ;", "del_tokens": "ObjectAnimator translateXAnimator = ObjectAnimatorCompat . ofFloat ( target , \"translateX\" , null , PATH_INDETERMINATE_HORIZONTAL_RECT1_TRANSLATE_X ) ; Interpolators . createIndeterminateHorizontalRect1TranslateX ( ) ) ; Interpolators . createIndeterminateHorizontalRect1ScaleX ( ) ) ; ObjectAnimator translateXAnimator = ObjectAnimatorCompat . ofFloat ( target , \"translateX\" , null , PATH_INDETERMINATE_HORIZONTAL_RECT2_TRANSLATE_X ) ; Interpolators . createIndeterminateHorizontalRect2TranslateX ( ) ) ; Interpolators . createIndeterminateHorizontalRect2ScaleX ( ) ) ; trimPathStartAnimator . setInterpolator ( Interpolators . createTrimPathStart ( ) ) ; trimPathEndAnimator . setInterpolator ( Interpolators . createTrimPathEnd ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["changing", "latency", "units", "to", "micros", "from", "millls"], "add_tokens": "long startTime = System . nanoTime ( ) / 1000 ; long duration = System . nanoTime ( ) / 1000 - startTime ; opResult . setLatency ( duration , TimeUnit . MICROSECONDS ) ;", "del_tokens": "long startTime = System . currentTimeMillis ( ) ; long duration = System . currentTimeMillis ( ) - startTime ; opResult . setLatency ( duration , TimeUnit . MILLISECONDS ) ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "RssGenerator", "so", "that", "it", "correctly", "uses", "default", "dir", "&", "extension", "the", "same", "way", "as", "in", "SitemapGenerators"], "add_tokens": "* Constructs name from dir and extension ( if available ) , used in SitemapGenerators / * * * Constructs shortName from dir and extension ( if available ) , used in RssGenerator * @ return Name * / public String constructShortName ( ) { String result = shortName ; if ( dir != null ) { result = dir + \"/\" + result ; } if ( extension != null ) { result = result + \".\" + extension ; } return result ; } public String getName ( ) { return name ; }", "del_tokens": "* Constructs name from dir and extension ( if available )", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "way", "to", "block", "data", "storage", "for", "ack", "handlers"], "add_tokens": "/ * * * Tells the connection if it should hold the data from a publish and send it to the ack handler . * * Added as a default in 2.2 .3 to allow apps to stop data retention in the connection . The default * version returns true . Override and return false to always receive null in the onAck and prevent * message accumulation when large acks in flight are used . * * @ return true to include data with the onAck callback , false to include null * / default boolean includeDataWithAck ( ) { return true ; }", "del_tokens": "* Not deprecated yet to avoid multiple warnings , will deprecate in the future .", "commit_type": "add"}
{"commit_tokens": ["removed", "cheesy", "comment", "and", "hardcoded", "max", "depth", "based", "on", "jco", "s", "comment"], "add_tokens": "private ColumnIO currentColumnIO ; private int currentLevel = 0 ; private final int [ ] currentIndex ; private final int [ ] r ; private final ColumnWriter [ ] columnWriter ; int maxDepth = 0 ; this . columnWriter = new ColumnWriter [ MessageColumnIO . this . getLeaves ( ) . size ( ) ] ; maxDepth = Math . max ( maxDepth , primitiveColumnIO . getFieldPath ( ) . length ) ; currentIndex = new int [ maxDepth ] ; r = new int [ maxDepth ] ;", "del_tokens": "ColumnIO currentColumnIO ; int currentLevel = 0 ; int [ ] currentIndex = new int [ 256 ] ; // \"256 levels of nesting ought to be enough to anybody\" int [ ] r = new int [ 256 ] ; private ColumnWriter [ ] columnWriter ; columnWriter = new ColumnWriter [ MessageColumnIO . this . getLeaves ( ) . size ( ) ] ;", "commit_type": "remove"}
{"commit_tokens": ["added", "extra", "attributes", "and", "TextSturcture", "layer"], "add_tokens": "public interface TextSpan extends ExtraAtrributes {", "del_tokens": "public interface TextSpan {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "minor", "doc", "typos", "."], "add_tokens": "* If the node doesn 't have a normal \"error\" field, an IOFacebookException is returned. Something // we simply throw the base FacebookException", "del_tokens": "* If the node doesn 't have a normal \"error\" field, an IOFacebookException is retrned. Something // we simply throw the base FormalFacebookException", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "class", "that", "wraps", "the", "Snackback", "to", "allow", "customisation", "after", "it", "has", "been", "built", ".", "Also", "means", "you", "can", "wrap", "a", "Snackbar", "created", "at", "any", "point", "to", "get", "access", "to", "extra", "customisations", "."], "add_tokens": "Compatibility . getInstance ( ) . setAllCaps ( action , true ) ;", "del_tokens": "import android . os . Build . VERSION ; import android . os . Build . VERSION_CODES ; if ( isApiAtLeast14 ( ) ) { action . setAllCaps ( actionAllCaps ) ; } private boolean isApiAtLeast14 ( ) { return VERSION . SDK_INT >= VERSION_CODES . ICE_CREAM_SANDWICH ; }", "commit_type": "add"}
{"commit_tokens": ["Improve", "power", "of", "2", "check"], "add_tokens": "while ( c < capacity ) c <<= 1 ; return p > 0 && Integer . bitCount ( p ) == 1 ;", "del_tokens": "while ( c < capacity ) c <<= 1 ; return p == 0x1 || ( ( p & 0x1 ) == 0 ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "a", "few", "more", "tests"], "add_tokens": "assertNotNull ( testObject . getData ( ) ) ;", "del_tokens": "assertNotNull ( testObject . getHasMore ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "all", "byte", "wipe", "instances", "null", "safe"], "add_tokens": "Bytes . wrapNullSafe ( passwordBytes ) . mutable ( ) . secureWipe ( ) ; Bytes . wrapNullSafe ( pwWithNullTerminator ) . mutable ( ) . secureWipe ( ) ; Bytes . wrapNullSafe ( rawSalt ) . mutable ( ) . secureWipe ( ) ; Bytes . wrapNullSafe ( rawHash ) . mutable ( ) . secureWipe ( ) ; Bytes . wrapNullSafe ( passwordBytes ) . mutable ( ) . secureWipe ( ) ; Bytes . wrapNullSafe ( bcryptHashBytes ) . mutable ( ) . secureWipe ( ) ;", "del_tokens": "if ( passwordBytes != null ) { Bytes . wrap ( passwordBytes ) . mutable ( ) . secureWipe ( ) ; } Bytes . wrap ( pwWithNullTerminator ) . mutable ( ) . secureWipe ( ) ; Bytes . wrap ( rawSalt ) . mutable ( ) . secureWipe ( ) ; Bytes . wrap ( rawHash ) . mutable ( ) . secureWipe ( ) ; if ( passwordBytes != null ) { Bytes . wrap ( passwordBytes ) . mutable ( ) . secureWipe ( ) ; } if ( bcryptHashBytes != null ) { Bytes . wrap ( bcryptHashBytes ) . mutable ( ) . secureWipe ( ) ; }", "commit_type": "make"}
{"commit_tokens": ["Updated", "to", "newer", "API", "."], "add_tokens": "scepClient . getCaCertificate ( ) ; byte [ ] fingerprint ; try { fingerprint = callback . getFingerprint ( \"MD5\" ) ; } catch ( Exception e ) { continue ; } writer . write ( \"Is this the MD5 hash of your CA's certificate?\\n\" ) ;", "del_tokens": "final List < X509Certificate > certs = scepClient . getCaCertificate ( ) ; final byte [ ] fingerprint = callback . getFingerprint ( ) ; writer . write ( \"Is this the \" + callback . getAlgorithm ( ) + \" hash of your CA's certificate?\\n\" ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "tests", "+", "fix", "in", "locale"], "add_tokens": "localize ( lang . tag , key , content , values , result ) ; private static void localize ( String [ ] languageTag , String key , String content , Object [ ] values , AsyncWork < String , NoException > result ) { for ( int i = 0 ; i < values . length ; ++ i ) if ( values [ i ] instanceof ILocalizableString ) { AsyncWork < String , NoException > l = ( ( ILocalizableString ) values [ i ] ) . localize ( languageTag ) ; Object [ ] newValues = new Object [ values . length ] ; System . arraycopy ( values , 0 , newValues , 0 , values . length ) ; int ii = i ; l . listenAsync ( new Task . Cpu . FromRunnable ( ( ) -> { newValues [ ii ] = l . getResult ( ) ; localize ( languageTag , key , content , newValues , result ) ; } , \"Localization\" , Task . PRIORITY_NORMAL ) , true ) ; return ; }", "del_tokens": "localize ( key , content , values , result ) ; private static void localize ( String key , String content , Object [ ] values , AsyncWork < String , NoException > result ) {", "commit_type": "add"}
{"commit_tokens": ["add", "modifier", "to", "method", "signature"], "add_tokens": "import static com . alibaba . ttl . threadpool . agent . internal . transformlet . impl . Utils . signatureOfMethod ; logger . info ( \"insert code before method \" + signatureOfMethod ( method ) + \" of class \" + method . getDeclaringClass ( ) . getName ( ) + \": \" + code ) ;", "del_tokens": "logger . info ( \"insert code before method \" + Utils . signatureOfMethod ( method ) + \" of class \" + method . getDeclaringClass ( ) . getName ( ) + \": \" + code ) ;", "commit_type": "add"}
{"commit_tokens": ["improve", "(", "task", "-", "name", "-", "beautifier", ")", ":", "simplify", "several", "aspects"], "add_tokens": "// normally no parse listeners should be set, so create an own list for it", "del_tokens": "// Change whatever you want to change in the configuration, see // https://app.camunda.com/confluence/display/foxUserGuide/Extending+the+configuration+of+the+fox+platform#Extendingtheconfigurationofthefoxplatform-UseCases // for some typical use cases // normally no parse listeners should be set, so create an own list for // it", "commit_type": "improve"}
{"commit_tokens": ["make", "the", "mbean", "server", "injectable"], "add_tokens": "@ Inject", "del_tokens": "/ * * * Default constructor for use by Guice if you do not bind anything ; * creates a MBeanExporter with the platform { @ link MBeanServer } * / @ Inject", "commit_type": "make"}
{"commit_tokens": ["Fixed", "names", "for", "hasNot", "methods", "where", "the", "Not", "word", "was", "placed", "incorrectly"], "add_tokens": "public static boolean hasNotClassContaining ( String searchText , WebElement webElement ) { public static boolean hasNotClassStartingWith ( String prefix , WebElement webElement ) { public static boolean hasNotClassEndingWith ( String suffix , WebElement webElement ) { if ( hasNotClassContaining ( searchText , webElement ) ) { public static void assertHasNotClassContaining ( String searchText , WebElement webElement ) { if ( hasNotClassStartingWith ( prefix , webElement ) ) { public static void assertHasNotClassStartingWith ( String prefix , WebElement webElement ) { if ( hasNotClassEndingWith ( suffix , webElement ) ) { public static void assertHasNotClassEndingWith ( String suffix , WebElement webElement ) {", "del_tokens": "public static boolean hasClassNotContaining ( String searchText , WebElement webElement ) { public static boolean hasClassNotStartingWith ( String prefix , WebElement webElement ) { public static boolean hasClassNotEndingWith ( String suffix , WebElement webElement ) { if ( hasClassNotContaining ( searchText , webElement ) ) { public static void assertHasClassNotContaining ( String searchText , WebElement webElement ) { if ( hasClassNotStartingWith ( prefix , webElement ) ) { public static void assertHasClassNotStartingWith ( String prefix , WebElement webElement ) { if ( hasClassNotEndingWith ( suffix , webElement ) ) { public static void assertHasClassNotEndingWith ( String suffix , WebElement webElement ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "when", "providing", "transaction", "to", "match", ".", "insert", "query"], "add_tokens": "private final Optional < MatchQuery > matchQuery ; this . matchQuery = Optional . ofNullable ( matchQuery ) ; matchQuery . ifPresent ( query -> query . withTransaction ( transaction ) ) ; return matchQuery . map ( query -> query . stream ( ) . flatMap ( this :: insertAll ) ) . orElseGet ( this :: insertAll ) ; return matchQuery ; return insertAll ( new HashMap < > ( ) ) ; } / * * * Insert all the Vars * @ param results the result of a match query * / private Stream < Concept > insertAll ( Map < String , Concept > results ) { concepts = new HashMap < > ( results ) ;", "del_tokens": "private final MatchQuery matchQuery ; this . matchQuery = matchQuery ; if ( matchQuery == null ) { concepts . clear ( ) ; return insertAll ( ) ; } else { return matchQuery . stream ( ) . flatMap ( resultMap -> { concepts = new HashMap < > ( resultMap ) ; return insertAll ( ) ; } ) ; } return Optional . ofNullable ( matchQuery ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "encrypt", "and", "decrypt", "methods", "to", "take", "String", "key", ".", "Added", "related"], "add_tokens": "import org . apache . commons . codec . binary . Base64 ; private final String A_GOOD_STRING_KEY = \"5XBoZ7li2W5wzhOULEqtQzdkufjsVFs4\" ; private final String A_BAD_STRING_KEY = \"c/t/nuBFwTgvB+lwzS/q5W0ZkQhhxCB1\" ; // String stringKey = Base64.encodeBase64String(key.getEncoded()); public void testEncryptDecryptString ( ) { @ Test public void testEncryptString ( ) { String encryptedString = null ; String decryptedString = null ; try { encryptedString = Encryption . encryptString ( THING_TO_BE_ENCRYPTED , A_GOOD_STRING_KEY ) ; decryptedString = Encryption . decryptString ( encryptedString , A_GOOD_STRING_KEY ) ; } catch ( EncryptionException e ) { e . printStackTrace ( ) ; } assertEquals ( THING_TO_BE_ENCRYPTED , decryptedString ) ; } @ Test ( expected = com . capitalone . dashboard . util . EncryptionException . class ) public void testDecryptionWithBadStringKey ( ) throws Exception { String encryptedString = Encryption . encryptString ( THING_TO_BE_ENCRYPTED , A_GOOD_STRING_KEY ) ; @ SuppressWarnings ( \"unused\" ) String decryptedString = Encryption . decryptString ( encryptedString , A_BAD_STRING_KEY ) ; }", "del_tokens": "public void testEncryptString ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "number", "tests", "for", "#", "flag"], "add_tokens": "// TODO: add more tests with other flags ',', ' ', '-', '+' assertThat ( log ( \"%(.0f\" , - 123f ) ) . isEqualTo ( \"(123)\" ) ; // '#' tests assertThat ( log ( \"%#o\" , - 123 ) ) . isEqualTo ( \"037777777605\" ) ; assertThat ( log ( \"%#x\" , 123 ) ) . isEqualTo ( \"0x7b\" ) ; assertThat ( log ( \"%#X\" , 123 ) ) . isEqualTo ( \"0X7B\" ) ; assertThat ( log ( \"%#.0f\" , 123. ) ) . isEqualTo ( \"123.\" ) ; assertFormatFailure ( \"%#h\" , \"foo\" ) ; assertFormatFailure ( \"%#b\" , true ) ; assertFormatFailure ( \"%#d\" , 123 ) ; assertFormatFailure ( \"%#g\" , BigDecimal . ONE ) ;", "del_tokens": "// TODO: add more tests with other flags '#', ',', ' ', '-', '+'", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "typo", "in", "SelectorGeneratorNative", "Fixes", "Issue_6"], "add_tokens": "sw . println ( \"return \" + wrap ( method , \"querySelectorAll(\\\"\" + selector + \"\\\")\" ) + \";\" ) ; + wrap ( method , \"querySelectorAll(\\\"\" + selector + \"\\\", root)\" ) + \";\" ) ;", "del_tokens": "System . out . println ( \"generateMethodBody \" + method + \" \" + hasContext ) ; sw . println ( \"return \" + wrap ( method , \"querySelectorAll(\\\"\" + selector + \"\\\"\" ) + \");\" ) ; + wrap ( method , \"querySelectorAll(\\\"\" + selector + \"\\\", root)\" ) + \");\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "java", "URIs", "instead", "."], "add_tokens": "import java . net . URI ; user = ManagerSingleton . getInstance ( ) . getUser ( URI . create ( accessToken . getAccessAs ( ) . toString ( ) ) ) ;", "del_tokens": "user = ManagerSingleton . getInstance ( ) . getUser ( accessToken . getAccessAs ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "test", "on", "an", "empty", "file"], "add_tokens": "import java . io . IOException ; private Path testOutput ; testOutput = tempDir . newFolder ( \"test-output\" ) . toPath ( ) ; / * * * Test method for * { @ link com . github . ansell . csv . access . AccessMapper # main ( java . lang . String [ ] ) } * . * / @ Test public final void testMainEmpty ( ) throws Exception { Path testFile = tempDir . newFile ( \"test-empty.accdb\" ) . toPath ( ) ; Files . copy ( this . getClass ( ) . getResourceAsStream ( \"/com/github/ansell/csvaccess/test-empty.accdb\" ) , testFile , StandardCopyOption . REPLACE_EXISTING ) ; thrown . expect ( IOException . class ) ; thrown . expectMessage ( \"Empty database file\" ) ; AccessMapper . main ( \"--input\" , testFile . toAbsolutePath ( ) . toString ( ) , \"--mapping\" , testMapping . toAbsolutePath ( ) . toString ( ) , \"--output\" , testOutput . toAbsolutePath ( ) . toString ( ) ) ; }", "del_tokens": "Path testOutput = tempDir . newFolder ( \"test-output\" ) . toPath ( ) ; Path testOutput = tempDir . newFolder ( \"test-output\" ) . toPath ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "recreation", "of", "the", "cache", "directory", "when", "deleted", "."], "add_tokens": "File dirtyFile = entry . getDirtyFile ( index ) ; FileOutputStream outputStream ; outputStream = new FileOutputStream ( dirtyFile ) ; // Attempt to recreate the cache directory and allow reading and writing. directory . mkdirs ( ) ; directory . setReadable ( true , false ) ; directory . setWritable ( true , false ) ; try { outputStream = new FileOutputStream ( dirtyFile ) ; } catch ( FileNotFoundException e2 ) { // We are unable to recover. Silently eat the writes. return NULL_OUTPUT_STREAM ; } return new FaultHidingOutputStream ( outputStream ) ;", "del_tokens": "return new FaultHidingOutputStream ( new FileOutputStream ( entry . getDirtyFile ( index ) ) ) ; return NULL_OUTPUT_STREAM ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "property", "called", "app", ".", "name", "and", "set", "cf", ".", "host", "to", "equal", "app", ".", "name", ".", "Use"], "add_tokens": "Node appNameNode = doc . createElement ( \"app.name\" ) ;", "del_tokens": "Node appNameNode = doc . createElement ( \"cf.host\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "rebuildCachedFields", "()", "protected", "."], "add_tokens": "protected void rebuildCachedFields ( ) {", "del_tokens": "private void rebuildCachedFields ( ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "test", "for", "replaying", "object", "upload"], "add_tokens": "if ( entity . getContentLength ( ) >= 0 ) { headers . put ( HttpHeaders . CONTENT_LENGTH , String . valueOf ( entity . getContentLength ( ) ) ) ; } headers . put ( HttpHeaders . CONTENT_TYPE , entity . getContentType ( ) ) ; for ( Header header : method . getRequestHeaders ( ) ) { headers . put ( header . getName ( ) , header . getValue ( ) ) ; } headers . remove ( HttpHeaders . HOST ) ; headers . remove ( HttpHeaders . USER_AGENT ) ;", "del_tokens": "for ( Header header : method . getRequestHeaders ( ) ) { headers . put ( header . getName ( ) , header . getValue ( ) ) ; } headers . remove ( HttpHeaders . HOST ) ; headers . remove ( HttpHeaders . USER_AGENT ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "NPE", "when", "response", "page", "is", "null", "(", "Ajax", "anyone?", ")"], "add_tokens": "if ( responsePage == null || responsePage . isErrorPage ( ) ) {", "del_tokens": "if ( responsePage . isErrorPage ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Implement", "a", "sensible", "way", "to", "initialize", "logging"], "add_tokens": "static { LogbackLogging . setup ( ) ; }", "del_tokens": "// TODO: this is the wrong place to mess with loggers... if ( System . getenv ( \"MQLIGHT_JAVA_LOG\" ) != null ) { ( ( ch . qos . logback . classic . Logger ) LoggerFactory . getLogger ( org . slf4j . Logger . ROOT_LOGGER_NAME ) ) . setLevel ( ch . qos . logback . classic . Level . DEBUG ) ; } else { ( ( ch . qos . logback . classic . Logger ) LoggerFactory . getLogger ( \"com.github.oxo42.stateless4j\" ) ) . setLevel ( ch . qos . logback . classic . Level . WARN ) ; ( ( ch . qos . logback . classic . Logger ) LoggerFactory . getLogger ( org . slf4j . Logger . ROOT_LOGGER_NAME ) ) . setLevel ( ch . qos . logback . classic . Level . INFO ) ; }", "commit_type": "implement"}
{"commit_tokens": ["Adding", "jersey", "-", "server", "dependency", "explicitly"], "add_tokens": "accessLogLocation = accessLogLocation + replaceSlash ( serverData . getModule ( ) . getContext ( ) ) + \"-access.log\" ; private String replaceSlash ( String context ) { if ( context != null && context . contains ( \"/\" ) ) { return context . substring ( 0 , context . indexOf ( \"/\" ) ) ; } return context ; }", "del_tokens": "accessLogLocation = accessLogLocation + serverData . getModule ( ) . getContext ( ) . substring ( 0 , serverData . getModule ( ) . getContext ( ) . indexOf ( \"/\" ) ) + \"-access.log\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "local", "staxutils", ".", "it", "supports", "indent"], "add_tokens": "IndentingXMLEventWriter writer ; this . writer = new IndentingXMLEventWriter ( xmlOutputFactory . createXMLEventWriter ( writer ) ) ; // this.writer.setNewLine(System.getProperty(\"line.separator\"));", "del_tokens": "XMLEventWriter writer ; this . writer = new IndentingXMLEventWriter ( xmlOutputFactory . createXMLEventWriter ( writer ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "comment", "with", "total", "number", "of", "violations", "for", "stash"], "add_tokens": "// Add comment with number of violations String json = objectMapper . writeValueAsString ( new Comment ( reviewInput . message ) ) ; stashConnector . sendReview ( json ) ; fileComment . setText ( comment . message ) ; Anchor anchor = Anchor . builder ( ) . path ( key ) . srcPath ( key ) . line ( comment . line ) . lineType ( changeType . name ( ) ) . build ( ) ; fileComment . setAnchor ( anchor ) ;", "del_tokens": "fileComment . text = comment . message ; fileComment . anchor = new Anchor ( ) ; fileComment . anchor . path = key ; fileComment . anchor . srcPath = key ; fileComment . anchor . line = comment . line ; fileComment . anchor . lineType = changeType . name ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "@Secured", "annotation", "from", "link", "type", "dependencies", "of", "superfly", "-", "client"], "add_tokens": "private Class < ? extends Annotation > annotationClass ;", "del_tokens": "import org . springframework . security . annotation . Secured ; private Class < ? extends Annotation > annotationClass = Secured . class ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "my", "postgres", "stupidity", "."], "add_tokens": "import java . net . URL ; import org . postgresql . ds . PGSimpleDataSource ; private URL databaseUrl ; final PGSimpleDataSource ds = new PGSimpleDataSource ( ) ; ds . setServerName ( databaseUrl . getHost ( ) ) ; ds . setPortNumber ( databaseUrl . getPort ( ) ) ; String [ ] userInfo = databaseUrl . getUserInfo ( ) . split ( \":\" ) ; ds . setUser ( userInfo [ 0 ] ) ; ds . setPassword ( userInfo [ 1 ] ) ;", "del_tokens": "import org . apache . commons . dbcp . BasicDataSource ; private String databaseUrl ; BasicDataSource ds = new BasicDataSource ( ) ; ds . setUrl ( databaseUrl ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "tests", "for", "TransportOptions", "taking", "an", "InetAddress", "."], "add_tokens": "try { LOG . debug ( \"Opening table %s for project %s on host %s and port %s on transport %s\" , tableName . toString ( ) , options . getProjectId ( ) , options . getTransportOptions ( ) . getHost ( ) , options . getTransportOptions ( ) . getPort ( ) , options . getTransportOptions ( ) . getTransport ( ) ) ; } catch ( IOException ioe ) { LOG . error ( \"Failed to acquire transport options for logging\" , ioe ) ; }", "del_tokens": "LOG . debug ( \"Opening table %s for project %s on host %s and port %s on transport %s\" , tableName . toString ( ) , options . getProjectId ( ) , options . getTransportOptions ( ) . getHost ( ) , options . getTransportOptions ( ) . getPort ( ) , options . getTransportOptions ( ) . getTransport ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "CDI", "producer", "method", "handling", "to", "be", "able", "to", "handle", "parameterized"], "add_tokens": "import java . lang . reflect . ParameterizedType ; if ( implTpye instanceof ParameterizedType ) { beanTypes . add ( ( ParameterizedType ) implTpye ) ; Typed typedAnnotation = ( ( Class < ? > ) implTpye ) . getAnnotation ( Typed . class ) ; if ( typedAnnotation != null ) { for ( Class < ? > cls : typedAnnotation . value ( ) ) { beanTypes . add ( cls ) ; } } else { beanTypes . addAll ( getTypeClasses ( ( Class < ? > ) implTpye ) ) ; }", "del_tokens": "Typed typedAnnotation = ( ( Class < ? > ) implTpye ) . getAnnotation ( Typed . class ) ; if ( typedAnnotation != null ) { for ( Class < ? > cls : typedAnnotation . value ( ) ) { beanTypes . add ( cls ) ; } beanTypes . addAll ( getTypeClasses ( ( Class < ? > ) implTpye ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "some", "errors", "in", "the", "javadoc"], "add_tokens": "* this is < a href = \"http://repo1.maven.org/maven/\" > http : //repo1.maven.org/maven/</a> * @ return The { @ link UpdateInfo } of the latest version of the artifact * this is < a href = \"http://repo1.maven.org/maven/\" > http : //repo1.maven.org/maven/</a> * @ return The { @ link UpdateInfo } of the latest version of the artifact * this is < a href = \"http://repo1.maven.org/maven/\" > http : //repo1.maven.org/maven/</a> * @ return The { @ link UpdateInfo } of the latest version of the artifact * this is < a href = \"http://repo1.maven.org/maven/\" > http : //repo1.maven.org/maven/</a>", "del_tokens": "* this is { @ link http : //repo1.maven.org/maven/} * @ return The { @ link UpdateINfo } of the latest version of the artifact * this is { @ link http : //repo1.maven.org/maven/} * @ return The { @ link UpdateINfo } of the latest version of the artifact * this is { @ link http : //repo1.maven.org/maven/} * @ return The { @ link UpdateINfo } of the latest version of the artifact * this is { @ link http : //repo1.maven.org/maven/}", "commit_type": "fix"}
{"commit_tokens": ["removed", "Stream", "from", "Stage", "more", "unit", "tests"], "add_tokens": "return new Stage < T , U > ( Stream . of ( actions ) . map (", "del_tokens": "return new Stage ( Stream . of ( actions ) . map (", "commit_type": "remove"}
{"commit_tokens": ["Move", "from", "autowired", "to", "resource", "annotations"], "add_tokens": "@ Resource @ Resource", "del_tokens": "@ Autowired @ Autowired", "commit_type": "move"}
{"commit_tokens": ["changed", "example", "robotics", "dependecy", "to", "compile", "...", "need", "to", "produce", "an", "api", "dependency"], "add_tokens": "", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["use", "adb", "shell", "to", "dump", "view"], "add_tokens": "import com . google . common . collect . Lists ; String f = \"/data/local/tmp/uidump.xml\" ; adb . shell ( Lists . newArrayList ( \"uiautomator\" , \"dump\" , f ) ) ; File xml = this . getLogPath ( ) . resolve ( \"ui-\" + System . currentTimeMillis ( ) + \".xml\" ) . toFile ( ) ; this . adb . pull ( f , xml ) ; LOG . debug ( \"Save WindowHierarchy to {}\" , xml . getAbsolutePath ( ) ) ; return xml ;", "del_tokens": "String f = \"/data/local/tmp/view.txt\" ; uiDeviceStub . dumpWindowHierarchy ( f ) ; File txt = this . getLogPath ( ) . resolve ( \"view-\" + System . currentTimeMillis ( ) + \".txt\" ) . toFile ( ) ; this . adb . pull ( f , txt ) ; LOG . debug ( \"Save WindowHierarchy to {}\" , txt . getAbsolutePath ( ) ) ; return txt ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "inherited", "but", "exclude", "static", "and", "transient", "in", "data", "validation", "/", "persistence"], "add_tokens": "statement . setObject ( i + 1 , type . getField ( _params [ i ] . name ) . get ( object ) , _params [ i ] . type ) ;", "del_tokens": "Field field = type . getDeclaredField ( _params [ i ] . name ) ; field . setAccessible ( true ) ; statement . setObject ( i + 1 , field . get ( object ) , _params [ i ] . type ) ;", "commit_type": "allow"}
{"commit_tokens": ["improved", "hash", "to", "use", "guava"], "add_tokens": "Assert . assertEquals ( \"should be equal to hash val\" , \"d41d8cd98f00b204e9800998ecf8427e\" , hash . get ( ) ) ;", "del_tokens": "Assert . assertEquals ( \"should be equal to hash val\" , \"00e9cae5d45fcd7010bac74086d678a8\" , hash . get ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Removed", "an", "unnecessary", "check", "."], "add_tokens": "if ( ! StringUtils . hasUpperCase ( getTableName ( ) ) ) {", "del_tokens": "if ( ! StringUtils . hasLowerCase ( getTableName ( ) ) ) { tableName = getTableName ( ) + \"_HATBOX\" ; } else if ( ! StringUtils . hasUpperCase ( getTableName ( ) ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Add", "self", "-", "bootstrap", "feature", "for", "embedded", "config", "server"], "add_tokens": "import org . springframework . boot . autoconfigure . condition . ConditionalOnMissingBean ; @ ConditionalOnMissingBean ( EnvironmentRepository . class ) @ ConfigurationProperties ( \"spring.cloud.config.server\" ) public SpringApplicationEnvironmentRepository repository ( ) { return new SpringApplicationEnvironmentRepository ( ) ;", "del_tokens": "import org . springframework . context . annotation . ComponentScan ; @ ComponentScan @ Autowired private ConfigurableEnvironment environment ; public NativeEnvironmentRepository repository ( ) { return new NativeEnvironmentRepository ( environment ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "templating", "helper", "for", "bash", "plugin"], "add_tokens": "import net . roboconf . plugin . bash . template . InstanceTemplateHelper ; * @ throws IOException protected File generateTemplate ( File template , Instance instance ) throws IOException { File generated = File . createTempFile ( instance . getName ( ) , \".sh\" ) ; InstanceTemplateHelper . injectInstanceImports ( instance , template , generated ) ; return generated ;", "del_tokens": "protected File generateTemplate ( File template , Instance instance ) { return null ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "Consumes", ".", "ALL", "and", "logging", "request", "consumption"], "add_tokens": "if ( declaredConsumes . contains ( Consumes . ALL ) ) { log . debug ( \"{} will handle Request because it consumes '{}'\" , Util . toString ( method ) , Consumes . ALL ) ; return true ; } log . debug ( \"{} will handle Request because it consumes '{}'\" , Util . toString ( method ) , \"*/*\" ) ; log . debug ( \"{} will handle Request because it consumes '{}'\" , Util . toString ( method ) , type ) ; log . debug ( \"{} will handle Request because it consumes '{}'\" , Util . toString ( method ) , type ) ; if ( types . isEmpty ( ) ) { log . warn ( \"{} can not handle Request because neither 'Accept' nor 'Content-Type' are set and Route @Consumes '{}'\" , Util . toString ( method ) , declaredConsumes ) ; } else { log . warn ( \"{} can not handle Request for '{}' because Route @Consumes '{}'\" , Util . toString ( method ) , types , declaredConsumes ) ; }", "del_tokens": "log . debug ( \"{} consumes '{}'\" , Util . toString ( method ) , \"*/*\" ) ; log . debug ( \"{} consumes '{}'\" , Util . toString ( method ) , type ) ; log . debug ( \"{} consumes '{}'\" , Util . toString ( method ) , type ) ; log . warn ( \"{} can not consume Request for '{}'\" , Util . toString ( method ) , types ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "oracle", "dialect", "t", "odialect", "registry"], "add_tokens": "MYSQL ( new MysqlDialect ( ) ) , ORACLE ( new OracleDialect ( ) ) ;", "del_tokens": "MYSQL ( new MysqlDialect ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "fallback", "onto", "NIO", "in", "the", "event", "that", "epoll", "calsses", "are", "not", "available", "."], "add_tokens": "} catch ( ExceptionInInitializerError | NoClassDefFoundError e ) {", "del_tokens": "} catch ( ExceptionInInitializerError e ) {", "commit_type": "fix"}
{"commit_tokens": ["Made", "more", "user", "properties", "updatable", "."], "add_tokens": "existingUser . setAddress1 ( user . getAddress1 ( ) ) ; existingUser . setAddress2 ( user . getAddress2 ( ) ) ; existingUser . setBirthInfo ( user . getBirthInfo ( ) ) ; existingUser . setCity ( user . getCity ( ) ) ; existingUser . setCountry ( user . getCountry ( ) ) ; existingUser . setEmail ( user . getEmail ( ) . toLowerCase ( ) ) ; existingUser . setFirstName ( user . getFirstName ( ) ) ; existingUser . setLastName ( user . getLastName ( ) ) ; existingUser . setPhoneNumber1 ( user . getPhoneNumber1 ( ) ) ; existingUser . setPhoneNumber2 ( user . getPhoneNumber2 ( ) ) ; existingUser . setZipCode ( user . getZipCode ( ) ) ;", "del_tokens": "existingUser . setEmail ( user . getEmail ( ) . toLowerCase ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "console", "to", "window", ".", "Window", "is", "moveable", "and", "resizeable", "with", "mouse", "."], "add_tokens": "setSizePercent ( 50 , 50 ) ; setPositionPercent ( 50 , 50 ) ; hidden = ! hidden ;", "del_tokens": "//display.setTouchable(Touchable.disabled); //setSizePercent(50, 50); //setPositionPercent(50, 50); hidden = ! hidden ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", "test", "case", "in", "line", "-", "bot", "-", "spring", "-", "boot"], "add_tokens": "default BotApiResponse reply ( String replyToken , @ NonNull Message message ) return reply ( replyToken , Collections . singletonList ( message ) ) ;", "del_tokens": "default BotApiResponse reply ( String replyToken , Message messages ) return reply ( replyToken , Collections . singletonList ( messages ) ) ; boolean validateSignature ( @ NonNull String jsonText , @ NonNull String headerSignature ) throws LineBotAPIException ; / * * * Reads { @ link CallbackRequest } from the given json . * * @ param jsonText The text to be parsed . * @ return parsed { @ link CallbackRequest } object . * / CallbackRequest readCallbackRequest ( @ NonNull String jsonText ) throws LineBotAPIJsonProcessingException ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "servlet", "so", "that", "when", "a", "job", "finishes", "with", "an", "error", "the", "error", "is", "reported", "to", "the", "client", "."], "add_tokens": "import org . mapfish . print . servlet . job . SuccessfulPrintJob ; } else if ( metadata . get ( ) instanceof SuccessfulPrintJob ) { SuccessfulPrintJob succ = ( SuccessfulPrintJob ) metadata . get ( ) ; sendPdfFile ( succ , httpServletResponse , loader , pdfURI , inline ) ; } else if ( metadata . get ( ) instanceof FailedPrintJob ) { FailedPrintJob failedPrintJob = ( FailedPrintJob ) metadata . get ( ) ; error ( httpServletResponse , failedPrintJob . getError ( ) , HttpStatus . INTERNAL_SERVER_ERROR ) ; protected final void sendPdfFile ( final SuccessfulPrintJob metadata , final HttpServletResponse httpServletResponse ,", "del_tokens": "return ; sendPdfFile ( metadata . get ( ) , httpServletResponse , loader , pdfURI , inline ) ; protected final void sendPdfFile ( final CompletedPrintJob metadata , final HttpServletResponse httpServletResponse ,", "commit_type": "update"}
{"commit_tokens": ["Make", "channel", "a", "short", "-", "living", "object", "as", "it", "was", "before"], "add_tokens": "* < p > This function must be called before any other usage . < / p >", "del_tokens": "* < p > * This function must be called before any other usage .", "commit_type": "make"}
{"commit_tokens": ["implement", "predictive", "search", "for", "LOUDSTrie"], "add_tokens": "for ( String s : lt . predictiveSearch ( \"大阪城\")){", "del_tokens": "for ( String s : trie . predictiveSearch ( \"大阪城\")){", "commit_type": "implement"}
{"commit_tokens": ["Updated", "for", "translucent", "nav", "on", "Lollipop"], "add_tokens": "int translucentLolliPop = activity . getWindow ( ) . getDecorView ( ) . getSystemUiVisibility ( ) ; boolean isTranslucentLolliPop = ( translucentLolliPop == View . SYSTEM_UI_FLAG_LAYOUT_HIDE_NAVIGATION ) ; if ( isTranslucent || isTranslucentLolliPop ) {", "del_tokens": "if ( isTranslucent ) {", "commit_type": "update"}
{"commit_tokens": ["Using", "new", "self", "-", "validating", "Path", "class", "for", "book", "names", "and", "paths", "."], "add_tokens": "* This will be < code > \"/\" < / code > for the root book , * otherwise matches { @ link # getPrefix ( ) } . * The prefix of the book this refers to , useful for direct path concatenation . * This will be < code > \"\" < / code > for the root book < code > \"/\" < / code > , * otherwise matches { @ link # getPath ( ) } .", "del_tokens": "* The prefix of the book this refers to . * This will be < code > \"\" < / code > for the root book < code > \"/\" < / code > .", "commit_type": "use"}
{"commit_tokens": ["Use", "different", "names", "for", "models"], "add_tokens": "this ( \"english.all.3class.distsim.crf.ser.gz\" , \"english.all.3class.distsim.prop\" ) ;", "del_tokens": "this ( \"all.3class.distsim.crf.ser.gz\" , \"all.3class.distsim.prop\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "application", "/", "x", "-", "www", "-", "form", "-", "urlencoded", "POST", "queries", "to", "allow", "for", "requests", "that", "may", "exceed", "the", "URL", "max", "length", "."], "add_tokens": "import com . dottydingo . hyperion . exception . BadRequestException ; try { return Integer . parseInt ( value ) ; } catch ( NumberFormatException e ) { throw new BadRequestException ( e . getMessage ( ) ) ; }", "del_tokens": "return Integer . parseInt ( value ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "license", "information", "to", "file", "."], "add_tokens": "package org . wikidata . wdtk . wikibaseapi ; / * * # % L * Wikidata Toolkit Wikibase API * % % * Copyright ( C ) 2014 Wikidata Toolkit Developers * % % * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * # L % * /", "del_tokens": "package org . wikidata . wdtk . wikibaseapi ;", "commit_type": "add"}
{"commit_tokens": ["remove", "all", "double", "/", "single", "quotes", "."], "add_tokens": "* Replaces all . with _ and removes all spaces and double / single quotes . clean = clean . replace ( \"\\\"\" , \"\" ) ; clean = clean . replace ( \"'\" , \"\" ) ;", "del_tokens": "* Replaces all . with _ and removes all spaces .", "commit_type": "remove"}
{"commit_tokens": ["Makes", "static", "members", "final", "."], "add_tokens": "private static final String SQ = \"'\" ; private static final String DQ = \"\\\"\" ; private static final Tag htmlTag = Tag . valueOf ( \"html\" ) ; private static final Tag headTag = Tag . valueOf ( \"head\" ) ; private static final Tag bodyTag = Tag . valueOf ( \"body\" ) ; private static final Tag titleTag = Tag . valueOf ( \"title\" ) ; private final LinkedList < Element > stack ; private final TokenQueue tq ; private final Document doc ;", "del_tokens": "private static String SQ = \"'\" ; private static String DQ = \"\\\"\" ; private static Tag htmlTag = Tag . valueOf ( \"html\" ) ; private static Tag headTag = Tag . valueOf ( \"head\" ) ; private static Tag bodyTag = Tag . valueOf ( \"body\" ) ; private static Tag titleTag = Tag . valueOf ( \"title\" ) ; private LinkedList < Element > stack ; private TokenQueue tq ; private Document doc ;", "commit_type": "make"}
{"commit_tokens": ["fix", "bug", "of", "generate", "source", "for", "enumertation", "message", "faield"], "add_tokens": "try { Enum value = Enum . valueOf ( cls , name ) ; if ( value instanceof EnumReadable ) { code . append ( ( ( EnumReadable ) value ) . value ( ) ) ; } else { code . append ( value . ordinal ( ) ) ; } code . append ( \";\\n\" ) ; } catch ( Exception e ) { continue ;", "del_tokens": "Enum value = Enum . valueOf ( cls , name ) ; if ( value instanceof EnumReadable ) { code . append ( ( ( EnumReadable ) value ) . value ( ) ) ; } else { code . append ( value . ordinal ( ) ) ; code . append ( \";\\n\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "to", "penalty", "of", "death", "."], "add_tokens": ". penaltyDeath ( ) . penaltyDeath ( )", "del_tokens": ". penaltyLog ( ) . penaltyLog ( )", "commit_type": "update"}
{"commit_tokens": ["Added", "some", "public", "setters", "to", "ScriptableSource", "in", "order", "to", "use", "it", "programatically"], "add_tokens": "public void init ( ) throws IllegalStateException , IllegalArgumentException { public void setInput ( Path input ) { this . input = input ; } public void setScriptFile ( String scriptFile ) { this . scriptFile = scriptFile ; try { this . script = new FileReader ( this . scriptFile ) ; } catch ( FileNotFoundException ex ) { throw new IllegalStateException ( \"Cannot read script file \" + this . scriptFile , ex ) ; } }", "del_tokens": "void init ( ) throws IllegalStateException , IllegalArgumentException {", "commit_type": "add"}
{"commit_tokens": ["Add", "imports", "in", "sorted", "order", "for", "Courier", "IntelliJ", "plugin"], "add_tokens": "import com . intellij . psi . PsiElement ; boolean added = false ; for ( CourierImportDeclaration existing : importDecls . getImportDeclarationList ( ) ) { if ( importDecl . getFullname ( ) . toString ( ) . compareTo ( existing . getFullname ( ) . toString ( ) ) < 0 ) { importDecls . addBefore ( importDecl , existing ) ; added = true ; break ; } } if ( ! added ) { importDecls . add ( importDecl ) ; }", "del_tokens": "importDecls . add ( importDecl ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "history", "deletion", "after", "dropping", "of", "component", "."], "add_tokens": "private static boolean migrate = false ; private static boolean drop = false ; private static void showUsage ( ) { System . out . println ( \"Usage: <DDL.jar> (--drop | --migrate)\" ) ; } public static void main ( String [ ] args ) throws Exception { if ( args . length == 0 ) { showUsage ( ) ; return ; } for ( String arg : args ) { if ( \"--drop\" . equals ( arg ) ) { drop = true ; } else if ( \"--migrate\" . equals ( arg ) ) { migrate = true ; } } if ( drop ) { runDropAll ( ) ; } if ( migrate ) { runTransform ( ) ; } } logMigrationEnd ( metadata ) ; private void logMigrationEnd ( TransformationMetadata metadata ) { logInfo ( \"done.\" ) ; } logInfo ( \"\\n(!)SKIPPED: \" + metadata . getComponentName ( ) + \" \" + metadata . getDeveloper ( ) + \" (\" + metadata . getComment ( ) + \")\" ) ;", "del_tokens": "logInfo ( \"\\n\" + metadata . getComponentName ( ) + \" \" + metadata . getDeveloper ( ) + \" (\" + metadata . getComment ( ) + \"):\\n\\t(!)SKIPPED \" + metadata . getCommand ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "default", "port", "to", "443", "since", "default", "HTTP", "scheme", "is", "HTTPS"], "add_tokens": "public static final int DEFAULT_PORT = 443 ;", "del_tokens": "public static final int DEFAULT_PORT = 80 ;", "commit_type": "change"}
{"commit_tokens": ["fix", "cursor", "position", "during", "search"], "add_tokens": "out . append ( result ) ; moveCursor ( - buffer . getCursor ( ) + cursor ) ;", "del_tokens": "out . append ( result ) ; //.append(\"\\u001b[K\"); //moveCursor(cursor+1);", "commit_type": "fix"}
{"commit_tokens": ["Adding", "simplified", "service", "impl", "constructors", "and", "more", "simplified", "service", "action", "methods", "for", "iam", "and", "glacier", "."], "add_tokens": "this . model = V1ModelLoader . load ( interfaceType , annotation . model ( ) ) ;", "del_tokens": "import java . io . IOException ; import java . io . InputStream ; try ( InputStream stream = interfaceType . getResourceAsStream ( annotation . model ( ) ) ) { this . model = V1ModelLoader . load ( stream ) ; } catch ( IOException exception ) { throw new IllegalStateException ( \"Unable to load service model \" + annotation . model ( ) , exception ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "pretty", "print", "method", "for", "Range"], "add_tokens": "return Range . between ( ( range . getFrom ( ) * value ) / 100.0 , ( range . getTo ( ) * value ) / 100.0 ) . withType ( range . getRangeType ( ) ) ;", "del_tokens": "return Range . between ( ( range . getFrom ( ) * value ) / 100.0 , ( range . getTo ( ) * value ) / 100.0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "DbExtractor", "NPE", "with", "timezone", "converted", "values"], "add_tokens": "if ( attribute instanceof TimestampAttribute && value != null )", "del_tokens": "if ( attribute instanceof TimestampAttribute )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "exception", "type", "and", "changed", "non", "compiling", "function", "call"], "add_tokens": "throw new CommunicationException ( \"Waiting aborted - not connected!\" ) ;", "del_tokens": "throw new WebDriverException ( \"Waiting aborted - not connected!\" ) ;", "commit_type": "change"}
{"commit_tokens": ["changing", "LDAP", "default", "Logger", "to", "stdout"], "add_tokens": "import com . innoq . liqid . log . LogSystemOutput ; private Log log = new LogSystemOutput ( ) ;", "del_tokens": "private Log log = new LogZero ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "scaling", "factor", "to", "the", "aggresive", "autoscaler"], "add_tokens": "Map < String , Integer > shortfall = shortfallEvaluator . getShortfall ( hostAttributeGroupMap . keySet ( ) , autoScalerInput . getFailures ( ) , autoScaleRules ) ;", "del_tokens": "Map < String , Integer > shortfall = shortfallEvaluator . getShortfall ( hostAttributeGroupMap . keySet ( ) , autoScalerInput . getFailures ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "helper", "function", "to", "copy", "dates"], "add_tokens": "/ * * * Copies the date , since Date objects are mutable . * / private Date copyDate ( Date date ) { return ( date != null ) ? new Date ( date . getTime ( ) ) : null ; } this . expires = copyDate ( expires ) ; this . notBefore = copyDate ( notBefore ) ; this . expires = copyDate ( expires ) ; this . notBefore = copyDate ( notBefore ) ;", "del_tokens": "this . expires = ( expires != null ) ? new Date ( expires . getTime ( ) ) : null ; this . notBefore = ( notBefore != null ) ? new Date ( notBefore . getTime ( ) ) : null ; this . expires = ( expires != null ) ? new Date ( expires . getTime ( ) ) : null ; this . notBefore = ( notBefore != null ) ? new Date ( notBefore . getTime ( ) ) : null ;", "commit_type": "use"}
{"commit_tokens": ["Improve", "dependency", "linking", "through", "interface", "method", "calls"], "add_tokens": "private Map < DependencyNode , CtClass < ? > > dependencyNodeToAnyStagedClass = new Object2ObjectOpenCustomHashMap < > ( identityHashedEquivalence ( ) ) ; } public void bindDependencyNodeToAnyStagedClass ( DependencyNode node , CtClass < ? > ctClass ) { if ( dependencyNodeToAnyStagedClass . put ( node , ctClass ) != null ) throw new AssertionError ( ) ; } public CtClass < ? > getAnyStagedClassByDependencyNode ( DependencyNode node ) { return dependencyNodeToAnyStagedClass . get ( node ) ;", "del_tokens": "", "commit_type": "improve"}
{"commit_tokens": ["Adding", "metadata", "to", "serializer", "/", "deserializer"], "add_tokens": "import java . util . Iterator ; Tuple tuple = new Tuple ( key , value , visibility ) ; JsonNode metadataArray = root . get ( \"metadata\" ) ; if ( metadataArray != null ) { Iterator < JsonNode > metadata = metadataArray . iterator ( ) ; while ( metadata . hasNext ( ) ) { JsonNode metadataItem = metadata . next ( ) ; String metaKey = metadataItem . get ( \"key\" ) . asText ( ) ; String alias = metadataItem . get ( \"type\" ) . asText ( ) ; String normalized = metadataItem . get ( \"value\" ) . asText ( ) ; try { tuple . setMetadataValue ( metaKey , typeRegistry . decode ( alias , normalized ) ) ; } catch ( TypeDecodingException e ) { throw new RuntimeException ( e ) ; } } } return tuple ;", "del_tokens": "return new Tuple ( key , value , visibility ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "PostgreSQL", "integration", "test", "to", "set", "the", "default", "schema", "."], "add_tokens": "import liquibase . database . DatabaseConnection ; final Liquibase liquibase = createLiquibase ( changeLogFile , resourceAccessor , jdbcConnection ) ; / * * * Creates the < code > Liquibase < / code > instance . * * @ param changeLogFile * the database change log file name . * @ param resourceAccessor * the resource accessor . * @ param databaseConnection * the database connection . * @ return returns the new instance . * @ throws LiquibaseException * if unable to create the instance . * / protected Liquibase createLiquibase ( final String changeLogFile , final ResourceAccessor resourceAccessor , final DatabaseConnection databaseConnection ) throws LiquibaseException { return new Liquibase ( changeLogFile , resourceAccessor , databaseConnection ) ; }", "del_tokens": "import org . testng . annotations . AfterMethod ; @ AfterMethod System . out . println ( \"Cleaning up the database\" ) ; final Liquibase liquibase = new Liquibase ( changeLogFile , resourceAccessor , jdbcConnection ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "additional", "api", "scopes", "clarify", "comments"], "add_tokens": "* This is the main Genomics API scope that is required by nearly all API calls . / * * * The BigQuery API scope is needed to export variants to BigQuery . * / public static final String BIGQUERY_SCOPE = \"https://www.googleapis.com/auth/bigquery\" ; / * * * The Devstorage API scope is needed to import from or export to Google Cloud Storage . * / public static final String DEVSTORAGE_SCOPE = \"https://www.googleapis.com/auth/devstorage.read_write\" ; * Loads a client secrets file into an GoogleClientSecrets object that can be used to * send authorized requests to the Google Genomics API . * @ throws java . io . FileNotFoundException if the client secrets file doesn 't exist.", "del_tokens": "* This is the main Genomics API scope that will be needed by nearly all clients . * @ throws java . io . FileNotFoundException if the client secrets file doesn 't exist * ( this usually should be passed on to the user )", "commit_type": "add"}
{"commit_tokens": ["Move", "HTML", "URL", "query", "parameters", "into", "a", "common", "interface"], "add_tokens": "import forplay . html . HtmlUrlParameters . Renderer ; boolean useGlFromFlag = Renderer . shouldUseGL ( ) ;", "del_tokens": "import forplay . html . HtmlGraphics . Renderer ; String renderer = getUrlParameter ( Renderer . URL_QUERY_PARAMETER ) ; boolean useGlFromFlag = ( renderer == null || Renderer . GL . equals ( renderer ) ) ;", "commit_type": "move"}
{"commit_tokens": ["change", "name", "of", "ignoreDependency", "parameter", "to", "ignoreDependencyPattern", ";", "clean", "up", "some", "code", ";", "reformat", "for", "consistency"], "add_tokens": "* @ param ignoreDependencyPattern public void setIgnoreDependencyPattern ( String ignoreDependencyPattern ) { Pattern pattern = Pattern . compile ( ignoreDependencyPattern ) ; statCache . setIgnoreDependencyPattern ( pattern ) ; public void setIgnoreDependencyPattern ( Pattern ignoreDependencyPattern ) { + fileName + \"' against pattern '\" + ignoreDependencyPattern . pattern ( ) + \"'\" ) ;", "del_tokens": "* @ param ignoreDependency public void setIgnoreDependency ( String ignoreDependency ) { Pattern pattern = Pattern . compile ( ignoreDependency ) ; statCache . setIgnoreDependency ( pattern ) ; public void setIgnoreDependency ( Pattern ignoreDependencyPattern ) { + fileName + \"' against <<<\" + ignoreDependencyPattern . pattern ( ) + \">>>\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Adding", "null", "check", "in", "LtiLaunchValidator"], "add_tokens": "if ( arg != null && arg . getClass ( ) . equals ( LtiVerificationResult . class ) ) {", "del_tokens": "if ( arg . getClass ( ) . equals ( LtiVerificationResult . class ) ) {", "commit_type": "add"}
{"commit_tokens": ["removed", "unused", "props", "(", "there", "are", "still", "some", "to", "be", "removed", ")", "."], "add_tokens": "// TODO danny, is this used? // TODO danny, is this used? // TODO danny, can these be removed? * default is Firefox . private static String browserValue = \"firefox\" ;", "del_tokens": "private static String siteIndexablePath = \"site.indexable.path\" ; private static String baseUrl = \"site.base.url\" ; private static String formPropertiesValue = \"forms.properties\" ; private static String seleniumTestsuitePath = \"selenium.testsuite.path\" ; private static String maxHistorySizeText = \"history.maxsize\" ; * default is IE . private static String browserValue = \"ie\" ;", "commit_type": "remove"}
{"commit_tokens": ["Removing", "some", "comments", "and", "updating", "constants"], "add_tokens": "* Maximum size of file that be loaded into raw table : 500 MB private final static long DEFAULT_RAW_FILE_SIZE_LIMIT = 524288000 ; long maxFileSize = DEFAULT_RAW_FILE_SIZE_LIMIT ;", "del_tokens": "* Maximum size of file that be loaded into raw table : 779 MB private final static int DEFAULT_RAW_FILE_SIZE_LIMIT = 817387220 ; long maxFileSize = Long . MAX_VALUE ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "the", "ElasticSearch", "API", "to", "support", "searching", "across", "multiple", "indices", "."], "add_tokens": "import com . scaleset . search . Query ; String [ ] indicesForQuery ( Query query ) throws Exception ;", "del_tokens": "import com . scaleset . search . Query ; import java . util . List ;", "commit_type": "update"}
{"commit_tokens": ["Fixing", "squid", ":", "S1161", "-", "@Override", "annotation", "should", "be", "used", "on", "any", "method", "overriding", "."], "add_tokens": "@ Override @ Override public boolean setUserAsUser ( Node node , String uid , String password ) throws Exception { @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override public Set < Node > getUsersForGroup ( Node group ) { @ Override @ Override @ Override @ Override @ Override @ Override @ Override", "del_tokens": "public boolean setUserAsUser ( Node node , String uid , String password ) throws Exception { public Set < Node > getUsersForGroup ( Node group ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "duplicate", "handlers"], "add_tokens": "boolean passed = false ; try { String logLevel = baseConfigReader . getSingleValue ( ChorusConfigProperty . LOG_LEVEL ) ; setLogLevel ( logLevel ) ; ExecutionToken t = startTests ( ) ; List < FeatureToken > features = run ( t , ConfigMutator . NULL_MUTATOR ) ; endTests ( t , features ) ; passed = t . isPassedAndFullyImplemented ( ) ; } catch ( InterpreterPropertyException e ) { ChorusOut . err . println ( e . getMessage ( ) ) ; ConfigReader . logHelp ( ) ; } catch ( Throwable t ) { ChorusOut . err . println ( t . getMessage ( ) ) ; t . printStackTrace ( ChorusOut . err ) ; } return passed ;", "del_tokens": "String logLevel = baseConfigReader . getSingleValue ( ChorusConfigProperty . LOG_LEVEL ) ; setLogLevel ( logLevel ) ; ExecutionToken t = startTests ( ) ; List < FeatureToken > features = run ( t , ConfigMutator . NULL_MUTATOR ) ; endTests ( t , features ) ; return t . isPassedAndFullyImplemented ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "css", "on", "index", "page"], "add_tokens": "import com . uaihebert . uaimockserver . servlet . CssServlet ; servlet ( \"JavascriptServlet\" , JavascriptServlet . class ) . addMapping ( \"/javascript\" ) , servlet ( \"CssServlet\" , CssServlet . class ) . addMapping ( \"/css\" )", "del_tokens": "servlet ( \"JavascriptServlet\" , JavascriptServlet . class ) . addMapping ( \"/javascript\" )", "commit_type": "add"}
{"commit_tokens": ["use", "the", "factory", "configuration", "for", "the", "CC", "encoder"], "add_tokens": "import org . logicng . configurations . Configuration ; import org . logicng . configurations . ConfigurationType ; Configuration ccConfig = f . configurationFor ( ConfigurationType . CC_ENCODER ) ; if ( ccConfig == null ) ccConfig = new CCConfig . Builder ( ) . build ( ) ; this . config = ( CCConfig ) ccConfig ;", "del_tokens": "this . config = new CCConfig . Builder ( ) . build ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "deleteTrigger", "()", "and", "deleteTarget", "()", "methods"], "add_tokens": "public void deleteTarget ( long targetId ) { complete ( submit ( req ( \"DELETE\" , tmpl ( \"/targets/{id}.json\" ) . set ( \"id\" , targetId ) ) , handleStatus ( ) ) ) ; } public void deleteTrigger ( long triggerId ) { complete ( submit ( req ( \"DELETE\" , tmpl ( \"/triggers/{id}.json\" ) . set ( \"id\" , triggerId ) ) , handleStatus ( ) ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "in", "byte", "-", "to", "-", "register", "array", "conversion", "."], "add_tokens": "for ( int i = 0 , j = 0 ; i < dst . length ; i ++ , j += 2 ) dst [ i ] = ( ( src [ j ] & 0xff ) << 8 ) | ( src [ j + 1 ] & 0xff ) ;", "del_tokens": "for ( int i = 0 ; i < dst . length ; i ++ ) dst [ i ] = ( ( src [ i ] & 0xff ) << 8 ) | ( src [ i + 1 ] & 0xff ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "reconnection", "while", "remote", "slave", "not", "active", "and", "keepAlive", "flag", "is", "set", "."], "add_tokens": "import com . sbpinvertor . modbus . net . ModbusTransport ; ModbusTransport transport = getConnection ( ) . getTransport ( ) ; if ( transport == null ) throw new IOException ( \"transport is null\" ) ; transport . send ( msg ) ;", "del_tokens": "getConnection ( ) . getTransport ( ) . send ( msg ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "added", "reverse", "prefetch", "and", "optimized", "with", "shifts", "."], "add_tokens": "* logical blockaddress to read data from . * empty byte array to write read data to . This byte array must be a * multiple of blocksize . * logical blockaddress to write data to . * byte array with the data to write . This byte array must be a * multiple of blocksize .", "del_tokens": "* blockaddress to read data from . * empty byte array to write read data to . * blockaddress to write data to . * byte array with the data to write .", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "implementations", ".", "Test", "cases", "to", "follow", "."], "add_tokens": "return parse ( claimsJwt , new JwtHandlerAdapter < Jwt < Header , Claims > > ( ) { @ Override public Jwt < Header , Claims > onClaimsJwt ( Jwt < Header , Claims > jwt ) { return jwt ; } } ) ; return parse ( plaintextJws , new JwtHandlerAdapter < Jws < String > > ( ) { @ Override public Jws < String > onPlaintextJws ( Jws < String > jws ) { return jws ; } } ) ; return parse ( claimsJws , new JwtHandlerAdapter < Jws < Claims > > ( ) { @ Override public Jws < Claims > onClaimsJws ( Jws < Claims > jws ) { return jws ; } } ) ;", "del_tokens": "return null ; return null ; return null ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "swagger", "petstore", "example", "resources", "to", "start", "generating", "openapi", ".", "json"], "add_tokens": "writer . write ( '{' ) ; writer . write ( '}' ) ;", "del_tokens": "writer . write ( \"{\" ) ; writer . write ( \"}\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "broken", "build", "."], "add_tokens": "* @ param < T > for backward compatibility public interface LookupService < T > {", "del_tokens": "public interface LookupService {", "commit_type": "fix"}
{"commit_tokens": ["add", "fix", "parsing", "error", "for", "get", "an", "offers"], "add_tokens": "//TODO[VNi]: API error: when an offer is deleted, the subscription can not be serialized, because offer is empty array instead of null. //TODO[VNi]: Remove this line after fix String dump = dataNode . toString ( ) . replaceAll ( \"offer\\\":\\\\[\\\\]\" , \"offer\\\":null\" ) ; ; return ( T ) PaymillContext . getJacksonParser ( ) . readValue ( dump , clazz ) ;", "del_tokens": "return ( T ) PaymillContext . getJacksonParser ( ) . readValue ( dataNode . toString ( ) , clazz ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "override", "scripts", "."], "add_tokens": "String override = System . getProperty ( \"com.documents4j.conversion.msoffice.\" + path . substring ( 1 ) ) ; if ( override == null ) { Resources . asByteSource ( Resources . getResource ( getClass ( ) , path ) ) . copyTo ( Files . asByteSink ( script ) ) ; } else { Files . asByteSource ( new File ( override ) ) . copyTo ( Files . asByteSink ( script ) ) ; }", "del_tokens": "Resources . asByteSource ( Resources . getResource ( getClass ( ) , path ) ) . copyTo ( Files . asByteSink ( script ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "for", "rare", "race", "condition", "in", "JDBC", "storable", "reload", "after", "update", "."], "add_tokens": "( ! mFeatures . contains ( MasterFeature . UPDATE_FULL ) ) && ( ! mFeatures . contains ( MasterFeature . UPDATE_TXN ) ) )", "del_tokens": "( ! mFeatures . contains ( MasterFeature . UPDATE_FULL ) ) )", "commit_type": "fix"}
{"commit_tokens": ["implemented", "<clinit", ">", "to", "get", "exact", "method", "object", "from", "generated", "class"], "add_tokens": "* @ version $ Id : NoOpInterceptor . java , v 1.5 2002 / 09 / 26 18 : 57 : 13 baliuka Exp $", "del_tokens": "* @ version $ Id : NoOpInterceptor . java , v 1.4 2002 / 09 / 25 19 : 12 : 50 baliuka Exp $", "commit_type": "implement"}
{"commit_tokens": ["Updating", "deps", "/", "gradle", "adding", "in", "editorconfig", "(", "four", "spaces", "seems", "to", "be", "the", "default", ")", "formatting", "accordingly", "."], "add_tokens": "public GoogleAuthenticationService ( String apiKey , String appSecret ) { super ( new GoogleConnectionFactory ( apiKey , appSecret ) ) ; }", "del_tokens": "public GoogleAuthenticationService ( String apiKey , String appSecret ) { super ( new GoogleConnectionFactory ( apiKey , appSecret ) ) ; }", "commit_type": "update"}
{"commit_tokens": ["Moving", "to", "https", "&", "small", "cleanup"], "add_tokens": "static final private String proto = \"https\" ; static final private int port = 443 ; String path = \"/\" + apiVersion + \"/projects/\" + projectId + \"/\" + endpoint ; URL url = new URL ( proto , host , port , path ) ; conn . setRequestProperty ( \"Content-Type\" , \"application/json\" ) ; conn . setRequestProperty ( \"Authorization\" , \"OAuth \" + token ) ; conn . setRequestProperty ( \"User-Agent\" , \"IronMQ Java Client\" ) ;", "del_tokens": "static final private String proto = \"http\" ; String path = \"/\" + apiVersion + \"/projects/\" + projectId + \"/\" + endpoint + \"?oauth=\" + token ; URL url = new URL ( proto , host , path ) ; conn . setRequestProperty ( \"Content-Type\" , \"application/json\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "the", "DBContentSpecProvider", "to", "return", "the", "correct", "text", "representation", "."], "add_tokens": "import org . jboss . pressgang . ccms . contentspec . utils . ContentSpecUtilities ; if ( contentSpecWrapper . getFailed ( ) != null ) { return ContentSpecUtilities . fixFailedContentSpec ( contentSpecWrapper , contentSpec . toString ( ) ) ; } else { return contentSpec . toString ( ) ; }", "del_tokens": "return contentSpec . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "user", "field", "protected", "."], "add_tokens": "protected final IUser user ;", "del_tokens": "private final IUser user ;", "commit_type": "make"}
{"commit_tokens": ["Add", "a", "separate", "method", "of", "resource", "url", "and", "resource", "url", "base", "."], "add_tokens": "handleDelete ( getResourceUrl ( ) ) ; //There is a reason why this doesn't have a trailing slash return new URL ( getNamespacedUrl ( ) , name ) ; } protected URL getResourceUrl ( String context ) throws MalformedURLException { URL baseUrl = new URL ( getNamespacedUrl ( ) , name + \"/\" ) ; if ( context . startsWith ( \"/\" ) ) { return new URL ( baseUrl , context . substring ( 1 ) ) ; } return new URL ( baseUrl , context ) ; * * @ param r The { @ link com . ning . http . client . Response } object . * @ param expectedStatusCode The expected status code . * @ throws KubernetesClientException When the response code is not the expected .", "del_tokens": "import io . fabric8 . kubernetes . client . KubernetesClient ; handleDelete ( new URL ( getNamespacedUrl ( ) , name ) ) ; * @ param r The { @ link com . ning . http . client . Response } object . * @ param expectedStatusCode The expected status code . * @ throws KubernetesClientException When the response code is not the expected .", "commit_type": "add"}
{"commit_tokens": ["Add", "Loading", "widget", "onMeasure", "logic", "to", "init", "size"], "add_tokens": "* Changed 10 / 23 / 2015 public LoadingCircleDrawable ( ) { super ( ) ; } public LoadingCircleDrawable ( int minSize ) { super ( minSize ) ; }", "del_tokens": "* Changed 10 / 20 / 2015", "commit_type": "add"}
{"commit_tokens": ["move", "fetchColumnFamily", "for", "property", "soft", "delete"], "add_tokens": "scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_HIDDEN ) ; scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_SOFT_DELETE ) ; scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_HIDDEN ) ; scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_SOFT_DELETE ) ;", "del_tokens": "scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_SOFT_DELETE ) ; scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_HIDDEN ) ; scanner . fetchColumnFamily ( AccumuloElement . CF_PROPERTY_HIDDEN ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "IllegalStateException", "during", "parse", "error", "recovery", "of", "testNot", "()", "rules"], "add_tokens": "return inverted ? Characters . ALL_EXCEPT_EMPTY . remove ( characters ) : characters ;", "del_tokens": "return inverted ? Characters . ALL . remove ( characters ) : characters ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "stack", "overflow", "bug", "in", "KEEP_ARRAYS", "mode", "when", "null", "value", "occurs"], "add_tokens": "} else if ( val . isObject ( ) ) { if ( val . isArray ( ) ) { return newJsonifyArrayList ( ) ; } else if ( val . isObject ( ) ) { return newJsonifyLinkedHashMap ( ) ; }", "del_tokens": "} else { if ( val . isArray ( ) ) return newJsonifyArrayList ( ) ; if ( val . isObject ( ) ) return newJsonifyLinkedHashMap ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "bus", "temporarily", "as", "it", "is", "broken", "with", "the", "changes", "to", "spring", "-", "cloud", "-", "bus"], "add_tokens": "public class SampleConsulApplication /*implements ApplicationListener<SimpleRemoteEvent>*/ { / * @ Bean } * / / * @ Override } * /", "del_tokens": "import org . springframework . cloud . bus . jackson . SubtypeModule ; import org . springframework . cloud . consul . bus . SimpleRemoteEvent ; import org . springframework . context . ApplicationListener ; public class SampleConsulApplication implements ApplicationListener < SimpleRemoteEvent > { @ Bean } @ Override }", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "some", "unit", "-", "tests", "."], "add_tokens": "byte [ ] respBodyBytes = ByteBufUtils . toBytes ( response . getBodyStream ( ) . toBlocking ( ) . single ( ) ) ; Assert . assertNotNull ( respBodyBytes ) ; Assert . assertEquals ( body . length , respBodyBytes . length ) ;", "del_tokens": "Assert . assertNotNull ( response . getBody ( ) ) ; Assert . assertEquals ( body . length , response . getBody ( ) . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "more", "generic", "error", "message"], "add_tokens": "out . println ( \"Error while processing request:\" ) ; LOGGER . error ( \"Error while processing request: \" + message ) ; out . println ( \"Error while processing request:\" ) ; BaseMapServlet . LOGGER . error ( \"Error while processing request\" , e ) ;", "del_tokens": "out . println ( \"Error while generating PDF:\" ) ; LOGGER . error ( \"Error while generating PDF: \" + message ) ; out . println ( \"Error while generating PDF:\" ) ; BaseMapServlet . LOGGER . error ( \"Error while generating PDF\" , e ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "protocol", "and", "precision", "for", "timestamp"], "add_tokens": "new InfluxDbHttpSender ( config . influxdbProtocol , config . influxdbHost , config . influxdbPort ,", "del_tokens": "new InfluxDbHttpSender ( config . influxdbHost , config . influxdbPort ,", "commit_type": "add"}
{"commit_tokens": ["created", "new", "2", "version", "of", "secure", "utils"], "add_tokens": "* @ deprecated Use SecurePropertiesUtils2", "del_tokens": "*", "commit_type": "create"}
{"commit_tokens": ["Updated", "select", "to", "avoid", "rare", "100%", "CPU", "usage", "."], "add_tokens": "synchronized ( updateLock ) { // Blocks to avoid a select while the selector is used to bind the server connection. } int select = 0 ; if ( timeout > 0 ) { select = selector . select ( timeout ) ; } else { select = selector . selectNow ( ) ; } if ( select == 0 ) { Thread . yield ( ) ; return ;", "del_tokens": "synchronized ( updateLock ) { // Blocks to avoid a select while the selector is used to establish a new connection. if ( timeout > 0 ) selector . select ( timeout ) ; else selector . selectNow ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Adds", "some", "hardening", "around", "accepting", "content"], "add_tokens": "import java . util . logging . Logger ; import static java . util . logging . Level . FINEST ; private static final Logger LOGGER = Logger . getLogger ( JsonCodec . class . getName ( ) ) ; if ( LOGGER . isLoggable ( FINEST ) ) { LOGGER . log ( FINEST , adapter + \" could not read \" + new String ( bytes , UTF_8 ) , e ) ; } if ( LOGGER . isLoggable ( FINEST ) ) { LOGGER . log ( FINEST , adapter + \" could not write \" + value , e ) ; }", "del_tokens": "return null ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "NullPointerException", "if", "a", "response", "has", "no", "body"], "add_tokens": "if ( response . getBody ( ) != null && ! response . getBody ( ) . isArray ( ) && response . getBody ( ) . getObject ( ) . has ( \"retry_after\" ) ) {", "del_tokens": "if ( ! response . getBody ( ) . isArray ( ) && response . getBody ( ) . getObject ( ) . has ( \"retry_after\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "tests", "for", "L3", "sif", "(", "in", "fact", "copied", ";", "ideally", "tests", "should", "check", "the", "output", "and", "not", "only", "that", "there", "are", "no", "exceptions", "...", ")", ";", "XrefImpl", "tiString", "simplified", "(", "similar", "to", "L2", ")", "."], "add_tokens": "return getDb ( ) + ( ( getDbVersion ( ) == null ) ? \"\" : \".\" + getDbVersion ( ) ) + \":\" + getId ( ) + ( ( getIdVersion ( ) == null ) ? \"\" : \".\" + getIdVersion ( ) ) ;", "del_tokens": "return super . toString ( ) + \" [\" + getDb ( ) + \" \" + ( ( getDbVersion ( ) == null ) ? \"\" : \".\" + getDbVersion ( ) ) + getId ( ) + ( ( getIdVersion ( ) == null ) ? \"\" : \".\" + getIdVersion ( ) ) + \"]\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "recovery", "of", "single", "-", "byte", "secrets", "."], "add_tokens": "final byte [ ] [ ] points = new byte [ shares . size ( ) ] [ 2 ] ;", "del_tokens": "final byte [ ] [ ] points = new byte [ shares . size ( ) ] [ secret . length ] ;", "commit_type": "fix"}
{"commit_tokens": ["added", "more", "to", "README", ".", "Cleaned", "up", "pom", "indentation", ".", "Reworked", "src", "dir", "for", "Java", ".", "Created", "some", "package", "dirs", "for", "iodriver", "and", "aeron", "."], "add_tokens": "package uk . co . real_logic . aeron ;", "del_tokens": "package uk . co . real_logic ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Empty", "Search", "Query", "Exception"], "add_tokens": "import com . venky . core . util . ObjectUtil ; if ( ! ObjectUtil . isVoid ( strQuery ) ) { LuceneIndexer indexer = LuceneIndexer . instance ( getModelClass ( ) ) ; Query q = indexer . constructQuery ( strQuery ) ; List < Integer > ids = indexer . findIds ( q , 100 ) ; if ( ! ids . isEmpty ( ) ) { Select sel = new Select ( ) . from ( getModelClass ( ) ) . where ( new Expression ( \"ID\" , Operator . IN , ids . toArray ( ) ) ) ; return sel . execute ( getModelClass ( ) ) ; } } return new ArrayList < M > ( ) ;", "del_tokens": "LuceneIndexer indexer = LuceneIndexer . instance ( getModelClass ( ) ) ; Query q = indexer . constructQuery ( strQuery ) ; List < Integer > ids = indexer . findIds ( q , 100 ) ; Select sel = new Select ( ) . from ( getModelClass ( ) ) . where ( new Expression ( \"ID\" , Operator . IN , ids . toArray ( ) ) ) ; return sel . execute ( getModelClass ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["improve", "Hive", "serialization", "of", "lists"], "add_tokens": "return ( arrayContent != null ? new ArrayWritable ( arrayContent [ 0 ] . getClass ( ) , arrayContent ) : new ArrayWritable ( NullWritable . class , new Writable [ 0 ] ) ) ;", "del_tokens": "return ( arrayContent != null ? new ArrayWritable ( arrayContent [ 0 ] . getClass ( ) , arrayContent ) : new ArrayWritable ( NullWritable . class ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "typo", "in", "JSON", "payload", "for", "create", "user"], "add_tokens": "map . put ( \"country_code\" , countryCode ) ;", "del_tokens": "map . put ( \"countryCode\" , countryCode ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "spring", ".", "application", ".", "name", "as", "identifier", "of", "the", "application"], "add_tokens": "Assert . notNull ( env . getProperty ( \"spring.application.name\" ) , \"The id of the application is mandatory\" ) ;", "del_tokens": "Assert . notNull ( env . getProperty ( \"info.id\" ) , \"The id of the application is mandatory\" ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "INDEX_PREFIX", "public", "for", "the", "EmbeddedElasticSearchServer", "used", "in", "tests"], "add_tokens": "public static final String INDEX_PREFIX = \"blueflood-\" ;", "del_tokens": "private static final String INDEX_PREFIX = \"blueflood-\" ;", "commit_type": "make"}
{"commit_tokens": ["updating", "tests", "for", "soap", "service"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import javax . xml . ws . Binding ; import javax . xml . ws . BindingProvider ; import javax . xml . ws . handler . Handler ; private static User bob = new User ( \"bob\" ) ; @ SuppressWarnings ( \"rawtypes\" ) @ Test // HandlerChain installation Binding binding = ( ( BindingProvider ) requestHandler ) . getBinding ( ) ; List < Handler > handlerChain = binding . getHandlerChain ( ) ; if ( handlerChain == null ) { handlerChain = new ArrayList < Handler > ( ) ; } handlerChain . add ( new RegisterClientApplicationIdentificationHandler ( ) ) ; binding . setHandlerChain ( handlerChain ) ;", "del_tokens": "private static User bob = new User ( \"bob\" , \"1.2.3.4\" ) ; @ Test", "commit_type": "update"}
{"commit_tokens": ["Add", "swift", "custom", "types", "documentation", "and", "tests"], "add_tokens": "return SwiftyJSON . expr ( coercer ) . coercerInput ( SwiftyJSON . expr ( uncoerced ) ) . toSwiftCode ( ) . replaceFirst ( \"try\" , \"try!\" ) ;", "del_tokens": "return \"try! \" + SwiftyJSON . expr ( coercer ) . coercerInput ( SwiftyJSON . expr ( uncoerced ) ) . toSwiftCode ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "size", "in", "message", "size", "excedded", "exception", "."], "add_tokens": "throw new IOException ( String . format ( \"Message size %d exceeds maxiumum buffer size %d\" , nextCommand != 0 ? nextCommand : size , maximumBufferSize ) ) ;", "del_tokens": "throw new IOException ( String . format ( \"Message size %d exceeds maxiumum buffer size %d\" , nextCommand , maximumBufferSize ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "equals", "/", "hashCode", "/", "toString", "implementation"], "add_tokens": "import com . helger . commons . equals . EqualsUtils ; import com . helger . commons . hash . HashCodeGenerator ; / * * * A single CSP 1.0 directive . * * @ author Philip Helger * @ since 6.0 . 3 * / throw new IllegalArgumentException ( \"Value may not contain a comma (,): \" + sValue ) ; throw new IllegalArgumentException ( \"Value may not contain a semicolon (;): \" + sValue ) ; @ Override public boolean equals ( final Object o ) { if ( o == this ) return true ; if ( o == null || ! getClass ( ) . equals ( o . getClass ( ) ) ) return false ; final CSPDirective rhs = ( CSPDirective ) o ; return m_sName . equals ( rhs . m_sName ) && EqualsUtils . equals ( m_sValue , rhs . m_sValue ) ; } @ Override public int hashCode ( ) { return new HashCodeGenerator ( this ) . append ( m_sName ) . append ( m_sValue ) . getHashCode ( ) ; } *", "del_tokens": "throw new IllegalArgumentException ( \"Value may not contain a comma (,)\" ) ; throw new IllegalArgumentException ( \"Value may not contain a semicolon (;)\" ) ; *", "commit_type": "add"}
{"commit_tokens": ["Make", "assertJsonEquals", "case", "insensitive", ".", "Thanks", "to", "akbertram", "."], "add_tokens": "actual . toString ( ) . replace ( \" \" , \"\" ) . replace ( \"\\\\r\\\\n\" , \"\" ) . replace ( \"\\\\n\" , \"\" ) ) ;", "del_tokens": "actual . toString ( ) . replace ( \" \" , \"\" ) . replace ( \"\\\\n\" , \"\" ) ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "support", "for", "Google", "Accounts", "Authentication", "and", "Authorization", "API"], "add_tokens": "import org . springframework . social . google . api . oauth2 . OAuth2Operations ; import org . springframework . social . google . api . oauth2 . impl . OAuth2Template ; private OAuth2Operations oauth2Operations ; oauth2Operations = new OAuth2Template ( getRestTemplate ( ) , isAuthorized ( ) ) ; @ Override public OAuth2Operations oauth2Operations ( ) { return oauth2Operations ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "email", "+", "tool", "to", "Entrez", "interaction", "."], "add_tokens": "private String email = \"anonymous@biojava.org\" ; private String tool = \"biojavax\" ; String url = baseurl + db + \"&id=\" + id + \"&rettype=gb&tool=\" + getTool ( ) + \"&email=\" + getEmail ( ) ; params . append ( \"&email=\" + getEmail ( ) + \"&tool=\" + getTool ( ) ) ; / * * * Set the tool identifier for Entrez . Defaults to 'biojavax' . * @ param tool the new identifier . * / public void setTool ( String tool ) { this . tool = tool ; } / * * * Get the tool identifier for Entrez . Defaults to 'biojavax' . * @ return the identifier . * / public String getTool ( ) { return this . tool ; } / * * * Set the email for Entrez . Defaults to 'anonymous@biojava.org' . * @ param email the new email . * / public void setEmail ( String email ) { this . email = email ; } / * * * Get the email for Entrez . Defaults to 'anonymous@biojava.org' . * @ return the email . * / public String getEmail ( ) { return this . email ; }", "del_tokens": "String url = baseurl + db + \"&id=\" + id + \"&rettype=gb\" ;", "commit_type": "add"}
{"commit_tokens": ["add", "directory", "entries", "unless", "filesonly", "is", "used"], "add_tokens": "private ManifestProcessor ( ) { } return ! struct . name . equalsIgnoreCase ( MANIFEST_PATH ) ;", "del_tokens": "private ManifestProcessor ( ) { } if ( struct . file != null && struct . name . equalsIgnoreCase ( MANIFEST_PATH ) ) return false ; return true ;", "commit_type": "add"}
{"commit_tokens": ["adds", "liveblur", "adds", "observable", "views"], "add_tokens": "import android . support . v4 . app . Fragment ; import android . support . v7 . app . ActionBarActivity ; public class MainActivity extends ActionBarActivity { getSupportFragmentManager ( ) . beginTransaction ( ) . add ( R . id . container , new LiveBlurFragment ( ) ) // getMenuInflater().inflate(R.menu.main, menu);", "del_tokens": "import android . app . Activity ; import android . app . Fragment ; public class MainActivity extends Activity { getFragmentManager ( ) . beginTransaction ( ) . add ( R . id . container , new PlaceholderFragment ( ) ) // Inflate the menu; this adds items to the action bar if it is present. getMenuInflater ( ) . inflate ( R . menu . main , menu ) ; // Handle action bar item clicks here. The action bar will // automatically handle clicks on the Home/Up button, so long // as you specify a parent activity in AndroidManifest.xml.", "commit_type": "add"}
{"commit_tokens": ["removed", "deprecated", "MODIFIED_PRECEEDING", "and", "releated", "classes"], "add_tokens": "&& ( holidayHandler . getType ( ) . equals ( BACKWARD ) || holidayHandler . getType ( ) . equals ( MODIFIED_PRECEDING ) ) ) {", "del_tokens": "import static net . objectlab . kit . datecalc . common . HolidayHandlerType . MODIFIED_PRECEEDING ; && ( holidayHandler . getType ( ) . equals ( BACKWARD ) || holidayHandler . getType ( ) . equals ( MODIFIED_PRECEEDING ) || holidayHandler . getType ( ) . equals ( MODIFIED_PRECEDING ) ) ) {", "commit_type": "remove"}
{"commit_tokens": ["removed", "earlier", "impl", "for", "some", "functions", "which", "are", "rewritten"], "add_tokens": "lastFilteredNodeSet = new FilteredNodeSet ( current , toBoolean ( lastFilteredNodeSet ) ) ; filteredNodeSet = new FilteredNodeSet ( context , toBoolean ( current ) ) ; public UserResults toBoolean ( Node node ) {", "del_tokens": "lastFilteredNodeSet = new FilteredNodeSet ( current , _toBoolean ( lastFilteredNodeSet ) ) ; filteredNodeSet = new FilteredNodeSet ( context , _toBoolean ( current ) ) ; if ( derivedResults . resultType ( ) == ResultType . BOOLEAN ) current = toBoolean ( current ) ; if ( derivedResults . resultType ( ) == ResultType . BOOLEAN ) current = toBoolean ( current ) ; public UserResults _toBoolean ( Node node ) { public Node toBoolean ( Node node ) { if ( node . resultType ( ) == ResultType . BOOLEAN ) return node ; else if ( node . resultType ( ) == ResultType . NODESET ) { Function function = new BooleanFunction ( ) ; return node . addConstraint ( function ) ; } else { DerivedResults derivedResults = new Booleanize ( ) ; derivedResults . addMember ( node ) ; derivedResults = derivedResults . attach ( ) ; root . addConstraint ( derivedResults ) ; return derivedResults ; } }", "commit_type": "remove"}
{"commit_tokens": ["Adding", "support", "for", "building", "SIP", "messages", "from", "a", "stream"], "add_tokens": "@ Override", "del_tokens": "@ Override public int getWriterIndex ( ) { return this . writerIndex ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "missing", "fields", "to", "Metric", "and", "Entity", "models"], "add_tokens": "import java . util . TimeZone ; private Interpolate interpolate ; private TimeZone timeZone ; private String lastInsertDate ; public String getLastInsertDate ( ) { return lastInsertDate ; public Interpolate getInterpolate ( ) { return interpolate ; } public void setInterpolate ( Interpolate interpolate ) { this . interpolate = interpolate ; } public TimeZone getTimeZone ( ) { return timeZone ; } public void setTimeZone ( TimeZone timeZone ) { this . timeZone = timeZone ; \", interpolate=\" + interpolate + \", timeZone=\" + timeZone + \", lastInsertDate='\" + lastInsertDate + '\\'' +", "del_tokens": "@ JsonProperty @ JsonProperty @ JsonProperty @ JsonProperty private Long lastInsertTime ; @ JsonProperty public Long getLastInsertTime ( ) { return lastInsertTime ; public Entity setLastInsertTime ( Long lastInsertTime ) { this . lastInsertTime = lastInsertTime ; return this ; \", lastInsertTime=\" + lastInsertTime +", "commit_type": "add"}
{"commit_tokens": ["Made", "HandlerBox", "detect", "if", "string", "is", "null", "terminating", "or", "not"], "add_tokens": "assert size == box . getSize ( ) :", "del_tokens": "// the hdlr box has different sizes. If file is mov no zero termination in case of mp4 // zero termination assert size == box . getSize ( ) || \"hdlr\" . equals ( IsoFile . bytesToFourCC ( box . getType ( ) ) ) :", "commit_type": "make"}
{"commit_tokens": ["use", "hash", "child", "to", "query", "locations"], "add_tokens": "Query firebaseQuery = firebase . orderByChild ( \"g\" ) . startAt ( query . getStartValue ( ) ) . endAt ( query . getEndValue ( ) ) ;", "del_tokens": "Query firebaseQuery = firebase . startAt ( query . getStartValue ( ) ) . endAt ( query . getEndValue ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "yet", "another", "NPE", "by", "making", "a", "dummy", "button", "to", "pass", "to", "icon", ".", "paintIcon", "."], "add_tokens": "import javax . swing . JButton ; JButton foo = new JButton ( ) ; icon . paintIcon ( foo , g2 , 0 , 0 ) ;", "del_tokens": "icon . paintIcon ( null , g2 , 0 , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "small", "style", "violation", "."], "add_tokens": "messager . printMessage ( Kind . ERROR , \"Failed to process @AutoFactory annotations:\\n\" + Throwables . getStackTraceAsString ( e ) ) ;", "del_tokens": "messager . printMessage ( Kind . ERROR , \"Failed to process @AutoFactory annotations:\\n\" + Throwables . getStackTraceAsString ( e ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "constructor", "parameter", "name", "after", "merge"], "add_tokens": "public RecordParserImpl ( final int fieldNumber , final String fieldDelimiter , final boolean trimWhitespaces , final String qualifier ) {", "del_tokens": "public RecordParserImpl ( final int fieldNumber , final String fieldSeparator , final boolean trimWhitespaces , final String qualifier ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "symmetric", "encoding", "for", "CloseSecureChannelRequest"], "add_tokens": "uint ( 60 * 1000L ) // TODO Configurable lifetime // TODO Find out whether this should be sent symmetric or asymmetric List < ByteBuf > chunks = chunkEncoder . encodeSymmetric (", "del_tokens": "uint ( 60 * 1000L ) List < ByteBuf > chunks = chunkEncoder . encodeAsymmetric (", "commit_type": "use"}
{"commit_tokens": ["fix", "race", "condition", "in", "onBackpressureToFile", "where", "a", "partially", "constructed", "error", "could", "be", "emitted"], "add_tokens": "if ( isDone && error != null ) {", "del_tokens": "if ( error != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "ability", "to", "search", "for", "an", "equal", "min", "hash"], "add_tokens": "// we now have a list of topics that are possible candidates for a match. Now we compare the minhash values // to see what the similarity actually is.", "del_tokens": "// we now have a list of topics that are possible candidates for a match", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "last_revision", "on", "every", "commit"], "add_tokens": "boolean success = false ; success = true ; } finally { if ( success ) { logger . info ( \"Updated lastReplayedRevision to: {}\" , lastReplayedRevision ) ; } else { logger . error ( \"Failed to update lastReplayedRevision to: {}\" , lastReplayedRevision ) ; } updateLastReplayedRevision ( nextRevision ) ; } catch ( Throwable t ) { info . lastReplayedRevision , t ) ; if ( t instanceof ReplicationException ) { throw ( ReplicationException ) t ; info . lastReplayedRevision , t ) ;", "del_tokens": "logger . info ( \"Update lastReplayedRevision to: {}\" , lastReplayedRevision ) ; } catch ( Exception e ) { info . lastReplayedRevision , e ) ; if ( e instanceof ReplicationException ) { throw ( ReplicationException ) e ; info . lastReplayedRevision , e ) ; } try { updateLastReplayedRevision ( targetRevision ) ; } catch ( Exception e ) { logger . error ( \"Failed to update {} to {}; entering read-only mode\" , revisionFile , targetRevision , e ) ; stopLater ( ) ; throw new ReplicationException ( \"failed to update \" + revisionFile + \" to \" + targetRevision , e ) ;", "commit_type": "update"}
{"commit_tokens": ["Implement", "inline", "resources", "(", "css", "+", "images", ")", "using", "jsoup", "(", "work", "in", "progress", ")"], "add_tokens": "MimeMultipart multipart = new MimeMultipart ( \"related\" ) ;", "del_tokens": "MimeMultipart multipart = new MimeMultipart ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "the", "cast", "again", "..."], "add_tokens": "diff = ( ( double ) ( diff1 + 1.0 ) ) / ( double ) start . dayOfYear ( ) . getMaximumValue ( ) + ( ( double ) ( endYear - startYear - 1.0 ) ) + ( ( double ) ( diff2 ) ) / ( double ) end . dayOfYear ( ) . getMaximumValue ( ) ;", "del_tokens": "diff = ( ( diff1 + 1.0 ) ) / start . dayOfYear ( ) . getMaximumValue ( ) + ( ( endYear - startYear - 1.0 ) ) + ( ( double ) ( diff2 ) ) / ( double ) end . dayOfYear ( ) . getMaximumValue ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "possible", "scan", "for", "files", "in", "subdirectories"], "add_tokens": "/ * * * Scan subdirectories for a sources file . * / @ Parameter ( property = \"coveralls.scanForSources\" , defaultValue = \"false\" ) private boolean scanForSources ; . withScanForSources ( scanForSources )", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Added", "JobCommitPolicy", "that", "governs", "how", "job", "is", "committed"], "add_tokens": "import com . linkedin . uif . scheduler . * ; // Do job publishing based on the job commit policy JobCommitPolicy commitPolicy = JobCommitPolicy . forName ( properties . getProperty ( ConfigurationKeys . JOB_COMMIT_POLICY_KEY , ConfigurationKeys . DEFAULT_JOB_COMMIT_POLICY ) ) ; if ( commitPolicy == JobCommitPolicy . COMMIT_ON_PARTIAL_SUCCESS || ( commitPolicy == JobCommitPolicy . COMMIT_ON_FULL_SUCCESS && jobState . getState ( ) == JobState . RunningState . COMMITTED ) ) { LOG . info ( \"Publishing job data of job \" + jobId ) ; // taskStates cannot be empty because otherwise the job will not even start DataPublisher publisher = new HDFSDataPublisher ( taskStates . get ( 0 ) ) ; publisher . initialize ( ) ; publisher . publishData ( taskStates ) ; }", "del_tokens": "import com . linkedin . uif . scheduler . JobLock ; import com . linkedin . uif . scheduler . JobState ; import com . linkedin . uif . scheduler . TaskState ; import com . linkedin . uif . scheduler . WorkUnitManager ; LOG . info ( \"Publishing job data of job \" + jobId ) ; // taskStates cannot be empty because otherwise the job will not even start DataPublisher publisher = new HDFSDataPublisher ( taskStates . get ( 0 ) ) ; publisher . initialize ( ) ; publisher . publishData ( taskStates ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "introduced", "in", "7b4e9c47", ".", "Commit", "thread", "must", "wait", "for", "thread", "starting", "jobs", "to", "complete", "before", "continuing", "."], "add_tokens": "Thread thread = new Thread ( new Runnable ( ) { } ) ; thread . start ( ) ; try { thread . join ( ) ; } catch ( InterruptedException ie ) { }", "del_tokens": "( new Thread ( new Runnable ( ) { } ) ) . start ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "logging", "when", "a", "migration", "is", "performed"], "add_tokens": "eRoot . appendChild ( MicroTypeConverter . convertToMicroElement ( aMigrationResult , ELEMENT_SYSTEM_MIGRATION_RESULT ) ) ; s_aLogger . info ( \"Performing migration '\" + sMigrationID + \"'\" ) ; s_aLogger . info ( \"Finished performing migration '\" + sMigrationID + \"'\" ) ; s_aLogger . info ( \"Performing migration '\" + sMigrationID + \"'\" ) ; s_aLogger . info ( \"Finished performing migration '\" + sMigrationID + \"' with status \" + ( ret . isSuccess ( ) ? \"success\" : \"error\" ) ) ;", "del_tokens": "eRoot . appendChild ( MicroTypeConverter . convertToMicroElement ( aMigrationResult , ELEMENT_SYSTEM_MIGRATION_RESULT ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "typo", "in", "FileNotFoundException", "message"], "add_tokens": "this ( node , \"file not found\" ) ;", "del_tokens": "this ( node , \"file node found\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "selecting", "time", "with", "seconds", "precision"], "add_tokens": "private CheckBox enableSeconds ; enableSeconds = ( CheckBox ) findViewById ( R . id . enable_seconds ) ; tpd . enableSeconds ( enableSeconds . isChecked ( ) ) ; public void onTimeSet ( RadialPickerLayout view , int hourOfDay , int minute , int second ) { String secondString = second < 10 ? \"0\" + second : \"\" + second ; String time = \"You picked the following time: \" + hourString + \"h\" + minuteString + \"m\" + secondString + \"s\" ;", "del_tokens": "public void onTimeSet ( RadialPickerLayout view , int hourOfDay , int minute ) { String time = \"You picked the following time: \" + hourString + \"h\" + minuteString ;", "commit_type": "add"}
{"commit_tokens": ["fix", "SelectBuilder", "problem", "where", "needed", "to", "make", "copy", "of", "list", "when", "creating", "Flowable", "from", "it"], "add_tokens": "import java . util . stream . Collectors ; // called when about to add stream of parameters or about to call get Flowable < List < Object > > p = Flowable // . fromIterable ( new ArrayList < > ( parameterBuffer ) ) // . buffer ( sqlInfo . numParameters ( ) ) ; parameterGroups . add ( p ) ;", "del_tokens": "//called when about to add stream of parameters or about to call get parameterGroups . add ( Flowable . fromIterable ( parameterBuffer ) . buffer ( sqlInfo . numParameters ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "Boolean", "mapped", "to", "CHAR", "(", "1", ")", "with", "Y", "and", "N"], "add_tokens": "Integer , Long , Float , Double , BigDecimal , StringVar , StringFixed , Clob , Blob , Date , Boolean public Column asBoolean ( ) { return asType ( ColumnType . Boolean ) ; } case Boolean : sql . append ( flavor . typeBoolean ( ) ) ; break ;", "del_tokens": "Integer , Long , Float , Double , BigDecimal , StringVar , StringFixed , Clob , Blob , Date", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "multiple", "vertex", "edge", "and", "graph", "labels"], "add_tokens": "import java . util . Collections ; import java . util . List ; private List < String > labels ; return this . labels . get ( 0 ) ; this . labels = Collections . singletonList ( label ) ; } public List < String > getLabels ( ) { return this . labels ; } public void setLabels ( List < String > labels ) { this . labels = labels ;", "del_tokens": "private String label ; return label ; this . label = label ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "WeakReference", "to", "new", "WindowMonitor", "to", "shutdown", "monitoring", "task", "in", "case", "a", "Window", "is", "GC", "ed"], "add_tokens": "import java . lang . ref . WeakReference ; import java . util . Collection ; private ScheduledFuture < ? > monitorHandle ; private final WindowMonitor monitor ; this . monitor = new WindowMonitor ( this ) ; / * * private final WeakReference < Window > parent ; public Monitor ( Window parent ) { this . parent = new WeakReference < Window > ( parent ) ; } logger . debug ( \"WindowMonitor running, current size=\" + getSize ( ) ) ; // check if the window using this monitor was GC'ed if ( this . parent . get ( ) == null ) { logger . debug ( \"Window was GC'ed, stopping this monitor!\" ) ; monitorHandle . cancel ( false ) ; } logger . debug ( \"Found \" + expired . size ( ) + \" requests that expired\" ) ; * / / * * * Gets a list of all listeners . * @ return * / List < UnwrappedWeakReference < WindowListener < K , R , P > > > getListeners ( ) { return this . listeners ; } / * * public void shutdownMonitoring ( ) { this . monitorHandle . cancel ( true ) ; } * /", "del_tokens": "private final ScheduledFuture < ? > monitorHandle ; private final Monitor monitor ; this . monitor = new Monitor ( ) ; //logger.debug(\"WindowMonitor running, current size=\" + getSize()); //logger.debug(\"Found \" + expired.size() + \" requests that expired\");", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "when", "custom", "filter", "classes", "are", "used"], "add_tokens": "afterFilter = filter . getClass ( ) ;", "del_tokens": "afterFilter = filterClass ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "new", "self", "-", "validating", "Path", "class", "for", "book", "names", "and", "paths", "."], "add_tokens": "import com . aoindustries . net . Path ; import com . semanticcms . core . servlet . Book ; Path book , final Path path ResourceRef resourceRef = ResourceRefResolver . getResourceRef ( servletContext , request , domain , book , path . toString ( ) ) ; ResourceStore resourceStore = bookObj . getResources ( ) ;", "del_tokens": "import com . semanticcms . core . pages . Book ; String book , final String path ResourceRef resourceRef = ResourceRefResolver . getResourceRef ( servletContext , request , domain , book , path ) ; ResourceStore resourceStore = bookObj . getResourceStore ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Implemented", "the", "JDK", "moveByMonths", "(", "easier", "than", "thought", ")", "and", "now", "only", "1", "test", "fails", "for", "ACT_ACT", ".", "It", "does", "not", "seem", "to", "fail", "for", "JODA", "...", "could", "it", "be", "a", "TimeZone", "issue?"], "add_tokens": "Calendar date = getCurrentBusinessDate ( ) ; date . add ( Calendar . MONTH , months ) ; setCurrentBusinessDate ( date ) ;", "del_tokens": "// LocalDate date = getCurrentBusinessDate(); // int day = date.getDayOfMonth(); // date = date.withDayOfMonth(1).plusMonths(months); // // int lastDayOfMonth = date.dayOfMonth().getMaximumValue(); // if (day>lastDayOfMonth) { // day = lastDayOfMonth; // } // setCurrentBusinessDate(date.withDayOfMonth(day));", "commit_type": "implement"}
{"commit_tokens": ["add", "javadoc", "to", "configurable", "constants"], "add_tokens": "/ * * * Configurable via the property \"tinafw.base_url\" . * /", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "base", "implementation", "of", "ApiService"], "add_tokens": "apiService ( ) . configure ( props ) ; return AppService . getInstance ( ) ; return SsoService . getInstance ( ) ; } / * * * Return the Maestrano Api Service * @ return ApiService singleton * / public static ApiService apiService ( ) { return ApiService . getInstance ( ) ;", "del_tokens": "return ( AppService ) AppService . getInstance ( ) ; return ( SsoService ) SsoService . getInstance ( ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "a", "different", "object", "name", "so", "the", "test", "doesn", "t", "fail", "when", "running", "in", "a"], "add_tokens": "oName = new ObjectName ( \"jolokia:test=openExec\" ) ;", "del_tokens": "oName = new ObjectName ( \"jolokia:test=exec\" ) ;", "commit_type": "use"}
{"commit_tokens": ["improved", "Query", "interface", "by", "adding", "varargs", "for", "where", "and", "other", "methods"], "add_tokens": "public SubQuery < A > having ( EBoolean ... o ) { query . having ( o ) ; return this ; } public SubQuery < A > where ( EBoolean ... o ) { query . where ( o ) ; return this ; }", "del_tokens": "public SubQuery < A > having ( EBoolean o ) { query . having ( o ) ; return this ; } public SubQuery < A > where ( EBoolean o ) { query . where ( o ) ; return this ; }", "commit_type": "improve"}
{"commit_tokens": ["Updated", "the", "error", "message", "for", "the", "latest", "changes", "."], "add_tokens": "public static final String ERROR_TOPIC_WITH_DIFFERENT_REVS_MSG = INVALID_CS + \" Topic %d has two or more different revisions included in the Content Specification. The topic is located at:\" ;", "del_tokens": "public static final String ERROR_TOPIC_WITH_DIFFERENT_REVS_MSG = INVALID_CS + \" Topic %d has two or more different revisions included in the Content Specification. The topic is located on line(s) %s.\" ;", "commit_type": "update"}
{"commit_tokens": ["added", "offset", "/", "blockLength", "calculation", "and", "validation", ".", "Flushed", "out", "PrimitiveValue", "for", "float", "and", "double", "PrimitiveType"], "add_tokens": "FLOAT ( \"float\" , 4 , PrimitiveValue . MIN_VALUE_FLOAT , PrimitiveValue . MAX_VALUE_FLOAT , PrimitiveValue . NULL_VALUE_FLOAT ) , DOUBLE ( \"double\" , 8 , PrimitiveValue . MIN_VALUE_DOUBLE , PrimitiveValue . MAX_VALUE_DOUBLE , PrimitiveValue . NULL_VALUE_DOUBLE ) ; PrimitiveType ( final String name , final int size , final double minValue , final double maxValue , final double nullValue ) this . minValue = new PrimitiveValue ( minValue ) ; this . maxValue = new PrimitiveValue ( maxValue ) ; this . nullValue = new PrimitiveValue ( nullValue ) ;", "del_tokens": "FLOAT ( \"float\" , 4 ) , DOUBLE ( \"double\" , 8 ) ; PrimitiveType ( final String name , final int size ) this . minValue = null ; this . maxValue = null ; this . nullValue = null ;", "commit_type": "add"}
{"commit_tokens": ["add", "integration", "testing", "against", "the", "reference", "implementation"], "add_tokens": "", "del_tokens": "/ * * * Flag indicating if a CPE 2.3 Format String is being parsed in the test * case . If it is , an extra un - binding must be done due to a bug in the * reference implementation . See the showBugInReferenceImpl test case below * for a detailed example . * / private boolean is23 = false ; is23 = true ; //There is a bug in the unbindFS in the reference implementation. //See the showBugInReferenceImpl test case below to show the defect //in the reference implementation. if ( is23 ) { result = Convert . fromWellFormed ( result ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "setCancelableOnOutsideTouch", "()", "method", "in", "BaseDialogBuilder", "."], "add_tokens": "private boolean mCancelableOnOutsideTouch = true ; public T setCancelableOnOutsideTouch ( boolean cancelable ) { mCancelableOnOutsideTouch = cancelable ; return self ( ) ; } if ( mCancelable != mCancelableOnOutsideTouch ) { mFragmentManager . executePendingTransactions ( ) ; if ( fragment . getDialog ( ) != null ) fragment . getDialog ( ) . setCanceledOnTouchOutside ( mCancelableOnOutsideTouch ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["creates", "initial", "adocs", "for", "gemfire", "sources"], "add_tokens": "private Expression cqEventExpression = new SpelExpressionParser ( ) . parseExpression return cqEventExpression ; this . cqEventExpression = cqEventExpression ;", "del_tokens": "private Expression expression = new SpelExpressionParser ( ) . parseExpression return expression ; this . expression = cqEventExpression ;", "commit_type": "create"}
{"commit_tokens": ["Make", "the", "processor", "closeable", "to", "clean", "up", "the", "threads", "."], "add_tokens": "import java . io . Closeable ; import java . io . IOException ; public class ParallelResourceProcessor < R , S > implements Closeable { @ Override public void close ( ) throws IOException { if ( executorService != null ) { executorService . shutdown ( ) ; } }", "del_tokens": "public class ParallelResourceProcessor < R , S > {", "commit_type": "make"}
{"commit_tokens": ["Fixed", "bugs", "related", "to", "list", "view", "getting", "the", "touch", "events", ".", "Added", "support", "for", "bottom", "gravity"], "add_tokens": "import android . widget . AdapterView ; import android . widget . Toast ; setSupportActionBar ( ( Toolbar ) findViewById ( R . id . main_toolbar ) ) ; lv . setOnItemClickListener ( new AdapterView . OnItemClickListener ( ) { @ Override public void onItemClick ( AdapterView < ? > parent , View view , int position , long id ) { Toast . makeText ( DemoActivity . this , \"onItemClick\" , Toast . LENGTH_SHORT ) . show ( ) ; } } ) ;", "del_tokens": "setSupportActionBar ( ( Toolbar ) findViewById ( R . id . main_toolbar ) ) ; // Instanciating an array list (you don't need to do this, // you already have yours).", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "least", "specific", "type", "."], "add_tokens": "import java . util . Map ; private static final Map lookupLicense = new HashMap ( ) ; private static final Map lookup = new HashMap ( ) ;", "del_tokens": "private static final HashMap lookupLicense = new HashMap ( ) ; private static final HashMap lookup = new HashMap ( ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "ReadFileRecord", "request", "and", "response", "."], "add_tokens": "final public void setCoils ( boolean [ ] coils ) throws ModbusNumberException {", "del_tokens": "final public void setCoils ( boolean [ ] coils ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "measurement", "s", "class", "name", "as", "much", "as", "possible", "."], "add_tokens": "Log . d ( TAG , \"Looking up measurement for \" + measurementType ) ; mRemoteService . getNumericalMeasurement ( measurementType . toString ( ) ) ; mRemoteService . getStateMeasurement ( measurementType . toString ( ) ) ;", "del_tokens": "private String getMeasurementId ( Class < ? extends VehicleMeasurement > measurementType ) throws UnrecognizedMeasurementTypeException { try { String measurementId = ( String ) ( measurementType . getField ( \"ID\" ) . get ( measurementType ) ) ; Log . d ( TAG , measurementType + \"'s ID is \" + measurementId ) ; return measurementId ; } catch ( NoSuchFieldException e ) { throw new UnrecognizedMeasurementTypeException ( \"No ID field on given measurement type\" , e ) ; } catch ( IllegalAccessException e ) { throw new UnrecognizedMeasurementTypeException ( \"ID field on given measurement type is not public\" , e ) ; } } String measurementId = getMeasurementId ( measurementType ) ; Log . d ( TAG , \"Looking up measurement for ID \" + measurementId ) ; mRemoteService . getNumericalMeasurement ( measurementId ) ; mRemoteService . getStateMeasurement ( measurementId ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "unused", "dep", "on", "jitescript"], "add_tokens": "String className = PACKAGE + \"/\" + structClass . getName ( ) . replace ( '.' , '/' ) + \"$\" + counter . incrementAndGet ( ) ;", "del_tokens": "import static me . qmx . jitescript . util . CodegenUtils . p ; String className = PACKAGE + \"/\" + p ( structClass ) + \"$\" + counter . incrementAndGet ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Change", "TargetHandler", "to", "accept", "error", "handler", "to", "recieve", "carbon", "message"], "add_tokens": "HttpRequest httpRequest , CarbonMessage carbonMessage , CarbonCallback carbonCallback , boolean globalEndpointPooling , GenericObjectPool genericObjectPool , ConnectionManager connectionManager , RingBuffer ringBuffer ) { @ Override public void run ( ) { faultHandler . handleFault ( \"502\" , e , carbonMessage , carbonCallback ) ; . engage ( carbonMessage , EngagedLocation . SERVER_CONNECTION_INITIATED ) ; faultHandler . handleFault ( \"502\" , failedCause , carbonMessage , carbonCallback ) ;", "del_tokens": "HttpRequest httpRequest , CarbonMessage carbonMessage , CarbonCallback carbonCallback , boolean globalEndpointPooling , GenericObjectPool genericObjectPool , ConnectionManager connectionManager , RingBuffer ringBuffer ) { @ Override public void run ( ) { faultHandler . handleFault ( \"502\" , e , carbonCallback ) ; . engage ( carbonMessage , EngagedLocation . SERVER_CONNECTION_INITIATED ) ; faultHandler . handleFault ( \"502\" , failedCause , carbonCallback ) ;", "commit_type": "change"}
{"commit_tokens": ["removed", "unused", "methods", "in", "data", "classes"], "add_tokens": "import com . fasterxml . jackson . annotation . * ;", "del_tokens": "import com . fasterxml . jackson . annotation . JsonAnyGetter ; import com . fasterxml . jackson . annotation . JsonAnySetter ; import com . fasterxml . jackson . annotation . JsonIgnore ; import com . fasterxml . jackson . annotation . JsonInclude ; import com . fasterxml . jackson . annotation . JsonProperty ; import com . fasterxml . jackson . annotation . JsonPropertyOrder ; / * * * * @ param license * @ param buildInfo * / / * * * * @ return * The buildInfo * / / * * * * @ param buildInfo * The buildInfo * / public Version withBuildInfo ( BuildInfo buildInfo ) { this . buildInfo = buildInfo ; return this ; } / * * * * @ return * The license * / / * * * * @ param license * The license * / public Version withLicense ( License license ) { this . license = license ; return this ; } public Version withAdditionalProperty ( String name , Object value ) { this . additionalProperties . put ( name , value ) ; return this ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "access", "problem", "with", "javascript", "config", "evaluator", "console", "class"], "add_tokens": "static public class Console {", "del_tokens": "static protected class Console {", "commit_type": "fix"}
{"commit_tokens": ["Changing", "the", "way", "to", "create", "SparkStream"], "add_tokens": "import org . apache . spark . api . java . JavaRDD ; JavaRDD < T > rdd ; rdd = getSparkContext ( ) . parallelize ( Cast . < List < T > > as ( collection ) ) ; } else { rdd = getSparkContext ( ) . parallelize ( new ArrayList < T > ( collection ) ) ; return new SparkStream < > ( rdd ) ;", "del_tokens": "import static com . ibm . icu . impl . ValidIdentifiers . Datatype . t ; return new SparkStream < > ( Cast . < List < T > > as ( collection ) ) ; return new SparkStream < > ( collection . stream ( ) . collect ( Collectors . toList ( ) ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "public", "static", "String", "getTextContent", "(", "Node", "node", "boolean", "replaceProps", ")"], "add_tokens": "import org . jboss . util . StringPropertyReplacer ; * @ return getTextContent ( node , false ) . { return getTextContent ( node , false ) ; } / * * Get the concatenated text content , or null . * @ param the node to search for TEXT_NODE conent * @ param replaceProps flag indicating if $ { x } property refs should be replace * / public static String getTextContent ( Node node , boolean replaceProps ) String text = ( hasTextContent ? buffer . toString ( ) : null ) ; if ( text != null && replaceProps ) text = StringPropertyReplacer . replaceProperties ( text ) ; return text ;", "del_tokens": "return ( hasTextContent ? buffer . toString ( ) : null ) ;", "commit_type": "add"}
{"commit_tokens": ["Used", "consistent", "test", "method", "names"], "add_tokens": "public void linkGetHrefWhenAnchorAndAbsoluteHrefReturnsUrl ( ) throws IOException , InterruptedException public void linkGetHrefWhenAnchorAndRelativeHrefReturnsAbsoluteUrl ( ) throws IOException , InterruptedException public void linkGetHrefWhenLinkAndAbsoluteHrefReturnsUrl ( ) throws IOException , InterruptedException public void linkGetHrefWhenLinkAndRelativeHrefReturnsAbsoluteUrl ( ) throws IOException , InterruptedException", "del_tokens": "public void linkGetHrefWhenAnchorAndAbsoluteHrefReturnsHref ( ) throws IOException , InterruptedException public void linkGetHrefWhenAnchorAndRelativeHrefReturnsAbsoluteHref ( ) throws IOException , InterruptedException public void linkGetHrefWhenLinkAndAbsoluteHrefReturnsHref ( ) throws IOException , InterruptedException public void linkGetHrefWhenLinkAndRelativeHrefReturnsAbsoluteHref ( ) throws IOException , InterruptedException", "commit_type": "use"}
{"commit_tokens": ["added", "another", "tutorial", "for", "debugging"], "add_tokens": "import org . apache . commons . logging . Log ; import org . apache . commons . logging . LogFactory ; // you get that because you \"installed\" a log profile in configuration. public Log logger = LogFactory . getLog ( T04_MoreConfiguration . class ) ; wrappedBundle ( mavenBundle ( ) . groupId ( \"org.ops4j.base\" ) . artifactId ( \"ops4j-base-util\" ) . version ( \"0.5.3\" ) ) logger . trace ( \"******** This a trace from OSGi\" ) ; logger . debug ( \"******** This a debug from OSGi\" ) ; logger . info ( \"******** This a info from OSGi\" ) ; logger . warn ( \"******** This a warn from OSGi\" ) ; logger . error ( \"******** This a errory from OSGi\" ) ;", "del_tokens": "wrappedBundle ( mavenBundle ( ) . groupId ( \"org.ops4j.base\" ) . artifactId ( \"ops4j-base-util\" ) . version ( \"0.5.3\" ) )", "commit_type": "add"}
{"commit_tokens": ["fixed", "typo", "in", "MangooRequestFilter", "Interface"], "add_tokens": "public Response execute ( Request request , Response response ) ;", "del_tokens": "public Response execute ( Request request , Response reponse ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "javadoc", "to", "be", "a", "bit", "more", "compliant", "."], "add_tokens": "* < p > * < / p > * < p > * < / p >", "del_tokens": "* < p / >", "commit_type": "update"}
{"commit_tokens": ["Move", "compiler", "converter", "and", "util", "packages", "into", "tools", "."], "add_tokens": "}", "del_tokens": "}", "commit_type": "move"}
{"commit_tokens": ["moved", "Strings", "to", "fields", "extra", "test", "cases", "null", "check"], "add_tokens": "private final String alert = \"alert\" ; private final String sound = \"sound\" ; private final String badge = \"badge\" ; private final String simplePush = \"simple-push\" ; this . attributes . put ( alert , message ) ; this . attributes . put ( this . sound , sound ) ; this . attributes . put ( this . badge , badge ) ; this . attributes . put ( simplePush , fixVersion ( version ) ) ; this . attributes . put ( simplePush , entries ) ; if ( version != null && ! version . startsWith ( \"version=\" ) ) {", "del_tokens": "this . attributes . put ( \"alert\" , message ) ; this . attributes . put ( \"sound\" , sound ) ; this . attributes . put ( \"badge\" , badge ) ; this . attributes . put ( \"simple-push\" , fixVersion ( version ) ) ; this . attributes . put ( \"simple-push\" , entries ) ; if ( ! version . startsWith ( \"version=\" ) ) {", "commit_type": "move"}
{"commit_tokens": ["Add", "spring", "configurations", "unify", "the", "different", "servers"], "add_tokens": "import org . apache . cxf . BusFactory ; private Bus bus = BusFactory . getDefaultBus ( ) ; public void init ( ) throws IOException , InterruptedException , ServiceLocatorException { locatorClient . connect ( ) ; public ServiceLocator getLocatorClient ( ) { return locatorClient ; }", "del_tokens": "private Bus bus ; public void init ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "OutputStream", "unavailable", "because", "request", "headers", "have", "already", "been", "sent"], "add_tokens": "import java . io . OutputStream ; OutputStream out = connection . getOutputStream ( ) ; content . writeTo ( out ) ; out . close ( ) ;", "del_tokens": "content . writeTo ( connection . getOutputStream ( ) ) ; connection . getOutputStream ( ) . close ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "with", "comparing", "historical", "servers"], "add_tokens": "public Iterable < T > getInventory ( )", "del_tokens": "public Collection < T > getInventory ( )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "to", "return", "empty", "list"], "add_tokens": "import java . util . * ; if ( category == null || category . length == 0 ) { return Collections . emptyList ( ) ; } if ( versions == null || versions . length == 0 ) { return Collections . emptyList ( ) ; } if ( milestone == null || milestone . length == 0 ) { return Collections . emptyList ( ) ; } if ( customFields == null || customFields . length == 0 ) { return Collections . emptyList ( ) ; } if ( attachments == null || attachments . length == 0 ) { return Collections . emptyList ( ) ; } if ( sharedFiles == null || sharedFiles . length == 0 ) { return Collections . emptyList ( ) ; } if ( stars == null || stars . length == 0 ) { return Collections . emptyList ( ) ; }", "del_tokens": "import java . util . Arrays ; import java . util . Date ; import java . util . List ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "the", "POJO", "to", "support", "provisioning_ticket_url", "for", "AD", "/", "LDAP", "connection"], "add_tokens": "@ JsonProperty ( \"provisioning_ticket_url\" ) private String provisioningTicketUrl ; / * * * Getter for the ad / ldap connection 's ticket url. * * @ return the provisioning ticket url . * / @ JsonProperty ( \"provisioning_ticket_url\" ) public String getProvisioningTicketUrl ( ) { return provisioningTicketUrl ; } }", "del_tokens": "}", "commit_type": "update"}
{"commit_tokens": ["Add", "bootstrap", "support", "for", "TextEncryptor"], "add_tokens": "import org . springframework . cloud . config . encrypt . KeyFormatException ; controller . uploadKey ( \"ssh-rsa ...\" , MediaType . TEXT_PLAIN ) ; controller . uploadKey ( \"---- BEGIN RSA PUBLIC KEY ...\" , MediaType . TEXT_PLAIN ) ; controller . uploadKey ( \"foo\" , MediaType . TEXT_PLAIN ) ; controller . uploadKey ( \"foo\" , MediaType . TEXT_PLAIN ) ; controller . uploadKey ( \"foo\" , MediaType . TEXT_PLAIN ) ; controller . uploadKey ( \"foo\" , MediaType . TEXT_PLAIN ) ;", "del_tokens": "controller . uploadKey ( \"ssh-rsa ...\" ) ; controller . uploadKey ( \"---- BEGIN RSA PUBLIC KEY ...\" ) ; controller . uploadKey ( \"foo\" ) ; controller . uploadKey ( \"foo\" ) ; controller . uploadKey ( \"foo\" ) ; controller . uploadKey ( \"foo\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "buffered", "reading", "/", "writing", "from", "/", "to", "streams", "to", "speed", "up", "Zip", "-", "Extracting", "a", "lot"], "add_tokens": "int size ; byte [ ] buffer = new byte [ 2048 ] ; try ( OutputStream fout = new BufferedOutputStream ( new FileOutputStream ( target ) , buffer . length ) ) { while ( ( size = data . read ( buffer , 0 , buffer . length ) ) != - 1 ) { fout . write ( buffer , 0 , size ) ; }", "del_tokens": "try ( OutputStream fout = new FileOutputStream ( target ) ) { for ( int c = data . read ( ) ; c != - 1 ; c = data . read ( ) ) { fout . write ( c ) ; }", "commit_type": "use"}
{"commit_tokens": ["Change", "user", "to", "customer", "in", "person", ".", "proto", "to", "be", "consistent", "with", "web", "examples"], "add_tokens": "* A list of the customer 's phone numbers. * The customer 's phone number.", "del_tokens": "* A list of the user 's phone numbers. * The user 's phone number.", "commit_type": "change"}
{"commit_tokens": ["Adding", "better", "support", "for", "initMet", "&", "stopCodon", "trimming", ".", "This", "will", "be", "replaced", "by", "the", "sequence", "edit", "capability", "but", "for", "the", "moment", "this", "allows", "us", "to", "work", "with", "peptides", "correctly"], "add_tokens": "private boolean initMet = true ; private boolean trimStop = true ; public Builder initMet ( boolean initMet ) { this . initMet = initMet ; return this ; } public Builder trimStop ( boolean trimStop ) { this . trimStop = trimStop ; return this ; } getAminoAcidCompounds ( ) , getTable ( ) , isTrimStop ( ) , isInitMet ( ) private boolean isInitMet ( ) { return initMet ; } private boolean isTrimStop ( ) { return trimStop ; }", "del_tokens": "getAminoAcidCompounds ( ) , getTable ( ) , true", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "TransportMetadata", "OSGi", "service", "to", "expose", "metadata", "about", "the", "Netty", "transports"], "add_tokens": "import org . wso2 . carbon . transport . http . netty . internal . config . TransportsConfiguration ; import org . wso2 . carbon . transport . http . netty . listener . TransportsMetadata ; TransportsMetadata trpMetadata = new TransportsMetadata ( ) ; for ( NettyListener listener : createNettyListeners ( trpMetadata ) ) { bundleContext . registerService ( TransportsMetadata . class , trpMetadata , null ) ; private Set < NettyListener > createNettyListeners ( TransportsMetadata trpMetadata ) { TransportsConfiguration trpConfig = YAMLTransportConfigurationBuilder . build ( ) ; trpConfig . getListenerConfigurations ( ) ; trpMetadata . addTransportID ( listenerConfiguration . getId ( ) ) ;", "del_tokens": "for ( NettyListener listener : createNettyListeners ( ) ) { private Set < NettyListener > createNettyListeners ( ) { YAMLTransportConfigurationBuilder . build ( ) . getListenerConfigurations ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "logger", "to", "outer", "class"], "add_tokens": "private static final Logger LOG = LoggerFactory . getLogger ( TinyPlugzLookUp . class ) ;", "del_tokens": "private static final Logger LOG = LoggerFactory . getLogger ( TinyPlugzLookUp . class ) ;", "commit_type": "move"}
{"commit_tokens": ["improved", "header", "handling", ";", "fix", "for", "responses", "that", "have", "no", "content", "(", "i", ".", "e", ".", "headers", "only", ".", ")", "-", "TMN"], "add_tokens": "for ( String key : headers . keySet ( ) ) { String val = headers . get ( key ) ; if ( val == null ) reqMethod . removeHeaders ( key ) ; else reqMethod . setHeader ( key , val ) ; } // For HEAD or DELETE requests, there should be no response entity. if ( resp . getEntity ( ) == null ) { log . warn ( \"Response contains no entity, but response closure \" + \"expects parsed data. Passing null as second closure arg.\" ) ; closureArgs = new Object [ ] { resp , null } ; break ; } // Otherwise, parse the response entity: HttpEntity responseContent = resp . getEntity ( ) ; if ( responseContent != null && responseContent . isStreaming ( ) ) responseContent . consumeContent ( ) ; if ( headers != null ) this . getHeaders ( ) . putAll ( headers ) ;", "del_tokens": "for ( String key : headers . keySet ( ) ) reqMethod . setHeader ( key , headers . get ( key ) ) ; if ( resp . getEntity ( ) . isStreaming ( ) ) resp . getEntity ( ) . consumeContent ( ) ; if ( headers != null ) this . setHeaders ( headers ) ;", "commit_type": "improve"}
{"commit_tokens": ["moving", "out", "I", "/", "O", "implementations", "to", "vabr", "where", "they", "re", "more", "reusable", "and", "being", "more", "careful", "to", "close", "I", "/", "O", "that", "gets", "setup", "to", "handle", "a", "vert", ".", "x", "-", "bound", "request", ".", "Other", "minor", "fixes", "to", "get", "this", "up", "and", "running", "both", "inside", "a", "WAR", "and", "a", "vert", ".", "x", "deployment"], "add_tokens": "import org . apache . commons . io . IOUtils ; final VertXWebdavResponse response = new VertXWebdavResponse ( request . response ( ) ) ; VertXWebdavRequest req = null ; try { req = new VertXWebdavRequest ( request , contextPath , servicePath , serviceSubPath , principal ) ; service . service ( req , response ) ; } finally { IOUtils . closeQuietly ( req ) ; IOUtils . closeQuietly ( response ) ; try { request . response ( ) . end ( ) ; } catch ( final IllegalStateException e ) { // TODO Do we need to log this? The end() call is defensive... } }", "del_tokens": "service . service ( new VertXWebdavRequest ( request , contextPath , servicePath , serviceSubPath , principal ) , new VertXWebdavResponse ( request . response ( ) ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "excessive", "use", "of", "memory", "in", "SimpleFs", "server", "/", "client", ".", "Test", "for", "uploading", "multiple", "files"], "add_tokens": "final TransformerNoEnd transformer = new TransformerNoEnd ( eventloop ) ; forwarder . streamTo ( transformer ) ; transformer . streamTo ( streamByteChunker ) ; return forwarder ; new StreamGsonDeserializer < > ( eventloop , SimpleFsResponseSerialization . GSON , SimpleFsResponse . class , 10 ) ,", "del_tokens": "final TransformerNoEnd transformer = new TransformerNoEnd ( eventloop ) ; transformer . streamTo ( forwarder ) ; forwarder . streamTo ( streamByteChunker ) ; StreamFilter < ByteBuf > filter = new StreamFilter < > ( eventloop , Predicates . < ByteBuf > alwaysTrue ( ) ) ; filter . streamTo ( transformer ) ; return filter ; new StreamGsonDeserializer < > ( eventloop , SimpleFsResponseSerialization . GSON , SimpleFsResponse . class , 256 * 1024 ) ,", "commit_type": "fix"}
{"commit_tokens": ["Fix", "typo", "in", "physical", "dimensions", "profile", "and", "@context"], "add_tokens": "return \"http://iiif.io/api/annex/services/physdim/1/context.json\" ; return \"http://iiif.io/api/annex/services/physdim\" ;", "del_tokens": "return \"http://iiiif.io/api/annex/services/physdim/1/context.json\" ; return \"http://iiiif.io/api/annex/services/physdim\" ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "IonSystem#singleValue", "(", "byte", "[]", "int", "int", ")"], "add_tokens": "return singleValue ( ionData , 0 , ionData . length ) ; } @ Override public IonValue singleValue ( byte [ ] ionData , int offset , int len ) { IonReader reader = newReader ( ionData , offset , len ) ;", "del_tokens": "IonReader reader = newReader ( ionData ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "Map", "interface", "instead", "of", "class", "."], "add_tokens": "import java . util . Map ; private static final Map < String , Typeface > sCachedFonts = new HashMap < String , Typeface > ( ) ; private static final Map < Typeface , CalligraphyTypefaceSpan > sCachedSpans = new HashMap < Typeface , CalligraphyTypefaceSpan > ( ) ;", "del_tokens": "private static final HashMap < String , Typeface > sCachedFonts = new HashMap < String , Typeface > ( ) ; private static final HashMap < Typeface , CalligraphyTypefaceSpan > sCachedSpans = new HashMap < Typeface , CalligraphyTypefaceSpan > ( ) ;", "commit_type": "use"}
{"commit_tokens": ["changed", "streamId", "to", "Number", "because", "it", "can", "be", "Double", "too"], "add_tokens": "private Number streamId ; if ( result instanceof Number ) { streamId = ( Number ) result ;", "del_tokens": "private int streamId ; if ( result instanceof Integer ) { streamId = ( ( Integer ) result ) . intValue ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "management", "API", "tests", "."], "add_tokens": "return super . removeNamedGroupingPolicy ( ptype , params ) ;", "del_tokens": "return super . removeNamedPolicy ( ptype , params ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "method", "to", "create", "managed", "user"], "add_tokens": "return createManagedUser ( username , null , null , passwordHash , false ) ; } / * * * Creates a new ManagedUser object . * @ param username The username for the user * @ param fullname The fullname of the user * @ param email The users email address * @ param passwordHash The hashed password * @ param suspended Whether or not user being created is suspended or not * @ return a ManagedUser * @ see alpine . auth . PasswordService * @ since 1.0 . 1 * / public ManagedUser createManagedUser ( final String username , final String fullname , final String email , final String passwordHash , final boolean suspended ) { user . setFullname ( fullname ) ; user . setEmail ( email ) ; user . setSuspended ( suspended ) ;", "del_tokens": "user . setSuspended ( false ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "logger", "in", "MOJO", "s", "."], "add_tokens": "getLog ( ) . error ( e ) ; getLog ( ) . error ( e ) ; getLog ( ) . error ( \"Analyze: \" + each ) ;", "del_tokens": "e . printStackTrace ( ) ; e . printStackTrace ( ) ; System . err . println ( \"Analyze: \" + each ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "option", "to", "enable", "to", "disable", "local", "variable", "reduction", "."], "add_tokens": "private Boolean mReduceLocalVariables ; public void reduceLocalVariables ( boolean b ) { mReduceLocalVariables = b ; } boolean doLivenessAnalysis = DO_LIVENESS_ANALYSIS ; if ( mReduceLocalVariables != null ) { doLivenessAnalysis = mReduceLocalVariables ; } if ( ! doLivenessAnalysis ) {", "del_tokens": "if ( ! DO_LIVENESS_ANALYSIS ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bugs", "that", "was", "causing", "the", "main", "entity", "to", "not", "be", "set", "for", "ManyToMany", "collections", "."], "add_tokens": "final Collection < TagToCategory > newCategories = dbCategories . unwrap ( ) ; for ( final TagToCategory category : newCategories ) { category . setTag ( getTag ( ) ) ; entity . setTag ( getTag ( ) ) ;", "del_tokens": "final Collection < TagToCategory > newLanguageImages = dbCategories . unwrap ( ) ; for ( final TagToCategory category : newLanguageImages ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "serializer", "and", "deserializer", "examples", "to", "Serialization", "page", "."], "add_tokens": "@ UiField PreElement overlaysSetup , autobeansSetup , gwtjacksonSetup , mySerializer ; HighlightJs . highlightBlock ( overlaysSetup , autobeansSetup , gwtjacksonSetup , mySerializer ) ;", "del_tokens": "@ UiField PreElement overlaysSetup , autobeansSetup , gwtjacksonSetup ; HighlightJs . highlightBlock ( overlaysSetup , autobeansSetup , gwtjacksonSetup ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "inplace", "operation", "to", "speedy", "(", "untested", ")"], "add_tokens": "public Container inPlaceANDNOT ( final BitmapContainer B2 ) { this . cardinality = 0 ; for ( int k = 0 ; k < this . bitmap . length ; k ++ ) { this . bitmap [ k ] &= ~ B2 . bitmap [ k ] ; this . cardinality += Long . bitCount ( this . bitmap [ k ] ) ; } if ( cardinality <= ArrayContainer . DEFAULTMAXSIZE ) return ContainerFactory . transformToArrayContainer ( this ) ; return this ; } public Container inPlaceANDNOT ( final ArrayContainer B2 ) { this . cardinality = 0 ; for ( int k = 0 ; k < B2 . cardinality ; ++ k ) { this . remove ( B2 . content [ k ] ) ; } if ( cardinality <= ArrayContainer . DEFAULTMAXSIZE ) return ContainerFactory . transformToArrayContainer ( this ) ; return this ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "on", "(", "DateTime", "Runnable", ")", "to", "AppJobManager"], "add_tokens": "if ( S . eq ( FixedDelay . class . getName ( ) , prefix ) ) { } else { prefix = prefix . toLowerCase ( ) ;", "del_tokens": "if ( S . eq ( \"FixedDelay\" , prefix ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "core", "lifecycle", "bean", "."], "add_tokens": "public Lifecycle ( ) {", "del_tokens": "import java . util . concurrent . Executors ; import java . util . concurrent . ThreadFactory ; @ Deprecated public Lifecycle ( Logger log ) { ThreadFactory threadFactory = Executors . defaultThreadFactory ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "all", "dependencies", "to", "latest", "version", "."], "add_tokens": "messageDispatcherServlet . setContextConfigLocation ( removeEnd ( items . toString ( ) , \",\" ) ) ; public static String removeEnd ( String str , String remove ) { if ( str == null || str . isEmpty ( ) || remove == null || remove . isEmpty ( ) ) { return str ; } if ( str . endsWith ( remove ) ) { return str . substring ( 0 , str . length ( ) - remove . length ( ) ) ; } return str ; }", "del_tokens": "import org . apache . commons . lang . StringUtils ; messageDispatcherServlet . setContextConfigLocation ( StringUtils . removeEnd ( items . toString ( ) , \",\" ) ) ;", "commit_type": "update"}
{"commit_tokens": ["move", "POJOService", "to", "proper", "nested", "package"], "add_tokens": "import cz . muni . fi . processor . service . POJOService ;", "del_tokens": "import cz . muni . fi . service . POJOService ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "InputReader", "to", "implement", "AutoCloseable"], "add_tokens": "public class InputReader extends Reader implements AutoCloseable @ Override", "del_tokens": "public class InputReader extends Reader", "commit_type": "change"}
{"commit_tokens": ["Add", "/", "Refine", "issue", "references", "."], "add_tokens": "// //FIXME: This test kills the whole Test file, nothing is recorded. See Issue #2.", "del_tokens": "// //FIXME: This test kills the whole Test file, nothing is recorded. // // See Issue #2.", "commit_type": "add"}
{"commit_tokens": ["Add", "Scroller", "class", "to", "implement", "scroll", "features", "based", "on", "OverScroller", "and", "GestureDetectorCompat"], "add_tokens": "import android . view . MotionEvent ; private Scroller scroller ; float left = path . getLeftForItemAtPosition ( i ) + scroller . getCurrentX ( ) ; float top = path . getTopForItemAtPosition ( i ) + scroller . getCurrentY ( ) ; @ Override public void computeScroll ( ) { super . computeScroll ( ) ; scroller . computeScrollOffset ( ) ; } @ Override public boolean onTouchEvent ( MotionEvent event ) { return scroller . getGestureDetector ( ) . onTouchEvent ( event ) ; } //TODO: MOVE THIS TO OTHER METHOD this . post ( new Runnable ( ) { @ Override public void run ( ) { scroller = new Scroller ( NoxView . this ) ; } } ) ;", "del_tokens": "float left = path . getLeftForItemAtPosition ( i ) ; float top = path . getTopForItemAtPosition ( i ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "comments", "and", "test", "for", "Datacenter", "/", "ConfigurationRest", "files"], "add_tokens": "* Returns the VNF software image selected by id * Updates the VNF software image * : the VNF software image to be updated * : the id of VNF software image * @ return networkServiceDescriptor : the VNF software image updated", "del_tokens": "* This operation returns the VNF software image selected by id * This operation updates the Network Service Descriptor ( NSD ) * : the Network Service Descriptor to be updated * : the id of Network Service Descriptor * @ return networkServiceDescriptor : the Network Service Descriptor updated", "commit_type": "add"}
{"commit_tokens": ["Added", "retry", "logic", "when", "getting", "splits", "for", "Stash", "times", "out", "."], "add_tokens": "try { ScanRangeSplits splits = _dataTools . getScanRangeSplits ( placement , splitSize , Optional . of ( resplitRange ) ) ; for ( ScanRangeSplits . SplitGroup splitGroup : splits . getSplitGroups ( ) ) { for ( ScanRangeSplits . TokenRange tokenRange : splitGroup . getTokenRanges ( ) ) { builder . addAll ( tokenRange . getScanRanges ( ) ) ; } } catch ( Exception e ) { _log . warn ( \"Generating splits for resplit failed, falling back to using entire resplit: placement={}, range={}\" , placement , resplitRange , e ) ; builder . add ( resplitRange ) ;", "del_tokens": "ScanRangeSplits splits = _dataTools . getScanRangeSplits ( placement , splitSize , Optional . of ( resplitRange ) ) ; for ( ScanRangeSplits . SplitGroup splitGroup : splits . getSplitGroups ( ) ) { for ( ScanRangeSplits . TokenRange tokenRange : splitGroup . getTokenRanges ( ) ) { builder . addAll ( tokenRange . getScanRanges ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "lift", "for", "handlers", "internally"], "add_tokens": "import static com . github . davidmoten . rx . RxUtil . toOperator ; return bufferedParameters ( this ) . flatMap ( executeOnce ( ) ) . lift ( toOperator ( context . handlers ( ) . selectHandler ( ) ) ) ;", "del_tokens": "return context . handlers ( ) . selectHandler ( ) . call ( bufferedParameters ( this ) . flatMap ( executeOnce ( ) ) ) ;", "commit_type": "use"}
{"commit_tokens": ["changed", "references", "to", "Sample", "1a", "and", "Sample", "1b"], "add_tokens": "* Sample 1 b - simple sample to show the usage of basic UI helpers as well as * when a button is pressed , and displays it in a TextView . Unlike Sample 1 a ,", "del_tokens": "* Sample 2 - simple sample to show the usage of basic UI helpers as well as * when a button is pressed , and displays it in a TextView . Unlike Sample 1 ,", "commit_type": "change"}
{"commit_tokens": ["Allow", "the", "stored", "procedures", "to", "generate", "encounter_nums", "and", "patient_nums", "."], "add_tokens": "private final Set < VisitDimension > visitCache = new HashSet < > ( ) ; return visitCache ; prop . getSourceSystem ( ) . getStringRepresentation ( ) , public VisitDimension addVisit ( String encryptedPatientId , encryptedIdStr = '@' + encryptedPatientId ; VisitDimension vd = new VisitDimension ( encryptedPatientId , I2B2QueryResultsHandlerSourceId . getInstance ( ) . getStringRepresentation ( ) , visitCache . add ( vd ) ;", "del_tokens": "private final TreeMap < Long , VisitDimension > visitCache = new TreeMap < > ( ) ; return visitCache . values ( ) ; public VisitDimension addVisit ( long patientNum , String encryptedPatientId , encryptedIdStr = null ; VisitDimension vd = new VisitDimension ( patientNum , encryptedPatientId , visitCache . put ( vd . getEncounterNum ( ) , vd ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixing", "#objectNode", ".", "put", "since", "it", "is", "deprecated"], "add_tokens": "public void applyDoesNotMutateSource2 ( ) throws Exception {", "del_tokens": "public void applyDoesNotMutateSource ( ) throws Exception {", "commit_type": "fix"}
{"commit_tokens": ["Added", "ability", "to", "create", "differential", "clone"], "add_tokens": "public static DifferentialArchetype createDifferentialArchetypeClone ( FlatArchetype source ) { DifferentialArchetype result = new DifferentialArchetype ( ) ; fillArchetypeFields ( result , source ) ; return makeClone ( result ) ; } private static void fillArchetypeFields ( Archetype target , Archetype source ) {", "del_tokens": "private static void fillArchetypeFields ( FlatArchetype target , Archetype source ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "wrong", "default", "connection", "name"], "add_tokens": "private static final String DEFAULT_CONNECTION_NAME = \"Username-Password-Authentication\" ;", "del_tokens": "private static final String DEFAULT_CONNECTION_NAME = \"auth0\" ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "including", "of", "static", "fields", "in", "mapping", "operations"], "add_tokens": "final int modifiers = f . getModifiers ( ) ; if ( Modifier . isTransient ( modifiers ) || Modifier . isStatic ( modifiers ) || f . getName ( ) . indexOf ( '$' ) >= 0 ) {", "del_tokens": "if ( Modifier . isTransient ( f . getModifiers ( ) ) || f . getName ( ) . indexOf ( '$' ) >= 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "BsonParser", "so", "JavaDocs", "can", "be", "generated"], "add_tokens": "import org . codehaus . jackson . JsonParser ; public JsonParser . NumberType getNumberType ( ) throws IOException , JsonParseException {", "del_tokens": "public NumberType getNumberType ( ) throws IOException , JsonParseException {", "commit_type": "fix"}
{"commit_tokens": ["fix", "tests", "broken", "by", "copyright", "changes"], "add_tokens": "String expectedHTML = \"<!-- ~ Copyright 2014, The Sporting Exchange Limited ~ ~ Licensed under the Apache License, Version 2.0 (the \\\"License\\\"); ~ you may not use this file except in compliance with the License. ~ You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 ~ ~ Unless required by applicable law or agreed to in writing, software ~ distributed under the License is distributed on an \\\"AS IS\\\" BASIS, ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the License for the specific language governing permissions and ~ limitations under the License. --><!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\"><html xmlns=\\\"http://www.w3.org/1999/xhtml\\\"><head><title>Service not Found</title></head><body><b>The URL you specified did not correspond to a service.x</b></body></html>\" ;", "del_tokens": "String expectedHTML = \"<!-- ~ Copyright 2014, The Sporting Exchange Limited ~ ~ Licensed under the Apache License, Version 2.0 (the \\\"License\\\"); ~ you may not use this file except in compliance with the License. ~ You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 ~ ~ Unless required by applicable law or agreed to in writing, software ~ distributed under the License is distributed on an \\\"AS IS\\\" BASIS, ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the License for the specific language governing permissions and ~ limitations under the License. --><!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\"><html xmlns=\\\"http://www.w3.org/1999/xhtml\\\"> <head> <title>Service not Found</title> </head> <body><b>The URL you specified did not correspond to a service.x</b></body></html>\" ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", ":", "expression", "output", "not", "correct", "in", "tag", "body", "-", "bring", "in", "with", "auto", "escape", "feature"], "add_tokens": "StringBuilder sbNew = new StringBuilder ( ) ; StringBuilder sbOld = _context . getOut ( ) ; _context . setOut ( sbNew ) ; this . _out = sbNew ; String s = sbNew . toString ( ) ; _context . setOut ( sbOld ) ; this . _out = null ; return s ; // _out.setLength(0); // call(); // return _out.toString();", "del_tokens": "_out . setLength ( 0 ) ; return _out . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "UNPROCESSABLE_ENTITY", "to", "the", "DSL"], "add_tokens": "return new Response ( ResponseCode . ACCEPTED , representation , headers ) ; } public static final Response UNPROCESSABLE_ENTITY ( HeaderField ... headers ) { return new Response ( ResponseCode . UNPROCESSABLE_ENTITY , Text ( \"422 Client Error: Unprocessable Entity\" ) , headers ) ; } public static final Response UNPROCESSABLE_ENTITY ( Representation representation , HeaderField ... headers ) { return new Response ( ResponseCode . UNPROCESSABLE_ENTITY , representation , headers ) ;", "del_tokens": "return new Response ( ResponseCode . ACCEPTED , representation , headers ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "following", "group", "id", "to", "global", "info"], "add_tokens": "if ( ( id >= 1011 && id <= 1081 ) || id == 2011 || id == 2031 || id == 2121 || id == 2071 || id == 2081 || id == 2091 || id == 2101 || id == 2111 || id == 2141 || id == 2211 ) { } else if ( id == 2142 ) { } else if ( id == 2092 ) { } else if ( id == 2112 ) { } else if ( id == 2102 ) {", "del_tokens": "if ( ( id >= 1011 && id <= 1081 ) || id == 2011 || id == 2031 || id == 2121 || id == 2071 || id == 2081 || id == 2211 ) { } else if ( id == 2141 || id == 2142 ) { } else if ( id == 2091 || id == 2092 ) { } else if ( id == 2111 || id == 2112 ) { } else if ( id == 2101 || id == 2102 ) {", "commit_type": "update"}
{"commit_tokens": ["Using", "the", "new", "Transport", "enum"], "add_tokens": "import io . pkts . packet . sip . Transport ; private final Transport transport ; final Transport transport , return this . transport . toUpperCaseBuffer ( ) ; return transport == Transport . udp ; return transport == Transport . tcp ; return transport == Transport . tls ; return transport == Transport . sctp ; } @ Override public boolean isWS ( ) { return transport == Transport . ws ; } @ Override public boolean isWSS ( ) { return transport == Transport . wss ;", "del_tokens": "private final Buffer transport ; final Buffer transport , return this . transport ; return SipParser . isUDP ( this . transport ) ; return SipParser . isTCP ( this . transport ) ; return SipParser . isTLS ( this . transport ) ; return SipParser . isSCTP ( this . transport ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "to", "allow", "signing", "of", "jars", "under", "libDirectory", "not", "just", "under", "workDirectory", "(", "which", "is", "the", "default", "libDirectory", ")", "."], "add_tokens": "int signedJars = signJars ( getLibDirectory ( ) , updatedJarFileFilter ) ;", "del_tokens": "int signedJars = signJars ( getWorkDirectory ( ) , updatedJarFileFilter ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "label", "/", "prefix", "to", "properties", "files", "in", "the", "native", "profile"], "add_tokens": "return clean ( environment . findOne ( application , profile , \"\" ) ) ;", "del_tokens": "return clean ( environment . findOne ( application , profile , label ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "class_name", "field"], "add_tokens": "assertEquals ( \"RollbarSerializerTest.java\" , lastFrame . get ( \"filename\" ) . getAsString ( ) ) ; assertEquals ( \"RollbarSerializerTest.java\" , secondToLastFrame . get ( \"filename\" ) . getAsString ( ) ) ; assertEquals ( \"com.rollbar.payload.RollbarSerializerTest\" , lastFrame . get ( \"class_name\" ) . getAsString ( ) ) ; assertEquals ( \"com.rollbar.payload.RollbarSerializerTest\" , secondToLastFrame . get ( \"class_name\" ) . getAsString ( ) ) ;", "del_tokens": "assertEquals ( \"com.rollbar.payload.RollbarSerializerTest.java\" , lastFrame . get ( \"filename\" ) . getAsString ( ) ) ; assertEquals ( \"com.rollbar.payload.RollbarSerializerTest.java\" , secondToLastFrame . get ( \"filename\" ) . getAsString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "little", "issue", "with", "UID"], "add_tokens": "null ,", "del_tokens": "String uid = configuration . getCurrentUid ( ) ; uid != null ? Arrays . asList ( ModelFactory . createTestReport ( uid ) ) : null ,", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "different", "directory", "for", "tests", "."], "add_tokens": "File file = new File ( new File ( new File ( \".\" ) , \"target\" ) , \"testfiles\" ) ; file . mkdirs ( ) ;", "del_tokens": "File file ; if ( System . getProperty ( \"os.name\" ) . toLowerCase ( ) . contains ( \"windows\" ) ) { file = new File ( System . getProperty ( \"java.io.tmpdir\" ) ) ; } else { file = new File ( \"/tmp\" ) ; } System . out . println ( \"First path:\" + file . getAbsolutePath ( ) ) ; file = new File ( file . getAbsoluteFile ( ) , String . valueOf ( dir ) ) ; file . mkdir ( ) ; System . out . println ( \"Second path:\" + file . getAbsolutePath ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "an", "errorCount", "in", "ThrowableInformationConverter", ".", "java", "to", "that", "it", "does", "not", "flood", "the", "status", "manager", "is", "case", "of"], "add_tokens": "final int MAX_ERROR_COUNT = 2 ; int errorCount = 0 ; if ( ++ errorCount <= MAX_ERROR_COUNT ) { addError ( \"Exception thrown for evaluator named [\" + ee . getName ( ) + \"]\" , eex ) ; }", "del_tokens": "addError ( \"Exception thrown for evaluator named [\" + ee . getName ( ) + \"]\" , eex ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "primitive", "to", "allow", "it", "to", "be", "resolved", "by", "@value", "in", "javadoc"], "add_tokens": "private static final int FIRST_NON_ROOT_PORT_NUMBER = 1024 ;", "del_tokens": "private static final Integer FIRST_NON_ROOT_PORT_NUMBER = 1024 ;", "commit_type": "use"}
{"commit_tokens": ["Add", "support", "for", "custom", "HTTP", "headers", "in", "API", "calls"], "add_tokens": "UnleashConfig . setRequestProperties ( connection , this . unleashConfig ) ;", "del_tokens": "connection . setRequestProperty ( \"UNLEASH-APPNAME\" , this . unleashConfig . getAppName ( ) ) ; connection . setRequestProperty ( \"UNLEASH-INSTANCEID\" , this . unleashConfig . getInstanceId ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "ie", "browser", "download", "json", "."], "add_tokens": "} else { }", "del_tokens": "System . out . println ( req . getHeader ( \"user-agent\" ) ) ; } else { }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "deregister", "managment", "to", "use", "id", "not", "name"], "add_tokens": "deregister ( getManagementServiceId ( ) ) ;", "del_tokens": "deregister ( getManagementServiceName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "more", "icon", "examples", "to", "sample"], "add_tokens": "* Holds static instances of Typefaces , and FontIcon sets .", "del_tokens": "* Holds static instances of Typefaces", "commit_type": "add"}
{"commit_tokens": ["removed", "unsupported", "test", "case", "from", "DocumentCRUDTest", "and", "added", "expected"], "add_tokens": "boolean exceptionRaised = false ; try { cookieBasedClient . generateApiKey ( ) ; exceptionRaised = false ; } catch ( Exception e ) { exceptionRaised = true ; } if ( exceptionRaised == false ) { Assert . fail ( \"Need to connect from cloudant using UserName & Password\" ) ; } boolean exceptionRaised = false ; cookieBasedClient = new CloudantClient (", "del_tokens": "cookieBasedClient . generateApiKey ( ) ; boolean exceptionRaised = true ; CloudantClient cookieBasedClient = new CloudantClient (", "commit_type": "remove"}
{"commit_tokens": ["added", "an", "mbean", "for", "working", "with", "the", "git", "repo"], "add_tokens": "import javax . management . MBeanServer ; import javax . management . ObjectName ; import java . lang . management . ManagementFactory ; public class GitFacade implements GitFacadeMXBean { private ObjectName objectName ; private MBeanServer mBeanServer ; public void init ( ) throws Exception { // now lets expose the mbean... if ( objectName == null ) { objectName = new ObjectName ( \"io.hawt.git:type=GitFacade\" ) ; } if ( mBeanServer == null ) { mBeanServer = ManagementFactory . getPlatformMBeanServer ( ) ; } mBeanServer . registerMBean ( this , objectName ) ; public void destroy ( ) throws Exception { if ( objectName != null && mBeanServer != null ) { mBeanServer . unregisterMBean ( objectName ) ; }", "del_tokens": "import org . eclipse . jgit . api . ResetCommand ; import java . util . Iterator ; public class GitFacade { public void init ( ) throws IOException , GitAPIException { public void destroy ( ) {", "commit_type": "add"}
{"commit_tokens": ["add", "rythm", ".", "logger", ".", "disabled", "configuration"], "add_tokens": "import com . greenlaw110 . rythm . logger . NullLogger ; public static final String version = \"1.0-SNAPSHOT\" ; boolean disableLogging = configuration . getAsBoolean ( \"rythm.logger.disabled\" , false ) ; if ( disableLogging ) { Logger . registerLoggerFactory ( new NullLogger . Factory ( ) ) ; } else { ILoggerFactory fact = configuration . getAs ( \"rythm.logger.factory\" , null , ILoggerFactory . class ) ; if ( null != fact ) Logger . registerLoggerFactory ( fact ) ; }", "del_tokens": "public static final String version = \"1.0\" ; ILoggerFactory fact = configuration . getAs ( \"rythm.logger.factory\" , null , ILoggerFactory . class ) ; if ( null != fact ) Logger . registerLoggerFactory ( fact ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "single", "or", "double", "quotes", "for", "literals"], "add_tokens": "final private char delimiter ; private int delims ; public TokLiteral ( final char p_delimiter ) this . delimiter = p_delimiter ; if ( c != delimiter )", "del_tokens": "private int delims ; public TokLiteral ( ) if ( c != '\\'' )", "commit_type": "allow"}
{"commit_tokens": ["Fix", "handling", "of", "jobs", "which", "disallow", "concurrent", "execution"], "add_tokens": "if ( logger . isDebugEnabled ( ) ) { logger . debug ( \"misfired trigger: \" + triggerTuple . getElement ( ) ) ; } if ( logger . isTraceEnabled ( ) ) { logger . trace ( \"Attempting to acquire job \" + job . getKey ( ) + \" with concurrent execution disallowed.\" ) ; } if ( acquiredJobHashKeysForNoConcurrentExec . contains ( jobHashKey ) ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( \"Job \" + job . getKey ( ) + \" with concurrent execution disallowed already acquired.\" ) ; } } else { if ( logger . isTraceEnabled ( ) ) { logger . trace ( \"Job \" + job . getKey ( ) + \" with concurrent execution disallowed not yet acquired. Acquiring.\" ) ; }", "del_tokens": "logger . debug ( \"misfired trigger: \" + triggerTuple . getElement ( ) ) ; if ( acquiredJobHashKeysForNoConcurrentExec . contains ( jobHashKey ) ) { } else {", "commit_type": "fix"}
{"commit_tokens": ["Implement", "an", "easier", "more", "flexiable", "method", "for", "upload", "files", "to", "histories", "(", "file", "type", "defaults", "to", "auto", "db", "key", "defaults", "to", "?", "can", "override", "tool", "id", "can", "upload", "multiple", "files", "(", "if", "tool", "supports", "it", "))", "."], "add_tokens": "import java . util . ArrayList ; protected Iterable < BodyPart > prepareUploads ( final Iterable < File > files ) { final List < BodyPart > bodyParts = new ArrayList < BodyPart > ( ) ; int index = 0 ; for ( final File file : files ) { final String paramName = String . format ( \"files_%d|file_data\" , index ++ ) ; final FileDataBodyPart fdbp = new FileDataBodyPart ( paramName , file ) ; bodyParts . add ( fdbp ) ; } return bodyParts ; } return prepareUploads ( Arrays . asList ( file ) ) ;", "del_tokens": "final FileDataBodyPart fdbp = new FileDataBodyPart ( \"files_0|file_data\" , file ) ; return Arrays . < BodyPart > asList ( fdbp ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "tests", "which", "were", "failing", "after", "the", "addition", "of", "metrics"], "add_tokens": "new MetricRegistry ( ) , Clock . systemUTC ( ) ) ; new MetricRegistry ( ) , Clock . systemUTC ( ) ) ; new MetricRegistry ( ) , Clock . systemUTC ( ) ) ;", "del_tokens": "mock ( MetricRegistry . class ) , Clock . systemUTC ( ) ) ; mock ( MetricRegistry . class ) , Clock . systemUTC ( ) ) ; mock ( MetricRegistry . class ) , Clock . systemUTC ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "char", "conversion", "."], "add_tokens": "CONVERSIONS . put ( Character . class , new Conversion < Character > ( ' ' ) { @ Override public Character convert ( String data ) { if ( data . length ( ) == 1 ) { return data . charAt ( 0 ) ; } String trimmed = data . trim ( ) ; return trimmed . isEmpty ( ) ? getDefaultValue ( ) : trimmed . charAt ( 0 ) ; } } ) ; CONVERSIONS . put ( Character . TYPE , CONVERSIONS . get ( Character . class ) ) ; // CONVERSIONS.put(Node.class, new Conversion<Node>(null){ // @Override // public Node convert(String data) { // return null; // }}); assert type != null ; public < T > DefaultTypeConverter setConversionForType ( final Class < T > type , final Conversion < T > conversion ) { assert type != null ; if ( conversion == null ) {", "del_tokens": "// CONVERSIONS.put(Node.class, new Conversion<Node>(null){ // @Override // public Node convert(String data) { // return null; // }}); assert type != null ; public < T > DefaultTypeConverter setConversionForType ( final Class < T > type , final Conversion < T > conversion ) { assert type != null ; if ( conversion == null ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "so", "that", "FilteredNodeChildren", "is", "translated", "to", "a", "List", "of", "Nodes"], "add_tokens": "* List < Node > itemsBetweenTenAndTwenty = with ( XML ) . get ( \"shopping.category.item.findAll { item -> def price = item.price.toFloat(); price >= 10 && price <= 20 }\" ) ;", "del_tokens": "* NodeChildren itemsBetweenTenAndTwenty = with ( XML ) . get ( \"shopping.category.item.findAll { item -> def price = item.price.toFloat(); price >= 10 && price <= 20 }\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "really", "executable", "jars", "(", "abandon", "ZipFS", ")"], "add_tokens": "return launchCapsule ( CapsuleLauncher . newCapsule ( capsulePath , cacheDir ) , cmdLine , args ) ;", "del_tokens": "return launchCapsule ( CapsuleLauncher . getCapsule ( capsulePath , cacheDir ) , cmdLine , args ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "end_user_last_seen", "documentation", "code", "cleanup", "and", "bug", "fix"], "add_tokens": "/ * * Copyright ( c ) 2016 Wootric ( https : //wootric.com) * * Permission is hereby granted , free of charge , to any person obtaining a copy * of this software and associated documentation files ( the \"Software\" ) , to deal * in the Software without restriction , including without limitation the rights * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell * copies of the Software , and to permit persons to whom the Software is * furnished to do so , subject to the following conditions : * * The above copyright notice and this permission notice shall be included in * all copies or substantial portions of the Software . * * THE SOFTWARE IS PROVIDED \"AS IS\" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR * IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER * LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN * THE SOFTWARE . * /", "del_tokens": "import android . util . Log ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "locations", "for", "amazon", "rds", "service", "fail", "-", "over"], "add_tokens": "ClassPathXmlApplicationContext classPathXmlApplicationContext = new ClassPathXmlApplicationContext ( getClass ( ) . getSimpleName ( ) + \"-maxNumberOfRetries.xml\" , getClass ( ) ) ;", "del_tokens": "ClassPathXmlApplicationContext classPathXmlApplicationContext = new ClassPathXmlApplicationContext ( getClass ( ) . getSimpleName ( ) + \"-maxNUmberOfRetries.xml\" , getClass ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "YAML", "mapper", "to", "JAX", "-", "RS"], "add_tokens": "private final ServiceAnnotationClassesProvider annotationProvider ; private final AtomicReference < OpenAPI > swaggerCache = new AtomicReference < > ( ) ; @ Autowired public ApiListing ( ServiceAnnotationClassesProvider annotationProvider ) { this . annotationProvider = annotationProvider ; } @ Autowired ( required = false ) public void setConfig ( OpenApiModification config ) { this . config = config ; } if ( openAPI != null ) { return Response . ok ( ) . entity ( openAPI ) . type ( \"application/yaml\" ) . build ( ) ;", "del_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import io . swagger . v3 . core . util . Yaml ; @ Autowired private ServiceAnnotationClassesProvider annotationProvider ; @ Autowired ( required = false ) private final AtomicReference < OpenAPI > swaggerCache = new AtomicReference < > ( ) ; private static final Logger LOGGER = LoggerFactory . getLogger ( ApiListing . class ) ; try { if ( openAPI != null ) { return Response . ok ( Response . Status . OK ) . entity ( Yaml . mapper ( ) . writeValueAsString ( openAPI ) ) . type ( \"application/yaml\" ) . build ( ) ; } } catch ( Exception e ) { LOGGER . error ( \"Failed to create YAML\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "javadoc", "links", "in", "TCK"], "add_tokens": "* < b > Technology Compatibility Kit < / b > ( TCK ) for { @ link Objenesis } s . * < p / > * This TCK accepts a set of candidate classes ( class it attempts to instantiate ) and a set of * Objenesis implementations . It then tries instantiating every candidate with every Objenesis * implementations , reporting the results to a { @ link Reporter } . * @ see org . objenesis . instantiator . ObjectInstantiator private final List objenesisInstances = new ArrayList ( ) ; private final List candidates = new ArrayList ( ) ; private final Map descriptions = new HashMap ( ) ;", "del_tokens": "* < b > Technology Compatibility Kit < / b > ( TCK ) for { @ link Objenesis } s . < p / > This TCK accepts a set * of candidate classes ( class it attempts to instantiate ) and a set of Objenesis implementations . * It then tries instantiating every candidate with every Objenesis implementations , reporting the * results to a { @ link Reporter } . * @ see ObjectInstantiator private List objenesisInstances = new ArrayList ( ) ; private List candidates = new ArrayList ( ) ; private Map descriptions = new HashMap ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "SecureDirectoryStream", "tests", "."], "add_tokens": "import java . util . ArrayList ; import java . util . List ; * Asserts that the directory has children with the given names , in the given order . List < Path > expectedNames = new ArrayList < > ( ) ; List < Path > actualNames = new ArrayList < > ( ) ;", "del_tokens": "* Asserts that the directory has children with the given names . Set < Path > expectedNames = new HashSet < > ( ) ; Set < Path > actualNames = new HashSet < > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "logging", "for", "underline", "http", "connections"], "add_tokens": "System . setProperty ( \"org.apache.commons.logging.simplelog.log.org.apache.http.impl.conn\" , \"debug\" ) ; System . setProperty ( \"org.apache.commons.logging.simplelog.log.org.apache.http.impl.client\" , \"debug\" ) ;", "del_tokens": "System . setProperty ( \"org.apache.commons.logging.simplelog.log.org.apache.http.headers\" , \"debug\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "skipped", "optionals", "caused", "bad", "rendering"], "add_tokens": "if ( ! branch . containsNothing ( ) ) { group . add ( branch ) ; } boolean containsNothing ( ) { if ( alt . isEmpty ( ) ) { return true ; } for ( Diagram . Figure f : alt ) { if ( ! f . isNothing ( ) ) { return false ; } } return true ; }", "del_tokens": "group . add ( branch ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "methods", "to", "allow", "setup", "from", "collection", "(", "object", ")", "when", "executing", "query"], "add_tokens": "/ * * * Same as < code > from ( Collections . singleton ( bean ) ) < / code > * / public BeanQuery < T > from ( Object bean ) { this . from = Collections . singleton ( bean ) ; return this ; } / * * * A convenient method of from ( from ) . execute ( ) ; * / public List < T > executeFrom ( Collection < ? > from ) { return from ( from ) . execute ( ) ; } / * * * Execute from a bean to check does it match the filtering condition and * convert it . * / public T executeFrom ( Object bean ) { List < T > executeFromCollectionResult = executeFrom ( Collections . singleton ( bean ) ) ; if ( CollectionUtils . isEmpty ( executeFromCollectionResult ) ) { return null ; } else { return executeFromCollectionResult . get ( 0 ) ; } } if ( null != this . comparator && copied . size ( ) > 1 ) {", "del_tokens": "if ( null != this . comparator ) {", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "customize", "the", "feature", "admin", "flag", "in", "JAASUserProvider"], "add_tokens": "import org . togglz . core . user . UserProvider ; * determining whether a user is a feature admin and therefore always sets it to false . Overriding * { @ link # isFeatureAdmin ( String ) } allows to change the default behavior . String name = iter . next ( ) . getName ( ) ; return new SimpleFeatureUser ( name , isFeatureAdmin ( name ) ) ; / * * * Checks if the supplied user is a feature admin . The default implementation always returns < code > false < / code > . Users can * overwrite this method to implement a different behavior . * * @ param user The name of the user * @ return < code > true < / code > for feature admins , < code > false < / code > otherwise * / protected boolean isFeatureAdmin ( String user ) { return false ; }", "del_tokens": "import org . togglz . core . user . UserProvider ; * determining whether a user is a feature admin . return new SimpleFeatureUser ( iter . next ( ) . getName ( ) , false ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "configurability", "for", "field", "name", "of", "RuleChain", "test", "rule", "list", "."], "add_tokens": "import com . nordstrom . automation . junit . JUnitConfig . JUnitSettings ; Field ruleChainList ; String fieldName = JUnitConfig . getConfig ( ) . getString ( JUnitSettings . RULE_CHAIN_LIST . key ( ) ) ; ruleChainList = RuleChain . class . getDeclaredField ( fieldName ) ; ruleChainList . setAccessible ( true ) ; return ( List < TestRule > ) ruleChainList . get ( ruleChain ) ;", "del_tokens": "Field field ; field = RuleChain . class . getDeclaredField ( \"rulesStartingWithInnerMost\" ) ; field . setAccessible ( true ) ; return ( List < TestRule > ) field . get ( ruleChain ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "test", "of", "timestamps", "containing", "arbitrary", "version", "#s", "."], "add_tokens": "import java . util . Random ; //@Test TODO(carterpage) - enable once implemented putGetDeleteExists ( table , rowKey , testQualifier , testValue ) ; } //@Test TODO(carterpage) - enable once implemented public void testBinaryPutGetDelete ( ) throws IOException { // Initialize HTableInterface table = connection . getTable ( TABLE_NAME ) ; Random random = new Random ( ) ; byte [ ] rowKey = new byte [ 100 ] ; random . nextBytes ( rowKey ) ; byte [ ] testQualifier = new byte [ 100 ] ; random . nextBytes ( testQualifier ) ; byte [ ] testValue = new byte [ 100 ] ; random . nextBytes ( testValue ) ; // TODO(carterpage) - need to test that column-family can work as raw binary // Put putGetDeleteExists ( table , rowKey , testQualifier , testValue ) ; } private void putGetDeleteExists ( HTableInterface table , byte [ ] rowKey , byte [ ] testQualifier , byte [ ] testValue ) throws IOException {", "del_tokens": "//@Test TODO - enable once implemented", "commit_type": "implement"}
{"commit_tokens": ["Make", "get", "/", "remove", "content", "public", "."], "add_tokens": "/ * * * Does not unbind scrolling from Content before returning Content . * @ return - the content * / public V getContent ( ) { return content ; } public V removeContent ( ) {", "del_tokens": "V removeContent ( ) {", "commit_type": "make"}
{"commit_tokens": ["Change", "visibility", "of", "CastChannel", "class", "to", "package", "level", "since", "it", "is", "for", "internal", "use", "when", "writing", "proto", "-", "buf", "messages"], "add_tokens": "final class CastChannel {", "del_tokens": "public final class CastChannel {", "commit_type": "change"}
{"commit_tokens": ["Remove", "threadlocal", "from", "cookie", "operations", "on", "request"], "add_tokens": "private Map < String , Cookie > cookies = C . newMap ( ) ; cookies . put ( name , cookie ) ; if ( cookies . isEmpty ( ) ) { return cookies . get ( name ) ; public List < H . Cookie > cookies ( ) { if ( cookies . isEmpty ( ) ) { return C . list ( cookies . values ( ) ) ;", "del_tokens": "Current . setCookie ( name , cookie ) ; if ( ! Current . cookieMapInitialized ( ) ) { return Current . getCookie ( name ) ; public Iterable < H . Cookie > cookies ( ) { if ( ! Current . cookieMapInitialized ( ) ) { return Current . cookies ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "type", "-", "level", "@PathPrefix", "annotation", "+", "path", "concatenation", "handling", "add", "query", "parsing", "and", "inclusion", "in", "request", "params", "()", "with", "q", ":", "<name", ">", "key", "format", "add", "built", "-", "in", "parameters", "_classBase", "(", "path", "up", "to", "and", "including", "@PathPrefix", "path", ")", "and", "_routeBase", "(", "path", "up", "to", "and", "including", "@Route", "path", "but", "excluding", "anything", "after", "the", "beginning", "of", "the", "first", "path", "parameter", "in", "the", "uri", ")", "."], "add_tokens": "String value ( ) default \"\" ; String path ( ) default \"\" ; Method method ( ) default Method . GET ;", "del_tokens": "String path ( ) ; Method method ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "OnTabSelectedListener", "to", "be", "called", "after", "change", "has", "been", "made", "(", "like", "ViewPager", "and", "TabLayout", "implementations", ")"], "add_tokens": "int oldPosition = mSelectedPosition ; if ( callListener ) sendListenerCall ( oldPosition , newPosition ) ; void onTabSelected ( int position ) ; void onTabUnselected ( int position ) ; void onTabReselected ( int position ) ; } / * * * Simple implementation of the OnTabSelectedListener interface with stub implementations of each method . * Extend this if you do not intend to override every method of OnTabSelectedListener . * / public class SimpleOnTabSelectedListener implements OnTabSelectedListener { @ Override public void onTabSelected ( int position ) { } @ Override public void onTabUnselected ( int position ) { } @ Override public void onTabReselected ( int position ) { }", "del_tokens": "if ( callListener ) sendListenerCall ( mSelectedPosition , newPosition ) ; public void onTabSelected ( int position ) ; public void onTabUnselected ( int position ) ; public void onTabReselected ( int position ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "exec", "()", "and", "flatMap", "()", "methods", "to", "Either", "."], "add_tokens": "return hook ( either -> either . exec ( leftSideEffect , rightSideEffect ) ) ; return split ( either -> either . flatMap ( leftMap , rightMap ) ) ; return split ( either -> either . flatMapLeft ( leftMap ) ) ; return split ( either -> either . flatMapRight ( rightMap ) ) ;", "del_tokens": "return hook ( either -> { either . ifLeft ( leftSideEffect ) ; either . ifRight ( rightSideEffect ) ; } ) ; return split ( either -> either . isLeft ( ) ? leftMap . apply ( either . getLeft ( ) ) : rightMap . apply ( either . getRight ( ) ) ) ; return split ( leftMap , Either :: right ) ; return split ( Either :: left , rightMap ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "reporting", "instances", "to", "use", "BugInstance", ".", "addCalledMethod", "()", "where"], "add_tokens": "bugReporter . reportBug ( new BugInstance ( \"FI_NULLIFY_SUPER\" , NORMAL_PRIORITY ) . addClassAndMethod ( this ) . addCalledMethod ( this ) ) ; bugReporter . reportBug ( new BugInstance ( \"FI_EXPLICIT_INVOCATION\" , NORMAL_PRIORITY ) . addClassAndMethod ( this ) . addCalledMethod ( this ) ) ;", "del_tokens": "bugReporter . reportBug ( new BugInstance ( \"FI_NULLIFY_SUPER\" , NORMAL_PRIORITY ) . addClassAndMethod ( this ) ) ; bugReporter . reportBug ( new BugInstance ( \"FI_EXPLICIT_INVOCATION\" , NORMAL_PRIORITY ) . addClassAndMethod ( this ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "mandatory", "attribute", "to", "context", "parameter", "annotation", "."], "add_tokens": "* < p > * If tiny container start ends in fatal error , signal the host container that hopefully will stop the application . Stack * trace is dumped to logger . // WARN: if development context is declared it can access private resources without authentication } catch ( Error | RuntimeException e ) { log . dump ( String . format ( \"Fatal error on container |%s| start:\" , appName ) , e ) ; log . debug ( \"Signal fatal error |%s| to host container. Application abort.\" , e . getClass ( ) ) ; throw e ;", "del_tokens": "// WARN: if development context is declared it can access private resources without authentication } catch ( Throwable t ) { log . dump ( String . format ( \"Fatal error on container |%s| start:\" , appName ) , t ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "from", "gradle", "to", "maven"], "add_tokens": "* @ param versionzwei Versionsobjekt welches zum vergleich rangezogen werden soll", "del_tokens": "* @ param a Versionsobjekt welches zum vergleich rangezogen werden soll", "commit_type": "change"}
{"commit_tokens": ["fixed", "a", "bug", "where", "the", "auto", "-", "generated", "constructors", "(", "actual", "or", "static", ")", "would", "throw", "eclipse", "errors", "if", "you", "had", "0", "non", "-", "static", "fields", "."], "add_tokens": "constructor . statements = assigns . isEmpty ( ) ? null : assigns . toArray ( new Statement [ assigns . size ( ) ] ) ; constructor . arguments = args . isEmpty ( ) ? null : args . toArray ( new Argument [ args . size ( ) ] ) ; statement . arguments = assigns . isEmpty ( ) ? null : assigns . toArray ( new Expression [ assigns . size ( ) ] ) ; constructor . arguments = args . isEmpty ( ) ? null : args . toArray ( new Argument [ args . size ( ) ] ) ;", "del_tokens": "constructor . statements = assigns . toArray ( new Statement [ assigns . size ( ) ] ) ; constructor . arguments = args . toArray ( new Argument [ args . size ( ) ] ) ; statement . arguments = assigns . toArray ( new Expression [ assigns . size ( ) ] ) ; constructor . arguments = args . toArray ( new Argument [ args . size ( ) ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "all", "fields", "are", "updated", "."], "add_tokens": "ss = new StepServer ( tc , if ( ! text . getText ( ) . trim ( ) . isEmpty ( ) ) { ss . setText ( text . getText ( ) . trim ( ) . getBytes ( \"UTF-8\" ) ) ; } if ( ! notes . getText ( ) . trim ( ) . isEmpty ( ) ) { ss . setNotes ( notes . getText ( ) . trim ( ) ) ; } final RequirementSelectionDialog dialog = new RequirementSelectionDialog ( new javax . swing . JFrame ( ) ,", "del_tokens": "ss = new StepServer ( tc , final RequirementSelectionDialog dialog = new RequirementSelectionDialog ( new javax . swing . JFrame ( ) ,", "commit_type": "make"}
{"commit_tokens": ["Change", "executeThreadHbTime", "in", "class", "TaskHeartbeatTrigger", "to", "volatile", "."], "add_tokens": "private volatile long executeThreadHbTime ;", "del_tokens": "private long executeThreadHbTime ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "startup", "race", "adding", "cache", "bucket", "asking", "for", "failures", "."], "add_tokens": "import java . util . concurrent . CountDownLatch ; private Selector selector ; private CountDownLatch listenLatch ; this . listenLatch = new CountDownLatch ( 0 ) ; listenLatch . await ( ) ; if ( selector == null || ! selector . isOpen ( ) ) { selector = Selector . open ( ) ; server . register ( selector , SelectionKey . OP_ACCEPT ) ; } System . err . println ( e . getLocalizedMessage ( ) ) ; } catch ( InterruptedException ex ) { System . err . println ( ex . getLocalizedMessage ( ) ) ; public void shutdown ( ) { try { this . listenLatch = new CountDownLatch ( 1 ) ; this . selector . close ( ) ; } catch ( IOException ex ) { Logger . getLogger ( MemcachedServer . class . getName ( ) ) . log ( Level . SEVERE , null , ex ) ; } } public void startup ( ) { this . listenLatch . countDown ( ) ; }", "del_tokens": "private final Selector selector ; selector = Selector . open ( ) ; server . register ( selector , SelectionKey . OP_ACCEPT ) ; e . printStackTrace ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "v2", "implementation", "of", "list", "datastreams", "that", "utilises", "mongo", "directly", "and", "provides", "more", "metadata", "."], "add_tokens": "router . attach ( \"/v2/datastream/{oid}/list\" , com . googlecode . fascinator . redbox . ws . v2 . resources . ListDatastreamResource . class ) ;", "del_tokens": "router . attach ( \"/v2/datastream/{oid}/list\" , ListDatastreamResource . class ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "package", "-", "private", "build", "()", "to", "the", "builders", "to", "obtain", "instances", "of", "channel", "tag", "and", "property", "needed", "by", "unit", "tests"], "add_tokens": "XmlProperty toXml ( ) { Property build ( ) { return new Property ( this ) ; } private Property ( Builder builder ) { this . name = builder . name ; this . value = builder . value ; this . owner = builder . owner ; } / * * ( non - Javadoc ) * / * * ( non - Javadoc ) *", "del_tokens": "import javax . xml . bind . annotation . XmlAttribute ; import javax . xml . bind . annotation . XmlElement ; import javax . xml . bind . annotation . XmlRootElement ; import javax . xml . bind . annotation . XmlTransient ; import javax . xml . bind . annotation . XmlType ; XmlProperty toXml ( ) { / * ( non - Javadoc ) / * ( non - Javadoc )", "commit_type": "add"}
{"commit_tokens": ["Improved", "the", "error", "handling", "in", "the", "dashboard"], "add_tokens": "try { Planner planner = new Planner ( yaml ) ; response . setCharacterEncoding ( \"UTF-8\" ) ; response . getWriter ( ) . write ( planner . plan ( ) ) ; } catch ( Exception e ) { response . sendError ( 500 , \"Error processing Application Model\" ) ; }", "del_tokens": "Planner planner = new Planner ( yaml ) ; response . setCharacterEncoding ( \"UTF-8\" ) ; response . getWriter ( ) . write ( planner . plan ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Updated", "Iso8601TimepointAdapterTest", "to", "correspond", "with", "Iso8601TimepointAdapter", "output", "(", "don", "t", "include", "milliseconds", ")", "."], "add_tokens": "assertEquals ( \"2010-04-07T13:30:37Z\" , adapter . format ( calendar . getTime ( ) ) ) ;", "del_tokens": "assertEquals ( \"2010-04-07T13:30:37.123Z\" , adapter . format ( calendar . getTime ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["fix", "variable", "bug", "and", "improve", "tests", "so", "that", "there", "are", "no", "dependencies", "to", "the", "multiply", "()", "method"], "add_tokens": "private Matrix exponentBySqaring ( Matrix x , int n , Factory factory ) {", "del_tokens": "private Matrix exponentBySqaring ( Matrix x , int n , Factory factory2 ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "sync", "on", "code", "part", "that", "generates", "the", "loggingKeys", "map"], "add_tokens": "synchronized ( instance ) { if ( loggingKeys == null ) { logger . info ( \"Initializing 'LoggingKeysHandler' class\" ) ; loggingKeys = new LoggingKeysHandler ( keysPropStream ) ; } } initInstance ( instance , logger , auditor ) ; setInstance ( instance ) ; synchronized ( instance ) { if ( loggingKeys == null ) { logger . info ( \"Initializing 'LoggingKeysHandler' class\" ) ; loggingKeys = new LoggingKeysHandler ( keysPropStream ) ; } }", "del_tokens": "loggingKeys = new LoggingKeysHandler ( keysPropStream ) ; initInstance ( instance , logger , auditor ) ; setInstance ( instance ) ; loggingKeys = new LoggingKeysHandler ( keysPropStream ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "JSON", "-", "LD", "support", "."], "add_tokens": "import org . ldp4j . server . impl . JSONLDMediaTypeProvider ; addAsServiceProvider ( IMediaTypeProvider . class , TurtleMediaTypeProvider . class , RDFXMLMediaTypeProvider . class , JSONLDMediaTypeProvider . class ) ;", "del_tokens": "addAsServiceProvider ( IMediaTypeProvider . class , TurtleMediaTypeProvider . class , RDFXMLMediaTypeProvider . class ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "platform", "id", "mappers", "for", "jdbi", "."], "add_tokens": "import com . nesscomputing . types . PlatformId ; public static < U > PlatformIdArgument < U > forPlatformid ( final PlatformId < U > platformIdValue ) { return new PlatformIdArgument < U > ( platformIdValue ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "non", "european", "chars", "+", "removed", "excessive", "normalisation", "during", "lookup", "of", "lexicon"], "add_tokens": "// tokenForm = tokenForm.replaceAll(\"\\\\W+\", \"_\");", "del_tokens": "tokenForm = tokenForm . replaceAll ( \"\\\\W+\" , \"_\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "SQS", "permissions", "and", "added", "integration", "test"], "add_tokens": "sqsExecutorBuilder , element , \"queue-url\" ) ;", "del_tokens": "sqsExecutorBuilder , element , \"queue-arn\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["added", "code", "and", "updated", "resources", "to", "prepare", "for", "the", "ACE", "Tern", "2005", "corpus"], "add_tokens": "// get rid of expressions such as \"1999\" in 53453.1999 if ( r . start ( ) > 1 ) { if ( ( s . getCoveredText ( ) . substring ( r . start ( ) - 2 , r . start ( ) ) . matches ( \"\\\\d\\\\.\" ) ) ) { ok = false ; } } // get rid of expressions if there is a character or symbol ($+) directly in front of the expression if ( ( ( s . getCoveredText ( ) . substring ( r . start ( ) - 1 , r . start ( ) ) . matches ( \"[\\\\w\\\\$\\\\+\\\\-]\" ) ) ) &&", "del_tokens": "if ( ( ( s . getCoveredText ( ) . substring ( r . start ( ) - 1 , r . start ( ) ) . matches ( \"\\\\w\" ) ) ) &&", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "annotation", "@JGivenConfiguration", "."], "add_tokens": "List < Tag > tags = new ReportModelBuilder ( ) . toTags ( AnnotationTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = new ReportModelBuilder ( ) . toTags ( AnnotationWithSingleValueTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = new ReportModelBuilder ( ) . toTags ( AnnotationWithArrayValueTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = new ReportModelBuilder ( ) . toTags ( AnnotationWithoutExplodedArrayValueTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = new ReportModelBuilder ( ) . toTags ( AnnotationWithDescription . class . getAnnotations ( ) [ 0 ] ) ;", "del_tokens": "List < Tag > tags = ReportModelBuilder . toTags ( AnnotationTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = ReportModelBuilder . toTags ( AnnotationWithSingleValueTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = ReportModelBuilder . toTags ( AnnotationWithArrayValueTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = ReportModelBuilder . toTags ( AnnotationWithoutExplodedArrayValueTestClass . class . getAnnotations ( ) [ 0 ] ) ; List < Tag > tags = ReportModelBuilder . toTags ( AnnotationWithDescription . class . getAnnotations ( ) [ 0 ] ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "Swift", "authentication", "fixing", "bug", "in", "standard", "authentication"], "add_tokens": "private String storageToken ; public AuthenticationContext ( @ Nonnull String regionId , @ Nonnull String token , @ Nonnull String tenantId , @ Nonnull Map < String , Map < String , String > > services , @ Nullable String storageToken ) { this . storageToken = storageToken ; public String getStorageToken ( ) { if ( storageToken == null ) { return getAuthToken ( ) ; } return storageToken ; }", "del_tokens": "public AuthenticationContext ( @ Nonnull String regionId , @ Nonnull String token , @ Nonnull String tenantId , @ Nonnull Map < String , Map < String , String > > services ) {", "commit_type": "add"}
{"commit_tokens": ["Change", "verbage", "to", "be", "more", "clear"], "add_tokens": "logger . debug ( \"No children operators for this operator. Tuple now being passed on \" + tuple ) ;", "del_tokens": "logger . debug ( \"No children swallowing \" + tuple ) ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "dependency", "on", "logula", "."], "add_tokens": "Module module = MODULE $ . moduleByFileName ( file ) ;", "del_tokens": "Module module = MODULE $ . moduleByFileName ( file , verbose ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "throw", "on", "impossible", "state"], "add_tokens": "throw new IllegalStateException ( \"An AssertionError should have been thrown.\" ) ;", "del_tokens": "return reference ;", "commit_type": "add"}
{"commit_tokens": ["allow", "customization", "of", "turbine", "clusterName", "via", "SPEL", "expression", "in", "applcation", ".", "properties", "."], "add_tokens": "import org . springframework . expression . Expression ; import org . springframework . expression . spel . standard . SpelExpressionParser ; import org . springframework . expression . spel . support . StandardEvaluationContext ; private final Expression clusterNameExpression ; public EurekaInstanceDiscovery ( TurbineProperties turbineProperties ) { SpelExpressionParser parser = new SpelExpressionParser ( ) ; clusterNameExpression = parser . parseExpression ( turbineProperties . getClusterNameExpression ( ) ) ; StandardEvaluationContext context = new StandardEvaluationContext ( iInfo ) ; Object value = clusterNameExpression . getValue ( context ) ; if ( value != null ) { return value . toString ( ) ; } return null ;", "del_tokens": "public EurekaInstanceDiscovery ( ) { //TODO: make ASG configurable using app name for demo. //return iInfo.getASGName(); //AppGroupName is UPPERCASE from eureka //return iInfo.getAppGroupName(); return iInfo . getAppName ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["update", "README", "and", "add", "final", "modifier", "to", "classes"], "add_tokens": "public final class Base32 {", "del_tokens": "public class Base32 {", "commit_type": "update"}
{"commit_tokens": ["Implemented", "Long", "ACAS", "(", "DF16", ")", "and", "added", "it", "to", "decoders"], "add_tokens": "import org . opensky . libadsb . msgs . LongACAS ; LongACAS long_acas = ( LongACAS ) msg ; System . out . println ( \"[\" + icao24 + \"]: Altitude is \" + long_acas . getAltitude ( ) + \" and ACAS is \" + ( long_acas . hasOperatingACAS ( ) ? \"operating.\" : \"not operating.\" ) ) ; System . out . println ( \" A/C is \" + ( long_acas . isAirborne ( ) ? \"airborne\" : \"on the ground\" ) + \" and sensitivity level is \" + long_acas . getSensitivityLevel ( ) ) ; System . out . println ( \" RAC is \" + ( long_acas . hasValidRAC ( ) ? \"valid\" : \"not valid\" ) + \" and is \" + long_acas . getResolutionAdvisoryComplement ( ) + \" (MTE=\" + long_acas . hasMultipleThreats ( ) + \")\" ) ;", "del_tokens": "System . out . println ( \"[\" + icao24 + \"]: Long ACAS message\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "select", "disabled", "time", "by", "dragging", "over", "it"], "add_tokens": "if ( mMinTime != null && mMinTime . compareTo ( midday ) > 0 ) return true ; if ( mMaxTime != null && mMaxTime . compareTo ( midday ) < 0 ) return true ; if ( mMinTime != null && mMinTime . compareTo ( time ) > 0 ) return mMinTime ; if ( mMaxTime != null && mMaxTime . compareTo ( time ) < 0 ) return mMaxTime ;", "del_tokens": "if ( mMinTime != null && mMinTime . compareTo ( midday ) > 0 ) return true ; if ( mMaxTime != null && mMaxTime . compareTo ( midday ) < 0 ) return true ; if ( mMinTime != null && mMinTime . compareTo ( time ) > 0 ) return mMinTime ; if ( mMaxTime != null && mMaxTime . compareTo ( time ) < 0 ) return mMaxTime ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "Node", "not", "a", "bean", "so", "that", "the", "property", "access", "can", "look", "into", "its", "children", "and", "things", "like", "name", "()", "value", "()", "text", "()", "and", "children", "()", "are", "functions", "like", "XPath", "."], "add_tokens": "Object parentValue = current . value ( ) ; //System.out.println(\"Created node: \" + node);", "del_tokens": "Object parentValue = current . getValue ( ) ; System . out . println ( \"Created node: \" + node ) ;", "commit_type": "make"}
{"commit_tokens": ["Improved", "reporting", "for", "when", "goals", "/", "plans", "are", "not", "found", "at", "runtime"], "add_tokens": "if ( gtype == null ) { throw new JillException ( Log . logPrefix ( agent . getId ( ) ) + \" has no goal matching \" + node . getClass ( ) . getName ( ) ) ; } if ( ptypes == null ) { throw new JillException ( Log . logPrefix ( agent . getId ( ) ) + \" has no plans for handling goal \" + node . getClass ( ) . getName ( ) ) ; }", "del_tokens": "assert ( ptypes != null ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "for", "negative", "ids", "."], "add_tokens": "while ( map . containsKey ( id ) ) { id = Math . abs ( ( int ) Math . round ( Math . random ( ) * Integer . MAX_VALUE ) ) ; }", "del_tokens": "while ( map . containsKey ( id ) ) id = ( int ) Math . round ( Math . random ( ) * Integer . MAX_VALUE ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "string", "(", "Collection", ")", "and", "toString", "(", "Collection", ")", "."], "add_tokens": "public static List < String > toString ( Collection o ) { public static List < String > string ( Collection o ) {", "del_tokens": "public static List < String > toString ( Collection < Object > o ) { public static List < String > string ( Collection < Object > o ) {", "commit_type": "update"}
{"commit_tokens": ["remove", "new", "line", "character", "in", "context", "clue", "--", "avoid", "unexpected", "formatting"], "add_tokens": "context . setTargetConcept ( concept . getCoveredText ( ) . replaceAll ( \"[\\\\n|\\\\r]\" , \" \" ) + \" (\" + concept . getBegin ( ) + \"~\" + concept . getEnd ( ) + \")\" ) ;", "del_tokens": "context . setTargetConcept ( concept . getCoveredText ( ) + \" (\" + concept . getBegin ( ) + \"~\" + concept . getEnd ( ) + \")\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "additional", "testing", "for", "received", "after"], "add_tokens": "import java . util . GregorianCalendar ; List < MessageSummary > pastEmails = client . messages ( ) . list ( server , new GregorianCalendar ( 2000 , Calendar . JANUARY , 1 ) . getTime ( ) ) . items ( ) ; assertTrue ( pastEmails . size ( ) > 0 ) ; List < MessageSummary > futureEmails = client . messages ( ) . list ( server , new Date ( ) ) . items ( ) ;", "del_tokens": "List < MessageSummary > futureEmails = client . messages ( ) . list ( server , new Date ( ) ) . items ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "Bug", "in", "EventManager"], "add_tokens": "Future futureTemp = next . activatorEventFired ( id ) ; if ( futureTemp != null ) { futures . add ( futureTemp ) ; }", "del_tokens": "futures . add ( next . activatorEventFired ( id ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "failing", "superclass", "test", "case", "."], "add_tokens": "log . info ( \"Initializing the autowiring aspect.\" ) ;", "del_tokens": "log . info ( \"Initializing an autowiring aspect.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "angle", "brackets", "in", "Javadoc"], "add_tokens": "* Return - 1 if extractedValue is & lt ; testValue , 1 if it is & gt ; , 0 if it is equals .", "del_tokens": "* Return - 1 if extractedValue is < testValue , 1 if it is > , 0 if it is equals .", "commit_type": "fix"}
{"commit_tokens": ["Add", "trace", "text", "size", "in", "pixels", "to", "LynxConfig", "class"], "add_tokens": "private static final float DEFAULT_TEXT_SIZE_IN_PX = 36 ; private Float textSizeInPx ; public LynxConfig withTextSizeInPx ( float fontSizeInPx ) { this . textSizeInPx = fontSizeInPx ; return this ; } public float getTextSizeInPx ( ) { return textSizeInPx == null ? DEFAULT_TEXT_SIZE_IN_PX : textSizeInPx ; } public boolean hasTextSizeInPx ( ) { return textSizeInPx != null ; } + \"maxNumberOfTracesToShow=\" + maxNumberOfTracesToShow + \", filter='\" + filter + '\\'' + '}' ;", "del_tokens": "+ \"maxNumberOfTracesToShow=\" + maxNumberOfTracesToShow + \", filter='\" + filter + '\\'' + '}' ;", "commit_type": "add"}
{"commit_tokens": ["Added", "created", "at", "and", "total", "cost", "methods", "to", "the", "Definition", "class", "and", "renamed", "getCost", "to", "getCostBreakdown", "."], "add_tokens": "private String _user_agent = \"DataSiftJava/0.3\" ;", "del_tokens": "private String _user_agent = \"DataSiftJava/0.2\" ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "crash", "when", "using", "turkish", "locale"], "add_tokens": "import java . util . Locale ; AbstractAttribute attribute = getStaticFieldValue ( definition , column . getName ( ) . toUpperCase ( Locale . US ) ) ;", "del_tokens": "AbstractAttribute attribute = getStaticFieldValue ( definition , column . getName ( ) . toUpperCase ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "import", "package", "of", "minim", "-", "java"], "add_tokens": "* Copyright ( C ) 2012 , Xcoo , Inc . import ddf . minim . AudioMetaData ; import ddf . minim . spi . AudioRecordingStream ; ddf . minim . AudioPlayer audioPlayer ; audioPlayer = new ddf . minim . AudioPlayer ( recording ) ; public AudioPlayer ( ddf . minim . AudioPlayer audioPlayer ) { public ddf . minim . AudioBuffer left ( ) { public ddf . minim . AudioBuffer right ( ) {", "del_tokens": "* Copyright ( C ) 2011 , Xcoo , Inc . import minim . sound . AudioMetaData ; import minim . sound . spi . AudioRecordingStream ; minim . sound . AudioPlayer audioPlayer ; audioPlayer = new minim . sound . AudioPlayer ( recording ) ; public AudioPlayer ( minim . sound . AudioPlayer audioPlayer ) { public minim . sound . AudioBuffer left ( ) { public minim . sound . AudioBuffer right ( ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "FromStringUsingPropertyEditor", "and", "ToStringUsingPropertyEditor", "converters", "."], "add_tokens": "// $JUnit-BEGIN$ // $JUnit-END$ suite . addTest ( net . entropysoft . transmorph . converters . propertyeditors . AllTests . suite ( ) ) ;", "del_tokens": "//$JUnit-BEGIN$ //$JUnit-END$", "commit_type": "add"}
{"commit_tokens": ["Updated", "interface", "definition", "to", "use", "generics", "to", "make", "it", "easier", "for", "clients"], "add_tokens": "* @ param < T > The concrete type that implements { @ link UserDetails } . public interface OAuth2UserDetailsLoader < T extends UserDetails > { public T getUserByUserId ( UUID uuid ) ;", "del_tokens": "public interface OAuth2UserDetailsLoader { public UserDetails getUserByUserId ( UUID uuid ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "object", "construction", "with", "a", "private", "constructor", "."], "add_tokens": "try { // Try a private constructor. Constructor < T > constructor = type . getDeclaredConstructor ( ) ; constructor . setAccessible ( true ) ; return constructor . newInstance ( ) ; } catch ( SecurityException ignored ) { } catch ( NoSuchMethodException ignored ) { throw new SerializationException ( \"Class cannot be created (missing no-arg constructor): \" + type . getName ( ) , ex ) ; } catch ( Exception privateConstructorException ) { ex = privateConstructorException ;", "del_tokens": "if ( ex instanceof InstantiationException ) { Constructor [ ] constructors = type . getConstructors ( ) ; boolean hasZeroArgConstructor = false ; for ( int i = 0 , n = constructors . length ; i < n ; i ++ ) { Constructor constructor = constructors [ i ] ; if ( constructor . getParameterTypes ( ) . length == 0 ) { hasZeroArgConstructor = true ; break ; } } if ( ! hasZeroArgConstructor ) throw new SerializationException ( \"Class cannot be created (missing no-arg constructor): \" + type . getName ( ) , ex ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "tests", "to", "the", "FilePipelineStore", "to", "cover", "new", "logic"], "add_tokens": "@ VisibleForTesting File getStoreDir ( ) { return storeDir ; } if ( ! doesPipelineExist ( DEFAULT_PIPELINE_NAME ) ) { try { create ( DEFAULT_PIPELINE_NAME , DEFAULT_PIPELINE_DESCRIPTION , SYSTEM_USER ) ; } catch ( PipelineStoreException ex ) { throw new RuntimeException ( ex ) ; @ VisibleForTesting File getInfoFile ( String name ) {", "del_tokens": "boolean create = ! ( doesPipelineExist ( DEFAULT_PIPELINE_NAME ) && isPipelineOK ( DEFAULT_PIPELINE_NAME ) ) ; if ( create ) { if ( ! doesPipelineExist ( DEFAULT_PIPELINE_NAME ) ) { try { cleanUp ( DEFAULT_PIPELINE_NAME ) ; create ( DEFAULT_PIPELINE_NAME , DEFAULT_PIPELINE_DESCRIPTION , SYSTEM_USER ) ; } catch ( PipelineStoreException ex ) { throw new RuntimeException ( ex ) ; } private File getInfoFile ( String name ) { private boolean isPipelineOK ( String name ) { return getInfoFile ( name ) . exists ( ) && getPipelineFile ( name ) . exists ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["fixing", "non", "public", "method", "bug"], "add_tokens": "import javax . annotation . Nullable ; import com . google . common . base . Predicate ; import com . google . common . collect . Iterables ; for ( DAMethod daMethod : Iterables . filter ( methods , DAMethodPredicates . isGuavaFunction ( ) ) ) {", "del_tokens": "for ( DAMethod daMethod : methods ) {", "commit_type": "fix"}
{"commit_tokens": ["adds", "ftest", "for", "pact", "provider"], "add_tokens": "import org . jboss . arquillian . test . spi . annotation . SuiteScoped ; @ SuiteScoped", "del_tokens": "import org . jboss . arquillian . test . spi . annotation . TestScoped ; @ TestScoped", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "get", "places", "in", "order", "of", "proximity", "to", "location"], "add_tokens": "public void testGetNearbyPlacesRankedByDistance ( ) { System . out . println ( \"******************** getNearbyPlacesRankedByDistance ********************\" ) ; if ( ! hasAtLeastAPlace ( google . getNearbyPlacesRankedByDistance ( TEST_PLACE_LAT , TEST_PLACE_LNG , MAXIMUM_RESULTS , Param . name ( \"name\" ) . value ( TEST_PLACE_NAME ) ) ) ) testGetNearbyPlaces ( ) ; } public void testGetNearbyPlaces ( ) { System . out . println ( \"******************** getNearbyPlaces ********************\" ) ; if ( ! findPlace ( google . getNearbyPlaces ( TEST_PLACE_LAT , TEST_PLACE_LNG , MAXIMUM_RADIUS , MAXIMUM_RESULTS ) , TEST_PLACE_NAME ) ) fail ( \"Test place could not be found at coordinates.\" ) ; if ( ! hasAtLeastAPlace ( google . getNearbyPlaces ( TEST_PLACE_LAT , TEST_PLACE_LNG , MAXIMUM_RADIUS , TypeParam . name ( STRING_TYPES ) . value ( Arrays . asList ( Types . TYPE_BAR , Types . TYPE_RESTAURANT ) ) ) ) ) fail ( \"Test place could not be found at coordinates.\" ) ;", "del_tokens": "public void testGetNearbyPlaces ( ) { System . out . println ( \"******************** getNearbyPlaces ********************\" ) ; if ( ! hasAtLeastAPlace ( google . getNearbyPlaces ( TEST_PLACE_LAT , TEST_PLACE_LNG , MAXIMUM_RADIUS , TypeParam . name ( STRING_TYPES ) . value ( Arrays . asList ( Types . TYPE_BAR , Types . TYPE_RESTAURANT ) ) ) ) )", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "with", "Config", "getPropertyEnv", "passed", "a", "null", "map"], "add_tokens": "Object value = null ; if ( securityProps != null ) { value = securityProps . get ( key ) ; if ( value != null ) return value . toString ( ) ; }", "del_tokens": "Object value = securityProps . get ( key ) ; if ( value != null ) return value . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "threads", "num", "parameters", "error"], "add_tokens": "Integer threadsNum = SAXCLIParameters . THREADS_NUM ;", "del_tokens": "Integer threadsNum = 1 ; if ( args . length > 6 ) { threadsNum = Integer . valueOf ( args [ 6 ] ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Added", "Serializable", ".", "Fixed", "a", "method", "that", "did", "not", "require", "authentication", "."], "add_tokens": "Document doc = Jinx . getInstance ( ) . callFlickr ( params , false ) ;", "del_tokens": "Document doc = Jinx . getInstance ( ) . callFlickr ( params ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "when", "gradients", "used", "with", "non", "-", "mirror", "reversed", "mode"], "add_tokens": "float left = mReversed ? ( mMirrorMode ? Math . abs ( mBounds . left - mBounds . right ) / 2 : mBounds . left ) : mBounds . left ; mBounds . right ;", "del_tokens": "float left = mReversed ? ( mMirrorMode ? Math . abs ( mBounds . left - mBounds . right ) / 2 : mBounds . right ) : mBounds . left ; ( mReversed ? mBounds . left : mBounds . right ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "some", "utils", "and", "opened", "the", "normalization"], "add_tokens": "/ * * * This method is used to determine the bucket the { @ code unixTimeStamp } belongs into . The bucket is represented by * a { @ link BucketEndPoints } instance , which defines the end - points of the bucket and provides methods to calculate * the distance between buckets . * * @ param unixTimeStamp the time - stamp to determine the bucket for * * @ return the bucket for the specified { @ code unixTimeStamp } based on the configuration of the time - series * / public BucketEndPoints normalizeUnixTimeStamp ( final long unixTimeStamp ) {", "del_tokens": "protected BucketEndPoints normalizeUnixTimeStamp ( final long unixTimeStamp ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "very", "simple", "graph", "as", "a", "dummy", "to", "be", "able", "to", "show", "end2end"], "add_tokens": "@ Path ( \"/\" ) public Response listMetrics ( @ QueryParam ( \"q\" ) String filter ) { if ( ( filter == null || filter . isEmpty ( ) ) || ( name . contains ( filter ) ) ) { SimpleLink link = new SimpleLink ( \"metrics\" , \"/rhq-metrics/\" + name + \"/data\" , name ) ; listWithLinks . add ( link ) ; }", "del_tokens": "import javax . ws . rs . core . Link ; @ Path ( \"/rhq-metrics\" ) public Response listMetrics ( ) { SimpleLink link = new SimpleLink ( \"metrics\" , \"/rhq-metrics/\" + name + \"/data\" ) ; listWithLinks . add ( link ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "unused", "parameter", "fullName", "from", "constructor", "declaration", ";", "explicitly", "listed", "out", "imports", ";", "fixed", "javadoc", "errors", "on", "constructor"], "add_tokens": "import org . apache . commons . lang3 . builder . ToStringBuilder ; import java . sql . Connection ; import java . sql . PreparedStatement ; import java . sql . SQLException ; * Constructs a provider dimension record . * * @ param concept the i2b2 concept representing the provider * @ param sourceSystem the source system where the provider came from public ProviderDimension ( Concept concept , String sourceSystem ) {", "del_tokens": "import java . sql . * ; import org . apache . commons . lang3 . builder . ToStringBuilder ; * Constructs a provider dimension record . The provider path , which also is * in this dimension , is added later on with the * { @ link # setI2b2Path ( java . lang . String ) } after the ontology hierarchy is * created . * * @ param id the provider unique id , or < code > null < / code > if the provider is * not recorded or unknown . * @ param firstName the provider 's first name, if known. * @ param middleName the provider 's middle name, if known. * @ param lastName the provider 's last name, if known. * @ param fullName the provider 's full name, if known. public ProviderDimension ( Concept concept , String fullName , String sourceSystem ) {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "formatting", "of", "pool", "size", "violations"], "add_tokens": "\"Pool hard cap violation?\" + \" Hard cap = \" + hardCap + \" Used size = \" + usedBytes + \" Free size = \" + freeBytes + \" Request size = \" + allocSize ) ;", "del_tokens": "\"Pool hard cap violation? \" + \"Hard cap = \" + hardCap + \"Used size = \" + usedBytes + \"Free size = \" + freeBytes + \"Request size = \" + allocSize ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "way", "proto3", "syntax", "is", "detected"], "add_tokens": "import com . google . protobuf . Descriptors . FileDescriptor . Syntax ; boolean proto3 = message . getDescriptorForType ( ) . getFile ( ) . getSyntax ( ) == Syntax . PROTO3 ;", "del_tokens": "import com . google . protobuf . GeneratedMessageV3 ; boolean proto3 = message instanceof GeneratedMessageV3 || message instanceof GeneratedMessageV3 . Builder ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "16", "additional", "language", "profiles", "from", "https", ":", "//", "github", ".", "com", "/", "rmtheis", "/", "language", "-", "detection"], "add_tokens": "assertEquals ( profiles . size ( ) , 69 ) ; //adjust this number when adding more languages assertEquals ( result . size ( ) , 69 ) ; //adjust this number when adding more languages", "del_tokens": "assertEquals ( profiles . size ( ) , 53 ) ; //adjust this number when adding more languages assertEquals ( result . size ( ) , 53 ) ; //adjust this number when adding more languages", "commit_type": "add"}
{"commit_tokens": ["Add", "delete", "copy", "move", "functionality", "to", "FedoraResourceImpl"], "add_tokens": "private final static Node binaryType = NodeFactory . createLiteral ( \"fedora:Binary\" ) ;", "del_tokens": "private final static Node binaryType = NodeFactory . createLiteral ( \"fedora:binary\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "proxool", "and", "c3p0", "classes", "to", "other", "project", "in", "order", "to", "remove", "their", "transitive", "dependencies"], "add_tokens": ". append ( \" <provider>C3P0</provider>\" ) //.append(\" <provider>PROXOOL</provider>\")", "del_tokens": "//.append(\" <provider>C3P0</provider>\") . append ( \" <provider>PROXOOL</provider>\" )", "commit_type": "move"}
{"commit_tokens": ["Fix", "problem", "with", "resolving", "types", "not", "really", "sure", "why", "this", "fixes", "it", "but", "it", "does"], "add_tokens": "public void gotoPhase ( final int phase ) throws CompilationFailedException { super . gotoPhase ( phase ) ; if ( phase == Phases . SEMANTIC_ANALYSIS ) { // This appears to be needed to avoid missing imports Iterator modules = getAST ( ) . getModules ( ) . iterator ( ) ; while ( modules . hasNext ( ) ) { ModuleNode module = ( ModuleNode ) modules . next ( ) ; module . setImportsResolved ( false ) ; } } }", "del_tokens": "import org . codehaus . groovy . tools . javac . JavaAwareResolveVisitor ; import org . codehaus . groovy . tools . javac . JavaCompiler ; // Copied from groovy/core, trying to see how to fix import problems // addPhaseOperation(new PrimaryClassNodeOperation() // { // public void call(final SourceUnit source, final GeneratorContext context, final ClassNode node) throws CompilationFailedException { // new JavaAwareResolveVisitor(JavaStubCompilationUnit.this).startResolving(node, source); // } // },Phases.CONVERSION); // Copied from groovy/core, trying to see how to fix import problems // public void gotoPhase(final int phase) throws CompilationFailedException { // super.gotoPhase(phase); // // if (phase==Phases.SEMANTIC_ANALYSIS) { // Iterator modules = getAST().getModules().iterator(); // while (modules.hasNext()) { // ModuleNode module = (ModuleNode) modules.next(); // module.setImportsResolved(false); // } // } // }", "commit_type": "fix"}
{"commit_tokens": ["Use", "Closeables", ".", "closeQuietly", "to", "close", "a", "proxy", "avoid", "dealing", "with", "IOException", "."], "add_tokens": "import com . google . common . io . Closeables ; public static void main ( String [ ] args ) throws InterruptedException { Closeables . closeQuietly ( ( Closeable ) service ) ;", "del_tokens": "import java . io . IOException ; public static void main ( String [ ] args ) throws InterruptedException , IOException { ( ( Closeable ) service ) . close ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "reconnect", "bug", "in", "low", "-", "level", "interface", "code", "."], "add_tokens": "this . connector . setConnectTimeoutMillis ( waitTime - 5 ) ; } while ( this . stayConnected && waitTime > 0 ) ;", "del_tokens": "} while ( this . stayConnected ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "dw", "-", "example", "use", "metrics", "-", "aop", "."], "add_tokens": "import com . yammer . dropwizard . config . Environment ; import static com . yammer . metrics . aop . Instrumentation . instrument ; environment . addResource ( instrument ( new HelloWorldResource ( template ) ) ) ;", "del_tokens": "import com . yammer . dropwizard . config . Environment ; environment . addResource ( new HelloWorldResource ( template ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "ButterKnife", "library", "in", "LiveVideoRenderer", "to", "mapGUI", "and", "hookListeners", "."], "add_tokens": "import butterknife . ButterKnife ; import butterknife . InjectView ; @ InjectView ( R . id . date ) TextView date ; View inflatedView = inflater . inflate ( R . layout . live_video_renderer , parent , false ) ; ButterKnife . inject ( this , inflatedView ) ; return inflatedView ; / * * Empty implementation substituted with the usage of ButterKnife library by Jake Wharton . * /", "del_tokens": "private TextView date ; return inflater . inflate ( R . layout . live_video_renderer , parent , false ) ; super . setUpView ( rootView ) ; date = ( TextView ) rootView . findViewById ( R . id . date ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "FXBindable", "to", "match", "latest", "JavaFX", "property", "pattern"], "add_tokens": "* Annotates a groovy property or a class to support JavaFX properties . * * When annotating a property it indicates that the property should be a * bound property according to JavaFX beans , announcing to listeners * that the value has changed . < br / > < br / > * * When annotating a class it indicates that all groovy properties in that * class should be bound as though each property had the annotation ( even * if it already has it explicitly ) . < br / > < br / > * It is a compilation error to place this annotation on a field ( that is * not a property , i . e . has scope visibility modifiers ) . < br / > < br / > * * If a property with a user defined setter method is annotated the code * block is wrapped with the needed code to fire off the event . < br / > < br / > * * @ author jimclarke ( inspired by Danno Ferrin ( shemnon ) and Chris Reeved ) @ java . lang . annotation . Documented }", "del_tokens": "* @ author jimclarke }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "of", "backup", "files", "restore"], "add_tokens": "Buffer buffer = new Buffer ( this , recordFormatter ) ; buffer . init ( ) ; return buffer ;", "del_tokens": "return new Buffer ( this , recordFormatter ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "fix", "issue", "with", "deleted", "constraints", "being", "resurrected", "."], "add_tokens": "m_offset = new int [ itemCount ] ; m_offset [ loop ] = itemOffset ; int offset = 0 ; m_offset = new int [ itemCount ] ; m_offset [ loop ] = offset ; offset += itemSize ; / * * * This method converts an offset value into an array index , which in * turn allows the data present in the fixed block to be retrieved . Note * that if the requested offset is not found , then this method returns - 1. * * @ param offset Offset of the data in the fixed block * @ return Index of data item within the fixed data block * / public int getIndexFromOffset ( int offset ) { int result = - 1 ; for ( int loop = 0 ; loop < m_offset . length ; loop ++ ) { if ( m_offset [ loop ] == offset ) { result = loop ; break ; } } return ( result ) ; } / * * * Array containing offset values for each item in the array . * / private int [ ] m_offset ;", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Allowing", "custom", "html", "inapps", "to", "be", "shown", "on", "landscape", "mode"], "add_tokens": "if ( ! inAppNotification . getInAppType ( ) . toString ( ) . contains ( \"Html\" ) ) { setRequestedOrientation ( ActivityInfo . SCREEN_ORIENTATION_PORTRAIT ) ; } if ( inAppNotification . getInAppType ( ) . toString ( ) . contains ( \"Html\" ) ) { Logger . d ( \"App in Landscape, allowing HTML InApp Notifications\" ) ; } else { Logger . d ( \"App in Landscape, dismissing portrait InApp Notification\" ) ; finish ( ) ; didDismiss ( null ) ; return ; }", "del_tokens": "setRequestedOrientation ( ActivityInfo . SCREEN_ORIENTATION_PORTRAIT ) ; Logger . d ( \"App in Landscape, dismissing portrait InApp Notification\" ) ; finish ( ) ; didDismiss ( null ) ; return ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "stack", "overflow", "in", "SimpleBeanAccess"], "add_tokens": "// parser must be != then null otherwise we we have a stack overflow by recursing in getPropertyInfo if ( parser != null ) { // Allow expressions of the form: <array-of-foo>.<property-of-foo>. The // result of evaluating such an expression is of type array-of-property-type IPropertyInfo propertyInfo = getPropertyInfo ( componentType , strProperty , filter , parser , scriptabilityConstraint ) ; if ( propertyInfo != null ) { return new ArrayExpansionPropertyInfo ( propertyInfo ) ; }", "del_tokens": "// Allow expressions of the form: <array-of-foo>.<property-of-foo>. The // result of evaluating such an expression is of type array-of-property-type. IPropertyInfo propertyInfo = getPropertyInfo ( componentType , strProperty , filter , parser , scriptabilityConstraint ) ; if ( propertyInfo != null ) { return new ArrayExpansionPropertyInfo ( propertyInfo ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "properties", "class", "to", "make", "constructing", "services", "easier", "."], "add_tokens": "import net . uncontended . precipice . timeout . TimeoutService ; public class ServiceProperties { private TimeoutService timeoutService = TimeoutService . defaultTimeoutService ; public void actionMetrics ( ActionMetrics metrics ) { this . metrics = metrics ; } public void ircuitBreaker ( CircuitBreaker breaker ) { this . breaker = breaker ; } public void timeoutService ( TimeoutService timeoutService ) { this . timeoutService = timeoutService ; }", "del_tokens": "public class ServiceBuilder {", "commit_type": "add"}
{"commit_tokens": ["Update", "icon", "and", "fix", "capitalization"], "add_tokens": "return \"GitHub\" ;", "del_tokens": "return \"Github\" ;", "commit_type": "update"}
{"commit_tokens": ["FIXED", ":", "text", "has", "to", "be", "split", "if", "comment", "or", "processingInstruction", "occours", "in", "between", "text"], "add_tokens": "import jlibs . xml . sax . SAXProperties ; import org . xml . sax . ext . DefaultHandler2 ; import javax . xml . parsers . SAXParser ; public class Sniffer extends DefaultHandler2 implements Debuggable { @ Override public void processingInstruction ( String target , String data ) throws SAXException { for ( Context context : contexts ) context . matchText ( contents ) ; contents . reset ( ) ; } @ Override public void comment ( char [ ] ch , int start , int length ) throws SAXException { for ( Context context : contexts ) context . matchText ( contents ) ; contents . reset ( ) ; } SAXParser parser = SAXUtil . newSAXParser ( true , false ) ; parser . getXMLReader ( ) . setProperty ( SAXProperties . LEXICAL_HANDLER , handler ) ; parser . parse ( source , handler ) ;", "del_tokens": "public class Sniffer extends DefaultHandler implements Debuggable { SAXUtil . newSAXParser ( true , false ) . parse ( source , handler ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "duplicate", "update", "notifications", "."], "add_tokens": "abstractConfig . addConfigurationListener ( event -> { if ( ! event . isBeforeUpdate ( ) ) {", "del_tokens": "abstractConfig . addConfigurationListener ( new ConfigurationListener ( ) { @ Override public void configurationChanged ( ConfigurationEvent event ) {", "commit_type": "fix"}
{"commit_tokens": ["changed", "scheduling", "of", "app", "listing"], "add_tokens": "public boolean getExternAppListing ( ) { return BNC_App_Listing ; }", "del_tokens": "private static final int SYSTEM_READ_TIMEOUT = 260000 ; public boolean getSystemReadStatus ( ) { Calendar c = Calendar . getInstance ( ) ; long prevDate = getLong ( KEY_LAST_READ_SYSTEM ) ; if ( ( c . getTimeInMillis ( ) / 1000 - prevDate ) > SYSTEM_READ_TIMEOUT ) { return true && BNC_App_Listing ; } return false ; }", "commit_type": "change"}
{"commit_tokens": ["Use", "passed", "in", "content", "if", "object", "content", "is", "null"], "add_tokens": "ServiceReference ServiceReference = getClassServiceReference ( ( bundleContext != null ) ? bundleContext : context , interfaceClassName , versionRange , filter ) ;", "del_tokens": "ServiceReference ServiceReference = getClassServiceReference ( bundleContext , interfaceClassName , versionRange , filter ) ;", "commit_type": "use"}
{"commit_tokens": ["moved", "data", "to", "bdd", "project", "removed", "external", "dependency"], "add_tokens": "import org . camunda . bpm . data . ActivityGuard ; import static org . camunda . bpm . data . Guards . * ; private static final long serialVersionUID = 1L ; @ Override public void checkPostconditions ( final DelegateExecution execution ) throws IllegalStateException { checkIsSet ( execution , Variables . IS_AUTOMATIC ) ; checkIsSet ( execution , Variables . CONTRACT_ID ) ; }", "del_tokens": "import static org . camunda . bpm . engine . guard . Guards . checkIsSet ; import org . camunda . bpm . engine . guard . ActivityGuard ; private static final long serialVersionUID = 1L ; @ Override public void checkPostconditions ( final DelegateExecution execution ) throws IllegalStateException { checkIsSet ( execution , Variables . IS_AUTOMATIC ) ; checkIsSet ( execution , Variables . CONTRACT_ID ) ; }", "commit_type": "move"}
{"commit_tokens": ["Updated", "the", "demo", "application", "to", "include", "independent", "usage", "of", "the", "CalendarPanel", "component", "."], "add_tokens": "package com . github . lgooddatepicker . ysandbox ; public class CalendarPanelTest {", "del_tokens": "package com . github . lgooddatepicker . demo ; public class IndependentCalendarPanelDemo {", "commit_type": "update"}
{"commit_tokens": ["fix", "completionCallback", "on", "StreamMessagingConnection", "add", "MessagingEndOfStream", "and", "MessagingException"], "add_tokens": "import io . datakernel . stream . net . * ; } ) . addEndOfStream ( new MessagingEndOfStream ( ) { @ Override public void onEndOfStream ( ) { logger . info ( \"onReadEndOfStream\" ) ; } } ) . addException ( new MessagingException ( ) { @ Override public void onException ( Exception e ) { logger . error ( \"onReadException\" , e ) ; } } ) . addEndOfStream ( new MessagingEndOfStream ( ) { @ Override public void onEndOfStream ( ) { logger . info ( \"onReadEndOfStream\" ) ; } } ) . addException ( new MessagingException ( ) { @ Override public void onException ( Exception e ) { logger . error ( \"onReadException\" , e ) ; }", "del_tokens": "import io . datakernel . stream . net . Messaging ; import io . datakernel . stream . net . MessagingHandler ; import io . datakernel . stream . net . MessagingStarter ; import io . datakernel . stream . net . StreamMessagingConnection ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "constant", "for", "file", "system", "cache", "size", "as", "suggested", "in", "issue", "27", "."], "add_tokens": "this . getBaseContext ( ) , FS_CACHE_SIZE ) ;", "del_tokens": "this . getBaseContext ( ) , 4 * 1024 * 1024 ) ; // 4MB FSCache", "commit_type": "add"}
{"commit_tokens": ["added", "some", "incomplere", "javadoc", "for", "PrimitiveValue", "methods"], "add_tokens": "* Return string reresentaiton of this object * * @ return String representing object value * @ throws IllegalArgumentException if unknown representation / * * * Determine if two values are equivalent * * @ param value to compare this value with * @ return equivalence of values * /", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Fixed", "ValidationIT", "and", "first", "mapping", "tests", "."], "add_tokens": "count = source . query ( ) . direction ( Direction . IN ) . labels ( label )", "del_tokens": "count = source . query ( ) . direction ( Direction . OUT ) . labels ( label )", "commit_type": "fix"}
{"commit_tokens": ["Add", "icon", "property", "to", "tab", "pane", "."], "add_tokens": "if ( \"accordion\" . equals ( orientation ) ) { tabBox . setOrient ( \"horizontal\" ) ; tabBox . setMold ( \"accordion\" ) ; } else { tabBox . setMold ( null ) ; tabBox . setOrient ( orientation ) ; } * Returns the orientation ( horizontal , vertical or accordion ) . return \"accordion\" . equals ( tabBox . getMold ( ) ) ? \"accordion\" : tabBox . getOrient ( ) ;", "del_tokens": "tabBox . setOrient ( orientation ) ; * Returns the orientation ( horizontal or vertical ) . return tabBox . getOrient ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "installation", "code", "on", "Windows"], "add_tokens": "private static final String BMP_LOCAL_ZIP_RES = \"/browsermob-proxy-local.zip\" ; try { installedVersion ( ) ; return true ; } catch ( BMPCLocalNotInstalledException nie ) { return false ; }", "del_tokens": "private static final String BMP_LOCAL_ZIP_RES = File . separator + \"browsermob-proxy-local.zip\" ; File installDir = new File ( BMP_LOCAL_INSTALL_DIR ) ; return installDir . exists ( ) && installDir . isDirectory ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "URL", "for", "Topics"], "add_tokens": "return CommonConstants . SERVER_URL + \"/TopicIndex/Topic.seam?topicTopicId=\" + source . getId ( ) ;", "del_tokens": "return CommonConstants . SERVER_URL + \"/TopicIndex/CustomSearchTopicList.seam?topicIds=\" + source . getId ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "names", "of", "option", "variables", "for", "thumbnail", "width", "and", "height", "."], "add_tokens": "this . thumbnailHeight = height ; this . thumbnailWidth = width ;", "del_tokens": "this . height = height ; this . width = width ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "remote", "factory", "provider", "to", "support", "multiple", "protocols", "."], "add_tokens": "* by { @ link # getProtocols ( ) } . Protocol syntax is implementation detail but is part of < code > implementationURL < / code > * supplied to { @ link RemoteFactory # getRemoteInstance ( String , Class ) } . * Get URL protocols that { @ link # getRemoteFactory ( ) } is able to handle . * @ return URL protocols list handled by remote instance factory . String [ ] getProtocols ( ) ; * Get remote factory instance able to handle declared { @ link # getProtocols ( ) } .", "del_tokens": "* by { @ link # getProtocol ( ) } . * Get URL protocol that { @ link # getRemoteFactory ( ) } is able to handle . * @ return URL protocol handled by remote instance factory . String getProtocol ( ) ; * Get remote factory instance able to handle declared { @ link # getProtocol ( ) } .", "commit_type": "update"}
{"commit_tokens": ["Changed", "handling", "of", "precision", "values", "not", "defined", "in", "the", "data", "model", "."], "add_tokens": "\"BasicItem.json\" , basicItemDocument ) ; @ Test public void testRealItems ( ) throws JSONException { List < ItemTestCase > testCases = new LinkedList < > ( ) ; testCases . add ( this . generateItemTestCase ( \"Chicago.json\" , null ) ) ; testCases . add ( this . generateItemTestCase ( \"Haaften.json\" , null ) ) ; for ( ItemTestCase t : testCases ) { t . convert ( ) ; } }", "del_tokens": "import org . wikidata . wdtk . datamodel . interfaces . EntityIdValue ; \"BasicItem.json\" , null ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "system", "branch", "that", "creates", "izou", "relevant", "file", "system", "and", "generalized", "file", "watcher", "service"], "add_tokens": "reloadFiles ( ) ; if ( ! ( c == ( byte ) '\\uFFFF' ) ) { bufferedWriter . write ( c ) ; } public void reloadFiles ( ) throws IOException {", "del_tokens": "import java . nio . file . Path ; import java . nio . file . Paths ; reloadProperties ( ) ; bufferedWriter . write ( c ) ; System . out . println ( defaultPropsPath ) ; public void reloadProperties ( ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Allow", "jdbc", "to", "return", "proper", "server", "version", "number"], "add_tokens": "java . sql . ResultSet resultSet = connection . ExecSQL ( \"select version()\" ) ; resultSet . next ( ) ; StringTokenizer versionParts = new StringTokenizer ( resultSet . getString ( 1 ) ) ; versionParts . nextToken ( ) ; /* \"PostgreSQL\" */ String versionNumber = versionParts . nextToken ( ) ; /* \"X.Y.Z\" */ return versionNumber ;", "del_tokens": "* < p > Note that PostgreSQL 6.3 has a system catalog called pg_version - * however , select * from pg_version on any database retrieves * no rows . * * < p > For now , we will return the version 6.3 ( in the hope that we change * this driver as often as we change the database ) * return connection . this_driver . getVersion ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fixed", "frame", "length", "issue", "exceeding", "short", "value"], "add_tokens": "decoderState . frameLen = in . getUnsignedShort ( ) ; }", "del_tokens": "decoderState . frameLen = in . getShort ( ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "with", "AggregatorProxy", "and", "subclasses", "that", "don", "t", "explicitly"], "add_tokens": "new Class [ ] { IAggregator . class } ,", "del_tokens": "aggr . getClass ( ) . getInterfaces ( ) ,", "commit_type": "fix"}
{"commit_tokens": ["Removed", "the", "remaining", "amazon", ".", "com", "reference", "and", "replaced", "with", "sauce", "labs", "test", "page", "."], "add_tokens": "* Runs a simple test verifying the title of the sauce labs test page . driver . get ( \"https://saucelabs.com/test/guinea-pig\" ) ; assertEquals ( \"I am a page title - Sauce Labs\" , driver . getTitle ( ) ) ;", "del_tokens": "* Runs a simple test verifying the title of the amazon . com homepage . driver . get ( \"http://www.amazon.com/\" ) ; assertEquals ( \"Amazon.com: Online Shopping for Electronics, Apparel, Computers, Books, DVDs & more\" , driver . getTitle ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["allows", "for", "improved", "getSiteInfo", "with", "Wiki", ".", "java"], "add_tokens": "String scriptPath ) throws Exception { wiki . init ( siteUrl , scriptPath ) ;", "del_tokens": "String defaultScriptpath ) throws Exception { wiki . setSiteurl ( siteUrl ) ; wiki . setScriptPath ( defaultScriptpath ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "argument", "collections", "to", "legacy", "parser", "append", "/", "replace", "switch", "to", "new", "parser", "."], "add_tokens": "", "del_tokens": "/ * * * Overwrite default order in which Option are printed in usage by explicitly setting a * print position e . g . printOrder = 1 is printed before printOrder = 2. * Options without printOrder automatically receive a printOrder that ( 1 ) is a multiple of 1000 * and ( 2 ) reflects the order 's default position. This gives you the option to insert your own options between * options inherited from super classes ( which order you do not control ) . * The default ordering follows ( 1 ) the option declaration position in the class and ( 2 ) sub - classes options printed * before superclass options . * * @ author charles girardot * / int printOrder ( ) default Integer . MAX_VALUE ; / * * * This boolean determines if this annotation overrides a parent annotation . If that is the case then * the options of the parent annotation are overridden with this annotation . * / boolean overridable ( ) default false ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "demo", "app", "to", "properly", "handle", "test", "app", "s", "client", "token", "response", "format"], "add_tokens": "import org . json . JSONException ; import org . json . JSONObject ; try { JSONObject json = new JSONObject ( response ) ; ready ( json . getString ( \"client_token\" ) ) ; } catch ( JSONException e ) { showDialog ( \"Unable to fetch a client token!\" ) ; }", "del_tokens": "ready ( response ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "custom", "HTTP", "headers"], "add_tokens": "import java . util . Map ; if ( DoStop ( ) ) return ; for ( Map . Entry < String , String > entry : mConnection . getHeaders ( ) . entrySet ( ) ) { httpClient . addHeader ( entry . getKey ( ) , entry . getValue ( ) ) ; }", "del_tokens": "if ( DoStop ( ) ) return ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "toString", "method", "in", "Field", "and", "VisibleField"], "add_tokens": "protected final GameStateFieldContext gameStateContext ; private final Position position ; private final FieldTerrainType terrainType ; public FieldTerrainType getTerrainType ( ) { return terrainType ; } @ Override public String toString ( ) { return String . format ( \"Field[position=%s, terrain=%s]\" , getPosition ( ) , terrainType ) ; }", "del_tokens": "import lombok . ToString ; @ ToString ( callSuper = true ) protected GameStateFieldContext gameStateContext ; protected Position position ; protected FieldTerrainType terrainType ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "issue", "with", "inner", "class", "loading"], "add_tokens": "ClassNode node = repo . node ( name ) ;", "del_tokens": "ClassNode node = repo . node ( cname ) ;", "commit_type": "fix"}
{"commit_tokens": ["made", "getMatches", "(", "double", "[]", ")", "public"], "add_tokens": "@ Override public List < Match > getMatches ( final double [ ] vec , int maxNumMatches ) {", "del_tokens": "private List < Match > getMatches ( final double [ ] vec , int maxNumMatches ) {", "commit_type": "make"}
{"commit_tokens": ["added", "tests", "for", "domain", "types"], "add_tokens": "import com . mysema . query . grammar . types . CollectionType ;", "del_tokens": "import com . mysema . query . grammar . types . Expr . CollectionType ;", "commit_type": "add"}
{"commit_tokens": ["Using", "Locale", ".", "ROOT", "for", "locale", "-", "neutral", "comparisons", "and", "conversions", "."], "add_tokens": "CaptureLevel . valueOf ( level . toUpperCase ( Locale . ROOT ) ) CaptureLevel . valueOf ( level . toUpperCase ( Locale . ROOT ) ) CaptureLevel . valueOf ( level . toUpperCase ( Locale . ROOT ) ) return CaptureLevel . getCaptureLevel ( request ) . name ( ) . toLowerCase ( Locale . ROOT ) ;", "del_tokens": "CaptureLevel . valueOf ( level . toUpperCase ( Locale . ENGLISH ) ) CaptureLevel . valueOf ( level . toUpperCase ( Locale . ENGLISH ) ) CaptureLevel . valueOf ( level . toUpperCase ( Locale . ENGLISH ) ) return CaptureLevel . getCaptureLevel ( request ) . name ( ) . toLowerCase ( Locale . ENGLISH ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bug", ":", "a", "tiny", "code", "bug", "http", ":", "//", "github", ".", "com", "/", "rantav", "/", "hector", "/", "issues", "/", "#issue", "/", "2"], "add_tokens": "+ ( superColumnMap == null ? 0 : superColumnMap . size ( ) ) ;", "del_tokens": "+ ( columnMap == null ? 0 : columnMap . size ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "distinct", "support", "lists", "smaller", "than", "chunkSize", "."], "add_tokens": "return new DelegatingMergeIterator < T > ( list . iterator ( ) , comparator , config . distinct ) ; private final boolean distinct ; private T prev ; private Comparator < T > comparator ; private DelegatingMergeIterator ( Iterator < T > nested , Comparator < T > comparator , boolean distinct ) { this . comparator = comparator ; this . distinct = distinct ; if ( distinct ) { T next ; do { next = nested . next ( ) ; } while ( prev != null && comparator . compare ( prev , next ) == 0 && nested . hasNext ( ) ) ; prev = next ; return next ; } else { return nested . next ( ) ; }", "del_tokens": "return new DelegatingMergeIterator < T > ( list . iterator ( ) ) ; private DelegatingMergeIterator ( Iterator < T > nested ) { return nested . next ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "input", "stream", "wrapper", "."], "add_tokens": "InternalHttpResponse ires = new InternalHttpResponse ( httpResponse , httpClient . getConnectionManager ( ) ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse , httpClient . getConnectionManager ( ) ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse , httpClient . getConnectionManager ( ) ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse , httpClient . getConnectionManager ( ) ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse , httpClient . getConnectionManager ( ) ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse , httpClient . getConnectionManager ( ) ) ;", "del_tokens": "InternalHttpResponse ires = new InternalHttpResponse ( httpResponse ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse ) ; InternalHttpResponse ires = new InternalHttpResponse ( httpResponse ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "in", "out", "animations"], "add_tokens": "keyTimes . add ( 0f ) ; keys . add ( 1f ) ; keys . add ( 1f ) ; keys . add ( 0f ) ; keys . add ( 0f ) ; public boolean hasInAnimation ( ) { public boolean hasInOutAnimation ( ) { public boolean hasOutAnimation ( ) {", "del_tokens": "keys . add ( 1f ) ; keyTimes . add ( 0f ) ; keys . add ( 0f ) ; keys . add ( 1f ) ; keys . add ( 1f ) ; public boolean isHasInAnimation ( ) { public boolean isHasInOutAnimation ( ) { public boolean isHasOutAnimation ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "some", "doc", "and", "logging", "gitignore"], "add_tokens": "* Builder to define configuration to access memcached . @ Override public String toString ( ) { return \"MemcachedConfiguration{\" + \"username='\" + username + '\\'' + \", password= Not displayed\" + \", url='\" + url + '\\'' + \", port=\" + port + '}' ; }", "del_tokens": "* Builder to define configuration to access to memcached . * * @ author Nicolas Hurion * * @ author Nicolas Hurion", "commit_type": "add"}
{"commit_tokens": ["add", "new", "VoidReportWriter", "as", "default", "ReportWriter", "for", "less", "noise"], "add_tokens": "reportWriter = new VoidReportWriter ( ) ;", "del_tokens": "reportWriter = new TextReportWriter ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "WireOuput", ".", "makeTag", "public"], "add_tokens": "/** Makes a tag value given a field number and wire type. */ public static int makeTag ( int fieldNumber , WireType wireType ) { return ( fieldNumber << WireType . TAG_TYPE_BITS ) | wireType . value ( ) ; }", "del_tokens": "/** Makes a tag value given a field number and wire type. */ static int makeTag ( int fieldNumber , WireType wireType ) { return ( fieldNumber << WireType . TAG_TYPE_BITS ) | wireType . value ( ) ; }", "commit_type": "make"}
{"commit_tokens": ["Add", "Email", ".", "getAddress", "()", "method", "."], "add_tokens": "/ * * * Return the full EMail address : id + \"@\" + domain . * * @ return the full EMail address : id + \"@\" + domain * / public String getAddress ( ) { return _id + \"@\" + _domain ; } return getAddress ( ) ;", "del_tokens": "return _id + \"@\" + _domain ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "JPMML", "-", "Model", "dependency"], "add_tokens": "Source source = ImportFilter . apply ( new InputSource ( is ) ) ;", "del_tokens": "Source source = SchemaUtil . createImportSource ( new InputSource ( is ) ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "map", "information", "to", "infons"], "add_tokens": "default void putAllInfons ( Map < String , String > infons ) {", "del_tokens": "default void putAllInfos ( Map < String , String > infons ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "copyright", "and", "tab", "."], "add_tokens": "* ( C ) Copyright IBM Corporation 2016 , 2017. String extension = null ;", "del_tokens": "* ( C ) Copyright IBM Corporation 2016. String extension = null ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "few", "null", "checks"], "add_tokens": "* Looks up the serializer for the given class else { @ code null } if no serializer is registered for the { @ code type } .", "del_tokens": "* Looks up the serializer for the given class .", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "OSGI", "in", "final", "jar"], "add_tokens": "private static final String TIMESTAMP = \"20111026-1710\" ; private static final String VERSION = \"2.3.0\" ; private static final String LONG_VERSION = \"2.3.0 (Build @ 20111026-1710)\" ; /** Returns the library build timestamp such as \"20111026-1710\" */ /** Returns the library version such as \"2.3.0\" */ /** Returns a longer library version that includes the timestamp such as \"2.3.0 (Build @ 20111026-1710)\" */", "del_tokens": "private static final String TIMESTAMP = \"20111026-1417\" ; private static final String VERSION = \"2.3.0-SNAPSHOT\" ; private static final String LONG_VERSION = \"2.3.0-SNAPSHOT (Build @ 20111026-1417)\" ; /** Returns the library build timestamp such as \"20111026-1417\" */ /** Returns the library version such as \"2.3.0-SNAPSHOT\" */ /** Returns a longer library version that includes the timestamp such as \"2.3.0-SNAPSHOT (Build @ 20111026-1417)\" */", "commit_type": "add"}
{"commit_tokens": ["Remove", "connected", "test", "from", "triangulatonTest"], "add_tokens": "/ * List < Point3D > connected = triangulation . findConnectedVertices ( pointA , triangles ) ; Assert . assertEquals ( 2 , connected . size ( ) ) ; * /", "del_tokens": "List < Point3D > connected = triangulation . findConnectedVertices ( pointA , triangles ) ; Assert . assertEquals ( 2 , connected . size ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "override", "test", ".", "galaxy", ".", "instance", "and", "test", ".", "galaxy", ".", "key", "with", "Java", "system", "properties", ".", "This", "should", "take", "precedance", "over", "$HOME", "/", ".", "blend4j", ".", "properties", "."], "add_tokens": "import java . util . Properties ; if ( System . getProperties ( ) . contains ( key ) ) { value = System . getProperties ( ) . getProperty ( key ) ; } else if ( properties . containsKey ( key ) ) {", "del_tokens": "import java . util . Properties ; if ( properties . containsKey ( key ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "support", "for", "short", "primitive", "types"], "add_tokens": "if ( returnType . isAssignableFrom ( int . class ) || returnType . isAssignableFrom ( Integer . class ) || returnType . isAssignableFrom ( short . class ) || returnType . isAssignableFrom ( Short . class ) ) {", "del_tokens": "if ( returnType . isAssignableFrom ( int . class ) || returnType . isAssignableFrom ( Integer . class ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "of", "slow", "name", "resolution", "http", ":", "//", "github", ".", "com", "/", "rantav", "/", "hector", "/", "issues#issue", "/", "3", "by", "making", "name", "resolution", "optional", "and", "dependent", "on", "system", "property", "HECTOR_PERFORM_NAME_RESOLUTION"], "add_tokens": "String timeoutStr = System . getProperty ( SystemProperties . CASSANDRA_THRIFT_SOCKET_TIMEOUT . toString ( ) ) ;", "del_tokens": "String timeoutStr = System . getProperty ( \"CASSANDRA_THRIFT_SOCKET_TIMEOUT\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "java", "-", "logging", "xml", "-", "schema"], "add_tokens": "import static java . util . logging . Level . * ;", "del_tokens": "import static java . util . logging . Level . INFO ; import static java . util . logging . Level . SEVERE ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "all", "model", "translators", "to", "compile"], "add_tokens": "import org . agmip . core . types . weather . WeatherFile ; public class AgMIPFileLoader implements WeatherFile { public void writeFile ( String fileName , AdvancedHashMap data ) { }", "del_tokens": "public class AgMIPFileLoader {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "1", "-", "arg", "version", "of", "the", "key", "/", "configurator", "method", "without", "a", "key", "."], "add_tokens": "accessor . addParameter ( \"T\" , \"value\" ) ;", "del_tokens": "accessor . addParameter ( plan . getClassName ( ) , \"value\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "reflection", "Annotation", "out", "of", "JavaAnnotation"], "add_tokens": "SOME_VALUE , OTHER_VALUE ;", "del_tokens": "SOME_VALUE ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "DBConn", ".", "getColumn", "()", "to", "handle", "NotFoundException", "for", "missing", "row", "."], "add_tokens": "import org . apache . cassandra . thrift . NotFoundException ; } catch ( NotFoundException ex ) { return null ; return col == null ? null : new CassandraColumn ( col . getName ( ) , col . getValue ( ) ) ;", "del_tokens": "return new CassandraColumn ( col . getName ( ) , col . getValue ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bugs", ";", "Test", "failed", "with", "@Parameters", "annotation"], "add_tokens": "//String methodName = description.getMethodName(); //methodName. //Method method = description.getTestClass().getMethod(methodName); if ( description . getAnnotation ( FlakyTest . class ) != null ) { runCount = description . getAnnotation ( FlakyTest . class ) . tolerance ( ) ; } else if ( description . getAnnotation ( RepetitiveTest . class ) != null ) { runCount = description . getAnnotation ( RepetitiveTest . class ) . numIterations ( ) ; if ( fInstrumentation != null && description . getAnnotation ( UiThreadTest . class ) != null ) {", "del_tokens": "import java . lang . reflect . Method ; String methodName = description . getMethodName ( ) ; Method method = description . getTestClass ( ) . getMethod ( methodName ) ; if ( method . isAnnotationPresent ( FlakyTest . class ) ) { runCount = method . getAnnotation ( FlakyTest . class ) . tolerance ( ) ; } else if ( method . isAnnotationPresent ( RepetitiveTest . class ) ) { runCount = method . getAnnotation ( RepetitiveTest . class ) . numIterations ( ) ; if ( fInstrumentation != null && method . isAnnotationPresent ( UiThreadTest . class ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Move", "VerifySearch", "endpoint", "from", "XML", "to", "json", "."], "add_tokens": "return this . search . search ( requestId ) [ 0 ] ; return this . search . search ( requestIds ) ;", "del_tokens": "import com . nexmo . client . verify . endpoints . SearchEndpoint ; return search . search ( requestId ) ; return search . search ( requestIds ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "multiply", "bound", "module", "clashes", "."], "add_tokens": "populateModulesFromInjectorInterface ( ginjectorInterface , modules , new HashSet < Class < ? extends GinModule > > ( ) ) ; private void populateModulesFromInjectorInterface ( JClassType iface , List < Module > modules , Set < Class < ? extends GinModule > > added ) { if ( added . contains ( moduleClass ) ) { continue ; } added . add ( moduleClass ) ; populateModulesFromInjectorInterface ( superIface , modules , added ) ;", "del_tokens": "populateModulesFromInjectorInterface ( ginjectorInterface , modules ) ; private void populateModulesFromInjectorInterface ( JClassType iface , List < Module > modules ) { populateModulesFromInjectorInterface ( superIface , modules ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "provider", "setter", "to", "log", "factory", "for", "Android", "integration", "."], "add_tokens": "* use { @ link # LooperThread ( Looper , int , boolean ) } constructor to set { @ link # breakOnException } flag to true .", "del_tokens": "* use { @ link # setBreakOnException ( boolean ) } to set { @ link # breakOnException } flag to true .", "commit_type": "add"}
{"commit_tokens": ["use", "IPv6NetworkMask", "in", "stead", "of", "int", "prefixLength", "in", "IPv6AddressPool", "."], "add_tokens": "IPv6Address . fromString ( \"fe80::226:2dff:fefa:ffff\" ) , new IPv6NetworkMask ( 120 ) ) ;", "del_tokens": "IPv6Address . fromString ( \"fe80::226:2dff:fefa:ffff\" ) , 120 ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "technology", "property", "to", "relationships", "."], "add_tokens": "contentUpdater . uses ( twitter , \"Gets profile information and recent tweets using the REST API from.\" , \"JSON over HTTPS\" ) ; contentUpdater . uses ( twitter , \"Subscribes to tweets using the Twitter Streaming API from.\" , \"JSON over HTTPS\" ) ; contentUpdater . uses ( gitHub , \"Gets information about public code repositories using the GitHub API from.\" , \"JSON over HTTPS\" ) ; contentUpdater . uses ( blogs , \"Gets blog posts and news from.\" , \"RSS and Atom over HTTP\" ) ;", "del_tokens": "contentUpdater . uses ( twitter , \"Gets profile information and recent tweets using the REST API from.\" , \"JSON over HTTPS\" , 443 , \"1.1\" ) ; contentUpdater . uses ( twitter , \"Subscribes to tweets using the Twitter Streaming API from.\" , \"JSON over HTTPS\" , 443 , \"1.1\" ) ; contentUpdater . uses ( gitHub , \"Gets information about public code repositories using the GitHub API from.\" , \"JSON over HTTPS\" , 443 , \"v3\" ) ; contentUpdater . uses ( blogs , \"Gets blog posts and news from.\" , \"RSS and Atom over HTTP\" , 80 , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "file", "store", "flush", "to", "public", "interface"], "add_tokens": "* * / * * * Flush any opened { @ linkplain FilePreferences } to the backing store . * / public static void flush ( ) { FilePreferencesStore . flushFileStores ( ) ; }", "del_tokens": "* *", "commit_type": "add"}
{"commit_tokens": ["Add", "binders", "for", "GC", "memory", "/", "buffer", "pools", "classloader", "CPU", "and", "threads"], "add_tokens": "* Used to measure the rate of change based on calls to increment .", "del_tokens": "* Measures the rate of change based on calls to increment .", "commit_type": "add"}
{"commit_tokens": ["Fixed", "more", "assiste", "inject", "parametrization", "errors", "."], "add_tokens": "for ( TypeLiteral < ? > param : assistData . params ) { assistData . add ( new AssistData ( implementation , gwtConstructor , method , parameterNames , params ) ) ; private static class AssistData { final List < TypeLiteral < ? > > params ; String [ ] parameterNames , List < TypeLiteral < ? >> params ) { this . params = params ;", "del_tokens": "for ( Class < ? > param : assistData . method . getParameterTypes ( ) ) { assistData . add ( new AssistData ( implementation , gwtConstructor , method , parameterNames ) ) ; private class AssistData { String [ ] parameterNames ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "session", "method", "to", "add", "all", "extensions", "."], "add_tokens": "import java . util . * ; private static final Map < Integer , CastAlertFunction > CAST_TABLE = buildAlertCastTable ( ) ; public Session ( fingerprint fingerprint ) { this . s = new session ( fingerprint ) ; int_int_pair pr = new int_int_pair ( 6881 , 6981 ) ; s . start_upnp ( ) ; s . start_natpmp ( ) ; s . start_lsd ( ) ; s . add_all_extensions ( ) ; } public Session ( ) { this ( new fingerprint ( \"FW\" , 0 , 0 , 1 , 1 ) ) ;", "del_tokens": "import java . util . ArrayList ; import java . util . Collections ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; private static final Map < Integer , CastAlertFunction > CAST_TABLE = buildAlertCastTable ( ) ; public Session ( ) { this . s = new session ( ) ; int_int_pair pr = new int_int_pair ( 6881 , 6889 ) ; s . start_dht ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "blocking", "control", "service", "that", "waits", "for", "user", "s", "exit", "command"], "add_tokens": "import java . net . ServerSocket ; import java . net . Socket ; import java . util . concurrent . Future ; private static final int DEFAULT_CONTROL_PORT = 9090 ; public static final String OPT_CONTROL_PORT = \"controlPort\" ; waitForShutdown ( getControlPort ( options ) ) ; private static void waitForShutdown ( int port ) { ServerSocket serverSocket ; try { serverSocket = new ServerSocket ( port ) ; Socket client = serverSocket . accept ( ) ; } catch ( IOException e ) { System . err . println ( \"Exception: couldn't create socket\" ) ; System . exit ( 1 ) ; } } private static int getControlPort ( Options options ) { Option opt = options . getOption ( \"controlPort\" ) ; String value = opt . getValue ( ) ; if ( value == null ) { return DEFAULT_CONTROL_PORT ; } return Integer . parseInt ( value ) ; } Option controlPort = OptionBuilder . withArgName ( OPT_CONTROL_PORT ) . hasArg ( ) . isRequired ( false ) . withDescription ( \"The port used to send command to this server\" ) . create ( 'c' ) ; options . addOption ( controlPort ) ;", "del_tokens": "// Hmmm... is this the right way to do this? Should this block on the status server instead? Thread . sleep ( Long . MAX_VALUE ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "new", "store", "factory", "tests"], "add_tokens": "import krati . core . StorePartitionConfig ; ArrayStore base = ( config instanceof StorePartitionConfig ) ? StoreFactory . createArrayStorePartition ( ( StorePartitionConfig ) config ) : StoreFactory . createStaticArrayStore ( config ) ;", "del_tokens": "ArrayStore base = StoreFactory . createStaticArrayStore ( config ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "getFloat", "and", "getObject", "for", "float", "type"], "add_tokens": "import java . sql . Types ; import org . apache . calcite . avatica . * ; @ Override public float getFloat ( int columnIndex ) throws SQLException { // casting needed as Avatica stores sql FLOAT in java.lang.Double return ( float ) getDouble ( columnIndex ) ; } @ Override public Object getObject ( int columnIndex ) throws SQLException { Object result = super . getObject ( columnIndex ) ; final ColumnMetaData metaData = columnMetaDataList . get ( columnIndex - 1 ) ; if ( metaData . type . id == Types . FLOAT && result != null ) { double primitiveDouble = ( double ) result ; return ( float ) primitiveDouble ; } return result ; }", "del_tokens": "import org . apache . calcite . avatica . AvaticaResultSet ; import org . apache . calcite . avatica . AvaticaStatement ; import org . apache . calcite . avatica . Meta ; import org . apache . calcite . avatica . QueryState ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "private", "SSL", "context", "with", "OkHttpClient", "to", "avoid", "libssl", "crash", "."], "add_tokens": "import java . security . GeneralSecurityException ; import javax . net . ssl . SSLContext ; OkHttpClient client = createOkHttpClient ( ) ; / * * * Create an OkHttpClient with its own private SSL context . Avoids libssl crash because other * libraries do not expect the global SSL context to be changed . Also see * https : //github.com/square/okhttp/issues/184. * / private static OkHttpClient createOkHttpClient ( ) { OkHttpClient okHttpClient = new OkHttpClient ( ) ; SSLContext sslContext ; try { sslContext = SSLContext . getInstance ( \"TLS\" ) ; sslContext . init ( null , null , null ) ; } catch ( GeneralSecurityException e ) { throw new AssertionError ( ) ; // The system has no TLS. Just give up. } okHttpClient . setSslSocketFactory ( sslContext . getSocketFactory ( ) ) ; return okHttpClient ; }", "del_tokens": "OkHttpClient client = new OkHttpClient ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "background", "launching", "and", "power", "saving", "into", "open", "source", "library"], "add_tokens": "* beaconManager . unbind ( this ) ;", "del_tokens": "* beaconManager . unBind ( this ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "possible", "NPE", "when", "logging", "an", "exception"], "add_tokens": "log . error ( e . toString ( ) , e ) ;", "del_tokens": "log . error ( \"Error validating markup from \" + responsePage . getClass ( ) . getName ( ) + \": \" + e . getMessage ( ) , e ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "state", "issues", "with", "shutting", "down", "the", "environment", "and", "class", "catalog"], "add_tokens": "private boolean isClosed ; this . isClosed = false ; classCatalog = null ; env = null ; this . isClosed = true ; @ Override public boolean isClosed ( ) { return isClosed ; } if ( env == null || ! env . isValid ( ) ) {", "del_tokens": "if ( env == null ) {", "commit_type": "fix"}
{"commit_tokens": ["use", "Throwable", "instead", "of", "string", "representation", "of", "error"], "add_tokens": "scenarioTest . log ( LogStatus . FAIL , testSteps . poll ( ) . getName ( ) , result . getError ( ) ) ;", "del_tokens": "scenarioTest . log ( LogStatus . FAIL , testSteps . poll ( ) . getName ( ) , result . getErrorMessage ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["make", "BufferedOutput", "the", "default", "serializer", "."], "add_tokens": "* Maintains a decent - sized byte buffer for writing . If the delimited field 's byte-array-value * is too large , it is wrapped by another buffer and linked together .", "del_tokens": "* More or less the same as { @ code DeferredOutput } but it maintains a decent - sized byte buffer * for writing . { @ code DeferredOutput } converts every field to a btye array whereas * { @ code BufferedOutput } writes it to the buffer .", "commit_type": "make"}
{"commit_tokens": ["fix", "missing", "page", "events", "."], "add_tokens": "if ( pageMode != null && elementId != null && pageMode . contains ( elementId ) ) { if ( ( pageModeToUse == null || pageModeToUse . equals ( \"\" ) ) && ApplicationEventGroup . USER . equals ( applicationEventGroup ) ) { pageModeToUse = \"Overview\" ; }", "del_tokens": "if ( ( pageMode == null || pageMode . equals ( \"\" ) ) && ApplicationEventGroup . USER . equals ( applicationEventGroup ) ) { pageModeToUse = \"Overview\" ; } else if ( pageMode != null && elementId != null && pageMode . contains ( elementId ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "autoescape", "=", "strict", "the", "implicit", "autoescape", "mode", "for", "Soy", "templates", "."], "add_tokens": "private static final AutoescapeMode DEFAULT_FILE_WIDE_DEFAULT_AUTOESCAPE_MODE = AutoescapeMode . STRICT ; new Attribute ( \"autoescape\" , AutoescapeMode . getAttributeValues ( ) , DEFAULT_FILE_WIDE_DEFAULT_AUTOESCAPE_MODE . getAttributeValue ( ) ) ,", "del_tokens": "private static final AutoescapeMode DEFAULT_FILE_WIDE_DEFAULT_AUTOESCAPE_MODE = null ; new Attribute ( \"autoescape\" , AutoescapeMode . getAttributeValues ( ) , null ) ,", "commit_type": "make"}
{"commit_tokens": ["Added", "pre", "-", "defined", "CSS", "class"], "add_tokens": "import com . helger . html . css . DefaultCSSClassProvider ; import com . helger . html . css . ICSSClassProvider ; public class BootstrapViewForm extends AbstractHCDiv < BootstrapViewForm > implements IMutableBootstrapFormGroupContainer public static final ICSSClassProvider CSS_CLASS_VIEW_FORM = DefaultCSSClassProvider . create ( \"view-form\" ) ; addClass ( CSS_CLASS_VIEW_FORM ) ; final BootstrapGridSpec aNewLeft = BootstrapGridSpec . create ( nLeftPartsXS , nLeftPartsSM , nLeftPartsMD , nLeftPartsLG ) ; public BootstrapViewForm setSplitting ( @ Nonnull final BootstrapGridSpec aLeft , @ Nonnull final BootstrapGridSpec aRight )", "del_tokens": "public class BootstrapViewForm extends AbstractHCDiv < BootstrapViewForm > implements IMutableBootstrapFormGroupContainer final BootstrapGridSpec aNewLeft = BootstrapGridSpec . create ( nLeftPartsXS , nLeftPartsSM , nLeftPartsMD , nLeftPartsLG ) ; public BootstrapViewForm setSplitting ( @ Nonnull final BootstrapGridSpec aLeft , @ Nonnull final BootstrapGridSpec aRight )", "commit_type": "add"}
{"commit_tokens": ["Fix", "Java", "6", "compatibility", "in", "CatalogEntry", ".", "compareTo", "()"], "add_tokens": "int result = Integer . valueOf ( ast . getLineNo ( ) ) . compareTo ( Integer . valueOf ( pOther . getAst ( ) . getLineNo ( ) ) ) ;", "del_tokens": "int result = Integer . compare ( ast . getLineNo ( ) , pOther . getAst ( ) . getLineNo ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "using", "US", "locale", "in", "formatter"], "add_tokens": "import java . util . Locale ; byte [ ] costFactorBytes = String . format ( Locale . US , \"%02d\" , hashData . cost ) . getBytes ( defaultCharset ) ;", "del_tokens": "byte [ ] costFactorBytes = String . format ( \"%02d\" , hashData . cost ) . getBytes ( defaultCharset ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "tests", "so", "that", "DateTimes", "are", "equated", "without", "relying", "on", "the", "zone", "name", "to", "be", "the", "same", "."], "add_tokens": "assertThat ( reconstituted . dt . toString ( ) , is ( original . dt . toString ( ) ) ) ; // work-around the loss of zone name and just worry about the offset", "del_tokens": "assertThat ( reconstituted . dt , is ( original . dt ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "Scalpel", "Module", "to", "sample", "app"], "add_tokens": "import com . squareup . okhttp . Cache ; import com . squareup . okhttp . OkHttpClient ; import com . squareup . picasso . OkHttpDownloader ; import com . squareup . picasso . Picasso ; import io . palaima . debugdrawer . scalpel . ScalpelModule ; new ScalpelModule ( this ) ,", "del_tokens": "import com . squareup . okhttp . Cache ; import com . squareup . okhttp . OkHttpClient ; import com . squareup . picasso . OkHttpDownloader ; import com . squareup . picasso . Picasso ;", "commit_type": "add"}
{"commit_tokens": ["created", "enum", "CompressionType", ".", "Now", "a", "compression", "type", "can", "be", "set", "to", "a", "graph", ".", "We", "have", "2", "compression", "types", ":", "NO_COMPRESSION", "and", "GZIP_COMPRESSION"], "add_tokens": "", "del_tokens": "", "commit_type": "create"}
{"commit_tokens": ["Removed", "duplicate", "dependency", "on", "protempa", "-", "dsb", "-", "relationaldb", ".", "Fixed", "use", "of", "StringUtils", "to", "use", "commons", "-", "lang3", "instead", "of", "commons", "-", "lang", "."], "add_tokens": "import org . apache . commons . lang3 . StringUtils ;", "del_tokens": "import org . apache . commons . lang . StringUtils ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "method", "only", "call", "the", "getGuesses", "()", "method", "once", "rather", "than", "over", "and", "over", "."], "add_tokens": "final BigDecimal guesses = getGuesses ( ) ; if ( guesses . compareTo ( BigDecimal . valueOf ( 1e3 ) ) == - 1 ) else if ( guesses . compareTo ( BigDecimal . valueOf ( 1e6 ) ) == - 1 ) else if ( guesses . compareTo ( BigDecimal . valueOf ( 1e8 ) ) == - 1 ) else if ( guesses . compareTo ( BigDecimal . valueOf ( 1e10 ) ) == - 1 )", "del_tokens": "if ( getGuesses ( ) . compareTo ( BigDecimal . valueOf ( 1e3 ) ) == - 1 ) else if ( getGuesses ( ) . compareTo ( BigDecimal . valueOf ( 1e6 ) ) == - 1 ) else if ( getGuesses ( ) . compareTo ( BigDecimal . valueOf ( 1e8 ) ) == - 1 ) else if ( getGuesses ( ) . compareTo ( BigDecimal . valueOf ( 1e10 ) ) == - 1 )", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "credentials", "of", "type", "ssh", "."], "add_tokens": "private static final RsaCredential CREDENTIAL = new RsaCredential ( \"public-key\" , \"private-key\" ) ;", "del_tokens": "private static final RsaCredential CREDENTIAL = new RsaCredential ( \"myname\" , \"secret\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Message", "serializetion", "/", "deserialization", "."], "add_tokens": "/ * * * Interface of Message object . * * < h2 > JSON Deserialization < / h2 > * * < p > If you want serialize / deserialize of this object , please use Jackson 's ObjectMapper with * * < pre > . registerModule ( new < a href = \"https://github.com/FasterXML/jackson-modules-java8/tree/master/parameter-names\" > ParameterNamesModule < / a > ( ) ) ; < / pre > * / property = \"type\" @ JsonSubTypes . Type ( VideoMessage . class ) ,", "del_tokens": "property = \"type\" , visible = true", "commit_type": "add"}
{"commit_tokens": ["Adding", "a", "MTS", "replace", "PID", "utility"], "add_tokens": "return key >= storage . length ? Integer . MIN_VALUE : storage [ key ] ; } public boolean contains ( int key ) { return key >= 0 && key < storage . length ;", "del_tokens": "return key >= storage . length ? null : storage [ key ] ;", "commit_type": "add"}
{"commit_tokens": ["upgraded", "to", "latest", "recent", "camunda", "camel", "and", "Spring", "version", ".", "added", "java", "suffixes", "to", "osgi", "component", "."], "add_tokens": "ActivityExecution execution = ( ActivityExecution ) Context . getBpmnExecutionContext ( ) . getExecution ( ) ;", "del_tokens": "ActivityExecution execution = ( ActivityExecution ) Context . getExecutionContext ( ) . getExecution ( ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Added", "tooltip", "example", "+", "small", "refactoring", "of", "docu", "page"], "add_tokens": "if ( theme == null ) { theme = \"aristo\" ; encodeTheme ( context , \"primefaces-\" + theme , \"theme.css\" ) ;", "del_tokens": "if ( theme == null || theme . equalsIgnoreCase ( \"aristo\" ) ) { encodeTheme ( context , \"primefaces\" , \"themes/aristo/theme.css\" ) ; } else if ( ! theme . equalsIgnoreCase ( \"none\" ) ) { encodeTheme ( context , PREFIX_PRIMEFACES + theme , \"theme.css\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Create", "average", "entropy", "method", "to", "get", "rid", "of", "in", "-", "line", "calculations"], "add_tokens": "if ( match . getAverageEntropy ( ) > to_compare . getAverageEntropy ( ) )", "del_tokens": "if ( match . calculateEntropy ( ) / match . getLength ( ) > to_compare . calculateEntropy ( ) / to_compare . getLength ( ) )", "commit_type": "create"}
{"commit_tokens": ["Updated", "the", "tests", "extended", "StubFinding", "contract"], "add_tokens": "@ Bean ( destroyMethod = \"close\" ) StubRunnerOptions stubRunnerOptions = new StubRunnerOptions ( minPortValue , maxPortValue , uriStringOrEmpty ( stubRepositoryRoot ) , BatchStubRunner batchStubRunner = new BatchStubRunnerFactory ( stubRunnerOptions , dependencies ) . buildBatchStubRunner ( ) ; // TODO: Consider running it in a separate thread batchStubRunner . runStubs ( ) ; return batchStubRunner ;", "del_tokens": "@ Bean ( initMethod = \"runStubs\" , destroyMethod = \"close\" ) StubRunnerOptions stubRunnerOptions = new StubRunnerOptions ( minPortValue , maxPortValue , uriStringOrEmpty ( stubRepositoryRoot ) , return new BatchStubRunnerFactory ( stubRunnerOptions , dependencies ) . buildBatchStubRunner ( ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "cgc", "option", "in", "JavaOption"], "add_tokens": "return new LaunchArgument ( option , tokens , option . getExtraArguments ( ) , javaLibraries , nativesDir ) ;", "del_tokens": "return new LaunchArgument ( option , tokens , option . getExtraArguments ( ) , Utils . isCGCSupported ( ) , javaLibraries , nativesDir ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "some", "deprecated", "methods", "changed", "default", "font", "size", "name", "."], "add_tokens": "title . setTextSize ( permissionModel . getTextSize ( ) ) ; message . setTextColor ( permissionModel . getTextColor ( ) == 0 ? Color . WHITE : permissionModel . getTextColor ( ) ) ; if ( permissionModel . getTextSize ( ) != 0 ) message . setTextSize ( TypedValue . COMPLEX_UNIT_PX , permissionModel . getTextSize ( ) ) ;", "del_tokens": "title . setTextSize ( TypedValue . COMPLEX_UNIT_PX , permissionModel . getTextSize ( ) ) ; message . setTextColor ( permissionModel . getTextColor ( ) ) ; if ( permissionModel . getTextSize ( ) != 0 ) message . setTextSize ( TypedValue . COMPLEX_UNIT_PX , permissionModel . getTextSize ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["make", "JsonNodeClaim", "always", "return", "false", "for", "isNull", "invocation"], "add_tokens": "return false ;", "del_tokens": "return ! ( data . isObject ( ) || data . isArray ( ) || data . canConvertToLong ( ) || data . isTextual ( ) || data . isNumber ( ) || data . isBoolean ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "a", "document", "creation", "for", "checking", "footer", "/", "header", "output"], "add_tokens": "public class OdsFileCreation {", "del_tokens": "public class OdsFileChecks {", "commit_type": "add"}
{"commit_tokens": ["fix", "typos", "and", "inefficient", "type", "conversion", "warnings"], "add_tokens": "* @ author Michael Keppler ( bananeweizen @ gmx . de ) // TODO parameterize this rounding to allow variable decimal points * Utility enumeration used to convert between Numbers and doubles . return Long . valueOf ( ( long ) value ) ; return Integer . valueOf ( ( int ) value ) ; return Float . valueOf ( ( float ) value ) ; return Short . valueOf ( ( short ) value ) ; return Byte . valueOf ( ( byte ) value ) ; return BigDecimal . valueOf ( value ) ;", "del_tokens": "// TODO parametrise this rounding to allow variable decimal points * Utility enumaration used to convert between Numbers and doubles . return new Long ( ( long ) value ) ; return new Integer ( ( int ) value ) ; return new Float ( value ) ; return new Short ( ( short ) value ) ; return new Byte ( ( byte ) value ) ; return new BigDecimal ( value ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "MessageService", "result", "param", "."], "add_tokens": "SentMessage [ ] messages = messageService . getMessages ( \"1234567890\" , \"017021315000000004\" ) ; System . out . println ( messages [ 0 ] . getResult ( ) + \" \" + messages [ 0 ] . getReceiptDT ( ) ) ; String EDate = \"20170213\" ; String Order = \"D\" ; System . out . println ( response . getTotal ( ) + \" \" + response . getList ( ) . get ( 0 ) . getResult ( ) + \" \" + response . getList ( ) . get ( 0 ) . getReceiptDT ( ) ) ;", "del_tokens": "SentMessage [ ] messages = messageService . getMessages ( \"1234567890\" , \"016011515000000009\" ) ; System . out . println ( messages [ 0 ] . getSendResult ( ) + \" \" + messages [ 0 ] . getReceiptDT ( ) ) ; String EDate = \"20160115\" ; String Order = \"A\" ; System . out . println ( response . getTotal ( ) + \" \" + response . getList ( ) . get ( 0 ) . getTranNet ( ) + \" \" + response . getList ( ) . get ( 0 ) . getReceiptDT ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "cleanup", "to", "hsqldb", "preparing", "for", "next", "release"], "add_tokens": "cleanUp ( ) ; FileUtils . deleteFolder ( getHsqldbTempDir ( ) + \".tmp\" ) ; FileUtils . deleteFolder ( getHsqldbTempDir ( ) + \".log\" ) ; FileUtils . deleteFolder ( getHsqldbTempDir ( ) + \".properties\" ) ; FileUtils . deleteFolder ( getHsqldbTempDir ( ) + \".script\" ) ;", "del_tokens": "FileUtils . deleteFolder ( getHsqldbTempDir ( ) + \"*\" ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "docs", "to", "BaseSender", "&", "Receipt", "Template"], "add_tokens": "* @ param configs an instance of configs class", "del_tokens": "* @ param configs an instance of configs class ß", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "JAWR", "-", "318", "catching", "container", "specific", "browser", "abort", "excpetions"], "add_tokens": "import net . jawr . web . servlet . util . ClientAbortExceptionReoslver ; LOGGER . error ( \"Unable to write resource \" + request . getRequestURI ( ) , ex ) ; LOGGER . error ( \"No binary extension match the extension '\" + extension + \"' for the request URI : \" + requestUri ) ; } catch ( IOException e ) { if ( ClientAbortExceptionReoslver . isClientAbortException ( e ) ) { LOGGER . debug ( \"Browser cut off response\" , e ) ; } else { throw e ; } String [ ] resourceInfo = PathNormalizer . extractBinaryResourceInfo ( realFilePath ) ;", "del_tokens": "LOGGER . error ( \"Unable to write resource \" + request . getRequestURI ( ) , ex ) ; LOGGER . error ( \"No binary extension match the extension '\" + extension + \"' for the request URI : \" + requestUri ) ; String [ ] resourceInfo = PathNormalizer . extractBinaryResourceInfo ( realFilePath ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "method", "for", "upload", "user", "entities"], "add_tokens": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *", "del_tokens": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *", "commit_type": "add"}
{"commit_tokens": ["made", "ILinkedDataFragment", "an", "extension", "of", "the", "Closable", "interface"], "add_tokens": "import java . io . Closeable ; public interface ILinkedDataFragment extends Closeable", "del_tokens": "public interface ILinkedDataFragment", "commit_type": "make"}
{"commit_tokens": ["Update", "Javadoc", "for", "getAutoEventDate", "()"], "add_tokens": "* This function will clone the original management events for each year in * the experiment duration . Only the date of each event will be increased * year by year . If experiment duration is no longer than 1 year , no * generation will be executed . *", "del_tokens": "* This function will use the first event data of each type to generate the * other events of that type for the following year in the experiment * duration . The month and date will be same with the original one . If * experiment duration is no longer than 1 year , this will return empty * result set . *", "commit_type": "update"}
{"commit_tokens": ["Make", "cache", "-", "max", "-", "age", "configurable"], "add_tokens": "environment . jersey ( ) . register ( new CacheControlFilter ( config . getCacheMaxAge ( ) ) ) ;", "del_tokens": "// TODO make this configurable private static final Integer CACHE_MAX_AGE = 86400 ; // TODO -- make this prefix configurable environment . jersey ( ) . register ( new CacheControlFilter ( CACHE_MAX_AGE ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "FlexyPool", "to", "auto", "-", "start", "the", "JMX", "Reporter"], "add_tokens": "DS dataSource = propertyLoader . getDataSource ( ) ; Integer metricLogReporterMillis = propertyLoader . getMetricLogReporterMillis ( ) ; Boolean jmxEnabled = propertyLoader . isJmxEnabled ( ) ; Boolean jmxAutoStart = propertyLoader . isJmxAutoStart ( ) ; if ( metricLogReporterMillis != null ) { configurationBuilder . setMetricLogReporterMillis ( metricLogReporterMillis ) ; } if ( jmxEnabled != null ) { configurationBuilder . setJmxEnabled ( jmxEnabled ) ; } if ( jmxAutoStart != null ) { configurationBuilder . setJmxAutoStart ( jmxAutoStart ) ; }", "del_tokens": "DS dataSource = ( DS ) propertyLoader . getDataSource ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "utility", "methods", "to", "ScoredTermOrVariant", ".", "java"], "add_tokens": "public boolean isScoredTerm ( ) { return this instanceof ScoredTerm ; } public ScoredTerm asScoredTerm ( ) { return ( ScoredTerm ) this ; } public boolean isScoredVariation ( ) { return this instanceof ScoredVariation ; } public ScoredVariation asScoredVariation ( ) { return ( ScoredVariation ) this ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "methods", "to", "take", "a", "schema", "file", "as", "an", "alternative", "to", "the", "schema", "itself", "."], "add_tokens": "import java . io . File ; import java . io . IOException ; private SpecificRecord specificRecord ; this . specificRecord = ( SpecificRecord ) SpecificData . get ( ) . deepCopy ( result . getBytesProcessed ( ) , specificRecord ) ; public SpecificRecord getSpecificRecord ( ) { return specificRecord ; public Builder schemaFile ( File schemaFile ) { try { this . schema = new Schema . Parser ( ) . parse ( schemaFile ) ; } catch ( IOException e ) { throw new IllegalArgumentException ( e ) ; } return this ; }", "del_tokens": "private SpecificRecord datum ; this . datum = ( SpecificRecord ) SpecificData . get ( ) . deepCopy ( result . getBytesProcessed ( ) , datum ) ; public SpecificRecord getDatum ( ) { return datum ;", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "test", "for", "required", "with", "multi", "options"], "add_tokens": "\"Options: \" + \" ----value=<String> \" + \" -value=<String>\" , public void testRequiredMultiOption ( ) { // Required option try { final Cmd tail = commands . get ( \"requiredMultiOption\" ) ; tail . exec ( null ) ; fail ( ) ; } catch ( final IllegalArgumentException e ) { } } public void testRequiredMultiOptionWithFirstAliasProvided ( ) throws Exception { // Required option try { final Cmd tail = commands . get ( \"requiredMultiOption\" ) ; tail . exec ( null , \"-p\" ) ; fail ( ) ; } catch ( final IllegalArgumentException e ) { } } public void testRequiredMultiOptionWithSecondAliasProvided ( ) throws Exception { // Required option try { final Cmd tail = commands . get ( \"requiredMultiOption\" ) ; tail . exec ( null , \"--pass\" ) ; fail ( ) ; } catch ( final IllegalArgumentException e ) { } } @ Command public static void requiredMultiOption ( @ Option ( { \"pass\" , \"p\" } ) @ Required final String pass ) { }", "del_tokens": "import org . tomitribe . crest . cmds . processors . Help ; \"Options: \" + \" ----value=<String> \" + \" -value=<String>\" ,", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "cases", "for", "getPathInitScripts", "in", "AbstractElasticsearchMojo"], "add_tokens": "if ( pathInitScripts != null && ! pathInitScripts . isEmpty ( ) ) { return Stream . of ( pathInitScripts . split ( \",\" ) ) . map ( String :: trim ) . collect ( Collectors . toList ( ) ) ; } else { return new ArrayList < > ( ) ; }", "del_tokens": "return Stream . of ( pathInitScripts . split ( \",\" ) ) . map ( String :: trim ) . collect ( Collectors . toList ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "insert", "data", "into", "kafka", "problem"], "add_tokens": "message . setOperation ( STREAM_OPERATIONS . MANIPULATION . INSERT . toLowerCase ( ) ) ; producer . send ( new KeyedMessage < String , String > ( InternalTopic . TOPIC_DATA . getTopicName ( ) , STREAM_OPERATIONS . MANIPULATION . INSERT , json ) ) ;", "del_tokens": "message . setOperation ( STREAM_OPERATIONS . MANIPULATION . INSERT ) ; producer . send ( new KeyedMessage < String , String > ( InternalTopic . TOPIC_DATA . getTopicName ( ) , json ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "club", ".", "ico", "to", "server", "side"], "add_tokens": "Time t1 = new Time ( \"00:00\" ) ;", "del_tokens": "Time t1 = new Time ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Allow", "count", "as", "a", "functionName"], "add_tokens": "\"functionName : UnescapedSymbolicName\\n | EscapedSymbolicName\\n | COUNT ;\" ) ;", "del_tokens": "\"functionName : UnescapedSymbolicName\\n | EscapedSymbolicName ;\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Updated", "JPMML", "-", "Model", "dependency"], "add_tokens": "NormDiscrete . Method method = normDiscrete . getMethod ( ) ; switch ( method ) { case INDICATOR : { boolean equals = value . equalsString ( normDiscrete . getValue ( ) ) ; return FieldValueUtil . create ( equals ? 1d : 0d ) ; } default : throw new UnsupportedFeatureException ( normDiscrete , method ) ; }", "del_tokens": "boolean equals = value . equalsString ( normDiscrete . getValue ( ) ) ; return FieldValueUtil . create ( equals ? 1d : 0d ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "referencing", "wrong", "tags", "object", "which", "causes", "reports", "to", "not", "be", "sent", "when", "the", "customer", "assigns", "tags", "to", "the", "RaygunClient", "."], "add_tokens": "else if ( tags != null ) {", "del_tokens": "else if ( RaygunClient . tags != null ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "unit", "test", "for", "chaining", "updates", "in", "transaction"], "add_tokens": "private static final int TIMEOUT_SECONDS = 3 ; @ Test public void testCanChainUpdateStatementsWithinTransaction ( ) { Database db = db ( ) ; db . beginTransaction ( ) ; Observable < Integer > updates = Observable // set name parameter . from ( \"FRED\" ) // push into update . lift ( db . update ( \"update person set score=1 where name=?\" ) . parameterOperator ( ) ) // map num rows affected to JOHN . map ( constant ( \"JOHN\" ) ) // push into second update . lift ( db . update ( \"update person set score=2 where name=?\" ) . parameterOperator ( ) ) ; db . commit ( updates ) . toBlockingObservable ( ) . single ( ) ; }", "del_tokens": "private static final int TIMEOUT_SECONDS = 60 ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "stream", "-", "copying", "ideum", "."], "add_tokens": "import org . apache . commons . logging . Log ; import org . apache . commons . logging . LogFactory ; private final Log log = LogFactory . getLog ( CopyFileTask . class ) ; // Don't declare as static in general libraries if ( log . isTraceEnabled ( ) ) { StringBuilder msg = new StringBuilder ( ) ; msg . append ( \"\\n\\turl=\" ) . append ( loc . toString ( ) ) . append ( \"\\n\\tcontent-length=\" ) . append ( conn . getContentLength ( ) ) ; log . trace ( msg ) ; } byte [ ] buf = new byte [ 4096 ] ; for ( int len = is . read ( buf ) ; len > 0 || bytesRead < conn . getContentLength ( ) ; len = is . read ( buf ) ) { os . write ( buf , 0 , len ) ; bytesRead = bytesRead + len ;", "del_tokens": "for ( int avail = is . available ( ) ; avail > 0 || bytesRead < conn . getContentLength ( ) ; avail = is . available ( ) ) { byte [ ] b = new byte [ avail ] ; is . read ( b ) ; os . write ( b ) ; bytesRead = bytesRead + avail ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "extra", "decryption", "step", "before", "propery", "source", "locators"], "add_tokens": "import org . springframework . cloud . autoconfigure . ConfigurationPropertiesRebinderAutoConfiguration ; ConfigurationPropertiesRebinderAutoConfiguration {", "del_tokens": "ConfigurationPropertiesRebinderConfiguration {", "commit_type": "add"}
{"commit_tokens": ["make", "sentence", "tokenizer", "work", "correctly", "with", "German", "umlauts"], "add_tokens": "private static final Pattern letterPunct = Pattern . compile ( \"(\\\\s[\\\\wüöäÜÖÄß]\" + P + ) ) private static final Pattern abbrev1 = Pattern . compile ( \"([^-\\\\wüöäÜÖÄß][\\\\wüöäÜÖÄß]\" + PAP + \"\\\\s) EO ) private static final Pattern abbrev2 = Pattern . compile ( \"([^-\\\\wüöäÜÖÄß][\\\\wüöäÜÖÄß]\" + P + \")\" + E S ; private static final Pattern abbrev3 = Pattern . compile ( \"(\\\\s[\\\\wüöäÜÖÄß]\\\\.\\\\s+)\" + EOS) private static final Pattern repair1 = Pattern . compile ( \"('[\\\\wüöäÜÖÄß]\" + P + ) \\ s \");", "del_tokens": "private static final Pattern letterPunct = Pattern . compile ( \"(\\\\s\\\\w\" + P + \")\" ) ; private static final Pattern abbrev1 = Pattern . compile ( \"([^-\\\\w]\\\\w\" + PAP + \"\\\\s)\" + EOS ) ; private static final Pattern abbrev2 = Pattern . compile ( \"([^-\\\\w]\\\\w\" + P + \")\" + EOS ) ; private static final Pattern abbrev3 = Pattern . compile ( \"(\\\\s\\\\w\\\\.\\\\s+)\" + EOS ) ; private static final Pattern repair1 = Pattern . compile ( \"('\\\\w\" + P + \")(\\\\s)\" ) ;", "commit_type": "make"}
{"commit_tokens": ["make", "diffeerent", "parser", "implementations", "pluggable", "replacements", "for", "each", "other"], "add_tokens": "import com . pogofish . jadt . parser . StandardParserImpl1Factory ; final Parser parser = new StandardParser ( new StandardParserImpl1Factory ( ) ) ;", "del_tokens": "final Parser parser = new StandardParser ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "a", "flag", "to", "make", "the", "highlighted", "marker", "drawn", "on", "top", "optional", "."], "add_tokens": "private boolean mDrawHighlightedMarkerOnTop ; mDrawHighlightedMarkerOnTop = false ; mHighlightedMarker = null ; if ( ! mDrawHighlightedMarkerOnTop || ! marker . equals ( mHighlightedMarker ) ) { if ( mDrawHighlightedMarkerOnTop && mHighlightedMarker != null ) { * / * * * Returns the flag the determines if the highlighted marker will draw on top of other markers . * * @ return True if the highlighted marker will draw on top of other markers , false if they 're all drawn in order. * / public boolean isDrawHighlightedMarkerOnTop ( ) { return mDrawHighlightedMarkerOnTop ; } / * * * Set the flag that determines if the highlighted marker will draw on top of other markers . * This is false by default . * * @ param drawHighlightedMarkerOnTop the flag that determines if the highlighted marker will draw on top of other markers . * / public void setDrawHighlightedMarkerOnTop ( boolean drawHighlightedMarkerOnTop ) { this . mDrawHighlightedMarkerOnTop = drawHighlightedMarkerOnTop ; }", "del_tokens": "if ( ! marker . equals ( mHighlightedMarker ) ) { if ( mHighlightedMarker != null ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "issues", "and", "added", "some", "logging", "and", "convenience", "methods", "."], "add_tokens": "if ( stream != null ) { DaoManager . loadDatabaseConfigFromStream ( stream ) ; } if ( configFile == null ) { return null ; } else { return new FileInputStream ( configFile ) ; }", "del_tokens": "DaoManager . loadDatabaseConfigFromStream ( stream ) ; return new FileInputStream ( configFile ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missing", "equals", "and", "hashCode", "methods", "for", "several", "compound", "components", ".", "Added", "more", "canonical", "way", "of", "creating", "ambiguity", "resolver", "chains", "in", "order", "to", "remove", "their", "nesting", "state", "from", "equals", "and", "hashCode", "methods", "."], "add_tokens": "import static org . hamcrest . core . IsNot . not ; private MethodDelegationBinder . AmbiguityResolver first , second , third ; @ Test public void testEqualsHashCode ( ) throws Exception { MethodDelegationBinder . AmbiguityResolver firstChain = MethodDelegationBinder . AmbiguityResolver . Chain . of ( MethodDelegationBinder . AmbiguityResolver . Chain . of ( first , second ) , third ) ; MethodDelegationBinder . AmbiguityResolver secondChain = MethodDelegationBinder . AmbiguityResolver . Chain . of ( first , second , third ) ; assertThat ( firstChain . hashCode ( ) , is ( secondChain . hashCode ( ) ) ) ; assertThat ( firstChain , is ( secondChain ) ) ; assertThat ( firstChain . hashCode ( ) , not ( is ( chain . hashCode ( ) ) ) ) ; assertThat ( firstChain , not ( is ( chain ) ) ) ; }", "del_tokens": "private MethodDelegationBinder . AmbiguityResolver first , second ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "or", "names", "requests", "."], "add_tokens": "import com . basistech . rosette . apimodel . NameSimilarityRequest ; import com . basistech . rosette . apimodel . NameTranslationRequest ; @ JsonProperty ( \"documentRequest\" ) Request documentRequest , @ JsonProperty ( \"nameTranslationRequest\" ) NameTranslationRequest nameTranslationRequest , @ JsonProperty ( \"nameSimilarityRequest\" ) NameSimilarityRequest nameSimilarityRequest ) {", "del_tokens": "@ JsonProperty ( \"request\" ) Request request ) {", "commit_type": "allow"}
{"commit_tokens": ["Adding", "Mapbox", "Access", "Token", "and", "Map", "Id", "checks", "for", "Web", "Map", "provider"], "add_tokens": "import android . text . TextUtils ; if ( ! TextUtils . isEmpty ( mapboxAccessToken ) && ! TextUtils . isEmpty ( mapboxMapId ) ) { options = new MapboxWebMapType ( mapboxAccessToken , mapboxMapId ) ; } else { options = new GoogleWebMapType ( ) ; }", "del_tokens": "options = new MapboxWebMapType ( mapboxAccessToken , mapboxMapId ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "any", "throw", "new", "TechnicalException", "by", "simple", "log", "in", "all", "loop"], "add_tokens": "import org . apache . log4j . Logger ; protected final Logger logger = Logger . getLogger ( CommonSteps . class . getClass ( ) ) ; logger . error ( TechnicalException . TECHNICAL_SUBSTEP_ERROR_MESSAGE + e . getMessage ( ) ) ; logger . error ( TechnicalException . TECHNICAL_SUBSTEP_ERROR_MESSAGE + e . getMessage ( ) ) ; logger . error ( TechnicalException . TECHNICAL_SUBSTEP_ERROR_MESSAGE + e . getMessage ( ) ) ;", "del_tokens": "throw new TechnicalException ( TechnicalException . TECHNICAL_SUBSTEP_ERROR_MESSAGE + e . getMessage ( ) , e . getCause ( ) ) ; throw new TechnicalException ( TechnicalException . TECHNICAL_SUBSTEP_ERROR_MESSAGE + e . getMessage ( ) , e . getCause ( ) ) ; throw new TechnicalException ( TechnicalException . TECHNICAL_SUBSTEP_ERROR_MESSAGE + e . getMessage ( ) , e . getCause ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "some", "properties", "after", "I", "took", "I", "inspected", "each", "property", "one", "by", "one", "(", "double", "check", ")", ";"], "add_tokens": "errorEventItem = prop . getProperty ( \"constantcontact.api.errors.eventitem\" ) ; private String accountInfo ; private String errorEventItem ; private String errorInvalidWebhook ; private String utf8 ; public String getErrorEventItem ( ) { return errorEventItem ; } public void setErrorEventItem ( String errorEventItem ) { this . errorEventItem = errorEventItem ; } public String getErrorEventItemAttributeId ( )", "del_tokens": "eventItem = prop . getProperty ( \"constantcontact.api.errors.eventitem\" ) ; private String accountInfo = \"/v2/account/info\" ; private String eventItem ; private String errorInvalidWebhook = \"Invalid Webhook. The x-ctct-hmac-sha256 does not correspond to message encryption.\" ; private String utf8 = \"UTF-8\" ; public String getEventItem ( ) { return eventItem ; } public void setEventItem ( String eventItem ) { this . eventItem = eventItem ; } public String getErrorEventItemAttributeId ( )", "commit_type": "fix"}
{"commit_tokens": ["add", "prefixes", "to", "simple", "log", "messages"], "add_tokens": "sendToConsole ( \"DEBUG: \" + msg ) ; sendToConsole ( \"DEBUG: \" + msg , e ) ; sendToConsole ( \"ERROR: \" + msg ) ; sendToConsole ( \"ERROR: \" + msg , e ) ; sendToConsole ( \"INFO: \" + msg ) ; @ Override sendToConsole ( \"INFO: \" + msg , e ) ; sendToConsole ( \"WARN: \" + msg ) ; sendToConsole ( \"WARN: \" + msg , e ) ;", "del_tokens": "sendToConsole ( msg ) ; sendToConsole ( msg , e ) ; sendToConsole ( msg ) ; sendToConsole ( msg , e ) ; sendToConsole ( msg ) ; sendToConsole ( msg , e ) ; sendToConsole ( msg ) ; sendToConsole ( msg , e ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "text", "field", "alignment", "issue"], "add_tokens": "field . prefWidthProperty ( ) . addListener ( ( o , oldVal , newVal ) -> { field . setMaxWidth ( newVal . doubleValue ( ) ) ; invalid = true ; } ) ; startX = getSkinnable ( ) . getBoundsInLocal ( ) . getMinX ( ) ; endX = getSkinnable ( ) . getWidth ( ) - getSkinnable ( ) . getBaselineOffset ( ) ;", "del_tokens": "startX = getSkinnable ( ) . getBoundsInLocal ( ) . getMinX ( ) ; endX = getSkinnable ( ) . getBoundsInLocal ( ) . getMaxX ( ) ; endX -= endX / 20 ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "onlyIfNewer", "for", "the", "file", "protocol"], "add_tokens": "executeFileProtocol ( src , timestamp , destFile ) ; private void executeFileProtocol ( URL src , long timestamp , File destFile ) throws IOException { File srcFile = null ; srcFile = new File ( src . toURI ( ) ) ; //check if file was modified long lastModified = 0 ; if ( srcFile != null ) { lastModified = srcFile . lastModified ( ) ; if ( lastModified != 0 && timestamp >= lastModified ) { if ( ! quiet ) { project . getLogger ( ) . info ( \"Not modified. Skipping '\" + src + \"'\" ) ; } ++ upToDate ; return ; } } //set last-modified time of destination file if ( onlyIfModified && lastModified > 0 ) { destFile . setLastModified ( lastModified ) ; } //set last-modified time of destination file long newTimestamp = parseLastModified ( response ) ; if ( onlyIfModified && newTimestamp > 0 ) { destFile . setLastModified ( newTimestamp ) ; }", "del_tokens": "executeFileProtocol ( src , destFile ) ; private void executeFileProtocol ( URL src , File destFile ) throws IOException { File srcFile = new File ( src . toURI ( ) ) ; long newTimestamp = parseLastModified ( response ) ; if ( onlyIfModified && newTimestamp > 0 ) { destFile . setLastModified ( newTimestamp ) ; }", "commit_type": "implement"}
{"commit_tokens": ["Fix", "some", "DL", "leaking", "keys"], "add_tokens": "import hex . FrameTask ; import static water . util . MRUtils . sampleFrame ; import static water . util . MRUtils . sampleFrameStratified ; import water . * ; for ( Key k : trash ) Keyed . remove ( k , fs ) ;", "del_tokens": "import water . * ; import hex . FrameTask ; import static water . util . MRUtils . sampleFrame ; import static water . util . MRUtils . sampleFrameStratified ; for ( Key k : trash ) DKV . remove ( k , fs ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "in", "JSComparator", "and", "bugs", "in", "tests"], "add_tokens": "this . func = func ; ret = Integer . valueOf ( invocable . invokeFunction ( \"Utils_invoke\" , params ) . toString ( ) ) ; exc . printStackTrace ( ) ;", "del_tokens": "this . functionName = Utils . getUniqeFunctionName ( ) ; this . func = \"var \" + this . functionName + \" = \" + func ; ret = Integer . valueOf ( invocable . invokeFunction ( this . functionName , params ) . toString ( ) ) ; // do nothing for now", "commit_type": "fix"}
{"commit_tokens": ["Allow", "cache", "size", "adjustment", "."], "add_tokens": "private long maxSize ; final ThreadPoolExecutor executorService = new ThreadPoolExecutor ( 0 , 1 , public long getMaxSize ( ) { / * * * Changes the maximum number of bytes the cache can store and queues a job * to trim the existing store , if necessary . * / public synchronized void setMaxSize ( long maxSize ) { this . maxSize = maxSize ; executorService . submit ( cleanupCallable ) ; }", "del_tokens": "import java . util . concurrent . ExecutorService ; private final long maxSize ; private final ExecutorService executorService = new ThreadPoolExecutor ( 0 , 1 , public long maxSize ( ) {", "commit_type": "allow"}
{"commit_tokens": ["fixed", "issue", "2", ":", "https", ":", "//", "github", ".", "com", "/", "adyliu", "/", "jafka", "/", "issues", "/", "2"], "add_tokens": "import java . util . LinkedHashMap ; this . originalBrokerTopicsParitions = new LinkedHashMap < String , SortedSet < Partition > > ( originalBrokerTopicsParitions ) ; this . originBrokerIds = new LinkedHashMap < Integer , Broker > ( originBrokerIds ) ;", "del_tokens": "this . originalBrokerTopicsParitions = originalBrokerTopicsParitions ; this . originBrokerIds = originBrokerIds ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "arbitrary", "number", "of", "elements", "from", "QueueFile"], "add_tokens": "public final void remove ( int n ) throws IOException { try { queueFile . remove ( n ) ; if ( listener != null ) { for ( int i = 0 ; i < n ; i ++ ) { listener . onRemove ( this ) ; } } } catch ( IOException e ) { throw new FileException ( \"Failed to remove.\" , e , file ) ; } }", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Improve", "Gradle", "model", "to", "avoid", "system", "properties", "extending", "the", "index", "-", "TODO", "make", "the", "project", "properties", "nested"], "add_tokens": "import com . google . common . annotations . VisibleForTesting ; import com . google . common . base . Supplier ; import nebula . plugin . metrics . model . GradleToolContainer ; GradleToolContainer tool = GradleToolContainer . fromGradle ( gradle ) ;", "del_tokens": "import com . google . common . annotations . VisibleForTesting ; import com . google . common . base . Supplier ; nebula . plugin . metrics . model . Gradle tool = new nebula . plugin . metrics . model . Gradle ( gradle . getStartParameter ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "dynamic", "huffman", "and", "PairHMM", "edits"], "add_tokens": "String operSys = System . getProperty ( \"os.name\" ) . toLowerCase ( ) ; final boolean isMAC ; if ( operSys . contains ( \"mac\" ) ) isMAC = true ; else isMAC = false ; if ( ! isMAC ) boolean Supported = new IntelPairHmmOMP ( ) . load ( ) ; Assert . assertTrue ( Supported ) ;", "del_tokens": "boolean isSupported = new IntelPairHmmOMP ( ) . load ( ) ; if ( ! isSupported ) Assert . assertTrue ( isSupported ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "a", "schema", "budiler", "and", "a", "basic", "testbed", "loader"], "add_tokens": "private static final Random TX_TYPE_RANDOM = new Random ( ) ; int index = TX_TYPE_RANDOM . nextInt ( TpccConstants . FREQUENCY_TOTAL ) ;", "del_tokens": "private static Random txnTypeRandom ; txnTypeRandom = new Random ( ) ; int index = txnTypeRandom . nextInt ( TpccConstants . FREQUENCY_TOTAL ) ;", "commit_type": "implement"}
{"commit_tokens": ["Updated", "to", "improve", "priority", "support", "."], "add_tokens": "import com . tapsterrock . mpx . Priority ; task . setPriority ( getPriority ( MPPUtility . getShort ( data , 120 ) ) ) ; // getPriority (MPPUtility.getShort (data, 120)) / * * * This method converts between the numeric priority value * used in versions of MSP after MSP98 and the 10 priority * levels defined by the MPX standard . * * @ param priority value read from MPP file * / private Priority getPriority ( int priority ) { int result ; if ( priority >= 1000 ) { result = Priority . DO_NOT_LEVEL ; } else { result = priority / 100 ; } return ( new Priority ( result ) ) ; }", "del_tokens": "// MPPUtility.getShort (data, 120); // 120-121", "commit_type": "update"}
{"commit_tokens": ["Adding", "in", "-", "place", "operations", "and", "their", "function", "tests"], "add_tokens": "\"Density\" , // domain axis label \"Time\" , // range axis label", "del_tokens": "\"Type\" , // domain axis label \"Value\" , // range axis label", "commit_type": "add"}
{"commit_tokens": ["allow", "ResourceFieldContributor", "to", "access", "ResourceInformation"], "add_tokens": "import java . util . List ;", "del_tokens": "import java . util . List ;", "commit_type": "allow"}
{"commit_tokens": ["add", "jmeter", "support", "for", "web", "services", "testing", "(", "http", ")"], "add_tokens": "private String username ; private String password ; wsc . setBasicUsernamePassword ( user , pass ) ; @ Deprecated / * * * Calls this to provide username and password . This will use Basic authentication , with a header such as * \"Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\" * * @ param username user name * @ param password password * / public void setBasicUsernamePassword ( String username , String password ) { this . username = username ; this . password = password ; LOG . debug ( \"use basic username/password {}/********\" , username ) ; userPassCredentialsProvider = new BasicCredentialsProvider ( ) ; userPassCredentialsProvider . setCredentials ( AuthScope . ANY , new UsernamePasswordCredentials ( username , password ) ) ; authCache = new BasicAuthCache ( ) ; BasicScheme basicAuth = new BasicScheme ( ) ; authCache . put ( httpHost , basicAuth ) ; } public String getClientCertificate ( ) { return clientCertificate ; } public String getKeyPassword ( ) { return keyPassword ; } public String getUsername ( ) { return username ; } public String getPassword ( ) { return password ; }", "del_tokens": "wsc . setUsernamePassword ( user , pass ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "fetch", "FCM", "token", "using", "specific", "sender", "id"], "add_tokens": "import com . google . firebase . messaging . FirebaseMessaging ; final DeviceInfo _deviceInfo = this . deviceInfo ; String freshToken = FCMGetFreshToken ( _deviceInfo . getFCMSenderID ( ) ) ; private String FCMGetFreshToken ( final String senderID ) { if ( senderID != null ) { token = FirebaseInstanceId . getInstance ( ) . getToken ( senderID , FirebaseMessaging . INSTANCE_ID_SCOPE ) ; } else { token = FirebaseInstanceId . getInstance ( ) . getToken ( ) ; }", "del_tokens": "String freshToken = FCMGetFreshToken ( ) ; private String FCMGetFreshToken ( ) { token = FirebaseInstanceId . getInstance ( ) . getToken ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Makes", "it", "possible", "to", "set", "a", "native", "ad", "unit", "id"], "add_tokens": "import java . util . Collection ; private final List < String > mAdmobReleaseUnitIds = new ArrayList < > ( ) ; private String getReleaseUnitId ( ) { return mAdmobReleaseUnitIds . size ( ) > 0 ? mAdmobReleaseUnitIds . get ( 0 ) : null ; } String unitId = getReleaseUnitId ( ) != null ? getReleaseUnitId ( ) : getDefaultUnitId ( ) ; public void setReleaseUnitIds ( Collection < String > admobReleaseUnitIds ) { if ( admobReleaseUnitIds . size ( ) > 1 ) throw new RuntimeException ( \"Currently only supports one unit id.\" ) ; mAdmobReleaseUnitIds . addAll ( admobReleaseUnitIds ) ; }", "del_tokens": "import java . util . HashMap ; import java . util . Map ; String unitId = getDefaultUnitId ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "call", "to", "getFlowContext", "in", "async", "case"], "add_tokens": "public static void successAsync ( ResponseEntity response , HttpSpringLogger httpSpringLogger ) { FlowContextFactory . deserializeNativeFlowContext ( TransactionLogger . getFlowContextAsync ( httpSpringLogger ) ) ; FlowContextFactory . deserializeNativeFlowContext ( TransactionLogger . getFlowContextAsync ( httpSpringLogger ) ) ; putProperty ( LoggingKeys . HTTP_CODE . name ( ) , String . valueOf ( response . getStatusCode ( ) ) ) ; putProperty ( LoggingKeys . MSG . name ( ) , ( String ) response . getBody ( ) ) ;", "del_tokens": "public static void successAsync ( ResponseEntity response , HttpSpringLogger httpSpringLogger ) { FlowContextFactory . deserializeNativeFlowContext ( httpSpringLogger . getFlowContextAsync ( httpSpringLogger ) ) ; FlowContextFactory . deserializeNativeFlowContext ( httpSpringLogger . getFlowContextAsync ( httpSpringLogger ) ) ; putProperty ( LoggingKeys . HTTP_CODE . name ( ) , String . valueOf ( response . getStatusCode ( ) ) ) ; //this.properties.put(loggingKeys.getKeyValue(LoggingKeys.HTTP_CODE.name()), String.valueOf(response.getStatusCode())); putProperty ( LoggingKeys . MSG . name ( ) , ( String ) response . getBody ( ) ) ; //this.properties.put(loggingKeys.getKeyValue(LoggingKeys.MSG.name()), (String)response.getBody());", "commit_type": "fix"}
{"commit_tokens": ["Added", "equals", "()", "method", "."], "add_tokens": "public boolean equals ( Object obj ) { if ( obj instanceof AbstractAdapterAuthenticationToken ) { if ( ! super . equals ( obj ) ) return false ; AbstractAdapterAuthenticationToken test = ( AbstractAdapterAuthenticationToken ) obj ; return ( this . getKeyHash ( ) == test . getKeyHash ( ) ) ; } return false ; } }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Move", "to", "JUnit", "5", "."], "add_tokens": "import org . junit . jupiter . api . Test ; class HSalsa20Test { void interoperability ( ) throws Exception {", "del_tokens": "import org . junit . Test ; public class HSalsa20Test { public void interoperability ( ) throws Exception {", "commit_type": "move"}
{"commit_tokens": ["Added", "an", "interface", "CheckedCacheClassLoaderStrategy", ".", "DigestLookup", "interface", "that", "must", "be", "provided", "to", "the", "strategy", "to", "provide", "the", "digests", "to", "use", "when", "looking", "up", "a", "class", "."], "add_tokens": "private final DigestLookup digestLookup ; public CheckedCacheClassLoaderStrategy ( CheckedCache cache , DigestLookup digestLookup , ClassLoaderStrategy fallback ) { this ( cache , \"MD5\" , digestLookup , fallback ) ; public CheckedCacheClassLoaderStrategy ( CheckedCache cache , String digestAlgorithm , DigestLookup digestLookup , ClassLoaderStrategy fallback ) { this . digestLookup = digestLookup ; public static interface DigestLookup { byte [ ] getDigest ( String name ) ; } byte [ ] digest = digestLookup . getDigest ( name ) ; def = cache . get ( classPath , digest ) ;", "del_tokens": "public CheckedCacheClassLoaderStrategy ( CheckedCache cache , ClassLoaderStrategy fallback ) { this ( cache , \"MD5\" , fallback ) ; public CheckedCacheClassLoaderStrategy ( CheckedCache cache , String digestAlgorithm , ClassLoaderStrategy fallback ) { def = cache . get ( classPath , null ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "FullQuery", "/", "FullQueryBuilder", "and", "move", "builder", "methods", "to", "Query"], "add_tokens": "* Query & lt ; Entity & gt ; query = * Query . gqlQueryBuilder ( Query . Type . FULL , \"select * from kind\" ) . build ( ) ; * Query & lt ; ? & gt ; query = Query . gqlQueryBuilder ( \"select __key__ from kind\" ) . build ( ) ;", "del_tokens": "* Query & lt ; Entity & gt ; query = GqlQuery . builder ( Query . Type . FULL , \"select * from kind\" ) . build ( ) ; * Query & lt ; ? & gt ; query = GqlQuery . builder ( \"select __key__ from kind\" ) . build ( ) ; / * * * Returns a new GQL query builder . * * @ see < a href = \"https://cloud.google.com/datastore/docs/apis/gql/gql_reference\" > GQL Reference < / a > * / public static GqlQuery . Builder < ? > builder ( String gql ) { return builder ( Type . UNKNOWN , gql ) ; } / * * * Returns a new GQL query builder . * * @ see < a href = \"https://cloud.google.com/datastore/docs/apis/gql/gql_reference\" > GQL Reference < / a > * / public static < V > GqlQuery . Builder < V > builder ( Type < V > type , String gql ) { return new GqlQuery . Builder < > ( type , gql ) ; }", "commit_type": "add"}
{"commit_tokens": ["fixed", "up", "problems", "with", "ignored", "keys", "and", "added", "processor", "options", "for", "ignored", "keys", "in", "the", "triple", "callbacks"], "add_tokens": "expanded = p . expand ( p . new ActiveContext ( ) , p . new UniqueNamer ( \"_:t\" ) , null , input ) ; UniqueNamer namer = p . new UniqueNamer ( \"_:t\" ) ; Object expanded = p . expand ( p . new ActiveContext ( ) , namer , null , input ) ; compacted . put ( graph , p . removePreserve ( ctx , compacted . get ( graph ) ) ) ;", "del_tokens": "expanded = p . expand ( p . new ActiveContext ( ) , null , input ) ; Object expanded = p . expand ( p . new ActiveContext ( ) , null , input ) ; compacted . put ( graph , JSONLDProcessor . removePreserve ( ctx , compacted . get ( graph ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "all", "test", "for", "the", "VNFD", "CRUD", "operations"], "add_tokens": "public class Security implements Serializable { public String getId ( ) { return id ; } public void setId ( String id ) { this . id = id ; }", "del_tokens": "public class Security implements Serializable {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "visibility", "reduction", "error", "of", "public", "method", "SuggestBox", ".", "SuggestionDisplay", ".", "isSuggestionListShowing", "()"], "add_tokens": "public boolean isSuggestionListShowing ( ) {", "del_tokens": "private boolean isSuggestionListShowing ( ) {", "commit_type": "fix"}
{"commit_tokens": ["moving", "things", "around", "in", "chatroom", "sample", "added", "some", "helpers", "in", "Iteratees", "and", "Websocket"], "add_tokens": "play . api . libs . iteratee . PushEnumerator < A > enumerator = play . core . j . JavaResults . chunked ( ) ; final play . api . libs . iteratee . PushEnumerator < A > enumerator ; public Out ( play . api . libs . iteratee . PushEnumerator < A > enumerator ) {", "del_tokens": "play . api . libs . iteratee . CallbackEnumerator < A > enumerator = play . core . j . JavaResults . chunked ( ) ; final play . api . libs . iteratee . CallbackEnumerator < A > enumerator ; public Out ( play . api . libs . iteratee . CallbackEnumerator < A > enumerator ) {", "commit_type": "move"}
{"commit_tokens": ["Added", "initial", "version", "of", "the", "jmx", "web", "server", "."], "add_tokens": "if ( mbeanServer == null ) { throw new JMException ( \"JmxServer has not be started\" ) ; } if ( mbeanServer == null ) { throw new JMException ( \"JmxServer has not be started\" ) ; } unregisterThrow ( ObjectNameUtil . makeObjectName ( obj ) ) ; if ( mbeanServer == null ) { throw new JMException ( \"JmxServer has not be started\" ) ; } registeredCount -- ;", "del_tokens": "ObjectName objectName = ObjectNameUtil . makeObjectName ( obj ) ; mbeanServer . unregisterMBean ( objectName ) ; registeredCount -- ;", "commit_type": "add"}
{"commit_tokens": ["Make", "EXTERNAL", "more", "usable", "handles", "now", "all", "aspects", "except", "Asn", "encoding", "which", "is", "out", "of", "its", "scope", "."], "add_tokens": "import java . util . BitSet ; / * ( non - Javadoc ) * @ see org . mobicents . protocols . asn . External # getEncodeBitStringType ( ) * / @ Override public BitSet getEncodeBitStringType ( ) throws AsnException { throw new UnsupportedOperationException ( ) ; } / * ( non - Javadoc ) * @ see org . mobicents . protocols . asn . External # getEncodeType ( ) * / public byte [ ] getEncodeType ( ) throws AsnException { / * ( non - Javadoc ) * @ see org . mobicents . protocols . asn . External # setEncodeBitStringType ( java . util . BitSet ) * / @ Override public void setEncodeBitStringType ( BitSet data ) { throw new UnsupportedOperationException ( ) ; } / * ( non - Javadoc ) * @ see org . mobicents . protocols . asn . External # setEncodeType ( byte [ ] ) * / @ Override public void setEncodeType ( byte [ ] data ) { throw new UnsupportedOperationException ( ) ; }", "del_tokens": "public byte [ ] encodeType ( ) throws AsnException {", "commit_type": "make"}
{"commit_tokens": ["Change", "visibility", "for", "unit", "tests"], "add_tokens": "* Used to connect class - and resource loading between different plugins . This * interface is only used internally and not meant to be implemented or used by * clients . public interface DependencyResolver extends Closeable {", "del_tokens": "* Used to connect class - and resource loading between different plugins . interface DependencyResolver extends Closeable {", "commit_type": "change"}
{"commit_tokens": ["added", "urls", "to", "prov", "-", "family"], "add_tokens": "} else if ( \"color\" . equals ( attribute . getLocalPart ( ) ) ) { } else if ( \"url\" . equals ( attribute . getLocalPart ( ) ) ) { properties . put ( \"URL\" , je . getValue ( ) . toString ( ) ) ;", "del_tokens": "break ; } if ( \"color\" . equals ( attribute . getLocalPart ( ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["moved", "map", "functions", "to", "MapUtils"], "add_tokens": "return URLUtils . percentEncode ( MapUtils . concatSortedPercentEncodedParams ( params ) ) ;", "del_tokens": "return URLUtils . percentEncode ( URLUtils . concatSortedPercentEncodedParams ( params ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "extractedZip", "variable", "include", "tempDir", ".", "Don", "t", "create", "log", "file", "as"], "add_tokens": "import javax . ws . rs . client . Invocation . Builder ; import javax . ws . rs . client . WebTarget ; private final String extractedZip = tempDir + \"/extractedZip\" ; File file = new File ( extractedZip ) ; WebTarget target = client . target ( url ) ; Builder builder = target . request ( ) ; Response response = builder . get ( ) ;", "del_tokens": "private final String extractedZip = \"/extractedZip\" ; String filePath = tempDir + extractedZip ; logFile . createNewFile ( ) ; File file = new File ( filePath ) ; Response response = client . target ( url ) . request ( ) . get ( ) ; File file = new File ( tempDir + \"/TestApp.zip\" ) ; System . out . println ( \"Creating zip file: \" + file . toString ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Making", "interface", "constants", "static", "final", "."], "add_tokens": "static final String STATUS_OK = \"OK\" ; static final String STATUS_ZERO_RESULTS = \"ZERO_RESULTS\" ; static final String STATUS_OVER_QUERY_LIMIT = \"OVER_QUERY_LIMIT\" ; static final String STATUS_REQUEST_DENIED = \"REQUEST_DENIED\" ; static final String STATUS_INVALID_REQUEST = \"INVALID_REQUEST\" ; static final String STATUS_UNKNOWN_ERROR = \"UNKNOWN_ERROR\" ; static final String STATUS_NOT_FOUND = \"NOT_FOUND\" ;", "del_tokens": "String STATUS_OK = \"OK\" ; String STATUS_ZERO_RESULTS = \"ZERO_RESULTS\" ; String STATUS_OVER_QUERY_LIMIT = \"OVER_QUERY_LIMIT\" ; String STATUS_REQUEST_DENIED = \"REQUEST_DENIED\" ; String STATUS_INVALID_REQUEST = \"INVALID_REQUEST\" ; String STATUS_UNKNOWN_ERROR = \"UNKNOWN_ERROR\" ; String STATUS_NOT_FOUND = \"NOT_FOUND\" ;", "commit_type": "make"}
{"commit_tokens": ["Use", "path", ".", "cubicTo", "instead", "of", "custom", "interpolation", "."], "add_tokens": "import android . view . MenuItem ; private LineChart chart ; chart = new LineChart ( this ) ; chart . setData ( data ) ; layout . addView ( chart ) ; @ Override public boolean onOptionsItemSelected ( MenuItem item ) { if ( item . getItemId ( ) == R . id . action_settings ) { chart . invalidate ( ) ; } return super . onOptionsItemSelected ( item ) ; }", "del_tokens": "LineChart lineChart = new LineChart ( this ) ; lineChart . setData ( data ) ; lineChart . setPadding ( 20 , 20 , 20 , 20 ) ; layout . addView ( lineChart ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "issue", "-", "problem", "was", "that", "the", "dynamic", "query", "builder", "was", "constructing", "the", "wrong", "kind", "of", "join"], "add_tokens": "import org . hibernate . sql . JoinType ; criteria . createAlias ( field , alias , JoinType . LEFT_OUTER_JOIN ) ; // We know we've joined to the parent so we must be able to join to one level deeper", "del_tokens": "criteria . createAlias ( field , alias ) ; // We know we've joined to the parent so we must be able to join to one level deeper", "commit_type": "fix"}
{"commit_tokens": ["use", "logger", "instead", "of", "system", ".", "err"], "add_tokens": "* YUICssCompressorProcessor . Use YUI css compression utility for processing a css resource . * public class YUICssCompressorProcessor implements ResourcePreProcessor , ResourcePostProcessor { public void process ( final String resourceUri , final Reader reader , final Writer writer ) throws IOException { throws IOException {", "del_tokens": "* YUICssCompressorProcessor . Use YUI css compression utility for processing a * css resource . * public class YUICssCompressorProcessor implements ResourcePreProcessor , ResourcePostProcessor { public void process ( final String resourceUri , final Reader reader , final Writer writer ) throws IOException { throws IOException {", "commit_type": "use"}
{"commit_tokens": ["Added", "the", "Rest", "api", "for", "managing", "NetworkServiceDescriptors"], "add_tokens": "new_nsd = nsdRepository . find ( nsd . getId ( ) ) ;", "del_tokens": "try { new_nsd = nsdRepository . find ( nsd . getId ( ) ) ; } catch ( ClassNotFoundException e ) { e . printStackTrace ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["implemented", "and", "tested", "basic", "Archive", "functionalities"], "add_tokens": "@ Override public boolean contains ( Task task ) throws IOException { return conf . getApiUrl ( currentWorkspace . getName ( ) , currentProject . getId ( ) , \"archive\" , \"tasks\" ) ;", "del_tokens": "@ Override public boolean contains ( Task task ) throws IOException { String url = getArchiveUrl ( ) ; return conf . getApiUrl ( currentWorkspace . getName ( ) , currentProject . getId ( ) , \"archive\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "testTypesAsSessionAttributes", ":", "ask", "kryo", "to", "deserialize", "the", "actual", "type", "not", "the", "declared", "type", "-", "this", "would", "fail", "for", "the", "calendar", "otherwise", "."], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) final T deserialized = ( T ) deserialize ( serialize ( instance ) , instance . getClass ( ) ) ;", "del_tokens": "final T deserialized = deserialize ( serialize ( instance ) , type ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "demo", "for", "icon", "round", "corner", "progress", "bar"], "add_tokens": "if ( isShown ( ) ) { disableAnimation ( ) ; setProgress ( 0 ) ; enableAnimation ( ) ; setProgress ( 100 ) ; }", "del_tokens": "disableAnimation ( ) ; setProgress ( 0 ) ; enableAnimation ( ) ; setProgress ( 100 ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "dictionary", "to", "the", "newest", "release", "available", "on", "sourceforge", "."], "add_tokens": "ArrayAssert . assertEquals ( new String [ ] { \"żywotopisarstwo\", subst:sg:loc:n\" , . s temAndForm( \" żywotopisarstwie\")) ; ArrayAssert . assertEquals ( new String [ ] { \"bazia\" , \"subst:pl:inst:f\" } , s . stemAndForm ( \"baziami\" ) ) ;", "del_tokens": "ArrayAssert . assertEquals ( new String [ ] { \"żywotopisarstwo\", -\" , . s temAndForm( \" żywotopisarstwie\")) ; ArrayAssert . assertEquals ( new String [ ] { \"abradować\", -\" , . s temAndForm( \" abradowałoby\")) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "bad", "conversion", "on", "events", "response", "body", "parsing", "when", "item", "attributes", "are", "JSON", "objects", "."], "add_tokens": "import com . fasterxml . jackson . databind . ser . impl . JsonSerializerMap ; import com . google . gson . Gson ; import org . json . JSONObject ; if ( value instanceof String ) { ret . put ( entry . getKey ( ) , new ItemAttribute ( ( String ) value ) ) ; } if ( value instanceof LinkedHashMap ) { ret . put ( entry . getKey ( ) , new ItemAttribute ( new Gson ( ) . toJson ( value ) ) ) ;", "del_tokens": "else { ret . put ( entry . getKey ( ) , new ItemAttribute ( value . toString ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["moved", "id", "generator", "providers", "in", "a", "proper", "package"], "add_tokens": "package org . slurry . quartz4guice . spi . idgenerator ;", "del_tokens": "package org . slurry . quartz4guice . spi ;", "commit_type": "move"}
{"commit_tokens": ["Fixing", "FileSystem", ".", "get", "()", "call", "to", "pass", "in", "URI"], "add_tokens": "final FileSystem fileSystem = FileSystem . get ( this . split . getPath ( ) . toUri ( ) , context . getConfiguration ( ) ) ;", "del_tokens": "final FileSystem fileSystem = FileSystem . get ( context . getConfiguration ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "defaultChild", "missing", "value", "strategy", "type"], "add_tokens": "CompoundPredicateResult result = evaluateCompoundPredicateInternal ( compoundPredicate , context ) ; return result . getResult ( ) ; } static CompoundPredicateResult evaluateCompoundPredicateInternal ( CompoundPredicate compoundPredicate , EvaluationContext context ) { return new CompoundPredicateResult ( result , false ) ; return new CompoundPredicateResult ( value , true ) ; return new CompoundPredicateResult ( result , false ) ; static class CompoundPredicateResult { private Boolean result = null ; private boolean alternative = false ; private CompoundPredicateResult ( Boolean result , boolean alternative ) { setResult ( result ) ; setAlternative ( alternative ) ; } public Boolean getResult ( ) { return this . result ; } private void setResult ( Boolean result ) { this . result = result ; } public boolean isAlternative ( ) { return this . alternative ; } private void setAlternative ( boolean alternative ) { this . alternative = alternative ; } }", "del_tokens": "return result ; return value ; return result ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "inconsistently", "named", "method", "in", "Code", "."], "add_tokens": "return code . createDifference ( getAnalysisContext ( ) . getLocale ( ) , params , attachments ) ;", "del_tokens": "return code . createProblem ( getAnalysisContext ( ) . getLocale ( ) , params , attachments ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "debug", "code", "for", "file", "permissions"], "add_tokens": "Set < PosixFilePermission > permissions = getPosixFilePermissions ( entry ) ; private static Set < PosixFilePermission > getPosixFilePermissions ( final TarArchiveEntry entry ) { int mode = entry . getMode ( ) ; if ( mode == 0 ) { if ( entry . isSymbolicLink ( ) ) { mode = DEFAULT_LINK_MODE ; } else if ( entry . isDirectory ( ) ) { mode = DEFAULT_DIRECTORY_MODE ; } else { mode = DEFAULT_FILE_MODE ; } } return getPosixFilePermissions ( mode ) ; } private static Set < PosixFilePermission > getPosixFilePermissions ( final ZipArchiveEntry entry ) { int mode = entry . getUnixMode ( ) ; if ( mode == 0 ) { if ( entry . isUnixSymlink ( ) ) { mode = DEFAULT_LINK_MODE ; } else if ( entry . isDirectory ( ) ) { mode = DEFAULT_DIRECTORY_MODE ; } else { mode = DEFAULT_FILE_MODE ; } } return getPosixFilePermissions ( mode ) ; } Set < PosixFilePermission > permissions = getPosixFilePermissions ( entry ) ; LOG . debug ( \"Unix mode of file=\" + file + \", mode=\" + mode ) ;", "del_tokens": "Set < PosixFilePermission > permissions = getPosixFilePermissions ( entry . getMode ( ) ) ; Set < PosixFilePermission > permissions = getPosixFilePermissions ( entry . getUnixMode ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Makes", "the", "Status", "-", "generated", "exceptions", "contain", "the", "status", "code", "."], "add_tokens": "super ( status . getCode ( ) + \": \" + status . getDescription ( ) , status . getCause ( ) ) ; super ( status . getCode ( ) + \": \" + status . getDescription ( ) , status . getCause ( ) ) ;", "del_tokens": "super ( status . getDescription ( ) , status . getCause ( ) ) ; super ( status . getDescription ( ) , status . getCause ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "issue", "with", "@fullUrl", "()", "allow", "load", "error", "pages", "without", "regarding", "app", "view", "root", "configuration"], "add_tokens": "import org . springframework . context . ApplicationContext ; if ( ! resourceLoaderPath . contains ( \"/WEB-INF/rythm\" ) ) { // where the default error page template is located resourceLoaderPath += \",/WEB-INF/rythm\" ; } this . resourceLoaderPath = resourceLoaderPath ; // the i18 message resolver ApplicationContext ctx = getApplicationContext ( ) ; if ( null != ctx ) { SpringI18nMessageResolver i18n = new SpringI18nMessageResolver ( ) ; i18n . setApplicationContext ( getApplicationContext ( ) ) ; p . put ( RythmConfigurationKey . I18N_MESSAGE_RESOLVER . getKey ( ) , i18n ) ; }", "del_tokens": "this . resourceLoaderPath = resourceLoaderPath ; // the i18 message resolver SpringI18nMessageResolver i18n = new SpringI18nMessageResolver ( ) ; i18n . setApplicationContext ( getApplicationContext ( ) ) ; p . put ( RythmConfigurationKey . I18N_MESSAGE_RESOLVER . getKey ( ) , i18n ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "|", "instead", "of", ";", "as", "feature", "string", "delimiter", "to", "save", "space", "in", "request"], "add_tokens": "for ( String s : has . split ( \"[;|]\" ) ) { //$NON-NLS-1$", "del_tokens": "for ( String s : has . split ( \";\" ) ) { //$NON-NLS-1$", "commit_type": "use"}
{"commit_tokens": ["Added", "IXMLBracketModeDeterminator", "and", "some", "implementations"], "add_tokens": "public void onDocumentStart ( @ Nullable final EXMLVersion eXMLVersion , if ( eXMLVersion != null && m_eXMLVersion . isXML ( ) ) { // Maybe switch from 1.0 to 1.1 or vice versa m_eXMLVersion = EXMLSerializeVersion . getFromXMLVersionOrThrow ( eXMLVersion ) ; } if ( StringHelper . hasText ( sEncoding ) )", "del_tokens": "public void onDocumentStart ( @ Nullable final EXMLVersion eVersion , if ( eVersion != null && m_eXMLVersion . isXML ( ) ) m_eXMLVersion = EXMLSerializeVersion . getFromXMLVersionOrThrow ( eVersion ) ; if ( sEncoding != null )", "commit_type": "add"}
{"commit_tokens": ["adding", "logging", "reader", "and", "APIs"], "add_tokens": "import io . soabase . core . features . logging . LoggingReader ; private final LoggingReader loggingReader ; this ( null , null , null , null ) ; SoaFeaturesImpl ( SoaDiscovery discovery , SoaDynamicAttributes dynamicAttributes , SoaInfo info , LoggingReader loggingReader ) this . loggingReader = loggingReader ; @ Override public LoggingReader getLoggingReader ( ) { return loggingReader ; }", "del_tokens": "this ( null , null , null ) ; SoaFeaturesImpl ( SoaDiscovery discovery , SoaDynamicAttributes dynamicAttributes , SoaInfo info )", "commit_type": "add"}
{"commit_tokens": ["Made", "copy", "always", "behavior", "configurable", "via", "command", "line", "option", "off", "by", "default"], "add_tokens": "private final boolean copyAlways ; public BuilderGeneratorSettings ( final boolean generatingPartialCopy , final boolean generatingNarrowCopy , final String newBuilderMethodName , final String newCopyBuilderMethodName , final String builderFieldSuffix , final ClassName builderClassName , final String copyToMethodName , final boolean copyAlways ) { this . copyAlways = copyAlways ; public boolean isCopyAlways ( ) { return this . copyAlways ; }", "del_tokens": "public BuilderGeneratorSettings ( final boolean generatingPartialCopy , final boolean generatingNarrowCopy , final String newBuilderMethodName , final String newCopyBuilderMethodName , final String builderFieldSuffix , final ClassName builderClassName , final String copyToMethodName ) {", "commit_type": "make"}
{"commit_tokens": ["Use", "accessor", "method", "instead", "of", "direct", "access", "."], "add_tokens": "if ( isSupportedByWebDriver ( methodName ) ) {", "del_tokens": "if ( WEB_DRIVER_COMMANDS . contains ( methodName ) ) {", "commit_type": "use"}
{"commit_tokens": ["Add", "helper", "to", "set", "response", "code", "to", "AtomicInteger"], "add_tokens": "import java . util . concurrent . atomic . AtomicInteger ; * @ return the response code / * * * Set the value of the given { @ link AtomicInteger } to the status code of * the response * * @ param output * @ return this request * @ throws HttpRequestException * / public HttpRequest code ( AtomicInteger output ) throws HttpRequestException { output . set ( code ( ) ) ; return this ; }", "del_tokens": "* @ return this request", "commit_type": "add"}
{"commit_tokens": ["add", "null", "check", "at", "CreateWebhookParams", "UpdateWebhookParams"], "add_tokens": "String nameValue = ( name == null ) ? \"\" : name ; String hookUrlValue = ( hookUrl == null ) ? \"\" : hookUrl ; parameters . add ( new NameValuePair ( \"name\" , nameValue ) ) ; parameters . add ( new NameValuePair ( \"hookUrl\" , hookUrlValue ) ) ; String nameValue = ( name == null ) ? \"\" : name ; String hookUrlValue = ( hookUrl == null ) ? \"\" : hookUrl ; parameters . add ( new NameValuePair ( \"name\" , nameValue ) ) ; parameters . add ( new NameValuePair ( \"hookUrl\" , hookUrlValue ) ) ; String value = ( description == null ) ? \"\" : description ; parameters . add ( new NameValuePair ( \"description\" , value ) ) ; if ( activityTypeIds != null ) {", "del_tokens": "parameters . add ( new NameValuePair ( \"name\" , name ) ) ; parameters . add ( new NameValuePair ( \"hookUrl\" , hookUrl ) ) ; parameters . add ( new NameValuePair ( \"name\" , name ) ) ; parameters . add ( new NameValuePair ( \"hookUrl\" , hookUrl ) ) ; parameters . add ( new NameValuePair ( \"description\" , description ) ) ; if ( activityTypeIds == null ) { parameters . add ( new NameValuePair ( \"activityTypeIds[]\" , \"\" ) ) ; } else {", "commit_type": "add"}
{"commit_tokens": ["added", "same", "ISO", "timestamp", "change", "to", "FileOVerwriterOutputWriter"], "add_tokens": "import java . text . SimpleDateFormat ; private static DateFormat dfISO8601 = new SimpleDateFormat ( \"yyyy-MM-dd'T'HH:mm'Z'\" ) ; dfISO8601 . setTimeZone ( TimeZone . getTimeZone ( \"GMT\" ) ) ; public synchronized void writeQueryResult ( @ Nonnull String name , @ Nullable String type , @ Nullable Object value ) throws IOException { getTemporaryFileWriter ( ) . write ( \"[\" + dfISO8601 . format ( Calendar . getInstance ( ) . getTime ( ) ) + \"] \" + name + \" \" + value + \"\\n\" ) ;", "del_tokens": "DateFormat df = DateFormat . getDateTimeInstance ( ) ; df . setTimeZone ( TimeZone . getTimeZone ( \"GMT\" ) ) ; public void writeQueryResult ( @ Nonnull String name , @ Nullable String type , @ Nullable Object value ) throws IOException { getTemporaryFileWriter ( ) . write ( \"[\" + df . format ( Calendar . getInstance ( ) . getTime ( ) ) + \"] \" + name + \" \" + value + \"\\n\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "map", "creation", "bug", "in", "cmap", "decoder"], "add_tokens": "void setBuilders ( MapBuilder mapBuilder , ListBuilder listBuilder ) ;", "del_tokens": "void setMapBuilder ( MapBuilder mapBuilder ) ; void setListBuilder ( ListBuilder listBuilder ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "concurrent", "map", "in", "classifier"], "add_tokens": "import java . util . concurrent . ConcurrentHashMap ; import java . util . concurrent . ConcurrentMap ; private ConcurrentMap < Class < ? extends T > , C > classified = new ConcurrentHashMap < Class < ? extends T > , C > ( ) ; this . classified = new ConcurrentHashMap < Class < ? extends T > , C > ( typeMap ) ; this . classified = new ConcurrentHashMap < Class < ? extends T > , C > ( map ) ;", "del_tokens": "private Map < Class < ? extends T > , C > classified = new HashMap < Class < ? extends T > , C > ( ) ; this . classified = new HashMap < Class < ? extends T > , C > ( typeMap ) ; this . classified = new HashMap < Class < ? extends T > , C > ( map ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "abstraction", "boundary", "around", "HTTP", "connections"], "add_tokens": "public class KeenUtils { public static void closeQuietly ( Closeable c ) { public static String convertFileToString ( java . io . File file ) throws IOException { public static String convertStreamToString ( java . io . InputStream is ) { public static String getStackTraceFromThrowable ( Throwable t ) { public static byte [ ] hexStringToByteArray ( String s ) { public static String byteArrayToHexString ( byte [ ] bytes ) {", "del_tokens": "class KeenUtils { static void closeQuietly ( Closeable c ) { static String convertFileToString ( java . io . File file ) throws IOException { static String convertStreamToString ( java . io . InputStream is ) { static String getStackTraceFromThrowable ( Throwable t ) { static byte [ ] hexStringToByteArray ( String s ) { static String byteArrayToHexString ( byte [ ] bytes ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "experiment", "with", "jnr", "-", "unixsocket", "."], "add_tokens": "import org . apache . http . conn . ClientConnectionManager ; // HttpClient httpClient = new DefaultHttpClient(cm); // client = new ApacheHttpClient4(new ApacheHttpClient4Handler(httpClient, null, false), clientConfig); client = new UnixSocketClient ( ) ;", "del_tokens": "HttpClient httpClient = new DefaultHttpClient ( cm ) ; client = new ApacheHttpClient4 ( new ApacheHttpClient4Handler ( httpClient , null , false ) , clientConfig ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "to", "manually", "schedule", "a", "job", "through", "LocalJobScheduler"], "add_tokens": "public boolean publishData ( State state ) throws IOException { Path stagingDataDir = new Path ( state . getProp ( ConfigurationKeys . OUTPUT_DIR_KEY ) ) ; Path outputDataDir = new Path ( state . getProp ( ConfigurationKeys . JOB_FINAL_DIR_HDFS ) ) ;", "del_tokens": "public boolean publishData ( State state ) throws IOException { WorkUnitState task = ( WorkUnitState ) state ; Path stagingDataDir = new Path ( task . getProp ( ConfigurationKeys . OUTPUT_DIR_KEY ) ) ; Path outputDataDir = new Path ( task . getProp ( ConfigurationKeys . JOB_FINAL_DIR_HDFS ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "Java5", "/", "6", "issues", "again"], "add_tokens": "Grammars grs = grammarFactory . createGrammars ( new ByteArrayInputStream ( schema . getBytes ( ) ) ) ; // StandardCharsets.UTF_8 not Java5/6 Grammars grs = grammarFactory . createGrammars ( new ByteArrayInputStream ( schema . getBytes ( ) ) ) ; // StandardCharsets.UTF_8 not Java5/6", "del_tokens": "import java . nio . charset . StandardCharsets ; Grammars grs = grammarFactory . createGrammars ( new ByteArrayInputStream ( schema . getBytes ( StandardCharsets . UTF_8 ) ) ) ; Grammars grs = grammarFactory . createGrammars ( new ByteArrayInputStream ( schema . getBytes ( ) ) ) ; // StandardCharsets.UTF_8 not JAVa5/6", "commit_type": "fix"}
{"commit_tokens": ["Fix", "illegal", "constructing", "filter", "."], "add_tokens": "String filterStr = \"(&(\" + Constants . OBJECTCLASS + \"=\" + IClassResolver . class . getName ( ) + \")(\" String message = Content . APPLICATION_NAME + \"[\" + applicationName + \"] has an invalid format. \" ; throw new IllegalArgumentException ( message ) ;", "del_tokens": "String filterStr = \"&((\" + Constants . OBJECTCLASS + \"=\" + IClassResolver . class . getName ( ) + \")(\" throw new IllegalArgumentException ( Content . APPLICATION_NAME + \" has an invalid format.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "ReflectionUtils", ".", "findSetter", "()", "to", "allow", "setters", "with", "compatible", "parameter", "types", "to", "be", "used", "."], "add_tokens": "private boolean sailForTreasure ; private Number overloaded ; public boolean getSailForTreasure ( ) { return sailForTreasure ; } public void setSailForTreasure ( boolean sailForTreasure ) { this . sailForTreasure = sailForTreasure ; } public void setSailForTreasure ( ) { throw new RuntimeException ( \"this method isn't a setter and should never be invoked\" ) ; } public Number getOverloaded ( ) { return overloaded ; } public void setOverloaded ( Integer overloaded ) { throw new RuntimeException ( \"this overloaded setter shouldn't be invoked!\" ) ; } public void setOverloaded ( Number overloaded ) { this . overloaded = overloaded ; }", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Added", "comments", ".", "First", "of", "many", "commits", "attempting", "to", "document", "project", "."], "add_tokens": "guildObj . setRegion ( Region . fromKey ( guild . getString ( \"region\" ) ) ) ;", "del_tokens": "guildObj . setRegion ( Region . getRegion ( guild . getString ( \"region\" ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "elementsInFrames", "()", "for", "search", "in", "all", "frames"], "add_tokens": "List < WebElement > visibleElements = getVisibleWebElements ( framesTransparentWebDriver . findElementsInFrames ( locator ) ) ; return getVisibleWebElements ( driver . findElements ( locator ) ) ; return getVisibleWebElements ( searchContext . findElements ( locator ) ) ; private static List < WebElement > getVisibleWebElements ( List < WebElement > elements ) { List < WebElement > visibleElements = elements . stream ( ) . filter ( WebElement :: isDisplayed ) . collect ( Collectors . toList ( ) ) ;", "del_tokens": "import java . util . ArrayList ; List < WebElement > visibleElements = getVisibleWebElements ( framesTransparentWebDriver , locator ) ; return getVisibleWebElements ( driver , locator ) ; return getVisibleWebElements ( searchContext , locator ) ; private static List < WebElement > getVisibleWebElements ( SearchContext context , By locator ) { List < WebElement > visibleElements = context . findElements ( locator ) . stream ( ) . filter ( WebElement :: isDisplayed ) . collect ( Collectors . toList ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "RubyEnumerble", "::", "eachCons"], "add_tokens": "for ( RubyArray < E > cons : eachCons ( n ) ) { block . yield ( cons ) ; public RubyEnumerator < E > eachEntry ( ) { return new RubyEnumerator < E > ( iter ) ; }", "del_tokens": "RubyArray < E > list = newRubyArray ( iter ) ; for ( int i = 0 ; i < list . size ( ) ; i ++ ) { if ( i + n <= list . size ( ) ) { RubyArray < E > cons = newRubyArray ( ) ; for ( int j = i ; j < i + n ; j ++ ) { cons . add ( list . get ( j ) ) ; } block . yield ( cons ) ; } public RubyEnumerator < E > eachEntry ( ) { return new RubyEnumerator < E > ( iter ) ; }", "commit_type": "add"}
{"commit_tokens": ["Moving", "the", "logger", "inside", "the", "if", "block"], "add_tokens": "Log . v ( TAG , \"Found legacy ID: '\" + registrationId + \"'\" ) ;", "del_tokens": "Log . v ( TAG , \"Found legacy ID \" + registrationId ) ;", "commit_type": "move"}
{"commit_tokens": ["implemented", "remote", "storage", "w", "/", "distributeme"], "add_tokens": "import net . anotheria . anoprise . metafactory . Service ; import org . distributeme . annotation . DistributeMe ; @ DistributeMe ( initcode = { \"MetaFactory.addFactoryClass(net.java.dev.moskito.central.StatStorage.class, Extension.LOCAL, net.java.dev.moskito.central.storages.RemoteStorageFactory.class);\" } ) public interface StatStorage extends Service {", "del_tokens": "public interface StatStorage {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "the", "deprecated", "doc", "link"], "add_tokens": "* @ deprecated Replaced by { @ link # setUser ( String , String , String ) } }", "del_tokens": "* @ deprecated Replaced by { @ link # setUser ( ) }", "commit_type": "fix"}
{"commit_tokens": ["Use", "ThreadLocal", "to", "avoid", "concurrency", "issues"], "add_tokens": "private static ThreadLocal < RiderDSL > INSTANCE ; private static synchronized void createInstance ( ) { INSTANCE = new ThreadLocal < > ( ) ; INSTANCE . set ( new RiderDSL ( ) ) ; INSTANCE . get ( ) . connection = connection ; return withConnection ( INSTANCE . get ( ) . connection ) ; INSTANCE . get ( ) . dataSetConfig = dataSetConfig ; return withDataSet ( INSTANCE . get ( ) . dataSetConfig ) ; RiderDSL riderDSL = INSTANCE . get ( ) ; riderDSL . dbUnitConfig = dbUnitConfig ; return riderDSL ; INSTANCE . get ( ) . createDataSet ( ) ;", "del_tokens": "private static RiderDSL INSTANCE ; private static void createInstance ( ) { INSTANCE = new RiderDSL ( ) ; INSTANCE . connection = connection ; return withConnection ( INSTANCE . connection ) ; INSTANCE . dataSetConfig = dataSetConfig ; return withDataSet ( INSTANCE . dataSetConfig ) ; INSTANCE . dbUnitConfig = dbUnitConfig ; return INSTANCE ; INSTANCE . createDataSet ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "node", "id", "offset", "field", "to", "dynamic", "flake", "id", "configuration"], "add_tokens": "void addFlakeIdGeneratorConfig ( String name , int prefetchCount , long prefetchValidity , long idOffset , boolean statisticsEnabled , long nodeIdOffset ) ;", "del_tokens": "void addFlakeIdGeneratorConfig ( String name , int prefetchCount , long prefetchValidity , long idOffset , boolean statisticsEnabled ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "encryptedOptions", "field", "to", "ExportConfiguration"], "add_tokens": "fillExportConfigurationTransformations ( name , conf ) ; fillExportConfigurationOptions ( name , conf ) ; fillExportConfigurationEncryptedOptions ( name , conf ) ; return conf ; } private void fillExportConfigurationTransformations ( String name , ExportConfiguration conf ) { } private void fillExportConfigurationOptions ( String name , ExportConfiguration conf ) { } private void fillExportConfigurationEncryptedOptions ( String name , ExportConfiguration conf ) { String rawConfigEncryptedOptionNames = configuration . get ( resolveTemplatedKey ( EXPORT_CONFIG_ENCRYPTED_OPTIONS_TEMPLATE_NAME , name ) ) ; if ( rawConfigEncryptedOptionNames != null && ! rawConfigEncryptedOptionNames . isEmpty ( ) ) { String [ ] configEncryptedOptionNames = rawConfigEncryptedOptionNames . split ( \",\" ) ; for ( String configEncryptedOptionName : configEncryptedOptionNames ) { conf . addEncryptedOption ( configEncryptedOptionName , configuration . get ( resolveTemplatedKey ( EXPORT_CONFIG_ENCRYPTED_OPTIONS_TEMPLATE_VALUE_TEMPLATE , name , configEncryptedOptionName ) ) ) ; } }", "del_tokens": "return conf ;", "commit_type": "add"}
{"commit_tokens": ["added", "multiple", "rec", "runner", "so", "far", "only", "mahout", "works"], "add_tokens": "public class RecommendationRunner { public static final String framework = \"framework\" ; recommend ( properties ) ; } public static void recommend ( Properties properties ) { return ; return ; return ; long time = System . currentTimeMillis ( ) ; rr . run ( ) ; rr . run ( ) ; time = System . currentTimeMillis ( ) - time ;", "del_tokens": "public class Recommend { public static final String framework = \"framework\" ; System . exit ( 0 ) ; System . exit ( 0 ) ; System . exit ( 0 ) ; rr . runRecommender ( ) ; rr . runRecommender ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "fix", "for", "Java", "8", "-", "media", "queries", "are", "now", "output", "in", "the", "same", "order", "as", "they", "are", "defined"], "add_tokens": "private Map < String , Section > mediaQueries = new LinkedHashMap < String , Section > ( ) ;", "del_tokens": "private Map < String , Section > mediaQueries = new HashMap < String , Section > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "StorIOSQLiteDb", "DefaultPutResolver", "id", "as", "Object"], "add_tokens": "@ NonNull String idFieldName , @ NonNull String id ) { . whereArgs ( id )", "del_tokens": "@ NonNull final String idFieldName , @ NonNull Object id ) { . whereArgs ( String . valueOf ( id ) )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "causing", "NPE", "when", "the", "library", "is", "called", "with", "null", "context", "class", "loader"], "add_tokens": "if ( ldr != null && ( is = ldr . getResourceAsStream ( resource ) ) != null ) {", "del_tokens": "if ( ( is = ldr . getResourceAsStream ( resource ) ) != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "users", "even", "if", "they", "didn", "t", "have", "a", "private", "channel", "."], "add_tokens": "if ( ! api . getGuildMap ( ) . values ( ) . stream ( ) . anyMatch ( g -> ( ( GuildImpl ) g ) . getUserRoles ( ) . containsKey ( user ) ) ) if ( user . hasPrivateChannel ( ) ) api . getUserMap ( ) . remove ( user . getId ( ) ) ;", "del_tokens": "if ( user . hasPrivateChannel ( ) ) boolean exists = api . getGuildMap ( ) . values ( ) . stream ( ) . anyMatch ( g -> ( ( ( GuildImpl ) g ) . getUserRoles ( ) . containsKey ( user ) ) ) ; if ( ! exists ) api . getUserMap ( ) . remove ( user . getId ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["make", "switching", "between", "scaling", "strategies", "config", "based"], "add_tokens": "ScalingStrategy strategy ; if ( config . getStrategyImpl ( ) . equalsIgnoreCase ( \"ec2\" ) ) { strategy = new EC2AutoScalingStrategy ( new AmazonEC2Client ( new BasicAWSCredentials ( props . getProperty ( \"com.metamx.aws.accessKey\" ) , props . getProperty ( \"com.metamx.aws.secretKey\" ) ) ) , configFactory . build ( EC2AutoScalingStrategyConfig . class ) ) ; } else if ( config . getStorageImpl ( ) . equalsIgnoreCase ( \"noop\" ) ) { strategy = new NoopScalingStrategy ( ) ; } else { throw new IllegalStateException ( String . format ( \"Invalid strategy implementation: %s\" , config . getStrategyImpl ( ) ) ) ; }", "del_tokens": "ScalingStrategy strategy = new EC2AutoScalingStrategy ( new AmazonEC2Client ( new BasicAWSCredentials ( props . getProperty ( \"com.metamx.aws.accessKey\" ) , props . getProperty ( \"com.metamx.aws.secretKey\" ) ) ) , configFactory . build ( EC2AutoScalingStrategyConfig . class ) ) ; // TODO: use real strategy before actual deployment strategy = new NoopScalingStrategy ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "nano", "time", "for", "timeout"], "add_tokens": "public final long nanosAbsoluteTimeout ; this . nanosAbsoluteTimeout = 0 ; this . nanosAbsoluteTimeout = TimeUnit . NANOSECONDS . convert ( millisRelativeTimeout , TimeUnit . MILLISECONDS ) + System . nanoTime ( ) ; return unit . convert ( nanosAbsoluteTimeout - System . nanoTime ( ) , TimeUnit . NANOSECONDS ) ; return Long . compare ( nanosAbsoluteTimeout , ( ( ResilientTask ) o ) . nanosAbsoluteTimeout ) ; return Long . compare ( getDelay ( TimeUnit . NANOSECONDS ) , o . getDelay ( TimeUnit . NANOSECONDS ) ) ;", "del_tokens": "public final long millisAbsoluteTimeout ; this . millisAbsoluteTimeout = 0 ; this . millisAbsoluteTimeout = millisRelativeTimeout + System . currentTimeMillis ( ) ; return unit . convert ( millisAbsoluteTimeout - System . currentTimeMillis ( ) , TimeUnit . MILLISECONDS ) ; return Long . compare ( millisAbsoluteTimeout , ( ( ResilientTask ) o ) . millisAbsoluteTimeout ) ; return Long . compare ( getDelay ( TimeUnit . MILLISECONDS ) , o . getDelay ( TimeUnit . MILLISECONDS ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "criterion", "to", "compute", "total", "count"], "add_tokens": "* * * addCriterionsToCriteria ( criteria , criterion ) ; * addCriterionsToCriteria ( criteria , criterion ) ; return new PagingResult < E > ( criteria . list ( ) , getTotalCount ( criterion ) ) ; * @ param criterion * private Number getTotalCount ( Criterion ... criterion ) { addCriterionsToCriteria ( criteria , criterion ) ; / * * * * @ param criteria * @ param criterion * / private void addCriterionsToCriteria ( Criteria criteria , Criterion ... criterion ) { for ( Criterion c : criterion ) { if ( c != null ) { criteria . add ( c ) ; } } }", "del_tokens": "* * * for ( Criterion c : criterion ) { if ( c != null ) { criteria . add ( c ) ; } } * for ( Criterion c : criterion ) { if ( c != null ) { criteria . add ( c ) ; } } return new PagingResult < E > ( criteria . list ( ) , getTotalCount ( ) ) ; * private Number getTotalCount ( ) {", "commit_type": "use"}
{"commit_tokens": ["use", "schedulers", "in", "nonblockingpool", "for", "emitting", "items", "(", "connections", ")"], "add_tokens": "} else if ( s . name == INITIALIZED_IN_USE || s . name == DISPOSING ) { RxJavaPlugins . onError ( t ) ; new State ( DISPOSING , DisposableHelper . DISPOSED , s . enabled ) ) ) { RxJavaPlugins . onError ( t ) ; state . set ( new State ( NOT_INITIALIZED_NOT_IN_USE , DisposableHelper . DISPOSED , s . enabled ) ) ; //TODO is close needed (not covered)?", "del_tokens": "} else if ( s . name == INITIALIZED_IN_USE ) { log . debug ( \"checking out member in use={}\" , this ) ; log . debug ( \"already in use, member={}\" , this ) ; return Maybe . empty ( ) ; } } else if ( s . name == DISPOSING ) { log . debug ( \"checking out member disposed={}\" , this ) ; if ( state . compareAndSet ( s , s . copy ( ) ) ) { log . debug ( \"disposing, member={}\" , this ) ; // ignore new State ( NOT_INITIALIZED_NOT_IN_USE , DisposableHelper . DISPOSED , s . enabled ) ) ) { // TODO race condition with checkout? // ignore", "commit_type": "use"}
{"commit_tokens": ["change", "core", "examples", "to", "use", "SparkSession"], "add_tokens": "\"{\\\"0\\\":12,\\\"1\\\":\\\"I\\\",\\\"length\\\":2},{\\\"0\\\":12,\\\"1\\\":\\\"from\\\",\\\"length\\\":2},\" +", "del_tokens": "\"{\\\"0\\\":12,\\\"1\\\":\\\"from\\\",\\\"length\\\":2},{\\\"0\\\":12,\\\"1\\\":\\\"I\\\",\\\"length\\\":2},\" +", "commit_type": "change"}
{"commit_tokens": ["added", "save", "in", "transaction", "with", "list", "parameter"], "add_tokens": "public static < T extends SugarRecord > void saveInTx ( T ... objects ) { Log . i ( \"Sugar\" , \"Error in saving in transaction \" + e . getMessage ( ) ) ; } public static < T extends SugarRecord > void saveInTx ( Collection < T > objects ) { SQLiteDatabase sqLiteDatabase = getSugarContext ( ) . database . getDB ( ) ; try { sqLiteDatabase . beginTransaction ( ) ; sqLiteDatabase . setLockingEnabled ( false ) ; for ( T object : objects ) { object . save ( sqLiteDatabase ) ; } sqLiteDatabase . setTransactionSuccessful ( ) ; } catch ( Exception e ) { Log . i ( \"Sugar\" , \"Error in saving in transaction \" + e . getMessage ( ) ) ; } finally { sqLiteDatabase . endTransaction ( ) ; sqLiteDatabase . setLockingEnabled ( true ) ; }", "del_tokens": "public static < T extends SugarRecord > void saveInTx ( Class < T > type , T ... objects ) { long start = System . currentTimeMillis ( ) ; long end = System . currentTimeMillis ( ) ; Log . i ( \"Sugar\" , \"Time taken : \" + ( end - start ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "problem", "with", "wrong", "ipa", "pointer", "files"], "add_tokens": "public class PreDeployMojo extends DeployMojo final TransferListener transferListener = getTransferListener ( ) ; final TransferListener prepareIpaPointerFileTransferListener = new PrepareIpaPointerFileTransferListener ( \"TransferListener '\" + prepareIpaPointerFileTransferListener . getClass ( ) . getName ( ) + \"' has been set. The previously used transfere listener was: '\" + transferListener + \"'.\" ) ; TransferListener getForward ( ) { return this . forward ; }", "del_tokens": "import org . sonatype . aether . RepositorySystemSession ; public class PreDeployMojo extends AbstractXCodeMojo / * * * The current repository / network configuration of Maven . * * @ parameter default - value = \"${repositorySystemSession}\" * @ readonly * / protected RepositorySystemSession repoSession ; final TransferListener transferListener = ( TransferListener ) this . repoSession . getClass ( ) . getMethod ( \"getTransferListener\" , new Class [ 0 ] ) . invoke ( this . repoSession , new Object [ 0 ] ) ; TransferListener prepareIpaPointerFileTransferListener = new PrepareIpaPointerFileTransferListener ( \"TransferListener '\" + prepareIpaPointerFileTransferListener . getClass ( ) . getName ( ) + \"' has been set.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "or", "/", "just", "/", "generate", "marbles"], "add_tokens": "* < img width = \"500\" src = \"https://raw.githubusercontent.com/reactor/projectreactor.io/master/src/main/static/assets/img/marble/flatmaps1.png\" alt = \"\" > * @ param mapperOnNext the { @ link Function } to call on next data and returning a sequence to merge * @ param mapperOnError the { @ link Function } to call on error signal and returning a sequence to merge * @ param mapperOnComplete the { @ link Function } to call on complete signal and returning a sequence to merge * @ param < R > the type of the produced merged sequence * < img width = \"500\" src = \"https://raw.githubusercontent.com/reactor/projectreactor.io/master/src/main/static/assets/img/marble/or.png\" alt = \"\" >", "del_tokens": "* < img width = \"500\" src = \"https://raw.githubusercontent.com/reactor/projectreactor.io/master/src/main/static/assets/img/marble/flatmap1.png\" alt = \"\" > * @ param mapperOnNext * @ param mapperOnError * @ param mapperOnComplete * @ param < R > * < img width = \"500\" src = \"https://raw.githubusercontent.com/reactor/projectreactor.io/master/src/main/static/assets/img/marble/any.png\" alt = \"\" >", "commit_type": "add"}
{"commit_tokens": ["fix", "none", "unicode", "content", "type", "parsing", "and", "test"], "add_tokens": "String charset = ParallecGlobalConfig . httpResponseBodyCharsetUsesResponseContentType && response . getContentType ( ) != null ? if ( charset == null ) { getLogger ( ) . error ( \"charset is not provided from response content type. Use default\" ) ; charset = ParallecGlobalConfig . httpResponseBodyDefaultCharset ; }", "del_tokens": "String charset = ParallecGlobalConfig . httpResponseBodyCharsetUsesResponseContentType ?", "commit_type": "fix"}
{"commit_tokens": ["Changed", "goal", "name", "to", "validate"], "add_tokens": "* @ goal validate", "del_tokens": "* @ goal convert", "commit_type": "change"}
{"commit_tokens": ["Added", "comment", "to", "performance", "test", "."], "add_tokens": "* A semi - useless microbenchmark . Spring and Guice constuct the same object * graph a bunch of times , and we see who can construct the most per second . * As of this writing Guice is more than 50 X faster . Also useful for comparing * pure Java configuration options .", "del_tokens": "* Performance test .", "commit_type": "add"}
{"commit_tokens": ["Added", "class", "AbstractInflater", ";", "added", "class", "ViewBinderInflater", "."], "add_tokens": "mAdapter . setBinder ( getResources ( ) , R . xml . vb_example_two ) ;", "del_tokens": "import android . ext . adapter . CompositeViewBinder ; CompositeViewBinder < ExampleData , View > binder = new CompositeViewBinder < ExampleData , View > ( ) ; binder . add ( android . R . id . text1 , ExampleTitleBinder . getInstance ( ) ) ; binder . add ( android . R . id . progress , ExampleRatingBinder . getInstance ( ) ) ; mAdapter . setBinder ( binder ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "getCouchConfig", "()", "public", "on", "{", "Push", "Pull", "}", "Replication"], "add_tokens": "public CouchConfig getCouchConfig ( ) {", "del_tokens": "CouchConfig getCouchConfig ( ) {", "commit_type": "make"}
{"commit_tokens": ["improved", "VARIANT", "and", "SAFEARRAY", "support"], "add_tokens": "if ( obj instanceof Wrapper ) return ( Wrapper ) obj ; else return ( Wrapper ) Proxy . getInvocationHandler ( obj ) ; } // called by the native side to get the raw pointer value of Com4jObject. static int getPtr ( Com4jObject obj ) { if ( obj == null ) return 0 ; return unwrap ( obj ) . getPtr ( ) ;", "del_tokens": "return ( Wrapper ) Proxy . getInvocationHandler ( obj ) ;", "commit_type": "improve"}
{"commit_tokens": ["fix", "typo", "in", "discover", "of", "server", "port"], "add_tokens": "public static final String SERVER_PORT = \"server.port\" ;", "del_tokens": "public static final String SERVER_PORT = \"server.port.\" ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "@NotEmpty", "over", "@NotNull", "for", "Strings", "."], "add_tokens": "import org . hibernate . validator . constraints . NotEmpty ; @ NotEmpty @ NotEmpty", "del_tokens": "import javax . validation . constraints . NotNull ; @ NotNull @ NotNull", "commit_type": "use"}
{"commit_tokens": ["Updated", "ffmpeg", "locator", "to", "do", "some", "more", "checks", "if", "it", "s", "the", "current", "executable"], "add_tokens": "public void testFindExecutable ( ) {", "del_tokens": "public void testSomeMethod ( ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "an", "image", "(", "from", "https", ":", "//", "webkit", ".", "org", "/", "blog", "-", "files", "/", "color", "-", "gamut", "/", ")", "with", "ICC", "Profile", "to", "test", "writing", "profiled", "images", ".", "But", "for", "some", "reason", "the", "image", "is", "not", "loaded", "with", "the", "profile", "..."], "add_tokens": "import org . apache . pdfbox . pdmodel . graphics . color . PDICCBased ; import java . awt . color . ICC_ColorSpace ; import java . awt . color . ICC_Profile ; import java . io . OutputStream ; PDImageXObject imageXObject = LosslessFactory . createFromImage ( document , bi ) ; / * * Do we have a color profile we need to embed ? * / if ( bi . getColorModel ( ) . getColorSpace ( ) instanceof ICC_ColorSpace ) { ICC_Profile profile = ( ( ICC_ColorSpace ) bi . getColorModel ( ) . getColorSpace ( ) ) . getProfile ( ) ; / * * Only tag a profile if it is not the default sRGB profile . * / if ( bi . getColorModel ( ) . getColorSpace ( ) != ICC_ColorSpace . getInstance ( ICC_ColorSpace . CS_sRGB ) ) { PDICCBased pdProfile = new PDICCBased ( document ) ; OutputStream outputStream = pdProfile . getPDStream ( ) . createOutputStream ( ) ; outputStream . write ( profile . getData ( ) ) ; outputStream . close ( ) ; imageXObject . setColorSpace ( pdProfile ) ; } } return imageXObject ; } catch ( IOException e ) {", "del_tokens": "return LosslessFactory . createFromImage ( document , bi ) ; } catch ( IOException e ) {", "commit_type": "add"}
{"commit_tokens": ["add", "PluginClasspath", "-", "now", "you", "can", "add", "any", "classes", "and", "lib", "directories", "to", "plugin", "classpath"], "add_tokens": "private final ExtensionFinder extensionFinder ; private final PluginDescriptorFinder pluginDescriptorFinder ; private final PluginClasspath pluginClasspath ; pluginClasspath = createPluginClasspath ( ) ; return new DefaultPluginDescriptorFinder ( pluginClasspath ) ; / * * * Add the possibility to override the PluginClassPath . * / protected PluginClasspath createPluginClasspath ( ) { return new PluginClasspath ( ) ; } PluginLoader pluginLoader = new PluginLoader ( this , pluginDescriptor , pluginDirectory , pluginClasspath ) ;", "del_tokens": "private ExtensionFinder extensionFinder ; private PluginDescriptorFinder pluginDescriptorFinder ; return new DefaultPluginDescriptorFinder ( ) ; PluginLoader pluginLoader = new PluginLoader ( this , pluginDescriptor , pluginDirectory ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "incorrect", "dependency", "on", "example", "service"], "add_tokens": "import static org . jboss . as . threads . AbstractExecutorElement . * ; serviceBuilder . addDependency ( ServiceName . of ( JBOSS_THREAD_EXECUTOR . append ( threadPoolName ) ) ) . toInjector ( executorInjector ) ;", "del_tokens": "import java . util . EnumSet ; import org . jboss . msc . services . ThreadPoolExecutorService ; serviceBuilder . addDependency ( ServiceName . of ( ThreadPoolExecutorService . JBOSS_THREADS_EXECUTOR . append ( threadPoolName ) ) ) . toInjector ( executorInjector ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "signature", "of", "getDefaultLayoutXml", "()", ".", "It", "is", "no", "longer", "necessary", "to", "pass", "a", "user", "name", "because", "the", "default", "layout", "xml", "is", "taken", "from", "a", "user", "named", "default", ".", "With", "this", "change", "a", "DEFAULT_LAYOUT_XML", "column", "is", "no", "longer", "needed", "in", "the", "PORTAL_USERS", "table", "."], "add_tokens": "public IXml getDefaultLayoutXml ( HttpServletRequest req ) String sQuery = \"SELECT LAYOUT_XML FROM PORTAL_USERS WHERE USER_NAME='default'\" ; String sLayoutXml = rs . getString ( \"LAYOUT_XML\" ) ;", "del_tokens": "public IXml getDefaultLayoutXml ( HttpServletRequest req , String sUserName ) String sQuery = \"SELECT DEFAULT_LAYOUT_XML FROM PORTAL_USERS WHERE USER_NAME='\" + sUserName + \"'\" ; String sLayoutXml = rs . getString ( \"DEFAULT_LAYOUT_XML\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "null", "check", "for", "input", "args"], "add_tokens": "return o != null && ( compareTo ( o ) == 0 ) ;", "del_tokens": "return ( compareTo ( o ) == 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "the", "junit", "matching", "test", "to", "a", "seperate", "test", "class"], "add_tokens": "public Map get ( String path ) throws IOException { return jsonToMap ( Request . Get ( url + path ) . execute ( ) . returnContent ( ) . asString ( ) ) ; return jsonToMap ( respBody ) ; } private HashMap jsonToMap ( String respBody ) throws IOException {", "del_tokens": "public String get ( String path ) throws IOException { return Request . Get ( url + path ) . execute ( ) . returnContent ( ) . asString ( ) ;", "commit_type": "move"}
{"commit_tokens": ["improved", "widths", "on", "the", "process", "and", "audit", "forms"], "add_tokens": "import com . vaadin . ui . TextArea ; String [ ] fieldList = new String [ ] { \"created\" , \"lockedBy\" , \"status\" , \"comment\" } ; TextArea comment = ( TextArea ) m_auditForm . getField ( \"comment\" ) ; comment . setWidth ( \"700px\" ) ;", "del_tokens": "String [ ] fieldList = new String [ ] { \"created\" , \"lockedBy\" , \"comment\" , \"status\" } ;", "commit_type": "improve"}
{"commit_tokens": ["update", "payment", "object", "with", "results", "from", "post"], "add_tokens": "protected static ApruveClient client = null ;", "del_tokens": "private static ApruveClient client = null ;", "commit_type": "update"}
{"commit_tokens": ["Add", "tests", "for", "Code", "93", "refactor", "/", "Javafy", "Code", "93", "implementation", "a", "bit", "."], "add_tokens": "int count = ( int ) Math . ceil ( pattern [ 0 ] . length ( ) / ( double ) size ) ; int substringStart = j * size ; int substringEnd = Math . min ( ( j + 1 ) * size , row . length ( ) ) ; codewords [ ( i * count ) + j ] = Integer . parseInt ( row . substring ( substringStart , substringEnd ) ) ;", "del_tokens": "int count = pattern [ 0 ] . length ( ) / size ; codewords [ ( i * count ) + j ] = Integer . parseInt ( row . substring ( j * size , ( j + 1 ) * size ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "getPositionNAC", "and", "added", "getPositionUncertainty"], "add_tokens": "* @ return the navigation accuracy for position messages ; rather use getPositionUncertainty public byte getPositionNAC ( ) { return nac_pos ; } / * * * @ return the estimated position uncertainty according to the position NAC in meters ( - 1 for unknown ) * / public double getPositionUncertainty ( ) {", "del_tokens": "* @ return the navigation accuracy for position messages in meters and - 1 for unknown public double getPositionNAC ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "getBoxesInRegion", "()", "definition", "(", "it", "always", "returned", "the", "root", ")"], "add_tokens": "if ( r . encloses ( root . getBounds ( ) ) )", "del_tokens": "if ( r . intersects ( root . getBounds ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "make", "class", "final", "and", "constructors", "package", "access", ".", "Removed", "unused", "code", "."], "add_tokens": "final class Var2Data extends MPPComponent Var2Data ( VarMeta meta , InputStream is ) int itemCount = m_meta . getItemCount ( ) ; int itemOffset ;", "del_tokens": "public class Var2Data extends MPPComponent public Var2Data ( VarMeta meta , InputStream is ) int itemCount = m_meta . getItemCount ( ) ; int index ; int offset = 0 ; int itemOffset ; int itemSize ;", "commit_type": "update"}
{"commit_tokens": ["add", "client", "side", "code", "to", "report", "lost", "file", "."], "add_tokens": "// validateIO(false); // validateIO(false); // validateIO(false); // validateIO(true); // validateIO(false); try { mTachyonClient . reportLostFile ( mId ) ; } catch ( FileDoesNotExistException e ) { throw new IOException ( \"File does not exist anymore: \" + mClientFileInfo ) ; } catch ( TException e ) { throw new IOException ( \"Can not connect to Tachyon system.\" ) ; } // validateIO(true); // validateIO(true);", "del_tokens": "// validateIO(false); // validateIO(false); // validateIO(false); // validateIO(true); // validateIO(false); // validateIO(true); // validateIO(true);", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "test", ".", "Now", "it", "s", "possible", "to", "run", "it", "from", "IDE"], "add_tokens": "import org . apache . curator . test . TestingServer ; import org . springframework . util . SocketUtils ; public static final String ROOT = \"/\" + PREFIX + UUID . randomUUID ( ) ; private TestingServer testingServer ; int port = SocketUtils . findAvailableTcpPort ( ) ; this . testingServer = new TestingServer ( port ) ; String connectString = \"localhost:\" + port ; . connectString ( connectString ) . run ( \"--spring.cloud.zookeeper.connectString=\" + connectString , \"--spring.application.name=testZkPropertySource\" ,", "del_tokens": "public static final String ROOT = \"/\" + PREFIX + UUID . randomUUID ( ) ; . connectString ( new ZookeeperProperties ( ) . getConnectString ( ) ) . run ( \"--spring.application.name=testZkPropertySource\" ,", "commit_type": "fix"}
{"commit_tokens": ["added", "all", "bulk", "rest", "endpoints"], "add_tokens": "// TODO Bulk api does not using default index and type yet public Bulk ( ) { setURI ( \"_bulk\" ) ; } public Bulk ( String indexName ) { setURI ( buildURIWithoutDefaults ( indexName , null , null ) + \"/_bulk\" ) ; } public Bulk ( String indexName , String typeName ) { setURI ( buildURIWithoutDefaults ( indexName , typeName , null ) + \"/_bulk\" ) ; }", "del_tokens": "@ Override public String getURI ( ) { return \"_bulk\" ; }", "commit_type": "add"}
{"commit_tokens": ["Removing", "Project", "loaders", "and", "merging", "them", "back", "into", "the", "ProjectManager", "because", "the", "project", "manager"], "add_tokens": "//int portNumber = azkabanSettings.getInt(\"jetty.port\",DEFAULT_PORT_NUMBER);", "del_tokens": "import azkaban . project . FileProjectLoader ; import azkaban . project . ProjectLoader ; int portNumber = azkabanSettings . getInt ( \"jetty.port\" , DEFAULT_PORT_NUMBER ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "infinite", "loop", "in", "NamedPattern", "on", "Android", "(", "REGEX", "-", "9", ")"], "add_tokens": "m . reset ( s ) ;", "del_tokens": "m . reset ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "match", "new", "version", "of", "JME", "."], "add_tokens": "_rotm . fromAngleAxis ( deltaAngle , axis ) ;", "del_tokens": "_rotm . fromAxisAngle ( axis , deltaAngle ) ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "bug", "with", "secure", "storage", "not", "using", "the", "correct", "session", "state"], "add_tokens": "import org . apache . tapestry5 . services . RequestGlobals ; import org . slf4j . LoggerFactory ; private Logger log = LoggerFactory . getLogger ( PortalModule . class ) ; final RequestGlobals requestGlobals , securityManager , appStateManager . getIfExists ( JsonSessionState . class ) ) ) ;", "del_tokens": "final JsonSessionState sessionState = appStateManager . getIfExists ( JsonSessionState . class ) ; securityManager , sessionState ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "javadocs", "preliminary", "config", "dumper", "method", "."], "add_tokens": "String getFullName ( ) { if ( parent == null ) { return name ; } else { return parent . getFullName ( ) + \".\" + name ; } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Implemented", "Google", "+", "activity", "attachments", "model", "and", "updated", "example"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; public static class ActivityObject { private final String content ; private final List < Attachment > attachments ; @ JsonCreator protected ActivityObject ( @ JsonProperty ( \"content\" ) String content , @ JsonProperty ( \"attachments\" ) List < Attachment > attachments ) { this . content = content ; this . attachments = attachments ; } } private final ActivityObject object ; @ JsonProperty ( \"actor\" ) BasicProfile actor , @ JsonProperty ( \"object\" ) ActivityObject object ) { this . object = object ; public String getContent ( ) { return object . content ; } public List < Attachment > getAttachments ( ) { return object . attachments == null ? new ArrayList < Attachment > ( ) : object . attachments ; }", "del_tokens": "@ JsonProperty ( \"actor\" ) BasicProfile actor ) {", "commit_type": "implement"}
{"commit_tokens": ["add", "multiple", "range", "query", "to", "test"], "add_tokens": "if ( lat >= - 6 && lat <= - 5 && lon >= 136 && lon <= 138 ) System . out . println ( \"--------------------------------------\" ) ; System . out . println ( \"running multiple range query\" ) ; PreparedStatement ps = con . prepareStatement ( \"select name,lat,lon from report where time >= ? and time <? and lat>=-6 and lat<=-5 and lon>=136 and lon<=138\" ) ; ps . setLong ( 1 , now - Math . round ( TimeUnit . DAYS . toMillis ( 1 ) ) ) ; ps . setLong ( 2 , now ) ; long t = System . currentTimeMillis ( ) ; ResultSet rs = ps . executeQuery ( ) ; int count = 0 ; while ( rs . next ( ) ) count ++ ; System . out . println ( \"found=\" + count + \" from \" + count + \" in \" + ( System . currentTimeMillis ( ) - t ) / 1000.0 + \"s\" ) ;", "del_tokens": "if ( lat >= - 6 && lat <= - 5 && lon >= 136 && lon < 138 )", "commit_type": "add"}
{"commit_tokens": ["Fix", "compiler", "warning", "about", "unchecked", "conversion"], "add_tokens": "TriggerBehaviour < S , T > result = tryFindLocalHandler ( trigger ) ;", "del_tokens": "TriggerBehaviour result = tryFindLocalHandler ( trigger ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "deploy", "already", "-", "created", "Rack", "apps"], "add_tokens": "Object rackApp = options . get ( \"rack_app\" ) ; IRubyObject rackApplication ; if ( rackApp != null ) { rackApplication = ( IRubyObject ) rackApp ; } else { String rackScript = \"require 'rack'\\n\" + \"app, _ = Rack::Builder.parse_file(File.join('\" + root + \"', 'config.ru'))\\n\" + \"app\\n\" ; rackApplication = RuntimeHelper . evalScriptlet ( getRuntime ( application ) , rackScript , false ) ; }", "del_tokens": "String rackScript = \"require 'rack'\\n\" + \"app, _ = Rack::Builder.parse_file(File.join('\" + root + \"', 'config.ru'))\\n\" + \"app\\n\" ; IRubyObject rackApplication = RuntimeHelper . evalScriptlet ( getRuntime ( application ) , rackScript , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "method", "to", "estimate", "how", "large", "the", "JSON", "equivalent", "might", "be"], "add_tokens": "public int estimateMaximumBytes ( ) { int count = this . size ( ) ; for ( String key : _rsets . keySet ( ) ) { CachedResultSet crs = _rsets . get ( key ) ; count += crs . columns . length * crs . rows . size ( ) ; } return count * 64 ; }", "del_tokens": "//import java.sql.ResultSet;", "commit_type": "add"}
{"commit_tokens": ["Adds", "additional", "PathSegment", "tests", "."], "add_tokens": "public void testGetPathSegmentNoMatrixParams ( ) throws ClientProtocolException , IOException verifyOkResult ( new RequestResult ( \"get/pathsegment/ps1\" ) , \"pp:ps1;kval:null,jval:null\" ) ; public void testGetPathSegmentNoPathParams ( ) throws ClientProtocolException , IOException verifyOkResult ( new RequestResult ( \"get/pathsegment/;k=v;j=x\" ) , \"pp:;kval:v,jval:x\" ) ; // TODO: *Possibly* support List<PathSegment>. // // This is a part of the spec but to me it seems an unnecessary complication. // It seems more reasonable to me to not convolute the processing of the path // for that special case, and instead expect users to figure out how to work around it. // I'm going to wait until someone makes me support List<PathSegment> before // I add it. // Of course if someone else wants to add support for it, whatever. -MR", "del_tokens": "import javax . ws . rs . core . PathSegment ; import org . jboss . resteasy . specimpl . PathSegmentImpl ; public void testGetListOfPathSegment ( ) public void testGetPathSegmentMultipleMatrixParams ( ) @ Test public void testGetPathSegmentDuplicateMatrixParams ( ) { } @ Test public void testGetPathSegmentNoMatrixParams ( ) { } @ Test public void testGetPathSegmentNoPathParams ( ) { }", "commit_type": "add"}
{"commit_tokens": ["Implemented", "echo", "server", "again", "."], "add_tokens": "BotApiResponse apiResponse = lineBotClient . push ( Collections . singletonList ( mid ) , Collections . singletonList ( new TextMessage ( textMessageContent . getText ( ) ) ) ) ;", "del_tokens": "BotApiResponse apiResponse = lineBotClient . push ( Collections . singletonList ( mid ) , Collections . singletonList ( new TextMessage ( textMessageContent . getText ( ) ) ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Use", "LinkedList", ".", "listIterator", "instead", "of", "LinkedList", ".", "descendingIterator", "()", "for", "API", "compatibility"], "add_tokens": "import java . util . ListIterator ; for ( ListIterator < Connection > i = connections . listIterator ( connections . size ( ) ) ; i . hasPrevious ( ) ; ) { Connection connection = i . previous ( ) ; for ( ListIterator < Connection > i = connections . listIterator ( connections . size ( ) ) ; i . hasPrevious ( ) && idleConnectionCount > maxIdleConnections ; ) { Connection connection = i . previous ( ) ;", "del_tokens": "for ( Iterator < Connection > i = connections . descendingIterator ( ) ; i . hasNext ( ) ; ) { Connection connection = i . next ( ) ; for ( Iterator < Connection > i = connections . descendingIterator ( ) ; i . hasNext ( ) && idleConnectionCount > maxIdleConnections ; ) { Connection connection = i . next ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "convenience", "method", "to", "customIconsBuilder", "and", "added", "test"], "add_tokens": "import java . util . ArrayList ; List < CustomIcon > customIcons = new ArrayList < CustomIcon > ( ) ; public CustomIconsBuilder addIcon ( CustomIcon icon ) { customIcons . add ( icon ) ; return this ; }", "del_tokens": "List < CustomIcon > customIcons ;", "commit_type": "add"}
{"commit_tokens": ["added", "param", "krati", ".", "test", ".", "jvm", ".", "args", "to", "pom", ".", "xml"], "add_tokens": "public String getStatus ( ) {", "del_tokens": "public String getStatus ( ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "another", "genertor", "so", "that", "folks", "can", "directly", "access", "JsonEncoderDecoder", "implemenations", "for", "thier", "data", "transfer", "objects", "."], "add_tokens": "import com . google . gwt . core . client . GWT ; import com . hiramchirino . restygwt . client . JsonEncoderDecoder ; / * * * Example of how to create an instance of a JsonEncoderDecoder for a data * transfer object . * / public interface OrderConfirmationJED extends JsonEncoderDecoder < OrderConfirmation > { } @ Override public String toString ( ) { if ( GWT . isClient ( ) ) { // Shows how to access the code generated json encoder/decoder. // Only works in client code, won't work on the server side. JsonEncoderDecoder < OrderConfirmation > jed = GWT . create ( OrderConfirmationJED . class ) ; return jed . encode ( this ) . toString ( ) ; } return super . toString ( ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Allow", "specifying", "different", "URL", "for", "API"], "add_tokens": "private String baseUri ; this ( null , apiKey ) ; } public DependencyWatcherClient ( String baseUri , String apiKey ) { if ( baseUri != null ) { while ( baseUri . endsWith ( \"/\" ) ) { baseUri = baseUri . substring ( 0 , baseUri . length ( ) - 1 ) ; } } this . baseUri = baseUri == null ? \"https://dependencywatcher.com/api/v1\" : baseUri ; HttpPut putMethod = new HttpPut ( baseUri + \"/repository/\" public static void main ( String [ ] args ) throws ClientException { DependencyWatcherClient client = new DependencyWatcherClient ( \"http://localhost:3001/api/v1/\" , \"235a3eef-8419-48e1-aed8-92b4062ea6e9\" ) ; client . uploadRepository ( \"TLDRify\" , new File ( \"/tmp/tldrify.com.zip\" ) ) ; }", "del_tokens": "private static final String BASE_URI = \"https://dependencywatcher.com/api/v1/\" ; HttpPut putMethod = new HttpPut ( BASE_URI + \"repository/\"", "commit_type": "allow"}
{"commit_tokens": ["Allow", "string", "option", "values", "with", "both", "single", "&", "double", "quotes"], "add_tokens": "} else if ( ctx . textFormatOptionValue ( ) . STRING_VALUE ( ) != null ) { String text = ctx . textFormatOptionValue ( ) . STRING_VALUE ( ) . getText ( ) ;", "del_tokens": "} else if ( ctx . textFormatOptionValue ( ) . TEXTFORMAT_STRING_VALUE ( ) != null ) { String text = ctx . textFormatOptionValue ( ) . TEXTFORMAT_STRING_VALUE ( ) . getText ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "download", "method", "to", "download", "a", "linked", "image", "."], "add_tokens": "import com . google . api . client . http . * ; import com . google . api . client . json . gson . GsonFactory ; import com . mailosaur . exception . MailosaurException ; static final HttpRequestFactory requestFactory = HTTP_TRANSPORT . createRequestFactory ( new HttpRequestInitializer ( ) { public void initialize ( HttpRequest request ) { request . setParser ( new JsonObjectParser ( JSON_FACTORY ) ) ; }", "del_tokens": "import com . google . api . client . http . GenericUrl ; import com . google . api . client . http . HttpRequest ; import com . google . api . client . http . HttpRequestFactory ; import com . google . api . client . http . HttpRequestInitializer ; import com . google . api . client . http . HttpTransport ; import com . google . api . client . json . gson . GsonFactory ; static final HttpRequestFactory requestFactory = HTTP_TRANSPORT . createRequestFactory ( new HttpRequestInitializer ( ) { public void initialize ( HttpRequest request ) { request . setParser ( new JsonObjectParser ( JSON_FACTORY ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "ot", "namespace", "for", "config"], "add_tokens": "return ImmutableMap . of ( \"ot.db.\" + dbModuleName + \".uri\" , getJdbcUri ( db ) , \"ot.db.\" + dbModuleName + \".ds.user\" , db . user ) ;", "del_tokens": "return ImmutableMap . of ( \"ness.db.\" + dbModuleName + \".uri\" , getJdbcUri ( db ) , \"ness.db.\" + dbModuleName + \".ds.user\" , db . user ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "ability", "to", "set", "action", "item", "text", "color"], "add_tokens": "import android . os . Bundle ; mSnackBar . show ( String . format ( getString ( R . string . syrup_added ) , mSnackNames [ mSnackIndex ++ % mSnackNames . length ] . toLowerCase ( ) ) , getString ( R . string . undo ) , SnackBar . Style . INFO ) ;", "del_tokens": "import android . content . Intent ; import android . os . Bundle ; mSnackBar . show ( String . format ( getString ( R . string . syrup_added ) , mSnackNames [ mSnackIndex ++ % mSnackNames . length ] . toLowerCase ( ) ) , getString ( R . string . undo ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "note", "about", "the", "endpoint", "being", "null", "for", "a", "root", "(", "/", ")", "request", "."], "add_tokens": "import com . github . davidcarboni . restolino . RequestHandler ; * The class that the error occurred in . This will be null for a * root ( '/' ) request .", "del_tokens": "import com . github . davidcarboni . restolino . servlet . RequestHandler ; * The class that the error occurred in .", "commit_type": "add"}
{"commit_tokens": ["Added", "experimental", "binding", "utilities", "and", "classes"], "add_tokens": "// Get value from all masters public void to ( Collection < Slave < SI > > slaves ) { // Connect master -> proxy -> slaves SingleProxy < MO , SI > proxy = new SingleProxy < MO , SI > ( transformers ) ; master . addSlave ( proxy ) ; for ( Slave < SI > slave : slaves ) { proxy . addSlave ( slave ) ; } // Set initial values in proxy and slave proxy . setValue ( master . getValue ( ) ) ; } public void to ( Slave < SI > ... slaves ) { to ( Arrays . asList ( slaves ) ) ; } public void to ( Collection < Slave < SI > > slaves ) { // Connect masters -> proxy -> slaves MultipleProxy < MO , SI > proxy = new MultipleProxy < MO , SI > ( masters , transformers ) ; for ( Master < MO > master : masters ) { master . addSlave ( proxy ) ; } for ( Slave < SI > slave : slaves ) { proxy . addSlave ( slave ) ; } // Slave initial values in proxy and slave proxy . setValue ( null ) ; } public void to ( Slave < SI > ... slaves ) { to ( Arrays . asList ( slaves ) ) ; }", "del_tokens": "// TODO Get value from all masters", "commit_type": "add"}
{"commit_tokens": ["move", "StringValue", "in", "util", "package"], "add_tokens": "package ro . fortsoft . pippo . core . util ;", "del_tokens": "package ro . fortsoft . pippo . core ;", "commit_type": "move"}
{"commit_tokens": ["Use", "staus", "property", "instead", "of", "hadcoded", "."], "add_tokens": "//task status runningBuild.getStatus() //TODO use to track current operation eg. env-setup, maven-repo-config, staring-build, waiting-build, storing-results this . status = runningBuild . getBuildJobDetails ( ) . getBuildStatus ( ) ;", "del_tokens": "this . status = BuildStatus . BUILDING ;", "commit_type": "use"}
{"commit_tokens": ["Make", "Tomcat", "allow", "a", ".", "JAR", "file", "that", "contains", "a", "webapp"], "add_tokens": "// Use our own WebResourceRoot implementation so that we can load a ZIP/JAR file // whose extention is not '.war'. ctx . setResources ( new ArmeriaWebResourceRoot ( ctx , config ) ) ;", "del_tokens": "import org . apache . coyote . ProtocolHandler ; final ProtocolHandler protocolHandler = connector . getProtocolHandler ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "javadoc", "and", "exception", "message", "."], "add_tokens": "* { @ link SerDe } implementation that serializes and de - serializes { @ link TMessageSet } . This is serde is used to persist * { @ link TMessageSet } objects to a disk - based queue . Messages in { @ link TMessageSet } objects that are not consumed would be lost when the server fails , * if only in - memory queue is used to store { @ link TMessageSet } objects . app , numMessages , compression , crc , ByteBuffer . wrap ( messages ) throw new RuntimeException ( \"Failed to de-serialize payload into TMessageSet: \" + e . getMessage ( ) , e ) ; throw new RuntimeException ( \"Failed to serialize TMessageSet: \" + e . getMessage ( ) , e ) ;", "del_tokens": "* SerDe about TMessageSet . This is necessary when we want to persist * TMessageSet to the disk based queue . Otherwise , TMessageSet which is not * consumed yet would be lost when the server fails . app , numMessages , compression , crc , ByteBuffer . wrap ( messages ) throw new RuntimeException ( e ) ; throw new RuntimeException ( e ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "so", "any", "layout", "manager", "can", "be", "set", "on", "the", "recyclerview"], "add_tokens": "* < p / > * < p / > * http : //www.apache.org/licenses/LICENSE-2.0 * < p / >", "del_tokens": "* * * http : //www.apache.org/licenses/LICENSE-2.0 *", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "case", "to", "converter", "registry", "."], "add_tokens": "import no . kantega . pdf . throwables . ConversionInputException ; throw new ConversionInputException ( \"No converter for conversion of \" + sourceFormat + \" to \" + targetFormat + \" available\" ) ;", "del_tokens": "throw new ConverterException ( \"No converter for conversion of \" + sourceFormat + \" to \" + targetFormat + \" available\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "new", "ph", "-", "xml", "project"], "add_tokens": "import com . helger . xml . microdom . IMicroElement ; import com . helger . xml . microdom . MicroElement ; import com . helger . xml . microdom . convert . IMicroTypeConverter ;", "del_tokens": "import com . helger . commons . microdom . IMicroElement ; import com . helger . commons . microdom . MicroElement ; import com . helger . commons . microdom . convert . IMicroTypeConverter ;", "commit_type": "use"}
{"commit_tokens": ["Use", "bean", "post", "processor", "to", "rebind", "info", "endpoint"], "add_tokens": "import org . springframework . beans . factory . config . BeanPostProcessor ; ApplicationListener < EnvironmentChangeEvent > , BeanPostProcessor { @ Override public Object postProcessAfterInitialization ( Object bean , String beanName ) throws BeansException { if ( bean instanceof InfoEndpoint ) { return infoEndpoint ( ( InfoEndpoint ) bean ) ; } return bean ; } @ Override public Object postProcessBeforeInitialization ( Object bean , String beanName ) throws BeansException { return bean ; } private InfoEndpoint infoEndpoint ( InfoEndpoint endpoint ) { return new InfoEndpoint ( endpoint . invoke ( ) ) { BeanFactoryAware { + \".store\" , ConfigurationBeanFactoryMetaData . class ) ;", "del_tokens": "ApplicationListener < EnvironmentChangeEvent > { @ Autowired private EndpointAutoConfiguration endpoints ; @ Bean public InfoEndpoint infoEndpoint ( ) throws Exception { return new InfoEndpoint ( this . endpoints . infoEndpoint ( ) . invoke ( ) ) { BeanFactoryAware { + \".store\" , ConfigurationBeanFactoryMetaData . class ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "the", "RobustScaler", "transformation", "type"], "add_tokens": "scaler . put ( \"min_\" , 0d ) ; scaler . put ( \"scale_\" , 1d ) ;", "del_tokens": "scaler . put ( \"min_\" , 0 ) ; scaler . put ( \"scale_\" , 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Upgrade", "to", "JUnit", "5", "platform"], "add_tokens": "import static org . junit . jupiter . api . Assertions . assertEquals ; import org . junit . jupiter . api . Test ; import org . junit . platform . runner . JUnitPlatform ; import org . junit . runner . RunWith ; @ RunWith ( JUnitPlatform . class )", "del_tokens": "import static org . junit . Assert . assertEquals ; import org . junit . Test ;", "commit_type": "upgrade"}
{"commit_tokens": ["Fixed", "problem", "with", "parents", "in", "the", "case", "of", "a", "root", "node", "with", "empty", "extent"], "add_tokens": "private static final boolean ASSERTS = false ; private static final boolean DEBUG = false ; private static final boolean DDDEBUG = false ; // If the exit node is the root, there is no parent. if ( parexOrExitNode == root ) return new ParexData < T > ( null , parexOrExitNode , lcpLength ) ; // If the extent of the parent is zero, but the exit node is not the root, the root is the parent (and it has an empty extent). if ( parexOrExitNode . parentExtentLength == 0 ) { stack . push ( ( InternalNode < T > ) root ) ; return new ParexData < T > ( ( InternalNode < T > ) root , parexOrExitNode , lcpLength ) ; } // If the exit node is the root, there is no parent. if ( parexOrExitNode == root ) return new ParexData < T > ( null , parexOrExitNode , lcpLength ) ; // If the extent of the parent is zero, but the exit node is not the root, the root is the parent (and it has an empty extent). if ( parexOrExitNode . parentExtentLength == 0 ) { stack . push ( ( InternalNode < T > ) root ) ; return new ParexData < T > ( ( InternalNode < T > ) root , parexOrExitNode , lcpLength ) ; } // If the parent of the exit node is the root, there is no grandparent. // If the extent of the grandparent is zero, but the parent is not the root, the root is the grandparent (and it has an empty extent).", "del_tokens": "private static final boolean ASSERTS = true ; private static final boolean DEBUG = true ; private static final boolean DDDEBUG = true ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "writer", "enforces", "the", "same", "encoder"], "add_tokens": "cache . journalWriter = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( cache . journalFile , true ) , Charsets . US_ASCII ) ) ; Writer writer = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( journalFileTmp ) , Charsets . US_ASCII ) ) ; journalWriter = new BufferedWriter ( new OutputStreamWriter ( new FileOutputStream ( journalFile , true ) , Charsets . US_ASCII ) ) ;", "del_tokens": "import java . io . FileWriter ; cache . journalWriter = new BufferedWriter ( new FileWriter ( cache . journalFile , true ) ) ; Writer writer = new BufferedWriter ( new FileWriter ( journalFileTmp ) ) ; journalWriter = new BufferedWriter ( new FileWriter ( journalFile , true ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Change", "dependency", "to", "maven", "-", "central", "kdtree"], "add_tokens": "package de . biomedical_imaging . traj . math ; import de . biomedical_imaging . edu . wlu . cs . levy . CG . KDTree ; import de . biomedical_imaging . edu . wlu . cs . levy . CG . KeyDuplicateException ; import de . biomedical_imaging . edu . wlu . cs . levy . CG . KeySizeException ; import de . biomedical_imaging . traJ . Trajectory ;", "del_tokens": "package de . biomedical_imaging . traJ ; import de . biomedical_imaging . traj . math . RadiusGyrationTensor2D ; import edu . wlu . cs . levy . CG . KDTree ; import edu . wlu . cs . levy . CG . KeyDuplicateException ; import edu . wlu . cs . levy . CG . KeySizeException ;", "commit_type": "change"}
{"commit_tokens": ["add", "standard", "primitive", "types", "to", "the", "types", "map"], "add_tokens": "/ * * * Construct a new EncodedDataType with direct values * * @ param name of the type * @ param presence of the type * @ param description of the type or null * @ param fixUsage of the type or null * @ param primitive of the EncodedDataType * @ param length of the EncodedDataType * @ param varLen of the EncodedDataType * / public EncodedDataType ( final String name , final Presence presence , final String description , final String fixUsage , final Primitive primitive , final int length , final boolean varLen ) { super ( name , presence , description , fixUsage ) ; // TODO: use similar constructor for super so setting all specifics this . primitive = primitive ; this . length = length ; this . varLen = varLen ; // TODO: add nullValue, minValue, maxValue } * The size ( in octets ) of the primitiveType", "del_tokens": "* The size ( in octets ) of the Type", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "use", "a", "custom", "JobParametersConverter", "within", "JobOperationsController"], "add_tokens": "@ Autowired private JobParametersConverter jobParametersConverter ;", "del_tokens": "private JobParametersConverter jobParametersConverter = new DefaultJobParametersConverter ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "partial", "downloads", "using", "Range", "requests", "."], "add_tokens": "final List < HttpRequestor . Header > extraHeaders , final List < HttpRequestor . Header > headers = new ArrayList < HttpRequestor . Header > ( extraHeaders ) ; if ( response . getStatusCode ( ) == 200 || response . getStatusCode ( ) == 206 ) {", "del_tokens": "final List < HttpRequestor . Header > headers = new ArrayList < HttpRequestor . Header > ( ) ; if ( response . getStatusCode ( ) == 200 ) {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "all", "errors", "in", "both", "projects", "."], "add_tokens": "import com . tjeannin . provigen . InvalidContractException ; import com . tjeannin . provigen . annotations . Id ; public AlarmContentProvider ( ) throws InvalidContractException { @ Id @ Column ( Type . INTEGER ) public static final Uri CONTENT_URI = Uri . parse ( \"content://com.tjeannin.alarm/alarm\" ) ;", "del_tokens": "public AlarmContentProvider ( ) { @ Column ( Colu Type . INTEGER )", "commit_type": "fix"}
{"commit_tokens": ["Make", "sure", "color", "wheel", "is", "always", "displayed", "completely"], "add_tokens": "int min = Math . min ( width , height ) ; setMeasuredDimension ( min , min ) ;", "del_tokens": "int max = Math . max ( width , height ) ; setMeasuredDimension ( max , max ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "correlation", "id", "suffix", "to", "on", "-", "behalf", "-", "of", "token", "request"], "add_tokens": "import java . util . * ; private static final String REQUEST_ID_SUFFIX = \"aadfeed5\" ; context . setCorrelationId ( getCorrelationId ( ) ) ; private static String getCorrelationId ( ) { final String uuid = UUID . randomUUID ( ) . toString ( ) ; return uuid . substring ( 0 , uuid . length ( ) - REQUEST_ID_SUFFIX . length ( ) ) + REQUEST_ID_SUFFIX ; }", "del_tokens": "import java . util . ArrayList ; import java . util . LinkedHashSet ; import java . util . List ; import java . util . Set ;", "commit_type": "add"}
{"commit_tokens": ["add", "support", "for", "malformed", "properties", "files", "in", "git", "source"], "add_tokens": "} catch ( IOException | IllegalArgumentException e ) {", "del_tokens": "} catch ( IOException e ) {", "commit_type": "add"}
{"commit_tokens": ["make", "default", "dead", "instance", "thresh", "15", "min"], "add_tokens": "return ( int ) TimeUnit . MILLISECONDS . convert ( 15 , TimeUnit . MINUTES ) ;", "del_tokens": "return ( int ) TimeUnit . MILLISECONDS . convert ( 1 , TimeUnit . HOURS ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "inheritance", "for", "the", "IndexQuery"], "add_tokens": "public class IndexQuery extends Query { public IndexQuery ( String index ) { super ( ) ; public IndexQuery ( String index , String query ) { super ( query ) ; this . index = index ; public IndexQuery ( String index , Query other ) { super ( other ) ; public String getIndex ( ) { return index ; public void setIndex ( String index ) { this . index = index ;", "del_tokens": "public class IndexQuery { private Query query ; public IndexQuery ( String index , Query q ) { this . query = q ; public String getIndex ( ) { return index ; public void setIndex ( String index ) { public Query getQuery ( ) { return query ; public void setQuery ( Query query ) { this . query = query ;", "commit_type": "use"}
{"commit_tokens": ["Add", "colon", "after", "default", "in", "option", "descriptions"], "add_tokens": "String defaultStr = \"default: \" + oi . defaultStr ;", "del_tokens": "String defaultStr = \"default \" + oi . defaultStr ;", "commit_type": "add"}
{"commit_tokens": ["Use", "StringUtility", ".", "nullIfEmpty", "(", "String", ")"], "add_tokens": "import com . aoindustries . util . StringUtility ; return StringUtility . nullIfEmpty ( ( String ) value ) ; return StringUtility . nullIfEmpty ( value . toString ( ) ) ;", "del_tokens": "return ( ( String ) value ) . isEmpty ( ) ? null : value ; String toString = value . toString ( ) ; return toString . isEmpty ( ) ? null : toString ;", "commit_type": "use"}
{"commit_tokens": ["Updating", "scanning", "WiFi", "Access", "Points", "functionality"], "add_tokens": "setScanResultAdapter ( ) ; refreshWifiInfo ( ) ; private void setScanResultAdapter ( ) { wifiManager . startScan ( ) ; scanResultAdapter = new ScanResultAdapter ( this , R . layout . list_row , accessPoints ) ; lvAccessPointScanResults . setAdapter ( scanResultAdapter ) ; scanResultAdapter . notifyDataSetChanged ( ) ; } private void refreshWifiInfo ( ) { WifiManager wifiManager = ( WifiManager ) getSystemService ( Context . WIFI_SERVICE ) ; tvWifiInfo . setText ( wifiManager . getConnectionInfo ( ) . toString ( ) ) ; refreshWifiInfo ( ) ;", "del_tokens": "import java . util . HashMap ; import java . util . Map ; setScanResultAdapter ( ) ; / * * * This method is used only to display list of available access points . * It 's an additional feature and we don' t have to use it . * / private void setScanResultAdapter ( ) { scanResultAdapter = new ScanResultAdapter ( this , R . layout . list_row , accessPoints ) ; lvAccessPointScanResults . setAdapter ( scanResultAdapter ) ; scanResultAdapter . notifyDataSetChanged ( ) ; } refreshAccessPointsListAndWifiInfo ( ) ; private void refreshAccessPointsListAndWifiInfo ( ) { tvWifiInfo . setText ( wifiManager . getConnectionInfo ( ) . toString ( ) ) ; refreshAccessPointsListAndWifiInfo ( ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "test", "for", "user", "defined", "functions", "and", "actions"], "add_tokens": "throw context . makeException ( \"Extension can't process action \" , null ) ;", "del_tokens": "throw context . makeException ( \"Extension can't process the action\" , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "more", "tests", "but", "unable", "to", "re", "-", "produce", "bug", "."], "add_tokens": "{ ROOT , \"sorted ? (readonly ? 'currentSortDesc' : 'currentSortAsc') : 'currentSortNone'\" , \"currentSortAsc\" } , { ROOT , \"getAsset( (genericIndex?'Yes':'No')+'Icon' )\" , null }", "del_tokens": "{ ROOT , \"sorted ? (readonly ? 'currentSortDesc' : 'currentSortAsc') : 'currentSortNone'\" , \"currentSortAsc\" }", "commit_type": "add"}
{"commit_tokens": ["implemented", "BooleanColumn", "constructer", "based", "on", "roaring", "bitmaps"], "add_tokens": "public View head ( int nRows ) { View view = new View ( this , Math . min ( nRows , rowCount ( ) ) ) ; view . setName ( name ) ;", "del_tokens": "public View head ( int i ) { View view = new View ( this , Math . min ( i , rowCount ( ) ) ) ; view . setName ( name ( ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "fuzziness", "image", "recognition", "control"], "add_tokens": "import org . sikuli . slides . utils . Constants ; ImageTarget newImageTarget = new ImageTarget ( croppedRegionImage ) ; newImageTarget . setMinScore ( Constants . MinScore ) ; List < ScreenRegion > lookupRegion = fullScreenRegion . findAll ( newImageTarget ) ;", "del_tokens": "List < ScreenRegion > lookupRegion = fullScreenRegion . findAll ( new ImageTarget ( croppedRegionImage ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "time", "measuring", "for", "filters"], "add_tokens": "private long nsFirstPass = 0 ; private long nsSecondPass = 0 ; public long getNsFirstPass ( ) { return nsFirstPass ; } public long getNsSecondPass ( ) { return nsSecondPass ; } long time = System . nanoTime ( ) ; if ( chain == null ) { try { return read ( sf ) ; } finally { time = System . nanoTime ( ) - time ; nsFirstPass += time ; } try { this . chain = chain ; sfBuffer . add ( sf ) ; if ( ! onStructuredField ( sf ) ) { commit ( ) ; return false ; } return true ; } finally { time = System . nanoTime ( ) - time ; nsSecondPass += time ; }", "del_tokens": "if ( chain == null ) return read ( sf ) ; this . chain = chain ; sfBuffer . add ( sf ) ; if ( ! onStructuredField ( sf ) ) { commit ( ) ; return false ; return true ;", "commit_type": "add"}
{"commit_tokens": ["moved", "test", "converter", "classes", "to", "the", "test", "class"], "add_tokens": "throw new RuntimeException ( \"Your ParamConverter class must have a public no-arg constructor!\" , e ) ;", "del_tokens": "import junitparams . * ; throw new RuntimeException ( \"Your ParamConverter class must have a public no-arg constructor!\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Adding", "method", "to", "list", "courses", "on", "an", "account"], "add_tokens": "/ * * * Retrieve a list of all courses on a given account * @ param accountId Canvas account ID of account ( or sub - account ) to query * @ return List of courses in the account * @ throws IOException * / List < Course > listActiveCoursesInAccount ( Integer accountId ) throws IOException ;", "del_tokens": "//public List<User> getUsersInCourse(Integer courseId, String searchTerm, EnrollmentType enrollmentType, Integer enrollmentRoleId, List<CourseIncludes> includes, ) throws IOException;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "an", "issue", "where", "the", "step", "wasn", "t", "calculated", "for", "TextNodes", "."], "add_tokens": "final Node parent = getParent ( ) ; if ( parent == null ) return null ; Integer previousNode = 0 ; if ( parent instanceof Level ) { // Get the position of the level in its parents nodes final Integer nodePos = ( ( Level ) parent ) . getChildNodes ( ) . indexOf ( this ) ; // If the level isn't the first node then get the previous nodes step if ( nodePos > 0 ) { final Node node = ( ( Level ) parent ) . getChildNodes ( ) . get ( nodePos - 1 ) ; previousNode = node . getStep ( ) ; // If the add node is a level then add the number of nodes it contains if ( node instanceof Level ) { previousNode = ( previousNode == null ? 0 : previousNode ) + ( ( Level ) node ) . getTotalNumberOfChildren ( ) ; } // The node is the first item so use the parent levels step } else { previousNode = getParent ( ) . getStep ( ) ; } // Make sure the previous nodes step isn't 0 previousNode = previousNode == null ? 0 : previousNode ; // Add one since we got the previous nodes step return previousNode + 1 ; } else { return null ; }", "del_tokens": "// TODO Auto-generated method stub return null ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "AbstractAction", "that", "caused", "duplicated", "parameters", "in", "produced", "URI", "when", "buildURI", "method", "is", "called", "multiple", "times", "."], "add_tokens": "String finalUri = URI ; finalUri += buildQueryString ( ) ; return finalUri ;", "del_tokens": "URI = URI + buildQueryString ( ) ; return URI ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "Path", "implementation", "to", "take", "into", "account", "the", "view", "scroll", "offset", "to", "check", "if", "a", "NoxItem", "is", "inside", "the", "view", "or", "not", ".", "Remove", "OverScroller", "temporally"], "add_tokens": "updatePathOffset ( ) ; float left = path . getLeftForItemAtPosition ( i ) ; float top = path . getTopForItemAtPosition ( i ) ; private void updatePathOffset ( ) { int offsetX = scroller . getOffsetX ( ) ; int offsetY = scroller . getOffsetY ( ) ; path . setOffset ( offsetX , offsetY ) ; }", "del_tokens": "float left = path . getLeftForItemAtPosition ( i ) + scroller . getCurrentX ( ) ; float top = path . getTopForItemAtPosition ( i ) + scroller . getCurrentY ( ) ; @ Override public void computeScroll ( ) { super . computeScroll ( ) ; scroller . computeScrollOffset ( ) ; }", "commit_type": "update"}
{"commit_tokens": ["Moved", "tile", "edge", "length", "into", "IsoSceneView", "since", "it", "s", "specific", "to"], "add_tokens": "// $Id: Tile.java,v 1.6 2001/07/20 08:17:10 shaper Exp $ / * * * Return a string representation of the tile information . * /", "del_tokens": "// $Id: Tile.java,v 1.5 2001/07/18 22:45:35 shaper Exp $ public static final float EDGE_LENGTH = ( float ) Math . sqrt ( ( HALF_WIDTH * HALF_WIDTH ) + ( HALF_HEIGHT * HALF_HEIGHT ) ) ; / * * * Construct a new tile with the specified identifiers . Intended * only for use by the TileManager . Do not use this method . * * @ see com . threerings . miso . TileManager # getTile * / public Tile ( short tsid , short tid ) { this . tsid = tsid ; this . tid = tid ; }", "commit_type": "move"}
{"commit_tokens": ["Added", "force", "close", "upon", "an", "additional", "idle", "notification"], "add_tokens": "int idleCount = 1 ; if ( session . containsAttribute ( Constants . IDLE_COUNTER ) ) { idleCount = ( int ) session . getAttribute ( Constants . IDLE_COUNTER ) ; idleCount += 1 ; } else { session . setAttribute ( Constants . IDLE_COUNTER , idleCount ) ; } // after the first idle we force-close if ( conn != null && idleCount == 1 ) { log . info ( \"Force closing idle session: {}\" , session ) ; log . info ( \"Close operation completed {}: {}\" , session . getId ( ) , future . isClosed ( ) ) ;", "del_tokens": "if ( conn != null ) { log . debug ( \"WebSocketConnection attribute was empty, force closing idle session: {}\" , session ) ; log . debug ( \"Close operation completed {}: {}\" , session . getId ( ) , future . isClosed ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "ThreadLocal", "to", "store", "ObjectMapper", "and", "OutputStream", "in", "MessageBuffer"], "add_tokens": "ObjectMapper objectMapper = objectMapperHolder . get ( ) ; ByteArrayOutputStream outputStream = outputStreamHolder . get ( ) ; outputStream . reset ( ) ; objectMapper . writeValue ( outputStream , Arrays . asList ( tag , timestamp , data ) ) ; outputStream . close ( ) ; packedBytes = outputStream . toByteArray ( ) ;", "del_tokens": "// TODO: Use ThreadLocal synchronized ( outputStream ) { outputStream . reset ( ) ; objectMapper . writeValue ( outputStream , Arrays . asList ( tag , timestamp , data ) ) ; outputStream . close ( ) ; packedBytes = outputStream . toByteArray ( ) ; }", "commit_type": "use"}
{"commit_tokens": ["use", "StringUtils", "to", "check", "null"], "add_tokens": "if ( StringUtils . isEmpty ( stringBuilder ) ) { return stringBuilder . toString ( ) ; } if ( request . getParameterMap ( ) . keySet ( ) . size ( ) > 0 ) { return request . getParameterMap ( ) . keySet ( ) . toArray ( ) [ 0 ] . toString ( ) ; }", "del_tokens": "if ( ! stringBuilder . toString ( ) . isEmpty ( ) ) return stringBuilder . toString ( ) ; if ( request . getParameterMap ( ) . keySet ( ) . size ( ) > 0 ) return request . getParameterMap ( ) . keySet ( ) . toArray ( ) [ 0 ] . toString ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "some", "useful", "classes", "."], "add_tokens": "import java . util . Map . Entry ; public abstract class AbstractMap < T extends TypeSafeCloneable < T > > extends TypeSafeCloneable < AbstractMap < T > > { @ Override public AbstractMap < T > clone ( ) { AbstractMap < T > newMap = ( AbstractMap < T > ) super . clone ( ) ; for ( Entry < Point2 , T > e : newMap . tiles . entrySet ( ) ) { newMap . tiles . put ( e . getKey ( ) , e . getValue ( ) . cloneTypeSafely ( ) ) ; } return newMap ; }", "del_tokens": "public abstract class AbstractMap < T > {", "commit_type": "add"}
{"commit_tokens": ["added", "a", "csv", "example", "and", "assembly", "plugin"], "add_tokens": "import com . stratio . streaming . generator . ValuesGenerator ; throw new RuntimeException ( \"Usage: \\n param 1 - data multiplier (default = 1) \\n param 2 - kafka broker list\" ) ;", "del_tokens": "throw new RuntimeException ( \"Parameters are incorrect!\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "the", "ExcelSheetReader", "+", "wrote", "tests"], "add_tokens": "final Map < String , Integer > colNamesMap ; if ( hasHeader ) { Row headerRow = it . next ( ) ; colNamesMap = this . colNamesMap == null ? toColNamesMap ( headerRow ) : this . colNamesMap ; } else colNamesMap = null ;", "del_tokens": "final Map < String , Integer > colNamesMap = hasHeader ? ( this . colNamesMap == null ? toColNamesMap ( it . next ( ) ) : this . colNamesMap ) : null ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "helper", "class", "to", "extract", "metadata", "services"], "add_tokens": "return getCacheLifecyleManager ( factory ) . getCacheManager ( ) ; } public static CacheLifecycleManager getCacheLifecyleManager ( SessionFactoryImplementor factory ) { return ( CacheLifecycleManager ) sessionFactoryObserver ;", "del_tokens": "return ( ( CacheLifecycleManager ) factory ) . getCacheManager ( ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "timestamp", "type", "with", "fractional", "digits"], "add_tokens": "public String timestamp ( int fractionalDigits ) { return \"TIMESTAMP(\" + fractionalDigits + \")\" ; } public String timestampWithMilliseconds ( ) { return timestamp ( 3 ) ; } public String timestampWithMicroseconds ( ) { return timestamp ( 6 ) ; }", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Implement", "flow", "control", "for", "the", "incoming", "stream", "."], "add_tokens": "/ * * * The number of unacknowledged bytes at which the input stream will send * the peer a { @ code WINDOW_UPDATE } frame . Must be less than this client 's * window size , otherwise the remote peer will stop sending data on this * stream . * / public static final int WINDOW_UPDATE_THRESHOLD = Settings . DEFAULT_INITIAL_WINDOW_SIZE / 2 ; private final byte [ ] buffer = new byte [ Settings . DEFAULT_INITIAL_WINDOW_SIZE ] ; / * * * The total number of bytes consumed by the application ( with { @ link * # read } ) , but not yet acknowledged by sending a { @ code WINDOW_UPDATE } * frame . * / private int unacknowledgedBytes = 0 ; // Flow control: notify the peer that we're ready for more data! unacknowledgedBytes += copied ; if ( unacknowledgedBytes >= WINDOW_UPDATE_THRESHOLD ) { connection . writeWindowUpdateLater ( id , unacknowledgedBytes ) ; unacknowledgedBytes = 0 ; } // TODO: Await flow control (WINDOW_UPDATE) if necessary.", "del_tokens": "private final byte [ ] buffer = new byte [ 64 * 1024 ] ; // 64KiB specified by TODO // TODO: notify peer of flow-control", "commit_type": "implement"}
{"commit_tokens": ["Changed", "so", "there", "is", "a", "release", "connection", "so", "we", "can", "better", "cache", "and", "re", "-", "use", "connections", "."], "add_tokens": "* Return a database connection suitable for read - only operations . After you are done , you should call * { @ link # releaseReadOnlyConnection ( DatabaseConnection ) } . * Release a database connection previously returned by { @ link # getReadOnlyConnection ( ) } . * / public void releaseReadOnlyConnection ( DatabaseConnection connection ) throws SQLException ; / * * * Return a database connection suitable for read or write operations . After you are done , you should call * { @ link # releaseReadWriteConnection ( DatabaseConnection ) } . / * * * Release a database connection previously returned by { @ link # getReadWriteConnection ( ) } . * / public void releaseReadWriteConnection ( DatabaseConnection connection ) throws SQLException ;", "del_tokens": "* Return a database connection suitable for read - only operations . * Return a database connection suitable for read or write operations .", "commit_type": "change"}
{"commit_tokens": ["Fix", "unsafe", "compression", "on", "BIG_ENDIAN", "archs", "."], "add_tokens": "if ( readLong ( src , sOff ) == readLong ( src , ref ) ) { sOff += 8 ; zeroBits = Long . numberOfLeadingZeros ( readLong ( src , sOff ) ^ readLong ( src , ref ) ) ; zeroBits = Long . numberOfTrailingZeros ( readLong ( src , sOff ) ^ readLong ( src , ref ) ) ;", "del_tokens": "final long diff = readLong ( src , sOff ) - readLong ( src , ref ) ; if ( diff == 0 ) { sOff += 8 ; zeroBits = Long . numberOfLeadingZeros ( diff ) ; zeroBits = Long . numberOfTrailingZeros ( diff ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "default", "messages", "for", "failure", "and", "succes", "messages"], "add_tokens": "private String msgSuccess = \"Test PASSed.\" ; private String msgFailure = \"Test FAILed.\" ; if ( msgSuccess == null ) { return \"Test PASSed.\" ; } if ( msgFailure == null ) { return \"Test FAILed.\" ; }", "del_tokens": "private String msgSuccess ; private String msgFailure ;", "commit_type": "add"}
{"commit_tokens": ["added", "some", "javadoc", "and", "comments"], "add_tokens": "/ * * * * @ param position * list item 's position in list, NOT the index of the header * @ param convertView * a reused view , use this if not null * @ return * the header for list item at position * / / * * * * @ param position * list item 's position in list. * @ param convertView * a reused view , use this if not null * @ return * the list item at position * / //returns a header for position. will pass a header from cache if one exists //attaches a header to a list item //attaches a divider to list item //puts header into headerCache, wrapper into wrapperCache and returns listItem //if convertView is null, returns null / * * * @ internal * used by the StickyListHeadersListView , set the divider and divider height via listview instead ! * / / * * * @ internal * used by the StickyListHeadersListView , set the divider and divider height via listview instead ! * / / * * * @ internal * used by the StickyListHeadersListView , set the divider and divider height via listview instead ! * /", "del_tokens": "/ * * * puts header into headerCache , wrapper into wrapperCache and returns listItem * if convertView is null , returns null * /", "commit_type": "add"}
{"commit_tokens": ["fixed", "another", "bug", "which", "caused", "the", "OutputExtension", "without", "argument", "to", "return", "null", "for", "the", "return", "type", "and", "Object", "for", "the", "argument", "type", "(", "should", "be", "the", "other", "way", "around", ")"], "add_tokens": "* returns the Type of the argument for the OutputExtensions , or null if none * @ return the type of the Argument public TypeToken < Object > getArgumentType ( ) {", "del_tokens": "* returns the ReturnType of the generic * @ return the type of the generic public TypeToken < T > getReturnType ( ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "data", "type", "TestResultMetric", ".", "java"], "add_tokens": "import com . tascape . qa . th . db . TestResultMetric ; import java . util . List ; List < TestResultMetric > resultMetrics = test . getTestResultMetrics ( ) ; if ( ! resultMetrics . isEmpty ( ) ) { db . saveTestResultMetrics ( tcr . getId ( ) , resultMetrics ) ;", "del_tokens": "import java . util . Map ; Map < String , Map < String , Double > > metricData = test . getMetricData ( ) ; if ( ! metricData . isEmpty ( ) ) { LOG . info ( \"Save result metric data {}\" , metricData ) ; for ( String group : metricData . keySet ( ) ) { db . saveTestResultMetrics ( tcr . getId ( ) , group , metricData . get ( group ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["implemented", "dragging", "files", "and", "attaching", "them", "to", "topics"], "add_tokens": "public class TopicTest {", "del_tokens": "public class MindMapTopicTest {", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "invalid", "caching", "if", "a", "class", "loader", "was", "provided"], "add_tokens": "@ Nonnull private Schema _createSchema ( @ Nullable final ClassLoader aClassLoader ) { final List < ? extends IReadableResource > aXSDRes = getAllXSDResources ( aClassLoader ) ; final Schema ret = XMLSchemaCache . getInstanceOfClassLoader ( aClassLoader ) . getSchema ( aXSDRes ) ; if ( ret == null ) throw new IllegalStateException ( \"Failed to create Schema from \" + aXSDRes + \" using class loader \" + aClassLoader ) ; return ret ; } if ( aClassLoader != null ) { // Don't cache if a class loader is provided return _createSchema ( aClassLoader ) ; } // Lazy initialization if no class loader is present m_aSchema = _createSchema ( aClassLoader ) ;", "del_tokens": "// Lazy initialization final List < ? extends IReadableResource > aXSDRes = getAllXSDResources ( aClassLoader ) ; m_aSchema = XMLSchemaCache . getInstanceOfClassLoader ( aClassLoader ) . getSchema ( aXSDRes ) ; if ( m_aSchema == null ) throw new IllegalStateException ( \"Failed to create Schema from \" + aXSDRes + \" using class loader \" + aClassLoader ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "lightbox", "for", "screenshots", "."], "add_tokens": "for ( File screenshotFile : testNameDir . listFiles ( ) ) { result . screenshots . add ( result . new Screenshot ( screenshotFile ) ) ; }", "del_tokens": "Collections . addAll ( result . screenshots , testNameDir . listFiles ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "big", "where", "first", "event", "was", "not", "being", "added"], "add_tokens": "} if ( ! uniqCalendarDayEvents . contains ( event ) ) { uniqCalendarDayEvents . add ( event ) ;", "del_tokens": "} else { if ( ! uniqCalendarDayEvents . contains ( event ) ) { uniqCalendarDayEvents . add ( event ) ; }", "commit_type": "fix"}
{"commit_tokens": ["added", "MetricsWithCountFilter", "to", "JMX", "reporter"], "add_tokens": "import com . codahale . metrics . * ; import org . stagemonitor . collector . core . metrics . SortedTableLogReporter ; import org . stagemonitor . entities . MeasurementSession ; JmxReporter . forRegistry ( getMetricRegistry ( ) ) . filter ( new MetricsWithCountFilter ( ) ) . build ( ) . start ( ) ;", "del_tokens": "import com . codahale . metrics . JmxReporter ; import com . codahale . metrics . Metered ; import com . codahale . metrics . Metric ; import com . codahale . metrics . MetricFilter ; import com . codahale . metrics . MetricRegistry ; import com . codahale . metrics . SharedMetricRegistries ; import org . stagemonitor . collector . core . metrics . SortedTableLogReporter ; import org . stagemonitor . entities . MeasurementSession ; JmxReporter . forRegistry ( getMetricRegistry ( ) ) . build ( ) . start ( ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "a", "more", "sensible", "test", "function", "name"], "add_tokens": "// $Id: DistributedQueueTest.java,v 1.2 2003/10/15 16:10:02 rds13 Exp $ public void testMultipleWriter ( ) throws Exception", "del_tokens": "// $Id: DistributedQueueTest.java,v 1.1 2003/09/09 01:24:12 belaban Exp $ public void testConcurrent ( ) throws Exception", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "method", "which", "allows", "to", "retrieve", "the", "view", "which", "is", "used", "to", "draw", "a", "separator", "between", "the", "bread", "crumbs", "and", "the", "preferences", "on", "tablets", "."], "add_tokens": "/ * * * The view , which is used to draw a separator between the bread crumbs and * the preferences on devices with a large screen . * / private View breadCrumsSeperator ; * preference header is selected , as an instance of the class * { @ link ViewGroup } or null , if the device has a small screen / * * * Returns the view , which is used to draw a separator between the bread * crumbs and the preferences on devices with a large screen . * * @ return The view , which is used to draw a separator between the bread * crumbs and the preferences , as an instance of the class * { @ link View } or null , if the device has a small display * / public final View getBreadCrumsSeparator ( ) { return breadCrumsSeperator ; } breadCrumsSeperator = findViewById ( R . id . bread_crumbs_separator ) ;", "del_tokens": "* preference header is selected , or null , if the device has a small * screen", "commit_type": "add"}
{"commit_tokens": ["Move", "shared", "link", "auth", "into", "a", "separate", "class"], "add_tokens": "if ( this . api instanceof SharedLinkAPIConnection ) { SharedLinkAPIConnection sharedItemAPI = ( SharedLinkAPIConnection ) this . api ; String sharedLink = sharedItemAPI . getSharedLink ( ) ; String sharedLinkPassword = sharedItemAPI . getSharedLinkPassword ( ) ;", "del_tokens": "String sharedLink = this . api . getSharedLink ( ) ; if ( sharedLink != null ) { String sharedLinkPassword = this . api . getSharedLinkPassword ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "to", "ClassCastException", "when", "using", "JPA"], "add_tokens": "import java . util . HashSet ; import java . util . Set ; private static void recurse ( final Class < ? > iface , final Set < Class < ? > > set ) { if ( set . contains ( iface ) ) return ; set . add ( iface ) ; for ( final Class < ? > extended : iface . getInterfaces ( ) ) recurse ( extended , set ) ; } static Class < ? > [ ] getAllInterfaces ( final Class < ? > cls ) { Class < ? > next = cls ; final Set < Class < ? > > ifaces = new HashSet < > ( ) ; do { for ( final Class < ? > iface : next . getInterfaces ( ) ) recurse ( iface , ifaces ) ; next = next . getSuperclass ( ) ; } while ( next != null ) ; return ifaces . toArray ( new Class [ ifaces . size ( ) ] ) ; } . newProxyInstance ( cls . getClassLoader ( ) , getAllInterfaces ( cls ) , new InvocationHandler ( ) {", "del_tokens": ". newProxyInstance ( cls . getClassLoader ( ) , cls . getInterfaces ( ) , new InvocationHandler ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Remove", "unneccesary", "private", "method", "and", "place", "it", "inline", "with", "the", "sole", "caller", "."], "add_tokens": "state . getDiagnosticBuffer ( ) . append ( tapLine ) ; state . getDiagnosticBuffer ( ) . append ( '\\n' ) ;", "del_tokens": "this . appendTapLineToDiagnosticBuffer ( tapLine ) ; / * * * Appends a diagnostic line to diagnostic buffer . If the diagnostic line * contains -- - or ... then it ignores this line . In the end of each line it * appends a break line . * * @ param diagnosticLine diagnostic line * / private void appendTapLineToDiagnosticBuffer ( String diagnosticLine ) { if ( state . isCurrentlyInYaml ( ) ) { state . getDiagnosticBuffer ( ) . append ( diagnosticLine ) ; state . getDiagnosticBuffer ( ) . append ( '\\n' ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["fix", "Groovy", "IT", "with", "JDK", "5"], "add_tokens": "assertThat ( getProjectMeasure ( \"lines_to_cover\" ) . getValue ( ) , closeTo ( 1668.0 , 5.0 ) ) ;", "del_tokens": "assertThat ( getProjectMeasure ( \"lines_to_cover\" ) . getValue ( ) , is ( 1668.0 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "download", "file", "method", "for", "the", "Dropbox", "API"], "add_tokens": "private WebResource downloadResource ; this ( \"api.podio.com\" , \"upload.podio.com\" , \"download.podio.com\" , 443 , true , false , clientCredentials , userCredentials ) ; public ResourceFactory ( String apiHostname , String uploadHostname , String downloadHostname , int port , boolean ssl , boolean test , this . downloadResource = client . resource ( getURI ( downloadHostname , port , ssl ) ) ; public WebResource getDownloadResource ( String path ) { return getDownloadResource ( path , true ) ; } public WebResource getDownloadResource ( String path , boolean secure ) { WebResource subResource = downloadResource . path ( path ) ; if ( secure ) { subResource . addFilter ( this . apiLoginFilter ) ; } return subResource ; }", "del_tokens": "this ( \"api.podio.com\" , \"upload.podio.com\" , 443 , true , false , clientCredentials , userCredentials ) ; public ResourceFactory ( String apiHostname , String uploadHostname , int port , boolean ssl , boolean test ,", "commit_type": "add"}
{"commit_tokens": ["added", "options", "for", "time", "diff"], "add_tokens": "new SubtitleListTranslatedSubFileReader ( command . getExactMatchTimeDiff ( ) , command . getApproxMatchTimeDiff ( ) ) . readTranslationSubtitles ( s , enF ,", "del_tokens": "new SubtitleListTranslatedSubFileReader ( ) . readTranslationSubtitles ( s , enF ,", "commit_type": "add"}
{"commit_tokens": ["fixed", "synchronization", "issue", "in", "test", "code"], "add_tokens": "import junit . framework . Assert ; private volatile List generatedListeners ; public synchronized List < Object > getAll ( ) { if ( generatedListeners != null ) return generatedListeners ; List listeners = new ArrayList ( requiredSize ) ; listeners . add ( clazz . newInstance ( ) ) ; // if instantiation fails, counts will be incorrect // -> fail early here Assert . fail ( \"There was a problem instantiating a listener \" + e ) ; Collections . shuffle ( listeners ) ; generatedListeners = Collections . unmodifiableList ( listeners ) ; public synchronized void clear ( ) { * * NOTE : Iterator is not perfectly synchronized with mutator methods of the list of generated listeners * In theory , it is possible that the list is changed while iterators are still running which should be avoided . getAll ( ) ;", "del_tokens": "private List generatedListeners ; public List < Object > getAll ( ) { generatedListeners = new ArrayList ( requiredSize ) ; generatedListeners . add ( clazz . newInstance ( ) ) ; e . printStackTrace ( ) ; throw new RuntimeException ( e ) ; Collections . shuffle ( generatedListeners ) ; public void clear ( ) { if ( generatedListeners == null ) getAll ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "some", "of", "the", "paths", "that", "are", "checked", "for", "RW", "as", "they", "were", "causing", "root", "to", "be", "reported", "on", "non", "-", "rooted", "device"], "add_tokens": "//\"/sys\", //\"/proc\", //\"/dev\"", "del_tokens": "\"/sys\" , \"/proc\" , \"/dev\"", "commit_type": "remove"}
{"commit_tokens": ["Made", "the", "Database", "provider", "use", "the", "TranslatedTopicFieldFilter", "instead", "of", "the", "TopicFieldFilter", "."], "add_tokens": "import org . jboss . pressgang . ccms . filter . TranslatedTopicFieldFilter ; CommonFilterConstants . CATEORY_EXTERNAL_LOGIC , CommonFilterConstants . MATCH_LOCALE , new TranslatedTopicFieldFilter ( ) ) ;", "del_tokens": "import org . jboss . pressgang . ccms . filter . TopicFieldFilter ; CommonFilterConstants . CATEORY_EXTERNAL_LOGIC , CommonFilterConstants . MATCH_LOCALE , new TopicFieldFilter ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixing", "gRPC", "code", "to", "work", "with", "new", "Netty", "jar"], "add_tokens": "int streamDependency , short weight , boolean exclusive , int padding , boolean endStream , boolean endSegment ) throws Http2Exception {", "del_tokens": "int padding , boolean endStream , boolean endSegment ) throws Http2Exception { @ Override public void onHeadersRead ( ChannelHandlerContext ctx , int streamId , Http2Headers headers , int streamDependency , short weight , boolean exclusive , int padding , boolean endStream , boolean endSegment ) throws Http2Exception { onHeadersRead ( ctx , streamId , headers , padding , endStream , endSegment ) ; }", "commit_type": "fix"}
{"commit_tokens": ["make", "WAY_POINT_MAX_DISTANCE", "available", "in", "map", "matching", "too"], "add_tokens": "import com . graphhopper . util . Parameters . Routing ; int maxVisitedNodes = Math . min ( getIntParam ( httpReq , Routing . MAX_VISITED_NODES , 3000 ) , 5000 ) ; double wayPointMaxDistance = getDoubleParam ( httpReq , Routing . WAY_POINT_MAX_DISTANCE , 1d ) ; DouglasPeucker peucker = new DouglasPeucker ( ) . setMaxDistance ( wayPointMaxDistance ) ; PathMerger pathMerger = new PathMerger ( ) . setDouglasPeucker ( peucker ) . setSimplifyResponse ( wayPointMaxDistance > 0 ) ; pathMerger . doWork ( matchGHRsp , Collections . singletonList ( path ) , tr ) ;", "del_tokens": "int maxVisitedNodes = Math . min ( getIntParam ( httpReq , \"max_visited_nodes\" , 3000 ) , 5000 ) ; new PathMerger ( ) . doWork ( matchGHRsp , Collections . singletonList ( path ) , tr ) ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "re", "-", "use", "of", "render", "-", "props", "for", "visitor"], "add_tokens": "// @since 4.1.2 - do not reuse render-props (each render call should have own render-props) configuration ) ;", "del_tokens": "final RenderProps renderProps = new RenderPropsImpl ( ) ; configuration , renderProps ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "+", "IT", "for", "MEXEC", "-", "79", ":", "Use", "File", ".", "toURI", "()", ".", "toURL", "()", "when", "adding", "dependencies", "to", "the", "classpath"], "add_tokens": "path . add ( classPathElement . getFile ( ) . toURI ( ) . toURL ( ) ) ; URL url = ( ( File ) it . next ( ) ) . toURI ( ) . toURL ( ) ; path . add ( classPathElement . getFile ( ) . toURI ( ) . toURL ( ) ) ;", "del_tokens": "path . add ( classPathElement . getFile ( ) . toURL ( ) ) ; URL url = ( ( File ) it . next ( ) ) . toURL ( ) ; path . add ( classPathElement . getFile ( ) . toURL ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["changing", "default", "bushwhacker", "rule", "creation", "to", "fail", "if", "it", "can", "t", "parse", "the", "bushwhacker", "rule", "file", ".", "failure", "includes", "handy", "toStrings", "and", "specific", "exceptions"], "add_tokens": "import com . github . steveash . bushwhacker . exception . BushwhackerStartupException ; * See # testRuleFor for an example of how to use bushwhacker in your code Bushwhacker maybeInstance = Holder . defaultInstance ; if ( maybeInstance == null ) { throw Holder . initFailure ; } return maybeInstance ; private static final BushwhackerStartupException initFailure ; BushwhackerStartupException failure ; failure = null ; result = null ; //noinspection ThrowableInstanceNeverThrown failure = new BushwhackerStartupException ( \"Cannot load the Bushwhacker XML file from \" + defaultRulesFileName + \" due to \" + e . getMessage ( ) , e ) ; initFailure = failure ;", "del_tokens": "* if these rules cant be found a warning will be logged and a no - op bushwhacker instance will * be returned . See # testRuleFor for an example of how to use bushwhacker in your code return Holder . defaultInstance ; result = logAndMakeNoOp ( defaultRulesFileName , e ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "more", "TestSubscriber", "unit", "tests"], "add_tokens": "throw new AssertionError ( \"The \" + i + \" th elements differ: expected = \" + valueAndClass ( t2 ) + \", actual = \"", "del_tokens": "throw new AssertionError ( \"The \" + i + \" th elements differ: expected = \" + valueAndClass ( t2 ) + \", actual =\"", "commit_type": "add"}
{"commit_tokens": ["Add", "String", "[]", "tests", "+", "fix"], "add_tokens": "block . addStatement ( \"$N = $N.createStringArray()\" , getName ( ) , in ) ;", "del_tokens": "block . addStatement ( \"$N = $N.readStringArray()\" , getName ( ) , in ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "method", "getRecordCount", "()", "."], "add_tokens": "$ Id : DBFReader . java , v 1.6 2004 - 01 - 08 17 : 50 : 16 anil Exp $ / * * Returns the number of records in the DBF . * / public int getRecordCount ( ) { return this . numberOfRecords ; }", "del_tokens": "$ Id : DBFReader . java , v 1.5 2003 - 10 - 16 07 : 50 : 15 anil Exp $", "commit_type": "add"}
{"commit_tokens": ["make", "sure", "handlers", "using", "marker", "interface", "on", "base", "classes", "are", "called"], "add_tokens": "import java . util . Arrays ; Set < Class < ? > > typeInterfaces = getAllImplementedInterfaces ( sourceType ) ; private Set < Class < ? > > getAllImplementedInterfaces ( final Class < ? > clazz ) { Set < Class < ? > > interfaces = new HashSet < > ( ) ; interfaces . addAll ( Arrays . asList ( clazz . getInterfaces ( ) ) ) ; Class < ? > superclass = clazz . getSuperclass ( ) ; if ( superclass != null ) { interfaces . addAll ( getAllImplementedInterfaces ( superclass ) ) ; } return interfaces ; }", "del_tokens": "Class < ? > [ ] typeInterfaces = sourceType . getInterfaces ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "attribute", "to", "set", "background", "selector", "."], "add_tokens": "private int backgroundSelector ; backgroundSelector = ta . getResourceId ( R . styleable . MaterialSpinner_ms_background_selector , 0 ) ; } else if ( backgroundSelector != 0 ) { setBackgroundResource ( backgroundSelector ) ; adapter = new MaterialSpinnerAdapter < > ( getContext ( ) , items ) . setBackgroundSelector ( backgroundSelector ) . setTextColor ( textColor ) ; this . adapter = new MaterialSpinnerAdapterWrapper ( getContext ( ) , adapter ) . setBackgroundSelector ( backgroundSelector ) . setTextColor ( textColor ) ; this . adapter . setBackgroundSelector ( backgroundSelector ) ;", "del_tokens": "adapter = new MaterialSpinnerAdapter < > ( getContext ( ) , items ) . setTextColor ( textColor ) ; this . adapter = new MaterialSpinnerAdapterWrapper ( getContext ( ) , adapter ) . setTextColor ( textColor ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "xml", "and", "xsl", "mime", "types"], "add_tokens": "\"css\" , \"html\" , \"htm\" , \"txt\" , \"xml\" , \"xsl\" , \"xslt\" , \"csv\" \"json\" , \"js\" , \"pdf\" , \"zip\" , \"jnlp\" , \"swf\" , \"cab\" , \"jar\" , \"ogg\" , \"gzip\" \"mpeg\" , \"mov\" , \"mp4\"", "del_tokens": "\"css\" , \"html\" , \"htm\" , \"txt\" \"json\" , \"js\" , \"pdf\" , \"zip\" , \"jnlp\" , \"swf\" , \"cab\" , \"jar\" \"mpeg\" , \"mov\"", "commit_type": "add"}
{"commit_tokens": ["Added", "columns", "into", "table", "and", "partition", "classes", "as", "there", "are", "no", "back", "references", "to", "table", "/", "partition", "from", "column", "classes"], "add_tokens": "tableRef . set ( \"columns\" , sdStruct . get ( \"cols\" ) ) ; partRef . set ( \"columns\" , sdStruct . get ( \"cols\" ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "forced", "cache", "state", "for", "in", "-", "memory", "lru", "cache"], "add_tokens": "protected final OkHttpInMemoryLruCache _cache ; _cache = new OkHttpInMemoryLruCache ( DEFAULT_CACHE_SIZE ) ; _cache . clearForcedCache ( ) ; _cache . evictAll ( ) ; _cache . clearForcedCache ( ) ; * * * HashMap < String , Object > params , final CallbackWithRetrofit < Prices > callback ) {", "del_tokens": "protected OkHttpInMemoryLruCache _cache = new OkHttpInMemoryLruCache ( DEFAULT_CACHE_SIZE ) ; _cache . evictAll ( ) ; HashMap < String , Object > params , final CallbackWithRetrofit < Prices > callback ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "at", "()", ".", "serve", "()", "style", "configuration", "of", "headless", "web", "services", "."], "add_tokens": "at ( \"/service\" ) . serve ( RestfulWebService . class ) ;", "del_tokens": "at ( \"/service\" ) . show ( RestfulWebService . class ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "jackson", "to", "generate", "json", "object", "from", "build", "info", "object"], "add_tokens": "import org . artifactory . build . api . Agent ; import java . io . IOException ; import static org . testng . Assert . assertTrue ; public void simplestBuildInfoToJSON ( ) throws IOException { buildInfo . setAgent ( new Agent ( \"Hudson\" , \"1.888\" ) ) ; String buildInfoJson = buildInfoDeployer . buildInfoToJsonString ( buildInfo ) ; assertNotNull ( buildInfoJson , \"Got null json result\" ) ; assertTrue ( buildInfoJson . contains ( \"\\\"agent\\\":{\\\"name\\\":\\\"Hudson\\\",\\\"version\\\":\\\"1.888\\\"\" ) , \"Unexpected json result:\" + buildInfoJson ) ;", "del_tokens": "import net . sf . json . JSONObject ; import static org . testng . Assert . assertNull ; public void simplestBuildInfoToJSON ( ) { JSONObject buildInfoJson = buildInfoDeployer . buildInfoToJsonObject ( buildInfo ) ; assertNotNull ( buildInfoJson , \"Got null json object\" ) ; assertNull ( buildInfoJson . get ( \"STARTED_FORMAT\" ) , \"Build info should not contain this public static final field\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Adds", "other", "Geometries", "and", "fixes", "travis", "compilation", "problem", "."], "add_tokens": "String name = in . nextName ( ) ; if ( \"type\" . equals ( name ) ) { type = in . nextString ( ) ; } else if ( \"coordinates\" . equals ( name ) ) { positions = readPosition ( in ) ; } else if ( \"geometries\" . equals ( name ) ) { // TODO } else { // Ignore", "del_tokens": "switch ( in . nextName ( ) ) { case \"type\" : type = in . nextString ( ) ; break ; case \"coordinates\" : positions = readPosition ( in ) ; break ; case \"geometries\" : // TODO break ; default : // Ignore", "commit_type": "add"}
{"commit_tokens": ["fixed", ":", "/", "descendant", "::", "*", "was", "not", "working"], "add_tokens": "results . hit ( node , elementStack ) ; if ( debug )", "del_tokens": "if ( debug ) { }", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "java", "data", "sources", "."], "add_tokens": "this . jdbcConnection = this . getSql2o ( ) . getDataSource ( ) . getConnection ( ) ; throw new RuntimeException ( String . format ( \"Could not aquire a connection from DataSource - \" , ex . getMessage ( ) ) , ex ) ;", "del_tokens": "Properties conProps = new Properties ( ) ; conProps . put ( \"user\" , sql2o . getUser ( ) ) ; conProps . put ( \"password\" , sql2o . getPass ( ) ) ; String url = this . sql2o . getUrl ( ) ; if ( ! url . startsWith ( \"jdbc\" ) ) { url = \"jdbc:\" + url ; } this . jdbcConnection = DriverManager . getConnection ( url , conProps ) ; throw new RuntimeException ( ex ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "firstGPU", "to", "best", "to", "solve", "a", "NPE", "if", "there", "is", "no", "opencl", "gpu", "."], "add_tokens": "Device device = Device . best ( ) ;", "del_tokens": "Device device = Device . firstGPU ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "option", "for", "filtering", "flights", "without", "positions"], "add_tokens": "opts . addOption ( \"0\" , \"nopos\" , false , \"do not include flight without positions\" ) ; boolean option_nopos = true ; if ( cmd . hasOption ( \"0\" ) ) option_nopos = false ; if ( option_nopos | flights . get ( key ) . coords . size ( ) > 0 ) kml . addFlight ( flights . get ( key ) ) ; if ( option_nopos | flights . get ( key ) . coords . size ( ) > 0 ) kml . addFlight ( flights . get ( key ) ) ;", "del_tokens": "kml . addFlight ( flights . get ( key ) ) ; kml . addFlight ( flights . get ( key ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "focusing", "to", "element", "from", "navigator", "panel"], "add_tokens": "import com . igormaznitsa . nbmindmap . model . Topic ; import javax . swing . tree . TreePath ; final MMDEditorSupport edSupport = current . getLookup ( ) . lookup ( MMDEditorSupport . class ) ; if ( edSupport != null ) { edSupport . edit ( ) ; final TreePath path = mindMapTree . getSelectionPath ( ) ; if ( path != null ) { edSupport . focusToPosition ( ( ( Topic ) path . getLastPathComponent ( ) ) . getPositionPath ( ) ) ; }", "del_tokens": "import org . netbeans . api . actions . Openable ; final Openable openable = current . getLookup ( ) . lookup ( Openable . class ) ; if ( openable != null ) { openable . open ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "criteria", "for", "displaying", "a", "failed", "login", "attempt", "message", "."], "add_tokens": "/ * * * Called when channel should output its contents * @ param the servlet request object * @ param the servlet response object * @ param the JspWriter object * / / * * * Called when user clicks this channel 's edit button * @ param the servlet request object * @ param the servlet response object * @ param the JspWriter object * / / * * * Called by this channels render method . Outputs an html form prompting * for user name and password . * @ param the servlet request object * @ param the servlet response object * @ param the JspWriter object * / String sUserName = ( String ) session . getAttribute ( \"userName\" ) ; if ( sUserName != null && sUserName . equals ( \"guest\" ) ) / * * * Called when this channel is redisplayed after an incorrect username / password * is submitted by the user * @ param the servlet request object * @ param the servlet response object * @ param the JspWriter object * / out . print ( \"Invalid user name or password!<br>\" ) ;", "del_tokens": "* String sLogonStatus = ( String ) session . getAttribute ( \"logonStatus\" ) ; if ( sLogonStatus != null && sLogonStatus . equals ( \"true\" ) ) out . print ( \"Invalid user name or password!\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "find", "buildable", "constructor", "utility", "method", "in", "inline", "methods", ".", "Move", "builder", "utils", "in", "its", "own", "class", "."], "add_tokens": "import static io . sundr . builder . internal . utils . BuilderUtils . findBuildableConstructor ; JavaMethod constructor = findBuildableConstructor ( clazz ) ;", "del_tokens": "JavaMethod constructor = clazz . getConstructors ( ) . iterator ( ) . next ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Created", "the", "ResourceNotFoundException", "class", "in", "the", "org", ".", "cp", ".", "elements", ".", "lang", "package", "extending", "java", ".", "lang", ".", "RuntimeException", ".", "Refactored", "the", "ObjectNotFoundException", "and", "TypeNotFoundException", "RuntimeException", "classes", "to", "extend", "the", "ResourceNotFoundException", "class", "instead", ".", "Created", "the", "ImmutableObjectException", "class", "in", "the", "org", ".", "cp", ".", "elements", ".", "lang", "package", "extending", "java", ".", "lang", ".", "RuntimeException", "to", "indicate", "a", "mutable", "operation", "on", "an", "immutable", "object", "."], "add_tokens": "* * * * * The ObjectNotFoundException class is a ResourceNotFoundException indicating that a object could not be found * in Java heap memory . * * @ see org . cp . elements . lang . ResourceNotFoundException public class ObjectNotFoundException extends ResourceNotFoundException { * * *", "del_tokens": "* < p / > * < p / > * < p / > * < p / > * The ObjectNotFoundException class is a RuntimeException indicating that a object could not be found in Java * heap memory . * < p / > * @ see java . lang . RuntimeException public class ObjectNotFoundException extends RuntimeException { * < p / > * < p / > * < p / >", "commit_type": "create"}
{"commit_tokens": ["Added", "new", "methods", "like", "assertLowMemory", "()", "clickOnEditText", "()", "isCheckBoxChecked", "()", "etc", ".", "Also", "made", "many", "changes", "to", "the", "current", "methods", "in", "particular", "the", "search", "methods", "."], "add_tokens": "import android . app . ActivityManager ; } / * * * Asserts that the available memory in the system is not low . * * / public void assertLowMemory ( ) { ActivityManager . MemoryInfo mi = new ActivityManager . MemoryInfo ( ) ; ( ( ActivityManager ) soloActivity . getCurrentActivity ( ) . getSystemService ( \"activity\" ) ) . getMemoryInfo ( mi ) ; Assert . assertFalse ( \"Low memory available: \" + mi . availMem + \" bytes\" , mi . lowMemory ) ; }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Removed", "the", "extra", "logging", "that", "was", "just", "output", "the", "booleans"], "add_tokens": "private void checkForErrors ( List < String > results ) throws MojoExecutionException , MojoFailureException {", "del_tokens": "private void checkForErrors ( List < String > results ) throws MojoExecutionException , MojoFailureException { getLog ( ) . info ( \"jmeterIgnoreError = \" + this . jmeterIgnoreError ) ; getLog ( ) . info ( \"jmeterIgnoreFailure = \" + this . jmeterIgnoreFailure ) ;", "commit_type": "remove"}
{"commit_tokens": ["Changed", "HttpClient", "configuration", "to", "be", "thread", "safe", "."], "add_tokens": "import org . apache . http . impl . conn . PoolingClientConnectionManager ; import org . apache . http . util . EntityUtils ; if ( httpClient == null ) PoolingClientConnectionManager cm = new PoolingClientConnectionManager ( ) ; httpClient = new DefaultHttpClient ( cm ) ; if ( skipValidation ) { log . debug ( \"Configuring HTTPS with no validation\" ) ; SSLSocketFactory sf = new SSLSocketFactory ( getSSLContext ( ) , new AllowAllHostnameVerifier ( ) ) ; Scheme https = new Scheme ( \"https\" , 443 , sf ) ; httpClient . getConnectionManager ( ) . getSchemeRegistry ( ) . register ( https ) ; } if ( obj != null ) writeObject ( obj , post ) ; if ( responseClass == null ) { EntityUtils . consumeQuietly ( response . getEntity ( ) ) ; return null ; }", "del_tokens": "if ( httpClient == null ) if ( skipValidation ) log . debug ( \"Configuring HTTPS with no validation\" ) ; httpClient = new DefaultHttpClient ( ) ; SSLSocketFactory sf = new SSLSocketFactory ( getSSLContext ( ) , new AllowAllHostnameVerifier ( ) ) ; Scheme https = new Scheme ( \"https\" , 443 , sf ) ; httpClient . getConnectionManager ( ) . getSchemeRegistry ( ) . register ( https ) ; else httpClient = new DefaultHttpClient ( ) ; writeObject ( obj , post ) ;", "commit_type": "change"}
{"commit_tokens": ["Fixed", "lastname", "logic", "in", "person"], "add_tokens": "double remainder = Math . abs ( ( number * 1.0d ) / ( divisor * 1.0d ) ) ; double retval = remainder - Math . floor ( remainder ) ; return retval ; double firstNameProbability = getDoubleFromLong ( number , 66767676967l ) ; double lastNameProbability = getDoubleFromLong ( number , 41935324l ) ; LastName nameObject = ( LastName ) getNameObject ( dataUtil . getLastNames ( ) , lastNameProbability * getMax ( dataUtil . getLastNames ( ) ) ) ; double raceProbability = getDoubleFromLong ( number , 21321567657l ) ;", "del_tokens": "double retval = Math . abs ( ( number * 1.0d ) / ( divisor * 1.0d ) ) ; return retval - Math . floor ( retval ) ; double firstNameProbability = getDoubleFromLong ( number , 66767676967l ) ; double lastNameProbability = getDoubleFromLong ( number , 41935324l ) ; LastName nameObject = ( LastName ) getNameObject ( dataUtil . getLastNames ( ) , lastNameProbability ) ; double raceProbability = getDoubleFromLong ( number , 21321567657l ) ;", "commit_type": "fix"}
{"commit_tokens": ["Changed", "AbstractMemoryMappedDataSource", "into", "InMemoryDataSource", "to", "make", "it"], "add_tokens": "import java . sql . Statement ; / * * * Data source which retrieves a JDBC connection from JNDI . * @ since 0.4 * /", "del_tokens": "import java . sql . Statement ;", "commit_type": "change"}
{"commit_tokens": ["Added", "display", "property", "to", "types", "of", "RmModel"], "add_tokens": "import org . openehr . jaxb . rm . ItemStructure ; if ( ItemStructure . class . isAssignableFrom ( rmClass ) ) { node . setDisplay ( RmType . Display . transparent ) ; }", "del_tokens": "import org . openehr . jaxb . rm . DataValue ;", "commit_type": "add"}
{"commit_tokens": ["Make", "defensive", "copies", "of", "the", "see", "also", "and", "other", "lists"], "add_tokens": "import static com . github . therapi . runtimejavadoc . internal . RuntimeJavadocHelper . unmodifiableDefensiveCopy ; this . other = unmodifiableDefensiveCopy ( other ) ; this . seeAlso = unmodifiableDefensiveCopy ( seeAlso ) ;", "del_tokens": "this . other = other ; this . seeAlso = seeAlso ;", "commit_type": "make"}
{"commit_tokens": ["add", "support", "for", "File", "and", "InputStream", "upload", ";", "more", "documentation"], "add_tokens": "static final byte [ ] EMPTY_BYTE_ARRAY = new byte [ 0 ] ; static final Class BYTE_ARRAY_CLASS = EMPTY_BYTE_ARRAY . getClass ( ) ;", "del_tokens": "static final Class BYTE_ARRAY_CLASS = ( new byte [ 0 ] ) . getClass ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "so", "we", "don", "t", "escapeHTML", "unless", "necessary", "for", "the", "server", "side", ".", "This", "allows", "the", "client", "-", "side", "to", "receive", "a", "JS", "hash", "/", "object", "directly", ".", "This", "is", "useful", "depending", "on", "how", "the", "input", "is", "rendered", "."], "add_tokens": "return JSONObject . toJSONString ( params ) ; String tagParams = StringEscapeUtils . escapeHtml ( prepareUploadTagParams ( options ) ) ;", "del_tokens": "return StringEscapeUtils . escapeHtml ( JSONObject . toJSONString ( params ) ) ; String tagParams = prepareUploadTagParams ( options ) ;", "commit_type": "update"}
{"commit_tokens": ["adding", "license", "information", "and", "library", "overview", "to", "the", "project", "files"], "add_tokens": "/ * * Copyright ( C ) 2015 Piotr Wittchen * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "discovery", "engine", "to", "provide", "some", "basic", "information", "on", "the"], "add_tokens": "* / @ Path ( \"/disco/svc\" ) TransformerConfigurationException , IOException , WSDLException , ParserConfigurationException { // plugin = new IMatcherDiscoveryPlugin(connector); // plugins.put(plugin.getName(), plugin); MediaType . APPLICATION_JSON , MediaType . TEXT_XML } ) @ Path ( \"{name}\" ) // Else find discovery plug-in and apply it", "del_tokens": "* / @ Path ( \"/disco/svc/{name}\" ) TransformerConfigurationException , IOException , WSDLException , ParserConfigurationException { // plugin = new IMatcherDiscoveryPlugin(connector); // plugins.put(plugin.getName(), plugin); MediaType . APPLICATION_JSON , MediaType . TEXT_XML } ) // find discovery plug-in", "commit_type": "update"}
{"commit_tokens": ["added", "some", "more", "defaults", "and", "POST", "param", "handling"], "add_tokens": "private String method = \"GET\" ;", "del_tokens": "private String method ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "leading", "/", "in", "classpath", ":", "paths"], "add_tokens": "String path = removeClasspathMarker ( classpath ) ; path = removeLeadingSlash ( path ) ; InputStream fileInputStream = InputStreamUtils . class . getClassLoader ( ) . getResourceAsStream ( path ) ; private static String removeLeadingSlash ( String path ) { if ( path . startsWith ( \"/\" ) ) { return path . substring ( 1 ) ; } return path ; }", "del_tokens": "InputStream fileInputStream = InputStreamUtils . class . getClassLoader ( ) . getResourceAsStream ( removeClasspathMarker ( classpath ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["improved", "markdown", "format", "support", "removed", "commons", "-", "lang"], "add_tokens": "final String newTopicText = Utils . unescapeMarkdownStr ( topicMatcher . group ( 2 ) ) ; out . append ( ' ' ) . append ( Utils . escapeMarkdownStr ( this . text ) ) . append ( NEXT_LINE ) ;", "del_tokens": "final String newTopicText = Utils . unescapeHtmlStr ( topicMatcher . group ( 2 ) ) ; out . append ( ' ' ) . append ( Utils . escapeHtmlStr ( this . text ) ) . append ( NEXT_LINE ) ;", "commit_type": "improve"}
{"commit_tokens": ["Adds", "javadoc", "to", "the", "newly", "created", "method"], "add_tokens": "/ * * * Parses and consumes selector prefixes which add pseudo - classes ( '&:' ) or pseudo - elements ( '&::' ) to an existing selector , * Arguments on pseudo classes like '&:not(.class)' are also parsed and consumed . * For valid input like e . g . '&::after' , '&:first-child' , '&:not(.class)' two selectors are added to the given List : * 1. '&' * 2. the pseudo - class / element e . g . '::after' , ':first-child' , ':not(.class)' * * @ param selector the List to which the selectors are added . * / String pseudoOperator = tokenizer . current ( ) . getSource ( ) . substring ( 1 ) ; // Consume arguments like :nth-child(2)", "del_tokens": "String pseudoOperator = tokenizer . current ( ) . getSource ( ) . substring ( 1 ) ; // either : or ::", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "extracted", "metadata", "from", "Tika"], "add_tokens": "private boolean rawMetadata ; private boolean rawMetadata = true ; public Builder setRawMetadata ( boolean rawMetadata ) { this . rawMetadata = rawMetadata ; return this ; } removeDeleted , storeSource , indexedChars , indexContent , attributesSupport , rawMetadata ) ; boolean indexContent , boolean attributesSupport , boolean rawMetadata ) { this . rawMetadata = rawMetadata ; public boolean isRawMetadata ( ) { return rawMetadata ; } public void setRawMetadata ( boolean rawMetadata ) { this . rawMetadata = rawMetadata ; } if ( rawMetadata != fs . rawMetadata ) return false ; result = 31 * result + ( rawMetadata ? 1 : 0 ) ;", "del_tokens": "removeDeleted , storeSource , indexedChars , indexContent , attributesSupport ) ; boolean indexContent , boolean attributesSupport ) {", "commit_type": "add"}
{"commit_tokens": ["Adding", "first", "test", "for", "the", "native", "api", "."], "add_tokens": "static URL findLibraryResource ( String library ) throws UnsupportedOperationException { static String saveLibrary ( File dir , String library ) throws IOException {", "del_tokens": "private static URL findLibraryResource ( String library ) throws UnsupportedOperationException { private static String saveLibrary ( File dir , String library ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["change", "password", "with", ".", "ftl"], "add_tokens": "import javax . ws . rs . core . Response ; @ Consumes ( MediaType . TEXT_HTML ) @ Consumes ( MediaType . APPLICATION_FORM_URLENCODED ) public Response consumeTicket ( @ FormParam ( \"ticketOid\" ) String tickedOid , @ FormParam ( \"newPassword\" ) String newPassword , @ FormParam ( \"newPasswordConfirm\" ) String newPasswordConfirm ) { // Preconditions.checkNotNull(tickedOid); // Ticket ticket = ticketDao.findById(tickedOid); // Preconditions.checkNotNull(ticket); return Response . status ( 200 ) . entity ( \"ticketOid : \" + tickedOid + \" newPassword : \" + newPassword + \" newPasswordConfirm : \" + newPasswordConfirm ) . build ( ) ;", "del_tokens": "@ Consumes ( MediaType . APPLICATION_JSON ) @ Path ( \"{ticketOid}\" ) public void consumeTicket ( @ PathParam ( \"ticketOid\" ) String tickedOid ) { Preconditions . checkNotNull ( tickedOid ) ; Ticket ticket = ticketDao . findById ( tickedOid ) ; Preconditions . checkNotNull ( ticket ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "DelegatingProgressBarConsumer", "and", "create", "a", "log4j", "test", "as", "example", "implementation"], "add_tokens": "/ * * * Progress bar consumer that prints the progress bar state to console . * By default { @ link System # err } is used as { @ link PrintStream } * / this ( out , DEFAULT_CONSOLE_WIDTH ) ;", "del_tokens": "this ( System . err , DEFAULT_CONSOLE_WIDTH ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "deep", "core", "and", "refactor", "to", "avoid", "compilation", "errors"], "add_tokens": "import com . stratio . deep . config . ICassandraDeepJobConfig ; private ICassandraDeepJobConfig < Cells > auditCassandraConfig ;", "del_tokens": "import com . stratio . deep . config . IDeepJobConfig ; private IDeepJobConfig < Cells > auditCassandraConfig ;", "commit_type": "update"}
{"commit_tokens": ["added", "user", "-", "agent", "to", "all", "dnsapi", "calls"], "add_tokens": "request . getHeaders ( ) . setUserAgent ( \"DNSAPI-Java-Client\" ) ; request . getHeaders ( ) . set ( \"X-Auth-Token\" , this . getDnsapi ( ) . requestToken ( ) ) ;", "del_tokens": "HttpHeaders headers = new HttpHeaders ( ) ; headers . set ( \"X-Auth-Token\" , this . getDnsapi ( ) . requestToken ( ) ) ; request . setHeaders ( headers ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "the", "endless", "loop", "situation", "by", "rewriting", "rules", "starting", "with", "testNot", ".", "This", "means", "the", "earlier", "workaround", "to", "make", "[", "non", "-", "enforced", "for", "array", "access", "has", "been", "undone", "."], "add_tokens": "import org . parboiled . ActionResult ; public Node createIdentifier ( String text ) { return text == null ? new Identifier ( ) : new Identifier ( ) . setName ( text ) ; } public ActionResult checkIfKeyword ( String text ) { if ( text == null ) return ActionResult . CONTINUE ; return BasicsParser . KEYWORDS . contains ( text ) ? ActionResult . CANCEL_MATCH : ActionResult . CONTINUE ;", "del_tokens": "import java . util . List ; public Node createIdentifier ( String text , List < String > texts ) { StringBuilder s = new StringBuilder ( 1 + ( texts == null ? 0 : texts . size ( ) ) ) ; if ( text != null ) s . append ( text ) ; if ( texts != null ) for ( String p : texts ) { if ( p != null ) s . append ( p ) ; } return new Identifier ( ) . setName ( s . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "option", "to", "include", "locale", "in", "Properties", "filenames", "(", "eg", "messages_fr", ".", "properties", ")", "."], "add_tokens": "import java . io . BufferedOutputStream ; import java . io . FileOutputStream ; private String locale = null ; public void setLocale ( String locale ) { this . locale = locale ; } String localeSuffix ; if ( locale == null ) localeSuffix = \"\" ; else localeSuffix = \"_\" + locale ; String basename = poFilename . substring ( 0 , poFilename . length ( ) - \".po\" . length ( ) ) ; String propFilename = basename + localeSuffix + \".properties\" ; BufferedOutputStream out = new BufferedOutputStream ( new FileOutputStream ( propFile ) ) ;", "del_tokens": "import java . io . BufferedWriter ; import java . io . FileWriter ; String propFilename = poFilename . substring ( 0 , poFilename . length ( ) - \"po\" . length ( ) ) + \"properties\" ; BufferedWriter out = new BufferedWriter ( new FileWriter ( propFile ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "new", "log", "levels", "VERBOSE", "=", "200", "and", "DEBUG", "=", "100"], "add_tokens": "log . debug ( \"get recycled %s\" , recyclable ) ; log . debug ( \"create new recycled %s\" , recyclable ) ; log . debug ( \"put to recycle queue %s\" , recyclable ) ; log . debug ( \"recycled %s\" , recyclable ) ;", "del_tokens": "log . finest ( \"get recycled %s\" , recyclable ) ; log . finest ( \"create new recycled %s\" , recyclable ) ; log . finest ( \"put to recycle queue %s\" , recyclable ) ; log . finest ( \"recycled %s\" , recyclable ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "simple", "page", "check", "to", "main"], "add_tokens": "options . addOption ( \"s\" , \"size\" , true , \"Browser screen size\" ) ; galen . setScreenSize ( convertScreenSize ( cmd . getOptionValue ( \"s\" ) ) ) ;", "del_tokens": "private String spec ; public GalenArguments withSpec ( String spec ) { this . setSpec ( spec ) ; return this ; } public String getSpec ( ) { return spec ; } public void setSpec ( String spec ) { this . spec = spec ; } options . addOption ( \"d\" , \"size\" , true , \"Browser screen size\" ) ; options . addOption ( \"s\" , \"spec\" , true , \"Path for page specifications file\" ) ; galen . setScreenSize ( convertScreenSize ( cmd . getOptionValue ( \"d\" ) ) ) ; galen . setSpec ( cmd . getOptionValue ( \"s\" ) ) ; . append ( spec ) . append ( spec , rhs . spec ) . append ( \"spec\" , spec )", "commit_type": "add"}
{"commit_tokens": ["Updated", "number", "exceptions", "to", "indicate", "what", "the", "source", "of", "the", "error", "was", "."], "add_tokens": "badValue ( \"0x\" ) ; badValue ( \"-0x\" ) ; badValue ( \"-0b\" ) ; badValue ( \"0b\" ) ;", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Added", "MySQL", "Oracle", "and", "PostgreSQL", "integration", "tests", "."], "add_tokens": "@ Override protected String getUrl ( ) { return \"jdbc:h2:target/\" + getDatabaseName ( ) ; } getConnection ( ) . close ( ) ;", "del_tokens": "import java . sql . Connection ; import java . sql . DriverManager ; DriverManager . getConnection ( \"jdbc:h2:target/\" + getDatabaseName ( ) ) . close ( ) ; / * * * @ see liquibase . ext . spatial . LiquibaseIT # getConnection ( ) * / @ Override protected Connection getConnection ( ) throws SQLException { return DriverManager . getConnection ( \"jdbc:h2:target/\" + getDatabaseName ( ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["fix", "spring_web", "aop", "no", "such", "method", "found", "exception"], "add_tokens": "import org . springframework . util . ReflectionUtils ; import java . lang . reflect . Method ; Method method = ReflectionUtils . findMethod ( pjp . getTarget ( ) . getClass ( ) , name , parameterTypes ) ; return AnnotationUtils . findAnnotation ( method , PrometheusTimeMethod . class ) ;", "del_tokens": "return AnnotationUtils . findAnnotation ( pjp . getTarget ( ) . getClass ( ) . getDeclaredMethod ( name , parameterTypes ) , PrometheusTimeMethod . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "StringBuilder", "instead", "of", "string", "concatenation", "(", "enhance", "batch", "reporter", "performance", "by", "about", "15%", ")"], "add_tokens": "StringBuilder stringBuilder = new StringBuilder ( ) ; rejectedRecordsReporter . info ( stringBuilder . append ( \"Record #\" ) . append ( record . getNumber ( ) ) . append ( \" [\" ) . append ( record . getContentAsString ( ) ) . append ( \"] is rejected, Error : \" ) . append ( error ) . toString ( ) ) ; StringBuilder stringBuilder = new StringBuilder ( ) ; ignoredRecordsReporter . info ( stringBuilder . append ( \"Record #\" ) . append ( recordNumber ) . append ( \" [\" ) . append ( record ) . append ( \"] is ignored, Error : \" ) . append ( error ) . toString ( ) ) ;", "del_tokens": "rejectedRecordsReporter . info ( \"Record #\" + record . getNumber ( ) + \" [\" + record . getContentAsString ( ) + \"] is rejected, Error : \" + error ) ; ignoredRecordsReporter . info ( \"Record #\" + recordNumber + \" [\" + record + \"] is ignored, Error : \" + error ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "jts", "version", "use", "the", "same", "as", "h2"], "add_tokens": "import org . h2 . value . ValueGeometry ; public static byte [ ] toBytes ( ValueGeometry geometry ) { return geometry . getBytes ( ) ;", "del_tokens": "import com . vividsolutions . jts . geom . Geometry ; import org . h2gis . h2spatial . ValueGeometry ; public static byte [ ] toBytes ( Geometry geometry ) { return new ValueGeometry ( geometry ) . getBytesNoCopy ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "instructions", "for", "variable", "col", "/", "row", "span"], "add_tokens": "// Swap the next 2 lines to have items with variable // column/row span. // int rowSpan = Math.random() < 0.2f ? 2 : 1; int rowSpan = colSpan ; final DemoItem item = new DemoItem ( colSpan , rowSpan , currentOffset + i ) ;", "del_tokens": "int rowSpan = Math . random ( ) < 0.2f ? 2 : 1 ; final DemoItem item = new DemoItem ( colSpan , colSpan , currentOffset + i ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "problem", "with", "URI", "handling", "."], "add_tokens": "// Step 1: determine the correct URI of the request. String uri = this . urlPathHelper . getLookupPathForRequest ( request ) ;", "del_tokens": "// Step 1: determine the name of the controller. // This maps to a slash + the name of the controller. String uri = this . urlPathHelper . getRequestUri ( request ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "Groovy", "IT", "with", "JDK", "5"], "add_tokens": "assertThat ( \"coverage\" , getProjectMeasure ( \"coverage\" ) . getValue ( ) , closeTo ( 89.5 , 0.2 ) ) ; assertThat ( getProjectMeasure ( \"line_coverage\" ) . getValue ( ) , closeTo ( 98.8 , 0.2 ) ) ; assertThat ( getPackageMeasure ( \"coverage\" ) . getValue ( ) , closeTo ( 88.3 , 0.2 ) ) ; assertThat ( getPackageMeasure ( \"line_coverage\" ) . getValue ( ) , closeTo ( 99.6 , 0.2 ) ) ; assertThat ( getFileMeasure ( \"coverage\" ) . getValue ( ) , closeTo ( 86.5 , 0.2 ) ) ;", "del_tokens": "assertThat ( \"coverage\" , getProjectMeasure ( \"coverage\" ) . getValue ( ) , closeTo ( 89.5 , 0.1 ) ) ; assertThat ( getProjectMeasure ( \"line_coverage\" ) . getValue ( ) , closeTo ( 98.8 , 0.1 ) ) ; assertThat ( getPackageMeasure ( \"coverage\" ) . getValue ( ) , closeTo ( 88.3 , 0.1 ) ) ; assertThat ( getPackageMeasure ( \"line_coverage\" ) . getValue ( ) , closeTo ( 99.6 , 0.1 ) ) ; assertThat ( getFileMeasure ( \"coverage\" ) . getValue ( ) , closeTo ( 86.5 , 0.1 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "more", "functionality", "to", "ListChangeAccumulator", "."], "add_tokens": "import javafx . collections . ObservableList ; ObservableList < ? extends E > getList ( ) ; private final ObservableList < ? extends E > list ; TransientListChangeImpl ( ObservableList < ? extends E > list , int from , int to , List < ? extends E > removed ) { public ObservableList < ? extends E > getList ( ) {", "del_tokens": "List < ? extends E > getList ( ) ; private final List < ? extends E > list ; TransientListChangeImpl ( List < ? extends E > list , int from , int to , List < ? extends E > removed ) { public List < ? extends E > getList ( ) {", "commit_type": "move"}
{"commit_tokens": ["Made", "it", "so", "path", "params", "at", "the", "class", "level", "propogate", "to", "the", "method", "level"], "add_tokens": "params [ paramIndex ] = mm . pathParams . get ( paramName ) ;", "del_tokens": "params [ paramIndex ] = mm . pathMatch . params ( ) . get ( paramName ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "custom", "profiles", "by", "selector", "property", "file", "and", "system", "property", "."], "add_tokens": "NONE ( null ) , BASIC ( \"_TraceeContextLoggerBasicProfile.properties\" ) , ENHANCED ( \"_TraceeContextLoggerEnhancedProfile.properties\" ) , FULL ( \"_TraceeContextLoggerFullProfile.properties\" ) ; private final String filename ; Profile ( final String filename ) { this . filename = filename ; } public String getFilename ( ) { return this . filename ; }", "del_tokens": "NONE ( null ) , BASIC ( \"TraceeContextLoggerBasicProfile.properties\" ) , ENHANCED ( \"TraceeContextLoggerEnhancedProfile.properties\" ) , FULL ( \"TraceeContextLoggerFullProfile.properties\" ) ; private final String filename ; Profile ( final String filename ) { this . filename = filename ; } public String getFilename ( ) { return this . filename ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "debug", "and", "explicitly", "specified", "UTF", "-", "8", "character", "set", "when", "creating", "MD5", "hashes", "and", "Base64", "encoded", "strings", "."], "add_tokens": "return DatatypeConverter . printHexBinary ( digest . digest ( content . getBytes ( \"UTF-8\" ) ) ) . toLowerCase ( ) ;", "del_tokens": "return DatatypeConverter . printHexBinary ( digest . digest ( content . getBytes ( ) ) ) . toLowerCase ( ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "cloudmade", "downloads", "use", "all", "three", "servers"], "add_tokens": "CLOUDMADESMALLTILES ( ResourceProxy . string . cloudmade_small , \".png\" , 0 , 13 , 6 , CodeScheme . CLOUDMADE , \"http://a.tile.cloudmade.com/%s/1/64/%d/%d/%d%s?token=%s\" , \"http://b.tile.cloudmade.com/%s/1/64/%d/%d/%d%s?token=%s\" , \"http://c.tile.cloudmade.com/%s/1/64/%d/%d/%d%s?token=%s\" ) , CLOUDMADESTANDARDTILES ( ResourceProxy . string . cloudmade_standard , \".png\" , 0 , 18 , 8 , CodeScheme . CLOUDMADE , \"http://a.tile.cloudmade.com/%s/1/256/%d/%d/%d%s?token=%s\" , \"http://b.tile.cloudmade.com/%s/1/256/%d/%d/%d%s?token=%s\" , \"http://c.tile.cloudmade.com/%s/1/256/%d/%d/%d%s?token=%s\" ) ;", "del_tokens": "CLOUDMADESMALLTILES ( ResourceProxy . string . cloudmade_small , \".png\" , 0 , 13 , 6 , CodeScheme . CLOUDMADE , \"http://tile.cloudmade.com/%s/2/64/%d/%d/%d%s?token=%s\" ) , CLOUDMADESTANDARDTILES ( ResourceProxy . string . cloudmade_standard , \".png\" , 0 , 18 , 8 , CodeScheme . CLOUDMADE , \"http://tile.cloudmade.com/%s/2/256/%d/%d/%d%s?token=%s\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "the", "spring", "bean", "def", "file", "name"], "add_tokens": "springConfigLocation = \"spring/senbot-runner-beans.xml\" ;", "del_tokens": "springConfigLocation = \"cucumber.xml\" ;", "commit_type": "change"}
{"commit_tokens": ["added", "color", "tinting", "for", "action", "menu"], "add_tokens": "/ * * * Sets the clear button 's color. * * @ param color the color to be applied to the * clear button . * / public void setClearBtnColor ( int color ) { DrawableCompat . setTint ( mIconClear , color ) ; } if ( mMenuView != null ) mMenuView . setActionIconColor ( color ) ; * Sets the action menu overflow icon 's color. * overflow icon . public void setActionMenuOverflowColor ( int color ) { if ( mMenuView != null ) mMenuView . setOverflowColor ( color ) ;", "del_tokens": "* Sets the clear button 's color. * clear button . public void setClearBtnColor ( int color ) { DrawableCompat . setTint ( mIconClear , color ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "PersistentDateTimeWithZone", "to", "replace", "previous", "PersistentDateTime", ".", "New", "PersistentDateTime", "class", "persists", "to", "a", "single", "column", "without", "zone", "."], "add_tokens": "private static final LocalDateTime [ ] localDateTimes = new LocalDateTime [ ] { new LocalDateTime ( 2004 , 2 , 25 , 12 , 11 , 10 ) , new LocalDateTime ( 1980 , 3 , 11 , 13 , 12 , 11 ) } ; private static final LocalDateTime [ ] jodaLocalDateTimes = new LocalDateTime [ ] { new LocalDateTime ( 2004 , 2 , 25 , 12 , 11 , 10 ) , new LocalDateTime ( 1980 , 3 , 11 , 13 , 12 , 11 ) } ;", "del_tokens": "private static final LocalDateTime [ ] localDateTimes = new LocalDateTime [ ] { new LocalDateTime ( 2004 , 2 , 25 , 12 , 11 , 10 ) , new LocalDateTime ( 1980 , 3 , 11 , 13 , 12 , 11 ) } ; private static final org . joda . time . LocalDateTime [ ] jodaLocalDateTimes = new org . joda . time . LocalDateTime [ ] { new org . joda . time . LocalDateTime ( 2004 , 2 , 25 , 12 , 11 , 10 ) , new org . joda . time . LocalDateTime ( 1980 , 3 , 11 , 13 , 12 , 11 ) } ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "some", "new", "HQL", "operations"], "add_tokens": "protected abstract void visit ( AliasNoEntity < ? > expr ) ; protected abstract void visit ( OperationNoArg < ? , ? > expr ) ; protected abstract void visit ( PathEntityCollection < ? > expr ) ;", "del_tokens": "protected abstract void visit ( AliasNoEntity < ? > expr ) ; protected abstract void visit ( PathEntityCollection < ? > expr ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "the", "initial", "values", "of", "Dnd", "component", "."], "add_tokens": "private double right = 1 ; private double bottom = 1 ;", "del_tokens": "private double right = 0 ; private double bottom = 0 ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "fallback", "time", "between", "retries"], "add_tokens": "import org . apache . commons . lang3 . ObjectUtils ; this ( DEFAULT_NUMBER_OF_RETRIES , null , task ) ; this ( numberOfRetries , null , task ) ; this . timeToWait = ObjectUtils . defaultIfNull ( timeToWait , DEFAULT_WAIT_TIME ) ;", "del_tokens": "this ( DEFAULT_NUMBER_OF_RETRIES , DEFAULT_WAIT_TIME , task ) ; this ( numberOfRetries , DEFAULT_WAIT_TIME , task ) ; this . timeToWait = timeToWait ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "refresh", "indicator", "appears", "too", "early", "when", "scroll", "from", "outside", "of", "top", "or", "bottom", "edge", "."], "add_tokens": "private float mInitialDownY ; final float initialDownY = getMotionEventY ( ev , mActivePointerId ) ; if ( initialDownY == - 1 ) { mInitialDownY = initialDownY ; if ( y > mInitialDownY ) { } else if ( y < mInitialDownY ) { mInitialDownY = y ; yDiff = mInitialDownY - y ; yDiff = y - mInitialDownY ; switch ( mDirection ) { case BOTTOM : mInitialMotionY = mInitialDownY - mTouchSlop ; break ; case TOP : default : mInitialMotionY = mInitialDownY + mTouchSlop ; break ; }", "del_tokens": "final float initialMotionY = getMotionEventY ( ev , mActivePointerId ) ; if ( initialMotionY == - 1 ) { mInitialMotionY = initialMotionY ; if ( y > mInitialMotionY ) { } else if ( y < mInitialMotionY ) { yDiff = mInitialMotionY - y ; yDiff = y - mInitialMotionY ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "https", ":", "//", "github", ".", "com", "/", "couchbase", "/", "couchbase", "-", "lite", "-", "android", "/", "issues", "/", "952"], "add_tokens": "// Somewhat of a hack: There probably won't be a file at the exact _path because ForestDB // likes to append \".0\" etc., but there will be a file with a \".meta\" extension: File metaFile = new File ( this . _path + \".meta\" ) ; if ( ! metaFile . exists ( ) ) { // NOTE: .0, .1, etc is created by forestdb if auto compact is enabled. // renaming forestdb file name with .0 etc with different name could cause problem. // Following migration could work because forestdb filename is without .0 etc. // Once filename has .0 etc, do not rename file. File file = new File ( this . _path ) ;", "del_tokens": "File file = new File ( this . _path ) ; if ( ! file . exists ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Use", "manual", "vehicle", "data", "source", "by", "default", "."], "add_tokens": "import com . openxc . remote . sources . ManualVehicleDataSource ; import android . os . Bundle ; private final static String DEFAULT_DATA_SOURCE = ManualVehicleDataSource . class . getName ( ) ; Bundle extras = intent . getExtras ( ) ; String dataSource = DEFAULT_DATA_SOURCE ; String resource = null ; if ( extras != null ) { dataSource = intent . getExtras ( ) . getString ( DATA_SOURCE_NAME_EXTRA ) ; resource = intent . getExtras ( ) . getString ( DATA_SOURCE_RESOURCE_EXTRA ) ; }", "del_tokens": "String dataSource = intent . getExtras ( ) . getString ( DATA_SOURCE_NAME_EXTRA ) ; String resource = intent . getExtras ( ) . getString ( DATA_SOURCE_RESOURCE_EXTRA ) ;", "commit_type": "use"}
{"commit_tokens": ["Removed", "all", ".", "replace", "(", "\\", ")", "in", "InPlaceApplyProcessor", "."], "add_tokens": "String cleanPath = path . asText ( ) ; builder . delete ( 0 , builder . length ( ) ) ;", "del_tokens": "String cleanPath = path . toString ( ) . replaceAll ( \"\\\"\" , \"\" ) ; builder . delete ( 0 , builder . length ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "the", "LICENSE", "trait", "."], "add_tokens": "WEBSITE ( \"${library}.website\" ) , / * * * The library license ( GPL , EUPL , FreeBSD ... ) . * / LICENSE ( \"${library}.license\" ) ;", "del_tokens": "WEBSITE ( \"${library}.website\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "validation", "of", "empty", "json"], "add_tokens": "if ( payload != null && payload . size ( ) != 0 ) {", "del_tokens": "if ( payload != null ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "integration", "test", "for", "TopicBrowser", "and", "spring", "APIs"], "add_tokens": "'\"' , ',' , ';' , '/' , '?' , '[' , ']' , '<' , '>' , '.' , ':' , ' ' } ; MessageConsumer consumer = this . createConsumer ( new ConsumerConfig ( \"Just_for_Browser\" ) ) ;", "del_tokens": "'\"' , ',' , ';' , '/' , '?' , '[' , ']' , '<' , '>' , '.' , ':' } ; MessageConsumer consumer = this . createConsumer ( new ConsumerConfig ( \"just for topic browser\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "test", "for", "Database", "s", "toString", "()", "."], "add_tokens": "assertEquals ( \"Database [dialect=\" + new PostgreSQLDialect ( ) . toString ( ) + \", allowImplicitTransactions=true, defaultIsolation=READ_UNCOMMITTED, defaultPropagation=DEFAULT]\" , db . toString ( ) ) ;", "del_tokens": "assertEquals ( \"Database [dialect=\" + new PostgreSQLDialect ( ) . toString ( ) + \", allowImplicitTransactions=true, defaultIsolation=READ_UNCOMMITTED]\" , db . toString ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Use", "a", "_default_", "mapping", "instead", "of", "going", "per", "type"], "add_tokens": "json . writeObjectFieldStart ( \"_default_\" ) ; json . writeObjectFieldStart ( \"_all\" ) ; json . writeBooleanField ( \"enabled\" , false ) ; json . writeEndObject ( ) ; json . writeObjectFieldStart ( \"properties\" ) ; json . writeObjectFieldStart ( \"name\" ) ; json . writeObjectField ( \"type\" , \"string\" ) ; json . writeObjectField ( \"index\" , \"not_analyzed\" ) ; json . writeEndObject ( ) ; json . writeEndObject ( ) ; json . writeEndObject ( ) ;", "del_tokens": "// PER TYPE String [ ] types = new String [ ] { \"timer\" , \"counter\" , \"meter\" , \"gauge\" , \"histogram\" } ; for ( String type : types ) { json . writeObjectFieldStart ( type ) ; json . writeObjectFieldStart ( \"_all\" ) ; json . writeBooleanField ( \"enabled\" , false ) ; json . writeEndObject ( ) ; json . writeObjectFieldStart ( \"properties\" ) ; json . writeObjectFieldStart ( \"name\" ) ; json . writeObjectField ( \"type\" , \"string\" ) ; json . writeObjectField ( \"index\" , \"not_analyzed\" ) ; json . writeEndObject ( ) ; json . writeEndObject ( ) ; json . writeEndObject ( ) ; }", "commit_type": "use"}
{"commit_tokens": ["fixing", "bug", "in", "copy", "operation", "and", "added", "test", "cases", "for", "it"], "add_tokens": "if ( matchingValuePath != null && ! isSame ( matchingValuePath , diff . getPath ( ) ) ) { private static boolean isSame ( List < Object > source , List < Object > destination ) { return source . equals ( destination ) ; }", "del_tokens": "if ( matchingValuePath != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "unit", "test", "(", "botched", "merge", ")"], "add_tokens": "", "del_tokens": "<< << << < HEAD public void testOrdinal ( ) { == == == = >>> >>> > b3b0bf34d842ad7be8b2cc16ae51a36612ab516c", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "faster", "map", "for", "property", "deserializers"], "add_tokens": "private final SimpleStringMap < BeanPropertyDeserializer < T , ? > > deserializers = SimpleStringMap . createObject ( ) . cast ( ) ; private final SimpleStringMap < BackReferenceProperty < T , ? > > backReferenceDeserializers = SimpleStringMap . createObject ( ) . cast ( ) ;", "del_tokens": "import java . util . LinkedHashMap ; private final Map < String , BeanPropertyDeserializer < T , ? > > deserializers = new LinkedHashMap < String , BeanPropertyDeserializer < T , ? > > ( ) ; private final Map < String , BackReferenceProperty < T , ? > > backReferenceDeserializers = new LinkedHashMap < String , BackReferenceProperty < T , ? > > ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "provision", "methods", "to", "thrown", "any", "ServiceBrokerException", "."], "add_tokens": "ServiceInstance create ( CreateRequest request ) throws ServiceBrokerException ; void delete ( String instanceId ) throws ServiceBrokerException ; ServiceBinding bind ( BindRequest request ) throws ServiceBrokerException ; void unbind ( String instanceId , String bindingId ) throws ServiceBrokerException ;", "del_tokens": "ServiceInstance create ( CreateRequest request ) ; void delete ( String instanceId ) throws ResourceNotFoundException ; ServiceBinding bind ( BindRequest request ) throws ResourceNotFoundException ; void unbind ( String instanceId , String bindingId ) throws ResourceNotFoundException ;", "commit_type": "allow"}
{"commit_tokens": ["Adding", "support", "for", "XML", "generation"], "add_tokens": "import java . io . File ; import java . io . FileNotFoundException ; import java . io . FileOutputStream ; import net . sf . mardao . api . dao . DaoImpl ; import org . xml . sax . SAXException ; public void setup ( ) throws SAXException , FileNotFoundException { final File dest = new File ( \"UberDaoBeans.xml\" ) ; DaoImpl . xmlGenerateEntities ( dest , bookDao , chapterDao , pageDao , footnoteDao ) ;", "del_tokens": "public void setup ( ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "0", "width", "/", "height", "issue", "in", "VectorDrawable"], "add_tokens": "int width = getBounds ( ) . width ( ) ; int height = getBounds ( ) . height ( ) ; if ( width <= 0 || height <= 0 ) return ; bitmap = Bitmap . createBitmap ( width , height , Bitmap . Config . ARGB_8888 ) ;", "del_tokens": "bitmap = Bitmap . createBitmap ( getBounds ( ) . width ( ) , getBounds ( ) . height ( ) , Bitmap . Config . ARGB_8888 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "some", "issues", "with", "non", "-", "persistent", "connections"], "add_tokens": "if ( response == null ) { private static class FileWriteTask implements Runnable , ChannelListener < StreamSinkChannel > { channel . suspendWrites ( ) ;", "del_tokens": "if ( response == null ) { private class FileWriteTask implements Runnable , ChannelListener < StreamSinkChannel > { channel . suspendWrites ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "CheckBox", "attires", "and", "Improve", "widget", "size"], "add_tokens": "* < p / > * < p / >", "del_tokens": "* < p > * < p >", "commit_type": "change"}
{"commit_tokens": ["added", "SortedVertexDegree", "which", "uses", "MapReduces", "shuffle", "and", "sort", "to", "order", "the", "vertices", "by", "degree", "."], "add_tokens": "//System.out.println(results);", "del_tokens": "System . out . println ( results ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "broken", "testcases", "due", "to", "shifting", "penalty", "support"], "add_tokens": "import org . drools . solver . core . score . comparator . NaturalScoreComparator ; public void testPickMoveMaxScoreOfAll ( ) { StepScope stepScope = createStepScope ( localSearchSolverScope ) ; public void testPickMoveFirstBestScoreImproving ( ) { StepScope stepScope = createStepScope ( localSearchSolverScope ) ; public void testPickMoveFirstLastStepScoreImproving ( ) { StepScope stepScope = createStepScope ( localSearchSolverScope ) ; public void testPickMoveRandomly ( ) { StepScope stepScope = createStepScope ( localSearchSolverScope ) ; private StepScope createStepScope ( LocalSearchSolverScope localSearchSolverScope ) { StepScope stepScope = new StepScope ( localSearchSolverScope ) ; stepScope . setDeciderScoreComparator ( new NaturalScoreComparator ( ) ) ; return stepScope ; }", "del_tokens": "public void FIXME_testPickMoveMaxScoreOfAll ( ) { StepScope stepScope = new StepScope ( localSearchSolverScope ) ; public void FIXME_testPickMoveFirstBestScoreImproving ( ) { StepScope stepScope = new StepScope ( localSearchSolverScope ) ; public void FIXME_testPickMoveFirstLastStepScoreImproving ( ) { StepScope stepScope = new StepScope ( localSearchSolverScope ) ; public void FIXME_testPickMoveRandomly ( ) { StepScope stepScope = new StepScope ( localSearchSolverScope ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "up", "broken", "assertions", "on", "assertions"], "add_tokens": "Matchable < T > tMatchable = new Matchable < T > ( val , shouldBe , context + \".shouldBe(\" + shouldBe + \")\" , true ) ; tMatchable . match ( ) ; return tMatchable ; Matchable < T > tMatchable = new Matchable < T > ( val , shouldNotBe , context + \".shouldNotBe(\" + shouldNotBe + \")\" , false ) ; tMatchable . match ( ) ; return tMatchable ;", "del_tokens": "return new Matchable < T > ( val , shouldBe , context + \".shouldBe(\" + shouldBe + \")\" , true ) ; return new Matchable < T > ( val , shouldNotBe , context + \".shouldNotBe(\" + shouldNotBe + \")\" , false ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "new", "method", "for", "setting", "Allure", "results", "directory", "make", "tests", "independent"], "add_tokens": "import ru . yandex . qatools . allure . utils . AllureResultsUtils ; @ Before public void setUp ( ) throws IOException { AllureResultsUtils . setResultsDirectory ( resultsDir . toFile ( ) ) ; testNG . setTestClasses ( new Class [ ] { TestDataClass . class } ) ; @ After public void tearDown ( ) throws IOException { AllureResultsUtils . setResultsDirectory ( null ) ;", "del_tokens": "private static final String ALLURE_RESULTS_DIRECTORY_PROP = \"allure.results.directory\" ; @ BeforeClass public static void setUpClass ( ) throws IOException { System . setProperty ( ALLURE_RESULTS_DIRECTORY_PROP , resultsDir . toAbsolutePath ( ) . toString ( ) ) ; testNG . setTestClasses ( new Class [ ] { TestDataClass . class } ) ; @ AfterClass public static void tearDownClass ( ) throws IOException { System . clearProperty ( ALLURE_RESULTS_DIRECTORY_PROP ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "tests", "for", "binding", "builder", ".", "Added", "missing", "method", "return", "to", "method", "delegation", "binder", "."], "add_tokens": "private final List < Assignment > parameterAssignments ; List < Assignment > parameterAssignments , this . parameterAssignments = new ArrayList < Assignment > ( parameterAssignments ) ; this . registeredTargetIndices = new HashMap < Object , Integer > ( registeredTargetIndices ) ;", "del_tokens": "private final Iterable < Assignment > parameterAssignments ; Iterable < Assignment > parameterAssignments , this . parameterAssignments = parameterAssignments ; this . registeredTargetIndices = registeredTargetIndices ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "build", "number", "to", "the", "snapshot", "version", "API", "response"], "add_tokens": "String buildNumber = props . get ( \"buildNumber\" ) . toString ( ) ; return Response . ok ( ) . entity ( \"{\\\"version\\\":\\\"\" + version + \"\\\",\\\"build\\\":\\\"\" + buildNumber + \"\\\"}\" ) . build ( ) ;", "del_tokens": "return Response . ok ( ) . entity ( \"{\\\"version\\\":\\\"\" + version + \"\\\"}\" ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "MappedEntity", "AutoCloseable", "and", "close", "it", "before", "reloading", "on", "recovery"], "add_tokens": "for ( final MappedEntity me : niw . values ( ) ) { try { me . close ( ) ; } catch ( final Exception e ) { logger . trace ( \"Could not close prepared statement.\" , e ) ; }", "del_tokens": "for ( MappedEntity me : niw . values ( ) ) {", "commit_type": "make"}
{"commit_tokens": ["add", "test", "for", "detecting", "backwards", "time", "fix", "bug", "where", "a", "RuntimeException", "was", "being", "thrown", "instead", "of", "an", "InterruptedException"], "add_tokens": "throw new InterruptedException ( \"Backwards time detected, try again in \" + ( lastTime - currentTime ) + \" ms\" ) ;", "del_tokens": "throw new RuntimeException ( \"Backwards time detected, try again in \" + ( lastTime - currentTime ) + \" ms\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "integer", "and", "dimension", "values", "to", "xml"], "add_tokens": "// public static int dpToPx(int dp) { // return (int) (dp * Resources.getSystem().getDisplayMetrics().density); // } public static float pxToDp ( float px ) { return px / Resources . getSystem ( ) . getDisplayMetrics ( ) . density ;", "del_tokens": "public static int dpToPx ( int dp ) { return ( int ) ( dp * Resources . getSystem ( ) . getDisplayMetrics ( ) . density ) ;", "commit_type": "move"}
{"commit_tokens": ["use", "an", "atomic", "reference", "not", "a", "transient", "variable"], "add_tokens": "import java . util . concurrent . atomic . AtomicReference ; private final AtomicReference < Connector > connectorHolder = new AtomicReference < Connector > ( null ) ; this . connectorHolder . set ( connector ) ; final Connector connector = connectorHolder . get ( ) ; if ( connector != null ) { Preconditions . checkState ( connector . getLocalPort ( ) > 0 , \"no port was set and the connector is not yet started!\" ) ; return connector . getLocalPort ( ) ; } else { return 0 ; }", "del_tokens": "private transient Connector connector = null ; this . connector = connector ; } else if ( connector != null ) { Preconditions . checkState ( connector . getLocalPort ( ) > 0 , \"no port was set and the connector is not yet started!\" ) ; return connector . getLocalPort ( ) ; return 0 ;", "commit_type": "use"}
{"commit_tokens": ["add", "a", "new", "ctor", "from", "array"], "add_tokens": "- 1 , 0 , 1 , num , 1", "del_tokens": "// @checkstyle MagicNumber (2 lines) new ArrayAsIterable < > ( 0 , 1 , 2 , num , 3 , 4 )", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "change", "for", "normalization", "of", "property", "names"], "add_tokens": "this . addProperty ( this . normalizeName ( garbageCollectorName ) + \"_\" + PROPERTY_GARBAGE_COLLECTOR_RUN_COUNT , runCount ) ; this . addProperty ( this . normalizeName ( garbageCollectorName ) + \"_\" + PROPERTY_GARBAGE_COLLECTOR_TIME , collectionTime ) ;", "del_tokens": "this . addProperty ( this . normalizeName ( garbageCollectorName ) + \"-\" + PROPERTY_GARBAGE_COLLECTOR_RUN_COUNT , runCount ) ; this . addProperty ( this . normalizeName ( garbageCollectorName ) + \"-\" + PROPERTY_GARBAGE_COLLECTOR_TIME , collectionTime ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "timestamp", "serialization", "before", "epoch", "with", "nanos", "test", "case"], "add_tokens": "decimal = DecimalUtils . toDecimal ( - 22704862 , 599000000 ) ; assertEquals ( \"The returned decimal is not correct.\" , \"-22704862.599000000\" , decimal ) ; @ Test public void testExtractSecondsAndNanosFromNegativeBigDecimal ( ) { BigDecimal value = new BigDecimal ( \"-22704862.599000000\" ) ; checkExtractSecondsAndNanos ( - 22704862L , 599000000 , value ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Make", "hashCode", "compatible", "with", "equals"], "add_tokens": "return 31 * listener . hashCode ( ) ;", "del_tokens": "return 31 * Integer . hashCode ( this . priority ) ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "when", "to", "steal", "the", "scroll", "event", "from", "boardview"], "add_tokens": "if ( diffY > mTouchSlop * 0.5 ) {", "del_tokens": "if ( diffY > diffX && diffY > mTouchSlop * 0.25 ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "diffusion", "coefficient", "estimator", "by", "regression"], "add_tokens": "public class MSDCalculator {", "del_tokens": "public class MSDCaclulator {", "commit_type": "add"}
{"commit_tokens": ["Make", "transition", "smoother", "to", "projectId"], "add_tokens": "/** The Google Cloud Platform project Id to use for this invocation */ @ Deprecated @ Parameter ( alias = \"deploy.project\" , property = \"app.deploy.project\" ) private String project ; /** The Google Cloud Platform project Id to use for this invocation. */ if ( project != null ) { throw new IllegalArgumentException ( \"Configuring <project> is deprecated, use <projectId> to set your \" + \"Google Cloud ProjectId\" ) ; }", "del_tokens": "/** The Google Cloud Platform project name to use for this invocation. */", "commit_type": "make"}
{"commit_tokens": ["Update", "to", "new", "CSSBox", "API"], "add_tokens": "VisualContext ctx = new VisualContext ( null , null ) ;", "del_tokens": "VisualContext ctx = new VisualContext ( null ) ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "references", "to", "Contants", "class", ".", "(", "It", "was", "recently", "removed", "and", "its", "contents", "moved", "to", "SystemPropsBinder", "."], "add_tokens": "import org . slf4j . impl . SystemPropBinder ; System . setProperty ( SystemPropBinder . LOGGER_FACTORY_PROPERTY , \"org.slf4j.XLoggerFAFactory\" ) ;", "del_tokens": "System . setProperty ( LOGGER_FACTORY_PROPERTY , \"org.slf4j.XLoggerFAFactory\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["use", "context", "scheduler", "for", "query", "update"], "add_tokens": "log . debug ( \"getting connection\" ) ;", "del_tokens": "log . info ( \"getting connection\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "mangled", "unicode", "character", "in", "UtilitiesTest", "."], "add_tokens": "String m = \"esemény\";", "del_tokens": "String m = \"esemny\" ;", "commit_type": "fix"}
{"commit_tokens": ["add", "parsing", "for", "the", "MODULE", "-", "IDENTITY", "section"], "add_tokens": "import org . jsmiparser . smi . SmiIndex ; import org . jsmiparser . smi . SmiModuleIdentity ; import org . jsmiparser . smi . SmiModuleRevision ; import org . jsmiparser . smi . SmiNotificationType ; import org . jsmiparser . smi . SmiOidNode ; import org . jsmiparser . smi . SmiVariable ; public void testModuleIdentity ( ) { SmiModule ifMib = getMib ( ) . findModule ( \"IF-MIB\" ) ; assertNotNull ( ifMib ) ; SmiModuleIdentity moduleIdentity = ifMib . getModuleIdentity ( ) ; assertNotNull ( \"ModuleIdentity must not be null\" , moduleIdentity ) ; assertEquals ( \"IETF Interfaces MIB Working Group\" , moduleIdentity . getOrganization ( ) ) ; assertEquals ( \"200006140000Z\" , moduleIdentity . getLastUpdated ( ) ) ; List < SmiModuleRevision > revisions = moduleIdentity . getRevisions ( ) ; assertEquals ( 3 , revisions . size ( ) ) ; SmiModuleRevision lastRevision = revisions . get ( 2 ) ; assertEquals ( \"199311082155Z\" , lastRevision . getRevision ( ) ) ; assertEquals ( \"Initial revision, published as part of RFC 1573.\" , lastRevision . getDescription ( ) ) ; }", "del_tokens": "import org . jsmiparser . smi . SmiNotificationType ; import org . jsmiparser . smi . SmiVariable ; import org . jsmiparser . smi . SmiIndex ; import org . jsmiparser . smi . SmiOidNode ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "potential", "need", "of", "incremental", "build", "variables"], "add_tokens": "this . putValue ( entry . getKey ( ) , entry . getValue ( ) . format ( this . data ) ) ;", "del_tokens": "this . data . put ( entry . getKey ( ) , entry . getValue ( ) . format ( this . data ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["removing", "default", "generator", "from", "factory", "and", "SequenceLabelerME"], "add_tokens": "/ * * * Based on opennlp . tools . namefind . TokenNameFinderFactory . * @ author ragerri * @ version 2016 - 11 - 11 * / throw new NullPointerException ( \"featureGenerator must not be null\" ) ; @ SuppressWarnings ( \"unchecked\" )", "del_tokens": "// Idea of this factory is that most resources/impls used by the name finder // can be modified through this class! // That only works if thats the central class used for training/runtime featureGenerator = SequenceLabelerME . createFeatureGenerator ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["removed", "launching", "of", "debug", "activity", "from", "test", "scan", "in", "main", "screen"], "add_tokens": "new MVBarcodeScanner . Builder ( ) //Intent intent = new Intent(this, IssueDebugActivity.class); //startActivity(intent);", "del_tokens": "/ * new MVBarcodeScanner . Builder ( ) * / Intent intent = new Intent ( this , IssueDebugActivity . class ) ; startActivity ( intent ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "support", "for", "var", "arg", "functions"], "add_tokens": "* < p > In order to support functions with a variable number of arguments , a negative number can be returned . * This will essentially disable the check . < / p > * @ return the number of arguments expected by this function or a negative number to indicate that this * function accepts a variable number of arguments", "del_tokens": "* @ return the number of arguments expected by this function", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "@ContextName", "annotated", "RouteBuiler", "bean"], "add_tokens": "import org . apache . camel . cdi . se . bean . FirstCamelContextRoute ; . addClass ( FirstCamelContextBean . class ) . addClass ( FirstCamelContextRoute . class ) . addClass ( SecondCamelContextBean . class )", "del_tokens": "// Custom Camel contexts . addClass ( FirstCamelContextBean . class ) . addClass ( SecondCamelContextBean . class ) firstCamelContext . addRoutes ( new RouteBuilder ( ) { @ Override public void configure ( ) throws Exception { from ( \"direct:inbound\" ) . setHeader ( \"context\" ) . constant ( \"first\" ) . to ( \"mock:outbound\" ) ; } } ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "a", "few", "gif", "examples", "to", "readme"], "add_tokens": "int x = ( int ) event . getRawX ( ) ; setContentOffset ( x , ( int ) event . getRawY ( ) ) ;", "del_tokens": "int x = ( int ) event . getX ( ) ; setContentOffset ( x , ( int ) event . getY ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["using", "spring", "message", "header", "constant", "instead", "of", "plain", "string", "value"], "add_tokens": "import org . springframework . integration . core . MessageHeaders ; if ( headerEntry . getKey ( ) . startsWith ( MessageHeaders . PREFIX ) ) {", "del_tokens": "if ( headerEntry . getKey ( ) . startsWith ( \"springintegration\" ) ) {", "commit_type": "use"}
{"commit_tokens": ["Updated", "README", ";", "removed", "Turkish", "dotless", "i", "safe", "unicode", "replacement"], "add_tokens": "/** deprecated at recommendation by Turkcell - these replacements changed meaning too much */ //{ '\\u0131', '1' }, // U+0131 is a lower case letter dotless i (ı) //{ '\\u0130', 'i' }, // U+0130 (İ) is capital i with dot", "del_tokens": "{ '\\u0131' , '1' } , // U+0131 is a lower case letter dotless i (ı) { '\\u0130' , 'i' } , // U+0130 (İ) is capital i with dot", "commit_type": "update"}
{"commit_tokens": ["Make", "the", "unit", "of", "time", "configurable", "for", "the", "timestamp", "range"], "add_tokens": "import java . util . concurrent . TimeUnit ; private final AbstractAuthenticator < String > authenticator = createAuthenticator ( ) ; DateTime requestTime = nowInUTC ( ) . minusMinutes ( 1 ) ; DateTime requestTime = nowInUTC ( ) . plusMinutes ( 1 ) ; private AbstractAuthenticator < String > createAuthenticator ( ) { // Implement an authenticator that allows a 5 second difference between client and server timestamps return new AbstractAuthenticator < String > ( 5 , TimeUnit . SECONDS ) {", "del_tokens": "import static org . joda . time . Minutes . minutes ; private static final int ACCEPTABLE_TIMESTAMP_RANGE = minutes ( 5 ) . getMinutes ( ) ; private final AbstractAuthenticator < String > authenticator = createAuthenticator ( ACCEPTABLE_TIMESTAMP_RANGE ) ; DateTime requestTime = nowInUTC ( ) . minusMinutes ( ACCEPTABLE_TIMESTAMP_RANGE + 2 ) ; DateTime requestTime = nowInUTC ( ) . plusMinutes ( ACCEPTABLE_TIMESTAMP_RANGE + 2 ) ; private AbstractAuthenticator < String > createAuthenticator ( int acceptableTimestampRange ) { return new AbstractAuthenticator < String > ( acceptableTimestampRange ) {", "commit_type": "make"}
{"commit_tokens": ["added", "getSDCardPath", "to", "the", "sdcard", "category"], "add_tokens": "/ * * * Get the SDCard Path * * @ return the complete path to the SDCard * / public static String getSDCardPath ( ) { return Environment . getExternalStorageDirectory ( ) . toString ( ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "another", "unlikely", "NPE", "."], "add_tokens": "if ( contentSpecRev != null ) { final RESTAssignedPropertyTagV1 cspType = ComponentBaseRESTEntityWithPropertiesV1 . returnProperty ( contentSpecRev , CSConstants . CSP_TYPE_PROPERTY_TAG_ID ) ; if ( cspType != null && cspType . getValue ( ) != null && cspType . getValue ( ) . equals ( CSConstants . CSP_PRE_PROCESSED_STRING ) ) { preContentSpec = contentSpecRev ; break ; } if ( contentSpecRev != null ) { final RESTAssignedPropertyTagV1 cspType = ComponentBaseRESTEntityWithPropertiesV1 . returnProperty ( contentSpecRev , CSConstants . CSP_TYPE_PROPERTY_TAG_ID ) ; if ( cspType != null && cspType . getValue ( ) != null && cspType . getValue ( ) . equals ( CSConstants . CSP_POST_PROCESSED_STRING ) ) { postContentSpec = contentSpecRev ; break ; }", "del_tokens": "final RESTAssignedPropertyTagV1 cspType = ComponentBaseRESTEntityWithPropertiesV1 . returnProperty ( contentSpecRev , CSConstants . CSP_TYPE_PROPERTY_TAG_ID ) ; if ( cspType != null && cspType . getValue ( ) != null && cspType . getValue ( ) . equals ( CSConstants . CSP_PRE_PROCESSED_STRING ) ) { preContentSpec = contentSpecRev ; break ; final RESTAssignedPropertyTagV1 cspType = ComponentBaseRESTEntityWithPropertiesV1 . returnProperty ( contentSpecRev , CSConstants . CSP_TYPE_PROPERTY_TAG_ID ) ; if ( cspType != null && cspType . getValue ( ) != null && cspType . getValue ( ) . equals ( CSConstants . CSP_POST_PROCESSED_STRING ) ) { postContentSpec = contentSpecRev ; break ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "all", "remaining", "cases", "from", "test_regexp", ".", "rb", "/", "test_unicode"], "add_tokens": "root = setupTree ( root , 0 ) ; private Node expandCaseFoldString ( Node node ) { if ( sn . isAmbig ( ) || sn . length ( ) <= 0 ) return node ; swap ( node , xnode ) ; return xnode ; protected final Node setupTree ( Node node , int state ) { node = expandCaseFoldString ( node ) ; target = setupTree ( target , state ) ; return node ;", "del_tokens": "setupTree ( root , 0 ) ; private void expandCaseFoldString ( Node node ) { if ( sn . isAmbig ( ) || sn . length ( ) <= 0 ) return ; if ( xnode instanceof StringNode ) { sn . assign ( ( StringNode ) xnode ) ; } else { swap ( node , xnode ) ; } protected final void setupTree ( Node node , int state ) { expandCaseFoldString ( node ) ; setupTree ( target , state ) ; return ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "getInferredAxioms", "()", "method", "for", "DNF", "-", "style", "axioms", "-", "very", "ugly", "code"], "add_tokens": "final static int CONCEPT_COUNT_ESTIMATE = 500000 ; // TODO: how do we estimate these numbers better? new DenseConceptMap < MonotonicCollection < IConjunctionQueueEntry > > ( CONCEPT_COUNT_ESTIMATE ) , new SparseConceptMap < MonotonicCollection < NF2 > > ( CONCEPT_COUNT_ESTIMATE , \"ontologyNF2\" ) , new SparseConceptMap < ConcurrentMap < Integer , Collection < IConjunctionQueueEntry > > > ( CONCEPT_COUNT_ESTIMATE , \"ontologyNF3\" ) , Set < Inclusion < T > > oldIs = new HashSet < > ( newIs . size ( ) ) ; final Set < Inclusion < T > > done = new HashSet < > ( newIs . size ( ) ) ;", "del_tokens": "new DenseConceptMap < MonotonicCollection < IConjunctionQueueEntry > > ( 500000 ) , new SparseConceptMap < MonotonicCollection < NF2 > > ( 500000 , \"ontologyNF2\" ) , new SparseConceptMap < ConcurrentMap < Integer , Collection < IConjunctionQueueEntry > > > ( 500000 , \"ontologyNF3\" ) , // TODO: how do we estimate these numbers better? final Set < Inclusion < T > > done = new HashSet < > ( ) ; Set < Inclusion < T > > oldIs = new HashSet < > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "in", "pub", "/", "sub", "protocol", "decoding"], "add_tokens": "while ( output . type ( ) == null && ! queue . isEmpty ( ) ) {", "del_tokens": "while ( ! queue . isEmpty ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "orientdb", "specific", "test", "module"], "add_tokens": "assertTrue ( ! g . traversal ( ) . V ( person . id ( ) ) . hasNext ( ) ) ;", "del_tokens": "assertTrue ( ! g . traversal ( ) . V ( Person . class ) . hasNext ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "more", "generation", "methods"], "add_tokens": "//TODO variations //TODO variations and UT return new TreeMap < > ( manyAsMapOf ( key , value ) ) ; public static < T , V > Map < T , V > manyAsMapOf ( Class < T > keyType , Class < V > valueType ) { T [ ] keys = ( T [ ] ) FIXTURE . createMany ( TypeToken . of ( keyType ) ) . toArray ( ) ; V [ ] values = ( V [ ] ) FIXTURE . createMany ( TypeToken . of ( valueType ) ) . toArray ( ) ; Map < T , V > map = new HashMap < T , V > ( ) ; for ( int i = 0 ; i < keys . length ; ++ i ) { map . put ( keys [ i ] , values [ i ] ) ; } return map ;", "del_tokens": "//TODO UT and variations //TODO variations return FIXTURE . create ( new InstanceOf < SortedMap < T , V > > ( ) ) ; public static < T , V > Map < T , V > manyAsMapOf ( Class < T > key , Class < V > value ) { return FIXTURE . create ( new InstanceOf < Map < T , V > > ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "some", "typos", "in", "docs", "."], "add_tokens": "* Copyright ( c ) Nmote Ltd . 2004 - 2014. All rights reserved . * * * * * Returns serializer for this dataset . *", "del_tokens": "* Copyright ( c ) Nmote Ltd . 2004 - 2014. All rights reserved . * * * * * Returs serializer for this dataset . *", "commit_type": "fix"}
{"commit_tokens": ["Improve", "injection", "of", "CollectorRegistry", "in", "Prometheus", "configuration"], "add_tokens": "import org . springframework . boot . autoconfigure . condition . ConditionalOnMissingBean ; @ ConditionalOnMissingBean PrometheusMeterRegistry meterRegistry ( CollectorRegistry collectorRegistry ) { return new PrometheusMeterRegistry ( ) ;", "del_tokens": "PrometheusMeterRegistry meterRegistry ( ) { return new PrometheusMeterRegistry ( collectorRegistry ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["use", "getActivity", "()", "instead", "of", "storing", "a", "reference", "to", "the", "Activity"], "add_tokens": "import android . app . DialogFragment ; import android . content . Context ; Context context = getActivity ( ) ; LayoutInflater li = LayoutInflater . from ( context ) ; AlertDialog . Builder builder = new AlertDialog . Builder ( context )", "del_tokens": "import android . app . Activity ; import android . app . DialogFragment ; import java . lang . ref . SoftReference ; private SoftReference < Activity > mActivity ; @ Override public final void onAttach ( Activity activity ) { super . onAttach ( activity ) ; mActivity = new SoftReference < Activity > ( activity ) ; } @ Override public final void onDetach ( ) { super . onDetach ( ) ; mActivity = null ; } LayoutInflater li = LayoutInflater . from ( mActivity . get ( ) ) ; AlertDialog . Builder builder = new AlertDialog . Builder ( mActivity . get ( ) )", "commit_type": "use"}
{"commit_tokens": ["Adding", "AbstractStringEntity", "whatsChanged", "(", "parentKey", ")"], "add_tokens": "return whatsChanged ( null , since , pageSize , cursorKey ) ; } / * * * Returns the IDs for the entities with updatedDate >= since , in descending order . * @ param since * @ return the IDs for the entities with updatedDate >= since , in descending order . * / @ Override public CursorPage < ID , ID > whatsChanged ( Object parentKey , Date since , int pageSize , Serializable cursorKey , Filter ... filters ) { Filter allFilters [ ] = Arrays . copyOf ( filters , ( null != filters ? filters . length : 0 ) + 1 ) ; allFilters [ allFilters . length - 1 ] = createGreaterThanOrEqualFilter ( updatedDateColumnName , since ) ; final CursorPage < T , ID > entityPage = queryPage ( true , pageSize , parentKey , null , cursorKey , allFilters ) ;", "del_tokens": "final Filter hasChangedFilter = createGreaterThanOrEqualFilter ( updatedDateColumnName , since ) ; final CursorPage < T , ID > entityPage = queryPage ( true , pageSize , null , null , cursorKey , hasChangedFilter ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "config", "loading", "into", "it", "s", "own", "class", "."], "add_tokens": "this . config = ConfigUtil . load ( source ) ;", "del_tokens": "loadConfig ( ) ; public CompositeConfiguration loadConfig ( ) throws ConfigurationException { this . config = new CompositeConfiguration ( ) ; File customConfig = new File ( source , \"custom.properties\" ) ; if ( customConfig . exists ( ) ) { config . addConfiguration ( new PropertiesConfiguration ( customConfig ) ) ; } config . addConfiguration ( new PropertiesConfiguration ( \"default.properties\" ) ) ; return config ; }", "commit_type": "move"}
{"commit_tokens": ["Add", "missing", "return", "this", ";", "to", "options", "class"], "add_tokens": "public CreateMessageOptions setVisibilityTimeoutInSeconds ( Integer visibilityTimeoutInSeconds ) { return this ; public CreateMessageOptions setTimeToLiveInSeconds ( Integer timeToLiveInSeconds ) { return this ;", "del_tokens": "public void setVisibilityTimeoutInSeconds ( Integer visibilityTimeoutInSeconds ) { public void setTimeToLiveInSeconds ( Integer timeToLiveInSeconds ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "versioned", "command", "classes", "."], "add_tokens": "/ * * * Returns the highest supported command class version * * @ return the version * / public int getMaxSupportedVersion ( ) { return 1 ; } * Returns the command class name . This is primarily for logging purposes .", "del_tokens": "* Returns the command class name . This is primarily for loggin purposes .", "commit_type": "add"}
{"commit_tokens": ["fix", "host", "status", "reporting", "for", "connecting", "to", "port", "22122", "for", "DynoQueueDAO"], "add_tokens": "updatedHosts . add ( new Host ( host . getHostName ( ) , host . getIpAddress ( ) , readConnPort , host . getRack ( ) , host . getDatacenter ( ) , host . isUp ( ) ? Status . Up : Status . Down ) ) ;", "del_tokens": "updatedHosts . add ( new Host ( host . getHostName ( ) , host . getIpAddress ( ) , readConnPort , host . getRack ( ) , host . getDatacenter ( ) , Status . Up ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "simple", "TwitterTemplate", "constructor", "to", "set", "error", "handler", "and", "translator", "."], "add_tokens": "import org . scribe . builder . api . LinkedInApi ; // TODO : REMOVE THE SPECIFIC API HERE...FIGURE OUT WHICH ONE WE NEED OR // BUILD UP THE SERVICE PROGRAMMATICALLY this . service = new ServiceBuilder ( ) . provider ( LinkedInApi . class ) . apiKey ( apiKey ) . apiSecret ( apiSecret )", "del_tokens": "import org . scribe . builder . api . TwitterApi ; this . service = new ServiceBuilder ( ) . provider ( TwitterApi . class ) . apiKey ( apiKey ) . apiSecret ( apiSecret )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "Via", "header", "bug", "and", "added", "stuff", "to", "the", "sip", "message", "builders"], "add_tokens": "return false ; default boolean isSipRequestBuilder ( ) { return false ; } default boolean isSipResponseBuilder ( ) { return false ; } default SipMessage . Builder < SipRequest > toSipRequestBuilder ( ) { throw new ClassCastException ( \"Cannot cast \" + getClass ( ) . getName ( ) + \" into a SipRequest builder\" ) ; } default SipMessage . Builder < SipResponse > toSipResponseBuilder ( ) { throw new ClassCastException ( \"Cannot cast \" + getClass ( ) . getName ( ) + \" into a SipResponse builder\" ) ; }", "del_tokens": "return true ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "returning", "a", "TweakedModule"], "add_tokens": "import com . nesscomputing . testing . tweaked . TweakedModule ; new MapConfiguration ( getConfigurationTweak ( dbModuleName ) ) ) ; / * * * @ return a { @ link TweakedModule } which gives services database URLs * / public TweakedModule getTweakedModule ( final String dbModuleName ) { return new TweakedModule ( ) { @ Override public Map < String , String > getServiceConfigTweaks ( ) { return getConfigurationTweak ( dbModuleName ) ; } } ; } private ImmutableMap < String , String > getConfigurationTweak ( String dbModuleName ) { return ImmutableMap . of ( \"ness.db.\" + dbModuleName + \".uri\" , cluster . getNextDbUri ( ) ) ; }", "del_tokens": "new MapConfiguration ( ImmutableMap . of ( \"ness.db.\" + dbModuleName + \".uri\" , cluster . getNextDbUri ( ) ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "Throwing", "an", "exception", "instead", "of", "returning", "it"], "add_tokens": "throw new ObjenesisException ( e ) ;", "del_tokens": "return new ObjenesisException ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "the", "getViewOf", "on", "container", ".", "The", "nature", "of", "the", "list", "returned", "by", "Container#getAll", "(", "..", ")", "depends", "on", "implementation", ":"], "add_tokens": "import static java . util . Collections . unmodifiableList ; return unmodifiableList ( loadingCache . get ( key ) ) ;", "del_tokens": "import static com . google . common . collect . ImmutableList . copyOf ; @ Override public List < V > getViewOf ( K key ) { try { return loadingCache . get ( key ) ; } catch ( ExecutionException e ) { throw propagate ( e ) ; } } return copyOf ( loadingCache . get ( key ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "methods", "shouldBe", "and", "haveText"], "add_tokens": "if ( \"should\" . equals ( method . getName ( ) ) || \"shouldBe\" . equals ( method . getName ( ) ) ) {", "del_tokens": "if ( \"should\" . equals ( method . getName ( ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "missing", "brace", "in", "generated", "toString"], "add_tokens": "toString . addStatement ( \"sb.append($S).append(\\\"{\\\\n \\\")\" , struct . name ( ) ) ;", "del_tokens": "toString . addStatement ( \"sb.append($S).append(\\\"\\\\n \\\")\" , struct . name ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "error", "handling", "to", "generated", "route", "/", "filter", "classes", "and", "add", "redirection", "for", "prefixed", "multi", "-", "application", "routes", "when", "the", "URI", "isn", "t", "within", "the", "prefixed", "area", "."], "add_tokens": "import org . commonjava . vertx . vabr . helper . RedirectHandler ; final NoMatchHandler handler = noMatchHandler == null ? new RedirectHandler ( prefix ) : noMatchHandler ; handler . handle ( request ) ; // else // { // // Default 404 // request.response() // .setStatusCode( 404 ) // .setStatusMessage( \"Not Found\" ) // .setChunked( true ) // .write( \"No handler found\" ) // .end(); // }", "del_tokens": "if ( noMatchHandler != null ) { noMatchHandler . handle ( request ) ; } else { // Default 404 request . response ( ) . setStatusCode ( 404 ) . setStatusMessage ( \"Not Found\" ) . setChunked ( true ) . write ( \"No handler found\" ) . end ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["add", "Travis", "CI", "configuration", "and", "badge"], "add_tokens": "@ NonNull String verifyToken , @ NonNull MessengerHttpClient customHttpClient ) {", "del_tokens": "import com . sun . istack . internal . NotNull ; @ NonNull String verifyToken , @ NotNull MessengerHttpClient customHttpClient ) {", "commit_type": "add"}
{"commit_tokens": ["moved", "setup", "/", "teardownFixture", "to", "DatabaseTestSupport"], "add_tokens": "public void setupFixtures ( ) {", "del_tokens": "import org . junit . BeforeClass ; import org . junit . runners . JUnit4 ; import org . springframework . test . annotation . DirtiesContext ; import javax . swing . * ; protected void setupFixtures ( ) {", "commit_type": "move"}
{"commit_tokens": ["Added", "Tests", "for", "Modified", "Following", "and", "Preceeding", "...", "you", "can", "use", "them", "for", "JDK", "...", "BUT", "I", "m", "not", "sure", "it", "is", "100%", "."], "add_tokens": "date = date . plusDays ( step ) ; date = date . plusDays ( step ) ;", "del_tokens": "date = date . minusDays ( step ) ; date = date . minusDays ( step ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "logging", "for", "actor", "stop", "tests", "."], "add_tokens": "System . out . println ( \"Test: testStopActors\" ) ; System . out . println ( \"Test: testStopActors: starting actors\" ) ; System . out . println ( \"Test: testStopActors: stopping actors\" ) ; System . out . println ( \"Test: testStopActors: stopped actors\" ) ; System . out . println ( \"Test: testStopActors: terminating world\" ) ; System . out . println ( \"Test: testWorldTerminateToStopAllActors\" ) ; System . out . println ( \"Test: testWorldTerminateToStopAllActors: starting actors\" ) ; System . out . println ( \"Test: testWorldTerminateToStopAllActors: stopping actors\" ) ; System . out . println ( \"Test: testWorldTerminateToStopAllActors: terminating world\" ) ;", "del_tokens": "final World world = World . start ( \"test\" ) ; final World world = World . start ( \"test\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Integer", "support", "in", "OGM"], "add_tokens": "* Represents a Long type *", "del_tokens": "@ SuppressWarnings ( { \"UnnecessaryBoxing\" } ) private static final Long ZERO = Long . valueOf ( 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "lesser", "size", "for", "the", "last", "windows", "in", "a", "windowed", "stream", "to", "avoid", "data", "loss"], "add_tokens": "private boolean allowLesserSize ; public WindowedSpliterator ( Spliterator < T > input , int windowSize , int overlap , boolean allowLesserSize ) { this . allowLesserSize = allowLesserSize ; static < T > WindowedSpliterator < T > over ( Spliterator < T > source , int windowSize , int overlap , boolean allowLesserSize ) { return new WindowedSpliterator < > ( source , windowSize , overlap , allowLesserSize ) ; if ( ! allowLesserSize ) { if ( next . size ( ) != windowSize ) { next . clear ( ) ; }", "del_tokens": "public WindowedSpliterator ( Spliterator < T > input , int windowSize , int overlap ) { static < T > WindowedSpliterator < T > over ( Spliterator < T > source , int windowSize , int overlap ) { return new WindowedSpliterator < > ( source , windowSize , overlap ) ; if ( next . size ( ) != windowSize ) { next . clear ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "correct", "behaviour", "for", "free", "()", "and", "fixed", "1", "-", "based", "getArray", "(", "long"], "add_tokens": "private static final String FREE_EXCEPTION = \"free() has been called, array is no longer available\" ; private void checkFree ( ) throws SQLException { if ( data == null ) { throw new SQLException ( FREE_EXCEPTION ) ; } } checkFree ( ) ; checkFree ( ) ; checkFree ( ) ; checkFree ( ) ; checkFree ( ) ; checkFree ( ) ; System . arraycopy ( data , ( int ) index - 1 , res , 0 , count ) ; if ( data != null ) for ( Object o : ( Object [ ] ) data ) { joiner . add ( o . toString ( ) ) ; }", "del_tokens": "System . arraycopy ( data , ( int ) index , res , 0 , count ) ; for ( Object o : ( Object [ ] ) data ) joiner . add ( o . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "to", "latest", "calendar", "changes"], "add_tokens": "import com . sun . jersey . api . client . GenericType ; private List < Event > getCalendar ( String path , LocalDate dateFrom , new GenericType < List < Event > > ( ) { } ) ; public List < Event > getApp ( int appId , LocalDate dateFrom , LocalDate dateTo , public List < Event > getSpace ( int spaceId , LocalDate dateFrom , LocalDate dateTo , ReferenceType ... types ) { public List < Event > getGlobal ( LocalDate dateFrom , LocalDate dateTo ,", "del_tokens": "private Calendar getCalendar ( String path , LocalDate dateFrom , Calendar . class ) ; public Calendar getApp ( int appId , LocalDate dateFrom , LocalDate dateTo , public Calendar getSpace ( int spaceId , LocalDate dateFrom , LocalDate dateTo , ReferenceType ... types ) { public Calendar getGlobal ( LocalDate dateFrom , LocalDate dateTo ,", "commit_type": "update"}
{"commit_tokens": ["Make", "UnescapeAtSymbolRepair", "work", "together", "with", "AtSymbolRepair", "minor", "doc", "corrections", "."], "add_tokens": "* AtSymbolRepair allows to use the '@' symbol in external JavaDoc fragments ( like * the Gist Taglet ) without running into any issues with JavaDoc . * * * Important Note * * : This is only useful when importing fragments that may contain * '@' from external sources . If an '@' is in the actual JavaDoc source code , it will * be interpreted by JavaDoc before this class gets a chance to fix anything . * { @ link UnescapeAtSymbolRepair } is used for providing an escape for the JavaDoc sources . * The two classes don 't clash, i.e. in external sources, there' s no need to escape * the '@' symbol , escaping actually won 't even work with those.", "del_tokens": "* AtSymbolRepair corrects the & # 64 ; symbol issue , by replacing it with ` & # 64 ; ` . * * Demo : * ( which will currently fail , unfortunately ) * * ``` java * @ MyAnnotation * public class MyClass { * } * ``` * * @ see Issue soundso", "commit_type": "make"}
{"commit_tokens": ["fixed", "Model", "::", "save", "()"], "add_tokens": "long id = t . insert ( Utils . getTableName ( getClass ( ) ) , Utils . getContentValues ( this ) ) ; final ModelInfo info = ModelInfo . from ( getClass ( ) ) ; if ( info . autoIncrementColumn != null ) { info . autoIncrementColumn . field . setAccessible ( true ) ; try { info . autoIncrementColumn . field . set ( this , id ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } }", "del_tokens": "import java . util . List ; long id = t . insert ( Utils . getTableName ( getClass ( ) ) , Utils . getContentValues ( this ) ) ; final List < ColumnField > columns = Utils . getColumns ( getClass ( ) ) ; for ( ColumnField column : columns ) { if ( column . isAutoIncrementPrimaryKey ) { column . field . setAccessible ( true ) ; try { column . field . set ( this , id ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } break ; } }", "commit_type": "fix"}
{"commit_tokens": ["add", "new", "chooser", "builder", "options", ":", "withIcon", "/", "withLayoutView", ";"], "add_tokens": "public final static int VERSION_CODE = 101006 ;", "del_tokens": "public final static int VERSION_CODE = 101004 ;", "commit_type": "add"}
{"commit_tokens": ["Added", "handling", "of", "empty", "requests", ".", "Instead", "of", "internal", "server", "error", "a", "correct", "400", "error", "is", "returned"], "add_tokens": "import java . io . ByteArrayInputStream ; int result = ErrorResolver . JsonError . PARSE_ERROR . code ; try { result = handleRequest ( input , output ) ; } catch ( Throwable t ) { if ( StreamEndedException . class . isInstance ( t ) ) { logger . debug ( \"Bad request: empty contents!\" ) ; } } String method = request . getParameter ( METHOD ) ; String id = request . getParameter ( ID ) ; String params = request . getParameter ( PARAMS ) ; if ( method == null && id == null && params == null ) { return new ByteArrayInputStream ( new byte [ ] { } ) ; } else { return createInputStream ( method , id , params ) ; }", "del_tokens": "int result = handleRequest ( input , output ) ; return createInputStream ( request . getParameter ( METHOD ) , request . getParameter ( ID ) , request . getParameter ( PARAMS ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "tabs", "to", "white", "space", "."], "add_tokens": "try { timeUnit . sleep ( sleepTime ) ; } catch ( final InterruptedException e ) { log . log ( Level . WARNING , e . getMessage ( ) ) ; }", "del_tokens": "private Cube cube ; this . cube = cube ; try { timeUnit . sleep ( sleepTime ) ; } catch ( final InterruptedException e ) { log . log ( Level . WARNING , e . getMessage ( ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["improve", "doc", "tests", "exposes", "a", "previously", "existing", "problem", "with", "encrypted"], "add_tokens": "assertParseable ( \"issue-104.docx\" ) ; assertException ( \"encrypted.pdf\" ) ; assertParseable ( \"htmlWithEmptyDateMeta.html\" ) ; assertParseable ( \"testXHTML.html\" ) ; assertParseable ( \"text-in-english.txt\" ) ; assertParseable ( \"asciidoc.asciidoc\" ) ; void assertException ( String filename ) { Tika tika = tika ( ) ; assumeTrue ( \"Tika has been disabled. Ignoring test...\" , tika != null ) ; try ( InputStream is = VariousDocTest . class . getResourceAsStream ( \"/org/elasticsearch/index/mapper/attachment/test/sample-files/\" + filename ) ) { tika . parseToString ( is ) ; fail ( \"expected exception\" ) ; } catch ( Exception e ) { // expected. TODO: check message } } protected void assertParseable ( String filename ) throws Exception {", "del_tokens": "testTika ( \"issue-104.docx\" , false ) ; testTika ( \"encrypted.pdf\" , true ) ; testTika ( \"htmlWithEmptyDateMeta.html\" , false ) ; testTika ( \"testXHTML.html\" , false ) ; testTika ( \"text-in-english.txt\" , false ) ; testTika ( \"asciidoc.asciidoc\" , false ) ; protected void testTika ( String filename , boolean errorExpected ) { } catch ( Throwable e ) { if ( ! errorExpected ) { fail ( \"exception caught: \" + e . getMessage ( ) ) ; }", "commit_type": "improve"}
{"commit_tokens": ["Add", "isStarted", "()", "and", "some", "small", "code", "fixes", "."], "add_tokens": "if ( STARTED != m_state ) { m_state . start ( this ) ; m_state = STARTED ; } if ( STOPPED != m_state ) { m_state . stop ( this ) ; m_state = STOPPED ; } public boolean isStarted ( ) { return m_state == STARTED ; }", "del_tokens": "m_state . start ( this ) ; m_state = STARTED ; m_state . stop ( this ) ; m_state = STOPPED ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "failing", "test", "for", "Travis"], "add_tokens": "@ Test ( expected = Exception . class )", "del_tokens": "import org . jboss . netty . channel . ChannelPipelineException ; @ Test ( expected = ChannelPipelineException . class )", "commit_type": "fix"}
{"commit_tokens": ["Adding", "ssh", "protocol", "url", "pattern", "to", "commit", "hook", "handler"], "add_tokens": "Pattern . compile ( \"git://github.com/([^/.]+)/([^/.]+).git\" ) , Pattern . compile ( \"ssh://git@github.com/([^/.]+)/([^/.]+).git\" )", "del_tokens": "Pattern . compile ( \"git://github.com/([^/.]+)/([^/.]+).git\" )", "commit_type": "add"}
{"commit_tokens": ["Making", "sure", "JUnit", "tests", "explicitly", "use", "the", "en_US", "locale", "for", "consistency", "across", "VMs"], "add_tokens": "* < p > Java class for Flat01Record complex type . * < p > The following schema fragment specifies the expected content contained within this class . * Gets the value of the comNumber property . * Sets the value of the comNumber property . * Gets the value of the comName property . * Sets the value of the comName property . * Gets the value of the comAmount property . * Sets the value of the comAmount property .", "del_tokens": "* < p > Classe Java pour Flat01Record complex type . * < p > Le fragment de sch ém a uivant ndique e ontenu ttendu igurant ans ette lasse. * Obtient la valeur de la propri ét é c mNumber. * D éf init a aleur e a roprié té co Number. * Obtient la valeur de la propri ét é c mName. * D éf init a aleur e a roprié té co Name. * Obtient la valeur de la propri ét é c mAmount. * D éf init a aleur e a roprié té co Amount.", "commit_type": "make"}
{"commit_tokens": ["Remove", "GenerativeMap", "in", "favor", "of", "MapMaker#makeComputingMap", "()", "."], "add_tokens": "import com . google . common . base . Function ; import com . google . common . collect . MapMaker ; Map < Pattern , Set < File > > patternsToUses = new MapMaker ( ) . makeComputingMap ( new Function < Pattern , Set < File > > ( ) { @ Override public Set < File > apply ( Pattern key ) { return newHashSet ( ) ; } } ) ;", "del_tokens": "import com . kaching . platform . common . GenerativeMap ; Map < Pattern , Set < File > > patternsToUses = new GenerativeMap < Pattern , Set < File > > ( ) { @ Override protected Set < File > compute ( Pattern key ) { return newHashSet ( ) ; } } ;", "commit_type": "remove"}
{"commit_tokens": ["Update", "JavaDoc", "for", "CreatedTimestamp", "and", "UpdatedTimestamp", "annotations"], "add_tokens": "import java . time . OffsetDateTime ; import java . time . ZonedDateTime ; * < li > { @ link Date } < / li > * < li > { @ link Calendar } < / li > * < li > { @ link Long } < / li > * < li > long < / li > * < li > { @ link OffsetDateTime } } < / li > * < li > { @ link ZonedDateTime } } < / li >", "del_tokens": "* < li > { @ link Date } - Value will be set to new Date ( ) < / li > * < li > { @ link Calendar } - Value will be set to Calendar . getInstance ( ) < / li > * < li > { @ link Long } - Value will be set to System . currentTimeMillis ( ) < / li > * < li > long - Value will be set to System . currentTimeMillis ( ) < / li >", "commit_type": "update"}
{"commit_tokens": ["Added", "toString", "()", "method", "to", "UserInfo", ".", "java", ".", "Perhaps", "useful", "for", "debugging?"], "add_tokens": "public static final String USER_UPDATE = REDDIT_BASE_API_ENDPOINT + \"/update\" ;", "del_tokens": "public static final String USER_UPDATE = REDDIT_BASE_API_ENDPOINT + \"/update\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "merge", "issue", "in", "the", "snapshot", "."], "add_tokens": "if ( categoryName != null ) { }", "del_tokens": "/ * if ( categoryName != null ) { } * /", "commit_type": "fix"}
{"commit_tokens": ["Changed", "a", "log", "message", "from", "error", "to", "warning", "level", "."], "add_tokens": "Log . w ( TAG , \"Failed to close Index: \" + _view ) ;", "del_tokens": "Log . e ( TAG , \"Failed to close Index: \" + _view ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "full", "ip", "address", "just", "remove", ":", "and", "%"], "add_tokens": "hostName = hostName . replaceAll ( \":\" , \"\" ) ; hostName = hostName . replaceAll ( \"%\" , \"\" ) ;", "del_tokens": "hostName = hostName . substring ( 0 , hostName . indexOf ( ':' ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixing", "Java8", "javadoc", ":", "lipstick", ":"], "add_tokens": "* \"pushServerURL\" : \"pushServerURL (e.g http(s)//host:port/context)\" , * \"senderID\" : \"senderID (e.g Google Project ID only for android)\" , * \"variantID\" : \"variantID (e.g. 1234456-234320)\" , * \"variantSecret\" : \"variantSecret (e.g. 1234456-234320)\"", "del_tokens": "* \"pushServerURL\" : \"<pushServerURL e.g http(s)//host:port/context >\" , * \"senderID\" : \"<senderID e.g Google Project ID only for android>\" , * \"variantID\" : \"<variantID e.g. 1234456-234320>\" , * \"variantSecret\" : \"<variantSecret e.g. 1234456-234320>\"", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "not", "explode", "if", "we", "could", "not", "locate", "a", "method", "on", "the", "executor"], "add_tokens": "if ( ! iterator . hasNext ) { return setString ; }", "del_tokens": "if ( ! iterator . hasNext )", "commit_type": "update"}
{"commit_tokens": ["add", "access", "denied", "info", "."], "add_tokens": "import com . hack23 . cia . service . api . ConfigurationManager ; import com . hack23 . cia . service . api . UserConfiguration ; private static final String LOG_INFO_BROWSER_ADDRESS_APPLICATION_SESSION_ID_RESULT = \"Browser url: {} , lang: {} , address: {} , application:{}, sessionId:{}, result:{}\" ; @ Autowired private transient ConfigurationManager configurationManager ; final String requestUrl = currentPage . getLocation ( ) . toString ( ) ; final String language = request . getLocale ( ) . getLanguage ( ) ; final UserConfiguration userConfiguration = configurationManager . getUserConfiguration ( requestUrl , language ) ; currentPage . setTitle ( userConfiguration . getAgency ( ) . getAgencyName ( ) + \":\" + userConfiguration . getPortal ( ) . getPortalName ( ) + \":\" + userConfiguration . getLanguage ( ) . getLanguageName ( ) ) ; LOGGER . info ( LOG_INFO_BROWSER_ADDRESS_APPLICATION_SESSION_ID_RESULT , requestUrl , language , ipInformation , webBrowser . getBrowserApplication ( ) , serviceRequest . getSessionId ( ) , serviceResponse . getResult ( ) . toString ( ) ) ;", "del_tokens": "import java . util . Locale ; private static final String LOG_INFO_BROWSER_ADDRESS_APPLICATION_SESSION_ID_RESULT = \"Browser address: {} , application:{}, sessionId:{}, result:{}\" ; /** The Constant CITIZEN_INTELLIGENCE_AGENCY. */ private static final String CITIZEN_INTELLIGENCE_AGENCY = \"Citizen Intelligence Agency\" ; UI . getCurrent ( ) . setLocale ( Locale . ENGLISH ) ; currentPage . setTitle ( CITIZEN_INTELLIGENCE_AGENCY ) ; LOGGER . info ( LOG_INFO_BROWSER_ADDRESS_APPLICATION_SESSION_ID_RESULT , ipInformation , webBrowser . getBrowserApplication ( ) , serviceRequest . getSessionId ( ) , serviceResponse . getResult ( ) . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "package", "name", "where", "not", "needed"], "add_tokens": "return new SecurityMarkerFilter ( ) ;", "del_tokens": "private SecurityMarkerFilter ( Boolean acceptAll ) { super ( ) ; } return new SecurityMarkerFilter ( acceptAll ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "test", "and", "fix", "for", "column", "filter", "ordering", "."], "add_tokens": "filteredRow = new LinkedHashMap < > ( cleanRow ) ;", "del_tokens": "import java . util . HashMap ; filteredRow = new HashMap < > ( cleanRow ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "for", "pending", "exceptions", "plus", "test", "for", "remote", "jmx", "listener"], "add_tokens": "fail ( \"Failed to read contents of stream \" + is ) ;", "del_tokens": "fail ( \"Failed to read contents of file stream \" + is ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "balance", "and", "fees", "endpoints"], "add_tokens": "private static final String BITSO_BASE_URL_DEV = \"https://dev.bitso.com\" ; public BitsoBalance getUserAccountBalance ( ) { String json = sendBitsoGet ( \"/api/v3/balance\" ) ; JSONObject o = Helpers . parseJson ( json ) ; if ( o == null || o . has ( \"error\" ) ) { logError ( \"Error getting account balance\" ) ; return null ; } return new BitsoBalance ( o ) ; } public BitsoFee getUserFees ( ) { String json = sendBitsoGet ( \"/api/v3/fees\" ) ; JSONObject o = Helpers . parseJson ( json ) ; if ( o == null || o . has ( \"error\" ) ) { logError ( \"Error getting user fees\" ) ; return null ; } return new BitsoFee ( o ) ; }", "del_tokens": "private static final String BITSO_BASE_URL_DEV = \"http://bitso.lan\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "sample", "case", "for", "placing", "MaterialCalendarView", "in", "a", "dialog"], "add_tokens": "new Route ( R . string . title_activity_customize_code , CustomizeCodeActivity . class ) , new Route ( R . string . title_activity_dialogs , DialogsActivity . class )", "del_tokens": "new Route ( R . string . title_activity_customize_code , CustomizeCodeActivity . class )", "commit_type": "add"}
{"commit_tokens": ["Changing", "the", "text", "in", "the", "Javadoc", "for", "the", "class", "."], "add_tokens": "* A class to manage passing commit arguments to the < code > GitCommit < / code > command .", "del_tokens": "* A class to manage passing commit arguments to the commit command .", "commit_type": "change"}
{"commit_tokens": ["Added", "server", "response", "check", ".", "If", "the", "response", "is", "an", "error", "then", "the", "nonce", "and", "otp", "fields", "are", "not", "checked", ";", "if", "the", "response", "is", "not", "an", "error", "they", "are", "checked", "."], "add_tokens": "import com . yubico . client . v2 . YubicoResponseStatus ; // // NONCE/OTP fields are not returned to the client when sending error codes. // If there is an error response, don't need to check them. if ( ! isError ( response . getStatus ( ) ) ) { if ( response . getOtp ( ) == null || ! otp . equals ( response . getOtp ( ) ) ) { if ( response . getNonce ( ) == null || ! nonce . equals ( response . getNonce ( ) ) ) { / * * * Function is used to determine if the response status is an error or not . * * @ param status * @ return boolean * / private boolean isError ( YubicoResponseStatus status ) { return ( YubicoResponseStatus . BACKEND_ERROR . equals ( status ) || YubicoResponseStatus . BAD_OTP . equals ( status ) || YubicoResponseStatus . BAD_SIGNATURE . equals ( status ) || YubicoResponseStatus . NO_SUCH_CLIENT . equals ( status ) || YubicoResponseStatus . MISSING_PARAMETER . equals ( status ) ) ; }", "del_tokens": "if ( response . getOtp ( ) != null ) { if ( ! otp . equals ( response . getOtp ( ) ) ) { } if ( response . getNonce ( ) != null ) { if ( ! nonce . equals ( response . getNonce ( ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["Adds", "PDFDomTree", "font", "extract", "modes", "for", "embedding", "fonts", "saving", "fonts", "to", "disk", "and", "ignoring", "pdf", "fonts", "completely", "."], "add_tokens": "private String fileEnding ; return String . format ( \"data:%s;base64,%s\" , mimeType , new String ( cdata ) ) ; mimeType = \"application/x-font-truetype\" ; fileEnding = \"otf\" ; mimeType = \"application/x-font-woff\" ; fileEnding = font . getProperties ( ) . getFileEnding ( ) ; public String getFileEnding ( ) { return fileEnding ; }", "del_tokens": "return String . format ( \"data:application/%s;base64,%s\" , mimeType , new String ( cdata ) ) ; mimeType = \"x-font-truetype\" ; mimeType = \"x-font-woff\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "commons", "-", "lang", "added", "values", "classes", "Barcode", "and", "Weight"], "add_tokens": "private static String persistenceUnit = \"OpenWMS-test\" ;", "del_tokens": "private static String persistenceUnit = \"OpenWMS-test-durable\" ;", "commit_type": "add"}
{"commit_tokens": ["moved", "examples", "to", "subdirectory", "and", "restructured", "Maven", "pom", "to", "minimize", "dependencies", "."], "add_tokens": "import java . io . Serializable ; import javax . jms . JMSException ; import javax . jms . Session ; import backtype . storm . tuple . Tuple ; public interface JmsMessageProducer extends Serializable { * Translate a < code > backtype . storm . tuple . Tuple < / code > object * * @ param session * @ throws JMSException public Message toMessage ( Session session , Tuple input ) throws JMSException ;", "del_tokens": "public interface JmsMessageProducer { * Translate a < code > backtype . storm . tuple . Values < / code > object public Message toMessage ( Values input ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "warning", "dialog", "with", "color", "scheme"], "add_tokens": "public final class WarningDialog extends Dialog implements Initializable { public WarningDialog ( String header , String details ) { . getResource ( Fxml . WARNING_DIALOG . getFxml ( ) ) ) ; setTitle ( DialogText . WARNING_HEAD_TITLE . getText ( ) ) ;", "del_tokens": "public final class ErrorDialog extends Dialog implements Initializable { public ErrorDialog ( String header , String details ) { . getResource ( Fxml . ERROR_DIALOG . getFxml ( ) ) ) ; setTitle ( DialogText . ERROR_HEAD_TITLE . getText ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "and", "improved", "git", "commands"], "add_tokens": "checkUncommittedChanges ( ) ; // git for-each-ref --format='%(refname:short)' refs/heads/release/* \"for-each-ref\" , \"--format=\\\"%(refname:short)\\\"\" , \"refs/heads/\" + gitFlowConfig . getReleaseBranchPrefix ( ) + \"*\" ) ;", "del_tokens": "if ( executeGitHasUncommitted ( ) ) { throw new MojoFailureException ( \"You have some uncommitted files. Commit or discard local changes to proceed.\" ) ; } // git for-each-ref refs/heads/release \"for-each-ref\" , \"refs/heads/\" + gitFlowConfig . getReleaseBranchPrefix ( ) ) ; // remove * in case current branch is the release branch // TODO v", "commit_type": "fix"}
{"commit_tokens": ["use", "value", "mapper", "for", "sets"], "add_tokens": "msg . setKey ( valueMapper . map ( new ObservedValue ( key , keyIsObservableObject ) ) ) ; msg . setKey ( valueMapper . map ( new ObservedValue ( key , keyIsObservableObject ) ) ) ; msg . setValue ( valueMapper . map ( new ObservedValue ( value , valueIsObservableObject ) ) ) ;", "del_tokens": "if ( keyIsObservableObject ) { msg . setKeyObservableObjectId ( parent . getId ( key ) ) ; } else { msg . setKeySimpleObjectValue ( key ) ; } if ( keyIsObservableObject ) { msg . setKeyObservableObjectId ( parent . getId ( key ) ) ; } else { msg . setKeySimpleObjectValue ( key ) ; } if ( valueIsObservableObject ) { msg . setValueObservableObjectId ( parent . getId ( value ) ) ; } else { msg . setValueSimpleObjectValue ( value ) ; }", "commit_type": "use"}
{"commit_tokens": ["Add", "logic", "from", "RingBufferDescriptor", "to", "BroadcastBufferDescriptor"], "add_tokens": "public static final int TAIL_INTENT_COUNTER_OFFSET ; public static final int TAIL_COUNTER_OFFSET ; public static final int LATEST_COUNTER_OFFSET ; public static final int TRAILER_LENGTH ; static { int offset = 0 ; TAIL_INTENT_COUNTER_OFFSET = offset ; offset += BitUtil . CACHE_LINE_LENGTH ; TAIL_COUNTER_OFFSET = offset ; offset += BitUtil . CACHE_LINE_LENGTH ; LATEST_COUNTER_OFFSET = offset ; offset += BitUtil . CACHE_LINE_LENGTH ; TRAILER_LENGTH = offset ; }", "del_tokens": "public static final int TAIL_INTENT_COUNTER_OFFSET = 0 ; public static final int TAIL_COUNTER_OFFSET = TAIL_INTENT_COUNTER_OFFSET + BitUtil . SIZE_OF_LONG ; public static final int LATEST_COUNTER_OFFSET = TAIL_COUNTER_OFFSET + BitUtil . SIZE_OF_LONG ; public static final int TRAILER_LENGTH = BitUtil . CACHE_LINE_LENGTH * 3 ;", "commit_type": "add"}
{"commit_tokens": ["added", "attribute", "for", "suggestion", "item", "text", "size"], "add_tokens": "private final int ATTRS_SUGGESTION_TEXT_SIZE_SP_DEFAULT = 18 ; private int mSuggestionsTextSizePx ; setSuggestionItemTextSize ( a . getDimensionPixelSize ( R . styleable . FloatingSearchView_floatingSearch_searchSuggestionTextSize , Util . spToPx ( ATTRS_SUGGESTION_TEXT_SIZE_SP_DEFAULT ) ) ) ; public void closeMenu ( boolean withAnim ) { private void setSuggestionItemTextSize ( int sizePx ) { this . mSuggestionsTextSizePx = sizePx ; //setup adapter }", "del_tokens": "public void closeMenu ( boolean withAnim ) {", "commit_type": "add"}
{"commit_tokens": ["add", "more", "session", "creation", "test", "cases", "add", "validation", "of", "SessionProperties", "location"], "add_tokens": "import com . opentok . exception . OpenTokInvalidArgumentException ; import org . apache . commons . validator . routines . InetAddressValidator ; private SessionProperties ( Builder builder ) { public static class Builder { public Builder location ( String location ) throws OpenTokInvalidArgumentException { if ( ! InetAddressValidator . getInstance ( ) . isValidInet4Address ( location ) ) { throw new OpenTokInvalidArgumentException ( \"Location must be a valid IPv4 address. location=\" + location ) ; } public Builder p2p ( boolean p2p ) { public SessionProperties build ( ) {", "del_tokens": "private SessionProperties ( Builder builder ) { public static class Builder { public Builder location ( String location ) { public Builder p2p ( boolean p2p ) { public SessionProperties build ( ) {", "commit_type": "add"}
{"commit_tokens": ["using", "unique", "class", "to", "convert", "bigdecimal"], "add_tokens": "return ConvertBigDecimal . of ( num ) ;", "del_tokens": "// try fast equality check first (delegates to identity!) if ( BigDecimal . class . equals ( num . getClass ( ) ) ) { return ( BigDecimal ) num ; } if ( Long . class . equals ( num . getClass ( ) ) || Integer . class . equals ( num . getClass ( ) ) || Short . class . equals ( num . getClass ( ) ) || Byte . class . equals ( num . getClass ( ) ) || AtomicLong . class . equals ( num . getClass ( ) ) ) { return BigDecimal . valueOf ( num . longValue ( ) ) ; } if ( Float . class . equals ( num . getClass ( ) ) || Double . class . equals ( num . getClass ( ) ) ) { return new BigDecimal ( num . toString ( ) ) ; } // try instance of (slower) if ( num instanceof BigDecimal ) { return ( BigDecimal ) num ; } if ( num instanceof BigInteger ) { return new BigDecimal ( ( BigInteger ) num ) ; } try { // Avoid imprecise conversion to double value if at all possible return new BigDecimal ( num . toString ( ) ) ; } catch ( NumberFormatException e ) { } return BigDecimal . valueOf ( num . doubleValue ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Changed", "semantics", "of", "stream", "more", "IO", "limiting", "code", "."], "add_tokens": "for ( ; ; ) { } // End read loop", "del_tokens": "do { } while ( input . ready ( ) ) ; // End read loop return null ;", "commit_type": "change"}
{"commit_tokens": ["implemented", "frame", "(", "note", ":", "the", "modified", "test", "fails", "on", "pyld", "in", "its", "original", "form", "as", "well", ")"], "add_tokens": "} else if ( jsonString . trim ( ) . equals ( \"null\" ) ) { rval = null ; throw new JsonParseException ( \"document doesn't start with a valid json element\" , new JsonLocation ( \"\\\"\" + jsonString . substring ( 0 , Math . min ( jsonString . length ( ) , 100 ) ) + \"...\\\"\" , 0 , 1 , 0 ) ) ;", "del_tokens": "throw new JsonParseException ( \"document doesn't start with a valid json element\" , new JsonLocation ( \"\\\"\" + jsonString . substring ( 0 , 100 ) + \"...\\\"\" , 0 , 1 , 0 ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Fix", "cache", "hit", "in", "background", "threads", "to", "use", "correct", "key", "."], "add_tokens": "cached = memoryCache . get ( request . key ) ;", "del_tokens": "String path = request . path ; cached = memoryCache . get ( path ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adds", "required", "methods", "to", "use", "in", "forge", "."], "add_tokens": "import org . arquillian . container . chameleon . spi . model . Target ; \"Make sure that this file exists in classpath resource or in the project folder.\" ) ; ClassLoader classLoader = Target . class . getClassLoader ( ) ; }", "del_tokens": "\"Something is terrible wrong with the Classpath.\" ) ; ClassLoader classLoader = Thread . currentThread ( ) . getContextClassLoader ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["added", "summer", "filter", ".", "Fixed", "vignetter", "filter"], "add_tokens": "texture = ImageIO . read ( getClass ( ) . getResource ( \"/com/sksamuel/scrimage/filter/texture_old_square.jpg\" ) ) ;", "del_tokens": "texture = ImageIO . read ( getClass ( ) . getResource ( \"/texture_old_square.jpg\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "extra", "constructors", "to", "allow", "reusing", "thread", "-", "safe", "ObjectWriter", "objects"], "add_tokens": "public PKFileBasedSigningUtil ( ) { super ( new ObjectMapper ( ) ) ; } @ Inject public PKFileBasedSigningUtil ( ObjectWriter objectWriter ) { super ( objectWriter ) ; } @ Deprecated super ( objectMapper ) ;", "del_tokens": "import java . security . Security ; import org . bouncycastle . jce . provider . BouncyCastleProvider ; import com . fasterxml . jackson . annotation . JsonFilter ; private ObjectWriter objectWriter ; addBCProvider ( ) ; objectWriter = configureObjectMapper ( objectMapper ) ; @ JsonFilter ( \"pkPassFilter\" ) private class PkPassFilterMixIn { // just a dummy } @ JsonFilter ( \"validateFilter\" ) private class ValidateFilterMixIn { // just a dummy } @ JsonFilter ( \"barcodeFilter\" ) private class BarcodeFilterMixIn { // just a dummy } @ JsonFilter ( \"charsetFilter\" ) private class CharsetFilterMixIn { // just a dummy } private void addBCProvider ( ) { if ( Security . getProvider ( BouncyCastleProvider . PROVIDER_NAME ) == null ) { Security . addProvider ( new BouncyCastleProvider ( ) ) ; } }", "commit_type": "add"}
{"commit_tokens": ["Added", "multiple", "global", "error", "handlers", "/", "writers"], "add_tokens": "readerType + \"' in: '\" + bodyReader . getClass ( ) + \"'\" ) ; @ SafeVarargs @ SafeVarargs", "del_tokens": "readerType + \"' in: '\" + bodyReader . getClass ( ) + \"'\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "getRevocationList", "to", "add", "support", "for", "user", "-", "specified", "issuer", "name", "and", "serial", "number", ".", "Fixed", "issue", "47", "."], "add_tokens": "import javax . security . auth . x500 . X500Principal ; public X509CRL getRevocationList ( X500Principal issuer , BigInteger serial ) throws IOException , OperationFailureException { X509Name name = new X509Name ( issuer . getName ( ) ) ; IssuerAndSerialNumber iasn = new IssuerAndSerialNumber ( name , serial ) ;", "del_tokens": "public X509CRL getRevocationList ( ) throws IOException , OperationFailureException { X509Name name = new X509Name ( ca . getIssuerX500Principal ( ) . toString ( ) ) ; BigInteger serialNumber = ca . getSerialNumber ( ) ; IssuerAndSerialNumber iasn = new IssuerAndSerialNumber ( name , serialNumber ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", "reconnection", "policies"], "add_tokens": "private ReconnectPolicy reconnectPolicy = ReconnectPolicy . Provided . NEVER . newObject ( ) ; * Specify the reconnection policy for the socket connection . * Note : This option has no effect when using non - blocking * connections . * / public ApnsServiceBuilder withReconnectPolicy ( ReconnectPolicy rp ) { this . reconnectPolicy = rp ; return this ; } / * * * Specify the reconnection policy for the socket connection . public ApnsServiceBuilder withReconnectPolicy ( ReconnectPolicy . Provided rp ) { this . reconnectPolicy = rp . newObject ( ) ; ApnsConnection conn = new ApnsConnectionImpl ( sslFactory , gatewayHost , gatewaPort , reconnectPolicy ) ;", "del_tokens": "private boolean forceReconnect = false ; * Specify that a new connection is established for every * message . This is helpful in debugging mode . * This is helpful in debugging mode , to ensure that a corrupted * message doesn 't affect the subsequent messages delivery. * * Apple may ban your provider , if you send a lot of messages * with this enabled as they may mistakenly assume you are * performing a DoS attack . public ApnsServiceBuilder withForceReconnect ( ) { this . forceReconnect = true ; ApnsConnection conn = new ApnsConnectionImpl ( sslFactory , gatewayHost , gatewaPort , forceReconnect ) ;", "commit_type": "add"}
{"commit_tokens": ["Create", "getter", "method", "in", "classes", "utility", "."], "add_tokens": "* camel case . For example , getter for < em > email - addresses < / em > is < em > getEmailAddresses < / em > and for < em > picture < / em >", "del_tokens": "* camel case . For example getter for < em > email - addresses < / em > is < em > getEmailAddresses < / em > and for < em > picture < / em >", "commit_type": "create"}
{"commit_tokens": ["Added", "JSON", "serializer", "and", "deserializer", "for", "Timecode", "classes", "."], "add_tokens": "package com . glookast . commons . timecode . xml ; import com . glookast . commons . timecode . AbstractTimecode ; import com . glookast . commons . timecode . Timecode ;", "del_tokens": "package com . glookast . commons . timecode ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "new", "generic", "transform", "to", "the", "basic", "extensions", ".", "This", "will", "enable", "users", "to", "change", "the", "predefined", "severities", "of", "compatibility", "types", "on", "found", "differences", ".", "Useful", "for", "example", "to", "force", "@Deprecated", "elements", "as", "breakages", "to", "force", "them", "to", "be", "explicitely", "ignored", "and", "thus", "reported", "on", "."], "add_tokens": "* An element filter that can filter out elements based on matching their full human readable representations .", "del_tokens": "* An element filter that can filter out elements based on matching their full human readable reprensentations .", "commit_type": "add"}
{"commit_tokens": ["Updated", "tests", "to", "use", "JSONAssert", "framework"], "add_tokens": "JSONObject expected = new JSONObject ( expectedStr ) ; JSONObject actual = new JSONObject ( actualStr ) ; assertEquals ( expected , actual , strict ) ; } public static void assertEquals ( String expectedStr , JSONObject actual , boolean strict ) throws JSONException { JSONObject expected = new JSONObject ( expectedStr ) ; assertEquals ( expected , actual , strict ) ; } public static void assertEquals ( JSONObject expected , JSONObject actual , boolean strict ) throws JSONException { JSONAssertResult result = compareJSON ( expected , actual , strict ) ; // Entry for unit tests throws JSONException return compareJSON ( expected , actual , strict ) ; } protected static JSONAssertResult compareJSON ( JSONObject expected , JSONObject actual , boolean strict ) throws JSONException {", "del_tokens": "JSONAssertResult result = compareJSON ( expectedStr , actualStr , strict ) ; throws JSONException", "commit_type": "update"}
{"commit_tokens": ["Improve", "content", "-", "type", "suffix", "Swagger", "notes"], "add_tokens": "sb . append ( \"\\n\\n\" ) ; sb . append ( \"#### \" ) ; String header = \"Content-Type Suffixes\" ; if ( messages != null ) { header = messages . getWithDefault ( \"swagger.contentTypeSuffixHeader\" , header , \"\" ) ; } sb . append ( header ) ; String message = \"A Content-Type suffix is **required**.\" ; sb . append ( message ) ; String message = \"A Content-Type suffix is *optional*.\" ; sb . append ( message ) ;", "del_tokens": "String message = \"A Content-Type suffix is required.\" ; sb . append ( \"**\" ) . append ( message ) . append ( \"**\" ) ; String message = \"A Content-Type suffix is optional.\" ; sb . append ( \"*\" ) . append ( message ) . append ( \"*\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "helper", "to", "extension", "for", "configuring", "multimodule", "run"], "add_tokens": "runTask . dependsOn ( project . getTasks ( ) . findByName ( BasePlugin . ASSEMBLE_TASK_NAME ) ) ; startTask . dependsOn ( project . getTasks ( ) . findByName ( BasePlugin . ASSEMBLE_TASK_NAME ) ) ;", "del_tokens": "runTask . dependsOn ( BasePlugin . ASSEMBLE_TASK_NAME ) ; startTask . dependsOn ( BasePlugin . ASSEMBLE_TASK_NAME ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "of", "cross", "domain"], "add_tokens": "* LastModified : Mar 2 , 2015 * if ( method . equals ( \"GET\" ) ) { if ( getEnabled ) { ostream = doFunctionList ( methods , httpContext ) ; ostream . writeTo ( httpContext . getResponse ( ) . getOutputStream ( ) ) ; } else { httpContext . getResponse ( ) . sendError ( HttpServletResponse . SC_FORBIDDEN ) ; } }", "del_tokens": "* LastModified : Apr 17 , 2014 * if ( method . equals ( \"GET\" ) && getEnabled ) { ostream = doFunctionList ( methods , httpContext ) ; ostream . writeTo ( httpContext . getResponse ( ) . getOutputStream ( ) ) ; else { httpContext . getResponse ( ) . sendError ( HttpServletResponse . SC_FORBIDDEN ) ; } }", "commit_type": "fix"}
{"commit_tokens": ["Fix", "how", "we", "run", "tests", "against", "a", "secured", "cluster"], "add_tokens": "import org . elasticsearch . client . RestClient ; import static org . junit . Assume . assumeTrue ; // If a user is defined, we just ignore the tests as we did not bring in the deprecated // transport secured client assumeTrue ( \"Transport tests are not run on a secured cluster\" , testClusterUser == null ) ; RestClient restClient = restClient ( ) ; . addTransportAddress ( new TransportAddress ( new InetSocketAddress ( restClient . getNodes ( ) . get ( 0 ) . getHost ( ) . getHostName ( ) , testClusterTransportPort ) ) ) ;", "del_tokens": "restClient ( ) ; . addTransportAddress ( new TransportAddress ( new InetSocketAddress ( testClusterHost , testClusterTransportPort ) ) ) ; private static boolean testClusterRunning ( boolean withSecurity ) throws IOException { try { NodesInfoResponse response = client . admin ( ) . cluster ( ) . prepareNodesInfo ( ) . get ( ) ; Version version = response . getNodes ( ) . get ( 0 ) . getVersion ( ) ; logger . info ( \"Starting integration tests against an external cluster running elasticsearch [{}] with {}\" , version , withSecurity ? \"security\" : \"no security\" ) ; return withSecurity ; // } catch (NoNodeAvailableException e) { // // If we have an exception here, let's ignore the test // logger.warn(\"Integration tests are skipped: [{}]\", e.getMessage()); // assumeThat(\"Integration tests are skipped\", e.getMessage(), not(containsString(\"Connection refused\"))); // return withSecurity; } catch ( NoNodeAvailableException e ) { if ( e . getMessage ( ) == \"401\" ) { logger . debug ( \"The cluster is secured. So we need to build a client with security\" , e ) ; return true ; } else { logger . error ( \"Full error is\" , e ) ; throw e ; } } }", "commit_type": "fix"}
{"commit_tokens": ["updated", "needed", "dependency", "use", "guava"], "add_tokens": "import com . google . common . collect . Lists ;", "del_tokens": "import jersey . repackaged . com . google . common . collect . Lists ;", "commit_type": "update"}
{"commit_tokens": ["fixed", "error", "when", "database", "type", "is", "timestamp", "and", "object", "type", "id", "java", ".", "util", ".", "Date"], "add_tokens": "Class valueClass = getValueClass ( value ) ; method = objClass . getMethod ( methodName , valueClass ) ; catch ( NoSuchMethodException ex ) { // if error, try using jodatime if ( java . util . Date . class . equals ( valueClass ) ) { private Class getValueClass ( Object value ) { Class valClass = value . getClass ( ) ; if ( java . util . Date . class . isAssignableFrom ( valClass ) ) { return java . util . Date . class ; } else { return valClass ; } }", "del_tokens": "import java . nio . channels . NonWritableChannelException ; method = objClass . getMethod ( methodName , value . getClass ( ) ) ; catch ( NoSuchMethodException ex ) { if ( java . util . Date . class . isAssignableFrom ( value . getClass ( ) ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "BD", "-", "11", ":", "Spider", ":", "multi", "-", "level", "aggregate", "query", "with", "filtering", "causes", "NPE"], "add_tokens": "mergeParameters ( branch , entry ) ; query . subqueries . add ( entry2 . query ) ; if ( USEQUERYCACHE ) { entry1 . queryCache = new LRUCache < ObjectID , Boolean > ( QUERYCACHECAPACITY ) ; } QueryExecutor qe = new QueryExecutor ( entry1 . tableDef ) ; entry1 . filter = qe . filter ( entry1 . query ) ;", "del_tokens": "mergeParameters ( this , branch ) ; query . subqueries . add ( entry1 . query ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "of", "calling", "/", "me", "/", "photos", "."], "add_tokens": "public class PagedTests extends TestBase static class Comment { String id ; String message ; } static class Photo { String id ; String name ; Paged < Comment > comments ; } / * * * Getting photos and comments . You 'll need to modify this code to reflect your particular photo content. * / @ Test public void photos ( ) throws Exception { PagedLater < Photo > photos = this . authBatcher . paged ( \"me/photos\" , Photo . class ) ; assert photos . get ( ) . size ( ) > 0 ; Photo first = photos . get ( ) . get ( 0 ) ; assert first . name . contains ( \"Deadwood mustache\" ) ; assert first . comments . getData ( ) . size ( ) > 0 ; assert first . comments . getData ( ) . get ( 0 ) . message . contains ( \"Jeff gave up on his\" ) ; }", "del_tokens": "public class ConnectionTests extends TestBase", "commit_type": "add"}
{"commit_tokens": ["Fix", "java", ".", "lang", ".", "IllegalStateException", ":", "allow", "state", "loss", "when", "showing", "dialog"], "add_tokens": "frag . showAllowingStateLoss ( ft , FRAGMENT_TAG ) ;", "del_tokens": "frag . show ( ft , FRAGMENT_TAG ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "additional", "javadoc", "comments", "."], "add_tokens": "/ * * * Configuration of scheduler . * / private boolean manualStart = false ;", "del_tokens": "private boolean manualStart ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "logging", "if", "no", "zone", "found"], "add_tokens": "// only log the exception and the message, Hazelcast should still start getLogger ( ) . warning ( \"Cannot fetch the current zone, ZONE_AWARE feature is disabled\" ) ;", "del_tokens": "getLogger ( ) . warning ( \"Cannot fetch the current zone, ZONE_AWARE feature is disabled\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["changing", "default", "presentationML", "for", "emoji", "to", "its", "unicode"], "add_tokens": "if ( this . getChildren ( ) . isEmpty ( ) ) { out . append ( EmojiShortcodeToUnicode . getUnicode ( shortcode ) ) ; } else { for ( Element child : getChildren ( ) ) { child . asPresentationML ( out ) ; } @ Override public String asText ( ) { StringBuilder b = new StringBuilder ( ) ; if ( this . getChildren ( ) . isEmpty ( ) ) { b . append ( EmojiShortcodeToUnicode . getUnicode ( shortcode ) ) ; } else { for ( Element child : this . getChildren ( ) ) { b . append ( child . asText ( ) ) ; } } return b . toString ( ) ; }", "del_tokens": "* for ( Element child : getChildren ( ) ) { child . asPresentationML ( out ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "error", "handler", "to", "the", "servlet", "example"], "add_tokens": "/ * * * Simple servlet example * / } catch ( RuntimeException e ) { } catch ( RuntimeException ex ) { bugsnag . notify ( ex , Severity . INFO ) ; // Throw an exception - not automatically reported so must be handled by the error handler throw new ServletException ( \"Servlet exception\" ) ;", "del_tokens": "} catch ( RuntimeException e ) { } catch ( RuntimeException e ) { bugsnag . notify ( e , Severity . INFO ) ; // Throw an exception throw new ServletException ( \"Unhandled exception\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "setting", "log", "-", "level", "and", "security", "-", "log", "-", "level", "globally", "for", "tests", "from", "command", "-", "line", "logLevel", "and", "securityLogLevel", "properties"], "add_tokens": "* This returns the log level configured for the test run . * It can be configured globally for dunit tests using * \"logLevel\" system property . *", "del_tokens": "* This finds the log level configured for the test run . It should be used * when creating a new distributed system if you want to specify a log level .", "commit_type": "allow"}
{"commit_tokens": ["fix", "some", "ali", "code", "warnings"], "add_tokens": "/ * * * 我们向外暴露出只读map,供session数量监控使用 * /", "del_tokens": "//我们向外暴露出只读map,供session数量监控使用", "commit_type": "fix"}
{"commit_tokens": ["remove", "v5", "sample", "item", "as", "the", "api", "is", "still", "experimental"], "add_tokens": "new SampleItem ( \"Directions\" , \"\" , DirectionsV4Activity . class ) , //new SampleItem(\"Directions v5\", \"\", DirectionsV5Activity.class),", "del_tokens": "new SampleItem ( \"Directions v4\" , \"\" , DirectionsV4Activity . class ) , new SampleItem ( \"Directions v5\" , \"\" , DirectionsV5Activity . class ) ,", "commit_type": "remove"}
{"commit_tokens": ["change", "customProperties", "signature", "and", "fix", "test"], "add_tokens": "public MessageBuilder customProperties ( Map < String , String > fullPayLoad ) {", "del_tokens": "public MessageBuilder customProperties ( Map < String , Object > fullPayLoad ) {", "commit_type": "change"}
{"commit_tokens": ["Create", "static", "lock", "in", "order", "to", "synchronize", "the", "reading", "process"], "add_tokens": "private final boolean checkTimeout ; //Create static lock in order to synchronize the reading process private static final Object LOCK = new Object ( ) ; synchronized ( LOCK ) {", "del_tokens": "private volatile boolean checkTimeout ; synchronized ( this ) {", "commit_type": "create"}
{"commit_tokens": ["changed", "the", "filter", "test", "back", "to", "be", "3", ".", "x", "compatible"], "add_tokens": "Tokenizer tokenizer = new MockTokenizer ( new StringReader ( aInput ) ) ; / * Do we want a KEYWORD tokenizer ? The default is WHITESPACE . * * For now , we 'll use the default, but the below will need to be * backported to work with 3. x if we want to use a KEYWORD config * * new MockTokenizer ( new StringReader ( aInput ) , MockTokenizer . KEYWORD , * false ) ; * /", "del_tokens": "Tokenizer tokenizer = new MockTokenizer ( new StringReader ( aInput ) , MockTokenizer . KEYWORD , false ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "clear", "instead", "of", "resetting", "position", "where", "applicable"], "add_tokens": "lineColorBuffer . clear ( ) ; lineCoordinatesBuffer . clear ( ) ; particlesTrianglesCoordinates . clear ( ) ;", "del_tokens": "} else { lineCoordinatesBuffer . position ( 0 ) ; } else { lineColorBuffer . position ( 0 ) ; particlesTrianglesCoordinates . position ( 0 ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "bug", "where", "all", "but", "the", "last", "statement", "in", "a", "statement", "block", "in", "a", "Speck", "method", "where", "lost"], "add_tokens": "import org . spockframework . util . InternalSpockError ; if ( result == null ) throw new InternalSpockError ( \"result not set\" ) ; public void visitBlockStatement ( BlockStatement stat ) { ListIterator < Statement > iter = stat . getStatements ( ) . listIterator ( ) ; result = stat ;", "del_tokens": "public void visitBlockStatement ( BlockStatement block ) { ListIterator < Statement > iter = block . getStatements ( ) . listIterator ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "unit", "tests", "and", "handling", "of", "integer", "vs", "long", "datatypes"], "add_tokens": "List < Object > claimArr ; Object [ ] claimAsObject = claim . as ( Object [ ] . class ) ; // Jackson uses 'natural' mapping which uses Integer if value fits in 32 bits. if ( value instanceof Long [ ] ) { // convert Integers to Longs for comparison with equals claimArr = new ArrayList < > ( claimAsObject . length ) ; for ( Object cao : claimAsObject ) { if ( cao instanceof Integer ) { claimArr . add ( ( ( Integer ) cao ) . longValue ( ) ) ; } else { claimArr . add ( cao ) ; } } } else { claimArr = Arrays . asList ( claim . as ( Object [ ] . class ) ) ; }", "del_tokens": "List < Object > claimArr = Arrays . asList ( claim . as ( Object [ ] . class ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "to", "a", "domain", "that", "really", "does", "not", "exist", "."], "add_tokens": "UrlSourceLoader sourceLoader = new UrlSourceLoader ( folder . getRoot ( ) . toURI ( ) . toURL ( ) , new URL ( \"http://domainthatreallydoesnotexistsdfsmshjsfsj.com\" ) , \"UTF-8\" ) ;", "del_tokens": "UrlSourceLoader sourceLoader = new UrlSourceLoader ( folder . getRoot ( ) . toURI ( ) . toURL ( ) , new URL ( \"http://domainthatdoesnotexist.com\" ) , \"UTF-8\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Remove", "use", "of", "com", ".", "google", ".", "common", ".", "base", ".", "Throwables"], "add_tokens": "if ( throwable instanceof Error ) { throw ( Error ) throwable ; } if ( throwable instanceof RuntimeException ) { throw ( RuntimeException ) throwable ; } if ( throwable instanceof InterruptedException ) { Thread . currentThread ( ) . interrupt ( ) ; } throw new RuntimeException ( throwable ) ;", "del_tokens": "import com . google . common . base . Throwables ; throw Throwables . propagate ( throwable ) ;", "commit_type": "remove"}
{"commit_tokens": ["Moved", "the", "short", "name", "generation", "from", "FarLfnDirector", "to", "the", "new", "ShortNameGenerator", "class", "."], "add_tokens": "realEntry . setName ( parent . getShortNameGenerator ( ) . generateShortName ( newName ) ) ;", "del_tokens": "realEntry . setName ( parent . generateShortNameFor ( newName ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "predictable", "map", "ordering", "on", "URL", "tests", "that", "were", "failing", "JDK8", "UTs"], "add_tokens": "import java . net . URLEncoder ; + \"?objectMask=\" + URLEncoder . encode ( service . withMask ( ) . getMask ( ) , \"UTF-8\" ) , http . fullUrl ) ; + \"?objectMask=\" + URLEncoder . encode ( mask . getMask ( ) , \"UTF-8\" ) , http . fullUrl ) ;", "del_tokens": "+ \"?objectMask=mask%5Bbar%2Cchild%5Bbaz%2Cdate%5D%5D\" , http . fullUrl ) ; + \"?objectMask=mask%5Bbar%2Cchild%5Bbaz%2Cdate%5D%5D\" , http . fullUrl ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "delete", "and", "delete", "in", "transaction", "tests"], "add_tokens": "import java . util . ArrayList ; SugarRecord . delete ( model ) ; @ Test public void deleteInTransactionFewTest ( ) throws Exception { SimpleExtendedModel first = new SimpleExtendedModel ( ) ; SimpleExtendedModel second = new SimpleExtendedModel ( ) ; SimpleExtendedModel third = new SimpleExtendedModel ( ) ; save ( first ) ; save ( second ) ; save ( third ) ; assertEquals ( 3L , SugarRecord . count ( SimpleExtendedModel . class ) ) ; SugarRecord . deleteInTx ( first , second , third ) ; assertEquals ( 0L , SugarRecord . count ( SimpleExtendedModel . class ) ) ; } @ Test public void deleteInTransactionManyTest ( ) throws Exception { List < SimpleExtendedModel > models = new ArrayList < > ( ) ; for ( int i = 1 ; i <= 100 ; i ++ ) { SimpleExtendedModel model = new SimpleExtendedModel ( ) ; models . add ( model ) ; save ( model ) ; } assertEquals ( 100L , SugarRecord . count ( SimpleExtendedModel . class ) ) ; SugarRecord . deleteInTx ( models ) ; assertEquals ( 0L , SugarRecord . count ( SimpleExtendedModel . class ) ) ; }", "del_tokens": "model . delete ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "SingleFileMergeIterator", "as", "it", "is", "now", "replaced", "by", "ChunkFile", "."], "add_tokens": "private static class MultiFileMergeIterator < T > implements MergeIterator < T > {", "del_tokens": "// return new SingleFileMergeIterator<T>(sortedChunk, handler, config.cleanup, config.distinct, config.bufferSize); // public static class SingleFileMergeIterator<T> implements MergeIterator<T> { // // private final ChunkFile<T> cf; // // private final boolean cleanup; // private final boolean distinct; // // private T next; // // SingleFileMergeIterator(File file, SortHandler<T> handler, boolean cleanup, boolean distinct, int bufferSize) throws IOException { // this.cf = new ChunkFile<T>(file, handler, bufferSize); // this.cleanup = cleanup; // this.distinct = distinct; // readNext(); // } // // private void readNext() { // T next_ = null; // while (cf.hasNext()) { // next_ = cf.next(); // if (!distinct || !next_.equals(next)) { // break; // } // }; // this.next = next_; // } // // @Override // public boolean hasNext() { // return next != null; // } // // @Override // public T next() { // T result = next; // readNext(); // return result; // } // // @Override // public void remove() { // throw new UnsupportedOperationException(); // } // // @Override // public void close() throws IOException { // cf.close(); // if (cleanup) { // cf.delete(); // } // } // // } public static class MultiFileMergeIterator < T > implements MergeIterator < T > {", "commit_type": "remove"}
{"commit_tokens": ["Fix", "internal", "references", "for", "Inlineable", "types", "."], "add_tokens": "JavaType builderType = TypeAs . SHALLOW_BUILDER . apply ( item . getType ( ) ) ; . withName ( \"item\" ) . withType ( item . getType ( ) ) . addToAttributes ( BODY , \"this.builder=new \" + builderType . getSimpleName ( ) + \"(this, item);this.visitor=visitor;\" )", "del_tokens": ". withName ( \"builder\" ) . withType ( builderProperty . getType ( ) ) . addToAttributes ( BODY , \"this.builder=builder;this.visitor=visitor;\" )", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "in", "OpenstackClient", "regarding", "network", "retrievement"], "add_tokens": "if ( jcloudsNetwork . getNetworkType ( ) != null ) network . setNetworkType ( jcloudsNetwork . getNetworkType ( ) . toString ( ) ) ; if ( jcloudsNetwork . getSegmentationId ( ) != null ) network . setSegmentationId ( jcloudsNetwork . getSegmentationId ( ) ) ;", "del_tokens": "network . setNetworkType ( jcloudsNetwork . getNetworkType ( ) . toString ( ) ) ; network . setSegmentationId ( jcloudsNetwork . getSegmentationId ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "a", "fixed", "session", "ID"], "add_tokens": "import com . helger . commons . lang . ClassHelper ; import com . helger . quartz . JobDataMap ; final OfflineHttpServletRequest ret = new OfflineHttpServletRequest ( WebScopeManager . getGlobalScope ( ) . getServletContext ( ) , false ) ; // Use a fixed session ID, because Quartz jobs regularly use the session and // this avoids spanning too many sessions ret . setSessionID ( \"quartz.job.\" + ClassHelper . getClassLocalName ( getClass ( ) ) ) ; return ret ;", "del_tokens": "import com . helger . quartz . JobDataMap ; return new OfflineHttpServletRequest ( WebScopeManager . getGlobalScope ( ) . getServletContext ( ) , false ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "helper", "options", "(", "Map", ")", "method", "to", "support", "custom", "options", "lookup", "implementations"], "add_tokens": "import java . util . Map ; @ SuppressWarnings ( { \"PMD.ExcessiveImports\" , \"PMD.TooManyMethods\" , \"PMD.ExcessiveClassLength\" } ) / * * * Sets multiple options at once . No options lookup mechanism provided out of the box ( like for bundles ) , * but it 's very easy to implement custom lookup solution (e.g. for providing specific options in tests). * This method would be useful for such lookup implementations . * < p > * Note : { @ link Option } type is not mixed with enum in declaration to simplify usage , * but used enums must be correct options . * * @ param options options map ( not null ) * @ param < K > helper type for option signature definition * @ return builder instance for chained calls * @ throws NullPointerException is null value provided for any option * @ throws IllegalArgumentException if any provided value incompatible with option type * @ see # option ( Enum , Object ) for more info * / @ SuppressWarnings ( \"unchecked\" ) public < K extends Enum & Option > Builder < T > options ( final Map < Enum , Object > options ) { ( ( Map < K , Object > ) ( Map ) options ) . forEach ( this :: option ) ; return this ; }", "del_tokens": "@ SuppressWarnings ( { \"PMD.ExcessiveImports\" , \"PMD.TooManyMethods\" } )", "commit_type": "add"}
{"commit_tokens": ["Adding", "PUT", "as", "allowed", "method", "."], "add_tokens": "CORSConfiguration . DEFAULT_ALLOWED_HTTP_METHODS + \",PUT\" ; CORSConfiguration . DEFAULT_ALLOWED_HTTP_METHODS + \",PUT\" ;", "del_tokens": "CORSConfiguration . DEFAULT_ALLOWED_HTTP_METHODS ; CORSConfiguration . DEFAULT_ALLOWED_HTTP_METHODS ;", "commit_type": "add"}
{"commit_tokens": ["Added", "URI", "path", "matching", "and", "updated", "readme", "with", "JAX", "-", "RS", "plans"], "add_tokens": "@ Test public void canGetOne ( ) throws IOException { try ( okhttp3 . Response resp = call ( request ( ) . url ( server . uri ( ) . resolve ( \"/api/fruits/orange\" ) . toString ( ) ) ) ) { assertThat ( resp . code ( ) , is ( 200 ) ) ; assertThat ( resp . body ( ) . string ( ) , is ( \"{ \\\"name\\\": \\\"orange\\\" }\" ) ) ; } }", "del_tokens": "import ronin . muserver . Method ; import scaffolding . ClientUtils ; import javax . ws . rs . core . Response ; import java . net . URI ;", "commit_type": "add"}
{"commit_tokens": ["Added", "null", "check", "in", "paginator"], "add_tokens": "if ( fields != null ) { search . setFields ( fields ) ; }", "del_tokens": "search . setFields ( fields ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "auto", "create", "container", "flag", "in", "reactive", "repository"], "add_tokens": "if ( this . entityInformation . isAutoCreateContainer ( ) ) { createContainerIfNotExists ( ) ; } if ( this . entityInformation . isAutoCreateContainer ( ) ) { createContainerIfNotExists ( ) ; }", "del_tokens": "createContainerIfNotExists ( ) ; createContainerIfNotExists ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "bogus", "CPIO", "stream", "."], "add_tokens": "int total = 0 ; total = header . write ( compressor , total ) ; while ( in . read ( ( ByteBuffer ) buffer . rewind ( ) ) > 0 ) total += compressor . write ( ( ByteBuffer ) buffer . flip ( ) ) ; total += header . skip ( compressor , total ) ; total = trailer . write ( compressor , total ) ; trailer . skip ( compressor , total ) ;", "del_tokens": "header . write ( compressor ) ; while ( in . read ( ( ByteBuffer ) buffer . rewind ( ) ) > 0 ) compressor . write ( ( ByteBuffer ) buffer . flip ( ) ) ; Util . empty ( compressor , ByteBuffer . wrap ( new byte [ Util . round ( header . getFileSize ( ) , 3 ) - ( int ) source . length ( ) ] ) ) ; trailer . write ( compressor ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "latest", "validation", "artefacts"], "add_tokens": "private static final LocalDate LAST_MOD = PDTFactory . createLocalDate ( 2017 , Month . NOVEMBER , 21 ) ;", "del_tokens": "private static final LocalDate LAST_MOD = PDTFactory . createLocalDate ( 2017 , Month . OCTOBER , 4 ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "support", "for", "slot", "expressions"], "add_tokens": "throw new RmModelException ( \"No attribute [%s] on rm type [%s]\" , attribute , rmType . getRmType ( ) ) ;", "del_tokens": "throw new RmModelException ( \"No attribute %s on rm type %s\" , attribute , rmType . getRmType ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "wro4j", "work", "in", "reactor", "build"], "add_tokens": "import org . springframework . boot . builder . SpringApplicationBuilder ; @ IntegrationTest ( { \"server.port=0\" , \"spring.application.name=eureka\" , \"management.contextPath=/admin\" } ) new SpringApplicationBuilder ( Application . class ) . properties ( \"spring.application.name=eureka\" , \"management.contextPath=/admin\" ) . run ( args ) ; ResponseEntity < Map > entity = new TestRestTemplate ( ) . getForEntity ( \"http://localhost:\" + port + \"/v2/apps\" , Map . class ) ; ResponseEntity < Map > entity = new TestRestTemplate ( ) . getForEntity ( \"http://localhost:\" + port + \"/admin/env\" , Map . class ) ;", "del_tokens": "@ IntegrationTest ( { \"server.port=0\" , \"spring.application.name=eureka\" , \"management.contextPath=/admin\" } ) SpringApplication . run ( Application . class , args ) ; ResponseEntity < Map > entity = new TestRestTemplate ( ) . getForEntity ( \"http://localhost:\" + port + \"/v2/apps\" , Map . class ) ; ResponseEntity < Map > entity = new TestRestTemplate ( ) . getForEntity ( \"http://localhost:\" + port + \"/admin/env\" , Map . class ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "generic", "protoloader", "instead", "of", "requiring", "pre", "-", "generated", "ProtobufLoaders", "."], "add_tokens": "import com . twitter . elephantbird . pig . load . LzoProtobufB64LinePigLoader ; sb . append ( protoToPig_ . toPigScript ( msgDescriptor , LzoProtobufB64LinePigLoader . class . getCanonicalName ( ) , String . format ( \"%s.%s\" , packageName_ , descriptorProto_ . getName ( ) ) ) ) . endl ( ) ;", "del_tokens": "String loaderClassname = String . format ( \"%s.pig.load.Lzo%sProtobufB64LinePigLoader\" , packageName_ , descriptorProto_ . getName ( ) ) ; sb . append ( protoToPig_ . toPigScript ( msgDescriptor , loaderClassname ) ) . endl ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Removing", "Java", "8", "specific", "code"], "add_tokens": "public class DiscoveryErrors { // TODO: Use or delete this class", "del_tokens": "public class DiscoveryErrors {", "commit_type": "remove"}
{"commit_tokens": ["Changed", "milestones", "to", "use", "duration", "values"], "add_tokens": "public static final int NEXT_STEP_DURATION_SECONDS = 0x00000011 ; SparseArray < Number [ ] > statementObjects = new SparseArray < > ( 13 ) ; statementObjects . put ( TriggerProperty . NEXT_STEP_DURATION_SECONDS , new Number [ ] { routeProgress . currentLegProgress ( ) . upComingStep ( ) != null ? routeProgress . currentLegProgress ( ) . upComingStep ( ) . getDuration ( ) : 0 } ) ;", "del_tokens": "SparseArray < Number [ ] > statementObjects = new SparseArray < > ( 12 ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "typo", "!", "=", "vs", "=="], "add_tokens": "if ( response == null ) {", "del_tokens": "if ( response != null ) {", "commit_type": "fix"}
{"commit_tokens": ["updating", "as", "per", "rewivew", ":", "adding", "final", "and", "getting", "the", "class", "logger"], "add_tokens": "private static final Log LOG = LogFactory . getLog ( JobFile . class ) ;", "del_tokens": "private static Log LOG = LogFactory . getLog ( JobFilePreprocessor . class ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "nature", "param", "for", "ansj", "server"], "add_tokens": "String method = paramers . get ( \"method\" ) ; String nature = paramers . get ( \"nature\" ) ; responseMsg = AnsjServlet . processRequest ( input , method , nature ) ;", "del_tokens": "String method = paramers . get ( \"method\" ) ; responseMsg = AnsjServlet . processRequest ( input , method ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "parsing", "geplande", "storing", "without", "date"], "add_tokens": "Date datum = null ; if ( storingXml . isPresent ( \"Datum\" ) ) { datum = format . parse ( storingXml . child ( \"Datum\" ) . content ( ) ) ; }", "del_tokens": "Date datum = format . parse ( storingXml . child ( \"Datum\" ) . content ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "inflater", "/", "deflater", "in", "IO", "test", "."], "add_tokens": "import java . util . zip . DeflaterOutputStream ; import java . util . zip . InflaterInputStream ; DeflaterOutputStream os = new DeflaterOutputStream ( new FileOutputStream ( \"da.dat\" ) ) ; os . finish ( ) ; os . flush ( ) ; da . load ( new InflaterInputStream ( new FileInputStream ( \"da.dat\" ) ) ) ; da . dump ( ) ;", "del_tokens": "import java . io . OutputStream ; OutputStream os = new FileOutputStream ( \"da.dat\" ) ; da . load ( new FileInputStream ( \"da.dat\" ) ) ; da . dump ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "the", "RFC", "2822", "date", "set", "in", "the", "control", "file", "by", "the", "Processor"], "add_tokens": "import java . util . Locale ; private PackageDescriptor buildControl ( final File [ ] pControlFiles , final BigInteger pDataSize , final StringBuffer pChecksums , final File pOutput ) throws IOException , ParseException { SimpleDateFormat fmt = new SimpleDateFormat ( \"EEE, d MMM yyyy HH:mm:ss Z\" , Locale . ENGLISH ) ; // Mon, 26 Mar 2007 11:44:04 +0200 (RFC 2822) packageDescriptor . set ( \"Date\" , fmt . format ( new Date ( ) ) ) ;", "del_tokens": "private PackageDescriptor buildControl ( final File [ ] pControlFiles , final BigInteger pDataSize , final StringBuffer pChecksums , final File pOutput ) throws FileNotFoundException , IOException , ParseException { packageDescriptor . set ( \"Date\" , new SimpleDateFormat ( \"EEE, d MMM yyyy HH:mm:ss Z\" ) . format ( new Date ( ) ) ) ; // Mon, 26 Mar 2007 11:44:04 +0200", "commit_type": "fix"}
{"commit_tokens": ["Move", "receipt", "output", "to", "after", "the", "dispatcher", "as", "the", "buildId", "may", "not", "have", "been", "set", "before", "the", "dispatcher", "queue", "is", "flushed", "on", "shutdonw"], "add_tokens": "Optional < String > receipt = dispatcher . receipt ( ) ; if ( receipt . isPresent ( ) ) { logger . warn ( receipt . get ( ) ) ; }", "del_tokens": "Optional < String > receipt = dispatcher . receipt ( ) ; if ( receipt . isPresent ( ) ) { logger . warn ( receipt . get ( ) ) ; }", "commit_type": "move"}
{"commit_tokens": ["Fix", "test", "to", "pass", "when", "running", "in", "project", "."], "add_tokens": "import org . junit . BeforeClass ; private static InputStream defaultIn ; private static PrintStream defaultOut ; private static PrintStream defaultErr ; @ BeforeClass public static void setUpIO ( ) { defaultIn = System . in ; defaultOut = System . out ; defaultErr = System . err ; } thriftFile = temp . newFile ( \"cont.thrift\" ) ; IOUtils . copy ( getClass ( ) . getResourceAsStream ( \"/cont.thrift\" ) , file ) ; System . setErr ( defaultErr ) ; System . setOut ( defaultOut ) ; System . setIn ( defaultIn ) ; \"cont.Containers\" ) ;", "del_tokens": "thriftFile = temp . newFile ( \"test.thrift\" ) ; IOUtils . copy ( getClass ( ) . getResourceAsStream ( \"/test.thrift\" ) , file ) ; System . setErr ( null ) ; System . setOut ( null ) ; System . setIn ( null ) ; \"test.Containers\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "numerous", "NPE", "s", "and", "related", "bugs", "in", "the", "interpreter"], "add_tokens": "if ( out != null ) out . accept ( this ) ; if ( object . elseBlock != null ) object . elseBlock . accept ( this ) ; List < ? > list = ( ( List < ? > ) source ) ; else if ( source instanceof Map < ? , ? > ) { Map < ? , ? > map = ( ( Map < ? , ? > ) source ) ; return map . get ( index ) ; }", "del_tokens": "out . accept ( this ) ; object . elseBlock . accept ( this ) ; @ SuppressWarnings ( \"unchecked\" ) List < Object > list = ( ( List < Object > ) source ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "spec", "about", "before", "and", "after", "filter"], "add_tokens": "if ( server . before ( ) != null ) { final Action before = ( Action ) Routed . instanceFromTarget ( server . before ( ) ) ; before . run ( request , response ) ; } if ( ! response . responded ( ) ) { final Action action = ( Action ) routed . instanceFromTarget ( ) ; action . run ( request , response ) ; // After filter is run at Response#respond }", "del_tokens": "final Action action = ( Action ) routed . instanceFromTarget ( ) ; action . run ( request , response ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "default", "command", "in", "CLI", "IT"], "add_tokens": "import static org . assertj . core . api . Assertions . assertThat ; SeedRunner . execute ( new String [ ] { \"-a\" , \"-b\" , \"babar\" , \"zob\" , \"-Pkey1=value1\" , \"-Pkey2=value2\" } ) ; assertThat ( SampleCommandLineHandler . called ) . isTrue ( ) ; assertThat ( UnusedCommandLineHandler . called ) . isFalse ( ) ;", "del_tokens": "SeedRunner . execute ( new String [ ] { \"test\" , \"-a\" , \"-b\" , \"babar\" , \"zob\" , \"-Pkey1=value1\" , \"-Pkey2=value2\" } ) ;", "commit_type": "use"}
{"commit_tokens": ["remove", "a", "useless", "nested", "RuntimeException", "when", "an", "error", "occur", "during", "loading", "of", "plugins"], "add_tokens": "if ( ! started && isConnectedToDatabase ( ) ) { TimeProfiler profiler = new TimeProfiler ( ) . start ( \"Start services\" ) ; startCoreComponents ( ) ; startServiceComponents ( ) ; executeStartupTasks ( ) ; started = true ; profiler . stop ( ) ; private void startServiceComponents ( ) {", "del_tokens": "import java . io . IOException ; try { if ( ! started && isConnectedToDatabase ( ) ) { TimeProfiler profiler = new TimeProfiler ( ) . start ( \"Start services\" ) ; startCoreComponents ( ) ; startServiceComponents ( ) ; executeStartupTasks ( ) ; started = true ; profiler . stop ( ) ; } } catch ( Exception e ) { throw new ServerStartException ( e ) ; private void startServiceComponents ( ) throws ClassNotFoundException , IOException , InstantiationException , IllegalAccessException {", "commit_type": "remove"}
{"commit_tokens": ["Added", "comments", "and", "made", "an", "error", "message", "better"], "add_tokens": "/ * * * Performs a root finding search on the function f ( x ) = s . * * @ param a the minimum value in the range to look for the solution * @ param b the maximum value in the range to look for the solution * @ param f the function to use * @ param args the first value of this function must be the value s , * that we want to f ( x ) = s . All subsiquent arguments will be passed * to the function f in given order , and the first argument will be * adjusted . Ie : the search is for f ( x , v1 , v2 , v3 . . ) = s , where * all v will be heald constant . * * @ return the value x , such that f ( x ) = s * @ throws ArithmeticException if the desired value is not in the given range * / throw new ArithmeticException ( \"The given search interval doe snot appear to contain the desired root \" + shift ) ;", "del_tokens": "throw new ArithmeticException ( \"The given search interval doe snot appear to contain the desired root\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "features", "to", "RegularExpression", "."], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import com . google . common . base . Joiner ; public class Group < E > implements Expression < E > { public final List < Expression < E > > expressions ; public Group ( List < Expression < E > > expressions ) { this . expressions = expressions ; } @ Override public boolean apply ( E entity ) { throw new UnsupportedOperationException ( ) ; } @ Override public String toString ( ) { List < String > subs = new ArrayList < String > ( this . expressions . size ( ) ) ; for ( Expression < E > expr : this . expressions ) { subs . add ( expr . toString ( ) ) ; } return \"(\" + Joiner . on ( \" \" ) . join ( subs ) + \")\" ; } } public final Expression < E > expr ; public abstract boolean apply ( E entity ) ;", "del_tokens": "Expression < E > expr ; public abstract boolean apply ( E arg0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "the", "null", "coordinates", "element"], "add_tokens": "static JSONArray getJSONArray ( JSONObject obj , String name ) { if ( obj . get ( name ) == JSONObject . NULL ) return new JSONArray ( ) ; else return obj . getJSONArray ( name ) ; } JSONArray geometries = getJSONArray ( lastObject , \"geometries\" ) ; JSONArray coordinateArray = getJSONArray ( geometryJSONObject , \"coordinates\" ) ;", "del_tokens": "JSONArray geometries = lastObject . getJSONArray ( \"geometries\" ) ; JSONArray coordinateArray = geometryJSONObject . getJSONArray ( \"coordinates\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "end", "of", "line", "in", "test", "more", "independent", "from", "the", "OS"], "add_tokens": "/** system independent End Of Line */ private static final String EOL = System . getProperty ( \"line.separator\" ) ; @ Test assertEquals ( fileAsString ( \"/test.html\" ) . render ( ) , \"<body>\" + EOL + \" Any content\" + EOL + \"</body>\" + EOL ) ; assertEquals ( fileAsEscapedString ( \"/test.html\" ) . render ( ) , \"&lt;body&gt;\" + EOL + \" Any content\" + EOL + \"&lt;/body&gt;\" + EOL ) ; assertEquals ( fileAsString ( \"/test.java\" ) . render ( ) , \"public class AnyContent{}\" + EOL ) ;", "del_tokens": "@ Test assertEquals ( fileAsString ( \"/test.html\" ) . render ( ) , \"<body>\\r\\n\" + \" Any content\\r\\n\" + \"</body>\\r\\n\" ) ; assertEquals ( fileAsEscapedString ( \"/test.html\" ) . render ( ) , \"&lt;body&gt;\\r\\n\" + \" Any content\\r\\n\" + \"&lt;/body&gt;\\r\\n\" ) ; assertEquals ( fileAsString ( \"/test.java\" ) . render ( ) , \"public class AnyContent{}\\r\\n\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Improved", "look", "ahead", "test", "more", "closely", "follows", "Annex", "P"], "add_tokens": "/* 'look ahead test' from Annex P */ /* ascii */ /* c40 */ c40_count += ( 8.0 / 3.0 ) ; done = 1 ; /* text */ text_count += ( 8.0 / 3.0 ) ; done = 1 ; /* x12 */ x12_count += ( 10.0 / 3.0 ) ; } if ( inputData [ sp ] > 128 ) { x12_count += ( 3.0 / 4.0 ) ; /* edifact */ edf_count += ( 13.0 / 4.0 ) ; if ( inputData [ sp ] > 128 ) { edf_count += ( 4.0 / 3.0 ) ; } / * if ( sp >= ( sourcelen - 5 ) ) { } * / /* MMmmm fudge! */ /* base 256 */", "del_tokens": "/* A custom version of the 'look ahead test' from Annex P */ /* This version is deliberately very reluctant to end a data stream with EDIFACT encoding */ c40_count += ( 4.0 / 3.0 ) ; text_count += ( 4.0 / 3.0 ) ; x12_count += 4.0 ; edf_count += 6.0 ; if ( sp >= ( sourcelen - 5 ) ) { } /* MMmmm fudge! */", "commit_type": "improve"}
{"commit_tokens": ["Adding", "autoboxing", "iterator", "to", "speed", "test", "(", "results", "below", ")", ".", "Also", "methods", "for", "getting", "internal", "indices", "."], "add_tokens": "import java . util . Iterator ; import edu . jhu . prim . vector . LongDoubleUnsortedVector ; import edu . jhu . prim . vector . LongDoubleUnsortedVector . LongDouble ; { Timer timer = new Timer ( ) ; long idxSum = 0 ; double valSum = 0 ; for ( int t = 0 ; t < trials ; t ++ ) { LongDoubleUnsortedVector map = new LongDoubleUnsortedVector ( ) ; for ( int i = 0 ; i < max ; i ++ ) { map . add ( Primitives . hashOfInt ( i ) % max , i ) ; } map . compact ( ) ; timer . start ( ) ; Iterator < LongDouble > iter = map . indicesAndValues ( ) ; while ( iter . hasNext ( ) ) { LongDouble e = iter . next ( ) ; idxSum += e . getKey ( ) ; valSum += e . getValue ( ) ; } timer . stop ( ) ; } System . out . println ( \"Primitive UnsortedMap (auto-boxing iterator): \" + timer . totMs ( ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "FIXME", "-", "references", "to", "Issue", "20", ":", "Minor", "flag", "is", "always", "true", "."], "add_tokens": "* * * //FIXME: Currently always returns true. See Issue 20: http://code.google.com/p/jwpl/issues/detail?id=20", "del_tokens": "* * *", "commit_type": "add"}
{"commit_tokens": ["Improve", "to", "default", "setters", "in", "grouped", "avp", ".", "This", "allow", "to", "properly", "set", "default", "types", "via", "predefined", "methods", "in", "super", "class", ":", "]"], "add_tokens": "avpSet . addAvp ( code , value , mandatory , false , octet ) ; protected void setAvpAsIdentity ( int code , String value , long vendorId , boolean octet , boolean mandatory , boolean isProtected , boolean ... remove ) { if ( remove . length == 0 || remove [ 0 ] ) avpSet . removeAvp ( code ) ; avpSet . addAvp ( code , value , vendorId , mandatory , isProtected , octet ) ; } protected void setAvpAsByteArray ( int code , long vendorId , byte [ ] value , boolean mandatory , boolean isProtected ) { avpSet . addAvp ( code , value , vendorId , mandatory , isProtected ) ; } protected void setAvpAsUInt32 ( int code , long vendorId , long value , boolean mandatory , boolean isProtected , boolean ... remove ) { if ( remove . length == 0 || remove [ 0 ] ) avpSet . removeAvp ( code ) ; avpSet . addAvp ( code , value , vendorId , mandatory , isProtected ) ; }", "del_tokens": "avpSet . addAvp ( code , value , octet , mandatory , false ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "the", "ability", "to", "enable", "/", "disable", "the", "map", "toolbar"], "add_tokens": "import com . google . android . gms . maps . GoogleMap ; import com . google . android . gms . maps . model . LatLng ; import com . google . android . gms . maps . model . LatLngBounds ; @ Override public void setMapToolbarEnabled ( boolean enabled ) { // no-op }", "del_tokens": "import com . google . android . gms . maps . GoogleMap ; import com . google . android . gms . maps . model . LatLng ; import com . google . android . gms . maps . model . LatLngBounds ;", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "implementation", "(", "untested", ")", "for", "Joda", "YearMonthDay", "based", "as", "much", "as", "possible", "on", "the", "LocalDate", "one", "."], "add_tokens": "final LocalDateCalculator cal = new LocalDateCalculator ( ) ;", "del_tokens": "final BaseDateCalculator cal = new BaseDateCalculator ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "completion", "with", "multiple", "results"], "add_tokens": "private Size size ; private String prompt = \": \" ; this ( editMode , completions , null ) ; } public TestConnection ( EditMode editMode , List < Completion > completions , Size size ) { if ( size == null ) this . size = new Size ( 80 , 20 ) ; clearOutputBuffer ( ) ; readline . readline ( this , prompt , out -> { this . out = out ; } ) ; clearOutputBuffer ( ) ; readline . readline ( this , prompt , out -> { this . out = out ; } , completions ) ; } public void clearOutputBuffer ( ) { if ( bufferBuilder . length ( ) > 0 ) bufferBuilder . delete ( 0 , bufferBuilder . length ( ) ) ; } public String getOutputBuffer ( ) { return bufferBuilder . toString ( ) ; } public String getPrompt ( ) { return prompt ; return size ;", "del_tokens": "readline . readline ( this , \": \" , out -> { this . out = out ; } ) ; readline . readline ( this , \": \" , out -> { this . out = out ; } , completions ) ; return new Size ( 80 , 20 ) ;", "commit_type": "fix"}
{"commit_tokens": ["remove", "redundant", "test", "now", "that", "ApplicationState", "is", "an", "enum", "-", "singleton"], "add_tokens": "", "del_tokens": "import java . lang . reflect . Constructor ; @ Test public void mockCtor ( ) throws Exception { // NOPMD @ SuppressWarnings ( \"unchecked\" ) Constructor < ApplicationState > [ ] constructors = ( Constructor < ApplicationState > [ ] ) ApplicationState . class . getDeclaredConstructors ( ) ; for ( Constructor < ApplicationState > constructor : constructors ) { constructor . setAccessible ( true ) ; constructor . newInstance ( ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["changed", "ObjectFieldWrapperTest", "to", "skip", "null", "att", "values", "and", "not", "serialize", "them"], "add_tokens": "// Serialization should go ONLY for NON-NULL Attribute Values", "del_tokens": "", "commit_type": "change"}
{"commit_tokens": ["added", "some", "extra", "comment", "for", "JBBPTextWriter#Bin", "()", "added", "one", "more", "test"], "add_tokens": "* Print objects which marked by Bin annotation or successors of JBBPAbstractField . * < b > NB ! Keep in mind that values of fields will be processed for their attributes before printing * and for instance a bit field with inversion will be shown as inverted one . < / b >", "del_tokens": "* Print objects which marked by Bin annotation or successors of * JBBPAbstractField .", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "configure", "SSL", "for", "remote", "connections", "."], "add_tokens": "import javax . net . ssl . SSLContext ; int corePoolSize , int maximumPoolSize , long keepAliveTime , SSLContext sslContext ) { this . client = makeClient ( requestTimeout , maximumPoolSize , sslContext ) ; private static Client makeClient ( long requestTimeout , int maxConnections , SSLContext sslContext ) { if ( sslContext != null ) { return ClientBuilder . newBuilder ( ) . sslContext ( sslContext ) . withConfig ( clientConfig ) . build ( ) ; } else { return ClientBuilder . newClient ( clientConfig ) ; } private SSLContext sslContext ; / * * * Configures to use SSL for the server connection using the given context . * * @ param sslContext The SSL context to use . * @ return This builder instance . * / public Builder sslContext ( SSLContext sslContext ) { checkNotNull ( sslContext ) ; this . sslContext = sslContext ; return this ; } corePoolSize , maximumPoolSize , keepAliveTime , sslContext ) ;", "del_tokens": "int corePoolSize , int maximumPoolSize , long keepAliveTime ) { this . client = makeClient ( requestTimeout , maximumPoolSize ) ; private static Client makeClient ( long requestTimeout , int maxConnections ) { return ClientBuilder . newClient ( clientConfig ) ; corePoolSize , maximumPoolSize , keepAliveTime ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "HTTP", "port", "specification", "support"], "add_tokens": "return Http ( remotehost , 80 , url ) ; } / * * * Creates an HTTP client connection to a specified HTTP server and * returns the entire response . This function simulates < code > curl * http : //remotehost/url</code>. * * @ param remotehost the DNS or IP address of the HTTP server * @ param url the path / file of the resource to look up on the HTTP * server * @ return the response from the HTTP server * @ throws Exception upon a variety of error conditions * / public static String Http ( String remotehost , int port , String url ) throws Exception { s = new Socket ( remotehost , port ) ;", "del_tokens": "s = new Socket ( remotehost , 80 ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "jitpack", ".", "io"], "add_tokens": "import com . devpaul . materiallibrary . views . MaterialFloatingActionButton ; FilePickerActivity . this . setListAdapter ( adapter ) ;", "del_tokens": "import com . devpaul . materialfabmenu . MaterialFloatingActionButton ; setListAdapter ( adapter ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "ArchUnitIntegrationTestRunner", "analogous", "to", "ArchUnitRunner", "so", "failures", "will", "be", "detected", "by", "gradle", "."], "add_tokens": "} finally { notifier . fireTestFinished ( description ) ;", "del_tokens": "notifier . fireTestFinished ( description ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "line", "joins", "."], "add_tokens": "public static final long SPECIFIED_STROKE_LINEJOIN = ( 1 << 7 ) ; public static final long SPECIFIED_OPACITY = ( 1 << 8 ) ; public static final long SPECIFIED_FONT_FAMILY = ( 1 << 9 ) ; public static final long SPECIFIED_FONT_SIZE = ( 1 << 10 ) ; public static final long SPECIFIED_FONT_WEIGHT = ( 1 << 11 ) ; public static final long SPECIFIED_FONT_STYLE = ( 1 << 12 ) ; public static final long SPECIFIED_TEXT_DECORATION = ( 1 << 13 ) ; public LineJoin strokeLineJoin ; public enum LineJoin { Miter , Round , Bevel } def . strokeLineJoin = LineJoin . Miter ;", "del_tokens": "public static final long SPECIFIED_OPACITY = ( 1 << 7 ) ; public static final long SPECIFIED_FONT_FAMILY = ( 1 << 8 ) ; public static final long SPECIFIED_FONT_SIZE = ( 1 << 9 ) ; public static final long SPECIFIED_FONT_WEIGHT = ( 1 << 10 ) ; public static final long SPECIFIED_FONT_STYLE = ( 1 << 11 ) ; public static final long SPECIFIED_TEXT_DECORATION = ( 1 << 12 ) ;", "commit_type": "add"}
{"commit_tokens": ["change", "rest", "base", "from", "jersey", "to", "cxf"], "add_tokens": "import com . fasterxml . jackson . jaxrs . json . JacksonJsonProvider ; client . register ( JacksonJsonProvider . class ) ; Response signinResponse = signin . request ( MediaType . WILDCARD_TYPE ) . post ( Entity . form ( f ) ) ;", "del_tokens": "import org . glassfish . jersey . client . ClientProperties ; Response signinResponse = signin . property ( ClientProperties . FOLLOW_REDIRECTS , false ) . request ( MediaType . WILDCARD_TYPE ) . post ( Entity . form ( f ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "an", "example", "for", "chaning", "fonts"], "add_tokens": "mImageGenerator . setDateColor ( Color . parseColor ( \"#3c6eaf\" ) ) ;", "del_tokens": "mImageGenerator . setDateColor ( Color . parseColor ( \"#009688\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "transaction", "with", "empty", "amount", "+", "add", "tests"], "add_tokens": "protected EmvCard parse ( final byte [ ] pSelectResponse , final IProvider pProvider ) throws CommunicationException { protected List < EmvTransactionRecord > extractLogEntry ( final byte [ ] pLogEntry ) throws CommunicationException { // Skip transaction with nul amount if ( record . getAmount ( ) == null || record . getAmount ( ) == 0 ) { continue ; }", "del_tokens": "public EmvCard parse ( final byte [ ] pSelectResponse , final IProvider pProvider ) throws CommunicationException { private List < EmvTransactionRecord > extractLogEntry ( final byte [ ] pLogEntry ) throws CommunicationException {", "commit_type": "remove"}
{"commit_tokens": ["add", "an", "authenticated", "connection", "to", "mysql"], "add_tokens": "import java . sql . ResultSet ; @ Test public void testAuthConnection ( ) throws SQLException { Connection conn = DriverManager . getConnection ( \"jdbc:mysql:thin://test:test@localhost:3306/test_units_jdbc\" ) ; Statement stmt = conn . createStatement ( ) ; ResultSet rs = stmt . executeQuery ( \"select * from t1\" ) ; rs . close ( ) ; stmt . close ( ) ; conn . close ( ) ; }", "del_tokens": "import org . junit . After ; import static junit . framework . Assert . assertTrue ;", "commit_type": "add"}
{"commit_tokens": ["Added", "primitive", "values", "to", "matching", "check", "when", "doing", "await", "()", ".", "untilTrue", "(", "..", ")", "and", "await", "()", ".", "untilFalse", "(", "..", ")"], "add_tokens": "import static org . hamcrest . Matchers . anyOf ; import static org . hamcrest . Matchers . is ; untilAtomic ( atomic , anyOf ( is ( Boolean . TRUE ) , is ( true ) ) ) ; untilAtomic ( atomic , anyOf ( is ( Boolean . FALSE ) , is ( false ) ) ) ;", "del_tokens": "import org . hamcrest . Matchers ; untilAtomic ( atomic , Matchers . is ( Boolean . TRUE ) ) ; untilAtomic ( atomic , Matchers . is ( Boolean . FALSE ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "Deep", "fetch", "issue"], "add_tokens": "if ( joinedList . isEmpty ( ) ) { return new FastList ( 0 ) ; }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "bugs", "introduced", "by", "new", "API", "."], "add_tokens": "import au . csiro . ontology . model . IRole ; IRole [ ] lh = ri . lhs ( ) ; INamedRole [ ] lhs = new INamedRole [ lh . length ] ; for ( int i = 0 ; i < lh . length ; i ++ ) { lhs [ i ] = ( INamedRole ) lh [ i ] ; } if ( c == au . csiro . ontology . model . Concept . TOP ) { return new Concept ( IFactory . TOP_CONCEPT ) ; } else if ( c == au . csiro . ontology . model . Concept . TOP ) { return new Concept ( IFactory . BOTTOM_CONCEPT ) ; } else if ( c instanceof au . csiro . ontology . model . Concept ) {", "del_tokens": "INamedRole [ ] lhs = ( INamedRole [ ] ) ri . lhs ( ) ; if ( c instanceof au . csiro . ontology . model . Concept ) {", "commit_type": "fix"}
{"commit_tokens": ["adding", "in", "jetty6", "based", "web", "server", "removing", "javax", ".", "servlet", "package", "because", "hopefully", "we", "don", "t", "need", "it"], "add_tokens": "@ Override public String getContextPath ( ) { return null ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "broken", "test", "due", "to", "changes"], "add_tokens": "TransactionsResponse response = plaidUserClient . mfaConnectStep ( \"1234\" , \"chase\" ) ;", "del_tokens": "TransactionsResponse response = plaidUserClient . mfaStep ( \"1234\" , \"chase\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "curly", "braces", "for", "loop", "logic"], "add_tokens": "}", "del_tokens": "}", "commit_type": "fix"}
{"commit_tokens": ["fixing", "bug", "resolving", "default", "bean", "in", "the", "implementation", "of"], "add_tokens": ". addConstructorArgReference ( \"servicesManager\" )", "del_tokens": ". addConstructorArgReference ( \"serviceManager\" )", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "equality", ";", "add", "javadoc", "tempate"], "add_tokens": "public static boolean imagesAreEquals ( BufferedImage image1 , BufferedImage image2 , double deviation ) {", "del_tokens": "public static boolean equals ( BufferedImage image1 , BufferedImage image2 , double deviation ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "parsing", "for", "logical", "ranges"], "add_tokens": "return null ;", "del_tokens": "throw new IllegalArgumentException ( \"No maximum for this range\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "+", "test", "for", "NegativeArraySizeException", "when", "deserializing", "RoaringArray", "(", "mask", "unsigned", "byte", ")", "."], "add_tokens": "final int cookie = ( buffer4 [ 0 ] & 0xFF ) | ( ( buffer4 [ 1 ] & 0xFF ) << 8 ) this . size = ( buffer4 [ 0 ] & 0xFF ) | ( ( buffer4 [ 1 ] & 0xFF ) << 8 )", "del_tokens": "final int cookie = buffer4 [ 0 ] | ( ( buffer4 [ 1 ] & 0xFF ) << 8 ) this . size = buffer4 [ 0 ] | ( ( buffer4 [ 1 ] & 0xFF ) << 8 )", "commit_type": "fix"}
{"commit_tokens": ["added", "an", "initial", "implementation", "of", "GroovyLog", "for", "logging", "in", "Groovy", "applications"], "add_tokens": "import org . codehaus . groovy . lang . GroovyObject ; if ( object instanceof GroovyObject ) { GroovyObject groovy = ( GroovyObject ) object ; return groovy . invokeMethod ( methodName , arguments ) ; List argumentList = asList ( arguments ) ; if ( object instanceof Class ) { Class theClass = ( Class ) object ; MetaClass metaClass = metaRegistry . getMetaClass ( theClass ) ; return metaClass . invokeStaticMethod ( object , methodName , arguments , argumentList ) ; } else { Class theClass = object . getClass ( ) ; MetaClass metaClass = metaRegistry . getMetaClass ( theClass ) ; return metaClass . invokeMethod ( object , methodName , arguments , argumentList ) ; }", "del_tokens": "List argumentList = asList ( arguments ) ; if ( object instanceof Class ) { Class theClass = ( Class ) object ; MetaClass metaClass = metaRegistry . getMetaClass ( theClass ) ; return metaClass . invokeStaticMethod ( object , methodName , arguments , argumentList ) ; Class theClass = object . getClass ( ) ; MetaClass metaClass = metaRegistry . getMetaClass ( theClass ) ; return metaClass . invokeMethod ( object , methodName , arguments , argumentList ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "syntax", "implementations", "and", "extended", "factory", "accordingly"], "add_tokens": "import org . semanticweb . elk . util . hashing . StructuralHashObject ; public interface ElkFacetRestriction extends StructuralHashObject {", "del_tokens": "public interface ElkFacetRestriction {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "some", "problems", "and", "added", "cleanup", "on", "shutdown"], "add_tokens": "// .port(48444) ctx . cleanup ( ) ;", "del_tokens": ". port ( 48444 )", "commit_type": "fix"}
{"commit_tokens": ["Fix", "null", "span", "bug", "in", "Zuul", "filter"], "add_tokens": "public class TracePostZuulFilter extends ZuulFilter implements ApplicationEventPublisherAware { return getCurrentSpan ( ) != null ;", "del_tokens": "public class TracePostZuulFilter extends ZuulFilter implements ApplicationEventPublisherAware { return true ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "junit", "failure", ":", "set", "exception", "or", "response", "first", "before", "latch", "count", "down", "so", "that", "Future", ".", "get", "()", "will", "return", "correct", "object", "."], "add_tokens": "latch . countDown ( ) ; latch . countDown ( ) ;", "del_tokens": "latch . countDown ( ) ; latch . countDown ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "SetterHandler", "for", "javac", ".", "Also", "added", "a", "way", "to", "get", "the", "SymbolTable", "on", "a", "JavacAST", ".", "Node", "because", "you", "need", "it", "to", "e", ".", "g", ".", "access", "constant", "types", "like", "void", "."], "add_tokens": "return buildName ( prefix , fieldName . toString ( ) ) ; } private static String buildName ( String prefix , String suffix ) { if ( suffix . length ( ) == 0 ) return prefix ; char first = suffix . charAt ( 0 ) ; suffix = String . format ( \"%s%s\" , Character . toTitleCase ( first ) , suffix . subSequence ( 1 , suffix . length ( ) ) ) ; public static String toSetterName ( CharSequence fieldName ) { return buildName ( \"set\" , fieldName . toString ( ) ) ; }", "del_tokens": "final String suffix ; char first = fieldName . charAt ( 0 ) ; suffix = String . format ( \"%s%s\" , Character . toTitleCase ( first ) , fieldName . subSequence ( 1 , fieldName . length ( ) ) ) ; else suffix = fieldName . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "default", "implementation", "of", "isEmpty"], "add_tokens": "boolean isEmpty ( ) ;", "del_tokens": "default boolean isEmpty ( ) { return getRowCount ( ) == 0 ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "Progress", "and", "Seek", "bars"], "add_tokens": "public int getResolvedLayoutDirection ( ) { return 0 ; } : 0 ;", "del_tokens": "@ Override : super . getResolvedLayoutDirection ( who ) ;", "commit_type": "fix"}
{"commit_tokens": ["Made", "EncodingUtils", ".", "toString", "(", "Object", ")", "consistent", "with", "Coercion"], "add_tokens": "/* TODO: Code will move here once encodingutils no longer used */ // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations // Otherwise, if is a Writable, support optimizations", "del_tokens": "/ * Code will move here once encodingutils no longer used // If A is a string, then the result is A. if ( value instanceof String ) return ( String ) value ; // Otherwise, if A is null, then the result is \"\". if ( value == null ) return \"\" ; // Otherwise, if is a DOM node, serialize the output // Get implementation from other EncodingUtils // Otherwise, if A.toString() throws an exception, then raise an error String str = value . toString ( ) ; // Otherwise, the result is A.toString(); return str ; * /", "commit_type": "make"}
{"commit_tokens": ["Add", "an", "additional", "Callbacks", ".", "stream", "(", "Callback<T", ">", "T", "...", ")"], "add_tokens": "/ * * * For every element , invoke the given callback . * Stops if { @ link CallbackRefusedException } is thrown . * / @ SafeVarargs public static < T > void stream ( Callback < T > callback , T ... items ) throws Exception { stream ( callback , Arrays . asList ( items ) ) ; } * Stops if { @ link CallbackRefusedException } is thrown . public static < T > void stream ( Callback < T > callback , Iterable < T > iterable ) throws Exception { try { callback . call ( item ) ; } catch ( CallbackRefusedException e ) { return ; }", "del_tokens": "public static < T > void stream ( Callback < T > callback , Iterable < T > iterable ) throws Exception { callback . call ( item ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "some", "Java", "6isms", "."], "add_tokens": "Block prev = blockChain . getLast ( ) ; Block prev = blockChain . getLast ( ) ; return blockChain . getLast ( ) ;", "del_tokens": "Block prev = blockChain . peekLast ( ) ; Block prev = blockChain . peekLast ( ) ; return blockChain . peekLast ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Allow", "negotiation", "of", "secure", "channel", "lifetime"], "add_tokens": "import static com . digitalpetri . opcua . stack . core . util . NonceUtil . generateNonce ; import static com . digitalpetri . opcua . stack . core . util . NonceUtil . getNonceLength ; private static final long SecureChannelLifetimeMin = 15000L ; private static final long SecureChannelLifetimeMax = 60000L * 5L ; long channelLifetime = request . getRequestedLifetime ( ) ; channelLifetime = Math . min ( SecureChannelLifetimeMax , channelLifetime ) ; channelLifetime = Math . max ( SecureChannelLifetimeMin , channelLifetime ) ; channelLifetime", "del_tokens": "import static com . digitalpetri . opcua . stack . core . util . NonceUtil . generateNonce ; import static com . digitalpetri . opcua . stack . core . util . NonceUtil . getNonceLength ; private static final long SecureChannelLifetimeMillis = 60000L * 5L ; SecureChannelLifetimeMillis", "commit_type": "allow"}
{"commit_tokens": ["Add", "custom", "BorderFormatter", "unit", "test"], "add_tokens": "private static final char VERTICAL_BORDER_CHAR = '║'; * Add { @ value # VERTICAL_BORDER_CHAR } to each line of msg . * @ return the message with { @ value # VERTICAL_BORDER_CHAR } in the start of each line borderedMsgBuilder . append ( VERTICAL_BORDER_CHAR ) . append ( line ) ;", "del_tokens": "public static final char DEFAULT_VERTICAL_BORDER_CHAR = '║'; * Add { @ value # DEFAULT_VERTICAL_BORDER_CHAR } to each line of msg . * @ return the message with { @ value # DEFAULT_VERTICAL_BORDER_CHAR } in the start of each line borderedMsgBuilder . append ( DEFAULT_VERTICAL_BORDER_CHAR ) . append ( line ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "MAJ", "-", "719", "."], "add_tokens": "import com . vividsolutions . jts . geom . Coordinate ; // GeodeticCalculator calculator = new GeodeticCalculator(crs); // calculator.setStartingPosition(new DirectPosition2D(crs, mapBounds.getX(), mapBounds.getY())); // calculator.setDestinationPosition(new DirectPosition2D(crs, mapBounds.getMaxX(), mapBounds.getY())); // double distance = calculator.getOrthodromicDistance(); // return distance / mapBounds.getWidth(); Coordinate c1 = new Coordinate ( 0 , 0 ) ; Coordinate c2 = new Coordinate ( 1 , 0 ) ; double distance = JTS . orthodromicDistance ( c1 , c2 , crs ) ; return distance ;", "del_tokens": "import org . geotools . geometry . DirectPosition2D ; import org . geotools . referencing . GeodeticCalculator ; GeodeticCalculator calculator = new GeodeticCalculator ( crs ) ; calculator . setStartingPosition ( new DirectPosition2D ( crs , mapBounds . getX ( ) , mapBounds . getY ( ) ) ) ; calculator . setDestinationPosition ( new DirectPosition2D ( crs , mapBounds . getMaxX ( ) , mapBounds . getY ( ) ) ) ; double distance = calculator . getOrthodromicDistance ( ) ; return distance / mapBounds . getWidth ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "wrapper", "around", "exception", "and", "re", "-", "thrown", "correct", "exception"], "add_tokens": "try { ResponseEntity < Status > responseEntity = restOperations . exchange ( buildUri ( Endpoint . GET_STATUS . getEndpoint ( ) ) , HttpMethod . GET , getRequestEntity ( etag , MediaType . APPLICATION_XML ) , Status . class ) ; return responseEntity ; } catch ( Exception e ) { throw new MythServiceApiRuntimeException ( e ) ; }", "del_tokens": "ResponseEntity < Status > responseEntity = restOperations . exchange ( buildUri ( Endpoint . GET_STATUS . getEndpoint ( ) ) , HttpMethod . GET , getRequestEntity ( etag , MediaType . APPLICATION_XML ) , Status . class ) ; return responseEntity ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "String<any", "suffix", ">", "-", "typed", "attribute", "values"], "add_tokens": "if ( INT . equals ( type ) ) { } else if ( type != null && ( type . startsWith ( STRING ) || type . startsWith ( NUMBER ) ) ) { return value ;", "del_tokens": "if ( STRING . equals ( type ) || NUMBER . equals ( type ) ) { return value ; } else if ( INT . equals ( type ) ) {", "commit_type": "add"}
{"commit_tokens": ["Make", "createdir", "depend", "only", "on", "CREATE_DIR", "argument"], "add_tokens": "// If it should be possible to create directories. item . setVisible ( allowCreateDir ) ;", "del_tokens": "// If it should be possible to create directories. Only valid with MODE_DIR item . setVisible ( allowCreateDir && ( mode == MODE_DIR ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "the", "answer", "when", "is", "throw", "an", "Exception"], "add_tokens": "import org . springframework . web . bind . annotation . ExceptionHandler ; import org . springframework . web . bind . annotation . PathVariable ; import org . springframework . web . bind . annotation . RequestBody ; import org . springframework . web . bind . annotation . RequestMapping ; import org . springframework . web . bind . annotation . RequestMethod ; import org . springframework . web . bind . annotation . ResponseStatus ; import org . springframework . web . bind . annotation . RestController ;", "del_tokens": "import org . project . neutrino . nfvo . catalogue . mano . common . VNFDependency ; import org . springframework . web . bind . annotation . * ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "missing", "parantheses", "to", "list", "/", "set", "writers"], "add_tokens": "\"$N.$L($T.$L, $L.size())\" ,", "del_tokens": "\"$N.$L($T.$L, $L.size()\" ,", "commit_type": "add"}
{"commit_tokens": ["Move", "MessageInfoApplication", "to", ".", "app"], "add_tokens": "import org . jbundle . base . message . app . * ;", "del_tokens": "import org . jbundle . base . message . app . MessageApplication ; import org . jbundle . base . message . core . * ;", "commit_type": "move"}
{"commit_tokens": ["Add", "new", "request", "and", "result", "type", ":", "GetDependencyDataRequest", "&", "GetDependencyDataResult"], "add_tokens": "result = ( new BASE64Encoder ( ) ) . encode ( baos . toByteArray ( ) ) ; / * TODO Replace result raw to this one : result = Base64 . encodeBase64String ( baos . toByteArray ( ) ) ; See : Should not be using classes that are in sun . * packages - those classes are not part of the public API Java and can change in any new Java version http : //stackoverflow.com/questions/29692146/java-lang-noclassdeffounderror-sun-misc-base64encoder http : //www.oracle.com/technetwork/java/faq-sun-packages-142232.html * /", "del_tokens": "result = new BASE64Encoder ( ) . encode ( baos . toByteArray ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "skip", "property"], "add_tokens": "/ * * * Set this to 'true' to bypass sortpom plugin * * @ parameter expression = \"${sort.skip}\" default - value = \"false\" * / private boolean skip ; * @ throws org . apache . maven . plugin . MojoFailureException exception that will be handled by plugin framework if ( skip ) { getLog ( ) . info ( \"Skipping sortpom\" ) ; } else { setup ( ) ; sortPom ( ) ; }", "del_tokens": "* @ throws org . apache . maven . plugin . MojoFailureException * exception that will be handled by plugin framework setup ( ) ; sortPom ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "callback", "after", "the", "dismiss", "animation", "was", "finished", ".", "This", "solves", "some", "redraw", "issues", "."], "add_tokens": "* @ return boolean that indicates whether the list item should be dismissed or shown again . public boolean onPreAction ( ListView listView , int position , int direction ) { return mSwipeActionListener != null && mSwipeActionListener . shouldDismiss ( position , direction ) ; } / * * * SwipeActionTouchListener . ActionCallbacks callback * We just link it through to our own interface * * @ param listView The originating { @ link ListView } . * @ param position The positions to perform the action on , sorted in descending order * for convenience . * @ param direction The type of swipe that triggered the action . * / @ Override public void onAction ( ListView listView , int [ ] position , int [ ] direction ) { if ( mSwipeActionListener != null ) mSwipeActionListener . onSwipe ( position , direction ) ; public boolean shouldDismiss ( int position , int direction ) ; public void onSwipe ( int [ ] position , int [ ] direction ) ;", "del_tokens": "* @ return boolean indicating whether the item should be dismissed afterwards or not public boolean onAction ( ListView listView , int position , int direction ) { return mSwipeActionListener != null && mSwipeActionListener . onSwipe ( position , direction ) ; public boolean onSwipe ( int position , int direction ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "RequestRejected", "instead", "of", "TimeoutedException"], "add_tokens": "import services . moleculer . error . RequestRejectedError ; if ( err instanceof RequestRejectedError ) { // Rejected", "del_tokens": "import java . util . concurrent . TimeoutException ; if ( err instanceof TimeoutException ) {", "commit_type": "use"}
{"commit_tokens": ["Fixed", "NPE", "and", "added", "extra", "overloaded", "methods", "(", "addRuntimeResources", ")", "for", "runtime", "resources"], "add_tokens": "if ( jarSet != null && ! jarSet . contains ( item ) ) {", "del_tokens": "if ( ! jarSet . contains ( item ) ) {", "commit_type": "fix"}
{"commit_tokens": ["fixed", "unknown", "ConnectException", "on", "selector"], "add_tokens": "import java . net . ConnectException ; import java . net . SocketTimeoutException ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . locks . LockSupport ; } catch ( SocketTimeoutException ste ) { logger . error ( \"Reconnect fail and recur now: {}\" , ste . getMessage ( ) ) ; LockSupport . parkNanos ( TimeUnit . SECONDS . toNanos ( 1 ) ) ; return send ( request ) ; } catch ( ConnectException ce ) { logger . error ( \"Reconnect fail and recur now: {}\" , ce . getMessage ( ) ) ; LockSupport . parkNanos ( TimeUnit . SECONDS . toNanos ( 1 ) ) ; return send ( request ) ; } catch ( IOException e2 ) {", "del_tokens": "} catch ( IOException e2 ) {", "commit_type": "fix"}
{"commit_tokens": ["update", "Linnaeus", "annotator", "and", "its", "resources"], "add_tokens": "// TODO for consistency it should be PARAM_MODEL_FILE, no? @ ConfigurationParameter ( name = CONFIG_FILE , mandatory = true )", "del_tokens": "import static ch . epfl . bbp . uima . CommonAnnotatorsHelper . COMMON_ANNOTATORS_ROOT ; @ ConfigurationParameter ( name = CONFIG_FILE , mandatory = false ) if ( configFile == null ) { configFile = COMMON_ANNOTATORS_ROOT + \"src/main/resources/config/linnaeus/properties.conf\" ; }", "commit_type": "update"}
{"commit_tokens": ["Improving", "error", "message", "when", "the", "new", "arg", "for", "configuration", "is", "badly", "or", "not", "supplied"], "add_tokens": "logger . severe ( \"Please specify mobicents-balancer-config argument. Usage is : java -jar sip-balancer-jar-with-dependencies.jar -mobicents-balancer-config=lb-configuration.properties\" ) ; return ; } if ( ! args [ 0 ] . startsWith ( \"-mobicents-balancer-config=\" ) ) { logger . severe ( \"Impossible to find the configuration file since you didn't specify the mobicents-balancer-config argument. Usage is : java -jar sip-balancer-jar-with-dependencies.jar -mobicents-balancer-config=lb-configuration.properties\" ) ; return ;", "del_tokens": "logger . fine ( \"Insufficient args\" ) ; throw new IllegalArgumentException ( \"Bad args: supply configuration file location \" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Move", "validate", "after", "filter", "on", "updates"], "add_tokens": "apiVersionPlugin . getValidator ( ) . validateUpdate ( item , existing , context ) ;", "del_tokens": "apiVersionPlugin . getValidator ( ) . validateUpdate ( item , existing , context ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "manifest", "formatting", "to", "use", "4", "spaces", "for", "indenting"], "add_tokens": "public AnalysisRepositoryFactory ( Provider < AOPProxyAnalyzer > aopProxyAnalyzerProvider , Provider < InjectionAnalyzer > injectionAnalyzerProvider , Provider < MethodCallbackAnalysis > methodCallbackAnalysisProvider , Provider < ScopeAnalysis > scopeAnalysisProvider , Provider < RegistrationAnalyzer > registrationAnalysisProvider ) {", "del_tokens": "public AnalysisRepositoryFactory ( Provider < AOPProxyAnalyzer > aopProxyAnalyzerProvider , Provider < InjectionAnalyzer > injectionAnalyzerProvider , Provider < MethodCallbackAnalysis > methodCallbackAnalysisProvider , Provider < ScopeAnalysis > scopeAnalysisProvider , Provider < RegistrationAnalyzer > registrationAnalysisProvider ) {", "commit_type": "change"}
{"commit_tokens": ["Add", "no", "-", "args", "constructor", "to", "dummy", "classes"], "add_tokens": "public class Client0 extends Client { public Client0 ( ) { super ( ) ; } } public class Offer0 extends Offer { public Offer0 ( ) { super ( ) ; } } public class Payment0 extends Payment { public Payment0 ( ) { super ( ) ; } } public class Refund0 extends Refund { public Refund0 ( ) { super ( ) ; } } public class Subscription0 extends Subscription { public Subscription0 ( ) { super ( ) ; } } public class Transaction0 extends Transaction { public Transaction0 ( ) { super ( ) ; } }", "del_tokens": "public class Client0 extends Client { } public class Offer0 extends Offer { } public class Payment0 extends Payment { } public class Refund0 extends Refund { } public class Subscription0 extends Subscription { } public class Transaction0 extends Transaction { }", "commit_type": "add"}
{"commit_tokens": ["Added", "BaseComponentKeyStrokeTrigger", "and", "convenice", "derivates"], "add_tokens": "import java . util . ArrayList ; if ( keyStrokes . isEmpty ( ) ) { // No key stroke define, so react on any key event fireTriggerEvent ( new TriggerEvent ( source ) ) ; } else { for ( KeyStroke keyStroke : keyStrokes ) { if ( KeyStroke . getKeyStrokeForEvent ( keyEvent ) . equals ( keyStroke ) ) { fireTriggerEvent ( new TriggerEvent ( source ) ) ; break ; } * Constructor specifying the text component to listen to and the key stroke to trigger the validation . * < p / > * If no key stroke is provided , the trigger will initiate the validation on any key stroke . return new ArrayList < KeyStroke > ( keyStrokes ) ; * < p / > * If all key strokes are removed , the trigger will initiate the validation on any key stroke .", "del_tokens": "for ( KeyStroke keyStroke : keyStrokes ) { if ( KeyStroke . getKeyStrokeForEvent ( keyEvent ) . equals ( keyStroke ) ) { fireTriggerEvent ( new TriggerEvent ( source ) ) ; break ; * Constructor specifying the text component to listen to . return keyStrokes ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "a", "small", "security", "bug", "with", "rememberme", "tokens"], "add_tokens": "* Configures the authentication providers", "del_tokens": "* Configuers the authentication providers", "commit_type": "fix"}
{"commit_tokens": ["Use", "basic", "auth", "instead", "of", "signature", "auth"], "add_tokens": "import org . apache . http . auth . AuthScope ; import org . apache . http . auth . UsernamePasswordCredentials ; import org . apache . http . client . CredentialsProvider ; import org . apache . http . impl . auth . BasicScheme ; import org . apache . http . impl . client . BasicCredentialsProvider ; private final UsernamePasswordCredentials credentials ; credentials = new UsernamePasswordCredentials ( accessKey , secretKey ) ; request . addHeader ( new BasicScheme ( ) . authenticate ( credentials , request , null ) ) ;", "del_tokens": "import com . google . common . base . Preconditions ; import com . google . common . collect . Multimaps ; private final String accessKey ; private final String secretKey ; this . accessKey = accessKey ; this . secretKey = secretKey ; params = addAuthParams ( params ) ; params = addAuthParams ( params ) ; params = addAuthParams ( params ) ; params = addAuthParams ( params ) ; private Multimap < String , String > addAuthParams ( Multimap < String , String > params ) { Preconditions . checkNotNull ( params ) ; params . putAll ( Multimaps . forMap ( ViSearchAuthGenerator . getAuthParams ( accessKey , secretKey ) ) ) ; return params ; }", "commit_type": "use"}
{"commit_tokens": ["Added", "public", "API", "asserts", "for", "ObservableObjectValue"], "add_tokens": "public ObservableObjectValueAssertions ( ObservableObjectValue < T > actual ) {", "del_tokens": "protected ObservableObjectValueAssertions ( ObservableObjectValue < T > actual ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "simple", "test", "for", "AST", "position"], "add_tokens": "import org . junit . Assert ; String actualResult = formatter . format ( comment , 1 , CommentFormatter . CommentLocation . BEGINNING ) ; String expectedResult = \" /**\\n\" + \" * This is a test\\n\" + \" */\" ; Assert . assertEquals ( \"Comment formatter results do not match.\" , expectedResult , actualResult ) ; String actualResult = formatter . format ( comment , 1 , CommentFormatter . CommentLocation . BEGINNING ) ; String expectedResult = \" /**\\n\" + \" * This is a test\\n\" + \" * Line two\\n\" + \" * \\\"<b>Line3</b>\\\"\\n\" + \" */\\n\" ; Assert . assertEquals ( \"Comment formatter results do not match.\" , expectedResult , actualResult ) ;", "del_tokens": "System . out . println ( formatter . format ( comment , 1 , CommentFormatter . CommentLocation . BEGINNING ) ) ; System . out . println ( formatter . format ( comment , 1 , CommentFormatter . CommentLocation . BEGINNING ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "java", "and", "java", "-", "home", "commands", "along", "with", "coursier", "-", "jvm", "library"], "add_tokens": "return new File ( dir , \".\" + name + \".part\" ) ;", "del_tokens": "return new File ( dir , name + \".part\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "table", "prefixes", "(", "namespaces", "in", "SQL", "basically", ")", "."], "add_tokens": "private String tblprefix ; // prefix for table names (\"foo.\"); never null this . tblprefix = \"\" ; public void setTablePrefix ( String tblprefix ) { this . tblprefix = tblprefix ; } return queryForLinks ( \"select * from \" + tblprefix + \"links \" + where + return queryForLinks ( \"select * from \" + tblprefix + \"links where \" + ResultSet rs = stmt . executeQuery ( \"select * from \" + tblprefix + \"links where \" + query = \"update \" + tblprefix + \"links set status = \" + link . getStatus ( ) . getId ( ) + query = \"insert into \" + tblprefix + \"links values ('\" + escape ( link . getID1 ( ) ) + \"', \" + stmt . executeUpdate ( \"delete from \" + tblprefix + \"links\" ) ; String lastpart = \"\" ; if ( ! tblprefix . equals ( \"\" ) ) lastpart = \"AND owner = '\" + tblprefix . substring ( 0 , tblprefix . length ( ) - 1 ) + \"'\" ; \"where table_name = 'LINKS'\" + lastpart ) ;", "del_tokens": "return queryForLinks ( \"select * from links \" + where + return queryForLinks ( \"select * from links where \" + ResultSet rs = stmt . executeQuery ( \"select * from links where \" + query = \"update links set status = \" + link . getStatus ( ) . getId ( ) + query = \"insert into links values ('\" + escape ( link . getID1 ( ) ) + \"', \" + stmt . executeUpdate ( \"delete from links\" ) ; \"where table_name = 'LINKS'\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "less", "intrusive", "separator", "for", "path", "strings"], "add_tokens": "public static final String DIVIDER = \">>>\" ; return parent . getPath ( ) + DIVIDER + getName ( ) ;", "del_tokens": "public static final String DIVIDER = \":\" ; return parent . getPath ( ) + \":\" + getName ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Remove", "firstInstall", "and", "lastUpdate", "from", "metadata", "header", "rename", "appLabel", "to", "appStoreLabel", "add", "package", "name", "as", "appStoreId", "."], "add_tokens": "Context context = BMSClient . getAppContext ( ) ; // we assume the developer has called BMSClient.getInstance at least once by this point, so context is not try { String applicationPackageName = context . getPackageName ( ) ; metadataHeader . put ( \"appStoreId\" , applicationPackageName ) ; metadataHeader . put ( \"appStoreLabel\" , getAppLabel ( context ) ) ; // human readable app name - it's what shows in the app store, on the app icon, and may not align with mfpAppName pInfo = context . getPackageManager ( ) . getPackageInfo ( applicationPackageName , 0 ) ;", "del_tokens": "try { Context context = BMSClient . getAppContext ( ) ; // we assume the developer has called BMSClient.getInstance at least once by this point, so context is not pInfo = context . getPackageManager ( ) . getPackageInfo ( context . getPackageName ( ) , 0 ) ; metadataHeader . put ( \"firstInstall\" , pInfo . firstInstallTime ) ; // useful! metadataHeader . put ( \"lastUpdate\" , pInfo . lastUpdateTime ) ; // also useful! metadataHeader . put ( \"appLabel\" , getAppLabel ( context ) ) ; // human readable app name - it's what shows in the app store, on the app icon, and may not align with mfpAppName", "commit_type": "remove"}
{"commit_tokens": ["add", "logging", "for", "blink", "mode"], "add_tokens": "log . error ( \"Thread interruption into BLINK sequence\" , e ) ;", "del_tokens": "// TODO Auto-generated catch block e . printStackTrace ( ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "imports", ".", "removed", "unneeded", "code"], "add_tokens": "import static org . junit . Assert . assertTrue ; import static org . junit . Assert . assertNull ; import static org . junit . Assert . assertNotNull ;", "del_tokens": "import static org . junit . Assert . * ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "short", "tests", "+", "fix"], "add_tokens": "block . addStatement ( \"$N.writeInt($N)\" , dest , variableName ) ;", "del_tokens": "block . addStatement ( \"$N.writeInt(((Short) $N).intValue())\" , dest , variableName ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "print", "from", "fb", "retriever"], "add_tokens": "//logger.info(\"#Facebook : Retrieving Keywords Feed : \"+tags);", "del_tokens": "logger . info ( \"#Facebook : Retrieving Keywords Feed : \" + tags ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "bug", "in", "quicksort", "usage", "detection"], "add_tokens": "String useLegacySort = System . getProperty ( \"java.util.Arrays.useLegacyMergeSort\" ) ; return ! is16orLess || ( useLegacySort != null && useLegacySort . equals ( \"true\" ) ) ;", "del_tokens": "return ! is16orLess ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "a", "subclass", "of", "Executable", "to", "provide", "its", "own", "implementation", "of", "deleting"], "add_tokens": "deleteExecutable ( ) ; stopped = true ; / * * * Delete the executable at stop time ; available here for * subclassing . * / protected void deleteExecutable ( ) { if ( executable . exists ( ) && ! Files . forceDelete ( executable ) ) logger . warning ( \"Could not delete executable NOW: \" + executable ) ; } / * *", "del_tokens": "if ( executable . exists ( ) && ! Files . forceDelete ( executable ) ) logger . warning ( \"Could not delete executable NOW: \" + executable ) ; stopped = true ; / * *", "commit_type": "allow"}
{"commit_tokens": ["Added", "verification", "for", "at", "least", "number", "of", "times"], "add_tokens": "return new VerifySequenced ( getCallsAfterLastFound ( foundCalls ) ) ; } / * * * There should be at least < i > t < / i > calls which satisfies the given conditions * / public VerifySequenced atLeast ( int t , Condition ... conditions ) { final List < Call > foundCalls = filterByConditions ( conditions ) ; if ( t > foundCalls . size ( ) ) { throw new AssertionError ( format ( \"Expected to happen at least %s time(s), but happened %s times instead\" , t , foundCalls . size ( ) ) ) ; } return new VerifySequenced ( getCallsAfterLastFound ( foundCalls ) ) ; } private List < Call > getCallsAfterLastFound ( final List < Call > foundCalls ) { return foundCalls . size ( ) == 0 ? calls : calls . subList ( calls . indexOf ( foundCalls . get ( foundCalls . size ( ) - 1 ) ) + 1 , calls . size ( ) ) ;", "del_tokens": "List < Call > callsAfterLastFound = foundCalls . size ( ) == 0 ? calls : calls . subList ( calls . indexOf ( foundCalls . get ( foundCalls . size ( ) - 1 ) ) + 1 , calls . size ( ) ) ; return new VerifySequenced ( callsAfterLastFound ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "WriteFileRecord", "response", "and", "request", "."], "add_tokens": "* Copyright ( c ) 2015 - 2016 JSC Invertor", "del_tokens": "* Copyright ( c ) 2015 - 2016 JSC \"Zavod \" Invertor \"", "commit_type": "add"}
{"commit_tokens": ["Add", "final", "modifier", "on", "field", "DexterInstance", ".", "isRequestingPermission"], "add_tokens": "private final AtomicBoolean isRequestingPermission ; this . isRequestingPermission = new AtomicBoolean ( ) ;", "del_tokens": "private AtomicBoolean isRequestingPermission = new AtomicBoolean ( false ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "partitioned", "forwarded", "requests", "to", "return", "a", "well", "known", "error", "on", "connection", "exceptions", "."], "add_tokens": "new PartitionAwareServiceFactory < > ( SubjectDatabus . class , serviceFactory , localSubjectDatabus , self , healthCheckRegistry ) ) AuthQueueService . class , AuthDedupQueueService . class , serviceFactory , new TrustedDedupQueueService ( databus ) , self , healthCheckRegistry ) )", "del_tokens": "new PartitionAwareServiceFactory < > ( serviceFactory , localSubjectDatabus , self , healthCheckRegistry ) ) serviceFactory , new TrustedDedupQueueService ( databus ) , self , healthCheckRegistry ) )", "commit_type": "change"}
{"commit_tokens": ["Add", "an", "isValid", "method", "to", "ValidationResult"], "add_tokens": "public class ValidationResultImpl implements ValidationResult { private final Map < String , InvalidElement > invalidElements ; public ValidationResultImpl ( Object target ) { public void addInvalidElement ( InvalidElement element ) { this . invalidElements . put ( element . name ( ) , element ) ; } public Map < String , InvalidElement > invalidElementsMap ( ) { return invalidElements ; } return ! isValid ( ) ; } @ Override public boolean isValid ( ) { return invalidElements . isEmpty ( ) ;", "del_tokens": "class ValidationResultImpl implements ValidationResult { final Map < String , InvalidElement > invalidElements ; ValidationResultImpl ( Object target ) { return ! invalidElements . isEmpty ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "renaming", "types", "and", "enum", "constants"], "add_tokens": "return RenameHandler . INSTANCE . lookupType ( str ) ; throw new RuntimeException ( \"Unable to create type: \" + str , ex ) ; return RenameHandler . INSTANCE . lookupEnum ( cls , str ) ;", "del_tokens": "return getClass ( ) . getClassLoader ( ) . loadClass ( str ) ; throw new RuntimeException ( \"Unable to create class: \" + str , ex ) ; return Enum . valueOf ( cls , str ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "type", "safe", "Command", "Enum", "to", "represent", "and", "pass", "Command", "in", "RuntimeManager"], "add_tokens": "import com . twitter . heron . spi . scheduler . IRuntimeManager ; String sCommand = args [ 7 ] ; IRuntimeManager . Command command = IRuntimeManager . Command . makeCommand ( sCommand ) ; public static boolean manageTopology ( Config config , IRuntimeManager . Command command , IStateManager statemgr )", "del_tokens": "String command = args [ 7 ] ; public static boolean manageTopology ( Config config , String command , IStateManager statemgr )", "commit_type": "use"}
{"commit_tokens": ["Add", "state", "change", "callback", "to", "StateMachine"], "add_tokens": "import org . apache . zab . Zab . ZabState ; this . stateMachine . stateChanged ( ZabState . LOOKING ) ; this . stateMachine . stateChanged ( ZabState . LEADING ) ; this . stateMachine . stateChanged ( ZabState . FOLLOWING ) ;", "del_tokens": "enum ZabState { LOOKING , FOLLOWING , LEADING }", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "arguments", "check", "of", "FERT_DIST"], "add_tokens": "import java . util . Arrays ; * with offsets , the sum must be 100 % ) if ( iNum < 1 ) { LOG . error ( \"INPUT NUMBER OF FERTILIZER APPLICATIONS MUST BE A POSIIVE NUMBER\" ) ; return results ; } if ( iNum > offsets . length || ! compare ( \"100\" , round ( sum ( Arrays . copyOfRange ( ptps , 0 , iNum ) ) , 0 ) , CompareMode . EQUAL ) ) { LOG . error ( \"THE REQUESTED NUMBER OF APPLICATION IS NOT MATCH WITH THE GIVEN OFFSET DATA\" ) ; return results ; } } // Check if the sum of PTPs is 100% else if ( ! compare ( \"100\" , round ( sum ( ptps ) , 0 ) , CompareMode . EQUAL ) ) { LOG . error ( \"THE SUM OF PROPORTION OF TOTAL N ADDED (%) IS NOT EQUAL TO 100%\" ) ;", "del_tokens": "* with offsets ) LOG . error ( \"THE SPECIFIC DATA TO EACH APPLICATION MUST HAVE \" + num + \" PAIRS OF THESE DATA\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "Support", "for", "Collection", "Mapping"], "add_tokens": "import java . util . Collection ; public Collection < String > getKeys ( ) { if ( current instanceof Map ) return ( ( Map ) current ) . keySet ( ) ; return null ; } public Object get ( String key ) { if ( failure ) return this ; if ( ! isObject ( ) ) object ( ) ; if ( ! ( current instanceof Map ) ) return failure ( \"current node is not an Object\" , key ) ; return o ( current ) . get ( key ) ; } public Object get ( int index ) { if ( failure ) return this ; if ( ! isArray ( ) ) array ( ) ; if ( ! ( current instanceof List ) ) return failure ( \"current node is not an List\" , index ) ; return a ( current ) . get ( index ) ; } if ( isObject ( ) ) / * * * is the current node is an array * / / * * * is the current node is an object * /", "del_tokens": "if ( isObject ( current ) )", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "edge", "types", "BezierEdge", "and", "SplineEdge"], "add_tokens": "|| xml . contains ( \"QuadCurveEdge\" ) || xml . contains ( \"SplineEdge\" ) || xml . contains ( \"BezierEdge\" ) ; } else if ( xml . contains ( \"SplineEdge\" ) ) { return SplineEdgeDocument . Factory . parse ( xml ) . getSplineEdge ( ) ; } else if ( xml . contains ( \"BezierEdge\" ) ) { return BezierEdgeDocument . Factory . parse ( xml ) . getBezierEdge ( ) ;", "del_tokens": "|| xml . contains ( \"QuadCurveEdge\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "unittest", "for", "premature", "end", "-", "of", "-", "stream", "add", "entry", "to", "CHANGES", ".", "txt", "."], "add_tokens": "\"Received end of stream result before all the file data has been received; \" + \"totalBytesRead: %s, currentPosition: %s, size: %s\" , totalBytesRead , currentPosition , size ) ; \"Failed to read any data before all the file data has been received; \" + \"currentPosition: %s, size: %s\" , currentPosition , size ) ;", "del_tokens": "\"Received end of stream result before all the file data has been received\" ) ; \"Failed to read any data before all the file data has been received\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "caret", "on", "an", "empty", "line", "in", "non", "-", "wrapping", "area", "."], "add_tokens": "import javafx . scene . layout . Region ; double skinWrapWidth = skin . wrapWidth . get ( ) ; if ( skinWrapWidth == Region . USE_COMPUTED_SIZE ) { return Region . USE_COMPUTED_SIZE ; } else { return skinWrapWidth - snappedLeftInset ( ) - snappedRightInset ( ) ; }", "del_tokens": "return skin . wrapWidth . get ( ) - snappedLeftInset ( ) - snappedRightInset ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "released", "version", "of", "Pax", "URL", "(", "is", "only", "a", "tests", ")", "and", "add", "test", "dependencies", "so", "jars", "are", "in", "local", "repo", "."], "add_tokens": ". setBundle ( \"t1\" , \"mvn:org.ops4j.pax.url/pax-url-mvn/1.1.0\" ) . setBundle ( \"t1\" , \"mvn:org.ops4j.pax.url/pax-url-mvn/1.1.0\" ) . setBundle ( \"t2\" , \"mvn:org.ops4j.pax.url/pax-url-wrap/1.1.0\" ) . setBundle ( \"t1\" , \"mvn:org.ops4j.pax.url/pax-url-mvn/1.1.0\" ) . setBundle ( \"t2\" , \"mvn:org.ops4j.pax.url/pax-url-wrap/1.1.0\" ) . setBundle ( \"t3\" , \"mvn:org.ops4j.pax.url/pax-url-link/1.1.0\" ) . setBundle ( \"t2\" , \"mvn:org.ops4j.pax.url/pax-url-war/1.1.0\" ) // replace wrap by war ! Fix!", "del_tokens": ". setBundle ( \"t1\" , \"mvn:org.ops4j.pax.url/pax-url-mvn/1.1.0-SNAPSHOT\" ) . setBundle ( \"t1\" , \"mvn:org.ops4j.pax.url/pax-url-mvn/1.1.0-SNAPSHOT\" ) . setBundle ( \"t2\" , \"mvn:org.ops4j.pax.url/pax-url-wrap/1.1.0-SNAPSHOT\" ) . setBundle ( \"t1\" , \"mvn:org.ops4j.pax.url/pax-url-mvn/1.1.0-SNAPSHOT\" ) . setBundle ( \"t2\" , \"mvn:org.ops4j.pax.url/pax-url-wrap/1.1.0-SNAPSHOT\" ) . setBundle ( \"t3\" , \"mvn:org.ops4j.pax.url/pax-url-link/1.1.0-SNAPSHOT\" ) . setBundle ( \"t2\" , \"mvn:org.ops4j.pax.url/pax-url-war/1.1.0-SNAPSHOT\" ) // replace wrap by war ! Fix!", "commit_type": "use"}
{"commit_tokens": ["fix", "IO", ".", "copyDirectory", "issue", ":", "IOException", "triggered", "if", "parent", "folder", "of", "target", "does", "not", "exists"], "add_tokens": "if ( target . isDirectory ( ) ) { if ( ! target . exists ( ) ) { if ( ! target . mkdirs ( ) ) { throw E . ioException ( \"cannot copy [%s] to [%s]\" , source , target ) ; } } target = new File ( target , source . getName ( ) ) ; } else { File targetFolder = target . getParentFile ( ) ; if ( ! targetFolder . exists ( ) ) { if ( ! targetFolder . mkdirs ( ) ) { throw E . ioException ( \"cannot copy [%s] to [%s]\" , source , target ) ; } } } try { write ( new FileInputStream ( source ) , new FileOutputStream ( target ) ) ; } catch ( IOException e0 ) { throw E . ioException ( e0 ) ; }", "del_tokens": "throw E . ioException ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["update", "edit", "history", "and", "field", "change", "queries", "to", "return", "the", "correct", "list", "wrapper"], "add_tokens": "return this . performGetRequest ( url , EditHistoryListWrapper . class , uriVariables ) ; return this . performGetRequest ( url , FieldChangeListWrapper . class , uriVariables ) ;", "del_tokens": "return ( EditHistoryListWrapper ) this . performGetRequest ( url , BullhornEntityInfo . getTypesListWrapperType ( entityType ) , uriVariables ) ; return ( FieldChangeListWrapper ) this . performGetRequest ( url , BullhornEntityInfo . getTypesListWrapperType ( entityType ) , uriVariables ) ;", "commit_type": "update"}
{"commit_tokens": ["Made", "some", "FindBugs", "suggested", "improvements", "."], "add_tokens": "return 30 + random . nextInt ( 100 ) ; return - 10 + random . nextInt ( 50 ) ; return - 45 + random . nextInt ( 90 ) ;", "del_tokens": "return 30 + ( int ) ( random . nextDouble ( ) * 100.0 ) ; return - 10 + ( int ) ( random . nextDouble ( ) * 50.0 ) ; return - 45 + ( int ) ( random . nextDouble ( ) * 90.0 ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "CSV", "summary", "counts", "support"], "add_tokens": "} //------------------------------------------------ / * * * * @ param cells the cells row to append * @ throws IOException when IO error occurs * / public void appendRow ( String ... cells ) throws IOException { if ( cells == null ) return ; StringBuilder text = new StringBuilder ( ) ; for ( int i = 0 ; i < cells . length ; i ++ ) { if ( i != 0 ) text . append ( SEPARATOR ) ; text . append ( \"\\\"\" ) . append ( format ( cells [ i ] ) ) . append ( \"\\\"\" ) ; } IO . writeAppend ( file , new StringBuilder ( text . toString ( ) ) . append ( IO . newline ( ) ) . toString ( ) ) ; } * @ param row the row to append * @ throws IOException when IO error occurs", "del_tokens": "} * @ param file * @ param objects / * * * * @ param file * @ param objects * / public void appendFile ( Object ... objects ) throws IOException { String filePath = file . getAbsolutePath ( ) ; IO . writeAppend ( filePath , toRow ( objects ) ) ; } // --------------------------------------------", "commit_type": "add"}
{"commit_tokens": ["Making", "sure", "TimeRelativeInterval", "can", "handle", "ranges", "with", "only", "one", "side", "."], "add_tokens": "return String . valueOf ( start ) + \" - \" + String . valueOf ( end ) ;", "del_tokens": "return start . toString ( ) + \" - \" + end . toString ( ) ;", "commit_type": "make"}
{"commit_tokens": ["move", "name", "parsing", "to", "CompoundName", "class"], "add_tokens": "package com . netflix . frigga ; public class CompoundName { CompoundName names = dissectCompoundName ( autoScalingGroupName ) ; CompoundName names = dissectCompoundName ( autoScalingGroupName ) ; public static CompoundName dissectCompoundName ( String asgName ) { CompoundName clusterNames = new CompoundName ( ) ; return new CompoundName ( ) ;", "del_tokens": "package com . netflix . frigga . cluster ; public class ClusterNames { ClusterNames names = dissectCompoundName ( autoScalingGroupName ) ; ClusterNames names = dissectCompoundName ( autoScalingGroupName ) ; public static ClusterNames dissectCompoundName ( String asgName ) { ClusterNames clusterNames = new ClusterNames ( ) ; return new ClusterNames ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Change", "the", "AddPlaces", "method", "in", "GooglePlaces", ".", "java", "and", "the", "buildInput", "method", "within", "Placs", ".", "java"], "add_tokens": "String uri = buildUrl ( METHOD_ADD , String . format ( \"key=%s\" , apiKey ) ) ; //The extraParams should go into the Place.buildInput method as according to this website, we cannot add extraParams to the url for add Places: //https://developers.google.com/places/documentation/actions#PlaceReports JSONObject input = Place . buildInput ( lat , lng , accuracy , name , types , lang , extraParams ) ; //Please note the change from private to protected for the variable \"name\" protected final String name ;", "del_tokens": "String uri = buildUrl ( METHOD_ADD , String . format ( \"key=%s\" , apiKey ) , extraParams ) ; JSONObject input = Place . buildInput ( lat , lng , accuracy , name , types , lang ) ; private final String name ;", "commit_type": "change"}
{"commit_tokens": ["Removed", "the", "dependency", "on", "the", "bouncy", "castle", "library", "from", "the", "java", "-", "secure", "-", "messaging", "-", "providers", "project", "."], "add_tokens": "cryptex . getSymmetricKeyType ( ) ) ;", "del_tokens": "cryptex . getSymmetricEncryptionAlgorithm ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "log", "output", "to", "make", "clear", "which", "comment", "is", "processed", "by", "which", "processor"], "add_tokens": "import org . springframework . expression . spel . SpelEvaluationException ; logger . info ( String . format ( \"Starting run of comment processor %s\" , processor . getClass ( ) ) ) ; logger . info ( String . format ( \"Comment '%s' has been successfully processed.\" , comment ) ) ; } catch ( SpelEvaluationException e ) { logger . info ( String . format ( \"Skipping comment '%s' because it can not be resolved against current comment processor.\" , comment ) ) ; logger . info ( String . format ( \"Finished run of comment processor %s\" , processor . getClass ( ) ) ) ;", "del_tokens": "} catch ( Exception e ) { logger . warn ( String . format ( \"Skipping comment '%s' because it is not a valid expression.\" , comment ) ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "joda", "time", "test", "class", "to", "impl", "test", "package"], "add_tokens": "package io . github . benas . jpopulator . impl ;", "del_tokens": "package io . github . benas . jpopulator . test ;", "commit_type": "move"}
{"commit_tokens": ["Implement", "hasNextPosition", "/", "advanceNextPosition", "for", "RLE", "cursor"], "add_tokens": "private long position ; position = current . getRange ( ) . getStart ( ) ; if ( current == null || position == current . getRange ( ) . getEnd ( ) ) { return hasNextValue ( ) ; } return true ; if ( current == null || position == current . getRange ( ) . getEnd ( ) ) { advanceNextValue ( ) ; } else { position ++ ; } return position ;", "del_tokens": "throw new UnsupportedOperationException ( \"not yet implemented\" ) ; throw new UnsupportedOperationException ( \"not yet implemented\" ) ; throw new UnsupportedOperationException ( \"not yet implemented\" ) ;", "commit_type": "implement"}
{"commit_tokens": ["fixed", "a", "bug", "with", "generating", "collections", "without", "certain", "items"], "add_tokens": "return PrivateGenerate . manyAsListOf ( typeToken , generator ) ;", "del_tokens": "return PrivateGenerate . manyAsListOf ( typeToken ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "tests", "of", "the", "MockClients"], "add_tokens": "command . put ( \"command\" , \"respawn\" ) ;", "del_tokens": "command . put ( \"command\" , \"respawn\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "preload", "images", "on", "sample"], "add_tokens": "DaVinciDaemon . with ( getApplicationContext ( ) ) . load ( element . getUrl ( ) ) . send ( ) ;", "del_tokens": "//DaVinciDaemon.with(getApplicationContext()).load(element.getUrl()).into(\"/image/\" + position);", "commit_type": "add"}
{"commit_tokens": ["add", "date", "json", "serialiser", "use", "date", "serialiser", "in", "post", "and", "put", "request", "with", "objects", "fix", "put", "requests"], "add_tokens": "if ( httpResponse . getEntity ( ) != null ) { String responseContent = EntityUtils . toString ( httpResponse . getEntity ( ) ) ; responseVO . setServerResponse ( responseContent ) ; } int statusCode = httpResponse . getStatusLine ( ) . getStatusCode ( ) ;", "del_tokens": "String responseContent = EntityUtils . toString ( httpResponse . getEntity ( ) ) ; int statusCode = httpResponse . getStatusLine ( ) . getStatusCode ( ) ; responseVO . setServerResponse ( responseContent ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "version", "and", "doc", "error"], "add_tokens": "* @ param vecDirs", "del_tokens": "* @ param rootPath", "commit_type": "fix"}
{"commit_tokens": ["Use", "interface", "instead", "of", "Impl", "in", "UnleashUsageTest"], "add_tokens": "import no . finn . unleash . Unleash ; Unleash unleash = new UnleashImpl ( repository , new CustomStrategy ( ) ) ;", "del_tokens": "UnleashImpl unleash = new UnleashImpl ( repository , new CustomStrategy ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "immutable", "beans", "builder", "cast"], "add_tokens": "this . addressList = ( List < Address > ) newValue ;", "del_tokens": "this . addressList = ( ImmutableList < Address > ) newValue ;", "commit_type": "fix"}
{"commit_tokens": ["added", "GetBacklinkTitles", "functionality", "for", "old", "MediaWiki", "versions"], "add_tokens": "redirectFilter , createNsString ( namespaces ) , getVersion ( ) ) ; }", "del_tokens": "redirectFilter , createNsString ( namespaces ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "strategy", "labels"], "add_tokens": "return strategy . getName ( ) ;", "del_tokens": "return strategy . getClass ( ) . getSimpleName ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "the", "network", "interface", "we", "grab", "has", "a", "6", "byte", "hardware", "address", "."], "add_tokens": "import java . util . Enumeration ; Enumeration < NetworkInterface > interfaces = NetworkInterface . getNetworkInterfaces ( ) ; byte [ ] mac = null ; while ( interfaces . hasMoreElements ( ) && mac != null && mac . length != 6 ) { NetworkInterface netInterface = interfaces . nextElement ( ) ; if ( netInterface . isLoopback ( ) || netInterface . isVirtual ( ) ) { continue ; } mac = netInterface . getHardwareAddress ( ) ; }", "del_tokens": "byte [ ] mac = NetworkInterface . getNetworkInterfaces ( ) . nextElement ( ) . getHardwareAddress ( ) ;", "commit_type": "make"}
{"commit_tokens": ["change", "config", "by", "default", "in", "builder"], "add_tokens": "private int dialogColor = Color . DKGRAY ;", "del_tokens": "private int dialogColor = Color . WHITE ;", "commit_type": "change"}
{"commit_tokens": ["Move", "ProxyBuilder", "to", "the", ".", "stock", "subpackage", "(", "better", "names", "welcome", ")", "and", "kill", "DexCacheException", "."], "add_tokens": "package com . google . dexmaker . stock ; import com . google . dexmaker . DexGeneratorTest ; import junit . framework . AssertionFailedError ; import junit . framework . TestCase ; } catch ( IOException expected ) { }", "del_tokens": "package com . google . dexmaker ; import junit . framework . AssertionFailedError ; import junit . framework . TestCase ; } catch ( DexCacheException expected ) { }", "commit_type": "move"}
{"commit_tokens": ["Fixed", "an", "issue", "with", "exceptions", "being", "displayed", "and", "the", "image", "progress"], "add_tokens": "float imageProgress = 0 ; final float imageTotal = this . imageLocations . size ( ) ; log . debug ( ExceptionUtilities . getStackTrace ( ex ) ) ; final int progress = Math . round ( imageProgress / imageTotal * 100 ) ; if ( progress - lastPercent >= showPercent ) lastPercent = progress ;", "del_tokens": "int imageProgress = 0 ; final int imageTotal = this . imageLocations . size ( ) ; log . error ( ExceptionUtilities . getStackTrace ( ex ) ) ; final float progress = ( float ) imageProgress / ( float ) imageTotal * 100 ; if ( imageProgress - lastPercent >= showPercent )", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "another", "potential", "sticky", "reference", "bug", "in", "the", "mock", "APNS", "server", "."], "add_tokens": "import java . util . ArrayList ; return new ArrayList < SimpleApnsPushNotification > ( this . receivedNotifications ) ;", "del_tokens": "return java . util . Collections . unmodifiableList ( this . receivedNotifications ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "tests", "-", "version", "upgrades"], "add_tokens": "import org . apache . http . impl . conn . BasicClientConnectionManager ; assertTrue ( jestClient . getHttpClient ( ) . getConnectionManager ( ) instanceof BasicClientConnectionManager ) ;", "del_tokens": "assertTrue ( jestClient . getHttpClient ( ) . getConnectionManager ( ) instanceof PoolingClientConnectionManager ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "ability", "to", "fake", "the", "PagerDuty", "behavior", "for", "tests", "."], "add_tokens": "IncidentResult ( String status , String message , String incidentKey ) {", "del_tokens": "@ SuppressWarnings ( \"UnusedDeclaration\" ) // Hidden from public API, required for final fields. private IncidentResult ( String status , String message , String incidentKey ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "undeploy", "artifacts", ".", "https", ":", "//", "github", ".", "com", "/", "jbossas", "/", "jboss", "-", "as", "-", "maven", "-", "plugin", "/", "issues", "/", "14"], "add_tokens": "public class Undeploy extends AbstractDeployment {", "del_tokens": "public final class Undeploy extends AbstractDeployment {", "commit_type": "add"}
{"commit_tokens": ["Add", "Context", "argument", "to", "BMSClient", ".", "init", "removed", "internal", "persistence", "of", "Context", "added", "AuthorizationManager", ".", "createInstance", "to", "BMSClient", ".", "init", "()", ".", "Updated", "app", "with", "new", "API", "."], "add_tokens": "BMSClient . getInstance ( ) . initialize ( getApplicationContext ( ) , \"http://9.148.225.106:9080\" , \"vit1\" ) ; // BMSClient.getInstance().registerAuthenticationListener(\"customAuthRealm_1\", new CustomChallengeHandler()); // // AuthorizationManager.createInstance(this.getApplicationContext()); // AuthorizationManager.getInstance().obtainAuthorizationHeader(this, this); ResourceRequest r = new ResourceRequest ( this , \"http://9.148.225.106:3000/v1/apps/vit1/service\" , MFPRequest . GET ) ; r . send ( this ) ;", "del_tokens": "BMSClient . getInstance ( ) . initialize ( \"http://9.148.225.106:9080\" , \"vit1\" ) ; BMSClient . getInstance ( ) . registerAuthenticationListener ( \"customAuthRealm_1\" , new CustomChallengeHandler ( ) ) ; AuthorizationManager . createInstance ( this . getApplicationContext ( ) ) ; AuthorizationManager . getInstance ( ) . obtainAuthorizationHeader ( this , this ) ; try { ResourceRequest r = new ResourceRequest ( this , \"http://9.148.225.106:3000/v1/apps/vit1/service\" , MFPRequest . GET ) ; r . send ( this ) ; } catch ( MalformedURLException e ) { e . printStackTrace ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Move", "persistence", "related", "methods", "outside", "of", "CDAClient", "class", "."], "add_tokens": "import com . contentful . java . lib . ResourceUtils ; ResourceUtils . saveResourceToFile ( asset , f ) ; asset = ( CDAAsset ) ResourceUtils . readResourceFromFile ( f ) ; ResourceUtils . saveResourceToFile ( array , f ) ; array = ( CDAArray ) ResourceUtils . readResourceFromFile ( f ) ;", "del_tokens": "client . saveResourceToFile ( asset , f ) ; asset = ( CDAAsset ) client . readResourceFromFile ( f ) ; client . saveResourceToFile ( array , f ) ; array = ( CDAArray ) client . readResourceFromFile ( f ) ;", "commit_type": "move"}
{"commit_tokens": ["Implement", "the", "first", "test", "in", "cucumber"], "add_tokens": "operation . put ( \"arguments\" , Collections . singletonList ( queueName ) ) ;", "del_tokens": "operation . put ( \"arguments\" , Collections . singletonList ( \"test.req\" ) ) ;", "commit_type": "implement"}
{"commit_tokens": ["Implement", "internal", "DSL", "for", "SemVer", "Expressions"], "add_tokens": "* Checks if this version satisfies the specified SemVer Expression string . * @ param expr the SemVer Expression string return satisfies ( parser . parse ( expr ) ) ; } / * * * Checks if this version satisfies the specified SemVer Expression . * * This method is a part of the SemVer Expressions API . * * @ param expr the SemVer Expression * @ return { @ code true } if this version satisfies the specified * SemVer Expression or { @ code false } otherwise * @ since 0.9 . 0 * / public boolean satisfies ( Expression expr ) { return expr . interpret ( this ) ;", "del_tokens": "* Checks if this version satisfies the specified SemVer Expression . * @ param expr the SemVer Expression return parser . parse ( expr ) . interpret ( this ) ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "more", "interesting", "messaging", "demo"], "add_tokens": "private SampleSink gateway ; @ Autowired private SampleRequestResponse transformer ; @ RequestMapping ( \"/xform\" ) public String xform ( ) { String msg = \"Hello\" ; return this . transformer . send ( msg ) ; }", "del_tokens": "private SampleGateway gateway ;", "commit_type": "add"}
{"commit_tokens": ["Added", "better", "detection", "of", "JDBC", "database", "URLs", "."], "add_tokens": "public boolean isDatabaseUrlThisType ( String url , String dbTypePart ) { return true ;", "del_tokens": "public String getDriverUrlPart ( ) { return null ;", "commit_type": "add"}
{"commit_tokens": ["Added", "parameter", "conversion", "to", "SimpleQuery", "for", "the", "enum", "values", "case"], "add_tokens": "public enum EnumValues {", "del_tokens": "enum EnumValues {", "commit_type": "add"}
{"commit_tokens": ["Fix", "the", "case", "of", "the", "match", "returning", "an", "empty", "string"], "add_tokens": "if ( available . size ( ) > 0 ) { return available . remove ( 0 ) ; } if ( matchToken != null ) { // Returned empty token value and did not have available bytes. Need to reset and try again matchToken = null ; potentialMatches = getPotentialMatches ( bufferStr ) ; if ( potentialMatches . isEmpty ( ) ) { shift ( 1 , true ) ; return available . remove ( 0 ) ; } }", "del_tokens": "return available . remove ( 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixes", "a", "potential", "bug", "on", "removing", "a", "clazz", "from", "imports"], "add_tokens": "/ * * * @ param clazz the clazz to remove * / this . internalSet . remove ( clazz . getCanonicalName ( ) ) ;", "del_tokens": "this . internalSet . remove ( clazz ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "search", "time", "measuring", "fixed", "NullPointerException", "on", "empty", "search"], "add_tokens": "String SearchResult = null ; String SearchRequest = request . getParameter ( \"Search_Term\" ) ; long timePre = 0 ; long timePost = 0 ; long timeSpent = 0 ; if ( SearchRequest != null ) { // SearchRequest = (\"NoBand\"); // String SearchResult = Search.treeSearch(SearchRequest); timePre = System . nanoTime ( ) ; SearchResult = Search . treeSearch ( request . getParameter ( \"Search_Term\" ) ) ; timePost = System . nanoTime ( ) ; timeSpent = timePost - timePre ; } \" <b>Search Result</b>: \" + SearchResult + \" <b> Search time: </b>\" + timeSpent +", "del_tokens": "String SearchRequest = request . getParameter ( \"Search_Term\" ) ; if ( ! ( SearchRequest . equals ( null ) ) ) SearchRequest = ( \"NoBand\" ) ; String SearchResult = Search . treeSearch ( request . getParameter ( \"Search_Term\" ) ) ; \" <b>Search Result</b>: \" + SearchResult +", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "getInferredAxioms", "to", "IOntology", "interface", "."], "add_tokens": "/ * * * The collection of inferred axioms that form the ontology . * / protected final Collection < IAxiom > inferredAxioms = new ArrayList < IAxiom > ( ) ; * @ param id * @ param version @ Override @ Override public Collection < IAxiom > getInferredAxioms ( ) { return inferredAxioms ; } @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override @ Override", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "current", "results", "to", "total"], "add_tokens": "results . addAll ( active ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "condition", "that", "caused", "NullPointerException", "and", "implement"], "add_tokens": "private volatile boolean running = false ; private ThreadImplPool pool = null ; synchronized boolean isBorrowed ( ) return pool != null ; synchronized void setPool ( ThreadImplPool pool )", "del_tokens": "private boolean running = false ; private volatile ThreadImplPool pool = null ; boolean isBorrowed ( ) return false ; // To be implemented void setPool ( ThreadImplPool pool )", "commit_type": "fix"}
{"commit_tokens": ["adding", "in", "jetty6", "based", "web", "server", "removing", "javax", ".", "servlet", "package", "because", "hopefully", "we", "don", "t", "need", "it"], "add_tokens": "ProxyServer . start ( ) ; WebServer . start ( ) ;", "del_tokens": "import org . browsermob . proxy . jetty . http . HttpContext ; import org . browsermob . proxy . jetty . http . SocketListener ; import org . browsermob . proxy . jetty . http . handler . ProxyHandler ; import org . browsermob . proxy . jetty . jetty . Server ; import org . browsermob . proxy . jetty . util . InetAddrPort ; Server server = new Server ( ) ; server . addListener ( new SocketListener ( new InetAddrPort ( 9638 ) ) ) ; HttpContext context = new HttpContext ( ) ; context . setContextPath ( \"/\" ) ; ProxyHandler handler = new ProxyHandler ( ) ; context . addHandler ( handler ) ; server . addContext ( context ) ; server . start ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "version", "name", "and", "code", "headers"], "add_tokens": "private String getPackageVersionName ( ) { versionName = getVersionName ( ) + \"/\" + getVersionCode ( ) ; protected String getVersionName ( ) { return String . valueOf ( BuildConfig . VERSION_NAME ) ; } protected String getVersionCode ( ) { return String . valueOf ( BuildConfig . VERSION_CODE ) ; } . addHeader ( \"X-App-Version\" , getVersionName ( ) ) . addHeader ( \"X-App-Build-Number\" , getVersionCode ( ) )", "del_tokens": "protected String getPackageVersionName ( ) { versionName = BuildConfig . VERSION_NAME + \"/\" + BuildConfig . VERSION_CODE ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "test", "append", "only", "major", "and", "miner", "version", "number", "to", "dashboards"], "add_tokens": "private static final String STAGEMONITOR_MAJOR_MINOR_VERSION = getStagemonitorMajorMinorVersion ( ) ; dashboard . put ( \"title\" , dashboard . get ( \"title\" ) . asText ( ) + STAGEMONITOR_MAJOR_MINOR_VERSION ) ; private static String getStagemonitorMajorMinorVersion ( ) { final String value = attr . getValue ( \"Implementation-Version\" ) ; return \" \" + getMajorMinorVersionFromFullVersionString ( value ) ; } catch ( Exception e ) { static String getMajorMinorVersionFromFullVersionString ( String value ) { return value . substring ( 0 , value . lastIndexOf ( '.' ) ) ; }", "del_tokens": "private static final String STAGEMONITOR_VERSION = getStagemonitorVersion ( ) ; dashboard . put ( \"title\" , dashboard . get ( \"title\" ) . asText ( ) + \" \" + STAGEMONITOR_VERSION ) ; private static String getStagemonitorVersion ( ) { return attr . getValue ( \"Implementation-Version\" ) ; } catch ( IOException e ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "classloader", "issue", "in", "JSONRPCImporter"], "add_tokens": "@ ServiceProperty ( name = \"target\" ) private String filter ; proxy = ProxyUtil . createClientProxy ( klass . getClassLoader ( ) , klass , client ) ;", "del_tokens": "proxy = ProxyUtil . createClientProxy ( JSONRPCImporter . class . getClassLoader ( ) , klass , client ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "useless", "setKernelId", "call", "(", "was", "...", "hard", "-", "coded", "!", "and", "did", "not", "work"], "add_tokens": "// TBD provide kernel ID (eg. \"aki-62695816\") ? //runInstancesRequest.setKernelId(this.iaasProperties.get(Ec2Constants.KERNEL_ID);", "del_tokens": "import com . amazonaws . services . ec2 . model . DescribeVolumeAttributeRequest ; import com . amazonaws . services . ec2 . model . EbsBlockDevice ; import com . amazonaws . services . elasticmapreduce . model . InstanceState ; // FIXME (VZ): why this kernel ID? runInstancesRequest . setKernelId ( \"aki-62695816\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "doc", "with", "servlet", "annotations"], "add_tokens": "} else if ( i < servletAnnotations . length + classAnnotations . length ) {", "del_tokens": "} else if ( i < classAnnotations . length ) {", "commit_type": "fix"}
{"commit_tokens": ["Allow", "admins", "to", "create", "users", "and", "API", "keys", "."], "add_tokens": "protected < T > T readJson ( final String json , final Class < T > clazz ) { try { return mapper . readValue ( json , clazz ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } protected < T > T read ( final ClientResponse response , final Class < T > clazz ) { final String json = response . getEntity ( String . class ) ; return readJson ( json , clazz ) ; }", "del_tokens": "System . out . println ( json ) ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "wrap", "(", "...", ")", "factory", "methods", "for", "bindings", "."], "add_tokens": "private final BooleanBinding output = BooleanBinding . wrap ( a . and ( b ) ) ;", "del_tokens": "private final BooleanBinding output = new BooleanBinding ( ) { { bind ( a , b ) ; } @ Override protected boolean computeValue ( ) { return a . get ( ) && b . get ( ) ; } } ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "DataFrame", ".", "columns", "added", "DataFrame", ".", "agg"], "add_tokens": "@ Test public void dataFrameAggTest ( ) throws Exception { / * * test * DataFrame . col ( \"name\" ) * / ScriptEngine engine = TestUtils . getEngine ( ) ; String file = TestUtils . resourceToFile ( \"/data/people.txt\" ) ; TestUtils . evalJSResource ( engine , \"/dataframetest.js\" ) ; Object ret = ( ( Invocable ) engine ) . invokeFunction ( \"dataframeAggTest\" , file ) ; String json = \"{\\\"values\\\":[30,6],\\\"schema\\\":{\\\"fields\\\":[{\\\"name\\\":\\\"MAX(age)\\\",\\\"dataType\\\":\\\"IntegerType\\\",\\\"nullable\\\":true,\\\"metadata\\\":\\\"FIXME\\\"},{\\\"name\\\":\\\"SUM(expense)\\\",\\\"dataType\\\":\\\"LongType\\\",\\\"nullable\\\":true,\\\"metadata\\\":\\\"FIXME\\\"}]}}\" ; assertEquals ( \"should be same\" , json , ret . toString ( ) ) ; } assertEquals ( \"should be same\" , \"name,age,expense\" , ret . toString ( ) ) ;", "del_tokens": "assertEquals ( \"should be same\" , \"name,age\" , ret . toString ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "the", "test", "to", "influxdb", "/", "influxdb", "-", "java"], "add_tokens": "this . dockerClient . pull ( \"influxdb/influxdb-java\" ) ;", "del_tokens": "this . dockerClient . pull ( \"majst01/influxdb-java\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "unit", "tests", "for", "APILimitUtils", "."], "add_tokens": "* @ return Available API limit . - 1 if headers invalid . * @ return Remaining API limit . - 1 if headers invalid .", "del_tokens": "* @ return Available API limit * @ return Remaining API limit", "commit_type": "add"}
{"commit_tokens": ["Implement", "sorting", "by", "computed", "measure"], "add_tokens": "import java . util . * ; public boolean containsKey ( String key ) { return keys . containsKey ( key ) ; } public boolean containsInputField ( String field ) { return fields . containsKey ( field ) ; } public boolean containsOutputField ( String field ) { return outputFields . containsKey ( field ) ; } public boolean containsComputedMeasure ( String computedMeasure ) { return computedMeasures . containsKey ( computedMeasure ) ; } AsmBuilder < Comparator > builder = new AsmBuilder < > ( classLoader , Comparator . class ) ; return builder . newInstance ( ) ; public Class < QueryResultPlaceholder > createResultClass ( AggregationQuery query , Set < String > computedMeasureNames ) {", "del_tokens": "import java . util . Comparator ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; AsmBuilder builder = new AsmBuilder ( classLoader , Comparator . class ) ; return ( Comparator ) builder . newInstance ( ) ; public Class < QueryResultPlaceholder > createResultClass ( AggregationQuery query , List < String > computedMeasureNames ) {", "commit_type": "implement"}
{"commit_tokens": ["Updated", "for", "red5", "-", "server", "common", "split", "-", "up"], "add_tokens": "//import org.red5.server.adapter.ApplicationAdapter; //import org.red5.server.scope.WebScope; / * * commented due to dependencies problem * / / * * commented due to dependencies problem * / / * * commented due to dependencies problem * /", "del_tokens": "import org . red5 . server . adapter . ApplicationAdapter ; import org . red5 . server . scope . WebScope ;", "commit_type": "update"}
{"commit_tokens": ["Added", "incremental", "info", "to", "log"], "add_tokens": "LOG . error ( \"EMF model contains no content (incremental={})\" , incremental ) ; LOG . warn ( \"EMF model contains {} elements, but the generator wanted none (incremental={})\" , total , incremental ) ; LOG . info ( \"EMF model contains {} elements and generator wanted {} of them (incremental={})\" , total , wants , incremental ) ;", "del_tokens": "LOG . error ( \"EMF model contains no content\" ) ; LOG . warn ( \"EMF model contains {} elements, but the generator wanted none\" , total ) ; LOG . info ( \"EMF model contains {} elements and generator wanted {} of them\" , total , wants ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "method", "to", "protected", "to", "allow", "overriding", "it"], "add_tokens": "protected String getBaseUrl ( ) {", "del_tokens": "private String getBaseUrl ( ) {", "commit_type": "change"}
{"commit_tokens": ["Fix", "usage", "Object", ".", "finalize", "()", "method", "in", "tests", "."], "add_tokens": "public void destroy ( ) {", "del_tokens": "@ Override public void finalize ( ) {", "commit_type": "fix"}
{"commit_tokens": ["implemented", "but", "not", "connected", "and", "tested", "QUERY_RECORDER", "TOGGLE_CHANNEL_FAVORITE"], "add_tokens": "/ * * * Toggle the current channel as a member of the given channel group . The request only * works for recorders that are local to the connected backend . If the recorder is * remote , the request will be silently ignored . * * @ param channelGroup * the group in which to toggle the current channel * @ throws IOException * if there is a communication or protocol error * * @ since 63 * / public void toggleChannelFavorite ( String channelGroup ) throws IOException ;", "del_tokens": "// TODO public void toggleChannelFavorite ( ) throws IOException ;", "commit_type": "implement"}
{"commit_tokens": ["Add", "ability", "to", "filter", "tests", "with", "the", "new", "Rendering", "Test", "Framework", "annotations"], "add_tokens": "private static final String DEFAULT_PATTERN = \".*\\\\.test\" ; / * * * @ return the regex pattern to filter * . test files to execute * / String pattern ( ) default DEFAULT_PATTERN ; String packagePrefix = \"\" ; String pattern = DEFAULT_PATTERN ; packagePrefix = scopeAnnotation . value ( ) ; pattern = scopeAnnotation . pattern ( ) ; List < Object [ ] > parametersList = ( List < Object [ ] > ) GENERATOR . generateData ( packagePrefix , pattern ) ;", "del_tokens": "List < Object [ ] > parametersList ; parametersList = ( List < Object [ ] > ) GENERATOR . generateData ( scopeAnnotation . value ( ) ) ; } else { parametersList = ( List < Object [ ] > ) GENERATOR . generateData ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "card", "on", "top", "of", "the", "list"], "add_tokens": "public static final String CREATE_CARD = API_URL + \"/cards?pos=top&\" + API_KEY_TOKEN_PARAM ;", "del_tokens": "public static final String CREATE_CARD = API_URL + \"/cards?\" + API_KEY_TOKEN_PARAM ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "query", "against", "meta", "data", "e", ".", "g", ".", "generation", "or", "expiry"], "add_tokens": "@ SuiteClasses ( { SelectorTest . class , FlightsTest . class , UpdatorTest . class } )", "del_tokens": "@ SuiteClasses ( { SelectorTest . class , UpdatorTest . class } )", "commit_type": "add"}
{"commit_tokens": ["implemented", "a", "junit", "body", "DSL"], "add_tokens": "public PactDslRequestWithPath body ( DslPart body ) { public PactDslResponse body ( DslPart body ) {", "del_tokens": "public PactDslRequestWithPath body ( PactDslJsonBody body ) { public PactDslResponse body ( PactDslJsonBody body ) {", "commit_type": "implement"}
{"commit_tokens": ["changed", "DEFAULT_URI", "to", "https", ":", "//", "github", ".", "com", "/", "spring", "-", "platform", "-", "samples", "/", "config", "-", "repo"], "add_tokens": "public static final String DEFAULT_URI = \"https://github.com/spring-platform-samples/config-repo\" ;", "del_tokens": "public static final String DEFAULT_URI = \"https://github.com/scratches/config-repo\" ;", "commit_type": "change"}
{"commit_tokens": ["added", "implementations", "for", "QUERY_FILE_HASH", "and", "SET_SETTING", "(", "neither", "are"], "add_tokens": "public Command63QuerySetting ( String host , String name ) message = \"QUERY_SETTING \" + host + \" \" + name ;", "del_tokens": "public Command63QuerySetting ( String host , String key ) message = \"QUERY_SETTING \" + host + \" \" + key ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "getHeadlines", "method", "in", "Dysco", "DAO"], "add_tokens": "// Retrieve web pages from solr index Set < String > expandedUrls = new HashSet < String > ( ) ; solrQuery . setRows ( size ) ; if ( ! expandedUrls . contains ( expandedUrl ) && ! uniqueUrls . contains ( url ) ) { int shares = webPageDAO . getWebPageShares ( url ) ; webPage . setShares ( shares ) ; uniqueUrls . add ( url ) ; expandedUrls . add ( expandedUrl ) ; Logger . getRootLogger ( ) . info ( webPages . size ( ) + \" web pages retrieved. Re-rank by popularity (#shares)\" ) ; if ( wp1 . getDate ( ) . before ( wp2 . getDate ( ) ) ) return 1 ; else return - 1 ; return wp1 . getShares ( ) < wp2 . getShares ( ) ? 1 : - 1 ;", "del_tokens": "//Retrieve web pages that is stored in solr solrQuery . setRows ( 20 ) ; if ( ! uniqueUrls . contains ( expandedUrl ) ) { WebPage updatedWP = webPageDAO . getWebPage ( url ) ; webPage . setShares ( updatedWP . getShares ( ) ) ; uniqueUrls . add ( expandedUrl ) ; Logger . getRootLogger ( ) . info ( webPages . size ( ) + \" web pages retrieved. Re-rank...\" ) ; return 0 ; return wp1 . getShares ( ) <= wp2 . getShares ( ) ? 1 : - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "REST", "functions"], "add_tokens": "import javax . servlet . http . HttpServletResponse ; import org . apache . wicket . protocol . http . mock . MockHttpServletResponse ; @ Test public void testExecuteFunction ( ) throws Exception { String ret = executeUrl ( \"orientdb/function/db/fun1\" , \"GET\" , null ) ; assertTrue ( ret . contains ( \"fun1\" ) ) ; ret = executeUrl ( \"orientdb/function/db/fun2\" , \"POST\" , null ) ; assertTrue ( ret . contains ( \"fun2\" ) ) ; } @ Test ( expected = IOException . class ) public void testExecuteFailing ( ) throws Exception { String ret = executeUrl ( \"orientdb/function/db/fun2\" , \"GET\" , null ) ; System . out . println ( \"ret=\" + ret ) ; } MockHttpServletResponse response = tester . getLastResponse ( ) ; int status = response . getStatus ( ) ; if ( status >= HttpServletResponse . SC_OK + 100 ) { throw new IOException ( \"Code: \" + response . getStatus ( ) + \" Message: \" + response . getErrorMessage ( ) + \" Content: \" + response . getDocument ( ) ) ; } else { return response . getDocument ( ) ; }", "del_tokens": "return tester . getLastResponseAsString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "optional", "initial", "value", "to", "Money", "Market", "Account", ".", "This", "is", "useful", "when", "you", "consider", "options", "on", "the", "money", "market", "account", "."], "add_tokens": "private double initialValue = 1.0 ; * @ param initialValue The initial value , i . e . , the value at inception time . public MoneyMarketAccount ( double inceptionTime , double initialValue , double accrualPeriod ) { this . inceptionTime = inceptionTime ; this . initialValue = initialValue ; this . accrualPeriod = accrualPeriod ; if ( accrualPeriod <= 0 ) return new RandomVariable ( Double . MAX_VALUE ) ; RandomVariableInterface value = new RandomVariable ( initialValue ) ;", "del_tokens": "public MoneyMarketAccount ( double inceptionTime , double accrualPeriod ) { this . inceptionTime = inceptionTime ; this . accrualPeriod = accrualPeriod ; RandomVariableInterface value = new RandomVariable ( 1.0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "lambda", "expressions", "more", "terse"], "add_tokens": ". filter ( o -> o instanceof LazyElement ) . map ( e -> ( LazyElement ) e ) . forEach ( e -> e . setContext ( getContext ( ) ) ) ;", "del_tokens": ". filter ( ( o ) -> o instanceof LazyElement ) . map ( ( e ) -> ( LazyElement ) e ) . forEach ( ( e ) -> e . setContext ( getContext ( ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "NPE", "when", "unsuccessful", "response", "is", "returned", "from", "server", "when", "building", "the", "image", "."], "add_tokens": "String imageId = IOUtil . substringBetween ( fullLog , \"Successfully built \" , \"\\\\n\\\"}\" ) ; if ( imageId == null ) { throw new IllegalStateException ( String . format ( \"Docker server has not provided an imageId for image build from %s. Response from the server was:\\n%s\" , location , fullLog ) ) ; } return imageId . trim ( ) ;", "del_tokens": "String imageId = IOUtil . substringBetween ( fullLog , \"Successfully built \" , \"\\\\n\\\"}\" ) . trim ( ) ; return imageId ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "crash", "while", "acquiring", "wake", "lock"], "add_tokens": "final PowerManager . WakeLock wakeLock = WakeLockUtil . acquireWakeLock ( mContext , JobManager . class . getName ( ) , TimeUnit . MINUTES . toMillis ( 1 ) ) ; WakeLockUtil . releaseWakeLock ( wakeLock ) ;", "del_tokens": "PowerManager powerManager = ( PowerManager ) mContext . getSystemService ( Context . POWER_SERVICE ) ; final PowerManager . WakeLock wakeLock = powerManager . newWakeLock ( PowerManager . PARTIAL_WAKE_LOCK , JobManager . class . getName ( ) ) ; if ( JobUtil . hasWakeLockPermission ( mContext ) ) { wakeLock . setReferenceCounted ( false ) ; wakeLock . acquire ( TimeUnit . SECONDS . toMillis ( 3 ) ) ; } try { if ( wakeLock . isHeld ( ) ) { wakeLock . release ( ) ; } } catch ( Exception e ) { // just to make sure if the PowerManager crashes while acquiring a wake lock CAT . e ( e ) ; }", "commit_type": "fix"}
{"commit_tokens": ["fixed", "an", "issue", "with", "removeItem"], "add_tokens": "element . removeFromParent ( ) ; for ( int i = 0 ; i < groups . size ( ) ; i ++ ) { OptGroup group = groups . get ( i ) ; // remove empty groups if ( group . getCount ( ) <= 0 ) { group . remove ( ) ; groups . remove ( i ) ; }", "del_tokens": "if ( count == 0 ) { remove ( ) ; } getElement ( ) . removeChild ( element ) ; for ( OptGroup group : groups ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "in", "OracleURLPArser", "for", "LDAP", "connection", "string"], "add_tokens": "\"(?<username>.*)@(?<ldap>ldap:)?(//)?(?<host>[^:/]+)(?<port>:[0-9]+)?(?<service>[:/][^:/]+)?(?<server>:[^:/]+)?(?<instance>/[^:/]+)?\" ) ;", "del_tokens": "\"(?<username>.*)@(//)?(?<host>[^:/]+)(?<port>:[0-9]+)?(?<service>[:/][^:/]+)?(?<server>:[^:/]+)?(?<instance>/[^:/]+)?\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "the", "rest", "service", "list", "to", "return", "urls", "whos", "host", "and", "port", "match", "that", "used", "by", "the", "client", "(", "controlled", "by", "service", ".", "list", ".", "use", ".", "request", ".", "host", "defaults", "to", "being", "off", ")"], "add_tokens": "import javax . ws . rs . core . Context ; import javax . ws . rs . core . HttpHeaders ; import javax . ws . rs . core . UriInfo ; public String index ( @ Context HttpHeaders headers , @ Context UriInfo uriInfo ) throws Exception ; @ Doc ( value = \"Describes a single service\" ) public String getServiceDescription ( @ Doc ( value = \"the internal index of the service\" ) @ PathParam ( \"service_id\" ) int serviceId , @ Context HttpHeaders headers , @ Context UriInfo uriInfo ) throws Exception ;", "del_tokens": "public String index ( ) throws Exception ; @ Doc ( value = \"Describes a single service\" ) public String getServiceDescription ( @ Doc ( value = \"the internal index of the service\" ) @ PathParam ( \"service_id\" ) int serviceId ) throws Exception ;", "commit_type": "allow"}
{"commit_tokens": ["Use", "OSGi", "logger", "on", "http"], "add_tokens": "import org . jbundle . util . osgi . finder . ClassServiceUtility ; import org . osgi . service . log . LogService ; ClassServiceUtility . log ( context , LogService . LOG_INFO , \"Starting Http Service tracker\" ) ; ClassServiceUtility . log ( context , LogService . LOG_INFO , \"Stopping http service tracker\" ) ;", "del_tokens": "System . out . println ( \"Starting Http Service tracker\" ) ; System . out . println ( \"Stopping http service tracker\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "support", "for", "<switch", ">", "element", ".", "Added", "three", "SVG", "files", "to", "test", "it", "."], "add_tokens": "import java . util . Set ; // Any element that can appear inside a <switch> element. protected static abstract class SvgConditionalElement extends SvgElement { public Set < String > requiredFeatures = null ; public String requiredExtensions = null ; public Set < String > systemLanguage = null ; } protected static class SvgContainer extends SvgConditionalElement protected interface HasTransform { public void setTransform ( Matrix matrix ) ; } protected static abstract class GraphicsElement extends SvgConditionalElement implements HasTransform protected static class Use extends GraphicsElement // TODO: OverridesDisplayNone // An SVG element that can contain other elements. protected static class Switch extends Group // TODO: OverridesDisplayNone { }", "del_tokens": "import android . util . Log ; protected static class SvgContainer extends SvgElement protected interface HasTransform { public void setTransform ( Matrix matrix ) ; } protected static abstract class GraphicsElement extends SvgElement implements HasTransform protected static class Use extends GraphicsElement", "commit_type": "add"}
{"commit_tokens": ["fix", "a", "minor", "bug", "of", "mouse", "event"], "add_tokens": "updateMouse ( ) ; updateMouse ( ) ; eventListener . mouseEvent ( MouseEvent . ENTERED , MouseButton . NONE , mouse ) ; initMouse ( ) ; eventListener . mouseEvent ( MouseEvent . EXITED , MouseButton . NONE , mouse ) ; initMouse ( ) ; private final void initMouse ( ) { Point p = getMousePosition ( true ) ; if ( p != null ) { mouse . setX ( p . x ) ; mouse . setY ( getHeight ( ) - p . y ) ; mouse . setPrevX ( mouse . getX ( ) ) ; mouse . setPrevY ( mouse . getY ( ) ) ; } }", "del_tokens": "eventListener . mouseEvent ( MouseEvent . ENTERED , MouseButton . LEFT , mouse ) ; eventListener . mouseEvent ( MouseEvent . EXITED , MouseButton . LEFT , mouse ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "documentation", "of", "Jenkins", "hashes"], "add_tokens": "* @ return the third of the three hash values returned by { @ link # jenkins ( BitVector , long , long [ ] ) } . * @ return the third of the three hash values returned by { @ link # jenkins ( BitVector , long , long [ ] ) } with seed 0. * @ return the third of the three hash values returned by { @ link # jenkins ( BitVector , long , long [ ] , long [ ] , long [ ] , long [ ] ) } .", "del_tokens": "* @ return the first of the three hash values returned by { @ link # jenkins ( BitVector , long , long [ ] ) } . * @ return the first of the three hash values returned by { @ link # jenkins ( BitVector , long , long [ ] ) } with seed 0. * @ return the first of the three hash values returned by { @ link # jenkins ( BitVector , long , long [ ] , long [ ] , long [ ] , long [ ] ) } .", "commit_type": "fix"}
{"commit_tokens": ["Adding", "flow", "cancel", "pause", "resume", "hooks", "."], "add_tokens": "FAILED , FAILED_FINISHING , SUCCEEDED , RUNNING , WAITING , KILLED , DISABLED , READY , PAUSED , UNKNOWN", "del_tokens": "FAILED , FAILED_FINISHING , SUCCEEDED , RUNNING , WAITING , KILLED , DISABLED , READY , UNKNOWN", "commit_type": "add"}
{"commit_tokens": ["changed", "wording", "and", "added", "javadoc"], "add_tokens": "/ * * * Gets the end - points by an offset to now , i . e . , 0 means to get the now bucket , - 1 gets the previous bucket , and + 1 * will get the next bucket . * * @ param bucketsFromNow the amount of buckets to retrieve using now as anchor * * @ return the end - point ( bucket ) with an offset of { @ code bucketsFromNow } from now * * @ throws IllegalTimePoint if the current now is not defined * / public BucketEndPoints getEndPoints ( final int bucketsFromNow ) throws IllegalTimePoint { return now . move ( bucketsFromNow ) ;", "del_tokens": "public BucketEndPoints getEndPoints ( final int idx ) throws IllegalTimePoint { return now . move ( idx ) ;", "commit_type": "change"}
{"commit_tokens": ["allow", "url", "prefixes", "other", "than", "jdbc", ":", "tracing"], "add_tokens": "return url != null && url . startsWith ( getUrlPrefix ( ) ) ; protected String getUrlPrefix ( ) { return \"jdbc:tracing:\" ; } String extracted = url . startsWith ( getUrlPrefix ( ) ) ? url . replace ( getUrlPrefix ( ) , \"jdbc:\" ) : url ;", "del_tokens": "return url != null && url . startsWith ( \"jdbc:tracing:\" ) ; String extracted = url . startsWith ( \"jdbc:tracing:\" ) ? url . replace ( \"tracing:\" , \"\" ) : url ;", "commit_type": "allow"}
{"commit_tokens": ["Add", "support", "of", "Google", "Guice", "dependency", "injection", "at", "integration", "tests"], "add_tokens": "Guice . createInjector ( new ServersModule ( ) ) . injectMembers ( this ) ;", "del_tokens": "Guice . createInjector ( new ServersModule ( ) ) . injectMembers ( this ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "doc", "for", "port", "param", "."], "add_tokens": "* The port to serve the repository on . If not specified a random port will be used .", "del_tokens": "* The port to serve the repository on .", "commit_type": "update"}
{"commit_tokens": ["Add", "a", "log", "to", "inform", "on", "the", "yar", "registry", "properties", "used", "to", "build", "it", "in", "the", "activator"], "add_tokens": "import org . javabits . yar . guice . YarGuices ; import java . util . logging . Logger ; private static final Logger LOG = Logger . getLogger ( Activator . class . getName ( ) ) ; builder . timeout ( getExecutionTimeout ( bundleContext ) ) . blockingSupplierStrategy ( getBlockingSupplierStrategy ( bundleContext ) ) ; LOG . info ( \"Create Yar OSGi registry: \" + builder ) ; return builder . build ( ) ;", "del_tokens": "return builder . timeout ( getExecutionTimeout ( bundleContext ) ) . blockingSupplierStrategy ( getBlockingSupplierStrategy ( bundleContext ) ) . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "Fax", "Result", "State", "/", "SendFax", "(", "ResendFax", ")", "title", "field"], "add_tokens": "private String title ; private Integer state ; private Integer result ; / * * * 팩스제목 확인 * * @ return 팩스제목 * / public String getTitle ( ) { return title ; } / * * * 전송상태코드 * * @ return 전송상태 * / public Integer getState ( ) { return state ; } / * * * 전송결과코드 * * @ return 결과코드 * / public Integer getResult ( ) { return result ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["move", "from", "jaxb", "to", "stax"], "add_tokens": "import org . owasp . appsensor . configuration . client . StaxClientConfigurationReader ; ClientConfigurationReader reader = new StaxClientConfigurationReader ( ) ; assertTrue ( \"org.owasp.appsensor.response.impl.NoopResponseHandler\" . equals ( configuration . getResponseHandlerImplementation ( ) ) ) ; assertTrue ( \"org.owasp.appsensor.user.impl.NoopUserManager\" . equals ( configuration . getUserManagerImplementation ( ) ) ) ; assertTrue ( \"rest\" . equals ( configuration . getServerConnection ( ) . getType ( ) ) ) ; assertTrue ( \"https\" . equals ( configuration . getServerConnection ( ) . getProtocol ( ) ) ) ; assertTrue ( \"www.owasp.org\" . equals ( configuration . getServerConnection ( ) . getHost ( ) ) ) ; assertTrue ( 5000 == configuration . getServerConnection ( ) . getPort ( ) ) ; assertTrue ( \"/appsensor/v2/api/\" . equals ( configuration . getServerConnection ( ) . getPath ( ) ) ) ;", "del_tokens": "import org . owasp . appsensor . configuration . client . XmlClientConfigurationReader ; ClientConfigurationReader reader = new XmlClientConfigurationReader ( ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "methods", "for", "backlog", "webhook", "."], "add_tokens": "StarMethods , NotificationMethods , GitMethods , GroupMethods , WebhookMethods {", "del_tokens": "StarMethods , NotificationMethods , GitMethods , GroupMethods {", "commit_type": "add"}
{"commit_tokens": ["Fix", "all", "JavaDoc", "warnings", "and", "some", "IDE", "warnings"], "add_tokens": "* * @ param status The HTTP status code to report * @ param mimeType The mime - type of the response * @ param data The contents of hte response * Convenience method that creates a { @ link Response } out of * * @ param status The HTTP status code to report * @ param mimeType The mime - type of the response * @ param txt The contents of the response * * @ param name The name of the HTTP header * @ param value The value of the HTTP header * * @ param args The commandline arguments , e . g . for specifying the port * * * @ param uriIn Which file to serve * @ param header HTTP headers , currently ignored * @ param homeDir The base - dir from where to server the file * @ param allowDirectoryListing If contents of directories can be listed * * @ return The resulting response - object . msg . append ( \"<b><a href=\\\"\" ) . append ( uri , 0 , slash + 1 ) . append ( \"\\\">..</a></b><br/>\" ) ;", "del_tokens": "* Convenience method that makes an InputStream out of msg . append ( \"<b><a href=\\\"\" ) . append ( uri . substring ( 0 , slash + 1 ) ) . append ( \"\\\">..</a></b><br/>\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["removed", "/", "data", "from", "new", "model", "uris"], "add_tokens": ". addEntity ( \"identity\" , Identity . class ) . setString ( 0 , \"/model/new\" ) . uniqueResult ( ) ; identity . setUri ( \"/model/\" + identity . getId ( ) ) ;", "del_tokens": ". addEntity ( \"identity\" , Identity . class ) . setString ( 0 , \"/data/model/\" ) . uniqueResult ( ) ; identity . setUri ( \"/data/model/\" + identity . getId ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "mock", "and", "test", "for", "the", "original", "config", "to", "replace", "the", "integration", "tests", "."], "add_tokens": "//@Test", "del_tokens": "@ Test", "commit_type": "add"}
{"commit_tokens": ["Fix", "database", "name", "parsing", "when", "a", "path", "URL", "query", "params", "contains", "a", "path"], "add_tokens": "int hostLabelStartIndex = url . indexOf ( \"//\" ) ; int hostLabelEndIndex = url . indexOf ( \"/\" , hostLabelStartIndex + 2 ) ; int databaseStartTag = url . indexOf ( \"/\" , hostLabelEndIndex ) ;", "del_tokens": "int databaseStartTag = url . lastIndexOf ( \"/\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "more", "logging", "messages", "for", "when", "the", "connection", "acquire", "time", "is", "longer", "than", "timeoutMillis"], "add_tokens": "long connectionAcquireDurationMillis = TimeUnit . NANOSECONDS . toMillis ( endNanos - startNanos ) ; if ( connectionAcquireDurationMillis > timeoutMillis ) { LOGGER . warn ( \"Connection was acquired in {} millis, timeoutMillis is set to {}\" , connectionAcquireDurationMillis , timeoutMillis ) ; int maxPoolSize = poolAdapter . getMaxPoolSize ( ) ; if ( maxPoolSize < maxOverflowPoolSize ) { if ( ! incrementPoolSize ( expectingMaxSize ) ) { LOGGER . warn ( \"Can't acquire connection, pool size has already overflown to its max size.\" ) ; } } else { LOGGER . info ( \"Pool size has already overflown to its max size of {}\" , maxPoolSize ) ; } LOGGER . warn ( \"Can't acquire connection due to adaptor timeout, pool size has already overflown to its max size.\" ) ;", "del_tokens": "if ( ( TimeUnit . NANOSECONDS . toMillis ( endNanos - startNanos ) > timeoutMillis ) && ( poolAdapter . getMaxPoolSize ( ) < maxOverflowPoolSize ) && ! incrementPoolSize ( expectingMaxSize ) ) { LOGGER . warn ( \"Can't acquireConnection connection, pool size has already overflown to its max size.\" ) ; LOGGER . warn ( \"Can't acquireConnection connection due to adaptor timeout, pool size has already overflown to its max size.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "to", "filter", "rules", "that", "are", "actually", "processed", "at", "runtime"], "add_tokens": "import java . util . function . Predicate ; / * By default , process on all rules * / process ( jCas , r -> true ) ; } public void process ( JCas jCas , Predicate < Rule > ruleFilter ) { if ( ! ruleFilter . test ( rule ) ) continue ;", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["make", "uia", "-", "server", "a", "mvn", "module", "for", "easy", "development"], "add_tokens": "/ * * Copyright 2015. * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * /", "del_tokens": "import com . android . uiautomator . stub . IUiDevice ; import com . android . uiautomator . stub . Point ; import com . android . uiautomator . stub . UiSelector ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "memory", "leak", "by", "using", "an", "explicit", "permit", "object"], "add_tokens": "final Object permit = new Object ( ) ; final GatedStreamSinkChannel nextRequestResponseChannel = new GatedStreamSinkChannel ( targetChannel , permit , false , true ) ; nextRequestResponseChannel . openGate ( permit ) ;", "del_tokens": "final GatedStreamSinkChannel nextRequestResponseChannel = new GatedStreamSinkChannel ( targetChannel , this , false , true ) ; nextRequestResponseChannel . openGate ( HttpReadListener . this ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "more", "efficient", "logging", "API", "in", "RuntimeManager"], "add_tokens": "import java . util . logging . Level ; LOG . log ( Level . INFO , \"Topology: {0} to be {1}ed\" , new Object [ ] { topologyName , command } ) ; LOG . log ( Level . SEVERE , \"Failed to {0} topology {1}\" , new Object [ ] { command , topologyName } ) ; LOG . log ( Level . SEVERE , \"Topology {0} {1} successfully\" , new Object [ ] { topologyName , command } ) ;", "del_tokens": "LOG . info ( \"Topology: \" + topologyName + \" to be \" + command + \"ed\" ) ; LOG . severe ( \"Failed to \" + command + \" topology \" + topologyName ) ; LOG . info ( \"Topology \" + topologyName + \" \" + command + \" successfully\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Made", "the", "stdout", "/", "stderr", "capture", "properly", "differentiate", "between", "stdout", "/", "stderr"], "add_tokens": "import org . slf4j . Logger ; import java . io . OutputStream ; * Not - entirely Shameless ripoff from stackoverflow . com // Be sure log4j has been initialized here, which is always the case for embedded-jetty. System . setOut ( createLoggingProxy ( System . out , \"stdout\" , true ) ) ; System . setErr ( createLoggingProxy ( System . err , \"stderr\" , false ) ) ; private static PrintStream createLoggingProxy ( final PrintStream realPrintStream , final String stream , final boolean stdout ) { private Logger logger = LoggerFactory . getLogger ( stdout ? \"stdout\" : \"stderr\" ) ; if ( stdout ) logger . info ( line ) ; else logger . warn ( line ) ;", "del_tokens": "* Shameless ripoff from stackoverflow . com // Be sure log4j has been initialized here. System . setOut ( createLoggingProxy ( System . out ) ) ; System . setErr ( createLoggingProxy ( System . err ) ) ; private static PrintStream createLoggingProxy ( final PrintStream realPrintStream ) { LoggerFactory . getLogger ( \"stdout\" ) . info ( line ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "a", "bug", "related", "to", "shrinking", "body"], "add_tokens": "int d = currLength - payloadLength ; aps . put ( \"alert\" , body . subSequence ( 0 , body . length ( ) - d ) ) ;", "del_tokens": "int d = payloadLength - currLength ; aps . put ( \"alert\" , body . subSequence ( 0 , d ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "attach", "(", "Class", ")", "methods"], "add_tokens": "attach ( ob . getClass ( ) ) ; } public void attach ( Class < ? > cls ) { for ( Method method : cls . getMethods ( ) ) InstanceMethod instanceMethod = new InstanceMethod ( cls , method , setting . mandatory ( ) ) ;", "del_tokens": "for ( Method method : ob . getClass ( ) . getMethods ( ) ) InstanceMethod instanceMethod = new InstanceMethod ( ob , method , setting . mandatory ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "in", "result", "size", "fetched", "from", "hbase", "and", "timers", "for", "hbase", "scan", "and", "JobDetails", "and", "Flow", "population"], "add_tokens": "Stopwatch timerJob = new Stopwatch ( ) ; long resultSize = 0 ; resultSize += result . getWritableSize ( ) ; timerJob . start ( ) ; timerJob . stop ( ) ; LOG . info ( \"Fetched from hbase \" + rowCount + \" rows, \" + colCount + \" columns, \" + resultSize + \" bytes ( \" + resultSize / ( 1024 * 1024 ) + \") MB, in total time of \" + timer + \" with \" + timerJob + \" spent inJobDetails & Flow population\" ) ; } finally {", "del_tokens": "LOG . info ( \"Fetched from hbase \" + rowCount + \" rows, \" + colCount + \" columns in \" + timer ) ; } finally {", "commit_type": "add"}
{"commit_tokens": ["using", "the", "new", "builder", "API", "to", "bootstrap", "the", "SameAsService"], "add_tokens": "import org . sameas . sameas4j . bootstrap . SameAsServiceBuilder ; this . service = new SameAsServiceBuilder ( ) . createNew ( ) . usingDefaultInMemoryCache ( ) ;", "del_tokens": "this . service = DefaultSameAsServiceFactory . getSingletonInstance ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Improved", "the", "implementation", "of", "the", "method", "to", "only", "create", "and", "process", "the", "list", "when", "needed", "."], "add_tokens": "List < String > classpath = null ; if ( classpathElements != null ) { classpath = new ArrayList < String > ( ) ; classpath = Collections . unmodifiableList ( classpath ) ; } else { classpath = Collections . emptyList ( ) ; // already immutable return classpath ;", "del_tokens": "List < String > classpath = new ArrayList < String > ( ) ; if ( classpathElements != null && classpathElements . length != 0 ) { return Collections . unmodifiableList ( classpath ) ;", "commit_type": "improve"}
{"commit_tokens": ["fix", "jdk", "7", "build", "issue"], "add_tokens": "Map < String , String > options = processingEnv . getOptions ( ) ; toothpickRegistryPackageName = options . get ( PARAMETER_REGISTRY_PACKAGE_NAME ) ; String toothpickRegistryChildrenPackageNames = options . get ( PARAMETER_REGISTRY_CHILDREN_PACKAGE_NAMES ) ; //getOrDefault could be used here, but it's ony available on jdk 7. if ( options . containsKey ( PARAMETER_EXCLUDES ) ) { toothpickExcludeFilters = options . get ( PARAMETER_EXCLUDES ) ; }", "del_tokens": "toothpickRegistryPackageName = processingEnv . getOptions ( ) . get ( PARAMETER_REGISTRY_PACKAGE_NAME ) ; String toothpickRegistryChildrenPackageNames = processingEnv . getOptions ( ) . get ( PARAMETER_REGISTRY_CHILDREN_PACKAGE_NAMES ) ; toothpickExcludeFilters = processingEnv . getOptions ( ) . getOrDefault ( PARAMETER_EXCLUDES , toothpickExcludeFilters ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "public", "modification", "to", "API_VERSION", "."], "add_tokens": "public static final String API_VERSION = \"2019-05-29\" ;", "del_tokens": "static final String API_VERSION = \"2019-05-29\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "logging", "to", "a", "few", "classes"], "add_tokens": "import java . util . logging . Logger ; private static final Logger LOG = Logger . getLogger ( CreateKmerTable . class . getName ( ) ) ; LOG . info ( \"Loading data into hash tables\" ) ; LOG . info ( \"Loaded \" + accessions . size ( ) + \" rows and \" + kmers . size ( ) + \" columns\" ) ; LOG . info ( \"Generating rows\" ) ; LOG . info ( \"Completed table generation\" ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["added", "test", "for", "type", "serializers"], "add_tokens": "cv . put ( name , object ? 1 : 0 ) ;", "del_tokens": "cv . put ( name , object ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "the", "comment", "spelling", ":", "-", "p"], "add_tokens": "* This listener will listen to every incoming short message , recognized by", "del_tokens": "* This listener will listen to every incomming short message , recognized by", "commit_type": "update"}
{"commit_tokens": ["Added", "some", "more", "explanations", "to", "the", "programmers", "reference", ".", "Still", "a", "lot", "to", "do", "..."], "add_tokens": "/ *", "del_tokens": "/ * SeTOfMolecules . java", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "generating", "UiBinders", "that", "use", "parameterized", "types", "for", "their", "generated", "widgets"], "add_tokens": "import java . lang . reflect . Type ; Type uiRootType = parameterizedType . getActualTypeArguments ( ) [ 0 ] ; if ( uiRootType instanceof ParameterizedType ) { return ( Class < ? > ) ( ( ParameterizedType ) uiRootType ) . getRawType ( ) ; } else { return ( Class < ? > ) uiRootType ; }", "del_tokens": "Class < ? > uiRootType = ( Class < ? > ) parameterizedType . getActualTypeArguments ( ) [ 0 ] ; return uiRootType ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "it", "compile", "with", "Java", "5"], "add_tokens": "Method m = null ; try { m = ObjectStreamClass . class . getMethod ( \"lookupAny\" , new Class [ ] { Class . class } ) ; } catch ( NoSuchMethodException e ) { throw new ObjenesisException ( e ) ; } try { objectStreamClass = ( ObjectStreamClass ) m . invoke ( null , new Object [ ] { type } ) ; } catch ( IllegalAccessException e ) { throw new ObjenesisException ( e ) ; } catch ( InvocationTargetException e ) { throw new ObjenesisException ( e ) ; }", "del_tokens": "objectStreamClass = ObjectStreamClass . lookupAny ( type ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "fields", "to", "sort", "order"], "add_tokens": "@ JsonPropertyOrder ( { \"headers\" , \"query\" , \"totalItems\" , \"aggs\" , \"bbox\" , \"fields\" , \"items\" } )", "del_tokens": "@ JsonPropertyOrder ( { \"headers\" , \"query\" , \"totalItems\" , \"aggs\" , \"bbox\" , \"items\" } )", "commit_type": "add"}
{"commit_tokens": ["Add", "tests", "for", "Quote", ".", "btc"], "add_tokens": "public void transaction ( ) throws Exception { assertEquals ( Money . parse ( \"BTC 1\" ) , q . getBtc ( ) ) ; assertTrue ( DateTime . parse ( \"2013-10-01T00:11:31-07:00\" ) . isEqual ( transaction . getCreatedAt ( ) ) ) ; assertEquals ( \"an external account\" , cache . getOtherUser ( ) . getName ( ) ) ;", "del_tokens": "public void transaction ( ) throws Exception { assertTrue ( DateTime . parse ( \"2013-10-01T00:11:31-07:00\" ) . isEqual ( transaction . getCreatedAt ( ) ) ) ; assertEquals ( \"an external account\" , cache . getOtherUser ( ) . getName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "a", "Pattern", "object", "to", "compile", "the", "pattern", "only", "once", "for", "performance", "reasons", ".", "String", ".", "matches", "compiles", "the", "pattern", "every", "time", "."], "add_tokens": "import java . util . regex . Pattern ; public static final String SINGLE_LINE_COMMENT_PATTERN = \"(^--.*)|(^//.*)\" ; private final Pattern commentPattern ; this . commentPattern = Pattern . compile ( SINGLE_LINE_COMMENT_PATTERN ) ; . lines ( ) . filter ( line -> ! isLineComment ( line ) ) . forEach ( fileContent :: append ) ; private boolean isLineComment ( String line ) { return commentPattern . matcher ( line ) . matches ( ) ; }", "del_tokens": "public static final String SINGLE_LINE_COMMENT_PATTERN = \"(^--.*)|(^\\\\/\\\\/.*)\" ; . lines ( ) . filter ( line -> ! line . matches ( SINGLE_LINE_COMMENT_PATTERN ) ) . forEach ( fileContent :: append ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "nerPipe", ":", "byteStream", "to", "stringWriter"], "add_tokens": "import java . io . StringWriter ; StringWriter bos = new StringWriter ( ) ;", "del_tokens": "import java . io . OutputStream ; import java . io . PrintStream ; import com . sun . xml . internal . messaging . saaj . util . ByteOutputStream ; ByteOutputStream bos = new ByteOutputStream ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "ability", "to", "disable", "config", "via", "properties"], "add_tokens": "@ ConditionalOnProperty ( name = \"spring.cloud.consul.config.enabled\" , matchIfMissing = true )", "del_tokens": "@ ConditionalOnProperty ( name = \"spring.cloud.consul.enabled\" , matchIfMissing = true )", "commit_type": "add"}
{"commit_tokens": ["Fix", "wrong", "generification", "of", "ArraysAsListSerializer"], "add_tokens": "import java . lang . reflect . Array ; import java . lang . reflect . Field ; import java . util . Arrays ; import java . util . List ; public class ArraysAsListSerializer implements Serializer < List < ? > > { public List < ? > read ( Kryo kryo , Input input , Class < List < ? > > type ) { return Arrays . asList ( items ) ; public void write ( Kryo kryo , Output output , List < ? > obj ) {", "del_tokens": "import java . lang . reflect . Array ; import java . lang . reflect . Field ; import java . util . Arrays ; @ SuppressWarnings ( \"unchecked\" ) public class ArraysAsListSerializer < T > implements Serializer < T > { public T read ( Kryo kryo , Input input , Class < T > type ) { return ( T ) Arrays . asList ( items ) ; public void write ( Kryo kryo , Output output , T obj ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "doc", "of", "config", "utils", "."], "add_tokens": "* provide key string in properties file . < p / > * < p / > * Normally , use enum to provide config keys like this : * < pre > { @ code * public enum SelfConfig implements IConfigKey { * CONFIG1 ( \"str\" ) , * CONFIG2 ( \"bool\" ) , * CONFIG3 ( \"num\" ) ; * * private final String key ; * * SelfConfig ( String key ) { * this . key = key ; * } * * public String getKeyString ( ) { * return key ; * } * } * } < pre / >", "del_tokens": "* provide key string in properties file .", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "StreamingSolutions", "class", "for", "SHPSolutions", "which", "now", "correctly", "implements", "all", "cursor", "methods"], "add_tokens": "import spark . spi . StreamingSolutions ; public class SHPSolutions extends StreamingSolutions implements Solutions { protected Map < String , RDFNode > fetchNext ( ) { List < Object > rowData = null ; if ( query . incrementCursor ( ) ) rowData = query . getRow ( ) ;", "del_tokens": "import java . util . Iterator ; import spark . spi . BaseSolutions ; public class SHPSolutions extends BaseSolutions implements Solutions { public Map < String , RDFNode > getResult ( ) { List < Object > rowData = query . getRow ( ) ; @ Override public Iterator < Map < String , RDFNode > > iterator ( ) { // TODO Auto-generated method stub return null ; } @ Override public int getRow ( ) { return this . query . getCursor ( ) ; } @ Override public boolean isBeforeFirst ( ) { return this . query . getCursor ( ) == 0 ; } @ Override public boolean isFirst ( ) { return this . query . getCursor ( ) == 1 && ! this . query . isAfterLast ( ) ; } @ Override public boolean next ( ) { return this . query . incrementCursor ( ) ; }", "commit_type": "use"}
{"commit_tokens": ["Adding", "business", "notestore", "to", "producer", "adding", "async", "helper", "methods"], "add_tokens": "mUserStoreClient = mClientProducer . createUserStoreClient ( url ) ; //EvernoteUtil.getUserStoreClient(url, mUserAgent, mDataDir);", "del_tokens": "mUserStoreClient = mClientProducer . createUserStore ( url ) ; //EvernoteUtil.getUserStoreClient(url, mUserAgent, mDataDir);", "commit_type": "add"}
{"commit_tokens": ["Adding", "partial", "support", "for", "show", "/", "hide", "filter", "need", "to", "wire", "this", "with", "xml", "config", "next", "."], "add_tokens": "* This class is a component of FilterConfig and holds settings for individual filters // Allow user to show or hide filter public boolean isShowHideToggleEnabled = false ; // Set default state of show hide toggle public boolean defaultShowHideToggleStateIsVisible = true ; this . isShowHideToggleEnabled = builder . isShowHideToggleEnabled ; this . defaultShowHideToggleStateIsVisible = builder . defaultShowHideToggleStateIsVisible ; public FilterSettingsBuilder setIsShowHideToggleEnabled ( boolean isShowHideToggleEnabled ) { this . isShowHideToggleEnabled = isShowHideToggleEnabled ; return this ; } public FilterSettingsBuilder setDefaultShowHideToggleStateIsVisible ( boolean defaultShowHideToggleStateIsVisible ) { this . defaultShowHideToggleStateIsVisible = defaultShowHideToggleStateIsVisible ; return this ; } public boolean isShowHideToggleEnabled = false ; public boolean defaultShowHideToggleStateIsVisible = true ;", "del_tokens": "* Created by suay on 15 / 04 / 14.", "commit_type": "add"}
{"commit_tokens": ["change", "shutdown", "order", "of", "listener", "groups"], "add_tokens": "Future < ? > f = bossGroup . shutdownGracefully ( ) ; Future f = workerGroup . shutdownGracefully ( ) ;", "del_tokens": "Future < ? > f = workerGroup . shutdownGracefully ( ) ; Future f = bossGroup . shutdownGracefully ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "test", "case", "for", "wrapper", "chain", ".", "Refactored", "chain", "to", "become", "inner", "class", "of", "the", "class", "visitor", "wrapper", "interface", "."], "add_tokens": "new ClassVisitorWrapper . Chain ( ) ) ; private final ClassVisitorWrapper . Chain classVisitorWrapperChain ; ClassVisitorWrapper . Chain classVisitorWrapperChain ) { public ClassVisitorWrapper . Chain getClassVisitorWrapperChain ( ) {", "del_tokens": "import com . blogspot . mydailyjava . bytebuddy . asm . ClassVisitorWrapperChain ; new ClassVisitorWrapperChain ( ) ) ; private final ClassVisitorWrapperChain classVisitorWrapperChain ; ClassVisitorWrapperChain classVisitorWrapperChain ) { public ClassVisitorWrapperChain getClassVisitorWrapperChain ( ) {", "commit_type": "add"}
{"commit_tokens": ["change", "cookie", "log", "to", "trace"], "add_tokens": "LOG . trace ( \"outgoing {} {} {}\" , c . getName ( ) + \"=\" + c . getValue ( ) , c . getDomain ( ) , c . getPath ( ) ) ; LOG . trace ( \"incoming {} {} {}\" , c . getName ( ) + \"=\" + c . getValue ( ) , c . getDomain ( ) , c . getPath ( ) ) ;", "del_tokens": "LOG . debug ( \"outcoing {} {} {}\" , c . getName ( ) + \"=\" + c . getValue ( ) , c . getDomain ( ) , c . getPath ( ) ) ; LOG . debug ( \"incoming {} {} {}\" , c . getName ( ) + \"=\" + c . getValue ( ) , c . getDomain ( ) , c . getPath ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "same", "Loading", "view", "atts"], "add_tokens": "private static final int ANGLE_ADD = 5 ;", "del_tokens": "private static final int ANGLE_ADD = 4 ;", "commit_type": "add"}
{"commit_tokens": ["Added", "configurable", "index", "class", "and", "name"], "add_tokens": "String idxName = ( String ) resolve ( idx . field ( \"name\" ) ) ; final String idxClass = ( String ) resolve ( idx . field ( \"class\" ) ) ;", "del_tokens": "String idxName = idx . field ( \"name\" ) ; final String idxClass = idx . field ( \"class\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "parameter", "logging", "to", "statement", "logging"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Updated", "TypeInfoRegistry", "to", "handle", "hash", "collisions"], "add_tokens": "import static org . testng . Assert . assertNotEquals ; import org . modelmapper . config . Configuration ; import org . modelmapper . config . Configuration . AccessLevel ; public void shouldHashCorrectly1 ( ) { public void shouldHashCorrectly2 ( ) { Class < ? > type = Byte . class ; Configuration conf1 = new InheritingConfiguration ( ) { @ Override public int hashCode ( ) { return 0 ; } } ; Configuration conf2 = new InheritingConfiguration ( ) { @ Override public int hashCode ( ) { return 0 ; } } ; conf1 . setMethodAccessLevel ( AccessLevel . PRIVATE ) ; conf2 . setMethodAccessLevel ( AccessLevel . PUBLIC ) ; assertNotEquals ( conf1 , conf2 ) ; assertNotEquals ( TypeInfoRegistry . typeInfoFor ( type , conf1 ) , TypeInfoRegistry . typeInfoFor ( type , conf2 ) ) ; }", "del_tokens": "public void shouldHashCorrectly ( ) {", "commit_type": "update"}
{"commit_tokens": ["Removed", "use", "of", "deprecated", "API", "."], "add_tokens": "* Copyright ( C ) 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2019 AO Industries , Inc . import java . util . Objects ; assert Objects . equals ( canonicalize ( row . getKey ( ) ) , canonicalKey ) ;", "del_tokens": "* Copyright ( C ) 2011 , 2012 , 2013 , 2014 , 2015 , 2016 AO Industries , Inc . import com . aoindustries . lang . ObjectUtils ; assert ObjectUtils . equals ( canonicalize ( row . getKey ( ) ) , canonicalKey ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "more", "blank", "lines", "into", "the", "generated", "code", "to", "improve", "readability", "."], "add_tokens": "String counterVariableName = \"jsonFieldCounter\" + mCounterVariableCount ; codeBlock . addStatement ( \"in.beginObject()\" ) ; codeBlock . add ( \"\\n\" ) ; codeBlock . add ( \"\\n\" ) ; // Add a new line to improve readability for the multi-lined mapping. codeBlock . add ( \"\\n\" ) ; codeBlock . add ( \"\\n\" ) ; codeBlock . add ( \"\\n\" ) ;", "del_tokens": "String counterVariableName = \"counter\" + mCounterVariableCount ; codeBlock . addStatement ( \"in.beginObject()\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "some", "interface", "for", "tangram3"], "add_tokens": "super . setCells ( Collections . < BaseCell > singletonList ( cell ) ) ;", "del_tokens": "super . setCells ( Collections . < BaseCell > singletonList ( cell ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "still", "trigger", "onBatchScanResults", "after", "stopScan"], "add_tokens": "new Handler ( Looper . getMainLooper ( ) ) . post ( new Runnable ( ) { @ Override public void run ( ) { mHandler . removeCallbacks ( mFlushPendingScanResultsTask ) ; } } ) ; new Handler ( Looper . getMainLooper ( ) ) . post ( new Runnable ( ) { @ Override public void run ( ) { mHandler . removeCallbacks ( mMatchLostNotifierTask ) ; } } ) ;", "del_tokens": "mHandler . removeCallbacks ( mFlushPendingScanResultsTask ) ; mHandler . removeCallbacks ( mMatchLostNotifierTask ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "pages", "to", "be", "default", "if", "a", "type", "other", "then", "post", "is", "defined", ".", "This"], "add_tokens": "if ( fileContents . get ( \"type\" ) . equals ( \"post\" ) ) { } else { // everything else is considered a page pages . add ( fileContents ) ;", "del_tokens": "if ( fileContents . get ( \"type\" ) . equals ( \"page\" ) ) { pages . add ( fileContents ) ; } else { // everything else is considered a post", "commit_type": "make"}
{"commit_tokens": ["added", "HTML", "reporter", "section", "to", "README", "removed", "some", "printlns", "in", "test", "code"], "add_tokens": "// System.out.println( stream.toString( Charsets.UTF_8.name() ) );", "del_tokens": "import com . google . common . base . Charsets ; System . out . println ( stream . toString ( Charsets . UTF_8 . name ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "reference", "from", "the", "StateDocument", "to", "Owner", "be", "a", "DBRef"], "add_tokens": "import org . springframework . data . mongodb . core . mapping . DBRef ; @ DBRef ( lazy = true ) Object owner ; public Object getOwner ( ) { return owner ; public void setOwner ( Object owner ) { this . owner = owner ; if ( stateDoc != null && stateDoc . getOwner ( ) == null ) { stateDoc . setOwner ( obj ) ;", "del_tokens": "Object ownerId ; public Object getOwnerId ( ) { return ownerId ; public void setOwnerId ( Object ownerId ) { this . ownerId = ownerId ; if ( stateDoc != null && stateDoc . getOwnerId ( ) == null ) { stateDoc . setOwnerId ( id ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "Font", "Awesome", "support", "in", "navLink", "via", "iconAwesome", "attribute", "."], "add_tokens": "String faicon = A . asString ( attrs . get ( A . ICONAWESOME ) ) ; boolean fa = false ; //flag to indicate wether the selected icon set is Font Awesome or not. if ( faicon != null ) { icon = faicon ; fa = true ; } if ( icon != null ) { R . encodeIcon ( rw , this , icon , fa ) ; R . encodeIcon ( rw , this , icon , fa ) ;", "del_tokens": "if ( icon != null ) { R . encodeIcon ( rw , this , icon , false ) ; R . encodeIcon ( rw , this , icon , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "overloaded", "method", "to", "startserver", "and", "also", "altered", "default", "port"], "add_tokens": "int portNumber = 18090 ; public abstract void startServer ( ) ;", "del_tokens": "int portNumber = 8090 ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "kay", "string", "handling", "and", "tests"], "add_tokens": "final String privKeyPEM = keyString . replace ( \"-----BEGIN PRIVATE KEY-----\" , \"\" ) . replace ( \"-----END PRIVATE KEY-----\" , \"\" ) . replaceAll ( \"\\\\v\" , \"\" ) ; final String publicKeyPEM = keyString . replace ( \"-----BEGIN PUBLIC KEY-----\" , \"\" ) . replace ( \"-----END PUBLIC KEY-----\" , \"\" ) . replaceAll ( \"\\\\v\" , \"\" ) ;", "del_tokens": "final String privKeyPEM = keyString . replace ( \"-----BEGIN PRIVATE KEY-----\\n\" , \"\" ) . replace ( \"-----END PRIVATE KEY-----\" , \"\" ) . replaceAll ( \"\\n\" , \"\" ) ; final String publicKeyPEM = keyString . replace ( \"-----BEGIN PUBLIC KEY-----\\n\" , \"\" ) . replace ( \"-----END PUBLIC KEY-----\" , \"\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "non", "-", "shared", "instances", "to", "ResourceBundleMappingStrategy", "and", "ClassNameMappingStrategy", "(", "AJ", "-", "29", ")"], "add_tokens": "", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "file", "path", "issue", "on", "non", "Windows", "env"], "add_tokens": "public final class KoanRunner extends BlockJUnit4ClassRunner {", "del_tokens": "public class KoanRunner extends BlockJUnit4ClassRunner {", "commit_type": "fix"}
{"commit_tokens": ["moved", "jclouds", "repo", "out", "of", "trunk"], "add_tokens": "System . out . printf ( \"accessKey: %1$s, connectionClass: %2$s, bucketClass: %3$s, bucket: %4$s%n\" , accessKey ,", "del_tokens": "System . err . printf ( \"accessKey: %1s, connectionClass: %2s, bucketClass: %3s, bucket: %4s%n\" , accessKey ,", "commit_type": "move"}
{"commit_tokens": ["Removed", "dependency", "on", "Apache", "HttpClient", "."], "add_tokens": "response . setStatus ( HttpServletResponse . SC_NOT_FOUND ) ; response . setStatus ( HttpServletResponse . SC_INTERNAL_SERVER_ERROR ) ;", "del_tokens": "import org . apache . http . HttpStatus ; response . setStatus ( HttpStatus . SC_NOT_FOUND ) ; response . setStatus ( HttpStatus . SC_INTERNAL_SERVER_ERROR ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "logging", "of", "metrics", "a", "bit", "more", "concise", "and", "get", "rid", "of", "some", "extra", "precision"], "add_tokens": "printMessage ( buf ) ; return buf . toString ( ) ; } return \"metricsDisabled\" ; } public void printMessage ( StringBuilder buf ) { if ( enabled ) { buf . append ( \"(\" ) ; } else { buf . append ( \"metricsDisabled\" ) ; buf . append ( nanosStr . substring ( nanosStr . length ( ) - 6 , nanosStr . length ( ) - 3 ) ) ; buf . append ( \"0.0000000\" . substring ( 0 , 8 - Math . max ( nanosStr . length ( ) , 4 ) ) ) ; if ( nanosStr . length ( ) > 3 ) { buf . append ( nanosStr . substring ( 0 , nanosStr . length ( ) - 3 ) ) ; }", "del_tokens": "buf . append ( \" (\" ) ; return buf . toString ( ) ; return \"disabled\" ; buf . append ( nanosStr . substring ( nanosStr . length ( ) - 6 ) ) ; buf . append ( \"0.0000000\" . substring ( 0 , 8 - nanosStr . length ( ) ) ) ; buf . append ( nanosStr ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "one", "more", "use", "case", "test"], "add_tokens": "normalPrinter . writeBufferTo ( new BufferedWriter ( new OutputStreamWriter ( normal , globalOutCharacterEncoding ) ) ) ; postfixPrinter . writeBufferTo ( new BufferedWriter ( new OutputStreamWriter ( postfix , globalOutCharacterEncoding ) ) ) ;", "del_tokens": "normalPrinter . writeBufferTo ( new BufferedWriter ( new OutputStreamWriter ( prefix , globalOutCharacterEncoding ) ) ) ; postfixPrinter . writeBufferTo ( new BufferedWriter ( new OutputStreamWriter ( prefix , globalOutCharacterEncoding ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "!", ":", "optional", "special", "flag", "for", "flagging", "more", "specific"], "add_tokens": "new FileType ( \"/files/3.xml\" , ContentType . XML , \"xml\" , \"application/xml\" , \"XML document text\" ) , testFile ( util , new FileType ( \"/files/3.xml\" , ContentType . XML , \"xml\" , \"application/xml\" , \"XML document text\" ) ) ; contentInfoUtil = new ContentInfoUtil ( ) ;", "del_tokens": "testFile ( util , new FileType ( \"/files/3.xml\" , ContentType . XML , \"xml\" , \"application/xml\" , \"XML 2 document text\" ) ) ; try { contentInfoUtil = new ContentInfoUtil ( \"/magic2\" , null ) ; } catch ( IOException e ) { // TODO Auto-generated catch block e . printStackTrace ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "RFC", "5425"], "add_tokens": "RFC_5424 , / * * * < a href = \"https://tools.ietf.org/html/rfc5425\" > RFC 5425 - Transport Layer Security ( TLS ) Transport Mapping for Syslog < / a > * / RFC_5425", "del_tokens": "RFC_5424", "commit_type": "add"}
{"commit_tokens": ["Remove", "unnecessary", "update", "logging", "flag", "from", "ExecutionSite", "."], "add_tokens": "ee . setLogLevels ( org . voltdb . jni . EELoggers . getLogLevels ( ) ) ;", "del_tokens": "/ * * * When the system procedure @ UpdateLogging runs and updates the log levels for loggers it will * call updateBackendLogLevels to indicate that the log levels have changed . * / private volatile boolean m_haveToUpdateLogLevels = false ; m_haveToUpdateLogLevels = true ; // push log level changes to the ee. if ( ee != null && m_haveToUpdateLogLevels ) { m_haveToUpdateLogLevels = false ; ee . setLogLevels ( org . voltdb . jni . EELoggers . getLogLevels ( ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "a", "run", "-", "away", "loop", "."], "add_tokens": "done = true ; try {", "del_tokens": "try {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "FormInputValueHelper", ".", "Remember", ":", "switch", "cases", "always", "fall", "through", "unless", "you", "break", "somewhere", "."], "add_tokens": "System . err . println ( input . getIdentification ( ) . getHow ( ) ) ; break ; break ; break ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["adding", "test", "with", "real", "link"], "add_tokens": "SchemaLink link = new SchemaLink ( ) ; link . setMap ( Maps . asMap ( Sets . newHashSet ( OngoingResponseImpl . METHOD_PARAM_KEY ) , k -> \"put\" ) ) ; String uri = \"http://www.mercateo.com/\" ; link . setHref ( uri ) ; when ( jsonHyperSchema . getByRel ( any ( ) ) ) . thenReturn ( Optional . of ( link ) ) ;", "del_tokens": "SchemaLink mockLink = mock ( SchemaLink . class ) ; when ( mockLink . getMap ( ) ) . thenReturn ( Maps . asMap ( Sets . newHashSet ( OngoingResponseImpl . METHOD_PARAM_KEY ) , k -> \"put\" ) ) ; UriTemplate uri = new UriTemplate ( \"http://www.mercateo.com/\" ) ; when ( mockLink . getHref ( ) ) . thenReturn ( uri ) ; when ( jsonHyperSchema . getByRel ( any ( ) ) ) . thenReturn ( Optional . of ( mockLink ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "NullPointerException", "when", "traversing", "certain", "directories", "when", "running", "on", "Windows"], "add_tokens": "import java . util . Collections ; logger . debug ( \"Listing local files from {}\" , dir ) ; Collection < FileAbstractModel > result ; if ( files != null ) { result = new ArrayList < > ( files . length ) ; // Iterate other files for ( File file : files ) { result . add ( toFileAbstractModel ( dir , file ) ) ; } } else { logger . debug ( \"Symlink on windows gives null for listFiles(). Skipping [{}]\" , dir ) ; result = Collections . EMPTY_LIST ; logger . debug ( \"{} local files found\" , result . size ( ) ) ;", "del_tokens": "if ( logger . isDebugEnabled ( ) ) logger . debug ( \"Listing local files from {}\" , dir ) ; Collection < FileAbstractModel > result = new ArrayList < > ( files . length ) ; // Iterate other files for ( File file : files ) { result . add ( toFileAbstractModel ( dir , file ) ) ; if ( logger . isDebugEnabled ( ) ) logger . debug ( \"{} local files found\" , result . size ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "handling", "of", "absolute", "URLS", "on", "windows", "without", "starting", "slash", "like"], "add_tokens": "op . addLeftOperand ( new ValueExpression ( reader , relativeURL . toString ( ) ) ) ;", "del_tokens": "op . addLeftOperand ( new ValueExpression ( reader , relativeURL . getPath ( ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "cast", "to", "Statement", "to", "match", "updated", "signature", "."], "add_tokens": "Collection < Statement > lks = new LinkedList < Statement > ( ) ; else if ( o instanceof Statement ) { lks . add ( ( Statement ) o ) ; }", "del_tokens": "Collection < Object > lks = new LinkedList < Object > ( ) ; else lks . add ( o ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "specific", "exception", "for", "request", "timeout", "."], "add_tokens": "throw new RequestTimeoutException ( this . name + \" timedout waiting for response to \" + curReq ) ;", "del_tokens": "throw new TransportException ( this . name + \" timedout waiting for response to \" + curReq ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "retweeting", ";", "an", "empty", "map", "doesn", "t", "work", "...", "must", "send", "an", "empty", "body", "."], "add_tokens": "ResponseEntity < Map > response = restOperations . postForEntity ( RETWEET_URL , \"\" , Map . class , static final String RETWEET_URL = \"http://api.twitter.com/1/statuses/retweet/{tweet_id}.json\" ;", "del_tokens": "ResponseEntity < Map > response = restOperations . postForEntity ( RETWEET_URL , Collections . emptyMap ( ) , Map . class , static final String RETWEET_URL = \"https://api.twitter.com/1/statuses/retweet/{tweet_id}.json\" ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "DELETE", "/", "api", "/", "queues", "/", "{", "vhost", "}", "/", "{", "name", "}", "/", "contents"], "add_tokens": "public void purgeQueue ( String vhost , String name ) { this . deleteIgnoring404 ( uriWithPath ( \"./queues/\" + encodePathSegment ( vhost ) + \"/\" + encodePathSegment ( name ) + \"/contents/\" ) ) ; }", "del_tokens": "", "commit_type": "implement"}
{"commit_tokens": ["Added", "put", "()", "methods", "."], "add_tokens": "/ * * * Perform an HTTP PUT call with the specified form data and path objects , returning * a ClientResponse instance with the data returned from the endpoint . * * @ param queryParams * @ param pathArgs * @ return a ClientResponse instance with the data returned from the endpoint * @ throws UniformInterfaceException * @ throws ClientHandlerException * @ throws IOException * / protected ClientResponse put ( MultivaluedMap < String , String > queryParams , Object ... pathArgs ) throws UniformInterfaceException , ClientHandlerException , IOException { return ( getApiClient ( ) . put ( queryParams , pathArgs ) ) ; } / * * * Perform an HTTP PUT call with the specified form data and URL , returning * a ClientResponse instance with the data returned from the endpoint . * * @ param queryParams * @ param url * @ return a ClientResponse instance with the data returned from the endpoint * @ throws UniformInterfaceException * @ throws ClientHandlerException * / protected ClientResponse put ( MultivaluedMap < String , String > queryParams , URL url ) throws UniformInterfaceException , ClientHandlerException { return ( getApiClient ( ) . put ( queryParams , url ) ) ; } throws UniformInterfaceException , ClientHandlerException {", "del_tokens": "throws UniformInterfaceException , ClientHandlerException {", "commit_type": "add"}
{"commit_tokens": ["fix", "NullPointerException", "when", "using", "undefined", "shapes"], "add_tokens": "catch ( Exception e ) { e . printStackTrace ( ) ; } if ( shape != null ) shape . setText ( textBody ) ;", "del_tokens": "shape . setText ( textBody ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "auto", "-", "generated", "list", "/", "stack", "for", "ints"], "add_tokens": "* Array list of int primitives .", "del_tokens": "* Array list for int primitives .", "commit_type": "use"}
{"commit_tokens": ["Moved", "timestamp", "logic", "from", "the", "constructor", "to", "own", "method", "(", "which", "also", "ensures", "that", "pom", "file", "is", "valid", ")", ".", "Keeptimestamp", "will", "no", "longer", "affect", "backup", "file", "."], "add_tokens": "import static org . hamcrest . Matchers . greaterThan ; assertThat ( testpom . lastModified ( ) , is ( pomTimestamp ) ) ; // The backup file should not be modified assertThat ( backupFile . lastModified ( ) , greaterThan ( pomTimestamp ) ) ; } else { assertThat ( testpom . lastModified ( ) , greaterThan ( pomTimestamp ) ) ; assertThat ( backupFile . lastModified ( ) , greaterThan ( pomTimestamp ) ) ; assertTrue ( testpom . delete ( ) ) ; assertTrue ( backupFile . delete ( ) ) ;", "del_tokens": "assertTrue ( testpom . lastModified ( ) == pomTimestamp ) ; assertTrue ( backupFile . lastModified ( ) == pomTimestamp ) ; } else { assertTrue ( testpom . lastModified ( ) > pomTimestamp ) ; assertTrue ( backupFile . lastModified ( ) > pomTimestamp ) ; testpom . delete ( ) ; backupFile . delete ( ) ;", "commit_type": "move"}
{"commit_tokens": ["fixing", "support", "for", "unknown", "structured", "fields"], "add_tokens": "byte [ ] data = new byte [ stop - pos + 1 + 2 ] ; System . arraycopy ( buffer , pos , data , 0 , stop - pos + 1 + 2 ) ; if ( sf instanceof UNKNSF ) { System . arraycopy ( sf . getRawData ( ) , 0 , buffer , start , sf . getRawData ( ) . length ) ; length = sf . getRawData ( ) . length - 2 ; return length ; } default : throw new IllegalArgumentException ( \"unknown sf: \" + sf ) ;", "del_tokens": "byte [ ] data = new byte [ stop - pos + 1 ] ; System . arraycopy ( buffer , pos , data , 0 , stop - pos + 1 ) ; default : { System . arraycopy ( buffer , start , sf . getRawData ( ) , 0 , sf . getRawData ( ) . length ) ; length = sf . getRawData ( ) . length ; return length ; }", "commit_type": "fix"}
{"commit_tokens": ["Adding", "functional", "test", "for", "JarUnsignMojo"], "add_tokens": "* Path of the jar to unsign . When specified , the finalName is ignored . // FIXME we probably want to be more security conservative here. // it's very easy to guess where the directory will be and possible // to access/change its contents before the file is rejared.. try { FileUtils . deleteDirectory ( tempDir ) ; } catch ( IOException ex ) { throw new MojoExecutionException ( \"Error cleaning up temporary directory file: \" + tempDir , ex ) ; }", "del_tokens": "* Path of the jar to sign . When specified , the finalName is ignored .", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "key", "specific", "rules", "."], "add_tokens": "import es . moki . ratelimitj . core . limiter . request . * ; private final RequestLimitRulesSupplier < String > requestLimitRulesSupplier ; requestLimitRulesSupplier = new SerializedRequestLimitRulesSupplier ( rules ) ; String rulesJson = requestLimitRulesSupplier . getRules ( key ) ;", "del_tokens": "import es . moki . ratelimitj . core . limiter . request . AsyncRequestRateLimiter ; import es . moki . ratelimitj . core . limiter . request . ReactiveRequestRateLimiter ; import es . moki . ratelimitj . core . limiter . request . RequestLimitRule ; import es . moki . ratelimitj . core . limiter . request . RequestRateLimiter ; private final LimitRuleJsonSerialiser serialiser = new LimitRuleJsonSerialiser ( ) ; private final String rulesJson ; rulesJson = serialiserLimitRules ( rules ) ; private String serialiserLimitRules ( Set < RequestLimitRule > rules ) { return serialiser . encode ( rules ) ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "Environment", "to", "ProeprtySourceLocator", ".", "locate", "()"], "add_tokens": "import org . springframework . core . env . Environment ; PropertySource < ? > locate ( Environment environment ) ;", "del_tokens": "PropertySource < ? > locate ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "list", "bucket", "max", "-", "keys", "error", "handling"], "add_tokens": "int maxKeys = 1000 ; String maxKeysString = request . getParameter ( \"max-keys\" ) ; if ( maxKeysString != null ) { try { maxKeys = Integer . valueOf ( maxKeysString ) ; } catch ( NumberFormatException nfe ) { sendSimpleErrorResponse ( response , HttpServletResponse . SC_BAD_REQUEST , \"InvalidArgument\" , \"Bad Request\" , Optional . < String > absent ( ) ) ; return ; } options = options . maxResults ( maxKeys ) ; writer . write ( String . valueOf ( maxKeys ) ) ;", "del_tokens": "String maxKeys = request . getParameter ( \"max-keys\" ) ; if ( maxKeys != null ) { options = options . maxResults ( Integer . valueOf ( maxKeys ) ) ; writer . write ( String . valueOf ( set . size ( ) ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Moved", "sample", "site", "so", "it", "can", "be", "used", "in", "tests", "."], "add_tokens": "// File test = new File(\"/content\"); // System.out.println(test.exists()); Assert . assertEquals ( crawler . getPages ( ) . size ( ) , 3 ) ;", "del_tokens": "Assert . assertEquals ( crawler . getPages ( ) . size ( ) , 1 ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "test", "(", "SolrRelationTest", ")", "fixes", "from", "branch", "spark1_5_x"], "add_tokens": "fields1 . add ( DataTypes . createStructField ( \"testtype_s\" , DataTypes . createStructType ( fields2 ) , true ) ) ; createMLModelLRParquet ( ) ; File lRModel = new File ( \"LRParquet\" ) . getAbsoluteFile ( ) ; FileUtils . forceDelete ( lRModel ) ; createMLModelNBParquet ( ) ; File nBModel = new File ( \"NBParquet\" ) . getAbsoluteFile ( ) ; FileUtils . forceDelete ( nBModel ) ; assertTrue ( \"expected count == \" + expected + \" but got \" + actual + \" for \" + expr , expected == actual ) ;", "del_tokens": "fields1 . add ( DataTypes . createStructField ( \"testtype_s\" , DataTypes . createStructType ( fields2 ) , true ) ) ; @ Test @ Test FileUtils . forceDelete ( new File ( \"LRParquet\" ) ) ; FileUtils . forceDelete ( new File ( \"NBParquet\" ) ) ; assertTrue ( \"expected count == \" + expected + \" but got \" + actual + \" for \" + expr , expected == actual ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "to", "conform", "to", "the", "updated", "SceneParser", "interface", "."], "add_tokens": "// $Id: XMLSceneParser.java,v 1.2 2001/07/23 22:47:03 shaper Exp $ public ArrayList loadScenes ( String fname ) throws IOException", "del_tokens": "// $Id: XMLSceneParser.java,v 1.1 2001/07/23 22:45:04 shaper Exp $ import java . io . InputStream ; public ArrayList loadScenes ( InputStream tis ) throws IOException", "commit_type": "fix"}
{"commit_tokens": ["Fix", "javadoc", "warning", "in", "AbstractCassandraHystrixCommand"], "add_tokens": "* @ return the constructed ColumnFamily * @ return a constructed ColumnFamily", "del_tokens": "* @ return * @ return", "commit_type": "fix"}
{"commit_tokens": ["use", "snapshot", "version", "add", "client", "init", "api"], "add_tokens": "* new Client , use two keystores store client cert and trust ca cert / * * * new Client , just use one keystore store all certs * * @ param apiKey * * * apikey * * is set to the API access key applied on ` ChainConsole ` * management page * @ param creator * the enterprise 's wallet did * @ param created * the enterprise 's wallet created * @ param nonce * the enterprise 's wallet nonce * @ param privateKey * the enterprise 's wallet private key base64 * @ param address * * * Address * * is the IP address of the BAAS server entrance . * @ param keyStorePath * keystore of client cert * @ param keyStorePasswd * password of client keystore * / public Client ( String apiKey , String creator , String created , String nonce , String privateKey , String address , String keyStorePath , String keyStorePasswd ) { this . initClient ( apiKey , \"\" , creator , created , nonce , privateKey , address , false , \"wallet-ng\" , keyStorePath , keyStorePasswd , keyStorePath , keyStorePasswd ) ; }", "del_tokens": "* new Client", "commit_type": "use"}
{"commit_tokens": ["Add", "metric", "type", "info", "to", "ES", "index"], "add_tokens": "TYPE , Discovery md = new Discovery ( locator . getTenantId ( ) , locator . getMetricName ( ) ) ; Map < String , Object > info = new HashMap < String , Object > ( ) ; if ( metric . getUnit ( ) != null ) { // metric units may be null info . put ( UNIT . toString ( ) , metric . getUnit ( ) ) ; } info . put ( TYPE . toString ( ) , metric . getType ( ) ) ; md . withAnnotation ( info ) ;", "del_tokens": "private static Map < String , Object > extractUsefulInformation ( Metric metric ) { Map < String , Object > info = new HashMap < String , Object > ( ) ; if ( metric . getUnit ( ) != null ) { // metric units may be null info . put ( UNIT . toString ( ) , metric . getUnit ( ) ) ; } return info ; } Discovery md = new Discovery ( locator . getTenantId ( ) , locator . getMetricName ( ) ) . withAnnotation ( extractUsefulInformation ( metric ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "LIFO", "stucture", "to", "handle", "clear_requests"], "add_tokens": "if ( messageJson . has ( \"data\" ) ) { if ( messageJson . getJSONObject ( \"data\" ) . keys ( ) . hasNext ( ) ) { getConfigLogger ( ) . verbose ( getAccountId ( ) , \"Received message from dashboard:\\n\" + message ) ; } }", "del_tokens": "getConfigLogger ( ) . verbose ( getAccountId ( ) , \"Received message from dashboard:\\n\" + message ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "other", "constructor", "instead", "so", "we", "don", "t", "forget", "blinking"], "add_tokens": "targetScreen . putString ( x , y , string , foregroundColor , backgroundColor , drawStyle ) ;", "del_tokens": "targetScreen . putString ( x , y , string , foregroundColor , backgroundColor , drawStyle . contains ( ScreenCharacterStyle . Bold ) , drawStyle . contains ( ScreenCharacterStyle . Underline ) , drawStyle . contains ( ScreenCharacterStyle . Reverse ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "generic", "Scribe", "API", "class", "for", "signing", "requests", "."], "add_tokens": "this . service = new ServiceBuilder ( ) . provider ( PreAuthorizedOAuthApi . class ) . apiKey ( apiKey ) . apiSecret ( apiSecret )", "del_tokens": "import org . scribe . builder . api . LinkedInApi ; this . service = new ServiceBuilder ( ) . provider ( LinkedInApi . class ) . apiKey ( apiKey ) . apiSecret ( apiSecret )", "commit_type": "add"}
{"commit_tokens": ["Improve", "FetchRequestQueue", "comes", "from", "java7", "DelayQueue"], "add_tokens": "+ \" \" ) ; final ConcurrentTestCase testCase = new ConcurrentTestCase ( 500 , 10000 , new ConcurrentTestTask ( ) { assertEquals ( 5000000 , counter . get ( ) ) ;", "del_tokens": "+ \" \" ) ; final ConcurrentTestCase testCase = new ConcurrentTestCase ( 500 , 1000 , new ConcurrentTestTask ( ) { assertEquals ( 500000 , counter . get ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Updated", "to", "peppol", "-", "smp", "-", "client", "SNAPSHOT"], "add_tokens": "// Set Proxy Settings from property file. CSMPClient . getConfigFile ( ) . applyAllNetworkSystemProperties ( ) ;", "del_tokens": "// Set Proxy Settings from property file. See: // http://download.oracle.com/javase/6/docs/technotes/guides/net/proxies.html for ( final String sProperty : new String [ ] { \"javax.net.debug\" , \"java.net.useSystemProxies\" , \"http.proxyHost\" , \"http.proxyPort\" , \"http.nonProxyHosts\" , \"https.proxyHost\" , \"https.proxyPort\" } ) { final String sConfigValue = CSMPClient . getConfigFile ( ) . getString ( sProperty ) ; if ( sConfigValue != null ) { System . setProperty ( sProperty , sConfigValue ) ; s_aLogger . info ( \"Set proxy property: \" + sProperty + \"=\" + sConfigValue ) ; } }", "commit_type": "update"}
{"commit_tokens": ["making", "method", "final", "to", "prevent", "overriding"], "add_tokens": "public final T build ( ) throws IllegalArgumentException {", "del_tokens": "public T build ( ) throws IllegalArgumentException {", "commit_type": "make"}
{"commit_tokens": ["fixed", "LogLevel", "map", "not", "filling", "up"], "add_tokens": "import com . sun . org . apache . xpath . internal . operations . Mod ; import static java . lang . reflect . Modifier . isPublic ; import static java . lang . reflect . Modifier . isStatic ; if ( isStatic ( field . getModifiers ( ) ) && isPublic ( field . getModifiers ( ) ) && LogLevel . class . isAssignableFrom ( field . getType ( ) ) )", "del_tokens": "if ( Modifier . isStatic ( field . getModifiers ( ) ) && field . isAccessible ( ) && LogLevel . class . isAssignableFrom ( field . getType ( ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "c", "and", "h", "extensions", "to", "open", "in", "NetBeans", "."], "add_tokens": "\"c\" . equals ( extension ) || \"h\" . equals ( extension ) || \"java\" . equals ( extension )", "del_tokens": "\"java\" . equals ( extension )", "commit_type": "add"}
{"commit_tokens": ["Updated", "log", "statement", "in", "duplicateContent", "to", "use", "key", "=", "value", "pairs", "for", "data", "and", "added", "file", "size", "to", "the", "log", "statement", ".", "Added", "comment", "to", "method", "cleanProperties", "."], "add_tokens": "/ * * * Pull out the system - generated properties , to allow the properties that * are added to the duplicated item to be only the user - defined properties . * @ param props * / log . info ( \"Successfully duplicated id={} dup_size={} space={} account={}\" , contentId , localFile . length ( ) , spaceId , dupTask . getAccount ( ) ) ;", "del_tokens": "log . info ( \"Successfully duplicated \" + contentId + \" in space \" + spaceId + \" in account \" + dupTask . getAccount ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "close", "()", "method", "for", "freeing", "memory"], "add_tokens": "dict = JHyphen . hnj_hyphen_load ( dictPath ) ; / * * * Free memory * / public void close ( ) { JHyphen . hnj_hyphen_free ( dict ) ; }", "del_tokens": "dict = JHyphen . getDictionary ( dictPath ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "Activity", "isFinishing", "()", "check", "to", "DialogUtils"], "add_tokens": "final Builder builder = new AlertDialog . Builder ( context ) ; if ( ! context . isFinishing ( ) ) { dialog . show ( ) ; }", "del_tokens": "Builder builder = new AlertDialog . Builder ( context ) ; dialog . show ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "one", "remaining", "OWL", "API", "deprecated", "call"], "add_tokens": "import com . google . common . base . Optional ; Optional < String > fragment = iri . getRemainder ( ) ; if ( ! fragment . isPresent ( ) ) { dataOutput . writeUTF ( fragment . get ( ) ) ;", "del_tokens": "String fragment = iri . getFragment ( ) ; if ( fragment == null ) { dataOutput . writeUTF ( fragment ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "ClientChannelManager", ".", "disconnect", "()"], "add_tokens": "return channelManager . disconnect ( ) ;", "del_tokens": "CompletableFuture < Void > future = new CompletableFuture < > ( ) ; if ( channelManager . isConnected ( ) ) { channelManager . getChannel ( ) . thenAccept ( ch -> ch . close ( ) . addListener ( cf -> future . complete ( null ) ) ) ; } else { future . complete ( null ) ; } return future ;", "commit_type": "implement"}
{"commit_tokens": ["Fixed", "bad", "html", "in", "the", "javadoc"], "add_tokens": "* < br > * < br >", "del_tokens": "* < br / > * < br \\ >", "commit_type": "fix"}
{"commit_tokens": ["Make", "OAuth2RestTemplate", "a", "LoadBalancer", "client", "if", "one", "is", "available"], "add_tokens": "services . setClientId ( resource . getClientId ( ) ) ; services . setClientSecret ( resource . getClientSecret ( ) ) ;", "del_tokens": "import org . springframework . security . oauth2 . client . token . grant . code . AuthorizationCodeResourceDetails ; @ Autowired private AuthorizationCodeResourceDetails client ; services . setClientId ( client . getClientId ( ) ) ; services . setClientSecret ( client . getClientSecret ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["improve", "error", "message", "when", "instance", "location", "causes", "an", "exception", "(", "e", ".", "g", ".", "from", "your", "constructor", "or", "custom", "factory", ")"], "add_tokens": "import static com . google . inject . util . ReferenceType . SOFT ; import static com . google . inject . util . ReferenceType . WEAK ; import java . io . IOException ; import java . lang . reflect . Constructor ; String memberName = member instanceof Constructor ? \"<init>\" : member . getName ( ) ; declaringClass . getName ( ) , memberName , lineNumbers . getSource ( ) ,", "del_tokens": "import java . lang . reflect . Method ; import java . io . IOException ; import static com . google . inject . util . ReferenceType . * ; declaringClass . getName ( ) , member . getName ( ) , lineNumbers . getSource ( ) ,", "commit_type": "improve"}
{"commit_tokens": ["Created", "an", "API", "that", "abstracts", "away", "Java", "s", "two", "database", "access", "APIs", "."], "add_tokens": "/ * * * Provides an interface for getting a connection to a relational database . * * @ author Andrew Post * / / * * * Returns a connection to a SQL database that may be new or part of a * connection pool . * * @ return a { @ link Connection } . * @ throws SQLException if an error occurs getting the connection . * /", "del_tokens": "import java . sql . Driver ; Driver getDriver ( ) throws SQLException ;", "commit_type": "create"}
{"commit_tokens": ["Remove", "deprecated", "exceptions", "and", "optimize", "handling", "."], "add_tokens": "public class NotAvailableException extends InvalidStateException {", "del_tokens": "public class NotAvailableException extends CouldNotPerformException {", "commit_type": "remove"}
{"commit_tokens": ["fixed", "bug", "within", "Config", "class"], "add_tokens": "return new HttpSender ( props , host , port , apiKey ) ;", "del_tokens": "return new HttpSender ( host , port , apiKey ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "answer", "gold", "standard", "decorator", "."], "add_tokens": "package edu . cmu . lti . oaqa . baseqa . framework . eval . gs ;", "del_tokens": "package edu . cmu . lti . oaqa . baseqa . framework . eval ; import edu . cmu . lti . oaqa . baseqa . framework . eval . gs . GoldStandardPersistenceProvider ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "extra", "attributes", "to", "the", "ContentSpec", "and", "CSNode", "entities", "."], "add_tokens": "import java . io . Serializable ;", "del_tokens": "import java . io . Serializable ; import javax . persistence . Enumerated ; @ Enumerated", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "the", "feedback", "client", "(", "and", "fixed", "a", "couple", "dumb", "mistakes", "in", "the", "process", ")", "."], "add_tokens": "private final FeedbackServiceClient feedbackClient ; this . feedbackClient = new FeedbackServiceClient ( this . getEnvironment ( ) , this . getKeyStore ( ) , this . getKeyStorePassword ( ) ) ; this . feedbackClient . destroy ( ) ; return this . feedbackClient . getExpiredTokens ( ) ;", "del_tokens": "return new FeedbackServiceClient ( this ) . getExpiredTokens ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "where", "conversions", "of", "numbers", "to", "booleans", "in", "calls", "to", "Java", "methods", "were", "producing"], "add_tokens": "// First, we marshall the args.", "del_tokens": "// First, we kill the lawyers. Er, marshall the args.", "commit_type": "fix"}
{"commit_tokens": ["Using", "updated", "semantics", "for", "unlock", "and", "delete", "of", "messages"], "add_tokens": ". put ( \"\" ) ; try { getChannel ( ) . resource ( message . getLockLocation ( ) ) . delete ( ) ; } catch ( UniformInterfaceException e ) { throw processCatch ( new ServiceException ( e ) ) ; } catch ( ClientHandlerException e ) { throw processCatch ( new ServiceException ( e ) ) ; }", "del_tokens": ". delete ( ) ; // TODO Auto-generated method stub", "commit_type": "use"}
{"commit_tokens": ["add", "hidden", "visibility", "support", "to", "the", "cli"], "add_tokens": "import java . util . Collection ; import java . util . List ; import static org . vertexium . util . IterableUtils . toList ; Collection < Metadata . Entry > metadataEntries = prop . getMetadata ( ) . entrySet ( ) ; if ( metadataEntries . size ( ) == 0 ) { writer . println ( \" none\" ) ; } else { for ( Metadata . Entry m : metadataEntries ) { writer . println ( \" \" + m . getKey ( ) + \"[\" + m . getVisibility ( ) + \"]: \" + VertexiumScript . valueToString ( m . getValue ( ) , false ) ) ; } } writer . println ( \" @|bold hidden visibilities:|@\" ) ; List < Visibility > hiddenVisibilities = toList ( prop . getHiddenVisibilities ( ) ) ; if ( hiddenVisibilities . size ( ) == 0 ) { writer . println ( \" none\" ) ; } else { for ( Visibility hiddenVisibility : hiddenVisibilities ) { writer . println ( \" \" + hiddenVisibility . getVisibilityString ( ) ) ; }", "del_tokens": "for ( Metadata . Entry m : prop . getMetadata ( ) . entrySet ( ) ) { writer . println ( \" \" + m . getKey ( ) + \"[\" + m . getVisibility ( ) + \"]: \" + VertexiumScript . valueToString ( m . getValue ( ) , false ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "third", "party", "components", "into", "gwtbootstrap3", "-", "extras", "project"], "add_tokens": "import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . Bootbox ; import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . callback . AlertCallback ; import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . callback . ConfirmCallback ; import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . callback . PromptCallback ; public void handleAlertButton ( final ClickEvent event ) { public void handleAlertCallbackButton ( final ClickEvent event ) { public void handleConfirmButton ( final ClickEvent event ) { public void callback ( final boolean result ) { public void handlePromptButton ( final ClickEvent event ) { public void callback ( final String result ) {", "del_tokens": "import com . svenjacobs . gwtbootstrap3 . bootbox . client . Bootbox ; import com . svenjacobs . gwtbootstrap3 . bootbox . client . callback . AlertCallback ; import com . svenjacobs . gwtbootstrap3 . bootbox . client . callback . ConfirmCallback ; import com . svenjacobs . gwtbootstrap3 . bootbox . client . callback . PromptCallback ; public void handleAlertButton ( ClickEvent event ) { public void handleAlertCallbackButton ( ClickEvent event ) { public void handleConfirmButton ( ClickEvent event ) { public void callback ( boolean result ) { public void handlePromptButton ( ClickEvent event ) { public void callback ( String result ) {", "commit_type": "move"}
{"commit_tokens": ["fixed", "main", "()", ":", "provide", "bindings", "when", "evaluating"], "add_tokens": "import de . odysseus . el . tree . Bindings ; out . println ( tree . getRoot ( ) . getValue ( new Bindings ( null , null ) , new SimpleContext ( ) , null ) ) ;", "del_tokens": "out . println ( tree . getRoot ( ) . getValue ( null , new SimpleContext ( ) , null ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "configured", "buffer", "size", "when", "receiving", "response", "as", "file"], "add_tokens": "output = new BufferedOutputStream ( new FileOutputStream ( file ) , bufferSize ) ;", "del_tokens": "output = new BufferedOutputStream ( new FileOutputStream ( file ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "support", "for", "Class<?", ">", "and", "TypeElement", "instances", "out", "of", "TypeShortener", "and", "into", "QualifiedName", "."], "add_tokens": "return shortener . shorten ( QualifiedName . of ( ( TypeElement ) arg ) ) ; return shortener . shorten ( QualifiedName . of ( ( Class < ? > ) arg ) ) ;", "del_tokens": "return shortener . shorten ( ( TypeElement ) arg ) ; return shortener . shorten ( ( Class < ? > ) arg ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "support", "for", "default", "methods", "in", "automapped", "interfaces"], "add_tokens": "import java . lang . invoke . MethodHandles ; import java . lang . reflect . Constructor ; import java . lang . reflect . Modifier ; import org . davidmoten . rx . jdbc . exceptions . AutomappedClassInaccessibleException ; } else if ( method . isDefault ( ) ) { final Class < ? > declaringClass = method . getDeclaringClass ( ) ; if ( ! Modifier . isPublic ( declaringClass . getModifiers ( ) ) ) { throw new AutomappedClassInaccessibleException ( \"An automapped interface must be public for you to call default methods on that interface\" ) ; } Constructor < MethodHandles . Lookup > constructor = MethodHandles . Lookup . class . getDeclaredConstructor ( Class . class , int . class ) ; constructor . setAccessible ( true ) ; return constructor . newInstance ( declaringClass , MethodHandles . Lookup . PRIVATE ) // . unreflectSpecial ( method , declaringClass ) // . bindTo ( proxy ) // . invokeWithArguments ( args ) ; throw new RuntimeException ( \"unexpected\" ) ;", "del_tokens": "import org . davidmoten . rx . jdbc . exceptions . MethodCallNotSupportedException ; // TODO defer to a default method on the interface for example throw new MethodCallNotSupportedException ( \"extra methods like interface default methods not supported (yet): \" + method ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "AccessFlags", ".", "ACC_SYNTHETIC", "."], "add_tokens": "int supportedFlags = Modifier . PUBLIC | Modifier . FINAL | Modifier . ABSTRACT | AccessFlags . ACC_SYNTHETIC ; | Modifier . STATIC | Modifier . FINAL | Modifier . SYNCHRONIZED | AccessFlags . ACC_SYNTHETIC ;", "del_tokens": "int supportedFlags = Modifier . PUBLIC | Modifier . FINAL | Modifier . ABSTRACT ; | Modifier . STATIC | Modifier . FINAL | Modifier . SYNCHRONIZED ;", "commit_type": "allow"}
{"commit_tokens": ["Remove", "up", "implementation", "from", "code"], "add_tokens": "import android . annotation . TargetApi ; import android . os . Build ; @ TargetApi ( Build . VERSION_CODES . HONEYCOMB )", "del_tokens": "getSupportActionBar ( ) . setDisplayShowHomeEnabled ( true ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "the", "homepage", "and", "reduced", "the", "scope", "of", "some", "variables", "."], "add_tokens": "public static String padding ( final int repeat , final char padChar ) {", "del_tokens": "public static String padding ( int repeat , char padChar ) {", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "of", "object", "serialize", "."], "add_tokens": "* LastModified : May 19 , 2016 * ValueWriter . writeInt ( stream , cr ) ;", "del_tokens": "* LastModified : Apr 17 , 2016 * ValueWriter . write ( stream , cr ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "more", "readable", "API", "names"], "add_tokens": "super . onRequestPermissionsResult ( requestCode , permissions , grantResults ) ; builder . enableThreadInfo ( ) ; builder . disableThreadInfo ( ) ; builder . enableStackTrace ( STACK_TRACE_DEPTHS [ stackTraceDepth . getSelectedItemPosition ( ) ] ) ; builder . disableStackTrace ( ) ; builder . enableBorder ( ) ; builder . disableBorder ( ) ;", "del_tokens": "builder . t ( ) ; builder . nt ( ) ; builder . st ( STACK_TRACE_DEPTHS [ stackTraceDepth . getSelectedItemPosition ( ) ] ) ; builder . nst ( ) ; builder . b ( ) ; builder . nb ( ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "user", "not", "found", "exception", "while", "delete", "user"], "add_tokens": "import org . binwang . bard . basic . marker . ErrorCase ; import org . binwang . bard . basic . marker . HandleErrors ; @ HandleErrors ( { @ ErrorCase ( code = 20000 , logLevel = \"DEBUG\" , exception = UserNotFoundException . class , description = \"user not found\" ) } ) public User deleteUser ( @ PathParam ( \"id\" ) @ Required int id ) throws UserNotFoundException { User user = UserStorage . remove ( id ) ; if ( user == null ) { throw new UserNotFoundException ( id ) ; } return user ; public static class UserNotFoundException extends Exception { public UserNotFoundException ( Integer userId ) { super ( \"user \" + userId . toString ( ) + \" not found.\" ) ; } }", "del_tokens": "public String deleteUser ( @ PathParam ( \"id\" ) @ Required int id ) { UserStorage . remove ( id ) ; return \"ok\" ;", "commit_type": "add"}
{"commit_tokens": ["Removes", "temporary", "8px", "margin", "left", "from", "MaterialCheckBoxCell"], "add_tokens": "sb . append ( SafeHtmlUtils . fromSafeConstant ( \"<span class=\\\"gwt-CheckBox\\\"><input type=\\\"checkbox\\\" class=\\\"filled-in\\\" tabindex=\\\"-1\\\" value=\\\"on\\\" id=\\\"\"", "del_tokens": "sb . append ( SafeHtmlUtils . fromSafeConstant ( \"<span style='margin-left: 8px;' class=\\\"gwt-CheckBox\\\"><input type=\\\"checkbox\\\" class=\\\"filled-in\\\" tabindex=\\\"-1\\\" value=\\\"on\\\" id=\\\"\"", "commit_type": "remove"}
{"commit_tokens": ["Make", "NodeStatus", "final", ".", "Patch", "from", "Ismael", "."], "add_tokens": "private final NodeStatus status ;", "del_tokens": "private NodeStatus status ;", "commit_type": "make"}
{"commit_tokens": ["Added", "margin", "to", "Date", "&", "time", "picker", ".", "JsonMap", "improvement"], "add_tokens": "public Object put ( String key , Object value , MarshallerMode mode ) { / * * * @ see java . util . HashMap # put ( java . lang . Object , java . lang . Object ) * / @ Override public Object put ( String key , Object value ) { return put ( key , value , mode ) ; }", "del_tokens": "/ * * * @ see java . util . HashMap # put ( java . lang . Object , java . lang . Object ) * / @ Override public Object put ( String key , Object value ) {", "commit_type": "add"}
{"commit_tokens": ["Move", "the", "context", ".", "cleanup", "in", "the", "cleanup", "method"], "add_tokens": "// Release all resources, especially uploaded file. context . cleanup ( ) ;", "del_tokens": "context . cleanup ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "minor", "typos", "in", "header", "comments", "."], "add_tokens": "* Created on Oct 20 , 2010", "del_tokens": "* Created on Oct 20 , 2010 Oct 20 , 2010", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "exception", "for", "logs", "which", "are", "way", "too", "long"], "add_tokens": "private static final int LOG_LENGTH_LIMIT = 65536 ; if ( limit == 0 ) { throw new LogTooLongException ( ) ; }", "del_tokens": "import java . util . Arrays ; import sun . rmi . runtime . Log ; private static final int LOG_LENGTH_LIMIT = 65 ; //536; if ( limit == 0 ) { throw new LogTooLongException ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixing", "default", "port", "for", "aggregator", "."], "add_tokens": "private int port = 7007 ;", "del_tokens": "private int port = - 1 ;", "commit_type": "fix"}
{"commit_tokens": ["add", "padding", "test", "to", "bump", "up", "code", "coverage", "just", "a", "wee", "bit", "more"], "add_tokens": "public static String padding ( int repeat , char padChar ) throws IndexOutOfBoundsException {", "del_tokens": "private static String padding ( int repeat , char padChar ) throws IndexOutOfBoundsException {", "commit_type": "add"}
{"commit_tokens": ["fixed", "concurrency", "bug", "added", "concurrentmodification", "to", "offheap", "iteration"], "add_tokens": "protected FSTCoder coder ; public FSTCoder getCoder ( ) { return coder ; } V res = ( V ) coder . toObject ( buffer ) ; return res ;", "del_tokens": "FSTCoder coder ; return ( V ) coder . toObject ( buffer ) ; } public FSTCoder getCoder ( ) { return coder ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "bunch", "of", "deprecations", "IDE", "warnings", "etc", "..."], "add_tokens": "import org . apache . http . ssl . SSLContextBuilder ;", "del_tokens": "import org . apache . http . conn . ssl . SSLContextBuilder ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "error", "checking", "in", "sample", "method"], "add_tokens": "* @ throws IllegalArgumentException if { @ code stepWidth } is zero or negative if ( stepWidth <= 0 ) throw new IllegalArgumentException ( \"stepWidth cannot be zero or negative\" ) ;", "del_tokens": "", "commit_type": "improve"}
{"commit_tokens": ["Make", "Soy", "JS", "compilation", "fail", "if", "a", "referenced", "model", "or", "controller", "is", "not", "present", "in", "the", "compilation", "mode", "."], "add_tokens": "String xid = node . getText ( ) ; String js = \"xid('\" + xid + \"')\" ; jsExprs . add ( new JsExpr ( js , Integer . MAX_VALUE ) ) ;", "del_tokens": "jsExprs . add ( new JsExpr ( \"xid('\" + node . getText ( ) + \"')\" , Integer . MAX_VALUE ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "FloatActionButton", "default", "value", "files"], "add_tokens": "bgColor = getResources ( ) . getColorStateList ( R . color . g_defaulf_float_action_bg ) ;", "del_tokens": "bgColor = getResources ( ) . getColorStateList ( R . color . g_defaulf_background ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "urlcontext", "as", "a", "configurable", "parameter", "for", "json", "rpc", "exporter"], "add_tokens": "final String endpointURL = String . format ( \"%s/%s\" , jp . getUrlContext ( ) , jp . getInstanceName ( ) ) . toString ( ) ; final String endpointURL = String . format ( \"%s/%s\" , jp . getUrlContext ( ) , jp . getInstanceName ( ) ) . toString ( ) ;", "del_tokens": "private static final String SERVLET_NAME = \"/JSONRPC\" ; final String endpointURL = String . format ( \"%s/%s\" , SERVLET_NAME , jp . getInstanceName ( ) ) . toString ( ) ; final String endpointURL = String . format ( \"%s/%s\" , SERVLET_NAME , jp . getInstanceName ( ) ) . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "debug", "logging", "to", "describe", "what", "s", "being", "constructed", "in", "the", "guice", "environment"], "add_tokens": "{ final GuiceRole role = it . next ( ) ; log . debug ( \"Discovered guice role: \" + role ) ; roles . add ( role ) ; } { log . debug ( \"Adding requested guice role: \" + role ) ; } log . debug ( \"Applying overrides: \" + overrideFile . getFile ( ) ) ; log . debug ( \"Constructed GuiceSetup: \" + setupClass ) ; log . debug ( \"Using static GuiceSetup: \" + staticSetup ) ; if ( log . isTraceEnabled ( ) ) log . trace ( \"Creating Injector with modules: \" + modules ) ;", "del_tokens": "roles . add ( it . next ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "XMLGregorianCalendar", "conversion", "and", "separated", "Date", "and", "Calendar", "conversion"], "add_tokens": "new CharacterConverter ( ) , new DateConverter ( ) , new CalendarConverter ( ) } ;", "del_tokens": "new CharacterConverter ( ) , new DateConverter ( ) } ;", "commit_type": "add"}
{"commit_tokens": ["Use", "API", "-", "Common", "exception"], "add_tokens": "/ * * * Constructor , requires API key and a CommonHttpClient * @ param apiKey * @ param httpClient * / * @ throws com . omertron . tvrageapi . TVRageException public Episode getEpisodeInfo ( String showID , String seasonId , String episodeId ) throws TVRageException { * @ throws com . omertron . tvrageapi . TVRageException public EpisodeList getEpisodeList ( String showID ) throws TVRageException { * @ throws com . omertron . tvrageapi . TVRageException public ShowInfo getShowInfo ( int showID ) throws TVRageException { * @ throws com . omertron . tvrageapi . TVRageException public ShowInfo getShowInfo ( String showID ) throws TVRageException { * @ throws com . omertron . tvrageapi . TVRageException public List < ShowInfo > searchShow ( String showName ) throws TVRageException {", "del_tokens": "public Episode getEpisodeInfo ( String showID , String seasonId , String episodeId ) { public EpisodeList getEpisodeList ( String showID ) { public ShowInfo getShowInfo ( int showID ) { public ShowInfo getShowInfo ( String showID ) { public List < ShowInfo > searchShow ( String showName ) {", "commit_type": "use"}
{"commit_tokens": ["Removed", "the", "state", "map", "and", "replaced", "with", "ctx", "attribute"], "add_tokens": "static final AttributeKey < State > STATE_ATTRIBUTE = AttributeKey . newInstance ( \"state\" ) ; ctx . channel ( ) . attr ( STATE_ATTRIBUTE ) . set ( new State ( asyncContext , handler ) ) ; State state = ctx . channel ( ) . attr ( STATE_ATTRIBUTE ) . get ( ) ;", "del_tokens": "private final ConcurrentHashMap < ChannelHandlerContext , State > state = new ConcurrentHashMap < > ( ) ; state . put ( ctx , new State ( asyncContext , handler ) ) ; State state = this . state . get ( ctx ) ;", "commit_type": "remove"}
{"commit_tokens": ["Moved", "mojos", "from", "maven", "-", "aapt", "-", "plugin", "into", "maven", "-", "android", "-", "plugin", ".", "Renamed", "moved", "goals", "to", "aapt", "*", "."], "add_tokens": "* @ goal aaptCompile", "del_tokens": "* @ goal compile", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", "sending", "additional", "HTTP", "headers"], "add_tokens": "import org . apache . http . Header ; import java . util . ArrayList ; import java . util . List ; / * * * Any additional headers to be sent in the HTTP requests * / private List < Header > httpHeaders ; private List < Header > httpHeaders = new ArrayList < > ( ) ; / * * * Any additional headers to be sent in the HTTP requests * * @ param additionalHeader to be sent with every request * * @ return builder instance * / public Builder addHttpHeader ( Header additionalHeader ) { this . httpHeaders . add ( additionalHeader ) ; return this ; } ack , httpHeaders ) ; final boolean useAck , final List < Header > cHttpHeaders ) { httpHeaders = cHttpHeaders ; public List < Header > getHttpHeaders ( ) { return httpHeaders ; }", "del_tokens": "ack ) ; final boolean useAck ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "first", "few", "BigtableWriteException", "to", "suppressed", "list", "when", "rethrowing", "BigtableIO", "failures", "."], "add_tokens": "IOException failure = new IOException ( String . format ( \"At least %d errors occurred writing to Bigtable. Some added to suppressed list.\" , failures . size ( ) ) ) ; failure . addSuppressed ( exc ) ; throw failure ;", "del_tokens": "throw new IOException ( message ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "empty", "array", "list", "was", "always", "being", "returned", "causing"], "add_tokens": "return new ArrayList < V > ( c ) ; return new ArrayList < V > ( c ) ;", "del_tokens": "return new ArrayList < V > ( ) ; return new ArrayList < V > ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "examples", "sequentialy", "publish", "strategy", "changed", "defaults", "and", "updated", "README", ".", "md"], "add_tokens": "* A builder for the PSBroker class . < br > * < br > * By default , it uses the Sequential publish strategy and the * FastSubscribeUnsubscribe subscribe strategy .", "del_tokens": "* A builder for the PSBroker class .", "commit_type": "add"}
{"commit_tokens": ["added", "autobahn", "proved", "fragmentation", "support"], "add_tokens": "private Framedata fragmentedframe = null ; if ( ! FIN ) { if ( optcode == Opcode . PING || optcode == Opcode . PONG || optcode == Opcode . CLOSING ) { throw new InvalidFrameException ( \"control frames may no be fragmented\" ) ; } }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "method", "chaining", "to", "MySqlDataSourceConfig"], "add_tokens": "public MySqlDataSourceConfig setHost ( String host ) return this ; public MySqlDataSourceConfig setPort ( int port ) return this ; public MySqlDataSourceConfig setDatabaseName ( String databaseName ) return this ; public MySqlDataSourceConfig setUsername ( String username ) return this ; public MySqlDataSourceConfig setPassword ( String password ) return this ; public MySqlDataSourceConfig setMaxConnections ( int maxConnections ) return this ; public MySqlDataSourceConfig setMaxConnectionWait ( Duration maxConnectionWait ) return this ; public MySqlDataSourceConfig setDefaultFetchSize ( int defaultFetchSize ) return this ; public MySqlDataSourceConfig setUseSsl ( boolean useSsl ) return this ;", "del_tokens": "public void setHost ( String host ) public void setPort ( int port ) public void setDatabaseName ( String databaseName ) public void setUsername ( String username ) public void setPassword ( String password ) public void setMaxConnections ( int maxConnections ) public void setMaxConnectionWait ( Duration maxConnectionWait ) public void setDefaultFetchSize ( int defaultFetchSize ) public void setUseSsl ( boolean useSsl )", "commit_type": "add"}
{"commit_tokens": ["Using", "the", "launching", "with", "Quartz", "caused", "an", "InterruptedException", "in", "the", "EventConsumer", "thread", "."], "add_tokens": "/ * * / //EventManagement eventManagement = EventManagement.getInstance(); //eventManagement.dispatch(event); for ( EventListener listener : KReflection . Holder . INSTANCE . listeners ) { try { listener . handleEvent ( event ) ; } catch ( Exception e ) { // ignore // TODO add message kind } }", "del_tokens": "EventManagement eventManagement = EventManagement . getInstance ( ) ; eventManagement . dispatch ( event ) ;", "commit_type": "use"}
{"commit_tokens": ["add", "support", "for", "upload", "-", "compression"], "add_tokens": "import java . util . zip . GZIPOutputStream ; public static final String HDR_CONTENT_ENCODING = Const . HDR_CONTENT_ENCODING ; WebbUtils . setContentTypeAndLengthForStreaming ( connection , request , request . compress ) ; connection . setDoOutput ( true ) ; streamBody ( connection , request . payload , request . compress ) ; byte [ ] requestBody = WebbUtils . getPayloadAsBytesAndSetContentType ( connection , request , request . compress , jsonIndentFactor ) ; if ( requestBody != null ) { connection . setDoOutput ( true ) ; writeBody ( connection , requestBody ) ; } private void streamBody ( HttpURLConnection connection , Object body , boolean compress ) throws IOException { if ( compress ) { os = new GZIPOutputStream ( os ) ; }", "del_tokens": "import org . json . JSONException ; import java . io . UnsupportedEncodingException ; byte [ ] requestBody = null ; requestBody = WebbUtils . getPayloadAsBytesAndSetContentType ( connection , request , jsonIndentFactor ) ; if ( requestBody != null ) { connection . setDoOutput ( true ) ; } } connection . connect ( ) ; // write the body (of course headers are written first by HUC) if ( requestBody != null ) { streamBody ( connection , request . payload ) ; writeBody ( connection , requestBody ) ; private void streamBody ( HttpURLConnection connection , Object body ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Updated", "Plans", "with", "Actions", "."], "add_tokens": "import javax . persistence . OneToOne ; @ OneToOne ( targetEntity = ActionResource . class ) private Action action ; return action ; }", "del_tokens": "import org . hibernate . annotations . Type ; //private ActionResource action; //return action; return null ; / * } * /", "commit_type": "update"}
{"commit_tokens": ["Fixed", "typo", ".", "(", "Forwent", "review", "as", "the", "change", "is", "so", "trivial", ".", ")"], "add_tokens": "ForPlay . log ( ) . error ( \"Uncaught Exception: \" , e ) ;", "del_tokens": "ForPlay . log ( ) . error ( \"Uncacught Exception: \" , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "mutability", "violation", "and", "added", "null", "-", "check"], "add_tokens": "import static java . util . Arrays . asList ; private static List < String > formatMember ( String params ) { return params != null ? asList ( params . split ( \",\\\\s?\" ) ) : null ;", "del_tokens": "private static String [ ] formatMember ( String params ) { return params != null ? params . split ( \",\\\\s?\" ) : null ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "requirement", "for", "pipe", "and", "arg", "lists", "on", "closures", "."], "add_tokens": "boolean pipeRequired = true ; if ( expr . getChild ( 0 ) . getChildren ( ) . length > 0 ) { pipeRequired = true ; } CSTNode block = null ; if ( pipeRequired || lt ( ) == Token . PIPE ) { block = rootNode ( Token . PIPE ) ; } else { block = new CSTNode ( ) ; }", "del_tokens": "CSTNode block = rootNode ( Token . PIPE ) ;", "commit_type": "remove"}
{"commit_tokens": ["Removed", "the", "2nd", "space", "char", "after", ":", "in", "the", "package", "descriptor"], "add_tokens": "* A descriptor holds the usual key value pairs . * * @ see < a href = \"http://www.debian.org/doc/debian-policy/ch-controlfields.html\" > Debian Policy Manual - Control files and their fields < / a > s . append ( key ) . append ( \":\" ) ; BufferedReader reader = new BufferedReader ( new StringReader ( value ) ) ; if ( line . length ( ) != 0 && ! Character . isWhitespace ( line . charAt ( 0 ) ) ) {", "del_tokens": "import java . io . LineNumberReader ; * A descriptor holds the usual key value pairs s . append ( key ) . append ( \": \" ) ; LineNumberReader reader = new LineNumberReader ( new StringReader ( value ) ) ; if ( reader . getLineNumber ( ) > 0 && line . length ( ) != 0 && ! Character . isWhitespace ( line . charAt ( 0 ) ) ) { // indent the line with a white space", "commit_type": "remove"}
{"commit_tokens": ["fixes", "Jboss", "-", "logging", "provider", "(", "provider", "-", "configuration", "file", "was", "wrong", ")"], "add_tokens": "* @ author Daniel Wegener ( Holisticon AG )", "del_tokens": "* @ author Daniel", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "cases", "for", "SonarQube", "plugin", "glue", "code"], "add_tokens": "private final String rulesRelativeFilePath ; * { this ( pXmlRuleParser , \"/\" + CheckstyleExtensionRepository . class . getPackage ( ) . getName ( ) . replace ( '.' , '/' ) + \"/sonarqube.xml\" ) ; } / * * * Constructor for tests . * * @ param pXmlRuleParser the XML rule parser * @ param pFilePath the path by which to find the rules description file * / CheckstyleExtensionRepository ( final XMLRuleParser pXmlRuleParser , final String pFilePath ) rulesRelativeFilePath = pFilePath ; InputStream input = getClass ( ) . getResourceAsStream ( rulesRelativeFilePath ) ; if ( input == null ) { throw new IllegalStateException ( \"File not found: \" + rulesRelativeFilePath ) ; }", "del_tokens": "private static final String RULES_RELATIVE_FILE_PATH = \"/\" + CheckstyleExtensionRepository . class . getPackage ( ) . getName ( ) . replace ( '.' , '/' ) + \"/sonarqube.xml\" ; InputStream input = getClass ( ) . getResourceAsStream ( RULES_RELATIVE_FILE_PATH ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "class", "usage", "in", "comment", "to", "match", "code"], "add_tokens": "* datastore . clear ( ) ; * datastore . stop ( ) ;", "del_tokens": "* datastore . clearDatastore ( ) ; * datastore . stopDatastore ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "tests", "to", "the", "sorting", "functions", "of", "the", "documentation", "transformer"], "add_tokens": "if ( configuration . getEndPointComparator ( ) != null && transformed . getApis ( ) != null ) { for ( DocumentationEndPoint endpoint : transformed . getApis ( ) ) { if ( configuration . getOperationComparator ( ) != null && endpoint . getOperations ( ) != null ) { Collections . sort ( endpoint . getOperations ( ) , configuration . getOperationComparator ( ) ) ; }", "del_tokens": "if ( configuration . getEndPointComparator ( ) != null ) { } for ( DocumentationEndPoint endpoint : transformed . getApis ( ) ) { if ( configuration . getOperationComparator ( ) != null ) { Collections . sort ( endpoint . getOperations ( ) , configuration . getOperationComparator ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["making", "methods", "used", "only", "in", "the", "class", "private", "."], "add_tokens": "private READERTYPE readAsUser ( String masqueradeAs , String masqueradeType ) { private WRITERTYPE writeAsUser ( String masqueradeAs , String masqueradeType ) {", "del_tokens": "public READERTYPE readAsUser ( String masqueradeAs , String masqueradeType ) { public WRITERTYPE writeAsUser ( String masqueradeAs , String masqueradeType ) {", "commit_type": "make"}
{"commit_tokens": ["Added", "new", "message", "to", "shell", "and", "removed", "bad", "number", "version"], "add_tokens": "import com . stratio . streaming . shell . Main ; sb . append ( OsUtils . LINE_SEPARATOR ) ; sb . append ( \"Type \\\"help\\\" to see all available commands.\" ) ; return \"1\" ;", "del_tokens": "import org . springframework . beans . factory . annotation . Autowired ; import com . stratio . streaming . api . IStratioStreamingAPI ; import com . stratio . streaming . shell . Main ; * private String version = \"0.3.4\" ; @ Autowired private IStratioStreamingAPI stratioStreamingAPI ; sb . append ( \"Version:\" + this . getVersion ( ) + OsUtils . LINE_SEPARATOR ) ; sb . append ( OsUtils . LINE_SEPARATOR ) ; return version ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "couchbase", "/", "couchbase", "-", "lite", "-", "android", "/", "issues", "/", "80", ".", "There", "is", "some", "confusion", "over", "content_type", "vs", "content", "-", "type", "and", "it", "currently", "uses", "both", "which", "needs", "to", "be", "fixed", "in", "a", "future", "commit", "."], "add_tokens": "String contentType = cursor . getString ( 2 ) ; attachment . put ( \"content_type\" , contentType ) ; attachment . put ( \"content-type\" , contentType ) ; // workaround for issue #80 - it was looking at the \"content_type\" field instead of \"content-type\". // fix is backwards compatible in case any code is using content_type. String contentType = null ; if ( newAttach . containsKey ( \"content_type\" ) ) { contentType = ( String ) newAttach . get ( \"content_type\" ) ; Log . w ( TAG , \"Found attachment that uses content_type field name instead of content-type: \" + newAttach ) ; } else if ( newAttach . containsKey ( \"content-type\" ) ) { contentType = ( String ) newAttach . get ( \"content-type\" ) ; } status = insertAttachmentForSequenceWithNameAndType ( new ByteArrayInputStream ( newContents ) , newSequence , name , contentType , revpos ) ;", "del_tokens": "attachment . put ( \"content_type\" , cursor . getString ( 2 ) ) ; status = insertAttachmentForSequenceWithNameAndType ( new ByteArrayInputStream ( newContents ) , newSequence , name , ( String ) newAttach . get ( \"content_type\" ) , revpos ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "generic", "type", "for", "the", "parameter", "of", "the", "procedure", "associated", "to", "an", "AgentTask", "."], "add_tokens": "private Procedures . Procedure1 < ? super Agent > procedure ; public Procedures . Procedure1 < ? super Agent > getProcedure ( ) { public void setProcedure ( Procedures . Procedure1 < ? super Agent > procedure ) {", "del_tokens": "private Procedures . Procedure1 < Agent > procedure ; public Procedures . Procedure1 < Agent > getProcedure ( ) { public void setProcedure ( Procedures . Procedure1 < Agent > procedure ) {", "commit_type": "change"}
{"commit_tokens": ["Fixed", "to", "use", "received", "flag", "instead", "of", "Thread", ".", "sleep", "(", "1000", ")"], "add_tokens": "import java . util . concurrent . atomic . AtomicBoolean ; final AtomicBoolean received = new AtomicBoolean ( false ) ; received . set ( true ) ; // wait for fluentd's getting at least one kv pair while ( ! received . get ( ) ) { Thread . sleep ( 100 ) ; }", "del_tokens": "Thread . sleep ( 1000 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Created", "a", "fake", "test", "failure", "...", "THIS", "IS", "NOT", "A", "REAL", "FAILURE"], "add_tokens": "assertFalse ( socialize . isInitialized ( ) ) ;", "del_tokens": "assertTrue ( socialize . isInitialized ( ) ) ;", "commit_type": "create"}
{"commit_tokens": ["fixing", "toggle", "method", "which", "was", "sharing", "the", "click", "counter", "for", "all", "elements"], "add_tokens": "* GwtQuery is a GWT clone of the popular jQuery library . for ( Element e : elements ( ) ) { $ ( e ) . click ( new Function ( ) { int click = 0 ; public boolean f ( Event e ) { int n = fn . length == 1 ? 0 : ( click ++ % fn . length ) ; return fn [ n ] . f ( e ) ; } } ) ; } return this ;", "del_tokens": "* Gwt Query is a GWT clone of the popular jQuery library . return click ( new Function ( ) { int click = 0 ; public boolean f ( Event e ) { int n = fn . length == 1 ? 0 : ( click ++ % fn . length ) ; return fn [ n ] . f ( e ) ; } } ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "condition", "to", "noMatch", "if", "no", "EclipselinkEntityManager", "was", "found"], "add_tokens": "return ConditionOutcome . noMatch ( \"did not find EclipselinkEntityManager class\" ) ;", "del_tokens": "return ConditionOutcome . match ( \"did not find EclipselinkEntityManager class\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "relationships", "weren", "t", "being", "removed", "when", "elements", "were", "removed", "."], "add_tokens": "public void test_add_AddsTheComponent_WhenTheComponentIsNotInTheViewAlready ( ) { @ Test public void test_remove_RemovesTheComponentAndRelationships_WhenTheComponentIsInTheViewAndHasArelationshipToAnotherElement ( ) { Component componentA = webApplication . addComponent ( \"Component A\" , \"Does something\" , \"Java\" ) ; Component componentB = webApplication . addComponent ( \"Component B\" , \"Does something\" , \"Java\" ) ; componentA . uses ( componentB , \"uses\" ) ; view . add ( componentA ) ; view . add ( componentB ) ; assertEquals ( 2 , view . getElements ( ) . size ( ) ) ; assertEquals ( 1 , view . getRelationships ( ) . size ( ) ) ; view . remove ( componentB ) ; assertEquals ( 1 , view . getElements ( ) . size ( ) ) ; assertEquals ( 0 , view . getRelationships ( ) . size ( ) ) ; }", "del_tokens": "public void test_add_AddsTheComponent_WhenTheComponentIsNoInTheViewAlready ( ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "-", "simplify", "endCapture", "add", "tests", "for", "null", "or"], "add_tokens": "if ( this . suffixes . indexOf ( \")\" ) != - 1 ) {", "del_tokens": "if ( this . suffixes . length ( ) > 0 && this . suffixes . indexOf ( \")\" ) + 1 == this . suffixes . length ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["Changed", "Sunrise", "example", "location", "for", "testing"], "add_tokens": "//public static final double LONGITUDE_OSLO = 10.7460923576733; public static final double LONGITUDE_SARPSBORG = 11.11 ; //public static final double LATITUDE_OSLO = 59.912726542422; public static final double LATITUDE_SARPSBORG = 59.28 ; return sunriseService . fetchContent ( LONGITUDE_SARPSBORG , LATITUDE_SARPSBORG , LocalDate . now ( ) ) ; MeteoDateUtils . zonedDateTimeToHHMM ( sunriseDate . getSun ( ) . getRise ( ) ) ) ;", "del_tokens": "public static final double LONGITUDE_OSLO = 10.7460923576733 ; public static final double LATITUDE_OSLO = 59.912726542422 ; return sunriseService . fetchContent ( LONGITUDE_OSLO , LATITUDE_OSLO , LocalDate . now ( ) ) ; MeteoDateUtils . zonedDateTimeToHHMM ( sunriseDate . getSun ( ) . getRise ( ) ) + \" in Oslo\" ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "/", "updated", "license", "to", "files", "in", "sample", "app"], "add_tokens": "* Copyright ( C ) 2016 Subinkrishna Gopi", "del_tokens": "* Copyright ( C ) 2015 Subinkrishna Gopi", "commit_type": "add"}
{"commit_tokens": ["Create", "authentication", "instance", "using", "entered", "username", "/", "access", "key"], "add_tokens": "public SauceOnDemandAuthentication authentication = new SauceOnDemandAuthentication ( \"${sauceUserName}\" , \"${sauceAccessKey}\" ) ;", "del_tokens": "public SauceOnDemandAuthentication authentication = new SauceOnDemandAuthentication ( ) ;", "commit_type": "create"}
{"commit_tokens": ["Add", "ability", "for", "IDs", "to", "be", "client", "specified", "in", "JPA"], "add_tokens": "@ OneToMany ( mappedBy = \"myResourceHistory\" , cascade = CascadeType . ALL , fetch = FetchType . LAZY , orphanRemoval = true ) Object id = getForcedId ( ) == null ? getResourceId ( ) : getForcedId ( ) . getForcedId ( ) ; return new IdDt ( getResourceType ( ) + '/' + id + '/' + Constants . PARAM_HISTORY + '/' + getVersion ( ) ) ;", "del_tokens": "@ OneToMany ( mappedBy = \"myResourceHistory\" , cascade = CascadeType . ALL , fetch = FetchType . EAGER , orphanRemoval = true ) return new IdDt ( getResourceType ( ) + '/' + getResourceId ( ) + '/' + Constants . PARAM_HISTORY + '/' + getVersion ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "not", "visible", "Toolbar", "title", "issue"], "add_tokens": "setTitle ( getResources ( ) . getString ( resId ) ) ; public void setTitle ( CharSequence text ) { if ( text != null ) { title . setText ( text ) ; title . setVisibility ( View . VISIBLE ) ; } else { title . setVisibility ( View . GONE ) ; }", "del_tokens": "title . setText ( resId ) ; public void setTitle ( CharSequence title ) { this . title . setText ( title ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "JBBPOut", "DSL", "added", "Utf8", "and", "Byte", "(", "Str", ")"], "add_tokens": "Utf8 ( \"JFIF\" ) . Byte ( \"Рус\"). assertEquals ( 47 , array . length ) ; 0x12 , 0x34 , 0x56 , 0x78 , ( byte ) 0x9A , ( byte ) 0xBC , ( byte ) 0xDE , ( byte ) 0xF1 , 0x21 , 0x23 , 0x56 , 0x23 , ( byte ) 0x90 , ( byte ) 0x91 , ( byte ) 0xAB , 0x32 , 0x4A , 0x46 , 0x49 , 0x46 , ( byte ) 0x20 , ( byte ) 0x43 , ( byte ) 0x41", "del_tokens": "assertEquals ( 40 , array . length ) ; 0x12 , 0x34 , 0x56 , 0x78 , ( byte ) 0x9A , ( byte ) 0xBC , ( byte ) 0xDE , ( byte ) 0xF1 , 0x21 , 0x23 , 0x56 , 0x23 , ( byte ) 0x90 , ( byte ) 0x91 , ( byte ) 0xAB , 0x32", "commit_type": "improve"}
{"commit_tokens": ["Added", "support", "for", "getting", "expired", "tokens", "from", "the", "feedback", "service", "."], "add_tokens": "final ChannelFuture connectFuture = this . bootstrap . connect ( this . pushManager . getEnvironment ( ) . getApnsHost ( ) , this . pushManager . getEnvironment ( ) . getApnsPort ( ) ) . sync ( ) ;", "del_tokens": "final ChannelFuture connectFuture = this . bootstrap . connect ( this . pushManager . getEnvironment ( ) . getHost ( ) , this . pushManager . getEnvironment ( ) . getPort ( ) ) . sync ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "query", "and", "type", "filter", "support"], "add_tokens": "import com . scaleset . search . es . filter . * ; register ( \"query\" , new QueryFilterConverter ( ) ) ; register ( \"type\" , new TypeFilterConverter ( ) ) ;", "del_tokens": "import com . scaleset . search . es . filter . FilterConverter ; import com . scaleset . search . es . filter . GeoDistanceFilterConverter ; import com . scaleset . search . es . filter . GeoPolygonFilterConverter ; import com . scaleset . search . es . filter . GeoShapeFilterConverter ;", "commit_type": "add"}
{"commit_tokens": ["removed", "print", "statements", "added", "observeModelField"], "add_tokens": "String manifestPackageName = ManifestPackageUtils . getPackageName ( processingEnv ) ;", "del_tokens": "String manifestPackageName = ManifestPackageUtils . getPackageName ( processingEnv ) ; System . out . println ( \"///////////////////////////////////////////////////\" ) ; System . out . println ( manifestPackageName ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "acks", "and", "audits", "of", "Bus", "events"], "add_tokens": "public String getServiceId ( ) {", "del_tokens": "private String getServiceId ( ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "JacobianFactory", "interface", ".", "In", "case", "when", "solving", "Jacobian", "derivates", "is", "practical", "is", "faster", "to", "use", "it", "."], "add_tokens": "private JacobianFactory jacobianFactory ; public LevenbergMarquardt ( Function func ) { this ( func , null ) ; } / * * * Creates a new instance that uses the provided cost function . * * @ param funcCost Cost function that is being optimized . * @ param jacobianFactory * / public LevenbergMarquardt ( Function funcCost , JacobianFactory jacobianFactory ) this . jacobianFactory = jacobianFactory ; } else if ( Y . getNumCols ( ) != 1 /*|| X.getNumCols() != 1*/ ) { if ( jacobianFactory != null ) { jacobianFactory . computeJacobian ( param , x , jacobian ) ; } else { computeNumericalJacobian ( param , x , jacobian ) ; } int length = y . getNumElements ( ) ; / * * * Jacobian matrix creator * / public interface JacobianFactory { public void computeJacobian ( DenseMatrix64F param , DenseMatrix64F x , DenseMatrix64F jacobian ) ; }", "del_tokens": "public LevenbergMarquardt ( Function funcCost ) } else if ( Y . getNumCols ( ) != 1 || X . getNumCols ( ) != 1 ) { computeNumericalJacobian ( param , x , jacobian ) ; int length = x . getNumElements ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "off", "-", "by", "-", "one", "error", "in", "HighlightErrorConverter"], "add_tokens": "boolean strip = options . length > 1 && \"strip\" . equals ( options [ 1 ] ) ;", "del_tokens": "boolean strip = options . length > 1 && \"strip\" . equals ( options [ 2 ] ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "write", "future", "on", "handshake", "response", "with", "2s", "await"], "add_tokens": "import org . apache . mina . core . future . IoFutureListener ; import org . apache . mina . core . future . WriteFuture ; WriteFuture future = session . write ( wsResponse ) ; future . addListener ( new IoFutureListener < WriteFuture > ( ) { @ Override public void operationComplete ( WriteFuture future ) { if ( future . isWritten ( ) ) { log . debug ( \"Write success!\" ) ; } else { log . debug ( \"Write failed from: {} to: {}\" , session . getLocalAddress ( ) , session . getRemoteAddress ( ) ) ; } } } ) ; // wait 2s for write if ( future . await ( 2000L ) ) { // remove handshake acculator session . removeAttribute ( Constants . WS_HANDSHAKE ) ; log . debug ( \"Handshake complete\" ) ; return true ; } else { log . debug ( \"Write future wait timed out\" ) ; }", "del_tokens": "session . write ( wsResponse ) ; log . debug ( \"Handshake complete\" ) ; return true ;", "commit_type": "add"}
{"commit_tokens": ["adding", "async", "names", "to", "needed", "methods"], "add_tokens": "public static void createBusinessNoteAsync ( final Note note , final LinkedNotebook businessNotebook , final OnClientCallback < Note > callback ) { public static void listBusinessNotebooksAsync ( final OnClientCallback < List < LinkedNotebook > > callback ) { public static void createBusinessNotebookAsync ( Notebook notebook , OnClientCallback < LinkedNotebook > callback ) { public static void deleteBusinessNotebookAsync ( LinkedNotebook businessNotebook , OnClientCallback < Integer > callback ) { public static void getCorrespondingBusinessNotebookAsync ( LinkedNotebook linkedNotebook , OnClientCallback < Notebook > callback ) { public static void isBusinessNotebookWritableAsync ( LinkedNotebook linkedNotebook , OnClientCallback < Boolean > callback ) { public void isBusinessUserAsync ( final OnClientCallback < Boolean > callback ) {", "del_tokens": "public static void createBusinessNote ( final Note note , final LinkedNotebook businessNotebook , final OnClientCallback < Note > callback ) { public static void listBusinessNotebooks ( final OnClientCallback < List < LinkedNotebook > > callback ) { public static void createBusinessNotebook ( Notebook notebook , OnClientCallback < LinkedNotebook > callback ) { public static void deleteBusinessNotebook ( LinkedNotebook businessNotebook , OnClientCallback < Integer > callback ) { public static void getCorrespondingBusinessNotebook ( LinkedNotebook linkedNotebook , OnClientCallback < Notebook > callback ) { public static void isBusinessNotebookWritable ( LinkedNotebook linkedNotebook , OnClientCallback < Boolean > callback ) { public void isBusinessUser ( final OnClientCallback < Boolean > callback ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "more", "lenient", "setter", "method", "checking", "in", "OgnlRuntime", ".", "getWriteMethod", "()", "so", "that", "ObjectPropertyAccessors", "can", "handle", "setters", "that", "return", "a", "value", "."], "add_tokens": "static void findObjectIndexedPropertyDescriptors ( Class targetClass , Map intoMap ) // try again on pure class Method [ ] cmethods = target . getClass ( ) . getMethods ( ) ; for ( int i = 0 ; i < cmethods . length ; i ++ ) { if ( ( cmethods [ i ] . getName ( ) . equalsIgnoreCase ( name ) || cmethods [ i ] . getName ( ) . toLowerCase ( ) . equals ( name . toLowerCase ( ) ) || cmethods [ i ] . getName ( ) . toLowerCase ( ) . equals ( \"set\" + name . toLowerCase ( ) ) ) && ! cmethods [ i ] . getName ( ) . startsWith ( \"get\" ) ) { if ( numParms > 0 && cmethods [ i ] . getParameterTypes ( ) . length == numParms ) return cmethods [ i ] ; else if ( numParms < 0 ) return cmethods [ i ] ; } }", "del_tokens": "private static final void findObjectIndexedPropertyDescriptors ( Class targetClass , Map intoMap )", "commit_type": "add"}
{"commit_tokens": ["adding", "additional", "hashing", "to", "the", "AES", "key"], "add_tokens": "import java . util . Arrays ; final static int minKeySize = 16 ; final static String hashStr = \"zDfb2E9yZartghdY\" ; key = new SecretKeySpec ( hash ( password . getBytes ( ) ) , Algorithm ) ; private byte [ ] hash ( byte [ ] array ) { byte [ ] result = Arrays . copyOf ( array , minKeySize ) ; byte [ ] hash = hashStr . getBytes ( ) ; for ( int i = 0 ; i < minKeySize ; ++ i ) { result [ i ] ^= hash [ i ] ; } return result ; }", "del_tokens": "key = new SecretKeySpec ( password . getBytes ( ) , Algorithm ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "poms", "and", "invalid", "dependencies"], "add_tokens": "( Class ) MinBinDemo . class , ( Class ) ARecord . class", "del_tokens": "MinBinDemo . class , ARecord . class", "commit_type": "fix"}
{"commit_tokens": ["Added", "event", "attachment", "type", "and", "renamed", "album", "attachment", "type", "."], "add_tokens": "@ JsonTypeName ( \"album\" )", "del_tokens": "@ JsonTypeName ( \"photo-album\" )", "commit_type": "add"}
{"commit_tokens": ["added", "deprecated", "asMap", "method", "to", "Cloudinary", "(", "support", "old", "api", ")"], "add_tokens": "@ Deprecated public static Map asMap ( Object ... values ) { return ObjectUtils . asMap ( values ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "CBL", "-", "189", ":", "Resolved", "doc", "has", "empty", "body", "when", "its", "docId", "doesn", "t", "match", "the", "conflicted", "doc"], "add_tokens": "this ( null , id , null ) ; MutableDocument ( String id , Document doc ) { this ( doc . getDatabase ( ) , id , null ) ; setData ( doc . getContent ( ) . toMap ( ) ) ; }", "del_tokens": "this ( null , id , ( C4Document ) null ) ; MutableDocument ( String id , Document doc ) { this ( doc . getDatabase ( ) , id , doc . getC4doc ( ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["making", "use", "of", "splendidly", "invented", "java", "features", "(", "inverse", "order", ")"], "add_tokens": "Collections . sort ( knnDistances , Collections . reverseOrder ( ) ) ;", "del_tokens": "Collections . sort ( knnDistances , new Comparator < Distance > ( ) { public int compare ( Distance d1 , Distance d2 ) { int asc = d1 . compareTo ( d2 ) ; if ( asc > 0 ) { return - 1 ; } else if ( asc < 0 ) { return 1 ; } else { return 0 ; } } } ) ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "also", "long", "values", "for", "min", "/", "max"], "add_tokens": "@ NotNull final long value , final long max ) @ NotNull final long value , final long min )", "del_tokens": "@ NotNull final int value , final int max ) @ NotNull final int value , final int min )", "commit_type": "allow"}
{"commit_tokens": ["remove", "dead", "code", "and", "add", "more", "javadoc"], "add_tokens": "* @ param cls the class to read line number information from * @ throws IOException if an error occurs while reading bytecode", "del_tokens": "private boolean inStatic ; inStatic = ( access & Opcodes . ACC_STATIC ) != 0 ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "worker", "name", "to", "be", "compatible", "with", "other", "Resque", "workers", "."], "add_tokens": "sb . append ( ManagementFactory . getRuntimeMXBean ( ) . getName ( ) . split ( \"@\" ) [ 0 ] ) // PID return this . namespace + \":\" + WORKER + \":\" + this . name ;", "del_tokens": "sb . append ( this . namespace ) . append ( ':' ) . append ( ManagementFactory . getRuntimeMXBean ( ) . getName ( ) . split ( \"@\" ) [ 0 ] ) // PID return this . name ;", "commit_type": "fix"}
{"commit_tokens": ["improve", "brute", "force", "make", "it", "more", "predictable"], "add_tokens": "public Container ( Dimension dimension ) { super ( dimension . getName ( ) , dimension . getWidth ( ) , dimension . getDepth ( ) , dimension . getHeight ( ) ) ;", "del_tokens": "public Container ( Dimension box ) { super ( box . getName ( ) , box . getWidth ( ) , box . getDepth ( ) , box . getHeight ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "char", "to", "byte", "transformation"], "add_tokens": "passwordBytes = new String ( CharBuffer . allocate ( password . length + 1 ) . put ( password ) . put ( \"\\000\" ) . array ( ) ) . getBytes ( charset ) ; byte [ ] cryptRaw ( int cost , byte [ ] salt , byte [ ] password , int [ ] cdata ) {", "del_tokens": "//passwordBytes = charset.encode(CharBuffer.wrap(password).put(\"\\000\")).array(); passwordBytes = String . valueOf ( CharBuffer . wrap ( password ) . put ( \"\\000\" ) ) . getBytes ( charset ) ; private byte [ ] cryptRaw ( int cost , byte [ ] salt , byte [ ] password , int [ ] cdata ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "optional", "feature", "to", "differ", "construction", "of", "Maps", "which", "can", "offset", "some", "of", "initial", "costs"], "add_tokens": "/ * * * This feature determines whether { @ link Map } instances constructed use * deferred materialization ( as implemented by { @ link DeferredMap } ) , in case * user has not specified custom { @ link Map } implementation . * Enabling feature typically reduces initial value read time and moves * overhead to actual access of contents ( materialization occurs when first * key or value access happens ) ; this makes sense when only a subset of * data is accessed . Conversely , when traversing full object hierarchy , it * makes sense to disable this feature . * < p > * Default setting is < code > true < / code > , meaning that reader is expected to try to * / USE_DEFERRED_MAPS ( true ) ,", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Used", "reverse", "comparator", "from", "Collections"], "add_tokens": "import org . junit . Test ; return new ReflectedHeap < Integer , String > ( FACTORY ) ; @ Test ( expected = NullPointerException . class ) public void testNoFactory ( ) { new ReflectedHeap < Integer , Void > ( null ) ; }", "del_tokens": "return new ReflectedHeap < Integer , String > ( FACTORY , null ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "a", "few", "remaining", "bits", "to", "use", "Paths", ".", "toFile", "(", "Path", ")", "."], "add_tokens": "import com . cloudera . data . hdfs . util . Paths ; dataFileWriter . create ( schema , Paths . toFile ( pathTmp ) ) ;", "del_tokens": "import java . io . File ; dataFileWriter . create ( schema , new File ( pathTmp . toUri ( ) . getPath ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "paymentMethodId", "to", "getSellQyote", "and", "getBuyQuote"], "add_tokens": "return getBuyQuote ( amount , null ) ; } @ Override public Quote getBuyQuote ( Money amount , String paymentMethodId ) throws IOException , CoinbaseException { \"prices/buy?\" + qtyParam + \"=\" + URLEncoder . encode ( amount . getAmount ( ) . toPlainString ( ) , \"UTF-8\" ) + ( _accountId != null ? \"&account_id=\" + _accountId : \"\" ) + ( paymentMethodId != null ? \"&payment_method_id=\" + paymentMethodId : \"\" ) return getSellQuote ( amount , null ) ; } @ Override public Quote getSellQuote ( Money amount , String paymentMethodId ) throws IOException , CoinbaseException { \"prices/sell?\" + qtyParam + \"=\" + URLEncoder . encode ( amount . getAmount ( ) . toPlainString ( ) , \"UTF-8\" ) + ( _accountId != null ? \"&account_id=\" + _accountId : \"\" ) + ( paymentMethodId != null ? \"&payment_method_id=\" + paymentMethodId : \"\" )", "del_tokens": "\"prices/buy?\" + qtyParam + \"=\" + URLEncoder . encode ( amount . getAmount ( ) . toPlainString ( ) , \"UTF-8\" ) \"prices/sell?\" + qtyParam + \"=\" + URLEncoder . encode ( amount . getAmount ( ) . toPlainString ( ) , \"UTF-8\" )", "commit_type": "add"}
{"commit_tokens": ["Use", "file", "basename", "instead", "of", "fullname", "in", "sonar"], "add_tokens": "import java . io . File ; / * * Some sonar plugin do no include git path as the source file path ( for * example , sonar - visual - studio plugin generates filenames that are relative * to the module csproj file ) . * * Using the file basename and a recursive match allows Sonar to match * modified files with their indexed names in Sonar . * * Although this can generate useless analysis ( as some files that are not * included in a review may be analysed ) , this has a limited additional * cost considering that few files have the same basename inside a * repository . * / files . add ( \"**/\" + new File ( file . getReviewFilename ( ) ) . getName ( ) ) ;", "del_tokens": "files . add ( file . getReviewFilename ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Implemented", "the", "graph", "-", "theoretic", "querying", "module", ".", "Needs", "testing", "."], "add_tokens": "\"This interaction is directed.\" , true ) , \"This interaction is undirected.\" , false ) ,", "del_tokens": "\"This interaction is directed.\" , false ) , \"This interaction is directed.\" , true ) ,", "commit_type": "implement"}
{"commit_tokens": ["Adds", "clone", "()", "to", "Author"], "add_tokens": "public class Author extends ObservableModel implements Cloneable { public Author clone ( ) { try { return ( Author ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { return null ; } }", "del_tokens": "public class Author extends ObservableModel {", "commit_type": "add"}
{"commit_tokens": ["Add", "violation", "messages", "to", "UnusedImport", "rule"], "add_tokens": "* @ param violationMessage - the violation message ; may be null protected Violation createViolationForImport ( SourceCode sourceCode , String className , String alias , String violationMessage ) { violation . setMessage ( violationMessage ) ;", "del_tokens": "@ Deprecated // should assign a message protected Violation createViolationForImport ( SourceCode sourceCode , String className , String alias ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "@Override", "+", "used", "@Named", "annotation", "+", "fixed", "javadoc"], "add_tokens": "import javax . inject . Named ; @ Component @ Named ( \"tex/1.0\" ) @ Override @ Override", "del_tokens": "@ Component ( \"tex/1.0\" ) / * * * { @ inheritDoc } * * @ see org . xwiki . rendering . renderer . PrintRenderer # getPrinter ( ) * / * @ see org . xwiki . rendering . renderer . PrintRenderer # setPrinter ( org . xwiki . rendering . renderer . printer . WikiPrinter )", "commit_type": "add"}
{"commit_tokens": ["added", "better", "error", "message", "when", "executeAndFetch", "fails", "."], "add_tokens": "throw new Sql2oException ( \"Database error: \" + ex . getMessage ( ) , ex ) ;", "del_tokens": "throw new Sql2oException ( \"Database error\" , ex ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "upload", "host", "and", "duration", "info", "according", "to", "@bailong"], "add_tokens": "* 定义HTTP 请求管理 相关方法 * 以PO ST方法 发送请求数据 * @ param url 请求的URL * @ param data 发送的数据 * @ param offset 发送的数据起始字节索引 * @ param size 发送的数据字节长度 * @ param headers 发送的数据请求头部 * @ param progressHandler 发送数据进度处理对象 * @ param completionHandler 发送数据完成后续动作处理对象 AsyncHttpResponseHandler handler = new ResponseHandler ( url , completionHandler , progressHandler ) ; * 以PO ST方式 发送multipart/ form-data 格 式数据 * @ param url 请求的URL * @ param args 发送的数据 * @ param progressHandler 发送数据进度处理对象 * @ param completionHandler 发送数据完成后续动作处理对象 AsyncHttpResponseHandler handler = new ResponseHandler ( url , completionHandler , progressHandler ) ;", "del_tokens": "* 定义HTTP 请求管理 相关方法 * 以PO ST方法 发送请求数据 * @ param url 请求的URL * @ param data 发送的数据 * @ param offset 发送的数据起始字节索引 * @ param size 发送的数据字节长度 * @ param headers 发送的数据请求头部 * @ param progressHandler 发送数据进度处理对象 * @ param completionHandler 发送数据完成后续动作处理对象 AsyncHttpResponseHandler handler = new ResponseHandler ( completionHandler , progressHandler ) ; * 以PO ST方式 发送multipart/ form-data 格 式数据 * @ param url 请求的URL * @ param args 发送的数据 * @ param progressHandler 发送数据进度处理对象 * @ param completionHandler 发送数据完成后续动作处理对象 AsyncHttpResponseHandler handler = new ResponseHandler ( completionHandler , progressHandler ) ;", "commit_type": "add"}
{"commit_tokens": ["changed", "java_object", "numeric", "type", "to", "double"], "add_tokens": "return Double . valueOf ( cell ) ; return this == AtsdType . STRING_DATA_TYPE && ! nullable ? cell : null ;", "del_tokens": "return new BigDecimal ( cell ) ; return this == AtsdType . STRING_DATA_TYPE ? ( nullable ? null : cell ) : null ;", "commit_type": "change"}
{"commit_tokens": ["fixed", "a", "bug", "in", "Assignment", "and", "added", "unit", "tests", "for", "Assignment", "s", "fast", "-", "evaluation", "feature"], "add_tokens": "else return Collections . unmodifiableList ( ( List < Literal > ) this . pos ) ; else return Collections . unmodifiableList ( ( List < Literal > ) this . neg ) ;", "del_tokens": "return Collections . unmodifiableList ( ( List < Literal > ) this . pos ) ; else return Collections . unmodifiableList ( ( List < Literal > ) this . neg ) ; else", "commit_type": "fix"}
{"commit_tokens": ["fixed", "documentation", "and", "spelling", "nits", "reported", "by", "edenman"], "add_tokens": "* @ return - whether we where able to set the date monthCellWithMonthIndex . cell . setSelected ( true ) ; selectedCell = monthCellWithMonthIndex . cell ; if ( monthCellWithMonthIndex . monthIndex != 0 ) { scrollToSelectedMonth ( monthCellWithMonthIndex . monthIndex ) ; /** Hold a cell with a month-index. */ private static class MonthCellWithMonthIndex { public MonthCellDescriptor cell ; public int monthIndex ; this . cell = cell ; this . monthIndex = monthIndex ; * Return cell and month - index ( for scrolling there ) for a given Date .", "del_tokens": "* @ return - weather we where able to set the date monthCellWithMonthIndex . getCell ( ) . setSelected ( true ) ; selectedCell = monthCellWithMonthIndex . getCell ( ) ; if ( monthCellWithMonthIndex . getmMonthIndex ( ) != 0 ) { scrollToSelectedMonth ( monthCellWithMonthIndex . getmMonthIndex ( ) ) ; /** hold a cell with a month-index * */ private class MonthCellWithMonthIndex { private MonthCellDescriptor mCell ; private int mMonthIndex ; mCell = cell ; mMonthIndex = monthIndex ; public MonthCellDescriptor getCell ( ) { return mCell ; } public int getmMonthIndex ( ) { return mMonthIndex ; } * return cell and month - index ( for scrolling there ) for a given Date", "commit_type": "fix"}
{"commit_tokens": ["remove", "unnecessary", "hashcode", "and", "equals"], "add_tokens": "public SQLCharExpr ( final String text ) {", "del_tokens": "public SQLCharExpr ( final String text ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "initial", "sauce", "connect", "plugin", "example", "code"], "add_tokens": "public SauceOnDemandAuthentication authentication = new SauceOnDemandAuthentication ( ) ;", "del_tokens": "import junit . framework . TestResult ; public SauceOnDemandAuthentication authentication = new SauceOnDemandAuthentication ( \"sbukhari\" , \"08a5e7d7-50b5-47a2-a1e7-b2ba8f221522\" ) ; TestResult result = new TestResult ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "sync", "wait", "logic", "from", "RetryPolicyExecutor", "to", "PolicyExecutor"], "add_tokens": "if ( result . completed )", "del_tokens": "import net . jodah . failsafe . FailsafeException ; import java . util . concurrent . TimeUnit ; if ( result . completed ) { } else { try { Thread . sleep ( TimeUnit . NANOSECONDS . toMillis ( waitNanos ) ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; return new PolicyResult ( null , new FailsafeException ( e ) , true , false ) ; } }", "commit_type": "move"}
{"commit_tokens": ["change", "ConditionParams", "by", "WAT", "-", "5958"], "add_tokens": "long timeout = 0 ; public ConditionParams setShortTimeout ( ) { timeout = 3 ; return this ; } public ConditionParams setMediumTimeout ( ) { timeout = 10 ; return this ; } public ConditionParams setCommonTimeout ( ) { timeout = 30 ; return this ; } public ConditionParams setLongTimeout ( ) { timeout = 60 ; return this ; public long getTimeout ( ) { return timeout ; } public ConditionParams setTimeout ( long timeoutInSec ) { this . timeout = timeoutInSec ; return this ; }", "del_tokens": "public ConditionParams ( String text ) { this . text = text ;", "commit_type": "change"}
{"commit_tokens": ["Add", "some", "basic", "test", "cases", "to", "assert", "RecordListView", "behaves", "as", "expected"], "add_tokens": "public void onNonTimedOutSuccess ( final QueryResult queryResult ) { scheduleStoreToOfflineDataStore ( queryResult ) ; private void scheduleStoreToOfflineDataStore ( final QueryResult queryResult ) { // attempt to store in 7 seconds after fetching from server, should help reduce initial load time. Timer scheduleStoreLater = new Timer ( ) { @ Override public void run ( ) { storeToOfflineDataStore ( queryResult ) ; } } ; scheduleStoreLater . schedule ( 7000 ) ; }", "del_tokens": "public void onNonTimedOutSuccess ( QueryResult queryResult ) { storeToOfflineDataStore ( queryResult ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "Form", ".", "setParameter", "throw", "IAE", "when", "parameter", "cannot", "be", "found"], "add_tokens": "/ * * * Sets the value of the specified parameter . * * @ param name * the name of the parameter to set * @ param value * the value to set * @ return this form * @ throws IllegalArgumentException * if the parameter cannot be found * /", "del_tokens": "", "commit_type": "make"}
{"commit_tokens": ["Changed", "method", "signature", "for", "postRun"], "add_tokens": "protected void postRun ( HttpServletRequest request , HttpServletResponse response , Object ... params ) { }", "del_tokens": "protected void postRun ( HttpServletRequest request , Object ... params ) { }", "commit_type": "change"}
{"commit_tokens": ["updated", "Traverse", "to", "support", "dynamic", "label", "declarations", "and", "impelmented", "a", "cleaner", "more", "efficient", "reduce", "-", "side", "join", "as", "learned", "from", "Ricky", "Ho", "."], "add_tokens": "import com . thinkaurelius . faunus . mapreduce . algebra . Traverse ; config . setStrings ( Traverse . LABELS_PROPERTY , \"knows\" , \"created\" ) ; job . setMapperClass ( Traverse . Map . class ) ; job . setReducerClass ( Traverse . Reduce . class ) ;", "del_tokens": "import com . thinkaurelius . faunus . mapreduce . algebra . Transpose ; job . setMapperClass ( Transpose . Map . class ) ; job . setReducerClass ( Transpose . Reduce . class ) ;", "commit_type": "update"}
{"commit_tokens": ["Made", "FSEntry", "implement", "Comparable", "."], "add_tokens": "* public boolean isDirty ( ) { public int compareTo ( FSEntry e ) { if ( e . isDirectory ( ) == this . isDirectory ( ) ) { /* compare names */ return this . getName ( ) . compareTo ( e . getName ( ) ) ; } else { if ( e . isDirectory ( ) ) return - 1 ; else return 1 ; } }", "del_tokens": "* @ throws IOException public boolean isDirty ( ) throws IOException {", "commit_type": "make"}
{"commit_tokens": ["Fix", "an", "issue", "with", "not", "throwing", "a", "Connect", "error", "when", "the", "etcd", "server", "is", "not", "running", "."], "add_tokens": "protected < R > void connect ( EtcdRequest < R > etcdRequest , ConnectionCounter counter , String url ) throws IOException { etcdRequest . getPromise ( ) . getNettyPromise ( ) . setFailure ( f . cause ( ) ) ;", "del_tokens": "protected < R > void connect ( EtcdRequest < R > etcdRequest , ConnectionCounter counter , String url ) throws IOException { etcdRequest . getPromise ( ) . setException ( f . cause ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "use", "new", "API"], "add_tokens": "import org . bouncycastle . asn1 . pkcs . CertificationRequest ; protected List < X509Certificate > doEnroll ( CertificationRequest certificationRequest ) {", "del_tokens": "import org . bouncycastle . jce . PKCS10CertificationRequest ; import org . jscep . server . ScepServlet ; @ Override protected List < X509Certificate > doEnroll ( PKCS10CertificationRequest certificationRequest ) {", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "SitestreamController", ".", "getInfo", "(", "streamId", "userId", ")"], "add_tokens": "public String getInfo ( String streamId ) throws IOException , ControlStreamException {", "del_tokens": "public String getInfo ( String streamId , long userId ) throws IOException , ControlStreamException { endpoint . addPostParameter ( Constants . USER_ID_PARAM , Long . toString ( userId ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "method", "to", "allow", "ungenericed", "map", "to", "genericed", "map", "fudge"], "add_tokens": "import java . util . Map ; / * * * Static methods to get around issues with generics ... * / @ SuppressWarnings ( \"unchecked\" ) /** Only static methods. */ private GenericFudge ( ) { } / * * * Fudge the return from getClass to include the generic . * / / * * * Fudge a ungenericified map to be one . * / static public < K , V > Map < K , V > map ( Map map ) { return map ; }", "del_tokens": "@ SuppressWarnings ( \"unchecked\" )", "commit_type": "add"}
{"commit_tokens": ["added", "percentage", "as", "bar", "in", "call", "stack", "tests"], "add_tokens": "sb . append ( \"--------------------------------------------------------------------------\\n\" ) ; sb . append ( \"Selftime (ms) Total (ms) Method signature\\n\" ) ; sb . append ( \"--------------------------------------------------------------------------\\n\" ) ;", "del_tokens": "sb . append ( \"--------------------------------------------------\\n\" ) ; sb . append ( \"Selftime (ms) Total (ms) Method signature\\n\" ) ; sb . append ( \"--------------------------------------------------\\n\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "lack", "of", "generic", "type", "in", "implemented", "interface", "(", "that", "caused", "unchecked", "assignments", "in", "projects", ")", "."], "add_tokens": "public class CachedFieldImpl < T > implements CachedField < T > {", "del_tokens": "public class CachedFieldImpl < T > implements CachedField {", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "hostname", "checking", "on", "legacy", "protocol", "connections"], "add_tokens": "import java . security . cert . X509Certificate ; import javax . net . ssl . SSLException ; import eu . emi . security . authn . x509 . impl . CertificateUtils ; import eu . emi . security . authn . x509 . impl . FormatMode ; import eu . emi . security . authn . x509 . impl . HostnameMismatchCallback ; import eu . emi . security . authn . x509 . impl . SocketFactoryCreator ; public class LegacyProtocol extends AbstractVOMSProtocol implements VOMSProtocol , HostnameMismatchCallback { public synchronized VOMSResponse doRequest ( X509Credential credential , VOMSACRequest request ) { sslSocket . setEnabledProtocols ( VOMS_LEGACY_PROTOCOLS ) ; SocketFactoryCreator . connectWithHostnameChecking ( sslSocket , this ) ; public void nameMismatch ( SSLSocket socket , X509Certificate peerCertificate , String hostName ) throws SSLException { String peerCertString = CertificateUtils . format ( peerCertificate , FormatMode . MEDIUM_ONE_LINE ) ; String message = String . format ( \"Hostname verificate failed for host: %s. Peer certificate : %s\" , hostName , peerCertString ) ; throw new SSLException ( message ) ; }", "del_tokens": "public class LegacyProtocol extends AbstractVOMSProtocol implements VOMSProtocol { public VOMSResponse doRequest ( X509Credential credential , VOMSACRequest request ) { sslSocket . setEnabledProtocols ( VOMS_LEGACY_PROTOCOLS ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "adb", "locator", "and", "apk", "installer"], "add_tokens": "import java . nio . file . Paths ; private final static String ADB = locateAdb ( ) ; private static String locateAdb ( ) { String sysAdb = SystemConfiguration . getInstance ( ) . getProperty ( SYSPROP_ADB_EXECUTABLE ) ; if ( sysAdb != null ) { return sysAdb ; } else { String paths = System . getenv ( ) . get ( \"PATH\" ) ; if ( paths != null ) { String [ ] path = paths . split ( System . getProperty ( \"path.separator\" ) ) ; for ( String p : path ) { LOG . debug ( \"path {}\" , p ) ; File f = Paths . get ( p , \"adb\" ) . toFile ( ) ; if ( f . exists ( ) ) { return f . getAbsolutePath ( ) ; } } } } throw new RuntimeException ( \"Cannot find adb based on system PATH. Please specify where adb executable is by\" + \" setting system property \" + SYSPROP_ADB_EXECUTABLE + \"=/path/to/your/sdk/platform-tools/adb\" ) ; } LOG . warn ( line ) ;", "del_tokens": "static { LOG . debug ( \"Please specify where adb executable is by setting system property {}={}\" , SYSPROP_ADB_EXECUTABLE , \"/path/to/your/sdk/platform-tools/adb\" ) ; } private final static String ADB = SystemConfiguration . getInstance ( ) . getProperty ( SYSPROP_ADB_EXECUTABLE , \"adb\" ) ; LOG . error ( line ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "PooledEngine", "to", "correctly", "reset", "entity", "signals", "and"], "add_tokens": "componentAdded . removeAllListeners ( ) ; componentRemoved . removeAllListeners ( ) ;", "del_tokens": "", "commit_type": "update"}
{"commit_tokens": ["Added", "additional", "reverse", "lookup", "method", "with", "zoom", "level", "parameter", "."], "add_tokens": "/ * * * Reverse geocode the given coordinates using a specific zoom level * * @ param longitude * a longitude * @ param latitude * a latitude * @ param zoom * a osm zoom level * @ return an address corresponding to the given longitude and latitude or < code > null < / code > if * no result found * @ throws IOException * a communication error occurred * / Address getAddress ( final double longitude , final double latitude , int zoom ) throws IOException ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "constructor", "with", "vararg", "and", "make", "addFileFilter", "method", "fluent", "in", "AndFileFilter"], "add_tokens": "import java . util . Arrays ; this ( new ArrayList < FileFilter > ( ) ) ; } public AndFileFilter ( FileFilter ... fileFilters ) { this ( Arrays . asList ( fileFilters ) ) ; public AndFileFilter addFileFilter ( FileFilter fileFilter ) { return this ;", "del_tokens": "this . fileFilters = new ArrayList < > ( ) ; public void addFileFilter ( FileFilter fileFilter ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "Javadocs", "for", "getRegisteredServiceInstance", "()", "of", "the", "JsonServiceRegistryDao"], "add_tokens": "/ * * * Constructs an instance of { @ link RegisteredServiceWithAttributes } based on the * syntax of the pattern defined . If the pattern is considered a valid regular expression , * an instance of { @ link RegexRegisteredServiceWithAttributes } is created . Otherwise , * { @ link RegisteredServiceWithAttributesImpl } . * @ see # isValidRegexPattern ( String ) * @ param pattern the pattern of the service definition * @ return an instance of { @ link RegisteredServiceWithAttributes } * / private RegisteredService getRegisteredServiceInstance ( final String pattern ) { if ( isValidRegexPattern ( pattern ) ) {", "del_tokens": "private RegisteredService getRegisteredServiceInstance ( final String id ) { if ( isValidRegexPattern ( id ) ) {", "commit_type": "update"}
{"commit_tokens": ["Added", "new", "tests", "for", "rollers"], "add_tokens": "@ FindBy ( css = \"main form\" ) public ContactForm contactForm ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "where", "base", "fields", "were", "not", "being", "applied", "when", "multiple", "negative", "dot", "paths", "are", "specified", "."], "add_tokens": "List < SquigglyExpressionParser . ExpressionContext > expressions = ctx . expression ( ) ; int negated = 0 ; for ( SquigglyExpressionParser . ExpressionContext expressionContext : expressions ) { if ( handleExpression ( expressionContext , parent ) ) { negated ++ ; } } if ( negated == expressions . size ( ) ) { parent . addChild ( new MutableNode ( new ExactName ( PropertyView . BASE_VIEW ) , false ) ) ; private boolean handleExpression ( SquigglyExpressionParser . ExpressionContext ctx , MutableNode parent ) { return handleNegatedExpression ( ctx . negated_expression ( ) , parent ) ; return false ; private boolean handleNegatedExpression ( SquigglyExpressionParser . Negated_expressionContext ctx , MutableNode parent ) { return true ; return true ; return false ;", "del_tokens": "for ( SquigglyExpressionParser . ExpressionContext expressionContext : ctx . expression ( ) ) { handleExpression ( expressionContext , parent ) ; private void handleExpression ( SquigglyExpressionParser . ExpressionContext ctx , MutableNode parent ) { handleNegatedExpression ( ctx . negated_expression ( ) , parent ) ; return ; private void handleNegatedExpression ( SquigglyExpressionParser . Negated_expressionContext ctx , MutableNode parent ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "for", "ignoring", "array", "order", "and", "for", "ignoring", "extra", "values", "."], "add_tokens": "import net . javacrumbs . jsonunit . core . Option ; import java . util . EnumSet ; super ( actual , path , description , ignorePlaceholder , null , EnumSet . noneOf ( Option . class ) ) ;", "del_tokens": "super ( actual , path , description , ignorePlaceholder , null , false ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "Tree", "memory", "limit", "to", "CL", "Gurobi", "solver"], "add_tokens": "private double workMemMegs ; public ClGurobiIlpSolver ( File tempDir , int numThreads , double workMemMegs ) { this . workMemMegs = workMemMegs ; \"NodefileDir=\" + tempDir . getAbsolutePath ( ) , \"NodefileStart=\" + workMemMegs / 1024.0 ,", "del_tokens": "public ClGurobiIlpSolver ( File tempDir , int numThreads ) {", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "multi", "session", "communication", "on", "the", "same", "Rserve", "host"], "add_tokens": "public Rdaemon ( RserverConf conf , Logger log , String R_HOME ) { this ( conf , log , null ) ;", "del_tokens": "import java . net . SocketException ; import org . rosuda . REngine . Rserve . RserveException ; public Rdaemon ( RserverConf conf , Logger log , String R_HOME , String Rserve_HOME ) { this ( conf , log , null , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "the", "modified", "drag", "method", "in", "a", "(", "hopefully", ")", "correctly", "documented", "way", "instead", "of", "including", "TouchUtils", ".", "java", "verbatim", "from", "AOSP", "."], "add_tokens": "/ * * * Simulate touching a specific location and dragging to a new location . * * This method was copied from { @ code TouchUtils . java } in the Android Open Source Project , and modified here . * * @ param fromX X coordinate of the initial touch , in screen coordinates * @ param toX Xcoordinate of the drag destination , in screen coordinates * @ param fromY X coordinate of the initial touch , in screen coordinates * @ param toY Y coordinate of the drag destination , in screen coordinates * @ param stepCount How many move steps to include in the drag * /", "del_tokens": "/ * * * Private method used to drag the screen . * * /", "commit_type": "use"}
{"commit_tokens": ["use", "addition", "instead", "of", "XOR", "as", "associative", "commutative", "hash", "function", ";", "XOR", "is", "bad", "because", "elements", "cancel", "out", "themselves"], "add_tokens": "* Combine many hash codes with an associative commutative hash function . * Associativity ensures that the result of this functions can be further * combined with other hash codes for getting the same result as if all hash * codes had been combined in one step . hash = hash + h ; * Combine the hash codes of a collection of structural hash objects with an * associative commutative hash function . Associativity ensures that the * result of this functions can be further combined with other hash codes * for getting the same result as if all hash codes had been combined in one * step . hash += o . structuralHashCode ( ) ;", "del_tokens": "* Combine many hash codes into one in a way that does not depend on their * order . hash = hash ^ h ; * Combine the hash codes of a collection of structural hash objects into * one in a way that does not depend on their order . hash ^= o . structuralHashCode ( ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "assert", "on", "number", "of", "data", "headers", "seen", "."], "add_tokens": "import java . util . concurrent . atomic . AtomicInteger ; final AtomicInteger dataHeadersRcved = new AtomicInteger ( 0 ) ; dataHeadersRcved . incrementAndGet ( ) ; assertThat ( dataHeadersRcved . get ( ) , is ( 1 ) ) ;", "del_tokens": "//assertThat(headersRcved, is(1)); // TODO: make this assert on receiving at least one message", "commit_type": "add"}
{"commit_tokens": ["Changed", "naming", "of", "super", "annotation", "attributes", ".", "Added", "further", "tests", "and", "javadoc", "."], "add_tokens": "when ( annotation . constructorParameters ( ) ) . thenReturn ( new Class < ? > [ 0 ] ) ;", "del_tokens": "when ( annotation . constructorArguments ( ) ) . thenReturn ( new Class < ? > [ 0 ] ) ;", "commit_type": "change"}
{"commit_tokens": ["Update", "to", "use", "the", "compile", "-", "testing", "release", "."], "add_tokens": ". compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . compilesWithoutError ( ) . failsToCompile ( ) . withErrorContaining ( \"AutoFactory does not support generic types\" ) . in ( file ) . onLine ( 6 ) . atColumn ( 14 ) ;", "del_tokens": ". hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasNoErrors ( ) . hasError ( \"AutoFactory does not support generic types\" ) . in ( file ) . onLine ( 6 ) . atColumn ( 14 ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "complex", "tokenization", "tests", "and", "continued", "Complex", "tokenization", "implementation"], "add_tokens": "else if ( complex && ch == 'i' ) { idx = tryParseComplexNumber ( expression , ch , idx + 1 , tokens ) ; } boolean imgOnly = false ; if ( ch == 'i' ) { imgOnly = true ; } else { realBuilder . append ( ch ) ; } if ( imgOnly ) { // a complex if ( realBuilder . length ( ) == 0 ) { realBuilder . append ( '1' ) ; } double imaginary = Double . parseDouble ( realBuilder . toString ( ) ) ; NumberToken < ComplexNumber > z = new NumberToken < ComplexNumber > ( ComplexNumber . class , new ComplexNumber ( 0d , imaginary ) , true ) ; tokens . add ( z ) ; return offset ; } if ( imgBuilder . length ( ) == 0 ) { imgBuilder . append ( '1' ) ; } imaginary ) , imaginary != 0d ) ;", "del_tokens": "realBuilder . append ( ch ) ; imaginary ) , imaginary != 0d ) ;", "commit_type": "add"}
{"commit_tokens": ["make", "the", "test", "more", "robust"], "add_tokens": "socket . on ( \"message\" , new Function < String > ( ) {", "del_tokens": "socket . on ( new Function < String > ( ) {", "commit_type": "make"}
{"commit_tokens": ["update", "pmd", "checkstyle", ";", "fix", "pmd", "warnings"], "add_tokens": "private static List < Class < ? extends Exception > > wrapExceptions ( final Class < ? extends Exception > ... list ) {", "del_tokens": "private static List < Class < ? extends Exception > > wrapExceptions ( final Class < ? extends Exception > [ ] list ) {", "commit_type": "update"}
{"commit_tokens": ["Add", "ID", "not", "found", "fixture", "JSON", ".", "Dont", "throw", "error", "if", "response", "is", "not", "200"], "add_tokens": "httpClient . executeMethod ( method ) ; throw new RuntimeException ( \"Not implemented\" ) ; throw new RuntimeException ( \"Not implemented\" ) ; throw new RuntimeException ( \"Not implemented\" ) ;", "del_tokens": "int statusCode = httpClient . executeMethod ( method ) ; if ( statusCode != HttpStatus . SC_OK ) { String error = String . format ( \"Expected 200 OK. Received %d %s. Response: %s.\" , statusCode , HttpStatus . getStatusText ( statusCode ) , method . getResponseBodyAsString ( ) ) ; throw new RuntimeException ( error ) ; } throw new RuntimeException ( \"Expected response body, got null\" ) ; throw new RuntimeException ( e ) ; throw new RuntimeException ( e ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "untested", "addCommandLineOption", "to", "Tang", "."], "add_tokens": "import com . microsoft . tang . Tang . CommandLineCallback ; for ( Option o : applicationOptions . keySet ( ) ) { opts . addOption ( o ) ; } public interface CommandLineCallback { public void process ( Option option ) ; } Map < Option , CommandLineCallback > applicationOptions = new HashMap < Option , CommandLineCallback > ( ) ; public void addCommandLineOption ( Option option , CommandLineCallback cb ) { // TODO: Check for conflicting options. applicationOptions . put ( option , cb ) ; } // XXX completely untested. if ( applicationOptions . containsKey ( option ) ) { applicationOptions . get ( option ) . process ( option ) ; } else { setNamedParameter ( ( Class < ? extends Name > ) ( n . clazz ) , ReflectionUtilities . parse ( n . argClass , value ) ) ; }", "del_tokens": "setNamedParameter ( ( Class < ? extends Name > ) ( n . clazz ) , ReflectionUtilities . parse ( n . argClass , value ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "class", "final", "to", "pass", "a", "certain", "check", "."], "add_tokens": "public final class ImmutableProvidedOtherClassIsImmutable {", "del_tokens": "public class ImmutableProvidedOtherClassIsImmutable {", "commit_type": "make"}
{"commit_tokens": ["Adding", "repository", "with", "random", "search", "capability"], "add_tokens": "if ( StringUtils . isNotBlank ( firstName ) && StringUtils . isNotBlank ( lastName ) && StringUtils . isNotBlank ( facebookId ) ) {", "del_tokens": "if ( StringUtils . isNotBlank ( firstName ) && StringUtils . isNotBlank ( lastName ) && StringUtils . isNotBlank ( email ) && StringUtils . isNotBlank ( facebookId ) ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "dependency", "on", "trellis", "-", "vocabulary"], "add_tokens": "private final IRI prefer = rdf . createIRI ( \"http://example.org/prefer/Custom\" ) ; assertEquals ( 0L , mockResource . stream ( prefer ) . count ( ) ) ; assertEquals ( 0L , mockResource . stream ( singleton ( prefer ) ) . count ( ) ) ;", "del_tokens": "import org . trellisldp . vocabulary . Trellis ; assertEquals ( 0L , mockResource . stream ( Trellis . PreferUserManaged ) . count ( ) ) ; assertEquals ( 0L , mockResource . stream ( singleton ( Trellis . PreferAudit ) ) . count ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "calgary", "test", "data", "set"], "add_tokens": "if ( header [ 0 ] != SnappyCodec . MAGIC_HEADER [ 0 ] ) { int writtenBytes = 0 ; for ( ; writtenBytes < len ; ) { return writtenBytes == 0 ? - 1 : writtenBytes ; System . arraycopy ( uncompressed , uncompressedCursor , b , off + writtenBytes , bytesToWrite ) ; writtenBytes += bytesToWrite ; return writtenBytes ;", "del_tokens": "if ( readBytes < header . length ) { int wroteBytes = 0 ; for ( ; wroteBytes < len ; ) { return wroteBytes == 0 ? - 1 : wroteBytes ; System . arraycopy ( uncompressed , uncompressedCursor , b , off + wroteBytes , bytesToWrite ) ; wroteBytes += bytesToWrite ; return wroteBytes ;", "commit_type": "add"}
{"commit_tokens": ["Create", "Self", "Documenting", "Reference", "File"], "add_tokens": "* name or the { @ code on ( ) } method .", "del_tokens": "* parameter or the { @ code on ( ) } method .", "commit_type": "create"}
{"commit_tokens": ["Added", "tests", "on", "delayed", "load", "interface", "method"], "add_tokens": "JMethod delayedLoadMethod = definedClass . method ( JMod . PUBLIC , codeModel . VOID , DelayedLoad . LOAD_METHOD ) ; proxyVariable . getExpression ( ) . invoke ( DelayedLoad . LOAD_METHOD ) . arg ( variableBuilder . getExpression ( ) ) ) ;", "del_tokens": "protected static final String DELAYED_LOAD_METHOD_NAME = \"load\" ; JMethod delayedLoadMethod = definedClass . method ( JMod . PUBLIC , codeModel . VOID , DELAYED_LOAD_METHOD_NAME ) ; proxyVariable . getExpression ( ) . invoke ( DELAYED_LOAD_METHOD_NAME ) . arg ( variableBuilder . getExpression ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "ColumnDescriptorAdapter", "in", "createTable", "()"], "add_tokens": "builder . addColumnFamilies ( columnDescriptorAdapter . adapt ( column ) ) ;", "del_tokens": "builder . addColumnFamilies ( AnviltopData . ColumnFamily . newBuilder ( ) . setName ( column . getNameAsString ( ) ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "before", "test", "hook", "clearing", "the", "webdriver", "created", "and", "webdriver", "destroyed", "lists"], "add_tokens": "import org . junit . Before ; @ Before public void setup ( ) { //clear the webdriver storage hooks MockWebDriverCreationHook . createdWebDrivers . clear ( ) ; MockWebDriverCreationHook . destroyedWebdrivers . clear ( ) ; } SeleniumManager manager = SenBotContext . getSenBotContext ( ) . getSeleniumManager ( ) ;", "del_tokens": "SeleniumManager manager = SenBotContext . getSenBotContext ( ) . getSeleniumManager ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "of", "xml", "attributes", "to", "Drawable", "."], "add_tokens": "import android . os . Build ; import android . support . v4 . content . ContextCompat ; private ParticlesDrawable mDrawable ; if ( Build . VERSION . SDK_INT >= Build . VERSION_CODES . N ) { mDrawable = ( ParticlesDrawable ) ContextCompat . getDrawable ( this , R . drawable . particles_120dots ) ; } else { mDrawable = new ParticlesDrawable ( ) ; }", "del_tokens": "private final ParticlesDrawable mDrawable = new ParticlesDrawable ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Moved", "actual", "creation", "of", "JavaAnnotation", "out", "of", "JavaClass"], "add_tokens": "import java . util . Map ; import com . google . common . collect . ImmutableMap ; private final Map < String , JavaAnnotation > annotations ; annotations = builder . annotations . build ( ) ; return Optional . fromNullable ( annotations . get ( type . getName ( ) ) ) ; private final ImmutableMap . Builder < String , JavaAnnotation > annotations = ImmutableMap . builder ( ) ; for ( JavaAnnotation annotation : typeDetails . getAnnotations ( ) ) { annotations . put ( annotation . getType ( ) . getName ( ) , annotation ) ; }", "del_tokens": "Annotation annotation = reflect ( ) . getAnnotation ( type ) ; return annotation != null ? Optional . of ( JavaAnnotation . of ( annotation ) ) : Optional . < JavaAnnotation > absent ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "ability", "to", "specify", "arbitrary", "conditions", "(", "expression", ")", "for", "a", "model", "to", "allow", "controller", "action", ".", "This", "is", "in", "direction", "of", "providing", "work", "flow", "support"], "add_tokens": "import java . io . InputStream ; import com . venky . swf . sql . parser . SQLExpressionParser ; import com . venky . swf . sql . parser . XMLExpressionParser ; Model selectedModel = null ; selectedModel = possibleTable . get ( id ) ; Integer referenceValue = ( Integer ) reflector . getFieldGetter ( referencedModelIdFieldName ) . invoke ( selectedModel ) ; if ( selectedModel != null ) { for ( Iterator < RolePermission > permissionIterator = permissions . iterator ( ) ; permissionIterator . hasNext ( ) ; ) { RolePermission permission = permissionIterator . next ( ) ; InputStream condition = null ; //permission.getCondtion(); if ( condition != null ) { String sCondition = StringUtil . read ( condition ) ; Expression expression = new SQLExpressionParser ( modelClass ) . parse ( sCondition ) ; if ( expression == null ) { expression = new XMLExpressionParser ( modelClass ) . parse ( sCondition ) ; } if ( ! expression . eval ( selectedModel ) ) { permissionIterator . remove ( ) ; } } } }", "del_tokens": "Model model = possibleTable . get ( id ) ; Integer referenceValue = ( Integer ) reflector . getFieldGetter ( referencedModelIdFieldName ) . invoke ( model ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "feature", "to", "create", "custom", "AndroidApplication", ".", "xml", "file"], "add_tokens": "private static final String APK_FILE = \"src/test/resources/selendroid-test-app.apk\" ; private static final String SELENDROID_PREBUILD_SERVER = \"src/test/resources/selendroid-server.apk\" ; public static final String ANDROID_APPLICATION_XML_TEMPLATE = \"src/main/resources/AndroidManifest.xml\" ; SelendroidServerBuilder builder = new SelendroidServerBuilder ( SELENDROID_PREBUILD_SERVER , ANDROID_APPLICATION_XML_TEMPLATE ) ; builder . init ( APK_FILE ) ; @ Test public void testShouldBeAbleToCreateCustomizedAndroidApplicationXML ( ) throws Exception { SelendroidServerBuilder builder = new SelendroidServerBuilder ( SELENDROID_PREBUILD_SERVER , ANDROID_APPLICATION_XML_TEMPLATE ) ; builder . init ( APK_FILE ) ; builder . createAndAddCustomizedAndroidManifestToSelendroidServer ( ) ; }", "del_tokens": "private static final String apkFile = \"src/test/resources/selendroid-test-app.apk\" ; private static final String selendroidPrebuidlServer = \"src/test/resources/selendroid-server.apk\" ; SelendroidServerBuilder builder = new SelendroidServerBuilder ( selendroidPrebuidlServer ) ; builder . init ( apkFile ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "not", "scrolling", "up", "listview", "in", "demo", "app"], "add_tokens": "private class MyOnItemTouchListener extends RecyclerView . SimpleOnItemTouchListener {", "del_tokens": "private class MyOnItemTouchListener implements RecyclerView . OnItemTouchListener { @ Override public void onTouchEvent ( RecyclerView rv , MotionEvent e ) { // no op }", "commit_type": "fix"}
{"commit_tokens": ["add", "support", "for", "cursor", "codecs", "&", "minor", "query", "codecs", "in", "MySQL"], "add_tokens": "package io . vertx . mysqlclient . impl . protocol . backend ;", "del_tokens": "package io . reactiverse . myclient . impl . protocol . backend ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "that", "the", "filenames", "added", "to", "the", "manifest", "are", "correctly", "encoded"], "add_tokens": "throws Exception staticResources . add ( \"file with space.html\" ) ; cacheResources . add ( \"mydir/file_with_$.js\" ) ; final String manifest = linker . writeManifest ( TreeLogger . NULL , staticResources , cacheResources ) ; assertNotEquals ( findLine ( lines , cacheSectionStart + 1 , networkSectionStart , \"file%20with%20space.html\" ) , - 1 ) ; assertNotEquals ( findLine ( lines , cacheSectionStart + 1 , networkSectionStart , \"mydir/file_with_%24.js\" ) , - 1 ) ;", "del_tokens": "import static org . testng . Assert . assertEquals ; final String manifest = linker . writeManifest ( staticResources , cacheResources ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "user", "-", "supplied", "key", "to", "numeric", "range", "agg"], "add_tokens": "String key = range . path ( \"key\" ) . asText ( null ) ; result . addRange ( key , from . asDouble ( ) , to . asDouble ( ) ) ; result . addUnboundedFrom ( key , from . asDouble ( ) ) ; result . addUnboundedTo ( key , to . asDouble ( ) ) ; String key = bucket . getKey ( ) ;", "del_tokens": "result . addRange ( from . asDouble ( ) , to . asDouble ( ) ) ; result . addUnboundedFrom ( from . asDouble ( ) ) ; result . addUnboundedTo ( to . asDouble ( ) ) ; String key = \"[\" + label + \"}\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "the", "parameter", "parsing", "as", "boolean", "Fix", "issue", "when", "querying", "parameters"], "add_tokens": "String parameter = parameter ( name ) ; @ Override public Boolean parameterAsBoolean ( String name ) { String parameter = parameter ( name ) ; try { return Boolean . parseBoolean ( parameter ) ; } catch ( Exception e ) { return null ; } } @ Override public Boolean parameterAsBoolean ( String name , boolean defaultValue ) { Boolean parameter = parameterAsBoolean ( name ) ; if ( parameter == null ) { return defaultValue ; } return parameter ; } * Get all the parameters from the request . * This method does not check the attributes .", "del_tokens": "String parameter = parameterFromPath ( name ) ; * Get all the parameters from the request *", "commit_type": "add"}
{"commit_tokens": ["Changed", "get", "method", "to", "return", "immutable", "empty", "list", "if", "entries", "not", "found"], "add_tokens": "import java . util . Collections ; return Collections . EMPTY_LIST ;", "del_tokens": "private final List < L > emptyList = new ArrayList < > ( ) ; return emptyList ;", "commit_type": "change"}
{"commit_tokens": ["Change", "default", "path", "to", "FixedCircularPath", ".", "This", "change", "is", "temporal"], "add_tokens": "path = PathFactory . getFixedCircularPath ( pathConfig ) ;", "del_tokens": "path = PathFactory . getLinearPath ( pathConfig ) ;", "commit_type": "change"}
{"commit_tokens": ["added", "support", "of", "topic", "deletion"], "add_tokens": "import com . igormaznitsa . nbmindmap . model . MindMapTopic ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "Map", "handling", "in", "Thrift", "to", "Pig", "conversion", "."], "add_tokens": "* To create a converter for your Thrift class < code > MyThriftClass < / code > , you simply need to extend private final ThriftToTuple < T > thriftToTuple_ = new ThriftToTuple < T > ( ) ; return thriftToTuple_ . convert ( thriftObj_ ) ;", "del_tokens": "* To create a converter for your Thrift class < code > MyThriftClass < / code > , you simply need to extend private final ThriftToPigProtocol toPigProtocol_ = new ThriftToPigProtocol ( new TMemoryBuffer ( 1 ) ) ; thriftObj_ . write ( toPigProtocol_ ) ; return toPigProtocol_ . getPigTuple ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "the", "ability", "to", "specify", "a", "path", "in", "a", "cookie"], "add_tokens": "cookie ( \"\" , name , value , maxAge , secured ) ; } / * * * Adds cookie to the response . Can be invoked multiple times to insert more than one cookie . * * @ param path path of the cookie * @ param name name of the cookie * @ param value value of the cookie * @ param maxAge max age of the cookie in seconds ( negative for the not persistent cookie , zero - deletes the cookie ) * @ param secured if true : cookie will be secured * zero - deletes the cookie ) * / public void cookie ( String path , String name , String value , int maxAge , boolean secured ) { cookie . setPath ( path ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["fix", "defect", "in", "unit", "test", "code"], "add_tokens": "AddToLastAll . add ( a , ZeroTo . get ( n ) ) ;", "del_tokens": "AddToLastAll . add ( a , ZeroTo . get ( 100 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "common", "code", "out", "to", "dhemery", "-", "common", "project"], "add_tokens": "import com . dhemery . publishing . Channel ; private final Channel publisher = new Channel ( ) ;", "del_tokens": "import com . dhemery . publishing . DistributingPublisher ; private final DistributingPublisher publisher = new DistributingPublisher ( ) ;", "commit_type": "move"}
{"commit_tokens": ["Change", "the", "Card", ".", "{", "cvc", "addressZip", "addressLine1", "}", "Check", "properties", "to", "strings"], "add_tokens": "String addressZipCheck ; String addressLine1Check ; String cvcCheck ; public String getAddressZipCheck ( ) { public void setAddressZipCheck ( String addressZipCheck ) { public String getAddressLine1Check ( ) { public void setAddressLine1Check ( String addressLine1Check ) { public String getCvcCheck ( ) { public void setCvcCheck ( String cvcCheck ) {", "del_tokens": "Boolean addressZipCheck ; Boolean addressLine1Check ; Boolean cvcCheck ; public Boolean getAddressZipCheck ( ) { public void setAddressZipCheck ( Boolean addressZipCheck ) { public Boolean getAddressLine1Check ( ) { public void setAddressLine1Check ( Boolean addressLine1Check ) { public Boolean getCvcCheck ( ) { public void setCvcCheck ( Boolean cvcCheck ) {", "commit_type": "change"}
{"commit_tokens": ["Fixed", "a", "stupid", "bug", "."], "add_tokens": "} else { // Start of a new group callback . startGroup ( current ) ;", "del_tokens": "// Start of a new group callback . startGroup ( current ) ; } else {", "commit_type": "fix"}
{"commit_tokens": ["Added", "clearing", "of", "cache", "at", "restart", "."], "add_tokens": "import com . googlecode . jsonrpc4j . * ; ReflectionUtil . clearCache ( ) ;", "del_tokens": "import com . googlecode . jsonrpc4j . ConvertedParameterTransformer ; import com . googlecode . jsonrpc4j . ErrorResolver ; import com . googlecode . jsonrpc4j . HttpStatusCodeProvider ; import com . googlecode . jsonrpc4j . InvocationListener ; import com . googlecode . jsonrpc4j . JsonRpcServer ; import com . googlecode . jsonrpc4j . ProxyUtil ;", "commit_type": "add"}
{"commit_tokens": ["remove", "duplicate", "method", "from", "TypeDeclaration"], "add_tokens": "return other . isAssignableBy ( this ) ;", "del_tokens": "return other . isAssignableBy ( this , typeSolver ) ; default boolean isAssignableBy ( TypeDeclaration other , TypeSolver typeSolver ) { return isAssignableBy ( new ReferenceTypeUsage ( other , typeSolver ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["fixed", "compiler", "warnings", "&", "console", "eating", "touches"], "add_tokens": "consoleWindow . setTouchable ( Touchable . disabled ) ; * Makes the console also log to the System when { @ link Console # log ( String ) } is called . * @ param log to the system", "del_tokens": "* Sets logging to system with System . out . println as well as console * @ param Log to the system", "commit_type": "fix"}
{"commit_tokens": ["add", "tests", "on", "BufferedReverseIOReading", "+", "fixes"], "add_tokens": "int len = skip - done ;", "del_tokens": "int len = skip ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "layout_width", "is", "parsed", "incorrectly"], "add_tokens": "layoutWidth = a . getLayoutDimension ( R . styleable . BootstrapButton_android_layout_width , 0 ) ;", "del_tokens": "layoutWidth = a . getInt ( R . styleable . BootstrapButton_android_layout_width , 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "dependency", "on", "actual", "converters", "from", "test", "of", "converter", "server", "builder", "."], "add_tokens": "import com . documents4j . conversion . msoffice . MicrosoftExcelBridge ; import com . documents4j . conversion . msoffice . MicrosoftWordBridge ; import com . documents4j . job . PseudoConverter ; HttpServer httpServer = ConverterServerBuilder . builder ( ) . disable ( MicrosoftWordBridge . class ) . disable ( MicrosoftExcelBridge . class ) . enable ( PseudoConverter . class ) . baseUri ( String . format ( \"http://localhost:%d\" , port ) ) . build ( ) ;", "del_tokens": "HttpServer httpServer = ConverterServerBuilder . make ( String . format ( \"http://localhost:%d\" , port ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "mappings", "for", "the", "view", "id"], "add_tokens": "import java . util . Collections ; import java . util . Map ; * This really is an implementation of the { @ link CasLoginViewSelector } * existence of a particular parameter . private Map < String , String > viewMappings = Collections . emptyMap ( ) ; final String key = request . getRequestParameters ( ) . get ( parameterName ) ; if ( this . viewMappings . containsKey ( key ) ) { return this . viewMappings . get ( key ) ; } public final Map < String , String > getViewMappings ( ) { return this . viewMappings ; } public final void setViewMappings ( final Map < String , String > viewMappings ) { this . viewMappings = viewMappings ; }", "del_tokens": "* This really is a < i > sample < / i > implementation of the { @ link CasLoginViewSelector } * existence of a particular parameter . By default the value of { @ link # setParameterName ( String ) } * is mapped to a view state in the flow that can be rendered . return request . getRequestParameters ( ) . get ( parameterName ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "possible", "NPE", "when", "writing", "an", "Is24CsvRecord"], "add_tokens": "{ this . setAdressdruck ( Boolean . valueOf ( value ) ) ; } public void setAdressdruck ( Boolean value ) Is24CsvFormat . printBoolean ( ( value != null ) ? value : false ) ) ; { this . setAktiv ( Boolean . valueOf ( value ) ) ; } public void setAktiv ( Boolean value ) ( value || value == null ) ? \"1\" : \"0\" ) ; { this . setProvisionpflichtig ( Boolean . valueOf ( value ) ) ; } public void setProvisionpflichtig ( Boolean value ) Is24CsvFormat . printBoolean ( ( value != null ) ? value : false ) ) ;", "del_tokens": "Is24CsvFormat . printBoolean ( value ) ) ; ( value ) ? \"1\" : \"0\" ) ; Is24CsvFormat . printBoolean ( value ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "support", "to", "schedule", "and", "run", "a", "job", "only", "once"], "add_tokens": "public static final String JOB_RUN_ONCE_KEY = \"job.runonce\" ; public static final String JOB_CONFIG_FILE_PATH_KEY = \"job.config.path\" ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "property", "instead", "of", "field"], "add_tokens": "ObjectCache . remove ( resource ) ; . wl_resource_set_dispatcher ( getNative ( ) , . wl_resource_get_version ( getNative ( ) ) ; . wl_resource_get_client ( getNative ( ) ) ) ; . wl_resource_get_id ( getNative ( ) ) ; . wl_resource_add_destroy_listener ( getNative ( ) , . wl_resource_destroy ( getNative ( ) ) ; . wl_resource_post_event_array ( getNative ( ) , . wl_resource_post_event_array ( getNative ( ) , . wl_resource_post_error ( getNative ( ) ,", "del_tokens": "ObjectCache . remove ( getNative ( ) ) ; . wl_resource_set_dispatcher ( this . pointer , . wl_resource_get_version ( this . pointer ) ; . wl_resource_get_client ( this . pointer ) ) ; . wl_resource_get_id ( this . pointer ) ; . wl_resource_add_destroy_listener ( this . pointer , . wl_resource_destroy ( this . pointer ) ; . wl_resource_post_event_array ( this . pointer , . wl_resource_post_event_array ( this . pointer , . wl_resource_post_error ( this . pointer ,", "commit_type": "use"}
{"commit_tokens": ["Added", "additional", "alternative", "article", "source", "file", ":", "pages", "-", "meta", "-", "history", ".", "xml"], "add_tokens": "* private final static String INPUT_PAGESMETAHISTORY = \"pages-meta-history.xml\" ; private File inputPagesMetaHistory = null ; } else if ( currentFileName . contains ( INPUT_PAGESMETAHISTORY ) ) { inputPagesMetaHistory = currentFile ; return ! ( ( inputPagesarticles == null && inputPagesMetaCurrent == null && inputPagesMetaHistory == null ) *", "del_tokens": "* return ! ( ( inputPagesarticles == null && inputPagesMetaCurrent == null ) *", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "perf", "test", "that", "meant", "all", "jobs", "shared", "the", "same", "session", ".", "Also", "increase", "concurrency", "to", "4", "."], "add_tokens": "HasLessThan < ProcessWrapper > hasLessThen = new HasLessThan < ProcessWrapper > ( 4 ) ; for ( int i = 0 ; i < 10000 ; i ++ ) { pb . setProcessDetails ( new PerfRunner ( ) , \"run\" , new Class [ ] { } , new Object [ ] { } ) ;", "del_tokens": "HasLessThan < ProcessWrapper > hasLessThen = new HasLessThan < ProcessWrapper > ( 1 ) ; pb . setProcessDetails ( new PerfRunner ( ) , \"run\" , new Class [ ] { } , new Object [ ] { } ) ; for ( int i = 0 ; i < 1000 ; i ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "shortcut", "method", "which", "takes", "a", "callback", "and", "calls", "send"], "add_tokens": "onFailure ( new RestException ( \"An error occured. Status : \" + response . getStatusCode ( ) ) ) ;", "del_tokens": "throw new RestException ( \"An error occured. Status : \" + response . getStatusCode ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "Outlet", "to", "throw", "exception", "on", "set"], "add_tokens": "import com . beowulfe . hap . * ; public CompletableFuture < Void > setPowerState ( boolean state ) throws Exception ;", "del_tokens": "import com . beowulfe . hap . HomekitAccessory ; import com . beowulfe . hap . HomekitCharacteristicChangeCallback ; import com . beowulfe . hap . Service ; public CompletableFuture < Void > setPowerState ( boolean state ) ;", "commit_type": "allow"}
{"commit_tokens": ["Fix", "rename", "of", "WktParseException", "in", "geom"], "add_tokens": "import org . geolatte . geom . codec . WktDecodeException ; catch ( WktDecodeException e ) {", "del_tokens": "import org . geolatte . geom . codec . WktParseException ; catch ( WktParseException e ) {", "commit_type": "fix"}
{"commit_tokens": ["added", "hints", "and", "ordinalentries", "to", "importtest"], "add_tokens": "import com . github . katjahahn . sections . idata . OrdinalImport ; } else if ( entry . length == 4 ) { // ImportDLL entry if ( ! entry [ 3 ] . contains ( \"None\" ) ) { int ordinal = Integer . parseInt ( entry [ 3 ] ) ; OrdinalImport ord = new OrdinalImport ( ordinal , rva , null ) ; dll . add ( ord ) ; } else { int hint = Integer . parseInt ( entry [ 2 ] ) ; NameImport nameImp = new NameImport ( rva , name , hint , - 1 , null ) ; dll . add ( nameImp ) ; }", "del_tokens": "} else if ( entry . length == 2 ) { // ImportDLL entry dll . add ( new NameImport ( rva , name , - 1 , - 1 , null ) ) ; // hint, dirEntry and nameRVA are dummies", "commit_type": "add"}
{"commit_tokens": ["Fix", "race", "condition", "where", "a", "job", "status", "could", "be", "reset", "back", "to", "a", "RETRY", "even", "after"], "add_tokens": "updateSpec . getNonTransactionalGroup ( ) . includeJob ( jobRecord ) ; updateSpec . getFinalTransaction ( ) . includeJob ( jobRecord ) ; updateSpec . getFinalTransaction ( ) . registerTask ( task ) ; backEnd . saveWithJobStateCheck ( updateSpec , jobRecord . getQueueSettings ( ) , jobRecord . getKey ( ) , State . WAITING_TO_RUN , State . RETRY ) ;", "del_tokens": "updateSpec . getNonTransactionalGroup ( ) . includeJob ( jobRecord ) ; updateSpec . getNonTransactionalGroup ( ) . includeJob ( jobRecord ) ; updateSpec . getNonTransactionalGroup ( ) . includeJob ( rootJobRecord ) ; backEnd . save ( updateSpec , jobRecord . getQueueSettings ( ) ) ; backEnd . enqueue ( task ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "::", "fill"], "add_tokens": "public interface IndexWithReturnBlock < S > { public S yield ( Integer index ) ;", "del_tokens": "public interface ItemWithReturnBlock < E > { public E yield ( E item ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "to", "unit", "test", "so", "that", "it", "doesn", "t", "require", "the", "setup", "of", "multiple", "loopback", "devices", "."], "add_tokens": "import org . apache . log4j . Logger ; private static final Logger log = Logger . getLogger ( TenNodeThreeSeedTest . class ) ; log . info ( \"Adding seed nodes\" ) ; startupMembers . add ( new RemoteGossipMember ( \"127.0.0.1\" , 50000 + i , i + \"\" ) ) ; log . info ( \"Adding clients\" ) ; GossipService gossipService = new GossipService ( \"127.0.0.1\" , 50000 + i , i + \"\" ,", "del_tokens": "startupMembers . add ( new RemoteGossipMember ( \"127.0.0.\" + i , 2000 , i + \"\" ) ) ; GossipService gossipService = new GossipService ( \"127.0.0.\" + i , 2000 , i + \"\" ,", "commit_type": "change"}
{"commit_tokens": ["added", "HeaderUtil", "class", "to", "allow", "manipulation", "of", "header"], "add_tokens": "write ( HeaderUtil . generateDefaultHeader ( ) , writer ) ;", "del_tokens": "write ( generateHeader ( ) , writer ) ; protected Message generateHeader ( ) { Message header = new Message ( ) ; header . setMsgid ( \"\" ) ; header . addComment ( \"SOME DESCRIPTIVE TITLE.\" ) ; header . addComment ( \"Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER\" ) ; header . addComment ( \"This file is distributed under the same license as the PACKAGE package.\" ) ; header . addComment ( \"FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.\" ) ; header . addComment ( \"\" ) ; StringBuilder sb = new StringBuilder ( ) ; sb . append ( \"Project-Id-Version: PACKAGE VERSION\\n\" ) ; sb . append ( \"Report-Msgid-Bugs-To: \\n\" ) ; SimpleDateFormat dateFormat = new SimpleDateFormat ( \"yyyy-MM-dd HH:mmZ\" ) ; sb . append ( \"POT-Creation-Date: \" + dateFormat . format ( new Date ( ) ) + \"\\n\" ) ; sb . append ( \"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\\n\" ) ; sb . append ( \"Last-Translator: FULL NAME <EMAIL@ADDRESS>\\n\" ) ; sb . append ( \"Language-Team: LANGUAGE <LL@li.org>\\n\" ) ; sb . append ( \"MIME-Version: 1.0\\n\" ) ; sb . append ( \"Content-Type: text/plain; charset=UTF-8\\n\" ) ; sb . append ( \"Content-Transfer-Encoding: 8bit\\n\" ) ; header . setMsgstr ( sb . toString ( ) ) ; header . markFuzzy ( ) ; return header ; }", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "get", "prefix", "from", "method", "names", "."], "add_tokens": ". addMappingForUrlPatterns ( EnumSet . allOf ( DispatcherType . class ) , false , shiroConfig . filterUrlPattern ( ) ) ; shiroEnv . setConfigLocations ( shiroConfig . iniConfigs ( ) ) ;", "del_tokens": ". addMappingForUrlPatterns ( EnumSet . allOf ( DispatcherType . class ) , false , shiroConfig . getFilterUrlPattern ( ) ) ; shiroEnv . setConfigLocations ( shiroConfig . getIniConfigs ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["add", "system", "tmp", "directory", "constant", "and", "javadoc", "comments"], "add_tokens": "projectDirectory = Constants . workingDirectoryPath + File . separator + fileName . substring ( 0 , fileName . indexOf ( '.' ) ) ;", "del_tokens": "projectDirectory = Constants . zipDirectoryPath + File . separator + fileName . substring ( 0 , fileName . indexOf ( '.' ) ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "dependency", "on", "classes", "from", "repeat", "package"], "add_tokens": "* { @ link org . springframework . repeat . RepeatOperations } implementations to ensure that", "del_tokens": "import org . springframework . repeat . RepeatOperations ; * { @ link RetryOperations } implementations to ensure that", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "comment", "about", "the", "hash", "function", "."], "add_tokens": "/ * * The input data is specific ; it has low variance on lower bits and * high variance overall . We need to use a better hashing function * than simple identity . MurmurHash is good enough . * / final IntIntOpenHashMap map = new IntIntOpenHashMap ( IntIntOpenHashMap . DEFAULT_CAPACITY , IntIntOpenHashMap . DEFAULT_LOAD_FACTOR , new MurmurHashInt ( ) ) ;", "del_tokens": "// Note we're using a good hash function here, not identity hashing for integers. final IntIntOpenHashMap map = new IntIntOpenHashMap ( 16 , IntIntOpenHashMap . DEFAULT_LOAD_FACTOR , new MurmurHashInt ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "extra", "CLI", "options", "for", "debugging"], "add_tokens": "cliOptions . addOption ( \"ntc\" , \"no-test-cache\" , false , \"Do not load cached automatically generated test cases, regenerate them (Cached test cases are loaded by default)\" ) ; cliOptions . addOption ( \"nmt\" , \"no-manual-tests\" , false , \"Do not load any manually defined test cases (Manual test cases are loaded by default)\" ) ; boolean useTestCache = ! commandLine . hasOption ( \"nlc\" ) ; // for automatically generated test cases boolean useManualTestCases = ! commandLine . hasOption ( \"nmt\" ) ; //Use only automatic tests TestGeneratorExecutor testGeneratorExecutor = new TestGeneratorExecutor ( useTestCache , useManualTestCases ) ;", "del_tokens": "TestGeneratorExecutor testGeneratorExecutor = new TestGeneratorExecutor ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "noncharacter", "code", "points", "in", "unicode", "encoding", "and", "decoding"], "add_tokens": "* U + D800 . . U + DFFF ( surrogat pairs ) . && ( cp & ~ 0x7FF ) != 0xD800 ; // not in D800..DFFF; surrogate range", "del_tokens": "* U + D800 . . U + DFFF ( surrogat pairs ) , nor U + FFFE . . U + FFFF ( non - characters ) . && ( cp & ~ 0x7FF ) != 0xD800 // not in D800..DFFF; surrogate range && ( cp & ~ 1 ) != 0xFFFE ; // not in FFFE..FFFF; non-characters", "commit_type": "allow"}
{"commit_tokens": ["Added", "spring", "configuration", "to", "the", "Server", "side"], "add_tokens": ". valueOf ( \"{http://cxf.sample.esb.talend.org/}GreeterImplService\" ) ; public static final QName SERVICENAME1 = QName . valueOf ( \"{http://cxf.sample.esb.talend.org/}GreeterImplService\" ) ;", "del_tokens": ". valueOf ( \"{http://talend.org/esb/examples/}GreeterService\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "functionality", "to", "watchdog", "aspect", ".", "Watchdog", "Annotation", "now", "have", "optional", "id", "and", "suppressThrowsExceptions", "attributes", "."], "add_tokens": "import java . lang . reflect . Method ; import org . apache . commons . lang3 . builder . ReflectionToStringBuilder ; import org . aspectj . lang . reflect . MethodSignature ; // output parameters parameters . add ( attr == null ? null : ReflectionToStringBuilder . reflectionToString ( attr ) ) ; // output called instance String deSerializedInstance ; Object targetInstance = watchdogDataWrapper . getProceedingJoinPoint ( ) . getTarget ( ) ; if ( targetInstance != null ) { deSerializedInstance = ReflectionToStringBuilder . reflectionToString ( targetInstance ) ; } else { deSerializedInstance = null ; } return new WatchdogCategory ( watchdogDataWrapper . getAnnotatedId ( ) , clazz , method , parameters , deSerializedInstance ) ;", "del_tokens": "parameters . add ( attr == null ? null : attr . toString ( ) ) ; final String deserializedInstance = null ; return new WatchdogCategory ( clazz , method , parameters , deserializedInstance ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "horizontal", "infinite", "map", "rendering", "optional", "."], "add_tokens": "private boolean infiniteMapRendering = true ; return ( y >= 0 && y < mapSize . getHeight ( ) ) && ( isInfiniteMapRendering ( ) || x >= 0 && x < mapSize . getWidth ( ) ) ; / * * * Side note : This setting is ignored when horizontaklWrapped is set to true . * * @ param infiniteMapRendering true when infinite map rendering should be enabled * / public void setInfiniteMapRendering ( boolean infiniteMapRendering ) { this . infiniteMapRendering = infiniteMapRendering ; } / * * * @ return true if infinite map rendering is enabled * / public boolean isInfiniteMapRendering ( ) { return horizontalWrapped || infiniteMapRendering ; }", "del_tokens": "return y >= 0 && y < mapSize . getHeight ( ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "cache", "for", "annotation", "mapper"], "add_tokens": "return new String [ ] { \"org.binwang.bard.core.defines\" , \"org.binwang.bard.core.AdapterTest\" } ; servlet . removeHandler ( AllTrueAdapterHandler . class ) ; servlet . removeHandler ( AllFalseAdapterHandler . class ) ; servlet . removeHandler ( AdapterHandler . class ) ; servlet . removeHandler ( ClassAdpaterHandler . class ) ;", "del_tokens": "return new String [ ] { \"org.binwang.bard.core.defines\" } ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "wrong", "version", "reference", "in", "comment"], "add_tokens": "// i have this test, which fails in 0.3.2", "del_tokens": "// i have this test, which fails in 0.3.3", "commit_type": "fix"}
{"commit_tokens": ["Add", "isLoggable", "check", "for", "trace", "messages"], "add_tokens": "if ( logger . isLoggable ( LogLevel . TRACE ) ) logger . trace ( \"destination \" + remote + \" ready for use\" ) ; if ( logger . isLoggable ( LogLevel . TRACE ) ) logger . trace ( \"connected with \" + d . getAddress ( ) ) ; if ( logger . isLoggable ( LogLevel . TRACE ) ) logger . trace ( \"send disconnect to \" + sender ) ; if ( logger . isLoggable ( LogLevel . TRACE ) ) logger . trace ( \"positive ack by \" + d . getAddress ( ) ) ; if ( logger . isLoggable ( LogLevel . TRACE ) ) logger . trace ( \"disconnected from \" + p . getDestination ( ) . getAddress ( ) ) ;", "del_tokens": "logger . trace ( \"destination \" + remote + \" ready for use\" ) ; logger . trace ( \"connected with \" + d . getAddress ( ) ) ; logger . trace ( \"send disconnect to \" + sender ) ; logger . trace ( \"positive ack by \" + d . getAddress ( ) ) ; logger . trace ( \"disconnected from \" + p . getDestination ( ) . getAddress ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "JsonIgnore", "to", "the", "rest", "of", "the", "potential", "string", "fields"], "add_tokens": "@ JsonIgnore @ JsonIgnore @ JsonIgnore @ JsonIgnore @ JsonIgnore @ JsonIgnore", "del_tokens": "@ JsonProperty ( \"communicationMethod\" ) @ JsonProperty ( \"location\" ) @ JsonProperty ( \"type\" )", "commit_type": "add"}
{"commit_tokens": ["added", "more", "logging", "to", "PartitionedDataStore", ".", "java"], "add_tokens": "\" partitionCapacity=\" + _partitionCapacity + \" segmentFactory=\" + segFactory . getClass ( ) . getName ( ) + \" segmentFileSizeMB=\" + segFileSizeMB + \"MB\" ) ;", "del_tokens": "\" partitionCapacity=\" + _partitionCapacity ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "inconsistency", "in", "showing", "stacktrace", "between", "WSProvide", "and", "WSConsume"], "add_tokens": "* < tr > < td > - v , -- verbose < / td > < td > Show full exception stack traces < / td > < / tr > private boolean verbose ; new LongOpt ( \"verbose\" , LongOpt . NO_ARGUMENT , null , 'v' ) , case 'v' : verbose = true ; break ; System . err . println ( \"Error: Could not generate. (use --show-traces or --verbose to see full traces)\" ) ; if ( ! showTraces && ! verbose ) out . println ( \" -v, --verbose Show full exception stack traces\" ) ;", "del_tokens": "System . err . println ( \"Error: Could not generate. (use --show-traces to see full traces)\" ) ; if ( ! showTraces )", "commit_type": "fix"}
{"commit_tokens": ["Add", "SubListSerializers", ".", "addDefaultSerializers", "for", "easier", "registration", "."], "add_tokens": "/ * * * Adds appropriate sublist serializers as default serializers . * / public static Kryo addDefaultSerializers ( Kryo kryo ) { ArrayListSubListSerializer . addDefaultSerializer ( kryo ) ; JavaUtilSubListSerializer . addDefaultSerializer ( kryo ) ; return kryo ; } public static final Class < ? > SUBLIST_CLASS = SubListSerializers . getClassOrNull ( \"java.util.ArrayList$SubList\" ) ; public static Kryo addDefaultSerializer ( Kryo kryo ) { if ( SUBLIST_CLASS != null ) kryo . addDefaultSerializer ( SUBLIST_CLASS , new ArrayListSubListSerializer ( ) ) ; return kryo ; } public static final Class < ? > SUBLIST_CLASS = SubListSerializers . getClassOrNull ( \"java.util.SubList\" ) ; public static Kryo addDefaultSerializer ( Kryo kryo ) { if ( SUBLIST_CLASS != null ) kryo . addDefaultSerializer ( SUBLIST_CLASS , new JavaUtilSubListSerializer ( ) ) ; return kryo ; }", "del_tokens": "private static final Class < ? > SUBLIST_CLASS = SubListSerializers . getClassOrNull ( \"java.util.ArrayList$SubList\" ) ; private static final Class < ? > SUBLIST_CLASS = SubListSerializers . getClassOrNull ( \"java.util.SubList\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "some", "JavaDocto", "the", "Twitter", "package", "."], "add_tokens": "/ * * * Represents a Twitter status update ( e . g . , a \"tweet\" ) . * * @ author Craig Walls * /", "del_tokens": "/ * * TO CONSIDER : Tweets may also have extra metadata and geolocation * information . I 'm leaving those out for now, because very few tweets seem * to have much useful for those fields . After some bit of searching , I * did find a few tweets that had geolocation that resembled the following : * * geo : { type : \"Point\" , coordinates : [ 14.6167 , 120.9667 ] } * * But I 'm unclar on what other types there may be, what that data may look * like , and whether it 's even important given that such a relative few * tweets will have that info in it . * /", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "plugin", "and", "app", "loading", "and", "handling", "a", "bit", "simpler"], "add_tokens": "* Copyright ( c ) 2019 - present Martin Paljak", "del_tokens": "* Copyright ( c ) 2019 - 2020 Martin Paljak", "commit_type": "make"}
{"commit_tokens": ["fixed", "Platform", "to", "add", "URL", "patterns", "for", "filters", "."], "add_tokens": "import javax . servlet . FilterRegistration ; import io . graceland . filter . FilterPattern ; registerFilterSpec ( environment , filterSpec ) ; private void registerFilterSpec ( Environment environment , FilterSpec filterSpec ) { FilterRegistration . Dynamic dynamic = environment . servlets ( ) . addFilter ( filterSpec . getName ( ) , filterSpec . getFilter ( ) ) ; for ( FilterPattern pattern : filterSpec . getPatterns ( ) ) { for ( String urlPattern : pattern . getUrlPatterns ( ) ) { dynamic . addMappingForUrlPatterns ( pattern . getDispatcherTypes ( ) , pattern . isMatchAfter ( ) , urlPattern ) ; } } }", "del_tokens": "environment . servlets ( ) . addFilter ( filterSpec . getName ( ) , filterSpec . getFilter ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "handling", "integer", "underflows", "and", "overflows"], "add_tokens": "import java . math . BigInteger ; int average = avg ( min , max ) ; int base = abs ( min - average ) ; int randomNumber ; if ( base != 0 ) { randomNumber = random . nextInt ( base ) ; } else { randomNumber = 0 ; } if ( random . nextBoolean ( ) ) { return average + randomNumber ; } else { return average - randomNumber ; } } private int abs ( int number ) { if ( number == Integer . MIN_VALUE ) { // -1 * MIN_VALUE will overflow return Integer . MAX_VALUE ; } else { return Math . abs ( number ) ; } } private int avg ( int first , int second ) { BigInteger firstInt = BigInteger . valueOf ( first ) ; BigInteger secondInt = BigInteger . valueOf ( second ) ; return firstInt . add ( secondInt ) . divide ( BigInteger . valueOf ( 2 ) ) . intValue ( ) ;", "del_tokens": "return min + random . nextInt ( Math . abs ( max - min ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "missed", "part", "of", "the", "test", "."], "add_tokens": "import java . util . List ; jaxb . add ( ClassKeyedComment . class ) ; Assert . assertEquals ( unmarshalled . getResolvedClass ( ) , theType ) ; final List < String > expectedLines = aComment . getCommentLines ( ) ; final List < String > receivedLines = unmarshalled . getComment ( ) . getCommentLines ( ) ; Assert . assertEquals ( expectedLines . size ( ) , receivedLines . size ( ) ) ; for ( int i = 0 ; i < expectedLines . size ( ) ; i ++ ) { Assert . assertEquals ( expectedLines . get ( i ) , receivedLines . get ( i ) ) ; }", "del_tokens": "// Assert.assertEquals(unmarshalled.getClass(), );", "commit_type": "add"}
{"commit_tokens": ["Add", "utility", "method", "to", "get", "ORule", ".", "ResourceGeneric", "by", "name"], "add_tokens": "ORule . ResourceGeneric value = OSecurityHelper . getResourceGeneric ( resource . value ( ) ) ; ORule . ResourceGeneric generic = OSecurityHelper . getResourceGeneric ( resource ) ;", "del_tokens": "ORule . ResourceGeneric value = ORule . ResourceGeneric . valueOf ( resource . value ( ) ) ; ORule . ResourceGeneric generic = ORule . ResourceGeneric . valueOf ( resource ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "the", "file", "to", "the", "right", "place"], "add_tokens": "package net . sf . jabb . util . stat ; assertIsDivisorOf ( \"1000 milliseconds\" , \"1 second\" , true ) ; assertIsDivisorOf ( \"1000 milliseconds\" , \"2 second\" , true ) ; assertIsDivisorOf ( \"2000 milliseconds\" , \"1 second\" , false ) ;", "del_tokens": "package net . sf . jabb . util . state ;", "commit_type": "move"}
{"commit_tokens": ["Make", "remaining", "private", "Parser", "members", "protected"], "add_tokens": "protected static final char CROSSED_OUT = '\\uffff' ; protected final int options ; protected final ParseRunnerProvider parseRunnerProvider ; protected static final String [ ] HTML_TAGS = new String [ ] { protected void fixIndices ( Node node , int [ ] ixMap ) { protected interface SuperNodeCreator {", "del_tokens": "private static final char CROSSED_OUT = '\\uffff' ; private final int options ; private final ParseRunnerProvider parseRunnerProvider ; private static final String [ ] HTML_TAGS = new String [ ] { private void fixIndices ( Node node , int [ ] ixMap ) { private interface SuperNodeCreator {", "commit_type": "make"}
{"commit_tokens": ["Updated", "EndianConversor", "to", "work", "with", "unsigned", "big", "endian", "types"], "add_tokens": "} public static void ushortToBigEndian ( int v , byte [ ] data , int dataIndex ) { data [ dataIndex ] = ( byte ) ( v >> 8 & 0xff ) ; ; data [ dataIndex + 1 ] = ( byte ) ( v & 0xff ) ; } public static int byteArrayBigEndianToUShort ( byte [ ] data , int dataIndex ) { return ( int ) byteArrayBigEndianToShort ( data , dataIndex ) ; } } public static void uintToBigEndian ( long v , byte [ ] data , int dataIndex ) { data [ dataIndex ] = ( byte ) ( v >> 24 ) ; data [ dataIndex + 1 ] = ( byte ) ( v >> 16 & 0xff ) ; data [ dataIndex + 2 ] = ( byte ) ( v >> 8 & 0xff ) ; data [ dataIndex + 3 ] = ( byte ) ( v & 0xff ) ; } public static long byteArrayBigEndianToUInt ( byte [ ] data , int dataIndex ) { return ( long ) byteArrayBigEndianToInt ( data , dataIndex ) ; }", "del_tokens": "} }", "commit_type": "update"}
{"commit_tokens": ["Fixing", "visibility", "of", "Java", "POJO", "to", "fix", "broken", "test"], "add_tokens": "public Integer property1 ; public Integer camelCaseProperty ; public JavaTestUDTBean nested ;", "del_tokens": "Integer property1 ; Integer camelCaseProperty ; JavaTestUDTBean nested ;", "commit_type": "fix"}
{"commit_tokens": ["Allow", "use", "of", "Proxy", "on", "Requests"], "add_tokens": "import java . net . * ; private Proxy proxy ; * * URL url = new URL ( effectiveUrl ) ; connection = ( HttpURLConnection ) ( proxy == null ? url . openConnection ( ) : url . openConnection ( proxy ) ) ; * * * * * * * * * * * * * * * * * * * * / * * * Set the proxy that will be used for the rquest * @ param proxy proxy to be used * / public void setProxy ( Proxy proxy ) { this . proxy = proxy ; }", "del_tokens": "import java . net . HttpURLConnection ; import java . net . MalformedURLException ; import java . net . URL ; * * connection = ( HttpURLConnection ) new URL ( effectiveUrl ) . openConnection ( ) ; * * * * * * * * * * * * * * * * * * * *", "commit_type": "allow"}
{"commit_tokens": ["removed", "trailing", "new", "line", "character"], "add_tokens": "commonspec . getLogger ( ) . info ( \"Ended running hooks\" ) ;", "del_tokens": "commonspec . getLogger ( ) . info ( \"Ended running hooks\\n\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Using", "FileUtils", "to", "determine", "user", "home", "directory"], "add_tokens": "DEFAULT_PROPS . put ( CACHE_KEY , FilenameUtils . concat ( FileUtils . getUserDirectory ( ) . getAbsolutePath ( ) , \".victims\" ) ) ;", "del_tokens": "DEFAULT_PROPS . put ( CACHE_KEY , FilenameUtils . concat ( System . getProperty ( \"user.home\" ) , \".victims\" ) ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "accesstoken", "header", "verifycation", "failure", "bug"], "add_tokens": "put ( \"access_token\" , tokenString ) ;", "del_tokens": "put ( \"accessToken\" , tokenString ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "documentation", "for", "new", "tagging"], "add_tokens": "import java . util . ArrayList ; ArrayList < String > tags = new ArrayList < String > ( ) ; tags . add ( \"tag1\" ) ; tags . add ( \"tag2\" ) ; branch . getShortUrl ( tags , \"channel1\" , \"feature1\" , \"1\" , obj , new BranchLinkCreateListener ( ) {", "del_tokens": "branch . getShortUrl ( \"tag\" , obj , new BranchLinkCreateListener ( ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "connection", "fetch", "in", "executor", "wrapper", "to", "support", "transaction", "context", "for", "advisory", "locks", "and", "timeouts"], "add_tokens": "import org . springframework . jdbc . datasource . DataSourceUtils ; // use do get connection for SQLExceptions sameConnDs = new SameConnectionDatasource ( DataSourceUtils . doGetConnection ( ds ) ) ;", "del_tokens": "sameConnDs = new SameConnectionDatasource ( ds . getConnection ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "explicit", "encodings", "to", "HTML", "document", "loader", "from", "URL", "and", "getter", "for"], "add_tokens": "return loadHTML ( url , \"UTF-8\" , false ) ; } @ Override public Document loadHTML ( URL url , String encoding ) throws IllegalArgumentException { notNull ( url , \"Source URL\" ) ; notNullOrEmpty ( encoding , \"Character encoding\" ) ; return loadHTML ( url , encoding , false ) ; return loadHTML ( url , \"UTF-8\" , true ) ; } @ Override public Document loadHTMLNS ( URL url , String encoding ) throws IllegalArgumentException { notNull ( url , \"Source URL\" ) ; notNullOrEmpty ( encoding , \"Character encoding\" ) ; return loadHTML ( url , encoding , true ) ; private static Document loadHTML ( URL url , String encoding , boolean useNamespace ) InputSource source = new InputSource ( stream ) ; source . setEncoding ( encoding ) ; return loadHTML ( source , useNamespace ) ;", "del_tokens": "return loadHTML ( url , false ) ; return loadHTML ( url , true ) ; private static Document loadHTML ( URL url , boolean useNamespace ) return loadHTML ( new InputSource ( stream ) , useNamespace ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "geo", "hash", "width", "and", "height", "functions"], "add_tokens": "private static final double PRECISION_2 = 0.0001 ; assertEquals ( 360.0 / 16 , GeoHash . getGeoHashWidthInDegrees ( 2 ) , PRECISION_2 ) ; assertEquals ( 360.0 / 128 , GeoHash . getGeoHashWidthInDegrees ( 3 ) , PRECISION_2 ) ; assertEquals ( 180.0 / 8 , GeoHash . getGeoHashHeightInDegrees ( 1 ) , PRECISION_2 ) ; assertEquals ( 180.0 / 64 , GeoHash . getGeoHashHeightInDegrees ( 2 ) , PRECISION_2 ) ; assertEquals ( 180.0 / 256 , GeoHash . getGeoHashHeightInDegrees ( 3 ) , PRECISION_2 ) ;", "del_tokens": "assertEquals ( 360.0 / 16 , GeoHash . getGeoHashWidthInDegrees ( 2 ) , 0.0001 ) ; assertEquals ( 360.0 / 128 , GeoHash . getGeoHashWidthInDegrees ( 3 ) , 0.0001 ) ; assertEquals ( 180.0 / 8 , GeoHash . getGeoHashHeightInDegrees ( 1 ) , 0.0001 ) ; assertEquals ( 180.0 / 64 , GeoHash . getGeoHashHeightInDegrees ( 2 ) , 0.0001 ) ; assertEquals ( 180.0 / 256 , GeoHash . getGeoHashHeightInDegrees ( 3 ) , 0.0001 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "test", "failures", "on", "Mac", "OS", "X"], "add_tokens": "private int numNodes = 100 ; private int numVBuckets = 4096 ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; if ( System . getProperty ( \"os.name\" ) . equals ( \"Mac OS X\" ) ) { numNodes = 4 ; numVBuckets = 10 ; } } CouchbaseMock mock = new CouchbaseMock ( null , 8091 , numNodes , numVBuckets ) ; CouchbaseMock mock = new CouchbaseMock ( null , 8091 , numNodes , numVBuckets , \"xxx:,yyy:pass,zzz\" ) ; CouchbaseMock mock = new CouchbaseMock ( null , 8091 , numNodes , numVBuckets , \"xxx::,yyy::memcache,zzz,kkk::couchbase,aaa::unknown\" ) ; CouchbaseMock mock = new CouchbaseMock ( null , 8091 , numNodes , numVBuckets , \"xxx:pass:memcache,yyy:secret:couchbase\" ) ;", "del_tokens": "CouchbaseMock mock = new CouchbaseMock ( null , 8091 , 100 , 4096 ) ; CouchbaseMock mock = new CouchbaseMock ( null , 8091 , 100 , 4096 , \"xxx:,yyy:pass,zzz\" ) ; CouchbaseMock mock = new CouchbaseMock ( null , 8091 , 100 , 4096 , \"xxx::,yyy::memcache,zzz,kkk::couchbase,aaa::unknown\" ) ; CouchbaseMock mock = new CouchbaseMock ( null , 8091 , 100 , 4096 , \"xxx:pass:memcache,yyy:secret:couchbase\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "JavaDoc", "for", "java", "8"], "add_tokens": "* * See the reference documentation at * http : //developers.google.com/google-apps/calendar/v3/reference/</a>. * < br > * Requires one of the following OAuth scope ( s ) : * < ul > * < li > https : //www.googleapis.com/auth/calendar.readonly</li> * < li > https : //www.googleapis.com/auth/calendar</li> * < / ul > * < a href = \"http://developers.google.com/google-apps/calendar/auth\" > http : //developers.google.com/google-apps/calendar/auth</a> * for details about the different scopes . *", "del_tokens": "* < p > See the reference documentation at * http : //developers.google.com/google-apps/calendar/v3/reference/</a>.</p> * < p > Requires one of the following OAuth scope ( s ) : * < ul > * < li > https : //www.googleapis.com/auth/calendar.readonly</li> * < li > https : //www.googleapis.com/auth/calendar</li> * < / ul > * < a href = \"http://developers.google.com/google-apps/calendar/auth\" > * http : //developers.google.com/google-apps/calendar/auth</a> * for details about the different scopes . < / p >", "commit_type": "fix"}
{"commit_tokens": ["make", "sure", "the", "parameter", "s", "order", "is", "consistent", "in", "the", "final", "document"], "add_tokens": "List < MustacheParameterSet > list = new ArrayList < MustacheParameterSet > ( ) ;", "del_tokens": "List < MustacheParameterSet > list = new LinkedList < MustacheParameterSet > ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Improve", "JMH", "benchmarks", "add", "results", "to", "READMEs"], "add_tokens": "@ Warmup ( iterations = 5 , time = 1 , timeUnit = TimeUnit . SECONDS ) @ Measurement ( iterations = 10 , time = 1 , timeUnit = TimeUnit . SECONDS ) . maxRate ( 1 ) . every ( Duration . standardSeconds ( 1000 ) )", "del_tokens": ". maxRate ( 5 ) . every ( Duration . standardSeconds ( 10 ) )", "commit_type": "improve"}
{"commit_tokens": ["use", "constant", "instead", "of", "hardcode", "in", "ssl", "config"], "add_tokens": "trustServerCertificate ( DriverConstants . TRUST_PARAM_NAME , DriverConstants . DEFAULT_TRUST_SERVER_CERTIFICATE , Type . BOOLEAN ) ,", "del_tokens": "trustServerCertificate ( DriverConstants . TRUST_PARAM_NAME , false , Type . BOOLEAN ) ,", "commit_type": "use"}
{"commit_tokens": ["Fixed", "problem", "with", "zero", "color"], "add_tokens": "boolean fullRange = ( minValue < 0 && getSkinnable ( ) . getMaxValue ( ) > 0 ) ; double tickLabelFontSize = decimals == 0 ? 0.054 * size : 0.051 * size ; double tickMarkFontSize = decimals == 0 ? 0.047 * size : 0.044 * size ; if ( fullRange ) { ticksAndSections . setFill ( zeroColor ) ; } else { ticksAndSections . setFill ( tickLabelSectionsVisible ? Helper . getColorOfSection ( tickLabelSections , counter , tickLabelColor ) : tickLabelColor ) ; } ;", "del_tokens": "boolean fullRange = ( minValue < 0 && getSkinnable ( ) . getMaxValue ( ) > 0 ) ; double tickLabelFontSize = decimals == 0 ? 0.054 * size : 0.051 * size ; double tickMarkFontSize = decimals == 0 ? 0.047 * size : 0.044 * size ; if ( fullRange ) ticksAndSections . setFill ( zeroColor ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "GZIP", "CORS", "and", "caching", "filters"], "add_tokens": "boolean enableRestFilter = apiSec != null && \"enabled\" . equals ( apiSec . unwrapped ( ) ) ;", "del_tokens": "boolean enableRestFilter = apiSec != null && \"enabled\" . equals ( apiSec . toString ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "file", "encoding", "issue", "."], "add_tokens": "package com . tjeannin . provigen ; public class InvalidContractException extends Exception { public InvalidContractException ( String string ) { super ( string ) ; } / * * * Version UID . * / private static final long serialVersionUID = 721098022483610058L ; }", "del_tokens": "package com . tjeannin . provigen ; public class InvalidContractException extends Exception { public InvalidContractException ( String string ) { super ( string ) ; } / * * * Version UID . * / private static final long serialVersionUID = 721098022483610058L ; }", "commit_type": "fix"}
{"commit_tokens": ["make", "POS", "tag", "matching", "work", ";", "verbose", "mode"], "add_tokens": "/ * * * A part of a pattern that matches a part - of - speech tag . * Typically built from patterns like < code > JJ < / code > or < code > NNS < / code > . * * @ author Daniel Naber * / POSElement ( String token ) { this . tokens = new String [ ] { token } ; } POSElement ( String [ ] tokens ) { this . tokens = tokens ; }", "del_tokens": "//FIXME", "commit_type": "make"}
{"commit_tokens": ["Fix", "issue", "with", "status", "NO_CONTENT"], "add_tokens": "import static org . apache . http . HttpStatus . SC_NO_CONTENT ; if ( status != SC_NO_CONTENT ) { response . setEntity ( new StringEntity ( \"\" ) ) ; }", "del_tokens": "response . setEntity ( new StringEntity ( \"\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "dev", "domain", "from", "Consants"], "add_tokens": "public static final String BLOCKSCORE_DOMAIN = \"https://api.blockscore.com\" ;", "del_tokens": "private static final boolean DEBUG_MODE = false ; private static final String BLOCKSCORE_DOMAIN = \"https://api.blockscore.com\" ; private static final String BLOCKSCORE_DEV_DOMAIN = \"http://127.0.0.1:5400\" ; / * * * Gets the domain to use for testing this API client . ( DO NOT RELEASE IN DEBUG MODE ! ) * @ return Debug domain if we are in debug mode . * / @ NotNull public static String getDomain ( ) { if ( DEBUG_MODE ) { return BLOCKSCORE_DEV_DOMAIN ; } else { return BLOCKSCORE_DOMAIN ; } }", "commit_type": "remove"}
{"commit_tokens": ["Implemented", "feature", "to", "ignore", "properties", "regardless", "of", "type", "or", "place", "in", "the", "hierarchy"], "add_tokens": "/ * * * @ author Daniel Bechler * / To propertyNames ( String ... propertyNames ) ;", "del_tokens": "/** @author Daniel Bechler */", "commit_type": "implement"}
{"commit_tokens": ["Fix", "debug", "logging", "in", "OperationWithRetry", ".", "The", "%s", "for", "the", "exception", "is", "implied", "."], "add_tokens": "log . debug ( \"Retrying after catching exception\" , ioe ) ; log . debug ( \"Not retrying after catching exception\" , ioe ) ; log . debug ( \"Exhausted retries. lastException was: \" , lastException ) ;", "del_tokens": "log . debug ( \"Retrying after catching exception %s\" , ioe ) ; log . debug ( \"Not retrying after catching exception %s\" , ioe ) ; log . debug ( \"Exhausted retries. lastException was %s\" , lastException ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "lint", "warning", "for", "preference", "commit"], "add_tokens": "prefs . edit ( ) . putString ( \"braintreeUUID\" , uuid ) . apply ( ) ;", "del_tokens": "prefs . edit ( ) . putString ( \"braintreeUUID\" , uuid ) . commit ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "crash", "when", "using", "try", "-", "with", "-", "resource", "with", "an", "empty", "try", "block", "."], "add_tokens": "if ( tryTree . getBlock ( ) != null ) { result . addAll ( getSafeInitMethods ( tryTree . getBlock ( ) , classSymbol , state ) ) ; } if ( tryTree . getFinallyBlock ( ) != null ) { result . addAll ( getSafeInitMethods ( tryTree . getFinallyBlock ( ) , classSymbol , state ) ) ; }", "del_tokens": "result . addAll ( getSafeInitMethods ( tryTree . getBlock ( ) , classSymbol , state ) ) ; result . addAll ( getSafeInitMethods ( tryTree . getFinallyBlock ( ) , classSymbol , state ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "OptionsAwareModule", "wiring", "interface", "for", "gucie", "modules"], "add_tokens": "import ru . vyarus . dropwizard . guice . module . context . option . Options ; ConfigurationAwareModule < C > , OptionsAwareModule { private Options options ; @ Override public void setOptions ( final Options options ) { this . options = options ; } / * * * @ return options accessor object * / protected Options options ( ) { return options ; }", "del_tokens": "ConfigurationAwareModule < C > {", "commit_type": "add"}
{"commit_tokens": ["Added", "one", "more", "overloaded", "method", "to", "check", "emptiness", "of", "a", "string"], "add_tokens": "@ Test public void notEmpty_checkReferenceIsSame_withString ( ) { final String text = \"beer tastes good\" ; Assert . assertSame ( text , Check . notEmpty ( text ) ) ; Assert . assertSame ( text , Check . notEmpty ( text , \"text\" ) ) ; } @ Test ( expected = IllegalEmptyArgumentException . class ) public void notEmpty_emptyText_isInvalid ( ) { final String text = \"\" ; Check . notEmpty ( text ) ; } public void notEmpty_emptyText_withArgName_isInvalid ( ) { public void notEmpty_withNullReference_isInvalid ( ) { Check . notEmpty ( ( String ) null ) ; } @ Test ( expected = IllegalNullArgumentException . class ) public void notEmpty_withNullReference_withArgName_isInvalid ( ) {", "del_tokens": "public void notEmpty_emptyText_withArgName_isValid ( ) { public void notEmpty_withNullReference_withArgName_isValid ( ) {", "commit_type": "add"}
{"commit_tokens": ["remove", "throw", "error", "in", "get", "instance", "cause", "it", "is", "freaking", "annoying"], "add_tokens": "* You need to call { @ link # setInstance ( Cache ) } to create instance with custom caching * If you don 't, this method will create a new instance without custom caching public static GuildWars2 getInstance ( ) { if ( instance == null ) instance = new GuildWars2 ( ) ;", "del_tokens": "* You need to call { @ link # setInstance ( ) } or { @ link # setInstance ( Cache ) } to create instance , * if this is the first time you try to run this class * @ throws GuildWars2Exception instance not initialized public static GuildWars2 getInstance ( ) throws GuildWars2Exception { if ( instance == null ) throw new GuildWars2Exception ( ErrorCode . Other , \"Instance not initialized\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "Markup", "-", "dependent", "specifiers", "on", "tables", "(", "AsciiDoc", ":", "header", "style", "on", "name", "column", "&", "vertically", "centered", "columns", ")"], "add_tokens": "* Optionally prefix all anchors for unicity", "del_tokens": "* Pptionally prefix all anchors for unicity", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "new", "parametrized", "operation", "API"], "add_tokens": "import org . fit . layout . impl . BaseBoxTreeProvider ; public class CSSBoxTreeProvider extends BaseBoxTreeProvider", "del_tokens": "import org . fit . layout . api . BoxTreeProvider ; import org . fit . layout . impl . BaseParametrizedOperation ; public class CSSBoxTreeProvider extends BaseParametrizedOperation implements BoxTreeProvider", "commit_type": "use"}
{"commit_tokens": ["Add", "buckets", "to", "the", "byte", "array", "params", "."], "add_tokens": "import android . util . SparseIntArray ; public static final int DEFAULT_MAX_BYTE_ARRAY_SIZE = 4 * ByteConstants . MB ; public static SparseIntArray generateBuckets ( int min , int max ) { SparseIntArray buckets = new SparseIntArray ( ) ; for ( int i = min ; i <= max ; i *= 2 ) { buckets . put ( i , 1 ) ; } return buckets ; } generateBuckets ( DEFAULT_MIN_BYTE_ARRAY_SIZE , DEFAULT_MAX_BYTE_ARRAY_SIZE ) ,", "del_tokens": "private static final int DEFAULT_MAX_BYTE_ARRAY_SIZE = 4 * ByteConstants . MB ; null ,", "commit_type": "add"}
{"commit_tokens": ["added", "the", "pages", "for", "the", "user"], "add_tokens": "BookmarkablePageLink < UserDetailsPage > viewUserLink = new BookmarkablePageLink < UserDetailsPage > ( \"view-user\" , UserDetailsPage . class , actionsParameters ) ;", "del_tokens": "BookmarkablePageLink < ViewUserPage > viewUserLink = new BookmarkablePageLink < ViewUserPage > ( \"view-user\" , ViewUserPage . class , actionsParameters ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", "for", "next", "release"], "add_tokens": "public static final int ZMQ_VERSION_PATCH = 2 ;", "del_tokens": "public static final int ZMQ_VERSION_PATCH = 1 ;", "commit_type": "update"}
{"commit_tokens": ["Moved", "unused", "field", "to", "local", "variable", "so", "it", "s", "perfectly", "clear", "how", "it", "is", "used", "."], "add_tokens": "IntentFilter filter = null ;", "del_tokens": "private IntentFilter filter ;", "commit_type": "move"}
{"commit_tokens": ["fix", "the", "bug", "of", "display", "item", "with", "large", "margin", "top", "or", "margin", "bottom"], "add_tokens": "if ( getOrientation ( ) == VERTICAL ) { widthSpec = updateSpecWithExtra ( widthSpec , lp . leftMargin + mDecorInsets . left , } if ( getOrientation ( ) == HORIZONTAL ) { heightSpec = updateSpecWithExtra ( heightSpec , mDecorInsets . top , mDecorInsets . bottom ) ; }", "del_tokens": "widthSpec = updateSpecWithExtra ( widthSpec , lp . leftMargin + mDecorInsets . left , heightSpec = updateSpecWithExtra ( heightSpec , lp . topMargin + mDecorInsets . top , lp . bottomMargin + mDecorInsets . bottom ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "in", "-", "memory", "lru", "cache", "to", "handle", "etag", "despite", "the", "server", "returning", "no", "-", "store", "Cache", "-", "Control"], "add_tokens": "int cacheSize ; * < p > this . access_token = access_token ; return this ; * < p > * @ param api_key the HMAC API Key this . api_key = api_key ; this . api_secret = api_secret ; return this ; this . acct_id = acct_id ; return this ; * < p > * < p > * < p > / * * * Optional - specify the cache size to use for the lru in - memory cache * If you don 't specify one, the default cache size of 500kb will be used. In practice you shouldn' t need more than 250 kb . * @ param cacheSize an int representing the size in BYTES * * @ return this CoinbaseBuilder object * / public CoinbaseBuilder cacheSize ( int cacheSize ) { this . cacheSize = cacheSize ; return this ; }", "del_tokens": "* * this . access_token = access_token ; return this ; * * @ param api_key the HMAC API Key * this . api_key = api_key ; this . api_secret = api_secret ; return this ; * this . acct_id = acct_id ; return this ; * * * * * * * *", "commit_type": "add"}
{"commit_tokens": ["added", "html", "attribute", "to", "TypefaceTextView", "so", "that", "we", "support", "html", "formating"], "add_tokens": "import android . text . Html ; / * * * True if the supplied text should be displayed as html * / private boolean mHtmlEnabled ; loadAttributes ( context , null ) ; loadAttributes ( context , attrs ) ; loadAttributes ( context , attrs ) ; loadAttributes ( context , attrs ) ; } @ Override public void setText ( CharSequence text , BufferType type ) { if ( mHtmlEnabled ) { super . setText ( Html . fromHtml ( text . toString ( ) ) , type ) ; } else { super . setText ( text , type ) ; } private void loadAttributes ( Context context , AttributeSet attrs ) { mHtmlEnabled = styledAttrs . getBoolean ( R . styleable . TypefaceView_html , false ) ; if ( mHtmlEnabled ) { setText ( getText ( ) ) ; }", "del_tokens": "setCustomTypeface ( context , null ) ; setCustomTypeface ( context , attrs ) ; setCustomTypeface ( context , attrs ) ; setCustomTypeface ( context , attrs ) ; private void setCustomTypeface ( Context context , AttributeSet attrs ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "interaction", "test", ":", "use", "newer", "interaction", "."], "add_tokens": "public static final String SAMPLE_INTERACTION = \"getgluejava/2014-04-22T17:08:08Z\" ;", "del_tokens": "public static final String SAMPLE_INTERACTION = \"getgluejava/2013-10-24T18:30:38Z\" ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "internal", "graphics", "state", "for", "colors"], "add_tokens": "float lineWidth = transformLength ( ( float ) getGraphicsState ( ) . getLineWidth ( ) ) ; String color = colorString ( getGraphicsState ( ) . getStrokingColor ( ) ) ; String color = colorString ( getGraphicsState ( ) . getNonStrokingColor ( ) ) ; float lineWidth = transformLength ( ( float ) getGraphicsState ( ) . getLineWidth ( ) ) ; String color = colorString ( getGraphicsState ( ) . getNonStrokingColor ( ) ) ;", "del_tokens": "import org . apache . pdfbox . pdmodel . graphics . color . PDColor ; lineWidth = transformLength ( ( float ) getGraphicsState ( ) . getLineWidth ( ) ) ; String color = ( strokingColor == null ) ? \"#000000\" : strokingColor ; PDColor pcolor = getGraphicsState ( ) . getNonStrokingColor ( ) ; String color = \"#000000\" ; try { float [ ] rgb = pcolor . getColorSpace ( ) . toRGB ( pcolor . getComponents ( ) ) ; color = colorString ( rgb [ 0 ] , rgb [ 1 ] , rgb [ 2 ] ) ; } catch ( IOException e ) { // TODO Auto-generated catch block e . printStackTrace ( ) ; } //String color = style.getColor(); lineWidth = transformLength ( ( float ) getGraphicsState ( ) . getLineWidth ( ) ) ; String color = ( strokingColor == null ) ? \"#000000\" : strokingColor ;", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "appropriate", "local", "names", "in", "Hawk"], "add_tokens": "String persistedText = HAWK . storage . get ( key ) ; if ( persistedText == null ) { DataInfo dataInfo = DataHelper . getDataInfo ( persistedText ) ; String plainText = null ; plainText = HAWK . encryption . decrypt ( key , dataInfo . cipherText ) ; if ( plainText == null ) { return HAWK . converter . fromString ( plainText , dataInfo ) ; String plainText = HAWK . converter . toString ( value ) ; if ( plainText == null ) { cipherText = HAWK . encryption . encrypt ( key , plainText ) ;", "del_tokens": "String fullText = HAWK . storage . get ( key ) ; if ( fullText == null ) { DataInfo dataInfo = DataHelper . getDataInfo ( fullText ) ; String decryptedValue = null ; decryptedValue = HAWK . encryption . decrypt ( key , dataInfo . cipherText ) ; if ( decryptedValue == null ) { return HAWK . converter . fromString ( decryptedValue , dataInfo ) ; String encodedValue = HAWK . converter . toString ( value ) ; if ( encodedValue == null ) { cipherText = HAWK . encryption . encrypt ( key , encodedValue ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "more", "tests", "for", "fragmenttransactions", "replace", "/", "add"], "add_tokens": "@ RunWith ( AndroidJUnit4 . class ) public class BackstackActivityWithChildFragmentsTest { @ Rule public ActivityTestRule < BackstackActivityWithChildFragments > rule = new ActivityTestRule < > ( BackstackActivityWithChildFragments . class ) ; BackstackActivityWithChildFragments activity = rule . getActivity ( ) ; // Will call onStop() where we set the onbackStack flag", "del_tokens": "@ RunWith ( AndroidJUnit4 . class ) public class BackstackActivityTest { @ Rule public ActivityTestRule < BackstackActivity > rule = new ActivityTestRule < > ( BackstackActivity . class ) ; BackstackActivity activity = rule . getActivity ( ) ; // Will call onStop() where we set the onbackStackflag", "commit_type": "add"}
{"commit_tokens": ["Add", "constructors", "for", "Measurement", "."], "add_tokens": "private Range < TheUnit > mRange ; public Measurement ( ) { } public Measurement ( TheUnit value ) { this ( ) ; mValue = value ; } public Measurement ( TheUnit value , Range < TheUnit > range ) { this ( value ) ; mRange = range ; } return mRange != null ; public Range < TheUnit > getRange ( ) throws NoRangeException { if ( ! hasRange ( ) ) { throw new NoRangeException ( ) ; } return mRange ;", "del_tokens": "return true ; public Range < Double > getRange ( ) { return new Range < Double > ( 0.0 , 0.0 ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "issue", "with", "no", "menu"], "add_tokens": "private int mMenu = - 1 ; if ( mMenu == - 1 ) return ; if ( mMenu == - 1 ) return ; if ( mMenu == - 1 ) return ;", "del_tokens": "private int mMenu ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "the", "listener", "WizardDialog", ".", "WizardListener", "."], "add_tokens": "import java . util . LinkedHashSet ; import java . util . Set ; import de . mrapp . android . dialog . WizardDialog . WizardListener ; / * * * The listeners , which should be notified , when the user navigates within the dialog . * / private final Set < WizardListener > listeners ; this . fragments = new ArrayList < > ( ) ; this . listeners = new LinkedHashSet < > ( ) ; @ Override public final void addWizardListener ( @ NonNull final WizardListener listener ) { ensureNotNull ( listener , \"The listener may not be null\" ) ; listeners . add ( listener ) ; } @ Override public final void removeWizardListener ( @ NonNull final WizardListener listener ) { ensureNotNull ( listener , \"The listener may not be null\" ) ; listeners . remove ( listener ) ; }", "del_tokens": "fragments = new ArrayList < > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "depickling", "python", "datetime", "objects", "with", "dateutil", ".", "tz", ".", "tzutc", "objects", "as", "their", "timezone"], "add_tokens": "public static int DATEUTIL_TZUTC = 3 ; public static int TZINFO = 4 ; if ( this . pythontype == DATEUTIL_TZUTC ) return createInfoFromDateutilTzutc ( args ) ; if ( this . pythontype == TZINFO ) return createInfo ( args ) ; public Object reconstruct ( Object baseConstructor , Object state ) { if ( ! ( state instanceof Tzinfo ) ) throw new PickleException ( \"invalid pickle data for tzinfo reconstruction; expected emtpy tzinfo state class\" ) ; if ( ! ( baseConstructor instanceof TimeZoneConstructor ) ) throw new PickleException ( \"invalid pickle data for tzinfo reconstruction; expected a TimeZoneConstructor from a known tzinfo subclass\" ) ; // The subclass (this) is reconstructing the state given the base class and state. If it is known that the // subclass is always UTC, ie dateutil.tz.tzutc, then we can just return the timezone we know matches that. if ( this . pythontype == DATEUTIL_TZUTC ) { return TimeZone . getTimeZone ( \"UTC\" ) ; } else { throw new PickleException ( \"unsupported pickle data for tzinfo reconstruction; support for tzinfo subclasses other than tztuc has not been implemented\" ) ; } } private Object createInfo ( Object [ ] args ) { // args is empty, datetime.tzinfo objects are unpickled via setstate, so return an object which is ready to have it's state set return new Tzinfo ( ) ; } private Object createInfoFromDateutilTzutc ( Object [ ] args ) { // In the case of the dateutil.tz.tzutc constructor, which is a python subclass of the datetime.tzinfo class, there is no state // to set, because the zone is implied by the constructor. Pass the timezone indicated by hte constructor here return new Tzinfo ( TimeZone . getTimeZone ( \"UTC\" ) ) ; } throw new PickleException ( \"invalid pickle data for pytz timezone; expected 1 or 4 args, got \" + args . length ) ;", "del_tokens": "throw new PickleException ( \"invalid pickle data for pytz timezone; expected 2 or 4 args, got \" + args . length ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "vector", "transpose", "operation", "."], "add_tokens": "result . set ( 0 , i , getCoord ( i ) ) ;", "del_tokens": "result . set ( 1 , i , getCoord ( i ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "a", "TaggedHolder", "to", "allow", "for", "tag", "based", "reduce", "-", "side", "joins", ".", "Added", "RemoveProperties", "operation", "to", "remove", "properties", "from", "a", "vertex", "."], "add_tokens": "public class Holder < T extends FaunusElement > extends GenericWritable { public Holder ( ) { public Holder ( final T element ) {", "del_tokens": "public class ElementHolder < T extends FaunusElement > extends GenericWritable { public ElementHolder ( ) { public ElementHolder ( final T element ) {", "commit_type": "add"}
{"commit_tokens": ["Adds", "better", "handling", "of", "information", "being", "written", "to", "processing", "results", "file", "also", "simplifies", "the", "processFile", "()", "method", "a", "bit"], "add_tokens": "File resultFile = mapper . processFile ( fileToProcess ) ; assertTrue ( resultKey . toString ( ) . contains ( key . toString ( ) ) ) ; protected File processFile ( File file ) throws IOException {", "del_tokens": "import org . duracloud . services . hadoop . base . ProcessFileMapper ; File resultFile = mapper . processFile ( fileToProcess , \"fileName\" ) ; Text resultValue = collection . get ( resultKey ) ; assertNotNull ( resultValue ) ; assertTrue ( resultValue . toString ( ) . contains ( key . toString ( ) ) ) ; protected File processFile ( File file , String fileName ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Use", "hard", "coded", "status", "codes"], "add_tokens": "import tmp . texugo . util . StatusCodes ; setResponseCode ( 101 ) ; public void setResponseCode ( final int responseCode ) { final HeaderMap responseHeaders = this . responseHeaders ; final int responseCode = this . responseCode ; response . append ( StatusCodes . getReason ( responseCode ) ) ;", "del_tokens": "private String reasonPhrase = \"OK\" ; setResponseCode ( 101 , \"Switching Protocols\" ) ; / * * * @ return The reason phrase that is returned with the response * / public String getReasonPhrase ( ) { return reasonPhrase ; } * @ param reasonPhrase The reason phrase for this repsonse public void setResponseCode ( final int responseCode , final String reasonPhrase ) { this . reasonPhrase = reasonPhrase ; response . append ( reasonPhrase ) ;", "commit_type": "use"}
{"commit_tokens": ["remove", "line", "for", "the", "moment", "-", ">", "compile", "problems"], "add_tokens": "//when(openstackClient.launchInstance(anyString(), anyString(), anyString(), anyString(), anyList(), anyList(), anyString())).thenReturn(environment.getProperty(\"mocked_id\"));", "del_tokens": "when ( openstackClient . launch_instance ( anyString ( ) , anyString ( ) , anyString ( ) , anyString ( ) , anyList ( ) , anyList ( ) , anyString ( ) ) ) . thenReturn ( environment . getProperty ( \"mocked_id\" ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixed", "the", "rdf", "prefix", "comparision"], "add_tokens": "", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["fix", "ArrayValue", "ArrayIndexOutOfBoundsException", "since", "last", "commit"], "add_tokens": "value [ i ] = StatmentUtil . execute ( valueExprs [ i ] , context ) ; i ++ ;", "del_tokens": "value [ i ++ ] = StatmentUtil . execute ( valueExprs [ i ] , context ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "incorrect", "internal", "state", "management"], "add_tokens": "import static com . nominanuda . dataobject . DataStructHelper . STRUCT ; private Stack < DataStruct > parentHierarchy = null ; parentHierarchy = new Stack < DataStruct > ( ) ; parentHierarchy = null ; if ( STRUCT . isDataArray ( cur ) ) { parentHierarchy . pop ( ) ; cur = parentHierarchy . isEmpty ( ) ? null : parentHierarchy . peek ( ) ; if ( STRUCT . isDataArray ( cur ) ) { parentHierarchy . pop ( ) ; cur = parentHierarchy . isEmpty ( ) ? null : parentHierarchy . peek ( ) ; Check . illegalargument . assertTrue ( STRUCT . isPrimitiveOrNull ( value ) ) ; if ( STRUCT . isDataArray ( cur ) ) {", "del_tokens": "private final DataStructHelper dataStructHelper = new DataStructHelper ( ) ; private Stack < DataStruct > parentHierarchy = new Stack < DataStruct > ( ) ; if ( dataStructHelper . isDataArray ( cur ) ) { //cur = cur.getParent(); cur = parentHierarchy . pop ( ) ; if ( dataStructHelper . isDataArray ( cur ) ) { cur = parentHierarchy . pop ( ) ; // cur = cur.getParent(); Check . illegalargument . assertTrue ( dataStructHelper . isPrimitiveOrNull ( value ) ) ; if ( dataStructHelper . isDataArray ( cur ) ) {", "commit_type": "fix"}
{"commit_tokens": ["adding", "PMD", "to", "the", "build", "fixing", "some", "of", "its", "warnings"], "add_tokens": "globalTrackVisitRegistry ) ; HashMap < String , ArrayList < Integer > > hash , VisitRegistry globalRegistry ) throws Exception {", "del_tokens": "globalTrackVisitRegistry , markerAlgorithm ) ; HashMap < String , ArrayList < Integer > > hash , VisitRegistry globalRegistry , SlidingWindowMarkerAlgorithm marker ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "driver", "wasn", "t", "closed", "properly"], "add_tokens": "// check if a read partition is required Neo4JGraph graph ; if ( graphName != null ) { graph = new Neo4JGraph ( new AnyLabelReadPartition ( graphName ) , new String [ ] { graphName } , driver , database , vertexIdProvider , edgeIdProvider , configuration , readonly ) ; } else { // no graph name graph = new Neo4JGraph ( new NoReadPartition ( ) , new String [ ] { } , driver , database , vertexIdProvider , edgeIdProvider , configuration , readonly ) ; } // make sure driver gets closed properly graph . addCloseListener ( g -> driver . close ( ) ) ; return graph ;", "del_tokens": "// check a read partition is required if ( graphName != null ) return new Neo4JGraph ( new AnyLabelReadPartition ( graphName ) , new String [ ] { graphName } , driver , database , vertexIdProvider , edgeIdProvider , configuration , readonly ) ; // no graph name return new Neo4JGraph ( new NoReadPartition ( ) , new String [ ] { } , driver , database , vertexIdProvider , edgeIdProvider , configuration , readonly ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "ViewDragHelper", "state", "changes", "to", "the", "new", "Slidr", "Listener"], "add_tokens": "@ Override public void onSlideStateChanged ( int state ) { } @ Override public void onSlideChange ( float percent ) { } @ Override public void onSlideOpened ( ) { } @ Override public void onSlideClosed ( ) { }", "del_tokens": "@ Override public void onSlideChange ( float percent ) { } @ Override public void onSlideOpened ( ) { } @ Override public void onSlideClosed ( ) { }", "commit_type": "add"}
{"commit_tokens": ["adds", "the", "possibility", "to", "escape", "labels", "and", "removes", "the", "old", "non", "working", "escape", "code", "."], "add_tokens": "boolean commentEscaped = false ; if ( ! commentEscaped && ( c == MACRO_SEPARATOR || c == MACRO_END ) ) // end of name if ( ! commentEscaped && comment && c == MACRO_ESCAPE ) { commentEscaped = true ; } else if ( ! commentEscaped && c == MACRO_LABEL ) // start of comment commentEscaped = false ; } else if ( commentEscaped ) { commentEscaped = false ;", "del_tokens": "case MACRO_ESCAPE : // escaped text if ( message . hasNext ( ) ) { c = message . next ( ) ; } sb . append ( c ) ; if ( c == MACRO_SEPARATOR || c == MACRO_END ) // end of name if ( c == MACRO_LABEL ) // start of comment", "commit_type": "add"}
{"commit_tokens": ["Changed", "event", "equals", "semantics", "."], "add_tokens": "builder . append ( '#' ) ; builder . append ( Common . getId ( getClass ( ) , this ) ) ;", "del_tokens": "/ * ( non - Javadoc ) * @ see java . lang . Object # hashCode ( ) * / @ Override public int hashCode ( ) { return getMatchKey ( ) . hashCode ( ) ; } / * ( non - Javadoc ) * @ see java . lang . Object # equals ( java . lang . Object ) * / @ Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; Event < ? > other = ( Event < ? > ) obj ; if ( getMatchKey ( ) == null ) { if ( other . getMatchKey ( ) != null ) return false ; } else if ( ! getMatchKey ( ) . equals ( other . getMatchKey ( ) ) ) return false ; return true ; }", "commit_type": "change"}
{"commit_tokens": ["Improve", "response", "and", "request", "error", "handling", "."], "add_tokens": "return java . util . Optional . ofNullable ( exchange . getAttachment ( FormDataParser . FORM_DATA ) . get ( name ) ) . map ( Deque :: getFirst ) . map ( fv -> fv . getPath ( ) ) ; else if ( a instanceof javax . ws . rs . HEAD ) { return Methods . HEAD ; }", "del_tokens": "return java . util . Optional . ofNullable ( exchange . getAttachment ( FormDataParser . FORM_DATA ) . get ( name ) ) . map ( Deque :: getFirst ) . map ( fv -> fv . getFile ( ) . toPath ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "Claims", "mutation", "methods", "to", "JwtBuilder", "for", "convenience"], "add_tokens": "long seconds = ( ( Number ) v ) . longValue ( ) ; long millis = seconds * 1000 ; return new Date ( millis ) ; long seconds = Long . parseLong ( ( String ) v ) ; long millis = seconds * 1000 ; return new Date ( millis ) ;", "del_tokens": "int seconds = ( ( Number ) v ) . intValue ( ) ; return new Date ( seconds * 1000 ) ; int seconds = Integer . parseInt ( ( String ) v ) ; return new Date ( seconds * 1000 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "up", "stuff", "for", "gradle", "to", "compile", "things", "properly", "."], "add_tokens": "public static interface PathParam {", "del_tokens": "public interface PathParam {", "commit_type": "fix"}
{"commit_tokens": ["move", "source", "name", "accessor", "into", "result", "descriptor", "class"], "add_tokens": "import java . util . Set ; import org . opennms . newts . api . MetricType ; import org . opennms . newts . api . Sample ; private final Set < String > m_metrics ; public Rate ( Iterator < Row < Sample > > input , Set < String > metrics ) {", "del_tokens": "import org . opennms . newts . api . Sample ; private final String [ ] m_metrics ; public Rate ( Iterator < Row < Sample > > input , String [ ] metrics ) {", "commit_type": "move"}
{"commit_tokens": ["added", "some", "tests", "for", "JavaSource", "Code", "generation"], "add_tokens": "protected static final String TOKEN_PACKAGE = Grammars2JavaSourceCode . class + Grammars2JavaSourceCode . class . getSimpleName ( ) ; + Grammars2JavaSourceCode . class . getSimpleName ( ) ; static final String STATIC_SAMPLE_GRAMMAR = \"./com/siemens/ct/exi/grammars/persistency/Grammars2JavaSourceCodeTemplate.java\" ; // File staticSimpleGrammar = new File(STATIC_SAMPLE_GRAMMAR); ClassLoader classLoader = getClass ( ) . getClassLoader ( ) ; File staticSimpleGrammar = new File ( classLoader . getResource ( STATIC_SAMPLE_GRAMMAR ) . getFile ( ) ) ; String className = \"Notebook\" ; String xsd = \"./data/W3C/PrimerNotebook/notebook.xsd\" ; // String className = \"ISO15118_2_2013\"; // String xsd = \"..\\\\V2G_CI_MsgDef.xsd\"; Grammars2JavaSourceCode . class . getPackage ( ) . toString ( ) ,", "del_tokens": "protected static final String TOKEN_PACKAGE = Grammars2JavaSourceCodeTemplate . class + Grammars2JavaSourceCodeTemplate . class . getSimpleName ( ) ; + Grammars2JavaSourceCodeTemplate . class . getSimpleName ( ) ; static final String STATIC_SAMPLE_GRAMMAR = \"./src/main/java/com/siemens/ct/exi/grammars/persistency/Grammars2JavaSourceCodeTemplate.java\" ; File staticSimpleGrammar = new File ( STATIC_SAMPLE_GRAMMAR ) ; // String className = \"Notebook\"; // String xsd = \"./data/W3C/PrimerNotebook/notebook.xsd\"; String className = \"ISO15118_2_2013\" ; String xsd = \"..\\\\V2G_CI_MsgDef.xsd\" ; Grammars2JavaSourceCodeTemplate . class . getPackage ( ) . toString ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "workarround", "for", "a", "DB2", "driver", "bug", "."], "add_tokens": "if ( this . connection . getSql2o ( ) . quirksMode == QuirksMode . DB2 ) { // With the DB2 driver you can get an error if trying to put a date value into a timestamp column, // but of some reason it works if using setObject(). return addParameter ( name , ( Object ) value ) ; } else { Date sqlDate = value == null ? null : new Date ( value . getTime ( ) ) ; return addParameter ( name , sqlDate ) ; }", "del_tokens": "Date sqlDate = value == null ? null : new Date ( value . getTime ( ) ) ; return addParameter ( name , sqlDate ) ;", "commit_type": "add"}
{"commit_tokens": ["Using", "new", "IRI", "class", "to", "be", "resilient", "to", "variations", "in", "URL", "encoding", "."], "add_tokens": "import com . aoindustries . net . IRI ; IRI iri = new IRI ( url ) ; String hierPart = iri . getHierPart ( ) ; return iri . setHierPart ( shortenedHierPart ) . toASCIIString ( ) ; return iri . setHierPart ( shortenedHierPart ) . toASCIIString ( ) ;", "del_tokens": "import com . aoindustries . net . AnyURI ; // TODO: org.xbib.net.URL or org.apache.http.client.utils.URIBuilder AnyURI anyURI = new AnyURI ( url ) ; String hierPart = anyURI . getHierPart ( ) ; // TODO: This will fail on overly %-encoded paths, but they would be an anomaly anyway // TODO: This will fail on overly %-encoded paths, but they would be an anomaly anyway return anyURI . setHierPart ( shortenedHierPart ) . toString ( ) ; // TODO: This will fail on overly %-encoded paths, but they would be an anomaly anyway return anyURI . setHierPart ( shortenedHierPart ) . toString ( ) ; // TODO: AnyURI here and similar", "commit_type": "use"}
{"commit_tokens": ["Fixed", "missing", "native", "bindings", ".", "Extended", "basic", "binding", "test", "."], "add_tokens": "return checkResult ( cuPointerSetAttributeNative ( value , attribute , ptr ) ) ; return checkResult ( cuCtxGetSharedMemConfigNative ( pConfig ) ) ;", "del_tokens": "return checkResult ( cuPointerSetAttribute ( value , attribute , ptr ) ) ; return checkResult ( cuCtxGetSharedMemConfig ( pConfig ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "constant", "pool", "long", "/", "double", "storage", ".", "According", "to", "specification", "if", "long", "/", "double", "entry", "is", "stored", "in", "position", "n", "-", ">", "constant_pool", "index", "n", "+", "1", "must", "be", "valid", "but", "is", "considered", "unusable", "."], "add_tokens": "import org . vesalainen . bcc . ConstantInfo . Filler ; constant_pool . add ( new Filler ( ) ) ;", "del_tokens": "constant_pool . add ( new ConstantInfo . Filler ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "jar", "precedence", "rules", "match", "URLClassLoader"], "add_tokens": "private final List < URL > jars ; private URLClassLoader loader ; this . jars = new ArrayList < > ( Arrays . asList ( jars ) ) ; this . loader = new URLClassLoader ( jars , this . getClass ( ) . getClassLoader ( ) ) ; this . jars = new ArrayList < URL > ( Arrays . asList ( jars ) ) ; if ( ! this . jars . contains ( u ) ) { this . jars . add ( u ) ; // Note, URL class loader first looks in its parent, then in the array of // URLS passed in, in order. So, this line is equivalent to \"reaching into\" // URLClassLoader and adding the URLS to the end of the array.", "del_tokens": "private final MonotonicSet < URL > jars ; private ClassLoader loader ; this . jars = new MonotonicSet < > ( ) ; this . loader = this . getClass ( ) . getClassLoader ( ) ; addJars ( jars ) ; this . jars = new MonotonicSet < URL > ( Arrays . asList ( jars ) ) ; if ( ! newJars . contains ( u ) ) { if ( newJars . size ( ) != 0 ) { jars . addAllIgnoreDuplicates ( newJars ) ; }", "commit_type": "make"}
{"commit_tokens": ["Use", "longs", "to", "avoid", "overflow", "of", "integers", ".", "Related", "to", ":", "https", ":", "//", "github", ".", "com", "/", "MindscapeHQ", "/", "raygun4android", "/", "issues", "/", "29#event", "-", "828128897"], "add_tokens": "private long diskSpaceFree ; long availableBlocks = ( long ) stat . getAvailableBlocks ( ) ; long blockSize = ( long ) stat . getBlockSize ( ) ; diskSpaceFree = ( availableBlocks * blockSize ) / 0x100000 ;", "del_tokens": "private int diskSpaceFree ; diskSpaceFree = ( stat . getAvailableBlocks ( ) * stat . getBlockSize ( ) ) / 0x100000 ;", "commit_type": "use"}
{"commit_tokens": ["Made", "Options", "and", "Channel", "public", "visibility"], "add_tokens": "public class Channel < T > { public Channel ( ) { public Channel ( LinkedBlockingQueue < T > queue ) { public Channel ( int capacity ) { public T get ( ) { public synchronized T get ( long timeout ) throws TimeoutException { public T get ( long timeout , TimeUnit unit ) throws TimeoutException { public T poll ( ) { public boolean add ( T item ) public synchronized boolean isClosed ( ) public int getCount ( )", "del_tokens": "class Channel < T > { Channel ( ) { Channel ( LinkedBlockingQueue < T > queue ) { Channel ( int capacity ) { T get ( ) { synchronized T get ( long timeout ) throws TimeoutException { T get ( long timeout , TimeUnit unit ) throws TimeoutException { T poll ( ) { boolean add ( T item ) synchronized boolean isClosed ( ) int getCount ( )", "commit_type": "make"}
{"commit_tokens": ["use", "property", "instead", "of", "field"], "add_tokens": "ObjectCache . remove ( resource ) ; . wl_resource_set_dispatcher ( getNative ( ) , . wl_resource_get_version ( getNative ( ) ) ; . wl_resource_get_client ( getNative ( ) ) ) ; . wl_resource_get_id ( getNative ( ) ) ; . wl_resource_add_destroy_listener ( getNative ( ) , . wl_resource_destroy ( getNative ( ) ) ; . wl_resource_post_event_array ( getNative ( ) , . wl_resource_post_event_array ( getNative ( ) , . wl_resource_post_error ( getNative ( ) ,", "del_tokens": "ObjectCache . remove ( getNative ( ) ) ; . wl_resource_set_dispatcher ( this . pointer , . wl_resource_get_version ( this . pointer ) ; . wl_resource_get_client ( this . pointer ) ) ; . wl_resource_get_id ( this . pointer ) ; . wl_resource_add_destroy_listener ( this . pointer , . wl_resource_destroy ( this . pointer ) ; . wl_resource_post_event_array ( this . pointer , . wl_resource_post_event_array ( this . pointer , . wl_resource_post_error ( this . pointer ,", "commit_type": "use"}
{"commit_tokens": ["make", "function", "easier", "to", "read"], "add_tokens": "this . globalContext . setIsGlobalContext ( true ) ;", "del_tokens": "this . globalContext . isGlobalContext ( true ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixed", "the", "default", "implementation", "of", "the", "MaterialWaterfall", "s", "show", "and", "hide", "callbacks", "that", "was", "incorrectly", "declared", "in", "local", "scope", "instead", "of", "using", "the", "class", "scoped", "variables", ".", "This", "resulted", "in", "no", "callbacks", "set", "on", "MaterialWaterfall", "which", "caused", "an", "error", "in", "the", "browser", "."], "add_tokens": "openCallback = new Runnable ( ) { closeCallback = new Runnable ( ) {", "del_tokens": "final Runnable openCallback = new Runnable ( ) { final Runnable closeCallback = new Runnable ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "transactional", "bug", "in", "mysql", "--", "transaction", "must", "be", "committed", "."], "add_tokens": "execute ( \"create table \" + getName ( ) + \" (key_ varbinary(200) not null, version_ varbinary(200) not null, \" + \" value_ blob, primary key(key_, version_)) engine = InnoDB\" ) ; doCommit = true ;", "del_tokens": "execute ( \"create table \" + getName ( ) + \" (key_ varbinary(200) not null, version_ varbinary(200) not null, value_ blob, primary key(key_, version_))\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "@RosettaDeserialize", "and", "@RosettaSerialize", "."], "add_tokens": "import com . fasterxml . jackson . databind . util . ClassUtil ; import com . hubspot . rosetta . annotations . RosettaDeserialize ; import com . hubspot . rosetta . annotations . RosettaSerialize ; if ( storedAsJson != null ) { RosettaSerialize rosettaSerialize = a . getAnnotation ( RosettaSerialize . class ) ; if ( rosettaSerialize != null ) { Class < ? extends JsonSerializer > klass = rosettaSerialize . using ( ) ; if ( klass != JsonSerializer . None . class ) { return ClassUtil . createInstance ( klass , objectMapper . getSerializationConfig ( ) . canOverrideAccessModifiers ( ) ) ; } } return null ; if ( storedAsJson != null ) { RosettaDeserialize rosettaDeserialize = a . getAnnotation ( RosettaDeserialize . class ) ; if ( rosettaDeserialize != null ) { Class < ? extends JsonDeserializer > klass = rosettaDeserialize . using ( ) ; if ( klass != JsonDeserializer . None . class ) { return ClassUtil . createInstance ( klass , objectMapper . getDeserializationConfig ( ) . canOverrideAccessModifiers ( ) ) ; } } return null ;", "del_tokens": "if ( storedAsJson == null ) { return null ; } else { if ( storedAsJson == null ) { return null ; } else {", "commit_type": "add"}
{"commit_tokens": ["Add", "generics", "to", "reflection", "invoke", "/", "get"], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) public static < T > T invoke ( Method method , Object self , Object ... args ) { return ( T ) method . invoke ( self , args ) ; @ SuppressWarnings ( \"unchecked\" ) public static < T > T getValue ( Field field , Object self ) { return ( T ) field . get ( self ) ;", "del_tokens": "public static Object invoke ( Method method , Object self , Object ... args ) { return method . invoke ( self , args ) ; public static Object getValue ( Field field , Object self ) { return field . get ( self ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "the", "new", "jStyleParser", "color", "API"], "add_tokens": "import org . fit . cssbox . css . CSSUnits ; clr = CSSUnits . convertColor ( tclr . getValue ( ) ) ;", "del_tokens": "clr = tclr . getValue ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "overloaded", "versions", "of", "usage", "()", "with", "StringBuilders"], "add_tokens": "jc . setProgramName ( \"TestCommander\" ) ; jc . usage ( ) ; jc . usage ( \"add\" ) ; jc . usage ( \"commit\" ) ; public static void main ( String [ ] args ) { new CommandTest ( ) . commandTest2 ( ) ; }", "del_tokens": "// jc.usage(); // jc.usage(\"add\"); // jc.usage(\"commit\");", "commit_type": "add"}
{"commit_tokens": ["fixed", "accidental", "spaces", "(", "2", ")"], "add_tokens": "@ JsonProperty public final String controlType ;", "del_tokens": "@ JsonProperty public final String controlType ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "slash", "ate", "the", "end", "of", "a", "url", "if", "exists"], "add_tokens": "import org . apache . commons . lang . StringUtils ; this . url = StringUtils . removeEnd ( url , \"/\" ) ;", "del_tokens": "this . url = url ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "quiet", "mode", "option", "to", "Sauce", "Connect", "Maven", "plugin"], "add_tokens": "* @ goal start - sauceconnect * @ parameter expression = \"${sauce.httpsProtocol} * @ parameter expression = \"${sauce.options} * / private String options ; / * * * @ parameter expression = \"${sauce.quietMode} * / private boolean quietMode ; / * * SauceConnectTwoManager sauceConnectTwoManager = new SauceConnectTwoManager ( quietMode ) ; sauceConnectTwoManager . openConnection ( sauceUsername , sauceAccessKey , port , null , options , httpsProtocol , null ) ;", "del_tokens": "* @ goal start - sauceconnect * * * SauceConnectTwoManager sauceConnectTwoManager = new SauceConnectTwoManager ( ) ; sauceConnectTwoManager . openConnection ( sauceUsername , sauceAccessKey , port , null , httpsProtocol , null ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "ability", "for", "BitVector", "to", "be", "constructed", "from", "BitStores", "."], "add_tokens": "public static BitVector fromStore ( BitStore store ) { if ( store instanceof BitVector ) { return ( ( BitVector ) store ) . mutableCopy ( ) ; } else { if ( store == null ) throw new IllegalArgumentException ( \"null store\" ) ; return new BitVector ( store ) ; } } private BitVector ( BitStore store ) { this ( store . size ( ) ) ; store . writeTo ( new VectorWriter ( ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["use", "wiremock", "for", "unit", "test", "mocking"], "add_tokens": "private String accessToken = \"1bdc909c-4457-4071-aa8c-42719e9392dd\" ; private String invalidUUID ; @ Test", "del_tokens": "import org . junit . Ignore ; private String accessToken = \"2049bbaf-2513-449d-b489-fcc5c2d7788b\" ; @ Test @ Ignore", "commit_type": "use"}
{"commit_tokens": ["Fixed", ":", "replace", "empty", "block", "of", "JavaDoc", "with", "link", "to", "default", "implementation", "."], "add_tokens": "* Wraps platform specific bits . For android implementation take a look at * AndroidMockServer implementation * { @ link https : //github.com/byoutline/AndroidMockServer} *", "del_tokens": "* Wraps platform specific bits . * For android implementation will look something like this : * < code class = \"java\" > * * < / code >", "commit_type": "fix"}
{"commit_tokens": ["Make", "gzip", "compression", "configurable", "enabled", "by", "default", "."], "add_tokens": "private static final String REQUEST_COMPRESSION = \"hawkular.request-compression\" ; private static final String REQUEST_COMPRESSION_DEFAULT = \"true\" ; boolean requestCompression = Boolean . valueOf ( HawkularProperties . getProperty ( REQUEST_COMPRESSION , REQUEST_COMPRESSION_DEFAULT ) ) ; serverOptions . setCompressionSupported ( requestCompression ) ;", "del_tokens": "serverOptions . setCompressionSupported ( true ) ;", "commit_type": "make"}
{"commit_tokens": ["Updated", "groupId", "of", "eval", "folder"], "add_tokens": "menumElements . put ( Class . SPECIFIER , \"pron-indp\" ) ; // ?", "del_tokens": "// menumElements.put(Class.SPECIFIER, \"pron-indp\");// ?", "commit_type": "update"}
{"commit_tokens": ["added", "query", "logging", "support", "and", "configuration", "parameters", ".."], "add_tokens": "import static com . orm . SugarConfig . getDatabaseName ; import static com . orm . SugarConfig . getDatabaseVersion ; import static com . orm . SugarConfig . getDebugEnabled ; super ( context , getDatabaseName ( context ) , new SugarCursorFactory ( getDebugEnabled ( context ) ) , getDatabaseVersion ( context ) ) ;", "del_tokens": "super ( context , \"sugar.db\" , null , 102 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "expiration", "support", "to", "@CacheSpec", "and", "faster", "test", "execution"], "add_tokens": "import java . util . concurrent . Executor ; import java . util . concurrent . Executors ; import java . util . concurrent . TimeUnit ; import com . jayway . awaitility . Awaitility ; final Executor executor = Executors . newCachedThreadPool ( ) ; static { Awaitility . setDefaultPollDelay ( 1 , TimeUnit . MILLISECONDS ) ; Awaitility . setDefaultPollInterval ( 1 , TimeUnit . MILLISECONDS ) ; } Node < Integer , Integer > dummy = new Node < > ( null , null ) ; localCache . afterRead ( dummy ) ; localCache . afterRead ( dummy ) ; executor . execute ( ( ) -> { localCache . drainStatus . set ( DrainStatus . REQUIRED ) ; task . run ( ) ; done . set ( true ) ; } ) ; await ( ) . until ( ( ) -> lock . hasQueuedThreads ( ) ) ;", "del_tokens": "localCache . afterRead ( null ) ; localCache . afterRead ( null ) ; Thread thread = new Thread ( ( ) -> { localCache . drainStatus . set ( DrainStatus . REQUIRED ) ; task . run ( ) ; done . set ( true ) ; } ) ; thread . start ( ) ; await ( ) . until ( ( ) -> lock . isQueued ( thread ) ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "int", "to", "string", "for", "posturi"], "add_tokens": "String postUri = String . format ( \"http://%s:%s%s\" , METADATA_HOST , METADATA_PORT , METADATA_PATH ) ;", "del_tokens": "String postUri = String . format ( \"http://%s:%s%s%s\" , METADATA_HOST , METADATA_PORT , METADATA_PATH ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "feed", "based", "on", "url"], "add_tokens": "super ( since , Feed . FeedType . URL ) ;", "del_tokens": "super ( since , Feed . FeedType . SOURCE ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "string", "decoding", "to", "private", "utility", "class"], "add_tokens": "import static io . airlift . slice . StringDecoder . decodeString ; return decodeString ( toByteBuffer ( index , length ) , charset ) ;", "del_tokens": "return Slices . decodeString ( toByteBuffer ( index , length ) , charset ) ;", "commit_type": "move"}
{"commit_tokens": ["Fixed", "the", "layers", "some", "animations", "were", "attached", "to"], "add_tokens": "public class LotteShapeLayer extends LotteAnimatableLayer { super ( 0 , callback ) ;", "del_tokens": "public class LotteShapeLayer extends Drawable { setCallback ( callback ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "void", "/", "null", "/", "int", "/", "float", "as", "keywords", "."], "add_tokens": "else if ( name . equals ( \"void\" ) || name . equals ( \"int\" ) || name . equals ( \"float\" ) ) else if ( matches ( nameRoot , Token . KEYWORD_VOID ) ) { return \"void\" ; } else if ( matches ( nameRoot , Token . KEYWORD_INT ) ) { return \"int\" ; } else if ( matches ( nameRoot , Token . KEYWORD_FLOAT ) ) { return \"float\" ; }", "del_tokens": "if ( \"void\" . equals ( name ) ) System . err . println ( \"paramarmaa: \" + Arrays . asList ( parameters ) ) ; System . err . println ( \"PARAM: \" + parameters [ i ] ) ;", "commit_type": "add"}
{"commit_tokens": ["made", "replace", "function", "take", "an", "array", "of", "strings", "to", "match", "on"], "add_tokens": "default TextColumn replaceAll ( String [ ] regexArray , String replacement ) { for ( String regex : regexArray ) { newColumn . set ( r , value . replaceAll ( regex , replacement ) ) ; }", "del_tokens": "default TextColumn replaceAll ( String regex , String replacement ) { newColumn . set ( r , value . replaceAll ( regex , replacement ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Update", "to", "lz4", "r88", "."], "add_tokens": "if ( ref >= off - 4 && ref >= base ) { // potential repetition if ( readIntEquals ( buf , ref , off ) ) { // confirmed final int delta = off - ref ; int ptr = off ; match . len = MIN_MATCH + commonBytes ( buf , ref + MIN_MATCH , off + MIN_MATCH , matchLimit ) ; final int end = off + match . len - ( MIN_MATCH - 1 ) ; while ( ptr < end - delta ) { chainTable [ ptr & MASK ] = ( short ) delta ; // pre load ++ ptr ; } do { chainTable [ ptr & MASK ] = ( short ) delta ; hashTable [ hashHC ( readInt ( buf , ptr ) ) ] = ptr - base ; // head of table ++ ptr ; } while ( ptr < end ) ; nextToUpdate = end ; match . ref = ref ; } ref = next ( ref ) ; } final int matchLen = MIN_MATCH + commonBytes ( buf , ref + MIN_MATCH , off + MIN_MATCH , matchLimit ) ;", "del_tokens": "final int matchLen = 4 + commonBytes ( buf , ref + MIN_MATCH , off + MIN_MATCH , matchLimit ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "redraw", "invocations", "from", "move", "commands", ".", "Clean", "up", "quit", "when", "running", "from", "inside", "a", "jline", "app", "."], "add_tokens": "JlEditConsole . out . print ( ansi ( ) . eraseScreen ( Erase . ALL ) ) ; if ( running ) { redrawCoords ( ) ; flush ( ) ; }", "del_tokens": "JlEditConsole . out . print ( ansi ( ) . eraseScreen ( ) ) ; redrawCoords ( ) ; flush ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "fill", "to", "use", "set"], "add_tokens": "final T val ; val = zero ( ) ; val = null ; } // set the values for ( int i = fromIndex ; i < endIndex ; i ++ ) { set ( i , val ) ;", "del_tokens": "Arrays . fill ( this . timeSeries , fromIndex , endIndex , zero ( ) ) ; Arrays . fill ( this . timeSeries , fromIndex , endIndex , null ) ;", "commit_type": "change"}
{"commit_tokens": ["Upgraded", "admob", "version", ".", "Improved", "ImageHolder"], "add_tokens": "/ * * * @ see com . jdroid . android . images . ImageHolder # setImageContent ( com . jdroid . android . domain . FileContent , int ) * / @ Override / * * * @ see com . jdroid . android . images . ImageHolder # setImageContent ( com . jdroid . android . domain . FileContent , int , * java . lang . Integer , java . lang . Integer ) * / @ Override / * * * @ see com . jdroid . android . images . ImageHolder # setImageContent ( android . net . Uri , int ) * / @ Override * @ see com . jdroid . android . images . ImageHolder # setImageContent ( android . net . Uri , int , java . lang . Integer , * java . lang . Integer ) @ Override", "del_tokens": "* @ param imageUri The image Uri * @ param stubId The id of the resource stub to display while the image is been downloaded * @ param maxWidth The maximum width of the image used to scale it . If null , the image won 't be scaled * @ param maxHeight The maximum height of the image used to scale it . If null , the image won 't be scaled", "commit_type": "upgrade"}
{"commit_tokens": ["Make", "the", "parent", "classloader", "default", "to", "the", "context", "classloader", "instead", "of", "the", "system", "classloader"], "add_tokens": "* the current thread 's context classloader. This can be customized by defining a custom test * runner extending { @ link GwtMockitoTestRunner } and overriding this method . return Thread . currentThread ( ) . getContextClassLoader ( ) ;", "del_tokens": "* the system classloader . This can be customized by defining a custom test runner extending * { @ link GwtMockitoTestRunner } and overriding this method . return ClassLoader . getSystemClassLoader ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Move", "mappings", "root", "directory", "to", "~", "/", ".", "fscrawler", "/", "{", "job_name", "}", "/", "_mappings", "/"], "add_tokens": "Path jobMappingDir = config . resolve ( settings . getName ( ) ) . resolve ( \"_mappings\" ) ; String mapping = FsCrawlerUtil . readMapping ( jobMappingDir , config , elasticsearchVersion , FsCrawlerUtil . INDEX_TYPE_DOC ) ; String mapping = FsCrawlerUtil . readMapping ( jobMappingDir , config , elasticsearchVersion , FsCrawlerUtil . INDEX_TYPE_FOLDER ) ;", "del_tokens": "Path jobSettingsDir = config . resolve ( settings . getName ( ) ) ; String mapping = FsCrawlerUtil . readMapping ( jobSettingsDir , config , elasticsearchVersion , FsCrawlerUtil . INDEX_TYPE_DOC ) ; String mapping = FsCrawlerUtil . readMapping ( jobSettingsDir , config , elasticsearchVersion , FsCrawlerUtil . INDEX_TYPE_FOLDER ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "the", "build", "wrt", "deadline", "."], "add_tokens": "if ( ! source . exhausted ( ) ) {", "del_tokens": "if ( ! source . exhausted ( deadline ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "VictimsScannerTest", "to", "use", "VictimsRecord", "to", "compare", "expected", "and", "result", "values", "rather", "than", "string", "comparisons"], "add_tokens": "VictimsRecord result = VictimsRecord . fromJSON ( os . toString ( ) . trim ( ) ) ; String jstr = FileUtils . readFileToString ( new File ( jsonFile ) ) . trim ( ) ; VictimsRecord expected = VictimsRecord . fromJSON ( jstr ) ; assertTrue ( \"Scanned record not equal to expected\" , expected . equals ( result ) ) ; VictimsRecord result = records . get ( 0 ) ; String jstr = FileUtils . readFileToString ( new File ( jsonFile ) ) . trim ( ) ; VictimsRecord expected = VictimsRecord . fromJSON ( jstr ) ; assertTrue ( \"Scanned record not equal to expected\" , expected . equals ( result ) ) ;", "del_tokens": "String expected = FileUtils . readFileToString ( new File ( jsonFile ) ) . trim ( ) ; String result = os . toString ( ) . trim ( ) ; assertEquals ( \"Scanned json string not equal to expected\" , expected , result ) ; String expected = FileUtils . readFileToString ( new File ( jsonFile ) ) . trim ( ) ; String result = records . get ( 0 ) . toString ( ) ; assertEquals ( \"Scanned json string not equal to expected\" , expected , result ) ;", "commit_type": "change"}
{"commit_tokens": ["changed", "parser", "/", "factory", "to", "return", "EObject", "instead", "of", "object"], "add_tokens": "import org . eclipse . emf . ecore . EObject ; public void add ( EObject _this , String feature , Object value ) { public EObject create ( String typeName ) { return null ; public void set ( EObject _this , String feature , Object value ) {", "del_tokens": "public void add ( Object _this , String feature , Object value ) { public Object create ( String typeName ) { return typeName ; public void set ( Object _this , String feature , Object value ) {", "commit_type": "change"}
{"commit_tokens": ["Added", "general", "flattening", "path", "iterator", "."], "add_tokens": "@ Override // from interface IShape public PathIterator getPathIterator ( AffineTransform t , float flatness ) { return new FlatteningPathIterator ( getPathIterator ( t ) , flatness ) ; }", "del_tokens": "// @Override // from interface IShape // public PathIterator getPathIterator (AffineTransform t, float flatness) { // return new FlatteningPathIterator(getPathIterator(t), flatness); // }", "commit_type": "add"}
{"commit_tokens": ["Changed", "Exception", "types", "added", "new", "root", "exception", "type"], "add_tokens": "* @ since 1.0 public class ExpressionParseException extends UriTemplateParseException", "del_tokens": "public class ExpressionParseException extends RuntimeException", "commit_type": "change"}
{"commit_tokens": ["Use", "method", "called", "tag", "()", "for", "resubscription"], "add_tokens": "/ * * Copyright ( C ) 2016 Airbnb , Inc . * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * /", "del_tokens": "/** The tag(s) to resubscribe to */ String [ ] value ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Move", "snake", "case", "handling", "into", "bean", "resolver"], "add_tokens": "value = resolver . getValue ( context , value , name ) ;", "del_tokens": "value = resolveInternal ( context , resolver , value , name ) ; private Object resolveInternal ( ELContext context , ELResolver resolver , Object value , String name ) { Object result = resolver . getValue ( context , value , name ) ; if ( result != null ) { return result ; } String transformedName = transformName ( name ) ; if ( name . equals ( transformedName ) ) { return null ; } // Try again with snake case return resolver . getValue ( context , value , transformedName ) ; } private static final Pattern SNAKE_CASE = Pattern . compile ( \"_([^_]?)\" ) ; private String transformName ( String name ) { Matcher m = SNAKE_CASE . matcher ( name ) ; StringBuffer result = new StringBuffer ( name . length ( ) ) ; while ( m . find ( ) ) { String replacement = m . group ( 1 ) . toUpperCase ( ) ; m . appendReplacement ( result , replacement ) ; } m . appendTail ( result ) ; return result . toString ( ) ; }", "commit_type": "move"}
{"commit_tokens": ["Adding", "priority", "order", "back", "in"], "add_tokens": "log . debug ( \"Reading ORD file: \" + ordFile . getPath ( ) ) ; cplex . readOrder ( ordFile . getAbsolutePath ( ) ) ; cplex . setParam ( IntParam . MIPOrdType , 1 ) ;", "del_tokens": "log . warn ( \"NOT Reading ORD file: \" + ordFile . getPath ( ) ) ; //log.debug(\"Reading ORD file: \" + ordFile.getPath()); //cplex.readOrder(ordFile.getAbsolutePath()); //cplex.setParam(IntParam.MIPOrdType, 1);", "commit_type": "add"}
{"commit_tokens": ["Removing", "unnecessary", "dependency", "declarations", "and", "fixing", "the", "osgi", "tests"], "add_tokens": "Configuration config = configAdmin . getConfiguration ( \"sfmf4j-commonsio\" , null ) ; properties . put ( \"pollingInterval\" , \"100\" ) ;", "del_tokens": "Configuration config = configAdmin . getConfiguration ( \"sfmf4j-commonsio\" ) ; properties . put ( \"pollingInterval\" , \"50\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fixing", "scanning", "of", "annotated", "method", "commands", "and", "also", "fixed", "grammar", "for", "handling", "annotations"], "add_tokens": "ann . setScanMethodAnnotations ( false ) ; ann . setScanFieldAnnotations ( false ) ; ann . setScanParameterAnnotations ( false ) ;", "del_tokens": "import org . apache . log4j . Logger ; import java . io . InputStream ; import java . util . Properties ; private static final Logger log = Logger . getLogger ( ExecutionContextFactory . class ) ; scanPackage ( \"com.github.srec.command.jemmy\" ) ; InputStream is = ClassLoader . getSystemResourceAsStream ( \"custom_commands.properties\" ) ; if ( is != null ) { Properties props = new Properties ( ) ; props . load ( is ) ; for ( Object obj : props . keySet ( ) ) { scanPackage ( obj . toString ( ) ) ; } } } private void scanPackage ( String packageName ) throws IOException , ClassNotFoundException , IllegalAccessException , InstantiationException {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "a", "bug", "in", "offer", "method", "."], "add_tokens": "} else if ( null == lvElement ( buffer , calcElementOffset ( index + 1 , mask ) ) ) { // buffer is not full", "del_tokens": "} else if ( null != lvElement ( buffer , calcElementOffset ( index + 1 , mask ) ) ) { // buffer is not full", "commit_type": "fix"}
{"commit_tokens": ["improved", "performance", "of", "MavenFacetImpl", "fixed", "bug", "in", "ProjectFactory", "where", "certain", "default", "facets", "would", "not", "be", "registered", "after", "installation", "of", "requested", "facets", "."], "add_tokens": "private ProjectBuildingResult buildingResult ; if ( this . buildingResult == null ) { buildingResult = builder . build ( getPOMFile ( ) , request ) ; } invalidateBuildingResult ( ) ; } private void invalidateBuildingResult ( ) { this . buildingResult = null ; invalidateBuildingResult ( ) ;", "del_tokens": "ProjectBuildingResult buildingResult = builder . build ( getPOMFile ( ) , request ) ;", "commit_type": "improve"}
{"commit_tokens": ["update", "docs", "and", "correct", "comments", "in", "the", "java", "docs"], "add_tokens": "* @ param playerContainer View to integrate default player UI into .", "del_tokens": "* @ param playerContainer View to add default player UI to .", "commit_type": "update"}
{"commit_tokens": ["implement", "bootstrapsize", "for", "edit", "text"], "add_tokens": "super . onRestoreInstanceState ( state ) ;", "del_tokens": "super . onRestoreInstanceState ( state ) ;", "commit_type": "implement"}
{"commit_tokens": ["Update", "src", "/", "main", "/", "java", "/", "de", "/", "paymill", "/", "Paymill", ".", "java"], "add_tokens": "return System . getProperty ( \"apiUrl\" , \"https://api.paymill.de/v2\" ) ;", "del_tokens": "return System . getProperty ( \"apiUrl\" , \"https://api.paymill.de/v1\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Using", "ajdt", "configurator", ".", "Adding", "minor", "comments", "."], "add_tokens": "import com . carrotsearch . randomizedtesting . RandomizedRunner ; import com . carrotsearch . randomizedtesting . aspects . DiskProblems ; import com . carrotsearch . randomizedtesting . aspects . TrackTempDirLocks ; / * * * This is an example of a \"business class\" that we will test using * { @ link RandomizedRunner } and aspect to simulate real - life problems * ( { @ link DiskProblems } ) or code issues ( { @ link TrackTempDirLocks } ) . * / / * * * Read a file from disk and convert it to a Java String using the given * charset . * / try { is . readFully ( bytes ) ; } finally { is . close ( ) ; // don't suppress IOException if it happens. }", "del_tokens": "is . readFully ( bytes ) ; is . close ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "simple_list_item", "layouts", "and", "fix", "preferencescreen", "crash"], "add_tokens": "private ListNavigationAdapter adapter ; if ( adapter == null ) { adapter = new ListNavigationAdapter ( ) ; } else { adapter . clear ( ) ; } adapter . add ( MainFragment . class , R . string . demo ) ; adapter . add ( SettingsFragment . class , R . string . settings ) ; adapter . add ( OtherFragment . class , R . string . other ) ; adapter . add ( AboutFragment . class , R . string . about ) ; navigationWidget . init ( adapter , adapter ,", "del_tokens": "private ListNavigationAdapter lastListNavigationAdapter ; lastListNavigationAdapter = new ListNavigationAdapter ( ) ; lastListNavigationAdapter . add ( MainFragment . class , R . string . demo ) ; lastListNavigationAdapter . add ( SettingsFragment . class , R . string . settings ) ; lastListNavigationAdapter . add ( OtherFragment . class , R . string . other ) ; lastListNavigationAdapter . add ( AboutFragment . class , R . string . about ) ; navigationWidget . init ( lastListNavigationAdapter , lastListNavigationAdapter ,", "commit_type": "add"}
{"commit_tokens": ["Made", "the", "webdriver", "equals", "check", "the", "toString", "in", "stead", "of", "the", "object", "as", "they", "are", "proxied", "in", "the", "case", "of", "remote", "webdrivers"], "add_tokens": "//when remote webdrivers are used, they will be proxies and the equeals methods won't work. Let's equal on the toString assertEquals ( \"Ensure the startup hook is called with the correct webdriver\" , ffWebDriver . toString ( ) , foundWebdriver . toString ( ) ) ; assertEquals ( \"Ensure the shutdown hook is called with the correct webdriver\" , ffWebDriver . toString ( ) , foundRemovedWebdriver . toString ( ) ) ;", "del_tokens": "assertEquals ( \"Ensure the startup hook is called with the correct webdriver\" , ffWebDriver , foundWebdriver ) ; assertEquals ( \"Ensure the shutdown hook is called with the correct webdriver\" , ffWebDriver , foundRemovedWebdriver ) ;", "commit_type": "make"}
{"commit_tokens": ["Fixing", "Diameter", "tests", "...", "due", "to", "new", "strict", "methods", "were", "failing", "."], "add_tokens": "DiameterAvp unitTypeAvp = avpFactory . createAvp ( 193 , 611 , unitType ) ; avps . add ( avpFactory . createAvp ( 193 , 602 , new DiameterAvp [ ] { unitTypeAvp , unitValueAvp } ) ) ;", "del_tokens": "import net . java . slee . resource . diameter . base . events . avp . FailedAvp ; DiameterAvp unitTypeAvp = avpFactory . createAvp ( 193 , 602 , unitType ) ; avps . add ( avpFactory . createAvp ( 193 , 606 , new DiameterAvp [ ] { unitTypeAvp , unitValueAvp } ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "unification", "example", "from", "the", "WAM", "book", "."], "add_tokens": "import com . thesett . common . parsing . SourceCodeException ; public class BasicUnificationUnitTestBase < S extends Clause , T , Q > extends BasicResolverUnitTestBase < S , T , Q > /** A unification example from the WAM book, but with the statement and query swapped around. */ public void testWamBook2_9OtherWay ( ) throws Exception { unifyAndAssertNumBindings ( \"p(Z,h(Z,W),f(W))\" , \"p(f(X),h(Y,f(a)),Y)\" , 2 ) ; }", "del_tokens": "import com . thesett . common . parsing . SourceCodeException ; public class BasicUnificationUnitTestBase < S extends Clause , T , Q > extends BasicResolverUnitTestBase < S , T , Q >", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "interface", "bean", "proxies"], "add_tokens": "import org . supercsv . util . BeanInterfaceProxy ; * Creates an object of the type or if it is an interface , create a proxy instance implementing the interface type . * * the type to instantiate . If the type is a class type , an instance can be created straight away . If the * type is an interface type , a proxy is created on the fly which acts as an implementation . // create a proxy instance if an interface type is provided final T resultBean ; if ( clazz . isInterface ( ) ) { resultBean = ( T ) new BeanInterfaceProxy ( ) . createProxy ( clazz ) ; } else { resultBean = clazz . newInstance ( ) ; } public < T > T read ( final Class < T > clazz , final String ... nameMapping ) throws IOException , SuperCSVReflectionException {", "del_tokens": "final T resultBean = clazz . newInstance ( ) ; public < T > T read ( final Class < T > clazz , final String [ ] nameMapping ) throws IOException , SuperCSVReflectionException {", "commit_type": "add"}
{"commit_tokens": ["Made", "things", "more", "optional", "."], "add_tokens": "return create ( some ( href ) , links , items , queries , fromNullable ( template ) , fromNullable ( error ) ) ; private Optional < Template > template = Optional . none ( ) ; private Optional < Error > error = Optional . none ( ) ; public Builder ( URI href ) { this ( fromNullable ( href ) ) ; }", "del_tokens": "return create ( some ( href ) , links , items , queries , some ( template ) , some ( error ) ) ; private Optional < Template > template ; private Optional < Error > error ;", "commit_type": "make"}
{"commit_tokens": ["Remove", "magic", "sleep", "()", "s", "and", "join", "()", "s"], "add_tokens": "this . listeners . clear ( ) ; if ( this . listenThread != null ) { this . listenThread . halt ( ) ;", "del_tokens": "try { Thread . sleep ( 500 ) ; } catch ( final InterruptedException e ) { GPSdEndpoint . LOG . debug ( \"Interrupted while sleeping\" , e ) ; } try { this . listeners . clear ( ) ; if ( this . listenThread != null ) { this . listenThread . halt ( ) ; } } catch ( final Exception e ) { GPSdEndpoint . LOG . debug ( \"Interrupted while waiting for listenThread to stop\" , e ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updating", "the", "Wrapper", "Manager", "Tester", "to", "include", "Conversations"], "add_tokens": "expectedMap . put ( \"Conversation\" , new Class [ ] { Conversation . class } ) ; expectedMap . put ( \"Expression\" , new Class [ ] { Expression . class } ) ;", "del_tokens": "expectedMap . put ( \"Expression\" , new Class [ ] { Conversation . class } ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "a", "new", "function", "to", "allow", "reading", "all", "forward", "in", "chunks"], "add_tokens": "import org . fuin . esc . spi . AbstractReadableEventStore ; public abstract class AbstractJpaEventStore extends AbstractReadableEventStore implements ReadableEventStore {", "del_tokens": "public abstract class AbstractJpaEventStore implements ReadableEventStore {", "commit_type": "add"}
{"commit_tokens": ["Add", "on", "the", "fly", "resources", "processing", ".", "Simplify", "code"], "add_tokens": "this . extensionsMap = ( null == extensions ) ? InstanceOfMap . empty ( ) : InstanceOfMap . < Module > builder ( ) . fromList ( extensions ) ;", "del_tokens": "this . extensionsMap = ( null == extensions ) ? InstanceOfMap . < Module > empty ( ) : InstanceOfMap . < Module > builder ( ) . fromList ( extensions ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "upper", "-", "case", "StreamType", "elements", "to", "support", "Pandora", "format", "added", "test", "for", "Pandora", "response"], "add_tokens": "* < p > Stream type < / p > * * < p > Some receivers use upper - case ( like Pandora ) , some use lower - case ( like Google Audio ) , * duplicate elements to support both < / p > public enum StreamType { BUFFERED , buffered , LIVE , live , NONE , none }", "del_tokens": "* Stream type public enum StreamType { buffered , live , none }", "commit_type": "add"}
{"commit_tokens": ["Moved", "methods", "related", "to", "file", "attribute", "handling", "to", "new", "utility", "class"], "add_tokens": "private FileAttributeUtil fileAttrUtils = new FileAttributeUtil ( ) ; timestamp = fileAttrUtils . getLastModifiedTimestamp ( pomFile ) ; throw new FailureException ( \"Cound not retrieve the timestamp of the pom file: \" + pomFile . getAbsolutePath ( ) ) ; fileAttrUtils . setTimestamps ( pomFile , timestamp ) ;", "del_tokens": "import java . nio . file . Files ; import java . nio . file . attribute . BasicFileAttributeView ; import java . nio . file . attribute . FileTime ; timestamp = pomFile . lastModified ( ) ; throw new FailureException ( \"Cound not save the timestamp of the pom file: \" + pomFile . getAbsolutePath ( ) ) ; BasicFileAttributeView attributes = Files . getFileAttributeView ( pomFile . toPath ( ) , BasicFileAttributeView . class ) ; FileTime time = FileTime . fromMillis ( timestamp ) ; attributes . setTimes ( time , time , time ) ;", "commit_type": "move"}
{"commit_tokens": ["removing", "the", "debug", "outputs", "and", "fixing", "the", "test", "errors"], "add_tokens": "", "del_tokens": "import java . util . Arrays ; if ( neighborhood . contains ( 140 ) ) { LOGGER . debug ( \" ***\" ) ; } if ( 140 == neighborhood . get ( i ) ) { LOGGER . debug ( Arrays . toString ( admDistances [ i ] ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Add", "missing", "license", "headers", "and", "activated", "check", "for", "missing", "licenses"], "add_tokens": "package com . sap . prd . mobile . ios . mios ; / * * # % L * Xcode Maven Plugin * % % * Copyright ( C ) 2012 SAP AG * % % * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * # L % * /", "del_tokens": "package com . sap . prd . mobile . ios . mios ;", "commit_type": "add"}
{"commit_tokens": ["Use", "class", "name", "to", "create", "factory", "."], "add_tokens": "XmlPullParserFactory factory = XmlPullParserFactory . newInstance ( \"org.xmlpull.mxp1.MXParserFactory\" , null ) ;", "del_tokens": "XmlPullParserFactory factory = XmlPullParserFactory . newInstance ( ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "auto", "-", "insert", "for", "array", "-", "access", "(", "was", "broken", "from", "array", "-", "acces", "optimizations", ")"], "add_tokens": "} if ( needsAutoinsert ) { IType typeToAutoInsert = ArrayAccess . getTypeToAutoInsert ( getParsedElement ( ) . getRootExpression ( ) ) ; // add an maybeAutoInsert before the array access arrayAccess = buildComposite ( buildMethodCall ( callStaticMethod ( ArrayAccessTransformer . class , \"maybeAutoInsert\" , new Class [ ] { Object . class , int . class , IType . class } , Arrays . asList ( identifier ( tempRoot ) , identifier ( tempIndex ) , pushType ( typeToAutoInsert ) ) ) ) , arrayAccess ) ;", "del_tokens": "if ( needsAutoinsert ) { IType typeToAutoInsert = ArrayAccess . getTypeToAutoInsert ( getParsedElement ( ) . getRootExpression ( ) ) ; // add an maybeAutoInsert before the array access arrayAccess = buildComposite ( buildMethodCall ( callStaticMethod ( ArrayAccessTransformer . class , \"maybeAutoInsert\" , new Class [ ] { Object . class , int . class , IType . class } , Arrays . asList ( identifier ( tempRoot ) , identifier ( tempIndex ) , pushType ( typeToAutoInsert ) ) ) ) , arrayAccess ) ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "final", "to", "ModelKey", ".", "java"], "add_tokens": "private final Object dataKey ; private final String formName ; private final Class modelClass ; this . modelClass = null ; this . formName = null ;", "del_tokens": "private Object dataKey ; private String formName ; private Class modelClass ; public void setDataKey ( Object dataKey ) { this . dataKey = dataKey ; } public void setFormName ( String formName ) { this . formName = formName ; } public void setModelClass ( Class modelClass ) { this . modelClass = modelClass ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "mutable", "value", "types"], "add_tokens": "obj . put ( \"baz\" , 42 ) ; obj . put ( \"dval\" , 3.1415 ) ; obj . put ( \"fval\" , false ) ; obj . put ( \"tval\" , true ) ; assertEquals ( obj . getInt ( \"baz\" ) , 42 ) ; assertEquals ( obj . getLong ( \"baz\" ) , 42l ) ; assertEquals ( obj . getDouble ( \"dval\" ) , 3.1415 , 0.0 ) ; assertEquals ( obj . getBoolean ( \"fval\" ) , false ) ; assertEquals ( obj . getBoolean ( \"tval\" ) , true ) ; assertEquals ( obj . toString ( ) , \"{\\\"foo\\\":\\\"bar\\\",\\\"baz\\\":42,\\\"dval\\\":3.1415,\\\"fval\\\":false,\\\"tval\\\":true,\\\"test\\\":\\\"Hello World\\\"}\" ) ;", "del_tokens": "assertEquals ( obj . toString ( ) , \"{\\\"foo\\\":\\\"bar\\\",\\\"test\\\":\\\"Hello World\\\"}\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Change", "default", "consistency", "level", "from", "ONE", "to", "QUORUM"], "add_tokens": "this . setDefaultReadConsistencyLevel ( HConsistencyLevel . QUORUM ) ; this . setDefaultWriteConsistencyLevel ( HConsistencyLevel . QUORUM ) ;", "del_tokens": "this . setDefaultReadConsistencyLevel ( HConsistencyLevel . ONE ) ; this . setDefaultWriteConsistencyLevel ( HConsistencyLevel . ONE ) ;", "commit_type": "change"}
{"commit_tokens": ["Removed", "use", "of", "File", "()", ".", "deleteOnExit", "()", "to", "avoid", "memory", "leaks", "in", "long", "-", "running", "applications", "."], "add_tokens": "* Copyright ( C ) 2000 - 2013 , 2014 , 2015 , 2016 , 2017 AO Industries , Inc . // Not necessary since there is a clean-up thread: file.deleteOnExit(); // JDK implementation builds an ever-growing set", "del_tokens": "* Copyright ( C ) 2000 - 2013 , 2014 , 2015 , 2016 AO Industries , Inc . file . deleteOnExit ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Moved", "annotaion", "in", "their", "own", "package", "."], "add_tokens": "package com . tjeannin . provigen . annotations ;", "del_tokens": "package com . tjeannin . provigen ;", "commit_type": "move"}
{"commit_tokens": ["remove", "dead", "paths", "and", "add", "test", "coverage"], "add_tokens": "private final int STACK_INCREASE = 31 ; private int STACK_SIZE = 32 ; // TODO: Do we have any legal cases that should send us in here? if ( token == null ) { throw new LazyException ( \"Unexpected end of object character\" , n ) ; } if ( token == null || token . type != LazyToken . ARRAY ) {", "del_tokens": "private final int STACK_INCREASE = 127 ; private int STACK_SIZE = 128 ; } else { // This shouldn't occur should it? throw new LazyException ( \"Syntax error\" , n ) ; if ( token . type != LazyToken . ARRAY ) {", "commit_type": "remove"}
{"commit_tokens": ["updated", "example", "and", "its", "visualization"], "add_tokens": "public Object loadProvGraph ( String filename ) throws java . io . IOException , JAXBException , Throwable { try { return loadProvKnownGraph ( filename ) ; } catch ( Throwable e ) { return loadProvUnknownGraph ( filename ) ; } } public Object loadProvKnownGraph ( String filename ) } else if ( filename . endsWith ( \".json\" ) ) { throw new UnsupportedOperationException ( ) ; System . out . println ( \"Unkown format \" + filename ) ; public Object loadProvUnknownGraph ( String filename ) throws java . io . IOException , JAXBException , Throwable { try { Utility u = new Utility ( ) ; CommonTree tree = u . convertASNToTree ( filename ) ; Object o = u . convertTreeToJavaBean ( tree ) ; return o ; } catch ( Throwable t1 ) { try { File in = new File ( filename ) ; ProvDeserialiser deserial = ProvDeserialiser . getThreadProvDeserialiser ( ) ; Bundle c = deserial . deserialiseBundle ( in ) ; return c ; } catch ( Throwable t2 ) { System . out . println ( \"Unparseable format \" + filename ) ; throw new UnsupportedOperationException ( ) ; } } }", "del_tokens": "public Object loadProvGraph ( String filename ) System . out . println ( \"Unkownn format \" + filename ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "override", "of", "contains", "()", "as", "implementation", "is", "complex", "and", "unused", "ATM"], "add_tokens": "// TODO: possibly override contains()", "del_tokens": "public boolean contains ( Object obj ) { if ( obj instanceof Entry < ? , ? > ) { Entry < ? , ? > entry = ( Entry < ? , ? > ) obj ; return entry . getKey ( ) instanceof String && bean . metaBean ( ) . metaPropertyExists ( obj . toString ( ) ) ; } return false ; } @ Override", "commit_type": "remove"}
{"commit_tokens": ["Move", "variable", "declaration", "inside", "the", "loop"], "add_tokens": "DatagramPacket packet = AsyncPacketProvider . this . packetProvider . getNextPacket ( this . changeTalking ) ;", "del_tokens": "DatagramPacket packet ; packet = AsyncPacketProvider . this . packetProvider . getNextPacket ( this . changeTalking ) ;", "commit_type": "move"}
{"commit_tokens": ["Added", "static", "modifier", "to", "inner", "class"], "add_tokens": "static class VerifyTask implements Callable < YubicoResponse > {", "del_tokens": "class VerifyTask implements Callable < YubicoResponse > {", "commit_type": "add"}
{"commit_tokens": ["Adding", "support", "for", "reading", "the", "HEADLINE", "and", "DATELINE", "when", "they", "exist", "."], "add_tokens": "private String headline ; private String dateline ; public String getHeadline ( ) { return headline ; } public void setHeadline ( String headline ) { this . headline = headline ; } public String getDateline ( ) { return dateline ; } public void setDateline ( String dateline ) { this . dateline = dateline ; } && Util . safeEquals ( type , o . type ) && Util . safeEquals ( headline , o . headline ) && Util . safeEquals ( dateline , o . dateline ) && Util . safeEquals ( sents , o . sents ) && Util . safeEquals ( corefs , o . corefs ) ; //&& Util.safeEquals(prefs, o.prefs); return Util . safeHashCode ( docId , type , headline , dateline , sents , corefs , prefs ) ;", "del_tokens": "&& Util . safeEquals ( type , o . type ) && Util . safeEquals ( sents , o . sents ) && Util . safeEquals ( corefs , o . corefs ) ; //&& Util.safeEquals(prefs, o.prefs); return Util . safeHashCode ( docId , type , sents , corefs , prefs ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "structure", "for", "create", "queue", "insertion", "."], "add_tokens": "import de . metalcon . autocompleteServer . Command ; import de . metalcon . autocompleteServer . Search ; public class CreateRequestContainer extends Command { // TODO replace this example suggestTree with concrete ones. @ Override public void run ( ) { Search . suggestTree . put ( this . suggestString , this . weight , this . key ) ; }", "del_tokens": "public class CreateRequestContainer {", "commit_type": "add"}
{"commit_tokens": ["Updated", "version", ";", "changed", "exception", "to", "relevant", "type", ";", "updated", "unit", "test", "."], "add_tokens": "import java . lang . IllegalArgumentException ; throw new IllegalArgumentException ( \"TokenGenerator.createToken: data is empty and no options are set. This token will have no effect on Firebase.\" ) ;", "del_tokens": "throw new Error ( \"TokenGenerator.createToken: data is empty and no options are set. This token will have no effect on Firebase.\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Change", "fields", "of", "ValidationErrorMessage", ".", "Error", "to", "be", "final"], "add_tokens": "errors . add ( new Error ( field , rejectedValue , message ) ) ; errors . add ( new Error ( null , null , message ) ) ; private final String field ; private final Object rejected ; private final String message ;", "del_tokens": "Error error = new Error ( ) ; error . field = field ; error . rejected = rejectedValue ; error . message = message ; errors . add ( error ) ; Error error = new Error ( ) ; error . message = message ; errors . add ( error ) ; private String field ; private Object rejected ; private String message ;", "commit_type": "change"}
{"commit_tokens": ["Fixing", "the", "NIO2", "tests", "and", "speeding", "up", "the", "other", "tests", "on", "OS", "X", ".", "Also", "fixing", "the", "jpathwatch", "osgi", "tests", "."], "add_tokens": "return 3 ; *", "del_tokens": "if ( System . getProperty ( \"os.name\" ) . contains ( \"Mac OS X\" ) ) { return 120 ; } else { return 3 ; }", "commit_type": "fix"}
{"commit_tokens": ["Move", "isPrimitiveOrString", "()", "method", "from", "ObjectNavigator", "to", "JsonPrimitive", "."], "add_tokens": "private static final Class < ? > [ ] PRIMITIVE_TYPES = { int . class , long . class , short . class , float . class , double . class , byte . class , boolean . class , char . class , Integer . class , Long . class , Short . class , Float . class , Double . class , Byte . class , Boolean . class , Character . class } ; || isPrimitiveOrString ( primitive ) ) ; private static boolean isPrimitiveOrString ( Object target ) { if ( target instanceof String ) { return true ; } Class < ? > classOfPrimitive = target . getClass ( ) ; for ( Class < ? > standardPrimitive : PRIMITIVE_TYPES ) { if ( standardPrimitive . isAssignableFrom ( classOfPrimitive ) ) { return true ; } } return false ; }", "del_tokens": "|| ObjectNavigator . isPrimitiveOrString ( primitive ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "tool", "chain", "to", "use", "Java", "7", "for", "compilation", ";", "fix", "global", "timeout", "impl"], "add_tokens": "Field field = Method . class . getDeclaredField ( DECLARED_ANNOTATIONS ) ;", "del_tokens": "import org . junit . rules . ExpectedException ; import java . lang . reflect . Executable ; Field field = Executable . class . getDeclaredField ( DECLARED_ANNOTATIONS ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "start", "of", "the", "AST"], "add_tokens": "import com . bazaarvoice . jless . ast . DocumentNode ; import com . bazaarvoice . jless . ast . Node ; import com . bazaarvoice . jless . ast . SimpleNode ; import org . parboiled . annotations . BuildParseTree ; @ BuildParseTree public class Parser extends BaseParser < Node > { // @SuppressSubnodes return Sequence ( push ( new DocumentNode ( ) ) , ZeroOrMore ( Sequence ( FirstOf ( /*Import(), */ Declaration ( ) , RuleSet ( ) /*, Mixin()*/ , Comment ( ) ) , peek ( ) . addChild ( new SimpleNode ( match ( ) ) ) ) ) ) ;", "del_tokens": "import org . parboiled . annotations . SuppressSubnodes ; //@BuildParseTree public class Parser extends BaseParser < Object > { @ SuppressSubnodes return ZeroOrMore ( FirstOf ( /*Import(), */ Declaration ( ) , RuleSet ( ) /*, Mixin()*/ , Comment ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "material", "colors", "to", "sample", "project"], "add_tokens": "void onWheelItemSelected ( WheelAdapter adapter , int position ) ;", "del_tokens": "void onWheelItemSelected ( WheelAdapter wheelItem , int position ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "problem", "where", "in", "one", "bit", "per", "sample", "mode", "we", "treated", "the", "most"], "add_tokens": "int offsetWithinByte = 1 << ( Byte . SIZE - ( x % Byte . SIZE ) - 1 ) ; int offsetWithinByte = 1 << ( Byte . SIZE - ( x % Byte . SIZE ) - 1 ) ;", "del_tokens": "int offsetWithinByte = 1 << ( x % Byte . SIZE ) ; int offsetWithinByte = 1 << ( x % Byte . SIZE ) ;", "commit_type": "fix"}
{"commit_tokens": ["updated", "TurtleTree", "w", "/", "Hashmap"], "add_tokens": "import java . awt . Color ; import java . util . HashMap ; // ------------- Recipe for adjustColor --#15.2 (this recipe uses the HashMap) HashMap < Integer , Color > colors = new HashMap < Integer , Color > ( ) ; // A 60 pixel long branch is saddle brown --#13 (TIP: put the values into the HashMap)", "del_tokens": "// ------------- Recipe for adjustColor --#15.2 // A 60 pixel long branch is saddle brown --#13", "commit_type": "update"}
{"commit_tokens": ["Remove", "unnecessary", "temporary", "list", "for", "sample", "values"], "add_tokens": "import java . util . function . Consumer ; final StringBuilder sampleValue = new StringBuilder ( ) ; Consumer < ? super String > sampleHandler = s -> { } ; if ( maxSampleCount >= 0 ) { stream . limit ( maxSampleCount ) . sorted ( ) . forEach ( sampleHandler ) ; if ( valueCount > maxSampleCount ) { sampleValue . append ( \", ...\" ) ; } } else { stream . sorted ( ) . forEach ( sampleHandler ) ;", "del_tokens": "List < String > list ; if ( maxSampleCount >= 0 ) { list = stream . limit ( maxSampleCount ) . sorted ( ) . collect ( Collectors . toList ( ) ) ; } else { list = stream . sorted ( ) . collect ( Collectors . toList ( ) ) ; } StringBuilder sampleValue = new StringBuilder ( ) ; list . forEach ( s -> { } ) ; if ( valueCount > maxSampleCount ) { sampleValue . append ( \", ...\" ) ; // System.out.println(sampleValue.toString());", "commit_type": "remove"}
{"commit_tokens": ["Adding", "configuration", "download", "/", "upload", "to", "Profiles", "UI"], "add_tokens": "import javax . servlet . http . HttpServletResponse ; String getBackup ( Model model , HttpServletResponse response ) throws Exception { response . addHeader ( \"Content-Disposition\" , \"attachment; filename=backup.json\" ) ; response . setContentType ( \"application/json\" ) ;", "del_tokens": "String getBackup ( Model model ) throws Exception {", "commit_type": "add"}
{"commit_tokens": ["remove", "store", "choice", "cache", "use", "only", "localeStore"], "add_tokens": "String ALL = \"ALL\" ; String USE_ALL_ARGUMENTS = \"*\" ; String ARGS_NOT_CONSIDERATED = \"-\" ;", "del_tokens": "String STORE = \"store\" ; String ALL = \"all\" ;", "commit_type": "remove"}
{"commit_tokens": ["added", "function", "getFullTree", "()", "which", "makes", "testing", "easier"], "add_tokens": "protected Tree < FeatureStructure > getFullTree ( JCas jcas ) { return tree ; } public synchronized List < List < Object > > convert ( JCas jcas , boolean newHeader ) { Tree < FeatureStructure > tree = getFullTree ( jcas ) ;", "del_tokens": "public synchronized List < List < Object > > convert ( JCas jcas , boolean newHeader ) {", "commit_type": "add"}
{"commit_tokens": ["fix", "that", "w", ".", "r", ".", "t", ".", "Canonical", "EXI", "the", "Hour", "value", "used", "to", "compute", "the", "Time", "component", "MUST", "NOT", "be", "24"], "add_tokens": "// Time: ((Hour * 64) + Minutes) * 64 + seconds // Canonical EXI: The Hour value MUST NOT be 24 { int hour = time / ( 64 * 64 ) ; if ( hour == 24 ) { time -= hour * ( 64 * 64 ) ; int minute = time / 64 ; time -= minute * 64 ; // second // add one day / set hour to zero monthDay ++ ; hour = 0 ; // adapt time time = ( ( hour * 64 ) + minute ) * 64 + time ; } } // this . year = year ; this . monthDay = monthDay ; // Month * 32 + Day minutes ++ ; // adds one minute", "del_tokens": "this . year = year ; this . monthDay = monthDay ; minutes ++ ; // ads one minute", "commit_type": "fix"}
{"commit_tokens": ["allow", "injection", "of", "plugin", "repositories", "into", "server"], "add_tokens": "import static edu . emory . mathcs . backport . java . util . Collections . emptyMap ; Server server = new DefaultServerImpl ( ( EmbeddedGraphStore ) store , getScannerPluginRepository ( store , emptyMap ( ) ) , getRulePluginRepository ( ) ) ;", "del_tokens": "Server server = new DefaultServerImpl ( ( EmbeddedGraphStore ) store ) ;", "commit_type": "allow"}
{"commit_tokens": ["add", "convention", ":", "PK", "for", "maps", "is", "the", "id", "key", "."], "add_tokens": "public PrimaryKeyInfo getPrimaryKeyInfo ( Class < ? > clazz , PropertyDesc propertyDesc , NameConverter nameConverter ) { // note: for Maps, the default PK is the \"ID\" key as a convention. String name = propertyDesc . getPropertyName ( ) ; if ( clazz == Map . class || clazz == HashMap . class || clazz == LinkedHashMap . class ) { if ( \"id\" . equalsIgnoreCase ( name ) ) { return new PrimaryKeyInfo ( PrimaryKey . GenerationType . IDENTITY ) ; } return null ; } public ColumnInfo getColumnInfo ( Class < ? > clazz , PropertyDesc propertyDesc , NameConverter nameConverter ) {", "del_tokens": "public PrimaryKeyInfo getPrimaryKeyInfo ( Class < ? > clazz , PropertyDesc propertyDesc , NameConverter nameConverter ) { public ColumnInfo getColumnInfo ( Class < ? > clazz , PropertyDesc propertyDesc , NameConverter nameConverter ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "the", "max", "wait", "before", "doing", "the", "result", ".", "get"], "add_tokens": "Thread . sleep ( MAX_WAIT ) ;", "del_tokens": "Thread . sleep ( WAIT_PAUSE ) ;", "commit_type": "use"}
{"commit_tokens": ["Improve", "the", "coverage", "sensor", ".", "Details", ":"], "add_tokens": "verify ( context , times ( 30 ) ) . saveMeasure ( ( Resource ) anyObject ( ) , any ( Measure . class ) ) ;", "del_tokens": "@ Ignore // This unit test (the production code, actually) depends // on absolute paths in the report file and will fail if checked out // elsewhere. The gcov sensor would *also* fail if the project // is moved to a different place after creating the reports and before // analyzing. Skip for now... verify ( context , times ( 15 ) ) . saveMeasure ( ( Resource ) anyObject ( ) , any ( Measure . class ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["Changed", "the", "replaceByName", "method", "signature", "to", "make", "it", "clearer"], "add_tokens": "public boolean replaceByName ( Cell c ) {", "del_tokens": "public boolean replace ( Cell c ) {", "commit_type": "change"}
{"commit_tokens": ["Added", "host", "to", "HttpHost", "construction", "from", "IpAddress", "to", "avoid", "problems", "with", "virtualhosts"], "add_tokens": "new HttpHost ( InetAddress . getByAddress ( visitState . workbenchEntry . ipAddress ) . getHostAddress ( ) , uri . getHost ( ) , port , scheme ) :", "del_tokens": "new HttpHost ( InetAddress . getByAddress ( visitState . workbenchEntry . ipAddress ) . getHostAddress ( ) , port , scheme ) :", "commit_type": "add"}
{"commit_tokens": ["added", "location", "extraction", "method", "(", "based", "on", "geonames", ")"], "add_tokens": "// initial capacity set to 405, since the entries in the country list of // Geonames are 303 and the default load factor of 0.75 is used protected final Map < String , String > countryCodes = new HashMap < String , String > ( 405 ) ; protected final Map < String , String > countryNames = new HashMap < String , String > ( 405 ) ; readCountryCodeMap ( gnCountryInfoFile ) ; protected void readCountryCodeMap ( String countryInfoFile ) { // we want to look country names irrespective of casing countryNames . put ( parts [ 4 ] . toLowerCase ( ) , parts [ 0 ] ) ;", "del_tokens": "protected final Map < String , String > countryCodes ; countryCodes = readCountryCodeMap ( gnCountryInfoFile ) ; protected Map < String , String > readCountryCodeMap ( String countryInfoFile ) { Map < String , String > countryCodes = new HashMap < String , String > ( ) ; return countryCodes ;", "commit_type": "add"}
{"commit_tokens": ["added", "elementOrNull", "with", "timeout", "as", "a", "replacement", "for", "waitForElementByNoThrow"], "add_tokens": "protected final WebElement elementOrNull ( final By locator , long timeOutInSeconds ) { return waitForElementByNoThrow ( locator , timeOutInSeconds ) ; } / * * * use { @ link # elementOrNull ( By , long ) } * this method will be removed * / protected final WebElement waitForElementByNoThrow ( final By locator , long timeout ) { try { return waitForPresenceOfElementLocatedBy ( locator , timeout ) ; } catch ( WebDriverException e ) { return null ; } }", "del_tokens": "protected final WebElement waitForElementByNoThrow ( final By locator , long timeout ) { try { return waitForPresenceOfElementLocatedBy ( locator , timeout ) ; } catch ( WebDriverException e ) { return null ; } }", "commit_type": "add"}
{"commit_tokens": ["Moved", "default", "ac", "service", "with", "support", "for", "notifications", "back", "in"], "add_tokens": "import org . italiangrid . voms . request . VOMSACRequest ; import org . italiangrid . voms . request . VOMSErrorMessage ; import org . italiangrid . voms . request . VOMSRequestListener ; import org . italiangrid . voms . request . VOMSWarningMessage ; VOMSTrustStoreUpdateListener , UncaughtExceptionHandler , VOMSRequestListener { public void notifyVOMSRequestStart ( VOMSACRequest request , VOMSServerInfo si ) { } public void notifyVOMSRequestSuccess ( VOMSACRequest request , VOMSServerInfo endpoint ) { } public void notifyVOMSRequestFailure ( VOMSACRequest request , VOMSServerInfo endpoint , Throwable error ) { } public void notifyErrorsInVOMSReponse ( VOMSACRequest request , VOMSServerInfo si , VOMSErrorMessage [ ] errors ) { } public void notifyWarningsInVOMSResponse ( VOMSACRequest request , VOMSServerInfo si , VOMSWarningMessage [ ] warnings ) { }", "del_tokens": "VOMSTrustStoreUpdateListener , UncaughtExceptionHandler {", "commit_type": "move"}
{"commit_tokens": ["Add", "support", "for", ".", "tgz", "file", "extraction"], "add_tokens": "logger . info ( \"Starting Archive Extraction (may take a few minutes)\" ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "CARD", "value", "to", "the", "ApplicationViewType", "enum", "."], "add_tokens": "GALLERY , CARD ;", "del_tokens": "GALLERY ;", "commit_type": "add"}
{"commit_tokens": ["Add", "ability", "to", "set", "a", "listitem", "divider", "in", "theme"], "add_tokens": "import android . content . res . TypedArray ; import android . graphics . drawable . Drawable ; / * * * Checks if a divider drawable has been defined in the current theme . If it has , will apply * an item decoration with the divider . If no divider has been specified , then does nothing . * / protected void configureItemDecoration ( @ NonNull LayoutInflater inflater , @ NonNull RecyclerView recyclerView ) { final TypedArray attributes = getActivity ( ) . obtainStyledAttributes ( new int [ ] { R . attr . nnf_list_item_divider } ) ; Drawable divider = attributes . getDrawable ( 0 ) ; attributes . recycle ( ) ; if ( divider != null ) { recyclerView . addItemDecoration ( new DividerItemDecoration ( divider ) ) ; } }", "del_tokens": "import java . net . URI ; import static com . nononsenseapps . filepicker . Utils . isValidFileName ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "assert", "to", "a", "more", "stable", "testing", "criteria", "."], "add_tokens": "import javafx . collections . ObservableList ; import javafx . scene . Node ; import javafx . scene . control . Button ; ObservableList < Node > sceneContent = uut . getScene ( ) . getRoot ( ) . getChildrenUnmodifiable ( ) ; Button firstButton = ( Button ) sceneContent . get ( 0 ) ; assertThat ( firstButton . getText ( ) , is ( \"Weld App\" ) ) ;", "del_tokens": "assertThat ( uut . getHeight ( ) , is ( 129.0 ) ) ; assertThat ( uut . getWidth ( ) , is ( 102.0 ) ) ;", "commit_type": "change"}
{"commit_tokens": ["updating", "the", "methods", "for", "ts", "to", "string", "conversion", "."], "add_tokens": "import edu . hawaii . jmotif . sax . SAXException ; * @ throws SAXException if error occurs . double normalizationThreshold ) throws SAXException {", "del_tokens": "import edu . hawaii . jmotif . timeseries . TSException ; * @ throws TSException if error occurs . double normalizationThreshold ) throws TSException {", "commit_type": "update"}
{"commit_tokens": ["Made", "the", "viewholder", "static", "so", "it", "is", "independent", "of", "the", "adapter", "."], "add_tokens": "holder . setDragStartCallback ( mDragStartCallback ) ; } @ Override public void onViewRecycled ( VH holder ) { super . onViewRecycled ( holder ) ; holder . setDragStartCallback ( null ) ; public static abstract class ViewHolder extends RecyclerView . ViewHolder { private DragStartCallback mDragStartCallback ; public ViewHolder ( final View itemView , int handleResId , boolean dragOnLongPress ) { if ( dragOnLongPress ) { if ( mDragStartCallback == null ) { return false ; } if ( mDragStartCallback == null ) { return false ; } public void setDragStartCallback ( DragStartCallback dragStartedListener ) { mDragStartCallback = dragStartedListener ; }", "del_tokens": "private boolean mDragOnLongPress ; public DragItemAdapter ( boolean dragOnLongPress ) { mDragOnLongPress = dragOnLongPress ; } public abstract class ViewHolder extends RecyclerView . ViewHolder { public ViewHolder ( final View itemView , int handleResId ) { if ( mDragOnLongPress ) {", "commit_type": "make"}
{"commit_tokens": ["adding", "identity", "verification", "apis", "and", "test", "cases", "javadoc", "needs", "to", "be", "updated"], "add_tokens": "import com . plivo . api . models . identity . * ; @ Body AddressCreator addressCreator ) ; @ Path ( \"addressId\" ) String addressId , @ Body AddressUpdater addressUpdater ) ; // Identity @ POST ( \"Account/{authId}/Verification/Identity/\" ) Call < IdentityCreateResponse > identityCreate ( @ Path ( \"authId\" ) String authId , @ Body IdentityCreator identitycreator ) ; @ GET ( \"Account/{authId}/Verification/Identity/\" ) Call < ListResponse < Identity >> identityList ( @ Path ( \"authId\" ) String authId , @ QueryMap Map < String , Object > identityListRequest ) ; @ GET ( \"Account/{authId}/Verification/Identity/{id}/\" ) Call < Identity > identityGet ( @ Path ( \"authId\" ) String authId , @ Path ( \"id\" ) String id ) ; @ DELETE ( \"Account/{authId}/Verification/Identity/{id}/\" ) Call < ResponseBody > identityDelete ( @ Path ( \"authId\" ) String authId , @ Path ( \"id\" ) String number ) ; @ POST ( \"Account/{authId}/Verification/Identity/{id}/\" ) Call < IdentityUpdateResponse > identityUpdate ( @ Path ( \"authId\" ) String authId , @ Path ( \"id\" ) String identityId , @ Body IdentityUpdater identityUpdater ) ;", "del_tokens": "@ Body AddressCreator address ) ; @ Path ( \"addressId\" ) String addressId , @ Body AddressUpdater address ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "exception", "extracting", "zips", "when", "there", "are", "files", "in", "sub", "-", "dirs", "without", "proper", "dir", "-", "entries"], "add_tokens": "6 , results . size ( ) ) ; ZipEntry fileEntry3 = new ZipEntry ( \"subdir/subdir/file3\" ) ; zipout2 . putNextEntry ( fileEntry3 ) ; zipout2 . write ( \"testcontent\" . getBytes ( ) ) ; zipout2 . closeEntry ( ) ;", "del_tokens": "5 , results . size ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "post", "processing", "to", "handle", "hyphen"], "add_tokens": "private PostPOSTagger postPOSTagger ; postPOSTagger = new PostPOSTagger ( ) ; if ( MultiCogrooSettings . TOK ) { this . postPOSTagger . process ( sentence ) ; } } catch ( Exception e ) { LOGGER . error ( \"Error processing text: \" + text + \" sentences: \" + sentences , e ) ; //input = \"couves-flores, amores-perfeitos, gentis-homens, quintas-feiras, guarda-roupas, alto-falantes, reco-recos, águas-de-colônia, cavalos-vapor, palavras-chave, bota-fora, saca-rolhas, louva-a-deus\"; // input = \"Os inimigos que eram fácil derrotar estão próximo.\"; //input = \"A construção do trecho inicial da Linha 5-Lilás.\"; input = \"problemas político-econômicos\"; System . out . println ( s . getSentence ( ) ) ; System . out . println ( s ) ;", "del_tokens": "} catch ( RuntimeException e ) { e . printStackTrace ( ) ; // input = \"Vestia-se à Luís XV\"; input = \"Estes são os jogadores a quem entregaremos o prêmio.\";", "commit_type": "add"}
{"commit_tokens": ["Added", "option", "for", "async", "execution", "of", "the", "main", "ElasticSearch", "requests"], "add_tokens": "mapcfg . setEvictionPercentage ( getEvictionPercentage ( ) ) ; mapcfg . setEvictionPolicy ( getEvictionPolicy ( ) ) ; mapcfg . setMaxSizeConfig ( getMaxSize ( ) ) ; cfg . setProperty ( \"hazelcast.jmx\" , Boolean . toString ( isJMXOn ( ) ) ) ; private static MapConfig . EvictionPolicy getEvictionPolicy ( ) { return \"LFU\" . equals ( Config . getConfigParamUnwrapped ( \"hc.eviction_policy\" , \"LRU\" ) ) ? MapConfig . EvictionPolicy . LFU : MapConfig . EvictionPolicy . LRU ; } private static int getEvictionPercentage ( ) { return Config . getConfigParamUnwrapped ( \"hc.eviction_percentage\" , 25 ) ; } private static MaxSizeConfig getMaxSize ( ) { return new MaxSizeConfig ( ) . setSize ( Config . getConfigParamUnwrapped ( \"hc.max_size\" , 25 ) ) . setMaxSizePolicy ( USED_HEAP_PERCENTAGE ) ; } private static boolean isJMXOn ( ) { return Config . getConfigParamUnwrapped ( \"hc.jmx_enabled\" , true ) ; }", "del_tokens": "mapcfg . setEvictionPercentage ( 25 ) ; mapcfg . setEvictionPolicy ( MapConfig . EvictionPolicy . LRU ) ; mapcfg . setMaxSizeConfig ( new MaxSizeConfig ( ) . setSize ( 25 ) . setMaxSizePolicy ( USED_HEAP_PERCENTAGE ) ) ; cfg . setProperty ( \"hazelcast.jmx\" , \"true\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "return", "types", "to", "many", "of", "the", "methods", "in", "_2DMatrix", "class", "."], "add_tokens": "public final native void send ( Object data )", "del_tokens": "public final native void send ( JavaScriptObject data )", "commit_type": "add"}
{"commit_tokens": ["Adding", "an", "integration", "test", "on", "retry", "policy", "composition"], "add_tokens": "RetryPolicyObserver observer = new RetryPolicyObserver ( ) ; service = service . withFilter ( observer ) ; service = service . withFilter ( new ExponentialRetryPolicyFilter ( ExponentialRetryPolicyFilter . DEFAULT_MIN_BACKOFF , 3 , new int [ ] { 400 , 500 , 503 } ) ) ; ServiceException Error = null ; try { service . createPageBlob ( \"mycontainer1\" , \"test\" , 12 ) ; } catch ( ServiceException e ) { Error = e ; } // Assert assertNotNull ( Error ) ; assertEquals ( 400 , Error . getHttpStatusCode ( ) ) ; assertEquals ( 4 , observer . requestCount ) ; } @ Test public void retryPolicyCompositionWorks ( ) throws Exception { // Arrange Configuration config = createConfiguration ( ) ; BlobService service = config . create ( BlobService . class ) ; // Act service = service . withFilter ( new ExponentialRetryPolicyFilter ( ExponentialRetryPolicyFilter . DEFAULT_MIN_BACKOFF , 2 , new int [ ] { 400 , 500 , 503 } ) ) ; assertEquals ( 3 , observer . requestCount ) ;", "del_tokens": "assertEquals ( 4 , observer . requestCount ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "to", "/", "from", "CIEXYZ", "(", "via", "sRGB", "conversio", ")", "for", "completeness", "."], "add_tokens": "return sRGB . toCIEXYZ ( toRGB ( colorvalue ) ) ; return sRGB . fromCIEXYZ ( fromRGB ( colorvalue ) ) ;", "del_tokens": "throw new UnsupportedOperationException ( \"Method toCIEXYZ not implemented\" ) ; // TODO: Implement throw new UnsupportedOperationException ( \"Method fromCIEXYZ not implemented\" ) ; // TODO: Implement", "commit_type": "implement"}
{"commit_tokens": ["added", "help", "support", "thanks", "to", "@bravegag"], "add_tokens": "import org . springframework . core . io . ClassPathResource ; import org . springframework . core . io . Resource ; import org . valkyriercp . application . ApplicationDescriptor ; import org . valkyriercp . application . config . ApplicationConfig ; import org . valkyriercp . util . ValkyrieRepository ; import org . valkyriercp . util . WindowUtils ; import javax . help . HelpSet ; import javax . help . JHelp ; import java . awt . * ; applicationConfig = ValkyrieRepository . getInstance ( ) . getApplicationConfig ( ) ;", "del_tokens": "import java . awt . * ; import javax . help . * ; import org . springframework . beans . factory . annotation . * ; import org . springframework . core . io . * ; import org . valkyriercp . application . * ; import org . valkyriercp . application . config . * ; import org . valkyriercp . util . * ; @ Configurable @ Autowired // empty", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "Dockerfile", "s", "EXPOSE", "command"], "add_tokens": "import com . google . common . base . Joiner ; import java . util . Set ; import java . util . TreeSet ; @ Parameter ( property = \"dockerExposes\" ) private List < String > exposes ; private Set < String > exposesSet ; // Put the list of exposed ports into a TreeSet which will remove duplicates and keep them // in a sorted order. This is useful when we merge with ports defined in the profile. exposesSet = new TreeSet < String > ( exposes ) ; expressionEvaluator = new PluginParameterExpressionEvaluator ( session , execution ) ; // Exposed ports List < String > exposesList = emptyList ( ) ; try { exposesList = profileConfig . getStringList ( \"exposes\" ) ; } catch ( ConfigException . Missing ignore ) { } for ( final String raw : exposesList ) { exposesSet . add ( expand ( raw ) ) ; } if ( exposesSet . size ( ) > 0 ) { // The values will be sorted with no duplicated since exposesSet is a TreeSet commands . add ( \"EXPOSE \" + Joiner . on ( \" \" ) . join ( exposesSet ) ) ; }", "del_tokens": "expressionEvaluator = new PluginParameterExpressionEvaluator ( session , execution ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "isPasswordCorrect", "protected", "to", "facilitate", "subclass", "use", "."], "add_tokens": "protected boolean isPasswordCorrect ( Authentication authentication , User user ) {", "del_tokens": "private boolean isPasswordCorrect ( Authentication authentication , User user ) {", "commit_type": "make"}
{"commit_tokens": ["fix", "pmd", "and", "findbugs", "warnings", "for", "idl", "and", "service", "module"], "add_tokens": "import java . util . ArrayList ; import java . util . BitSet ; import java . util . Collections ; import java . util . EnumMap ; import java . util . EnumSet ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; private static final long serialVersionUID = 1L ; private static final long serialVersionUID = 1L ;", "del_tokens": "import java . util . ArrayList ; import java . util . BitSet ; import java . util . Collections ; import java . util . EnumMap ; import java . util . EnumSet ; import java . util . HashMap ; import java . util . List ; import java . util . Map ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "convenience", "factory", "method", "that", "takes", "only", "a", "port", "number"], "add_tokens": "DB db = DB . newEmbeddedDB ( 3307 ) ;", "del_tokens": "Configuration options = new Configuration ( ) ; options . setPort ( 3307 ) ; DB db = DB . newEmbeddedDB ( options ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "findbugs", "warnings", "."], "add_tokens": "if ( input == null ) throw new BuildException ( \"Input not specified\" ) ; if ( output == null ) throw new BuildException ( \"Output not specified\" ) ; / * FilterSetCollection executionFilters = new FilterSetCollection ( ) ; if ( filtering ) { executionFilters . addFilterSet ( getProject ( ) . getGlobalFilterSet ( ) ) ; } for ( Enumeration filterEnum = getFilterSets ( ) . elements ( ) ; filterEnum . hasMoreElements ( ) ; ) { executionFilters . addFilterSet ( ( FilterSet ) filterEnum . nextElement ( ) ) ; } * /", "del_tokens": "import org . apache . tools . ant . types . FilterSet ; import org . apache . tools . ant . types . FilterSetCollection ; if ( input == null ) throw new BuildException ( \"Input not specified\" ) ; if ( output == null ) throw new BuildException ( \"Output not specified\" ) ; FilterSetCollection executionFilters = new FilterSetCollection ( ) ; if ( filtering ) { executionFilters . addFilterSet ( getProject ( ) . getGlobalFilterSet ( ) ) ; } for ( Enumeration filterEnum = getFilterSets ( ) . elements ( ) ; filterEnum . hasMoreElements ( ) ; ) { executionFilters . addFilterSet ( ( FilterSet ) filterEnum . nextElement ( ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["added", "hbase", "client", "to", "pom", "added", "test", "vars", "began", "implementing", "table", "create", "and", "put", "test"], "add_tokens": "import org . apache . hadoop . hbase . client . HBaseAdmin ; createHbaseTable ( propertyParser . getProperty ( ConfigVars . HBASE_TEST_TABLE_NAME_KEY ) , hbaseLocalCluster . getHbaseConfiguration ( ) ) ; private static void createHbaseTable ( String tableName , Configuration configuration ) { try { final HBaseAdmin admin = new HBaseAdmin ( configuration ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } }", "del_tokens": "import com . github . sakserv . minicluster . impl . HdfsLocalCluster ; import org . apache . hadoop . fs . FSDataInputStream ; import org . apache . hadoop . fs . FSDataOutputStream ; import org . apache . hadoop . fs . FileSystem ; import org . apache . hadoop . fs . Path ; import org . apache . hadoop . hbase . MiniHBaseCluster ; assertEquals ( propertyParser . getProperty ( ConfigVars . HBASE_ZNODE_PARENT_KEY ) , hbaseLocalCluster . getZookeeperZnodeParent ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "test", "for", "Rserve", "install"], "add_tokens": "//new File(Rout).deleteOnExit();", "del_tokens": "import java . io . FileFilter ; import java . util . logging . Level ; import java . util . logging . Logger ; import org . apache . commons . io . FileSystemUtils ; import org . apache . commons . vfs2 . FileContent ; new File ( Rout ) . deleteOnExit ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "value", "read", "-", "back", "to", "test", "of", "unsigned", "write"], "add_tokens": "* @ throws InterruptedException public final void testWriteGroupAddressIntString ( ) throws KNXException , InterruptedException final int v = 80 ; pc . write ( dpUnsigned1 , v , ProcessCommunicationBase . SCALING ) ; Thread . sleep ( 100 ) ; final int i = pc . readUnsigned ( dpUnsigned1 , ProcessCommunicationBase . SCALING ) ; assertEquals ( v , i ) ;", "del_tokens": "public final void testWriteGroupAddressIntString ( ) throws KNXException pc . write ( dpUnsigned1 , 80 , ProcessCommunicationBase . SCALING ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "the", "clear", "planting", "event", "handling", "to", "avoid", "changing", "the", "original", "data", "set"], "add_tokens": "// Iterator<HashMap<String, String>> iter = eventData.iterator(); // while (iter.hasNext()) { // if (getValueOr(iter.next(), \"event\", \"\").equals(\"planting\")) { // iter.remove(); // } // } // event.removeEvent();", "del_tokens": "Iterator < HashMap < String , String > > iter = eventData . iterator ( ) ; while ( iter . hasNext ( ) ) { if ( getValueOr ( iter . next ( ) , \"event\" , \"\" ) . equals ( \"planting\" ) ) { iter . remove ( ) ; } } event . removeEvent ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["removing", "bogus", "onError", "method", "and", "throw", "custom", "exception", "instead"], "add_tokens": "* Will be called when push message could be delivered . Please consult the * for details . void onComplete ( ) ;", "del_tokens": "* Will be called whatever the response status code is . It 's the developer * responsibility to implement the status code handling . Please consult the * for a list of valid responses . * * @ param statusCode the status code as returned by the server . void onComplete ( int statusCode ) ; / * * * Will be called if an Exception occurs ( i . e : { @ link java . io . IOException } ) * * @ param throwable contains failure details . * / void onError ( Throwable throwable ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "testcases", "for", "change", "-", "abandoned", "and", "change", "-", "restored", "events"], "add_tokens": "/ * * * The person who triggered this event . * / private Account abandoner ; / * * * Get the abandoner who triggered this event . * @ return the abandoner * / public Account getAbandoner ( ) { return this . abandoner ; } / * * * Set the abandoner for this event . * @ param abandoner the abandoner to set * / public void setAbandoner ( Account abandoner ) { this . abandoner = abandoner ; } abandoner = new Account ( json . getJSONObject ( ABANDONER ) ) ;", "del_tokens": "account = new Account ( json . getJSONObject ( ABANDONER ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "shared", "string", "builder", "and", "lambda", "for", "sample", "value", "handling"], "add_tokens": "final StringBuilder sampleValue = new StringBuilder ( ) ; Consumer < ? super String > sampleHandler = s -> { if ( sampleValue . length ( ) > 0 ) { sampleValue . append ( \", \" ) ; } sampleValue . append ( s ) ; } ; } finally { sampleValue . setLength ( 0 ) ;", "del_tokens": "final StringBuilder sampleValue = new StringBuilder ( ) ; Consumer < ? super String > sampleHandler = s -> { if ( sampleValue . length ( ) > 0 ) { sampleValue . append ( \", \" ) ; } sampleValue . append ( s ) ; } ;", "commit_type": "use"}
{"commit_tokens": ["add", "metric", "connection", "to", "kafka", "topics"], "add_tokens": "import org . springframework . beans . factory . annotation . Value ; import org . springframework . kafka . core . KafkaAdmin ; import java . util . List ; private static final String PROP_METRIC_CONNECTION_TO_TOPIC = \"kafka\" ; private final KafkaAdmin kafkaAdmin ; @ Value ( \"${application.kafkaMetric.enabled:false}\" ) private Boolean kafkaMetricEnabled ; @ Value ( \"${application.kafkaMetric.connectionTimeoutTopic:#{null}}\" ) private Integer connectionTimeoutTopic ; @ Value ( \"${application.kafkaMetric.metricTopics:#{null}}\" ) private List < String > metricTopics ; public MetricsConfiguration ( JHipsterProperties jhipsterProperties , KafkaAdmin kafkaAdmin ) { this . kafkaAdmin = kafkaAdmin ; if ( kafkaMetricEnabled ) { metricRegistry . register ( PROP_METRIC_CONNECTION_TO_TOPIC , new KafkaMetricsSet ( kafkaAdmin , connectionTimeoutTopic , metricTopics ) ) ; }", "del_tokens": "public MetricsConfiguration ( JHipsterProperties jhipsterProperties ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "crash", "on", "missing", "main"], "add_tokens": "JsonNode mainJs = jsonNode . get ( \"main\" ) ; if ( mainJs == null ) throw new IllegalArgumentException ( \"no 'main' attribute; cannot generate a config\" ) ; if ( mainJs . getNodeType ( ) == JsonNodeType . STRING ) { String main = mainJs . asText ( ) ; else if ( mainJs . getNodeType ( ) == JsonNodeType . ARRAY ) { for ( JsonNode mainJsonNode : mainJs ) { } catch ( IllegalArgumentException e ) { e . printStackTrace ( ) ; log . warn ( \"Could not create the RequireJS config for the \" + webJar . getKey ( ) + \" \" + webJar . getValue ( ) + \" WebJar\" + \" from \" + path + \"\\n\" + \"There was not enough information in the package metadata to do so.\\n\" + \"If you think you have received this message in error, \" + \"please file a bug at: http://github.com/webjars/webjars-locator/issues/new\" ) ;", "del_tokens": "if ( jsonNode . get ( \"main\" ) . getNodeType ( ) == JsonNodeType . STRING ) { String main = jsonNode . get ( \"main\" ) . asText ( ) ; else if ( jsonNode . get ( \"main\" ) . getNodeType ( ) == JsonNodeType . ARRAY ) { for ( JsonNode mainJsonNode : jsonNode . withArray ( \"main\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Made", "the", "password", "length", "128", "to", "accomodate", "Azure"], "add_tokens": "+ \"password VARCHAR(128) NOT NULL)\" ;", "del_tokens": "+ \"password VARCHAR(64) NOT NULL)\" ;", "commit_type": "make"}
{"commit_tokens": ["Added", "old", "password", "validation", "to", "change", "password", "function", "except", "for", "admin", "."], "add_tokens": "void changePassword ( Authorizable authorizable , String password , String oldPassword ) throws StorageClientException , AccessDeniedException ;", "del_tokens": "void changePassword ( Authorizable authorizable , String password ) throws StorageClientException , AccessDeniedException ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "the", "SpecTopic", "DBId", "variable", "to", "an", "Integer", "rather", "than", "a", "primitive", "int", "."], "add_tokens": "if ( childTopic . getDBId ( ) . equals ( DBId ) ) { if ( childTopic . getDBId ( ) . equals ( topicId ) ) {", "del_tokens": "if ( childTopic . getDBId ( ) == DBId ) { if ( childTopic . getDBId ( ) == topicId ) {", "commit_type": "change"}
{"commit_tokens": ["fixing", "unbind", "with", "multiple", "events", "(", "fixes", "issue48", ")"], "add_tokens": "return ( type & etype ) == type ;", "del_tokens": "return ( type | etype ) == type ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "protocol", "version", "and", "description", "to", "server", "info"], "add_tokens": "public static final String protocolVersion = \"0.1\" ;", "del_tokens": "bootstrapServerList . add ( \"http://nanopub-server.ops.labs.vu.nl/\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "error", "during", "reading", "card"], "add_tokens": "mException = false ; } else { display ( getResources ( ) . getText ( R . string . error_communication_nfc ) , false ) ;", "del_tokens": "display ( getResources ( ) . getText ( R . string . error_communication_nfc ) , false ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "for", "RubyArray", "factory", "methods"], "add_tokens": "public < S > RubyArray < S > assoc ( S target ) { for ( E item : list ) { if ( item instanceof List ) { @ SuppressWarnings ( \"unchecked\" ) List < S > itemList = ( List < S > ) item ; if ( itemList . size ( ) > 0 && itemList . get ( 0 ) . equals ( target ) ) { return newRubyArray ( itemList , true ) ; } } } return null ; }", "del_tokens": "public < S > RubyArray < S > assoc ( S target ) { for ( E item : list ) { if ( item instanceof List ) { @ SuppressWarnings ( \"unchecked\" ) List < S > itemList = ( List < S > ) item ; if ( itemList . size ( ) > 0 && itemList . get ( 0 ) . equals ( target ) ) { return newRubyArray ( itemList , true ) ; } } } return null ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "statementToResultSet", "()", "method", "to", "OrmElf", "cleaned", "up", "JavaDoc", "."], "add_tokens": "* @ return the number of rows updated }", "del_tokens": "}", "commit_type": "add"}
{"commit_tokens": ["Add", "finally", "blocks", "to", "close", "stream", "."], "add_tokens": "import org . apache . commons . io . IOUtils ; InputStream inputStream = null ; } finally { IOUtils . closeQuietly ( inputStream ) ;", "del_tokens": "InputStream inputStream ;", "commit_type": "add"}
{"commit_tokens": ["adds", "a", "real", "-", "life", "example", "to", "the", "tests"], "add_tokens": "//TODO: we need to loop over the textelement characters // because it is possible for a textelement to contain multiple characters?", "del_tokens": "//TODO: we might need to loop over the textelement characters // is it possible for a textelement to contain multiple characters?", "commit_type": "add"}
{"commit_tokens": ["Implemented", "encodings", "for", "Bourne", "shell", "scripts", "MySQL", "command", "line", "mysql", "and", "PostgreSQL", "command", "line", "psql", "."], "add_tokens": "* Copyright ( C ) 2009 , 2010 , 2011 , 2013 , 2015 , 2016 , 2018 AO Industries , Inc . case SH : return new ShValidator ( out ) ; case MYSQL : return new MysqlValidator ( out ) ; case PSQL : return new PsqlValidator ( out ) ;", "del_tokens": "* Copyright ( C ) 2009 , 2010 , 2011 , 2013 , 2015 , 2016 AO Industries , Inc .", "commit_type": "implement"}
{"commit_tokens": ["Updated", "examples", "to", "use", "HttpRestClient"], "add_tokens": "import com . github . jreddit . utils . restclient . HttpRestClient ; import com . github . jreddit . utils . restclient . RestClient ; RestClient restClient = new HttpRestClient ( ) ; restClient . setUserAgent ( \"Generous-Bot\" ) ; User user = new User ( restclient , \"user\" , \"password\" ) ;", "del_tokens": "import com . github . jreddit . utils . Utils ; Utils . setUserAgent ( \"Generous-Bot\" ) ; User user = new User ( \"user\" , \"password\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "tests", "for", "issue", "74"], "add_tokens": "config = new JdbcConfig ( \"driverClassName\" , \"url\" , \"username\" , \"password\" , \"showSql\" , \"mysql\" , \"none\" , new Properties ( ) , null , \"false\" , 100 ) ; assertThat ( config . getMaxPoolSize ( ) , is ( 100 ) ) ;", "del_tokens": "config = new JdbcConfig ( \"driverClassName\" , \"url\" , \"username\" , \"password\" , \"showSql\" , \"mysql\" , \"none\" , new Properties ( ) , null , \"false\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "stupid", "bug", "(", "play", "has", "dependency", "to", "playerontroller", "and", "reverse", "...", "not", "able", "to", "instantiate", "one", "of", "them", ")"], "add_tokens": "private Player player ; public PlayerController ( Context context , String ID ) { super ( context , ID ) ; this . player = null ; } public void setPlayer ( Player player ) { this . player = player ; }", "del_tokens": "private final Player player ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "checkClosed", "()", "to", "all", "three", "receive", "*", "()", "methods"], "add_tokens": "* this message consumer is closed during the receive call checkClosed ( ) ; * the timeout expires or this message consumer is closed during the receive call checkClosed ( ) ; checkClosed ( ) ;", "del_tokens": "* this message consumer is closed * the timeout expires or this message consumer is closed", "commit_type": "add"}
{"commit_tokens": ["making", "changes", "to", "support", "loose", "files", "in", "classpath"], "add_tokens": "//String lcPath= paths[i].toLowerCase(); //if ( lcPath.endsWith(\".jar\") || lcPath.endsWith(\".zip\") ) if ( BshClassPath . isArchiveFileName ( paths [ i ] ) try { System . out . println ( \"Adding classes: \" + paths [ i ] ) ; addJar ( paths [ i ] ) ; } catch ( IOException e ) { }", "del_tokens": "String lcPath = paths [ i ] . toLowerCase ( ) ; if ( lcPath . endsWith ( \".jar\" ) || lcPath . endsWith ( \".zip\" ) ) try { System . out . println ( \"Adding classes: \" + paths [ i ] ) ; addJar ( paths [ i ] ) ; } catch ( IOException e ) { }", "commit_type": "make"}
{"commit_tokens": ["Added", "for", "loop", "inside", "builder", "syntax", "."], "add_tokens": "Class clazz = cl . parseClass ( \"import grails.util.*; class TestClass { List names = [\\\"Steven\\\", \\\"Hans\\\", \\\"Erwin\\\"]; @Property Closure test = { response -> new OpenRicoBuilder(response).\" + groovy + \"; } }\" ) ; parse ( \"ajax { element(id:\\\"test\\\") { select(name:\\\"test\\\") { for (name in names) { span(name) } } } }\" ) ;", "del_tokens": "Class clazz = cl . parseClass ( \"import grails.util.*; class TestClass { @Property Closure test = { response -> new OpenRicoBuilder(response).\" + groovy + \"; } }\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "a", "simple", "example", "for", "ModelType", ".", "OBJECT", "support", "."], "add_tokens": "import java . util . HashMap ; import java . util . Map ; // Simple support for ModelType.LIST // Simple support for ModelType.OBJECT final HashMap < String , String > file = new HashMap ( ) ; file . put ( \"path\" , \"/path/to/some/log\" ) ; file . put ( \"relative-to\" , \"jboss.server.log.dir\" ) ; final HashMap < String , String > formatterProperties = new HashMap < > ( ) ; formatterProperties . put ( \"metaData\" , \"someKey=someValue,otherKey=otherValue\" ) ; final HashMap < String , String > handlerProperties = new HashMap < > ( ) ; handlerProperties . put ( \"one-key\" , \"one-key-value-expression\" ) ; handlerProperties . put ( \"two-key\" , \"two-key-value-expression\" ) ; . attributeClass ( \"FormatterClassName\" ) . properties ( formatterProperties ) ) . namedFormatter ( \"formatter-name\" ) . file ( file ) ) . level ( \"INFO\" ) . properties ( handlerProperties ) )", "del_tokens": ". attributeClass ( \"FormatterClassName\" ) ) . namedFormatter ( \"formatter-name\" ) ) . level ( \"INFO\" ) )", "commit_type": "add"}
{"commit_tokens": ["Make", "Sonar", "happy", "and", "log", "the", "whole", "exception"], "add_tokens": "LOGGER . warn ( \"Could not get processor from context, instantiating new instance instead\" , e ) ;", "del_tokens": "LOGGER . warn ( \"Could not get processor from context: {}, instantiating new instance instead\" , e . getMessage ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["added", "call", "to", "find", "()", "on", "matcher"], "add_tokens": "private static final String METHOD_PATTERN = \"(listOrderBy)(\\\\w+)\" ; // find match match . find ( ) ; final String propertyName = nameInSignature . substring ( 0 , 1 ) . toLowerCase ( ) +", "del_tokens": "private static final String METHOD_PATTERN = \"(listOrderBy)(\\\\+)\" ; final String propertyName = nameInSignature . substring ( 0 , 0 ) . toLowerCase ( ) +", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "in", "keys", "in", "super", "classes"], "add_tokens": "try { field = t . getDeclaredField ( fieldName ) ; } catch ( NoSuchFieldException ignore ) { // ignore }", "del_tokens": "field = t . getDeclaredField ( fieldName ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "some", "basic", "files", "for", "the", "retrieve", "part", "of", "the", "ASTP"], "add_tokens": "import de . metalcon . autocompleteServer . Helper . ProcessRetrieveRequest ; public class RetrieveServlet extends HttpServlet { public RetrieveServlet ( ) { ProcessRetrieveRequest . checkRequestParameter ( request ) ; out . println ( \"[\" + SearchResult + timeSpent + \"]\" ) ;", "del_tokens": "public class TestServlet extends HttpServlet { public TestServlet ( ) { out . println ( \"{\" + SearchResult + timeSpent + \"}\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "use", "of", "deprecated", "APIs", "."], "add_tokens": "import com . google . common . base . MoreObjects ; import com . intellij . openapi . vfs . VfsUtilCore ; URL baseUrl = VfsUtilCore . convertToURL ( file . getVirtualFile ( ) . getUrl ( ) ) ; return MoreObjects . firstNonNull ( urls , Collections . < String , URL > emptyMap ( ) ) ;", "del_tokens": "import com . google . common . base . Objects ; import com . intellij . openapi . vfs . VfsUtil ; URL baseUrl = VfsUtil . convertToURL ( file . getVirtualFile ( ) . getUrl ( ) ) ; return Objects . firstNonNull ( urls , Collections . < String , URL > emptyMap ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Upgrade", "to", "new", "AddonManager", "API"], "add_tokens": "import org . jboss . forge . addon . manager . spi . AddonDependencyResolver ; import org . jboss . forge . addon . maven . addon . MavenAddonDependencyResolver ; AddonDependencyResolver resolver = new MavenAddonDependencyResolver ( ) ; AddonManager manager = new AddonManagerImpl ( furnace , resolver , false ) ;", "del_tokens": "import org . jboss . forge . addon . maven . dependencies . FileResourceFactory ; import org . jboss . forge . addon . maven . dependencies . MavenContainer ; import org . jboss . forge . addon . maven . dependencies . MavenDependencyResolver ; MavenDependencyResolver resolver = new MavenDependencyResolver ( new FileResourceFactory ( ) , new MavenContainer ( ) ) ; AddonManager manager = new AddonManagerImpl ( furnace , resolver ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["Add", "@EndpointInject", "support", "for", "multi", "Camel", "contexts"], "add_tokens": "import static org . apache . camel . cdi . se . expression . ExchangeExpression . fromCamelContext ;", "del_tokens": "import org . apache . camel . Exchange ; import org . apache . camel . Expression ; import org . apache . camel . Predicate ; import org . apache . camel . util . PredicateToExpressionAdapter ; private static Expression fromCamelContext ( final String name ) { return new PredicateToExpressionAdapter ( new Predicate ( ) { @ Override public boolean matches ( Exchange exchange ) { return exchange . getContext ( ) . getName ( ) . equals ( name ) ; } } ) ; }", "commit_type": "add"}
{"commit_tokens": ["Moving", "Option", "to", "common", "instead", "of", "common", ".", "values", ".", "Option", "is", "a", "not", "a", "value", "but", "rather", "a", "value", "producing", "object", ".", "Same", "goes", "for", "AbstractIdentifier", "which", "will", "be", "moved", "next", "."], "add_tokens": "package com . kaching . platform . common ;", "del_tokens": "package com . kaching . platform . common . values ;", "commit_type": "move"}
{"commit_tokens": ["Add", "utility", "method", "to", "construct", "SaneWord", "from", "a", "byte", "[]", "with", "offset"], "add_tokens": "import static org . junit . Assert . assertEquals ; * @ Test public void fromArrayWithOffset ( ) { byte [ ] array = new byte [ ] { 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 4 } ; assertEquals ( 0 , SaneWord . fromBytes ( array , 0 ) . integerValue ( ) ) ; assertEquals ( 1 , SaneWord . fromBytes ( array , 4 ) . integerValue ( ) ) ; assertEquals ( 2 , SaneWord . fromBytes ( array , 8 ) . integerValue ( ) ) ; assertEquals ( 3 , SaneWord . fromBytes ( array , 12 ) . integerValue ( ) ) ; assertEquals ( 4 , SaneWord . fromBytes ( array , 16 ) . integerValue ( ) ) ; }", "del_tokens": "import static org . junit . Assert . * ; *", "commit_type": "add"}
{"commit_tokens": ["Implemented", "a", "close", "method", "on", "the", "database", ".", "Normally", "the", "migrations", "are", "executed", "during", "application", "startup", "so", "there", "is", "no", "need", "to", "hold", "an", "open", "session", "in", "memory", "if", "it", "will", "not", "be", "used", "anymore", "."], "add_tokens": "import java . io . Closeable ; public class Database implements Closeable { / * * * Closes the underlying session object . The cluster will not be touched * and will stay open . Call this after all migrations are done . * After calling this , this database instance can no longer be used . * / public void close ( ) { this . session . close ( ) ; }", "del_tokens": "public class Database {", "commit_type": "implement"}
{"commit_tokens": ["added", "comment", "regarding", "implementing", "serializable", "so", "we", "might", "fix", "it", "one", "day", "."], "add_tokens": "//we implement Serializable just because RAS uses spring-remoting that requires it //it should be removed from score and handled in oo public class EventWrapper implements Serializable {", "del_tokens": "public class EventWrapper implements Serializable {", "commit_type": "add"}
{"commit_tokens": ["Use", "busy", "spin", "for", "1P1C", "perf", "test"], "add_tokens": "WaitStrategy . Option . BUSY_SPIN ) ; Assert . assertTrue ( \"Performance preserved\" , disruptorOpsPerSecond > ( blockingQueueOpsPerSecond * 2 ) ) ; while ( producerBarrier . getConsumedSequence ( ) < expectedSequence )", "del_tokens": "WaitStrategy . Option . YIELDING ) ; Assert . assertTrue ( disruptorOpsPerSecond > blockingQueueOpsPerSecond ) ; while ( batchEntryConsumer . getSequence ( ) < expectedSequence )", "commit_type": "use"}
{"commit_tokens": ["updated", "sample", "to", "better", "reflect", "real", "world", "use"], "add_tokens": "String headerText = \"\" + countries [ position ] . subSequence ( 0 , 1 ) . charAt ( 0 ) ;", "del_tokens": "char headerChar = countries [ position ] . subSequence ( 0 , 1 ) . charAt ( 0 ) ; String headerText ; if ( headerChar % 2 == 0 ) { headerText = headerChar + \"\\n\" + headerChar + \"\\n\" + headerChar ; } else { headerText = headerChar + \"\\n\" + headerChar ; }", "commit_type": "update"}
{"commit_tokens": ["remove", "unnecessary", "lines", ".", "sorry", "."], "add_tokens": "args = new String [ ] { \"ILLEGAL_ANIMAL\" } ; Assert . assertTrue ( \"Illegal exception message: \" + e . getMessage ( ) , e . getMessage ( ) . startsWith ( String . format ( \"\\\"%s\\\" is not a valid value for \\\"\" , args [ args . length - 1 ] ) ) ) ;", "del_tokens": "String [ ] args = new String [ ] { \"ILLEGAL_ANIMAL\" } ; parseParameter ( args , new EnumArgument ( ) ) ; } private void parseParameter ( String [ ] args , Object bean ) { CmdLineParser parser = new CmdLineParser ( bean ) ; if ( args . length > 0 ) { Assert . assertTrue ( \"Illegal exception message: \" + e . getMessage ( ) , e . getMessage ( ) . startsWith ( String . format ( \"\\\"%s\\\" is not a valid value for \\\"\" , args [ args . length - 1 ] ) ) ) ; } else { Assert . assertEquals ( \"Illegal exception message: \" + e . getMessage ( ) , \"Argument \\\"ANIMAL\\\" is required\" , e . getMessage ( ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Added", "generation", "of", "javadoc", "and", "source", "artifacts", "."], "add_tokens": "* @ return raw http client", "del_tokens": "* @ return", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "retrieving", "custom", "user", "data"], "add_tokens": "if ( ! jsonObject . isNull ( String . valueOf ( key ) ) ) { map . put ( ( String ) key , ( String ) jsonObject . get ( String . valueOf ( key ) ) ) ; } else { map . put ( ( String ) key , null ) ; }", "del_tokens": "map . put ( ( String ) key , ( String ) jsonObject . get ( String . valueOf ( key ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Improve", "tests", "for", "PreparedGet", "operation", "for", "StorIODb", "and", "StorIOContentProvider"], "add_tokens": "public Builder < T > withGetResolver ( @ NonNull GetResolver getResolver ) {", "del_tokens": "public Builder withGetResolver ( @ NonNull GetResolver getResolver ) {", "commit_type": "improve"}
{"commit_tokens": ["Fixed", "assertj", "dependencies", "instead", "of", "Guava"], "add_tokens": "import com . google . common . collect . Lists ; import com . google . common . collect . Maps ; import com . google . common . collect . Sets ;", "del_tokens": "import org . assertj . core . util . Lists ; import org . assertj . core . util . Maps ; import org . assertj . core . util . Sets ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "same", "config", "key", "for", "bigtable", "instance"], "add_tokens": "public static final String BIGTABLE_INSTANCE_ID = \"styx.bigtable.instance-id\" ; public static StyxScheduler createDefault ( ) { return newBuilder ( ) . build ( ) ; } final String instanceId = config . getString ( BIGTABLE_INSTANCE_ID ) ; LOG . info ( \"Creating Bigtable connection for project:{}, instance:{}\" , projectId , instanceId ) ; return BigtableConfiguration . connect ( projectId , instanceId ) ;", "del_tokens": "public static final String BIGTABLE_CLUSTER_ID = \"styx.bigtable.cluster-id\" ; public static final String PUBSUB_PROJECT_ID = \"styx.pubsub.project-id\" ; public static final String PUBSUB_AUDIT_DEPLOY_TOPIC = \"styx.pubsub.audit.deploy-topic\" ; final String clusterId = config . getString ( BIGTABLE_CLUSTER_ID ) ; LOG . info ( \"Creating Bigtable connection for project:{}, cluster:{}\" , projectId , clusterId ) ; return BigtableConfiguration . connect ( projectId , clusterId ) ;", "commit_type": "use"}
{"commit_tokens": ["Use", "the", "correct", "symbol", "notation"], "add_tokens": "subscribeJson . put ( \"symbol\" , orderbookConfiguration . getCurrencyPair ( ) . toBitfinexString ( ) ) ;", "del_tokens": "subscribeJson . put ( \"symbol\" , orderbookConfiguration . getCurrencyPair ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Add", "interaction", "votes", "and", "replies", "endpoints", "rename", "get", "."], "add_tokens": "import com . uwetrottmann . getglue . entities . GetGlueInteraction ; import java . util . List ; * Endpoints for < a href = \"http://developer.getglue.com/#interaction-resources\" > Interaction * Resources < / a > . / * * * Retrieves the specified interaction . Returns an Interaction resource . * / GetGlueInteractionResource get ( @ EncodedPath ( \"interaction-id\" ) String interactionId ) ; / * * * Retrieves the collection of vote interactions attached to the specified parent interaction . * Returns an array of Interaction resources . * / @ GET ( \"/{interaction-id}/votes\" ) List < GetGlueInteraction > votes ( @ EncodedPath ( \"interaction-id\" ) String interactionId ) ; / * * * Retrieves the collection of reply interactions attached to the specified parent interaction . * Returns an array of Interaction resources . * / @ GET ( \"/{interaction-id}/replies\" ) List < GetGlueInteraction > replies (", "del_tokens": "* Endpoints for < a href = \"http://developer.getglue.com/#interaction-resources\" > Interaction Resources < / a > . GetGlueInteractionResource getInteraction (", "commit_type": "add"}
{"commit_tokens": ["create", "linked", "map", "to", "allow", "map", "operations"], "add_tokens": "import java . util . LinkedHashMap ; Map < K , Integer > linkedMap = new LinkedHashMap < K , Integer > ( newMap ) ; return linkedMap ;", "del_tokens": "return newMap ;", "commit_type": "create"}
{"commit_tokens": ["Added", "offset", "and", "length", "to", "KoreanToken"], "add_tokens": "public CharSequence stem ( CharSequence text ) {", "del_tokens": "import com . twitter . penguin . korean . TwitterKoreanProcessor . KoreanSegment ; import com . twitter . penguin . korean . TwitterKoreanProcessor . KoreanSegmentWithText ; public KoreanStemmer . StemmedTextWithTokens stem ( CharSequence text ) { / * * * Tokenize into KoreanSegments , which includes the indices * * @ param text Input text . * @ return A list of KoreanSegments . * / public List < KoreanSegment > tokenizeWithIndex ( CharSequence text ) { return JavaConversions . seqAsJavaList ( TwitterKoreanProcessor . tokenizeWithIndex ( text ) ) ; } / * * * Tokenize into KoreanSegmentWithText , which includes * the stemmed text and the KoreanSegments * * @ param text Input text . * @ return KoreanSegmentWithText ( text , KoreanSegments ) * / public KoreanSegmentWithText tokenizeWithIndexWithStemmer ( CharSequence text ) { return TwitterKoreanProcessor . tokenizeWithIndexWithStemmer ( text ) ; }", "commit_type": "add"}
{"commit_tokens": ["Removed", "time", "checking", "for", "mt", "messages"], "add_tokens": "// if (TimeOverlord.getInstance().getTimeAccuracy() < 10) { // long time = (messageId >> 32); // long serverTime = TimeOverlord.getInstance().getServerTime(); // // if (serverTime + 30 < time) { // return null; // } // // if (time < serverTime - 300) { // return null; // } // } Logger . d ( TAG , \"message ignored\" ) ;", "del_tokens": "if ( TimeOverlord . getInstance ( ) . getTimeAccuracy ( ) < 10 ) { long time = ( messageId >> 32 ) ; long serverTime = TimeOverlord . getInstance ( ) . getServerTime ( ) ; if ( serverTime + 30 < time ) { return null ; } if ( time < serverTime - 300 ) { return null ; } }", "commit_type": "remove"}
{"commit_tokens": ["Add", "license", "to", "package", "htmlflow", ".", "elements", "files"], "add_tokens": "/ * * Copyright ( c ) 2016 , Miguel Gamboa * * This program is free software : you can redistribute it and / or modify * it under the terms of the GNU General Public License as published by * the Free Software Foundation , either version 3 of the License , or * ( at your option ) any later version . * * This program is distributed in the hope that it will be useful , * but WITHOUT ANY WARRANTY ; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the * GNU General Public License for more details . * * You should have received a copy of the GNU General Public License * along with this program . If not , see < http : //www.gnu.org/licenses/>. * / * @ author Miguel Gamboa * created on 29 - 03 - 2012", "del_tokens": "* @ uml . dependency supplier = \"htmlflow.ModelBinder\"", "commit_type": "add"}
{"commit_tokens": ["Add", "nicer", "error", "message", "when", "new", "string", "value", "size", "exceeds", "max", "size", "."], "add_tokens": "Preconditions . checkState ( newValue . length ( ) < getSize ( ) , \"string value '\" + newValue + \"' (length=\" + newValue . length ( ) + \") exceeds maximum size of \" + ( getSize ( ) - 1 ) + \" byte(s) for option \" + getName ( ) ) ;", "del_tokens": "Preconditions . checkState ( newValue . length ( ) < getSize ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "Copyable", "interface", "to", "get", "around", "nasty", "Cloneable", "contract", "if", "required"], "add_tokens": "import com . kscs . util . jaxb . Copyable ; groupInterface . _implements ( Copyable . class ) ;", "del_tokens": "final JMethod cloneMethod = groupInterface . method ( JMod . PUBLIC , this . apiConstructs . codeModel . ref ( Object . class ) , \"clone\" ) ; if ( this . cloneMethodThrows ) { cloneMethod . _throws ( CloneNotSupportedException . class ) ; }", "commit_type": "add"}
{"commit_tokens": ["Create", "a", "test", "case", "runner", "that", "will", "modify", "testsuite", "properties"], "add_tokens": "import org . ktc . soapui . maven . extension . impl . runner . SoapUIExtensionTestCaseRunner ; return new SoapUIExtensionTestCaseRunner ( \"SoapUI Maven2 TestCase Runner\" ) ;", "del_tokens": "return new SoapUITestCaseRunner ( \"SoapUI Maven2 TestCase Runner\" ) ;", "commit_type": "create"}
{"commit_tokens": ["Add", "@Deprecated", "anotation", "re", "-", "add", "tests", "using", "deprecated", "setters"], "add_tokens": "@ Deprecated @ Deprecated @ Deprecated", "del_tokens": "* @ deprecated * @ deprecated * @ deprecated", "commit_type": "add"}
{"commit_tokens": ["make", "utility", "classes", "package", "private"], "add_tokens": "final class ObjectUtils { static < T > Class < T > getClass ( Object object ) { static String getHumanClassName ( Object object ) {", "del_tokens": "public final class ObjectUtils { public static < T > Class < T > getClass ( Object object ) { public static String getHumanClassName ( Object object ) {", "commit_type": "make"}
{"commit_tokens": ["added", "multi", "thread", "integration", "test", ".", "couldn", "t", "show", "that", "IntBuffer", "fails", ".", "removed", "it", "nevertheless"], "add_tokens": "private int [ ] spatialKey2Id ; spatialKey2Id = new int [ size ] ; int oldNodeId = spatialKey2Id [ key ] ; spatialKey2Id [ key ] = nodeId ; spatialKey2Id [ key ] = nodeId ; int tmpId = spatialKey2Id [ tmpKey ] ; spatialKey2Id [ mainKey ] = closestNode . node ; final int id = spatialKey2Id [ ( int ) key ] ;", "del_tokens": "private IntBuffer spatialKey2Id ; spatialKey2Id = ByteBuffer . allocateDirect ( size * 4 ) . asIntBuffer ( ) ; int oldNodeId = spatialKey2Id . get ( key ) ; spatialKey2Id . put ( key , nodeId ) ; spatialKey2Id . put ( key , nodeId ) ; int tmpId = spatialKey2Id . get ( tmpKey ) ; spatialKey2Id . put ( mainKey , closestNode . node ) ; final int id = spatialKey2Id . get ( ( int ) key ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "flatMap", "processing", "when", "one", "of", "inner", "stream", "is", "empty"], "add_tokens": "if ( ( inner != null ) && inner . hasNext ( ) ) { next = inner . next ( ) ; return true ; } while ( iterator . hasNext ( ) ) { if ( ( inner != null ) && inner . hasNext ( ) ) { next = inner . next ( ) ; return true ; }", "del_tokens": "if ( iterator . hasNext ( ) ) { } if ( ( inner != null ) && inner . hasNext ( ) ) { next = inner . next ( ) ; return true ;", "commit_type": "fix"}
{"commit_tokens": ["Moved", "most", "of", "the", "account", "package", "out", "of", "Greenhouse", "and", "into", "Spring", "Social"], "add_tokens": "package org . springframework . social . account ;", "del_tokens": "package org . springframework . social . oauth ;", "commit_type": "move"}
{"commit_tokens": ["add", "Genie", ".", "get", "(", "Type", "Annotations", "[]", ")", "method"], "add_tokens": "import javax . enterprise . inject . spi . Bean ; public < T > T get ( BeanSpec spec ) { Provider < ? > provider = findProvider ( spec , C . set ( spec ) ) ; return ( T ) provider . get ( ) ; } / * * * Returns a bean of given type and annotations . This is helpful * when it needs to inject a value for a method parameter * @ param type the type of the bean * @ param annotations the annotations tagged to the ( parameter ) * @ param < T > the generic type * @ return the bean instance * / public < T > T get ( Type type , Annotation [ ] annotations ) { return get ( BeanSpec . of ( type , annotations ) ) ; }", "del_tokens": "public < T > T get ( BeanSpec spec ) { Provider < ? > provider = findProvider ( spec , C . set ( spec ) ) ; return ( T ) provider . get ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Use", "deprecated", "method", "to", "ensure", "we", "don", "t", "break", "with", "older", "versions", "of", "jackson"], "add_tokens": "@ SuppressWarnings ( \"deprecation\" ) // Use deprecated method to ensure we don't break with older versions of jackson . setVisibilityChecker (", "del_tokens": ". setVisibility (", "commit_type": "use"}
{"commit_tokens": ["Fixed", "problem", "with", "visibility", "of", "threshold", "rectangle", "and", "value"], "add_tokens": "thresholdRect . setFill ( sectionsVisible ? Color . TRANSPARENT : getSkinnable ( ) . getValue ( ) > getSkinnable ( ) . getThreshold ( ) ? getSkinnable ( ) . getThresholdColor ( ) : Tile . GRAY ) ; thresholdRect . setFill ( sectionsVisible ? Color . TRANSPARENT : getSkinnable ( ) . getValue ( ) > getSkinnable ( ) . getThreshold ( ) ? getSkinnable ( ) . getThresholdColor ( ) : Tile . GRAY ) ; thresholdText . setFill ( sectionsVisible ? Color . TRANSPARENT : getSkinnable ( ) . getBackgroundColor ( ) ) ; if ( ! sectionsVisible ) {", "del_tokens": "thresholdRect . setFill ( sectionsVisible ? getSkinnable ( ) . getBackgroundColor ( ) : getSkinnable ( ) . getThresholdColor ( ) ) ; thresholdRect . setFill ( VALUE > threshold ? thresholdColor : Tile . GRAY ) ; if ( sectionsVisible ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "reflect", "that", "publish", "can", "throw", "IOException"], "add_tokens": "* @ throws IOException if an I / O error is encountered public void publish ( String subject , byte [ ] data ) throws IOException ; * @ throws IOException if an I / O error is encountered public void publish ( Message msg ) throws IOException ; * @ throws IOException if an I / O error is encountered public void publish ( String subject , String reply , byte [ ] data ) throws IOException ;", "del_tokens": "public void publish ( String subject , byte [ ] data ) ; public void publish ( Message msg ) ; public void publish ( String subject , String reply , byte [ ] data ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "a", "minor", "mistake", "in", "the", "javadoc", "."], "add_tokens": "* < li > Set these system properties : < pre >", "del_tokens": "* < li > Set these system variables : < pre >", "commit_type": "fix"}
{"commit_tokens": ["Remove", "duplicate", "test", "data", "in", "xgboost", "-", "predictor", "-", "example"], "add_tokens": "import biz . k11i . xgboost . TestHelper ; Predictor predictor = new Predictor ( TestHelper . getResourceAsStream ( \"model/gbtree/v47/binary-logistic.model\" ) ) ; for ( String line : Files . readAllLines ( new File ( TestHelper . getResourcePath ( \"data/agaricus.txt.0.test\" ) ) . toPath ( ) , StandardCharsets . UTF_8 ) ) {", "del_tokens": "Predictor predictor = new Predictor ( Example . class . getResourceAsStream ( \"model/binary-logistic.model\" ) ) ; for ( String line : Files . readAllLines ( new File ( Example . class . getResource ( \"model/agaricus.txt.test\" ) . getPath ( ) ) . toPath ( ) , StandardCharsets . UTF_8 ) ) {", "commit_type": "remove"}
{"commit_tokens": ["Added", "public", "getter", "for", "the", "used", "thread", "pool"], "add_tokens": "@ Override public ThreadPool getThreadPool ( ) { return pool ; }", "del_tokens": "/ * * * Gets the ThreadPool used by this api . * * @ return The used ThreadPool . * / public ThreadPool getThreadPool ( ) { return pool ; }", "commit_type": "add"}
{"commit_tokens": ["Adding", "signatures", "tested", "manually", "for", "1", "sig"], "add_tokens": "public static void main ( String [ ] args ) throws Exception { /* Sign */ byte [ ] msg = new byte [ 1000 ] ; byte [ ] sig_out = new byte [ 64 ] ; byte [ ] privkey = new byte [ 32 ] ; byte [ ] random = new byte [ 64 ] ; curve_sigs . curve25519_sign ( sig_out , privkey , msg , 100 , random ) ; System . out . printf ( \"\\n\" ) ; for ( int c = 0 ; c < 64 ; c ++ ) System . out . printf ( \"%02x \" , sig_out [ c ] ) ; System . out . printf ( \"\\n\" ) ; }", "del_tokens": "public static void main ( String [ ] args ) { }", "commit_type": "add"}
{"commit_tokens": ["Add", "link", "from", "Javadoc", "to", "hystrix", "-", "contrib", "/", "hystrix", "-", "request", "-", "servlet"], "add_tokens": "* Example ServletFilter for initializing { @ link HystrixRequestContext } at the beginning of an HTTP request and shutting down at the end : * HystrixRequestContext context = HystrixRequestContext . initializeContext ( ) ; * try { * chain . doFilter ( request , response ) ; * } finally { * context . shutdown ( ) ; * } * < p > * You can find an implementation at < a href = \"https://github.com/Netflix/Hystrix/tree/master/hystrix-contrib/hystrix-request-servlet\" > hystrix - contrib / hystrix - request - servlet < / a > on GitHub .", "del_tokens": "* Example ServletFilter for initializing { @ link HystrixRequestContext } at the beginning of an HTTP request and shutting down at the end . * HystrixRequestContext context = HystrixRequestContext . initializeContext ( ) ; * try { * chain . doFilter ( request , response ) ; * } finally { * context . shutdown ( ) ; * } *", "commit_type": "add"}
{"commit_tokens": ["Made", "newInstance", "an", "abstract", "method", "."], "add_tokens": "* Creates a new instance of the component class . public abstract T newInstance ( ) ;", "del_tokens": "* Creates a new instance of the component class by calling its default * constructor . Child classes can override this if the component class does * not have a default constructor . public T newInstance ( ) { try { return clazz . newInstance ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } }", "commit_type": "make"}
{"commit_tokens": ["add", "ReadWrite", "to", "SubIO", "LinkedIO", "and", "FragmentedSubIO"], "add_tokens": "IO . Seekable io , SeekType type , long move , RunnableWithParameter < Pair < Long , IOException >> ondone public static long seekSyncUsingAsync ( IO . Seekable io , SeekType type , long move ) throws IOException {", "del_tokens": "IO . Readable . Seekable io , SeekType type , long move , RunnableWithParameter < Pair < Long , IOException >> ondone public static long seekSyncUsingAsync ( IO . Readable . Seekable io , SeekType type , long move ) throws IOException {", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "few", "javadoc", "warnings"], "add_tokens": "* < code > * OutlookMessageParser msgp = new OutlookMessageParser ( ) ; < br > * msgp . setRtf2htmlConverter ( new SimpleRTF2HTMLConverter ( ) ) ; //optional (if you want to use * your own implementation ) < br > * OutlookMessage msg = msgp . parseMsg ( \"test.msg\" ) ; * < / code >", "del_tokens": "* < code > OutlookMessageParser msgp = new OutlookMessageParser ( ) ; < br / > msgp . setRtf2htmlConverter ( new SimpleRTF2HTMLConverter ( ) ) ; //optional (if you want to use * your own implementation ) < br / > OutlookMessage msg = msgp . parseMsg ( \"test.msg\" ) ; < / code >", "commit_type": "fix"}
{"commit_tokens": ["Fix", "CBL", "-", "172", ":", "There", "should", "be", "no", "initial", "delay", "when", "starting", "a", "liveQuery"], "add_tokens": "public void changed ( @ NonNull DatabaseChange change ) { update ( LIVE_QUERY_UPDATE_INTERVAL_MS ) ; } // In either case we probably want to kick off a new query. update ( 0 ) ; private void update ( long delay ) { query . getDatabase ( ) . scheduleOnQueryExecutor ( this :: refreshResults , delay ) ;", "del_tokens": "public void changed ( @ NonNull DatabaseChange change ) { update ( ) ; } // In either case we may want to kick off a new query. update ( ) ; private void update ( ) { query . getDatabase ( ) . scheduleOnQueryExecutor ( this :: refreshResults , LIVE_QUERY_UPDATE_INTERVAL_MS ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "nested", "mistmatch", "for", "arrays"], "add_tokens": "StringBuilder sb = new StringBuilder ( ) ; if ( ! validator . validate ( item . asJsonArray ( ) . opt ( i ) , sb ) ) { mismatchDescription . appendText ( \"item at pos: \" + i + \", does not validate by validator \" + validator . getTitle ( ) ) . appendText ( \"\\nDetails: \" ) . appendText ( sb . toString ( ) ) ; return false ; } description . appendText ( \"are array items valid\" ) ; // if(!validator.validate(item.asJsonObject().opt(property), sb)) { // mismatchDescription.appendText(\", mismatch value: \" + item.asJsonObject().opt(property)) // .appendText(\"\\nDetails: \") // .appendText(sb.toString()); // return false; // } StringBuilder sb = new StringBuilder ( ) ; if ( ! validator . validate ( item . asJsonArray ( ) . opt ( itemPos ) , sb ) ) { mismatchDescription . appendText ( \"item at pos: \" + itemPos + \", does not validate by validator \" + validator . getTitle ( ) ) . appendText ( \"\\nDetails: \" ) . appendText ( sb . toString ( ) ) ; . appendText ( \"\\nDetails: \" )", "del_tokens": "if ( ! isItemValid ( validator , i ) . matches ( item ) ) return false ; description . appendText ( \"is array item valid\" ) ; if ( ! validator . isValid ( item . asJsonArray ( ) . opt ( itemPos ) ) ) { mismatchDescription . appendText ( \"item at pos: \" + itemPos + \", does not validate by validator \" + validator . getTitle ( ) ) ; . appendText ( \"\\nDetails: \" )", "commit_type": "add"}
{"commit_tokens": ["fixed", "bug", "with", "single", "valued", "unparsed", "option", "being", "returned", "as", "a", "list"], "add_tokens": "if ( ! argumentSpecification . isOptional ( ) && m_validatedUnparsedArguments . isEmpty ( ) ) else if ( ! argumentSpecification . isMultiValued ( ) && m_validatedArguments . size ( ) > 1 ) { m_validationErrorBuilder . unexpectedValue ( argumentSpecification ) ; }", "del_tokens": "if ( ! argumentSpecification . isOptional ( ) && ( m_validatedUnparsedArguments . isEmpty ( ) || ( argumentSpecification . isMultiValued ( ) && m_validatedArguments . size ( ) == 1 ) ) )", "commit_type": "fix"}
{"commit_tokens": ["Using", "DisposableBean", "interface", "to", "add", "destroy", "method"], "add_tokens": "import org . springframework . beans . factory . DisposableBean ; public class JmsConnectingMessageHandler implements MessageHandler , InitializingBean , DisposableBean { public void destroy ( ) throws Exception { / * * * @ throws Exception * / createSession ( connection ) ; connection . start ( ) ;", "del_tokens": "public class JmsConnectingMessageHandler implements MessageHandler , InitializingBean { connection . start ( ) ; public void destroy ( ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "doComplete", "methods", "to", "make", "it", "easier", "to", "be", "used", "as", "method", "reference"], "add_tokens": "/ * * * Sets this CompletionStage as success with provided value * if it hasn 't been already completed. Same as {@link #complete(T)}, the only difference * is the return type which makes this method more suitable to be used as method reference . * * @ param result the success value . May be null . * / public default void doComplete ( T result ) { complete ( result ) ; } / * * * Accepts a value and a throwable to complete this CompletionStage * if it hasn 't been already completed. If throwable is null, completes normally, if * throwable is not null , completes exceptionally . * * @ param result the success value . May be null . * Completes this computation as a success with this value only if throwable is null . * @ param throwable the failure value . * If not null , completes this computation as a failure with this value . * / public default void doComplete ( T result , Throwable throwable ) { if ( throwable == null ) { complete ( result ) ; } else { completeExceptionally ( throwable ) ; } }", "del_tokens": "*", "commit_type": "add"}
{"commit_tokens": ["Adding", "query", "leaves", "and", "pair", "object"], "add_tokens": "", "del_tokens": "/ * * * Date : 11 / 9 / 12 * Time : 1 : 46 PM * /", "commit_type": "add"}
{"commit_tokens": ["Updating", "existing", "tile", "matrix", "set", "with", "additional", "tiles", "projection", "fix", "for", "adjusting", "previous", "tiles"], "add_tokens": "ProjectionTransform transformWgs84ToWebMercator = ProjectionFactory . getProjection ( ProjectionConstants . EPSG_WORLD_GEODETIC_SYSTEM ) BoundingBox previousTileMatrixSetWebMercatorBoundingBox = transformWgs84ToWebMercator BoundingBox tileMatrixSetWebMercatorBoundingBox = transformWgs84ToWebMercator", "del_tokens": "ProjectionTransform transformToWebMercator = ProjectionFactory . getProjection ( tileMatrixSet . getSrs ( ) . getOrganizationCoordsysId ( ) ) BoundingBox previousTileMatrixSetWebMercatorBoundingBox = transformToWebMercator BoundingBox tileMatrixSetWebMercatorBoundingBox = transformToWebMercator", "commit_type": "update"}
{"commit_tokens": ["Make", "JerseyClient", "thread", "pools", "managed", "."], "add_tokens": "public class JerseyClient extends ApacheHttpClient4 {", "del_tokens": "import com . yammer . dropwizard . lifecycle . Managed ; import java . util . concurrent . TimeUnit ; public class JerseyClient extends ApacheHttpClient4 implements Managed { @ Override public void start ( ) throws Exception { // already started man } @ Override public void stop ( ) throws Exception { getExecutorService ( ) . shutdown ( ) ; getExecutorService ( ) . awaitTermination ( 1 , TimeUnit . MINUTES ) ; destroy ( ) ; }", "commit_type": "make"}
{"commit_tokens": ["Create", "a", "new", "RendererException", "to", "be", "thrown", "when", "RendererBuilder", "can", "t", "find", "the", "prototype", "in", "prototypes", "collection", "."], "add_tokens": "int itemViewType = - 1 ; if ( itemViewType == - 1 ) { throw new PrototypeNotFoundException ( \"Review your RendererBuilder implementation, you are returning one\" + \" prototype class not found in prototypes collection\" ) ; }", "del_tokens": "int itemViewType = 0 ;", "commit_type": "create"}
{"commit_tokens": ["Make", "ServicePool", "interrupt", "health", "checks", "on", "close", "."], "add_tokens": "_batchHealthChecksFuture . cancel ( true ) ; _healthCheckExecutor . shutdownNow ( ) ; // If we were interrupted during checking the health (but weren't blocked so an InterruptedException // couldn't be thrown), then we should exit now. if ( Thread . currentThread ( ) . isInterrupted ( ) ) { break ; }", "del_tokens": "_batchHealthChecksFuture . cancel ( false ) ; _healthCheckExecutor . shutdown ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Use", "collect", "stack", "to", "access", "entity", "instead", "keeping", "a", "reference", "."], "add_tokens": "private boolean setEntityName ; if ( setEntityName ) { ( ( Entity ) collectStack . peek ( ) ) . setNameSource ( data ) ; setEntityName = false ; setEntityName = true ; setEntityName = false ; // must be set after recursive calls to flush descendants before parent if ( setEntityName ) { ( ( Entity ) collectStack . peek ( ) ) . setNameSource ( collect ) ; setEntityName = false ; collectStack . push ( collect ) ; }", "del_tokens": "private Entity entity ; if ( entity != null ) { entity . setNameSource ( data ) ; entity = null ; entity = ( Entity ) collectStack . peek ( ) ; entity = null ; // must be set after recursive calls to flush decendents before parent collectStack . push ( collect ) ; if ( entity != null ) { entity . setNameSource ( collect ) ; entity = null ; }", "commit_type": "use"}
{"commit_tokens": ["Fixed", "bad", "class", "name", "when", "initializing", "the", "logger"], "add_tokens": "log = new FOKLogger ( Common . class . getName ( ) ) ;", "del_tokens": "log = new FOKLogger ( UpdateChecker . class . getName ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "on", "Date", "handler", "(", "not", "stable", ")"], "add_tokens": "import java . text . DateFormat ; String vtext = DateFormat . getDateInstance ( ) . format ( ( Date ) value ) ; JSONValue . writeJSONString ( vtext , out , compression ) ;", "del_tokens": "JSONValue . writeJSONString ( value . toString ( ) , out , compression ) ;", "commit_type": "change"}
{"commit_tokens": ["make", "local", "copy", "of", "NamesFilter", "names", ";", "modifying", "caller", "s", "List", "is", "buggy"], "add_tokens": "private List < String > names_ ; names_ = new ArrayList < String > ( names ) ; names_ . remove ( column . name ( ) ) ; else if ( values . length == 2 && DatabaseDescriptor . getColumnType ( cfName ) . equals ( \"Super\" ) ) SuperColumn filteredSuperColumn = new SuperColumn ( superColumn . name ( ) ) ; filteredCf . addColumn ( filteredSuperColumn ) ; names_ . remove ( subColumn . name ( ) ) ; else { names_ . remove ( columnName ) ;", "del_tokens": "private List < String > names_ = new ArrayList < String > ( ) ; names_ = names ; names_ . remove ( column . name ( ) ) ; else if ( values . length == 2 && DatabaseDescriptor . getColumnType ( cfName ) . equals ( \"Super\" ) ) SuperColumn filteredSuperColumn = new SuperColumn ( superColumn . name ( ) ) ; filteredCf . addColumn ( filteredSuperColumn ) ; names_ . remove ( subColumn . name ( ) ) ; else { names_ . remove ( columnName ) ;", "commit_type": "make"}
{"commit_tokens": ["add", "Message", "Delivered", "Webhook", "Class"], "add_tokens": "import java . util . ArrayList ; protected String user_id ; protected String page_id ; protected Long timestamp ; protected String message_id ; protected String message_text ; protected String quick_reply_payload ; protected Map < String , String > attachments = new HashMap < String , String > ( ) ;", "del_tokens": "private String user_id ; private String page_id ; private Long timestamp ; private String message_id ; private String message_text ; private String quick_reply_payload ; private Map < String , String > attachments = new HashMap < String , String > ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Moving", "common", "chronology", "functionality", "to", "IdentifiableChronology"], "add_tokens": "final Chronology chronology = IdentifiableChronology . readChronology ( input ) ; final String chronologyId = IdentifiableChronology . getChronologyId ( obj . getChronology ( ) ) ;", "del_tokens": "final Chronology chronology = readChronology ( input ) ; final String chronologyId = getChronologyId ( obj . getChronology ( ) ) ; private Chronology readChronology ( final Input input ) { final String chronologyId = input . readString ( ) ; return IdentifiableChronology . valueOfId ( \"\" . equals ( chronologyId ) ? null : chronologyId ) ; } private String getChronologyId ( final Chronology chronology ) { return IdentifiableChronology . getIdByChronology ( chronology . getClass ( ) ) ; }", "commit_type": "move"}
{"commit_tokens": ["Add", "exception", "message", "explaining", "that", "PasswordEncryptionService", "impl", "is", "not", "configured"], "add_tokens": "throw new AuthenticationException ( \"No password encryption service is installed\" ) ;", "del_tokens": "throw new AuthenticationException ( ) ;", "commit_type": "add"}
{"commit_tokens": ["making", "example", ".", "com", "be", "the", "same", "as", "example", ".", "com", "/"], "add_tokens": "// here's a hack for saying http://example.com is the same as http://example.com/ if ( uri . toString ( ) == null ) return 0 ; String hash = uri . toString ( ) ; if ( hash . endsWith ( \"/\" ) ) hash = hash . substring ( 0 , hash . length ( ) - 1 ) ; result = prime * result + hash . hashCode ( ) ; } else if ( uri . equals ( other . uri ) ) return true ; // here's a hack for saying http://example.com is the same as // http://example.com/ else if ( uri . toString ( ) . endsWith ( \"/\" ) ) { String withoutEndingSlash = uri . toString ( ) . substring ( 0 , uri . toString ( ) . length ( ) - 1 ) ; if ( withoutEndingSlash . equals ( other . uri . toString ( ) ) ) return true ; } return false ;", "del_tokens": "result = prime * result + ( ( uri == null ) ? 0 : uri . hashCode ( ) ) ; } else if ( ! uri . equals ( other . uri ) ) return false ; return true ;", "commit_type": "make"}
{"commit_tokens": ["Allow", "framework", "models", "like", "User", "to", "be", "extended", "by", "applications"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; List < String > modelClasses = new ArrayList < String > ( ) ;", "del_tokens": "import java . util . HashSet ; Set < String > modelClasses = new HashSet < String > ( ) ;", "commit_type": "allow"}
{"commit_tokens": ["Improve", "the", "documentation", "of", "the", "JoggerTest#getInterceptors", "()", "abstract", "method", "."], "add_tokens": "* Retrieves the { @ link Interceptors } implementation that you use in your class . Remember that it must be already * initialized and ready to use . * @ return an initialized { @ link Interceptors } implementation object .", "del_tokens": "* Retrieves the { @ link Interceptors } implementation that you use in your class . * @ return a { @ link Interceptors } implementation object .", "commit_type": "improve"}
{"commit_tokens": ["added", "missing", "URL", "resolving", "step"], "add_tokens": "SYNTAX_ERROR , PARSE_ERROR , RDF_ERROR , CONTEXT_URL_ERROR , INVALID_URL , COMPACT_ERROR", "del_tokens": "SYNTAX_ERROR , PARSE_ERROR , RDF_ERROR", "commit_type": "add"}
{"commit_tokens": ["making", "changes", "to", "flush", "trying", "to", "fix", "undertow", "problem", "[", "3", "]"], "add_tokens": "private static final int MIN_TIME_WAITING = 490 ; final long regularRequestWithHoldTime = timeLapseRegularRequest + MIN_TIME_WAITING ;", "del_tokens": "private static final int MIN_TIME_WAITTING = 490 ; final long regularRequestWithHoldTime = timeLapseRegularRequest + MIN_TIME_WAITTING ;", "commit_type": "make"}
{"commit_tokens": ["use", "SecureRandom", "to", "generate", "nonce", "and", "state", "values"], "add_tokens": "import android . util . Base64 ; import java . security . SecureRandom ; if ( getResponseType ( ) . contains ( RESPONSE_TYPE_ID_TOKEN ) ) { queryParameters . put ( KEY_NONCE , getNonce ( ) ) ; } queryParameters . put ( KEY_STATE , getState ( ) ) ; return parameters . containsKey ( KEY_STATE ) ? parameters . get ( KEY_STATE ) : secureRandomString ( ) ; return parameters . containsKey ( KEY_NONCE ) ? parameters . get ( KEY_NONCE ) : secureRandomString ( ) ; private String secureRandomString ( ) { final SecureRandom sr = new SecureRandom ( ) ; final byte [ ] randomBytes = new byte [ 32 ] ; sr . nextBytes ( randomBytes ) ; return Base64 . encodeToString ( randomBytes , Base64 . URL_SAFE | Base64 . NO_WRAP | Base64 . NO_PADDING ) ; }", "del_tokens": "import java . util . UUID ; withState ( UUID . randomUUID ( ) . toString ( ) ) ; withNonce ( UUID . randomUUID ( ) . toString ( ) ) ; if ( ! getResponseType ( ) . contains ( RESPONSE_TYPE_ID_TOKEN ) ) { queryParameters . remove ( KEY_NONCE ) ; } return parameters . get ( KEY_STATE ) ; return parameters . get ( KEY_NONCE ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "some", "updates", "to", "csproj", "-", "file", ".", "Net"], "add_tokens": "* You can do some actions with Cendell : < br >", "del_tokens": "* You can do some actions with Cell : < br >", "commit_type": "add"}
{"commit_tokens": ["fix", "multiple", "files", "in", "same", "directory"], "add_tokens": "import java . util . HashSet ; import java . util . Set ; Map < WatchKey , Set < ProxyFileListener > > keysFileListener ; Set < ProxyFileListener > fileListeners = keysFileListener . get ( key ) ; if ( directoryListener != null || ( fileListeners != null && ! fileListeners . isEmpty ( ) ) ) { if ( fileListeners != null ) { fileListeners . forEach ( fileListener -> notifyFileListener ( fileListener , kind , path ) ) ; } keysFileListener . computeIfAbsent ( key , k -> new HashSet < > ( ) ) . add ( new ProxyFileListener ( fileListener , file ) ) ; //keysFileListener.put(key, new ProxyFileListener(fileListener, file));", "del_tokens": "Map < WatchKey , ProxyFileListener > keysFileListener ; ProxyFileListener fileListener = keysFileListener . get ( key ) ; if ( fileListener != null || directoryListener != null ) { notifyFileListener ( fileListener , kind , path ) ; keysFileListener . put ( key , new ProxyFileListener ( fileListener , file ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "a", "caching", "mechanism", "for", "the", "services", "rather", "than", "requrying", "the"], "add_tokens": "private CQVariablesService variablesService ; CQVariables variables = variablesService . getVariables ( bindings ) ; ci . addBindings ( variables , bindings ) ;", "del_tokens": "private CQVariablesService bs ; CQVariables binding = bs . getVariables ( bindings ) ; ci . addBindings ( binding , bindings ) ;", "commit_type": "add"}
{"commit_tokens": ["Create", "ModelObjectMapper", "method", "and", "all", "into", "this", "method", "."], "add_tokens": "import com . linecorp . bot . model . objectmapper . ModelObjectMapper ; return ModelObjectMapper . createNewObjectMapper ( ) . configure ( DeserializationFeature . FAIL_ON_UNKNOWN_PROPERTIES , failOnUnknownProperties ) ;", "del_tokens": "import com . fasterxml . jackson . datatype . jsr310 . JavaTimeModule ; import com . fasterxml . jackson . module . paramnames . ParameterNamesModule ; return new ObjectMapper ( ) . configure ( DeserializationFeature . FAIL_ON_UNKNOWN_PROPERTIES , failOnUnknownProperties ) // Register ParameterNamesModule to read parameter name from lombok generated constructor. . registerModule ( new ParameterNamesModule ( ) ) // Register JSR-310(java.time.temporal.*) module and read number as millsec. . registerModule ( new JavaTimeModule ( ) ) . configure ( DeserializationFeature . READ_DATE_TIMESTAMPS_AS_NANOSECONDS , false ) ;", "commit_type": "create"}
{"commit_tokens": ["added", "CSS", "to", "check", "box"], "add_tokens": "import customui . components . C3DCheckBox ; public C3DCheckBoxSkin ( C3DCheckBox control ) { box . setBorder ( new Border ( new BorderStroke ( control . getUnCheckedColor ( ) , BorderStrokeStyle . SOLID , new CornerRadii ( 0 ) , new BorderWidths ( lineThick ) ) ) ) ; rippler . setRipplerFill ( getSkinnable ( ) . isSelected ( ) ? control . getUnCheckedColor ( ) : control . getCheckedColor ( ) ) ; rightLine . setStroke ( control . getCheckedColor ( ) ) ; leftLine . setStroke ( control . getCheckedColor ( ) ) ; rippler . setRipplerFill ( newVal ? control . getUnCheckedColor ( ) : control . getCheckedColor ( ) ) ;", "del_tokens": "import javafx . scene . paint . Color ; private Color uncheckedColor = Color . valueOf ( \"#5A5A5A\" ) ; private Color checkedColor = Color . valueOf ( \"#0F9D58\" ) ; public C3DCheckBoxSkin ( CheckBox control ) { box . setBorder ( new Border ( new BorderStroke ( uncheckedColor , BorderStrokeStyle . SOLID , new CornerRadii ( 0 ) , new BorderWidths ( lineThick ) ) ) ) ; rippler . setRipplerFill ( getSkinnable ( ) . isSelected ( ) ? uncheckedColor : checkedColor ) ; rightLine . setStroke ( checkedColor ) ; leftLine . setStroke ( checkedColor ) ; rippler . setRipplerFill ( newVal ? uncheckedColor : checkedColor ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "if", "CDemoStringTables", "had", "modifiers", "they", "were", "not", "applied"], "add_tokens": "import clarity . decoder . StringTableApplier ; StringTableApplier . forName ( t . getTableName ( ) ) . apply ( match , t . getTableName ( ) , i , l . get ( i ) . getStr ( ) , l . get ( i ) . getData ( ) ) ;", "del_tokens": "import clarity . model . StringTable ; StringTable st = match . getStringTables ( ) . forName ( t . getTableName ( ) ) ; st . set ( i , l . get ( i ) . getStr ( ) , l . get ( i ) . getData ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "code", "to", "defuse", "grou", "-", "producing", "parentheses", "()", "in", "repattern", "-", "regexes"], "add_tokens": "import de . unihd . dbs . uima . annotator . heideltime . utilities . Logger ; Logger . printDetail ( component , \"Adding pattern resource: \" + resource ) ; Logger . printError ( component , \"Cannot read one of the lines of pattern resource \" + resource ) ; Logger . printError ( component , \"Line: \" + line ) ; / * this was added to reduce the danger of getting unusable groups from user - made repattern * files with group - producing parentheses ( i . e . \"(foo|bar)\" while matching against the documents . * / rePattern = rePattern . replaceAll ( \"\\\\(([^\\\\?])\" , \"(?:$1\" ) ; rePattern = rePattern . replaceAll ( \"\\\\\\\\\" , \"\\\\\\\\\\\\\\\\\" ) ; hmAllRePattern . put ( name , rePattern ) ;", "del_tokens": "System . err . println ( \"[\" + component + \"] Adding pattern resource: \" + resource ) ; System . err . println ( \"[\" + component + \"] Cannot read one of the lines of pattern resource \" + resource ) ; System . err . println ( \"[\" + component + \"] Line: \" + line ) ; hmAllRePattern . put ( name , rePattern . replaceAll ( \"\\\\\\\\\" , \"\\\\\\\\\\\\\\\\\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "special", "case", "for", "colon"], "add_tokens": "if ( Character . isUpperCase ( token . charAt ( 0 ) ) && ! tokens [ i - 1 ] . getToken ( ) . equals ( \":\" ) ) {", "del_tokens": "if ( Character . isUpperCase ( token . charAt ( 0 ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "version", "utils", "(", "this", "now", "lives", "in", "librato", "-", "java", ")"], "add_tokens": "final String version = Versions . getVersion ( \"META-INF/maven/com.librato.metrics/metrics-librato/pom.properties\" , LibratoReporter . class ) ; final String codaVersion = Versions . getVersion ( \"META-INF/maven/com.yammer.metrics/metrics-core/pom.properties\" , MetricsRegistry . class ) ;", "del_tokens": "final String version = VersionUtil . getVersion ( \"META-INF/maven/com.librato.metrics/metrics-librato/pom.properties\" , LibratoReporter . class ) ; final String codaVersion = VersionUtil . getVersion ( \"META-INF/maven/com.yammer.metrics/metrics-core/pom.properties\" , MetricsRegistry . class ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "async", "start", "and", "success", "functionality", "to", "scheduler", "logger", "following", "implementation", "in", "TaskLogger"], "add_tokens": "import com . cisco . oss . foundation . flowcontext . FlowContextFactory ; import org . slf4j . event . Level ; public static SchedulerLogger startAsync ( final Logger logger , final Logger auditor , final String schedulerName ) { SchedulerLogger schedulerLogger = new SchedulerLogger ( ) ; createLoggingActionAsync ( logger , auditor , schedulerLogger ) ; schedulerLogger . startInstance ( schedulerName ) ; return schedulerLogger ; } public static void successAsync ( SchedulerLogger schedulerLogger ) { FlowContextFactory . deserializeNativeFlowContext ( TransactionLogger . getFlowContextAsync ( schedulerLogger ) ) ; schedulerLogger . successInstance ( ) ; } public void successAsync ( ) { FlowContextFactory . deserializeNativeFlowContext ( this . flowContext ) ; this . successInstance ( ) ; } public void failureAsync ( final String errorMessage ) { this . failureInstance ( errorMessage ) ; }", "del_tokens": "import org . slf4j . event . Level ;", "commit_type": "add"}
{"commit_tokens": ["Allow", "for", "multiple", "query", "params", "with", "the", "same", "name"], "add_tokens": "for ( String p : req . getParams ( ) . get ( param ) ) { builder . addParameter ( param , p ) ; }", "del_tokens": "builder . addParameter ( param , req . getParams ( ) . get ( param ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "fixed", "length", "to", "CollectionSerializer", "."], "add_tokens": "private Integer length ; / * * * Sets the number of objects in the collection . Saves 1 - 2 bytes . * / public void setLength ( int length ) { this . length = length ; } int length ; if ( this . length != null ) length = this . length ; else { length = collection . size ( ) ; IntSerializer . put ( buffer , length , true ) ; } int length ; if ( this . length != null ) length = this . length ; else length = IntSerializer . get ( buffer , true ) ;", "del_tokens": "int length = collection . size ( ) ; IntSerializer . put ( buffer , length , true ) ; int length = IntSerializer . get ( buffer , true ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "comment", "to", "the", "correct", "line"], "add_tokens": "writeComment ( \"# \" , comment , writer ) ; writeComment ( \"#\" , comment , writer ) ; // no space on purpose!!!", "del_tokens": "writeComment ( \"# \" , comment , writer ) ; // no space on purpose!!! writer . write ( \"#\\n\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Changed", "client_id", "attribute", "to", "client", "for", "Token"], "add_tokens": "public String getClient ( ) { return ( String ) this . get ( \"client\" ) ; public Builder client ( String client ) { this . t . set ( \"client\" , client ) ; }", "del_tokens": "public String getClientId ( ) { return ( String ) this . get ( \"client_id\" ) ; public Builder clientId ( String clientId ) { this . t . set ( \"client_id\" , clientId ) ; }", "commit_type": "change"}
{"commit_tokens": ["add", "jgiven", "configuration", "to", "HtmlWriterScenarioTest", "to", "enable", "Issue", "tag"], "add_tokens": "import com . tngtech . jgiven . JGivenTestConfiguration ; import com . tngtech . jgiven . annotation . JGivenConfiguration ; @ JGivenConfiguration ( JGivenTestConfiguration . class )", "del_tokens": "@ FeatureDataTables", "commit_type": "add"}
{"commit_tokens": ["Adding", "implementation", "for", "FedoraRepository", ".", "exists", "()", "createObject", "()", "and", "findOrCreateObject", "()", ";", "improving", "Javadocs"], "add_tokens": "* @ param repository FedoraRepository that created this resource * @ param path Repository path of this resource * @ param triples Properties of this resource * Get the properties graph * @ return Graph containing properties for this resource * @ param property The Property to get values for * @ return Collection of values", "del_tokens": "* @ param response * get the graph consume . * @ return * @ param property * @ return", "commit_type": "add"}
{"commit_tokens": ["Fix", "handling", "of", "all", "uppercase", "attribute", "names"], "add_tokens": "String name = elementName ; name = elementName . replaceFirst ( \"get\" , \"\" ) ; break ; name = elementName . replaceFirst ( \"is\" , \"\" ) ; break ; return Names . isAllUpper ( name ) ? name : Names . lowerCaseFirst ( name ) ;", "del_tokens": "return Names . lowerCaseFirst ( elementName . replaceFirst ( \"get\" , \"\" ) ) ; return Names . lowerCaseFirst ( elementName . replaceFirst ( \"is\" , \"\" ) ) ; case NONE : default : return Names . lowerCaseFirst ( elementName ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "preliminary", "inferred", "axiom", "support", "for", "concrete", "domains"], "add_tokens": "import au . csiro . ontology . model . IDatatype ; final private Set < IExistential > items = new HashSet < IExistential > ( ) ; } else if ( concept instanceof IDatatype ) { return concept ; log . info ( \"WARNING: pass through of complex value: \" + concept ) ; final IConcept value = candidate . getConcept ( ) ; if ( ! ( value instanceof INamedConcept ) ) { log . warn ( \"WARNING: pass through of nested complex value: \" + value ) ; continue ; } final int dInt = factory . getConcept ( ( ( INamedConcept ) value ) . getId ( ) ) ;", "del_tokens": "final private List < IExistential > items = new ArrayList < IExistential > ( ) ; log . debug ( \"WARNING: pass through of complex value: \" + concept ) ; final int dInt = factory . getConcept ( ( ( INamedConcept ) candidate . getConcept ( ) ) . getId ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "platform", "-", "specific", "library", "name", "."], "add_tokens": "LibMediaInfo INSTANCE = ( LibMediaInfo ) Native . loadLibrary ( Platform . isWindows ( ) ? \"MediaInfo\" : \"mediainfo\" , LibMediaInfo . class ) ;", "del_tokens": "LibMediaInfo INSTANCE = ( LibMediaInfo ) Native . loadLibrary ( Platform . isWindows ( ) ? \"libmediainfo\" : \"mediainfo\" , LibMediaInfo . class ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "for", "quickfixj", "client", "and", "server", "actuators"], "add_tokens": "properties . put ( \"BeginString\" , sessionID . getBeginString ( ) ) ; properties . put ( \"SenderCompID\" , sessionID . getSenderCompID ( ) ) ; properties . put ( \"SenderSubID\" , senderSubID ) ; properties . put ( \"SenderLocationID\" , senderLocationID ) ; properties . put ( \"TargetCompID\" , sessionID . getTargetCompID ( ) ) ; properties . put ( \"TargetSubID\" , targetSubID ) ; properties . put ( \"TargetLocationID\" , targetLocationID ) ; properties . put ( \"Qualifier\" , sessionQualifier ) ;", "del_tokens": "// Session session = Session.lookupSession(sessionId); properties . put ( \"beginString\" , sessionID . getBeginString ( ) ) ; properties . put ( \"senderCompID\" , sessionID . getSenderCompID ( ) ) ; properties . put ( \"senderSubID\" , senderSubID ) ; properties . put ( \"senderLocationID\" , senderLocationID ) ; properties . put ( \"targetCompID\" , sessionID . getTargetCompID ( ) ) ; properties . put ( \"targetSubID\" , targetSubID ) ; properties . put ( \"targetLocationID\" , targetLocationID ) ; properties . put ( \"qualifier\" , sessionQualifier ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "to", "find", "count", "of", "single", "value", "elements", ".", "There", "should", "then", "be", "only", "1", "element", "."], "add_tokens": "@ SuppressWarnings ( \"unchecked\" ) Object object = null ; object = JsonPath . read ( json , jsonPath ) ; if ( object != null ) { // TODO: Find a way to do this without suppressing the warning if ( object instanceof List < ? > ) { elements = ( List < Object > ) object ; if ( CollectionUtils . isNotEmpty ( elements ) ) { match = ( elements . size ( ) == count ) ; if ( ! match ) { System . out . println ( \"*ERROR* Element counts did not match. Expected '\" + count + \"', got '\" + elements . size ( ) + \"'\" ) ; } } else { // In practice, it's impossible to end here. System . out . println ( \"*ERROR* Could not find elements from '\" + jsonPath + \"'\" ) ; } } else if ( count == 1 ) { System . out . println ( \"*DEBUG* Found 1 item as expected from '\" + jsonPath + \"'\" ) ; match = true ; } else { System . out . println ( \"*ERROR* Found 1 item, but expected '\" + count + \"'\" ) ;", "del_tokens": "elements = JsonPath . read ( json , jsonPath ) ; if ( CollectionUtils . isNotEmpty ( elements ) ) { match = ( elements . size ( ) == count ) ; if ( ! match ) { System . out . println ( \"*ERROR* Element counts did not match. Expected '\" + count + \"', got '\" + elements . size ( ) + \"'\" ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "checkstyle", "warning", "about", "missing", "dots", "in", "javadocs"], "add_tokens": "* The wrapped configurable object . * The key of objects configuration . * Returns the configurable object . * Returns the configuration key . * Returns the environment .", "del_tokens": "* The wrapped configurable object * The key of objects configuration * Returns the configurable object * Returns the configuration key * Returns the environment", "commit_type": "fix"}
{"commit_tokens": ["Added", "some", "documentation", "to", "the", "rest", "of", "directions", "doc"], "add_tokens": "* Constants used to customize the directions requested / * * * For car and motorcycle routing . This profile shows the fastest routes by preferring * high - speed roads like highways . * / / * * * For pedestrian and hiking routing . This profile shows the shortest path by using sidewalks * and trails . * / / * * * For bicycle routing . This profile shows routes that are short and safe for cyclist , avoiding * highways and preferring streets with bike lanes . * / / * * * Format to return route instructions will be text . * / / * * * Format to return route instructions will be html . * / / * * * Format to return route geometry will be geojson . * / public static final String GEOMETRY_GEOJSON = \"geojson\" ; / * * * Format to return route geometry will be encoded polyline . * / / * * * Use false to omit geometry from response . * / public static final String GEOMETRY_FALSE = \"false\" ;", "del_tokens": "* Created by antonio on 1 / 30 / 16. public static final String GEOMETRY_GEOJSON = \"geojson\" ; public static final String GEOMETRY_FALSE = \"false\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "API", "to", "easily", "remove", "registered", "units", "and", "retrieve", "their", "formats"], "add_tokens": "PrettyTime p = new PrettyTime ( new Date ( 0 ) , Locale . ROOT ) ; assertEquals ( \"moments from now\" , p . format ( new Date ( 1 ) ) ) ; p . setReference ( new Date ( 0 ) ) ; assertEquals ( \"Jetzt\" , p . format ( new Date ( 1 ) ) ) ; PrettyTime p = new PrettyTime ( new Date ( 0 ) ) ; assertEquals ( p . format ( new Date ( 1 ) ) , \"moments from now\" ) ; PrettyTime p = new PrettyTime ( new Date ( 0 ) ) ; assertEquals ( p . format ( new Date ( 1 ) ) , \"Jetzt\" ) ;", "del_tokens": "PrettyTime p = new PrettyTime ( Locale . ROOT ) ; assertEquals ( \"moments from now\" , p . format ( new Date ( ) ) ) ; assertEquals ( \"Jetzt\" , p . format ( new Date ( ) ) ) ; PrettyTime p = new PrettyTime ( ) ; assertEquals ( p . format ( new Date ( ) ) , \"moments from now\" ) ; PrettyTime p = new PrettyTime ( ) ; assertEquals ( p . format ( new Date ( ) ) , \"Jetzt\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "pruner", "tests", ";", "Construct", "polymorphic", "pruners", "using", "the", "builder", "pattern"], "add_tokens": "* @ author int33484 * @ param < O > object type * @ param < A > attribute type public void go ( Pruner pruner ) { LatticePruner filter = ( LatticePruner ) pruner ; if ( filter . go ( ) == Lattice . Direction . DOWN ) { it = top ( filter ) ; it = bottom ( filter ) ; Pruner writer = new LatticeWriter . Builder ( ) . go ( Lattice . Direction . DOWN ) . withObjects ( objects ) . withAttributes ( attributes ) . build ( ) ;", "del_tokens": "public void go ( LatticePruner pruner ) { if ( pruner . go ( ) == LatticePruner . Direction . DOWN ) { it = top ( pruner ) ; it = bottom ( pruner ) ; LatticeWriter writer = new LatticeWriter ( LatticePruner . Direction . DOWN , objects , attributes ) ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "unique", "and", "upgrade", "druid"], "add_tokens": "+ \"----------------> binlog[{}:{}] , name[{},{}] , eventType : {} , executeTime : {}({}) , delay : {}ms\" transaction_format = SEP + \"================> binlog[{}:{}] , executeTime : {}({}) , delay : {}ms\" + SEP ; Date date = new Date ( entry . getHeader ( ) . getExecuteTime ( ) ) ; SimpleDateFormat simpleDateFormat = new SimpleDateFormat ( \"yyyy-MM-dd HH:mm:ss\" ) ; String . valueOf ( entry . getHeader ( ) . getExecuteTime ( ) ) , simpleDateFormat . format ( date ) , String . valueOf ( delayTime ) } ) ; String . valueOf ( entry . getHeader ( ) . getExecuteTime ( ) ) , simpleDateFormat . format ( date ) , String . valueOf ( delayTime ) } ) ; String . valueOf ( entry . getHeader ( ) . getExecuteTime ( ) ) , simpleDateFormat . format ( date ) , String . valueOf ( delayTime ) } ) ;", "del_tokens": "+ \"----------------> binlog[{}:{}] , name[{},{}] , eventType : {} , executeTime : {} , delay : {}ms\" transaction_format = SEP + \"================> binlog[{}:{}] , executeTime : {} , delay : {}ms\" + SEP ; String . valueOf ( entry . getHeader ( ) . getExecuteTime ( ) ) , String . valueOf ( delayTime ) } ) ; String . valueOf ( entry . getHeader ( ) . getExecuteTime ( ) ) , String . valueOf ( delayTime ) } ) ; String . valueOf ( entry . getHeader ( ) . getExecuteTime ( ) ) , String . valueOf ( delayTime ) } ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "the", "new", "parameter", "definition", "API", "for", "all", "operations"], "add_tokens": "import java . util . ArrayList ; import java . util . List ; import org . fit . layout . api . Parameter ; import org . fit . layout . impl . ParameterBoolean ; import org . fit . layout . impl . ParameterString ; public List < Parameter > defineParams ( ) List < Parameter > ret = new ArrayList < > ( 3 ) ; ret . add ( new ParameterString ( \"filename\" ) ) ; ret . add ( new ParameterBoolean ( \"produceHeader\" ) ) ; ret . add ( new ParameterBoolean ( \"boxTreeOnly\" ) ) ; return ret ;", "del_tokens": "protected final String [ ] paramNames = { \"filename\" , \"produceHeader\" , \"boxTreeOnly\" } ; protected final ValueType [ ] paramTypes = { ValueType . STRING , ValueType . BOOLEAN , ValueType . BOOLEAN } ; public String [ ] getParamNames ( ) { return paramNames ; } @ Override public ValueType [ ] getParamTypes ( ) return paramTypes ;", "commit_type": "use"}
{"commit_tokens": ["Adding", "equals", "and", "hashcode", "to", "base", "event"], "add_tokens": "if ( ! super . equals ( o ) ) return false ; int result = super . hashCode ( ) ; result = 31 * result + ( id != null ? id . hashCode ( ) : 0 ) ;", "del_tokens": "int result = id != null ? id . hashCode ( ) : 0 ;", "commit_type": "add"}
{"commit_tokens": ["Use", "simpler", "more", "widely", "applicable", "structure", "for", "global", ".", "Also", "avoids", "test", "failure", "for", "Function", "called", "as", "a", "function", "."], "add_tokens": "public class Main { global = new Global ( ) ; Environment . defineClass ( global ) ; catch ( EcmaError ee ) { Context . reportError ( ToolErrorReporter . getMessage ( \"msg.uncaughtJSException\" , ee . toString ( ) ) ) ; } catch ( EcmaError ee ) { Context . reportError ( ToolErrorReporter . getMessage ( \"msg.uncaughtJSException\" , ee . toString ( ) ) ) ; } static protected Global global ;", "del_tokens": "public class Main extends ScriptableObject { // A bit of shorthand: since Main extends ScriptableObject, // we can make it the global object. // We create a shared global with sealed properties that // we can share with other threads (see spawn). sharedGlobal = new SharedGlobal ( ) ; // Set its prototype to the sharedGlobal where all the standard // functions and objects live. global = new Main ( ) ; global . setPrototype ( sharedGlobal ) ; Environment . defineClass ( sharedGlobal ) ; / * * * Return name of this class , the global object . * * This method must be implemented in all concrete classes * extending ScriptableObject . * * @ see org . mozilla . javascript . Scriptable # getClassName * / public String getClassName ( ) { return \"global\" ; } static protected Main global ; static protected SharedGlobal sharedGlobal ; boolean quitting ; boolean debug = false ; boolean processStdin = true ; boolean showDebuggerUI = false ; NativeArray history ;", "commit_type": "use"}
{"commit_tokens": ["Update", "src", "/", "java", "/", "azkaban", "/", "project", "/", "ProjectManager", ".", "java"], "add_tokens": "if ( \"zip\" . equals ( fileType ) ) {", "del_tokens": "if ( fileType . equals ( \"zip\" ) ) {", "commit_type": "update"}
{"commit_tokens": ["changed", "integration", "test", "setup", "into", "default"], "add_tokens": "public class CloudSpannerIT private static final Logger log = Logger . getLogger ( CloudSpannerIT . class . getName ( ) ) ; public CloudSpannerIT ( )", "del_tokens": "public class JdbcIntegrationTest private static final Logger log = Logger . getLogger ( JdbcIntegrationTest . class . getName ( ) ) ; public JdbcIntegrationTest ( )", "commit_type": "change"}
{"commit_tokens": ["Fix", "for", "Swagger", "security", "definition", "name", "and", "key", "."], "add_tokens": "swagger . addSecurityDefinition ( key , keyAuthDefinition ) ; registeredHandlerWrappers . put ( key , wrapper ) ;", "del_tokens": "swagger . addSecurityDefinition ( name , keyAuthDefinition ) ; registeredHandlerWrappers . put ( name , wrapper ) ;", "commit_type": "fix"}
{"commit_tokens": ["Implement", "getCachedFormulaResultTypeEnum", ".", "Some", "comments", "are", "now", "out", "of", "date", "."], "add_tokens": "return getCachedFormulaResultTypeEnum ( ) . getCode ( ) ; } / * * * Not supported * / @ Override public CellType getCachedFormulaResultTypeEnum ( ) { return CellType . BLANK ; return CellType . NUMERIC ; return CellType . STRING ; return CellType . FORMULA ; return CellType . BOOLEAN ; return CellType . ERROR ;", "del_tokens": "return CELL_TYPE_BLANK ; return CELL_TYPE_NUMERIC ; return CELL_TYPE_STRING ; return CELL_TYPE_FORMULA ; return CELL_TYPE_BOOLEAN ; return CELL_TYPE_ERROR ; / * * * Not supported * / @ Override public CellType getCachedFormulaResultTypeEnum ( ) { throw new NotSupportedException ( ) ; }", "commit_type": "implement"}
{"commit_tokens": ["Removed", "misbehaving", "and", "unnecessary", "checks", "in", "Response"], "add_tokens": "out . put ( \"result\" , paramsObj ) ; out . put ( \"result\" , paramsObj ) ;", "del_tokens": "if ( paramsObj . length ( ) > 0 ) { out . put ( \"result\" , paramsObj ) ; } if ( paramsObj . length ( ) > 0 ) { } if ( paramsObj . length ( ) > 0 ) { out . put ( \"result\" , paramsObj ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Using", "newer", "char", "stream", "class", "for", "processing", "the", "received", "string"], "add_tokens": "import org . antlr . v4 . runtime . CharStream ; import org . antlr . v4 . runtime . CharStreams ; final CharStream stream ; // Input stream for the expression stream = CharStreams . fromString ( expression ) ; lexer = new DiceNotationGrammarLexer ( stream ) ;", "del_tokens": "import org . antlr . v4 . runtime . ANTLRInputStream ; final ANTLRInputStream input ; // Input stream for the expression input = new ANTLRInputStream ( expression ) ; lexer = new DiceNotationGrammarLexer ( input ) ;", "commit_type": "use"}
{"commit_tokens": ["Updated", "lucene", "query", "following", "the", "new", "stratio", "-", "cassandra", "query", "syntax"], "add_tokens": ". filterByField ( \"lucene\" , \"{filter:{type:\\\"range\\\",field:\\\"response_time\\\",lower:160,upper:840,include_lower:true,include_upper:true}}\" )", "del_tokens": ". filterByField ( \"lucene\" , \"response_time:[160 TO 840]\" )", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "Issue", "954", "http", ":", "//", "code", ".", "google", ".", "com", "/", "p", "/", "mobicents", "/", "issues", "/", "detail?id", "=", "954"], "add_tokens": "String headerName = getProperties ( ) . getProperty ( \"CONSISTENT_HASH_AFFINITY_HEADER\" ) ; if ( headerName != null ) { this . headerName = headerName ; }", "del_tokens": "// TODO Auto-generated method stub", "commit_type": "fix"}
{"commit_tokens": ["Updating", "classloader", "to", "properly", "load", "V2", "overrides"], "add_tokens": "URL [ ] urls = new URL [ ] { classURL } ; URLClassLoader child = new URLClassLoader ( urls , this . getClass ( ) . getClassLoader ( ) ) ; Class < ? > cls = child . loadClass ( className ) ;", "del_tokens": "ClassLoader sysClassLoader = Thread . currentThread ( ) . getContextClassLoader ( ) ; //Get the URLs URL [ ] oldUrls = ( ( URLClassLoader ) sysClassLoader ) . getURLs ( ) ; ArrayList < URL > urlList = new ArrayList < URL > ( ) ; Collections . addAll ( urlList , oldUrls ) ; urlList . add ( classURL ) ; URL [ ] urls = urlList . toArray ( new URL [ 0 ] ) ; classLoader = new URLClassLoader ( urls ) ; Class < ? > cls = classLoader . loadClass ( className ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "Content", "-", "Type", "header", "field"], "add_tokens": "import java . nio . charset . Charset ; private String statusLine ; private String requestLine ; public void setHeaders ( Header [ ] headers ) { for ( Header header : headers ) { public void updateResponse ( ) { if ( entity != null ) { public String getContentAsString ( ) { Charset charset = contentType . getCharset ( ) ; if ( charset != null ) { content = new String ( contentBytes , charset ) ; } else { content = new String ( contentBytes ) ; } public byte [ ] getContentAsByteArray ( ) { public String toString ( ) { for ( String key : responseHeaders . keySet ( ) ) {", "del_tokens": "private String statusLine ; private String requestLine ; public void setHeaders ( Header [ ] headers ) { for ( Header header : headers ) { public void updateResponse ( ) { if ( entity != null ) { public String getContentAsString ( ) { content = new String ( contentBytes , contentType . getCharset ( ) ) ; public byte [ ] getContentAsByteArray ( ) { public String toString ( ) { for ( String key : responseHeaders . keySet ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["change", "name", "of", "sherpa", "endpoint"], "add_tokens": "ReflectionCache . addObject ( SherpaEndpoint . class . getName ( ) , SherpaEndpoint . class ) ;", "del_tokens": "ReflectionCache . addObject ( \"sherpa\" , SherpaEndpoint . class ) ;", "commit_type": "change"}
{"commit_tokens": ["add", "support", "for", "exporting", "maps"], "add_tokens": "private final Multibinder < MapMapping < ? , ? > > mapBinder ; ExportBinder ( Multibinder < Mapping > binder , Multibinder < SetMapping < ? > > collectionBinder , Multibinder < MapMapping < ? , ? > > mapBinder ) this . mapBinder = mapBinder ; Multibinder < MapMapping < ? , ? > > mapBinder = newSetBinder ( binder , new TypeLiteral < MapMapping < ? , ? > > ( ) { } ) ; return new ExportBinder ( newSetBinder ( binder , Mapping . class ) , collectionBinder , mapBinder ) ; public < V > StringMapExportBinder < V > exportMap ( Class < V > valueClass ) { return new StringMapExportBinder < V > ( mapBinder , valueClass ) ; } public < K , V > MapExportBinder < K , V > exportMap ( Class < K > keyClass , Class < V > valueClass ) { return new MapExportBinder < K , V > ( mapBinder , keyClass , valueClass ) ; }", "del_tokens": "ExportBinder ( Multibinder < Mapping > binder , Multibinder < SetMapping < ? > > collectionBinder ) return new ExportBinder ( newSetBinder ( binder , Mapping . class ) , collectionBinder ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "invalid", "deobfuscated", "names", "in", "transformer"], "add_tokens": "final String methodName = \"run\" ; final String methodName = isObfuscated ? \"as\" : \"runGameLoop\" ; System . out . println ( \"MALMO: Found Minecraft.runGameLoop() method, attempting to transform it\" ) ; if ( visitMethodNode . name . equals ( isObfuscated ? \"h\" : \"updateDisplay\" ) ) if ( isObfuscated ) { visitMethodNode . name = \"updateDisplay\" ; }", "del_tokens": "final String methodName = isObfuscated ? \"minecraft\" : \"run\" ; final String methodName = isObfuscated ? \"av\" : \"runGameLoop\" ; System . out . println ( \"MALMO: Found MinecraftServer.run() method, attempting to transform it\" ) ; if ( visitMethodNode . name . equals ( \"updateDisplay\" ) )", "commit_type": "fix"}
{"commit_tokens": ["Added", "generic", "implementation", "of", "ExpandableRecyclerAdapter", "."], "add_tokens": "public abstract class ExpandableRecyclerAdapter < VH extends RecyclerView . ViewHolder > extends RecyclerView . Adapter < VH > implements ParentItemClickListener { public VH onCreateViewHolder ( ViewGroup viewGroup , int viewType ) { public abstract VH onCreateParentViewHolder ( ViewGroup parentViewGroup ) ; public abstract VH onCreateChildViewHolder ( ViewGroup childViewGroup ) ;", "del_tokens": "public abstract class ExpandableRecyclerAdapter extends RecyclerView . Adapter < RecyclerView . ViewHolder > implements ParentItemClickListener { public RecyclerView . ViewHolder onCreateViewHolder ( ViewGroup viewGroup , int viewType ) { public abstract ParentViewHolder onCreateParentViewHolder ( ViewGroup parentViewGroup ) ; public abstract ChildViewHolder onCreateChildViewHolder ( ViewGroup childViewGroup ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "condition", "code", "of", "onSizeChanged", "for", "always", "in", "center"], "add_tokens": "if ( tabStrip . isIndicatorAlwaysInCenter ( ) && tabStrip . getChildCount ( ) > 0 ) {", "del_tokens": "if ( tabStrip . isIndicatorAlwaysInCenter ( ) && getChildCount ( ) > 0 ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "language", "codes", "for", "swedish", "language"], "add_tokens": "DE , SV", "del_tokens": "DE", "commit_type": "add"}
{"commit_tokens": ["Removing", "imports", "not", "required", "in", "JDK", "7"], "add_tokens": "import java . lang . annotation . Retention ; import java . lang . annotation . Target ; import javax . inject . Qualifier ;", "del_tokens": "import java . lang . annotation . Retention ; import java . lang . annotation . Target ; import javax . inject . Qualifier ; import static java . lang . annotation . ElementType . * ; import static java . lang . annotation . RetentionPolicy . RUNTIME ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "a", "test", "for", "GET", "query", "params"], "add_tokens": "public OAuthRequest constructGet ( String path , Map < String , ? > queryParams ) {", "del_tokens": "private OAuthRequest constructGet ( String path , Map < String , ? > queryParams ) {", "commit_type": "add"}
{"commit_tokens": ["change", "default", "value", "for", "rememberLastLlogin", "to", "TRUE"], "add_tokens": "* Whether it should remember the last account used to log in or it should ask the user to input his credentials . * By default it 's true, meaning it will not ask for the user account if he' s already logged in . * @ param rememberLastLogin flag to remember last Google login", "del_tokens": "* Whether it should clear the session and logout any existing user before trying to authenticate or not . * This can be useful when using Lock , so that the user always need to select which account / credentials to use . * Defaults to true . * @ param rememberLastLogin the new flag value .", "commit_type": "change"}
{"commit_tokens": ["add", "loop", "feature", "in", "gherkin"], "add_tokens": "Context . getInstance ( ) . initializeRobot ( Runner . class ) ;", "del_tokens": "Context . getInstance ( ) . initializeRobot ( Runner . class . getClassLoader ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "null", "check", "for", "notification"], "add_tokens": "if ( notificationManager != null ) { notificationManager . onDestroy ( ) ; }", "del_tokens": "notificationManager . onDestroy ( ) ;", "commit_type": "add"}
{"commit_tokens": ["improve", "filesystem", ".", "toString", "support"], "add_tokens": "startSingleZkServer ( _tickTime , dataDir , dataLogDir , port ) ;", "del_tokens": "startSingleZkServer ( _tickTime , dataDir , dataLogDir , port ) ;", "commit_type": "improve"}
{"commit_tokens": ["Make", "Gson", "static", "inside", "CMAClient"], "add_tokens": "// Gson private static Gson gson ; if ( gson == null ) { gson = new GsonBuilder ( ) . registerTypeAdapter ( CMAField . class , new FieldTypeAdapter ( ) ) . create ( ) ; } return gson ;", "del_tokens": "return new GsonBuilder ( ) . registerTypeAdapter ( CMAField . class , new FieldTypeAdapter ( ) ) . create ( ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "on", "-", "success", "callback", "to", "the", "hbase", "dbharness"], "add_tokens": "return db . runBatchAsync ( batch , flushErrorHandler ) ;", "del_tokens": "final Future < ? > flushFuture = db . runBatchAsync ( batch , flushErrorHandler ) ; ; return flushFuture ;", "commit_type": "add"}
{"commit_tokens": ["move", "src", "/", "universal", "to", "shell", "/", "src", "/", "universal"], "add_tokens": "private static String home = System . getProperty ( \"smile.home\" , \"shell/src/universal/bin\" ) ;", "del_tokens": "private static String home = System . getProperty ( \"smile.home\" , \"src/universal/data\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Implement", "javax", ".", "servlet", ".", "Filter", "to", "prevent", "ThreadLocal", "leaks", "+", "Improve", "test", "framework"], "add_tokens": "private final String name ; this ( parent , null ) ; this ( ( String ) null ) ; } RedefiningClassLoader ( ClassLoader parent , String name ) { super ( parent , DEFAULT_IGNORED_PACKAGES ) ; this . name = name ; } RedefiningClassLoader ( String name ) { this . name = name ; @ Override protected void finalize ( ) throws Throwable { System . out . println ( this + \" is being finalized\" ) ; // TODO: Report? } @ Override public String toString ( ) { return ( name != null ) ? ( this . getClass ( ) . getName ( ) + '[' + name + ']' ) : super . toString ( ) ; }", "del_tokens": "super ( parent , DEFAULT_IGNORED_PACKAGES ) ; // TODO: Add finalizer that reports garbage collection // TODO: Add name", "commit_type": "implement"}
{"commit_tokens": ["Added", "ability", "to", "supply", "ObjectMapper", "to", "RepresentationConverter", "dsl"], "add_tokens": "private ObjectMapper objectMapper ; public RepresentationConverter using ( ObjectMapper objectMapper ) { this . objectMapper = objectMapper ; return this ; }", "del_tokens": "private final ObjectMapper objectMapper ;", "commit_type": "add"}
{"commit_tokens": ["fixes", "Toolbar", "impl", "on", "appsupport", "-", "v21", "+", "(", "Supports", "Toolbar", "impli", ")"], "add_tokens": "if ( attributeId == - 1 || attrs == null ) if ( attributeId == - 1 || attrs == null ) if ( attributeId == - 1 || attrs == null ) {", "del_tokens": "if ( attributeId == - 1 ) if ( attributeId == - 1 ) if ( attributeId == - 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Added", "mllp", "-", "connector", "and", "udp", "-", "fire", "-", "forget", "-", "connector"], "add_tokens": "* < li > MediatorHTTPRequest : Will add the auth headers to the request and forward it to http - connector - * responds with MediatorHTTPResponse < / li >", "del_tokens": "* < li > MediatorHTTPRequest : Will add the auth headers to the request and forward it to http - connector < / li >", "commit_type": "add"}
{"commit_tokens": ["fixed", "TFJ", "-", "19", "support", "for", "favorite", "methods"], "add_tokens": "public void gotFavorites ( List < Status > statuses ) { this . statuses = statuses ; } public void createdFavorite ( Status status ) { this . status = status ; } public void destroyedFavorite ( Status status ) { this . status = status ; }", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Add", "test", "case", "for", "documentation", "completeness"], "add_tokens": "// supported discovery selectors @ Test public void select_tests_by_class ( ) { List < TestIdentifier > tests = runTests ( selectClass ( SampleSpec . class ) ) ; assertThat ( \"tests\" , tests , hasSize ( 6 ) ) ; assertThat ( tests . get ( 0 ) . getUniqueId ( ) , is ( \"[engine:specsy]\" ) ) ; assertThat ( tests . get ( 1 ) . getUniqueId ( ) , is ( \"[engine:specsy]/[class:org.specsy.junit.SampleSpec]\" ) ) ; } List < TestIdentifier > tests = runTests ( selectPackage ( SampleSpec . class . getPackage ( ) . getName ( ) ) ) ;", "del_tokens": "List < TestIdentifier > tests = runTests ( selectPackage ( getClass ( ) . getPackage ( ) . getName ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "-", "check", "libraries", "according", "to", "allLibraries", "parameter"], "add_tokens": "String jsonDiff = null ; case UPDATE : jsonDiff = gson . toJson ( ( ( UpdateInventoryRequest ) request ) . getProjects ( ) ) ; break ; case CHECK_POLICIES : jsonDiff = gson . toJson ( ( ( CheckPoliciesRequest ) request ) . getProjects ( ) ) ; break ; case CHECK_POLICY_COMPLIANCE : nvps . add ( new BasicNameValuePair ( APIConstants . PARAM_ALL_DEPENDENCIES , String . valueOf ( ( ( CheckPolicyComplianceRequest ) request ) . isAllDependencies ( ) ) ) ) ;", "del_tokens": "String jsonDiff = null ; case UPDATE : jsonDiff = gson . toJson ( ( ( UpdateInventoryRequest ) request ) . getProjects ( ) ) ; break ; case CHECK_POLICIES : jsonDiff = gson . toJson ( ( ( CheckPoliciesRequest ) request ) . getProjects ( ) ) ; break ; case CHECK_POLICY_COMPLIANCE : POLICIES :", "commit_type": "add"}
{"commit_tokens": ["Added", "possibility", "to", "influence", "precedence", "of", "unary", "minus"], "add_tokens": "/ * * * Property name for unary precedence choice . You can set System . getProperty ( PROPERTY_UNARY_HIGH_PRECEDENCE , \"false\" ) * in order to change evaluation from an expression like \"-3^2\" from \"(-3)^2\" to \"-(3^2)\" * / public static final String PROPERTY_UNARY_HIGH_PRECEDENCE = \"exp4j.unary.precedence.high\" ; private final boolean highUnaryPrecedence ; highUnaryPrecedence = System . getProperty ( PROPERTY_UNARY_HIGH_PRECEDENCE ) == null || ! System . getProperty ( PROPERTY_UNARY_HIGH_PRECEDENCE ) . equals ( \"false\" ) ; CustomOperator umin = new CustomOperator ( \"\\'\" , false , this . highUnaryPrecedence ? 7 : 5 , 1 ) {", "del_tokens": "CustomOperator umin = new CustomOperator ( \"\\'\" , false , 5 , 1 ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "command", "list", "from", "WebDriver", "directly", ".", "Fixed", "initialization", "of", "htmlUnit", "."], "add_tokens": "import org . openqa . selenium . WebDriver ; import org . openqa . selenium . chrome . ChromeDriver ; import org . openqa . selenium . firefox . FirefoxDriver ; import org . openqa . selenium . htmlunit . HtmlUnitDriver ; import org . openqa . selenium . ie . InternetExplorerDriver ; public CommandProcessor startWebDriverCommandProcessor ( final String browser , String browserUrl ) { WebDriver driver ; driver = new FirefoxDriver ( ) ; driver = new InternetExplorerDriver ( ) ; driver = new ChromeDriver ( ) ; driver = new HtmlUnitDriver ( true ) ; return new WebDriverCommandProcessor ( browserUrl , driver ) ; commandProcessor = startWebDriverCommandProcessor ( browser , browserUrl ) ;", "del_tokens": "import org . openqa . selenium . Capabilities ; import org . openqa . selenium . remote . DesiredCapabilities ; public CommandProcessor detectWebDriverCommandProcessor ( final String browser , String browserUrl ) { Capabilities capabilities ; capabilities = DesiredCapabilities . firefox ( ) ; capabilities = DesiredCapabilities . internetExplorer ( ) ; capabilities = DesiredCapabilities . chrome ( ) ; capabilities = DesiredCapabilities . htmlUnit ( ) ; return new WebDriverCommandProcessor ( browserUrl , capabilities ) ; commandProcessor = detectWebDriverCommandProcessor ( browser , browserUrl ) ; commandProcessor . start ( ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "BASE", "-", "37", "use", "FileObjects", "instead", "of", "String", "arguments", "also", "use"], "add_tokens": "* public class HierarchicalIOException extends IOException { / * * * * / private static final long serialVersionUID = 3608772268419554801L ; * * @ param message * exception message public HierarchicalIOException ( final String message ) { super ( message ) ; * * @ param message * exception message * @ param cause * exception cause public HierarchicalIOException ( final String message , final Throwable cause ) { super ( message ) ; initCause ( cause ) ; * * @ param cause * exception cause public HierarchicalIOException ( final Throwable cause ) { initCause ( cause ) ; }", "del_tokens": "* public class HierarchicalIOException extends IOException { * * @ param message exception message public HierarchicalIOException ( final String message ) { super ( message ) ; * * @ param message exception message * @ param cause exception cause public HierarchicalIOException ( final String message , final Throwable cause ) { super ( message ) ; initCause ( cause ) ; * * @ param cause exception cause public HierarchicalIOException ( final Throwable cause ) { initCause ( cause ) ; }", "commit_type": "fix"}
{"commit_tokens": ["updated", "to", "me", ".", "atrox", ".", "haikunator", "some", "fixes"], "add_tokens": "package me . atrox . haikunator ; import com . sun . deploy . util . StringUtils ; return StringUtils . join ( list , delimiter ) ;", "del_tokens": "package at . atrox . haikunator ; return String . join ( delimiter , list ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "support", "for", "ranged", "search", "queries", "using", "range", "filters", "."], "add_tokens": "u . setTimestamp ( 1000000000L ) ;", "del_tokens": "u . setTimestamp ( Utils . timestamp ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "analysis", "fully", "configurable", "added", "customername", "to", "snapshots", "and", "analyses"], "add_tokens": "public void setProperties ( Properties properties ) { System . out . println ( new LogEntry ( \"session timeout set to \" + sessionTimeout + \" (sec)\" ) ) ; defaultAdminPassword = properties . getProperty ( \"default_admin_password\" , defaultAdminPassword ) ;", "del_tokens": "protected void setProperties ( Properties properties ) { defaultAdminPassword = properties . getProperty ( \"default_admin_password\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "rules", "to", "create", "bundle", "fixed", "javadoc", "issue"], "add_tokens": "* For j , in the range < tt > 0 & lt ; = j & lt ; = N < / tt > , < tt > jc [ j ] < / tt > is the index in ir and < tt > pr < / tt > ( and < tt > pi < / tt > * if it exists ) of the first nonzero entry in the jth column and < tt > jc [ j + 1 ] �1< / t t > i dex", "del_tokens": "* For j , in the range < tt > 0 & lt ; = j & lt ; = N1 < / tt > , < tt > jc [ j ] < / tt > is the index in ir and < tt > pr < / tt > ( and < tt > pi < / tt > * if it exists ) of the first nonzero entry in the jth column and < tt > jc [ j + 1 ] 1 < / tt > index", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "to", "clear", "selection", "of", "ComboBox", "items"], "add_tokens": "public void setItemSelected ( int i , boolean isSelected ) { if ( ! isSelected ) { currentValue . setText ( \"\" ) ; this . selectedItemIndex = - 1 ; this . selectedItemIndex = i ; currentValue . setText ( values . get ( selectedItemIndex ) ) ; public void clearSelection ( ) { for ( int i = 0 ; i < getItemCount ( ) ; i ++ ) { setItemSelected ( i , false ) ; } }", "del_tokens": "public void setItemSelected ( int i , boolean b ) { if ( b ) { this . selectedItemIndex = i ; currentValue . setText ( values . get ( selectedItemIndex ) ) ; this . selectedItemIndex = - 1 ;", "commit_type": "add"}
{"commit_tokens": ["Move", "vendor", "js", "files", "from", "CouchApp", "structure", "to", "Javascript", "library", "."], "add_tokens": "// Libraries { FSEntry f = FSEntryFile . getPositionedFile ( \"a/_attachments/nunaliit2\" , n2Dir ) ; entries . add ( f ) ; } // Vendor file 'utils.js' { File file = new File ( n2Dir , \"n2.couchUtils.js\" ) ; FSEntry f = FSEntryFile . getPositionedFile ( \"a/vendor/nunaliit2/utils.js\" , file ) ; entries . add ( f ) ; } // Vendor file 'tiles.js' { File file = new File ( n2Dir , \"n2.couchTiles.js\" ) ; FSEntry f = FSEntryFile . getPositionedFile ( \"a/vendor/nunaliit2/tiles.js\" , file ) ; entries . add ( f ) ; }", "del_tokens": "// Vendor files { File utilsFile = new File ( atlasDesignDir , \"vendor/nunaliit2/utils.js\" ) ; if ( utilsFile . exists ( ) ) { FSEntry f = FSEntryFile . getPositionedFile ( \"a/_attachments/lib/utils.js\" , utilsFile ) ; entries . add ( f ) ; } } { File tilesFile = new File ( atlasDesignDir , \"vendor/nunaliit2/tiles.js\" ) ; if ( tilesFile . exists ( ) ) { FSEntry f = FSEntryFile . getPositionedFile ( \"a/_attachments/lib/tiles.js\" , tilesFile ) ; entries . add ( f ) ; } } FSEntry f = FSEntryFile . getPositionedFile ( \"a/_attachments/nunaliit2\" , n2Dir ) ; entries . add ( f ) ;", "commit_type": "move"}
{"commit_tokens": ["make", "initialization", "less", "strict", "and", "more", "talkative"], "add_tokens": "LOG . info ( \"initializing InApplicationMonitorJMXConnector\" ) ; LOG . warn ( \"JMXConnector allready initialized, will shut previous instance down and create a new one\" ) ; instance . shutdown ( ) ; //throw new IllegalStateException(\"JMXConnector allready initialized\"); instance = this ;", "del_tokens": "throw new IllegalStateException ( \"JMXConnector allready initialized\" ) ; instance = this ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "stop", "()", "to", "the", "BMPCManager", "interface"], "add_tokens": "@ Override public synchronized void stop ( ) { if ( isRunning ( ) ) { try { process . destroy ( ) ; process . waitFor ( ) ; process = null ; stdout = null ; } catch ( Exception ie ) { throw new BMPCLocalStartStopException ( String . format ( \"Failed to stop Local BrowserMob Proxy on port '%d'\" , port ) , ie ) ; } } }", "del_tokens": "/ * * * Stop Local BrowserMob proxy * / public synchronized void stop ( ) { if ( isRunning ( ) ) { try { process . destroy ( ) ; process . waitFor ( ) ; process = null ; stdout = null ; } catch ( Exception ie ) { throw new BMPCLocalStartStopException ( String . format ( \"Failed to stop Local BrowserMob Proxy on port '%d'\" , port ) , ie ) ; } } }", "commit_type": "add"}
{"commit_tokens": ["Making", "marker", "animation", "more", "efficient", "."], "add_tokens": "* TODO Document", "del_tokens": "* Created by rjszabo on 3 / 22 / 14. CircularViewObject ( final Context context , final float x , final float y , final float radius , final float radiusPadding , final int centerBackgroundColor ) { this ( context ) ; this . radiusPadding = radiusPadding ; paint . setColor ( centerBackgroundColor ) ; init ( x , y , radius , null ) ; }", "commit_type": "make"}
{"commit_tokens": ["Added", "chained", "flatmap", "tests", "."], "add_tokens": "@ Test public void flatMapChain ( ) { assertEquals ( View . ofArray ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ) . flatMap ( null ) . flatMap ( null ) . flatMap ( null ) , View . EMPTY_VIEW ) ; assertEquals ( View . EMPTY_VIEW . flatMap ( null ) . flatMap ( null ) . flatMap ( null ) , View . EMPTY_VIEW ) ; assertArrayEquals ( View . ofArray ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ) . flatMap ( null ) . flatMap ( null ) . flatMap ( null ) . toArray ( ) , new Integer [ ] { } ) ; assertArrayEquals ( View . ofArray ( 1 , 10 ) . flatMap ( i -> View . ofArray ( i , i * 2 , i * 3 ) ) . flatMap ( i -> View . ofArray ( i , i + 1 ) ) . toArray ( ) , new Integer [ ] { 1 , 2 , 2 , 3 , 3 , 4 , 10 , 11 , 20 , 21 , 30 , 31 } ) ; }", "del_tokens": "// TODO: Test flatmap chaining", "commit_type": "add"}
{"commit_tokens": ["Updated", "the", "CDATA", "methods", "(", "cdata", "data", "d", ")", "to", "automatically", "Base64", "-", "encode", "text", "values", ".", "To", "perform", "this", "task", "added", "the", "excellent", "public", "domain", "Base64", "implementation", "from", "http", ":", "//", "iharder", ".", "net", "/", "base64"], "add_tokens": "import net . iharder . base64 . Base64 ; * the data value that will be Base64 - encoded and added to a CDATA element . public XMLBuilder cdata ( byte [ ] data ) { xmlElement . appendChild ( getDocument ( ) . createCDATASection ( Base64 . encodeBytes ( data , Base64 . DONT_BREAK_LINES ) ) ) ; public XMLBuilder data ( byte [ ] data ) { public XMLBuilder d ( byte [ ] data ) {", "del_tokens": "* the data value to add to the element . public XMLBuilder cdata ( String data ) { xmlElement . appendChild ( getDocument ( ) . createCDATASection ( data ) ) ; public XMLBuilder data ( String data ) { public XMLBuilder d ( String data ) {", "commit_type": "update"}
{"commit_tokens": ["added", "enum", "support", "from", "@gaddas", "s", "pull", "request"], "add_tokens": "import java . lang . reflect . Method ; import java . lang . reflect . Modifier ; } else if ( Enum . class . isAssignableFrom ( field . getType ( ) ) ) { try { Method valueOf = field . getType ( ) . getMethod ( \"valueOf\" , String . class ) ; String strVal = cursor . getString ( cursor . getColumnIndex ( colName ) ) ; Object enumVal = valueOf . invoke ( field . getType ( ) , strVal ) ; field . set ( this , enumVal ) ; } catch ( Exception e ) { Log . e ( \"Sugar\" , \"Enum cannot be read from Sqlite3 database. Please check the type of field \" + field . getName ( ) ) ; } Log . e ( \"Sugar\" , \"Class cannot be read from Sqlite3 database. Please check the type of field \" + field . getName ( ) + \"(\" + field . getType ( ) . getName ( ) + \")\" ) ; if ( ! field . isAnnotationPresent ( Ignore . class ) && ! Modifier . isStatic ( field . getModifiers ( ) ) ) {", "del_tokens": "Log . e ( \"Sugar\" , \"Class cannot be read from Sqlite3 database.\" ) ; if ( ! field . isAnnotationPresent ( Ignore . class ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "input", "and", "output", "session", "buffers", ".", "Printed", "status", "type", "and", "headers", "of", "response", "from", "socket", ".", "Added", "constants", "and", "helper", "methods", "from", "ApacheHttpClient4Handler", "."], "add_tokens": "restEndpointUrl = \"/v1.3\" ; //schemeRegistry.register(new Scheme(\"http\", 4243, PlainSocketFactory.getSocketFactory())); //HttpClient httpClient = new DefaultHttpClient(cm); //client = new ApacheHttpClient4(new ApacheHttpClient4Handler(httpClient, null, false), clientConfig); //client.addFilter(new JsonClientFilter());", "del_tokens": "restEndpointUrl = serverUrl + \"/v1.3\" ; schemeRegistry . register ( new Scheme ( \"http\" , 4243 , PlainSocketFactory . getSocketFactory ( ) ) ) ; // HttpClient httpClient = new DefaultHttpClient(cm); // client = new ApacheHttpClient4(new ApacheHttpClient4Handler(httpClient, null, false), clientConfig); client . addFilter ( new JsonClientFilter ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "mistake", "location", "ID", "to", "corpus", "verification", "scripts"], "add_tokens": "System . out . printf ( \"Slikts tags vārdam %s : '%s' -> '%s' \\t\\t%s\\n\", . w ordform, . t ag, arkupConverter. t oKamolsMarkupNoDefaults( e talonaAV) , . i d) ; mistakes . add ( e . wordform + \"\\nKorpusā:\\t\"+ e . l emma+ \" \\t\"+ e . t ag+ \" \\t\\t(\" . i d )\\n\"+ o utput) ; mistakes . add ( \"Nav variantu :( \\t\" + e . wordform + \"\\t\" + e . lemma + \"\\t\" + e . tag + \"\\t\\t\" + e . id + \"\\n\" ) ; String id ; etalons . wordform = parse [ 0 ] ; etalons . lemma = parse [ 2 ] ; if ( parse . length > 3 ) etalons . id = parse [ 3 ] ; //some but not all vert files will have a 4th row containing the ID of the word in corpus", "del_tokens": "System . out . printf ( \"Slikts tags vārdam %s : '%s' -> '%s' \\n\", . w ordform, . t ag, arkupConverter. t oKamolsMarkupNoDefaults( e talonaAV) ) ; mistakes . add ( e . wordform + \"\\nKorpusā:\\t\"+ e . l emma+ \" \\t\"+ e . t ag+ \" \\n\"+ o utput) ; mistakes . add ( \"Nav variantu :( \\t\" + e . wordform + \"\\t\" + e . lemma + \"\\t\" + e . tag + \"\\n\" ) ; etalons . wordform = parse [ 0 ] ; etalons . lemma = parse [ 2 ] ;", "commit_type": "add"}
{"commit_tokens": ["Added", "testing", "for", "both", "methods", "of", "deserialization"], "add_tokens": "import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import java . util . List ; @ RunWith ( Parameterized . class ) private final boolean useStreamDeserialization ; @ Parameterized . Parameters public static List < Object [ ] > getParameters ( ) { return Arrays . asList ( new Object [ ] { true } , new Object [ ] { false } ) ; } public TestParsingAndGenerating ( boolean useStreamDeserialization ) { this . useStreamDeserialization = useStreamDeserialization ; } if ( useStreamDeserialization ) { coll . enable ( JacksonDBCollection . Feature . USE_STREAM_DESERIALIZATION ) ; } else { coll . disable ( JacksonDBCollection . Feature . USE_STREAM_DESERIALIZATION ) ; }", "del_tokens": "import com . mongodb . DB ; import com . mongodb . Mongo ; import org . junit . After ;", "commit_type": "add"}
{"commit_tokens": ["move", "log", "and", "config", "into", "static", "Util"], "add_tokens": "import org . binwang . bard . core . Util ; Util . getLogger ( ) . info ( \"Request complete, method: {}, URI: {}{}, time: {}ms\" , Util . getLogger ( ) . warn ( \"Exception found after request: {}\" , context . exception ) ;", "del_tokens": "logger . info ( \"Request complete, method: {}, URI: {}{}, time: {}ms\" , logger . warn ( \"Exception found after request: {}\" , context . exception ) ;", "commit_type": "move"}
{"commit_tokens": ["Fix", "a", "bug", "in", "certificate", "loading", "..."], "add_tokens": "// NOTE: this ordering is important. The API Client re-evaluates the CA certificate every // time the SSL info changes, which means that if this comes after the following call // you will try to load a certificate with an exhausted InputStream. So setting the CA // certificate _has_ to be the last thing that you do related to SSL. // // TODO: this (imho) is broken in the generate Java Swagger Client code. We should fix it // upstream and remove this dependency. // // TODO: Add a test to ensure that this works correctly... if ( caCertBytes != null ) { client . setSslCaCert ( new ByteArrayInputStream ( caCertBytes ) ) ; }", "del_tokens": "if ( caCertBytes != null ) { client . setSslCaCert ( new ByteArrayInputStream ( caCertBytes ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Use", "property", "file", "included", "with", "NER", "read", "Demonyms", ".", "txt", "from", "jar", "file"], "add_tokens": "import java . io . InputStream ; import java . io . InputStreamReader ; import java . util . Properties ; InputStream mpis = this . getClass ( ) . getClassLoader ( ) . getResourceAsStream ( \"models/all.3class.distsim.prop\" ) ; Properties mp = new Properties ( ) ; mp . load ( mpis ) ; // namedEntityRecognizer = (AbstractSequenceClassifier<CoreMap>) // CRFClassifier.getJarClassifier(\"/models/all.3class.distsim.crf.ser.gz\", System.getProperties()); namedEntityRecognizer = ( AbstractSequenceClassifier < CoreMap > ) CRFClassifier . getJarClassifier ( \"/models/all.3class.distsim.crf.ser.gz\" , mp ) ; // BufferedReader br = new BufferedReader(new FileReader(\"src/main/resources/Demonyms.txt\")); BufferedReader br = new BufferedReader ( new InputStreamReader ( this . getClass ( ) . getClassLoader ( ) . getResourceAsStream ( \"Demonyms.txt\" ) ) ) ;", "del_tokens": "namedEntityRecognizer = ( AbstractSequenceClassifier < CoreMap > ) CRFClassifier . getJarClassifier ( \"/models/all.3class.distsim.crf.ser.gz\" , System . getProperties ( ) ) ; BufferedReader br = new BufferedReader ( new FileReader ( \"src/main/resources/Demonyms.txt\" ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "error", "in", "the", "mutation", "for", "effective", "length"], "add_tokens": "while ( loc < instructions . size ( ) && instructions . get ( loc ) . getOperator ( ) . isConditionalConstruct ( ) )", "del_tokens": "while ( instructions . get ( loc ) . getOperator ( ) . isConditionalConstruct ( ) && loc < instructions . size ( ) )", "commit_type": "fix"}
{"commit_tokens": ["added", "slave", "address", "validation", "."], "add_tokens": "if ( request . getServerAddress ( ) == getSlave ( ) . getServerAddress ( ) ) { ModbusResponse response = request . getResponse ( dataHolder ) ; if ( ! response . isException ( ) ) getSlave ( ) . getDataHolder ( ) . getCommStatus ( ) . incrementEventCount ( ) ; transport . send ( response ) ; }", "del_tokens": "ModbusResponse response = request . getResponse ( dataHolder ) ; if ( ! response . isException ( ) ) getSlave ( ) . getDataHolder ( ) . getCommStatus ( ) . incrementEventCount ( ) ; transport . send ( response ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "specify", "the", "amount", "of", "text", "to", "extract", "and", "index", "from", "an", "attachment", "."], "add_tokens": "* _content_length : \"500000000\" , * _content_length = Specify the maximum amount of characters to extract from the attachment . If not specified , then the default for * tika is 100 , 000 characters . Caution is required when setting large values as this can cause memory issues . int contentLength = 100000 ; } else if ( token == XContentParser . Token . VALUE_NUMBER ) { if ( \"_content_length\" . equals ( currentFieldName ) ) { contentLength = parser . intValue ( ) ; } // Set the maximum length of strings returned by the parseToString method, -1 sets no limit tika ( ) . setMaxStringLength ( contentLength ) ; throw new MapperParsingException ( \"Failed to extract [\" + contentLength + \"] characters of text for [\" + name + \"]\" , e ) ;", "del_tokens": "throw new MapperParsingException ( \"Failed to extract text for [\" + name + \"]\" , e ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "default", "mapping", "issue", "by", "adding", "a", "constant", "for", "it"], "add_tokens": "import javax . script . ScriptEngineFactory ; DEFAULT , JAVASCRIPT // Uncomment the following to debug which script engines are available on // the classpath // static { // List<ScriptEngineFactory> factories = // SCRIPT_MANAGER.getEngineFactories(); // // System.out.println(\"Installed script engines:\"); // // for (ScriptEngineFactory nextFactory : factories) { // System.out.println(nextFactory.getEngineName()); // } // } try { result . language = CSVMappingLanguage . valueOf ( language . toUpperCase ( ) ) ; } catch ( IllegalArgumentException e ) { result . language = CSVMappingLanguage . DEFAULT ; }", "del_tokens": "JAVASCRIPT result . language = CSVMappingLanguage . valueOf ( language . toUpperCase ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "script", "to", "launch", "benchmark", "add", "hibernate", "cache", "benchmark"], "add_tokens": "protected Mapper < ResultSet , T > getMapper ( MapperKey key ) {", "del_tokens": "private Mapper < ResultSet , T > getMapper ( MapperKey key ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "default", "mappings", "for", "each", "language", "separately", "and", "utilise", "those", "to", "detect", "where", "we", "can", "short", "-", "circuit", "slightly", "better"], "add_tokens": "public enum ValueMappingLanguage { DEFAULT ( ValueMapping . DEFAULT_MAPPING ) , JAVASCRIPT ( \"return inputValue;\" ) , GROOVY ( \"inputValue\" ) , LUA ( \"return inputValue\" ) , ACCESS ( \"\" ) ; private final String defaultMapping ; ValueMappingLanguage ( String defaultMapping ) { this . defaultMapping = defaultMapping ; } public String getDefaultMapping ( ) { return this . defaultMapping ; } public boolean matchesDefaultMapping ( String mapping ) { return this . getDefaultMapping ( ) . equals ( mapping ) ; } } nextMapping = nextLanguage . getDefaultMapping ( ) ; // Short circuit if the mapping is a default mapping if ( this . language == ValueMappingLanguage . DEFAULT || this . language . matchesDefaultMapping ( this . mapping ) ) { if ( this . language == ValueMappingLanguage . DEFAULT || this . language . matchesDefaultMapping ( this . mapping ) ) {", "del_tokens": "public enum ValueMappingLanguage { DEFAULT , JAVASCRIPT , GROOVY , LUA , ACCESS } nextMapping = DEFAULT_MAPPING ; // Short circuit if the mapping is the default mapping if ( this . mapping . equalsIgnoreCase ( DEFAULT_MAPPING ) || this . language == ValueMappingLanguage . DEFAULT ) { if ( this . mapping . equalsIgnoreCase ( DEFAULT_MAPPING ) || this . language == ValueMappingLanguage . DEFAULT ) {", "commit_type": "add"}
{"commit_tokens": ["Use", "Variant", ".", "NullValue", "instead", "of", "null"], "add_tokens": "Variant value = ( ( mask & 0x01 ) == 0x01 ) ? decodeVariant ( null ) : Variant . NullValue ;", "del_tokens": "Variant value = ( ( mask & 0x01 ) == 0x01 ) ? decodeVariant ( null ) : null ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "intent", "builder", "in", "sample"], "add_tokens": "import org . parceler . Parcels ; Intent intent = SampleActivityIntentBuilder . withStringExtra ( \"a string\" ) . withIntExtra ( 4 ) . withParcelableExtra ( ComplexParcelable . random ( ) ) . withParcelExra ( new ExampleParcel ( \"Andy\" ) ) . build ( ) ; intent . putExtra ( \"defaultKeyExtra\" , \"defaultKeyExtra\" ) ;", "del_tokens": "Intent intent = SampleActivity . getLaunchIntent ( this , \"a string\" , 4 , ComplexParcelable . random ( ) , new ExampleParcel ( \"Andy\" ) , \"defaultKeyExtra\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Upgrade", "util", "-", "java", "version"], "add_tokens": "this . clientFactory = JsonClientFactory . of ( logic ) ;", "del_tokens": "this . clientFactory = JsonClientFactory . create ( logic ) ;", "commit_type": "upgrade"}
{"commit_tokens": ["make", "getStateEngine", "public", "on", "HollowObjectMapper"], "add_tokens": "public HollowWriteStateEngine getStateEngine ( ) {", "del_tokens": "HollowWriteStateEngine getStateEngine ( ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "support", "for", "using", "feature", "-", "pack", ".", "txt", "/", "manifest", "to", "determine", "modules"], "add_tokens": "String modulesStr = manifest . getMainAttributes ( ) . getValue ( \"Feature-Pack-Modules\" ) ; String [ ] modules = modulesStr . split ( \",\" ) ; for ( int i = 0 ; i < modules . length ; ++ i ) { String [ ] parts = modules [ i ] . trim ( ) . split ( \":\" ) ; builder . addDependency ( DependencySpec . createModuleDependencySpec ( ModuleIdentifier . create ( parts [ 0 ] , parts [ 1 ] ) , false ) ) ; }", "del_tokens": "builder . addDependency ( DependencySpec . createModuleDependencySpec ( ModuleIdentifier . create ( \"org.wildfly.boot.core\" ) , false , true ) ) ; builder . addDependency ( DependencySpec . createModuleDependencySpec ( ModuleIdentifier . create ( \"org.wildfly.boot.web\" ) , false , true ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "ability", "to", "restrict", "blob", "store", "Content", "-", "Type", "response", "headers"], "add_tokens": "import com . bazaarvoice . emodb . web . resources . blob . ApprovedBlobContentTypes ; import java . util . Set ; Set < String > approvedContentTypes = _injector . getInstance ( Key . get ( new TypeLiteral < Set < String > > ( ) { } , ApprovedBlobContentTypes . class ) ) ; resources . addResource ( _cluster , \"emodb-blob-1\" , new BlobStoreResource1 ( blobStore , dataCenters , approvedContentTypes ) ) ;", "del_tokens": "resources . addResource ( _cluster , \"emodb-blob-1\" , new BlobStoreResource1 ( blobStore , dataCenters ) ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "SubsetSolution", "to", "solutions", "package"], "add_tokens": "package org . jamesframework . core . problems . solutions ;", "del_tokens": "package org . jamesframework . core . problems . solutions . subset ;", "commit_type": "move"}
{"commit_tokens": ["fix", "platform", "reporting", "for", "Flex"], "add_tokens": "if ( hasMetadataServer && env . containsKey ( \"GAE_SERVICE\" ) ) {", "del_tokens": "if ( hasMetadataServer && onGae ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "tests", "for", "DataTerminatingInputStream", "and", "fix", "a", "bug", "in", "the", "impl"], "add_tokens": "import java . io . FileInputStream ; / * * * { @ link FileInputStream } which takes care of correctly terminating the DATA command . This is done by append a CRLF . CRLF to wrapped * { @ link InputStream } if needed . * * @ author Norman Maurer * * / extraData [ 0 ] = '.' ; extraData [ 1 ] = '\\r' ; extraData [ 2 ] = '\\n' ;", "del_tokens": "// Make sure we respect the offset. Otherwise it could let the RETRCmdHandler // hang forever. See JAMES-1222 extraData [ 1 ] = '.' ; extraData [ 2 ] = '\\r' ; extraData [ 3 ] = '\\n' ;", "commit_type": "add"}
{"commit_tokens": ["changed", "TreasureDataLogger", ".", "java", ".", "changed", "order", "for", "API", "key", "lookup", "."], "add_tokens": "/ * * Define order for API key lookup . * 1. lookup ENV [ 'TD_API_KEY' ] * 2. lookup props 's ' td . logger . api . key ' * 3. lookup props 's ' td . api . key ' * / if ( props . containsKey ( Config . TD_LOGGER_API_KEY ) ) { apiKey = props . getProperty ( Config . TD_LOGGER_API_KEY ) ; } if ( apiKey == null ) { if ( props . containsKey ( Config . TD_API_KEY ) ) { apiKey = props . getProperty ( Config . TD_API_KEY ) ; } }", "del_tokens": "apiKey = props . getProperty ( Config . TD_LOGGER_API_KEY ) ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "bug", "for", "multi", "jcrom", "package", "configuration"], "add_tokens": "JcrRepository repo = null ; continue ; //next configuration if ( repo == null ) { repo = new JcrRepository ( conf , repositoryFactory , applicationConfiguration ) ; }", "del_tokens": "break ; //next configuration //Create a pull for this configuration JcrRepository repo = null ; repo = new JcrRepository ( conf , repositoryFactory , applicationConfiguration ) ;", "commit_type": "fix"}
{"commit_tokens": ["make", "bus", "delay", "and", "timeout", "configurable"], "add_tokens": "@ Scheduled ( fixedDelayString = \"${spring.cloud.consul.bus.eventDelay:10}\" )", "del_tokens": "@ Scheduled ( fixedDelayString = \"10\" )", "commit_type": "make"}
{"commit_tokens": ["added", "history", "CI", "to", "shell"], "add_tokens": "import de . vandermeer . asciitable . v2 . render . width . V2_WidthFixedColumns ; this . width = new V2_WidthFixedColumns ( ) . add ( 15 ) . add ( 70 ) ; // this.width = new V2_WidthAbsoluteEven().setWidth(76);", "del_tokens": "import de . vandermeer . asciitable . v2 . render . width . V2_WidthAbsoluteEven ; this . width = new V2_WidthAbsoluteEven ( ) . setWidth ( 76 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "json", "decoding", "for", "failover", "log", "entry", "."], "add_tokens": "import com . couchbase . client . deps . com . fasterxml . jackson . annotation . JsonCreator ; import com . couchbase . client . deps . com . fasterxml . jackson . annotation . JsonProperty ; @ JsonCreator public FailoverLogEntry ( @ JsonProperty ( \"seqno\" ) long seqno , @ JsonProperty ( \"uuid\" ) long uuid ) {", "del_tokens": "public FailoverLogEntry ( long seqno , long uuid ) {", "commit_type": "add"}
{"commit_tokens": ["Fix", "StreamFileWriter", "StreamBinaryDeserializer", ".", "Improve", "test", ".", "Add", "method", "setActualConsumer", "to", "StreamConsumerDecorator"], "add_tokens": "close ( ) ; if ( upstreamConsumer . getStatus ( ) >= END_OF_STREAM ) {", "del_tokens": "// TODO (vsavchuk) fix // close(); if ( upstreamConsumer . getStatus ( ) == END_OF_STREAM ) {", "commit_type": "fix"}
{"commit_tokens": ["Removes", "old", "component", "correctly", "when", "adding", "duplicated", "one", "."], "add_tokens": "Component oldComponent = getComponent ( componentClass ) ; if ( component == oldComponent ) { return this ; if ( oldComponent != null ) { removeInternal ( componentClass ) ; } int componentTypeIndex = ComponentType . getIndexFor ( componentClass ) ;", "del_tokens": "for ( int i = 0 ; i < componentsArray . size ; ++ i ) { if ( componentsArray . get ( i ) . getClass ( ) == componentClass ) { componentsArray . removeIndex ( i ) ; break ; } int componentTypeIndex = ComponentType . getIndexFor ( component . getClass ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "CREATOR", "from", "PaperParcels", "and", "require", "that", "the", "user", "creates", "it", "themselves", "to", "allow", "for", "typed", "arrays"], "add_tokens": "public static class Creator < T > implements Parcelable . Creator < T > { private final Class < ? extends T > type ; public Creator ( Class < ? extends T > type ) { this . type = type ; } public T createFromParcel ( Parcel parcel ) { return PaperParcels . unsafeUnwrap ( parcel . readParcelable ( type . getClassLoader ( ) ) ) ; @ Override public T [ ] newArray ( int i ) { return PaperParcels . newArray ( type , i ) ; }", "del_tokens": "public static final Parcelable . Creator < Object > CREATOR = new Parcelable . Creator < Object > ( ) { @ Override public Object createFromParcel ( Parcel parcel ) { return PaperParcels . unsafeUnwrap ( parcel . readParcelable ( PaperParcelable . class . getClassLoader ( ) ) ) ; @ Override public Object [ ] newArray ( int i ) { return new Object [ i ] ; } ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "a", "method", "to", "force", "monoscopic", "rendering", "."], "add_tokens": "private boolean forceMonoscopic = false ; if ( isVrSupported ( ) && ! forceMonoscopic ) { / * * * Sets whether to force rendering to be single - eye , monoscopic view . * * @ param force * If true , will create a GVRMonoscopicViewManager when { @ linkplain setScript setScript ( ) } is called . If false , will proceed to auto - detect whether the device supports VR rendering and choose the appropriate ViewManager . * * / public void setForceMonoscopic ( boolean force ) { forceMonoscopic = force ; } / * * * Returns whether a monoscopic view will be created during { @ linkplain setScript setScript ( ) } . * / public boolean getForceMonoscopic ( ) { return forceMonoscopic ; }", "del_tokens": "if ( isVrSupported ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["add", "update", "/", "list", "webhooks"], "add_tokens": "final Webhook webhook = TestUtil . createWebhook ( ) ; final WebhookResponseData response = messageBirdClientInjectMock . createWebhook ( webhook ) ; final WebhookResponseData response = messageBirdClientInjectMock . viewWebhook ( \"ANY_ID\" ) ;", "del_tokens": "final Webhook webhook = TestUtil . createWebHook ( ) ; final WebhookResponseData response = messageBirdClientInjectMock . createWebHook ( webhook ) ; @ Test ( expected = IllegalArgumentException . class ) public void shouldThrowIllegalArgumentExceptionWhenCreateWebhookWithMissingTitle ( ) throws UnauthorizedException , GeneralException { final Webhook webhook = new Webhook ( ) ; webhook . setUrl ( \"ANY_URL\" ) ; messageBirdClient . createWebHook ( webhook ) ; } @ Test ( expected = IllegalArgumentException . class ) public void shouldThrowIllegalArgumentExceptionWhenCreateWebhookWithMissingUrl ( ) throws UnauthorizedException , GeneralException { final Webhook webhook = new Webhook ( ) ; webhook . setTitle ( \"ANY_TITLE\" ) ; messageBirdClient . createWebHook ( webhook ) ; } final WebhookResponseData response = messageBirdClientInjectMock . viewWebHook ( \"ANY_ID\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Making", "map", "immutable", "for", "Switch"], "add_tokens": "import com . google . common . collect . ImmutableMap ; private final ImmutableMap . Builder < SerializablePredicate < ? super T > , CheckedFunction < ? super T , ? extends R > > caseStmts = ImmutableMap . builder ( ) ; return new Switch < > ( caseStmts . build ( ) , defaultStmt ) ;", "del_tokens": "import java . util . HashMap ; private final Map < SerializablePredicate < ? super T > , CheckedFunction < ? super T , ? extends R > > caseStmts = new HashMap < > ( ) ; return new Switch < > ( caseStmts , defaultStmt ) ;", "commit_type": "make"}
{"commit_tokens": ["Improve", "RestController", "var", "names", "."], "add_tokens": "@ RequestParam Map < String , String > queryParamMap ) { final RawQueryParameters raw = new RawQueryParameters ( queryParamMap ) ;", "del_tokens": "@ RequestParam Map < String , String > queryParams ) { final RawQueryParameters raw = new RawQueryParameters ( queryParams ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "2", "functions", "to", "CONI", ".", "java", "."], "add_tokens": "public void addGesture ( Gesture ... gestures ) { if ( ! gestureEnabled ) { throw new CONIRuntimeException ( \"must enable gesture previously\" ) ; } try { for ( Gesture g : gestures ) { gestureGenerator . addGesture ( Gesture . toString ( g ) ) ; } } catch ( StatusException e ) { throw new CONIRuntimeException ( ) ; } } public void removeGesture ( Gesture ... gestures ) { if ( ! gestureEnabled ) { throw new CONIRuntimeException ( \"must enable gesture previously\" ) ; } try { for ( Gesture g : gestures ) { gestureGenerator . removeGesture ( Gesture . toString ( g ) ) ; } } catch ( StatusException e ) { throw new CONIRuntimeException ( ) ; } } poseDetectionCap . startPoseDetection ( skeletonCap . getSkeletonCalibrationPose ( ) , userID ) ; poseDetectionCap . stopPoseDetection ( userID ) ;", "del_tokens": "poseDetectionCap . StartPoseDetection ( skeletonCap . getSkeletonCalibrationPose ( ) , userID ) ; poseDetectionCap . StopPoseDetection ( userID ) ;", "commit_type": "add"}
{"commit_tokens": ["FIXED", ":", "https", ":", "//", "github", ".", "com", "/", "Pi4J", "/", "pi4j", "/", "issues", "/", "23"], "add_tokens": "logger . severe ( \"Library [\" + libraryName + \"] could not be located using the System.loadLibrary(name) method and no embedded file path was provided as an auxillary lookup.\" ) ; logger . fine ( \"Library [\" + libraryName + \"] could not be located using the System.loadLibrary(name) method; attempting to resolve the library using embedded resources in the JAR file.\" ) ; // check for system properties boolean armhf_force = false ; if ( System . getProperty ( \"pi4j.armhf\" ) != null ) armhf_force = true ; boolean armel_force = false ; if ( System . getProperty ( \"pi4j.armel\" ) != null ) armel_force = true ; if ( armhf_force ) { } else if ( armel_force ) { } else { logger . fine ( \"AUTO-DETECTED HARD-FLOAT ABI : \" + SystemInfo . isHardFloatAbi ( ) ) ; if ( SystemInfo . isHardFloatAbi ( ) ) { } // attempt to get the native library from the JAR file in the 'lib/hard-float' directory resourceUrl = NativeLibraryLoader . class . getResource ( \"/lib/hard-float/\" + fileName ) ; } else { // attempt to get the native library from the JAR file in the 'lib/soft-float' directory resourceUrl = NativeLibraryLoader . class . getResource ( \"/lib/soft-float/\" + fileName ) ; } } catch ( Exception | UnsatisfiedLinkError ex ) {", "del_tokens": "logger . severe ( \"Library [\" + libraryName + \"] could not be using the System.loadLibrary(name) method and no embedded file path was provided as an auxillary lookup.\" ) ; logger . fine ( \"Library [\" + libraryName + \"] could not be using the System.loadLibrary(name) method; attempting to resolve the library using embedded resources in the JAR file.\" ) ; if ( SystemInfo . isHardFloatAbi ( ) ) { } else { } catch ( Exception ex ) {", "commit_type": "fix"}
{"commit_tokens": ["Using", "the", "context", "class", "loader", "appears", "to", "be", "necessary", "for", "the", "command", "line", "interface", ".", "Not", "entirely", "sure", "why", "."], "add_tokens": "import static java . lang . Thread . currentThread ; assignedClass = currentThread ( ) . getContextClassLoader ( ) . loadClass ( dottedClassName ) ;", "del_tokens": "assignedClass = getClass ( ) . getClassLoader ( ) . loadClass ( dottedClassName ) ;", "commit_type": "use"}
{"commit_tokens": ["Improved", "JSON", "bracket", "notation", "."], "add_tokens": "import java . util . Scanner ; * < p / > * < p / > * < p / > * < p / > * < p / > * < p / > * < p / > * the path < code > $ . store . book [ 1 ] . category < / code > returns [ \"$\" , \"store\" , \"book\" , \"[1]\" , \"category\" ] jsonPath = jsonPath . replace ( \"$['\" , \"$.['\" ) . replaceAll ( \"\\\\['(\\\\w+)\\\\.(\\\\w+)']\" , \"['$1~$2']\" ) . replace ( \"']['\" , \"'].['\" ) . replace ( \"..\" , \".~~.\" ) fragments . add ( split [ i ] . replace ( \"@\" , \"@.\" ) . replace ( \"~\" , \".\" ) ) ; //for (String fragment : fragments) { // System.out.println(fragment); //}", "del_tokens": "* * * * * * * * the path < code > $ . store . book [ 1 ] . category < / code > returns [ \"$\" , \"store\" , \"book\" , \"[1]\" , \"value\" ] jsonPath = jsonPath . replace ( \"..\" , \".~.\" ) fragments . add ( split [ i ] . replace ( \"@\" , \"@.\" ) . replace ( \"~\" , \"..\" ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["move", "the", "ns", "filter", "after", "the", "wiretap"], "add_tokens": "// this must be after wiretap! if ( ! filteredNamespaces . isEmpty ( ) ) { reader = new NamespaceDroppingFilter ( reader , filteredNamespaces ) ; }", "del_tokens": "if ( ! filteredNamespaces . isEmpty ( ) ) { reader = new NamespaceDroppingFilter ( reader , filteredNamespaces ) ; }", "commit_type": "move"}
{"commit_tokens": ["Make", "abilities", "case", "-", "insensitive", "fix", "msg", "markdown", "bug", "and", "add", "group", "-", "admin", "privacy"], "add_tokens": "public void canRecoverDB ( ) {", "del_tokens": "public void canRecoverDB ( ) throws IOException {", "commit_type": "make"}
{"commit_tokens": ["Allow", "m", "for", "minutes", "when", "using", "annotations"], "add_tokens": "private static Pattern minutes = Pattern . compile ( \"^([0-9]+)mi?n?$\" ) ;", "del_tokens": "private static Pattern minutes = Pattern . compile ( \"^([0-9]+)mi?n$\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Improve", "styling", "of", "show", "/", "hide", "toggle", "now", "requires", "bootstrap", "."], "add_tokens": "public static final String SHOW_HIDE_FEATURE_DISABLED = \"showHideFeatureDisabled\" ; Boolean showHideFeatureEnabled = false , showHideIsVisible = false ; final String showHideToggle = StringUtils . ifEmpty ( getAttributeByName ( filterNode , \"showHideToggle\" ) , SHOW_HIDE_FEATURE_DISABLED ) ; if ( ! showHideToggle . equals ( SHOW_HIDE_FEATURE_DISABLED ) ) { showHideFeatureEnabled = true ; showHideIsVisible = showHideToggle . toLowerCase ( ) . equals ( \"visible\" ) ; } // Boolean enableShowHideToggle = (Boolean) showHideToggle; filterConfig . addFilterSetting ( new FilterConfig . FilterMultipleFields ( filterColumns , filterFieldName , filterFieldLabel , filterFieldValueToLabelMap ) ) ; filterConfig . addFilterSetting ( new FilterSetting . FilterSettingsBuilder ( filterColumn , filterFieldName , filterFieldLabel ) . setFilterFieldValueToLabelMap ( filterFieldValueToLabelMap ) . setVisibleItemCount ( visibleItemCount ) . setFilterShowItemsOptions ( filterConfigVisualization ) . setFacetType ( facetType ) . setIsShowHideToggleEnabled ( showHideFeatureEnabled ) . setDefaultShowHideToggleStateIsVisible ( showHideIsVisible ) . build ( ) ) ;", "del_tokens": "System . out . println ( markerChildNode . getNodeName ( ) ) ; filterConfig . addFilter ( filterColumns , filterFieldName , filterFieldLabel , filterFieldValueToLabelMap ) ; filterConfig . addFilter ( filterColumn , filterFieldName , filterFieldLabel , filterFieldValueToLabelMap , visibleItemCount , filterConfigVisualization , facetType ) ;", "commit_type": "improve"}
{"commit_tokens": ["Add", "an", "example", "of", "injecting", "Lazy<T", ">", "into", "the", "CoffeeMaker", "app", "."], "add_tokens": "import com . squareup . objectgraph . Lazy ; @ Inject Lazy < Heater > heater ; // Don't want to create a possibly costly heater until we need it. heater . get ( ) . on ( ) ; heater . get ( ) . off ( ) ;", "del_tokens": "@ Inject Heater heater ; heater . on ( ) ; heater . off ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "registerWriter", "method", "to", "globally", "map", "writer", "to", "response", "type", "or", "produces", "annotation"], "add_tokens": "assertEquals ( 8 , definitions . size ( ) ) ;", "del_tokens": "assertEquals ( 6 , definitions . size ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "new", "platformTest", "type", "for", "installing", "of", "test", "apk", "."], "add_tokens": "// private File platformUnitTestDirectory; // if(System.getProperty(\"masa.debug\") != null && platformUnitTestDirectory.exists()) // { // project.addCompileSourceRoot(platformUnitTestDirectory.getAbsolutePath()); // }", "del_tokens": "private File platformUnitTestDirectory ; if ( System . getProperty ( \"masa.debug\" ) != null && platformUnitTestDirectory . exists ( ) ) { project . addCompileSourceRoot ( platformUnitTestDirectory . getAbsolutePath ( ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Update", "caret", "shape", "in", "ParagraphGraphic", ".", "layoutChildren", "."], "add_tokens": "if ( caretPosition != pos ) { caretPosition = pos ; updateCaretShape ( ) ; } @ Override protected void layoutChildren ( ) { super . layoutChildren ( ) ; updateCaretShape ( ) ; }", "del_tokens": "caretPosition = pos ; updateCaretShape ( ) ;", "commit_type": "update"}
{"commit_tokens": ["adding", "parallelism", "to", "snappy", "-", "dunit", "runs"], "add_tokens": "import java . io . BufferedReader ; import java . io . File ; import java . io . IOException ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . io . PrintStream ; import com . gemstone . gemfire . internal . FileUtil ; import com . gemstone . gemfire . internal . shared . NativeCalls ; import io . snappydata . test . dunit . RemoteDUnitVMIF ; import io . snappydata . test . dunit . logging . log4j . ConfigLocator ; import org . apache . commons . io . FileUtils ; '_' + NativeCalls . getInstance ( ) . getProcessId ( ) ) ;", "del_tokens": "import com . gemstone . gemfire . internal . FileUtil ; import io . snappydata . test . dunit . RemoteDUnitVMIF ; import io . snappydata . test . dunit . logging . log4j . ConfigLocator ; import org . apache . commons . io . FileUtils ; import java . io . * ; '_' + getProcessId ( ) ) ; public static String getProcessId ( ) { String name = ManagementFactory . getRuntimeMXBean ( ) . getName ( ) ; return name . substring ( 0 , name . indexOf ( '@' ) ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "user", "fee", "parameter", "for", "transactions"], "add_tokens": "import java . math . BigDecimal ; private String _userFee ; public String getUserFee ( ) { return _userFee ; } public void setUserFee ( BigDecimal userFee ) { _userFee = userFee . toPlainString ( ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Use", "new", "methods", "in", "demo", "app"], "add_tokens": "Toast . makeText ( getContext ( ) , getString ( R . string . my_name_string , item . getName ( ) ) , Toast . LENGTH_LONG ) . show ( ) ;", "del_tokens": "Toast . makeText ( getView ( ) . getContext ( ) , \"My name is \" + item . getName ( ) + \"!\" , Toast . LENGTH_LONG ) . show ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Allow", "container", "to", "run", "as", "non", "-", "root"], "add_tokens": "\"EOF\" + \"\\n\" ) ;", "del_tokens": "\"EOF\" + \"\\n\" ) . withUser ( \"root\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Added", "TODO", "comment", "for", "optimization"], "add_tokens": "// TODO: I believe this feature has impacted performance. Optimization? private RouteEntry findTargetWithGivenAcceptType ( List < RouteEntry > routeMatches , String acceptType ) { if ( acceptType != null && routeMatches . size ( ) > 0 ) { Map < String , RouteEntry > acceptedMimeTypes = getAcceptedMimeTypes ( routeMatches ) ; if ( routeMatches . size ( ) > 0 ) { return routeMatches . get ( 0 ) ;", "del_tokens": "private RouteEntry findTargetWithGivenAcceptType ( List < RouteEntry > routeMatchs , String acceptType ) { if ( acceptType != null && routeMatchs . size ( ) > 0 ) { Map < String , RouteEntry > acceptedMimeTypes = getAcceptedMimeTypes ( routeMatchs ) ; if ( routeMatchs . size ( ) > 0 ) { return routeMatchs . get ( 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "log", "settings", "for", "structured", "logging", "to", "standard", "out"], "add_tokens": "public static void start ( String serviceName , DvalinLifecycleAdapter lifecycleAdapter ) { lifecycleAdapter . setupLogging ( ) ; protected void setupLogging ( ) { Log4jLoggingConfigurer . setup ( ) ; }", "del_tokens": "public static void start ( String serviceName , DaemonLifecycleAdapter lifecycleAdapter ) { Log4jLoggingConfigurer . setup ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "TranslatedContentSpec", "entity", "and", "added", "reference", "to", "that", "entity", "in", "CSTranslatedNode"], "add_tokens": "import javax . persistence . JoinColumn ; import javax . persistence . ManyToOne ; import org . hibernate . validator . NotNull ; private Integer contentSpecTranslatedNodeId = null ; private TranslatedContentSpec translatedContentSpec = null ; private Integer contentSpecNodeId = null ; private Integer contentSpecNodeRevision = null ; @ NotNull @ NotNull @ JoinColumn ( name = \"TranslatedContentSpecID\" ) @ ManyToOne ( fetch = FetchType . LAZY ) @ Cache ( usage = CacheConcurrencyStrategy . TRANSACTIONAL ) public TranslatedContentSpec getTranslatedContentSpec ( ) { return translatedContentSpec ; } public void setTranslatedContentSpec ( TranslatedContentSpec translatedContentSpec ) { this . translatedContentSpec = translatedContentSpec ; }", "del_tokens": "private Integer contentSpecTranslatedNodeId ; private Integer contentSpecNodeId ; private Integer contentSpecNodeRevision ;", "commit_type": "add"}
{"commit_tokens": ["remove", "annotation", "@Column", "and", "@Table", "support"], "add_tokens": "", "del_tokens": "import org . crazycake . jdbcTemplateTool . model . Person ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private static Logger logger = LoggerFactory . getLogger ( JdbcTemplateToolTest . class ) ; @ Test public void testGet2 ( ) throws NoIdAnnotationFoundException , NoColumnAnnotationFoundException , IOException , SQLException { build ( ) ; JdbcTemplateTool jtt = super . applicationContext . getBean ( \"jdbcTemplateTool\" , JdbcTemplateTool . class ) ; List < Person > personList = jtt . list ( \"select * from person2\" , null , Person . class ) ; assertThat ( personList . size ( ) , is ( 1 ) ) ; logger . info ( personList . get ( 0 ) . getName ( ) ) ; Person e = jtt . get ( Person . class , 1 ) ; assertThat ( e . getName ( ) , is ( \"jackie\" ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Using", "the", "new", "ph", "-", "fonts", "-", "api"], "add_tokens": "new Version ( 2 , 0 , 0 , \"RC2\" ) ,", "del_tokens": "new Version ( 1 , 8 , 10 ) ,", "commit_type": "use"}
{"commit_tokens": ["Removed", "re", "-", "nesting", "of", "arbitrary", "exceptions", "into", "ServletExceptions", "."], "add_tokens": "import de . holisticon . util . tracee . Tracee ; import de . holisticon . util . tracee . TraceeBackend ; } else if ( e instanceof ServletException ) { throw ( ServletException ) e ; } else if ( e instanceof IOException ) { throw ( IOException ) e ;", "del_tokens": "import de . holisticon . util . tracee . * ; private TraceeLogger traceeLogger = null ; traceeLogger = traceeBackend . getLoggerFactory ( ) . getLogger ( TraceeErrorLoggingFilter . class ) ; } else { throw new ServletException ( e ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "local", "rmi", "port", "conflict", "bug"], "add_tokens": "import java . util . concurrent . atomic . AtomicInteger ; private static final AtomicInteger LOCAL_RMI_PORT = new AtomicInteger ( IUiDevice . UIAUTOMATOR_RMI_PORT + 10000 ) ; int port = this . setupRmiPortForward ( ) ; this . client = new Client ( \"localhost\" , port , callHandler ) ; private int setupRmiPortForward ( ) throws IOException , InterruptedException { int local = LOCAL_RMI_PORT . getAndIncrement ( ) ;", "del_tokens": "import java . util . Collections ; private final String ip = \"localhost\" ; private int port = IUiDevice . UIAUTOMATOR_RMI_PORT ; private static final Set < Integer > LOCAL_PORTS = Collections . synchronizedSet ( new HashSet < > ( ) ) ; this . port = this . setupRmiPortForward ( ) ; this . client = new Client ( this . ip , this . port , callHandler ) ; private synchronized int setupRmiPortForward ( ) throws IOException , InterruptedException { int local = IUiDevice . UIAUTOMATOR_RMI_PORT + 10000 ; while ( LOCAL_PORTS . contains ( local ) ) { local ++ ; } LOCAL_PORTS . add ( local ) ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "UPDATING", "state", "when", "starting", "Titan"], "add_tokens": "private static boolean isTableAcceptingWrites ( String status ) { return isTableStatus ( TableStatus . ACTIVE , status ) || isTableStatus ( TableStatus . UPDATING , status ) ; if ( ! isTableAcceptingWrites ( gDesc . getIndexStatus ( ) ) ) { successFlag = isTableAcceptingWrites ( td . getTableStatus ( ) ) && areAllGSIsActive ; if ( isTableAcceptingWrites ( desc . getTableStatus ( ) ) ) {", "del_tokens": "private static boolean isTableActive ( String status ) { return isTableStatus ( TableStatus . ACTIVE , status ) ; if ( ! TableStatus . ACTIVE . toString ( ) . equals ( gDesc . getIndexStatus ( ) ) ) { successFlag = td . getTableStatus ( ) . equals ( TableStatus . ACTIVE . toString ( ) ) && areAllGSIsActive ; if ( isTableActive ( desc . getTableStatus ( ) ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Added", "tests", "and", "fixed", "some", "issues"], "add_tokens": "import java . util . Collections ; import java . util . Comparator ; import java . util . HashMap ; import java . util . LinkedHashSet ; import java . util . List ; import java . util . Map ; import java . util . ResourceBundle ; import java . util . Set ; import java . util . TreeSet ; import static org . apache . commons . lang3 . StringUtils . defaultString ; import static org . apache . commons . lang3 . StringUtils . isBlank ; import static org . apache . commons . lang3 . StringUtils . isNotBlank ; Map < String , Property > allProperties = new HashMap < > ( ) ; return ImmutableMap . copyOf ( allProperties ) ;", "del_tokens": "import io . github . robwin . markup . builder . MarkupDocBuilders ; import java . util . * ; import static org . apache . commons . lang3 . StringUtils . * ; ImmutableMap . Builder < String , Property > allProperties = ImmutableMap . builder ( ) ; return allProperties . build ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "couple", "issues", "dealing", "with", "null", "streams", "or", "playengines"], "add_tokens": "log . error ( \"Error executing call: {}\" , call , accessEx ) ;", "del_tokens": "log . error ( \"Error executing call: {}\" , call ) ; log . error ( \"Service invocation error\" , accessEx ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "logging", "messages", "for", "HTTP", "Requests", "and", "revision", "insertion"], "add_tokens": "import org . apache . http . Header ; import java . util . logging . Level ; import java . util . logging . Logger ; private static Logger logger = Logger . getLogger ( HttpRequests . class . getCanonicalName ( ) ) ; //log the request logger . info ( request . toString ( ) ) ; logger . info ( response . getStatusLine ( ) . toString ( ) ) ; if ( logger . isLoggable ( Level . FINER ) ) { for ( Header h : response . getAllHeaders ( ) ) { logger . finer ( h . toString ( ) ) ; } } logger . log ( Level . SEVERE , \"Aborting request\" , e ) ;", "del_tokens": "import org . apache . http . HttpHost ; import org . apache . http . client . params . HttpClientParams ; import org . apache . http . params . BasicHttpParams ; import org . apache . http . params . HttpConnectionParams ;", "commit_type": "add"}
{"commit_tokens": ["allow", "externally", "defined", "rulings", "for", "extraction"], "add_tokens": "sb . append ( String . format ( \",text=%s]\" , this . getText ( ) == null ? \"null\" : \"\\\"\" + this . getText ( ) + \"\\\"\" ) ) ;", "del_tokens": "sb . append ( String . format ( \",text=\\\"%s\\\"]\" , this . getText ( ) ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["added", "color", "attribute", "inheritance", "for", "new", "created", "children", "of", "topic"], "add_tokens": "if ( ! parent . isRoot ( ) ) { AbstractElement . copyColorAttributes ( parent , newTopic ) ; } final Stroke dashed = new BasicStroke ( scaledSize , BasicStroke . CAP_ROUND , BasicStroke . JOIN_BEVEL , 0 , new float [ ] { scaledSize , scaledSize * 3.0f } , 0 ) ;", "del_tokens": "final Stroke dashed = new BasicStroke ( scaledSize , BasicStroke . CAP_ROUND , BasicStroke . JOIN_BEVEL , 0 , new float [ ] { scaledSize , scaledSize * 3.0f } , 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "readDocumentStructure", "which", "read", "detail", "structure", "of"], "add_tokens": "String id ( ) ; String title ( ) ; String role ( ) ; String style ( ) ; List < Block > blocks ( ) ; Object content ( ) ; String render ( ) ; String context ( ) ; List < String > lines ( ) ;", "del_tokens": "String context ( ) ; List < String > lines ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "implementation", "for", "Nanopub", "interface"], "add_tokens": "import java . util . Set ; import org . openrdf . model . impl . URIImpl ; public static final URI NANOPUB_TYPE_URI = new URIImpl ( \"http://www.nanopub.org/nschema#Nanopublication\" ) ; public static final URI HAS_ASSERTION_URI = new URIImpl ( \"http://www.nanopub.org/nschema#hasAssertion\" ) ; public static final URI HAS_PROVENANCE_URI = new URIImpl ( \"http://www.nanopub.org/nschema#hasProvenance\" ) ; public static final URI HAS_PUBINFO_URI = new URIImpl ( \"http://www.nanopub.org/nschema#hasPublicationInfo\" ) ; public URI getUri ( ) ; public Set < Statement > getHead ( ) ; public Set < Statement > getAssertion ( ) ; public Set < Statement > getProvenance ( ) ; public Set < Statement > getPubinfo ( ) ;", "del_tokens": "public static final String TYPE_URI = \"http://www.nanopub.org/nschema#Nanopublication\" ; public URI getURI ( ) ; public Iterable < Statement > getHeadStatements ( ) ; public Iterable < Statement > getAssertionStatements ( ) ; public Iterable < Statement > getProvenanceStatements ( ) ; public Iterable < Statement > getPubinfoStatements ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "all", "special", "characters", "except", "null"], "add_tokens": "public void should_support_special_characters_in_strings ( ) { Toml toml = new Toml ( ) . parse ( new File ( getClass ( ) . getResource ( \"should_support_special_characters_in_strings.toml\" ) . getFile ( ) ) ) ; assertEquals ( \"\\\" \\t \\n \\r \\\\\" , toml . getString ( \"key\" ) ) ; } @ Test ( expected = IllegalStateException . class ) public void should_fail_on_reserved_special_character_in_strings ( ) throws Exception { new Toml ( ) . parse ( \"key=\\\"\\\\m\\\"\" ) ; } @ Test public void should_ignore_comma_at_end_of_array ( ) throws Exception { Toml toml = new Toml ( ) . parse ( \"key=[1,2,3,]\" ) ; assertEquals ( asList ( 1L , 2L , 3L ) , toml . getList ( \"key\" , Long . class ) ) ;", "del_tokens": "public void should_support_double_quote_in_string ( ) { Toml toml = new Toml ( ) . parse ( \"key=\\\"double \\\\\\\" quote\\\"\" ) ; assertEquals ( \"double \\\" quote\" , toml . getString ( \"key\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "typo", "in", "ECKey", "JavaDocs", "."], "add_tokens": "* Represents an elliptic curve keypair that we own and can use for signing transactions . Currently ,", "del_tokens": "* Represents either an elliptic curve keypair that we own and can use for signing transactions . Currently ,", "commit_type": "fix"}
{"commit_tokens": ["Using", "Locale", ".", "ROOT", "for", "locale", "-", "neutral", "comparisons", "and", "conversions", "."], "add_tokens": "String lowerPath = ( questionPos == - 1 ? url : url . substring ( 0 , questionPos ) ) . toLowerCase ( Locale . ROOT ) ; language = language . toLowerCase ( Locale . ROOT ) ; country = country . toUpperCase ( Locale . ROOT ) ;", "del_tokens": "String lowerPath = ( questionPos == - 1 ? url : url . substring ( 0 , questionPos ) ) . toLowerCase ( Locale . ENGLISH ) ; language = language . toLowerCase ( Locale . ENGLISH ) ; country = country . toUpperCase ( Locale . ENGLISH ) ;", "commit_type": "use"}
{"commit_tokens": ["created", "better", "error", "report", "for", "synchronous", "methods"], "add_tokens": "private ErrorCode errorCode ; public GuildWars2Exception ( ErrorCode errorCode , String message ) { super ( message ) ; this . errorCode = errorCode ; } / * * * Meaning for different error code : < br / > * APIServer : API server not found < br / > * APIKey : Invalid API key < br / > * ID : Invalid ID < br / > * TransTime : Invalid transaction time < br / > * TransType : Invalid transaction type < br / > * Network : Network error < br / > * Other : Other * @ return error code * / public ErrorCode getErrorCode ( ) { return errorCode ; }", "del_tokens": "public GuildWars2Exception ( String message ) { super ( message ) ; }", "commit_type": "create"}
{"commit_tokens": ["Move", "descriptor", "from", "being", "an", "inner", "class", "to", "an", "outer", "class", "."], "add_tokens": "import hudson . plugins . emailext . ExtendedEmailPublisherDescriptor ; Field f = ExtendedEmailPublisherDescriptor . class . getDeclaredField ( \"defaultBody\" ) ; f = ExtendedEmailPublisherDescriptor . class . getDeclaredField ( \"defaultSubject\" ) ;", "del_tokens": "Field f = ExtendedEmailPublisher . DescriptorImpl . class . getDeclaredField ( \"defaultBody\" ) ; f = ExtendedEmailPublisher . DescriptorImpl . class . getDeclaredField ( \"defaultSubject\" ) ;", "commit_type": "move"}
{"commit_tokens": ["Add", "a", "exception", "of", "image", "query", "append"], "add_tokens": "public static String SDK_VERSION = \"2.3.4\" ;", "del_tokens": "public static String SDK_VERSION = \"2.3.3\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "uploadsearch", "with", "detection"], "add_tokens": "private String detection ; public UploadSearchParams setDetection ( String detection ) { this . detection = detection ; return this ; } public String getDetection ( String detection ) { return detection ; } if ( detection != null ) { map . put ( \"detection\" , detection ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "test", "case", "about", "the", "+", "=", "operator"], "add_tokens": "public void plusEqualsMutation ( ) throws Exception { long l = 1L ; int i = 1 ; Long lL = Long . valueOf ( \"1\" ) ; Integer iI = Integer . valueOf ( \"1\" ) ; i = ( int ) ( i + l ) ; i += l ; iI = ( int ) ( iI + lL ) ; assertThat ( TestHelper . getLastRecordedStateForVariable ( \"iI\" ) , equalTo ( Integer . toString ( iI ) ) ) ; i = ( int ) ( i + lL ) ; i += lL ; assertThat ( TestHelper . getLastRecordedStateForVariable ( \"i\" ) , equalTo ( Integer . toString ( i ) ) ) ; iI = ( int ) ( iI + l ) ; assertThat ( TestHelper . getLastRecordedStateForVariable ( \"iI\" ) , equalTo ( Integer . toString ( iI ) ) ) ;", "del_tokens": "public void simpleMutationInc ( ) throws Exception { int i = 0 ; i ++ ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "most", "methods", "of", "ConcurrentNavigableMap", "."], "add_tokens": "import static org . junit . Assume . assumeTrue ; NavigableMap < Integer , String > map = DBMaker . newTempTreeMap ( ) ; if ( 1 == 1 ) return ; //TODO desc if ( 1 == 1 ) return ; //TODO desc", "del_tokens": "import org . mapdb . DBMaker ; static NavigableMap < Integer , String > map ; map = DBMaker . newMemoryDB ( ) . make ( ) . getTreeMap ( \"test\" ) ; @ Ignore", "commit_type": "implement"}
{"commit_tokens": ["Moved", "new", "Models", "project", "into", "new", "module", ".", "Fixed", "some", "readmes", "and", "texts", "."], "add_tokens": "getDriver ( ) . get ( \"http://mrjamesbrown.github.com/webdriverextension/index.html\" ) ;", "del_tokens": "getDriver ( ) . get ( \"http://mrjamesbrown.github.com/webdriver-extension/index.html\" ) ;", "commit_type": "move"}
{"commit_tokens": ["creating", "body", "validation", "(", "same", "text", ")", "on", "the", "back", "-", "end", "."], "add_tokens": "VALIDATE_IF_PRESENT_ONLY , RAW_TEXT", "del_tokens": "TEXT", "commit_type": "create"}
{"commit_tokens": ["Fix", "race", "condition", "in", "Candidate", "election"], "add_tokens": "long timeout = electionTimeout + ( RAND . nextLong ( ) % electionTimeout ) ; electionTimer = scheduler . schedule ( new Runnable ( ) { @ Override public void run ( ) { LOGGER . debug ( \"Election timeout\" ) ; transition ( ctx , CANDIDATE ) ; } } , timeout , MILLISECONDS ) ;", "del_tokens": "long timeout = electionTimeout + ( RAND . nextLong ( ) % electionTimeout ) ; electionTimer = scheduler . schedule ( new Runnable ( ) { @ Override public void run ( ) { LOGGER . debug ( \"Election timeout\" ) ; transition ( ctx , CANDIDATE ) ; } } , timeout , MILLISECONDS ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "performance", "of", "constrained", "array", "generation"], "add_tokens": "T [ ] templateArray = CollectionFactory . createArray ( typeToken , list . size ( ) ) ; //TODO rethink putting this into the Fixture class", "del_tokens": "T [ ] templateArray = manyAsArrayOf ( typeToken ) ;", "commit_type": "improve"}
{"commit_tokens": ["added", "direct", "getters", "to", "swap", "move"], "add_tokens": "/ * * * Returns the added ID . * * @ return added ID * / public int getAddedID ( ) { return add ; } / * * * Returns the deleted ID . * * @ return deleted ID * / public int getDeletedID ( ) { return delete ; }", "del_tokens": "import java . util . HashSet ;", "commit_type": "add"}
{"commit_tokens": ["Added", "comment", "on", "usage", "of", "servletContext"], "add_tokens": "if ( s_sServletContextPath != null && ! s_sServletContextPath . equals ( sServletContextPath ) ) if ( s_sCustomContextPath != null && ! s_sCustomContextPath . equals ( sCustomContextPath ) )", "del_tokens": "if ( s_sServletContextPath != null ) if ( s_sCustomContextPath != null )", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "compound", "indexes", "via", "datastore"], "add_tokens": "import java . util . Set ; import com . google . code . morphia . utils . IndexFieldDef ; < T > void ensureIndex ( Class < T > clazz , String field , IndexDirection dir ) ; /** Ensures (creating if necessary) the index and direction */ < T > void ensureIndex ( Class < T > clazz , Set < IndexFieldDef > fields ) ; < T > void ensureIndex ( Class < T > clazz , String name , Set < IndexFieldDef > fields , boolean unique , boolean dropDupsOnCreate ) ;", "del_tokens": "< T > void ensureIndex ( Class < T > clazz , String name , IndexDirection dir ) ; < T > void ensureIndex ( T entity , String name , IndexDirection dir ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "annotation", "properties", "to", "the", "OwlConverter"], "add_tokens": "import org . semanticweb . elk . owl . interfaces . ElkAnnotationProperty ; public ElkAnnotationProperty visit ( OWLAnnotationProperty owlAnnotationproperty ) { return CONVERTER . convert ( owlAnnotationproperty ) ;", "del_tokens": "public ElkEntity visit ( OWLAnnotationProperty property ) { throw new IllegalArgumentException ( OWLAnnotationProperty . class . getSimpleName ( ) + \" cannot be converted to \" + ElkEntity . class . getSimpleName ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["adds", "the", "isonline", "check", "to", "pulse", "too"], "add_tokens": "} else {", "del_tokens": "} else if ( hasInternetConnection ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["Remove", "these", "redundant", "variables", "(", "and", "possibly", "break", "backward", "compatibility", ")"], "add_tokens": "* Base { @ link InstantiatorStrategy } class basically . Only implements { @ link InstantiatorStrategy }", "del_tokens": "* Base { @ link InstantiatorStrategy } class basically containing helpful constant to sort out JVMs . /** JVM_NAME prefix for JRockit */ protected static final String JROCKIT = PlatformDescription . JROCKIT ; /** JVM_NAME prefix for GCJ */ protected static final String GNU = PlatformDescription . GNU ; /** JVM_NAME prefix for Sun Java HotSpot */ protected static final String SUN = PlatformDescription . SUN ; /** JVM_NAME prefix for Aonix PERC */ protected static final String PERC = PlatformDescription . PERC ; /** JVM_NAME prefix for Dalvik/Android */ protected static final String DALVIK = PlatformDescription . DALVIK ; /** JVM version */ protected static final String VM_VERSION = PlatformDescription . VM_VERSION ; /** JVM version */ protected static final String VM_INFO = PlatformDescription . VM_INFO ; /** Vendor version */ protected static final String VENDOR_VERSION = PlatformDescription . VENDOR_VERSION ; /** Vendor name */ protected static final String VENDOR = PlatformDescription . VENDOR ; /** JVM name */ protected static final String JVM_NAME = PlatformDescription . JVM_NAME ; /** Android API level */ protected static final int ANDROID_VERSION = PlatformDescription . ANDROID_VERSION ;", "commit_type": "remove"}
{"commit_tokens": ["removed", "absolute", "path", "s", "from", "expection", "test"], "add_tokens": "String expectedHtml = readFile ( exceptionHtml ) ; String html = e . toHtmlString ( ) ; assertEquals ( removeAbsolutePath ( expectedHtml ) , removeAbsolutePath ( html ) ) ; private String removeAbsolutePath ( String html ) { html = html . replaceAll ( \"(<h2>In ).*(compiler/exceptions/error\\\\.jade at line 9\\\\.</h2>)\" , \"$1\\\\.\\\\./$2\" ) ; return html ; }", "del_tokens": "assertEquals ( readFile ( exceptionHtml ) , e . toHtmlString ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "recycler", "TypedArray", "issue", "in", "TextView"], "add_tokens": "a . recycle ( ) ;", "del_tokens": "a . recycle ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "other", "missing", "@parameter", "expressions", "related", "to", "MBUILDNUM", "-", "112"], "add_tokens": "* @ parameter expression = \"${maven.buildNumber.format}\" * @ parameter expression = \"${maven.buildNumber.timestampFormat}\" * @ parameter expression = \"${maven.buildNumber.revisionOnScmFailure}\"", "del_tokens": "* @ parameter * @ parameter * @ parameter", "commit_type": "add"}
{"commit_tokens": ["Added", "runes", "and", "masteries", "to", "participant"], "add_tokens": "private long id ; private long ranks ;", "del_tokens": "private int id ; private int ranks ;", "commit_type": "add"}
{"commit_tokens": ["fix", "bug", "instantiating", "unreachable", "calendar", "object"], "add_tokens": "cal = Calendar . getInstance ( ) ;", "del_tokens": "Calendar cal = Calendar . getInstance ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["moving", "ToCollection", "to", "fn2", "where", "it", "should", "have", "been", "in", "the", "first", "place"], "add_tokens": "package com . jnape . palatable . lambda . functions . builtin . fn2 ;", "del_tokens": "package com . jnape . palatable . lambda . functions . builtin . fn1 ;", "commit_type": "move"}
{"commit_tokens": ["Move", "tests", "things", "to", "tools", "module", "."], "add_tokens": "package net . morimekta . providence . tools . speedtest ; // read write total public enum Format { // prov thrift - prov thrift = prov thrift json_pretty ( \"json\" ) , // 8.45 - 4.04 = 12.45 json_named ( \"json\" ) , // 5.52 - 3.75 = 9.27 json ( \"json\" ) , // 5.14 - 2.65 = 7.79 json_protocol ( \"json\" ) , // 6.31 6.10 - 3.95 3.77 = 10.25 9.87 binary ( \"bin\" ) , // 0.95 - 1.42 = 2.37 // fast_binary(\"bin\"), // 1.07 - 0.98 = 2.05 -- disc. // proto --- BUGGY! compact_protocol ( \"bin\" ) , // 1.33 1.22 - 1.89 0.85 = 3.23 2.07 binary_protocol ( \"bin\" ) , // 1.20 0.80 - 0.87 1.20 = 2.06 2.00 tuple_protocol ( \"tuples\" ) , // 1.23 1.02 - 0.75 0.73 = 1.99 1.75 // case fast_binary: // serializer = new PFastBinarySerializer(); // break; // case proto: // serializer = new PProtoSerializer(); // break;", "del_tokens": "package net . morimekta . speedtest ; // read write public enum Format { // prov thrift - prov thrift json_pretty ( \"json\" ) , // 13.65 - json_named ( \"json\" ) , // 12.41 - json ( \"json\" ) , // 11.52 - json_protocol ( \"json\" ) , // 8.86 10.86 - binary ( \"bin\" ) , // 2.37 - compact_protocol ( \"bin\" ) , // 2.44 2.71 - binary_protocol ( \"bin\" ) , // 2.05 2.43 - tuple_protocol ( \"tuples\" ) , // 2.04 1.97 -", "commit_type": "move"}
{"commit_tokens": ["fixed", "colummns", "not", "being", "deleted", "after", "a", "test"], "add_tokens": "import static pl . project13 . janbanery . test . TestConstants . COLUMN_NAME ; return new Column . Builder ( COLUMN_NAME ) . build ( ) ; List < Column > columns = janbanery . columns ( ) . byName ( COLUMN_NAME ) ;", "del_tokens": "return new Column . Builder ( TestConstants . COLUMN_NAME ) . build ( ) ; List < Column > columns = janbanery . columns ( ) . byName ( TASK_TITLE ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "app", "linking", "examples", "to", "the", "sample", "app"], "add_tokens": "import android . content . ContentResolver ; . setAppLinkIntent ( mContext . getPackageManager ( ) . getLaunchIntentForPackage ( \"com.google.android.music\" ) ) // .setAppLinkIcon(ContentResolver.SCHEME_ANDROID_RESOURCE + \"://\" + \"com.felkertech.sample.channelsurfer\" +\"/drawable/md_library_music\") . setAppLinkText ( \"Open YouTube\" ) . setAppLinkIntent ( mContext . getPackageManager ( ) . getLaunchIntentForPackage ( \"com.google.android.youtube.tv\" ) ) // .setAppLinkIcon(ContentResolver.SCHEME_ANDROID_RESOURCE + \"://\" + \"com.felkertech.sample.channelsurfer\" + \"/\"+R.drawable.md_movies) . setAppLinkIntent ( mContext . getPackageManager ( ) . getLaunchIntentForPackage ( \"com.google.android.youtube.tv\" ) ) // .setAppLinkIcon(ContentResolver.SCHEME_ANDROID_RESOURCE + \"://\" + \"com.felkertech.sample.channelsurfer\" +\"/drawable/md_library_music\") . setAppLinkIntent ( new Intent ( Intent . ACTION_SEARCH ) ) . setAppLinkText ( \"Get Cumulus TV\" ) . setAppLinkIntent ( new Intent ( Intent . ACTION_VIEW , Uri . parse ( \"https://play.google.com/store/apps/details?id=com.felkertech.n.cumulustv\" ) ) )", "del_tokens": ". setAppLinkIntent ( new Intent ( \"com.google.android.music\" ) ) . setAppLinkIcon ( \"android.resource://com.felkertech.sample.channelsurfer/drawable/md_library_music\" ) . setAppLinkText ( \"Open Netflix\" ) . setAppLinkIntent ( new Intent ( \"com.netflix.ninja\" ) ) . setAppLinkIcon ( \"android.resource://com.felkertech.sample.channelsurfer/drawable/md_movies\" ) . setAppLinkText ( \"Hi\" )", "commit_type": "add"}
{"commit_tokens": ["Added", "marshaller", "for", "VJOURNAL", "."], "add_tokens": "addMarshaller ( new VJournalMarshaller ( ) ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "keyPressed", "()", "keyReleased", "()", "keyTyped", "()", "patterns", "."], "add_tokens": "static EventPattern < Event , KeyEvent > keyPressed ( ) { return eventTypePattern ( KeyEvent . KEY_PRESSED ) ; } return keyPressed ( ) . and ( combination :: match ) ; static EventPattern < Event , KeyEvent > keyReleased ( ) { return eventTypePattern ( KEY_RELEASED ) ; } return keyReleased ( ) . and ( combination :: match ) ; static EventPattern < Event , KeyEvent > keyTyped ( ) { return eventTypePattern ( KEY_TYPED ) ; } return keyTyped ( ) . and ( combination :: match ) ;", "del_tokens": "return eventTypePattern ( KeyEvent . KEY_PRESSED ) . and ( combination :: match ) ; return eventTypePattern ( KEY_RELEASED ) . and ( combination :: match ) ; return eventTypePattern ( KEY_TYPED ) . and ( combination :: match ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "checks", "for", "nulls", "."], "add_tokens": "BMSClient . getInstance ( ) . initialize ( getApplicationContext ( ) , \"http://9.148.225.198:9080\" , \"vit1\" ) ; ResourceRequest r = new ResourceRequest ( this , \"http://9.148.225.198:3000/v1/apps/vit1/service\" , MFPRequest . GET ) ;", "del_tokens": "BMSClient . getInstance ( ) . initialize ( getApplicationContext ( ) , \"http://9.148.225.106:9080\" , \"vit1\" ) ; ResourceRequest r = new ResourceRequest ( this , \"http://9.148.225.106:3000/v1/apps/vit1/service\" , MFPRequest . GET ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "methods", "to", "retrieve", "query", "parameters", "."], "add_tokens": "@ Override public String getUrl ( ) { return request . getRequestURL ( ) . toString ( ) ; } public String getQueryParam ( String name ) { return request . getParameter ( name ) ; } @ SuppressWarnings ( \"unchecked\" ) @ Override public < T > T getQueryParam ( String name , Class < T > clazz ) throws ClassCastException { return ( T ) request . getParameter ( name ) ;", "del_tokens": "public String getUrl ( ) { return request . getRequestURL ( ) . toString ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "missing", "String", ".", "format"], "add_tokens": "logger . warn ( String . format ( \"Cannot do global CPR due to bad format (icao24: %s).\\n\" , tools . toHexString ( msg . getIcao24 ( ) ) ) ) ; logger . debug ( String . format ( \"Position staddle (icao24: %s).\\n\" , tools . toHexString ( msg . getIcao24 ( ) ) ) ) ; logger . debug ( String . format ( \"Missing information (global, icao24: %s).\\n\" , tools . toHexString ( msg . getIcao24 ( ) ) ) ) ;", "del_tokens": "logger . warn ( \"Cannot do global CPR due to bad format (icao24: %s).\\n\" , tools . toHexString ( msg . getIcao24 ( ) ) ) ; logger . debug ( \"Position staddle (icao24: %s).\\n\" , tools . toHexString ( msg . getIcao24 ( ) ) ) ; logger . debug ( \"Missing information (global, icao24: %s).\\n\" , tools . toHexString ( msg . getIcao24 ( ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "sure", "to", "deploy", "the", "websocket", "verticle", "by", "default", "as", "well", "."], "add_tokens": "vertx . deployVerticle ( \"java:\" + WebSocketVerticle . class . getName ( ) , webSocketCallback -> { vertx . deployVerticle ( \"java:\" + TcpMessageVerticle . class . getName ( ) , tcpMessageCallback -> observeStream ( Riemann . getEvents ( vertx ) ) ) ; } ) ;", "del_tokens": "vertx . deployVerticle ( \"java:reactmann.TcpMessageVerticle\" , event -> observeStream ( Riemann . getEvents ( vertx ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "exception", "for", "firebird", "driver"], "add_tokens": "if ( state . equals ( \"40001\" ) || state . equals ( \"HY000\" ) || state . startsWith ( \"08\" ) || ( firstChar >= '5' && firstChar <= '9' ) || ( firstChar >= 'I' && firstChar <= 'Z' ) ) {", "del_tokens": "if ( state . equals ( \"40001\" ) || state . startsWith ( \"08\" ) || ( firstChar >= '5' && firstChar <= '9' ) || ( firstChar >= 'I' && firstChar <= 'Z' ) ) {", "commit_type": "add"}
{"commit_tokens": ["Fixing", "issue", "with", "IE8", "and", "leading", "spaces", "in", "content", "types"], "add_tokens": "return aContentType . trim ( ) . replaceAll ( quote ( ASTERISK ) , PERIOD_PLUS_ASTERISK ) ;", "del_tokens": "return aContentType . replaceAll ( quote ( ASTERISK ) , PERIOD_PLUS_ASTERISK ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "longer", "timeout", "and", "add", "a", "tl", ";", "dr", "check"], "add_tokens": "connection . timeout ( 5000 ) ; } catch ( SocketTimeoutException e ) { System . err . println ( \"Grouphug request timed out. Waiting before retrying\" ) ; return ; } catch ( IOException e ) { /* tl;dr check */ if ( blurb . length ( ) < 800 ) { this . confessions . add ( blurb ) ; }", "del_tokens": "} catch ( IOException e ) { this . confessions . add ( blurb ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "bitfield", "message", "length", "calculation"], "add_tokens": "byte [ ] bitfield = new byte [ ( int ) Math . ceil ( ( double ) availablePieces . length ( ) / 8 ) ] ;", "del_tokens": "byte [ ] bitfield = new byte [ availablePieces . length ( ) / 8 + 1 ] ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "using", "winrm", "with", "windows", "guest", "vagrant", "boxes"], "add_tokens": "logger . info ( \"Waiting for the VM to become accessible...\" ) ;", "del_tokens": "logger . info ( \"Waiting for the VM to become accessible via SSH\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "characters", "instead", "of", "strings", "when", "length", "is", "1"], "add_tokens": "return authorization ( \"Basic \" + Base64 . encode ( name + ':' + password ) ) ; final String separator = \"; \" + PARAM_CHARSET + '=' ;", "del_tokens": "return authorization ( \"Basic \" + Base64 . encode ( name + \":\" + password ) ) ; final String separator = \"; \" + PARAM_CHARSET + \"=\" ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "logger", "usage", "of", "normalizationmanager"], "add_tokens": "Logger . printError ( component , \"Adding normalization resource: \" + resource ) ; Logger . printError ( \"[\" + component + \"] Cannot read one of the lines of normalization resource \" + resource ) ; Logger . printError ( \"[\" + component + \"] Line: \" + line ) ;", "del_tokens": "System . err . println ( \"[\" + component + \"] Adding normalization resource: \" + resource ) ; System . err . println ( \"[\" + component + \"] Cannot read one of the lines of normalization resource \" + resource ) ; System . err . println ( \"[\" + component + \"] Line: \" + line ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "{", "@code", "...", "}", "in", "javadoc", "to", "get", "generics", "included", "in", "the", "output", "."], "add_tokens": "* public { @ code < T > Task < T > cloneTask ( Task < T > } task ) {", "del_tokens": "* public < T > Task < T > cloneTask ( Task < T > task ) {", "commit_type": "use"}
{"commit_tokens": ["Implemented", "support", "for", "collections", "of", "DBRefs", "stored", "as", "@ObjectIds"], "add_tokens": "return findObjectIdDeserializer ( type . containedType ( 0 ) ) ; return findObjectIdDeserializer ( type . containedType ( 1 ) ) ; public Class findObjectIdDeserializer ( JavaType type ) { return DBRefDeserializer . class ;", "del_tokens": "import org . codehaus . jackson . map . JsonDeserializer ; import org . codehaus . jackson . map . type . TypeBindings ; import java . lang . reflect . GenericArrayType ; import java . lang . reflect . ParameterizedType ; import java . lang . reflect . Type ; return ( Class ) findObjectIdDeserializer ( type . containedType ( 0 ) ) ; return ( Class ) findObjectIdDeserializer ( type . containedType ( 1 ) ) ; private Object findObjectIdDeserializer ( JavaType type ) { Class < ? extends JsonDeserializer > keyTypeDeserializer = ( Class ) findObjectIdDeserializer ( type . containedType ( 1 ) ) ; if ( keyTypeDeserializer != null ) { JsonDeserializer keyDeserializer ; try { keyDeserializer = ( JsonDeserializer ) keyTypeDeserializer . newInstance ( ) ; } catch ( InstantiationException e ) { // We know this won't fail throw new RuntimeException ( e ) ; } catch ( IllegalAccessException e ) { // We know this won't fail throw new RuntimeException ( e ) ; } return new DBRefDeserializer ( type . containedType ( 0 ) , type . containedType ( 1 ) , keyDeserializer ) ; }", "commit_type": "implement"}
{"commit_tokens": ["Remove", "custom", "event", "class", "support"], "add_tokens": "import com . opentable . logging . otl . OtlType ; final ObjectNode logLine = mapper . valueToTree ( event instanceof OtlType ? event : new ApplicationLogEvent ( event ) ) ;", "del_tokens": "import com . fasterxml . jackson . databind . util . TokenBuffer ; private Class < ? > customEventClass = HttpLogFields . class ; public void setCustomEventClass ( String customEventClass ) throws ClassNotFoundException { this . customEventClass = Class . forName ( customEventClass ) ; } final ObjectNode logLine ; if ( customEventClass != null && customEventClass . isAssignableFrom ( event . getClass ( ) ) ) { final TokenBuffer buf = new TokenBuffer ( mapper , false ) ; try { mapper . writerFor ( customEventClass ) . writeValue ( buf , event ) ; logLine = mapper . readTree ( buf . asParser ( ) ) ; } catch ( IOException e ) { addError ( \"Failed to convert log event to json\" , e ) ; return null ; } } else { logLine = mapper . valueToTree ( new ApplicationLogEvent ( event ) ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Changed", "name", "of", "essential", "method", "from", "uploadFile", "to", "simply", "upload", "."], "add_tokens": "* { @ link HttpsFileUploader # upload ( com . addicticks . net . httpsupload . HttpsFileUploaderConfig , java . util . Map , java . util . Map , com . addicticks . net . httpsupload . FileUploadProgress ) uploadFiles map } .", "del_tokens": "* { @ link HttpsFileUploader # uploadFile ( com . addicticks . net . httpsupload . HttpsFileUploaderConfig , java . util . Map , java . util . Map , com . addicticks . net . httpsupload . FileUploadProgress ) uploadFiles map } .", "commit_type": "change"}
{"commit_tokens": ["Using", "a", "default", "test", "name", "if", "a", "macro", "substitution", "results", "to", "an", "empty", "name", "."], "add_tokens": "String builtName = buildNameByTemplate ( template , parametersIndex , parameters ) ; if ( builtName . trim ( ) . isEmpty ( ) ) { return buildNameByTemplate ( DEFAULT_TEMPLATE , parametersIndex , parameters ) ; } else { return builtName ; } if ( testCaseName != null ) {", "del_tokens": "return buildNameByTemplate ( template , parametersIndex , parameters ) ; if ( testCaseName != null && ! testCaseName . value ( ) . trim ( ) . isEmpty ( ) ) {", "commit_type": "use"}
{"commit_tokens": ["Update", "to", "latest", "version", "of", "PAV", "namespace"], "add_tokens": "// TODO Also support PROV-O // TODO Recognize different ontology versions public static final URI HAS_AUTHOR = new URIImpl ( \"http://purl.org/pav/authoredBy\" ) ; public static final URI HAS_CREATOR = new URIImpl ( \"http://purl.org/pav/createdBy\" ) ;", "del_tokens": "public static final URI HAS_AUTHOR = new URIImpl ( \"http://swan.mindinformatics.org/ontologies/1.2/pav/authoredBy\" ) ; public static final URI HAS_CREATOR = new URIImpl ( \"http://swan.mindinformatics.org/ontologies/1.2/pav/createdBy\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "for", "https", ":", "//", "github", ".", "com", "/", "Netflix", "/", "astyanax", "/", "issues", "/", "103"], "add_tokens": "@ Test public void testMutationBatchMultipleWithRow ( ) throws Exception { MutationBatch mb = keyspace . prepareMutationBatch ( ) ; Long key = 9L ; mb . withRow ( CF_USERS , key ) . delete ( ) ; mb . withRow ( CF_USERS , key ) . putEmptyColumn ( \"test\" , null ) ; mb . execute ( ) ; ColumnList < String > result = keyspace . prepareQuery ( CF_USERS ) . getRow ( key ) . execute ( ) . getResult ( ) ; Assert . assertEquals ( 1 , result . size ( ) ) ; } Assert . assertEquals ( 30 , result . getResult ( ) . getRows ( ) . size ( ) ) ;", "del_tokens": "Assert . assertEquals ( 28 , result . getResult ( ) . getRows ( ) . size ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "default", "background", "color", "for", "transparent", "indexed", "images", "."], "add_tokens": "import java . awt . image . IndexColorModel ; final Paint mCheckeredBG ; final Color mDefaultBG ; public ImageLabel ( final BufferedImage pImage ) { mCheckeredBG = createTexture ( ) ; // For indexed color, default to the color of the transparent pixel, if any mDefaultBG = getDefaultBackground ( pImage ) ; mBackground = mDefaultBG != null ? mDefaultBG : mCheckeredBG ; addCheckBoxItem ( new ChangeBackgroundAction ( \"Checkered\" , mCheckeredBG ) , popup , group ) ; addCheckBoxItem ( new ChooseBackgroundAction ( \"Choose...\" , mDefaultBG != null ? mDefaultBG : Color . BLUE ) , popup , group ) ; private static Color getDefaultBackground ( BufferedImage pImage ) { if ( pImage . getColorModel ( ) instanceof IndexColorModel ) { IndexColorModel cm = ( IndexColorModel ) pImage . getColorModel ( ) ; int transparent = cm . getTransparentPixel ( ) ; if ( transparent >= 0 ) { return new Color ( cm . getRGB ( transparent ) , false ) ; } } return null ; } private static Paint createTexture ( ) {", "del_tokens": "public ImageLabel ( BufferedImage pImage ) { mBackground = createTexture ( ) ; addCheckBoxItem ( new ChangeBackgroundAction ( \"Default\" , mBackground ) , popup , group ) ; addCheckBoxItem ( new ChooseBackgroundAction ( \"Choose...\" , Color . BLUE ) , popup , group ) ; private Paint createTexture ( ) {", "commit_type": "add"}
{"commit_tokens": ["allow", "to", "customize", "the", "typ", "header", "claim"], "add_tokens": "if ( ! headerClaims . containsKey ( PublicClaims . TYPE ) ) { headerClaims . put ( PublicClaims . TYPE , \"JWT\" ) ; }", "del_tokens": "headerClaims . put ( PublicClaims . TYPE , \"JWT\" ) ;", "commit_type": "allow"}
{"commit_tokens": ["Implement", "PUT", "/", "api", "/", "vhosts", "/", "{", "name", "}"], "add_tokens": "import com . fasterxml . jackson . core . JsonProcessingException ; import org . apache . http . HttpHeaders ; import org . apache . http . message . BasicHeader ; public void createVhost ( String name ) throws JsonProcessingException { final URI uri = uriWithPath ( \"./vhosts/\" + encodePathSegment ( name ) ) ; this . rt . put ( uri , null ) ; } public void deleteVhost ( String name ) { final URI uri = uriWithPath ( \"./vhosts/\" + encodePathSegment ( name ) ) ; this . rt . delete ( uri ) ; } final HttpClientBuilder bldr = HttpClientBuilder . create ( ) . setDefaultCredentialsProvider ( getCredentialsProvider ( url , username , password ) ) ; bldr . setDefaultHeaders ( Arrays . asList ( new BasicHeader ( HttpHeaders . CONTENT_TYPE , \"application/json\" ) ) ) ; HttpClient httpClient = bldr . build ( ) ;", "del_tokens": "HttpClient httpClient = HttpClientBuilder . create ( ) . setDefaultCredentialsProvider ( getCredentialsProvider ( url , username , password ) ) . build ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["Adding", "brikar", "-", "maintenance", "and", "first", "stab", "at", "testing", "gossip", "server", "(", "and", "consequently", "originating", "request", "ID", "propagation", ")"], "add_tokens": "launch ( \"classpath:/gossipService/\" ) ; } public static void launch ( String configPath ) throws Exception { try ( final StandardLauncher launcher = new StandardLauncher ( configPath ) ) { launcher . start ( ) ; }", "del_tokens": "new StandardLauncher ( \"classpath:/gossipService/\" ) . start ( ) . close ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adding", "AppendContext", "(", "part", "2", ")"], "add_tokens": "* Gets the Append Context for the last received append . This includes all appends made with the given client id , * regardless of whether they were committed or are still in flight . If the last append for this StreamSegment / ClientId * @ param clientId A UUID representing the Client Id to inquire about . CompletableFuture < AppendContext > getLastAppendContext ( String streamSegmentName , UUID clientId , Duration timeout ) ;", "del_tokens": "* Gets the Append Context for the last received append . This includes all appends made with the given connection id , * regardless of whether they were committed or are still in flight . If the last append for this StreamSegment / ConnectionId * @ param connectionId A UUID representing the Connection Id to inquire about . CompletableFuture < AppendContext > getAppendContext ( String streamSegmentName , UUID connectionId , Duration timeout ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "interface", "for", "fluent", "content"], "add_tokens": "import fr . sii . ogham . core . message . capability . HasContentFluent ; public class Email implements Message , HasContentFluent < Email > , HasSubject , HasSubjectFluent < Email > , HasRecipients < Recipient > , HasRecipientsFluent < Email , Recipient > , HasToFluent < Email > {", "del_tokens": "public class Email implements Message , HasSubject , HasSubjectFluent < Email > , HasRecipients < Recipient > , HasRecipientsFluent < Email , Recipient > , HasToFluent < Email > {", "commit_type": "add"}
{"commit_tokens": ["Improve", "docs", "send", "profile", "as", "file"], "add_tokens": "builder . addPart ( \"profileName\" , new MemoryFileBody ( \"profileName.txt\" , profileName , ContentType . TEXT_PLAIN ) ) ;", "del_tokens": "builder . addPart ( \"profileName\" , new StringBody ( profileName , ContentType . TEXT_PLAIN ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["updated", "onPermissionDeclined", "()", "to", "only", "return", "declined", "permission", "from", "the", "permissions", "list", "provided", "."], "add_tokens": "String [ ] declinedPermissions = declinedPermissions ( context , permissions ) ; requestAfterExplanation ( declinedPermissions ) ; permissionCallback . onPermissionDeclined ( declinedPermissions ) ; * < p > * < p >", "del_tokens": "requestAfterExplanation ( declinedPermissions ( context , permissions ) ) ; permissionCallback . onPermissionDeclined ( permissions ) ; * < p / > * < p / >", "commit_type": "update"}
{"commit_tokens": ["Fixing", "https", ":", "//", "bugzilla", ".", "redhat", ".", "com", "/", "show_bug", ".", "cgi?id", "=", "1090748#c26"], "add_tokens": "public static < E > List < Integer > getEditedEntitiesByRevision ( final EntityManager entityManager , final Class < E > type , final String pkColumnName ,", "del_tokens": "public static < E > List < Integer > getEditedEntities ( final EntityManager entityManager , final Class < E > type , final String pkColumnName ,", "commit_type": "fix"}
{"commit_tokens": ["Using", "new", "self", "-", "validating", "Path", "class", "for", "book", "names", "and", "paths", "."], "add_tokens": "import com . semanticcms . core . pages . CaptureLevel ; import com . semanticcms . core . servlet . Book ;", "del_tokens": "import com . semanticcms . core . pages . Book ; import com . semanticcms . core . servlet . CaptureLevel ;", "commit_type": "use"}
{"commit_tokens": ["Make", "linter", "happy", "in", "HapticFeedbackController"], "add_tokens": "* @ return true if Vibrate permission has been granted", "del_tokens": "import java . util . jar . Manifest ; * @ return", "commit_type": "make"}
{"commit_tokens": ["added", "better", "message", "to", "send", "to", "IDE", "when", "an", "error", "occurrs"], "add_tokens": "messager . printMessage ( WARNING , \"PEAPOD: an error has occurred while generating code.. \" + e . getMessage ( ) + \" \" + Arrays . toString ( e . getStackTrace ( ) ) ) ;", "del_tokens": "messager . printMessage ( ERROR , \"PEAPOD: an error has occurred while generating code.. \" + e . getMessage ( ) + \" \" + e . getStackTrace ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "removing", "packet", "listeners", "."], "add_tokens": "if ( wrapper != null && wrapper . packetListener . equals ( packetListener ) ) {", "del_tokens": "if ( wrapper . packetListener . equals ( packetListener ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "issue", "57", "(", "Timezone", "should", "allow", "for", "fractional", "offsets", ")", "in", "trunk"], "add_tokens": "private Double timezone ; public Double getTimezone ( ) {", "del_tokens": "private Integer timezone ; public Integer getTimezone ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Dataset", "to", "reveal", "partition", "support", "methods", "."], "add_tokens": "import java . io . IOException ; public interface Partition < E > { void getReader ( ) throws IOException ; DatasetWriter < E > getWriter ( ) throws IOException ;", "del_tokens": "interface Partition { void getReader ( ) ; void getWriter ( ) ;", "commit_type": "update"}
{"commit_tokens": ["removed", "placeholders", "in", "JavaDoc", "comments"], "add_tokens": "*", "del_tokens": "* A ... *", "commit_type": "remove"}
{"commit_tokens": ["moving", "dependencies", "for", "performance", "tests", "into", "appropriate", "scope", ".", "Spring", "-", "test", "now", "has", "maven", "test", "scope", ".", "Spring", "beans", "have", "been", "moved", "to", "their", "own", "file", ".", "The", "PerfRunner", "was", "moved", "into", "the", "test", "directory"], "add_tokens": "ApplicationContext context = new ClassPathXmlApplicationContext ( \"classpath:/applicationContext.xml\" , \"classpath:/applicationContext-test.xml\" ) ; System . out . println ( \"\\n\\nTesting default json\" ) ; perf . view = context . getBean ( \"json.view\" , AbstractYogaView . class ) ; test ( perf ) ; System . out . println ( \"\\n\\nTesting streaming json\" ) ; perf . view = context . getBean ( \"json.streaming.view\" , AbstractYogaView . class ) ; test ( perf ) ; perf . end ( ) ; } private static void test ( PerfRunner perf ) throws Exception { perf . render ( 1 ) ; }", "del_tokens": "ApplicationContext context = new ClassPathXmlApplicationContext ( \"classpath:/applicationContext.xml\" ) ; perf . view = context . getBean ( \"json.view\" , AbstractYogaView . class ) ; perf . render ( 1 ) ; perf . render ( 10 ) ; perf . render ( 10 ) ; perf . render ( 100 ) ; perf . render ( 100 ) ; }", "commit_type": "move"}
{"commit_tokens": ["Added", "Travis", "to", "this", "branch"], "add_tokens": "final PDFont font = PDType0Font . load ( new PDDocument ( ) , EFontResource . ALGREYA_SANS_NORMAL . getInputStream ( ) ) ;", "del_tokens": "final PDFont font = PDType0Font . load ( new PDDocument ( ) , EFontResource . LATO2_BLACK_ITALIC . getInputStream ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["removed", "default", "values", "so", "checkstyle", "would", "not", "compain", "about", "the", "final"], "add_tokens": "private String errorDesc ; private int lineNo ; private int errorLevel ;", "del_tokens": "private String errorDesc = null ; private int lineNo = 0 ; private int errorLevel = 0 ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "ModelProxyFactory", ".", "java", "bug"], "add_tokens": "import net . sf . cglib . proxy . MethodInterceptor ; import com . jdon . domain . proxy . ModelCGLIBMethodInterceptorImp ; private Map < Class , MethodInterceptor > modeInterceptors ; MethodInterceptor methodInterceptor = modeInterceptors . get ( model . getClass ( ) ) ; if ( methodInterceptor == null ) { List methodInterceptors = getAdviceName ( model ) ; if ( methodInterceptors == null || methodInterceptors . size ( ) == 0 ) return model ; methodInterceptor = new ModelCGLIBMethodInterceptorImp ( methodInterceptors ) ; modeInterceptors . put ( model . getClass ( ) , methodInterceptor ) ; return modelProxyFactory . create ( model . getClass ( ) , methodInterceptor ) ;", "del_tokens": "private Map < Class , List > modeInterceptors ; List methodInterceptors = modeInterceptors . get ( model . getClass ( ) ) ; if ( methodInterceptors == null ) { methodInterceptors = getAdviceName ( model ) ; modeInterceptors . put ( model . getClass ( ) , methodInterceptors ) ; if ( methodInterceptors == null || methodInterceptors . size ( ) == 0 ) return model ; return modelProxyFactory . create ( model . getClass ( ) , methodInterceptors ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "yaml", "files", "to", "match", "new", "config", ".", "FIxed", "bugs", "in", "kagura", ".", "js", ".", "Improved", "overall", "deserialization", "process", "in", "parameter", "configuration", "."], "add_tokens": "if ( from != null ) return from . getValues ( ) ; return null ; // return Arrays.asList(); } public void setValues ( Collection < Object > values ) { // Ignore..", "del_tokens": "import com . fasterxml . jackson . annotation . JsonIgnore ; // public static ParamConfig SQL(String name, ReportConfig reportConfig) { // return new SqlParamConfig(name, \"Combo\",\"\",\"\", reportConfig); // } // // public static ParamConfig Groovy(String name, String groovy) { // return new GroovyParamConfig(name, \"Groovy\",\"\",\"\", groovy); // } @ JsonIgnore return from . getValues ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "test", "to", "ensure", "zero", "-", "target", "injections", "work", "."], "add_tokens": "static void inject ( Object target , Object source , Finder finder ) {", "del_tokens": "private static void inject ( Object target , Object source , Finder finder ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "an", "easier", "to", "use", "token", "parser", "for", "fixed", "strings"], "add_tokens": "parsers . add ( new FixedStringTokenParser ( \"%%\" , \"%\" ) ) ;", "del_tokens": "parsers . add ( new TokenParser ( \"%%\" , TokenParser . FIXED_STRING , FIXED_STRING_TYPE , null , \"%\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implemented", "enough", "of", "the", "jax", "-", "rs", "Response", "classes", "continue", "on", "the", "RestHandler", "test"], "add_tokens": "import java . util . regex . Matcher ; private final Matcher matcher ; PathMatch ( boolean matches , Map < String , String > params , Matcher matcher ) { this . matcher = matcher ; / * * * @ return Returns the regex Matcher that was used * / public Matcher regexMatcher ( ) { return matcher ; } / * * * @ return Returns the last captured group value , which may be null * / String lastGroup ( ) { String group = matcher . group ( matcher . groupCount ( ) ) ; return \"/\" . equals ( group ) ? null : group ; }", "del_tokens": "PathMatch ( boolean matches , Map < String , String > params ) {", "commit_type": "implement"}
{"commit_tokens": ["Making", "the", "LtiLaunchVerifier", "aspect", "poincut", "broader"], "add_tokens": "if ( request . getParameter ( \"roles\" ) != null ) { for ( String role : request . getParameter ( \"roles\" ) . split ( \",\" ) ) { this . roles . add ( role . trim ( ) ) ; }", "del_tokens": "for ( String role : request . getParameter ( \"roles\" ) . split ( \",\" ) ) { this . roles . add ( role . trim ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Make", "JdbcCachedHelper", "more", "flexible", "-", "now", "you", "can", "wrap", "ConnectionProviderFactory", "into", "getting", "db", "source", "."], "add_tokens": "import org . javaz . jdbc . util . * ; public static ConnectionProviderFactory factory = null ; service . execute ( new GenericDbUpdaterThread ( db , queryUpdate , tmpList , factory == null ? ConnectionProviderFactory . instance . createProvider ( db ) : factory . createProvider ( db ) ) ) ;", "del_tokens": "import org . javaz . jdbc . util . ConnectionProviderI ; import org . javaz . jdbc . util . JdbcConstants ; import org . javaz . jdbc . util . SimpleConnectionProvider ; import org . javaz . jdbc . util . UnsafeSqlHelper ; public static ConnectionProviderI providerI = new SimpleConnectionProvider ( ) ; service . execute ( new GenericDbUpdaterThread ( db , queryUpdate , tmpList , providerI ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "regex", "page", "to", "the", "kdd", "demo", "."], "add_tokens": "@ Override public String toString ( ) { return this . expr . toString ( ) + \"*\" ; } @ Override public String toString ( ) { return this . expr . toString ( ) + \"+\" ; } @ Override public String toString ( ) { return this . expr . toString ( ) + \"?\" ; } if ( this . source . length ( ) > 40 ) { return \"<\" + this . source . substring ( 0 , 40 ) + \"...>\" ; } else { return \"<\" + this . source + \">\" ; }", "del_tokens": "return this . source ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "recent", "ValueQuery", "expressions", "fix", "to", "support", "fields", "like", "foo", ".", "*", ".", "bar", ".", "*", ".", "uid", "correctly"], "add_tokens": "public static final Pattern expressionPattern = Pattern . compile ( \"([\\\\w|\\\\*|\\\\.]+)\\\\s*(\\\\S+)\\\\s*(.+)$\" ) ;", "del_tokens": "public static final Pattern expressionPattern = Pattern . compile ( \"(\\\\w+)\\\\s*(\\\\S+)\\\\s*(.+)$\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "field", "modifiers", "(", "optional", "required", "repeated", ")"], "add_tokens": "protected FieldModifier modifier ; public FieldModifier getModifier ( ) { return modifier ; } public void setModifier ( FieldModifier modifier ) { this . modifier = modifier ; } . add ( \"modifier\" , modifier ) . add ( \"type\" , type . getReference ( ) )", "del_tokens": ". add ( \"type\" , type )", "commit_type": "add"}
{"commit_tokens": ["Fix", "ConcurrentModificationException", "in", "GVRAnimationEngine", "onDrawFrame"], "add_tokens": "List < GVRAnimation > animations = new ArrayList < GVRAnimation > ( mAnimations ) ; for ( GVRAnimation animation : animations ) { if ( animation . onDrawFrame ( frameTime ) == false ) { mAnimations . remove ( animation ) ;", "del_tokens": "Iterator < GVRAnimation > iterator = mAnimations . iterator ( ) ; while ( iterator . hasNext ( ) ) { GVRAnimation animation = iterator . next ( ) ; boolean terminate = animation . onDrawFrame ( frameTime ) != true ; if ( terminate ) { iterator . remove ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "incorrect", "colour", "value", "in", "SUCCESS", "constant"], "add_tokens": "PRIMARY ( \"primary\" ) , INFO ( \"info\" ) , SUCCESS ( \"success\" ) , WARNING ( \"warning\" ) , DANGER ( \"danger\" ) , DEFAULT ( \"default\" ) ;", "del_tokens": "PRIMARY ( \"primary\" ) , INFO ( \"info\" ) , SUCCESS ( \"primary\" ) , WARNING ( \"warning\" ) , DANGER ( \"danger\" ) , DEFAULT ( \"default\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "static", "method", "to", "utils", ".", "Reduce", "duplication", "between", "Zips", "&", "ZipUtil", "."], "add_tokens": "zf = ZipFileUtil . getZipFile ( dest , charset ) ;", "del_tokens": "zf = Zips . getZipFile ( dest , charset ) ;", "commit_type": "move"}
{"commit_tokens": ["Implement", "timeout", "manager", "running", "in", "memory", "."], "add_tokens": "* Use static builder method to create instance . private Timeout ( ) { * Gets the id of the matching saga . public String getSagaId ( ) { return sagaId ; * Creates a new Timeout instance . public static Timeout create ( final String sagaId , final String name , final Date expiredAt ) { Timeout timeout = new Timeout ( ) ; timeout . sagaId = sagaId ; timeout . expiredAt = expiredAt ; timeout . name = name ; return timeout ;", "del_tokens": "* Gets the id of the matching saga . public String getSagaId ( ) { return sagaId ; * Sets the id of the saga . public void setSagaId ( final String sagaId ) { this . sagaId = sagaId ; / * * * Sets the date the timeout expired is triggered . * / public void setExpiredAt ( final Date expiredAt ) { this . expiredAt = expiredAt != null ? new Date ( expiredAt . getTime ( ) ) : null ; } * Sets an optional name of the timeout . public void setName ( final String name ) { this . name = name ;", "commit_type": "implement"}
{"commit_tokens": ["add", "generate", "test", "code", "for", "generated", "code", "command", "line", "option", "defaults", "to", "false"], "add_tokens": "if ( args [ 2 ] . equals ( \"--generatetests\" ) ) { new Molgenis ( args [ 0 ] , args [ 1 ] ) . generateTests ( ) ; } else if ( args [ 2 ] . equals ( \"--updatedb\" ) ) public void generateTests ( ) throws Exception { options . setGenerateTests ( true ) ; generate ( ) ; }", "del_tokens": "if ( args [ 2 ] . equals ( \"--updatedb\" ) )", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "misaligned", "block", "in", "AnimatableColorValue"], "add_tokens": "} keyTimes . add ( timePercentage ) ; if ( keyframe . has ( \"h\" ) && keyframe . getBoolean ( \"h\" ) ) { outColor = startColor ; addStartValue = true ; addTimePadding = true ;", "del_tokens": "keyTimes . add ( timePercentage ) ; if ( keyframe . has ( \"h\" ) && keyframe . getBoolean ( \"h\" ) ) { outColor = startColor ; addStartValue = true ; addTimePadding = true ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "Next", "and", "fix", "scope", "of", "complet"], "add_tokens": "public Optional < byte [ ] > next ( ) {", "del_tokens": "Optional < byte [ ] > next ( ) {", "commit_type": "add"}
{"commit_tokens": ["allow", "default", "jax", "-", "rs", "packages", "to", "be", "overriden"], "add_tokens": "default List < String > getPackages ( ) { return ImmutableList . of ( ) ; }", "del_tokens": "", "commit_type": "allow"}
{"commit_tokens": ["Fix", "typo", "in", "SimpleForwa", "(", "r", ")", "dingCheckedFuture"], "add_tokens": "* < p > Most subclasses can simply extend { @ link SimpleForwardingCheckedFuture } . public abstract static class SimpleForwardingCheckedFuture < protected SimpleForwardingCheckedFuture ( CheckedFuture < V , X > delegate ) {", "del_tokens": "* < p > Most subclasses can simply extend { @ link SimpleForwadingCheckedFuture } . public abstract static class SimpleForwadingCheckedFuture < protected SimpleForwadingCheckedFuture ( CheckedFuture < V , X > delegate ) {", "commit_type": "fix"}
{"commit_tokens": ["implement", "a", "hopefully", "more", "memory", "efficient", "bimap", "for", "looking", "up", "efficient", "strings"], "add_tokens": "static final int HASH_MODULO = 5 ; // private static BiMap<EfficientString, Integer> allStrings = Maps.synchronizedBiMap(HashBiMap.<EfficientString, Integer>create()); private static EfficientStringBiMap allStrings = new EfficientStringBiMap ( ) ; return allStrings . get ( existingIndex ) ; return allStrings . get ( index ) ; return ( int ) ( CRC_32 . getValue ( ) % HASH_MODULO ) ;", "del_tokens": "import com . google . common . collect . BiMap ; import com . google . common . collect . HashBiMap ; import com . google . common . collect . Maps ; private static BiMap < EfficientString , Integer > allStrings = Maps . synchronizedBiMap ( HashBiMap . < EfficientString , Integer > create ( ) ) ; return allStrings . inverse ( ) . get ( existingIndex ) ; return allStrings . inverse ( ) . get ( index ) ; return ( int ) ( CRC_32 . getValue ( ) % 50000 ) ;", "commit_type": "implement"}
{"commit_tokens": ["Removed", "the", "null", "check", "inside", "GitlabGroup", "model"], "add_tokens": "this . ldapAccess = ldapGitlabAccessLevel . accessValue ;", "del_tokens": "if ( ldapGitlabAccessLevel != null ) //Check to see if a group has ldap_access as null this . ldapAccess = ldapGitlabAccessLevel . accessValue ;", "commit_type": "remove"}
{"commit_tokens": ["remove", "EJBDefinition", ".", "java", "EJBObjectFactory", ".", "java", "EJBTargetMetaDef", ".", "java"], "add_tokens": "Debug . logVerbose ( \"[JdonFramework] it is pojo target service\" , module ) ; result = mUtil . execute ( method , target , args ) ;", "del_tokens": "import com . jdon . bussinessproxy . TargetMetaDef ; import com . jdon . container . access . TargetMetaRequest ; private final TargetMetaRequestsHolder targetMetaRequestsHolder ; this . targetMetaRequestsHolder = targetMetaRequestsHolder ; TargetMetaRequest targetMetaRequest = targetMetaRequestsHolder . getTargetMetaRequest ( ) ; TargetMetaDef targetMetaDef = targetMetaRequest . getTargetMetaDef ( ) ; if ( targetMetaDef . isEJB ( ) ) { Debug . logVerbose ( \"[JdonFramework] it is ejb target service\" , module ) ; result = mUtil . execute ( method , target , mUtil . narrowArgs ( args ) ) ; } else { Debug . logVerbose ( \"[JdonFramework] it is pojo target service\" , module ) ; result = mUtil . execute ( method , target , args ) ; }", "commit_type": "remove"}
{"commit_tokens": ["updated", "dynamic", "array", "support", "for", "int", "/", "long", "/", "short"], "add_tokens": "File file = new File ( cacheDirectory , \"indexes.dat\" ) ;", "del_tokens": "File file = new File ( cacheDirectory , \"indexes_\" + length ( ) + \".dat\" ) ; / * protected RecoverableArray ( int elemSize , int entrySize , int maxEntries , File cacheDirectory , EntryFactory < V > entryFactory ) throws Exception { _cacheDir = cacheDirectory ; _entryFactory = entryFactory ; _entryManager = new ArrayEntryManager < V > ( this , maxEntries , entrySize ) ; if ( ! _cacheDir . exists ( ) ) { _cacheDir . mkdirs ( ) ; } boolean newFile = true ; File file = new File ( cacheDirectory , \"indexes_\" + length ( ) + \".dat\" ) ; if ( file . exists ( ) ) { newFile = false ; } _arrayFile = new ArrayFile ( file , elemSize ) ; _length = _arrayFile . readArrayLength ( ) ; if ( newFile ) { initArrayFileData ( ) ; } _log . info ( \"initialLength:\" + _length + \" entrySize:\" + entrySize + \" maxEntries:\" + maxEntries + \" cacheDirectory:\" + cacheDirectory . getAbsolutePath ( ) + \" arrayFile:\" + _arrayFile . getName ( ) ) ; init ( ) ; } * /", "commit_type": "update"}
{"commit_tokens": ["updated", "all", "dependencies", "verified", "unit", "tests"], "add_tokens": "return dataSource . getParentLogger ( ) ;", "del_tokens": "// TODO Auto-generated method stub return null ;", "commit_type": "update"}
{"commit_tokens": ["fixing", "JwtCreator", "to", "set", "the", "headers", "to", "the", "exisitng", "map", "instead", "of", "ovewriting", "it"], "add_tokens": "this . headerClaims . putAll ( headerClaims ) ;", "del_tokens": "this . headerClaims = new HashMap < > ( headerClaims ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "checkbox", "&", "radio", "states", "for", "button", "groups"], "add_tokens": "case END : setInsetOnLayers ( ldAry , n , 0 , 0 , 0 ) ; break ;", "del_tokens": "case END : setInsetOnLayers ( ldAry , n , 0 , 0 , 0 ) ; break ;", "commit_type": "add"}
{"commit_tokens": ["Make", "reader", "aliases", "singleton", "and", "show", "the", "reader", "name", "/", "alias", "when", "waiting", "for", "card"], "add_tokens": "import apdu4j . * ; System . err . format ( \"%n[%s] Waiting for card ...\" , ReaderAliases . getDefault ( ) . translate ( t . getName ( ) ) ) ;", "del_tokens": "import apdu4j . CardBIBO ; import apdu4j . SCard ; import apdu4j . TagRemovedException ; import apdu4j . TerminalManager ; System . err . print ( \"\\nWaiting for card ...\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Make", "endpoint", "optional", "and", "region", "required", "."], "add_tokens": "\"Sets the signing region to use for signing requests to DynamoDB. Required.\" ,", "del_tokens": "\"Sets the signing region to use for signing requests to DynamoDB.\" ,", "commit_type": "make"}
{"commit_tokens": ["Fixed", "misplaced", "argument", "in", "abstractDatabaseEngine", "when", "creating", "batches", ".", "Added", "new", "test", "to", "add", "coverage", "for", "the", "database", "engine", "batch", "creation", "."], "add_tokens": "/ * * * Constant { @ link FailureListener } representing the NO OP operation . * / public final static FailureListener NO_OP = rowsFailed -> { } ; this ( de , name , batchSize , batchTimeout , maxAwaitTimeShutdown , NO_OP ) ;", "del_tokens": "this ( de , name , batchSize , batchTimeout , maxAwaitTimeShutdown , rowsFailed -> { } ) ;", "commit_type": "fix"}
{"commit_tokens": ["improved", "error", "message", "in", "maven", "plugin"], "add_tokens": "// chaining the exception would result in a cluttered error message throw new MojoExecutionException ( e . toString ( ) ) ;", "del_tokens": "throw new MojoExecutionException ( \"IO error while searching for test classes\" , e ) ;", "commit_type": "improve"}
{"commit_tokens": ["Allow", "/", "in", "tag", "and", "metric", "names", "."], "add_tokens": "|| c == '-' || c == '_' || c == '.' || c == '/' ) ) {", "del_tokens": "|| c == '-' || c == '_' || c == '.' ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Removing", "accented", "characters", "from", "jDiameter", "."], "add_tokens": "* @ param commandCode message command code IMessage createEmptyMessage ( int commandCode , long headerAppId ) ;", "del_tokens": "* @ param ommandCode message command code IMessage createEmptyMessage ( int ommandCode , long headerAppId ) ;", "commit_type": "remove"}
{"commit_tokens": ["Updated", "build", "tools", "and", "dependencies", "to", "modern", "versions"], "add_tokens": "import com . stripe . net . RequestOptions ; RequestOptions requestOptions = RequestOptions . builder ( ) . setApiKey ( publishableKey ) . build ( ) ; hashMapFromCard ( card ) , requestOptions ) ; throw new AuthenticationException ( \"Invalid Publishable Key: You must use a valid publishable key to create a token. For more info, see https://stripe.com/docs/stripe.js.\" , null , 0 ) ; throw new AuthenticationException ( \"Invalid Publishable Key: You are using a secret key to create a token, instead of the publishable one. For more info, see https://stripe.com/docs/stripe.js\" , null , 0 ) ;", "del_tokens": "hashMapFromCard ( card ) , publishableKey ) ; throw new AuthenticationException ( \"Invalid Publishable Key: You must use a valid publishable key to create a token. For more info, see https://stripe.com/docs/stripe.js.\" ) ; throw new AuthenticationException ( \"Invalid Publishable Key: You are using a secret key to create a token, instead of the publishable one. For more info, see https://stripe.com/docs/stripe.js\" ) ;", "commit_type": "update"}
{"commit_tokens": ["add", "new", "widget", ".", "Update", "some", "dependencies"], "add_tokens": "Set < ClassPath . ClassInfo > classes = ClassPath . from ( Thread . currentThread ( ) . getContextClassLoader ( ) ) . getAllClasses ( ) ;", "del_tokens": "Set < ClassPath . ClassInfo > classes = ClassPath . from ( Thread . currentThread ( ) . getContextClassLoader ( ) ) . getTopLevelClassesRecursive ( \"com.github.avarabyeu\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "comment", "added", "implementation", "."], "add_tokens": "import java . util . ArrayList ; private List < Approval > approvals = new ArrayList < Approval > ( ) ;", "del_tokens": "private List < Approval > approvals ;", "commit_type": "fix"}
{"commit_tokens": ["Move", "MDC", "initialization", "to", "the", "Start", "state"], "add_tokens": "RaftStateContext ( StateFactory stateFactory , @ RaftExecutor Fiber executor ) {", "del_tokens": "import org . robotninjas . barge . log . RaftLog ; RaftStateContext ( RaftLog log , StateFactory stateFactory , @ RaftExecutor Fiber executor ) { this ( log . self ( ) . toString ( ) , stateFactory , executor ) ; } RaftStateContext ( String name , StateFactory stateFactory , @ RaftExecutor Fiber executor ) { MDC . put ( \"self\" , name ) ;", "commit_type": "move"}
{"commit_tokens": ["Remove", "stringutils", "and", "add", "simple", "escaper"], "add_tokens": "import j2html . utils . SimpleEscaper ; this . value = SimpleEscaper . escape ( value ) ;", "del_tokens": "import static org . apache . commons . lang3 . StringEscapeUtils . escapeHtml4 ; this . value = escapeHtml4 ( value ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", "new", "images", "for", "documentation", "and", "property", "filter", "map", "step", "and", "edgelabeldistribution", "statistic", "."], "add_tokens": "final String [ ] strings = context . getConfiguration ( ) . getStrings ( LABELS ) ; if ( null == strings || strings . length == 0 ) this . labels = new HashSet < String > ( ) ; else this . labels = new HashSet < String > ( Arrays . asList ( strings ) ) ;", "del_tokens": "this . labels = new HashSet < String > ( Arrays . asList ( context . getConfiguration ( ) . getStrings ( LABELS ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "getCommits", "()", "to", "set", "per_page", "to", "DEFAULT_PER_PAGE", "."], "add_tokens": "import javax . ws . rs . core . Form ; Form formData = new GitLabApiForm ( ) . withParam ( \"per_page\" , getDefaultPerPage ( ) ) ; Response response = get ( Response . Status . OK , formData . asMap ( ) , \"projects\" , projectId , \"repository\" , \"commits\" ) ; Form formData = new GitLabApiForm ( ) . withParam ( \"per_page\" , getDefaultPerPage ( ) ) ; Response response = get ( Response . Status . OK , formData . asMap ( ) , \"projects\" , projectId , \"repository\" , \"commits\" , sha ) ;", "del_tokens": "Response response = get ( Response . Status . OK , null , \"projects\" , projectId , \"repository\" , \"commits\" ) ; Response response = get ( Response . Status . OK , null , \"projects\" , projectId , \"repository\" , \"commits\" , sha ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "error", "while", "factoring", "out", "fade", "effect"], "add_tokens": "animator . setDuration ( JazzyListView . DURATION * DURATION_MULTIPLIER ) ;", "del_tokens": "animator . setDuration ( animator . getDuration ( ) * JazzyListView . DURATION * DURATION_MULTIPLIER ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "pack", "that", "would", "preserve", "root", "folder"], "add_tokens": "* The ZIP file must not be a directory and its parent directory must exist . Will * not include the root directory name in the archive . / * * * Compresses the given directory and all its sub - directories into a ZIP file . * < p > * The ZIP file must not be a directory and its parent directory must exist . Will * not include the root directory name in the archive . * * @ param sourceFolder * root directory . * @ param targetZipFile * ZIP file that will be created or overwritten . * / public static void pack ( final File sourceFolder , final File targetZipFile , boolean preserveRoot ) { if ( preserveRoot ) { pack ( sourceFolder , targetZipFile , new NameMapper ( ) { public String map ( String name ) { return sourceFolder . getName ( ) + \"/\" + name ; } } ) ; } else pack ( sourceFolder , targetZipFile ) ; }", "del_tokens": "* The ZIP file must not be a directory and its parent directory must exist .", "commit_type": "add"}
{"commit_tokens": ["Fix", "method", "to", "be", "private", "instead", "of", "public", "."], "add_tokens": "private List < String > extractTest ( final HttpServletRequest request ) {", "del_tokens": "public List < String > extractTest ( final HttpServletRequest request ) {", "commit_type": "fix"}
{"commit_tokens": ["removed", "unmeaningful", "check", "on", "engine", "existence", "on", "stop"], "add_tokens": "", "del_tokens": "if ( server == null ) return ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "documentation", "exposed", "minification", "via", "command", "line"], "add_tokens": "System . err . println ( \"You must specify an input file.\" ) ; String inputPath = null ; for ( String arg : args ) { if ( arg . equals ( \"-c\" ) ) { translator . setCompressionEnabled ( true ) ; } else { if ( inputPath != null ) { System . err . println ( \"Only one input file can be used.\" ) ; System . exit ( 1 ) ; } inputPath = arg ; } } System . out . println ( translator . process ( new FileInputStream ( inputPath ) ) ) ;", "del_tokens": "System . err . println ( \"You must specify at least one input file.\" ) ; } else if ( args . length > 1 ) { System . err . println ( \"Only the first input file will be used.\" ) ; System . out . println ( translator . process ( new FileInputStream ( args [ 0 ] ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "set", "to", "track", "seen", "tags", "since", "they", "have", "the", "potential", "to", "be", "sparse", "."], "add_tokens": "import java . util . LinkedHashSet ; import java . util . Set ; Set < Integer > tags = new LinkedHashSet < Integer > ( ) ; if ( ! tags . add ( tag ) ) { / * * * Though not mentioned in the spec , enum values use C ++ scoping rules , meaning that enum values * are siblings of their type , not children of it . * / Set < Integer > tags = new LinkedHashSet < Integer > ( ) ; if ( ! tags . add ( tag ) ) {", "del_tokens": "import java . util . BitSet ; BitSet tags = new BitSet ( ) ; if ( tags . get ( tag ) ) { tags . set ( tag ) ; BitSet tags = new BitSet ( ) ; if ( tags . get ( tag ) ) { tags . set ( tag ) ;", "commit_type": "use"}
{"commit_tokens": ["added", "typing", "to", "the", "sexp", "lists"], "add_tokens": "private final List < Sexp > scenarioBuffer = new ArrayList < Sexp > ( ) ; private final List < Sexp > examplesBuffer = new ArrayList < Sexp > ( ) ; private final List < Sexp > examplesRowsBuffer = new ArrayList < Sexp > ( ) ;", "del_tokens": "private final List < Sexp > scenarioBuffer = new ArrayList ( ) ; private final List < Sexp > examplesBuffer = new ArrayList ( ) ; private final List < Sexp > examplesRowsBuffer = new ArrayList ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "category", "deviceType", "and", "rename", "identifiers", "to", "aliases"], "add_tokens": "selectedPayloadObject . put ( \"alias\" , unifiedMessage . getAliases ( ) ) ;", "del_tokens": "import java . util . List ; selectedPayloadObject . put ( \"alias\" , unifiedMessage . getIdentifiers ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["updated", "ASCII", "art", "and", "more", "doc", "image", "."], "add_tokens": "logger . info ( \" .-' .'| \\\\ \\\\__\" ) ;", "del_tokens": "logger . info ( \" .-' .'| \\\\' \\\\__\" ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "the", "capability", "to", "specify", "a", "Java", "system", "property", "in", "the", "web", ".", "xml", "file", "and", "then", "use", "that", "property", "to", "override", "configuration", "."], "add_tokens": "public static final String SYSTEM_CONFIG_LOCATION_PARAM = \"jmxtrans.system.config\" ; String configuration = configureFromSystemProperty ( sce ) ; if ( configuration == null || configuration . isEmpty ( ) ) { configuration = configureFromWebXmlParam ( sce ) ; if ( configuration == null || configuration . isEmpty ( ) ) { configuration = \"classpath:jmxtrans.json, classpath:org/jmxtrans/embedded/config/jmxtrans-internals.json\" ; } private String configureFromSystemProperty ( ServletContextEvent sce ) { String configSystemProperty = sce . getServletContext ( ) . getInitParameter ( SYSTEM_CONFIG_LOCATION_PARAM ) ; if ( configSystemProperty == null || configSystemProperty . isEmpty ( ) ) { return null ; } return \"file:///\" + System . getProperty ( configSystemProperty ) ; } private String configureFromWebXmlParam ( ServletContextEvent sce ) { return sce . getServletContext ( ) . getInitParameter ( CONFIG_LOCATION_PARAM ) ; }", "del_tokens": "String configuration = sce . getServletContext ( ) . getInitParameter ( CONFIG_LOCATION_PARAM ) ; if ( configuration == null || configuration . isEmpty ( ) ) { configuration = \"classpath:jmxtrans.json, classpath:org/jmxtrans/embedded/config/jmxtrans-internals.json\" ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "for", "Oracle", "DB", "by", "removing", "the", "AS", "keywords", ".", "RI", "Bug", "6680", ".", "GLASSFISH", "-", "21022"], "add_tokens": "statement = conn . prepareStatement ( \"select A.* from stepexecutioninstancedata A inner join executioninstancedata B on A.jobexecid = B.jobexecid where B.jobinstanceid = ? order by A.stepexecid desc\" ) ; statement = conn . prepareStatement ( \"select A.jobexecid, A.createtime, A.starttime, A.endtime, A.updatetime, A.parameters, A.jobinstanceid, A.batchstatus, A.exitstatus, B.name from executioninstancedata A inner join jobinstancedata B on A.jobinstanceid = B.jobinstanceid where jobexecid = ?\" ) ; statement = conn . prepareStatement ( \"select A.jobexecid, A.jobinstanceid, A.createtime, A.starttime, A.endtime, A.updatetime, A.parameters, A.batchstatus, A.exitstatus, B.name from executioninstancedata A inner join jobinstancedata B ON A.jobinstanceid = B.jobinstanceid where A.jobinstanceid = ?\" ) ; statement = conn . prepareStatement ( \"select A.obj from jobstatus A inner join \" + \"executioninstancedata B on A.id = B.jobinstanceid where B.jobexecid = ?\" ) ;", "del_tokens": "statement = conn . prepareStatement ( \"select A.* from stepexecutioninstancedata as A inner join executioninstancedata as B on A.jobexecid = B.jobexecid where B.jobinstanceid = ? order by A.stepexecid desc\" ) ; statement = conn . prepareStatement ( \"select A.jobexecid, A.createtime, A.starttime, A.endtime, A.updatetime, A.parameters, A.jobinstanceid, A.batchstatus, A.exitstatus, B.name from executioninstancedata as A inner join jobinstancedata as B on A.jobinstanceid = B.jobinstanceid where jobexecid = ?\" ) ; statement = conn . prepareStatement ( \"select A.jobexecid, A.jobinstanceid, A.createtime, A.starttime, A.endtime, A.updatetime, A.parameters, A.batchstatus, A.exitstatus, B.name from executioninstancedata as A inner join jobinstancedata as B ON A.jobinstanceid = B.jobinstanceid where A.jobinstanceid = ?\" ) ; statement = conn . prepareStatement ( \"select A.obj from jobstatus as A inner join \" + \"executioninstancedata as B on A.id = B.jobinstanceid where B.jobexecid = ?\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "in", "AbstractManifestServlet", "which", "results", "in", "a", "NullPointerException"], "add_tokens": "final String propertyValue = provider . getPropertyValue ( request ) ; if ( null != propertyValue ) { computedBindings . add ( new BindingProperty ( provider . getPropertyName ( ) , propertyValue ) ) ; }", "del_tokens": "computedBindings . add ( new BindingProperty ( provider . getPropertyName ( ) , provider . getPropertyValue ( request ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Using", "javadocs", "links", "from", "properties", "defined", "in", "parent", "pom", "."], "add_tokens": "* Copyright ( C ) 2016 , 2017 AO Industries , Inc . // Self additionalApiLinks . put ( \"com.semanticcms.core.taglib.\" , Maven . properties . getProperty ( \"documented.url\" ) + \"apidocs/\" ) ; // Dependencies Maven . properties . getProperty ( \"javac.link.javaApi.jdk16\" ) , Maven . properties . getProperty ( \"javac.link.javaeeApi.6\" ) ,", "del_tokens": "* Copyright ( C ) 2016 AO Industries , Inc . additionalApiLinks . put ( \"com.semanticcms.core.taglib.\" , \"https://semanticcms.com/core/taglib/apidocs/\" ) ; \"https://docs.oracle.com/javase/6/docs/api/\" , \"https://docs.oracle.com/javaee/6/api/\" ,", "commit_type": "use"}
{"commit_tokens": ["Fix", "a", "bug", "where", "checking", "whether", "the", "repository", "is", "migrated", "or", "not"], "add_tokens": "internalRepo . getOrNull ( Revision . HEAD , METADATA_JSON ) . join ( ) != null ;", "del_tokens": "internalRepo . getOrNull ( Revision . HEAD , METADATA_JSON ) != null ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "import", "statement", "referencing", "inexistent", "class"], "add_tokens": "import com . navercorp . utilset . exception . InternalExceptionHandler ;", "del_tokens": "import com . navercorp . utilset . exception . InternalExceptionHandler ; import com . navercorp . utilset . storage . MicroSdDetector ;", "commit_type": "remove"}
{"commit_tokens": ["Use", "a", "logger", "to", "display", "our", "required", "copyright", "message", "."], "add_tokens": "import com . bbn . bue . common . BBNUtils ; BBNUtils . logCopyrightMessage ( ) ;", "del_tokens": "System . err . println ( \"Copyright 2015 Raytheon BBN Technologies Corp.\" ) ; System . err . println ( \"All Rights Reserved.\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Make", "sure", "ping", "thread", "runs", "and", "set", "all", "servers", "alive", "before", "running", "junit", "."], "add_tokens": "lb . setPingInterval ( 1 ) ; // make sure the ping cycle has kicked in and all servers are set to alive Thread . sleep ( 5000 ) ; System . out . println ( lb . getServerList ( true ) ) ;", "del_tokens": "lb . setPingInterval ( 5 ) ; Thread . sleep ( 2000 ) ;", "commit_type": "make"}
{"commit_tokens": ["Adding", "cards", "into", "a", "new", "All", "sets", "request", ".", "Made", "separate", "from", "the", "original", "request", "due", "to", "a", "massive", "performance", "difference", ".", "A", "few", "warning", "fixes", "as", "well", "."], "add_tokens": "import static org . junit . Assert . assertNotEquals ; assertNotEquals ( testSet , SetAPI . getSet ( \"LEB\" ) ) ; testSet = SetAPI . getSet ( \"LEA\" ) ; @ Test public void testGetAllSetsWithCards ( ) { List < MtgSet > sets = SetAPI . getAllSetsWithCards ( ) ; assertNotNull ( sets . get ( 0 ) . getCards ( ) ) ; }", "del_tokens": "assertFalse ( testSet . equals ( SetAPI . getSet ( \"LEB\" ) ) ) ; testSet = SetAPI . getSet ( \"DRK\" ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "the", "functionality", "to", "disable", "panning", "in", "order", "to", "enable", "for", "example", "selection", "rectangles"], "add_tokens": "if ( ! viewer . isPanningEnabled ( ) ) return ; if ( ! viewer . isPanningEnabled ( ) ) return ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fix", "some", "more", "javadoc", "comments"], "add_tokens": "* @ param queryWithOptions map containing the following : * < ul > * < li > \"query\" : a Map expressing the query < / li > * < li > \"options\" : an optional Map containing query options < / li > * < / ul >", "del_tokens": "* @ param query query", "commit_type": "fix"}
{"commit_tokens": ["Removed", "the", "+", "1", "and", "-", "1", "defaults", "in", "-", "core", "for", "looking", "up", "parameters", "and", "columns", ".", "Now", "only", "JDBC", "does", "that", "dance", ".", "Better", "."], "add_tokens": "return getCursor ( ) . getColumnName ( column ) ; args . add ( parameterIndex , null ) ; args . add ( parameterIndex , obj . toString ( ) ) ;", "del_tokens": "return getCursor ( ) . getColumnName ( AndroidDatabaseResults . jdbcColumnIndexToAndroid ( column ) ) ; args . add ( AndroidDatabaseResults . jdbcColumnIndexToAndroid ( parameterIndex ) , null ) ; args . add ( AndroidDatabaseResults . jdbcColumnIndexToAndroid ( parameterIndex ) , obj . toString ( ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixed", "new", "DefaultConfiguration", ".", "java"], "add_tokens": "String workspaceName = workspace . getName ( ) ; return format ( \"https://%s.kanbanery.com/api/v1/\" , workspaceName ) ; String workspaceName = workspace . getName ( ) ; return format ( \"https://%s.kanbanery.com/api/v1/%s/%d.json\" , workspaceName , resourcesId , id ) ; String workspaceName = workspace . getName ( ) ; return format ( \"https://%s.kanbanery.com/api/v1/projects/%s/%s.json\" , workspaceName , projectId , resourceDotJson ) ; String workspaceName = workspace . getName ( ) ; return format ( \"https://%s.kanbanery.com/api/v1/projects/%d/%s/%s.json\" , workspaceName , projectId , resource , resourceDotJson ) ; String workspaceName = workspace . getName ( ) ; return format ( \"https://%s.kanbanery.com/api/v1/%s/%d/%s.json\" , workspaceName , resourcesId , id , resourceDotJson ) ; String workspaceName = workspace . getName ( ) ; return format ( \"https://%s.kanbanery.com/api/v1/projects/%s/\" , workspaceName , projectId ) ;", "del_tokens": "return format ( \"https://%s.kanbanery.com/api/v1/\" , workspace ) ; return format ( \"https://%s.kanbanery.com/api/v1/%s/%d.json\" , workspace , resourcesId , id ) ; return format ( \"https://%s.kanbanery.com/api/v1/projects/%s/%s.json\" , workspace , projectId , resourceDotJson ) ; return format ( \"https://%s.kanbanery.com/api/v1/projects/%d/%s/%s.json\" , workspace , projectId , resource , resourceDotJson ) ; return format ( \"https://%s.kanbanery.com/api/v1/%s/%d/%s.json\" , workspace , resourcesId , id , resourceDotJson ) ; return format ( \"https://%s.kanbanery.com/api/v1/projects/%s/\" , workspace , projectId ) ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "some", "protected", "methods", "to", "package", "-", "private"], "add_tokens": "abstract boolean matches ( StartElement element ) ; NodeState < T > buildState ( ) { NodeState < T > addState ( NodeState < T > baseState ) { List < ElementConstraint > getConstraints ( ) {", "del_tokens": "protected abstract boolean matches ( StartElement element ) ; protected NodeState < T > buildState ( ) { protected NodeState < T > addState ( NodeState < T > baseState ) { protected List < ElementConstraint > getConstraints ( ) {", "commit_type": "change"}
{"commit_tokens": ["Updated", "to", "make", "the", "class", "final", "make", "constructors", "package", "access", "only", "and", "remove", "unused", "code", "."], "add_tokens": "final class FixedData extends MPPComponent FixedData ( FixedMeta meta , InputStream is ) FixedData ( int itemSize , InputStream is ) private int [ ] m_offset ;", "del_tokens": "class FixedData extends MPPComponent public FixedData ( FixedMeta meta , InputStream is ) public FixedData ( int itemSize , InputStream is ) private int [ ] m_offset ; / * * * Constant representing the magic number appearing * at the start of the block . * / private static final int MAGIC = 0xFADFADBA ;", "commit_type": "update"}
{"commit_tokens": ["Removed", "DistributedEventBus", "-", "related", "classes", "as", "Redis", "may", "be", "a", "better", "option", "than", "Hazelcast", "..."], "add_tokens": "public abstract class EventBus private Queue < Object > eventQueue ; public EventBus ( Queue < Object > queueImpl ) public Object poll ( ) public void publish ( Object event ) if ( ! canPublish ( event . getClass ( ) ) ) return ; public boolean canPublish ( Class < ? > eventType ) { return true ; } public abstract boolean subscribe ( EventHandler handler ) ; public abstract boolean unsubscribe ( EventHandler handler ) ;", "del_tokens": "public abstract class EventBus < T > private Queue < T > eventQueue ; public EventBus ( Queue < T > queueImpl ) public T poll ( ) public void publish ( T event )", "commit_type": "remove"}
{"commit_tokens": ["fix", "pebble", "path", "loader", "issue", "when", "using", "relative", "paths", "as", "a", "base", "dir"], "add_tokens": "PebblePathLoader ( Path contentDir , Directory root ) { return newBufferedReader ( template , StandardCharsets . UTF_8 ) ;", "del_tokens": "private final Path baseDir ; PebblePathLoader ( Path contentDir , Path baseDir , Directory root ) { this . baseDir = baseDir ; return newBufferedReader ( baseDir . resolve ( template ) , StandardCharsets . UTF_8 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "a", "test", "to", "reduce", "the", "coverage", "noise"], "add_tokens": "public final class XmlDataHandler extends DefaultHandler { / * * * Logs an issue while parsing XML . * * @ param prefix * log level as string to add at the beginning of the message * @ param e * exception to log * / protected static void logParsingIssue ( final String prefix , final SAXParseException e ) {", "del_tokens": "public class XmlDataHandler extends DefaultHandler { private static void logParsingIssue ( final String prefix , final SAXParseException e ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "better", "description", "of", "handling", "non", "-", "BMP", "characters"], "add_tokens": "* Gets the Unicode escape for a JavaScript character or null if may be passed - through without escape . * < p > * Code points outside the BMP ( 0x10000 + ) are simply handled as their * individual surrogates { @ code \"\\\\uhhhh\\\\uhhhh\" } - escaped . This is safe , * completely interoperable between Java and JavaScript , and works with * simple one - char - at - a - time streaming implementations . * < / p > * * @ param ch The character to encode * * @ return the encoded form of the character or { @ code null } when no * encoding needed", "del_tokens": "* Gets the unicode escape for a JavaScript character or null if may be passed - through without escape . * @ param ch * @ return", "commit_type": "add"}
{"commit_tokens": ["Improve", "error", "message", "when", "missing", "low", "-", "level", "HTTP", "transport"], "add_tokens": "boolean isAppEngineSdkOnClasspath = false ; isAppEngineSdkOnClasspath = true ; boolean isApacheHttpClientOnClasspath = false ; isApacheHttpClientOnClasspath = true ; StringBuilder buf = new StringBuilder ( \"Missing required low-level HTTP transport package.\\n\" ) ; if ( isAppEngineSdkOnClasspath ) { buf . append ( \"For Google App Engine, the required package is \" + \"\\\"com.google.api.client.appengine\\\".\\n\" ) ; } if ( isApacheHttpClientOnClasspath ) { boolean isAndroidOnClasspath = false ; try { Class . forName ( \"android.util.Log\" ) ; isAndroidOnClasspath = true ; } catch ( Exception e3 ) { } if ( isAndroidOnClasspath ) { buf . append ( \"For Android, the preferred package is \" + \"\\\"com.google.api.client.apache\\\".\\n\" ) ; } else { buf . append ( \"For Apache HTTP Client, the preferred package is \" + \"\\\"com.google.api.client.apache\\\".\\n\" ) ; } } if ( isAppEngineSdkOnClasspath || isApacheHttpClientOnClasspath ) { buf . append ( \"Alternatively, use\" ) ; } else { buf . append ( \"Use\" ) ; } buf . append ( \" package \\\"com.google.api.client.javanet\\\".\" ) ; throw new IllegalStateException ( buf . toString ( ) ) ;", "del_tokens": "throw new IllegalStateException ( \"unable to load NetHttpTrasnport\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Added", "changes", "for", "carousel", "inbox", "template"], "add_tokens": "ImageView readDot , carouselReadDot ; carouselReadDot = itemView . findViewById ( R . id . carousel_read_circle ) ;", "del_tokens": "ImageView readDot ;", "commit_type": "add"}
{"commit_tokens": ["fixed", "reading", "of", "value", "type"], "add_tokens": "import org . neo4j . driver . internal . types . TypeRepresentation ; TypeRepresentation type = ( TypeRepresentation ) value . type ( ) ; switch ( type . constructor ( ) ) { case LIST_TyCon : case MAP_TyCon :", "del_tokens": "switch ( value . type ( ) . name ( ) ) { case \"LIST\" : case \"MAP\" :", "commit_type": "fix"}
{"commit_tokens": ["Add", "some", "JavaDoc", "and", "enhance", "README"], "add_tokens": "* This class is used by the RequestLoggerFilter to dump request body into a byte buffer . * The byte buffer is then used to build a ServletInputStream for the HttpServletRequest it wraps . * /", "del_tokens": "* Created with IntelliJ IDEA . * User : slemesle * Date : 20 / 09 / 13 * Time : 10 : 33 * To change this template use File | Settings | File Templates . * /", "commit_type": "add"}
{"commit_tokens": ["Fixed", "UTF", "-", "8", "problems"], "add_tokens": "@ SuppressWarnings ( \"deprecation\" ) // I cann't figure out what the nondeprecated solution to this is MAPPER . configure ( SerializationConfig . Feature . WRITE_NULL_PROPERTIES , false ) ; conn . setRequestProperty ( \"Content-Type\" , \"application/json; charset=utf-8\" ) ; OutputStreamWriter writer = new OutputStreamWriter ( conn . getOutputStream ( ) , \"UTF-8\" ) ;", "del_tokens": "conn . setRequestProperty ( \"Content-Type\" , \"application/json\" ) ; OutputStreamWriter writer = new OutputStreamWriter ( conn . getOutputStream ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "resolution", "of", "$", "{", "parentProject", ".", "basedir", "}", "parameter"], "add_tokens": "logger . debug ( \"pomPath: \" + pomPath . getAbsolutePath ( ) ) ; logger . debug ( \"find false\" ) ; logger . debug ( \"parentPOM: \" + parentPOM . getAbsolutePath ( ) ) ; logger . debug ( \"parentBasedir: \" + parentBasedir . getAbsolutePath ( ) ) ; logger . debug ( \"parentFound\" ) ; logger . debug ( \"parentNotFound\" ) ; logger . debug ( parent . getArtifactId ( ) ) ; if ( parentBasedir == null && parent . getParent ( ) != null ) { parentBasedir = parent . getParent ( ) . getFile ( ) ; } logger . debug ( parentBasedir . getAbsolutePath ( ) ) ;", "del_tokens": "logger . debug ( pomPath . getAbsolutePath ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["allow", "custom", "configuration", "of", "EvaluationContext"], "add_tokens": "import org . wickedsource . docxstamper . api . EvaluationContextConfigurer ; import org . wickedsource . docxstamper . el . ExpressionResolver ; ExpressionResolver expressionResolver = new ExpressionResolver ( config . getEvaluationContextConfigurer ( ) ) ; placeholderReplacer . setExpressionResolver ( expressionResolver ) ; commentProcessorRegistry . setExpressionResolver ( expressionResolver ) ; commentProcessorRegistry . registerCommentProcessor ( IReplaceWithProcessor . class , new ReplaceWithProcessor ( ) ) ;", "del_tokens": "commentProcessorRegistry . registerCommentProcessor ( IReplaceWithProcessor . class , new ReplaceWithProcessor ( ) ) ;", "commit_type": "allow"}
{"commit_tokens": ["fixed", "message", "with", "an", "ALPHA", "string"], "add_tokens": "private String version = \"0.3.4\" ; return version ; return \"Stratio Streaming\" ;", "del_tokens": "return \"ALPHA\" ; return \"Init Banner Provider\" ;", "commit_type": "fix"}
{"commit_tokens": ["Added", ":", "now", "throwing", "an", "exception", "if", "required", "main", "parameters", "are", "not", "supplied"], "add_tokens": "private ParameterDescription m_mainParameterDescription ; if ( m_mainParameterDescription != null ) { if ( m_mainParameterDescription . getParameter ( ) . required ( ) && ! m_mainParameterDescription . wasAssigned ( ) ) { throw new ParameterException ( \"Main parameters are required (\\\"\" + m_mainParameterDescription . getDescription ( ) + \"\\\")\" ) ; } } m_mainParameterDescription = new ParameterDescription ( object , p , f , m_bundle , this ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bugs", "in", "initial", "multi", "-", "threaded", "implementation", "."], "add_tokens": "int numThreads = Runtime . getRuntime ( ) . availableProcessors ( ) ;", "del_tokens": "int numThreads = 1 ; //Runtime.getRuntime().availableProcessors();", "commit_type": "fix"}
{"commit_tokens": ["Fix", "issue", "that", "after", "note", "app", "restores", "note", "list", "doesn", "t", "response", "to", "click", "event"], "add_tokens": "@ Inject AppController mAppController ; drawerLayout = ( DrawerLayout ) view . findViewById ( R . id . drawer_container ) ; //When app starts or restore, notify the app controller the original orientation switch ( reason ) { case FIRST_TIME : case RESTORE : mAppController . notifyOrientationChanged ( convertOrientation ( getResources ( ) . getConfiguration ( ) . orientation ) , convertOrientation ( getCurrentOrientation ( ) ) ) ; break ; } if ( orientation == Configuration . ORIENTATION_PORTRAIT ) { } else if ( orientation == Configuration . ORIENTATION_LANDSCAPE ) { if ( curLoc != null && curLoc . getPreviousLocation ( ) != null ) {", "del_tokens": "@ Inject AppController mAppController ; drawerLayout = ( DrawerLayout ) view . findViewById ( R . id . drawer_container ) ; mAppController . notifyOrientationChanged ( convertOrientation ( Configuration . ORIENTATION_UNDEFINED ) , convertOrientation ( getCurrentOrientation ( ) ) ) ; if ( orientation == Configuration . ORIENTATION_PORTRAIT ) { } else if ( orientation == Configuration . ORIENTATION_LANDSCAPE ) { if ( curLoc != null && curLoc . getPreviousLocation ( ) != null ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "RFC", "proxy", "the", "default", "for", "VOMS", "Proxy", "Init"], "add_tokens": "LEGACY_PROXY ( \"old\" ) ,", "del_tokens": "LEGAGY_PROXY ( \"old\" ) ,", "commit_type": "make"}
{"commit_tokens": ["removed", "pomreplacer", "added", "changes", "for", "new", "cluster", "version"], "add_tokens": "import org . restcomm . cluster . MobicentsClusterFactory ; MobicentsClusterFactory clusterFactory = SleeContainer . lookupFromJndi ( ) . getClusterFactory ( ) ; ctCluster = clusterFactory . getCluster ( getName ( ) + \"_\" + CLIENT_TRANSACTION_APPENDER ) ; stCluster = clusterFactory . getCluster ( getName ( ) + \"_\" + SERVER_TRANSACTION_APPENDER ) ; sdCluster = clusterFactory . getCluster ( getName ( ) + \"_\" + SIP_DIALOG_APPENDER ) ;", "del_tokens": "cluster = SleeContainer . lookupFromJndi ( ) . getCluster ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["added", ".", "idea", "folder", "to", ".", "gitignore", "."], "add_tokens": "* @ return string value of flow context or null if flow context field is null if ( null == this . flowContext ) { return null }", "del_tokens": "* @ return string value of flow context", "commit_type": "add"}
{"commit_tokens": ["Allow", "creating", "Transfers", "add", "Recipient", "object", "."], "add_tokens": "objectMap . put ( \"dispute\" , Dispute . class ) ; objectMap . put ( \"recipient\" , Recipient . class ) ; }", "del_tokens": "objectMap . put ( \"dispute\" , Dispute . class ) ; }", "commit_type": "allow"}
{"commit_tokens": ["Fix", "selective", "ack", "for", "messages", "to", "the", "master", "."], "add_tokens": "import com . google . common . base . Optional ; final Optional < UPID > pid = statusUpdateMessage . hasPid ( ) ? Optional . of ( UPID . create ( statusUpdateMessage . getPid ( ) ) ) : Optional . < UPID > absent ( ) ; final boolean noAckRequired = envelope . getSender ( ) . equals ( context . getDriverUPID ( ) ) || pid . isPresent ( ) && pid . get ( ) . equals ( context . getDriverUPID ( ) ) ; eventBus . post ( new RemoteMessageEnvelope ( context . getDriverUPID ( ) , context . getMasterUPID ( ) , statusUpdateAcknowledgementMessage ) ) ;", "del_tokens": "final boolean noAckRequired = envelope . getSender ( ) . equals ( context . getDriverUPID ( ) ) || envelope . getSender ( ) . equals ( context . getMasterUPID ( ) ) ; final UPID pid = UPID . create ( statusUpdateMessage . getPid ( ) ) ; eventBus . post ( new RemoteMessageEnvelope ( context . getDriverUPID ( ) , pid , statusUpdateAcknowledgementMessage ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "Interrupt", "handling", "and", "related", "tests"], "add_tokens": "logger . debug ( \"Interrupted: \" , e ) ;", "del_tokens": "logger . trace ( \"Interrupted: \" , e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "db", "close", "()", "calls"], "add_tokens": "Cursor cursor = db . rawQuery ( builder . toString ( ) , args ) ; result = new ArrayList < Link > ( ) ; if ( cursor . moveToFirst ( ) ) { String child = cursor . getString ( 0 ) ; String childContentType = cursor . getString ( 1 ) ; do { result . add ( new Link ( parent , child , field . name ( ) , childContentType ) ) ; } while ( cursor . moveToNext ( ) ) ; cursor . close ( ) ;", "del_tokens": "Cursor cursor = db . rawQuery ( builder . toString ( ) , args ) ; result = new ArrayList < Link > ( ) ; try { if ( cursor . moveToFirst ( ) ) { String child = cursor . getString ( 0 ) ; String childContentType = cursor . getString ( 1 ) ; do { result . add ( new Link ( parent , child , field . name ( ) , childContentType ) ) ; } while ( cursor . moveToNext ( ) ) ; } } finally { cursor . close ( ) ; db . close ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["move", "to", "base", "pom", "18"], "add_tokens": "import com . nesscomputing . server . StandaloneServer ; import com . nesscomputing . server . templates . BasicDiscoveryServerModule ; @ Override protected String getServerType ( ) { return \"event\" ; } install ( new BasicDiscoveryServerModule ( config ) ) ;", "del_tokens": "import com . nesscomputing . httpserver . standalone . StandaloneServer ; import com . nesscomputing . jersey . BasicJerseyServerModule ; install ( new BasicJerseyServerModule ( config ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Make", "sure", "SMTPClientFutureImpl", "is", "thread", "-", "safe", "in", "all", "cases"], "add_tokens": "import java . util . concurrent . atomic . AtomicReference ; * Basic { @ link SMTPClientFuture } implementation * private final AtomicReference < E > result = new AtomicReference < E > ( ) ; * Set the < code > E < / code > for the future and notify all waiting threads + the listeners . * public void setResult ( E result ) { fireListeners = this . result . compareAndSet ( null , result ) ; return result . get ( ) ;", "del_tokens": "* Basic { @ link SMTPClientFuture } implementation private volatile E result ; * Set the < code > E < / code > for the future and notify all waiting threads + the listeners . This should get called only on time , * otherwise it will throw an { @ link IllegalStateException } * public void setDeliveryStatus ( E result ) { this . result = result ; fireListeners = true ; return result ;", "commit_type": "make"}
{"commit_tokens": ["fix", "several", "issues", "including", "map", "of", "object"], "add_tokens": "//TODO: change this!!! it's bad... /* This one does the trick but it is going to be slow to convert json -> map -> json */ // code += \"System.out.println(\\\"=======>0:\\\"+zapposJson.toJson((Map)_m1));\\n\"; // code += \"System.out.println(\\\"=======>1:\\\"+_m1);\\n\"; // code += \"System.out.println(\\\"=======>2:\\\"+zapposJson.toJson((Map)_m1));\\n\";", "del_tokens": "//TODO: change this it's bad /* This do the trick but it is going to be slow to convert json -> map -> json */ code += \"System.out.println(\\\"=======>1:\\\"+_m1);\\n\" ; code += \"System.out.println(\\\"=======>2:\\\"+zapposJson.toJson((Map)_m1));\\n\" ;", "commit_type": "fix"}
{"commit_tokens": ["Making", "sure", "several", "custom", "issue", "patterns", "can", "be", "set", "with", "API"], "add_tokens": "public GitChangelogApi withCustomIssue ( String name , String pattern , String link ) { settings . getCustomIssues ( ) . add ( new CustomIssue ( name , pattern , link ) ) ;", "del_tokens": "import static com . google . common . collect . Lists . newArrayList ; public GitChangelogApi withCustomIssues ( String name , String pattern , String link ) { settings . setCustomIssues ( newArrayList ( new CustomIssue ( name , pattern , link ) ) ) ;", "commit_type": "make"}
{"commit_tokens": ["use", "absolute", "paths", "of", "files", "to", "prevent", "false", "equals"], "add_tokens": "//Convert the files to absolute paths to prevent that equals returns true for files with the same name in a different location. this . source = source . getAbsoluteFile ( ) ; this . destination = destination . getAbsoluteFile ( ) ;", "del_tokens": "this . source = source ; this . destination = destination ;", "commit_type": "use"}
{"commit_tokens": ["Added", "documentation", "for", "Parser", ".", "stringEndingWith", "(", "...", ")"], "add_tokens": "/ * * * Tells the parser that there is a String at the current position , ending with the specified pattern . * @ param ending String pattern describing the ending of this string . * @ param sParser Special String parser to convert said String into some other type of Object * @ param property Target bean PropertyDestination to which to apply this relation . * @ param includeEndingWhenReading * @ since Dec 10 , 2013 * /", "del_tokens": "//TODO: Documentation", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "centralized", "validation", "errors", "."], "add_tokens": "protected String _code ; public NaaccrValidationError ( String code , Object ... msgValues ) { _message = NaaccrErrorUtils . getValidationError ( code , msgValues ) ; } public String getCode ( ) { return _code ; } public void setCode ( String code ) { _code = code ; } throw new RuntimeException ( \"Forbidden method, use the constructor along with the NaaccrValidationErrorUtils class!\" ) ;", "del_tokens": "_message = message ;", "commit_type": "add"}
{"commit_tokens": ["added", "more", "width", "objects", "worked", "on", "documentation"], "add_tokens": "at . addRow ( \"first\" , \"information\" ) ; at . addRow ( \"second\" , \"info\" ) ; at . addRow ( \"first\" , \"information\" ) . setPadding ( new int [ ] { 2 , 3 } ) ; at . addRow ( \"second\" , \"info\" ) . setPadding ( new int [ ] { 3 , 4 } ) ; * 17 for the second column ( longest word : information plus padding of 3 twice ) .", "del_tokens": "* < li > < / li > at . addRow ( \"first row (col1)\" , \"with some information (col2)\" ) ; at . addRow ( \"second row (col1)\" , \"with some information (col2)\" ) ; at . addRow ( \"first row (col1)\" , \"with some information (col2)\" ) . setPadding ( new int [ ] { 2 , 3 } ) ; at . addRow ( \"second row (col1)\" , \"with some information (col2)\" ) . setPadding ( new int [ ] { 3 , 4 } ) ; * 19 for the second column ( longest word : information plus padding of 4 twice ) .", "commit_type": "add"}
{"commit_tokens": ["Changed", "a", "few", "more", "things", "to", "uppercase", "."], "add_tokens": "String sQuery = \"SELECT MAX(CHAN_ID)+1 FROM PORTAL_CHANNELS\" ; status = setChannelCats ( req , nextID , con ) ; public boolean setChannelCats ( HttpServletRequest req , int id , Connection con ) out . println ( \"<td width=\\\"71%\\\" height=\\\"37\\\"><font size=\\\"2\\\">\" + rs . getString ( \"DESCR\" ) + \"</font></td>\" ) ; String sChanId = req . getParameter ( \"CHAN_ID\" ) ;", "del_tokens": "String sQuery = \"SELECT max(chan_id)+1 FROM PORTAL_CHANNELS\" ; status = setChannelCats ( req , nextID ) ; public boolean setChannelCats ( HttpServletRequest req , int id ) Connection con = null ; con = rdbmService . getConnection ( ) ; out . println ( \"<td width=\\\"71%\\\" height=\\\"37\\\"><font size=\\\"2\\\">\" + rs . getString ( \"DESC\" ) + \"</font></td>\" ) ; String sChanId = req . getParameter ( \"chan_id\" ) ;", "commit_type": "change"}
{"commit_tokens": ["create", "the", "validationService", "in", "constructor", "and", "let", "the", "constructors", "call", "each", "other", "."], "add_tokens": "private YubicoValidationService validationService ; validationService = new YubicoValidationService ( ) ; this ( ) ; this ( id ) ; this ( id , key ) ; YubicoResponse response = validationService . fetch ( validationUrls , userAgent ) ;", "del_tokens": "this . clientId = id ; this . clientId = id ; setKey ( key ) ; YubicoResponse response = new YubicoValidationService ( ) . fetch ( validationUrls , userAgent ) ;", "commit_type": "create"}
{"commit_tokens": ["fix", "issue", "with", "asm", "verison", "issue", "detection", "and", "jooq"], "add_tokens": "this ( AsmHelper . isAsmPresent ( ) ) ;", "del_tokens": "this ( true ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "shared", "queue", "affinity", "strategy"], "add_tokens": "private ASharedQueueAffinityStrategy sharedQueueAffinityStrategy = ASharedQueueAffinityStrategy . createDefault ( ) ; public AThreadPoolBuilder withSharedQueueAffinityStrategy ( ASharedQueueAffinityStrategy sharedQueueAffinityStrategy ) { this . sharedQueueAffinityStrategy = sharedQueueAffinityStrategy ; return this ; } return new AThreadPoolImpl ( isDaemon , threadNameFactory , exceptionHandler , numThreads , localQueueSize , numSharedQueues , checkShutdownOnSubmission , sharedQueueFactory , ownLocalFifoInterval , numPrefetchLocal , skipLocalWorkInterval , switchScharedQueueInterval , sharedQueueAffinityStrategy ) ;", "del_tokens": "return new AThreadPoolImpl ( isDaemon , threadNameFactory , exceptionHandler , numThreads , localQueueSize , numSharedQueues , checkShutdownOnSubmission , sharedQueueFactory , ownLocalFifoInterval , numPrefetchLocal , skipLocalWorkInterval , switchScharedQueueInterval ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "package", "names", ".", "Added", "license", "file"], "add_tokens": "package com . alexnederlof . jasperreport ;", "del_tokens": "package de . enovationbtc . jasperreport ;", "commit_type": "update"}
{"commit_tokens": ["Added", "close", "and", "onClose", "code", "and", "commented", "it", "out", "for", "later", "use"], "add_tokens": "private static final Logger LOGGER = LoggerFactory . getLogger ( WSServerRunner . class ) ; inbound . context ( ) . onClose ( ( ) -> LOGGER . info ( \"Byte byte\" ) ) ; // return outbound // .options(NettyPipeline.SendOptions::flushOnEach) // .sendObject(new CloseWebSocketFrame(1000, \"Byte byte\")) // .then(); . sendObject ( receiveFlux ) . then ( ) ; . initialBufferSize ( 8192 ) ) . startAndAwait ( handler ) ;", "del_tokens": "public static final Logger LOGGER = LoggerFactory . getLogger ( WSServerRunner . class ) ; . sendObject ( receiveFlux ) ; . initialBufferSize ( 8192 ) . preferNative ( false ) ) . startAndAwait ( handler ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "javadoc", "to", "ImageLoaderFactory", "and", "organize", "some", "methods"], "add_tokens": "* Provides ImageLoader instances based on third party libraries . An example could be * PicassoImageLoader , an ImageLoader implementation based on Picasso , a third party library * implemented by Square .", "del_tokens": "* Provides ImageLoader instances based on third party libraries .", "commit_type": "add"}
{"commit_tokens": ["Fixing", "broken", "unit", "test", "testWrite", "()"], "add_tokens": "BatchPoints batchPoints = BatchPoints . database ( dbName ) . tag ( \"async\" , \"true\" ) . retentionPolicy ( \"default\" ) . build ( ) ; Query query = new Query ( \"SELECT * FROM cpu GROUP BY *\" , dbName ) ;", "del_tokens": "BatchPoints batchPoints = BatchPoints . database ( dbName ) . time ( System . currentTimeMillis ( ) , TimeUnit . MILLISECONDS ) . tag ( \"async\" , \"true\" ) . retentionPolicy ( \"default\" ) . build ( ) ; Query query = new Query ( \"SELECT * FROM cpu\" , dbName ) ;", "commit_type": "fix"}
{"commit_tokens": ["use", "apache", "commons", "check", "routines", "for", "EMail", "and", "Url", "instead", "of", "own", "regex"], "add_tokens": "* * return org . apache . commons . validator . routines . EmailValidator . getInstance ( ) . isValid ( pvalue ) ; // return pvalue.matches(EMAIL_PATTERN);", "del_tokens": "* * / * * * regular expression to check eMails . * / private static final String EMAIL_PATTERN = \"^(([A-Za-z0-9]+_+)|([A-Za-z0-9]+\\\\-+)|([A-Za-z0-9]+\\\\.+)|\" + \"([A-Za-z0-9]+\\\\++))*[A-Za-z0-9]+@((\\\\w+\\\\-+)|(\\\\w+\\\\.))*\\\\w{1,63}\\\\.[a-zA-Z]{2,6}$\" ; return pvalue . matches ( EMAIL_PATTERN ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "display", "issue", "occurring", "after", "loading", "a", "previously", "saved"], "add_tokens": "private int addToTree ( Tree displayTree , TaskNode parentNode , Task < T > task , IntArray taskSteps , int taskStepIndex ) { taskStepIndex ++ ; taskStepIndex = addToTree ( displayTree , node , child , taskSteps , taskStepIndex ) ; return taskStepIndex ; // System.out.println(output.total());", "del_tokens": "private void addToTree ( Tree displayTree , TaskNode parentNode , Task < T > task , IntArray taskSteps , int taskStepIndex ) { addToTree ( displayTree , node , child , taskSteps , taskStepIndex + 1 ) ; System . out . println ( output . total ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "utf8", "encoding", "of", "tags", "in", "requests"], "add_tokens": "import org . jinstagram . http . URLUtils ; String apiMethod = String . format ( Methods . TAGS_RECENT_MEDIA , URLUtils . encodeURIComponent ( tagName ) ) ;", "del_tokens": "String apiMethod = String . format ( Methods . TAGS_RECENT_MEDIA , tagName ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "thread", "pool", "static", "and", "provide", "convenience", "wrappers"], "add_tokens": "assertNotNull ( new InetUtils ( new InetUtilsProperties ( ) ) . findFirstNonLoopbackHostInfo ( ) ) ; assertNotNull ( new InetUtils ( new InetUtilsProperties ( ) ) . findFirstNonLoopbackAddress ( ) ) ; assertNotNull ( new InetUtils ( new InetUtilsProperties ( ) ) . convertAddress ( InetAddress . getByName ( \"localhost\" ) ) ) ;", "del_tokens": "assertNotNull ( new InetUtils ( new InetUtilsProperties ( ) ) . findFirstNonLoopbackHostInfo ( ) ) ; assertNotNull ( InetUtils . getFirstNonLoopbackHostInfo ( ) ) ; assertNotNull ( new InetUtils ( new InetUtilsProperties ( ) ) . findFirstNonLoopbackAddress ( ) ) ; assertNotNull ( InetUtils . getFirstNonLoopbackAddress ( ) ) ; assertNotNull ( new InetUtils ( new InetUtilsProperties ( ) ) . convertAddress ( InetAddress . getByName ( \"localhost\" ) ) ) ; info = InetUtils . getFirstNonLoopbackHostInfo ( ) ; assertNotNull ( info . getIpAddressAsInt ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "customized", "ObjectMapper", "to", "fix", "parsing", "problems", ".", "(", "no", "squish", ")"], "add_tokens": "public class DiseaseVersion {", "del_tokens": "public class DiseaseVersionBean {", "commit_type": "add"}
{"commit_tokens": ["Add", "property", "model", "for", "OrientDB", "documents"], "add_tokens": "public class EmbeddOrientDbApplicationListener implements IApplicationListener { public EmbeddOrientDbApplicationListener ( ) public EmbeddOrientDbApplicationListener ( File configFile ) public EmbeddOrientDbApplicationListener ( String config ) public EmbeddOrientDbApplicationListener ( OServerConfiguration serverConfiguration )", "del_tokens": "public class EmbeddOrientDBApplicationListener implements IApplicationListener { public EmbeddOrientDBApplicationListener ( ) public EmbeddOrientDBApplicationListener ( File configFile ) public EmbeddOrientDBApplicationListener ( String config ) public EmbeddOrientDBApplicationListener ( OServerConfiguration serverConfiguration )", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "timezone", "obtaining"], "add_tokens": "} catch ( RuntimeException ignored ) { if ( cDefault == null ) { cDefault = getInstance ( java . util . TimeZone . getDefault ( ) ) ; } } catch ( IllegalArgumentException ignored ) {", "del_tokens": "} catch ( RuntimeException e ) { cDefault = getInstance ( java . util . TimeZone . getDefault ( ) ) ; } catch ( IllegalArgumentException e ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "field", "for", "the", "radius", "of", "the", "color", "wheel"], "add_tokens": "/ * * * Radius of the color wheel in pixels . * * < p > Note : ( Re ) calculated in { @ link # onMeasure ( int , int ) } . < / p > * / private float mColorWheelRadius ; colorWheelRectangle . set ( - mColorWheelRadius , - mColorWheelRadius , mColorWheelRadius , mColorWheelRadius ) ; mPointerPosition [ 1 ] = - mColorWheelRadius ; radians = ( ( min - getPaddingLeft ( ) - getPaddingRight ( ) ) * 0.5f ) ; mColorWheelRadius = radians - mPointerSize ;", "del_tokens": "radians = ( ( getWidth ( ) - getPaddingLeft ( ) - getPaddingRight ( ) ) * 0.5f ) ; colorWheelRectangle . set ( - radians + mPointerSize , - radians + mPointerSize , radians - mPointerSize , radians - mPointerSize ) ; mPointerPosition [ 1 ] = - radians + mPointerSize ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "swizzle", "stream", "and", "replace", "with", "per", "-", "put", "property", "interpolation"], "add_tokens": "public static final Pattern ARRAY_PROPERTY_REGEX = Pattern . compile ( \"(.*?)\\\\[\\\\d*?\\\\](\\\\}?)$\" ) ; public static final Pattern ARRAY_REFERENCE_REGEX = Pattern . compile ( \"(\\\\$\\\\{)?(.*?)\\\\[last\\\\](.*)$\" ) ; prev . load ( in ) ;", "del_tokens": "import org . codehaus . swizzle . stream . ReplaceVariablesInputStream ; public static final Pattern ARRAY_PROPERTY_REGEX = Pattern . compile ( \"(.*?)\\\\[\\\\d*?\\\\]$\" ) ; public static final Pattern ARRAY_REFERENCE_REGEX = Pattern . compile ( \"(.*?)\\\\[last\\\\](.*)$\" ) ; Map < String , String > tokens = prev . backingTable ( ) ; prev . load ( new ReplaceVariablesInputStream ( in , \"${\" , \"}\" , tokens ) ) ;", "commit_type": "remove"}
{"commit_tokens": ["Make", "Options", "a", "true", "Map", ";", "don", "t", "require", "Options", "for", "public", "API", "methods", "."], "add_tokens": "public void registerHttpHandler ( String context , HttpHandler httpHandler , Map < String , Object > opts ) { Options options = new Options ( opts ) ; if ( options . containsKey ( \"static_dir\" ) ) { public void registerServlet ( String context , Class servletClass , Map < String , Object > opts ) { Options options = new Options ( opts ) ;", "del_tokens": "public void registerHttpHandler ( String context , HttpHandler httpHandler , Options options ) { if ( options != null && options . containsKey ( \"static_dir\" ) ) { public void registerServlet ( String context , Class servletClass , Options options ) {", "commit_type": "make"}
{"commit_tokens": ["Fix", "for", "issue", "31", "(", "Java", "Json", ".", "Object", "and", "Json", ".", "Array", "don", "t", "handle", "missing", "array", "/", "object", "values", ")"], "add_tokens": "JSONObject o = jso . optJSONObject ( key ) ; return o == null ? null : new JavaObject ( o ) ; JSONArray a = jso . optJSONArray ( key ) ; return a == null ? null : new JavaArray ( a ) ; JSONObject o = jsa . optJSONObject ( index ) ; return o == null ? null : new JavaObject ( o ) ; JSONArray a = jsa . optJSONArray ( index ) ; return a == null ? null : new JavaArray ( a ) ;", "del_tokens": "return new JavaObject ( jso . optJSONObject ( key ) ) ; return new JavaArray ( jso . optJSONArray ( key ) ) ; return new JavaObject ( jsa . optJSONObject ( index ) ) ; return new JavaArray ( jsa . optJSONArray ( index ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "IncrementalArrayData", "never", "loaded", "the", "next", "chunk", "if", "look", "ahead", "was", "zero"], "add_tokens": "if ( ( flags & FLAG_PRESENTATION ) != 0 && position >= size ( ) - 1 - mLookAheadRowCount ) {", "del_tokens": "if ( ( flags & FLAG_PRESENTATION ) != 0 && position >= size ( ) - mLookAheadRowCount ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "servletPath", "because", "model", "is", "a", "high", "level", "concept", "independent", "of", "servlet", "implementation", "."], "add_tokens": "* Copyright ( C ) 2016 , 2017 AO Industries , Inc . String servletPath = pageRef . getBookRef ( ) . getPrefix ( ) + pageRef . getPath ( ) ;", "del_tokens": "* Copyright ( C ) 2016 AO Industries , Inc . String servletPath = pageRef . getServletPath ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["adding", "parameter", "to", "stop", "meaning", "stop", "current", "and", "remove", "all", "functions"], "add_tokens": "dequeueCurrentAndRunNext ( e ) ; * from the queue and start the next one . return stop ( false ) ; } / * * * Stop the function which is currently in execution and depending * on the value of the parameter : * - remove it from the queue and start the next one . * - or remove all functions in the queue . * / @ SuppressWarnings ( \"unchecked\" ) public T stop ( boolean clearQueue ) { stop ( e , clearQueue ) ; private void dequeueCurrentAndRunNext ( Element elem ) { // Remove current function // Run the next in the queue private void stop ( Element elem , boolean clear ) { if ( clear ) { q . clear ( ) ; } else { dequeueCurrentAndRunNext ( elem ) ; }", "del_tokens": "dequeue ( e ) ; * from the queue an start the next one . @ SuppressWarnings ( \"unchecked\" ) stop ( e ) ; private void dequeue ( Element elem ) { private void stop ( Element elem ) { dequeue ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Adds", "setCreatedWithSPI", "to", "all", "factory", "apis", "(", "factory", "makers", "still", "use", "the", "methods", "deprecated", "in", "this", "commit", ")"], "add_tokens": "/ * * * < p > Informs the implementation that it was discovered and instantiated using * information collected from a file within the < tt > META - INF / services < / tt > directory . * In other words , it was created using SPI ( service provider interfaces ) . < / p > * * < p > This information , in turn , enables the implementation to use the same mechanism * to set dependencies as needed . < / p > * * < p > If this information is < strong > not < / strong > given , an implementation * should avoid using SPIs and instead use * < a href = \"http://wiki.osgi.org/wiki/Declarative_Services\" > declarative services < / a > * for dependency injection as specified by OSGi . Note that this also applies to * several newInstance ( ) methods in the Java API . < / p > * * < p > The class that created an instance with SPI must call this method before * putting it to use . < / p > * / public void setCreatedWithSPI ( ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "automatically", "registering", "stubs", "in", "@AutoConfigureWireMock"], "add_tokens": "@ SpringBootTest ( properties = \"service.port=${wiremock.server.port}\" ) @ AutoConfigureWireMock ( port = 0 ) private LoanApplicationService service ; LoanApplicationResult loanApplication = service . loanApplication ( application ) ; LoanApplicationResult loanApplication = service . loanApplication ( application ) ;", "del_tokens": "@ SpringBootTest @ AutoConfigureWireMock private LoanApplicationService sut ; LoanApplicationResult loanApplication = sut . loanApplication ( application ) ; LoanApplicationResult loanApplication = sut . loanApplication ( application ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "issue", "when", "resolving", "unbound", "type", "variable", "defined", "on", "a", "method", "of", "a", "superclass"], "add_tokens": "if ( classThatContainsTypeVariable == null || concreteClass == classThatContainsTypeVariable ) { if ( classThatContainsTypeVariable == null ) { return resolve ( concreteClass , ( ( TypeVariable < ? > ) resolvedType ) . getBounds ( ) [ 0 ] ) ; } position = getTypeVariablePosition ( classToInspect , ( TypeVariable < ? > ) resolvedType ) ;", "del_tokens": "} else if ( typeVariable . getGenericDeclaration ( ) . getClass ( ) == Method . class ) { return ( ( Method ) typeVariable . getGenericDeclaration ( ) ) . getDeclaringClass ( ) ; } else if ( typeVariable . getGenericDeclaration ( ) . getClass ( ) == Constructor . class ) { return ( ( Constructor < ? > ) typeVariable . getGenericDeclaration ( ) ) . getDeclaringClass ( ) ; if ( concreteClass == classThatContainsTypeVariable ) { position = getTypeVariablePosition ( classToInspect , ( TypeVariable < ? > ) resolvedType ) ;", "commit_type": "fix"}
{"commit_tokens": ["Update", "example", "app", "due", "to", "Hibernate", "upgrade"], "add_tokens": "sess . beginTransaction ( ) ; sess . createNativeQuery ( \"create table people(id bigint primary key auto_increment not null, \" + sess . createNativeQuery ( \"create sequence hibernate_sequence\" ) . executeUpdate ( ) ; sess . getTransaction ( ) . commit ( ) ;", "del_tokens": "sess . createSQLQuery ( \"create table people(id bigint primary key auto_increment not null, \" + sess . createSQLQuery ( \"create sequence hibernate_sequence\" ) . executeUpdate ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fixed", "OOM", "reported", "by", "huxi", "."], "add_tokens": "out . append ( \"\\n\" ) . append ( spaces ( indent + 1 ) ) . append ( word ) ; i ++ ;", "del_tokens": "i ++ ; out . append ( \"\\n\" ) . append ( spaces ( indent ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "M3U8", "parser", "from", "CumulusTV", "to", "this", "library", "with", "appropriate", "models", "and", "documentation"], "add_tokens": ". setAppLinkColor ( mContext . getResources ( ) . getColor ( R . color . cs_blue_500 ) ) . setAppLinkIcon ( \"android.resource://com.felkertech.sample.channelsurfer/drawable/md_library_music\" ) . setAppLinkColor ( mContext . getResources ( ) . getColor ( R . color . md_red_500 ) ) . setAppLinkText ( \"Open Netflix\" ) . setAppLinkIntent ( new Intent ( \"com.netflix.ninja\" ) ) . setAppLinkIcon ( \"android.resource://com.felkertech.sample.channelsurfer/drawable/md_movies\" ) . setAppLinkColor ( mContext . getResources ( ) . getColor ( R . color . md_green_500 ) ) . setName ( \"androidtv.news\" ) / * . setAppLinkText ( \"Visit site\" ) * / . setAppLinkColor ( mContext . getResources ( ) . getColor ( R . color . md_purple_500 ) ) . setAppLinkColor ( mContext . getResources ( ) . getColor ( R . color . md_brown_500 ) )", "del_tokens": "// Toast.makeText(SampleTvInputProvider.this, \"Get all channels\", Toast.LENGTH_SHORT).show(); . setAppLinkColor ( mContext . getResources ( ) . getColor ( R . color . cs_blue_500 ) + \"\" ) . setAppLinkIcon ( mContext . getResources ( ) . getDrawable ( R . drawable . lb_ic_more ) . toString ( ) ) . setName ( \"androidtv.news\" ) // Toast.makeText(SampleTvInputProvider.this, \"Get all programs for \"+channelInfo.getName(), Toast.LENGTH_SHORT).show();", "commit_type": "add"}
{"commit_tokens": ["Use", "Java", "5", "annotations", "instead", "of", "Javadoc", "annotations", "for", "mojos", "."], "add_tokens": "import org . apache . maven . plugins . annotations . Mojo ; import org . apache . maven . plugins . annotations . Parameter ; @ Mojo ( name = FileMojo . NAME , threadSafe = true ) / * * * The mojo name . * / public static final String NAME = \"file\" ; @ Parameter ( property = \"file\" , required = true )", "del_tokens": "* @ goal file * @ threadSafe * @ parameter expression = \"${file}\" * @ required", "commit_type": "use"}
{"commit_tokens": ["add", "GET", "spot", "prices", "api"], "add_tokens": "import javax . annotation . Generated ; @ SerializedName ( \"base\" ) @ Expose private String base ; public String getBase ( ) { return base ; } public void setBase ( String base ) { this . base = base ; }", "del_tokens": "import javax . annotation . Generated ;", "commit_type": "add"}
{"commit_tokens": ["Allowed", "JSON", "service", "registry", "to", "still", "require", "REGEX_PREFIX", "for", "determining", "regex", "service", "instances", "."], "add_tokens": "if ( id . startsWith ( REGEX_PREFIX ) && isValidRegexPattern ( id ) ) {", "del_tokens": "if ( isValidRegexPattern ( id ) ) {", "commit_type": "allow"}
{"commit_tokens": ["Fix", "NullPointerException", "when", "commitCallback", "is", "null", "."], "add_tokens": "if ( commitCallback != null ) { try { commitCallback . action ( ) ; } catch ( Exception e ) { new QueujException ( e ) ; }", "del_tokens": "try { commitCallback . action ( ) ; } catch ( Exception e ) { new QueujException ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Use", "a", "subclassed", "test", "runner"], "add_tokens": "import org . robolectric . Robolectric ; @ RunWith ( RobolectricGradleTestRunner . class ) @ Config ( emulateSdk = 18 )", "del_tokens": "import org . robolectric . RobolectricTestRunner ; @ RunWith ( RobolectricTestRunner . class ) @ Config ( emulateSdk = 18 , manifest = \"example/src/main/AndroidManifest.xml\" )", "commit_type": "use"}
{"commit_tokens": ["Remove", "deep", "learning", "dependency", "from", "Model", "by", "commenting", "it", "out", "and", "breaking", "the"], "add_tokens": "// import hex.deeplearning.DeepLearningModel; // subVfr = vfr.subframe(names, (this instanceof DeepLearningModel && ((DeepLearningModel)this).get_params().sparse) ? 0 : Double.NaN); subVfr = vfr . subframe ( names , Double . NaN ) ;", "del_tokens": "import hex . deeplearning . DeepLearningModel ; subVfr = vfr . subframe ( names , ( this instanceof DeepLearningModel && ( ( DeepLearningModel ) this ) . get_params ( ) . sparse ) ? 0 : Double . NaN ) ;", "commit_type": "remove"}
{"commit_tokens": ["fix", "POLLOUT", "polling", "causes", "InvalidArgumentException"], "add_tokens": "* @ param data", "del_tokens": "* @ param string", "commit_type": "fix"}
{"commit_tokens": ["Creates", "an", "Edit", "mode", "and", "styles", "links"], "add_tokens": "", "del_tokens": "import edu . wisc . my . portlets . bookmarks . domain . Bookmark ; import edu . wisc . my . portlets . bookmarks . domain . CollectionFolder ; import edu . wisc . my . portlets . bookmarks . domain . Folder ; import edu . wisc . my . portlets . bookmarks . domain . Preferences ; final Preferences preferences = this . preferencesRequestResolver . getPreferences ( request , false ) ; if ( preferences != null ) { refData . put ( ViewConstants . OPTIONS , preferences ) ; } else { refData . put ( ViewConstants . OPTIONS , new Preferences ( ) ) ; } refData . put ( ViewConstants . COMMAND_EMPTY_BOOKMARK , new Bookmark ( ) ) ; refData . put ( ViewConstants . COMMAND_EMPTY_FOLDER , new Folder ( ) ) ; refData . put ( ViewConstants . COMMAND_AVAILABLE_COLLECTIONS , this . availableCollections ) ; refData . put ( ViewConstants . COMMAND_EMPTY_COLLECTION , new CollectionFolder ( ) ) ; if ( request . getRemoteUser ( ) == null ) { refData . put ( \"guestMode\" , true ) ; } else { refData . put ( \"guestMode\" , false ) ; }", "commit_type": "create"}
{"commit_tokens": ["Fix", "recycling", "for", "retrying", "."], "add_tokens": "cancelExistingRequest ( target ) ; Bitmap quickMemoryCacheCheck ( Object target , String path ) { cancelExistingRequest ( target ) ; if ( request . retryCancelled ) return ; private void cancelExistingRequest ( Object target ) { Request existing = targetsToRequests . remove ( target ) ; if ( existing != null ) { if ( ! existing . future . isDone ( ) ) { existing . future . cancel ( true ) ; } else { existing . retryCancelled = true ; } } } if ( cached != null ) { if ( debugging ) { request . metrics . loadedFrom = LOADED_FROM_MEM ; }", "del_tokens": "Request existing = targetsToRequests . remove ( target ) ; if ( existing != null ) { existing . future . cancel ( true ) ; } Bitmap quickMemoryCacheCheck ( String path ) { int loadedFrom = 0 ; if ( debugging && cached != null ) { request . metrics . loadedFrom = LOADED_FROM_MEM ; if ( cached != null ) { if ( debugging ) { request . metrics . loadedFrom = loadedFrom ; } }", "commit_type": "fix"}
{"commit_tokens": ["Moved", "mojos", "from", "maven", "-", "aidl", "-", "plugin", "into", "maven", "-", "android", "-", "plugin", ".", "Renamed", "moved", "goals", "to", "aidl", "*", "."], "add_tokens": "* @ goal aidlGenerate", "del_tokens": "* @ goal generate", "commit_type": "move"}
{"commit_tokens": ["adding", "invoke", "getter", "/", "setter", "support", "to", "mirror", "."], "add_tokens": "import net . vidageek . mirror . fixtures . BeanFixture ; private Field beanField ; beanField = new Mirror ( ) . on ( BeanFixture . class ) . reflect ( ) . field ( \"field\" ) ; @ Test public void testGetterInvocationInterface ( ) { new Mirror ( ) . on ( new BeanFixture ( ) ) . invoke ( ) . getterFor ( \"field\" ) ; new Mirror ( ) . on ( new BeanFixture ( ) ) . invoke ( ) . getterFor ( beanField ) ; @ Test public void testSetterInvocationInterface ( ) { new Mirror ( ) . on ( new BeanFixture ( ) ) . invoke ( ) . setterFor ( \"field\" ) . withValue ( \"12345\" ) ; new Mirror ( ) . on ( new BeanFixture ( ) ) . invoke ( ) . setterFor ( beanField ) . withValue ( \"12345\" ) ; }", "del_tokens": "public void name ( ) {", "commit_type": "add"}
{"commit_tokens": ["removed", "necessity", "to", "create", "new", "instance", "added", "functionality", "to", "put", "violations", "from", "ConstraintViolationException", "into", "checker", "."], "add_tokens": "ValidationViolationChecker . checkExpectedValidationViolations ( null , null ) ; ValidationViolationChecker . checkExpectedValidationViolations ( new HashSet < ConstraintViolation < ? > > ( ) , null ) ; ValidationViolationChecker . checkExpectedValidationViolations ( null , new ArrayList < String > ( ) ) ; ValidationViolationChecker . checkExpectedValidationViolations ( new HashSet < ConstraintViolation < ? > > ( ) , Set < ConstraintViolation < ? > > violations = new HashSet < ConstraintViolation < ? > > ( ) ; ValidationViolationChecker . checkExpectedValidationViolations ( violations , Set < ConstraintViolation < ? > > violations = new HashSet < ConstraintViolation < ? > > ( ) ; ValidationViolationChecker . checkExpectedValidationViolations ( violations ,", "del_tokens": "private ValidationViolationChecker < String > checker = new ValidationViolationChecker < String > ( ) ; checker . checkExpectedValidationViolations ( null , null ) ; checker . checkExpectedValidationViolations ( new HashSet < ConstraintViolation < String > > ( ) , null ) ; checker . checkExpectedValidationViolations ( null , new ArrayList < String > ( ) ) ; checker . checkExpectedValidationViolations ( new HashSet < ConstraintViolation < String > > ( ) , Set < ConstraintViolation < String > > violations = new HashSet < ConstraintViolation < String > > ( ) ; checker . checkExpectedValidationViolations ( violations , Set < ConstraintViolation < String > > violations = new HashSet < ConstraintViolation < String > > ( ) ; checker . checkExpectedValidationViolations ( violations ,", "commit_type": "remove"}
{"commit_tokens": ["moved", "more", "HTTPclient", "dependencies", "to", "sub", "-", "project"], "add_tokens": "import java . util . LinkedHashMap ; import com . google . common . io . ByteStreams ; import static com . google . common . net . HttpHeaders . CONTENT_ENCODING ; String contentEncoding = getHeader ( CONTENT_ENCODING ) ;", "del_tokens": "import java . util . * ; import com . google . common . io . * ; import org . apache . http . * ; String contentEncoding = getHeader ( HttpHeaders . CONTENT_ENCODING ) ;", "commit_type": "move"}
{"commit_tokens": ["add", "interconnect", "core", "and", "test", "modues"], "add_tokens": "public CryptoException ( String message ) { super ( message ) ; / * * * @ param message the exception message * @ param cause the root cause * / public CryptoException ( String message , Throwable cause ) { super ( message , cause ) ; }", "del_tokens": "* @ param cause the root cause public CryptoException ( String message , Throwable cause ) { super ( message , cause ) ;", "commit_type": "add"}
{"commit_tokens": ["fix", "no", "access", "to", "LastAnimationListener", "from", "children", "in", "different", "packages"], "add_tokens": "public class LastAnimationListener implements Animator . AnimatorListener {", "del_tokens": "protected class LastAnimationListener implements Animator . AnimatorListener {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "crash", "when", "sample", "app", "-", "Note", "starts", "from", "landscape", "orientation"], "add_tokens": "appController . notifyOrientationChanged ( convertOrientation ( Configuration . ORIENTATION_UNDEFINED ) , convertOrientation ( getCurrentOrientation ( ) ) ) ;", "del_tokens": "//When app starts or restore, notify the app controller the original orientation switch ( reason ) { case RESTORE : appController . notifyOrientationChanged ( convertOrientation ( Configuration . ORIENTATION_UNDEFINED ) , convertOrientation ( getCurrentOrientation ( ) ) ) ; break ; }", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "regeneration", "of", "credentials", "."], "add_tokens": "import java . util . HashMap ; import java . util . Map ; Assert . notNull ( parametersRequest , \"parametersRequest must not be null\" ) ; @ Override public < T > CredentialDetails < T > regenerate ( final CredentialName name ) { Assert . notNull ( name , \"credential name must not be null\" ) ; final ParameterizedTypeReference < CredentialDetails < T > > ref = new ParameterizedTypeReference < CredentialDetails < T > > ( ) { } ; return doWithRest ( new RestOperationsCallback < CredentialDetails < T > > ( ) { @ Override public CredentialDetails < T > doWithRestOperations ( RestOperations restOperations ) { Map < String , Object > request = new HashMap < String , Object > ( 2 ) ; request . put ( \"name\" , name . getName ( ) ) ; request . put ( \"regenerate\" , true ) ; ResponseEntity < CredentialDetails < T > > response = restOperations . exchange ( BASE_URL_PATH , POST , new HttpEntity < Map < String , Object > > ( request ) , ref ) ; throwExceptionOnError ( response ) ; return response . getBody ( ) ; } } ) ; }", "del_tokens": "Assert . notNull ( parametersRequest , \"generateRequest must not be null\" ) ;", "commit_type": "add"}
{"commit_tokens": ["removing", "unused", "import", "and", "formatting", "comment"], "add_tokens": "", "del_tokens": "", "commit_type": "remove"}
{"commit_tokens": ["Improving", "the", "equals", "method", "to", "compare", "URLs", "ignore", "-", "case"], "add_tokens": "assertTrue ( url . equals ( new URL ( \"tInyB://00:1a:7D:dA:71:04/CF:fC:9E:b2:0E:63/180F/2A19/leVel\" ) ) ) ;", "del_tokens": "assertTrue ( url . equals ( new URL ( raw ) ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["changed", "Gen_RunScript", "behavior", "removed", "figlets", "documentation"], "add_tokens": "// /** // * Returns the full class map of the executor. // * @return full class map, empty if no classes set // */ // Map<String, Class<? extends ExecutableService>> getClassMap(){ // return this.classmap; // } if ( svc instanceof Gen_RunScripts ) { //hook for GenRunScripts to get currrent class map - registered services ( ( Gen_RunScripts ) svc ) . setClassMap ( this . classmap ) ; } if ( svc instanceof Gen_RunScripts ) { //hook for GenRunScripts to get currrent class map - registered services ( ( Gen_RunScripts ) svc ) . setClassMap ( this . classmap ) ; }", "del_tokens": "/ * * * Returns the full class map of the executor . * @ return full class map , empty if no classes set * / Map < String , Class < ? extends ExecutableService > > getClassMap ( ) { return this . classmap ; }", "commit_type": "change"}
{"commit_tokens": ["update", "goal", "name", "of", "the", "maven", "plugin"], "add_tokens": "* @ goal run", "del_tokens": "* @ goal bundle", "commit_type": "update"}
{"commit_tokens": ["Fix", "spout", "sub", "-", "commands", "."], "add_tokens": "CC3SpoutLoader . getInstance ( ) . getEngine ( ) . getRootCommand ( ) . addSubCommand ( CC3SpoutLoader . getInstance ( ) , \"bank\" ) . setHelp ( \"Bank Related Commands\" ) . setExecutor ( this ) ; cmd = Common . getInstance ( ) . getCommandManager ( ) . getMoneyCmdList ( ) . get ( args . getString ( 0 ) ) ; cmd = Common . getInstance ( ) . getCommandManager ( ) . getBankCmdList ( ) . get ( args . getString ( 0 ) ) ;", "del_tokens": "Common . getInstance ( ) . getCommandManager ( ) . getMoneyCmdList ( ) . get ( args . getString ( 0 ) ) ; Common . getInstance ( ) . getCommandManager ( ) . getBankCmdList ( ) . get ( args . getString ( 0 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "NOT", "(", "!", ")", "from", "isdisplayed", "and", "ispresent", "filters"], "add_tokens": ". filter ( o -> o instanceof Element ) // Should check instance or field type? . filter ( o -> o instanceof Findable ) // Should check instance or field type?", "del_tokens": ". filter ( o -> ! ( o instanceof Element ) ) // Should check instance or field type? . filter ( o -> ! ( o instanceof Findable ) ) // Should check instance or field type?", "commit_type": "remove"}
{"commit_tokens": ["add", "Authentication", "failed", "alert", "on", "login", "failed"], "add_tokens": "request . getSession ( ) . setAttribute ( \"error\" , \"Access denied\" ) ; Map < String , Object > model = new HashMap < String , Object > ( ) ; String error = ( String ) request . getSession ( ) . getAttribute ( \"error\" ) ; request . getSession ( ) . removeAttribute ( \"error\" ) ; if ( error != null ) { model . put ( \"error\" , error ) ; } response . render ( \"crud/login.ftl\" , model ) ; request . getSession ( ) . setAttribute ( \"error\" , \"Authentication failed\" ) ;", "del_tokens": "response . render ( \"crud/login.ftl\" ) ;", "commit_type": "add"}
{"commit_tokens": ["move", "test", "case", "to", "the", "same", "package", "as", "the", "rule", "it", "tests"], "add_tokens": "package de . danielnaber . languagetool . rules ;", "del_tokens": "package de . danielnaber . languagetool . rules . en ;", "commit_type": "move"}
{"commit_tokens": ["Added", "Context", "parameter", "on", "RxBleDevice", ".", "establishConnection", "()"], "add_tokens": "import android . content . Context ; Observable < RxBleConnection > establishConnection ( Context context ) ; String getName ( ) ;", "del_tokens": "Observable < RxBleConnection > establishConnection ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Updated", "documentation", ";", "fixed", "compiler", "warnings", "."], "add_tokens": "* @ see java . util . Properties", "del_tokens": "* @ see Properties", "commit_type": "update"}
{"commit_tokens": ["Implement", "all", "list", "commands", ".", "No", "unit", "tests", "yet", "."], "add_tokens": "@ Override public String lset ( String key , long index , String element ) throws WrongTypeException , NoKeyException , IndexOutOfRangeException , NotImplementedException {", "del_tokens": "@ Override public String lset ( String key , long index , String element ) throws WrongTypeException , NotImplementedException {", "commit_type": "implement"}
{"commit_tokens": ["Remove", "ProxyElementSelection", "and", "redundancy", "in", "InvocationHandlers"], "add_tokens": "* @ see com . redhat . darcy . ui . elements . LazyElement * @ see com . redhat . darcy . ui . elements . Elements * @ see com . redhat . darcy . ui . AbstractView", "del_tokens": "import com . redhat . darcy . DarcyException ; import javax . annotation . Nullable ; * @ see LazyElement * @ see ProxyElementSelection this ( type , locator , null ) ; } public ElementInvocationHandler ( Class < ? extends Element > type , Locator locator , @ Nullable ElementContext context ) { this . context = context ;", "commit_type": "remove"}
{"commit_tokens": ["add", "licences", "and", "some", "javadocs"], "add_tokens": "/ * * * JBoss , Home of Professional Open Source * Copyright Red Hat , Inc . , and individual contributors * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * /", "del_tokens": "/ * * * Created with IntelliJ IDEA . * User : sebastien * Date : 6 / 10 / 13 * Time : 6 : 25 PM * To change this template use File | Settings | File Templates . * /", "commit_type": "add"}
{"commit_tokens": ["Made", "fingerprinting", "algorithms", "configurable", "."], "add_tokens": "import com . redhat . victims . VictimsConfig ; for ( Algorithms algorithm : VictimsConfig . algorithms ( ) ) {", "del_tokens": "for ( Algorithms algorithm : Algorithms . values ( ) ) {", "commit_type": "make"}
{"commit_tokens": ["Add", "the", "option", "to", "keep", "downloaded", "data", "on", "failure", ".", "An", "optional", "setter", "is", "used", "to", "maintain", "API", "backward", "compatibility", ".", "A", "default", "value", "is", "used", "to", "maintain", "behavior", "backward", "compatibility", "."], "add_tokens": "if ( mRequest . getDeleteOnFailure ( ) ) cleanupDestination ( ) ;", "del_tokens": "cleanupDestination ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "an", "option", "for", "Kafka", "replication", "factor", "into", "samoa", "-", "samza", ".", "properties"], "add_tokens": "private int kafkaReplicationFactor ; SystemsUtils . createKafkaTopic ( systemStream . getStream ( ) , systemStream . getParallelism ( ) , kafkaReplicationFactor ) ; public SamzaEngine setKafkaReplicationFactor ( int replicationFactor ) { this . kafkaReplicationFactor = replicationFactor ; return this ; } public SamzaEngine setKafkaProducerType ( String type ) { this . kafkaProducerType = type ; return this ; }", "del_tokens": "SystemsUtils . createKafkaTopic ( systemStream . getStream ( ) , systemStream . getParallelism ( ) ) ; public SamzaEngine setKafkaProducerType ( String type ) { this . kafkaProducerType = type ; return this ; }", "commit_type": "add"}
{"commit_tokens": ["adding", "rap", "apis", "-", "no", "tests"], "add_tokens": "@ SerializedName ( value = \"invoices\" , alternate = { \"orders\" , \"payouts\" , \"payment_requests\" } )", "del_tokens": "@ SerializedName ( value = \"invoices\" , alternate = { \"orders\" , \"payouts\" } )", "commit_type": "add"}
{"commit_tokens": ["added", "javadoc", "rule", "description", "and", "rule", "message"], "add_tokens": "* DefinitionListContainsItemsRule ensures that every definition list < code > & lt ; dl / & gt ; < / code > within the given HTML * document contains one or more definition terms < code > & lt ; dt / & gt ; < / code > and definition descriptions < code > & lt ; dd * / & gt ; < / code > . private static final String RULE_MESSAGE = \"Definition lists should always have one or more list items.\" ;", "del_tokens": "* TODO document rule private static final String RULE_MESSAGE = \"Some message!\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "NullThread", "to", "the", "server"], "add_tokens": "if ( thread != null ) pool . execute ( thread ) ;", "del_tokens": "private Thread runningThread = null ; synchronized ( this ) { this . runningThread = Thread . currentThread ( ) ; } pool . execute ( thread ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "preserveAspectRatio", "on", "the", "<svg", ">", "element", ".", "Added", "test", "case", "for", "it", "from", "the", "spec", ".", "Still", "need", "to", "add", "support", "for", "the", "overflow", "style", "attribute", "though", "."], "add_tokens": "public enum AspectRatioAlignment protected interface HasPreserveAspectRatio public void setPreserveAspectRatio ( AspectRatioAlignment alignment , boolean slice ) ; } protected static class Svg extends SvgContainer implements HasViewBox , HasPreserveAspectRatio { public Length x ; public Length y ; public Length width ; public Length height ; public Box viewBox ; public AspectRatioAlignment preserveAspectRatioAlignment = null ; public boolean preserveAspectRatioSlice ; @ Override public void setPreserveAspectRatio ( AspectRatioAlignment alignment , boolean slice ) { this . preserveAspectRatioAlignment = alignment ; this . preserveAspectRatioSlice = slice ; }", "del_tokens": "public enum AspectRatioRule protected static class Svg extends SvgContainer implements HasViewBox public Length width ; public Length height ; public Box viewBox ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "queues", "in", "/", "api", "/", "definitions"], "add_tokens": "private List < QueueInfo > queues = new ArrayList < QueueInfo > ( ) ; public List < QueueInfo > getQueues ( ) { return queues ; } public void setQueues ( List < QueueInfo > queues ) { this . queues = queues ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["add", "Map", "generic", "to", "Events"], "add_tokens": "private Events ( ) { } public void dispatch ( String eventName , Map eventArgs , AsyncCallback < Map > callback )", "del_tokens": "public void dispatch ( String eventName , Map eventArgs , AsyncCallback callback )", "commit_type": "add"}
{"commit_tokens": ["fixed", "output", "for", "age", "from", "ms", "to", "seconds", "."], "add_tokens": "req . setAttribute ( \"currentIntervalUpdateAge\" , ( System . currentTimeMillis ( ) - currentIntervalUpdateTimestamp ) / 1000 + \" seconds\" ) ;", "del_tokens": "req . setAttribute ( \"currentIntervalUpdateAge\" , ( System . currentTimeMillis ( ) - currentIntervalUpdateTimestamp ) / 1000 + \" ms\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "for", "camera", "capture", "not", "working", "on", "APIs", "24", "+"], "add_tokens": "import android . os . Build ; import android . support . v4 . content . FileProvider ; Uri uriForCamera ; if ( Build . VERSION . SDK_INT < Build . VERSION_CODES . LOLLIPOP ) { // There are compatibility issues with FileProvider Uris on lower versions uriForCamera = Uri . fromFile ( imageFile ) ; } else { uriForCamera = FileProvider . getUriForFile ( mActivity , \"com.onegravity.rteditor.fileprovider\" , imageFile ) ; } . putExtra ( MediaStore . EXTRA_OUTPUT , uriForCamera ) ;", "del_tokens": ". putExtra ( MediaStore . EXTRA_OUTPUT , Uri . fromFile ( imageFile ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "hash", "key", "constant", "in", "scan", "operator"], "add_tokens": "result . setLastEvaluatedKey ( new Key ( item . get ( this . tables . get ( request . getTableName ( ) ) . getHashKeyName ( ) ) ) ) ;", "del_tokens": "result . setLastEvaluatedKey ( new Key ( item . get ( \"id\" ) ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixing", "out", "-", "of", "-", "date", "dependency", "versions"], "add_tokens": "String version = \"2.9\" ; version = p . getProperty ( \"version\" , \"2.9\" ) ;", "del_tokens": "String version = \"2.8\" ; version = p . getProperty ( \"version\" , \"2.8\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "to", "use", "AccrueType", "."], "add_tokens": "case ACCRUE_AT : { set ( x , new AccrueType ( field ) ) ; break ; } * The options are : Start , End and Prorated ( Default ) * @ param type accrue type public void setAccrueAt ( AccrueType type ) set ( ACCRUE_AT , type ) ; * @ return accrue type public AccrueType getAccrueAt ( ) return ( ( AccrueType ) get ( ACCRUE_AT ) ) ;", "del_tokens": "* The options are : Start , End and Proraetd ( Default ) * @ param val percentage value * @ see # ACCRUE_AT Constants public void setAccrueAt ( String val ) set ( ACCRUE_AT , val ) ; * @ return percentage value * @ see # ACCRUE_AT Constants public String getAccrueAt ( ) return ( ( String ) get ( ACCRUE_AT ) ) ;", "commit_type": "update"}
{"commit_tokens": ["implemented", "a", "change", "for", "protocol", "65", "to", "QUERY_FILE_EXISTS", "-", "storage", "group", "is", "now", "optional"], "add_tokens": "* the name of the storage group to check ( starting with version * 65 , this can be < code > null < / code > , in which case the default * group will be used )", "del_tokens": "* the name of the storage group to check", "commit_type": "implement"}
{"commit_tokens": ["fixed", "new", "file", "name", "inconsistency"], "add_tokens": "newFolder = new File ( _currentDir , \"New folder (\" + i + ')' ) ;", "del_tokens": "newFolder = new File ( _currentDir , \"New Folder (\" + i + ')' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "tests", "for", "PPO", "indicator"], "add_tokens": "ticks . add ( new MockTick ( new DateTime ( ) . withMillisOfSecond ( i ) , data [ i ] ) ) ;", "del_tokens": "ticks . add ( new MockTick ( new DateTime ( ) . withMillisOfSecond ( i ) , data [ i ] ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "the", "kafka", "service", "api", "cleaner"], "add_tokens": "abstract class KafkaAction < T , K , V > implements ResilientAction < T > { protected final ProducerRecord < K , V > record ; protected RecordMetadata recordMetadata ;", "del_tokens": "public class KafkaAction < T , K , V > implements ResilientAction < T > { private final ProducerRecord < K , V > record ; private RecordMetadata recordMetadata ; @ Override public T run ( ) throws Exception { return null ; }", "commit_type": "make"}
{"commit_tokens": ["Add", "sample", "consumer", "for", "cxf", "service", ".", "Consumer", "demonstrate", "using", "of"], "add_tokens": "import java . io . IOException ; public EndpointResolver ( QName serviceName , String locatorEndpoints ) { try { lc = new LocatorClient ( ) ; lc . setLocatorEndpoints ( locatorEndpoints ) ; lc . connect ( ) ; endpointsList = receiveEndpointsList ( ) ; } catch ( IOException e ) { System . err . println ( \"Can not connect to zookeeper due to IOException\" ) ; e . printStackTrace ( ) ; } catch ( InterruptedException e ) { System . err . println ( \"Can not connect to zookeeper due to InterruptedException\" ) ; e . printStackTrace ( ) ; } catch ( ServiceLocatorException e ) { System . err . println ( \"Can not connect to zookeeper due to ServiceLocatorException\" ) ; e . printStackTrace ( ) ; } // TODO Set LOCATOR_ROOT for LocatorClient } catch ( Exception e ) { System . err . println ( \"Can not refresh list of endpoints due to unknown exception\" ) ; // public List<String> lookupServices() throws KeeperException, InterruptedException { // String providerPath = lc.LOCATOR_ROOT; // Stat s = zk.exists(providerPath, false); // if (s != null) { // return decode(zk.getChildren(providerPath, false)); // } else { // System.out.println(\"Lookup services failed, provider not known.\"); // return Collections.emptyList(); // } // }", "del_tokens": "public EndpointResolver ( QName serviceName ) { lc = new LocatorClient ( ) ; //TODO Set LOCATOR_ROOT for LocatorClient endpointsList = receiveEndpointsList ( ) ; } catch ( Exception e ) { System . err . println ( \"Can not refresh list of endpoints due to unknown exception\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "search", "for", "an", "equal", "min", "hash"], "add_tokens": "final Float threshold = Float . parseFloat ( components [ 1 ] ) ; if ( threshold < org . jboss . pressgang . ccms . model . constants . Constants . MIN_DOCUMENT_SIMILARITY || threshold > org . jboss . pressgang . ccms . model . constants . Constants . MAX_DOCUMENT_SIMILARITY ) { throw new IllegalArgumentException ( \"threshold must be between \" + org . jboss . pressgang . ccms . model . constants . Constants . MIN_DOCUMENT_SIMILARITY + \" and \" + org . jboss . pressgang . ccms . model . constants . Constants . MAX_DOCUMENT_SIMILARITY ) ; } final List < Integer > matchingTopics = TopicUtilities . getMatchingMinHash ( getEntityManager ( ) , sourceTopicId , threshold ) ; if ( matchingTopics != null ) { addIdInCollectionCondition ( \"topicId\" , matchingTopics ) ; }", "del_tokens": "final Float minimumSimilarity = Float . parseFloat ( components [ 1 ] ) ; final List < Integer > matchingTopics = TopicUtilities . getMatchingMinHash ( getEntityManager ( ) , sourceTopicId , minimumSimilarity ) ; if ( matchingTopics != null ) { addIdInCollectionCondition ( \"topicId\" , matchingTopics ) ; }", "commit_type": "add"}
{"commit_tokens": ["added", "country", "not", "supported", "test"], "add_tokens": "import java . nio . charset . Charset ; String body = new String ( content , Charset . forName ( \"utf-8\" ) ) ;", "del_tokens": "import java . nio . charset . StandardCharsets ; String body = new String ( content , StandardCharsets . UTF_8 ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "DBCursor", ".", "snapshot", "()"], "add_tokens": "* @ return same DBCursor for chaining operations / * * * Use snapshot mode for the query . Snapshot mode assures no duplicates are * returned , or objects missed , which were present at both the start and end * of the query 's execution (if an object is new during the query, or deleted * during the query , it may or may not be returned , even with snapshot mode ) . * Note that short query responses ( less than 1 MB ) are always effectively snapshotted . * Currently , snapshot mode may not be used with sorting or explicit hints . * @ return same DBCursor for chaining operations * / public DBCursor snapshot ( ) { if ( _it != null ) throw new IllegalStateException ( \"can't snapshot after executing the query\" ) ; _snapshot = true ; return this ; } if ( _snapshot ) foo . put ( \"$snapshot\" , true ) ; private boolean _snapshot = false ;", "del_tokens": "* @ return same DBCursort for chaining operations", "commit_type": "add"}
{"commit_tokens": ["moved", "search", "listeners", "to", "separate", "package"], "add_tokens": "package org . jamesframework . core . search . listeners ; import org . jamesframework . core . search . Search ;", "del_tokens": "package org . jamesframework . core . search ;", "commit_type": "move"}
{"commit_tokens": ["add", "tests", "for", "serialization", "+", "fix", "UnprotectedStringBuffer"], "add_tokens": "System . arraycopy ( strings , endIndex + 1 , strings , nb - ( lastUsed - endIndex ) , lastUsed - endIndex ) ; pos = nb - ( lastUsed - endIndex ) - 1 ;", "del_tokens": "System . arraycopy ( strings , endIndex + 1 , strings , nb - endIndex - 1 , lastUsed - endIndex + 1 ) ; pos = nb - ( lastUsed - endIndex + 1 ) - 1 ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "method", "name", "and", "some", "minor", "clean", "up", "."], "add_tokens": "private final Instrumentation inst ; private Activity activity ; private ArrayList < Activity > activityList = new ArrayList < Activity > ( ) ; IntentFilter filter = null ;", "del_tokens": "protected final Instrumentation inst ; protected Activity activity ; protected ArrayList < Activity > activityList = new ArrayList < Activity > ( ) ; IntentFilter filter = null ;", "commit_type": "change"}
{"commit_tokens": ["Add", "catching", "NameNotFoundException", "in", "getAppVersion", "method", "."], "add_tokens": "public static int getAppVersion ( @ NonNull final Context context ) { try { final PackageInfo packageInfo = context . getPackageManager ( ) . getPackageInfo ( context . getPackageName ( ) , 0 ) ; return packageInfo . versionCode ; } catch ( PackageManager . NameNotFoundException e ) { // ignore return Integer . MIN_VALUE ;", "del_tokens": "public static int getAppVersion ( @ NonNull final Context context ) throws PackageManager . NameNotFoundException { final PackageInfo packageInfo = context . getPackageManager ( ) . getPackageInfo ( context . getPackageName ( ) , 0 ) ; if ( packageInfo == null ) { throw new PackageManager . NameNotFoundException ( context . getPackageName ( ) ) ; return packageInfo . versionCode ;", "commit_type": "add"}
{"commit_tokens": ["added", "dropdown", "menu", "to", "dashboard"], "add_tokens": "public JsonObject addAttribute ( String name , String value ) { return this ; public JsonObject addAttribute ( String name , JsonDecorator value ) { return this ; public JsonObject addAttribute ( String name , Collection < ? extends JsonDecorator > value ) { return this ;", "del_tokens": "public void addAttribute ( String name , String value ) { public void addAttribute ( String name , JsonDecorator value ) { public void addAttribute ( String name , Collection < ? extends JsonDecorator > value ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "to", "ignore", ".", "svn", "/", "subdirectories", "or", "any", "sub", "-", "directories", ".", "Also", "fixed", "issue", "with", "lex", "-", "tag", "processing", "where", "additional", "user", "-", "provided", "attribute", "value", "pairs", "were", "getting", "dropped"], "add_tokens": "if ( file . isFile ( ) ) trainer . addDocumentFileAsTrainingInstance ( file , label ) ;", "del_tokens": "trainer . addDocumentFileAsTrainingInstance ( file , label ) ;", "commit_type": "update"}
{"commit_tokens": ["Updating", "groups", "page", "to", "add", "/", "delete", "methods", "when", "checked"], "add_tokens": "@ RequestParam ( value = \"addOverrides[]\" , required = false ) String [ ] addOverrides , @ RequestParam ( value = \"removeOverride\" , required = false ) String removeOverride ) { if ( removeOverride != null ) { int lastPart = removeOverride . lastIndexOf ( \".\" ) ; String className = removeOverride . substring ( 0 , lastPart ) ; String methodName = removeOverride . substring ( lastPart + 1 ) ; pathOverrideService . removeOverride ( groupId , methodName , className ) ; }", "del_tokens": "@ RequestParam ( value = \"addOverrides[]\" , required = false ) String [ ] addOverrides ) {", "commit_type": "update"}
{"commit_tokens": ["changed", "bit", "field", "type", "from", "short", "to", "byte"], "add_tokens": "getCurrentStruct ( ) . getReadFunc ( ) . indent ( ) . printf ( \"this.%s = In.readBitField(%s);%n\" , fieldName , sizeOfFieldIn ) ; getCurrentStruct ( ) . getFields ( ) . indent ( ) . printf ( \"%s byte %s;%n\" , fieldModifier , fieldName ) ;", "del_tokens": "getCurrentStruct ( ) . getReadFunc ( ) . indent ( ) . printf ( \"this.%s = (short)(In.readBitField(%s) & 0xFF);%n\" , fieldName , sizeOfFieldIn ) ; getCurrentStruct ( ) . getFields ( ) . indent ( ) . printf ( \"%s short %s;%n\" , fieldModifier , fieldName ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "FileProvider", "to", "transform", "URIs", "in", "results"], "add_tokens": "import android . support . v4 . content . FileProvider ; return FileProvider . getUriForFile ( getContext ( ) , getContext ( ) . getApplicationContext ( ) . getPackageName ( ) + \".provider\" , file ) ;", "del_tokens": "return Uri . fromFile ( file ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "an", "issue", "which", "happened", "in", "domManip", "when", "it", "received", "a", "list", "of", "nodes", "with", "multiple", "elements"], "add_tokens": "return $ ( clean ( html ) ) ; protected static JSArray clean ( String elem ) { private GQuery domManip ( NodeList < ? > nodes , int func ) { if ( nodes . getLength ( ) > 1 ) {", "del_tokens": "Element div = DOM . createDiv ( ) ; div . setInnerHTML ( html ) ; return new GQuery ( copyNodeList ( ( NodeList < Element > ) ( NodeList < ? > ) div . getChildNodes ( ) ) ) ; private JSArray clean ( String elem ) { private GQuery domManip ( NodeList nodes , int func ) { if ( size ( ) > 1 ) {", "commit_type": "fix"}
{"commit_tokens": ["Make", "GrammarRules", "and", "GrammarRuleRecord", "implement", "Serializable", "so", "they", "can", "be", "written", "and", "restored", "(", "useful", "for", "debugging", "/", "profiling", "remote", "protocols", "etc", ".", ")", "."], "add_tokens": "import java . io . Serializable ; public class GrammarRuleRecord implements Serializable {", "del_tokens": "public class GrammarRuleRecord {", "commit_type": "make"}
{"commit_tokens": ["Added", "getters", "to", "ProcessExecutor", "."], "add_tokens": "/ * * * Returns this process executor 's operating system program and arguments. * The returned list is a copy . * * @ return this process executor 's program and its arguments (not <code>null</code>). * / public List < String > getCommand ( ) { return new ArrayList < String > ( builder . command ( ) ) ; } / * * * Returns this process executor 's working directory. * * Subprocesses subsequently started by this object will use this as their working directory . * The returned value may be { @ code null } -- this means to use * the working directory of the current Java process , usually the * directory named by the system property { @ code user . dir } , * as the working directory of the child process . * * @ return this process executor 's working directory * / public File getDirectory ( ) { return builder . directory ( ) ; } / * * * Returns this process executor 's additional environment variables. * The returned value is not a copy . * * @ return this process executor 's environment variables (not <code>null</code>). * / public Map < String , String > getEnvironment ( ) { return environment ; } environment . putAll ( env ) ;", "del_tokens": "environment . putAll ( env ) ; ;", "commit_type": "add"}
{"commit_tokens": ["Added", "the", "ability", "to", "deserialize", "a", "Map", "key", "object", "from", "a", "String", "into", "a", "complex", "Java", "type", "."], "add_tokens": "Map < Object , Object > map = constructMapType ( typeOfT , context ) ; TypeInfoMap mapTypeInfo = new TypeInfoMap ( typeOfT ) ; Object key = context . deserialize ( new JsonPrimitive ( entry . getKey ( ) ) , mapTypeInfo . getKeyType ( ) ) ; Object value = context . deserialize ( entry . getValue ( ) , mapTypeInfo . getValueType ( ) ) ; map . put ( key , value ) ;", "del_tokens": "Map < String , Object > map = constructMapType ( typeOfT , context ) ; Type childType = new TypeInfoMap ( typeOfT ) . getValueType ( ) ; Object value = context . deserialize ( entry . getValue ( ) , childType ) ; map . put ( entry . getKey ( ) , value ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "ImageIOTest", "dependency", "on", "JEditorPaneTest"], "add_tokens": "import javax . swing . * ; // ImageIO.scanForPlugins() triggers two different leaks, but the preventor only removes one, so we need to avoid // the other one new ClassLoaderLeakPreventor ( ) . doInSystemClassLoader ( new Runnable ( ) { @ Override public void run ( ) { new JEditorPane ( \"text/plain\" , \"dummy\" ) ; } } ) ;", "del_tokens": "", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "version", "number", "in", "MessageBirdServiceImpl", ".", "java"], "add_tokens": "private final String clienVersion = \"1.0.0\" ;", "del_tokens": "private final String clienVersion = \"1.1.4\" ;", "commit_type": "fix"}
{"commit_tokens": ["Change", "the", "default", "value", "of", "numbersAsString"], "add_tokens": "* Log numbers as String . Default : false . private boolean numbersAsString ;", "del_tokens": "* Log numbers as String . Default : true ( will be changed in next major release ) . private boolean numbersAsString = true ;", "commit_type": "change"}
{"commit_tokens": ["Fix", "another", "issue", "with", "incorrect", "AST", "node", "indices"], "add_tokens": "//assertEquals(printNodeTree(getProcessor().parser.parseToParsingResult(markdown)), \"<parse tree>\"); @ SuppressWarnings ( { \"ConstantConditions\" } ) String markdown = FileUtils . readAllTextFromResource ( testName + \".text\" ) . replace ( \"\\r\\n\" , \"\\n\" ) ; RootNode astRoot = getProcessor ( ) . parseMarkdown ( markdown . toCharArray ( ) ) ; // check parse tree //assertEquals(printNodeTree(getProcessor().parser.parseToParsingResult(markdown)), \"<parse tree>\");", "del_tokens": "//assertEquals(printNodeTree(getProcessor().parser.parseInternal2(markdown)), \"\"); char [ ] markdown = FileUtils . readAllCharsFromResource ( testName + \".text\" ) ; RootNode astRoot = getProcessor ( ) . parseMarkdown ( markdown ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "Javadoc", "for", "new", "utility", "classes", "Permutation", "and", "PErmutationsWithRepetition", ".", "--", "F", "."], "add_tokens": "* * The algorithm is from Applied Combinatorics , by Alan Tucker . * Based on code from < a href = \"koders.com\" > koders . com < / a > . * public class Permutation { * @ param n Number of integers available . * @ param r Size of permutations . * Assess whether there is another permutation .", "del_tokens": "* The algorithm is from Applied Combinatorics , by Alan Tucker . Based on code from < code > koders . com < / code > . * class Permutation { * @ param n Number of integers available * @ param r Size of permutations * Assess weather there is another permutation . // Based on code from KodersCode: // The algorithm is from Applied Combinatorics, by Alan Tucker. // Move the index forward a notch. The algorithm first finds the // rightmost index that is less than its neighbor to the right. This // is the dip point. The algorithm next finds the least element to // the right of the dip that is greater than the dip. That element is // switched with the dip. Finally, the list of elements to the right // of the dip is reversed. // // For example, in a permutation of 5 items, the index may be // {1, 2, 4, 3, 0}. The dip is 2 the rightmost element less // than its neighbor on its right. The least element to the right of // 2 that is greater than 2 is 3. These elements are swapped, // yielding {1, 3, 4, 2, 0}, and the list right of the dip point is // reversed, yielding {1, 3, 0, 2, 4}.", "commit_type": "update"}
{"commit_tokens": ["add", "a", "/", "to", "the", "default", "coffee", "-", "script", ".", "js", "location", "otherwise", "instead", "of", "returning", "null", "tomcat", "8", "s", "ServletContext", ".", "getResourceAsStream", "()", "throws", "java", ".", "lang", ".", "IllegalArgumentException", ":", "The", "resource", "path", "[", "net", "/", "jawr", "/", "web", "/", "resource", "/", "bundle", "/", "generator", "/", "js", "/", "coffee", "/", "coffee", "-", "script", ".", "js", "]", "is", "not", "valid"], "add_tokens": "private static final String DEFAULT_COFFEE_SCRIPT_JS_LOCATION = \"/net/jawr/web/resource/bundle/generator/js/coffee/coffee-script.js\" ;", "del_tokens": "private static final String DEFAULT_COFFEE_SCRIPT_JS_LOCATION = \"net/jawr/web/resource/bundle/generator/js/coffee/coffee-script.js\" ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "JUnit", "s", "@Rule"], "add_tokens": "private final Map < Class < ? extends IAnnotationDrivenExtension > , IAnnotationDrivenExtension > extensions = for ( IAnnotationDrivenExtension extension : extensions . values ( ) ) extension . visitSpec ( spec ) ; IAnnotationDrivenExtension result = extensions . get ( clazz ) ; extensions . put ( clazz , result ) ;", "del_tokens": "private final Map < Class < ? extends IAnnotationDrivenExtension > , IAnnotationDrivenExtension > processors = for ( IAnnotationDrivenExtension processor : processors . values ( ) ) processor . visitSpec ( spec ) ; IAnnotationDrivenExtension result = processors . get ( clazz ) ; processors . put ( clazz , result ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "the", "remaining", "karaf", "archetypes", "https", ":", "//", "github", ".", "com", "/", "fabric8io", "/", "fabric8", "/", "issues", "/", "3458"], "add_tokens": "\"karaf-beginner-camel-cbr-archetype\" ,", "del_tokens": "/ * \"karaf-camel-amq-archetype\" , \"karaf-camel-rest-sql-archetype\" , * /", "commit_type": "add"}
{"commit_tokens": ["fixed", "complex", "number", "parsing", "errors", "tests"], "add_tokens": "String betweenparens = sr . readUntil ( \")\\n\" ) . trim ( ) ; { } sr . rewind ( 1 ) ; // rewind the +/- // because we're a bit more cautious here with reading chars than in the float parser, // it can be that the parser now stopped directly after the 'e' in a number like \"3.14e+20\". // (\"3.14e20\" is fine) So, check if the last char is 'e' and if so, continue reading 0..9. if ( numberstr . endsWith ( \"e\" ) || numberstr . endsWith ( \"E\" ) ) { // if the next symbol is + or -, accept it, then read the exponent integer if ( sr . peek ( ) == '-' || sr . peek ( ) == '+' ) numberstr += sr . read ( 1 ) ; numberstr += sr . readWhile ( \"0123456789\" ) ; } sr . skipWhitespace ( ) ;", "del_tokens": "String betweenparens = sr . readUntil ( ')' ) . trim ( ) ; sr . rewind ( 1 ) ; // rewind the +/-", "commit_type": "fix"}
{"commit_tokens": ["fixing", "overlapping", "of", "replace", "actions"], "add_tokens": "for ( ; actionLine < futureLine && index < contents . length ; index ++ ) {", "del_tokens": "for ( ; actionLine < futureLine ; index ++ ) {", "commit_type": "fix"}
{"commit_tokens": ["Removed", "deprecated", "java", "elements", "(", "node", "serialization", ")", "and", "fixed", "some", "warnings"], "add_tokens": "private Map < String , String > map ; map = new HashMap < String , String > ( ) ; List < String > prefixes = new ArrayList < String > ( ) ;", "del_tokens": "private Map map ; map = new HashMap ( ) ; List prefixes = new ArrayList ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Fix", "possible", "NPE", "in", "Wrapper", ".", "equals"], "add_tokens": "if ( obj instanceof Wrapper ) { Wrapper < T > comparedWrapper = ( Wrapper < T > ) obj ; T toCompare = comparedWrapper . getWrapped ( ) ; if ( wrapped == null && toCompare == null ) { return true ; } if ( ! ( wrapped != null && instanceOf ( wrapped . getClass ( ) ) . matches ( toCompare ) ) ) { return false ; } return safelyEquals ( this . wrapped , toCompare ) ; } return false ;", "del_tokens": "Wrapper < T > comparedWrapper = ( Wrapper < T > ) obj ; T toCompare = comparedWrapper . getWrapped ( ) ; if ( wrapped == null && toCompare == null ) { return true ; } if ( ! ( wrapped != null && instanceOf ( wrapped . getClass ( ) ) . matches ( toCompare ) ) ) { return false ; } return safelyEquals ( this . wrapped , toCompare ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "unneeded", "code", ".", "Touched", "up", "test", "."], "add_tokens": "import java . util . ArrayList ; // mon1/mon2/mon3 all point to different objects that are logically equivalent but different objects. Tracking should ignore logical // equivallence and instead focus on checking to make sure that they references are the same. We don't want to call MONITOREXIT on // the wrong object because it .equals() another object in the list of monitors being tracked. Object mon1 = new ArrayList < > ( ) ; Object mon2 = new ArrayList < > ( ) ; Object mon3 = new ArrayList < > ( ) ;", "del_tokens": "Object mon1 = new Object ( ) ; Object mon2 = new Object ( ) ; Object mon3 = new Object ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["changed", "UserImp", "method", "to", "use", "urlBuilder", "to", "append", "request", "parameters"], "add_tokens": "Map < String , List < String > > postParameters = new HashMap < > ( ) ; postParameters . put ( \"enrollment_type\" , Arrays . asList ( \"student\" ) ) ; postParameters . put ( \"include[]\" , Arrays . asList ( \"enrollments\" ) ) ; postParameters . put ( \"per_page\" , Arrays . asList ( API_RESULTS_PER_PAGE ) ) ; List < Response > responses = canvasMessenger . getFromCanvas ( oauthToken , url ) ;", "del_tokens": "Map < String , String > postParameters = new HashMap < > ( ) ; postParameters . put ( \"enrollment_type\" , \"student\" ) ; postParameters . put ( \"include[]\" , \"enrollments\" ) ; postParameters . put ( \"per_page\" , API_RESULTS_PER_PAGE ) ; List < Response > responses = canvasMessenger . getFromCanvas ( oauthToken , url , postParameters ) ;", "commit_type": "change"}
{"commit_tokens": ["Improve", "TransformLargeRdf2", ";", "check", "for", "newlines", "and", "tabs", "in", "URIs"], "add_tokens": "if ( plainURI . toString ( ) . matches ( \".*(\\\\n|\\\\t).*\" ) ) { throw new RuntimeException ( \"Newline or tab character in URI: \" + plainURI . toString ( ) ) ; } String s = uri . toString ( ) ; if ( s . matches ( \".*(\\\\n|\\\\t).*\" ) ) { throw new RuntimeException ( \"Newline or tab character in URI: \" + s ) ; } if ( hash == null ) return s ; return s . replaceAll ( hash , \" \" ) ;", "del_tokens": "if ( hash == null ) return uri . toString ( ) ; return uri . toString ( ) . replaceAll ( hash , \" \" ) ;", "commit_type": "improve"}
{"commit_tokens": ["Made", "BoxRequestCollectionUpdate", "abstract", "class", "public", "and", "Fields", "param", "protected"], "add_tokens": "public abstract class BoxRequestCollectionUpdate < E extends BoxItem , R extends BoxRequest < E , R > > extends BoxRequestItem < E , R > {", "del_tokens": "abstract class BoxRequestCollectionUpdate < E extends BoxItem , R extends BoxRequest < E , R > > extends BoxRequestItem < E , R > {", "commit_type": "make"}
{"commit_tokens": ["Fix", "java", ".", "lang", ".", "ArrayIndexOutOfBoundsException", ":", "-", "1", ";", "This", "happens", "with"], "add_tokens": "if ( icc == null ) { } int idx = order - 1 ; if ( idx >= 0 ) { icc [ idx ] = byteapp2 ; }", "del_tokens": "if ( icc == null ) icc [ order - 1 ] = byteapp2 ;", "commit_type": "fix"}
{"commit_tokens": ["Created", "AssertionReporter", "to", "be", "responsible", "for", "carrying", "out", "assertions", "failing", "tests", "where", "necessary", ".", "Inspired", "by", "Mockito", "this", "removes", "the", "dependency", "on", "JUnit", "s", "Assert", "class", "."], "add_tokens": "private final static AssertionReporter reporter = new AssertionReporter ( ) ; reporter . expectedImmutable ( analysisResult ) ; return reporter . formatReasons ( reasons ) ; reporter . expectedIsImmutable ( expected , analysisResult ) ;", "del_tokens": "import static java . lang . String . format ; import junit . framework . Assert ; StringBuilder message = new StringBuilder ( ) ; String simpleName = expectedImmutableClass . getSimpleName ( ) ; message . append ( format ( \"Expected %s to be %s immutable. Was: %s immutable.%n\" , simpleName , IsImmutable . DEFINITELY , analysisResult . isImmutable . toString ( ) ) ) ; formatReasons ( analysisResult . reasons , message ) ; Assert . assertTrue ( message . toString ( ) , IsImmutable . DEFINITELY == analysisResult . isImmutable ) ; return formatReasons ( reasons , new StringBuilder ( ) ) ; } private static String formatReasons ( Collection < CheckerReasonDetail > reasons , StringBuilder builder ) { builder . append ( format ( \"Reasons:%n\" ) ) ; for ( CheckerReasonDetail reason : reasons ) { builder . append ( format ( \"%s%n\" , reason . message ( ) ) ) ; } return builder . toString ( ) ; Assert . assertEquals ( expected , analysisResult . isImmutable ) ;", "commit_type": "create"}
{"commit_tokens": ["use", "OAuthProfile", "interface", "instead", "of", "BaseOAuthProfile", "implementation"], "add_tokens": "import org . scribe . up . profile . OAuthProfile ; } catch ( final HttpException e ) { } catch ( final HttpException e ) { ( ( OAuthProfile ) profile ) . setAccessToken ( token ) ; } catch ( final CredentialException e ) { final CredentialException credentialException = new CredentialException ( ) ; final String message = values [ 0 ] ;", "del_tokens": "import org . scribe . up . profile . BaseOAuthProfile ; } catch ( HttpException e ) { } catch ( HttpException e ) { ( ( BaseOAuthProfile ) profile ) . setAccessToken ( token ) ; } catch ( CredentialException e ) { CredentialException credentialException = new CredentialException ( ) ; String message = values [ 0 ] ;", "commit_type": "use"}
{"commit_tokens": ["Add", "verbose", "check", "for", "done", "message", "."], "add_tokens": "if ( verbose ) { System . out . println ( \"done.\" ) ; }", "del_tokens": "System . out . println ( \"done.\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "docs", "and", "more", "testing", "around", "reading", "the", "JSON", "object", "model", "."], "add_tokens": "public class ConfigLoader { private ConfigLoader ( ) { / * * * Loads a config file . * @ param path file path to config * @ return Config . * / ConfigLoader . class . getClassLoader ( ) . getResourceAsStream ( \"jjs-config-utils.js\" ) ) ) ;", "del_tokens": "public class JsLoader { private JsLoader ( ) { JsLoader . class . getClassLoader ( ) . getResourceAsStream ( \"jjs-config-utils.js\" ) ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "and", "used", "new", "interface", "IHasClassLoader"], "add_tokens": "import com . helger . commons . lang . IHasClassLoader ; public class ClassPathResource implements IReadableResource , IHasClassLoader", "del_tokens": "public class ClassPathResource implements IReadableResource", "commit_type": "add"}
{"commit_tokens": ["Add", "feature", ":", "Reply", "message", "by", "SDK", "from", "@EventHandler", "method", "return", "value", "."], "add_tokens": "import org . springframework . context . annotation . Import ; @ Import ( ReplyByReturnValueConsumer . Factory . class ) private final ReplyByReturnValueConsumer . Factory returnValueConsumerFactory ; public LineMessageHandlerSupport ( final ReplyByReturnValueConsumer . Factory returnValueConsumerFactory , final ConfigurableApplicationContext applicationContext ) { this . returnValueConsumerFactory = returnValueConsumerFactory ; @ VisibleForTesting void dispatch ( Event event ) { final Object returnValue = handlerMethod . getHandler ( ) . invoke ( handlerMethod . getObject ( ) , event ) ; handleReturnValue ( event , returnValue ) ; } private void handleReturnValue ( final Event event , final Object returnValue ) { if ( returnValue != null ) { returnValueConsumerFactory . createForEvent ( event ) . accept ( returnValue ) ; }", "del_tokens": "public LineMessageHandlerSupport ( final ConfigurableApplicationContext applicationContext ) { private void dispatch ( Event event ) { handlerMethod . getHandler ( ) . invoke ( handlerMethod . getObject ( ) , event ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "support", "for", "argument", "handling", "."], "add_tokens": "public final class ArgumentHandlerManager { private Map < String , ArgumentHandlerRegistryBean > handlers ; public ArgumentHandlerManager ( ApplicationContext context ) { handlers = context . getBeansOfType ( ArgumentHandlerRegistryBean . class ) ; for ( ArgumentHandlerRegistryBean handler : handlers . values ( ) ) {", "del_tokens": "public final class ArgumentHandlers { private Map < String , ArgumentHandler > handlers ; public ArgumentHandlers ( ApplicationContext context ) { handlers = context . getBeansOfType ( ArgumentHandler . class ) ; for ( ArgumentHandler handler : handlers . values ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "Seed", "M4", "-", "SNAPSHOT", "with", "named", "security", "scopes"], "add_tokens": "String expected = \"{\\\"id\\\":\\\"ThePoltergeist\\\",\\\"type\\\":\\\"user\\\",\\\"principals\\\":{\\\"userId\\\":\\\"ThePoltergeist\\\"},\\\"roles\\\":[{\\\"name\\\":\\\"jedi\\\",\\\"attributes\\\":{},\\\"permissions\\\":[[\\\"academy\\\",\\\"*\\\"],[\\\"lightSaber\\\",\\\"*\\\"]]},{\\\"name\\\":\\\"ghost\\\",\\\"attributes\\\":{\\\"scope\\\":[\\\"MU\\\",\\\"PY\\\"]},\\\"permissions\\\":[[\\\"site\\\",\\\"haunt\\\"]]}],\\\"permissions\\\":[]}\" ;", "del_tokens": "String expected = \"{\\\"id\\\":\\\"ThePoltergeist\\\",\\\"type\\\":\\\"user\\\",\\\"principals\\\":{\\\"userId\\\":\\\"ThePoltergeist\\\"},\\\"roles\\\":[{\\\"name\\\":\\\"jedi\\\",\\\"attributes\\\":{},\\\"permissions\\\":[[\\\"academy\\\",\\\"*\\\"],[\\\"lightSaber\\\",\\\"*\\\"]]},{\\\"name\\\":\\\"ghost\\\",\\\"attributes\\\":{\\\"domain\\\":[\\\"MU\\\",\\\"PY\\\"]},\\\"permissions\\\":[[\\\"site\\\",\\\"haunt\\\"]]}],\\\"permissions\\\":[]}\" ;", "commit_type": "update"}
{"commit_tokens": ["added", "methods", "for", "like", "/", "unlike", "messages"], "add_tokens": "public void like ( long messageId ) { restTemplate . postForObject ( buildUri ( \"messages/liked_by/current.json\" , \"message_id\" , String . valueOf ( messageId ) ) , null , String . class ) ; } public void unlike ( long messageId ) { restTemplate . delete ( buildUri ( \"messages/liked_by/current.json\" , \"message_id\" , String . valueOf ( messageId ) ) ) ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Implement", "static", "start", "method", "for", "HelpDoclet"], "add_tokens": "* { @ link # start ( RootDoc ) } A static method that instantiates the subclass and delegates to the * instance method { @ link # startProcessDocs ( RootDoc ) } . / * * * The entry point for javadoc generation . Default implementation creates an instance of * { @ link HelpDoclet } and calls { @ link # startProcessDocs ( RootDoc ) } on that instance . * * < p > Note : Custom Barclay doclets should subclass this class , and implement a similar static * method that creates an instance of the doclet subclass and delegates to that instance 's * { @ link # startProcessDocs ( RootDoc ) } . * / public static boolean start ( final RootDoc rootDoc ) throws IOException { return new HelpDoclet ( ) . startProcessDocs ( rootDoc ) ; }", "del_tokens": "*", "commit_type": "implement"}
{"commit_tokens": ["Added", "option", "to", "change", "title"], "add_tokens": "import net . magik6k . jwwf . util . Json ; private String title = \"Java Web Widget Framework\" ; return \"{\\\"content\\\":\" + String . valueOf ( content ) + \", \\\"title\\\":\" + Json . escapeString ( title ) + \"}\" ; * @ return This instance for chaining public MainFrame put ( Widget widget ) { return this ; } / * * * Sets page title * @ param title new title * @ return This instance for chaining * / public MainFrame setTitle ( String title ) { this . title = title ; this . sendElement ( ) ; return this ;", "del_tokens": "return \"{\\\"content\\\":\" + String . valueOf ( content ) + \"}\" ; public void put ( Widget widget ) {", "commit_type": "add"}
{"commit_tokens": ["changed", "variable", "of", "name", "field", "in", "Sender", "class"], "add_tokens": "name = String . format ( \"%s_%d\" , new Object [ ] { host , port } ) ;", "del_tokens": "name = String . format ( \"%s_%d_%d_%d\" , new Object [ ] { host , port , timeout , bufferCapacity } ) ; / * * FIXME int pos = pendings . position ( ) ; if ( pos > 0 ) { byte [ ] b = new byte [ pos ] ; pendings . get ( b , 0 , pos ) ; send ( b ) ; } * /", "commit_type": "change"}
{"commit_tokens": ["Improved", "some", "of", "the", "javadoc", "."], "add_tokens": "* @ param dest The destination object * @ param index The index of the object to get * @ return The fetched object", "del_tokens": "* @ param dest * @ param index * @ return", "commit_type": "improve"}
{"commit_tokens": ["Adds", "implicit", "restriction", "to", "**", "/", "*", ".", "class", "add", "dir", "=", "attribute", "to", "ant", "task", "add", "javadocs"], "add_tokens": "* Fail the build , if the bundled ASM library cannot read the class file format * of the runtime library or the runtime library cannot be discovered .", "del_tokens": "* If true , the build fails if the Java version used to build is not supported ( e . g . , Java 8 ) . * Otherwise a warning is printed and the MOJO does nothing ( which is the default ) .", "commit_type": "add"}
{"commit_tokens": ["changed", "semafore", "in", "FLVReader", "to", "reentrant", "lock"], "add_tokens": "import java . util . concurrent . locks . ReentrantLock ; private final ReentrantLock lock = new ReentrantLock ( ) ; lock . lockInterruptibly ( ) ; lock . unlock ( ) ; lock . lockInterruptibly ( ) ; lock . unlock ( ) ; lock . lockInterruptibly ( ) ; lock . unlock ( ) ;", "del_tokens": "import java . util . concurrent . Semaphore ; private final Semaphore lock = new Semaphore ( 2 , true ) ; lock . acquire ( ) ; lock . release ( ) ; lock . acquire ( ) ; lock . release ( ) ; // acquire both permits before we close lock . acquire ( 2 ) ; lock . release ( 2 ) ;", "commit_type": "change"}
{"commit_tokens": ["Added", "support", "for", "underscores", "in", "numbers"], "add_tokens": "boolean underscorable = false ; boolean notLastChar = chars . length > i + 1 ; underscorable = notLastChar ; } else if ( ( c == '+' || c == '-' ) && signable && notLastChar ) { underscorable = false ; } else if ( c == '.' && dottable && notLastChar ) { underscorable = false ; } else if ( ( c == 'E' || c == 'e' ) && exponentable && notLastChar ) { underscorable = false ; } else if ( c == '_' && underscorable && notLastChar && Character . isDigit ( chars [ i + 1 ] ) ) { underscorable = false ;", "del_tokens": "} else if ( ( c == '+' || c == '-' ) && signable && chars . length > i + 1 ) { } else if ( c == '.' && dottable && chars . length > i + 1 ) { } else if ( ( c == 'E' || c == 'e' ) && exponentable && chars . length > i + 1 ) {", "commit_type": "add"}
{"commit_tokens": ["Updated", "pom", ".", "xml", "to", "handle", "custom", "src", "and", "test", "-", "src", "directories"], "add_tokens": "String joinedValues = StringUtils . join ( ( ( Iterable < String > ) param . getValue ( ) ) . iterator ( ) , \",\" ) ; apiUrlBuilder . addParameter ( param . getKey ( ) , joinedValues ) ;", "del_tokens": "import org . apache . http . auth . AuthScope ; import org . apache . http . auth . UsernamePasswordCredentials ; for ( String single : ( Iterable < String > ) param . getValue ( ) ) { apiUrlBuilder . addParameter ( param . getKey ( ) + \"[]\" , single ) ; }", "commit_type": "update"}
{"commit_tokens": ["Fix", "sending", "of", "group", "messages", "that", "contain", "the", "character", ".", "Add", "test", "case", "."], "add_tokens": "JSONObject data = new JSONObject ( ) ; data . put ( \"endpointId\" , client . getEndpointID ( ) ) ; data . put ( \"message\" , message ) ;", "del_tokens": "JSONObject data = null ; data = new JSONObject ( \"{'endpointId':'\" + client . getEndpointID ( ) + \"','message':'\" + message + \"'}\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["fix", "bug", "in", "setRenderArgs", "(", "Object", "...", ")", "method", "generated", "by", "CodeBuilder"], "add_tokens": "p2t ( \"if (_p < l) { Object v = args[_p++]; boolean isString = (\\\"java.lang.String\\\".equals(\\\"\" )", "del_tokens": "first = true ; if ( first ) { first = false ; p2t ( \"\" ) ; } else { p2t ( \"else \" ) ; } ; p ( \"if (_p < l) { Object v = args[_p++]; boolean isString = (\\\"java.lang.String\\\".equals(\\\"\" )", "commit_type": "fix"}
{"commit_tokens": ["Changed", "package", "name", "to", "org", ".", "jasig", ".", "portal", ".", "channels"], "add_tokens": "package org . jasig . portal . channels ;", "del_tokens": "package org . jasig . portal . xmlchannels ;", "commit_type": "change"}
{"commit_tokens": ["fix", "getTypeName", "in", "resultset", "metadata"], "add_tokens": "return getColumnInformation ( column ) . getType ( ) . getTypeName ( ) ;", "del_tokens": "return getColumnInformation ( column ) . getType ( ) . toString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "small", "bug", "with", "ignored", "keywords", ".", "made", "simplify", "merge", "the", "original", "context", "with", "the", "generated", "context", "to", "keep", "prefixes"], "add_tokens": "// TODO: not sure if we should allow this, but as long as the tests pass it \"should\" be ok. if ( v1 == null && v2 == null ) { return 0 ; } if ( ! p . equals ( \"@id\" ) ) { // TODO: this should ignore \"ignoreKeyword\" keywords as well", "del_tokens": "if ( ! p . equals ( \"@id\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["add", "dispose", "method", "in", "PluginClassLoader"], "add_tokens": "classLoader . dispose ( ) ;", "del_tokens": "try { classLoader . close ( ) ; } catch ( IOException e ) { log . error ( e . getMessage ( ) , e ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fixed", "Session", "to", "use", "package", "SparseArray", "and", "formatting", "."], "add_tokens": "package com . frostwire . jlibtorrent ; class SparseArray < E > implements Cloneable { }", "del_tokens": "package com . frostwire . util ; public class SparseArray < E > implements Cloneable { static int binarySearch ( long [ ] array , int size , long value ) { int lo = 0 ; int hi = size - 1 ; while ( lo <= hi ) { final int mid = ( lo + hi ) >>> 1 ; final long midVal = array [ mid ] ; if ( midVal < value ) { lo = mid + 1 ; } else if ( midVal > value ) { hi = mid - 1 ; } else { return mid ; // value found } } return ~ lo ; // value not present } }", "commit_type": "fix"}
{"commit_tokens": ["update", "Disconnection", "Event", "Handler", "and", "add", "some", "commands"], "add_tokens": "room . setName ( ROOM_NAME ) ; // @Override // public String getName() { // return \"room\"; // }", "del_tokens": "@ Override public String getName ( ) { return \"room\" ; }", "commit_type": "update"}
{"commit_tokens": ["added", "basic", "implementation", "of", "reload", "()"], "add_tokens": "class PropertiesLoader implements Reloadable { private final Properties properties = new Properties ( ) ; defaults ( properties , clazz ) ; merge ( properties , reverse ( imports ) ) ; merge ( properties , loadedFromFile ) ; return properties ; public void reload ( ) { properties . clear ( ) ; load ( ) ; }", "del_tokens": "class PropertiesLoader { Properties props = defaults ( clazz ) ; merge ( props , reverse ( imports ) ) ; merge ( props , loadedFromFile ) ; return props ;", "commit_type": "add"}
{"commit_tokens": ["Updating", "minor", "style", "issues", "with", "BasicResponse"], "add_tokens": "@ JsonProperty ( \"created_at\" ) // TODO: Parse as Date way @ JsonProperty ( \"updated_at\" ) // TODO: \"\" * @ return the ID associated with this record * @ return the record 's creation date. * @ return the last updated date * @ return whether or not the company was created with a live or test API key", "del_tokens": "import com . fasterxml . jackson . annotation . JsonIgnoreProperties ; import com . fasterxml . jackson . annotation . JsonInclude ; * Created by Tony Dieppa on 9 / 30 / 14. @ JsonIgnoreProperties ( ignoreUnknown = true ) @ JsonInclude ( JsonInclude . Include . NON_DEFAULT ) @ JsonProperty ( \"created_at\" ) @ JsonProperty ( \"updated_at\" ) * @ return ID * @ return Creation date . * @ return Updated date . * @ return True if live .", "commit_type": "update"}
{"commit_tokens": ["Removed", "a", "blank", "line", "."], "add_tokens": "} ;", "del_tokens": "} ;", "commit_type": "remove"}
{"commit_tokens": ["Changed", "identifier", "of", "the", "enabled", "flag"], "add_tokens": "return config . getBoolean ( \"statistics.enabled\" ) ;", "del_tokens": "return config . getBoolean ( \"statistics.influx.enabled\" ) ;", "commit_type": "change"}
{"commit_tokens": ["fix", "tests", "after", "improve", "PluginDescriptorFinder"], "add_tokens": "if ( StringUtils . isNotEmpty ( version ) ) { pluginDescriptor . setPluginVersion ( Version . valueOf ( version ) ) ; } if ( pluginDescriptor . getVersion ( ) == null ) { throw new PluginException ( \"Plugin-Version cannot be empty\" ) ; }", "del_tokens": "pluginDescriptor . setPluginVersion ( Version . valueOf ( version ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "tests", "and", "clean", "existing", "indices", "before", "running", "the", "factories"], "add_tokens": "import java . util . Collections ; import java . util . List ; protected List < String > otherTestIndices ( ) { return Collections . singletonList ( \"badindex\" ) ;", "del_tokens": "protected String indexName ( ) { return \"badindex\" ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "where", "AssetWatcher", "would", "not", "call", "callback", ".", "done", "()", "if", "the", "last", "resource", "threw", "an", "error", "."], "add_tokens": "callback . error ( new RuntimeException ( \"Error loading image\" ) ) ;", "del_tokens": "callback . error ( new RuntimeException ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "configured", "static", "announcements"], "add_tokens": "{ return staticAnnouncement ( UUID . randomUUID ( ) , serviceName , serviceType , serviceScheme , serviceAddress , port ) ; } public static ServiceInformation staticAnnouncement ( final UUID serviceId , final String serviceName , final String serviceType , final String serviceScheme , final String serviceAddress , final int port ) serviceId ,", "del_tokens": "null ,", "commit_type": "add"}
{"commit_tokens": ["changed", "behavior", "for", "renderer", "utils", "and", "width", "-", "longets", "-", "line", "to", "new", "base", "line"], "add_tokens": "return new String [ ] { \"\" } ;", "del_tokens": "return new String [ ] { } ;", "commit_type": "change"}
{"commit_tokens": ["Making", "TarEntry", ".", "equals", "a", "standard", "java", "equals", "method", "(", "with", ".", "hashCode", "method", ")"], "add_tokens": "@ Override public boolean equals ( Object it ) { if ( ! ( it instanceof TarEntry ) ) { return false ; } return header . name . toString ( ) . equals ( ( ( TarEntry ) it ) . header . name . toString ( ) ) ; } @ Override public int hashCode ( ) { return header . name . hashCode ( ) ;", "del_tokens": "public boolean equals ( TarEntry it ) { return header . name . toString ( ) . equals ( it . header . name . toString ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Add", "OSGi", "DataSourceFactory", "properties", "building"], "add_tokens": "/ * * * h2spatial is a library that brings spatial support to the H2 Java database . * h2spatial is distributed under GPL 3 license . It is produced by the \"Atelier SIG\" * h2patial is free software : you can redistribute it and / or modify it under the * h2spatial is distributed in the hope that it will be useful , but WITHOUT ANY * h2spatial . If not , see < http : //www.gnu.org/licenses/>.", "del_tokens": "/ * * OrbisGIS is a GIS application dedicated to scientific spatial simulation . * This cross - platform GIS is developed at French IRSTV institute and is able to * manipulate and create vector and raster spatial information . * OrbisGIS is distributed under GPL 3 license . It is produced by the \"Atelier SIG\" * This file is part of OrbisGIS . * * OrbisGIS is free software : you can redistribute it and / or modify it under the * OrbisGIS is distributed in the hope that it will be useful , but WITHOUT ANY * OrbisGIS . If not , see < http : //www.gnu.org/licenses/>.", "commit_type": "add"}
{"commit_tokens": ["Added", "generic", "to", "indirect", "queues"], "add_tokens": "public static class SynchronizedIndirectPriorityQueue < K > implements IndirectPriorityQueue < K > { final protected IndirectPriorityQueue < K > q ; protected SynchronizedIndirectPriorityQueue ( final IndirectPriorityQueue < K > q , final Object sync ) { protected SynchronizedIndirectPriorityQueue ( final IndirectPriorityQueue < K > q ) { public Comparator < ? super K > comparator ( ) { synchronized ( sync ) { return q . comparator ( ) ; } } public static < K > IndirectPriorityQueue < K > synchronize ( final IndirectPriorityQueue < K > q ) { return new SynchronizedIndirectPriorityQueue < K > ( q ) ; } public static < K > IndirectPriorityQueue < K > synchronize ( final IndirectPriorityQueue < K > q , final Object sync ) { return new SynchronizedIndirectPriorityQueue < K > ( q , sync ) ; }", "del_tokens": "public static class SynchronizedIndirectPriorityQueue implements IndirectPriorityQueue { final protected IndirectPriorityQueue q ; protected SynchronizedIndirectPriorityQueue ( final IndirectPriorityQueue q , final Object sync ) { protected SynchronizedIndirectPriorityQueue ( final IndirectPriorityQueue q ) { public Comparator comparator ( ) { synchronized ( sync ) { return q . comparator ( ) ; } } public static IndirectPriorityQueue synchronize ( final IndirectPriorityQueue q ) { return new SynchronizedIndirectPriorityQueue ( q ) ; } public static IndirectPriorityQueue synchronize ( final IndirectPriorityQueue q , final Object sync ) { return new SynchronizedIndirectPriorityQueue ( q , sync ) ; }", "commit_type": "add"}
{"commit_tokens": ["Implement", "new", "refreshView", "()", "API"], "add_tokens": "refreshView ( ) ; //============================================================================================================= @ Override public void refreshView ( ) refreshView ( ) ;", "del_tokens": "refresh ( ) ; / * * * Refresh the trees . * / public void refresh ( ) //============================================================================================================= refresh ( ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "runtime", "changes", "to", "connector", "updates"], "add_tokens": "import org . jboss . msc . service . ServiceController ; final ServiceController < ? > controller = updateContext . getServiceContainer ( ) . getService ( ConnectorElement . connectorName ( name ) ) ; if ( controller == null ) { resultHandler . handleSuccess ( null , param ) ; } else { controller . addListener ( new UpdateResultHandler . ServiceRemoveListener < P > ( resultHandler , param ) ) ; controller . setMode ( ServiceController . Mode . REMOVE ) ; }", "del_tokens": "// TODO Auto-generated method stub", "commit_type": "add"}
{"commit_tokens": ["Fix", "resolving", "of", "{", "@link", "}", "{", "@linkplain", "}", "and", "{", "@see", "}", "."], "add_tokens": "String css = \"\\n\"", "del_tokens": "import org . intellij . lang . annotations . Language ; @ Language ( \"CSS\" ) String css = \"\\n\"", "commit_type": "fix"}
{"commit_tokens": ["fix", "pre", "-", "version", "enforcement"], "add_tokens": "* } else if ( contains ( this . differences , Add . class ) || } // if the current version is a pre-release then the corresponding release need to be superior or equal return current . toReleaseVersion ( ) . compareTo ( inferredVersion ) >= 0 ;", "del_tokens": "* } else if ( contains ( this . differences , Add . class ) || } return current . compareTo ( inferredVersion ) >= 0 ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "subresource", "-", "ordering", "for", "logging", "subsystem"], "add_tokens": "static class LoggingComparator implements Comparator < Method > { if ( o2 . getName ( ) . contains ( \"Formatter\" ) ) return 1 ; private static class DefaultComparator implements Comparator < Method > {", "del_tokens": "private class LoggingComparator implements Comparator < Method > { private class DefaultComparator implements Comparator < Method > {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", "not", "check", "mArrowDrawable", "null", "in", "showPopup", "()", "and", "onPopupDismissed", "()", "methods", "of", "Spinner", "class", "."], "add_tokens": "if ( mArrowDrawable != null && mArrowAnimSwitchMode ) if ( mArrowDrawable != null ) mArrowDrawable . setMode ( ArrowDrawable . MODE_DOWN , true ) ;", "del_tokens": "if ( mArrowAnimSwitchMode ) mArrowDrawable . setMode ( ArrowDrawable . MODE_DOWN , true ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "tests", "for", "Clock", ".", "system", "()", ".", "equals", "and", "hashCode"], "add_tokens": "if ( ! ( obj instanceof SystemMillis ) ) { return false ; } if ( timeZone != other . timeZone && ! timeZone . equals ( other . timeZone ) ) { hash = 41 * hash + timeZone . hashCode ( ) ;", "del_tokens": "if ( this . timeZone != other . timeZone && ( this . timeZone == null || ! this . timeZone . equals ( other . timeZone ) ) ) { hash = 41 * hash + ( this . timeZone != null ? this . timeZone . hashCode ( ) : 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Made", "fluent", "builder", "work", "more", "conveniently", "with", "properties", "that", "reference", "multiple", "elements", "or", "types", "(", "e", ".", "g", ".", "via", "<choice", ">", "etc", "...", ")"], "add_tokens": "import org . xml . sax . ErrorHandler ; import org . xml . sax . SAXException ; import org . xml . sax . SAXParseException ; import com . kscs . util . jaxb . Buildable ; import com . kscs . util . plugins . xjc . codemodel . ClassName ; if ( this . generateTools ) { pluginContext . writeSourceFile ( Buildable . class ) ; }", "del_tokens": "import com . kscs . util . plugins . xjc . codemodel . ClassName ; import org . xml . sax . ErrorHandler ; import org . xml . sax . SAXException ; import org . xml . sax . SAXParseException ;", "commit_type": "make"}
{"commit_tokens": ["Fix", "absolute", "URL", "resolution", "issue", "when", "a", "base", "tag", "has", "no", "href", "."], "add_tokens": "String href = child . absUrl ( \"href\" ) ; if ( ! href . isEmpty ( ) ) { // ignore <base target> etc baseUri = href ; doc . setBaseUri ( href ) ; // set on the doc so doc.createElement(Tag) will get updated base }", "del_tokens": "baseUri = child . absUrl ( \"href\" ) ; doc . setBaseUri ( baseUri ) ; // set on the doc so doc.createElement(Tag) will get updated base", "commit_type": "fix"}
{"commit_tokens": ["Added", "an", "annotation", "description", "for", "the", "sync", "percent", "IntAnnotation", "."], "add_tokens": ". addInt ( freq ) . describe ( \"INT_SYNC_PERCENT\" ) ) ;", "del_tokens": ". addInt ( freq ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "MessagesProxy", "to", "use", "MessageFormat", ".", "format", "()", "instead", "of", "regexes", "in", "order", "to"], "add_tokens": "import java . util . Date ; import java . util . Locale ; import com . teklabs . gwt . i18n . client . LocaleFactory ; @ Test public void dates ( ) { MessagesProxy . setLocale ( new Locale ( \"en\" ) ) ; Assert . assertEquals ( \"Today is January 1, 1970\" , getMessages ( ) . today ( new Date ( 0 ) ) ) ; }", "del_tokens": "import com . teklabs . gwt . i18n . client . LocaleFactory ; import java . util . Locale ;", "commit_type": "change"}
{"commit_tokens": ["fix", "sync", "when", "empty", "listeners"], "add_tokens": "import java . util . Collections ; while ( ! loggers . isEmpty ( ) ) { removeLogger ( loggers . get ( 0 ) ) ; while ( ! busy . isEmpty ( ) ) { removeBusyListener ( busy . get ( 0 ) ) ; while ( ! updateObjects . isEmpty ( ) ) { removeUpdateObjectsListener ( updateObjects . get ( 0 ) ) ; while ( ! eval . isEmpty ( ) ) { removeEvalListener ( eval . get ( 0 ) ) ;", "del_tokens": "for ( Iterator < Logger > it = loggers . iterator ( ) ; it . hasNext ( ) ; ) { Logger l = it . next ( ) ; removeLogger ( l ) ; for ( Iterator < BusyListener > it = busy . iterator ( ) ; it . hasNext ( ) ; ) { BusyListener b = it . next ( ) ; removeBusyListener ( b ) ; for ( Iterator < UpdateObjectsListener > it = updateObjects . iterator ( ) ; it . hasNext ( ) ; ) { UpdateObjectsListener u = it . next ( ) ; removeUpdateObjectsListener ( u ) ; for ( Iterator < EvalListener > it = eval . iterator ( ) ; it . hasNext ( ) ; ) { EvalListener e = it . next ( ) ; removeEvalListener ( e ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updating", "the", "GwtBootstrap3", "-", "Extra", "links", "."], "add_tokens": "import com . github . gwtbootstrap3 . extras . bootbox . client . Bootbox ; import com . github . gwtbootstrap3 . extras . bootbox . client . callback . AlertCallback ; import com . github . gwtbootstrap3 . extras . bootbox . client . callback . ConfirmCallback ; import com . github . gwtbootstrap3 . extras . bootbox . client . callback . PromptCallback ;", "del_tokens": "import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . Bootbox ; import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . callback . AlertCallback ; import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . callback . ConfirmCallback ; import com . svenjacobs . gwtbootstrap3 . extras . bootbox . client . callback . PromptCallback ;", "commit_type": "update"}
{"commit_tokens": ["Changed", "output", "to", "NAF", "format", "."], "add_tokens": "import ixa . kaflib . * ; try { kaf . addConstituencyFromParentheses ( parsingDoc . toString ( ) ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; } return kaf . toString ( ) ;", "del_tokens": "import ixa . kaflib . KAFDocument ; return parsingDoc . toString ( ) ;", "commit_type": "change"}
{"commit_tokens": ["Use", "weak", "modifiers", "for", "test", "nested", "classes"], "add_tokens": "static AssertFixture assertFixture ( Response response ) { AssertFixture body ( String body ) throws IOException { AssertFixture statusCode ( int statusCode ) { AssertFixture header ( String key , String value ) {", "del_tokens": "// awesome solutions, isn't it? Would be great to find a more proper solution @ Test public void delayResponse ( ) throws IOException { server . enqueue ( Fixtures . DELAYED_1000_MS ) ; long currentTime = System . currentTimeMillis ( ) ; execute ( ) ; long elapsedTime = System . currentTimeMillis ( ) ; assertThat ( elapsedTime - currentTime ) . isGreaterThan ( 1000 ) ; } public static AssertFixture assertFixture ( Response response ) { public AssertFixture body ( String body ) throws IOException { public AssertFixture statusCode ( int statusCode ) { public AssertFixture header ( String key , String value ) {", "commit_type": "use"}
{"commit_tokens": ["Added", "test", "for", "gettin", "single", "response"], "add_tokens": "import java . util . Optional ; public Optional < TestCanvasModel > getTestModel ( ) throws IOException { return getFromCanvas ( BaseImplUTest . URL_FOR_SINGLE_OBJECT_RESPONSE ) ; }", "del_tokens": "import edu . ksu . canvas . interfaces . CanvasReader ;", "commit_type": "add"}
{"commit_tokens": ["add", "latency", "and", "source", "to", "format"], "add_tokens": "public static final byte ROT_ABSENT = Byte . MIN_VALUE ; bb . put ( ROT_ABSENT ) ;", "del_tokens": "bb . put ( ( byte ) 0 ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "bug", "where", "content", "specs", "weren", "t", "being", "expanded", "on", "TranslatedContentSpecs"], "add_tokens": "import org . jboss . pressgang . ccms . rest . v1 . entities . contentspec . RESTContentSpecV1 ; final String expandString = getExpansionString ( RESTTranslatedContentSpecV1 . CONTENT_SPEC_NAME ) ; final RESTTranslatedContentSpecV1 updatedTranslatedContentSpec = getRESTClient ( ) . createJSONTranslatedContentSpec ( expandString , // Expire any content specs as it's translated content spec collection will now be invalid getRESTEntityCache ( ) . expire ( RESTContentSpecV1 . class , updatedTranslatedContentSpec . getContentSpecId ( ) ) ; final String expandString = getExpansionString ( RESTTranslatedContentSpecV1 . CONTENT_SPEC_NAME ) ; final RESTTranslatedContentSpecV1 updatedTranslatedContentSpec = getRESTClient ( ) . updateJSONTranslatedContentSpec ( expandString , // Expire any content specs as it's translated content spec collection will now be invalid getRESTEntityCache ( ) . expire ( RESTContentSpecV1 . class , updatedTranslatedContentSpec . getContentSpecId ( ) ) ; final String expandString = getExpansionString ( RESTv1Constants . TRANSLATED_CONTENT_SPEC_EXPANSION_NAME , RESTTranslatedContentSpecV1 . CONTENT_SPEC_NAME ) ; // Expire any content specs as it's translated content spec collection will now be invalid for ( final RESTTranslatedContentSpecV1 translatedContentSpec : createdNodes . returnItems ( ) ) { getRESTEntityCache ( ) . expire ( RESTContentSpecV1 . class , translatedContentSpec . getContentSpecId ( ) ) ; }", "del_tokens": "final RESTTranslatedContentSpecV1 updatedTranslatedContentSpec = getRESTClient ( ) . createJSONTranslatedContentSpec ( \"\" , final RESTTranslatedContentSpecV1 updatedTranslatedContentSpec = getRESTClient ( ) . updateJSONTranslatedContentSpec ( \"\" , final String expandString = getExpansionString ( RESTv1Constants . TRANSLATED_CONTENT_SPEC_EXPANSION_NAME ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "improper", "classcast", "for", "OutputStream"], "add_tokens": "final OutputStream bw = this . bw ;", "del_tokens": "import java . io . BufferedOutputStream ; final BufferedOutputStream bw = ( BufferedOutputStream ) this . bw ;", "commit_type": "fix"}
{"commit_tokens": ["added", "toString", "()", "to", "ErrorResponse", ".", "java"], "add_tokens": "* @ param title a few words for a dialog title or heading , or null . * @ param message a sentence or two with a more detailed , user friendly * message , or null . @ Override public String toString ( ) { return getClass ( ) . getSimpleName ( ) + \"[\" + \"title = \" + title + \", message = \" + message + \"]\" ; }", "del_tokens": "* @ param title a few words for a dialog title or heading , or null . * @ param message a sentence or two with a more detailed , user friendly * message , or null .", "commit_type": "add"}
{"commit_tokens": ["Add", "additional", "resources", "and", "tests"], "add_tokens": "this . attachments = new Attachments ( this ) ; this . events = new Events ( this ) ; this . projects = new Projects ( this ) ; this . stories = new Stories ( this ) ; this . tags = new Tags ( this ) ; this . teams = new Teams ( this ) ; this . users = new Users ( this ) ; this . workspaces = new Workspaces ( this ) ;", "del_tokens": "this . users = new Users ( this ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "binary", "input", "stream", "/", "etag", "handling"], "add_tokens": ". thenReturn ( empty ( ) ) ;", "del_tokens": "import static org . mockito . ArgumentMatchers . anyInt ; . thenReturn ( of ( mockInputStream ) ) ; when ( mockInputStream . available ( ) ) . thenReturn ( 0 ) ; when ( mockInputStream . read ( any ( byte [ ] . class ) , anyInt ( ) , anyInt ( ) ) ) . thenReturn ( - 1 ) ; doThrow ( new IOException ( ) ) . when ( mockInputStream ) . close ( ) ;", "commit_type": "update"}
{"commit_tokens": ["Fix", "multiline", "indentation", "and", "printing", "in", "Java", ".", "Also", "fix", "some", "off", "colours", "."], "add_tokens": "printDescription ( examples . getDescription ( ) , \" \" , true ) ;", "del_tokens": "printDescription ( examples . getDescription ( ) , \" \" , true ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "X", "axis", "range", "if", "all", "rows", "are", "unchecked"], "add_tokens": "Entry < String , AbstractGraphRow > row = null ; //prevent Y axis with only 0 values. We may have values such as 4.9E-324 } //prevent X axis not initialized in case of no row displayed //we use last known row if ( minXVal == Long . MAX_VALUE && maxXVal == 0 && row != null ) { maxXVal = row . getValue ( ) . getMaxX ( ) ; minXVal = row . getValue ( ) . getMinX ( ) ; }", "del_tokens": "Entry < String , AbstractGraphRow > row ; //prevent y axis with only 0 values. We may have values such as 4.9E-324 }", "commit_type": "fix"}
{"commit_tokens": ["fix", "spatial", "init", "and", "unit", "test"], "add_tokens": "", "del_tokens": "Thread . sleep ( 500 ) ; // let h2 close the database / * * * For this test , we will check to see that all of the feature tables are * represented by entries in the GEOMETRY_COLUMNS table / view . * @ throws Exception * / @ Test public void createIndexTest ( ) throws Exception { Statement st = connection . createStatement ( ) ; st . execute ( \"CALL CreateSpatialIndex('DEP','THE_GEOM')\" ) ; }", "commit_type": "fix"}
{"commit_tokens": ["add", "link", "to", "https", ":", "//", "github", ".", "com", "/", "zeroturnaround", "/", "zt", "-", "exec", "/", "pull", "/", "25", "in", "JavaDoc"], "add_tokens": "* < p > The < a href = \"https://github.com/zeroturnaround/zt-exec\" > zt - exec < / a > library is something similar . * ( < a href = \"https://github.com/zeroturnaround/zt-exec/pull/25\" > They unfortunately refused to back link this project < / a > . ) < / p > package ch . vorburger . exec ;", "del_tokens": "* < p > The < a href = \"https://github.com/zeroturnaround/zt-exec\" > zt - exec < / a > library is something similar . < / p > package ch . vorburger . exec ;", "commit_type": "add"}
{"commit_tokens": ["Added", "unneeded", ".", "toLowerCase", "()", "."], "add_tokens": "args . add ( \"-strict\" ) . add ( strict . toString ( ) ) ;", "del_tokens": "args . add ( \"-strict\" ) . add ( strict . toString ( ) . toLowerCase ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "problem", "with", "javadoc", "."], "add_tokens": "public static final String TOC_POSITION = \"toc-position\" ; * Sets which admonition icons to use . Attributes . IMAGE_ICONS constant can be used to use the original icons with images or Attributes . FONT_ICONS for font icons ( font - awesome ) .", "del_tokens": "* Sets which admonition icons to use . Attributes . ORIGINAL_ADMONITION_ICONS_WITH_IMG constant can be used to use the original icons with images .", "commit_type": "fix"}
{"commit_tokens": ["Added", "better", "error", "handling", "when", "invoking", "methods", "for", "non", "-", "generics", "with", "generic", "types"], "add_tokens": "import autofixture . generators . objects . implementationdetails . TypeAssertions ; Class < ? > requestedType = others [ 0 ] . getClass ( ) ; TypeAssertions . assertIsNotParameterized ( requestedType , \"otherThan() does not work for generics. Try Any.anonymous(new InstanceOf<MyType<GenericType>>() {}, otherThan(x,y,z))\" ) ; return Any . anonymous ( ( Class < T > ) requestedType , InlineGenerators . otherThan ( others ) ) ;", "del_tokens": "if ( others [ 0 ] . getClass ( ) . getTypeParameters ( ) . length > 0 ) { throw new RuntimeException ( \"otherThan() does not work for generics. Try Any.anonymous(new InstanceOf<MyType<GenericType>>() {}, otherThan(x,y,z))\" ) ; } return Any . anonymous ( ( Class < T > ) others [ 0 ] . getClass ( ) , InlineGenerators . otherThan ( others ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "how", "files", "are", "renmaed", "so", "that", "it", "works", "on", "windows", "too"], "add_tokens": "File to = new File ( databaseDir , currentFileName ( ) ) ; boolean ok = tempFile . renameTo ( to ) ; Files . write ( manifest + \"\\n\" , to , Charsets . UTF_8 ) ;", "del_tokens": "boolean ok = tempFile . renameTo ( new File ( databaseDir , currentFileName ( ) ) ) ; throw new IOException ( String . format ( \"Failed to rename temp file '%s' to descriptor file '%s'\" , temp , manifest ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "test", "case", "for", "NotContaining", "part", "type"], "add_tokens": "operations . getVersion ( ) . getVersion ( ) . compareTo ( \"93.2.0\" ) < 0 ) . createQuery ( ) ;", "del_tokens": "operations . getVersion ( ) . getVersion ( ) . compareTo ( \"3.2.0\" ) < 0 ) . createQuery ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "synchronization", "issue", ".", "Holding", "on", "to", "the", "m_queue", "lock", "when", "delivering", "to", "the", "EventAdmin", "==", "bad", "."], "add_tokens": "deliver ( ) ; cleanup ( ) ; deliver ( ) ; cleanup ( ) ; deliver ( ) ; return m_service ; m_service = null ; EventAdmin forDelivery = m_service ; if ( forDelivery == null ) return ; } while ( m_queue . size ( ) > 0 ) { Event event ; synchronized ( m_queue ) event = ( Event ) m_queue . remove ( 0 ) ; forDelivery . postEvent ( event ) ; synchronized ( m_queue ) { m_queue . remove ( 0 ) ; }", "del_tokens": "* * This design simplifies the PublishAppender , as it can assume that the service is always * available . deliver ( ) ; cleanup ( ) ; deliver ( ) ; cleanup ( ) ; synchronized ( m_queue ) { deliver ( ) ; return m_service ; } synchronized ( m_queue ) { m_service = null ; } synchronized ( m_queue ) if ( m_service == null ) { return ; } while ( m_queue . size ( ) > 0 ) Event event = ( Event ) m_queue . remove ( 0 ) ; m_service . postEvent ( event ) ; m_queue . remove ( 0 ) ;", "commit_type": "fix"}
{"commit_tokens": ["add", "com", ".", "sdl", ".", "bootstrap", ".", "button", ".", "UploadFile"], "add_tokens": "* Upload file with AutoIT exe", "del_tokens": "* Uploud file with AutoIT exe // Utils.sleep(1500);", "commit_type": "add"}
{"commit_tokens": ["Fix", "code", "to", "invoke", "Wrapper", "interfaces", "using", "INVOKEINTERFACE", "rather", "than", "INVOKEVIRTUAL", "."], "add_tokens": "// skip 3 for IFEQ, 3 for CHECKCAST, and 5 for INVOKEINTERFACE cfw . add ( ByteCode . IFEQ , 11 ) ; cfw . add ( ByteCode . INVOKEINTERFACE ,", "del_tokens": "// skip 3 for IFEQ, 3 for CHECKCAST, and 3 for INVOKEVIRTUAL cfw . add ( ByteCode . IFEQ , 9 ) ; cfw . add ( ByteCode . INVOKEVIRTUAL ,", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "multiple", "ContentType", "Responses"], "add_tokens": "private ContentType content_type ; private Double duration ; private String stdout ; public ContentType getContentType ( ) { return content_type ; } public Double getDuration ( ) { return duration ; } public String getStdout ( ) { return stdout ; }", "del_tokens": "public ContentType content_type ; public Double duration ; public String stdout ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", ":", "Fields", "of", "type", "Set", "(", "HashSet", "and", "SortedSet", ")", "are", "now", "supported"], "add_tokens": "import java . util . ArrayList ; import java . util . LinkedHashSet ; import java . util . SortedSet ; import java . util . TreeSet ; @ SuppressWarnings ( \"unchecked\" ) if ( SortedSet . class . isAssignableFrom ( type ) ) return new TreeSet ( ) ; else if ( LinkedHashSet . class . isAssignableFrom ( type ) ) return new LinkedHashSet ( ) ; else if ( List . class . isAssignableFrom ( type ) ) return new ArrayList ( ) ; else {", "del_tokens": "import com . beust . jcommander . internal . Lists ; import com . beust . jcommander . internal . Sets ; if ( List . class . isAssignableFrom ( type ) ) { return Lists . newArrayList ( ) ; } else if ( Set . class . isAssignableFrom ( type ) ) { return Sets . newLinkedHashSet ( ) ; } else {", "commit_type": "fix"}
{"commit_tokens": ["use", "external", "links", "for", "the", "build", "notification", "links"], "add_tokens": "import io . fabric8 . annotations . External ; public BuildWatchService ( @ External @ Protocol ( \"http\" ) @ ServiceName ( \"fabric8-console-service\" ) String consoleLink ,", "del_tokens": "public BuildWatchService ( @ Protocol ( \"http\" ) @ ServiceName ( \"fabric8-console-service\" ) String consoleLink ,", "commit_type": "use"}
{"commit_tokens": ["Adds", "configuration", "option", "for", "SSL", "/", "TLS"], "add_tokens": "private static final String REDIS_SSL = \"rediss\" ; @ JsonProperty private boolean ssl = false ; if ( uri . getScheme ( ) . equals ( REDIS_SSL ) ) { this . ssl = true ; } public boolean getSsl ( ) { return ssl ; } public void setSsl ( boolean ssl ) { this . ssl = ssl ; } final JedisPool pool = new JedisPool ( poolConfig , getHost ( ) , getPort ( ) , Protocol . DEFAULT_TIMEOUT , getPassword ( ) , ssl ) ;", "del_tokens": "final JedisPool pool = new JedisPool ( poolConfig , getHost ( ) , getPort ( ) , Protocol . DEFAULT_TIMEOUT , getPassword ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "javadoc", "header", "for", "PhasedHeapFriendlyHashMapTest"], "add_tokens": "* Copyright 2015 Netflix , Inc . / * * * JUnit tests for { @ link PhasedHeapFriendlyHashMap } * * @ author darrenbathgate * * /", "del_tokens": "* Copyright 2013 Netflix , Inc .", "commit_type": "add"}
{"commit_tokens": ["Changed", "default", "CheckType", "of", "RadioCheckField", "to", "TYPE_CHECK", "(", "was"], "add_tokens": "setCheckType ( TYPE_CHECK ) ; checkType = TYPE_CHECK ;", "del_tokens": "setCheckType ( TYPE_CIRCLE ) ; checkType = TYPE_CIRCLE ;", "commit_type": "change"}
{"commit_tokens": ["add", "test", "for", "batch", "delete"], "add_tokens": "import org . umlg . sqlg . test . index . TestForeignKeyIndexPerformance ; TestMultiThread . class , TestForeignKeyIndexPerformance . class", "del_tokens": "TestMultiThread . class", "commit_type": "add"}
{"commit_tokens": ["Remove", "check", "preventing", "turn", "lanes", "from", "showing", "up"], "add_tokens": "turnLanes = lanes ;", "del_tokens": "turnLanes = intersection . getLanes ( ) ; if ( lane . getIndications ( ) != null ) { return true ; }", "commit_type": "remove"}
{"commit_tokens": ["implement", "processing", "of", "jax", "rs", "responses"], "add_tokens": "try ( final RequestHandler requestHandler = mapRequest ( request , response ) ) if ( requestHandler != null ) { runPostProcess ( interceptors , request , response , requestHandler ) ; requestHandler . process ( request , response ) ; } else { Responses . notFound ( request , response ) ; }", "del_tokens": "final RequestHandler requestHandler = mapRequest ( request , response ) ; if ( requestHandler != null ) { runPostProcess ( interceptors , request , response , requestHandler ) ; requestHandler . process ( request , response ) ; } else Responses . notFound ( request , response ) ;", "commit_type": "implement"}
{"commit_tokens": ["updating", "enrichment", "to", "word", "wrap"], "add_tokens": "import org . apache . commons . lang3 . text . WordUtils ; private static final int BANNER_SIZE = 77 ; private static final int WRAP_LENGTH = 77 ; sb . append ( Strings . repeat ( \"*\" , BANNER_SIZE ) ) ; sb . append ( \" The original (matching) problem was: \" ) . append ( '\\n' ) ; sb . append ( WordUtils . wrap ( original , WRAP_LENGTH ) ) . append ( '\\n' ) ; sb . append ( \" \" ) . append ( WordUtils . wrap ( updateMessage , WRAP_LENGTH ) ) . append ( '\\n' ) ; sb . append ( Strings . repeat ( \"*\" , BANNER_SIZE ) ) ;", "del_tokens": "private static final int bannerSize = 75 ; sb . append ( Strings . repeat ( \"*\" , bannerSize ) ) ; sb . append ( \" The original (matching) problem was: \" + original ) . append ( '\\n' ) ; sb . append ( \" \" ) . append ( updateMessage ) . append ( '\\n' ) ; sb . append ( Strings . repeat ( \"*\" , bannerSize ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Add", "missing", "filters", "attribute", "in", "search", "result", "."], "add_tokens": "private Map < String , String > filters ; public Map < String , String > getFilters ( ) { return filters ; } public void setFilters ( Map < String , String > filters ) { this . filters = filters ; }", "del_tokens": "// private Map<String, String> filters; // public Map<String, String> getFilters() { // return filters; // } // // public void setFilters(Map<String, String> filters) { // this.filters = filters; // }", "commit_type": "add"}
{"commit_tokens": ["Use", "a", "regular", "expression", "to", "split", "parameters"], "add_tokens": "public static final String COMMAND_PARAMETER_SEPARATOR_REGEXP = \"\\\\s+\" ; }", "del_tokens": "public static final String COMMAND_PARAMETER_SEPARATOR = \" \" ; }", "commit_type": "use"}
{"commit_tokens": ["moved", "BuildTool", "as", "build", "package", "is", "ignored", "by", "git"], "add_tokens": "import pl . touk . sputnik . configuration . BuildTool ;", "del_tokens": "import pl . touk . sputnik . build . BuildTool ;", "commit_type": "move"}
{"commit_tokens": ["adds", "contentDirRoot", "and", "workDir", "properties", "to", "the", "test", "-", "init", ".", "json", "for", "reference", "and", "to", "facilitate", "integration", "tests", "."], "add_tokens": "import org . apache . commons . lang . StringUtils ; private void initializeLocalDirectories ( InitParams initParams ) { if ( StringUtils . isBlank ( initParams . getWorkDir ( ) ) ) { throw new IllegalArgumentException ( \"workDir must not be blank.\" ) ; } if ( StringUtils . isBlank ( initParams . getContentDirRoot ( ) ) ) { throw new IllegalArgumentException ( \"contentDirRoot must not be blank.\" ) ; } this . workDir = createDirectoryIfNotExists ( initParams . getWorkDir ( ) ) ; this . contentDirRoot = createDirectoryIfNotExists ( initParams . getContentDirRoot ( ) ) ; private File createDirectoryIfNotExists ( String path ) {", "del_tokens": "private void initializeLocalDirectories ( InitParams initParams ) throws IOException { String defaultDirRoot = System . getProperty ( \"java.io.tmpdir\" ) + File . separator ; this . workDir = createDirectoryIfNotExists ( initParams . getWorkDir ( ) , defaultDirRoot + \"snapshot-work\" ) ; this . contentDirRoot = createDirectoryIfNotExists ( initParams . getContentDirRoot ( ) , defaultDirRoot + \"snapshot-content\" ) ; * @ param defaultDir private File createDirectoryIfNotExists ( String path , String defaultDir ) { if ( path == null ) { path = defaultDir ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "more", "complete", "GET", "implementation"], "add_tokens": "import edu . amherst . acdc . trellis . http . LdpResource ; import edu . amherst . acdc . trellis . spi . ResourceService ; import edu . amherst . acdc . trellis . spi . SerializationService ;", "del_tokens": "import edu . amherst . acdc . trellis . app . resources . LdpResource ; import edu . amherst . acdc . trellis . spi . ResourceService ; import edu . amherst . acdc . trellis . spi . SerializationService ;", "commit_type": "add"}
{"commit_tokens": ["Made", "CloseQuietly#closeQuietly", "(", "JarFile", ")", "public"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public static void closeQuietly ( JarFile closeable ) { if ( closeable != null ) { try { closeable . close ( ) ; } catch ( IOException e ) { log . debug ( \"Exception while closing resource\" , e ) ; } } } 0 }", "del_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; static void closeQuietly ( JarFile closeable ) { if ( closeable != null ) { try { closeable . close ( ) ; } catch ( IOException e ) { log . debug ( \"Exception while closing resource\" , e ) ; } } } }", "commit_type": "make"}
{"commit_tokens": ["Implement", "download", "to", "temporary", "file"], "add_tokens": "public void stop ( ) { this . stop ( true ) ; } / * * Immediately but gracefully stop this client . * * @ param wait Whether to wait for the client execution thread to complete * or not . This allows for the client 's state to be settled down in one of * the < tt > DONE < / tt > or < tt > ERROR < / tt > states when this method returns . * / public void stop ( boolean wait ) { if ( wait ) { try { this . thread . join ( ) ; } catch ( InterruptedException ie ) { // Ignore } } this . torrent . close ( ) ;", "del_tokens": "public synchronized void stop ( ) {", "commit_type": "implement"}
{"commit_tokens": ["Fix", "for", "mdw", "as", "springboot", "dependency", "when", "not", "in", "dev", "mode"], "add_tokens": "else if ( new File ( WebAppContext . getMdw ( ) . getOverrideRoot ( ) + path ) . isFile ( ) ) {", "del_tokens": "if ( new File ( WebAppContext . getMdw ( ) . getOverrideRoot ( ) + path ) . isFile ( ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "lib", "with", "SingleActivity"], "add_tokens": "import com . wealthfront . magellan . support . SingleActivity ; public class MainActivity extends SingleActivity { @ Override protected Navigator createNavigator ( ) { return Navigator . withRoot ( new HomeScreen ( ) ) . loggingEnabled ( true ) . build ( ) ; }", "del_tokens": "import android . support . v7 . app . AppCompatActivity ; public class MainActivity extends AppCompatActivity { Navigator navigator ; navigator = Navigator . withRoot ( new HomeScreen ( ) ) . loggingEnabled ( true ) . build ( ) ; navigator . onCreate ( this , savedInstanceState ) ; } @ Override public void onBackPressed ( ) { if ( ! navigator . handleBack ( ) ) { super . onBackPressed ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["fixed", "handling", "of", "0", "-", "Part", "derived", "methods"], "add_tokens": "if ( criteria != null ) { disjunctionBuilder . add ( criteria . build ( ) ) ; }", "del_tokens": "disjunctionBuilder . add ( criteria . build ( ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "Javadoc", "in", "the", "new", "Default!Cipher", "which", "is", "causing", "the", "TravisCI", "build", "to", "fail"], "add_tokens": "* @ throws GeneralSecurityException a general security exception * @ throws GeneralSecurityException a general security exception * @ throws GeneralSecurityException a general security exception * @ throws GeneralSecurityException a general security exception / * * * This method is used to encrypt ( Symmetric ) plainText coming in input using AES algorithm * @ param plainText the plain text string to be encrypted * @ return Base64 encoded AES encrypted cipher text * / / * * * A method to decrypt the provided cipher text . * * @ param cipherText AES encrypted cipherText * @ return decrypted text * /", "del_tokens": "/** @{inheritDoc} */ /** @{inheritDoc} */", "commit_type": "fix"}
{"commit_tokens": ["added", "typerefs", "and", "existential", "predicate", "suffix", "in", "arrays"], "add_tokens": "case ARRAYVAL : Tree primitive = node . getChild ( 0 ) ; Tree existential = node . getChild ( 1 ) ; return new PrimitiveConsumer ( stack , makePrimitiveValidator ( primitive ) , tokenToPredicate ( existential ) ) ; case TYPEREF : String tname = node . getChild ( 0 ) . getText ( ) ; Tree typedef = Check . illegalargument . assertNotNull ( tMap . get ( tname ) , \"type not found \" + tname ) ; return makeConsumer ( typedef , stack ) ; } String valDef = t == null return primitiveValidatorFactory . create ( valDef ) ; public PrimitiveConsumer ( Stack < EventConsumer > stack , Fun1 < Object , String > validator , ExistentialPredicate pred ) { super ( stack , pred ) ; this . validator = validator ; } pop ( ) ;", "del_tokens": "import java . nio . channels . IllegalSelectorException ; import java . util . HashMap ; import com . nominanuda . dataobject . JsonContentHandler ; } String typeDef = t == null return primitiveValidatorFactory . create ( typeDef ) ;", "commit_type": "add"}
{"commit_tokens": ["Improve", "error", "handling", "in", "TreasureDataIngester"], "add_tokens": "private final String request ; public HttpResponseError ( String request , int statusCode , String reasonPhrase ) this . request = request ; \"request='\" + request + '\\'' + \", statusCode=\" + statusCode + errorHandler . handle ( new HttpResponseError ( response . request , response . statusCode , response . reasonPhrase ) ) ; private final String endpoint ; private final String request ; Response ( String request , int statusCode , String reasonPhrase , T content ) this . request = request ; public String getRequest ( ) { return request ; } this . endpoint = endpoint ; return new Response < > ( String . format ( \"PUT %s/v3/table/import_with_id/%s/%s/%s/msgpack.gz\" , endpoint , database , table , uniqueId ) , response . code ( ) , response . message ( ) , null ) ;", "del_tokens": "public HttpResponseError ( int statusCode , String reasonPhrase ) \"statusCode=\" + statusCode + errorHandler . handle ( new HttpResponseError ( response . statusCode , response . reasonPhrase ) ) ; Response ( int statusCode , String reasonPhrase , T content ) return new Response < > ( response . code ( ) , response . message ( ) , null ) ;", "commit_type": "improve"}
{"commit_tokens": ["Fix", "bug", "on", "fetching", "locations", "(", "ListApplicationServlet", ")"], "add_tokens": "LocationSummary locationDetails = BROOKLKYN_API . getLocationApi ( ) . get ( locationSummary . getId ( ) , null ) ; if ( locationDetails != null ) { jsonLocation . addProperty ( \"id\" , locationDetails . getId ( ) ) ; jsonLocation . addProperty ( \"name\" , locationDetails . getName ( ) ) ; jsonLocation . addProperty ( \"type\" , locationDetails . getType ( ) ) ; jsonLocation . addProperty ( \"spec\" , locationDetails . getSpec ( ) ) ;", "del_tokens": "for ( String location : application . getSpec ( ) . getLocations ( ) ) { LocationSummary locationSumary = BROOKLKYN_API . getLocationApi ( ) . get ( location , null ) ; if ( locationSumary != null ) { jsonLocation . addProperty ( \"id\" , locationSumary . getId ( ) ) ; jsonLocation . addProperty ( \"name\" , locationSumary . getName ( ) ) ; jsonLocation . addProperty ( \"type\" , locationSumary . getType ( ) ) ; jsonLocation . addProperty ( \"spec\" , locationSumary . getSpec ( ) ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Improve", "error", "on", "failure", "a", "tad", "."], "add_tokens": "import java . util . logging . Level ; LOG . log ( Level . FINE , \"Error decoding\" , e ) ; modelMap . addAttribute ( \"error\" , getMessageTrace ( e ) ) ; private String getMessageTrace ( Exception e ) { StringBuilder b = new StringBuilder ( e . getMessage ( ) ) ; for ( Throwable t = e . getCause ( ) ; t != null ; t = t . getCause ( ) ) { b . append ( \", \" ) . append ( t ) ; } return b . toString ( ) ; }", "del_tokens": "LOG . fine ( \"Error decoding \" + e . getMessage ( ) ) ; modelMap . addAttribute ( \"error\" , e . getMessage ( ) ) ;", "commit_type": "improve"}
{"commit_tokens": ["made", "sure", "sdk", "classes", "are", "not", "loaded", "by", "extended", "class", "loader"], "add_tokens": "FileSupport . copyClassLoadableResourceToFileSystem ( pathToResources + \"/jars/iglu-telnet-server-1.0.jar\" , tmpDir . getAbsolutePath ( ) + \"/jars/\" ) ;", "del_tokens": "FileSupport . copyClassLoadableResourceToFileSystem ( pathToResources + \"/jars/iglu-telnet-server-1.0.jar\" , tmpDir . getAbsolutePath ( ) + \"/jars/\" ) ;", "commit_type": "make"}
{"commit_tokens": ["Move", "Spring", "classes", "to", "new", "package", "."], "add_tokens": "import com . github . valdr . thirdparty . spring . AnnotationUtils ;", "del_tokens": "import com . github . valdr . util . AnnotationUtils ;", "commit_type": "move"}
{"commit_tokens": ["Use", "the", "database", "metadata", "to", "determine", "if", "a", "character", "is", "a", "valid", "name", "identifier", "and", "if", "so", "do", "not", "break", "tab", "-", "completion", "on", "those", "characters", "."], "add_tokens": "final String extraNameCharacters = meta . getExtraNameCharacters ( ) == null ? \"\" : meta . getExtraNameCharacters ( ) ; // underscore and characters that are specified // by the database to be valid name identifiers. && extraNameCharacters . indexOf ( c ) == - 1 ;", "del_tokens": "// underscore and dollar. && c != '$' ;", "commit_type": "use"}
{"commit_tokens": ["fix", "bug", "with", "null", "hash", "codes", "and", "add", "test", "case", "that", "triggered", "it"], "add_tokens": "if ( hash != null ) { lastModifiedMap . put ( child , hash ) ; }", "del_tokens": "lastModifiedMap . put ( child , hash ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "JSONRPCImporter", "factory", "name", "and", "package", "name"], "add_tokens": "package org . ow2 . chameleon . fuchsia . importer . jsonrpc . it ; ipojoHelper . createComponentInstance ( \"org.ow2.chameleon.fuchsia.importer.jsonrpc.JSONRPCImporter\" , conf ) ;", "del_tokens": "package org . ow2 . chameleon . fuchsia . jsonrpc . importer . it ; ipojoHelper . createComponentInstance ( \"Fuchsia-Importer:JSON-RPC\" , conf ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixing", ":", "Classpath", "config", "files", "are", "not", "loading", "in", "servlet", "configurations", "."], "add_tokens": "AuditManager . getInstance ( ) ; AuditManager . shutdown ( ) ;", "del_tokens": "import javax . servlet . ServletContext ; import org . audit4j . core . Context ; import org . audit4j . core . util . EnvUtil ; if ( EnvUtil . hasConfigFileExists ( getConfFilePath ( contextEvent . getServletContext ( ) ) ) ) { AuditManager . startWithConfiguration ( getConfFilePath ( contextEvent . getServletContext ( ) ) ) ; } else { Context . setConfigFilePath ( getConfFilePath ( contextEvent . getServletContext ( ) ) ) ; } AuditManager . getInstance ( ) . shutdown ( ) ; / * * * Gets the conf file path . * * @ param context * the context * @ return the conf file path * / private String getConfFilePath ( ServletContext context ) { return context . getRealPath ( \"/WEB-INF/classes\" ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Adding", "VNC", "console", "access", "."], "add_tokens": "// Commented-out because now using CDATA // if(ch=='<') return \"&lt;\"; // if(ch=='>') return \"&gt;\"; // if(ch=='&') return \"&amp;\";", "del_tokens": "if ( ch == '<' ) return \"&lt;\" ; if ( ch == '>' ) return \"&gt;\" ; if ( ch == '&' ) return \"&amp;\" ;", "commit_type": "add"}
{"commit_tokens": ["added", "IGNORE", "this", "error", "messages", "for", "some", "tests", "."], "add_tokens": "throw new IOException ( \"IGNORE. This is an expected commit exception for testing.\" ) ; throw new IOException ( \"IGNORE. This is an expected rollback exception for testing.\" ) ; throw new IOException ( \"IGNORE. This is an expected write exception for testing.\" ) ;", "del_tokens": "throw new IOException ( ) ; throw new IOException ( ) ; throw new IOException ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Removed", "explicit", "call", "to", "BC", "."], "add_tokens": "import java . security . Provider ; sd = sdGenerator . generate ( \"1.2.840.113549.1.7.1\" , signable , true , ( Provider ) null , true ) ;", "del_tokens": "import java . security . Security ; sd = sdGenerator . generate ( ( String ) \"1.2.840.113549.1.7.1\" , signable , true , Security . getProvider ( \"BC\" ) , true ) ;", "commit_type": "remove"}
{"commit_tokens": ["Add", "support", "for", "writing", "the", "DocumentEnd", "-", "Tag", "after", "writing", "a", "Document", "."], "add_tokens": "import com . esotericsoftware . yamlbeans . parser . DocumentEndEvent ; emitter . emit ( new DocumentEndEvent ( config . writeConfig . explicitEndDocument ) ) ;", "del_tokens": "emitter . emit ( Event . DOCUMENT_END_FALSE ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "junit", "test", "for", "MaskingRewritePolicy", ".", "java"], "add_tokens": "// get the markers for the log event. If no markers, nothing can be", "del_tokens": "// get the markers for the log event. If no markers, nothing cn be", "commit_type": "add"}
{"commit_tokens": ["add", "outputfile", "to", "log", "line"], "add_tokens": "+ \" to \" + outputFile ) . log ( ) ) ;", "del_tokens": "+ \" \" ) . log ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "main", "()", "routine", "for", "command", "line", "processing"], "add_tokens": "return \"Markdown Processor for Java (version 0.1.0)\" ; } public static void main ( String [ ] args ) { StringBuffer buf = new StringBuffer ( ) ; char [ ] cbuf = new char [ 1024 ] ; java . io . Reader in = new java . io . InputStreamReader ( System . in ) ; try { int charsRead = in . read ( cbuf ) ; while ( charsRead >= 0 ) { buf . append ( cbuf , 0 , charsRead ) ; charsRead = in . read ( cbuf ) ; } System . out . println ( new MarkdownProcessor ( ) . markdown ( buf . toString ( ) ) ) ; } catch ( java . io . IOException e ) { System . err . println ( \"Error reading input: \" + e . getMessage ( ) ) ; System . exit ( 1 ) ; }", "del_tokens": "return \"Markdown Processor version 0.1.0\" ;", "commit_type": "add"}
{"commit_tokens": ["use", "the", "shortcut", "method", "to", "get", "content"], "add_tokens": "customer . setFirstName ( record . getContentByIndex ( 0 ) ) ; customer . setLastName ( record . getContentByIndex ( 1 ) ) ; customer . setEmail ( record . getContentByIndex ( 2 ) ) ; birthday = TypeConverter . getDateTypedFieldContent ( record . getContentByIndex ( 3 ) , \"dd/MM/yyyy\" ) ; customer . setPhone ( record . getContentByIndex ( 4 ) ) ; String gender = record . getContentByIndex ( 5 ) ;", "del_tokens": "customer . setFirstName ( record . getFieldByIndex ( 0 ) . getContent ( ) ) ; customer . setLastName ( record . getFieldByIndex ( 1 ) . getContent ( ) ) ; customer . setEmail ( record . getFieldByIndex ( 2 ) . getContent ( ) ) ; birthday = TypeConverter . getDateTypedFieldContent ( record . getFieldByIndex ( 3 ) . getContent ( ) , \"dd/MM/yyyy\" ) ; customer . setPhone ( record . getFieldByIndex ( 4 ) . getContent ( ) ) ; String gender = record . getFieldByIndex ( 5 ) . getContent ( ) ;", "commit_type": "use"}
{"commit_tokens": ["Fix", "large", "content", "order", "test"], "add_tokens": "mainAction = composite ( contentType ( \"application/xml\" ) , mainAction ) ; mainAction = composite ( contentType ( \"application/json\" ) , mainAction ) ;", "del_tokens": "mainAction = composite ( mainAction , contentType ( \"application/xml\" ) ) ; mainAction = composite ( mainAction , contentType ( \"application/json\" ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["changed", "createAdapterClass", "()", "to", "only", "generate", "methods", "for", "properties", "defined", "in", "the", "wrapped", "object", "itself", "not", "for", "properties", "defined", "in", "prototypes", ".", "This", "makes", "sense", "as", "the", "prototype", "for", "the", "wrapped", "object", "becomes", "the", "LiveConnect", "wrapper", "thus", "prototype", "properties", "become", "inaccessible", "anyway", "."], "add_tokens": "( jsObj != null && jsObj . has ( method . getName ( ) , jsObj ) ) ) Object [ ] ids = jsObj . getIds ( ) ; String id = ( String ) ids [ j ] ; if ( generatedMethods . containsKey ( id ) ) Object f = jsObj . get ( id , jsObj ) ;", "del_tokens": "FlattenedObject obj = jsObj != null ? new FlattenedObject ( jsObj ) : null ; ( obj != null && obj . hasProperty ( method . getName ( ) ) ) ) Object [ ] ids = obj . getIds ( ) ; if ( generatedMethods . containsKey ( ( String ) ids [ j ] ) ) Object f = obj . getProperty ( ids [ j ] ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "event", "bus", "filter", "to", "AbstractEventBusBridge"], "add_tokens": "import com . netflix . eventbus . spi . EventFilter ; protected EventFilter filter ; / * * * Predicate used to filter which events may be sent to the sink * @ param filter * / public T withFilter ( EventFilter filter ) { this . filter = filter ; return self ( ) ; } protected final EventFilter filter ; this . filter = init . filter ; if ( filter != null ) this . eventBus . registerSubscriber ( filter , subscriber ) ; else this . eventBus . registerSubscriber ( subscriber ) ;", "del_tokens": "this . eventBus . registerSubscriber ( subscriber ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "for", "soil", "layer", "slitting", "function"], "add_tokens": "* @ param isICLayer True for handling initial condition soil layers for ( int j = 0 ; j < weights . size ( ) ; j ++ ) { layer = soilLayers . get ( j + start ) ;", "del_tokens": "for ( int j = 0 ; j < weights . size ( ) ; j ++ , start ++ ) { layer = soilLayers . get ( start ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "a", "target", "for", "generationg", "SnappyNativeLoader", "bytecode"], "add_tokens": "int readBytes = 0 ; while ( readBytes < header . length ) { int ret = in . read ( header , readBytes , header . length - readBytes ) ; if ( ret == - 1 ) break ; readBytes += ret ; } if ( readBytes < header . length || header [ 0 ] != SnappyCodec . MAGIC_HEADER [ 0 ] ) {", "del_tokens": "int readBytes = in . read ( header , 0 , header . length ) ; if ( header [ 0 ] != SnappyCodec . MAGIC_HEADER [ 0 ] ) {", "commit_type": "add"}
{"commit_tokens": ["fixing", "comments", "in", "unit", "tests"], "add_tokens": "* confirm that exception is thrown on incorrect input * confirm that exception is thrown on incorrect input", "del_tokens": "* confirm that exception is thrown on null input * confirm that exception is thrown on null input", "commit_type": "fix"}
{"commit_tokens": ["Added", "more", "AST", "nodes", "visitor", "pattern"], "add_tokens": "import com . bazaarvoice . jless . ast . visitor . NodeVisitor ; public abstract class Node extends MutableTreeNodeImpl < Node > { this ( ) ; public boolean accept ( NodeVisitor visitor ) { if ( visitor . visitEnter ( this ) ) { for ( Node child : getChildren ( ) ) { if ( ! child . accept ( visitor ) ) { break ; } } } return visitor . visit ( this ) ;", "del_tokens": "import com . bazaarvoice . jless . print . Printer ; public class Node extends MutableTreeNodeImpl < Node > { // empty constructor public void print ( Printer printer ) { printer . append ( \"Yay!\" ) ; printer . printChildren ( this ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "artifactId", "to", "be", "more", "descriptive", "."], "add_tokens": "* { @ code @ } Parameter with \"variableArity = true\" .", "del_tokens": "* @ Parameter with \"variableArity = true\" .", "commit_type": "change"}
{"commit_tokens": ["Add", "a", "utility", "method", "for", "creating", "a", "variety", "of", "absolute", "and", "relative", "permutations", "of", "a", "path", "for", "testing", "."], "add_tokens": "return isSameFileAs ( toPath ( path ) ) ; } / * * * Asserts that the path resolves to the same file as the given path . * / public PathSubject isSameFileAs ( Path path ) throws IOException { if ( ! Files . isSameFile ( getSubject ( ) , path ) ) {", "del_tokens": "if ( ! Files . isSameFile ( getSubject ( ) , toPath ( path ) ) ) {", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "I", "/", "O", "over", "services", "and", "operations"], "add_tokens": "/ * * * This plugin supports discovery over services and operations * If this is true we will discovery operations rather than services * / private boolean operationDiscovery = false ; IServiceDiscoveryPlugin plugin = new RDFSInputOutputDiscoveryPlugin ( connector , true ) ;", "del_tokens": "IServiceDiscoveryPlugin plugin = new RDFSInputOutputDiscoveryPlugin ( ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "entity", "class", "for", "exception"], "add_tokens": ". entity ( e . getEntity ( ) )", "del_tokens": ". entity ( e )", "commit_type": "use"}
{"commit_tokens": ["Updated", "to", "fix", "problems", "with", "certain", "types", "of", "modified", "MPP", "files", "."], "add_tokens": "int available ; available = is . available ( ) ; if ( available == 0 ) { break ; } if ( itemSize < 0 ) { itemSize = available ; } else { if ( itemSize > available ) { itemSize = available ; } } byte [ ] result = null ; if ( m_array [ index ] != null ) { result = m_array [ index ] . byteArrayValue ( ) ; } return ( result ) ;", "del_tokens": "return ( m_array [ index ] . byteArrayValue ( ) ) ;", "commit_type": "update"}
{"commit_tokens": ["Remove", "dependency", "on", "Spring", "for", "MapSessionRepository"], "add_tokens": "if ( sessions == null ) { throw new IllegalArgumentException ( \"sessions cannot be null\" ) ; }", "del_tokens": "import org . springframework . util . Assert ; Assert . notNull ( sessions , \"sessions cannot be null\" ) ;", "commit_type": "remove"}
{"commit_tokens": ["fixing", "outdated", "deps", "that", "were", "still", "bringing", "in", "logging", "/", "log4j", "...", "completing", "logback", "switch"], "add_tokens": "import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; private final Logger logger = LoggerFactory . getLogger ( getClass ( ) ) ; logger . info ( \"Setting status: {}\" , status ) ; logger . info ( \"Encoding redirect URL: '{}'\" , url ) ; logger . info ( \"Sending redirect: '{}'\" , redirectUrl ) ; logger . info ( \"Setting status: {}\\nNo Message\" , status ) ; logger . info ( \"Setting status: {}\\nMessage: {}\" , status , message ) ; logger . info ( \"Set header '{}' = '{}'\" , name , value ) ;", "del_tokens": "import org . commonjava . util . logging . Logger ; private final Logger logger = new Logger ( getClass ( ) ) ; logger . info ( \"Setting status: %s\" , status ) ; logger . info ( \"Encoding redirect URL: '%s'\" , url ) ; logger . info ( \"Sending redirect: '%s'\" , redirectUrl ) ; logger . info ( \"Setting status: %s\\nNo Message\" , status ) ; logger . info ( \"Setting status: %s\\nMessage: %s\" , status , message ) ; logger . info ( \"Set header '%s' = '%s'\" , name , value ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "null", "key", "when", "expression", "has", "no", "alias", "make", "lookup", "case", "insensitive"], "add_tokens": "import java . util . Locale ; String aliasName = ( ( Aliasable ) expression ) . aliasName ( ) ; if ( aliasName != null ) { key = aliasName ; } return key == null ? null : key . toLowerCase ( Locale . US ) ; return ( V ) keyMap . get ( key . toLowerCase ( Locale . US ) ) ;", "del_tokens": "key = ( ( Aliasable ) expression ) . aliasName ( ) ; return key ; return ( V ) keyMap . get ( key ) ;", "commit_type": "fix"}
{"commit_tokens": ["Make", "OsiamUserService", "uses", "its", "own", "builder", "too", "now", "."], "add_tokens": "final private static String endpoint = \"http://localhost:8080/osiam-server/\" ; service = new OsiamUserService . Builder ( endpoint ) . build ( ) ; private void then_returned_user_values ( UUID uuid ) throws Exception { private User get_expected_user ( ) throws Exception { User expectedUser ;", "del_tokens": "import org . codehaus . jackson . JsonParseException ; import org . codehaus . jackson . map . JsonMappingException ; import org . junit . Ignore ; import java . net . URI ; service = ServiceBuilder . buildUserService ( URI . create ( \"http://localhost:8080/osiam-server/\" ) , \"irrelvevant\" , URI . create ( \"http://localhost:5000\" ) , \"irrelevant\" ) ; private void then_returned_user_values ( UUID uuid ) throws IOException { private User get_expected_user ( ) throws JsonParseException , JsonMappingException , IOException { User expectedUser = null ;", "commit_type": "make"}
{"commit_tokens": ["add", "unit", "tests", "for", "automap"], "add_tokens": "if ( cls . isAssignableFrom ( Long . class ) ) if ( cls . isAssignableFrom ( Long . class ) )", "del_tokens": "import java . util . Date ; if ( cls . isAssignableFrom ( Date . class ) ) return new Date ( t . getTime ( ) ) ; else if ( cls . isAssignableFrom ( Long . class ) ) if ( cls . isAssignableFrom ( Date . class ) ) return new Date ( t . getTime ( ) ) ; else if ( cls . isAssignableFrom ( Long . class ) )", "commit_type": "add"}
{"commit_tokens": ["Use", "EmvBitStringDecoder", "for", "TSI", "."], "add_tokens": "public class TSIDecoder extends EmvBitStringDecoder { super ( \"fields/tsi.txt\" , true ) ;", "del_tokens": "public class TSIDecoder extends FixedLengthDecoder { super ( 4 , \"8000\" , \"Offline data authentication was performed\" , \"4000\" , \"Cardholder verification was performed\" , \"2000\" , \"Card risk management was performed\" , \"1000\" , \"Issuer authentication was performed\" , \"0800\" , \"Terminal risk management was performed\" , \"0400\" , \"Script processing was performed\" ) ;", "commit_type": "use"}
{"commit_tokens": ["Added", "test", "case", "for", "wild", "cards"], "add_tokens": "LOG . trace ( \"Colisiion found between {} and {}\" , previousElement . getName ( ) , LOG . trace ( \"New candidate is {}. Removed {}\" , tmp . getName ( ) ,", "del_tokens": "LOG . trace ( \"Collisiion found between {} and {}\" , previousElement . getName ( ) , LOG . trace ( \"New canditate is {}. Removed {}\" , tmp . getName ( ) ,", "commit_type": "add"}
{"commit_tokens": ["Allow", "execution", "from", "the", "default", "file", "system", "as", "well", "as", "an", "archive", "."], "add_tokens": "import java . io . OutputStream ; import java . nio . file . StandardOpenOption ; createManifest ( ) ; JarOutputStream out = new JarOutputStream ( fileOut ) private void createManifest ( ) throws MojoFailureException { // Write the manifest to the dir final Path manifestPath = dir . resolve ( \"META-INF\" ) . resolve ( \"MANIFEST.MF\" ) ; // Ensure the directories have been created try { Files . createDirectories ( manifestPath . getParent ( ) ) ; try ( final OutputStream out = Files . newOutputStream ( manifestPath , StandardOpenOption . CREATE ) ) { manifest . write ( out ) ; } } catch ( IOException e ) { throw new MojoFailureException ( \"Could not create manifest file: \" + manifestPath . toString ( ) , e ) ; }", "del_tokens": "Manifest manifest = createManifest ( ) ; JarOutputStream out = new JarOutputStream ( fileOut , manifest ) private Manifest createManifest ( ) throws MojoFailureException { return manifest ;", "commit_type": "allow"}
{"commit_tokens": ["Making", "this", "less", "confusing", "by", "not", "shadowing", "a", "global", "variable"], "add_tokens": "File numbersFile = File . createTempFile ( \"TestGetLargeFile\" , \"Numbers\" ) ; PrintStream ps = new PrintStream ( numbersFile ) ; file . put ( numbersFile ) ; Assert . assertEquals ( downloaded . length ( ) , numbersFile . length ( ) ) ; Assert . assertTrue ( numbersFile . delete ( ) ) ;", "del_tokens": "File largeFile = File . createTempFile ( \"TestGetLargeFile\" , \"Numbers\" ) ; PrintStream ps = new PrintStream ( largeFile ) ; file . put ( largeFile ) ; Assert . assertEquals ( downloaded . length ( ) , largeFile . length ( ) ) ; Assert . assertTrue ( largeFile . delete ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["Make", "downloading", "of", "large", "files", "work"], "add_tokens": "client . getFile ( getUrl ( ) , tempFile ) ;", "del_tokens": "FileOutputStream outputStream = new FileOutputStream ( tempFile ) ; IOUtils . copy ( getInputStream ( ) , outputStream ) ;", "commit_type": "make"}
{"commit_tokens": ["Added", "the", "data", "source", "type", "for", "the", "Event", "when", "it", "is", "instantiated", "."], "add_tokens": "import org . protempa . DatabaseDataSourceType ; * @ param filters Event event = new Event ( propId ) ; event . setDataSourceType ( new DatabaseDataSourceType ( getDataSourceBackendId ( ) ) ) ;", "del_tokens": "* @ param filter Event event = new Event ( propId ) ;", "commit_type": "add"}
{"commit_tokens": ["remove", "duplicate", "method", "from", "TypeDeclaration", "interface"], "add_tokens": "return isAssignableBy ( new ReferenceTypeUsage ( other , typeSolver ) ) ;", "del_tokens": "boolean isAssignableBy ( TypeUsage typeUsage , TypeSolver typeSolver ) ; return isAssignableBy ( new ReferenceTypeUsage ( other , typeSolver ) , typeSolver ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "some", "files", "fixing", "bad", "import", "."], "add_tokens": "// // This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, vJAXB 2.1.10 in JDK 6 // See <a href=\"http://java.sun.com/xml/jaxb\">http://java.sun.com/xml/jaxb</a> // Any modifications to this file will be lost upon recompilation of the source schema. // Generated on: 2011.11.18 at 12:56:16 PM CET // @ javax . xml . bind . annotation . XmlSchema ( namespace = \"parallelj\" , elementFormDefault = javax . xml . bind . annotation . XmlNsForm . QUALIFIED ) package org . parallelj . internal . conf ;", "del_tokens": "// // This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, vJAXB 2.1.10 in JDK 6 // See <a href=\"http://java.sun.com/xml/jaxb\">http://java.sun.com/xml/jaxb</a> // Any modifications to this file will be lost upon recompilation of the source schema. // Generated on: 2011.11.18 at 12:56:16 PM CET // @ javax . xml . bind . annotation . XmlSchema ( namespace = \"parallelj\" , elementFormDefault = javax . xml . bind . annotation . XmlNsForm . QUALIFIED ) package org . parallelj . internal . conf ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "a", "problem", "with", "certain", "ranges", "of", "segment", "angles", "(", "lerp", "vs", "slerp", ")", ".", "Added", "ray", "debug", "rendering", "."], "add_tokens": "import com . badlogic . gdx . graphics . glutils . ShapeRenderer ; public void debugRender ( ShapeRenderer shapeRenderer ) { shapeRenderer . setColor ( Color . YELLOW ) ; for ( int i = 0 ; i < rayNum ; i ++ ) { shapeRenderer . line ( startX [ i ] , startY [ i ] , endX [ i ] , endY [ i ] ) ; } } startAngle . set ( previousAngle ) . slerp ( currentAngle , 0.5f ) ; endAngle . set ( currentAngle ) . slerp ( nextAngle , 0.5f ) ; rayAngle . set ( startAngle ) . slerp ( endAngle , position / segmentLengths . items [ i ] ) ;", "del_tokens": "startAngle . set ( previousAngle ) . lerp ( currentAngle , 0.5f , tmpAngle ) ; endAngle . set ( currentAngle ) . lerp ( nextAngle , 0.5f , tmpAngle ) ; rayAngle . set ( startAngle ) . lerp ( endAngle , position / segmentLengths . items [ i ] , tmpAngle ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fixed", "lower", "bound", "move", "on", "Histogram", "."], "add_tokens": "lowerBound = Math . max ( upperBounds [ i ] + 1L , minValue ) ;", "del_tokens": "lowerBound = Math . max ( upperBounds [ i ] + 1L , minValue ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "hint", "for", "not", "wortking", "plugin", "in", "alpha8", "/", "9", "removed", "broken", "DemoDataGeneratorResource", "link"], "add_tokens": "// @Path(\"{engineName}/demo-data\") // public DemoDataGeneratorResource generateDemotData(@PathParam(\"engineName\") String engineName) { // return subResource(new DemoDataGeneratorResource(engineName), engineName); // }", "del_tokens": "@ Path ( \"{engineName}/demo-data\" ) public DemoDataGeneratorResource generateDemotData ( @ PathParam ( \"engineName\" ) String engineName ) { return subResource ( new DemoDataGeneratorResource ( engineName ) , engineName ) ; }", "commit_type": "add"}
{"commit_tokens": ["Added", "support", "for", "setting", "the", "X", "-", "Load", "-", "Impact_Agent", "request", "header", "from", "jenkins", "plugin"], "add_tokens": "private String agentRequestHeaderValue ; if ( agentRequestHeaderValue == null ) { agentRequestHeaderValue = String . format ( \"LoadImpactJavaSDK/%s\" , getVersion ( ) ) ; return agentRequestHeaderValue ; } public void setAgentRequestHeaderValue ( String agentRequestHeaderValue ) { this . agentRequestHeaderValue = agentRequestHeaderValue ;", "del_tokens": "import javax . ws . rs . core . MultivaluedMap ; private String cachedAgentRequestHeaderValue ; if ( cachedAgentRequestHeaderValue == null ) { cachedAgentRequestHeaderValue = String . format ( \"LoadImpactJavaSDK/%s\" , getVersion ( ) ) ; return cachedAgentRequestHeaderValue ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "what", "is", "expected", "in", "unittest", "1", "."], "add_tokens": "* * @ since MyLibrary 5.5 . 3 public static final TranslationBundle_en_US SINGLETON = new TranslationBundle_en_US ( ) ; private TranslationBundle_en_US ( ) { public String translation_101 ( long duration ) { buffer . append ( duration ) ; public String translation_102 ( int id , String description ) { buffer . append ( id ) ; public String translation_103 ( int id ) { buffer . append ( id ) ;", "del_tokens": "public static final TranslationBundle_en_US SINGLETON = new TranslationBundle_ ( ) ; private TranslationBundle_ ( ) { public String translation_101 ( ) { if ( duration == null ) { buffer . append ( \"(null)\" ) ; } else { buffer . append ( duration ) ; } public String translation_102 ( ) { if ( id == null ) { buffer . append ( \"(null)\" ) ; } else { buffer . append ( id ) ; } public String translation_103 ( ) { if ( id == null ) { buffer . append ( \"(null)\" ) ; } else { buffer . append ( id ) ; }", "commit_type": "fix"}
{"commit_tokens": ["Changed", "camunda", "fox", "to", "camunda", "BPM", "and", "fix", "testcase", "."], "add_tokens": "Assert . assertThat ( processEngineRule . getRuntimeService ( ) . getActiveActivityIds ( id ) , JUnitMatchers . hasItem ( \"user_task_review_tweet\" ) ) ; assertEquals ( \"user_task_review_tweet\" , historyActivities . get ( 5 ) . getActivityId ( ) ) ;", "del_tokens": "Assert . assertThat ( processEngineRule . getRuntimeService ( ) . getActiveActivityIds ( id ) , JUnitMatchers . hasItem ( \"user_task_review_tweet_XXXX\" ) ) ; assertEquals ( \"user_task_review_tweet_XXXX\" , historyActivities . get ( 5 ) . getActivityId ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["adding", "support", "for", "last", "5", "years", "past", "two", "weeks", "etc", ".", "Representing", "things", "like", "next", "5", "weeks", "as", "a", "date", "range", "instead", "of", "just", "a", "single", "date"], "add_tokens": "String value = \"last 2 weeks\" ;", "del_tokens": "String value = \"I want to go shopping in Knoxville, TN in the next five to six months.\" ;", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "hasTableInDatabase", "method", "."], "add_tokens": "public boolean hasTableInDatabase ( SQLiteDatabase database , ContractHolder contractHolder ) { Cursor cursor = database . rawQuery ( \"SELECT * FROM sqlite_master WHERE name = ? \" , new String [ ] { contractHolder . getTable ( ) } ) ; boolean exists = cursor . getCount ( ) != 0 ; cursor . close ( ) ; return exists ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "a", "public", "DEFAULT", "variable", "to", "concrete", "Types", "with", "the", "Solidity", "type", "s", "default", "value"], "add_tokens": "import java . math . BigInteger ; public static final Address DEFAULT = new Address ( BigInteger . ZERO ) ;", "del_tokens": "import java . math . BigInteger ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "some", "local", "variable", "names", "reorganized", "some", "code", "in", "preparation", "for", "adding", "some", "syntax", "validation", "checks"], "add_tokens": "/ * * * * * @ param value * @ return * / List < VarSpec > varspecs = new ArrayList < VarSpec > ( ) ; * Prefix variable varspecs . add ( new VarSpec ( pair [ 0 ] , Modifier . PREFIX , pos ) ) ; varspecs . add ( new VarSpec ( value , Modifier . EXPLODE ) ) ; varspecs . add ( new VarSpec ( value , Modifier . NONE ) ) ; String result = findExpressions ( operator , varspecs ) ; return result ;", "del_tokens": "List < VarSpec > vars = new ArrayList < VarSpec > ( ) ; * Prefex variable vars . add ( new VarSpec ( pair [ 0 ] , Modifier . PREFIX , pos ) ) ; vars . add ( new VarSpec ( value , Modifier . EXPLODE ) ) ; vars . add ( new VarSpec ( value , Modifier . NONE ) ) ; return findExpressions ( operator , vars ) ;", "commit_type": "change"}
{"commit_tokens": ["Adding", "zoo", "service", "(", "spring", "security", "example", ")"], "add_tokens": "public boolean isSpringSecurityEnabled ( ) { return false ; } // Enforce UTF-8 encoding - // this should be done on the LB side for browsers and this doesn't needed to be done for protobuf API //", "del_tokens": "protected boolean isSpringSecurityEnabled ( ) { return false ; } // Enforce UTF-8 encoding", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "case", "for", "getURL", "method"], "add_tokens": "import java . net . HttpURLConnection ; import java . net . URL ; import static com . epam . jdi . uitests . core . settings . JDISettings . logger ; public static String isLinkBroken ( URL url ) throws Exception { String response = \"\" ; HttpURLConnection connection = ( HttpURLConnection ) url . openConnection ( ) ; try { connection . connect ( ) ; response = connection . getResponseMessage ( ) ; connection . disconnect ( ) ; return response ; } catch ( Exception exp ) { return exp . getMessage ( ) ; } } public void getURLTest ( ) throws Exception { logger . info ( \"Response code from server: \" + isLinkBroken ( link ( ) . getURL ( ) ) ) ; } @ Test", "del_tokens": "// reference", "commit_type": "add"}
{"commit_tokens": ["added", "test", "watcher", "helpers", "and", "test"], "add_tokens": "public void testSimpleRender ( ) { public void textSimpleDiffRender ( ) {", "del_tokens": "void testSimpleRender ( ) { void textSimpleDiffRender ( ) {", "commit_type": "add"}
{"commit_tokens": ["made", "the", "code", "to", "compile"], "add_tokens": "super . sendrecv ( request , response , request . timeout == null ? RESPONSE_TIMEOUT : request . timeout . longValue ( ) ) ;", "del_tokens": "super . sendrecv ( request , response , RESPONSE_TIMEOUT ) ;", "commit_type": "make"}
{"commit_tokens": ["Changed", "request", "log", "to", "decode", "URI", "encoded", "request", "path"], "add_tokens": "import org . apache . http . RequestLine ; if ( log . isInfoEnabled ( ) ) { RequestLine requestLine = request . getRequestLine ( ) ; log . info ( \">> \" + requestLine . getMethod ( ) + \" \" + URI . create ( requestLine . getUri ( ) ) . getPath ( ) ) ; }", "del_tokens": "if ( log . isInfoEnabled ( ) ) log . info ( \">> \" + request . getRequestLine ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "pipeline", "file", "name", "."], "add_tokens": "String pathToPipelineFile = \"classpath:/pdf.xpl\" ; //use \"classpath:/path\" for this to work", "del_tokens": "String pathToPipelineFile = \"classpath:/test.xpl\" ; //use \"classpath:/path\" for this to work", "commit_type": "update"}
{"commit_tokens": ["added", "more", "kotlin", "supports", "and", ":"], "add_tokens": "import android . app . Fragment ; public ChooserDialog ( Activity activity ) { this . _context = activity ; } public ChooserDialog ( Fragment fragment ) { this . _context = fragment . getActivity ( ) ; } / * * * @ deprecated will be removed at v1 . 2 * @ param cxt android context * @ return ` this ` reference * * / * @ deprecated will be removed at v1 . 2 private @ StringRes int _titleRes = R . string . choose_file , _okRes = R . string . title_choose , _negativeRes = R . string . dialog_cancel ; private @ DrawableRes int _iconRes = - 1 ; private @ LayoutRes int _layoutRes = - 1 ; private @ LayoutRes int _rowLayoutRes = - 1 ;", "del_tokens": "private @ StringRes int _titleRes = R . string . choose_file , _okRes = R . string . title_choose , _negativeRes = R . string . dialog_cancel ; private @ DrawableRes int _iconRes = - 1 ; private @ LayoutRes int _layoutRes = - 1 ; private @ LayoutRes int _rowLayoutRes = - 1 ;", "commit_type": "add"}
{"commit_tokens": ["Add", "separate", "module", "for", "tests", "without", "RxJava"], "add_tokens": "// indirect usage of RxJava filter() required to avoid problems with ClassLoader when RxJava is not in ClassPath return ChangesFilter . apply ( changesBus , tables ) ;", "del_tokens": "import rx . functions . Func1 ; return changesBus . filter ( new Func1 < Changes , Boolean > ( ) { @ Override public Boolean call ( Changes changes ) { // if one of changed tables found in tables for subscription -> notify observer for ( String affectedTable : changes . affectedTables ( ) ) { if ( tables . contains ( affectedTable ) ) { return true ; } } return false ; } } ) ;", "commit_type": "add"}
{"commit_tokens": ["Improved", "toString", "()", "and", "created", "a", "visitor", "that", "uses", "it", "to", "print", "a", "nice", "hierarchical", "view"], "add_tokens": "sb . append ( \" = { \" ) . append ( getState ( ) . toString ( ) . toLowerCase ( ) ) ; sb . append ( \", type is \" ) . append ( getPropertyType ( ) . getCanonicalName ( ) ) ; sb . append ( \", \" ) . append ( getChildren ( ) . size ( ) ) . append ( \" children\" ) ; } else { sb . append ( \", no children\" ) ; } if ( ! getCategories ( ) . isEmpty ( ) ) { sb . append ( \", categorized as \" ) . append ( getCategories ( ) ) ;", "del_tokens": "sb . append ( \" = { State[\" ) . append ( getState ( ) . toString ( ) ) . append ( \"]\" ) ; sb . append ( \", Type[\" ) . append ( getPropertyType ( ) . getCanonicalName ( ) ) . append ( \"]\" ) ; sb . append ( \", Children[\" ) . append ( getChildren ( ) . size ( ) ) . append ( \"]\" ) ;", "commit_type": "improve"}
{"commit_tokens": ["removed", "counterproductive", "socket", ".", "shutdownInput", "()", "and", "refactored", "socket", "factory", "code"], "add_tokens": "import javax . net . SocketFactory ; / * * * Socket factory used for creating new sockets . * / private SocketFactory socketFactory ; protected void startAppender ( ) throws IOException { socketFactory = initSocketFactory ( ) ; } protected SocketFactory initSocketFactory ( ) { return SocketFactory . getDefault ( ) ; } final Socket socket = createSocket ( ) ; private Socket createSocket ( ) throws IOException { final Socket socket = socketFactory . createSocket ( ) ;", "del_tokens": "final Socket socket = getSocket ( ) ; protected Socket getSocket ( ) throws IOException { final Socket socket = new Socket ( ) ; socket . shutdownInput ( ) ;", "commit_type": "remove"}
{"commit_tokens": ["Added", "feature", "to", "weight", "prefix", "and", "suffix", "ngrams", "differently", "."], "add_tokens": "private double borderFactor = 1.0d ; / * * * To weight n - grams that are on the left or right border of a word differently from n - grams * in the middle of words , assign a value here . * * Affixes ( prefixes and suffixes ) often distinguish the specific features of languages . * Giving a value greater than 1.0 weights these n - grams higher . A 2.0 weights them double . * * Defaults to 1.0 , which means don 't use this feature. That' s the old behavior . * @ param borderFactor 0.0 to 10.0 , a suggested value is 2.0 * / public LanguageDetectorBuilder borderFactor ( double borderFactor ) { this . borderFactor = borderFactor ; return this ; } verbose , alpha , skipUnknownNgrams , shortTextAlgorithm , borderFactor ,", "del_tokens": "verbose , alpha , skipUnknownNgrams , shortTextAlgorithm ,", "commit_type": "add"}
{"commit_tokens": ["Use", "Stream", ".", "count", "in", "method", "HttpClientVerifyBuilder#called"], "add_tokens": "int matchingCalls = ( int ) requests . stream ( ) . filter ( req -> rule . matches ( req ) ) . count ( ) ;", "del_tokens": "int matchingCalls = 0 ; for ( Request request : requests ) { if ( rule . matches ( request ) ) { matchingCalls ++ ; } }", "commit_type": "use"}
{"commit_tokens": ["Added", "a", "check", "that", "a", "attribute", "is", "part", "of", "media", "description"], "add_tokens": "if ( md != null ) { md . addAttribute ( line ) ; } if ( md != null ) { md . addAttribute ( line ) ; }", "del_tokens": "md . addAttribute ( line ) ; md . addAttribute ( line ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "TestNG", "tests", "in", "CalculatorTest", "by", "swapping", "actual", "and", "expected", "as", "expected", "by", "TestNG", "assertions", "."], "add_tokens": "import org . jdom2 . Document ; import org . jdom2 . Element ; import org . jdom2 . input . SAXBuilder ; import org . jdom2 . output . Format ; import org . jdom2 . output . XMLOutputter ;", "del_tokens": "import org . jdom . Document ; import org . jdom . Element ; import org . jdom . input . SAXBuilder ; import org . jdom . output . Format ; import org . jdom . output . XMLOutputter ;", "commit_type": "fix"}
{"commit_tokens": ["Adding", "logs", "to", "so", "loading"], "add_tokens": "Log . d ( TAG , \"init start\" ) ; Log . d ( TAG , \"Preparing SO source: \" + finalSoSources [ i ] ) ; Log . d ( TAG , \"init finish: \" + sSoSources . length + \" SO sources prepared\" ) ; Log . d ( TAG , \"About to load: \" + soName ) ; Log . d ( TAG , \"Loaded: \" + soName ) ; Log . d ( TAG , \"About to merge: \" + shortName + \" / \" + soName ) ; Log . e ( TAG , \"Could not load: \" + soName + \" because no SO source exists\" ) ; Log . e ( TAG , \"Could not load: \" + soName ) ; Log . d ( TAG , \"Prepending to SO sources: \" + extraSoSource ) ; Log . d ( TAG , \"makeLdLibraryPath\" ) ; String joinedPaths = TextUtils . join ( \":\" , pathElements ) ; Log . d ( TAG , \"makeLdLibraryPath final path: \" + joinedPaths ) ; return joinedPaths ;", "del_tokens": "return TextUtils . join ( \":\" , pathElements ) ;", "commit_type": "add"}
{"commit_tokens": ["Update", "to", "latest", "kryo", "use", "register", "instead", "of", "setSerializer", "to", "register", "serializers", "(", "thanx", "to", "Nate", "for", "this", "hint", ")", "."], "add_tokens": "* Creates a new { @ link UnmodifiableCollectionsSerializer } and registers its serializer public static void registerSerializers ( final Kryo kryo ) { kryo . register ( item . type , serializer ) ;", "del_tokens": "* Creates a new { @ link UnmodifiableCollectionsSerializer } and sets it as serializer public static void setSerializer ( final Kryo kryo ) { kryo . setSerializer ( item . type , serializer ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "null", "check", "module", "lookup"], "add_tokens": "if ( module != null ) { modules . add ( module ) ; }", "del_tokens": "modules . add ( module ) ;", "commit_type": "add"}
{"commit_tokens": ["adding", "DropDownFilteredList", ".", "Filter", "interface", "to", "change", "the", "filter", "behavior"], "add_tokens": "private Filter filter = new DefaultFilter ( ) ; public void setFilter ( Filter filter ) { if ( filter != null ) { this . filter = filter ; } } public Filter getFilter ( ) { return filter ; } if ( getFilter ( ) . matches ( text , typedText ) ) { public static interface Filter { public boolean matches ( String itemText , String typedText ) ; } public static class DefaultFilter implements Filter { @ Override public boolean matches ( String itemText , String typedText ) { if ( itemText . length ( ) == 0 || itemText . indexOf ( typedText ) > - 1 ) { return true ; } return false ; } }", "del_tokens": "if ( text . length ( ) == 0 || text . indexOf ( typedText ) > - 1 ) {", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "SQS", "messages", "with", "a", "Type", "of", "Number"], "add_tokens": "if ( STRING . equals ( type ) || NUMBER . equals ( type ) ) {", "del_tokens": "if ( STRING . equals ( type ) ) {", "commit_type": "add"}
{"commit_tokens": ["changed", "actionCallbackDto", "to", "commons", "project"], "add_tokens": "import com . stratio . streaming . commons . dto . ActionCallbackDto ;", "del_tokens": "import com . stratio . streaming . dto . ActionCallbackDto ;", "commit_type": "change"}
{"commit_tokens": ["fix", "bug", "#", "form", "-", "entities", "will", "be", "print", "when", "turn", "off", "debug"], "add_tokens": "VolleyLog . v ( \"name=%1$s, value=%2$s\" , name , value ) ;", "del_tokens": "VolleyLog . d ( \"name=%1$s, value=%2$s\" , name , value ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "exception", "type", "to", "hash", "calculation", "method", "for", "cdnjs"], "add_tokens": "public Map < ChecksumType , String > calculateJavaScriptHashes ( File file ) throws WssHashException { throw new WssHashException ( \"Error calculating JavaScript hash: \" + e . getMessage ( ) ) ; public Map < ChecksumType , String > calculateJavaScriptHashes ( byte [ ] byteArray ) throws WssHashException { throw new WssHashException ( \"Error calculating JavaScript hash: \" + e . getMessage ( ) ) ;", "del_tokens": "public Map < ChecksumType , String > calculateJavaScriptHashes ( File file ) { logger . debug ( \"Error calculating JavaScript hash: {}\" , e . getMessage ( ) ) ; public Map < ChecksumType , String > calculateJavaScriptHashes ( byte [ ] byteArray ) { logger . debug ( \"Error calculating JavaScript hash: {}\" , e . getMessage ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "event", "buses", "for", "all", "event", "scopes"], "add_tokens": "/ * * Copyright 2014 The original authors * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / * @ author Petter Holmstr öm p etter@ v aadin. c om)", "del_tokens": "* @ author petter @ vaadin . com @ Override protected EventBus getParentEventBus ( ) { return null ; }", "commit_type": "add"}
{"commit_tokens": ["Created", "ToastBuilder", "class", ".", "Cleaned", "up", "code", "in", "SnackbarBuilder", "."], "add_tokens": "import android . graphics . Color ; import com . github . andrewlord1990 . toastbuilder . ToastBuilder ; new ToastBuilder ( SampleActivity . this ) . message ( message ) . duration ( Toast . LENGTH_LONG ) . messageTextColor ( Color . RED ) . build ( ) . show ( ) ;", "del_tokens": "Toast . makeText ( SampleActivity . this , message , Toast . LENGTH_SHORT ) . show ( ) ;", "commit_type": "create"}
{"commit_tokens": ["Update", "the", "supports", "method", "to", "support", "any", "implementation"], "add_tokens": "* Supports RegisteredService objects . return RegisteredService . class . isAssignableFrom ( clazz ) ;", "del_tokens": "import org . jasig . cas . services . RegisteredServiceImpl ; * Supports the RegisteredServiceImpl . return RegisteredServiceImpl . class . equals ( clazz ) ;", "commit_type": "update"}
{"commit_tokens": ["Added", "task", "manager", "test", "."], "add_tokens": "int priority = task . getCommand ( ) . getTaskPriority ( ) ;", "del_tokens": "int priority = task . getPriority ( ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "get", "classloader", "from", "current", "thread"], "add_tokens": "private static ClassLoader getClassLoader ( ) { ClassLoader contextClassLoader = Thread . currentThread ( ) . getContextClassLoader ( ) ; if ( contextClassLoader != null ) { return contextClassLoader ; } return null ; } c = Class . forName ( className , true , getClassLoader ( ) ) ;", "del_tokens": "c = Class . forName ( className ) ;", "commit_type": "add"}
{"commit_tokens": ["Use", "toast", "for", "demonstration", "of", "header", "interaction", "."], "add_tokens": "import android . widget . Toast ; private Toast mToast ; String text = \"Header \" + ( ( TextView ) view . findViewById ( android . R . id . text1 ) ) . getText ( ) + \" was tapped.\" ; if ( mToast == null ) { mToast = Toast . makeText ( getActivity ( ) , text , Toast . LENGTH_SHORT ) ; } else { mToast . setText ( text ) ; } mToast . show ( ) ; String text = \"Header \" + ( ( TextView ) view . findViewById ( android . R . id . text1 ) ) . getText ( ) + \" was long pressed.\" ; if ( mToast == null ) { mToast = Toast . makeText ( getActivity ( ) , text , Toast . LENGTH_SHORT ) ; } else { mToast . setText ( text ) ; } mToast . show ( ) ;", "del_tokens": "import android . util . Log ; Log . d ( \"asdf\" , \"clicked \" + id + \" \" + ( ( TextView ) view . findViewById ( android . R . id . text1 ) ) . getText ( ) ) ; Log . d ( \"asdf\" , \"long pressed \" + id + \" \" + ( ( TextView ) view . findViewById ( android . R . id . text1 ) ) . getText ( ) ) ;", "commit_type": "use"}
{"commit_tokens": ["Fixed", "a", "problem", "with", "config", "initializing", "before", "the", "config", "util"], "add_tokens": "public void init ( ) {", "del_tokens": "public EeConfig ( ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "bug", ":", "DataFactory", ".", "getRandomText", "returned", "often", "text", "with", "double", "spaces", "in", "there", "."], "add_tokens": "final double desiredWordLengthNormalDistributed = 1.0 + Math . abs ( random . nextGaussian ( ) ) * 6 ;", "del_tokens": "final double desiredWordLengthNormalDistributed = Math . abs ( 1.0 + random . nextGaussian ( ) * 6 ) ;", "commit_type": "fix"}
{"commit_tokens": ["updates", "to", "allow", "closing", "datasets", "and", "unpersisting", "data", "in", "spark", ".", "Adding", "NoOpt", "encoders", "for", "when", "they", "encoding", "is", "not", "needed", "."], "add_tokens": "import com . davidbracewell . hermes . ml . feature . NGramFeature ; Featurizer < HString > featurizer = Featurizer . chain ( BagOfAnnotations . builder ( ) . valueCalculator ( ValueCalculator . Binary ) . lowerCase ( ) . build ( ) , NGramFeature . builder ( ) . valueCalculator ( ValueCalculator . Binary ) . lowerCase ( ) . build ( ) Dataset < Instance > dataset = Corpus . of ( StreamingContext . local ( ) . stream ( training ) //Don't expect great results with this size data and feature set ClassifierEvaluation . crossValidation ( dataset , supplier , 10 ) . output ( System . out , true ) ;", "del_tokens": "Featurizer < HString > featurizer = Featurizer . chain ( BagOfAnnotations . builder ( ) . valueCalculator ( ValueCalculator . Frequency ) . lowerCase ( ) . ignoreStopWords ( ) . build ( ) Dataset < Instance > dataset = Corpus . of ( StreamingContext . local ( ) . stream ( training ) new ClassifierEvaluation ( ) . crossValidation ( dataset , supplier , 10 ) . output ( System . out , true ) ;", "commit_type": "update"}
{"commit_tokens": ["created", "handler", "for", "running", "jobs", "started", "work", "on", "persistence"], "add_tokens": "import me . tatarka . support . os . PersistableBundle ; builder . setExtras ( ( android . os . PersistableBundle ) job . getExtras ( ) . getRealBundle ( ) ) ; builder . setExtras ( new PersistableBundle ( job . getExtras ( ) ) ) ;", "del_tokens": "import android . content . ComponentName ; import android . os . PersistableBundle ; builder . setExtras ( ( PersistableBundle ) job . getExtras ( ) . getRealBundle ( ) ) ; builder . setExtras ( new me . tatarka . support . job . PersistableBundle ( job . getExtras ( ) ) ) ;", "commit_type": "create"}
{"commit_tokens": ["Fix", "JSON", "BidExt", ".", "attribute", "[", "s", "]"], "add_tokens": "\"exchange_deal_type\" , \"attribute\" ) ; case \"attribute\" :", "del_tokens": "\"exchange_deal_type\" , \"attributes\" ) ; case \"attributes\" :", "commit_type": "fix"}
{"commit_tokens": ["use", "pominfo", ".", "properties", "instead", "of", "wsd", ".", "properties"], "add_tokens": "public static final String PROJECT_PROPERTIES = \"META-INF/pominfo.properties\" ; properties = resolver . resolve ( base , PROJECT_PROPERTIES ) ; properties = resolver . resolve ( base , PROJECT_PROPERTIES ) ;", "del_tokens": "public static final String MODULE_PROPERTIES = \"META-INF/wsd.properties\" ; public static final String APPLICATION_PROPERTIES = \"WEB-INF/wsd.properties\" ; properties = resolver . resolve ( base , MODULE_PROPERTIES ) ; properties = resolver . resolve ( base , APPLICATION_PROPERTIES ) ;", "commit_type": "use"}
{"commit_tokens": ["fix", "typo", "in", "debug", "field"], "add_tokens": "private boolean mDebugEnable = false ; mDebugEnable = enable ; if ( mDebugEnable ) {", "del_tokens": "private boolean mDebudEnable = false ; mDebudEnable = enable ; if ( mDebudEnable ) {", "commit_type": "fix"}
{"commit_tokens": ["fix", "a", "bug", "that", "min", "/", "max", "time", "contains", "the", "time", "of", "child", "calls"], "add_tokens": "ProfileTime theTime = callEntry . getTime ( ) ; for ( ProfileMethodEntry methodEntry : entries ) { }", "del_tokens": "ProfileTime theTime = callEntry . getEndTime ( ) . minus ( callEntry . getStartTime ( ) ) ; if ( node . hasParent ( ) ) { ProfileCallEntry parent = node . getParent ( ) . getData ( ) ; if ( parent != null ) { String parentKey = String . format ( \"%s.%s\" , parent . getClassName ( ) , parent . getMethodName ( ) ) ; ProfileMethodEntry parentMethodEntry = methodEntryMap . get ( parentKey ) ; parentMethodEntry . setTime ( parentMethodEntry . getTime ( ) . minus ( theTime ) ) ; } }", "commit_type": "fix"}
{"commit_tokens": ["added", "match", "target", "and", "resource", "api"], "add_tokens": "return eq ( extractor , text ( expected ) ) ; return match ( extractor ( patternResource . id ( ) ) , patternResource ) ; } public static RequestMatcher match ( RequestExtractor extractor , String expected ) { return match ( extractor , text ( expected ) ) ; } public static RequestMatcher match ( RequestExtractor extractor , Resource expected ) { Pattern pattern = Pattern . compile ( new String ( expected . asByteArray ( ) ) ) ; return new MatchMatcher ( extractor , pattern ) ;", "del_tokens": "return new EqRequestMatcher ( extractor , text ( expected ) ) ; Pattern pattern = Pattern . compile ( new String ( patternResource . asByteArray ( ) ) ) ; return new MatchMatcher ( extractor ( patternResource . id ( ) ) , pattern ) ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "Javadoc", "of", "BigMoney", ".", "withScale"], "add_tokens": "* For example , scaling 'USD 43.2' to a scale of 2 will yield 'USD 43.20' .", "del_tokens": "* For example , scaling 'USD 43.271' to a scale of 1 will yield 'USD 43.2' .", "commit_type": "fix"}
{"commit_tokens": ["Fixing", "of", "ModifyAssociationTest", "for", "SCTP", "-", "8"], "add_tokens": "private static final int SERVER_PORT = 22347 ; private static final int CLIENT_PORT = 22348 ;", "del_tokens": "private static final int SERVER_PORT = 2347 ; private static final int CLIENT_PORT = 2348 ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "convienence", "method", "to", "StateImpl"], "add_tokens": "stateA . addTransition ( eventA , stateB , actionA ) ; stateB . addTransition ( eventB , stateC , actionB ) ;", "del_tokens": "stateA . addTransition ( eventA , new DeterministicTransitionImpl < Object > ( stateB , actionA ) ) ; stateB . addTransition ( eventB , new DeterministicTransitionImpl < Object > ( stateC , actionB ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "tests", "for", "configuration", "of", "Ancestry", "resolution", "mode", "and", "default", "Lazy", "loading", "behavior", "for", "CLAVIN", "resolution", "."], "add_tokens": "if ( gazetteer != null && parentId != null && ! geoName . isAncestryResolved ( ) ) {", "del_tokens": "if ( gazetteer != null && ! geoName . isAncestryResolved ( ) ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "compress", "file", "empty", "bug"], "add_tokens": "String remoteEncoding = \"utf-8\" ; // 2016-03-22 only pure http/https auto detect encoding if ( \"http\" . equalsIgnoreCase ( uri . substring ( 0 , 4 ) ) ) { fileContent . getSize ( ) ; // pass a bug {@link https://issues.apache.org/jira/browse/VFS-427} remoteEncoding = fileContent . getContentInfo ( ) . getContentEncoding ( ) ; } if ( null == remoteEncoding ) remoteEncoding = \"utf-8\" ; } catch ( StringIndexOutOfBoundsException stre ) { log . warn ( \"uri: \" + uri ) ; log . warn ( stre . getMessage ( ) ) ;", "del_tokens": "fileContent . getSize ( ) ; // pass a bug {@link https://issues.apache.org/jira/browse/VFS-427} String remoteEncoding = fileContent . getContentInfo ( ) . getContentEncoding ( ) ; if ( null == remoteEncoding ) remoteEncoding = \"utf8\" ;", "commit_type": "fix"}
{"commit_tokens": ["added", "ant", "style", "$", "{}", "variables", "support"], "add_tokens": "import java . util . regex . Matcher ; import java . util . regex . Pattern ; private static final Pattern VARIABLE_REPLACE_PATTERN = Pattern . compile ( \"\\\\$\\\\{(.*?)\\\\}\" ) ; String key ; String value ; String variable ; String variableKey ; String variableValue ; StringBuffer buffer ; for ( Entry < Object , Object > entry : this . configuration . entrySet ( ) ) { key = entry . getKey ( ) . toString ( ) ; value = entry . getValue ( ) . toString ( ) ; Matcher matcher = VARIABLE_REPLACE_PATTERN . matcher ( value ) ; buffer = new StringBuffer ( ) ; while ( matcher . find ( ) ) { variable = matcher . group ( ) ; variableKey = matcher . group ( 1 ) ; variableValue = this . configuration . getProperty ( variableKey ) ; if ( variableValue != null ) { matcher . appendReplacement ( buffer , variableValue ) ; } else { buffer . append ( variable ) ; } } matcher . appendTail ( buffer ) ; this . bindConstant ( ) . annotatedWith ( Names . named ( key ) ) . to ( buffer . toString ( ) ) ; }", "del_tokens": "Names . bindProperties ( this . binder ( ) , this . configuration ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "system", ".", "test", ".", "target", ".", "url", "to", "run", "test", "against", "different", "urls", "."], "add_tokens": "/** The Constant usingExternalServer. */ private static final boolean usingExternalServer ; static { String systemTestTargetUrlProperty = System . getProperty ( \"system.test.target.url\" ) ; if ( systemTestTargetUrlProperty != null && systemTestTargetUrlProperty . trim ( ) . length ( ) > 0 ) { usingExternalServer = true ; } else { usingExternalServer = false ; } } if ( ! usingExternalServer ) { CitizenIntelligenceAgencyServer . startTestServer ( ) ; } if ( ! usingExternalServer ) { CitizenIntelligenceAgencyServer . stopTestServer ( ) ; }", "del_tokens": "CitizenIntelligenceAgencyServer . startTestServer ( ) ; CitizenIntelligenceAgencyServer . stopTestServer ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "IncrementalArrayData", "subclasses", "to", "indicate", "if", "it", "s", "the", "last", "page", "of", "results", "eliminating", "the", "need", "for", "a", "final", "redundant", "load"], "add_tokens": "private static final int TOTAL = 30 ; protected Result < ? > load ( ) throws Throwable { return new Result < > ( mNewsService . getNews ( offset , INCREMENT ) , TOTAL - mOffset ) ;", "del_tokens": "private static final int TOTAL = 20 ; protected List < ? > load ( ) throws Throwable { return mNewsService . getNews ( offset , INCREMENT ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "bug", "where", "it", "wouldn", "t", "always", "use", "the", "inputText", "()", "from", "the", "account", "."], "add_tokens": "public final String getModifiedInputText ( String inputText , final Account account ) { if ( ! account . getUrl ( ) . isEmpty ( ) ) { return account . getUrl ( ) ; }", "del_tokens": "public final String getModifiedInputText ( final String inputText , final Account account ) {", "commit_type": "fix"}
{"commit_tokens": ["Changed", "reconnect", "test", "to", "use", "wrong", "port", "instead", "of", "wrong", "host", "name", "."], "add_tokens": "connectionFactory . setPort ( brokerSetup . getPort ( ) ) ;", "del_tokens": "connectionFactory . setHost ( brokerSetup . getHost ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Add", "caguilar187", "as", "author", "for", "input", "fixing", "header", "issues", "."], "add_tokens": "* @ author Tonic Artos , Emil Sj öl ander, aguilar187", "del_tokens": "* @ author Tonic Artos , Emil Sj öl ander", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "ftps", "."], "add_tokens": "public void configure ( String server , String username , String password , String remotePath , boolean ssl ) throws Exception ;", "del_tokens": "public void configure ( String server , String username , String password , String remotePath ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "methods", "shouldHave", "(", "text", "(", "xxx", "))", ";"], "add_tokens": "ShouldableWebElement should ( Condition ... condition ) ; ShouldableWebElement shouldHave ( Condition ... condition ) ; ShouldableWebElement shouldBe ( Condition ... condition ) ;", "del_tokens": "void should ( Condition condition ) ; void shouldBe ( Condition condition ) ;", "commit_type": "add"}
{"commit_tokens": ["moved", "unknown", "variable", "warning", "to", "trace"], "add_tokens": "logger . trace ( xjexl . getMessage ( ) ) ;", "del_tokens": "logger . warn ( xjexl . getMessage ( ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Move", "the", "native", "action", "bar", "handler", "to", "the", "appropriate", "subpackage", "where", "the", "other", "handlers", "live", "."], "add_tokens": "import com . jakewharton . android . actionbarsherlock . handler . NativeActionBar ; public static final class HelloNativeActionBarHandler extends NativeActionBar . Handler {", "del_tokens": "public static final class HelloNativeActionBarHandler extends ActionBarSherlock . NativeActionBarHandler {", "commit_type": "move"}
{"commit_tokens": ["Fixed", "a", "Javadoc", "error", "regarding", "external", "links"], "add_tokens": "* @ see < a href = \"http://stackoverflow.com/a/6162687\" > Stack Overflow < / a >", "del_tokens": "* @ see http : //stackoverflow.com/a/6162687", "commit_type": "fix"}
{"commit_tokens": ["Changed", "the", "type", "of", "expiresIn", "of", "TokenCreateResponse", "from", "int", "to", "long", "."], "add_tokens": "private static final long serialVersionUID = 2L ; private long expiresIn ; public long getExpiresIn ( ) public TokenCreateResponse setExpiresIn ( long expiresIn )", "del_tokens": "private static final long serialVersionUID = 1L ; private int expiresIn ; public int getExpiresIn ( ) public TokenCreateResponse setExpiresIn ( int expiresIn )", "commit_type": "change"}
{"commit_tokens": ["add", "ModelExt", "s", "cacheName", "logic", "update", "setCacheName", "comment"], "add_tokens": "* set cache 's name. * if current cacheName != the old cacheName , will reset old cache and update cache use the current cacheName .", "del_tokens": "* set cache 's name * @ param cacheName , if current cacheName != the old cacheName , will reset old cache and update cache use the current cacheName .", "commit_type": "add"}
{"commit_tokens": ["Added", "test", "cases", "and", "extra", "logging"], "add_tokens": "private static final Logger logger = Logger . getLogger ( ApiKeyHttpClientProvider . class . getName ( ) ) ; if ( logger . isLoggable ( Level . FINE ) ) client . register ( new LoggingFeature ( logger , Level . FINE , LoggingFeature . Verbosity . PAYLOAD_TEXT , 8192 ) ) ;", "del_tokens": "client . register ( new LoggingFeature ( Logger . getLogger ( getClass ( ) . getName ( ) ) , Level . INFO , LoggingFeature . Verbosity . PAYLOAD_TEXT , 8192 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixed", "several", "issues", "along", "testing", "with", "the", "TCK", "."], "add_tokens": ". setFixedScale ( true ) . setPrecision ( 14 ) . create ( ) ;", "del_tokens": ". setFixedScale ( true ) . setPrecision ( String . valueOf ( Integer . MAX_VALUE ) . length ( ) ) . create ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Removed", "some", "shadyness", "from", "JavaClass", "where", "instanceof", "checks", "were", "done", "."], "add_tokens": "import com . google . common . collect . ImmutableSet ; ImmutableSet . Builder < VALUE > result = ImmutableSet . builder ( ) ; return result . build ( ) ;", "del_tokens": "import java . util . HashSet ; Set < VALUE > result = new HashSet < > ( ) ; return result ;", "commit_type": "remove"}
{"commit_tokens": ["Removed", "getDriver", "()", "and", "setDriver", "()", "from", "Bot", "and", "FestBot"], "add_tokens": "return new ReadDriverTypes ( ThreadDriver . getDriver ( ) ) ; return new ReadTypes ( ThreadDriver . getDriver ( ) , webElement ) ; BotUtils . open ( url , ThreadDriver . getDriver ( ) ) ; return new IsTypes ( ThreadDriver . getDriver ( ) , webElement ) ; return new AssertTypes ( ThreadDriver . getDriver ( ) , webElement ) ;", "del_tokens": "import org . andidev . webdriverextension . internal . WebDriverExtensionException ; import org . openqa . selenium . WebDriver ; public static WebDriver getDriver ( ) { try { return ThreadDriver . getDriver ( ) ; } catch ( WebDriverExtensionException e ) { throw new WebDriverExtensionException ( \"WebDriver in FestBot is not set. Please set the driver with FestBot.setDriver(driver) before using the FestBot static methods. Note that the driver will be thread safe since it is set with ThreadLocal so don't worry about thread safety.\" ) ; } } public static void setDriver ( WebDriver driver ) { ThreadDriver . setDriver ( driver ) ; } return new ReadDriverTypes ( getDriver ( ) ) ; return new ReadTypes ( getDriver ( ) , webElement ) ; BotUtils . open ( url , getDriver ( ) ) ; return new IsTypes ( getDriver ( ) , webElement ) ; return new AssertTypes ( getDriver ( ) , webElement ) ;", "commit_type": "remove"}
{"commit_tokens": ["Making", "mapId", "and", "accessToken", "final"], "add_tokens": "private final String mapId ; private final String accessToken ;", "del_tokens": "private String mapId ; private String accessToken ;", "commit_type": "make"}
{"commit_tokens": ["Make", "version", "backward", "compatible", "by", "moving", "the", "new", "version", "object", "method", "to", "version", "()", "and", "let", "getVersion", "()", "retain", "its", "old", "behavior", "."], "add_tokens": "/ * * * Get the version of the Etcd server * * @ return version as String * @ deprecated use version ( ) * / @ Deprecated public String getVersion ( ) { try { return new EtcdOldVersionRequest ( this . client , retryHandler ) . send ( ) . get ( ) ; } catch ( IOException | EtcdException | TimeoutException e ) { return null ; } } public EtcdVersionResponse version ( ) {", "del_tokens": "public EtcdVersionResponse getVersion ( ) {", "commit_type": "make"}
{"commit_tokens": ["add", "constructor", "with", "container", "in", "Table"], "add_tokens": "public static WebLocator container = new WebLocator ( \"container\" ) ; { new Table ( container ) , \"//*[contains(@class, 'container')]//table\" } ,", "del_tokens": "import com . extjs . selenium . ExtJsComponent ; public static ExtJsComponent container = new ExtJsComponent ( \"container\" ) ;", "commit_type": "add"}
{"commit_tokens": ["added", "some", "basic", "functionality", "for", "Flink", "recoverability"], "add_tokens": "import org . apache . poi . ss . usermodel . DateUtil ; import org . apache . poi . ss . usermodel . CellValue ; import java . math . BigDecimal ; @ Override public void setCurrentRow ( long row ) { this . currentRow = ( int ) row ; } @ Override public void setCurrentSheet ( long sheet ) { this . currentSheet = ( int ) sheet ; } @ Override public long getCurrentSheet ( ) { return this . currentSheet ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Add", "file", "headers", "and", "clean", "chronology", "of", "BasicUsage"], "add_tokens": "/ * * Copyright ( c ) 2012 - 2014 Spotify AB * * Licensed under the Apache License , Version 2.0 ( the \"License\" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http : //www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an \"AS IS\" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * / * This interface exists to allow implementers to bridge the statistics", "del_tokens": "* This interface exists to allow implementors to bridge the statistics * * @ author udoprog", "commit_type": "add"}
{"commit_tokens": ["Fix", "bug", "in", "single", "-", "level", "package", "names", "(", "found", "and", "fixed", "by", "Dean", "Harding", ")"], "add_tokens": "while ( ! prefix . isEmpty ( ) ) {", "del_tokens": "while ( prefix . contains ( \".\" ) ) {", "commit_type": "fix"}
{"commit_tokens": ["Fix", "weird", "animation", "when", "SnackBar", "has", "been", "cleared", "programmatically", "."], "add_tokens": "if ( View . VISIBLE == mContainer . getVisibility ( ) ) { mContainer . startAnimation ( mOutAnimationSet ) ; }", "del_tokens": "import android . widget . Button ; mContainer . startAnimation ( mOutAnimationSet ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "inverse", "incomplete", "beta", "function", "using", "root", "finding", "method"], "add_tokens": "System . out . println ( SpecialMath . invBetaIncReg ( 0.1234 , 50 , 2 ) ) ;", "del_tokens": "System . out . println ( Zeroin . root ( 1 , Math . PI , func , 0.2 ) ) ; System . out . println ( Bisection . root ( 1 , Math . PI , func , 0.2 ) ) ; System . out . println ( RiddersMethod . root ( 1 , Math . PI , func , 0.2 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Implement", "refresh", "authorization", "token", "support"], "add_tokens": "import static java . util . concurrent . TimeUnit . DAYS ; return now ( ) . getTime ( ) - receivedAt . getTime ( ) > DAYS . toMicros ( 10 ) ;", "del_tokens": "return now ( ) . getTime ( ) - receivedAt . getTime ( ) > MINUTES . toMicros ( 10 ) ;", "commit_type": "implement"}
{"commit_tokens": ["add", "history", "file", "name", "example"], "add_tokens": "shell . setApplicationContext ( ctx ) ;", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Added", "sweep", "speed", "and", "rotation", "speed"], "add_tokens": "final float sweepSpeed = a . getFloat ( R . styleable . CircularProgressBar_cpb_sweep_speed , Float . parseFloat ( res . getString ( R . string . cpb_default_sweep_speed ) ) ) ; final float rotationSpeed = a . getFloat ( R . styleable . CircularProgressBar_cpb_rotation_speed , Float . parseFloat ( res . getString ( R . string . cpb_default_rotation_speed ) ) ) ; . sweepSpeed ( sweepSpeed ) . rotationSpeed ( rotationSpeed )", "del_tokens": "final float speed = a . getFloat ( R . styleable . CircularProgressBar_cpb_speed , Float . parseFloat ( res . getString ( R . string . cpb_default_speed ) ) ) ; . sweepSpeed ( speed )", "commit_type": "add"}
{"commit_tokens": ["Removed", "dead", "code", "such", "as", "support", "for", "default", "values", "which", "were", "removed", "in", "the", "final", "version", "of", "the", "spec"], "add_tokens": "public static enum VarFormat { SINGLE , ARRAY , PAIRS ; }", "del_tokens": "import com . damnhandy . uri . template . UriTemplate . Modifier ; / * * * * / private String defaultValue ; / * * * FIXME Comment this * * @ return * / public boolean hasDefaultValue ( ) { return ( defaultValue != null ) ; } / * * * Get the defaultValue . * * @ return the defaultValue . * / public String getDefaultValue ( ) { return defaultValue ; } / * * * Set the defaultValue . * * @ param defaultValue The defaultValue to set . * / public void setDefaultValue ( String defaultValue ) { this . defaultValue = defaultValue ; }", "commit_type": "remove"}
{"commit_tokens": ["Adding", "default", "value", "support", "for", "when", "regex", "fails"], "add_tokens": "final String defValue = s . defValue ( ) ; final boolean found = matcher . find ( ) ; if ( found ) { value = matcher . group ( 1 ) ; if ( value . isEmpty ( ) ) { value = defValue ; } } else { value = defValue ; }", "del_tokens": "matcher . find ( ) ; value = matcher . group ( 1 ) ;", "commit_type": "add"}
{"commit_tokens": ["Moves", "the", "SimpleDBCredentialsRepo", "out", "of", "the", "test", "area", "where", "it", "was", "mistakenly", "placed", "and", "adds", "support", "for", "table", "prefix", "so", "that", "test", "data", "can", "easily", "be", "used", "."], "add_tokens": "private String tablePrefix ; / * * * * @ param client * @ param tablePrefix * / public SimpleDBCredentialsRepo ( AmazonSimpleDBClient client , String tablePrefix ) { this . client = client ; this . tablePrefix = tablePrefix ; } this ( client , \"\" ) ; \"select SERVER_DETAILS_ID from \" + tablePrefix + \"DURACLOUD_ACCOUNTS where SUBDOMAIN = '\" String serverDetailsDomain = tablePrefix + \"DURACLOUD_SERVER_DETAILS\" ; String domain = tablePrefix + \"DURACLOUD_STORAGE_PROVIDER_ACCOUNTS\" ;", "del_tokens": "this . client = client ; \"select SERVER_DETAILS_ID from DURACLOUD_ACCOUNTS where SUBDOMAIN = '\" String serverDetailsDomain = \"DURACLOUD_SERVER_DETAILS\" ; String domain = \"DURACLOUD_STORAGE_PROVIDER_ACCOUNTS\" ;", "commit_type": "move"}
{"commit_tokens": ["added", "modules", "and", "new", "pom"], "add_tokens": "import com . github . sakserv . propertyparser . PropertyParser ;", "del_tokens": "import com . github . sakserv . minicluster . config . PropertyParser ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "NotifierType", "should", "return", "a", "Set", "of", "properties", "labels", "not", "a", "Map"], "add_tokens": "Set < String > payload = null ; payload = fromJson ( rs . getString ( 2 ) , Set . class ) ; return payload != null && ! payload . isEmpty ( ) ? new HashSet ( payload ) : null ;", "del_tokens": "Map < String , String > payload = null ; payload = fromJson ( rs . getString ( 2 ) , Map . class ) ; return payload != null && ! payload . isEmpty ( ) ? new HashSet ( payload . values ( ) ) : null ;", "commit_type": "fix"}
{"commit_tokens": ["Removing", "the", "unneeded", "CQ", "Client"], "add_tokens": "private SlingClient slingClient = new SlingClient ( this . getServerBaseUrl ( ) ,", "del_tokens": "private SlingClient slingClient = new CQClient ( this . getServerBaseUrl ( ) ,", "commit_type": "remove"}
{"commit_tokens": ["add", "transformation", "command", "+", "bug", "fixing"], "add_tokens": "public ConfigurationManager ( File walkmodcfg , boolean execute , ConfigurationProvider ... configurationProviders ) { if ( execute ) { executeConfigurationProviders ( ) ; ConfigurationAdapter ca = new DefaultConfigurationAdapter ( ) ; ca . setConfiguration ( configuration ) ; ca . prepare ( ) ; } } public ConfigurationManager ( File walkmodcfg , ConfigurationProvider ... configurationProviders ) { this ( walkmodcfg , true , configurationProviders ) ; public ProjectConfigurationProvider getProjectConfigurationProvider ( ) { Iterator < ConfigurationProvider > it = configurationProviders . iterator ( ) ; while ( it . hasNext ( ) ) { ConfigurationProvider current = it . next ( ) ; if ( current instanceof ProjectConfigurationProvider ) { return ( ProjectConfigurationProvider ) current ; } } return null ; }", "del_tokens": "public ConfigurationManager ( File walkmodcfg , ConfigurationProvider ... configurationProviders ) { executeConfigurationProviders ( ) ; ConfigurationAdapter ca = new DefaultConfigurationAdapter ( ) ; ca . setConfiguration ( configuration ) ; ca . prepare ( ) ;", "commit_type": "add"}
{"commit_tokens": ["update", "docs", "for", "MortarContext", "removal"], "add_tokens": "format ( \"Cannot find scope in %s. Make sure your Activity's content view is set using \" + \" an inflater from MortarScope.createContext()\" , context . getClass ( ) . getName ( ) ) ) ;", "del_tokens": "format ( \"Cannot find scope in %s.\" , context . getClass ( ) . getName ( ) ) ) ;", "commit_type": "update"}
{"commit_tokens": ["added", "namespace", "update", "to", "manifest", "build"], "add_tokens": "public static final String NAMESPACE = \"http://johncarl81.github.com/transfuse/\" ; private String transfuseNamespace ; public void updateNamespace ( ) { transfuseNamespace = NAMESPACE ; }", "del_tokens": "private final String transfuseNamespace = \"http://johncarl81.github.com/transfuse/\" ;", "commit_type": "add"}
{"commit_tokens": ["Add", "option", "to", "use", "self", "-", "edges", "in", "BLANC", "scoring"], "add_tokens": "return new StandardBLANCScorer ( false ) ; } public static BLANCScorer getStandardBLANCScorerWithSelfEdges ( ) { return new StandardBLANCScorer ( true ) ;", "del_tokens": "return new StandardBLANCScorer ( ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "wildcard", "type", "on", "Maps", "Collections", "and", "other", "parameterized", "types", "."], "add_tokens": "return map . get ( Map . class ) ; return map . get ( Collection . class ) ; } else { T handler = map . get ( type ) ; if ( handler == null ) { Class < ? > rawClass = TypeUtils . toRawClass ( type ) ; if ( rawClass != type ) { handler = getHandlerFor ( rawClass ) ; } } return handler ;", "del_tokens": "T handler = map . get ( type ) ; handler = map . get ( Map . class ) ; handler = map . get ( Collection . class ) ; return handler ;", "commit_type": "add"}
{"commit_tokens": ["Add", "support", "for", "managing", "registration", "lock"], "add_tokens": "public void setPin ( Optional < String > pin ) throws IOException { if ( pin . isPresent ( ) ) { this . pushServiceSocket . setPin ( pin . get ( ) ) ; } else { this . pushServiceSocket . removePin ( ) ; } } public void verifyAccountWithCode ( String verificationCode , String signalingKey , int signalProtocolRegistrationId , boolean fetchesMessages , String pin ) fetchesMessages , pin ) ; public void setAccountAttributes ( String signalingKey , int signalProtocolRegistrationId , boolean fetchesMessages , String pin ) this . pushServiceSocket . setAccountAttributes ( signalingKey , signalProtocolRegistrationId , fetchesMessages , pin ) ;", "del_tokens": "import org . whispersystems . signalservice . api . crypto . ProfileCipherInputStream ; import org . whispersystems . signalservice . internal . crypto . PaddingInputStream ; import org . whispersystems . signalservice . internal . configuration . SignalServiceUrl ; import java . io . InputStream ; public void verifyAccountWithCode ( String verificationCode , String signalingKey , int signalProtocolRegistrationId , boolean fetchesMessages ) fetchesMessages ) ; public void setAccountAttributes ( String signalingKey , int signalProtocolRegistrationId , boolean fetchesMessages ) this . pushServiceSocket . setAccountAttributes ( signalingKey , signalProtocolRegistrationId , fetchesMessages ) ; public String getAccountVerificationToken ( ) throws IOException { return this . pushServiceSocket . getAccountVerificationToken ( ) ; }", "commit_type": "add"}
{"commit_tokens": ["Fix", "a", "bug", "in", "HTTP", "header", "parsing", "due", "to", "misnamed", "HttpString", "constructor"], "add_tokens": "// this HttpString ctor has misleading variable names - // it's a copy from/to, not offset/length HttpString httpString = new HttpString ( keyBytes , 5 , keyBytes . length ) ; public IRubyObject op_aset ( ThreadContext context , IRubyObject key , IRubyObject value ) { fillKey ( key ) ; return super . op_aset ( context , key , value ) ; } @ Override", "del_tokens": "HttpString httpString = new HttpString ( keyBytes , 5 , keyBytes . length - 5 ) ; public IRubyObject op_aset ( ThreadContext context , IRubyObject key , IRubyObject value ) { fillEntireHash ( ) ; return super . op_aset ( context , key , value ) ; } @ Override", "commit_type": "fix"}
{"commit_tokens": ["Add", "support", "for", "named", "back", "-", "references", "(", "REGEX", "-", "11", ")"], "add_tokens": "NamedPattern p = NamedPattern . compile ( \"(a)(b)(?:c)(?<named>x)\" ) ; assertTrue ( p . equals ( p ) ) ; @ Test public void testCompileWithBackrefGetsStandardPatternWithCorrectGroupIndex ( ) { NamedPattern p = NamedPattern . compile ( \"(?<foo>xyz)(?<bar>\\\\d+)abc\\\\k<bar>\" ) ; assertEquals ( \"(xyz)(\\\\d+)abc\\\\2\" , p . standardPattern ( ) ) ; } @ Test public void testCompileWithUnknownBackref ( ) { thrown . expect ( PatternSyntaxException . class ) ; thrown . expectMessage ( \"unknown group name near index 11\\n\" + \"(xyz)abc\\\\k<bar>\\n\" + \" ^\" ) ; NamedPattern . compile ( \"(?<foo>xyz)abc\\\\k<bar>\" ) ; } @ Test public void testCompileWithEscapedBackref ( ) { // escaped backrefs are not translated NamedPattern p = NamedPattern . compile ( \"(?<foo>xyz)(?<bar>\\\\d+)abc\\\\\\\\k<bar>\" ) ; assertEquals ( \"(xyz)(\\\\d+)abc\\\\\\\\k<bar>\" , p . standardPattern ( ) ) ; }", "del_tokens": "NamedPattern p1 = NamedPattern . compile ( \"(a)(b)(?:c)(?<named>x)\" ) ; assertTrue ( p1 . equals ( p1 ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "SketchHex", "conform", "to", "AutoParcel"], "add_tokens": "* { @ link com . punchthrough . bean . sdk . message . SketchHex # sketchName ( ) } . if ( hex . bytes ( ) . length > 0 ) {", "del_tokens": "* { @ link com . punchthrough . bean . sdk . message . SketchHex # getSketchName ( ) } . if ( hex . getBytes ( ) . length > 0 ) {", "commit_type": "make"}
{"commit_tokens": ["Fixed", "some", "tests", "related", "to", "inklecate", "compile", "errors", "."], "add_tokens": "Assert . assertEquals ( \"The value is 7.0.\" , text . get ( 0 ) ) ;", "del_tokens": "Assert . assertEquals ( \"The value is 7.\" , text . get ( 0 ) ) ;", "commit_type": "fix"}
{"commit_tokens": ["Remove", "experimental", "stuff", ".", "Let", "s", "wait", "for", "LZ4", "framing", "format", "..."], "add_tokens": "LZ4JavaSafeCompressor . HIGH_COMPRESSION LZ4JavaSafeUncompressor . INSTANCE", "del_tokens": "import java . io . IOException ; import java . io . InputStream ; LZ4JavaSafeCompressor . HIGH_COMPRESSION , new LZ4StreamCompressor ( LZ4JavaSafeCompressor . FAST ) , new LZ4StreamCompressor ( LZ4JavaUnsafeCompressor . FAST ) LZ4JavaSafeUncompressor . INSTANCE , new LZ4StreamUncompressor ( ) { @ Override protected InputStream lz4InputStream ( InputStream is ) throws IOException { return new LZ4JavaSafeInputStream ( is ) ; } } , new LZ4StreamUncompressor ( ) { @ Override protected InputStream lz4InputStream ( InputStream is ) throws IOException { return new LZ4JavaUnsafeInputStream ( is ) ; } }", "commit_type": "remove"}
{"commit_tokens": ["added", "write", "file", "for", "Windows", "RemoteConnection"], "add_tokens": "//TODO: check why the Overthere encoding doesn't work for Windows and Linux! //int exitCode = this.overthereConnection.execute(CmdLine.build().addRaw(command)); //TODO: check again if windows wrtieFile works or build a switch case instead switch ( ( OperatingSystemFamily ) this . overthereConnection . getOptions ( ) . get ( ConnectionOptions . OPERATING_SYSTEM ) ) { case WINDOWS : return this . writeFileToWindows ( pathAndFilename , content ) ; case UNIX : return this . writeFileToUnix ( pathAndFilename , content , setExecutable ) ; default : throw new UnsupportedOperationException ( \"Execution of RemoteConnection.writeFile to given OSFamily (\" + ConnectionOptions . OPERATING_SYSTEM . toString ( ) + \") not supported.\" ) ; } } private int writeFileToUnix ( String pathAndFilename , String content , boolean setExecutable ) { private int writeFileToWindows ( String pathAndFilename , String content ) { String powershellContent = content . replaceAll ( System . getProperty ( \"line.separator\" ) , \"$( [System.Environment]::NewLine )\" ) ; //System.out.println(powershellContent); //return 0; //TODO: replace \\n with powershell newlines int returnCode = this . executeWindwosCommand ( \"powershell -command New-Item \" + pathAndFilename + \" -type file -force -value \\\"\" + powershellContent + \"\\\"\" ) ; return returnCode ; }", "del_tokens": "", "commit_type": "add"}
{"commit_tokens": ["Remove", "explicit", "cancel", "in", "watch", "no", "longer", "necessary", "as", "we", "now", "actually", "get", "the", "response", "(", "wasnt", "samba", "s"], "add_tokens": "this . handle . close ( 0L ) ;", "del_tokens": "import java . util . concurrent . atomic . AtomicReference ; private AtomicReference < CommonServerMessageBlockRequest > lastRequest = new AtomicReference < > ( ) ; this . lastRequest . set ( req ) ; finally { this . lastRequest . set ( null ) ; } try { CommonServerMessageBlockRequest lastReq = this . lastRequest . getAndSet ( null ) ; if ( lastReq != null && ! lastReq . getResponse ( ) . isReceived ( ) ) { CommonServerMessageBlockRequest cancel = lastReq . createCancel ( ) ; if ( cancel != null ) { try ( SmbTreeHandleImpl th = this . handle . getTree ( ) ) { th . send ( cancel , null ) ; } catch ( SmbException e ) { log . debug ( \"Cancel failed\" , e ) ; } } } } finally { this . handle . close ( 0L ) ; }", "commit_type": "remove"}
{"commit_tokens": ["Fix", "compilation", "errors", "in", "tests", ":", "gradle", "build", "passes"], "add_tokens": "* to the { @ link ServiceCallback # failure ( Throwable ) } if a property fails the validation .", "del_tokens": "* to the { @ link ServiceCallback # failure ( ServiceException ) } if a property fails the validation .", "commit_type": "fix"}
{"commit_tokens": ["Fix", "the", "issue", "for", "unlimited", "loop", "when", "loading", "broken", "data", "set", "and", "DOME"], "add_tokens": "} return ! rules . isEmpty ( ) ;", "del_tokens": "} if ( rules . size ( ) == 0 ) { return false ; } else { return true ; }", "commit_type": "fix"}
{"commit_tokens": ["Adds", "test", "for", "matching", "multiple", "matrix", "params", "in", "the", "same", "path", "."], "add_tokens": "String [ ] matrixParamParts = ppParts [ 1 ] . split ( \"=\" , 2 ) ;", "del_tokens": "String [ ] matrixParamParts = ppParts [ 1 ] . split ( \"=\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Remove", "old", "requests", "for", "MW1_09"], "add_tokens": "log . trace ( s ) ; // TODO do not use pattern matching return new RequestBuilder1x15 ( ) ; private static class RequestBuilder1x15 implements RequestBuilder {", "del_tokens": "return new RequestBuilder1x11 ( ) ; private static class RequestBuilder1x11 implements RequestBuilder { /** request builder for MW versions 1_09 and 1_10. */ private static class RequestBuilder1x09 implements RequestBuilder { / * * * { @ inheritDoc } * / public String buildInitialRequest ( String articleName , RedirectFilter redirectFilter , int [ ] namespace ) { return MediaWiki . URL_API + \"?action=query&list=backlinks\" + \"&titles=\" + MediaWiki . encode ( articleName ) + ( ( namespace != null && MWAction . createNsString ( namespace ) . length ( ) != 0 ) ? ( \"&blnamespace=\" + MediaWiki . encode ( MWAction . createNsString ( namespace ) ) ) : \"\" ) + \"&blfilterredir=\" + MediaWiki . encode ( redirectFilter . toString ( ) ) + \"&bllimit=\" + LIMIT + \"&format=xml\" ; } / * * * { @ inheritDoc } * / public String buildContinueRequest ( String articleName , String blcontinue ) { return MediaWiki . URL_API + \"?action=query&list=backlinks\" + \"&blcontinue=\" + MediaWiki . encode ( blcontinue ) + \"&bllimit=\" + LIMIT + \"&format=xml\" ; } }", "commit_type": "remove"}
{"commit_tokens": ["Make", "constant", "for", "429", "status"], "add_tokens": "private static final int STATUS_TOO_MANY_REQUESTS = 429 ; response . setStatus ( STATUS_TOO_MANY_REQUESTS ) ;", "del_tokens": "response . setStatus ( 429 ) ;", "commit_type": "make"}
{"commit_tokens": ["fix", "template", "class", "naming", "issue"], "add_tokens": "protected static final String TOKEN_CLASS_SUFFIX = \"Template\" ; + Grammars2JavaSourceCode . class . getSimpleName ( ) + TOKEN_CLASS_SUFFIX ; + Grammars2JavaSourceCode . class . getSimpleName ( ) + TOKEN_CLASS_SUFFIX ;", "del_tokens": "+ Grammars2JavaSourceCode . class . getSimpleName ( ) ; + Grammars2JavaSourceCode . class . getSimpleName ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "dedicated", "Exception", "class", "for", "the", "Unauthorized", "status", "code", "."], "add_tokens": "* An exception that 's thrown when a response was not handled by an {@link IResponseHandler}. else if ( status == HttpStatus . UNAUTHORIZED ) { throw new UnauthorizedError ( message ) ; }", "del_tokens": "* An exception that 's thrown when a reponse was not handled by an {@link IResponseHandler}.", "commit_type": "add"}
{"commit_tokens": ["Fix", "failing", "ZuulFilter", "unit", "test"], "add_tokens": "import static org . junit . Assert . assertSame ; assertSame ( f2 , list . get ( 0 ) ) ;", "del_tokens": "import static org . junit . Assert . assertTrue ; assertTrue ( list . get ( 0 ) == f1 ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "middle", "property", "to", "Invert", "module"], "add_tokens": "public static final double DEFAULT_MIDDLE = 0.0 ; private double middle = DEFAULT_MIDDLE ; public double getMiddle ( ) { return middle ; } public void setMiddle ( double middle ) { this . middle = middle ; } @ Override return middle - sourceModule [ 0 ] . getValue ( x , y , z ) ;", "del_tokens": "@ Override return - sourceModule [ 0 ] . getValue ( x , y , z ) ;", "commit_type": "add"}
{"commit_tokens": ["add", "rudimentary", "support", "for", "printing", "labels", "on", "a", "GraphViz", "graph", "from", "StateMachineConfig"], "add_tokens": "public class StateMachineConfig < TState , TTrigger > { * < p > return stateConfiguration . get ( state ) ; generateDotFileInto ( dotFile , false ) ; } public void generateDotFileInto ( final OutputStream dotFile , boolean printLabels ) throws IOException { if ( printLabels ) { writer . write ( String . format ( \"\\t%s -> %s [label = \\\"%s\\\" ];\\n\" , entry . getKey ( ) , destination , triggerBehaviour . getTrigger ( ) ) ) ; } else { writer . write ( String . format ( \"\\t%s -> %s;\\n\" , entry . getKey ( ) , destination ) ) ; }", "del_tokens": "public class StateMachineConfig < TState , TTrigger > { * return stateConfiguration . get ( state ) ; writer . write ( String . format ( \"\\t%s -> %s;\\n\" , entry . getKey ( ) , destination ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Added", "target", "attribute", "to", "a", "tag", "."], "add_tokens": "* Copyright ( C ) 2009 , 2010 , 2011 , 2012 , 2013 AO Industries , Inc . new PropertyDescriptor ( \"target\" , ATag . class ) ,", "del_tokens": "* Copyright ( C ) 2009 , 2010 , 2011 , 2012 AO Industries , Inc .", "commit_type": "add"}
{"commit_tokens": ["Fix", "unnecessary", "use", "of", "fully", "qualified", "name", "in", "ValidationErrorMessage"], "add_tokens": "* Copyright 2014 - 2016 Jakub Jirutka < jakub @ jirutka . cz > . @ JsonInclude ( NON_EMPTY ) //for Jackson 2.x", "del_tokens": "* Copyright 2014 Jakub Jirutka < jakub @ jirutka . cz > . import com . fasterxml . jackson . annotation . JsonInclude . Include ; @ JsonInclude ( Include . NON_EMPTY ) //for Jackson 2.x", "commit_type": "fix"}
{"commit_tokens": ["Removed", "need", "to", "use", "PRODUCTIOn", "stage", "in", "guice", "to", "make", "jmxutils", "work"], "add_tokens": "bind ( GuiceMBeanExporter . class ) . asEagerSingleton ( ) ;", "del_tokens": "import static com . google . inject . Scopes . SINGLETON ; bind ( GuiceMBeanExporter . class ) . in ( SINGLETON ) ;", "commit_type": "remove"}
{"commit_tokens": ["Remove", "@JsonIgnore", "from", "URL", "so", "JSON", "-", ">", "Java", "Java", "-", ">", "JSON", "produces", "the"], "add_tokens": "// @JsonIgnore", "del_tokens": "@ JsonIgnore", "commit_type": "remove"}
{"commit_tokens": ["fix", "token", "null", "and", "add", "lucene", "6", "support"], "add_tokens": "if ( reader == null ) { tokenizer = new AnsjTokenizer ( new IndexAnalysis ( ) , filter ) ; } else { tokenizer = new AnsjTokenizer ( new IndexAnalysis ( reader ) , filter ) ; } if ( reader == null ) { tokenizer = new AnsjTokenizer ( new DicAnalysis ( ) , filter ) ; } else { tokenizer = new AnsjTokenizer ( new DicAnalysis ( reader ) , filter ) ; } if ( reader == null ) { tokenizer = new AnsjTokenizer ( new ToAnalysis ( ) , filter ) ; } else { tokenizer = new AnsjTokenizer ( new ToAnalysis ( reader ) , filter ) ; } if ( reader == null ) { tokenizer = new AnsjTokenizer ( new ToAnalysis ( ) , filter ) ; } else { tokenizer = new AnsjTokenizer ( new ToAnalysis ( reader ) , filter ) ; }", "del_tokens": "tokenizer = new AnsjTokenizer ( new IndexAnalysis ( reader ) , filter ) ; tokenizer = new AnsjTokenizer ( new DicAnalysis ( reader ) , filter ) ; tokenizer = new AnsjTokenizer ( new ToAnalysis ( reader ) , filter ) ; tokenizer = new AnsjTokenizer ( new ToAnalysis ( reader ) , filter ) ;", "commit_type": "fix"}
{"commit_tokens": ["Fix", "showConfiguration", "for", "project", "/", "version"], "add_tokens": "+ \" (String) thrownException = <Failed to read property: \" + \"Getter threw an exception!>\\n\" + \" (String) zz = HELLO\\n\"", "del_tokens": "+ \" (String) zz = hello\\n\"", "commit_type": "fix"}
{"commit_tokens": ["Added", "configuration", "for", "basic", "auth", "for", "ES_HTTP", "dispatcher"], "add_tokens": "import com . google . common . base . Strings ; HttpClientConfig . Builder config = new HttpClientConfig . multiThreaded ( false ) ; if ( ! Strings . isNullOrEmpty ( extension . getEsBasicAuthUsername ( ) ) ) { config . defaultCredentials ( extension . getEsBasicAuthUsername ( ) , extension . getEsBasicAuthPassword ( ) ) ; } factory . setHttpClientConfig ( config . build ( ) ) ;", "del_tokens": "factory . setHttpClientConfig ( new HttpClientConfig . multiThreaded ( false ) . build ( ) ) ;", "commit_type": "add"}
{"commit_tokens": ["use", "account", "system", "in", "tests", "not", "leanix"], "add_tokens": "private static final String ACCOUNT_NAME = \"system\" ; private static String CONTRACT_DISPLAY_NAME = System . getProperty ( \"contract.displayname\" , ACCOUNT_NAME + \" eam REGULAR\" ) ;", "del_tokens": "private static final String ACCOUNT_NAME = \"leanix\" ; private static String CONTRACT_DISPLAY_NAME = System . getProperty ( \"contract.displayname\" , \"leanix eam REGULAR\" ) ;", "commit_type": "use"}
{"commit_tokens": ["fixed", "gson", "parsing", "with", "parameterized", "types"], "add_tokens": "import static org . junit . Assert . assertTrue ; import com . maestrano . net . MnoApiAccountClient ; Map < String , Object > attrsMap = new HashMap < String , Object > ( ) ; attrsMap . put ( \"groupId\" , \"cld-3\" ) ; attrsMap . put ( \"priceCents\" , 2000 ) ; attrsMap . put ( \"description\" , \"Product purchase\" ) ; MnoBill bill = MnoBill . create ( attrsMap ) ; assertTrue ( bill . cancel ( ) ) ; assertEquals ( \"cancelled\" , bill . getStatus ( ) ) ;", "del_tokens": "import java . util . ArrayList ;", "commit_type": "fix"}
{"commit_tokens": ["Add", "#expect", "for", "booleans", "and", "functions", "that", "returns", "a", "boolean", "value"], "add_tokens": "the ( function ) . accept ( value ) ;", "del_tokens": "import static tools . devnull . kodo . Expectation . performing ; performing ( function ) . accept ( value ) ;", "commit_type": "add"}
{"commit_tokens": ["Move", "interfaces", "to", "standalone", "class"], "add_tokens": "ra ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ) . eachSlice ( 3 , ( l ) -> { System . out . println ( l ) ; } ) ;", "del_tokens": "System . out . println ( rh ( \"a\" , 1 , \"b\" , 2 ) . chunk ( ( k , v ) -> { return k + k ; } ) ) ;", "commit_type": "move"}
{"commit_tokens": ["Improve", "exception", "handling", "for", "source", "attribute", "in", "ConnectionManagerForTests", "."], "add_tokens": "import org . junit . Assert ; public void testSourceAttributeMissing ( ) { try { Player player1 = new Player ( ) ; player1 . setId ( 100 ) ; player1 . insert ( ) ; } catch ( Exception e ) { Assert . assertTrue ( e instanceof NullPointerException ) ; Assert . assertEquals ( \"sourceAttribute expected for class: 'com.gs.fw.common.mithra.test.domain.Player', please ensure operation or new object correctly specifies the sourceAttribute!\" , e . getMessage ( ) ) ; } try { Player player2 = new Player ( ) ; player2 . setId ( 100 ) ; player2 . setSourceId ( \"NewSource\" ) ; player2 . insert ( ) ; } catch ( Exception e ) { Assert . assertTrue ( e instanceof NullPointerException ) ; Assert . assertEquals ( \"Could not find connection for class com.gs.fw.common.mithra.test.domain.Player Make sure the class is added to the test xml file. Double check that it's added to the correct connection mananger. If the object has a source attribute, also ensure that the operation correctly specifies a value for it. No connection manager found. for database: NewSource\" , e . getMessage ( ) ) ; } }", "del_tokens": "", "commit_type": "improve"}
{"commit_tokens": ["Fix", "bug", "where", "SequentialEvent", "was", "waiting", "timeoutx2", "before", "timing", "out"], "add_tokens": "long startTimeMillis = now ( ) ; long timePassedMillis = now ( ) - startTimeMillis ; return additional . waitUpTo ( TimeUnit . MILLISECONDS . convert ( timeout , unit ) - timePassedMillis , TimeUnit . MILLISECONDS ) ; private long now ( ) { return System . currentTimeMillis ( ) ; }", "del_tokens": "// TODO: This waits for up to timeout x2 total... is this appropriate? return additional . waitUpTo ( timeout , unit ) ;", "commit_type": "fix"}
{"commit_tokens": ["Created", "UrlProtocolHandler", "and", "two", "default", "implementations", "discovered"], "add_tokens": "}", "del_tokens": "0 }", "commit_type": "create"}
{"commit_tokens": ["fixed", "class", "loading", "issue", "on", "Windows"], "add_tokens": "final String replacedSeparators = fileName . replace ( File . separatorChar , '.' ) ;", "del_tokens": "final String replacedSeparators = fileName . replace ( '/' , '.' ) ;", "commit_type": "fix"}
{"commit_tokens": ["Added", "title", "support", "to", "code", "macro", "and", "unit", "test", "."], "add_tokens": "private String outerStart ; private String innerStart ; private String titleStart ; private String titleEnd ; outerStart = outputMessages . getString ( getLocaleKey ( ) + \".outer.start\" ) ; innerStart = outputMessages . getString ( getLocaleKey ( ) + \".inner.start\" ) ; titleStart = outputMessages . getString ( getLocaleKey ( ) + \".title.start\" ) ; titleEnd = outputMessages . getString ( getLocaleKey ( ) + \".title.end\" ) ; writer . write ( outerStart ) ; if ( params . get ( \"title\" ) != null ) { writer . write ( titleStart ) ; writer . write ( params . get ( \"title\" ) ) ; writer . write ( titleEnd ) ; } writer . write ( innerStart ) ;", "del_tokens": "private String start ; start = outputMessages . getString ( getLocaleKey ( ) + \".start\" ) ; writer . write ( start ) ;", "commit_type": "add"}
{"commit_tokens": ["Make", "Verify", "task", "compatible", "to", "Gradle", "1", ".", "x"], "add_tokens": "private String toHex ( byte [ ] barr ) { StringBuffer result = new StringBuffer ( ) ; for ( byte b : barr ) { result . append ( String . format ( \"%02X\" , b ) ) ; } return result . toString ( ) ; } calculatedChecksum = toHex ( md . digest ( ) ) ;", "del_tokens": "import org . apache . commons . codec . binary . Hex ; calculatedChecksum = Hex . encodeHexString ( md . digest ( ) ) ;", "commit_type": "make"}
{"commit_tokens": ["adding", "some", "new", "utilities", "to", "the", "clipboard", "management", "and", "regexp"], "add_tokens": "Pattern . compile ( \"(?:(?:ht|f)tp(?:s?)\\\\:\\\\/\\\\/|~/|/)?(?:\\\\w+:\\\\w+@)?(?:(?:[-\\\\w]+\\\\.)+(?:com|org|net|gov|mil|biz|info|mobi|name|aero|jobs|museum|travel|[a-z]{2}))(?::[\\\\d]{1,5})?(?:(?:(?:/(?:[-\\\\w~!$+|.,=]|%[a-f\\\\d]{2})+)+|/)+|\\\\?|#)?(?:(?:\\\\?(?:[-\\\\w~!$+|.,*:]|%[a-f\\\\d{2}])+=(?:[-\\\\w~!$+|.,*:=]|%[a-f\\\\d]{2})*)(?:&(?:[-\\\\w~!$+|.,*:]|%[a-f\\\\d{2}])+=(?:[-\\\\w~!$+|.,*:=]|%[a-f\\\\d]{2})*)*)*(?:#(?:[-\\\\w~!$+|.,*:=]|%[a-f\\\\d]{2})*)?\" ) ;", "del_tokens": "Pattern . compile ( \"^(?:(?:ht|f)tp(?:s?)\\\\:\\\\/\\\\/|~/|/)?(?:\\\\w+:\\\\w+@)?(?:(?:[-\\\\w]+\\\\.)+(?:com|org|net|gov|mil|biz|info|mobi|name|aero|jobs|museum|travel|[a-z]{2}))(?::[\\\\d]{1,5})?(?:(?:(?:/(?:[-\\\\w~!$+|.,=]|%[a-f\\\\d]{2})+)+|/)+|\\\\?|#)?(?:(?:\\\\?(?:[-\\\\w~!$+|.,*:]|%[a-f\\\\d{2}])+=(?:[-\\\\w~!$+|.,*:=]|%[a-f\\\\d]{2})*)(?:&(?:[-\\\\w~!$+|.,*:]|%[a-f\\\\d{2}])+=(?:[-\\\\w~!$+|.,*:=]|%[a-f\\\\d]{2})*)*)*(?:#(?:[-\\\\w~!$+|.,*:=]|%[a-f\\\\d]{2})*)?$\" ) ;", "commit_type": "add"}
{"commit_tokens": ["Changed", "API", ":", "Removed", "DisplayImageOptions", ".", "transform", "()"], "add_tokens": "bmp = decoder . decode ( imageLoadingInfo . targetSize , imageLoadingInfo . options . getImageScaleType ( ) , imageLoadingInfo . imageView . getScaleType ( ) ) ; result = decoder . decode ( imageLoadingInfo . targetSize , imageLoadingInfo . options . getImageScaleType ( ) , imageLoadingInfo . imageView . getScaleType ( ) ) ;", "del_tokens": "bmp = decoder . decode ( imageLoadingInfo . targetSize , imageLoadingInfo . options . getImageScaleType ( ) , imageLoadingInfo . imageView . getScaleType ( ) , imageLoadingInfo . options . getTransformationMatrix ( ) ) ; result = decoder . decode ( imageLoadingInfo . targetSize , imageLoadingInfo . options . getImageScaleType ( ) , imageLoadingInfo . imageView . getScaleType ( ) , imageLoadingInfo . options . getTransformationMatrix ( ) ) ;", "commit_type": "change"}
{"commit_tokens": ["Updated", "javadoc", "for", "aeSyntacticVariantGatherer", "()"], "add_tokens": "* Gathers terms according to their syntactic structures .", "del_tokens": "* Gathers terms syntactically .", "commit_type": "update"}
{"commit_tokens": ["Fix", "Potential", "NPE", "when", "Response", "has", "no", "content"], "add_tokens": "if ( cache != null ) { final byte [ ] bytes = cache . toByteArray ( ) ; if ( bytes . length > maxDumpSizeInB ) { body = new StringBuilder ( new String ( bytes , 0 , maxDumpSizeInB ) ) . append ( \"\\n-- \" ) . append ( bytes . length - maxDumpSizeInB ) . append ( \" more bytes skipped from dump by max dump size limit\" ) . toString ( ) ; } else { body = new String ( bytes , 0 , bytes . length ) ; }", "del_tokens": "final byte [ ] bytes = cache . toByteArray ( ) ; if ( bytes . length > maxDumpSizeInB ) { body = new StringBuilder ( new String ( bytes , 0 , maxDumpSizeInB ) ) . append ( \"\\n-- \" ) . append ( bytes . length - maxDumpSizeInB ) . append ( \" more bytes skipped from dump by max dump size limit\" ) . toString ( ) ; } else { body = new String ( bytes , 0 , bytes . length ) ;", "commit_type": "fix"}
{"commit_tokens": ["added", "group", "node", "to", "C3D", "list", "view"], "add_tokens": "group . getChildren ( ) . clear ( ) ; group . getChildren ( ) . add ( ( ( C3DListView < ? > ) item ) . getGroupnode ( ) ) ;", "del_tokens": "group . getChildren ( ) . clear ( ) ; group . getChildren ( ) . add ( new Label ( \"Title\" ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Fixing", "an", "exception", "message", "."], "add_tokens": "MESSAGE_MAP . put ( \"432000\" , \"432000: Error calling git-reset.\" ) ;", "del_tokens": "MESSAGE_MAP . put ( \"432000\" , \"432000: Error calling git-commit.\" ) ;", "commit_type": "fix"}
{"commit_tokens": ["Updated", "webbrowser", "to", "remove", "redundant", "check"], "add_tokens": "if ( cnx instanceof HttpURLConnection ) {", "del_tokens": "if ( cnx != null && cnx instanceof HttpURLConnection ) {", "commit_type": "update"}
{"commit_tokens": ["Changed", "PLUGIN_KEY", "const", "to", "new", "coordinates", "."], "add_tokens": "public static final String PLUGIN_KEY = \"org.whitesource:whitesource-maven-plugin\" ;", "del_tokens": "public static final String PLUGIN_KEY = \"com.wss:whitesource-maven-plugin\" ;", "commit_type": "change"}
{"commit_tokens": ["Adding", "context", "may", "be", "customized"], "add_tokens": "protected ServletContextHandlerBuilder addContext ( String contextPath ) {", "del_tokens": "private ServletContextHandlerBuilder addContext ( String contextPath ) {", "commit_type": "add"}
{"commit_tokens": ["fixed", "NPE", "thrown", "when", "the", "user", "had", "no", "avatar"], "add_tokens": "import com . google . gson . JsonObject ; JsonElement avatar = contactInfo . getAsJsonObject ( ) . getAsJsonObject ( ENTRY ) . get ( THUMBNAIL_URL ) ; if ( avatar != null ) { user . avatarUrl = avatar . getAsString ( ) ; }", "del_tokens": "user . avatarUrl = contactInfo . getAsJsonObject ( ) . getAsJsonObject ( ENTRY ) . get ( THUMBNAIL_URL ) . getAsString ( ) ;", "commit_type": "fix"}
{"commit_tokens": ["fixed", "bug", "of", "MaskWriteRegisterResponse", "validation", "."], "add_tokens": "( r . getMaskAnd ( ) == getMaskAnd ( ) ) &&", "del_tokens": "( r . getMaskAnd ( ) != getMaskAnd ( ) ) &&", "commit_type": "fix"}
{"commit_tokens": ["Implemented", "select", "(", "query", "query", "query", ")", "or", "group", "selector", "."], "add_tokens": "import java . util . LinkedHashSet ; private final LinkedHashSet < Element > elements ; // LHS for unique and ordered elements this . elements = new LinkedHashSet < Element > ( ) ; } else if ( tq . matchChomp ( \",\" ) ) { groupOr ( ) ; return new ElementList ( elements ) ; } private void groupOr ( ) { // no-op; just append uniques", "del_tokens": "private final ElementList elements ; this . elements = new ElementList ( ) ; return elements ;", "commit_type": "implement"}
{"commit_tokens": ["add", "failure", "response", "doc", "for", "unit", "validateAccessToken"], "add_tokens": "} } ) ) . addFailedUnitResponse ( UnitResponse . createError ( OAuthService . CODE_BAD_TOKEN , null , null ) ) ;", "del_tokens": "} } ) ) ;", "commit_type": "add"}
{"commit_tokens": ["Add", "posibility", "to", "generate", "classes", "by", "JAXB"], "add_tokens": "public class TestSuiteFinishedEvent extends AbstractTestSuiteFinishedEvent { setUid ( uid ) ;", "del_tokens": "public class TestSuiteFinishedEvent implements TestSuiteEvent { private String uid ; this . uid = uid ; @ Override public String getUid ( ) { return uid ; } public void setUid ( String uid ) { this . uid = uid ; }", "commit_type": "add"}
{"commit_tokens": ["Add", "method", "to", "add", "latency", "to", "slot"], "add_tokens": "public void recordLatency ( long duration ) { recorder . recordValue ( duration ) ; }", "del_tokens": "import org . HdrHistogram . SynchronizedHistogram ;", "commit_type": "add"}
{"commit_tokens": ["Fix", "delete", "all", "from", "iterable", "performance", "gap", "273"], "add_tokens": "import java . util . stream . StreamSupport ; StreamSupport . stream ( entities . spliterator ( ) , true ) . forEach ( this :: delete ) ;", "del_tokens": "entities . forEach ( this :: delete ) ;", "commit_type": "fix"}
